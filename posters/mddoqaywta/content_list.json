[{"type": "text", "text": "A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jungyhun Lee, Se-Young Yun Kim Jaechul Graduate School of AI KAIST Seoul, Republic of Korea {jh_lee00, yunseyoung}@kaist.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Kwang-Sung Jun   \nDepartment of Computer Science   \nUniversity of Arizona   \nTucson, AZ, USA   \nkjun@cs.arizona.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present a unified likelihood ratio-based confidence sequence (CS) for any (selfconcordant) generalized linear model (GLM) that is guaranteed to be convex and numerically tight. We show that this is on par or improves upon known CSs for various GLMs, including Gaussian, Bernoulli, and Poisson. In particular, for the first time, our CS for Bernoulli has a $\\mathrm{poly}(S)$ -free radius where $S$ is the norm of the unknown parameter. Our first technical novelty is its derivation, which utilizes a time-uniform PAC-Bayesian bound with a uniform prior/posterior, despite the latter being a rather unpopular choice for deriving CSs. As a direct application of our new CS, we propose a simple and natural optimistic algorithm called OFUGLB, applicable to any generalized linear bandits (GLB; Filippi et al. (2010)). Our analysis shows that the celebrated optimistic approach simultaneously attains stateof-the-art regrets for various self-concordant (not necessarily bounded) GLBs, and even $\\mathrm{poly}(S)$ -free for bounded GLBs, including logistic bandits. The regret analysis, our second technical novelty, follows from combining our new CS with a new proof technique that completely avoids the previously widely used selfconcordant control lemma (Faury et al., 2020, Lemma 9). Numerically, OFUGLB outperforms or is at par with prior algorithms for logistic bandits. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "One paramount task in statistics and machine learning is to estimate the uncertainty of the underlying model from (possibly noisy) observations. For example, in interactive machine learning scenarios such as bandits (Lattimore and Szepesv\u00e1ri, 2020; Robbins, 1952; Thompson, 1933) and recently reinforcement learning with human feedback (RLHF; Christiano et al. (2017); Ouyang et al. (2022)), at each time step $t$ , the learner chooses an action $\\pmb{x}_{t}$ from an available set of actions $\\textstyle{\\mathcal{X}}_{t}$ and observes reward or outcome $r_{t}$ that is modeled as a distribution whose mean is an unknown function $f^{*}$ of $\\pmb{x}_{t}$ ; i.e., $r_{t}\\sim p(\\cdot|\\pmb{x}_{t};f^{*})$ . One popular choice of such a model is the generalized linear model (GLM; McCullagh and Nelder (1989)) that extends exponential family distributions to have a linear structure in its natural parameter as $\\langle x,\\theta_{\\star}\\rangle$ , where $\\theta_{\\star}$ is an unknown parameter. In other words, the mean function is $f^{\\star}({\\pmb x})=\\mu(\\langle{\\pmb x},\\dot{\\pmb\\theta}_{\\star}\\rangle)$ for some inverse link function $\\mu$ . This encompasses a wide range of distributions, which in turn makes it ubiquitous in various real-world applications, such as news recommendations (Bernoulli; Li et al. (2010, 2012)), social network influence maximization (Poisson; Gisselbrecht et al. (2015); Lage et al. (2013)), and more. In such tasks, the learner must estimate the uncertainty about $\\theta_{\\star}$ at each time step $t\\geq1$ , given observations $\\{(\\pmb{x}_{s},r_{s})\\}_{s=1}^{t-1}$ , to make wise decisions. One popular and useful way to capture the uncertainty is via a time-uniform confidence sequence $(C S)$ $\\bar{\\{C_{t}\\}}(\\delta)\\}_{t=1}^{\\infty}$ , which takes the form of $\\mathbb{P}[\\exists t\\geq1:\\dot{\\theta}_{\\star}\\not\\in\\mathcal{C}_{t}(\\delta)]\\leq\\delta$ . Recently, CS has been described as one of the key components for safe anytime-valid inference (SAVI) that can ensure the validity/safeness of sequentially adaptive statistical inference (Ramdas et al., 2023). ", "page_idx": 0}, {"type": "text", "text": "Existing CSs for GLMs, however, are far from ideal. Much of the prior works focus on obtaining CS for specific instantiations of GLMs, such as Gaussian (Abbasi-Yadkori et al., 2011; Flynn et al., 2023) and Bernoulli (Abeille et al., 2021; Faury et al., 2020, 2022; Lee et al., 2024). Especially for Bernoulli, all the existing CSs suffer from poly $(S)$ factor in the radius, where $S$ is the norm of the unknown parameter $\\theta_{\\star}$ . Emmenegger et al. (2023); Jun et al. (2017); Li et al. (2017) proposed generic CSs that work for any convex GLMs, but their radii all suffer from a globally worst-case curvature of $\\mu$ , which is detrimental in many cases (e.g., for Bernoulli, it scales as $e^{S}$ ). ", "page_idx": 1}, {"type": "text", "text": "Contributions. First, we propose a unified construction of likelihood ratio-based CS for any convex GLMs (Theorem 3.1) and then instantiate it as an ellipsoidal CS for self-concordant GLMs, including Bernoulli, Gaussian, and Poisson distributions (Theorem 3.2). Notably, we keep track of all the constants so that any practitioner can directly implement it without trouble. The proof uses ingredients from time-uniform PAC-Bayesian bounds (Chugg et al., 2023) \u2013 martingale $^+$ DonskerVaradhan representation of $\\mathrm{KL+}$ Ville\u2019s inequality. The main technical novelty lies in using uniform prior/posterior for the analysis, inspired by various literature on portfolios (Blum and Kalai, 1999) and fast rates in statistical/online learning (Foster et al., 2018; Gr\u00fcnwald and Mehta, 2020; Hazan et al., 2007; van Erven et al., 2015). ", "page_idx": 1}, {"type": "text", "text": "Secondly, we apply our novel CSs to contextual generalized linear bandits (GLB; Filippi et al. (2010)) with changing (and adversarial) arm-sets, and propose a new algorithm called Optimism in the Face of Uncertainty for Generalized Linear Bandits (OFUGLB). OFUGLB employs the simple and standard optimistic approach, choosing an arm that maximizes the upper confidence bound (UCB) computed by our CS (Abbasi-Yadkori et al., 2011; Auer, 2002). We show that OFUGLB achieves the state-of-the-art regret bounds for self-concordant (possibly unbounded) GLB (Theorem 4.1). This is the first time a computationally tractable, purely optimistic strategy attains such $\\mathrm{poly}(S)$ -free regret for logistic bandits in that OFUGLB does not involve an explicit warmup phase and only involves convex optimization subroutines. Our other significant main technical contribution is the analysis of OFUGLB, as na\u00efvely applying existing analysis techniques for optimistic algorithms (Abeille et al., 2021; Lee et al., 2024) yields a regret bound whose leading term scales with $\\mathrm{poly}(S)$ . We identify the key reason for such additional dependency as the use of self-concordance control lemma (Faury et al., 2020, Lemma 9), and provide an alternate analysis that completely bypasses it, which may be of independent interest in the bandits community and beyond. ", "page_idx": 1}, {"type": "text", "text": "2 Problem Setting ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We consider the realizable (online) regression with the generalized linear model (GLM; McCullagh and Nelder (1989)) whose conditional probability measure of $r$ is given as ", "page_idx": 1}, {"type": "equation", "text": "$$\nd p(r|\\mathbf{\\boldsymbol{x}};\\pmb{\\theta}_{\\star})=\\exp\\left(\\frac{r\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle-m(\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle)}{g(\\tau)}+h(r,\\tau)\\right)d\\nu,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\tau$ is the dispersion parameter, and $\\nu$ is some known base measure (e.g., Lebesgue, counting). We assume the following: ", "page_idx": 1}, {"type": "text", "text": "Assumption 1. $\\pmb{\\theta}_{\\star}\\in\\Theta\\subseteq\\mathcal{B}^{d}(S):=\\{\\pmb{\\theta}\\in\\mathbb{R}^{d}:\\|\\pmb{\\theta}\\|_{2}\\leq S\\}$ for some known $S>0$ . Also, $\\Theta$ is nonempty, compact, and convex with intrinsic dimension1 $d$ . ", "page_idx": 1}, {"type": "text", "text": "Assumption 2. The domain $X$ for arm (context) $\\textbf{\\em x}$ satisfies $X\\subseteq B^{d}(1)$ ", "page_idx": 1}, {"type": "text", "text": "Assumption 3. m is three times differentiable and convex, i.e., $m^{\\prime\\prime\\prime}$ exists and $\\dot{\\mu}:=m^{\\prime\\prime}\\geq0$ . ", "page_idx": 1}, {"type": "text", "text": "In the generalized linear bandit (GLB) problem, at each time $t\\,\\in\\,[T]$ , the learner observes a time-varying, arbitrary (adversarial) arm-set $\\mathcal X_{t}\\subseteq\\ensuremath{\\boldsymbol{X}}$ , chooses a $\\mathbf{\\mathcal{x}}_{t}\\,\\in\\,\\mathcal{X}_{t}$ , and receives a reward $r_{t}\\,\\sim\\,p(\\bar{\\cdot}|\\pmb{x}_{t},\\pmb{\\theta}_{\\star})$ . Let $\\mathcal{X}_{[T]}\\,:=\\,\\cup_{t=1}^{T}\\mathcal{X}_{t}$ and $\\Sigma_{t+1}\\,:=\\,\\sigma(\\Sigma_{t},r_{t},\\mathbf{\\boldsymbol{x}}_{t+1})$ with $\\Sigma_{0}~=~\\sigma({\\pmb x}_{1})$ be the filtration in the canonical bandit model (Lattimore and Szepesv\u00e1ri, 2020, Chapter 4.6). From wellknown properties of GLMs (McCullagh and Nelder, 1989), we have that $\\mathbb{E}[r_{t}|\\Sigma_{t}]=m^{\\prime}(\\langle\\boldsymbol{x}_{t},\\boldsymbol{\\theta}_{\\star}\\rangle)\\triangleq$ $\\mu(\\langle\\mathbf{x}_{t},\\pmb{\\theta}_{\\star}\\rangle)$ and $\\mathrm{Var}[r_{t}|\\Sigma_{t}]=g(\\tau)\\dot{\\mu}\\big(\\langle\\mathbf{x}_{t},\\pmb{\\theta}_{\\star}\\rangle\\big)$ , where $\\mu$ is the inverse link function. We also define the following quantity describing the maximum slope of $\\mu:R_{\\dot{\\mu}}:=\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}_{[T]},\\pmb{\\theta}\\in\\Theta}\\dot{\\mu}\\big(\\langle\\pmb{x},\\pmb{\\theta}\\rangle\\big)$ . ", "page_idx": 1}, {"type": "text", "text": "Note that many common distributions, such as Gaussian $(\\mu(z)=z$ , $R_{\\dot{\\mu}}=1$ ), Poisson $(\\mu(z)=e^{z}$ , $R_{\\dot{\\mu}}=e^{S}$ ), and Bernoulli $(\\mu(z)=(1+e^{-z})^{-1}$ , $R_{\\dot{\\mu}}=1/4$ ), fall under the umbrella of GLM. ", "page_idx": 1}, {"type": "text", "text": "3 Unified Likelihood Ratio-based Confidence Sequence for GLMs ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The learner\u2019s goal is to output a time-uniform confidence sequence (CS) for $\\theta_{\\star}$ , $\\mathbb{P}[\\exists t\\geq1:\\pmb{\\theta}_{\\star}\\notin$ $\\mathcal{C}_{t}(\\delta)]\\,\\le\\,\\delta$ , where $\\mathbb{P}$ is w.r.t. the randomness of the confidence sets $\\mathcal{C}_{t}(\\delta)$ . In this work, we are particularly interested in the log-likelihood-based confidence set \u201ccentered\u201d at the norm-constrained, batch maximum likelihood estimator (MLE): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{C}_{t}(\\delta):=\\left\\{\\pmb{\\theta}\\in\\Theta:\\mathcal{L}_{t}(\\pmb{\\theta})-\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})\\leq\\beta_{t}(\\delta)^{2}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\beta_{t}(\\delta)^{2}$ is the \u201cradius\u201d of the CS that we will define later, $\\mathcal{L}_{t}(\\pmb{\\theta})$ is the negative log-likelihood of $\\pmb{\\theta}$ w.r.t. data collected up to $t-1$ , and $\\widehat{\\pmb{\\theta}}_{t}$ is the corresponding MLE: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{t}(\\pmb{\\theta}):=\\sum_{s=1}^{t-1}\\left\\{\\ell_{s}(\\pmb{\\theta})\\triangleq\\frac{-r_{s}\\langle\\pmb{x}_{s},\\pmb{\\theta}\\rangle+m(\\langle\\pmb{x}_{s},\\pmb{\\theta}\\rangle)}{g(\\tau)}\\right\\},\\quad\\widehat{\\pmb{\\theta}}_{t}:=\\underset{\\pmb{\\theta}\\in\\Theta}{\\arg\\operatorname*{min}}\\,\\mathcal{L}_{t}(\\pmb{\\theta}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Note that $h(r_{s},\\tau)$ is omitted as it plays no role in the confidence set nor the MLE. ", "page_idx": 2}, {"type": "text", "text": "The form of the confidence set is the same as Lee et al. (2024) and convex relaxation of Abeille et al. (2021), all of which utilizes a single, cumulative & constrained MLE $\\widehat{\\pmb{\\theta}}_{t}\\in\\Theta$ to compute the loss at time $t$ . Other approaches include using a single regularized MLE $\\widehat{\\pmb{\\theta}}_{t}$ that may lie outside of $\\Theta$ (Abbasi-Yadkori et al., 2011), using a sequence of MLEs $\\{\\widehat{\\pmb{\\theta}}_{s}\\}_{s=1}^{t}$ to compute the loss at time $t$ (Abbasi-Yadkori et al., 2012; Emmenegger et al., 2023; Faury et al., 2022; Jun et al., 2017; Wasserman et al., 2020), and computing the expected loss over some distribution (e.g., Gaussian) without committing to point estimators (Flynn et al., 2023). As one can see later, our derivation of the CS resembles the last approach: we also start from an expectation of loss over a prior distribution of $\\pmb{\\theta}$ without committing to an estimator. Yet, we introduce a single estimator $\\widehat{\\pmb{\\theta}}_{t}$ to avoid the computational difficulty of evaluating the expectation. ", "page_idx": 2}, {"type": "text", "text": "Our first main contribution is the following unified confidence sequence for any GLMs, regardless of whether it is bounded or not, as long as the corresponding log-likelihood loss is Lipschitz: ", "page_idx": 2}, {"type": "text", "text": "Theorem 3.1 (Unified CS for GLMs). Let $L_{t}:=\\operatorname*{max}_{\\pmb{\\theta}\\in\\Theta}\\left\\|\\nabla\\mathcal{L}_{t}(\\pmb{\\theta})\\right\\|_{2}$ be the Lipschitz   \nconstanta of $\\mathcal{L}_{t}(\\cdot)$ that may depend on $\\{(\\pmb{x}_{s},r_{s})\\}_{s=1}^{t-1}$ . Then, we have $\\mathbb{P}[\\exists t\\,\\geq\\,1\\,:\\,\\pmb{\\theta}_{\\star}\\,\\,\\notin$   \n$\\mathcal{C}_{t}(\\delta)]\\leq\\delta$ , where $\\beta_{t}(\\delta)^{2}=\\log\\frac{1}{\\delta}+\\operatorname*{inf}_{c\\in(0,1]}\\left\\{d\\log\\frac{1}{c}+2S L_{t}c\\right\\}\\leq\\log\\frac{1}{\\delta}+d\\log\\left(e\\vee\\frac{2e S L_{t}}{d}\\right),$   \nwhere the last inequality follows from the choice $\\begin{array}{r}{c=1\\wedge\\frac{d}{2S L_{t}}}\\end{array}$ . aRademacher\u2019s theorem (Federer, 1996, Theorem 3.1.6): for a differentiable function $\\mathcal{L}:\\Theta\\rightarrow\\mathbb{R}$ ,   \n$\\begin{array}{r}{\\operatorname*{inf}\\Big\\{L\\geq0:|{\\mathcal L}(\\pmb\\theta)-{\\mathcal L}(\\pmb\\theta^{\\prime})|\\leq L\\,\\big\\|\\pmb\\theta-\\pmb\\theta^{\\prime}\\big\\|_{2}\\,,\\,\\forall\\pmb\\theta,\\pmb\\theta^{\\prime}\\in\\Theta\\Big\\}=\\operatorname*{max}_{\\pmb\\theta\\in\\Theta}\\big\\|\\nabla{\\mathcal L}(\\pmb\\theta)\\big\\|_{2}.}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "Practically, the computation of $L_{t}$ involves a potentially non-concave maximization over a convex set, which is NP-hard in general (Murty and Kabadi, 1987). In Table 1, we provide closed-form (up to absolute constants), high-probability upper bounds for $L_{t}$ \u2019s for various GLMs. Note that for the learner to implement the CS, she needs the knowledge of $d,S$ , and $L_{t}$ , which may require the knowledge of $R_{\\dot{\\mu}}$ (see the first row of Table 1). ", "page_idx": 2}, {"type": "text", "text": "Comparisons to Prior Works. There have been some works on providing CSs for either generic GLMs (Emmenegger et al., 2023; Jun et al., 2017; Li et al., 2017) or specific GLMs (linear: Flynn et al. (2023), logistic: Abeille et al. (2021); Faury et al. (2020); Lee et al. (2024)). The generic CSs are generally not tight as the \u201cradius\u201d often scales with $\\begin{array}{r}{\\kappa\\;:=\\;\\left(\\operatorname*{min}_{\\pmb{x}\\in X,\\pmb{\\theta}\\in\\Theta}\\dot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}\\rangle)\\right)^{-1}}\\end{array}$ , which scales exponentially in $S$ for Bernoulli (Faury et al., 2020). For instance, Theorem 1 of Jun et al. (2017) and Theorem 1 of Li et al. (2017) propose ellipsoidal CSs that provably satisfy $\\left\\lVert\\widehat{\\pmb{\\theta}}_{t}-\\pmb{\\theta}_{\\star}\\right\\rVert_{V_{t}}^{2}\\,\\leq\\,\\zeta_{1}(t,\\delta)$ , with $\\zeta_{1}$ always scaling with $\\kappa$ . Emmenegger et al. (2023) proposed a weighted sequential likelihood testing-based CS $\\mathcal{W}_{t}$ and showed its efficacy empirically. Theoretically, ", "page_idx": 2}, {"type": "text", "text": "Table 1: Instantiations of $L_{t}$ \u2019s for various GLMs. \u201cBounded by $M^{\\bullet}$ means for any $\\pmb{x}\\in X$ and $r\\sim p(\\cdot|\\mathbf{\\boldsymbol{x}},\\theta_{\\star})$ , the following holds almost surely: $|r-\\mu(\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle)|\\leq M<\\infty$ . ", "page_idx": 3}, {"type": "table", "img_path": "MDdOQayWTA/tmp/6d759cc2145c372123401fb235358c84e41b0579e8da11b9844ddcabe315ebba.jpg", "table_caption": [], "table_footnote": ["The omitted absolute constants can be found in the respective proofs. "], "page_idx": 3}, {"type": "text", "text": "they showed that $\\pmb\\theta\\in\\mathcal{W}_{t}$ satisfies $D(\\pmb{\\theta},\\pmb{\\theta}_{\\star})\\leq\\zeta_{2}(t,\\delta)$ for some Bregman divergence $D(\\cdot,\\cdot)$ and a $\\zeta_{2}$ always scaling with $\\kappa$ as well. We believe their relaxation is not tight enough to warrant a fair comparison and leave to future work on theoretically comparing our CS to theirs. Interested readers are referred to Appendix A for further discussions on CSs for exponential family. On the other hand, the CSs for specific GLMs are inapplicable to GLM models beyond what they are designed for and may not even be sufficiently tight. The prior state-of-the-art (likelihood ratio-based) CS radius for Bernoulli is $\\mathcal{O}\\left(S\\log(1/\\dot{\\delta})+\\stackrel{\\circ}{d}\\log(S t/d)\\right)$ of Lee et al. (2024), while our theorem gives us $\\mathcal{O}\\left(\\log(1/\\delta)+d\\log(S t/d)\\right)$ . Note that we completely remove the $\\mathrm{poly}(S)$ -dependency from the radius, resolving one of the open problems posited by Lee et al. (2024). Later in Section 4, we show that this improvement is significant, both theoretically and numerically. ", "page_idx": 3}, {"type": "text", "text": "3.1 Ellipsoidal Confidence Sequence for Self-Concordant GLMs ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We now provide an ellipsoidal relaxation of Theorem 3.1 for the following class of GLMs: ", "page_idx": 3}, {"type": "text", "text": "Assumption 4 (Russac et al. (2021)). GLM is (generalized) self-concordant, i.e., the following quantity is well-defined (finite): $R_{s}:=\\operatorname*{inf}\\left\\{R\\geq\\bar{0}:|\\ddot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}\\rangle)|\\leq R\\dot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}\\rangle)\\right.$ , $\\forall{\\pmb x}\\in X,{\\pmb\\theta}\\in\\Theta\\}$ . ", "page_idx": 3}, {"type": "text", "text": "For instance, Bernoulli satisfies this with $R_{s}=1$ , and more generally, GLM bounded by $R$ a.s. satisfy this assumption with $R_{s}\\,=\\,R$ (Sawarni et al., 2024, Lemma 2.1). Many unbounded GLMs also satisfy this assumption, such as Gaussian ( $\\mathit{R}_{s}=0$ ), Poisson $\\left(R_{s}=1\\right)$ ), and Exponential $[R_{s}=0]$ ). ", "page_idx": 3}, {"type": "text", "text": "For such self-concordant $G L M s$ , we have the following slightly relaxed ellipsoidal CS, whose proof is deferred to Appendix D: ", "page_idx": 3}, {"type": "table", "img_path": "MDdOQayWTA/tmp/6010ec0c3b843a91d4d906fadab7a866bb3fb9e4baa6ed03b689196466118c2b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "Let us denote $A\\lesssim B$ if $A\\,\\le\\,c B$ for some absolute constant $c>0$ . Note that the relaxation is order-wise strict only when $R_{s}\\;>\\;0$ . For instance, for Gaussian where $R_{s}\\,=\\,0$ , the ellipsoidal relaxation does not introduce additional $S$ -dependency when we choose $\\begin{array}{r}{\\lambda=\\Theta\\left(\\frac{1}{S^{2}}\\right)}\\end{array}$ . We then have that $\\begin{array}{r}{\\nabla^{2}\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})=\\frac{1}{\\sigma^{2}}\\sum_{s=1}^{t-1}{\\pmb{x}}_{s}{\\pmb{x}}_{s}^{\\top}=:\\frac{1}{\\sigma^{2}}V_{t}}\\end{array}$ , and $L_{t}\\lesssim S t$ with high probability (Proposition C.1). Combining everything, we have $\\begin{array}{r}{\\left\\lVert\\theta-\\widehat{\\theta}_{t}\\right\\rVert_{V_{t}}^{2}\\lesssim\\sigma^{2}\\left(\\log\\frac{t}{\\delta}+d\\log\\frac{S t}{d}\\right)}\\end{array}$ , which completely matches the prior state-of-the-art radius as in Lemma D.10 of Flynn et al. (2023) with $c=\\sigma^{2}S^{2}$ . In bandits, the ellipsoidal CS allows one to equivalently rewrite the optimistic optimization in the ", "page_idx": 3}, {"type": "text", "text": "UCB algorithm (Auer et al., 2002) as a closed form bonus-based optimization over the arm-set $\\mathbf{\\mathcal{X}}_{t}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\underset{\\boldsymbol{x}\\in\\mathcal{X}_{t},\\boldsymbol{\\theta}\\in\\mathcal{E}_{t}(\\delta,\\lambda)}{\\arg\\operatorname*{max}}\\langle\\boldsymbol{x},\\boldsymbol{\\theta}\\rangle=\\underset{\\boldsymbol{x}\\in\\mathcal{X}_{t}}{\\arg\\operatorname*{max}}\\left.\\langle\\boldsymbol{x},\\widehat{\\boldsymbol{\\theta}_{t}}\\rangle+\\sqrt{\\gamma_{t}(\\delta)}\\|\\boldsymbol{x}\\|_{(\\nabla^{2}\\mathcal{L}_{t}(\\widehat{\\theta}_{t})+\\lambda I_{d})^{-1}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "i.e., there is no need to solve a convex optimization for each arm. In the high-dimensional scenario where $t=o(d)$ , one can compute $(\\nabla^{2}\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})+\\lambda\\pmb{I}_{d})^{-1}$ with a time complexity of $\\mathcal{O}(t d^{2})$ per round via the Sherman-Morrison formula (Sherman and Morrison, 1950), which is more efficient than the na\u00efve matrix inversion that takes $\\mathcal{O}(d^{3})$ time complexity. ", "page_idx": 3}, {"type": "text", "text": "3.2 Proof of Theorem 3.1 \u2013 PAC-Bayes Approach with Uniform Prior ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We consider $M_{t}(\\pmb\\theta):=\\exp\\left(\\mathcal L_{t}(\\pmb\\theta_{\\star})-\\mathcal L_{t}(\\pmb\\theta)\\right)$ , the likelihood ratio between the (estimated) distribution corresponding to $\\pmb{\\theta}$ and the true distribution corresponding to $\\theta_{\\star}$ . This has been the subject of study for over 50 years (Darling and Robbins, 1967a,b; Lai, 1976; Robbins and Siegmund, 1972) and recently revisited by statistics and machine learning communities (Emmenegger et al., 2023; Flynn et al., 2023; Ramdas et al., 2023; Wasserman et al., 2020). ", "page_idx": 4}, {"type": "text", "text": "We follow the usual recipes for deriving time-uniform PAC-Bayesian bound (Alquier, 2024; Chugg et al., 2023). We start with the following time-uniform property: ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.1. Let $\\delta\\in(0,1)$ . For any data-independent probability measure $\\mathbb{Q}$ on $\\Theta$ , we have: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\exists t\\geq1:\\mathbb{E}_{\\pmb\\theta\\sim\\mathbb{Q}}[M_{t}(\\pmb\\theta)]\\geq\\frac{1}{\\delta}\\right)\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbb{P}$ is over the randomness of the data (and thus randomness of $\\mathcal{L}_{t}$ \u2019s). ", "page_idx": 4}, {"type": "text", "text": "Proof. First, it is easy to see that Mt(\u03b8) =  ts=1ddpp((rrss||xxss;;\u03b8\u03b8\u22c6)) is a nonnegative martingale w.r.t. $\\Sigma_{t}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[M_{t}(\\theta)\\vert\\Sigma_{t-1}]=M_{t-1}(\\theta)\\mathbb{E}\\left[\\frac{d p(r_{t}\\vert x_{t};\\theta)}{d p(r_{t}\\vert x_{t};\\theta_{\\star})}\\Bigg\\vert\\Sigma_{t-1}\\right]=M_{t-1}(\\theta)\\underbrace{\\int_{\\mathcal{R}}\\frac{d p(r\\vert x_{t};\\theta)}{d p(r\\vert x_{t};\\theta_{\\star})}d p(r\\vert x_{t};\\theta_{\\star})}_{=1},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{R}$ is the support of the GLM. (Note that this holds for any distributions.) ", "page_idx": 4}, {"type": "text", "text": "Now consider the random variable $\\mathbb{E}_{\\pmb{\\theta}\\sim\\mathbb{Q}}[M_{t}(\\pmb{\\theta})]$ , which is adapted to $\\Sigma_{t}$ . This is a martingale, as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[M_{t}(\\pmb\\theta)]|\\Sigma_{t-1}]\\overset{(*)}{=}\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[\\mathbb{E}[M_{t}(\\pmb\\theta)|\\Sigma_{t-1}]]=\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[M_{t-1}(\\pmb\\theta)]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $(*)$ follows from Tonelli\u2019s theorem. We conclude by Ville\u2019s inequality (Ville, 1939). ", "page_idx": 4}, {"type": "text", "text": "We recall the variational representation of the KL divergence: ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.2 (Theorem 2.1 of Donsker and Varadhan (1983)). For two probability measures $\\mathbb{P},\\mathbb{Q}$ over $\\Theta$ , we have the following: $\\begin{array}{r}{D_{\\mathrm{KL}}(\\mathbb{P}||\\mathbb{Q})=\\operatorname*{sup}_{g:\\Theta\\to\\mathbb{R}}\\mathbb{E}_{\\pmb{\\theta}\\sim\\mathbb{P}}[g(\\pmb{\\theta})]-\\log\\mathbb{E}_{\\pmb{\\theta}\\sim\\mathbb{Q}}[e^{g(\\pmb{\\theta})}]}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "We then have the following: ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.3. For any data-independent prior $\\mathbb{Q}$ and any sequence of adapted posterior distributions (possibly learned from the data) $\\{\\mathbb{P}_{t}\\}$ , the following holds: for any $\\delta\\in(0,1)$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\exists t\\geq1:\\mathcal{L}_{t}(\\pmb{\\theta}_{\\star})-\\mathbb{E}_{\\pmb{\\theta}\\sim\\mathbb{P}_{t}}[\\mathcal{L}_{t}(\\pmb{\\theta})]\\geq\\log\\frac{1}{\\delta}+D_{\\mathrm{KL}}(\\mathbb{P}_{t}||\\mathbb{Q})\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proof. Note that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\log\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[M_{t}(\\theta)]-\\mathcal{L}_{t}(\\theta_{\\star})=\\log\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[\\exp\\left(-\\mathcal{L}_{t}(\\theta)\\right)]\\overset{(*)}{\\geq}\\mathbb{E}_{\\theta\\sim\\mathbb{P}_{t}}[-\\mathcal{L}_{t}(\\theta)]-D_{\\mathrm{KL}}(\\mathbb{P}_{t}||\\mathbb{Q}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $(*)$ follows from Lemma 3.2 with $\\begin{array}{r l r}{g(\\cdot)}&{{}=}&{-\\mathcal{L}_{t}(\\cdot)}\\end{array}$ . By Lemma 3.1, we have that $\\begin{array}{r}{\\mathbb{P}\\left(\\exists t\\geq1:\\log\\frac{1}{\\delta}\\leq\\log\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[M_{t}(\\pmb\\theta)]\\right)\\leq\\delta.}\\end{array}$ . Rearranging gives the desired statement. ", "page_idx": 4}, {"type": "text", "text": "Remark 1 (Choice of KL). One can replace $K L$ with other divergences with similar variational formulations (Ohnishi and Honorio, 2021). As we will show later, $K L$ suffices for our purpose. ", "page_idx": 4}, {"type": "text", "text": "Up to now, it is well-known in the PAC-Bayes literature. Our main technical novelty lies in how to choose $\\mathbb{Q}$ and $\\mathbb{P}_{t}$ , which is as follows: for $c\\in(0,1]$ to be determined later, we set ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{Q}=\\operatorname{Unif}(\\Theta),\\quad\\mathbb{P}_{t}=\\operatorname{Unif}(\\widetilde{\\Theta}_{t}\\triangleq(1-c)\\widehat{\\pmb{\\theta}}_{t}+c\\Theta),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathrm{Unif}(\\cdot)$ is the uniform distribution and $\\displaystyle a+\\Theta=\\{a+\\theta:\\theta\\in\\Theta\\}$ for a vector $\\pmb{a}\\in\\mathbb{R}^{d}$ . ", "page_idx": 4}, {"type": "text", "text": "Then, denoting $\\operatorname{vol}(\\cdot)$ as the (Lebesgue) volume in $\\mathbb{R}^{d}$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\mathrm{7}}_{\\mathrm{KL}}(\\mathbb{P}_{t}||\\mathbb{Q})=\\log{\\frac{\\operatorname{vol}(\\Theta)}{\\operatorname{vol}(\\widetilde\\Theta)}}=\\log{\\frac{\\operatorname{vol}(\\Theta)}{\\operatorname{vol}\\left((1-c)\\widehat{\\theta}_{t}+c\\Theta\\right)}}=\\log{\\frac{\\operatorname{vol}(\\Theta)}{\\operatorname{vol}(c\\Theta)}}=\\log{\\frac{\\operatorname{vol}(\\Theta)}{c^{d}\\operatorname{vol}(\\Theta)}}=d\\log{\\frac{1}{c}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "table", "img_path": "MDdOQayWTA/tmp/bca484de07f8b60361649af44f66dace560b6861fe59becb120229f8e2b09854.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "We also have that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\theta\\sim\\mathbb{P}_{t}}[\\mathcal{L}_{t}(\\pmb{\\theta})]=\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})+\\mathbb{E}_{\\theta\\sim\\mathbb{P}_{t}}[\\mathcal{L}_{t}(\\pmb{\\theta})-\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})]\\leq\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})+2S L_{t}c,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the last inequality follows from the Lipschitzness of $\\mathcal{L}_{t}(\\cdot)$ and the observation that for $\\theta=(1-$ $c)\\widehat{\\pmb{\\theta}}_{t}+c\\widetilde{\\pmb{\\theta}}\\in\\widetilde{\\Theta}_{t},\\left\\|\\pmb{\\theta}-\\widehat{\\pmb{\\theta}_{t}}\\right\\|_{2}=c\\left\\|\\widetilde{\\pmb{\\theta}}-\\widehat{\\pmb{\\theta}_{t}}\\right\\|_{2}\\leq2S c.$ . We conclude by minimizing over $c\\in(0,1]$ . ", "page_idx": 5}, {"type": "text", "text": "3.3 Intuitions Behind the Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Constrained MLE and Uniform Prior/Poster. As we consider constrained MLE, we know that $\\widehat{\\pmb{\\theta}}_{t}\\in\\Theta$ , i.e., our \u201cbelief\u201d on our MLE is precisely the prior $\\mathbb{Q}=\\operatorname{Unif}(\\Theta)$ . Then, as we want the true parameter $\\theta_{\\star}$ to be close to $\\widehat{\\pmb{\\theta}}_{t}$ , we want to show that a sufficiently large \u201cposterior volume\u201d is near $\\widehat{\\pmb{\\theta}}_{t}$ , formalized as $\\mathbb{P}_{t}=\\mathrm{Unif}\\left((1-c)\\widehat{\\pmb{\\theta}}_{t}+c\\Theta\\right)$ for some shrinkage factor $c\\in(0,1]$ . We later appropriately choose $c$ to optimize the PAC-Bayesian bound. ", "page_idx": 5}, {"type": "text", "text": "We remark that the uniform prior/posterior has been previously considered in universal portfolios (Blum and Kalai, 1999, Theorem 1) and fast rates in online learning (Foster et al., 2018; Hazan et al., 2007); see Appendix A for discussions on relations to fast rates literature. To our knowledge, we are the first to use such uniform prior/posterior in the (time-uniform) PAC-Bayes context. ", "page_idx": 5}, {"type": "text", "text": "Remark 2 (Use of Regularized MLE?). When one uses regularized MLE instead of constrained, as it is not guaranteed to be in $\\Theta$ , one cannot directly use the same uniform prior/posterior. One approach may be to appropriately project the regularized MLE onto $\\Theta$ (e.g., Eqn. (9) of Faury et al. (2020)). However, the previously considered projections that guarantee the tightness of the resulting CS involve a nonconvex optimization and are, thus, computationally intractable. One could also consider using high regularization, which may result in additional dependencies on $S$ in the final CS radius. We conjecture that similarly tight guarantees can be recovered with regularized MLE if one uses other appropriate prior/posterior whose supports are the entire $\\mathbb{R}^{d}$ (e.g., Gaussian). ", "page_idx": 5}, {"type": "text", "text": "Relations to Theorem 3 of Foster et al. (2018). Let us first briefly recall its proof. The authors first consider a distribution $P_{t}(\\cdot)$ over the parameter $W\\,\\in\\,{\\mathcal W}$ (see their Algorithm 1) and use $\\eta$ -mixability of the logistic loss to obtain an inequality involving the negative-log-integral term $\\begin{array}{r}{\\dot{\\int_{\\mathcal{W}}}\\exp\\left(-\\dot{\\eta}\\sum_{t}\\ell(W\\dot{x_{t}},y_{t})\\right)d W}\\end{array}$ . They define $\\bar{S^{'}}=\\,\\dot{\\theta}\\dot{W^{\\star}}+(1\\bar{-\\theta})\\mathcal{W}\\,\\,\\bar{\\subseteq}\\,\\,\\mathcal{W}$ , where $W^{\\star}$ is the ground-truth optimal parameter and $\\theta\\,\\in\\,[0,1)$ is to be determined later. The proof concludes by chaining $\\textstyle\\int_{\\mathcal{W}}\\geq\\int_{S}$ with the $\\ell_{\\infty}$ -Lipschitzness of the logistic loss and expanding the integral. ", "page_idx": 5}, {"type": "text", "text": "Our proof is inspired by the above, with some key differences. While the negative-log-integral also arises in our scenario, we adopt a more compact, streamlined PAC-Bayes approach. In our case, a similar quantity $\\mathbb{E}_{\\theta\\sim\\mathbb{Q}}[\\exp(-\\bar{\\mathcal{L}}_{t}(\\theta))]$ arises from our Donsker-Varadhan representation (Lemma 3.2). We then apply Ville\u2019s inequality to obtain the time-uniform PAC-Bayes bound (Lemma 3.1), and our choices of prior/posterior resemble their choice of $S$ . Our Lipschitzness argument at the end also resembles their $\\ell_{\\infty}$ -Lipschitzness argument. ", "page_idx": 5}, {"type": "text", "text": "4 OFUGLB: A Generic UCB Algorithm for Self-Concordant GLBs ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As a direct application of our CS, we consider self-concordant GLB (Filippi et al., 2010; Janz et al., 2024), where at each time $t$ , the learner chooses a $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ dependent on the history $\\{(\\pmb{x}_{s},r_{s})\\}_{s=1}^{t-1}$ and receives $r_{t}\\sim p(\\cdot|\\pmb{x}_{t},\\pmb{\\theta}_{\\star})$ . The learner\u2019s goal is to minimize the (pseudo-)regret, ${\\mathsf{R e g}}(T):=$ $\\begin{array}{r l}{\\sum_{t=1}^{T}\\left\\{\\mu(\\langle\\mathbf{x}_{t,\\star},\\pmb{\\theta}_{\\star}\\rangle)-\\mu(\\langle\\mathbf{x}_{t},\\pmb{\\theta}_{\\star}\\rangle)\\right\\}}&{{}}\\end{array}$ , where $\\begin{array}{r}{\\pmb{x}_{t,\\star}:=\\arg\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}_{t}}\\mu(\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle)}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "Inspired by the optimism principle (Abbasi-Yadkori et al., 2011; Auer, 2002), based on our new, improved confidence sequence (Theorem 3.1), we propose OFUGLB (Algorithm 1), a generic UCBtype algorithm that applies to any instantiations of GLB. Through a new proof technique that allows us to circumvent $\\kappa$ - and $\\mathrm{poly}(S)$ -dependencies in the leading term, our unified algorithm attains or improves the known state-of-the-art regret bound for the class of self-concordant GLB, which encompasses a zoo of well-studied stochastic bandits such as linear (Abbasi-Yadkori et al., 2011; Auer, 2002), Poisson (Gisselbrecht et al., 2015), logistic (Abeille et al., 2021; Faury et al., 2020), etc. ", "page_idx": 6}, {"type": "text", "text": "We define the following problem difficulty quantities: recalling that $\\textstyle{\\mathcal{X}}_{[T]}=\\bigcup_{t\\in[T]}{\\mathcal{X}}_{t}$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\kappa_{\\star}(T):=\\frac{1}{\\frac{1}{T}\\sum_{t\\in[T]}\\dot{\\mu}(\\langle x_{t,\\star},\\theta_{\\star}\\rangle)},\\quad\\kappa(T):=\\operatorname*{max}_{x\\in\\mathcal{X}_{[T]},\\theta\\in\\Theta}\\frac{1}{\\dot{\\mu}(\\langle x,\\theta\\rangle)}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "These may scale exponentially in $S$ , e.g., for logistic bandits (Faury et al., 2020; Filippi et al., 2010), but we will later show that through our new analysis, the leading term of the regret scales inversely with $\\kappa_{\\star}(T)$ , and the transient term scales linearly with $\\kappa(T)$ . ", "page_idx": 6}, {"type": "text", "text": "We now present the unified $\\&$ state-of-the-art regret guarantee for self-concordant GLBs: ", "page_idx": 6}, {"type": "image", "img_path": "MDdOQayWTA/tmp/560cb6a7a75cf25bd6fb80477b9e69139d9b6a80d2aa5291e9af57a08f0955ec.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "4.1 Proof Sketch of Theorem 4.1 \u2013 Regret Analysis of OFUGLB ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We first emphasize that even though we have a tight CS (Theorem 3.1), na\u00efvely combining it with existing regret analyses of logistic bandits (Abeille et al., 2021; Lee et al., 2024) still results in an extra factor of $S$ in the leading term. The prior proof applies the Cauchy-Schwartz inequality w.r.t. the (regularized) Hessian $\\begin{array}{r}{H_{t}(\\pmb{\\theta_{\\star}})=\\lambda\\pmb{I}+\\sum_{s=1}^{t-1^{\\prime}}\\dot{\\mu}_{s}(\\pmb{\\theta}_{\\star})\\pmb{x}_{s}\\pmb{x}_{s}^{\\top}}\\end{array}$ with $\\dot{\\mu}_{s}(\\cdot):=\\dot{\\mu}(\\langle\\pmb{x}_{s},\\cdot\\rangle)$ , which forces the use of self-concordant lemma (Abeille et al., 2021, Lemma 8). This results in a CS of the form $\\lVert\\theta_{\\star}-\\widehat{\\theta}_{t}\\rVert_{H_{t}(\\theta_{\\star})}=\\mathcal{O}(S\\beta_{t}(\\delta))$ . Then, using the same regret decomposition of Abeille et al. (2021) and the optimism principle, the leading term of the regret is bounded as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{t}\\dot{\\mu}_{t}(\\theta_{\\star})\\langle x_{t,\\star}-x_{t},\\theta_{\\star}\\rangle\\lesssim S\\beta_{t}(\\delta)\\underbrace{\\sqrt{\\sum_{t}\\dot{\\mu}_{t}(\\theta_{\\star})}}_{\\leq\\sqrt{T/\\kappa_{\\star}(T)}}\\underbrace{\\sqrt{\\sum_{t}\\left\\|\\sqrt{\\dot{\\mu}_{t}(\\theta_{\\star})}x_{t}\\right\\|_{H_{t}(\\theta_{\\star})^{-1}}^{2}}}_{\\mathrm{eliptical~potential~lemma~(Abbas+Yadkori~tral,~20)}}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Our proof begins by applying Cauchy-Schwartz w.r.t. $\\widetilde{G}_{t}(\\widehat{\\pmb{\\theta}}_{t})$ , derived from the integral remainder in first-order Taylor expansion of $\\mathcal{L}_{t}(\\cdot)$ at $\\widehat{\\pmb{\\theta}}_{t}$ . With thi s, we have that $\\lVert\\theta_{\\star}-\\widehat{\\theta}_{t}\\rVert_{\\widetilde{G}_{t}(\\widehat{\\theta}_{t})}=\\mathcal{O}(\\beta_{t}(\\delta))$ (Lemma E.6), avoiding the extra $S$ . However, as $\\begin{array}{r}{\\widetilde{\\pmb{G}}_{t}(\\widehat{\\pmb{\\theta}}_{t})=\\sum_{s=1}^{t-1}\\xi(\\pmb{x}_{s},\\widehat{\\pmb{\\theta}}_{t})\\pmb{x}_{s}\\pmb{x}_{s}^{\\top}}\\end{array}$ for some welldefined scalar function $\\xi_{s}$ , the elliptical potential lemma (as done above) is not applicable due to the explicit dependency on $\\widehat{\\pmb{\\theta}}_{t}$ ! This difficulty is analogous to the analysis of Logistic-UCB-2 in Faury et al. (2020), where a similar difficulty arose because their improved bonus $\\epsilon_{t,2}$ depends on the current estimate of the parameter as well (see their Lemma 4). They circumvent this issue by explicitly modifying the UCB algorithm to incorporate additional constraints on the \u201cadmissible log-odds,\u201d which leads to a computationally inefficient algorithm. ", "page_idx": 6}, {"type": "text", "text": "Notably, we show via a new proof technique that the vanilla UCB can implicitly handle those constraints by designating a \u201cworst-case\u201d parameter over all future iterations (Eqn. (21)). We develop many other intriguing results, such as a novel self-concordance lemma that bounds the difference of $\\dot{\\mu}$ \u2019s with that of $\\mu$ \u2019s times $R_{s}$ (Lemma E.3). We provide the full proof in Appendix E. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "Table 2: Regret bounds of OFUGLB for various self-concordant GLBs. Logarithmic factors are omitted to avoid a cognitive overload. Let $\\begin{array}{r}{\\kappa_{\\mathcal{X}}(T):=\\operatorname*{max}_{\\pmb{x}\\in\\cup_{t=1}^{T}\\mathcal{X}_{t}}\\frac{1}{\\dot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle)}}\\end{array}$ and $g(\\tau)\\,=\\,\\mathcal{O}(1)$ . Here, \u201c $\\mathcal{R}$ -Bounded\u201d means $|r_{t}|\\leq R\\,a.s.$ . ", "page_idx": 7}, {"type": "table", "img_path": "MDdOQayWTA/tmp/a238b610a6e71dd9163ae7969ce29b9574a833fad5bb270652fe70f10add08a8.jpg", "table_caption": [], "table_footnote": ["a We choose $c=\\sigma^{2}S^{2}$ in Lemma D.10 of Flynn et al. (2023). b Here, we omit the dependencies on $S$ and the transient term from explicit warmup. "], "page_idx": 7}, {"type": "text", "text": "4.2 Instantiations and Discussions of Theorem 4.1 ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In Table 2, we instantiate Theorem 4.1 for various self-concordant GLBs. It can be seen that our OFUGLB attains state-of-the-art regret guarantees in all considered scenarios, either by achieving (linear) or improving upon (bounded, logistic) the known regret bounds! Note that the instantiation for (sub-)Gaussian linear bandits is meant to be a sanity check because tighter confidence sets are available in Flynn et al. (2023) and Chowdhury et al. (2023, Appendix F). ", "page_idx": 7}, {"type": "text", "text": "To our knowledge, only a few works deal with generic, (possibly unbounded) self-concordant GLBs. Jun et al. (2017) proposed UCB-style GLOC and its variants, which, however, incur regret bounds scaling with $\\kappa_{\\star}(T)$ in the leading term. Another line of works (Abeille and Lazaric, 2017; Dong et al., 2019; Janz et al., 2024; Kim et al., 2023; Kveton et al., 2020) considers randomized exploration-based algorithms, including Thompson sampling, which we discuss further in Appendix A. ", "page_idx": 7}, {"type": "text", "text": "Below, we discuss our results for bounded GLB, logistic, and Poisson bandits in-depth. ", "page_idx": 7}, {"type": "text", "text": "Bounded GLB. The only prior work applicable to general bounded GLB is Sawarni et al. (2024), where the authors propose RS-GLinCB with regret as in Table 2. Compared to our regret, they are slightly better as their transient term scales as $\\kappa_{\\mathcal{X}}(T)$ while ours scales as $\\kappa(T)$ , but we have a much better dependency on $R$ $\\boldsymbol{R}$ vs. $R^{5}$ ). Despite this seeming gap, as RS-GLinCB relies on an explicit warm-up scheme, our OFUGLB is expected to have superior numerical performance as it avoids excessive exploration in the early phase. We will elaborate more on this issue in Section 5. Also, it should be noted that Sawarni et al. (2024) requires a nonconvex optimization as a subroutine to obtain $\\mathrm{poly}(S)$ -free regret (see their Appendix E). Still, RS-GLinCB has its advantages in that it only requires $\\Omega(\\log^{2}T)$ switches while we require $\\Omega(T)$ switches; it is an interesting open problem whether a lazy variant of OFUGLB with same (or better) regret guarantee is possible. ", "page_idx": 7}, {"type": "text", "text": "Logistic Bandits. Although the logistic bandit is a special case of the bounded GLB, the number of prior works and its practical applicability to recommender systems (Li et al., 2010, 2012) and recently RLHF (Das et al., 2024) makes it deserving of separate discussions. We first review the prior works on logistic bandits. Faury et al. (2020) was the first to obtain a regret bound of $\\tilde{\\mathcal{O}}(d\\sqrt{T}\\!+\\!\\bar{d}^{2}\\kappa(T))$ (up to some dependencies on $S$ ) that is $\\kappa$ -free in the leading term. Subsequently,  a local minimax regret lower bound of $\\Omega((d/S)\\sqrt{T/\\kappa_{\\star}(T)})$ was proven (Abeille et al., 2021, Theorem $2)^{2}$ , suggesting that more nonlinearity helps, and several works have focused on proposing and analyzing algorithms with matching upper bounds. One line of works (Abeille et al., 2021; Lee et al., 2024), including this work, focuses on getting a tight convex CS for logistic losses, which then directly gives an OFUL-type algorithm. Abeille et al. (2021) first proposed a likelihood ratio-based CS, albeit somewhat loose in $S$ . Lee et al. (2024) proposed a new framework for converting an achievable online learning algorithm to a tighter CS and proposed a UCB algorithm that attains the prior (to this work) state-ofthe-art regret bound of $\\tilde{\\mathcal{O}}(d S\\bar{\\sqrt{T/\\kappa_{\\star}(T)}}+R_{\\mathcal{X}}(\\bar{T}))$ with $R_{\\mathcal{X}}(T)$ being arm-set geometry-dependent transient term3 From a computational perspective, Faury et al. (2022) proposed an online Newton stepbased algorithms that attain the regret bound of $\\widetilde{\\mathcal{O}}(d S\\sqrt{T/\\kappa_{\\star}(T)}+d^{2}S^{6}\\kappa(T))$ using only ${\\mathcal{O}}(\\log t)$ computational cost and $\\mathcal{O}(1)$ storage per time step; the computational cost was later improved to $O(1)$ in Zhang and Sugiyama (2023). Another line of works (Mason et al., 2022; Sawarni et al., 2024) proposed algorithms that perform an explicit warm-up in the early stages. Thanks to the explicit warmup, both attain regret with $\\mathrm{poly}(S)$ -free leading term, e.g., $\\tilde{\\mathcal{O}}(d\\sqrt{T/\\kappa_{\\star}(T)}+d^{2}S^{2}\\kappa_{\\mathcal{X}}(T))$ by Sawarni et al. (2024). However, the explicit warmup typically lasts for $\\widetilde\\Omega(\\kappa(T))$ or $\\widetilde\\Omega(\\kappa_{\\mathcal{X}}(T))$ time steps, resulting in potentially very large initial regret. This is later verified in our logistic bandits experiments. Our OFUGLB is the first purely optimism-based UCB algorithm (no explicit warmup) that attains a $\\mathrm{poly}(S)$ -free leading term in the regret. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Poisson Bandits. Despite its potential to model various real-world problems involving count feedback, Poisson bandits have not been studied often in the literature. Gisselbrecht et al. (2015) was the first to consider contextual Poisson bandits and proposed UCB and optimistic Bayesian-based algorithms (May et al., 2012), but without any regret guarantees. To our knowledge, our Theorem 4.1 provides the first regret bound for the (finite-dimensional) contextual Poisson bandits without reward boundedness assumption. On a related note, Mutn\u00fd and Krause (2021) consider Poisson bandits with the intensity function in an RKHS. Their linear RKHS formulation is, however, incompatible with our log-linear formulation; see their Appendix A.1 for further discussions. ", "page_idx": 8}, {"type": "text", "text": "5 Experiments in Logistic Bandits ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We perform experiments on logistic bandits to complement the theoretical improvement in our regret bounds and CS. The codes are available in our GitHub repository4, which is based upon the previous GitHub repository5 of Faury et al. (2022). Our GitHub provides the unified implementations of all considered algorithms, which we hope will be helpful in future research and benchmarking of logistic bandits. In Appendix G, we provide the missing implementation details of the considered algorithms and additional experimental results for fixed arm-sets. ", "page_idx": 8}, {"type": "text", "text": "Baselines and Setting. We compare our OFUGLB (likelihood ratio-based CS; Theorem 3.1) and OFUGLB-e (ellipsoidal CS; Theorem 3.2) to the following five baselines: EMK (Emmenegger et al., 2023), EVILL (Janz et al., 2024), RS-GLinCB (Sawarni et al., 2024), $\\mathsf{O F U L o g^{+}}$ (Lee et al., 2024), and ada-OFU-ECOLog (Faury et al., 2022). Note that the last two are specific to logistic bandits, and RS-GLinCB is specific to bounded GLBs. We emphasize that when implementing OFUGLB and OFUGLB-e, we use the precise theoretical hyperparameters as given in our theorem statements without further tuning. To highlight the practical effectiveness of our theoretical algorithms in comparison to randomized exploration, which is known to perform well in practice (Chapelle and Li, 2011; Russo et al., 2018), we use a single, untuned hyperparameter guess for EVILL rather than its proposed theoretical value (see Appendix E of their work). For the experimental setup in this section, we set $T=10000$ , $d=2$ , and $\\delta=0.05$ . We consider time-varying arm-set: at each $t\\in[T]$ , an arm-set $A_{t}\\,\\subset\\,B^{d}(1)$ of size $|\\mathcal{A}_{t}|\\,=\\,20$ is uniformly sampled. We set $\\begin{array}{r}{\\theta_{\\star}\\,=\\,\\frac{S-1}{\\sqrt{d}}{\\bf1}}\\end{array}$ for $S\\,\\in\\,\\{4,6,8,10\\}$ Lastly, we consider 10 independent repeats per setting for statistical significance. ", "page_idx": 8}, {"type": "text", "text": "Results and Discussions. The results are shown in Figure 1. Note that in all considered settings, OFUGLB, EMK, and EVILL outperform every other baseline, both in terms of regret and numerical tightness of the CS. Moreover, for $S\\in\\{8,10\\}$ , our OFUGLB seems to achieve the best performance, although more comprehensive numerical studies would shed more light on this matter. As for our OFUGLB-e, despite having worse performance than OFUGLB, EMK, and EVILL, it always attains better numerical performance than the remaining algorithms. Notably, OFUGLB and EMK achieve at par or better numerical regret compared to EVILL with heuristic hyperparameter. This highlights the effectiveness of our theoretical results even compared to heuristically tuned randomized exploration. ", "page_idx": 8}, {"type": "image", "img_path": "MDdOQayWTA/tmp/2936e9be09397acc7352a558209f9a6833632f6694c3a60a472d78d285abe527.jpg", "img_caption": ["Figure 1: Time-varying arm-sets. (First row) Regret plots of all considered algorithms. (Second row) Magnified regret plots. (Third row) Confidence set plots at the final time $t=10000$ when applicable. Each column represents a different logistic bandit instance for $S\\in\\{4,6,8,10\\}$ . "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "One interesting observation is that even though $\\mathsf{O F U L o g^{+}}$ achieves a much tighter CS at the end, its regret is much worse than OFUGLB-e. We posit that this is related to the interplay between the CS and arm set geometries, and we leave further study of such discrepancy to future work. Another is that RS-GLinCB with the exact theoretical hyperparameters (Sawarni et al., 2024) performs the worst, even worse than ada-OFU-ECOLog. We believe this is because their theoretical hyperparameters are not numerically tight, forcing the algorithm to explore throughout the entire duration, probably as their Switching Criterion I (line 4 of their Algorithm 2) is always true. To use RS-GLinCB in practice, one must tune6 the hyperparameters to explicitly control the degree of exploration, which is not the case for our OFUGLB, making ours a viable, practical algorithm with a provable guarantee as well. Lastly, note how the likelihood-based CS, $\\{\\pmb{\\theta}\\in\\Theta:\\mathcal{L}_{t}\\(\\pmb{\\theta})\\leq c_{t}\\}$ for $c_{t}=\\Theta(\\log t)$ , resembles an ellipsoid. This is because the \u201cnormalized\u201d sublevel value $c_{t}/t$ (as there are $t$ summands in the LHS) gets smaller, making the second-order Taylor expansion more accurate. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper introduces a novel and unified likelihood ratio-based CS for generic (convex) GLMs, encompassing widely-used models such as Gaussian, Bernoulli, and Poisson. Our CS is equipped with exact constants for various scenarios, making it suitable for any practitioner. The proof involves leveraging key techniques from PAC-Bayes bounds with a uniform prior/posterior. We then propose OFUGLB, a generic UCB algorithm applicable to any GLBs, achieving state-of-the-art regret bounds across all self-concordant GLBs. The proof involves novel regret decomposition and maximally avoiding the self-concordance control lemma (Faury et al., 2020, Lemma 9), which may be of independent interest. Notably, for logistic bandits, OFUGLB is the first pure-optimism-based algorithm that achieves $\\mathrm{poly}(S)$ -free leading term in the theoretical regret, which is numerically verified to perform best. This work opens up various future directions, which we discuss in detail in Appendix B. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "J. Lee thanks Gergely Neu for hosting him at a wonderful mini-workshop after AISTATS \u201924 at UPF, during which many insightful discussions inspired the current PAC-Bayesian proof. J. Lee also thanks Branislav Kveton for suggesting trying a randomized algorithm for logistic bandits experiments, Tim van Erven for insightful discussions regarding the fast rates in statistical learning, and Aaditya Ramdas for insightful comments on the prior-posterior martingale, all during AISTATS \u201924. J. Lee also thanks Jaeyoung Cha for suggesting an elementary proof for Lemma C.1 that does not rely on Wolfram|Alpha. The authors thank the anonymous reviewers of the ICML \u201924 ARLET Workshop and NeurIPS \u201924 for insightful questions and suggestions that helped us significantly improve the paper. ", "page_idx": 10}, {"type": "text", "text": "J. Lee and S.-Y. Yun were supported in part by the Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korean government (MSIT) (No. RS-2022-II220311 Development of Goal-Oriented Reinforcement Learning Techniques for ContactRich Robotic Manipulation of Everyday Objects and No. RS-2019-II190075 Artificial Intelligence Graduate School Program (KAIST)) and the National Research Foundation of Korea(NRF) grant funded by the Korean government (MSIT) (No. RS-2019-NR040050 Stochastic Analysis and Application Research Center (SAARC)). K.-S. Jun was supported in part by the National Science Foundation under grant CCF-2327013. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved Algorithms for Linear Stochastic Bandits. In Advances in Neural Information Processing Systems, volume 24, pages 2312\u20132320. Curran Associates, Inc., 2011. URL https://sites.ualberta.ca/\\~szepesva/papers/ linear-bandits-NeurIPS2011.pdf.   \nYasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits. In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics, volume 22 of Proceedings of Machine Learning Research, pages 1\u20139. PMLR, 21\u201323 Apr 2012. URL https://proceedings.mlr.press/v22/ abbasi-yadkori12.html.   \nMarc Abeille and Alessandro Lazaric. Linear Thompson sampling revisited. Electronic Journal of Statistics, 11(2):5165 \u2013 5197, 2017. doi: 10.1214/17-EJS1341SI. URL https://doi.org/10. 1214/17-EJS1341SI.   \nMarc Abeille, Louis Faury, and Cl\u00e9ment Calauz\u00e8nes. Instance-Wise Minimax-Optimal Algorithms for Logistic Bandits. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pages 3691\u20133699. PMLR, 13\u201315 Apr 2021. URL https://proceedings.mlr.press/v130/abeille21a.html.   \nPierre Alquier. User-friendly Introduction to PAC-Bayes Bounds. Foundations and Trends\u00ae in Machine Learning, 17(2):174\u2013303, 2024. ISSN 1935-8237. doi: 10.1561/2200000100. URL http://dx.doi.org/10.1561/2200000100.   \nPeter Auer. Using Confidence Bounds for Exploitation-Exploration Trade-offs. Journal of Machine Learning Research, 3:397\u2013422, Nov 2002. URL https://jmlr.csail.mit.edu/papers/v3/ auer02a.html.   \nPeter Auer, Nicol\u00f2 Cesa-Bianchi, and Paul Fischer. Finite-time Analysis of the Multiarmed Bandit Problem. Machine Learning, 47(2):235\u2013256, May 2002. ISSN 1573-0565. doi: 10.1023/A: 1013689704352. URL https://doi.org/10.1023/A:1013689704352.   \nMohammad Javad Azizi, Branislav Kveton, and Mohammad Ghavamzadeh. Fixed-Budget BestArm Identification in Structured Bandits. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22, pages 2798\u20132804. International Joint Conferences on Artificial Intelligence Organization, 7 2022. doi: 10.24963/ijcai.2022/388. URL https: //doi.org/10.24963/ijcai.2022/388. Main Track.   \nJackie Baek and Vivek Farias. TS-UCB: Improving on Thompson Sampling With Little to No Additional Computation. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 11132\u2013 11148. PMLR, 25\u201327 Apr 2023. URL https://proceedings.mlr.press/v206/baek23a. html.   \nAvrim Blum and Adam Kalai. Universal Portfolios With and Without Transaction Costs. Machine Learning, 35(3):193\u2013205, Jun 1999. ISSN 1573-0565. doi: 10.1023/A:1007530728748. URL https://doi.org/10.1023/A:1007530728748.   \nVladimir Igorevich Bogachev. Gaussian Measures. Number 62 in Mathematical Surveys and Monographs. American Mathematical Society, 1998.   \nStephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, 2004.   \nGavin C. Cawley, Gareth J. Janacek, and Nicola L. C. Talbot. Generalised Kernel Machines. In 2007 International Joint Conference on Neural Networks, pages 1720\u20131725, 2007. doi: 10.1109/IJCNN. 2007.4371217. URL https://ieeexplore.ieee.org/document/4371217.   \nOlivier Chapelle and Lihong Li. An Empirical Evaluation of Thompson Sampling. In Advances in Neural Information Processing Systems, volume 24, pages 2249\u20132257. Curran Associates, Inc., 2011. URL https://papers.nips.cc/paper_files/paper/2011/hash/ e53a0a2978c28872a4505bdb51db06dc-Abstract.html.   \nSayak Ray Chowdhury and Aditya Gopalan. On Kernelized Multi-armed Bandits. In Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pages 844\u2013853. PMLR, 06\u201311 Aug 2017. URL https://proceedings. mlr.press/v70/chowdhury17a.html.   \nSayak Ray Chowdhury, Patrick Saux, Odalric Maillard, and Aditya Gopalan. Bregman Deviations of Generic Exponential Families. In Proceedings of Thirty Sixth Conference on Learning Theory, volume 195 of Proceedings of Machine Learning Research, pages 394\u2013449. PMLR, 12\u201315 Jul 2023. URL https://proceedings.mlr.press/v195/chowdhury23a.html.   \nPaul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep Reinforcement Learning from Human Preferences. In Advances in Neural Information Processing Systems, volume 30, pages 4302\u20134310. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/ d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf.   \nBen Chugg, Hongjian Wang, and Aaditya Ramdas. A Unified Recipe for Deriving (Time-Uniform) PAC-Bayes Bounds. Journal of Machine Learning Research, 24(372):1\u201361, 2023. URL http: //jmlr.org/papers/v24/23-0401.html.   \nGiuseppe Da Prato and Jerzy Zabczyk. Stochastic Equations in Infinite Dimensions. Number 152 in Encyclopedia of Mathematics and its Applications. Cambridge University Press, 2 edition, 2014.   \nD. A. Darling and Herbert Robbins. Confidence Sequences for Mean, Variance, and Median. Proceedings of the National Academy of Sciences, 58(1):66\u201368, 1967a. doi: 10.1073/pnas.58.1.66. URL https://www.pnas.org/doi/abs/10.1073/pnas.58.1.66.   \nD. A. Darling and Herbert Robbins. Iterated Logarithm Inequalities. Proceedings of the National Academy of Sciences, 57(5):1188\u20131192, 1967b. doi: 10.1073/pnas.57.5.1188. URL https: //www.pnas.org/doi/abs/10.1073/pnas.57.5.1188.   \nNirjhar Das, Souradip Chakraborty, Aldo Pacchiano, and Sayak Ray Chowdhury. Active Preference Optimization for Sample Efficient RLHF. arXiv preprint arXiv:2402.10500, 2024. URL https: //arxiv.org/abs/2402.10500.   \nVictor H. de la Pe\u00f1a, Michael J. Klass, and Tze Leung Lai. Self-normalized processes: exponential inequalities, moment bounds and iterated logarithm laws. The Annals of Probability, 32(3): 1902 \u2013 1933, 2004. doi: 10.1214/009117904000000397. URL https://doi.org/10.1214/ 009117904000000397.   \nShi Dong, Tengyu Ma, and Benjamin Van Roy. On the Performance of Thompson Sampling on Logistic Bandits. In Proceedings of the Thirty-Second Conference on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pages 1158\u20131160. PMLR, 25\u201328 Jun 2019. URL https://proceedings.mlr.press/v99/dong19a.html.   \nM. D. Donsker and S. R. S. Varadhan. Asymptotic Evaluation of Certain Markov Process Expectations for Large Time. IV. Communications on Pure and Applied Mathematics, 36(2):183\u2013212, 1983. doi: https://doi.org/10.1002/cpa.3160360204. URL https://onlinelibrary.wiley.com/ doi/abs/10.1002/cpa.3160360204.   \nJohn Duchi and Saminul Haque. An information-theoretic lower bound in time-uniform estimation. In Proceedings of Thirty Seventh Conference on Learning Theory, volume 247 of Proceedings of Machine Learning Research, pages 1486\u20131500. PMLR, 30 Jun\u201303 Jul 2024. URL https: //proceedings.mlr.press/v247/duchi24a.html.   \nNicolas Emmenegger, Mojm\u00edr Mutn\u00fd, and Andreas Krause. Likelihood Ratio Confidence Sets for Sequential Decision Making. In Advances in Neural Information Processing Systems, volume 36. Curran Associates, Inc., 2023. URL https://openreview.net/forum?id $=$ 4anryczeED.   \nLouis Faury, Marc Abeille, Cl\u00e9ment Calauz\u00e8nes, and Olivier Fercoq. Improved Optimistic Algorithms for Logistic Bandits. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 3052\u20133060. PMLR, 13\u201318 Jul 2020. URL https://proceedings.mlr.press/v119/faury20a.html.   \nLouis Faury, Marc Abeille, Kwang-Sung Jun, and Cl\u00e9ment Calauz\u00e8nes. Jointly Efficient and Optimal Algorithms for Logistic Bandits. In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, volume 151 of Proceedings of Machine Learning Research, pages 546\u2013 580. PMLR, 28\u201330 Mar 2022. URL https://proceedings.mlr.press/v151/faury22a. html.   \nHerbert Federer. Geometric Measure Theory. Classics in Mathematics. Springer Berlin, Heidelberg, 1996.   \nSarah Filippi, Olivier Cappe, Aur\u00e9lien Garivier, and Csaba Szepesv\u00e1ri. Parametric Bandits: The Generalized Linear Case. In Advances in Neural Information Processing Systems, volume 23, pages 586\u2013594. Curran Associates, Inc., 2010. URL https://proceedings.neurips.cc/ paper_files/paper/2010/file/c2626d850c80ea07e7511bbae4c76f4b-Paper.pdf.   \nHamish Flynn, David Reeb, Melih Kandemir, and Jan Peters. Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures. In Advances in Neural Information Processing Systems, volume 36. Curran Associates, Inc., 2023. URL https://openreview. net/forum?id $\\equiv$ TXoZiUZywf.   \nDylan J. Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Sridharan. Logistic Regression: The Importance of Being Improper. In Proceedings of the 31st Conference On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pages 167\u2013208. PMLR, 06\u201309 Jul 2018. URL https://proceedings.mlr.press/v75/foster18a.html.   \nSpencer B. Gales, Sunder Sethuraman, and Kwang-Sung Jun. Norm-Agnostic Linear Bandits. In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, volume 151 of Proceedings of Machine Learning Research, pages 73\u201391. PMLR, 28\u201330 Mar 2022. URL https://proceedings.mlr.press/v151/gales22a.html.   \nThibault Gisselbrecht, Sylvain Lamprier, and Patrick Gallinari. Policies for Contextual Bandit Problems with Count Payoffs. In 2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI), pages 542\u2013549, 2015. doi: 10.1109/ICTAI.2015.85. URL https:// ieeexplore.ieee.org/document/7372181.   \nPeter D. Gr\u00fcnwald and Nishant A. Mehta. Fast Rates for General Unbounded Loss Functions: From ERM to Generalized Bayes. Journal of Machine Learning Research, 21(56):1\u201380, 2020. URL http://jmlr.org/papers/v21/18-488.html.   \nNima Hamidi and Mohsen Bayati. On Frequentist Regret of Linear Thompson Sampling. arXiv preprint arXiv:2006.06790, 2020. URL https://arxiv.org/abs/2006.06790.   \nElad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2):169\u2013192, Dec 2007. ISSN 1573-0565. doi: 10.1007/ s10994-007-5016-8. URL https://doi.org/10.1007/s10994-007-5016-8.   \nDavid Janz, Shuai Liu, Alex Ayoub, and Csaba Szepesv\u00e1ri. Exploration via linearly perturbed loss minimisation. In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, volume 238 of Proceedings of Machine Learning Research, pages 721\u2013729. PMLR, 02\u201304 May 2024. URL https://proceedings.mlr.press/v238/janz24a.html.   \nChi Jin, Praneeth Netrapalli, Rong Ge, Sham M. Kakade, and Michael I. Jordan. A Short Note on Concentration Inequalities for Random Vectors with SubGaussian Norm. arXiv preprint arXiv:1902.03736, 2019. URL https://arxiv.org/abs/1902.03736.   \nKwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, and Rebecca Willett. Scalable Generalized Linear Bandits: Online Computation and Hashing. In Advances in Neural Information Processing Systems, volume 30, pages 98\u2013108. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/ 28dd2c7955ce926456240b2ff0100bde-Paper.pdf.   \nKwang-Sung Jun, Lalit Jain, Blake Mason, and Houssam Nassif. Improved Confidence Bounds for the Linear Logistic Model and Applications to Bandits. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 5148\u20135157. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/ jun21a.html.   \nEmilie Kaufmann and Wouter M. Koolen. Mixture Martingales Revisited with Applications to Sequential Tests and Confidence Intervals. Journal of Machine Learning Research, 22(246):1\u201344, 2021. URL http://jmlr.org/papers/v22/18-798.html.   \nAbbas Kazerouni and Lawrence M. Wein. Best arm identification in generalized linear bandits. Operations Research Letters, 49(3):365\u2013371, 2021. ISSN 0167-6377. doi: https://doi.org/10. 1016/j.orl.2021.03.011. URL https://www.sciencedirect.com/science/article/pii/ S0167637721000523.   \nWonyoung Kim, Kyungbok Lee, and Myunghee Cho Paik. Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7):8300\u20138307, Jun. 2023. doi: 10.1609/aaai.v37i7.26001. URL https://ojs.aaai.org/index.php/AAAI/article/view/26001.   \nYeoneung Kim, Insoon Yang, and Kwang-Sung Jun. Improved Regret Analysis for Variance-Adaptive Linear Bandits and Horizon-Free Linear Mixture MDPs. In Advances in Neural Information Processing Systems, volume 35, pages 1060\u20131072. Curran Associates, Inc., 2022. URL https: //openreview.net/forum?id=U_YPSEyN2ls.   \nJohannes Kirschner and Andreas Krause. Information Directed Sampling and Bandits with Heteroscedastic Noise. In Proceedings of the 31st Conference On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pages 358\u2013384. PMLR, 06\u201309 Jul 2018. URL https://proceedings.mlr.press/v75/kirschner18a.html.   \nDieter Kraft. A Software Package for Sequential Quadratic Programming. Technical Report DFVLRFB 88-28, Deutsche Forschungs und Versuchsanstalt f\u00fcr Luft- und Raumfahrt \u2013 Institut f\u00fcr Dynamik der Flugsysteme, K\u00f6ln, Deutschland, 1988. URL https://degenerateconic.com/ uploads/2018/03/DFVLR_FB_88_28.pdf.   \nBranislav Kveton, Manzil Zaheer, Csaba Szepesv\u00e1ri, Lihong Li, Mohammad Ghavamzadeh, and Craig Boutilier. Randomized Exploration in Generalized Linear Bandits. In Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 2066\u20132076. PMLR, 26\u201328 Aug 2020. URL https://proceedings.mlr.press/v108/kveton20a.html.   \nRicardo Lage, Ludovic Denoyer, Patrick Gallinari, and Peter Dolog. Choosing which message to publish on social networks: A contextual bandit approach. In 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013), pages 620\u2013 627, 2013. doi: 10.1145/2492517.2492541. URL https://ieeexplore.ieee.org/document/ 6785767.   \nTze Leung Lai. On Confidence Sequences. The Annals of Statistics, 4(2):265 \u2013 280, 1976. doi: 10.1214/aos/1176343406. URL https://doi.org/10.1214/aos/1176343406.   \nTor Lattimore and Csaba Szepesv\u00e1ri. Bandit Algorithms. Cambridge University Press, 2020.   \nJunghyun Lee, Se-Young Yun, and Kwang-Sung Jun. Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion. In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, volume 238 of Proceedings of Machine Learning Research, pages 4474\u20134482. PMLR, 02\u201304 May 2024. URL https://proceedings.mlr.press/v238/lee24d.html.   \nLihong Li, Wei Chu, John Langford, and Robert E. Schapire. A Contextual-Bandit Approach to Personalized News Article Recommendation. In Proceedings of the 19th International Conference on World Wide Web, WWW \u201910, page 661\u2013670, New York, NY, USA, 2010. Association for Computing Machinery. ISBN 9781605587998. doi: 10.1145/1772690.1772758. URL https: //doi.org/10.1145/1772690.1772758.   \nLihong Li, Wei Chu, John Langford, Taesup Moon, and Xuanhui Wang. An Unbiased Offline Evaluation of Contextual Bandit Algorithms with Generalized Linear Models. In Proceedings of the Workshop on On-line Trading of Exploration and Exploitation 2, volume 26 of Proceedings of Machine Learning Research, pages 19\u201336, Bellevue, Washington, USA, 02 Jul 2012. PMLR. URL https://proceedings.mlr.press/v26/li12a.html.   \nLihong Li, Yu Lu, and Dengyong Zhou. Provably Optimal Algorithms for Generalized Linear Contextual Bandits. In Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pages 2071\u20132080. PMLR, 06\u201311 Aug 2017. URL https://proceedings.mlr.press/v70/li17c.html.   \nXuheng Li, Heyang Zhao, and Quanquan Gu. Feel-Good Thompson Sampling for Contextual Dueling Bandits. In Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 29406\u201329426. PMLR, 21\u201327 Jul 2024. URL https://proceedings.mlr.press/v235/li24co.html.   \nElliott H Lieb. Convex trace functions and the Wigner-Yanase-Dyson conjecture. Advances in Mathematics, 11(3):267\u2013288, 1973. ISSN 0001-8708. doi: https://doi.org/10.1016/ 0001-8708(73)90011-X. URL https://www.sciencedirect.com/science/article/pii/ 000187087390011X.   \nShuai Liu, Alex Ayoub, Flore Sentenac, Xiaoqi Tan, and Csaba Szepesv\u00e1ri. Almost Free: Selfconcordance in Natural Exponential Families and an Application to Bandits. In Advances in Neural Information Processing Systems, volume 37. Curran Associates, Inc., 2024. URL https: //arxiv.org/abs/2410.01112.   \nBlake Mason, Kwang-Sung Jun, and Lalit Jain. An Experimental Design Approach for Regret Minimization in Logistic Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 36(7):7736\u20137743, Jun. 2022. doi: 10.1609/aaai.v36i7.20741. URL https://ojs.aaai.org/ index.php/AAAI/article/view/20741.   \nBenedict C. May, Nathan Korda, Anthony Lee, and David S. Leslie. Optimistic Bayesian Sampling in Contextual-Bandit Problems. Journal of Machine Learning Research, 13(67):2069\u20132106, 2012. URL http://jmlr.org/papers/v13/may12a.html.   \nPeter McCullagh and John A. Nelder. Generalized Linear Models. Monographs on Statistics and Applied Probability. Chapman & Hall/CRC, 2 edition, 1989.   \nHans-Georg M\u00fcller and Ulrich Stadtm\u00fcller. Generalized functional linear models. The Annals of Statistics, 33(2):774 \u2013 805, 2005. doi: 10.1214/009053604000001156. URL https://doi.org/ 10.1214/009053604000001156.   \nKatta G. Murty and Santosh N. Kabadi. Some NP-complete problems in quadratic and nonlinear programming. Mathematical Programming, 39(2):117\u2013129, Jun 1987. ISSN 1436-4646. doi: 10.1007/BF02592948. URL https://doi.org/10.1007/BF02592948.   \nMojm\u00edr Mutn\u00fd and Andreas Krause. No-regret Algorithms for Capturing Events in Poisson Point Processes. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 7894\u20137904. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/mutny21a.html.   \nWillie Neiswanger and Aaditya Ramdas. Uncertainty quantification using martingales for misspecified Gaussian processes. In Proceedings of the 32nd International Conference on Algorithmic Learning Theory, volume 132 of Proceedings of Machine Learning Research, pages 963\u2013982. PMLR, 16\u201319 Mar 2021. URL https://proceedings.mlr.press/v132/neiswanger21a.html.   \nYuki Ohnishi and Jean Honorio. Novel Change of Measure Inequalities with Applications to PAC-Bayesian Bounds and Monte Carlo Estimation. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pages 1711\u20131719. PMLR, 13\u201315 Apr 2021. URL https://proceedings. mlr.press/v130/ohnishi21a.html.   \nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems, volume 35, pages 27730\u201327744. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/ file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf.   \nJohn C. Oxtoby. Invariant Measures in Groups Which Are Not Locally Compact. Transactions of the American Mathematical Society, 60:215\u2013237, 1946. doi: https://doi.org/10.1090/ S0002-9947-1946-0018188-5. URL https://www.ams.org/journals/tran/1946-060-00/ S0002-9947-1946-0018188-5/.   \nVern I. Paulsen and Mrinal Raghupathi. An Introduction to the Theory of Reproducing Kernel Hilbert Spaces. Cambridge Studies in Advanced Mathematics. Cambridge University Press, 2016.   \nAaditya Ramdas, Peter Gr\u00fcnwald, Vladimir Vovk, and Glenn Shafer. Game-Theoretic Statistics and Safe Anytime-Valid Inference. Statistical Science, 38(4):576 \u2013 601, 2023. doi: 10.1214/23-STS894. URL https://doi.org/10.1214/23-STS894.   \nHerbert Robbins. Some Aspects of the Sequential Design of Experiments. Bulletin of the American Mathematical Society, 58(5):527 \u2013 535, 1952. URL https://projecteuclid.org/ journals/bulletin-of-the-american-mathematical-society/volume-58/issue-5/ Some-aspects-of-the-sequential-design-of-experiments/bams/1183517370. full.   \nHerbert Robbins and David Siegmund. A Class of Stopping Rules for Testing Parametric Hypotheses. Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 4: Biology and Health, 6(4):37\u201341, 1972. URL https://projecteuclid.org/proceedings/ berkeley-symposium-on-mathematical-statistics-and-probability/ Proceedings-of-the-Sixth-Berkeley-Symposium-on-Mathematical-Statistics-and Chapter/A-class-of-stopping-rules-for-testing-parametric-hypotheses/ bsmsp/1200514454.   \nYoan Russac, Louis Faury, Olivier Capp\u00e9, and Aur\u00e9lien Garivier. Self-Concordant Analysis of Generalized Linear Bandits with Forgetting. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pages 658\u2013666. PMLR, 13\u201315 Apr 2021. URL https://proceedings.mlr.press/v130/ russac21a.html.   \nDaniel Russo and Benjamin Van Roy. Learning to Optimize via Information-Directed Sampling. Operations Research, 66(1):230\u2013252, 2018. doi: 10.1287/opre.2017.1663. URL https://doi. org/10.1287/opre.2017.1663.   \nDaniel J. Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, and Zheng Wen. A Tutorial on Thompson Sampling. Foundations and Trends\u00ae in Machine Learning, 11(1):1\u201396, 2018. ISSN 1935-8237. doi: 10.1561/2200000070. URL http://dx.doi.org/10.1561/2200000070.   \nAyush Sawarni, Nirjhar Das, Siddharth Barman, and Gaurav Sinha. Generalized Linear Bandits with Limited Adaptivity. In Advances in Neural Information Processing Systems, volume 37. Curran Associates, Inc., 2024. URL https://arxiv.org/abs/2404.06831.   \nJack Sherman and Winifred J. Morrison. Adjustment of an Inverse Matrix Corresponding to a Change in One Element of a Given Matrix. The Annals of Mathematical Statistics, 21(1):124 \u2013 127, 1950. doi: 10.1214/aoms/1177729893. URL https://doi.org/10.1214/aoms/1177729893.   \nChengshuai Shi, Kun Yang, Zihan Chen, Jundong Li, Jing Yang, and Cong Shen. Efficient Prompt Optimization Through the Lens of Best Arm Identification. In Advances in Neural Information Processing Systems, volume 37. Curran Associates, Inc., 2024. URL https://arxiv.org/abs/ 2402.09723.   \nNiranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design. In Proceedings of The 27th International Conference on Machine Learning, pages 1015\u20131022, 2010. URL https://arxiv.org/abs/0912.3995.   \nWilliam R. Thompson. On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples. Biometrika, 25(3/4):285\u2013294, 1933. ISSN 00063444. URL http://www.jstor.org/stable/2332286.   \nJoel A. Tropp. An Introduction to Matrix Concentration Inequalities. Foundations and Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015. ISSN 1935-8237. doi: 10.1561/2200000048. URL http://dx.doi.org/10.1561/2200000048.   \nTim van Erven, Peter D. Gr\u00fcnwald, Nishant A. Mehta, Mark D. Reid, and Robert C. Williamson. Fast Rates in Statistical and Online Learning. Journal of Machine Learning Research, 16(54): 1793\u20131861, 2015. URL http://jmlr.org/papers/v16/vanerven15a.html.   \nRoman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint arXiv:1011.3027, 2010. URL https://arxiv.org/abs/1011.3027.   \nRoman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2018.   \nJean Ville. \u00c9tude critique de la notion de collectif. Monographies des Probabilit\u00e9s. Paris: GauthierVillars, 1939. URL http://eudml.org/doc/192893.   \nPauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St\u00e9fan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, \u02d9Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, Ant\u00f4nio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261\u2013272, 2020. doi: 10.1038/s41592-019-0686-2. URL https: //www.nature.com/articles/s41592-019-0686-2.   \nLarry Wasserman, Aaditya Ramdas, and Sivaraman Balakrishnan. Universal inference. Proceedings of the National Academy of Sciences, 117(29):16880\u201316890, 2020. doi: 10.1073/pnas.1922664117. URL https://www.pnas.org/doi/abs/10.1073/pnas.1922664117.   \nR. Wolke and H. Schwetlick. Iteratively Reweighted Least Squares: Algorithms, Convergence Analysis, and Numerical Comparisons. SIAM Journal on Scientific and Statistical Computing, 9 (5):907\u2013921, 1988. doi: 10.1137/0909062. URL https://doi.org/10.1137/0909062.   \nTong Zhang. Feel-Good Thompson Sampling for Contextual Bandits and Reinforcement Learning. SIAM Journal on Mathematics of Data Science, 4(2):834\u2013857, 2022. doi: 10.1137/21M140924X. URL https://doi.org/10.1137/21M140924X. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Yu-Jie Zhang and Masashi Sugiyama. Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost. In Advances in Neural Information Processing Systems, volume 36. Curran Associates, Inc., 2023. URL https://openreview.net/forum?id $=$ ofa1U5BJVJ. ", "page_idx": 17}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1 Introduction ", "page_idx": 18}, {"type": "text", "text": "2 Problem Setting 2 ", "page_idx": 18}, {"type": "text", "text": "3 Unified Likelihood Ratio-based Confidence Sequence for GLMs 3 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "3.1 Ellipsoidal Confidence Sequence for Self-Concordant GLMs 4   \n3.2 Proof of Theorem 3.1 \u2013 PAC-Bayes Approach with Uniform Prior 5   \n3.3 Intuitions Behind the Proof of Theorem 3.1 6 ", "page_idx": 18}, {"type": "text", "text": "OFUGLB: A Generic UCB Algorithm for Self-Concordant GLBs 6 ", "page_idx": 18}, {"type": "text", "text": "4.1 Proof Sketch of Theorem 4.1 \u2013 Regret Analysis of OFUGLB 7   \n4.2 Instantiations and Discussions of Theorem 4.1 . 8 ", "page_idx": 18}, {"type": "text", "text": "5 Experiments in Logistic Bandits 9 ", "page_idx": 18}, {"type": "text", "text": "6 Conclusion 10 ", "page_idx": 18}, {"type": "text", "text": "A Relations to Prior Works 20 ", "page_idx": 18}, {"type": "text", "text": "B Future Works 21 ", "page_idx": 18}, {"type": "text", "text": "C Missing Proofs from Table 1 \u2013 Bounding $L_{t}$ \u2019s 23 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 GLMs that are Bounded by $M$ 23   \nC.2 $\\sigma$ -subGaussian GLMs . 23   \nC.3 Poisson Distribution 24 ", "page_idx": 18}, {"type": "text", "text": "D Proof of Theorem 3.2 \u2013 Ellipsoidal Confidence Sequence 28 ", "page_idx": 18}, {"type": "text", "text": "E Proof of Theorem 4.1 \u2013 Regret Bound of OFUGLB 29 ", "page_idx": 18}, {"type": "text", "text": "E.1 Key Ideas of the Proof 29   \nE.2 Main Proof 30   \nE.3 Supporting Lemmas 34 ", "page_idx": 18}, {"type": "text", "text": "F Alternate CS via Discrete Uniform Prior and Covering Argument 36 ", "page_idx": 18}, {"type": "text", "text": "G.1 Implementation Details 38   \nG.2 Additional Results for Logistic Bandits with Fixed Arm-Set . 38 ", "page_idx": 18}, {"type": "text", "text": "A Relations to Prior Works ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "CSs for Exponential Family. Lai (1976) derived the first generic CS for the exponential family based on a generalized likelihood ratio. Their CS, however, only applies to scalar-valued unknown parameters, and instantiating it often requires solving an equation with no closed-form solution (e.g., $f_{n}$ and $g_{n}$ in Lai (1976)). Recently, Chowdhury et al. (2023) proposed a generic CS for exponential family expressed in the local Bregman geometry induced by the log-partition function. The proof relies on the method of mixtures (de la Pe\u00f1a et al., 2004; Kaufmann and Koolen, 2021), which resembles our PAC-Bayesian approach that utilizes a mixture of log-likelihood functions. One drawback is that their main result (Chowdhury et al., 2023, Theorem 3) is instantiated for scalar parameters (e.g., $\\mu\\in[0,1]$ for Bernoulli without observed feature vectors), and not for GLMs. While one can attempt to instantiate it to GLMs, we speculate that the resulting confidence set may not be convex since the prior itself is centered at the true parameter, unlike our choice of the prior. While we believe their second method (Chowdhury et al., 2023, Theorem 7) results in a convex set when instantiated to GLMs, the authors do not provide any computationally efficient way to evaluate the integral over the unknown parameter except for the Gaussian GLM. We mention in passing that their CS for Gaussian (Cho\u221awdhury et al., 202\u221a3, Appendix F) improves upon Abbasi-Yadkori et al. (2011) in the same manner $({\\sqrt{a+b}}\\leq{\\sqrt{a}}+{\\sqrt{b}})$ that Flynn et al. (2023) and ours do. ", "page_idx": 19}, {"type": "text", "text": "Fast Rates in Statistical Learning. Our goal is to obtain a tight CS for $\\theta_{\\star}$ , which is quite different from that of statistical learning, which is to obtain the optimal decay rate of the ERM. Although it is not immediately clear, we believe they have a connection. To illustrate our suspicion, we recall Example 10 of Gr\u00fcnwald and Mehta (2020). By taking a uniform prior over a function space ${\\mathcal{F}}^{7}$ and taking the posterior to be randomly sampling from $\\epsilon$ -ball centered at $\\hat{f}$ , the KL term becomes the metric entropy of $\\mathcal{F}$ , $\\log\\mathcal{N}(\\mathcal{F},\\epsilon)$ . Combining this with the Bernstein condition with exponent $\\beta$ , the ERM obtains the minimax rate of ${\\widetilde{O}}(n^{-1/(2-\\beta)})$ , which interpolates between the slow rate $\\widetilde{\\mathcal{O}}(n^{-1/2})$ and the fast rate $\\widetilde{\\mathcal{O}}(1/n)$ , where $n$ is the number of samples. This is similar to what we obtain by considering discrete uniform prior in our proof; see Appendix F for more details. We also remark that our proof of taking a prior over $\\mathcal{L}_{t}$ resembles improper learning and the $v$ -central condition (Foster et al., 2018; van Erven et al., 2015), which also outputs a mixture of predictors to obtain fast rates. ", "page_idx": 19}, {"type": "text", "text": "Randomized Exploration for GLBs. Somewhat orthogonal to UCB-based approaches (including ours), another line of works for GLBs (Abeille and Lazaric, 2017; Dong et al., 2019; Janz et al., 2024; Kim et al., 2023; Kveton et al., 2020) focuses on randomized exploration-based approaches. Kveton et al. (2020) proposed Thompson sampling and randomly perturbed history-based algorithms, both of which achieved a frequentist regret bound of $\\widetilde{\\mathcal{O}}(d\\kappa\\sqrt{T\\log K})$ for finite arm-set of size $K$ (Kveton et al., 2020, Theorem 3 & 5). Recently, Janz et al. (2024) proposed EVILL, which linearly perturbs the (regularized) log-likelihood loss that achieves a frequentist regret bound8 of $\\widetilde{\\mathcal{O}}(d^{3/2}\\sqrt{T/\\kappa_{\\star}(T)})$ for infinite arm-set (Janz et al., 2024, Theorem 1). In all cases, the extra factor of $\\sqrt{d}$ in the regret (due to posterior variance inflation) is shared across the randomized exploration-based approaches to GLBs (Abeille and Lazaric, 2017; Dong et al., 2019; Janz et al., 2024; Kim et al., 2023; Kveton et al., 2020) and is known to be unavoidable for linear Thompson sampling (Hamidi and Bayati, 2020). An interesting question is whether the intuitions from our PAC-Bayesian-derived CS can be combined with aggressive variants of Thompson sampling (e.g., Feel-Good Thompson Sampling of Li et al. (2024); Zhang (2022) or TS-UCB of Baek and Farias (2023)) to improve randomized exploration for GLBs. ", "page_idx": 19}, {"type": "text", "text": "B Future Works ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Extending our CS (Theorem 3.1) to RKHS. One may wonder if the framework in this paper can be extended to infinite dimensions, in which the covariate $\\textbf{\\em x}$ and unknown $\\theta_{\\star}$ are elements of some function space $\\mathcal{F}$ . Indeed, by exploiting the inner product structure of GLMs, in the case where $\\mathcal{F}=\\mathcal{H}_{k}$ is an RKHS with reproducing kernel $k$ (Paulsen and Raghupathi, 2016), the inner product $\\langle x,\\theta_{\\star}\\rangle$ can be replaced with $k(x,\\theta_{\\star})$ . In statistics literature, this is referred to as the kernelized or functional GLM (Cawley et al., 2007; M\u00fcller and Stadtm\u00fcller, 2005), and in bandits literature, this has been extensively studied under the name kernelized bandits (Chowdhury and Gopalan, 2017; Srinivas et al., 2010) as an infinite-dimensional generalization of linear bandits. ", "page_idx": 20}, {"type": "text", "text": "However, extending our CS to RKHS raises several issues, all related to the fact that the usual properties of finite-dimensional spaces often fail in infinite dimensions (Bogachev, 1998; Da Prato and Zabczyk, 2014). For instance, it is well-known that there exists no translation-invariant, locally finite, non-trivial Borel measure on infinite-dimensional Banach space (Oxtoby, 1946, Theorem 1). Then, it is entirely unclear how to extend our current PAC-Bayesian proof of Theorem 3.1 to infinite dimensions, as there is no uniform distribution or likelihood. ", "page_idx": 20}, {"type": "text", "text": "One promising alternate approach based on the Gaussian Process has been recently proposed by Neiswanger and Ramdas (2021), where the authors proposed a CS to quantify the uncertainty of GPs. The important point is that the CS is statistically valid even when the prior is misspecified. Still, in our context, choosing the mean and covariance to obtain similar guarantees (e.g., better dependency on $S^{\\prime}:=\\|\\pmb{\\theta}_{\\star}\\|_{k})$ is non-trivial. ", "page_idx": 20}, {"type": "text", "text": "Optimality of CS Radius (Theorem 3.1). Another interesting question is whether our CS radius in Theorem 3.1 is optimal. For general time-uniform estimation with i.i.d. samples, Duchi and Haque (2024) recently showed an information-theoretic lower bound of $\\Omega\\left(\\sqrt{\\frac{\\log\\log t}{t}}\\right)$ on the estimation error. It would be interesting to use a similar technique to show an information-theoretic lower bound on our CS radius for (self-concordant) GLMs, especially w.r.t. $S$ . ", "page_idx": 20}, {"type": "text", "text": "Regret Lower Bound for GLBs. One important open question here is the optimality of our obtained regret bound. As discussed in the Logistic Bandits paragraph of Section 4, the leading term of our regret bound for logistic bandits is (locally) minimax optimal in $d,T,\\kappa_{\\star}(T)$ relative to the lower bound of Abeille et al. (2021). A closer look into their proof shows that their lower bound additionally scales as $1/S$ , indicating a gap of $S$ between the lower and upper bounds. To the best of our knowledge, there is no generic regret lower bound for self-concordant GLBs, and we suspect that a similar $d\\sqrt{T/\\kappa_{\\star}(T)}$ lower bound holds. One could adapt the proof of Abeille et al. (2021) by modifying parts specific to Bernoulli (e.g., their relative entropy decomposition lemma (Lemma 6) relies on the fact that the reward distribution is Bernoulli), or come up with something new. ", "page_idx": 20}, {"type": "text", "text": "Arm-Set Geometry-Dependent Regret Analyses of OFUGLB. For the prior OFUL-type algorithms (Abeille et al., 2021; Lee et al., 2024), the transient term is $\\begin{array}{r l}{R_{\\mathcal{X}}(T)}&{{}:=}\\end{array}$ $\\begin{array}{r}{\\sum_{t=1}^{T}\\mu(\\langle x_{t,\\star},\\theta_{\\star}\\rangle)\\mathbb{1}[x_{t}\\,\\in\\,\\mathcal{X}_{-}(t)]}\\end{array}$ , where $\\chi_{-}(t)$ is the set of detrimental arms with a large reward gap and little information (small conditional variance). $R_{\\mathcal{X}}(T)$ is adaptive to the arm-set geometry and can be completely independent of $\\kappa$ for certain arm geometries (Abeille et al., 2021, Proposition 2). For the warmup-based algorithms (Faury et al., 2022; Mason et al., 2022; Sawarni et al., 2024), the transient term always scale with $\\kappa$ , which is not adaptive to the arm-set geometry. ", "page_idx": 20}, {"type": "text", "text": "Abeille et al. (2021) showed that via an arm-set geometry-dependent analysis for UCB, such $\\kappa$ -scaling transient term can be potentially avoided. However, as our regret analysis utilizes \u201cimplicit warmup\u201d, our transient term scales with $\\kappa(T)$ , which is not adaptive to the arm-set geometry. Thus, the natural question is whether a similar, arm-set geometry adaptive transient term is attainable for logistic bandits, while keeping the optimal $\\mathrm{poly}(S)$ -free leading term. Currently, it seems that the regret decomposition used in our analysis is incompatible with the arm-set geometry-dependent analysis, and we leave to future work for obtaining both characteristics $(\\mathrm{poly}(S)$ -free leading term, arm-set geometry-dependent transient term) for logistic bandits and GLBs in general. ", "page_idx": 20}, {"type": "text", "text": "The reason for being incompatible is as follows. Even when using our new CS (Theorem 3.1 in the regret analysis of Lee et al. (2024), one still obtains $\\tilde{\\mathcal{O}}(d S\\sqrt{T/\\kappa_{\\star}(T)}+R\\chi(T))$ , the same as Lee et al. (2024). This is because in their proof of Lemma 6, which involves deriving an ellipsoidal CS of the form $\\lVert\\theta-\\theta_{\\star}\\rVert_{H_{t}}\\leq\\gamma_{t}(\\delta)$ , the covering argument introduces a term in $\\gamma_{t}(\\delta)$ that always scales as $\\begin{array}{r}{d S^{2}\\log{\\frac{S t}{d}}}\\end{array}$ , regardless of the likelihood-ratio CS radius. This is unavoidable due to the use of previous self-concordance control (Abeille et al., 2021, Lemma 8), which gives an extra factor of $S$ , and the use of anytime Freedman\u2019s inequality (Lee et al., 2024, Lemma 3), which results in a multiplicative factor of $1/\\eta$ for some $\\eta\\le1/2S$ . In other words, attaining the best of both worlds may require thinking of an entirely new regret analysis technique. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Remark 3 (Detrimental arms for GLBs.). In Abeille et al. (2021), one key component for allowing such transient term that is adaptive to arm-set geometry is that there exists a ${\\mathcal{Z}}_{\\mu}\\subseteq\\mathbb{R}$ such that $\\operatorname*{sup}_{z\\in\\mathcal{Z}_{\\mu}}\\ddot{\\mu}(z)\\leq0,$ ; e.g., for logistic bandits $(\\mu(z)=(1+e^{-z})^{-1})$ , $\\mathcal{Z}=(-\\infty,0]$ . For general $\\mu_{\\scriptscriptstyle-}$ , we can define the set of detrimental arms as $\\mathcal{X}_{-}(t):=\\{\\pmb{x}\\in\\mathcal{X}_{t}:\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle\\in\\mathcal{Z}_{\\mu}\\}$ . Of course, the scaling of $R_{\\mathcal{X}}(T)$ depends on various factors, whose precise characterization for $\\mu$ \u2019s beyond the logistic function is left for future work. ", "page_idx": 21}, {"type": "text", "text": "Jointly Efficient and Optimal Algorithm for GLBs. Despite the statistical superiority of our CS (Theorem 3.1) and our regret bound (Theorem 4.1), it is computationally heavy, especially the UCB maximization (line 6 of Algorithm 1). Our ellipsoidal CS is computationally efficient, but it incurs additional factors of $S$ in the final regret bound. Then the question remains whether one could achieve order-wise the same regret guarantee for GLBs (e.g., $\\mathrm{poly}(S)$ -free for logistic bandits) while significantly improving the computational efficiency. One may, for instance, draw inspiration from recent progress in designing computationally efficient & statistically optimal algorithms for (multinomial) logistic bandits via online Newton steps (Faury et al., 2022; Zhang and Sugiyama, 2023). ", "page_idx": 21}, {"type": "text", "text": "Other Applications. It would be interesting to see if our new CS may lead to any improvements in algorithms for GLBs beyond OFU, e.g., information-directed sampling (Kirschner and Krause, 2018; Russo and Van Roy, 2018), best arm identification in GLBs (Azizi et al., 2022; Jun et al., 2021; Kazerouni and Wein, 2021), and even sample-efficient RLHF (Das et al., 2024; Shi et al., 2024). ", "page_idx": 21}, {"type": "text", "text": "C Missing Proofs from Table 1 \u2013 Bounding $L_{t}$ \u2019s ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "C.1 GLMs that are Bounded by $M$ ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Recall that the GLM is bounded by $M$ if for any $\\pmb{x}\\in X$ and $r\\sim p(\\cdot|\\mathbf{\\boldsymbol{x}},\\theta_{\\star})$ , the following holds almost surely: $|r-\\mu(\\langle\\pmb{x},\\pmb{\\theta}_{\\star})|\\leq\\dot{M}<\\infty$ . ", "page_idx": 22}, {"type": "text", "text": "Then, we have that for any $\\pmb\\theta\\in\\Theta$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\nabla{\\mathcal C}(\\theta)\\right|\\,{\\left\\vert{\\nabla{\\mathcal C}(\\theta)}\\right\\vert}\\,{\\left\\vert{\\frac{t-1}{s-1}}\\left(-r_{s}+\\mu\\left(x_{s},\\theta\\right)\\right)}\\right)x_{s}\\right\\vert_{\\geq}}\\\\ &{\\quad\\leq\\frac{1}{g(\\tau)}\\frac{t-1}{s-1}{\\left\\vert r_{s}-\\mu\\left(x_{s},\\theta\\right)\\right\\vert}\\left\\vert\\left\\vert{x}_{s}\\right\\vert\\right\\vert_{2}}\\\\ &{\\quad\\leq\\frac{1}{g(\\tau)}\\frac{t-1}{s-1}\\left({\\left\\vert r_{s}-\\mu(\\langle x_{s},\\theta_{*}\\rangle)\\right\\vert}+{\\left\\vert\\mu(\\langle x_{s},\\theta_{*}\\rangle)-\\mu(\\langle x_{s},\\theta\\rangle)\\right\\vert}\\right)}\\\\ &{\\quad\\leq\\frac{1}{g(\\tau)}\\frac{t-1}{s-1}\\left(M+R_{\\mu}\\left\\vert\\langle x_{s},\\theta_{*}-\\theta\\rangle\\right\\vert\\right)}\\\\ &{\\quad\\leq\\frac{(M+2S R_{\\mu})(t-1)}{g(\\tau)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "C.2 $\\sigma$ -subGaussian GLMs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We first recall some definitions: ", "page_idx": 22}, {"type": "text", "text": "Definition C.1. $A$ random variable $X~\\in~\\mathbb{R}$ is $\\sigma$ -subGaussian, if $\\mathbb{P}(\\left|X-\\mathbb{E}[X]\\right|\\ \\geq\\ t)\\ \\leq$ $\\begin{array}{r}{2\\exp\\left(-\\frac{t^{2}}{2\\sigma^{2}}\\right),\\;\\forall t\\in\\mathbb{R}.}\\end{array}$ . ", "page_idx": 22}, {"type": "text", "text": "Definition C.2 (Definition 3 of Jin et al. (2019)). A random vector $\\boldsymbol{X}\\in\\mathbb{R}^{d}$ is $\\sigma$ -norm-subGaussian, $\\begin{array}{r}{i f\\mathbb{P}(\\left\\|\\pmb{X}-\\mathbb{E}[\\pmb{X}]\\right\\|_{2}\\geq t)\\leq2\\exp\\left(-\\frac{t^{2}}{2\\sigma^{2}}\\right),\\;\\forall t\\in\\mathbb{R}.}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "Here is the full statement: ", "page_idx": 22}, {"type": "text", "text": "Proposition C.1. Suppose the GLM is $\\sigma$ -subGaussian. Then, for any $\\delta\\in(0,1)$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\exists t\\geq1:L_{t}>\\frac{2}{g(\\tau)}\\left(R_{\\hat{\\mu}}S(t-1)+2\\pi\\sigma\\sqrt{(t-1)\\log\\frac{\\pi^{2}d t^{2}}{3\\delta}}\\right)\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. Here, as $\\begin{array}{r}{\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X},\\pmb{\\theta}\\in\\Theta}|\\dot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}\\rangle)|\\leq R_{\\dot{\\mu}}}\\end{array}$ , we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{L_{t}=\\frac{1}{g(\\tau)}\\operatorname*{max}_{\\theta\\in\\Theta}\\left\\|\\sum_{s=1}^{t-1}(r_{s}-\\mu(\\langle x_{s},\\theta\\rangle))x_{s}\\right\\|_{2}}}\\\\ {\\displaystyle{\\leq\\frac{1}{g(\\tau)}\\operatorname*{max}_{\\theta\\in\\Theta}\\left\\|\\sum_{s=1}^{t-1}(\\mu(\\langle x_{s},\\theta\\rangle)-\\mu(\\langle x_{s},\\theta_{\\star}\\rangle))x_{s}\\right\\|_{2}+\\frac{1}{g(\\tau)}\\left\\|\\sum_{s=1}^{t-1}(r_{s}-\\mu(\\langle x_{s},\\theta_{\\star}\\rangle))x_{s}\\right\\|_{2}}}\\\\ {\\displaystyle{\\leq\\frac{2R_{\\mu}S(t-1)}{g(\\tau)}+\\frac{1}{g(\\tau)}\\left\\|\\sum_{s=1}^{t-1}y_{s}\\right\\|_{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We now utilize subGaussian concentrations from Jin et al. (2019). First note that $\\pmb{y}_{s}$ is a martingale difference sequence adapted to $\\Sigma_{s}$ and is norm-subGaussian with (conditional) variance $\\sigma^{2}$ be given. ", "page_idx": 22}, {"type": "text", "text": "Then, by Corollary 7 of Jin et al. (2019), we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left\\lVert\\sum_{s=1}^{t-1}\\pmb{y}_{s}\\right\\rVert_{2}\\leq4\\pi\\sigma\\sqrt{(t-1)\\log\\frac{2d}{\\delta}}\\right)\\geq1-\\delta,\\quad\\forall t\\geq1.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The exact constant $4\\pi$ is not available in Jin et al. (2019), as all the constants are hidden under $c$ . This is not useful, especially for practitioners wanting to use the concentration directly. Thus, we tracked the constant from their Corollary 7, the details of which we provide in Lemma C.1. ", "page_idx": 23}, {"type": "text", "text": "We then conclude by replacing $\\delta$ with $\\delta/t^{2}$ and applying union bound over $t\\geq1$ , which yields the Basel sum. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Lemma C.1 (Lemma 2 of Jin et al. (2019); originally Lemma 5.5 of Vershynin (2010)). For any $\\sigma$ -norm-subGaussian random vector $\\mathbf{\\deltaX}$ , we have that $\\begin{array}{r}{\\operatorname*{sup}_{p\\in\\mathbb{N}}p^{-1/2}\\left(\\mathbb{E}[\\|X\\|^{p}]\\right)^{1/p}\\leq\\sqrt{\\pi}\\sigma.}\\end{array}$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. This follows from brute-force computation. First, we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\|X\\|^{p}]=\\displaystyle\\int_{0}^{\\infty}\\mathbb{P}[\\|X\\|^{p}\\ge t]d t=p\\displaystyle\\int_{0}^{\\infty}\\mathbb{P}[\\|X\\|\\ge t]t^{p-1}d t\\le2p\\displaystyle\\int_{0}^{\\infty}t^{p-1}\\exp\\left(-\\frac{t^{2}}{2\\sigma^{2}}\\right)d t}\\\\ {=2^{\\frac{p-1}{2}}\\sigma^{p}p\\Gamma\\left(\\frac{p}{2}\\right).\\qquad\\qquad\\qquad\\qquad\\qquad=2^{\\frac{p-1}{2}}\\sigma^{p}p^{\\prime}\\left(\\frac{p}{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let us denote $f(p):=p^{-1/2}\\left(\\mathbb{E}[\\|X\\|^{p}]\\right)^{1/p}$ for $p\\in\\mathbb N$ . ", "page_idx": 23}, {"type": "text", "text": "Then, using well-known properties of the Gamma function, we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(2p)=\\sigma2^{\\frac{2p-1}{4p}}(2p)^{\\frac{1}{2p}-\\frac{1}{2}}\\left((p-1)!\\right)^{\\frac{1}{2p}}=\\sigma\\sqrt{p^{-1}\\left(\\sqrt{2}p!\\right)^{\\frac{1}{p}}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and ", "page_idx": 23}, {"type": "equation", "text": "$$\n^{\\tau}(2p-1)=\\sigma2^{\\frac{2p-2}{2(2p-1)}}(2p-1)^{\\frac{1}{2p-1}-\\frac{1}{2}}\\left(\\sqrt{\\pi}\\frac{(2p-3)!!}{2^{p-1}}\\right)^{\\frac{1}{2p-1}}=\\sigma(2p-1)^{\\frac{1}{2p-1}-\\frac{1}{2}}\\left(\\sqrt{\\pi}(2p-3)!!\\right)^{\\frac{1}{2p-1}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we define $(-1)!!:=1$ . ", "page_idx": 23}, {"type": "text", "text": "Then, we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(2p)\\stackrel{(i)}{<}\\sigma\\sqrt{p^{-1}(\\sqrt{2}p^{p})^{\\frac{1}{p}}}=\\sigma2^{\\frac{1}{4p}}\\leq\\sigma2^{\\frac{1}{4}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $(i)$ follows from $p!<p^{p}$ . We also have that ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(2p-1)\\stackrel{(i)}{<}\\sigma(2p-1)^{\\frac{1}{2p-1}-\\frac{1}{2}}\\left(\\sqrt{\\pi}(2p-1)^{p}\\right)^{\\frac{1}{2p-1}}\\stackrel{(i i)}{<}\\sigma\\left(\\sqrt{\\pi}(2p-1)\\right)^{\\frac{1}{2p-1}}\\stackrel{(i i i)}{<}\\sigma\\sqrt{\\pi},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $(i)$ follows from $(2p\\!-\\!3)!!<(2p\\!-\\!1)^{p},(i i)$ follows from $\\begin{array}{r}{\\frac{p}{2p-1}>\\frac{1}{2}}\\end{array}$ , a\u221and $(i i i)$ follows fr\u221aom the observations that for $z\\geq e$ , $f(z)=(\\sqrt{\\pi}z)^{1/z}$ is decreasing9, and $f(1)=\\sqrt{\\pi}>f(3)=(3\\sqrt{\\pi})^{1/3}$ . Finally, as $2^{1/4}<{\\sqrt{\\pi}}$ , we have that $\\operatorname*{sup}_{p\\in\\mathbb{N}}f(p)\\leq{\\sqrt{\\pi}}\\sigma$ . ", "page_idx": 23}, {"type": "text", "text": "C.3 Poisson Distribution ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We have the following result for Poisson, which may be of independent interest (to our knowledge, this is the first explicit martingale concentration for Poisson in the GLM form): ", "page_idx": 23}, {"type": "text", "text": "Proposition C.2. For the Poisson distribution, we have that for any $\\delta\\in(0,1)$ : when $S>1$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(L_{t}\\le C(S)(t-1)+\\frac{2}{1-2e^{-S}}\\log\\frac{\\pi^{2}(d+1)t^{2}}{3\\delta}\\right)\\ge1-\\delta,\\quad\\forall t\\ge1,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\begin{array}{r}{C(S):=\\frac{1}{4}(1-2e^{-S})(e^{S}+2S+2\\log\\frac{2(1-2e^{-S})}{e})+2S e^{S}}\\end{array}$ . When $S\\le1$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(L_{t}\\leq\\tilde{C}(S)(t-1)+4\\log\\frac{\\pi^{2}(d+1)t^{2}}{3\\delta}\\right)\\geq1-\\delta,\\quad\\forall t\\geq1,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\begin{array}{r}{\\tilde{C}(S):=\\frac{1}{16}\\left(e^{S}+4S+4\\log(8+2e^{S})\\right)+2S e^{S}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Proof. Proceeding similarly as in the previous subsection, we first have that ", "page_idx": 24}, {"type": "equation", "text": "$$\nL_{t}\\leq2S e^{S}(t-1)+\\left\\|\\sum_{s=1}^{t-1}y_{s}\\right\\|_{2},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where ${\\pmb y}_{s}\\,=\\,(r_{s}\\,-\\,e^{\\langle{\\pmb x}_{s},{\\pmb\\theta}_{\\star}\\rangle}){\\pmb x}_{s}$ is the martingale difference sequence satisfying $\\mathbb{E}[y_{s}|\\Sigma_{s}]\\,=\\,\\mathbf{0}$ as $r_{s}|\\Sigma_{s}\\sim\\mathrm{Poi}(\\langle\\pmb{x}_{s},\\pmb{\\theta}_{\\star}\\rangle)$ . ", "page_idx": 24}, {"type": "text", "text": "We now modify the proof of Corollary 7 of Jin et al. (2019) (which is based upon the celebrated Chernoff-Cram\u00e9r method) for the Poisson martingale vectors, details of which we provide here for completeness. ", "page_idx": 24}, {"type": "text", "text": "First, we consider the following MGF bound of the Poisson distribution whose proof is deferred to the end of this subsection: ", "page_idx": 24}, {"type": "text", "text": "Lemma C.2. Suppose that the random vector $\\textit{\\textbf{y}}$ is of the form ${\\pmb y}\\;=\\;(r\\,-\\,\\lambda){\\pmb x}$ for some fixed $\\pmb{x}\\in B^{d}(1)$ , $r\\sim\\mathrm{Poi}(\\lambda)$ , and $\\lambda>0$ . Then, for the Hermitian dilation (Tropp, 2015, Definition 2.1.5) of y, $Y:=\\left[\\!\\!{\\begin{array}{c c}{{0}}&{{y^{\\top}}}\\\\ {{y}}&{{0}}\\end{array}}\\!\\!\\right]$ , we have that $\\mathbb{E}e^{\\theta Y}\\preceq\\exp\\left(F(\\theta,\\lambda)\\right)I_{d+1}$ for $|\\theta|<\\,\\frac{1}{2}$ , where $F(\\theta,\\lambda):=$ $\\begin{array}{r}{\\lambda|\\theta|+\\log(2|\\theta|)+\\log{\\left(\\frac{e^{-\\frac{\\lambda}{2}}}{\\frac{1}{2}-|\\theta|}+\\lambda\\right)}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "We also recall the Lieb\u2019s trace inequality: ", "page_idx": 24}, {"type": "text", "text": "Theorem C.3 (Theorem 6 of Lieb (1973)). Let $\\pmb{A}$ be a fixed symmetric matrix, and let $\\mathbf{Y}$ be $a$ random symmetric matrix. Then, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\operatorname{tr}(\\exp(\\mathbf{A}+\\mathbf{Y}))\\leq\\operatorname{tr}\\exp(A+\\log\\mathbb{E}e^{\\mathbf{Y}})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Now let $0<\\theta<{\\frac{1}{2}}$ be fixed, and let us denote $\\mathbf{\\boldsymbol\\lambda}_{s}:=e^{\\langle\\mathbf{\\boldsymbol{x}}_{s},\\mathbf{\\boldsymbol{\\theta}}_{\\star}\\rangle}$ and $\\mathbb{E}_{s}[\\cdot]:=\\mathbb{E}[\\cdot|\\Sigma_{s}]$ for $s\\leq t-1$ . We start by noting that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\{\\exp\\left(-\\theta^{2}L_{1+\\frac{1}{\\alpha}}\\!\\!\\!\\int_{0}^{t}(\\theta,\\lambda_{\\alpha})+\\frac{\\theta^{\\star-1}}{\\alpha}Y_{*}\\right)}\\\\ &{=\\mathbb{E}\\left[\\mathbb{E}_{\\theta^{\\star-1}}\\left[\\mathrm{trexp}\\left(-\\theta^{q}L_{1+\\frac{1}{\\alpha}}\\!\\!\\!\\sum_{k=0}^{t-1}F(\\theta,\\lambda_{\\alpha})+\\frac{\\theta^{\\star-1}}{\\alpha}Y_{*}^{\\star}\\right)\\right]\\right]}\\\\ &{\\leq\\mathbb{E}\\left[\\mathrm{trexp}\\left(-\\theta^{q}L_{1+\\frac{1}{\\alpha}}\\!\\!\\!\\int_{0}^{t}(\\theta,\\lambda_{\\alpha})+\\theta\\!\\!\\!\\sum_{k=1}^{t-2}Y_{*}+\\log Z_{*-1}\\right)\\right]\\right]\\quad\\mathrm{~(Theoren~C3)}}\\\\ &{\\leq\\mathbb{E}\\left[\\mathrm{trexp}\\left(-\\theta^{q}L_{1+\\frac{1}{\\alpha}}\\!\\!\\!\\!\\sum_{k=0}^{t-1}F(\\theta,\\lambda_{\\alpha})+\\underbrace{\\theta^{\\star-2}}_{\\theta=1}Y_{*}+F(\\theta,\\lambda_{\\alpha})\\right)\\!\\!\\!\\prod_{\\substack{k=0}}\\!\\!\\!\\!\\int_{0}^{t}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\leq\\cdots\\leq\\mathrm{tr}\\exp(0I_{d+1})=d+1.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, for any $\\rho\\ge0$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{P}\\left(\\left\\|\\displaystyle\\sum_{s=1}^{t-1}\\pmb{y}_{s}\\right\\|\\geq\\theta\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\frac{\\rho}{\\theta}\\right)}\\\\ {\\displaystyle=\\mathbb{P}\\left(\\left\\|\\displaystyle\\sum_{s=1}^{t-1}\\pmb{Y}_{s}\\right\\|\\geq\\theta\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\frac{\\rho}{\\theta}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "$(\\sum_{s}Y_{s}$ is a rank-2 matrix with eigenvalues $\\pm\\left\\|\\sum_{s}{\\pmb y}_{s}\\|_{2}\\right)$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{=2\\mathbb{P}\\left(\\lambda_{\\operatorname*{max}}\\left(\\frac{t-1}{\\sum_{s=1}^{N}\\mathbf{r}_{s}}\\right)\\geq\\theta\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\frac{\\rho}{\\theta}\\right)\\quad}&{\\quad\\mathbb{(P}_{s}^{*}\\mathrm{~sare~symmetric})}\\\\ &{=2\\mathbb{P}\\left(\\lambda_{\\operatorname*{max}}\\left(\\exp\\left(\\theta\\displaystyle\\sum_{s=1}^{t-1}Y_{s}\\right)\\right)\\geq\\exp\\left(\\theta^{2}\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\rho\\right)\\right)}\\\\ &{\\leq2\\mathbb{P}\\left(\\mathrm{trexp}\\left(\\theta\\displaystyle\\sum_{s=1}^{t-1}Y_{s}\\right)\\geq\\exp\\left(\\theta^{2}\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\rho\\right)\\right)}\\\\ &{\\leq2e^{-\\rho}\\mathrm{Etrexp}\\left(-\\theta^{2}\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\theta\\displaystyle\\sum_{s=1}^{t-1}Y_{s}\\right)\\quad}&{\\quad\\mathrm{(Mateors~inequality)}}\\\\ &{\\leq2e^{-\\rho}\\mathrm{Etrexp}\\left(-\\theta^{2}\\displaystyle\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\theta\\displaystyle\\sum_{s=1}^{t-1}Y_{s}\\right)\\quad}&{\\quad\\mathrm{(Mateors~inequality)}}\\\\ &{\\leq2(d+1)e^{-\\rho}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Finally, by reparametrizing, we have that for any $\\delta\\in(0,1)$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left\\lVert\\sum_{s=1}^{t-1}y_{s}\\right\\rVert\\geq\\operatorname*{inf}_{\\theta\\in(0,1/2)}\\left\\{\\theta\\sum_{s=1}^{t-1}F(\\theta,\\lambda_{s})+\\frac{1}{\\theta}\\log\\frac{2d}{\\delta}\\right\\}\\right)\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we recall that $\\begin{array}{r}{F(\\theta,\\lambda)=\\lambda\\theta+\\log(2\\theta)+\\log\\left(\\frac{e^{-\\frac{\\lambda}{2}}}{\\frac{1}{2}-\\theta}+\\lambda\\right)\\mathrm{for}\\,\\theta>0.}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "First, when $S>1$ , let us choose $\\theta\\,=\\,{\\textstyle{\\frac{1}{2}}}\\,-\\,e^{-S}$ , which is guaranteed to be positive. Noting that $\\lambda_{s}=e^{\\langle\\pmb{x}_{s},\\pmb{\\theta}_{\\star}\\rangle}\\leq e^{S}$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\gamma\\left(\\frac{1}{2}-e^{-S},\\lambda_{s}\\right)\\leq e^{S}\\left(\\frac{1}{2}-e^{-S}\\right)+\\log(1-2e^{-S})+\\log(2e^{S})=\\frac{1}{2}e^{S}+S+\\log\\frac{2(1-2e^{-S})}{e}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, the RHS of Eqn. (15) ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\frac{(1-2e^{-S})(e^{S}+2S+2\\log\\frac{2(1-2e^{-S})}{e}(t-1)+\\frac2{1-2e^{-S}}\\log\\frac{2(d+1)}{\\delta}.}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For the case $S\\le1$ , choosing $\\theta={\\textstyle{\\frac{1}{4}}}$ , the RHS becomes ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\frac{e^{S}+4S+4\\log(8+2e^{S})}{16}(t-1)+4\\log\\frac{2(d+1)}{\\delta}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Finally, we conclude by parametrizing $\\delta$ as $\\delta/t^{2}$ , applying union bound over $t\\geq1$ , and using the Basel sum. ", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma C.2. We first have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}e^{\\theta Y}\\stackrel{(\\ast)}{=}I_{d+1}+\\displaystyle\\sum_{p=1}^{\\infty}\\frac{\\theta^{p}\\mathbb{E}Y^{2p}}{(2p)!}\\preceq I_{d+1}+\\displaystyle\\sum_{p=1}^{\\infty}\\frac{\\theta^{2p}\\mathbb{E}\\left\\lVert y\\right\\rVert^{2p}}{(2p)!}I_{d+1}=\\mathbb{E}\\left[\\frac{e^{\\theta\\left\\lVert y\\right\\rVert}+e^{-\\theta\\left\\lVert y\\right\\rVert}}{2}\\right]I_{d+1}}\\\\ &{}&{\\preceq\\mathbb{E}\\left[e^{|\\theta||r-\\lambda|}\\right]I_{d+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $(*)$ follows from the observation that $\\mathbb{E}Y^{2p+1}=\\mathbf{0}$ . We now recall a concentration result for Poisson distribution: ", "page_idx": 26}, {"type": "text", "text": "Lemma C.3 (Theorem 1 of the note by C. Canonne). $\\mathbb{P}(|r-y|\\geq x)\\leq2e^{-\\frac{x^{2}}{2(\\lambda+x)}}.$ ", "page_idx": 26}, {"type": "text", "text": "Then, we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{\\rho}(\\theta^{(n)}|^{2}\\cdots)\\Big|=\\int_{0}^{\\infty}\\mathbb{F}(\\theta^{(n)}|^{2}\\cdots)\\times j d\\theta}&{\\quad{\\mathrm{(dif~is~thegise~for~notante)}}}\\\\ &{\\le1+\\int_{0}^{\\infty}\\mathbb{F}(\\theta^{(n)}|^{2}\\cdots)\\times j d\\theta\\,d\\theta}\\\\ &{\\le2\\int_{0}^{\\infty}{e^{-\\pi\\frac{n\\theta^{(n)}\\theta^{(n)}}{2}\\theta}}d\\theta}\\\\ &{=2\\theta|\\int_{0}^{\\infty}{e^{-\\pi\\frac{n\\theta^{(n)}}{2}+|\\theta|}}d\\theta|}\\\\ &{=2\\theta^{\\ast}\\bigg\\{\\int_{0}^{\\infty}{e^{-\\pi\\frac{n\\theta^{(n)}}{2}+|\\theta|}}d\\theta}\\\\ &{=2\\theta^{\\ast}\\bigg\\{\\int_{0}^{\\infty}{e^{-\\pi\\frac{\\theta^{(n)}}{2}+|\\theta|}}d\\theta}\\bigg(\\int_{0}^{\\infty}{e^{-\\pi\\frac{n\\theta^{(n)}}{2}+|\\theta|}}d\\theta\\bigg\\}}\\\\ &{\\le2\\theta^{\\ast}\\bigg\\{\\int_{0}^{\\infty}{e^{-(1-\\theta)}d\\theta}d\\theta+\\delta\\theta^{(n)}\\bigg\\}\\qquad\\binom{n\\theta^{(n)}}{2\\prod_{\\mathrm{stan}}^{\\ast}}\\geq\\frac{1}{2}\\operatorname{infor}{\\theta}\\geq\\lambda_{n}}\\\\ &{\\leq2\\theta\\bigg(\\displaystyle\\frac{1}{2}-\\frac{1}{|\\theta|}e^{-(1-\\theta)}(\\lambda_{n}+\\lambda_{n}^{\\mathrm{(gn)}})}\\\\ &{=\\exp\\bigg(F(\\theta,\\Delta)\\bigg\\}\\triangleq\\Delta\\theta|+\\log(2\\theta)+\\log\\bigg(\\frac{e^{-\\theta}}{1-|\\theta|}+\\lambda\\bigg)\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "D Proof of Theorem 3.2 \u2013 Ellipsoidal Confidence Sequence ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "First, similarly to prior works on logistic bandits (Abeille et al., 2021; Lee et al., 2024), let us define the following quantities: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\tilde{G}_{t}(\\theta,\\nu):=\\frac{1}{g(\\tau)}\\sum_{s=1}^{t-1}\\tilde{\\alpha}_{s}(\\theta,\\nu)x_{s}x_{s}^{\\top},\\;\\tilde{\\alpha}_{s}(\\theta,\\nu):=\\int_{0}^{1}(1-v)\\dot{\\mu}\\left(\\langle x_{s},\\theta+v(\\nu-\\theta)\\rangle\\right)d v.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(We will later come back to these quantities in the regret analysis.) ", "page_idx": 27}, {"type": "text", "text": "Then, by Taylor\u2019s theorem with integral remainder and first-order optimality condition for convex constrained optimization10, we have that for any $\\lambda\\geq0$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\beta_{t}(\\delta)^{2}\\geq\\mathcal L_{t}(\\pmb\\theta)-\\mathcal L_{t}(\\widehat{\\pmb\\theta}_{t})=\\underbrace{\\langle\\nabla\\mathcal L_{t}(\\widehat{\\pmb\\theta}_{t}),\\pmb\\theta-\\widehat{\\pmb\\theta}_{t}\\rangle}_{\\geq0}+\\left\\|\\pmb\\theta-\\widehat{\\pmb\\theta}_{t}\\right\\|_{\\widetilde G_{t}(\\widehat{\\pmb\\theta}_{t},\\pmb\\theta)}^{2}}\\\\ {\\geq\\left\\|\\pmb\\theta-\\widehat{\\pmb\\theta}_{t}\\right\\|_{\\widetilde G_{t}(\\widehat{\\theta}_{t},\\pmb\\theta)+\\lambda{I}_{d}}^{2}-\\lambda\\left\\|\\pmb\\theta-\\widehat{\\pmb\\theta}_{t}\\right\\|_{2}^{2}}\\\\ {\\geq\\left\\|\\pmb\\theta-\\widehat{\\theta}_{t}\\right\\|_{\\widetilde G_{t}(\\widehat{\\theta}_{t},\\pmb\\theta)+\\lambda{I}_{d}}^{2}-4S^{2}\\lambda.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We conclude by using the self-concordance control for $\\tilde{G}$ (Abeille et al., 2021, Lemma 8), which we recall here: ", "page_idx": 27}, {"type": "text", "text": "Lemma D.1 (A slight extension of Lemma 8 of Abeille et al. (2021)). Let $\\mu$ be increasing $\\dot{\\mu}\\geq0$ , which is basically Assumption 3) and self-concordant with constant $R_{s}$ (as in Assumption 4). Let $\\mathcal{Z}\\subset\\mathbb{R}$ be bounded. Then, the following holds for any $z_{1},z_{2}\\in\\mathcal{Z}$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\int_{0}^{1}(1-v)\\dot{\\mu}(z_{1}+v(z_{2}-z_{1}))d v\\geq\\frac{\\dot{\\mu}(z_{1})}{2+R_{s}|z_{1}-z_{2}|}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "This then implies that $\\begin{array}{r}{\\widetilde{G}_{t}(\\pmb{\\theta},\\pmb{\\nu})\\succeq\\frac{1}{2+2S R_{s}}\\nabla^{2}\\mathcal{L}_{t}(\\pmb{\\theta}).}\\end{array}$ . ", "page_idx": 27}, {"type": "text", "text": "E Proof of Theorem 4.1 \u2013 Regret Bound of OFUGLB ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Let us denote $\\mu_{t}(\\cdot):=\\mu(\\langle\\pmb{x}_{t},\\cdot\\rangle)$ and $[a,b]:=\\{a,a+1,\\cdots\\,,b\\}$ for two integers $a\\leq b$ . We recall the following quantities: ", "page_idx": 28}, {"type": "equation", "text": "$$\nR_{\\mu,\\star}:=\\operatorname*{max}_{\\pmb{x}\\in X}|\\mu(\\langle\\pmb{x},\\pmb{\\theta}_{\\star}\\rangle)|,\\quad R_{\\dot{\\mu}}:=\\operatorname*{max}_{\\pmb{x}\\in X,\\pmb{\\theta}\\in\\Theta}\\dot{\\mu}(\\langle\\pmb{x},\\pmb{\\theta}\\rangle).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "E.1 Key Ideas of the Proof ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We will first expand upon the proof sketch provided in Section 4.1 of the main text. Recall the UCB strategy: $(\\pmb{x}_{t},\\pmb{\\theta}_{t})\\leftarrow\\arg\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}_{t},\\pmb{\\theta}\\in\\mathcal{C}_{t}}\\langle\\pmb{x},\\pmb{\\theta}\\rangle$ . ", "page_idx": 28}, {"type": "text", "text": "Why Prior Proof Technique Fails. We first show that even though we have a tight CS (Theorem 3.1), na\u00efvely combining it with existing regret analyses of logistic bandits (Abeille et al., 2021; Lee et al., 2024) still results in an extra factor of $S$ in the leading term. To see this, let us first recall the existing analyses. ", "page_idx": 28}, {"type": "text", "text": "The prior proof starts by bounding the regret by $\\begin{array}{r}{\\sum_{t=1}^{T}\\langle\\dot{\\mu}_{t}(\\pmb{\\theta}_{\\star})\\pmb{x}_{t},\\pmb{\\theta}_{t}-\\pmb{\\theta}_{\\star}\\rangle}\\end{array}$ (which follows from optimism and first-order Taylor expansion), plus a lower-order term that is easy to control. The first term becomes the leading regret we will now focus on. Using the Cauchy-Schwartz inequality w.r.t. the (regularized) Hessian $\\begin{array}{r}{H_{t}(\\pmb{\\theta}_{\\star})=\\lambda I+\\nabla^{2}\\mathcal{L}_{t}(\\pmb{\\theta}_{\\star})=\\lambda I+\\sum_{s=1}^{t-1}\\dot{\\mu}_{s}(\\pmb{\\theta}_{\\star})\\pmb{x}_{s}\\pmb{x}_{s}^{\\top}}\\end{array}$ , each summand is bounded as ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\dot{\\mu}}_{t}(\\theta_{\\star})\\langle x_{t},\\theta_{t}-\\theta_{\\star}\\rangle\\le{\\dot{\\mu}}_{t}(\\theta_{\\star})\\left\\|x_{t}\\right\\|_{H_{t}(\\theta_{\\star})^{-1}}\\left(\\left\\|\\theta_{t}-\\widehat\\theta_{t}\\right\\|_{H_{t}(\\theta_{\\star})}+\\left\\|\\theta_{\\star}-\\widehat\\theta_{t}\\right\\|_{H_{t}(\\theta_{\\star})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The prior proof then uses Taylor expansion (again) and self-concordant control (Abeille et al., 2021, Lemma 8) to obtain $\\lVert\\pmb{\\theta}_{t}-\\widehat{\\pmb{\\theta}_{t}}\\rVert_{H_{t}(\\pmb{\\theta}_{\\star})}\\,=\\,\\mathcal{O}\\left(S\\beta_{T}(\\delta)^{2}\\right)$ from the likelihood-based confidence set $\\mathcal{L}_{t}(\\pmb{\\theta}_{t})-\\mathcal{L}_{t}(\\widehat{\\pmb{\\theta}}_{t})\\leq\\beta_{T}(\\delta)^{2}$ , which introduces a factor of $S$ . This then leads to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t}\\dot{\\mu}_{t}(\\theta_{\\star})\\langle x_{t,\\star}-x_{t},\\theta_{\\star}\\rangle\\lesssim S\\beta_{T}(\\delta)^{2}\\underbrace{\\sqrt{\\sum_{t}\\dot{\\mu}_{t}(\\theta_{\\star})}}_{\\leq\\sqrt{T/\\kappa_{\\star}(T)}}\\underbrace{\\sqrt{\\sum_{t}\\left\\|\\sqrt{\\dot{\\mu}_{t}(\\theta_{\\star})}x_{t}\\right\\|_{H_{t}(\\theta_{\\star})^{-1}}^{2}}}_{\\mathrm{elipitical~potential~lemma~(Abasi-Yadkori~et~a,~2011)}},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "resulting in a regret whose leading term is $n o t\\,\\mathrm{poly}(S)$ -free. ", "page_idx": 28}, {"type": "text", "text": "Towards Our Approach. To obtain a $\\mathrm{poly}(S)$ -free leading term in the regret, we maximally avoid the self-concordance lemma (Abeille et al., 2021, Lemma 8). To do this, our proof begins by obtaining an elliptical CS w.r.t. $\\widetilde{G}_{t}(\\widehat{\\pmb{\\theta}}_{t})$ , derived from the first-order Taylor expansion of $\\mathcal{L}_{t}(\\cdot)$ at $\\widehat{\\pmb{\\theta}}_{t}^{\\phantom{\\dagger}}$ . With this, we have that $\\lVert\\theta_{\\star}-\\widehat{\\theta}_{t}\\rVert_{\\widetilde{G}_{t}(\\widehat{\\theta}_{t})}=\\mathcal{O}(\\beta_{T}(\\delta)^{2})$ (Lemma E.6), avoiding the extra $S$ compared to the prior proof that derives an elliptical CS w.r.t. $H_{t}(\\pmb\\theta_{\\star})$ . ", "page_idx": 28}, {"type": "text", "text": "However, the main difficulty of the proof is that $\\widetilde{G}_{t}(\\widehat{\\pmb{\\theta}}_{t})$ is not in a suitable form for elliptical potential arguments. To see this clearly, consider the  following natural optimistic upper-bound of the instantaneous regret: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mu(\\langle x_{t,\\star},\\theta_{\\star}\\rangle)-\\mu_{t}(\\pmb\\theta_{\\star})\\leq\\mu_{t}(\\pmb\\theta_{t})-\\mu_{t}(\\pmb\\theta_{\\star})}&{}\\\\ {=\\mu_{t}(\\pmb\\theta_{t})-\\mu_{t}(\\widehat\\pmb\\theta_{t})-\\mu_{t}(\\widehat\\pmb\\theta_{t})+\\mu_{t}(\\pmb\\theta_{\\star})}&{}\\\\ {\\leq2|\\mu_{t}(\\pmb\\theta_{t}^{\\prime})-\\mu_{t}(\\widehat\\pmb\\theta_{t})|}&{}\\\\ {\\lesssim\\dot{\\mu}_{t}(\\widehat\\pmb\\theta_{t})|\\langle x_{t},\\theta_{t}^{\\prime}-\\widehat\\theta_{t}\\rangle|+\\mathrm{lower~order~terms},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\pmb{\\theta}_{t}^{\\prime}=\\arg\\operatorname*{max}_{\\pmb{\\theta}\\in\\mathcal{C}_{t}}|\\mu_{t}(\\pmb{\\theta})-\\mu_{t}(\\widehat{\\pmb{\\theta}}_{t})|$ . One can then apply the aforementioned Cauchy-Schwarz w.r.t. $\\widetilde{G}_{t}(\\widehat{\\pmb{\\theta}}_{t})$ to obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\dot{\\mu}_{t}(\\widehat{\\theta}_{t})|\\langle x_{t},\\theta_{t}^{\\prime}-\\widehat{\\theta}_{t}\\rangle|\\leq\\dot{\\mu}_{t}(\\widehat{\\theta}_{t})\\,\\|x_{t}\\|_{\\widetilde{G}_{t}(\\widehat{\\theta}_{t})^{-1}}\\,\\|\\theta_{t}-\\widehat{\\theta}_{t}\\|_{\\widetilde{G}_{t}(\\widehat{\\theta}_{t})}\\lesssim\\dot{\\mu}_{t}(\\widehat{\\theta}_{t})\\beta_{T}(\\delta)\\,\\|x_{t}\\|_{\\widetilde{G}_{t}^{-1}(\\widehat{\\theta}_{t})}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This successfully avoids using previous self-concordant control (Abeille et al., 2021, Lemma 8), and thus seemingly getting closer to obtaining a $\\mathrm{poly}(S)$ -free regret. Omitting details, the final step is to sum the above over $t\\in[T]$ and apply the elliptical potential lemma (EPL; Abbasi-Yadkori et al. (2011)). EPL is applicable only when $\\widetilde{\\widetilde{G}}_{t}(\\widehat{\\pmb{\\theta}}_{t})$ can be written as $\\lambda{\\pmb{I}}+\\sum_{s=1}^{t-1}\\dot{\\mu}_{s}(\\widehat{\\pmb{\\theta}}_{s}){\\pmb{x}}_{s}{\\pmb{x}}_{s}^{\\top}$ for some $\\lambda>0$ . However, as $\\begin{array}{r}{\\widetilde{\\pmb{G}}_{t}(\\widehat{\\pmb{\\theta}}_{t})=\\sum_{s=1}^{t-1}\\xi(\\pmb{x}_{s},\\widehat{\\pmb{\\theta}}_{t})\\pmb{x}_{s}\\pmb{x}_{s}^{\\top}}\\end{array}$ for some scalar function $\\xi_{s}$ , the EPL is not applicable due to the explicit dependency on $\\widehat{\\pmb{\\theta}}_{t}$ , not on $\\{\\widehat{\\theta}_{s}\\}_{s\\in[t-1]}$ . The most challenging part of our proof development is making EPL applicable to the summation resulting from some decomposition of the (instantaneous) regret while avoiding extra $S$ -dependencies. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "Our Approach. The key insight is that if we could designate a \u201cworst-case\u201d $\\overline{{\\pmb\\theta}}_{s}$ for each time step $s$ such that $\\begin{array}{r}{\\widetilde{G}_{t}(\\widehat{\\pmb{\\theta}_{t}})\\succeq\\lambda\\bar{I}+\\sum_{s=1}^{t-1}\\dot{\\mu}(\\overline{{\\pmb{\\theta}}}_{s})x_{s}x_{s}^{\\top}=:{Q}_{t}}\\end{array}$ , then we can perform the following: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\dot{\\mu}_{t}(\\widehat{\\pmb{\\theta}_{t}})|\\langle\\pmb{x}_{t},\\pmb{\\theta}_{t}^{\\prime}-\\widehat{\\pmb{\\theta}_{t}}\\rangle|\\leq\\dot{\\mu}_{t}(\\overline{{\\pmb{\\theta}}}_{t})|\\langle\\pmb{x}_{t},\\pmb{\\theta}_{t}^{\\prime}-\\widehat{\\pmb{\\theta}_{t}}\\rangle|+|\\dot{\\mu}_{t}(\\widehat{\\pmb{\\theta}_{t}})-\\dot{\\mu}_{t}(\\overline{{\\pmb{\\theta}}}_{t})||\\langle\\pmb{x}_{t},\\pmb{\\theta}_{t}^{\\prime}-\\widehat{\\pmb{\\theta}_{t}}\\rangle|}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the first term is now be bounded by $\\mathcal{O}\\left(\\dot{\\mu}_{t}(\\overline{{\\pmb{\\theta}}}_{t})\\beta_{T}(\\delta)\\|\\pmb{x}_{t}\\|_{\\pmb{Q}_{t}^{-1}}\\right)$ . We can now apply the EPL when summing over $t\\in[T]$ , thanks to the form of $Q_{t}$ . The second term turns out to be a lower order term via our new self-concordant control that doesn\u2019t give additional $S$ -dependency (Lemma E.3). ", "page_idx": 29}, {"type": "text", "text": "We note that this is analogous to the analysis of Logistic-UCB-2 in Faury et al. (2020), where a similar difficulty arose because their improved bonus $\\epsilon_{t,2}$ depends on the current estimate of the parameter as well (see their Lemma 4). They circumvent this issue by explicitly modifying the UCB algorithm to incorporate additional constraints on the \u201cadmissible log-odds,\u201d which leads to a computationally inefficient algorithm. Indeed, initially, we took a similar approach by either using a confidence set defined as an intersection over all the confidence sets used so far, or by using an additional constraint set $\\mathcal{W}_{t}$ as defined in Logistic-UCB-2 of Faury et al. (2020). However, either approach significantly increases the computational complexity. ", "page_idx": 29}, {"type": "text", "text": "We later discovered that we could resolve the issue without changing the confidence set through an alternate analysis, which is the current proof. Specifically, we consider the following decomposition of the instantaneous regret: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mu(\\langle x_{t,\\star},\\theta_{\\star}\\rangle)-\\mu_{t}(\\pmb{\\theta}_{\\star})\\leq\\mu_{t}(\\pmb{\\theta}_{t})-\\mu_{t}(\\pmb{\\theta}_{\\star})\\leq2|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\widehat{\\pmb{\\theta}}_{b(t)})|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where we define $\\begin{array}{r}{(b(t),\\nu_{t}):=\\arg\\operatorname*{max}_{b\\in[t,T],\\theta\\in\\mathcal{C}_{b}}|\\mu_{t}(\\theta)-\\mu_{t}(\\widehat{\\theta}_{b})|.}\\end{array}$ That is, we are bounding the instantaneous regret by how large the difference can be from the current confidence set and how large the difference can be from the future confidence sets. With this, we can then define $\\bar{\\pmb\\theta}_{t}:=$ $\\arg\\operatorname*{min}_{\\pmb{\\theta}\\in\\bigcup_{b\\in[t,T]}\\mathcal{C}_{b}}\\dot{\\mu}_{t}(\\pmb{\\theta})$ , which satisfies the aforementioned desired property. This is our main technical novelty that allows for us to bypass all the aforementioned difficulties. ", "page_idx": 29}, {"type": "text", "text": "Among the omitted details, we consider a slightly more intricate regret decomposition by considering timesteps in which the \"warmup conditions\" are satisfied and the remaining term, and we derive a novel self-concordance lemma that bounds the difference of $\\dot{\\mu}$ \u2019s with that of $\\mu$ \u2019s times $R_{s}$ (Lemma E.3) that does not incur additional $S$ -dependencies. We then utilize the elliptical potential count lemma (EPCL; Gales et al. (2022)) for the terms that do not satisfy such conditions, and the remaining terms follow the reasoning as detailed above. ", "page_idx": 29}, {"type": "text", "text": "E.2 Main Proof ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We defer the statements and proofs of the supporting lemmas to Appendix E.3, although we will provide relevant context when using those lemmas for the proof\u2019s duration. We first define the following crucial quantities that we have discussed in the proof sketch: for $\\lambda>0$ to be chosen later, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\bar{\\theta}_{t}:=\\underset{\\theta\\in\\bigcup_{b\\in[t,T]}\\mathcal{C}_{b}}{\\arg\\operatorname*{min}}\\,\\dot{\\mu}_{t}(\\pmb{\\theta}),\\quad(b(t),\\nu_{t}):=\\underset{b\\in[t,T],\\theta\\in\\mathcal{C}_{b}}{\\arg\\operatorname*{max}}\\,\\Big|\\mu_{t}(\\pmb{\\theta})-\\mu_{t}(\\widehat{\\pmb{\\theta}_{b}})\\Big|,\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\bar{H}_{t}:=2g(\\tau)\\lambda I+\\sum_{s=1}^{t-1}\\dot{\\mu}_{s}(\\bar{\\theta}_{s})x_{s}x_{s}^{\\top},\\quad V_{t}:=2g(\\tau)\\kappa(T)\\lambda I+\\sum_{s=1}^{t-1}x_{s}x_{s}^{\\top},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\tilde{\\alpha}_{t}(\\pmb\\theta,\\pmb\\nu):=\\int_{0}^{1}(1-v)\\dot{\\mu}_{t}\\left(\\pmb\\theta+v(\\pmb\\nu-\\pmb\\theta)\\right)d v,\\quad\\tilde{G}_{t}(\\pmb\\theta,\\pmb\\nu):=\\lambda I+\\frac{1}{g(\\tau)}\\sum_{s=1}^{t-1}\\tilde{\\alpha}_{s}(\\pmb\\theta,\\pmb\\nu)\\pmb x_{s}\\pmb x_{s}^{\\top}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "$\\bar{\\pmb{\\theta}}_{t}$ in the union of future confidence sets, combined with the \u201cwarmup conditions\u201d allows for the elliptical potential lemma (EPL; Lemma E.2) and elliptical potential count lemma (EPCL; Lemma E.1) to be directly applicable, avoiding dependencies on $\\mathrm{poly}(S)$ and $\\kappa$ in the leading term; refer to the expanded proof sketch above for a more detailed explanation of the intuition. ", "page_idx": 30}, {"type": "text", "text": "Throughout, let us assume that the event $\\{\\forall t\\geq1,\\,\\theta_{\\star}\\in\\mathcal{C}_{t}\\}$ holds, which is with probability at least $1-\\delta$ by Theorem 3.1. ", "page_idx": 30}, {"type": "text", "text": "Regret Decomposition. Define the set of timesteps satisfying the \u201cwarmup conditions\u201d: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{T}:=\\left\\{t\\in[T]:\\left(\\left\\|\\sqrt{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})}x_{t}\\right\\|_{\\bar{H}_{t}^{-1}}\\geq1\\right)\\ \\vee\\ \\left(\\left\\|x_{t}\\right\\|_{V_{t}^{-1}}\\geq1\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then we have the following regret decomposition: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{Reg}(T)=\\sum_{t\\in\\mathcal{T}_{T}}\\left\\{\\mu((x_{t,*},\\theta_{*}))-\\mu(\\langle x_{t},\\theta_{*}\\rangle)\\right\\}+\\sum_{t\\in\\mathcal{T}_{T}}\\left\\{\\mu(\\langle x_{t,*},\\theta_{*}\\rangle)-\\mu(\\langle x_{t},\\theta_{*}\\rangle)\\right\\}}}\\\\ &{}&{\\stackrel{\\leqq}{\\underbrace{\\mu\\mathcal{R}_{\\mu,*}\\left[\\mathcal{Z}_{T}\\right]}}}\\\\ &{}&{\\leq2R_{\\mu,*}|\\mathcal{Z}_{T}|+\\mathrm{Reg}_{\\mathcal{Z}}(T)\\,}\\\\ &{}&{\\leq2R_{\\mu,*}\\sum_{t\\in\\mathcal{T}_{T}}\\mathbb{1}\\left[\\left\\|\\sqrt{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})}x_{t}\\right\\|_{\\bar{H}_{t}^{-1}}\\geq1\\right]+2R_{\\mu,*}\\sum_{t\\in\\mathcal{T}_{T}}\\mathbb{1}\\left[\\left\\|x_{t}\\right\\|_{V_{t}^{-1}}\\geq1\\right]+\\mathrm{Reg}_{\\mathcal{Z}}(T)}\\\\ &{}&{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\mathrm{Definition~of~}\\mathcal{Z}_{T})}\\\\ &{}&{\\leq\\frac{4d R_{\\mu,*}}{\\log2}\\left\\{\\log\\left(1+\\frac{R_{\\mu}}{2\\lambda g(\\tau)\\log2}\\right)+\\log\\left(1+\\frac{1}{2\\kappa(T)\\lambda g(\\tau)\\log2}\\right)\\right\\}+\\mathrm{Reg}_{\\mathcal{Z}}(T)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We now focus on bounding the last term: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathsf{R e g}_{\\mathbb{Z}}(T)=\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\{\\mu_{t,\\star}(\\theta_{\\star})-\\mu_{t}(\\hat{\\theta}_{t})\\right\\}+\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\{\\mu_{t}(\\hat{\\theta}_{t})-\\mu_{t}(\\theta_{\\star})\\right\\}}}\\\\ &{}&{\\displaystyle(\\mu_{t}(\\cdot):=\\mu(\\langle x_{t},\\cdot\\rangle),\\,\\mu_{t,\\star}(\\cdot):=\\mu(\\langle x_{t,\\star},\\cdot\\rangle))}\\\\ &{}&{\\displaystyle\\leq\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\{\\mu_{t}(\\theta_{t})-\\mu_{t}(\\hat{\\theta}_{t})\\right\\}+\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\{\\mu_{t}(\\hat{\\theta}_{t})-\\mu_{t}(\\theta_{\\star})\\right\\}}\\\\ &{}&{\\displaystyle(\\mathrm{optimism-line~7~of~Algorithm~1})}\\\\ &{}&{\\displaystyle=2\\sum_{t\\notin\\mathbb{Z}_{T}}\\operatorname*{max}_{t\\in[t,T]}\\theta_{\\in\\mathbb{C}_{\\delta}}\\left|\\mu_{t}(\\theta)-\\mu_{t}(\\hat{\\theta}_{b})\\right|}\\\\ &{}&{\\displaystyle=2\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\hat{\\theta}_{b(t)})\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Using Taylor\u2019s theorem with integral remainder form, we have that for $t\\not\\in{\\mathcal{Z}}_{T}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\widehat{\\theta}_{b(t)})\\right|}\\\\ &{=\\left|\\dot{\\mu}_{t}(\\widehat{\\theta}_{(t)})\\langle x_{t},\\nu_{t}-\\widehat{\\theta}_{b(t)}\\rangle+\\int_{\\mu_{t}(\\widehat{\\theta}_{b(t)})}^{\\mu_{t}(\\nu_{t})}(\\mu_{t}(\\nu_{t})-z)\\tilde{\\mu}_{t}(z)d z\\right|}\\\\ &{\\leq\\dot{\\mu}_{t}(\\widehat{\\theta}_{b(t)})\\left|\\langle x_{t},\\nu_{t}-\\widehat{\\theta}_{b(t)}\\rangle\\right|+\\langle x_{t},\\nu_{t}-\\widehat{\\theta}_{b(t)}\\rangle^{2}\\int_{0}^{1}(1-v)\\left|\\ddot{\\mu}_{t}\\left(\\widehat{\\theta}_{b(t)}+v(\\nu_{t}-\\widehat{\\theta}_{b(t)})\\right)\\right|d v}\\\\ &{\\qquad\\leq\\dot{\\mu}_{t}(\\widehat{\\theta}_{b(t)})\\left|\\langle x_{t},\\nu_{t}-\\widehat{\\theta}_{b(t)}\\rangle\\right|+R_{s}\\langle x_{t},\\nu_{t}-\\widehat{\\theta}_{b(t)}\\rangle^{2}\\underbrace{\\left(\\overset{\\mathrm{tin0ple~inequality,~reparametrizatit}}{\\sum_{0}^{\\mu}(1-v)\\dot{\\mu}_{t}\\left(\\widehat{\\theta}_{b(t)}+v(\\nu_{t}-\\widehat{\\theta}_{b(t)})\\right)\\right)d v}}_{=\\widehat{\\mu}_{t(t)}(\\widehat{\\theta}_{b(t)},\\nu_{t})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\dot{\\mu}_{t}(\\bar{\\theta}_{t})\\left|\\left\\langle x_{t},\\nu_{t}-\\hat{\\theta}_{\\hat{\\nu}(t)}\\right\\rangle\\right|+\\left|\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t}(\\hat{\\theta}_{t(t)})\\right|\\left|\\left\\langle x_{t},\\nu_{t}-\\hat{\\theta}_{\\hat{\\nu}(t)}\\right\\rangle\\right|}\\\\ &{\\qquad+R_{s}\\langle x_{t},\\nu_{t}-\\hat{\\theta}_{\\hat{\\nu}(t)}\\rangle\\dot{\\sigma}_{\\hat{\\nu}(t)}\\langle\\hat{\\theta}_{\\hat{\\nu}(t)},\\nu_{t}\\rangle}\\\\ &{\\leq\\underbrace{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})\\left\\lVert x_{t}\\right\\rVert}_{\\hat{\\theta}_{t(t)}=\\hat{\\mu}_{t}(\\bar{\\theta}_{t(t)},\\nu_{t})-1}\\left\\lVert\\nu_{t}-\\hat{\\theta}_{\\hat{\\nu}(t)}\\right\\rVert}_{\\hat{\\theta}_{A_{t}}}\\underbrace{\\hat{\\theta}_{t(t)}\\nu_{t}}_{\\mathrm{(b_{t})}=\\hat{\\mu}_{t}(\\hat{\\theta}_{t(t)},\\nu_{t})}}\\\\ &{\\qquad+\\underbrace{\\left|\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t}(\\hat{\\theta}_{t(t)})\\right|\\left\\lVert x_{t}\\right\\rVert}_{\\hat{\\theta}_{t(t)}=\\hat{\\mu}_{t}}\\underbrace{\\dot{\\mu}_{t(t)}\\left\\lVert\\hat{\\theta}_{t(t)},\\nu_{t}\\right\\rVert-\\left\\lVert\\nu_{t}-\\hat{\\theta}_{t(t)}\\right\\rVert}_{\\hat{\\theta}_{t(t)}=0}\\underbrace{\\left\\lVert\\hat{\\theta}_{t(t)},\\hat{\\theta}_{t(t)}\\right\\rVert}_{\\mathrm{(dr_{t})}=\\hat{\\mu}_{t}(\\hat{\\theta}_{t(t)},\\nu_{t})}}\\\\ &{\\qquad+\\underbrace{R_{s}\\left\\lVert\\nu_{t}-\\hat{\\theta}_{\\hat{\\nu}(t)}\\right\\rVert_{\\widetilde{\\mathcal{Q}}_{\\hat{\\nu}(t)}(\\hat{\\theta}_{t(t)},\\nu_{t})}^{2}\\hat{\\alpha}_{t(t)}(\\hat{\\theta}_{b(t)},\\nu_{t})\\left\\lVert x_{t} \n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(Cauchy-Schwartz inequality) ", "page_idx": 31}, {"type": "text", "text": "where $\\tilde{G}$ is as defined in Eqn. (21). As one will see soon, $\\textstyle\\sum_{t}A_{t}$ is the leading term, and $\\textstyle\\sum_{t}(B_{t}+C_{t})$ is the transient term. ", "page_idx": 31}, {"type": "text", "text": "We bound each sum separately: ", "page_idx": 31}, {"type": "text", "text": "Bounding $\\textstyle\\sum_{t}A_{t}$ . ", "text_level": 1, "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t\\notin\\cal T}A_{t}=\\sum_{t\\notin\\cal T}\\displaystyle\\beta_{t}(\\lVert\\hat{\\boldsymbol\\alpha}_{t}\\rVert_{\\mathcal{H}(\\bar{\\mathcal{H}}_{\\mathbb{I}})}\\rVert\\bar{\\alpha}_{t(\\bar{\\mathcal{H}}_{\\mathbb{I}})},\\mu_{t})-\\lVert\\,\\nu_{t}-\\hat{\\boldsymbol\\theta}_{b(t)}\\rVert_{\\bar{\\mathcal{H}}_{\\mathbb{I}(\\bar{\\mathcal{H}}_{\\mathbb{I}})}}\\Big\\rVert_{\\bar{\\mathcal{H}}_{\\mathbb{I}(\\bar{\\mathcal{H}}_{\\mathbb{I}})},\\nu_{t})}}\\\\ &{\\le\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sum_{t\\notin\\cal T}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\boldsymbol\\alpha}_{t})\\,\\lVert x_{t}\\rVert_{\\bar{\\mathcal{H}}_{\\mathbb{I}}|(\\bar{\\mathcal{H}}_{\\mathbb{I}})}\\displaystyle\\hat{\\mu}_{t(\\bar{\\mathcal{H}}_{\\mathbb{I}})}\\cdot1\\quad\\quad(\\nu_{t}\\in\\mathcal{C}_{b(t)},\\mathrm{Lemma~E},\\delta(i))}\\\\ &{\\le\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sqrt{\\sum_{t\\notin\\cal T}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\boldsymbol\\theta}_{t})}\\displaystyle\\sqrt{\\sum_{t\\notin\\cal T}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\boldsymbol\\theta}_{t})\\,\\lVert x_{t}\\rVert_{\\bar{\\mathcal{H}}_{\\mathbb{I}}(\\bar{\\mathcal{H}}_{\\mathbb{I}})}^{2}\\delta_{t(\\bar{\\mathcal{H}}_{\\mathbb{I}})}\\,}}\\\\ &{\\le\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\theta}_{t})\\,\\sqrt{\\sum_{t\\in\\mathbb{Z}_{T}}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\theta}_{t})\\,\\lVert x_{t}\\rVert_{H}^{2}\\frac{1}{R_{t}^{-1}}}\\quad\\quad(\\mathrm{Lemma~E},S)}\\\\ &{\\le\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\displaystyle\\hat{\\mu}_{t}(\\bar{\\theta}_{t})\\,\\\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(Definition of $\\mathcal{T}_{T}$ ) ", "page_idx": 31}, {"type": "text", "text": "Note that now, $\\bar{\\pmb{H}}_{t}$ is of the form such that we can use the EPL with $\\sqrt{\\dot{\\mu}_{t}(\\bar{\\pmb{\\theta}}_{t})}\\pmb{x}_{t}$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{\\ell^{\\mathbb{Z}}r}A_{t}\\leq2\\sqrt{d g(\\tau)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\log\\Big(1+\\frac{R_{\\hat{\\mu}}T}{d\\lambda}\\Big)}\\sqrt{\\sum_{t\\in\\mathbb{Z}_{T}}\\dot{\\mu}_{t}(\\bar{\\theta}_{t})}.}}&{\\quad\\mathrm{(EPL~(Lemma~E.2))}}\\\\ &{}&{\\leq2\\sqrt{d g(\\tau)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\log\\Big(1+\\frac{R_{\\hat{\\mu}}T}{d\\lambda}\\Big)}\\sqrt{\\sum_{t\\in[T]}\\dot{\\mu}_{t,\\star}(\\theta_{\\star})+\\sum_{t\\in\\mathcal{T}_{T}}\\big\\{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t,\\star}(\\theta_{\\star})\\big\\}}}\\\\ &{}&{\\quad\\mathrm{(}\\mu_{t,\\star}(\\cdot):=\\mu(\\langle x_{t,\\star},\\cdot\\rangle))}\\\\ &{}&{=2\\sqrt{d g(\\tau)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\log\\Big(1+\\frac{R_{\\hat{\\mu}}T}{d\\lambda}\\Big)}\\sqrt{\\frac{T}{\\kappa_{\\star}(T)}+\\sum_{t\\in\\mathcal{T}_{T}}\\big\\{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t,\\star}(\\theta_{\\star})\\big\\}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The last term in the square root is bounded as follows: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{t\\notin{\\cal Z}_{T}}\\left\\{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t,\\star}(\\theta_{\\star})\\right\\}=\\sum_{t\\notin{\\cal Z}_{T}}\\left\\{\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t}(\\theta_{\\star})\\right\\}+\\sum_{t\\notin{\\cal Z}_{T}}\\left\\{\\dot{\\mu}_{t}(\\theta_{\\star})-\\dot{\\mu}_{t,\\star}(\\theta_{\\star})\\right\\}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq R_{s}\\left\\{\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\bar{\\theta}_{t})-\\mu_{t}(\\theta_{*})\\right|+\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\theta_{*})-\\mu_{t,*}(\\theta_{*})\\right|\\right\\}}\\\\ &{\\leq R_{s}\\left\\{\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\theta_{*})\\right|+\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left\\{\\mu_{t,*}(\\theta_{*})-\\mu_{t}(\\theta_{*})\\right\\}\\right\\}}\\\\ &{\\leq R_{s}\\left\\{\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\hat{\\theta}_{t})\\right|+\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\theta_{*})-\\mu_{t}(\\hat{\\theta}_{t})\\right|+\\displaystyle\\mathsf{R e g}_{\\mathbb{Z}_{T}}(T)\\right\\}}\\\\ &{\\leq4R_{s}\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\hat{\\theta}_{t})\\right|+\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\theta_{*})-\\mu_{t}(\\hat{\\theta}_{t})\\right|+\\displaystyle\\mathsf{R e g}_{\\mathbb{Z}_{T}}(T)\\right\\}}\\\\ &{\\leq4R_{s}\\displaystyle\\sum_{t\\in\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\hat{\\theta}_{b(t)})\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Bounding $\\textstyle\\sum_{t}B_{t}$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}B_{t}=\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t}(\\widehat{\\theta}_{b(t)})\\right|\\|x_{t}\\|_{\\tilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\nu_{t})}-1\\left\\|\\nu_{t}-\\widehat{\\theta}_{b(t)}\\right\\|_{\\tilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\nu_{t})}}\\\\ &{\\qquad\\leq\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\dot{\\mu}_{t}(\\bar{\\theta}_{t})-\\dot{\\mu}_{t}(\\widehat{\\theta}_{b(t)})\\right|\\|x_{t}\\|_{\\widetilde{G}_{b(t)}^{-1}(\\widehat{\\theta}_{b(t)},\\nu_{t})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\nu_{t}\\in\\mathcal{C}_{b(t)},\\operatorname{Lemma}\\operatorname{E}.\\delta(i))}\\\\ &{\\qquad\\qquad\\leq R_{s}\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\bar{\\theta}_{t})-\\mu_{t}(\\widehat{\\theta}_{b(t)})\\right|\\|x_{t}\\|_{\\widetilde{G}_{b(t)}^{-1}(\\widehat{\\theta}_{b(t)},\\nu_{t})}\\cdot\\quad\\mathrm{(Lemma~E.3)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We then inevitably introduce a $\\kappa(T)$ dependency to use the elliptical potential arguments w.r.t. $V_{t}$ : ", "page_idx": 32}, {"type": "text", "text": "$\\sum_{t\\notin\\mathbb{Z}_{T}}B_{t}\\leq R_{s}\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\sqrt{2g(\\tau)\\kappa(T)}\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\bar{\\theta}_{t})-\\mu_{t}(\\widehat{\\theta}_{b(t)})\\right|\\|x_{t}\\|_{V_{t}^{-1}}$ (Lemma E.4, $b(t)\\geq t)$ ) $\\leq R_{s}\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\sqrt{2g(\\tau)\\kappa(T)}\\sum_{t\\notin\\mathbb{Z}_{T}}\\Big|\\mu_{t}(\\pmb{\\nu}_{t})-\\mu_{t}(\\widehat{\\pmb{\\theta}}_{b(t)})\\Big|\\,\\|\\pmb{x}_{t}\\|_{V_{t}^{-1}}$ (Definition of $\\pmb{\\nu}_{t}$ (Eqn. (19))) $\\begin{array}{r l}&{\\leq4R_{s}R_{\\dot{\\mu}}\\kappa(T)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\sqrt{g(\\tau)}\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}\\|x_{t}\\|_{V_{t}^{-1}}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\nu_{t},\\widehat{\\theta}_{b(t)}\\in\\mathcal{C}_{b(t)},\\operatorname{Lemma}\\mathrm{E},6\\ (\\dot{u}i))}\\\\ &{\\leq4R_{s}R_{\\dot{\\mu}}\\kappa(T)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\sqrt{g(\\tau)}\\displaystyle\\sum_{t\\in[T]}\\operatorname*{min}\\left\\{1,\\|x_{t}||_{V_{t}^{-1}}^{2}\\right\\}\\quad\\mathrm{(Definition~of}\\,\\mathcal{T}_{T})}\\\\ &{\\leq8d R_{s}R_{\\dot{\\mu}}\\kappa(T)(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2})\\sqrt{g(\\tau)}\\log\\left(1+\\displaystyle\\frac{T}{2d g(\\tau)\\kappa(T)\\lambda}\\right).}\\end{array}$ (EPL (Lemma E.2)) ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "Bounding $\\textstyle\\sum_{t}C_{t}$ . We proceed similarly as bounding $\\textstyle\\sum_{t}B_{t}$ : ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\sum_{t\\notin\\mathbb{Z}_{T}}C_{t}\\leq R_{s}\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\sum_{t\\notin\\mathbb{Z}_{T}}\\tilde{\\alpha}_{b(t)}\\big(\\widehat{\\pmb{\\theta}}_{b(t)},\\pmb{\\nu}_{t}\\big)\\,\\|x_{t}\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\pmb{\\theta}}_{b(t)},\\pmb{\\nu}_{t})^{-1}}^{2}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\leq R_{s}R_{\\mu}g(\\tau)\\kappa(T)\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\sum_{t\\in\\mathbb{Z}_{T}}\\|x_{t}\\|_{V_{t}}^{2}\\quad}&{\\displaystyle(\\mathrm{Lemma~E.4,}\\,b(t)\\geq t)}\\\\ {\\displaystyle\\leq R_{s}R_{\\mu}g(\\tau)\\kappa(T)\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\sum_{t\\in[T]}\\operatorname*{min}_{\\tau\\left[1,\\left\\|x_{t}\\right\\|_{V_{t}^{-1}}^{2}\\right\\}}&{\\displaystyle(\\mathrm{Definition~of}\\,\\mathcal{Z}_{T})}\\\\ {\\displaystyle\\leq2d R_{s}R_{\\mu}g(\\tau)\\kappa(T)\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}}\\log\\left(1+\\frac{T}{2d g(\\tau)\\kappa(T)\\lambda}\\right)}&{\\displaystyle(\\mathrm{EPL~(Lemma~E.2)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Wrapping Up. Let us choose $\\begin{array}{r}{\\lambda=\\frac{1}{4S^{2}}}\\end{array}$ , and let us denote $A\\lesssim B$ if $A\\le c B$ for some absolute constant . Then, combining everything, we have: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\vert\\mu_{t}(\\nu_{t})-\\mu_{t}(\\widehat{\\theta}_{b(t)})\\right\\vert}\\\\ {\\displaystyle}&{\\le\\displaystyle\\sum_{t\\notin\\mathbb{Z}_{T}}A_{t}+\\sum_{t\\notin\\mathbb{Z}_{T}}B_{t}+\\sum_{t\\notin\\mathbb{Z}_{T}}C_{t}}\\\\ {\\displaystyle}&{\\lesssim\\beta_{T}(\\delta)\\sqrt{d g(\\tau)\\log\\left(1+\\frac{R_{\\mu}S T}{d}\\right)}\\sqrt{\\frac{T}{\\kappa_{\\star}(T)}+R_{s}\\sum_{t\\notin\\mathbb{Z}_{T}}\\left\\vert\\mu_{t}(\\nu_{t})-\\mu_{t}(\\widehat{\\theta}_{b(t)})\\right\\vert}}\\\\ &{\\displaystyle\\qquad+d R_{s}R_{\\mu}\\kappa(T)\\beta_{T}(\\delta)\\sqrt{g(\\tau)}\\log\\left(1+\\frac{S T}{d g(\\tau)\\kappa(T)}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "as the upper bound for $\\textstyle\\sum_{t}C_{t}$ is asymptotically negligible compared to that of $\\textstyle\\sum_{t}B_{t}$ . ", "page_idx": 33}, {"type": "text", "text": "This is of the form $X\\ {\\stackrel{<}{\\sim}}\\ A{\\sqrt{B+R_{s}X}}+C$ with $\\begin{array}{r}{X:=\\sum_{t\\notin\\mathbb{Z}_{T}}\\left|\\mu_{t}(\\nu_{t})-\\mu_{t}(\\widehat{\\pmb{\\theta}}_{b(t)})\\right|}\\end{array}$ , which then implies $X\\lesssim A\\sqrt{B}+A\\sqrt{R_{s}}+C$ thanks to an elementary polynomial inequality (Abeille et al., 2021, Proposition 7). We then conclude by combining the above inequality with the regret decomposition done at the beginning. \u53e3 ", "page_idx": 33}, {"type": "text", "text": "E.3 Supporting Lemmas ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The following are the elliptical potential arguments, which we state without proof: ", "page_idx": 33}, {"type": "text", "text": "Lemma E.1 (Elliptical Potential Count Lemma; $\\mathrm{EPCL}^{11}$ ). For $X,L>0,$ , let $x_{1},\\cdot\\cdot\\cdot\\,,x_{T}\\in B^{d}(X)$ be a sequence of vectors, $\\begin{array}{r}{V_{t}\\;:=\\;\\lambda I+\\sum_{s=1}^{t-1}x_{s}x_{s}^{\\intercal}}\\end{array}$ , and let us define the following: $\\mathcal{H}_{T}\\;:=\\;$ $\\left\\{t\\in[T]:\\|\\pmb{x}_{t}\\|_{\\pmb{V}_{t}^{-1}}^{2}>L\\right\\}$ . Then, we have that ", "page_idx": 33}, {"type": "equation", "text": "$$\n|\\mathcal{H}_{T}|\\leq\\frac{2d}{\\log(1+L^{2})}\\log\\left(1+\\frac{X^{2}}{\\lambda\\log(1+L^{2})}\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Lemma E.2 (Elliptical Potential Lemma; $\\mathrm{EPL}^{12}$ ). Let $x_{1},\\cdot\\cdot\\cdot\\,,x_{T}\\,\\in\\,B^{d}(X)$ be a sequence of vectors and $\\begin{array}{r}{V_{t}:=\\lambda I+\\sum_{s=1}^{t-1}x_{s}{\\pmb x}_{s}^{\\intercal}}\\end{array}$ . Then, we have that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{1,\\|x_{t}\\|_{V_{t}^{-1}}^{2}\\right\\}\\leq2d\\log\\left(1+{\\frac{X^{2}T}{d\\lambda}}\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The following is a \u201cself-bounding\u201d property of self-concordant function: ", "page_idx": 33}, {"type": "text", "text": "Lemma E.3. For $\\pmb{\\theta},\\pmb{\\nu}\\in\\mathbb{R}^{d},\\,|\\dot{\\mu}_{t}(\\pmb{\\theta})-\\dot{\\mu}_{t}(\\pmb{\\nu})|\\leq R_{s}|\\mu_{t}(\\pmb{\\theta})-\\mu_{t}(\\pmb{\\nu})|$ ", "page_idx": 33}, {"type": "text", "text": "Proof. This follows from direct computation: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\dot{\\mu}_{t}(\\pmb\\theta)-\\dot{\\mu}_{t}(\\pmb\\nu)\\right|=\\left|\\langle x_{t},\\pmb\\theta-\\pmb\\nu\\rangle\\displaystyle\\int_{0}^{1}\\ddot{\\mu}_{t}(\\pmb\\nu+\\pmb v(\\pmb\\theta-\\pmb\\nu)d v\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left|\\langle x_{t},\\pmb\\theta-\\pmb\\nu\\rangle\\right|\\displaystyle\\int_{0}^{1}\\left|\\ddot{\\mu}_{t}(\\pmb\\nu+\\pmb v(\\pmb\\theta-\\pmb\\nu)\\right|d v}\\\\ &{\\qquad\\qquad\\qquad\\leq R_{s}\\left|\\langle x_{t},\\pmb\\theta-\\pmb\\nu\\rangle\\right|\\displaystyle\\int_{0}^{1}\\left|\\dot{\\mu}_{t}(\\pmb\\nu+\\pmb v(\\pmb\\theta-\\pmb\\nu)\\right|d v}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "(Assumption 4) ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=R_{s}\\left|\\langle\\pmb{x}_{t},\\pmb{\\theta}-\\pmb{\\nu}\\rangle\\int_{0}^{1}{\\dot{\\mu}}_{t}(\\pmb{\\nu}+\\pmb{v}(\\pmb{\\theta}-\\pmb{\\nu})d v\\right|}\\\\ {\\displaystyle\\qquad\\qquad\\qquad\\qquad\\quad(m\\mathrm{\\;is\\;con}}\\\\ {\\displaystyle=R_{s}\\left|\\mu_{t}(\\pmb{\\theta})-\\mu_{t}(\\pmb{\\nu})\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "vex, and thus $\\dot{\\mu}=m^{\\prime\\prime}\\ge0)$ ) ", "page_idx": 34}, {"type": "text", "text": "This self-concordant result is distinct from the original self-concordance control lemma (Faury et al., 2020, Lemma 9) and does not incur any dependency on $S$ . We also remark that the above self-bounding lemma has been independently proven and used for regret analyses of GLBs in two concurrent works (Janz et al., 2024, Claim 14) (Liu et al., 2024, Lemma 31). ", "page_idx": 34}, {"type": "text", "text": "The following properties are crucial in allowing for the application of $\\operatorname{EP}(\\mathbf{C})\\mathbf{L}$ : ", "page_idx": 34}, {"type": "text", "text": "Lemma E.4. For any $\\pmb{\\theta},\\pmb{\\nu}\\in\\mathbb{R}^{d}$ , $\\begin{array}{r}{\\frac{1}{2\\kappa(T)}\\leq\\tilde{\\alpha}_{t}(\\pmb{\\theta},\\pmb{\\nu})\\leq\\frac{R_{\\dot{\\mu}}}{2}}\\end{array}$ , and thus, $\\begin{array}{r}{\\frac{1}{2g(\\tau)\\kappa(T)}V_{t}\\preceq\\widetilde G_{t}(\\pmb{\\theta},\\pmb{\\nu})}\\end{array}$ ", "page_idx": 34}, {"type": "text", "text": "Proof. Follows from straightforward computation. ", "page_idx": 34}, {"type": "text", "text": "In the following two lemmas, $b(t)$ is as defined in Eqn. (19). ", "page_idx": 34}, {"type": "text", "text": "Proof. For each $s\\leq b(t)$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\tilde{\\alpha}_{s}(\\widehat{\\theta}_{b(t)},\\nu_{t})=\\int_{0}^{1}(1-v)\\dot{\\mu}_{s}\\left(\\widehat{\\theta}_{b(t)}+v(\\nu_{t}-\\widehat{\\theta}_{b(t)})\\right)d v\\overset{(*)}{\\geq}\\dot{\\mu}_{s}(\\bar{\\theta}_{s})\\int_{0}^{1}(1-v)d v=\\frac{1}{2}\\dot{\\mu}_{s}(\\bar{\\theta}_{s}),\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $(*)$ follows from the observations that $\\nu_{t},\\widehat{\\pmb{\\theta}}_{b(t)}\\in\\mathcal{C}_{b(t)}$ and $\\mathcal{C}_{b(t)}$ is convex. We then conclude by noting that $b(t)\\geq t$ , and thus $\\bar{H}_{b(t)}\\succeq\\bar{H}_{t}$ . \u53e3 ", "page_idx": 34}, {"type": "text", "text": "Lemma E.6. For any $t\\geq1$ and $\\pmb{\\theta},\\pmb{\\nu}\\in C_{b(t)}$ , we have the following: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(i)~\\left\\|\\nu-\\widehat{\\theta}_{b(t)}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\nu)}\\leq\\sqrt{4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}},}\\\\ &{(i i)~\\left|\\mu_{t}(\\nu)-\\mu_{t}(\\theta)\\right|\\leq2R_{\\dot{\\mu}}\\sqrt{2\\left(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}\\right)\\kappa(T)}\\left\\|x_{t}\\right\\|_{V_{t}^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. $(i)$ follows from Taylor\u2019s theorem with integral remainder, first-order condition for convex constrained optimization (see footnote 10 in Appendix D), and the fact that $C_{b(t)}\\subseteq B^{d}(S)$ : ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\beta_{T}(\\delta)^{2}\\geq\\mathcal{L}_{b(t)}(\\nu)-\\mathcal{L}_{b(t)}(\\widehat{\\theta}_{t})=\\underbrace{\\langle\\nabla\\mathcal{L}_{b(t)}(\\widehat{\\theta}_{b(t)}),\\nu-\\widehat{\\theta}_{b(t)}\\rangle}_{\\geq0}+\\left\\|\\nu-\\widehat{\\theta}_{b(t)}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\nu)-\\lambda I}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\left\\|\\nu-\\widehat{\\theta}_{b(t)}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\nu)}^{2}-4\\lambda S^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "$(i i)$ follows from $(i)$ and similar arguments: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mu_{t}(\\boldsymbol{\\nu})-\\mu_{t}(\\boldsymbol{\\theta})\\big|=\\left|\\langle\\mathbf{x}_{t},\\boldsymbol{\\nu}-\\boldsymbol{\\theta}\\rangle\\int_{0}^{1}\\dot{\\mu}_{t}(\\boldsymbol{\\theta}+\\boldsymbol{v}(\\boldsymbol{\\nu}-\\boldsymbol{\\theta}))d\\boldsymbol{v}\\right|}}\\\\ &{}&{\\leq R_{\\hat{\\mu}}\\left\\{\\left\\|\\nu-\\widehat{\\theta}_{b(t)}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\theta)}+\\left\\|\\theta-\\widehat{\\theta}_{b(t)}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\theta)}\\right\\}\\left\\|x_{t}\\right\\|_{\\widetilde{G}_{b(t)}(\\widehat{\\theta}_{b(t)},\\theta)}-}\\\\ &{}&{\\quad\\mathrm{(Cauchy-Schwartz~\\&~triangle~inequalities)}}\\\\ &{}&{\\leq2R_{\\hat{\\mu}}\\sqrt{2\\left(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}\\right)\\kappa(T)}\\left\\|x_{t}\\right\\|_{V_{b(t)}^{-1}}\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(\\boldsymbol{i}),\\mathrm{Lemma~E.4})}\\\\ &{}&{\\leq2R_{\\hat{\\mu}}\\sqrt{2\\left(4\\lambda S^{2}+\\beta_{T}(\\delta)^{2}\\right)\\kappa(T)}\\left\\|x_{t}\\right\\|_{V_{b}^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "F Alternate CS via Discrete Uniform Prior and Covering Argument ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "In this Appendix, instead of the PAC-Bayes with a continuous uniform prior/posterior as in the main text, we explore an alternate derivation of CS using a discrete uniform prior. This is a supplementary discussion for the \u201cFast Rates in Statistical Learning\u201d paragraph in Appendix A. ", "page_idx": 35}, {"type": "text", "text": "We present the alternate CS, which is strictly looser than our Theorem 3.1 but more \u201celementary\u201d: ", "page_idx": 35}, {"type": "text", "text": "Theorem F.1 (Slightly Looser, Unified CS for GLMs). Let $L_{t}:=\\operatorname*{max}_{\\pmb{\\theta}\\in\\Theta}\\left\\|\\nabla\\mathcal{L}_{t}(\\pmb{\\theta})\\right\\|_{2}b e$   \nthe Lipschitz constant of $\\mathcal{L}_{t}(\\cdot)$ that may depend on $\\{(\\pmb{x}_{s},r_{s})\\}_{s=1}^{t-1}$ . Then, we have $\\mathbb{P}[\\exists t\\geq1$ :   \n$\\theta_{\\star}\\notin\\bar{C}_{t}(\\delta)]\\leq\\delta$ , where $\\beta_{t}(\\delta)^{2}=\\log\\frac{\\pi^{2}t^{2}}{6\\delta}+\\operatorname*{inf}_{c\\in(0,5S]}\\left\\{d\\log\\frac{5S}{c}+c L_{t}\\right\\}\\le\\log\\frac{\\pi^{2}t^{2}}{6\\delta}+d\\log(1\\vee5S L_{t})+1,$   \nwhere the last inequality follows from the choice $\\begin{array}{r}{c=5S\\wedge\\frac{1}{L_{t}}}\\end{array}$ . ", "page_idx": 35}, {"type": "text", "text": "Proof. Consider $p=\\mathcal{U}(\\{\\pmb{\\theta}_{i}\\}_{i\\in[N]})$ , where the $\\theta_{i}$ \u2019s will be determined later. In that case, we have: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\mathbb{E}_{\\theta\\sim p}[M_{t}(\\theta)]=\\mathcal{L}_{t}(\\theta_{\\star})+\\log\\mathbb{E}_{\\theta\\sim p}[\\exp\\big(-\\mathcal{L}_{t}(\\theta)\\big)]}\\\\ &{\\qquad\\qquad\\qquad=\\mathcal{L}_{t}(\\theta)+\\log\\left\\{\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\exp\\big(-\\mathcal{L}_{t}(\\theta_{i})\\big)\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\mathcal{L}_{t}(\\theta_{\\star})+\\log\\left\\{\\displaystyle\\frac{1}{N}\\operatorname*{max}_{i\\in[N]}\\exp\\big(-\\mathcal{L}_{t}(\\theta_{i})\\big)\\right\\}}\\\\ &{\\qquad\\qquad=\\mathcal{L}_{t}(\\theta_{\\star})-\\displaystyle\\operatorname*{min}_{i\\in[N]}\\mathcal{L}_{t}(\\theta_{i})+\\log\\displaystyle\\frac{1}{N}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "From the proof of Lemma 3.1, one can see that $\\mathbb{E}[M_{t}(\\pmb{\\theta})|\\pmb{\\theta}]=1$ where $\\mathbb{E}$ is w.r.t. the randomness of the sequential data (i.e., of $\\mathcal{L}_{t}(\\cdot))$ . Then, by Markov\u2019s inequality, for any $\\delta\\in(0,1)$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(M_{t}(\\pmb{\\theta}_{i})\\geq\\frac{N}{\\delta}\\right)\\leq\\frac{\\delta}{N},\\quad\\forall i\\in[N],\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where again, $\\mathbb{P}$ is w.r.t. the randomness of $\\mathcal{L}_{t}(\\cdot)$ . Then, we have that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\mathbb{E}_{\\theta\\sim p}[M_{t}(\\theta)]=\\displaystyle\\frac{1}{N}\\sum_{i\\in[N]}M_{t}(\\theta_{i})\\geq\\displaystyle\\frac{1}{\\delta}\\right)\\leq\\mathbb{P}\\left(\\operatorname*{max}_{i\\in[N]}M_{t}(\\theta_{i})\\geq\\displaystyle\\frac{N}{\\delta}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{i\\in[N]}\\mathbb{P}\\left(M_{t}(\\theta_{i})\\geq\\displaystyle\\frac{N}{\\delta}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{i\\in[N]}\\displaystyle\\frac{\\delta}{N}=\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Combining this with Eqn. (25), we have that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\mathcal{L}_{t}(\\pmb{\\theta}_{\\star})-\\operatorname*{min}_{i\\in[N]}\\mathcal{L}_{t}(\\pmb{\\theta}_{i})\\leq\\log\\frac{N}{\\delta}\\right)\\geq1-\\delta,\\quad\\forall t\\geq1.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "By reparametrizing $\\delta$ as $\\frac{\\delta}{t^{2}}$ and taking the union bound over $t\\geq1$ , we have that by the Basel sum, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\exists t\\geq1:\\mathcal{L}_{t}(\\pmb{\\theta}_{\\star})-\\operatorname*{min}_{i\\in[N]}\\mathcal{L}_{t}(\\pmb{\\theta}_{i})\\geq\\log N+\\log\\frac{\\pi^{2}t^{2}}{6\\delta}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Thus, the following holds with probability at least $1-\\delta$ : for all $t\\geq1$ , ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{t}(\\theta_{\\star})-\\underset{\\theta\\in\\Theta}{\\operatorname*{min}}\\mathcal{L}_{t}(\\theta)\\leq\\log\\frac{\\pi^{2}t^{2}}{6\\delta}+\\log N+\\underset{i\\in[N]}{\\operatorname*{min}}\\mathcal{L}_{t}(\\theta_{i})-\\underset{\\theta\\in\\Theta}{\\operatorname*{min}}\\mathcal{L}_{t}(\\theta)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\log\\frac{\\pi^{2}t^{2}}{6\\delta}+\\log N+L_{t}\\underset{i\\in[N]}{\\operatorname*{min}}\\left\\lVert\\theta_{i}-\\widehat{\\theta_{t}}\\right\\rVert_{2},\\quad(\\widehat{\\theta_{t}}=\\arg\\operatorname*{min}_{\\theta\\in\\Theta}\\mathcal{L}_{t}(\\theta))}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where we recall that $L_{t}$ is the Lipschitz constant of $\\mathcal{L}_{t}(\\cdot)$ . ", "page_idx": 36}, {"type": "text", "text": "We choose $\\{\\pmb{\\theta}_{i}\\}$ to be a $c$ -net of $\\Theta$ for $c\\in(0,5S]$ . Then, $\\operatorname*{min}_{i\\in[N]}\\left\\|{\\pmb{\\theta}}_{i}-\\widehat{{\\pmb{\\theta}}}_{t}\\right\\|_{2}\\leq c$ by definition, and as $\\Theta\\subseteq B^{d}(S)$ , $\\begin{array}{r}{N\\le\\left(\\frac{5S}{c}\\right)^{d}}\\end{array}$ (Vershynin, 2018, Corollary 4.2.13). Combining everything and taking $\\mathrm{min}_{c\\in(0,5S]}$ gives the desired statement. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "G Deferred Experimental Details and Results from Section 5 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "G.1 Implementation Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "For time-varying arm-sets, the randomness of the arm-sets is shared across all the algorithms, i.e., at each time-step $t$ , all the algorithms see the same arm-set. Thus, the only randomness is from the reward distributions. Whenever applicable, we utilize the Sequential Least SQuares Programming (SLSQP; Kraft (1988)) implemented in SciPy (Virtanen et al., 2020) for computing the norm-constrained MLE. This minimizes the effect of optimization errors whenever possible, allowing us to compare the algorithms clearly from a statistical perspective. For OFUGLB, EMK, RS-GLinCB, and $0{\\mathrm{FULog}}^{+}$ , SLSQP is utilized to compute the UCB index as well. Lastly, we use the same implementation of ada-OFU-ECOLog and RS-GLinCB as in the publicly available GitHub repository of Faury et al. $(2022)^{13}$ and Sawarni et al. $(2024)^{14}$ , respectively. For RS-GLinCB, we use the exact theoretical hyperparameters as provided in Sawarni et al. (2024). For EVILL, we use $\\tau=K=20$ for the initial warmup period for collecting prior observations (each arm is pulled once in a round-robin fashion), $\\lambda=1$ for the $\\ell_{2}$ -regularization coefficient for the MLE, and $a=1$ for the perturbation scale. ", "page_idx": 37}, {"type": "text", "text": "G.2 Additional Results for Logistic Bandits with Fixed Arm-Set ", "text_level": 1, "page_idx": 37}, {"type": "image", "img_path": "MDdOQayWTA/tmp/6adeee3190add3f59e2f83474d8503f5f445463a68fc2e86ab034efb5a9a53ab.jpg", "img_caption": [], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "Figure 2: Fixed arm-set. (First row) Regret plots of all considered algorithms. (Second row) Magnified regret plots. (Third row) Confidence set plots at the final time $t=10000$ when applicable. Each column represents a different logistic bandit instance for $S\\in\\{4,6,8,10\\}$ . ", "page_idx": 37}, {"type": "text", "text": "Results and Discussions. The results are shown in Figure 2. There are some common characteristics compared to the plots for time-varying arm-sets (Figure 1 in the main text). There is still a discrepancy between the tightness of the CSs and the actual regret for $\\mathsf{O F U L o g^{+}}$ vs. OFUGLB-e, and RS-GLinCB still performs the worst. Also, OFUGLB, EMK, and EVILL are still the best-performing algorithms, at least eventually. Let us now highlight some key qualitative differences from time-varying arm-set plots as well as relevant discussions. ", "page_idx": 37}, {"type": "text", "text": "First, the regret curves seem linearly increasing overall, especially at $S\\in\\{8,10\\}$ . In our settings, $T=10000$ is still in a transient phase of all the algorithms and, thus, yet to reach the asymptotic regime. To see the logarithmic-looking regret curve and to numerically compare the \u201cnumerical asymptotic regret\u201d of the algorithms, we plan to run the experiments for much longer timesteps, e.g., $T=50000$ . ", "page_idx": 38}, {"type": "text", "text": "Second, for $S\\,=\\,10$ , it seems that OFUGLB-e is the best performing algorithm. We suspect that this is because the OFUGLB-e happens to exploit a \u201cgood\u201d direction in the beginning, and In other words, we believe that if the experiments are run with much more iterations, then at the end, due to its design, OFUGLB- $\\varTheta$ will have to explore other unexplored directions, causing an increase in the regret. Indeed, if one takes a close look at $S\\in\\{6,8\\}$ , note that there is a phase at which OFUGLB-e seems to perform the best in the beginning, but in the end its regret increases well beyond other well-performing baselines: OFUGLB, EMK, and EVILL. ", "page_idx": 38}, {"type": "text", "text": "Remark 4. Although our current implementation always uses SLSQP for all the optimization procedures (for MLE and UCB index computations), when the arm-set is fixed, the overall implementations of all the algorithms can be made more computationally efficient. One approach is to utilize the iterative reweighted least squares (IRLS; Wolke and Schwetlick (1988)) and keep track of the number of pulls of each arm vector, which is possible as the arm-set is fixed); see Section 3.3 of Kveton et al. (2020) and the original implementation15 of EVILL using IRLS. ", "page_idx": 38}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: The abstract and introduction accurately reflect the paper\u2019s contributions and scope by introducing the new CS for GLMs and applying it to GLBs to obtain state-of-the-art regrets ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 39}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: Several limitations are posited in the main text, as well as in Appendix B. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 39}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: All the assumptions are detailed in the main text, and the proofs for all the statements are provided either in the main text or in the Appendix. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 40}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: The experiments are simple enough to be reproduced, and we additionally present the GitHub repository containing the codes for reproducing the experiments. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 40}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: See our GitHub repository: https://github.com/nick-jhlee/ logistic_bandit ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 41}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: This is detailed in the experiment section. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 41}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: The experiments are averaged over 10 runs, and the standard deviations are marked in the regret plots (Figure 1). ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 41}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [No] ", "page_idx": 42}, {"type": "text", "text": "Justification: The experiments are very simple and can be run on normal CPUs. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 42}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: This is purely theoretical. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 42}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: This is purely theoretical and thus have no negative impact. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper is purely theoretical. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 43}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We cite Abeille et al. (2021); Faury et al. (2022); Janz et al. (2024); Lee et al. (2024); Sawarni et al. (2024), who has a public GitHub repository for the experimental setting that we follow in our paper. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 43}, {"type": "text", "text": "", "page_idx": 44}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: No new assets are introduced. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 44}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: No humans were involved. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 44}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: no humans were involved. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 44}]