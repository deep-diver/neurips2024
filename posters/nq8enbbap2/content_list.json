[{"type": "text", "text": "Occupancy-based Policy Gradient: Estimation, Convergence, and Optimality ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Audrey Huang ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Nan Jiang ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of Illinois Urbana-Champaign Champaign, IL 61820 audreyh5@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of Illinois Urbana-Champaign Champaign, IL 61820 nanjiang@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Occupancy functions play an instrumental role in reinforcement learning (RL) for guiding exploration, handling distribution shift, and optimizing general objectives beyond the expected return. Yet, computationally efficient policy optimization methods that use (only) occupancy functions are virtually non-existent. In this paper, we establish the theoretical foundations of model-free policy gradient (PG) methods that compute the gradient through the occupancy for both online and offline RL, without modeling value functions. Our algorithms reduce gradient estimation to squared-loss regression and are computationally oracle-efficient. We characterize the sample complexities of both local and global convergence, accounting for both finite-sample estimation error and the roles of exploration (online) and data coverage (offine). Occupancy-based PG naturally handles arbitrary offline data distributions, and, with one-line algorithmic changes, can be adapted to optimize any differentiable objective functional. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Value-based methods have been the dominant paradigm in model-free reinforcement learning, with a solid theoretical foundation in large state spaces under function approximation [CJ19; JYWJ20a; ZLKB20; JLM21; XJ21; XFBJK22]. In contrast, a model-free RL paradigm based on their natural counterparts\u2014the occupancy functions\u2014remains largely under-investigated. Occupancy functions are densities that describe a policy's state visitation, and play instrumental roles in guiding exploration [HKSVS19; AFK24], handling distribution shift [HM17; NCDL19; CJ22], and optimizing general objectives beyond the expected return [ZB WK20; MDSDBR22]. Despite this, they are seldom modeled directly in learning algorithms and appear only in the analyses, except in conjunction with value functions in marginalized importance sampling [LLTZ18; NDKCLS19; UHJ20; ZHHJL22; HJ22a]. Recently, [HCJ23] developed algorithms in online and offline RL that model only occupancies via density function classes, spotlighting their roles in handling non-exploratory offline data and in online exploration. However, their focus was on statistical guarantees, and computationally efficient policy optimization for occupancy-based methods remained an open problem. ", "page_idx": 0}, {"type": "text", "text": "In answer, we develop model-free policy gradient (PG) algorithms that compute the gradient through occupancy functions, without estimating any values. By leveraging a Bellman-like recursion, we reduce occupancy-based gradient estimation to solving a series of squared-loss minimization problems, which can be done in a computationally oracle-efficient manner. Our analysis captures the effects of gradient estimation error, exploration (in online PG, which is characterized by the initial state distribution), and offline data quality (in offine PG) on the sample and iteration complexity required for local and global convergence. In the online setting, our results complement previous works on the optimality of value-based PG [AKLM21; BR24] and extend past their scope to include general objectives of occupancy functions, such as entropy maximization for pure exploration and risk-sensitive functionals in safe RL [MDSDBR22]. These objectives generally cannot be optimized using value-based policy gradients because they do not admit value functions or Bellman-like equations with which to estimate them [ZBWK20; HDGP24]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In the offline setting, we handle gradient estimation from fixed datasets of poor coverage, which departs from most existing (value-based) off-policy PG estimators that assume an exploratory dataset [KU20; XYWL21; NZJZW22]. Learning with non-exploratory data is a core consideration in recent offline RL [XCJMA21; ZHHJL22], and gives rise to unique challenges in our setting: occupancies are converted into density ratios for learning purposes, but these ratios become unbounded when the data lacks coverage. [HCJ23] used clipping to handle occupancy estimation under poor coverage, which we show is insuficient for gradient estimation (Prop. 4.2). Instead, a novel smooth-clipping mechanism (Sec. 4.2) is developed to provide statistically robust gradient estimates. ", "page_idx": 1}, {"type": "text", "text": "App. A includes a full discussion of related work, and our contributions are organized as follows: ", "page_idx": 1}, {"type": "text", "text": "1. Online PG (Sec. 3) We propose OccuPG, an occupancy-based PG algorithm that reduces gradient estimation to squared-loss minimization, based on a recursive Bellman fow-like update for the occupancy gradient. We analyze the sample complexities for both local and global convergence, and, notably, our algorithm and analyses extend straightforwardly to the optimization of general objective functionals. ", "page_idx": 1}, {"type": "text", "text": "2. Offline PG (Sec. 4) For offline RL we develop and analyze OFF-OccUPG, which optimizes only the portions of a policy's return that are adequately covered by offline data. Conceptually, our algorithm is based on combining the methods in Sec. 3 with (a smoothed version of) the recursively clipped occupancies from [HCJ23]. As a result, our estimation and convergence guarantees do not require assumptions on data coverage, which relaxes the restrictions of previous works. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Finite-horizon Markov decision process (MDP). Finite-horizon MDPs are defined by the tuple $\\mathcal{M}=(\\mathcal{S},\\mathcal{A},P,R,H,d_{0})$ , where $\\boldsymbol{S}$ is the state space, $\\boldsymbol{\\mathcal{A}}$ is the action space, and $H$ is the horizon. We use $[H]=\\{0,\\dots,H\\}$ and when clear from the context, use $\\{\\sqcup_{h}\\}=\\{\\sqcup_{h}\\}_{h\\in[H]}$ For notational compactness we assume that $S={\\dot{\\cup}}_{h}S^{h}$ is the union of $H$ disjoint sets $\\{S^{h}\\}$ , each of which is the set of states reachable at timestep $h$ . This is WLOG as we can always augment the state space with $[H]$ at the cost of only $H$ factors [JKALS17; MBFR24]. ", "page_idx": 1}, {"type": "text", "text": "Since each state can only be visited at a single timestep, we can now define the (non-stationary) transitions as $P:S\\times A\\to\\Delta(S)$ , and the initial state distribution as $d_{0}\\in\\Delta(S^{0})$ . We assume the reward function $R:S\\rightarrow[0,1]$ is bounded on the unit interval and (for simplicity) state-wise deterministic. This sufficiently captures the challenges of our setting since the occupancies are densities $\\pi:S\\to\\Delta(A)$ $\\mathcal{M}$ $\\{(s_{h},a_{h},\\bar{s}_{h+1},r_{h+1})\\}_{h=0}^{H-1}$ expetedetum $\\begin{array}{r}{J(\\pi)=\\mathbb{E}_{\\pi}[\\sum_{h=1}^{H}R(s_{h})]}\\end{array}$ $(h,s,a)$   \nthe value function $\\begin{array}{r}{Q_{h}^{\\pi}(s,a)\\stackrel{=}{=}\\!\\!\\!\\!\\{\\!\\!\\mathbb{E}_{\\pi}[\\sum_{h^{\\prime}>h}R(s_{h^{\\prime}})|s_{h}=s,a_{h}=a]}\\end{array}$ ", "page_idx": 1}, {"type": "text", "text": "For each $h\\in[H]$ a policy's occupancy function $d_{h}^{\\pi}\\in\\Delta(S)$ is a p.d.f. describing its state visitation, $d_{h}^{\\pi}(s)=\\mathbb{P}_{\\pi}(\\dot{s_{h}}\\stackrel{.}{=}s)$ . In combination with the policy, the MDP dynamics dictate the evolution of the occupancy over timesteps. This is encoded in the recursive Bellman flow equation, which mandates that $d_{h}^{\\pi}\\,=\\,{\\bf P}^{\\pi}d_{h-1}^{\\pi}$ for all $\\textit{h}\\in[H]$ . Here, ${\\bf P}^{\\pi}$ is the Bellman flow operator with $(\\mathbf{P}^{\\pi}f)(s^{\\prime}):=$ $\\begin{array}{r}{\\sum_{s,a}P(s^{\\prime}|s,a)\\pi(a|s)f(s)\\in\\mathbb{R}^{\\Omega}}\\end{array}$ , for any function $f:S\\rightarrow\\mathbb{R}^{\\boxed{}}$ ", "page_idx": 1}, {"type": "text", "text": "Policy optimization. For an objective function $f~:~\\Pi_{\\Theta}~\\rightarrow~\\mathbb{R}$ , the general goal of this work is to find $\\operatorname{argmax}_{\\pi_{\\theta}\\in\\Pi_{\\Theta}}f(\\pi_{\\theta})$ over a policy class $\\Pi_{\\Theta}\\;=\\;\\{\\pi_{\\theta}\\;:\\;\\theta\\;\\in\\;\\bar{\\Theta},\\theta\\;\\in\\;\\mathbb{R}^{\\mathfrak{p}},\\|\\theta\\|\\;\\le\\;B\\}$ parameterized by a convex and closed parameter class $\\Theta$ with dimension $\\mathsf{p}$ .One example of $f$ is the expected return $J(\\pi_{\\boldsymbol{\\theta}})$ :Projected gradient ascent (PGA) will be_ our base algorithm for policy optimization. For a fixed learning rate $\\eta$ and iterations $t~\\in~[T]$ , it iteratively updates $\\theta^{(t+1)}\\,=\\,\\mathrm{Proj}_{\\Theta}\\,\\bigl(\\theta^{(t)}+\\eta\\nabla f\\bigl(\\pi_{\\theta^{(t)}}\\bigr)\\bigr)$ . Here, $\\begin{array}{r}{\\nabla f(\\pi_{\\boldsymbol{\\theta}})\\,=\\,[\\frac{\\partial f(\\pi_{\\boldsymbol{\\theta}})}{\\partial\\boldsymbol{\\theta^{p}}}]_{p\\in[\\mathsf{p}]}\\,\\in\\,\\mathbb{R}^{\\mathsf{p}}}\\end{array}$ [ pe[p] RP is the gradient with respect to $\\theta$ , where superscript $p$ indexes the $p$ -th entry of a vector. We will assume that the gradient of the policy's log-probability is bounded, as is ubiquitous in the PG literature [LSAB 19; AKLM21]. ", "page_idx": 1}, {"type": "text", "text": "We will later analyze the convergence rate of our algorithms to stationary points with (approximately) zero gradient, and refer to $\\pi^{(t)}\\,=\\,\\pi_{\\theta^{(t)}}$ for short. For PGA, stationarity will be measured using the standard gradient mapping $\\|G^{\\eta}({\\pi^{(t)}})\\|$ with $\\begin{array}{r}{G^{\\eta}({\\pi^{(t)}})\\,:=\\,\\frac{1}{\\eta}(\\theta^{(t)}\\,-\\theta^{(t+1)})}\\end{array}$ , the parameter change between iterations [Bec17]. Note that if $\\Theta\\,=\\,\\mathbb{R}^{\\mathsf{p}}$ and no projection is required, then $\\|G^{\\eta}({\\boldsymbol{\\pi}}^{(t)})\\|=\\|\\nabla f({\\boldsymbol{\\pi}}^{(t)})\\|$ reduces to the gradient magnitude. ", "page_idx": 2}, {"type": "text", "text": "Computational oracles. As is common in the literature, we analyze computational efficiency in terms of the number of calls to the following oracles, which serve as computational abstractions. We desire a polynomial number of such calls in terms of problem-relevant parameters. Given an i.i.d. dataset $\\bar{\\boldsymbol{D}}\\doteq\\{(x,y)\\}$ and function class $\\mathcal{F}$ , the maximum likelihood estimation oracle outputs $\\operatorname{argmax}_{f\\in\\mathcal{F}}\\mathbb{E}_{\\mathcal{D}}[\\log f(x)]$ . The squared-loss regression oracle finds $\\mathrm{argmin}_{f\\in\\mathcal{F}}\\mathbb{E}_{\\mathcal{D}}[(f(x)-\\stackrel{\\cdot}{y})^{2}]$ Both can be approximated efficiently whenever optimizing over $\\mathcal{F}$ is feasible [MHKL20; FR20]. ", "page_idx": 2}, {"type": "text", "text": "3   Online Occupancy-based PG ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We now develop our occupancy-based policy optimization algorithm for the online RL setting, where the policy can continuously interact with the environment to gather new trajectories. Our gradient estimation routine is based on a recursive Bellman flow-like equation that can be approximately solved using squared-loss regression, not unlike those used to estimate occupancy functions in FORC [HCJ23] or value functions in FQI [ASMO7]. The intuitions established for our online algorithm form the foundation for our later offline methods. ", "page_idx": 2}, {"type": "text", "text": "3.1  Occupancy-based Policy Gradient ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The expected return of a policy $\\pi$ can be expressed as the expectation over its occupancy of the per-state rewards, $\\begin{array}{r}{J(\\pi)={\\dot{\\sum}}_{h}\\sum_{s_{h}}d_{h}^{\\pi}(s_{h})R{\\dot{(}}s_{h})}\\end{array}$ .The gradient of $J(\\pi)$ then passes through $d^{\\pi}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla J(\\pi)=\\sum_{h}\\sum_{s_{h}}\\nabla d_{h}^{\\pi}(s_{h})R(s_{h})=\\sum_{h}\\mathbb{E}_{s_{h}\\sim d_{h}^{\\pi}}\\left[\\nabla\\log d_{h}^{\\pi}(s_{h})R(s_{h})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "We use the grad-log trick above to write $\\nabla J(\\pi)$ as an expectation over $d^{\\pi}$ , which makes it amenable to estimation from online samples as long as we can calculate $\\nabla\\log d_{h}^{\\pi}\\,:\\,\\mathcal{S}\\,\\rightarrow\\,\\mathbb{R}^{\\mathsf{p}}$ .We make the key observation that $\\nabla\\log d_{h}^{\\pi}$ can be expressed as a function of $\\nabla\\log d_{h-1}^{\\pi}$ , which involves a time-reversed conditional expectation over the previous timestep's $\\left(s_{h-1},a_{h-1}\\right)$ given the current $s_{h}$ ", "page_idx": 2}, {"type": "text", "text": "Lemma 3.1. For any $\\pi$ and $h\\in[H],\\nabla\\log d_{h}^{\\pi}$ satisfies the recursion ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\nabla\\log d_{h}^{\\pi}={\\bf E}_{h-1}^{\\pi}\\left(\\nabla\\log\\pi+\\nabla\\log d_{h-1}^{\\pi}\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathbf{E}_{h-1}^{\\pi}f](s^{\\prime}):=\\mathbb{E}_{\\pi}[f(s_{h-1},a_{h-1})|s_{h}=s^{\\prime}]=\\sum_{s,a}\\frac{P(s^{\\prime}|s,a)\\pi(a|s)d_{h-1}^{\\pi}(s)}{d_{h}^{\\pi}(s^{\\prime})}f(s,a)^{1},}\\end{array}$ function $f:S\\times A\\to\\mathbb{R}^{\\mathsf{p}}$ Further, under Asm. 2.1, $\\begin{array}{r}{\\operatorname*{max}_{s,h}\\|\\nabla\\log d_{h}^{\\pi}(s)\\|_{\\infty}\\leq h G}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "Eq. (1) is derived by propagating the gradient through the Bellman flow equation, and we can solve it from $h=1$ to $H$ to compute $\\nabla\\log d_{h}^{\\pi}$ (with $\\nabla\\log d_{0}^{\\pi}=\\mathbf{0}$ by definition). While related observations have been made throughout the rich history of PG literature [CC97; MT01; KU20; XYWL21], the expression in Eq. (1) is adapted to our unique pursuit of modeling $\\nabla\\log d^{\\pi}$ with general function approximators. In particular, the conditional expectation $(\\mathbf{E}^{\\pi})$ immediately hints that $\\nabla\\log d^{\\pi}$ is amenable to estimation using squared-loss regression, a technique that is well-understood for value functions [SB18] and, more recently, for occupancy functions [HCJ23]. ", "page_idx": 2}, {"type": "text", "text": "Formally, to solve the dynamic programming equation of Eq. (1) in a computationally efficient manner, we reduce it to minimizing a squared-loss regression problem. Consider the standard (superviedleaningregression setupThe solutiont $\\mathrm{argmin}_{f}\\,\\mathbb{E}_{(x,y)\\sim Q}[(f(x)\\!-\\!y)^{2}]$ maps $x\\mapsto\\mathbb{E}_{Q}[\\bar{y^{\\vert}}x]$ the conditional expectation given $x$ of the target $y$ under the joint $Q$ . As a result (see Lem. B.2), ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla\\log d_{h}^{\\pi}=\\operatorname{argmin}_{g:S\\to\\mathbb{R}^{p}}\\,\\mathbb{E}_{\\boldsymbol\\pi}\\Big[\\Big\\|g(s_{h})-\\big(\\nabla\\log\\pi(a_{h-1}|s_{h-1})+\\nabla\\log d_{h-1}^{\\pi}(s_{h-1})\\big)\\Big\\|^{2}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Input: Samples $n$ ; iterations $T$ ; policy class $\\Pi_{\\Theta}$ ; gradient function class $\\{\\mathcal{G}_{h}\\}$ ; learning rate $\\eta$   \n12: for $t=0,\\dots,T-1$ $n$ des witht $\\pi^{(t)}$ Set ${\\cal D}_{h}^{\\mathrm{reg}}\\ =\\ \\{(s_{h},a_{h},s_{h+1})\\}_{i=1}^{n}$ for al $h$ Repeat for {Dgrad}.   \n3: Initialize $g_{0}={\\bf0}$   \n4:for $h=1,\\ldots,H$ do   \n5: Let $\\begin{array}{r}{\\mathcal{L}_{h-1}^{(t)}(g_{h};g_{h-1}):=\\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\left\\|g_{h}(s^{\\prime})-\\left(\\nabla\\log\\pi^{(t)}(a|s)+g_{h-1}(s)\\right)\\right\\|^{2}\\!.}\\end{array}$ Set $\\begin{array}{r}{\\widehat{g}_{h}^{(t)}=\\operatorname*{argmin}_{g_{h}\\in\\mathcal{G}_{h}}\\mathcal{L}_{h-1}^{(t)}(g_{h};\\widehat{g}_{h-1}^{(t)}).}\\end{array}$ (3)   \n6: end for 7:  Estimate $\\begin{array}{r}{\\widehat{\\nabla}J(\\pi^{(t)})=\\frac{1}{n}\\sum_{h=1}^{H}\\sum_{(s,a,s^{\\prime},r^{\\prime})\\in{\\mathcal D}_{h-1}^{\\mathrm{grad}}}\\widehat{g}_{h}^{(t)}(s^{\\prime})\\cdot r^{\\prime}}\\end{array}$   \n8:  Update $\\theta^{(t+1)}=\\operatorname{Proj}_{\\Theta}\\left(\\theta^{(t)}+\\eta\\widehat{\\nabla}J(\\pi^{(t)})\\right)$   \n9: end for ", "page_idx": 3}, {"type": "text", "text": "Here, $g$ is a vector-valued function, and the norm $\\|\\cdot\\|^{2}$ is equivalent to the sum of p scalar-valued squared-losses for each parameter dimension. The RHS only requires sampling $(s_{h-1},a_{h-1},s_{h})\\sim$ $\\pi$ from online rollouts. Then, given finite samples, we can robustly estimate $\\nabla\\log d^{\\pi}$ by minimizing an empirical version of Eq. (2) using regression oracles. ", "page_idx": 3}, {"type": "text", "text": "3.2  Online policy gradient algorithm and analyses ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Alg. 1 (OcCUPG) displays our full online occupancy-based PG procedure. For each iteration $t\\in$ $[T]$ we frt coletwo independent datasets' $\\{\\mathcal{D}_{h}^{\\mathrm{reg}}\\}$ for $\\nabla\\log d^{\\pi^{(t)}}$ estimation and $\\{\\mathcal{D}_{h}^{\\mathrm{grad}}\\}$ for $\\nabla J(\\pi^{(t)})$ estimation. The former occurs in Line 5, where we recursively solve an empirical version of Eq. (2); the latter is computed in Line 7, then used to update the policy (Line 8). ", "page_idx": 3}, {"type": "text", "text": "Gradient estimation guarantee. In the following, we establish that our regression-based estimation procedure produces accurate estimates of $\\nabla J(\\pi)$ . Our guarantee holds under the requirement that the gradient function classes $\\{\\mathcal{G}_{h}\\}$ can express the population gradient update (Lem. 3.1) for any target function. It is analogous to the Bellman completeness assumption that is required for regression-based value or occupancy function estimation [CJ19; HCJ23]. ", "page_idx": 3}, {"type": "text", "text": "Assumption3.1 (Gradient functionclasscompleteness)Foral $h\\in[H]$ $\\begin{array}{r}{\\operatorname*{sup}_{g\\in\\mathcal{G}_{h},s\\in\\mathcal{S}}\\|g_{h}(s)\\|_{\\infty}\\le}\\end{array}$ $^{h G}$ . Further, for all $\\pi\\in\\Pi_{\\Theta}$ ,we have $\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+g_{h-1})\\in\\mathcal{G}_{h}$ , for all $g_{h-1}\\in\\mathcal{G}_{h-1}$ ", "page_idx": 3}, {"type": "text", "text": "Next, since we allow $\\mathcal{G}$ to be a continuous function class, our sample complexity bound for gradient estimation is expressed in terms of its pseudodimension $:={\\mathsf{d}}_{\\mathcal{G}}$ (Def. F.1). Examples of $\\mathcal{G}$ parameterizations and their ${\\mathsf{d}}_{\\mathcal{G}}$ are discussed in Rem. 3.1 below. Finally, Thm. 3.1 shows that OccUPG produces accurate gradient estimates given the following polynomial sample size. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. 1 ${\\mathfrak{G}}{\\mathfrak{i}}x\\,\\delta\\in(0,1)$ and $\\pi\\in\\Pi_{\\Theta}$ . Under Asm. 2.1 and Asm. 3.1, we have that ${w.p.}\\,\\geq1-\\delta$ IVJ(\u03c0) - J(m)\u2264 e when n = 0 (adeHgo(/). ", "page_idx": 3}, {"type": "text", "text": "Remark 3.1. Lastly, we provide examples of $\\mathcal{G}$ for Asm. 3.1 in representative MDP structures. Lowrank MDPs (Def. B.1) are a well-studied setting where the transition function admits a low-rank decomposition into two features of rank $k$ , i.e., there exists $\\phi:S\\times A\\to\\mathbb{R}^{k}$ and $\\mu:\\mathcal{S}\\rightarrow\\mathbb{R}^{k}$ such that $P(s^{\\prime}|s,a)\\;=\\;\\langle\\phi(s,a),\\mu(s^{\\prime})\\rangle$ [JYWJ20b]. Tabular MDPs are a special case with onehot features. Due to the bilinear transitions, both the occupancy and its gradient are linear functions of $\\mu$ ,i.e., $d^{\\pi}\\ =\\ \\mu(s)^{\\top}\\psi$ and $\\nabla d^{\\pi}(s)\\;=\\;\\mu(s)^{\\top}\\Psi$ for some $\\bar{\\Psi}~\\breve{\\in}~\\mathbb{R}^{k\\times p},\\psi~\\in~\\mathbb{R}^{k}$ , and all $s\\ \\in\\ S$ When $\\mu$ is known, we can set $\\mathcal{G}_{h}$ to be a linear-over-linear function class $\\mathcal{G}_{h}\\ =$ e Rkx, R,max l()l\u2264 h, which has dg =kp Prop.B.1). ", "page_idx": 3}, {"type": "text", "text": "Stationary convergence. Next, we analyze the convergence rate of OccuPG to a stationary policy, i.e., one that has near-zero gradient. Note that, in general, stationary policies are not necessarily optimal as the objective function is non-convex. As is standard in the literature, we will assume that the objective has a smooth gradient [LSAB19; AKLM21]. ", "page_idx": 3}, {"type": "text", "text": "Assumption 3.2 $\\beta$ -smooth objective). For a function $f:\\Pi_{\\Theta}\\rightarrow\\mathbb{R}$ , there exists $\\beta>0$ such that $\\|\\nabla f(\\bar{\\pi_{\\theta}})-\\nabla f(\\pi_{\\theta^{\\prime}})\\|_{2}\\le\\beta\\|\\bar{\\theta^{-}}\\theta^{\\prime}\\|_{2}$ for all $\\theta,\\theta^{\\prime}\\in\\Theta$ ", "page_idx": 4}, {"type": "text", "text": "Cor. 3.1 shows that, in expectation, OcCUPG with $T=O(\\beta H/\\varepsilon)$ iterations outputs a $\\varepsilon$ -stationary point, as measured by $\\begin{array}{r}{\\|G^{\\eta}({\\pi^{(t)}})\\|\\;=\\;\\frac{1}{\\eta}\\|\\theta^{(t)}\\,-\\theta^{(t-1)}\\|}\\end{array}$ . The proof relies on Thm. 3.1, i.e., with enough samples the statistical noise of the gradient estimates are sufficiently small to enable convergence. ", "page_idx": 4}, {"type": "text", "text": "Corollary 3.1. Under Asm. 2.1, Asm. 3.1, and Asm. 3.2, the iterates of OccuPG with ${\\cal T}\\,=$ $O(\\beta H\\varepsilon^{-1})$ and $n=\\widetilde{O}(\\mathfrak{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(T/\\delta)\\varepsilon^{-1})$ satisfiy $\\begin{array}{r}{\\frac1T\\sum_{t=1}^{T}\\mathbb{E}[\\|G^{\\eta}({\\bar{\\pi}}^{(t)})\\|^{2}]\\leq\\varepsilon}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Computational efficiency. OccUPG is not only statistically efficient but computationally oracleefficient as well, since it reduces to a series of squared-loss minimization problems. In each iteration, it makes $H$ calls to a regression oracle to compute the occupancy gradient (Line 5). Then to converge to a $\\varepsilon$ -stationary point, from Cor. 3.1 we require a total of $\\dot{\\cal O}(\\beta\\dot{\\cal H}^{2}/\\varepsilon)$ such calls. ", "page_idx": 4}, {"type": "text", "text": "Optimality. Lastly, we analyze when the policies recovered by OccUPG are also approximately optimal. The key inequality is an upper bound on the suboptimality of any policy in terms of its gradient magnitude (or stationarity), and a coverage coeffcient $\\mathcal{C}^{\\pi^{*}}$ with respect to the optimal policy. ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.2. For any $\\pi$ and $\\pi^{\\prime}$ define $\\begin{array}{r}{B^{\\pi}(\\pi^{\\prime}):=\\sum_{h,s,a}d_{h}^{\\pi}(s)\\pi^{\\prime}(a|s)Q_{h}^{\\pi}(s,a)}\\end{array}$ Suppose $\\forall\\pi\\in\\Pi_{\\Theta}$ \uff0c 1. (Policy completeness) There exists $\\pi^{+}\\in\\Pi_{\\Theta}$ such that $\\pi^{+}\\in\\mathrm{argmax}_{\\pi^{\\prime}}\\,B^{\\pi}(\\pi^{\\prime}).$ 2. (Gradient domination) $\\begin{array}{r}{\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\Theta}}B^{\\pi}(\\pi^{\\prime})-B^{\\pi}(\\pi)\\leq m\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\langle\\ddot{\\nabla}B^{\\pi}(\\pi),\\theta^{\\prime}-\\theta\\rangle}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Given $\\nu\\in\\Delta(S)$ define the coverage coeffcient $\\begin{array}{r}{\\mathcal{C}^{\\pi^{*}}:=\\left\\|\\sum_{h}d_{h}^{\\pi^{*}}/\\nu\\right\\|_{\\infty}}\\end{array}$ for $\\pi^{*}=\\operatorname{argmax}_{\\pi}J(\\pi)$ Then for any $\\pi_{\\theta}\\in\\Pi_{\\Theta}$ \uff0c ", "page_idx": 4}, {"type": "equation", "text": "$$\nJ(\\pi^{*})-J(\\pi_{\\theta})\\leq m\\,\\mathcal{C}^{\\pi^{*}}\\,\\operatorname*{max}_{\\theta^{\\prime}\\in\\Pi_{\\Theta}}\\,\\langle\\nabla J_{\\nu}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\rangle\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $J_{\\nu}(\\pi):=\\mathbb{E}_{s_{0}\\sim\\nu,\\pi}[\\sum_{h}r_{h}]$ is the expected return of $\\pi$ in $\\mathcal{M}$ with initial state distribution $\\nu$ ", "page_idx": 4}, {"type": "text", "text": "The lemma preconditions are identical to those required for value-based analysis [BR24]. $B^{\\pi}(\\pi^{\\prime})$ is a one-step improvement objective with respect to the occupancies and value functions of $\\pi$ ,and we require (1) the policy class to be expressive enough that it contains any maximizer; and (2) the one-step objective to itself have optimality gap upper-bounded by the one-step policy gradient magnitude, for which the constant $m$ is determined wholly by the policy parameterization. For example, the tabular policy $\\pi_{\\theta}(a|s)=\\theta_{s a}$ has $m=1$ [AKLM21]. ", "page_idx": 4}, {"type": "text", "text": "The coverage coefficient $\\mathcal{C}^{\\pi^{*}}$ is the finite-horizon counterpart to the infinite-horizon \u201cexploratory initial distribution\u201d salient to the analysis of [AKLM21] and [BR24] (which lists developing it as future work). In RL, a small gradient magnitude alone does not guarantee optimality, as it can also occur when the policy rarely visits rewarding states. The coverage coefficient quantifies both how policy performance can suffer from insufficient exploration, as well as how exploratory initializations mitigates this problem. Finally, combining Lem. 3.2 with the stationary convergence result in Cor. 3.1 shows that, on average, the best-iterate of OccuPG is near-optimal. ", "page_idx": 4}, {"type": "text", "text": "Corollary 3.2. Under the preconditions of Lem. 3.2 and Cor. 3.1, running OccUPG2 with initial distributionv satisfes E[min J(T\\*)  J()] \u2264 e when T = 0 (\u03b2B(C-)m\u00b2-H2) and $n=$ $\\begin{array}{r}{\\widetilde{O}\\left(\\frac{B^{2}(\\mathcal{C}^{\\pi^{*}})^{2}m^{2}\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(T)}{\\varepsilon^{2}}\\right).}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "3.3  Optimization of general functionals ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "One standout feature of OccuPG is that it can, with a one-line change, be adapted for policy optimization of any (differentiable) objective function involving occupancies. We work with $\\begin{array}{r}{\\dot{J_{F}}(\\dot{\\pi_{\\big)}}=\\sum_{h}F_{h}(d_{h}^{\\pi})}\\end{array}$ as a representative formula, where $F_{h}:\\Delta(\\bar{S(\\bigcirc)}\\rightarrow\\bar{\\mathbb{R}}$ is a general functional. Such objectives often evade value-based PG optimization because they do not admit value functions or Bellman-like recursions with which to compute them. Examples include entropy maximization where $F_{h}(d)=-\\left\\langle d,\\log d\\right\\rangle$ ; imitation learning where $F_{h}(d)=-\\|d-d_{h}^{\\pi_{E}}\\|_{2}^{2}$ for an expert policy $\\pi_{E}$ ; and the expected return with $F_{h}(d)=\\langle d,\\mathbf{\\bar{\\cal{R}}}\\rangle$ [MDSDBR22]. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Th poliey gadiet is then $\\begin{array}{r}{\\nabla J_{F}(\\pi)\\ =\\ \\sum_{h}\\mathbb{E}_{s\\sim d_{h}^{\\pi}}\\left[\\frac{\\partial F_{h}(d)}{\\partial d(s)}|{d=}d_{h}^{\\pi}\\nabla\\log d_{h}^{\\pi}(s)\\right]}\\end{array}$ Implementatinwise, we need only change Line 7 in OccuPG to accommodate the new gradient formula, to $\\begin{array}{r}{\\widehat{\\nabla}J_{F}(\\pi)\\;=\\;\\frac{1}{n}\\sum_{h}\\sum_{s\\in{\\mathcal D}_{h}}\\widehat g_{h}^{\\pi}(s)\\;\\left.\\frac{\\partial F_{h}(d)}{\\partial d(s)}\\right|_{d=\\widehat{d}_{h}^{\\pi}}}\\end{array}$ .The prtial derivaie of $F_{h}$ is ealuate with a plug-in occupancy estimate $\\widehat{d}^{\\pi}$ that can be obtained using maximum likelihood estimation (App. D). Notably, the occupancy gradient estimation module for $\\displaystyle\\widehat{g}_{h}^{\\pi}\\,\\approx\\,\\nabla\\log{d_{h}^{\\pi}}$ (Line 5) is reused verbatim. Given their resemblance to those in Sec. 3.2, the full algorithm and analyses are deferred to App. B.5. ", "page_idx": 5}, {"type": "text", "text": "4   Offline Occupancy-based PG ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we develop an algorithm for occupancy-based policy optimization in the offline setting, where only fixed datasets are available for learning. A direct modification of OccuPG, e.g., by converting occupancies to density ratios over the offline data distribution, will fail unless the data covers all possible policies, otherwise the density ratio may be unbounded. In-line with recent state-of-the-art offline RL algorithms, our goal is to establish an offline PG algorithm that adapts to and retains meaningful guarantees under arbitrary offline datasets, for which our key consideration is establishing an offline gradient estimation method. We begin by defining these offline datasets. ", "page_idx": 5}, {"type": "text", "text": "Definition 4.1. The offline dataset is $\\mathcal{D}=\\{\\mathcal{D}_{h}\\}$ , where $\\mathscr{D}_{h}=\\{(s_{h},a_{h},s_{h+1},r_{h+1})\\}_{i=1}^{n}$ is generated i.id. as $s_{h}\\sim d_{h}^{D}$ for some $d_{h}^{D}\\in\\Delta(S)$ and $a_{h}\\sim\\pi_{h}^{D}(\\cdot|s_{h})$ in $\\mathcal{M}$ , for a known behavior policy $\\pi_{h}^{D}$ . The marginal next-state distribution in $\\mathcal{D}_{h}$ is denoted as $d_{h}^{D,\\dag}(s_{h+1})$ ", "page_idx": 5}, {"type": "text", "text": "Def. 4.1 is more general than the typical i.i.d. trajectory setting [KU20; NZJZW22], where $d_{h}^{D}=$ $d_{h-1}^{D,\\dagger}$ Cruecilly, mlike previous works tha reguirelower-bounded $d^{D}$ orall-poliey coveragesIKUL2o; XYWL21; NZJZW22], we will make no assumptions about the quality of with respectto $\\Pi_{\\Theta}$ ", "page_idx": 5}, {"type": "text", "text": "Addit $\\mathbb{E}_{\\mathcal{D}_{h}}[\\cdot]\\equiv\\mathbb{E}_{(\\underline{{s}}_{h,2h},\\mathscr{s}_{h+1},r_{h+1})\\sim\\mathcal{D}_{h}}[\\cdot]$ ,and use $(s,a,s^{\\prime},r^{\\prime})\\sim$ $\\mathcal{D}_{h}$ when clear from the context. For any $g:S\\!\\times\\!A\\!\\to\\!\\mathbb{R}^{\\mathsf{p}}$ and reweighting function $\\rho:H\\!\\times\\!S\\!\\times\\!A\\!\\rightarrow$ $\\mathbb{R}_{+}$ , we define an offine reweighted analog to ${\\bf E}_{h}^{\\pi}$ (Lem. 3.1) for all $h\\in[H]$ to be ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathbf{E}_{h}^{D,\\rho}g](s^{\\prime}):=\\mathbb{E}_{(s,a,s^{\\prime})\\sim\\mathcal{D}_{h}\\cdot\\rho_{h}}[g(s,a)|s^{\\prime}]=\\sum_{s,a}\\frac{[\\mathcal{D}_{h}\\cdot\\rho_{h}](s,a,s^{\\prime})}{\\sum_{s,a}[\\mathcal{D}_{h}\\cdot\\rho_{h}](s,a,s^{\\prime})}\\;g(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The   (time-reversed)  conditional  expectation  is  taken  over $\\begin{array}{r l r l}{[\\ensuremath{\\mathcal \u1e0a D \u1e0c }_{h}}&{{}\\cdot}&{\\ensuremath{\\rho}_{h}](s,a,s^{\\prime})}&{{}}&{:=}\\end{array}$ $P(s^{\\prime}|s,a)d_{h}^{D}(s)\\pi_{h}^{D}(a|s)\\rho_{h}(s,a)$ , the joint offline distribution re-weighted by $\\rho_{h}$ ..While this may not be a valid density, its induced conditional distribution on $(s,a|s^{\\prime})$ always is, i.e., $\\begin{array}{r l r}{\\sum_{s,a}\\frac{\\left[\\mathcal{D}_{h}\\cdot\\rho_{h}\\right](s,a,s^{\\prime})}{\\sum_{s,a}\\left[\\mathcal{D}_{h}\\cdot\\rho_{h}\\right](s,a,s^{\\prime})}}&{=}&{1}\\end{array}$ As an example fra given $\\pi$ Iwe have $\\mathbf{E}_{h}^{D,\\rho}\\ =\\ \\mathbf{E}_{h}^{\\pi}$ when $\\begin{array}{r}{\\rho_{h}(s,a)=\\frac{d_{h}^{\\pi}(s)\\pi(a|s)}{d_{h}^{D}(s)\\pi_{h}^{D}(a|s)}}\\end{array}$ is the policy's density ratio and is well-defined. ", "page_idx": 5}, {"type": "text", "text": "4.1  Offine density-based policy gradient ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "A policy's occupancy $d^{\\pi}$ may not be covered by arbitrary offline data (Def. 4.1), so neither its expected return $\\begin{array}{r}{\\dot{J}(\\pi)=\\sum_{h}\\langle\\dot{d}_{h}^{\\pi},R\\rangle}\\end{array}$ nor its gradient $\\nabla J(\\pi)$ will be estimatable from $\\mathcal{D}$ . As a result, there is no hope of recovering ar $\\operatorname{gmax}_{\\pi\\in\\Pi_{\\Theta}}J(\\pi)$ . Our solution is to instead maximize return only on areas of the state space that are sufficiently covered by offline data, which is captured exactly by the recursively clipped occupancy $\\bar{d}^{\\pi}$ from [HCJ23]. It clamps the policy occupancy to preset multiples $C_{h}^{\\mathbf{s}},C_{h}^{\\mathbf{a}}$ of the offine data distribution, thereby representing only the\u201csufficiently covered portion. ", "page_idx": 5}, {"type": "text", "text": "Definition 4.2 (Recursively clipped occupancy). Let $(\\sqcup{\\textstyle\\wedge}\\,\\sqcap):=\\operatorname*{min}\\{\\sqcap,\\varsqcup\\}$ . Given clipping constants $\\{C_{h}^{\\mathbf{s}},C_{h}^{\\mathbf{a}}\\}\\geq1$ , define the clipped policy to be $\\bar{\\pi}_{h}=\\left(\\pi\\wedge C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\right)$ , and recursively define ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{d}_{h}^{\\pi}=\\mathbf{P}^{\\bar{\\pi}_{h-1}}\\left(\\bar{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right),\\;\\forall h\\in[H].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Eq. (6) resembles the Bellman flow equation with clipped policy $\\bar{\\pi}$ , and acts on the previous-timestep $\\bar{d}_{h-1}^{\\bar{\\pi}}$ clipped to at most $C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}$ . Above this threshold the occupancy is considered to be insufficiently covered for estimation, and $C^{\\mathbf{s}}$ strikes a bias-variance tradeoff between the amount of ", "page_idx": 5}, {"type": "text", "text": "clipped mass vs. distribution shift. The clipped occupancy's density ratio is always well-defined and bounded as $\\bar{d}_{h}^{\\pi}/d_{h-1}^{D,\\dagger}\\leq C_{h-1}^{\\mathbf{s}}C_{h-1}^{\\mathbf{a}}$ and we use it to define our (now learmable offine objetive, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{J}(\\pi)=\\sum_{h}\\sum_{s_{h}}\\bar{d}_{h}^{\\pi}(s_{h})R(s_{h})=\\sum_{h}\\mathbb{E}_{\\mathcal{D}_{h-1}}\\left[\\frac{\\bar{d}_{h}^{\\pi}(s_{h})}{d_{h-1}^{D,\\dagger}(s_{h})}R(s_{h})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "For any \u201cfully covered\" policy with $d_{h}^{\\pi}\\leq C_{h-1}^{\\mathbf{s}}C_{h-1}^{\\mathbf{a}}d_{h-1}^{D,\\dagger}$ for all $h\\in[H]$ , we have ${\\bar{d}}^{\\pi}=d^{\\pi}$ and $\\bar{J}(\\pi)=J(\\pi)$ . In this sense, $\\mathrm{argmax}_{\\pi}\\,\\bar{J}(\\pi)$ will be at least as good as the best policy fully covered by offline data Next, define the densityratio be $\\bar{w}_{h}^{\\pi}:=\\bar{d}_{h}^{\\pi}/d_{h-1}^{D,\\dagger}$ The gradient of $\\bar{J}(\\pi)$ .s ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla\\bar{J}(\\pi)=\\sum_{h}\\mathbb{E}_{\\mathcal{D}_{h-1}}\\left[\\bar{w}_{h}^{\\pi}(s_{h})R(s_{h})\\nabla\\log\\bar{d}_{h}^{\\pi}(s_{h})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "To calculate this gradient we must compute both $\\bar{w}^{\\pi}$ and $\\nabla\\log d^{\\pi}$ ; for the former, [HCJ23] provides a method that we will later call as a subroutine. Our focus is on computing $\\bar{\\nabla}\\log\\bar{d}_{h}^{\\pi}$ ,which is enabled by the following recursive equation, which is an offline analog of Lem. 3.1. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. For ay $\\pi$ and ll $h\\in[H].$ defne $\\begin{array}{r}{\\bar{\\rho}_{h}^{\\pi}(s,a):=\\frac{\\big(\\bar{d}_{h}^{\\pi}(s)\\wedge C_{h}^{\\mathbf{s}}d_{h}^{D}(s)\\big)}{d_{h}^{D}(s)}\\frac{\\bar{\\pi}_{h}(a|s)}{\\pi_{h}^{D}(a|s)}}\\end{array}$ Then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\nabla\\log\\bar{d}_{h}^{\\pi}=\\mathbf{E}_{h-1}^{D,\\bar{\\rho}^{\\pi}}\\left(\\nabla\\log\\pi\\odot\\mathbf{1}[\\pi\\le C_{h}^{\\mathbf{a}}\\pi_{h-1}^{D}]+\\nabla\\log\\bar{d}_{h-1}^{\\pi}\\odot\\mathbf{1}[\\bar{d}_{h-1}^{\\pi}\\le C_{h}^{\\mathbf{s}}d_{h-1}^{D}]\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Lem. 4.1 is derived from applying the chain rule to Def. 4.2, and the clipped occupancies play an instrumental role in handling insufficient offline coverage. Notably, the indicator function zeroes-out both the gradients $\\nabla\\log\\pi$ and $\\nabla\\log\\bar{d}_{h-1}^{\\pi}$ where they are insuficiently covered, e.g., $\\bar{d}_{h-1}^{\\pi}(s)>$ $C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)$ . Further, under full offline coverage we recover Lem. 3.1 and $\\nabla\\log\\bar{d}^{\\pi}=\\nabla\\log d^{\\pi}$ ", "page_idx": 6}, {"type": "text", "text": "Because the rewards are nonnegative, $\\nabla\\log d^{\\pi}$ induces a pessimistic policy gradient that shifts policies away from out-of-distribution actions, even if they generate high return. This is seen more clearly in Prop. 4.1, that rearranges the resulting expression for $\\nabla\\bar{J}(\\bar{\\pi})$ into a value-based form: ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.1. We can equivalently write ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla\\bar{J}(\\pi)=\\sum_{h}\\mathbb{E}_{\\mathcal{D}_{h}}[\\bar{\\rho}_{h}^{\\pi}(s,a)\\nabla\\log\\pi_{h}(a|s)\\bar{Q}_{h}^{\\pi}(s,a)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\bar{Q}^{\\pi}$ is a pessimistic value function that obeys the Bellman-like recursion $\\bar{Q}_{h}^{\\pi}(s,a)\\;\\;=\\;\\;$ $\\begin{array}{r}{\\mathbf{1}[\\pi\\leq C_{h}^{\\mathbf{a}}\\pi_{h}^{D}](a|s)\\sum_{s^{\\prime}}P(s^{\\prime}|s,a)\\Big(R(s^{\\prime})+\\mathbf{1}[\\bar{d}_{h+1}^{\\pi}\\leq C_{h+1}^{\\mathbf{s}}d_{h+1}^{D}](s^{\\prime})\\ \\bar{Q}_{h+1}^{\\pi}(s^{\\prime},\\bar{\\pi}_{h+1})\\Big)}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "In ${\\bar{Q}}^{\\pi}$ , future returns are zeroed out at states and actions that exceed the threshold of data coverage, due to indicators functions that are inherited from $\\nabla\\log{\\bar{d}^{\\pi}}$ . Prop. 4.1 can be seen as a pessimistic offline analog to the classical PG theorem $\\begin{array}{r}{\\nabla J(\\pi)=\\sum_{h}\\mathbb{E}_{s,a\\sim d_{h}^{\\pi}}\\left[\\nabla\\log\\pi(a|s)Q_{h}^{\\pi}(s,a)\\right]}\\end{array}$ [SMSM99], entirely induced by the definition of the clipped occupancy. ", "page_idx": 6}, {"type": "text", "text": "Non-robustness of $\\nabla\\log d^{\\pi}$ estimation to plug-in densities. With finite samples, however, it turns out that consistent estimates of $\\nabla\\log\\bar{d}_{h}^{\\pi}$ in Eq. (6) cannot be computed. To make this argument, we first outline the high-level gradient estimation procedure for a fixed policy: ", "page_idx": 6}, {"type": "text", "text": "\u00b7 Estimate occupancies $\\{\\widehat{d}_{h}^{\\pi}\\}$ and $\\{\\widehat{d}_{h}^{D}\\}$   \n\u00b7 Compute $\\widehat{\\nabla}\\log\\bar{d}_{h}^{\\pi}$ using Eq. (7) with plug-in indicator function estimate $1[\\widehat{d}_{h-1}^{\\pi}\\ \\leq$ $C_{h}^{\\mathbf{s}}\\widehat{d}_{h-1}^{D}]$ ", "page_idx": 6}, {"type": "text", "text": "The problem arises in step two, as $\\mathbf{1}[\\cdot]$ is a stepwise function and not smooth. Even if $\\widehat{d}^{\\pi}$ isvanishingly close to $d^{\\pi}$ , the gradient calculated from plug-in occupancy estimates can have constant error. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.2. There exists an MDP and policy $\\pi$ such that, for any $\\varepsilon>0$ $0,\\,\\operatorname*{max}_{h,s}\\,\\|\\nabla\\log d_{h}^{\\pi}(s)-$ $\\widehat{\\nabla}\\log\\bar{d}_{h}^{\\pi}(s)\\|=O(1)$ when $\\|\\bar{d}_{h}^{\\pi}-\\widehat{d}_{h}^{\\pi}\\|_{1}\\leq\\varepsilon$ and $\\|\\widehat{d_{h}^{D}}-d_{h}^{D}\\|_{1}\\le\\varepsilon$ for all $h$ ", "page_idx": 6}, {"type": "text", "text": "4.2  Smooth clipping ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To resolve this issue, we will use a \u201csmooth-clipping\u201d function $\\sigma\\left(x,c\\right)$ to approximate the \u201chard\"- clipping $(x\\wedge c)$ in Eq. (6), whose non-smooth gradient was the source of our estimation problems. Figure 1 plots 1-D examples of $\\sigma\\left(x,c\\right)$ against $(x\\land c)$ as reference (dashed), and Asm. 4.1 describes the properties of $\\sigma$ that enable our later estimation and convergence guarantees. ", "page_idx": 6}, {"type": "image", "img_path": "Nq8enbbaP2/tmp/c4f8a902c12898932d9468c6f58c440e9734351eadc27d18fbbca76ba7ae5fe0.jpg", "img_caption": ["Assumption 4.1. Assume that $\\sigma$ satisfies $\\forall x,x^{\\prime},c,c^{\\prime}\\in\\mathrm{dom}(\\sigma)$ ", "Figure 1: We plot $\\sigma(x,c)$ from Prop. 4.3 for different $b$ \uff0cthat trade-off between clipping approximation error and smoothness $(D_{\\sigma}\\propto1/L_{\\sigma})$ "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "1. (Approximate clipping) $\\exists D_{\\sigma}\\geq0$ such that $0\\leq\\left(x\\wedge c\\right)-\\sigma\\,(x,c)\\leq D_{\\sigma}\\,(x\\wedge c).$ 2. (Monotonicity) $\\sigma\\left(x^{\\prime},c\\right)\\leq\\sigma\\left(x,c\\right)$ $x^{\\prime}\\leq x;\\sigma\\left(x,c^{\\prime}\\right)\\leq\\sigma\\left(x,c\\right)$ $c^{\\prime}\\leq c$ and vice versa. 3. (Smooth gradient) Define the smoothed indicator $\\tilde{\\mathbf{1}}\\left(x,c\\right):=\\,x\\,\\partial_{x}\\log\\sigma\\left(x,c\\right)$ , where $\\partial_{x}$ is the partial derivative w.r.t. $x$ . Then $\\tilde{\\mathbf{1}}\\left(x,c\\right)\\in\\,[0,1]$ and $\\exists L_{\\sigma}\\,\\geq\\,0$ s.t. $\\forall x,x^{\\prime},c,c^{\\prime}\\in$ $\\operatorname{dom}(\\sigma)$ \uff0c ", "page_idx": 7}, {"type": "equation", "text": "$$\nc|\\widetilde{\\mathbf{1}}\\left(x,c\\right)-\\widetilde{\\mathbf{1}}\\left(x^{\\prime},c\\right)|\\leq L_{\\sigma}|x-x^{\\prime}|,\\mathrm{~and~}x|\\widetilde{\\mathbf{1}}\\left(x,c\\right)-\\widetilde{\\mathbf{1}}\\left(x,c^{\\prime}\\right)|\\leq L_{\\sigma}|c-c^{\\prime}|.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Note that $\\sigma\\left(x,c\\right)=(x\\wedge c)$ is a special case with $\\tilde{\\mathbf{1}}\\left(x,c\\right)=\\mathbf{1}[x\\leq c]$ , thus $D_{\\sigma}=0$ and $L_{\\sigma}=\\infty$ The following choice of $\\sigma$ , which is plotted in Fig. 1, fulfills Asm. 4.1. ", "page_idx": 7}, {"type": "text", "text": "Proposition 4.3. For any $b>1$ $\\sigma\\left(x,c\\right)=\\left(x^{-b}+c^{-b}\\right)^{-1/b}$ has $L_{\\sigma}=b$ and $D_{\\sigma}=1/b$ ", "page_idx": 7}, {"type": "text", "text": "Next, we define the smooth-clipped occupancy function $\\widetilde{d_{h}^{\\pi}}$ , which is no larger than $\\bar{d}_{h}^{\\pi}$ ", "page_idx": 7}, {"type": "text", "text": "Definition 4.3 (Recursively smooth-clipped occupancy). For smooth-clipping function $\\sigma$ satisfying Asm. 4.1 and clipping constants $\\{C_{h}^{\\mathbf{s}},\\bar{C}_{h}^{\\mathbf{\\bar{a}}}\\}$ ,define $\\widetilde{\\pi}_{h}:=\\sigma\\left(\\pi,C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\right)$ , and inductively set ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{d}_{h}^{\\pi}=\\mathbf{P}^{\\widetilde{\\pi}_{h-1}}\\left(\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right)\\right),\\,\\forall h\\in[H].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Then letting $\\widetilde{w}_{h}^{\\pi}:=\\widetilde{d_{h}^{\\pi}}/d_{h-1}^{D,\\dagger}$ , our new objectiv is $\\begin{array}{r}{\\widetilde{J}(\\pi)=\\sum_{h}\\mathbb{E}_{\\mathcal{D}_{h-1}}[\\widetilde{w}_{h}^{\\pi}(s_{h})R(s_{h})]}\\end{array}$ with gradient $\\begin{array}{r}{\\nabla\\widetilde{J}(\\pi)=\\sum_{h}\\mathbb{E}_{\\mathcal{D}_{h-1}}[\\widetilde{w}_{h}^{\\pi}(s_{h})R(s_{h})\\,\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s_{h})]}\\end{array}$ , where $\\nabla\\log\\widetilde{d_{h}^{\\pi}}$ obeys the following recursion. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.2. For $\\sigma$ satisfying Asm. 4.1,recall $\\tilde{\\mathbf{1}}\\left(x,c\\right):=x\\,\\partial_{x}\\log\\sigma\\left(x,c\\right)$ Then for all $h\\in[H],$ $\\nabla\\log\\widetilde{d}_{h}^{\\pi}=\\mathbf{E}_{h-1}^{D,\\widetilde{\\rho}^{\\pi}}\\Big(\\nabla\\log\\pi\\odot\\widetilde{\\textbf{1}}\\big(\\pi,C_{h-1}^{\\textbf{a}}\\pi_{h-1}^{D}\\big)+\\nabla\\log\\widetilde{d}_{h-1}^{\\pi}\\odot\\widetilde{\\textbf{1}}\\Big(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\textbf{s}}d_{h-1}^{D}\\Big)\\Big),$ (9) where P-1(s,a) :=-()-(@)(@) and EP- is defined in Eq. (5). Further, under Asm. 2.1, $\\begin{array}{r}{\\operatorname*{max}_{s,h}\\|\\nabla\\log\\widetilde{d_{h}^{\\pi}}(s)\\|_{\\infty}\\le h G.}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "Eq. (9) replaces the (non-smooth) indicator function in $\\nabla\\log d^{\\pi}$ (Lem. 4.1) with its smooth approximation $\\tilde{1}$ , which, as we will show shortly, enables robust gradient estimation with plug-in occupancy estimates. As before, we can reduce it to squared-loss regression (Eq. (11)). Further, by optimizing $\\widetilde{J}(\\pi)$ , we also approximately maximize our target objective $\\bar{J}(\\pi)$ , with bias proportional to $D_{\\sigma}$ ", "page_idx": 7}, {"type": "text", "text": "Proposition 4.4. Under Asm. 4.1, $\\begin{array}{r}{0\\leq\\operatorname*{max}_{\\pi\\in\\Pi_{\\Theta}}\\bar{J}(\\pi)-\\operatorname*{max}_{\\pi\\in\\Pi_{\\Theta}}\\widetilde{J}(\\pi)\\lesssim H^{2}D_{\\sigma}.}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "4.3   Offine smooth-clipped gradient estimation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Alg. 2 describes the offline PG algorithm for optimizing $\\widetilde{J}(\\pi)$ .To reduce clutter, we have used $\\nabla\\log\\widetilde{\\pi}_{h}\\;:=\\;\\nabla\\log\\pi\\odot\\;\\widetilde{\\textbf{1}}\\big(\\pi,C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\big)$ . First, OFF-OcCUPG estimates $d_{h-1}^{D}$ using MLE (details in App. D due to space constraints). Then, for each iteration $t$ , it estimates the smooth-clipped occupancy d $\\widetilde{d_{h}^{\\pi^{(t)}}}$ using FORC (adapted from [HCJ23], see App. E). This is plugged into a squaredloss regression problem approximating Eq. (9) to learn $\\nabla\\log\\tilde{d}_{h}^{(t)}$ (lines 8 to 10), then estimate $\\nabla\\widetilde{J}(\\pi^{(t)})$ (line 12). ", "page_idx": 7}, {"type": "text", "text": "Algorithm 2 OFF-OcCUPG: Offline Occupancy-based Policy Gradient ", "page_idx": 8}, {"type": "text", "text": "Input: data $\\mathcal{D}$ iters $T$ ; learning rate $\\eta$ function classes $\\Pi_{\\Theta},{\\mathcal{F}},\\mathcal{W},{\\mathcal{G}}$ ; clipping constants $\\overline{{\\{C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}\\}}}$   \n1: Split $\\mathcal{D}$ equally into $\\mathcal{D}^{\\mathrm{mle}},\\mathcal{D}^{\\mathrm{FORC}},\\mathcal{D}^{\\mathrm{reg}},\\mathcal{D}^{\\mathrm{grad}}$ each with $n$ samples.   \n2: Estimate $\\{\\widehat{d}_{h}^{D},\\widehat{d}_{h}^{D,\\dagger}\\}\\leftarrow\\mathrm{MLE}\\left(\\mathcal{D}^{\\mathrm{mle}},\\mathcal{F}\\right)$ // Alg. 4   \n3: for $t=0,\\dots,T-1$ do   \n4:  Estmate $\\{\\widehat{w}_{h}^{(t)}\\}\\gets\\mathrm{FoRc}\\left(\\pi^{(t)},\\mathcal{D}^{\\mathrm{FORC}},\\mathcal{W},\\{\\widehat{d}_{h}^{D},\\widehat{d}_{h}^{D,\\dagger}\\}\\right)$ //Alg.5   \n5: Set occupaney estimate $\\widehat{d}_{h}^{(t)}=\\widehat{w}_{h}^{(t)}\\;\\widehat{d}_{h-1}^{D,\\dagger}$ for all $h\\in[H]$   \n6: Initialize g $\\widehat{g}_{0}^{(t)}=\\mathbf{0}$   \n7: for $h=1,\\ldots,H$ do   \n8: Set density ratio $\\begin{array}{r}{\\widehat{\\rho}_{h-1}^{(t)}=\\frac{\\widetilde{\\pi}_{h-1}^{(t)}}{\\pi_{h-1}^{D}}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{(t)},C_{h-1}^{\\mathbf{s}}\\widehat{d}_{h-1}^{D}\\right)}{\\widehat{d}_{h-1}^{D}}}\\end{array}$   \n9: Set radient egresson target $\\boldsymbol{\\widehat{y}}_{h-1}^{(t)}=\\boldsymbol{\\widehat{g}}_{h-1}^{(t)}\\odot\\boldsymbol{\\widetilde{\\mathbf{1}}}\\left(\\boldsymbol{\\widehat{d}}_{h-1}^{(t)},C_{h-1}^{\\mathbf{s}}\\boldsymbol{\\widehat{d}}_{h-1}^{D}\\right)$   \n10: Lel $\\begin{array}{r}{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! $ Solve   \n$\\begin{array}{r}{\\widehat{g}_{h}^{(t)}=\\operatorname*{argmin}_{g_{h}\\in\\mathcal{G}_{h}}\\;\\widetilde{\\mathcal{L}}_{h-1}^{(t)}(g_{h};\\widehat{y}_{h-1}^{(t)},\\widehat{\\rho}_{h-1}^{(t)})}\\end{array}$ (10) ", "page_idx": 8}, {"type": "text", "text": "11: end for. ", "text_level": 1, "page_idx": 8}, {"type": "equation", "text": "$\\begin{array}{r}{\\hat{\\widetilde{\\nabla}}\\hat{\\mathcal{J}}(\\pi^{(t)})=\\frac{1}{n}\\sum_{h=1}^{H}\\sum_{(s,a,s^{\\prime},r^{\\prime})\\in{\\mathcal D}_{h}^{\\mathrm{grad}}}\\widehat w_{h}^{(t)}(s^{\\prime})\\cdot\\widehat g_{h}^{(t)}(s^{\\prime})\\cdot r^{\\prime}}\\end{array}$ ", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Before stating the estimation guarantee for $\\nabla\\widetilde{J}(\\pi)$ , we first introduce the required assumptions. For simplicity, we assume that the function classes used in MLE and FoRC are finite, and defer their guarantees to the respective appendices, as they have been well-established in previous papers [AKKS20; HCJ23]. We focus on discussing Asm. 4.2 for the offline gradient function class, which requires a stronger level of expressiveness. Since the regression target in OFF-OccUPG involves plug-in occupancy estimates, the completeness condition naturally requires $\\mathcal{G}_{h}$ to express the gradient update in Lem. 4.2 for all possible targets composed of functions from $F_{h-1},\\mathcal{W}_{h-1},\\mathcal{G}_{h-1}$ .As a result, Asm. 4.2 is generally stronger than Asm. 3.1 for OccuPG. ", "page_idx": 8}, {"type": "text", "text": "Assumption 4.2.For all $h$ $\\operatorname*{sup}_{g\\in\\mathcal{G}_{h}}\\|g_{h}\\|_{\\infty}\\,\\leq\\,h G$ and for all $(\\pi,g,f,f^{\\prime},w)\\,\\in\\,\\Pi_{\\Theta}\\,\\times\\,\\mathcal{G}_{h-1}\\,\\times$ $\\mathcal{F}_{h}\\,\\times\\,\\mathcal{F}_{h-1}\\,\\times\\,\\mathcal{W}_{h-1}$ , we have $\\mathbf{E}_{h-1}^{D,\\rho}(\\nabla\\log\\widetilde{\\pi}_{h-1}+g\\odot\\widetilde{\\textbf{1}}\\big(w f^{\\prime},C_{h-1}^{\\mathbf{s}}f\\big))\\ \\in\\ \\mathcal{G}_{h}$ where $\\rho=$ $\\frac{\\sigma\\big(w f^{\\prime},C_{h}^{\\mathbf{s}}f\\big)}{f}\\,\\frac{\\widetilde{\\pi}_{h-1}}{\\pi_{h-1}^{D}}$ ", "page_idx": 8}, {"type": "text", "text": "When the underlying MDP has favorable structure, however, we can expect that ${\\mathsf{d}}_{\\mathcal{G}}$ is not much larger than was required for OcCUPG. This is indeed the case in low-rank MDPs, where the $\\mathcal{G}$ defined in Rem. 3.1 also satisfies Asm. 4.2 (proof in Prop. C.1). Due to the bilinear transition structure, the offline gradient update (Lem. 4.2) applied to any target remains a linear-over-linear function. ", "page_idx": 8}, {"type": "text", "text": "The guarantees for the MLE (Alg. 4) and weight estimation (Alg. 5) subroutines require Asm. D.1 and Asm. E.1, respectively, which are included in the preconditions of the main result below. Briefly, Asm. D.1 reqguires $\\mathcal{F}$ to realie thetruedatadsributions $d_{h}^{D}$ and $d_{h}^{D,\\dagger}$ .whichis standard in supervised learning. Asm. E.1 requires to be closed under the Bellman flow operator, and can be viewed as a 1-dimensional version of Asm. 4.2 where $\\rho\\,=\\,1$ . In this sense both assumptions are weaker requirements on expressivity than that of the gradient class in Asm. 4.2, and more detailed discussions are left to App. D and App. E. ", "page_idx": 8}, {"type": "text", "text": "Having established its preconditions, we now present our main estimation guarantee for OFFOccuPG, which pays additional factors for the coverage of offine data $(\\sum_{h}C_{h}^{\\mathbf{s}}\\bar{C}_{h}^{\\mathbf{a}})$ and the smoothnessof $\\sigma$ ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1. Suppose $\\widetilde J(\\cdot)$ satisfies Asm. 3.2 and fix $\\pi~\\in~\\Pi_{\\Theta}$ .Under Asm. 2.1, Asm. 4.1, Asm. 4.2, Asm. D.l, and Asm. E.1, w.p. $\\ge~1~-~\\delta$ we have $\\|\\nabla\\widetilde{J}(\\pi)\\,-\\,\\widehat{\\nabla}\\widetilde{J}(\\pi)\\|\\ \\le\\ \\varepsilon$ when $\\begin{array}{r}{n=\\widetilde{O}\\left(\\frac{\\ p\\mathsf{d}_{\\mathcal{G}}H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}\\right)^{2}L_{\\sigma}^{2}\\log\\left(|\\mathcal{W}||\\mathcal{F}|/\\delta\\right)}{\\varepsilon^{2}}\\right)}\\end{array}$ ", "page_idx": 9}, {"type": "text", "text": "Stationary convergence $\\pmb{\\&}$ computational efficiency. Similar to OcCUPG, OFF-OcCUPG with $T=O(\\beta\\dot{H}^{2}/\\varepsilon^{2})$ converges to an $\\varepsilon$ -stationary point. The formal statement is given in Cor. C.1 and is based on the estimation guarantee in Thm. 4.1. As a result, OFF-OccUPG is also computationally oracle-efficient. Each invocation of MLE involves $2H$ calls to a likelihood maximization oracle (see Alg. 4), and each invocation of FoRC requires $H$ calls to a squared-loss regression oracle (see Alg. 5). Then local convergence is still achieved with $O(\\beta H^{2}/\\varepsilon^{2})$ such calls, as increasing $T$ further cannot reduce error from statistical noise (that depends only on the fixed $n$ ", "page_idx": 9}, {"type": "text", "text": "Optimality.  Analyzing the conditions under which offline PG recovers global optima is more challenging, as we can no longer utilize exploratory initialization (from Cor. 3.2). However, since all occupancies have been clipped to the data distribution, we show in App. C.5 that the offline data itself can sometimes suffice as an exploratory initial distribution, and the corresponding bound is in terms of $\\{C_{h}^{\\mathbf{s}}\\}$ (instead of the online $\\mathcal{C}^{\\pi^{*}}$ ). However, this is not guaranteed in general and our current result only holds under strong all-policy offline data coverage. Briefly, some hardness comes from the fact that clipping causes gradient signals to vanish, so a stationary policy might be far offsupport, rather than optimal. Investigating the possibility of more relaxed conditions for offline PG convergence (or, conversely, refining hardness results) are especially interesting directions for future Work. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "For the first time, we demonstrate how policy optimization can be conducted with (only) occupancy functions for both online and offline RL, and comprehensively analyze both local and global convergence. In the online setting our method directly extends to optimizing general objective functionals that cannot be optimized using value-based methods, and in the offline setting the occupancy-based gradient naturally handles incomplete offine data coverage. As our work is the first in this line of research and theoretical in nature, for future work we plan to launch empirical investigations of our methods, especially those for optimizing general functionals. Additionally, the conditions under which offline PG can converge to global optima is not well-understood, and we hope that our preliminary results here encourage greater interest and investigation into this question. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Nan Jiang acknowledges funding support from NSF IIS-2112471, NSF CAREER IIS-2141781, Google Scholar Award, and Sloan Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[AFK24] Philip Amortila, Dylan J Foster, and Akshay Krishnamurthy. \u201cScalable Online Exploration via Coverability\". In: arXiv preprint arXiv:2403.06571 (2024).   \n[AKKS20] Alekh Agarwal, Sham Kakade, Akshay Krishnamurthy, and Wen Sun. \u201cFlambe: Structural complexity and representation learning of low rank mdps\". In: Advances in Neural Information Processing Systems (2020).   \n[AKLM21] Alekh Agarwal, Sham M Kakade, Jason D Lee, and Gaurav Mahajan. \u201cOn the theory of policy gradient methods: Optimality, approximation, and distribution shift'. In: The Journal of Machine Learning Research 22.1 (2021), pp. 4431-4506.   \n[ASM07] Andras Antos, Csaba Szepesvari, and R\u00e9mi Munos. \u201cFitted Q-iteration in continuous action-space MDPs\". In: Advances in neural information processing systems 20 (2007).   \n[Bec17] Amir Beck. First-order methods in optimization. SIAM, 2017.   \n[BFH23] Anas Barakat, llyas Fatkhullin, and Niao He. \\*Reinforcement learning with general utilities: Simpler variance reduction and large state-action space\". In: International Conference on Machine Learning. PMLR. 2023, pp. 1753-1800.   \n[BR24] Jalaj Bhandari and Daniel Russo. \u201cGlobal optimality guarantees for policy gradient methods\". In: Operations Research (2024).   \n[CC97] Xi-Ren Cao and Han-Fu Chen. \u201cPerturbation realization, potentials, and sensitivity analysis of Markov processes\". In: IEEE Transactions on Automatic Control 42.10 (1997), pPp. 1382-1393.   \n[CJ19] Jinglin Chen and Nan Jiang. \u201cInformation-Theoretic Considerations in Batch Reinforcement Learning\". In: International Conference on Machine Learning. 2019.   \n[CJ22] Jinglin Chen and Nan Jiang. \u201cOffine reinforcement learning under value and density-ratio realizability: the power of gaps\". In: Uncertainty in Artificial Intelligence. PMLR. 2022, p. 378-388.   \n[DWS12] Thomas Degris, Martha White, and Richard S Sutton. \u201cOff-policy actor-critic\". In: arXiv preprint arXiv: 1205.4839 (2012).   \n[FR20] Dylan Foster and Alexander Rakhlin. \u201cBeyond ucb: Optimal and efficient contextual bandits with regression oracles\". In: International Conference on Machine Learning. PMLR. 2020, pp. 3199-3210.   \n[GL16] Saeed Ghadimi and Guanghui Lan. \u201cAccelerated gradient methods for nonconvex nonlinear and stochastic programming\". In: Mathematical Programming 156.1-2 (2016), pp. 59-99.   \n[HCJ23] Audrey Huang, Jinglin Chen, and Nan Jiang. \\*Reinforcement Learning in LowRank MDPs with Density Features\". In: arXiv preprint arXiv:2302.02252 (2023).   \n[HDGP24] Jia Lin Hau, Erick Delage, Mohammad Ghavamzadeh, and Marek Petrik. \u201cOn Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes\". In: Advances in Neural Information Processing Systems 36 (2024).   \n[HJ22a] Audrey Huang and Nan Jiang. \u201cBeyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions\". In: Advances in Neural Information Processing Systems. 2022.   \n[HJ22b] Jiawei Huang and Nan Jiang. \u201cOn the convergence rate of off-policy policy optimization methods with density-ratio correction\". In: International Conference on Artificial Intelligence and Statistics. PMLR. 2022, pp. 2658-2705.   \n[HKSVS19] Elad Hazan, Sham Kakade,Karan Singh, and AbbyVan Soest. \u201cProvably fcint maximum entropy exploration\". In: International Conference on Machine Learning. PMLR. 2019, pp. 2681-2691.   \n[HM17] Assaf Hallak and Shie Mannor. \"Consistent on-line off-policy evaluation\". In: International Conference on Machine Learning. PMLR. 2017, pp. 1372-1383.   \n[JKALS17] Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert E Schapire. \u201cContextual decision processes with low Bellman rank are PAClearnable\". In: International Conference on Machine Learning. 2017.   \n[JLM21] Chi Jin, Qinghua Liu, and Sobhan Miryoosef. \u201cBellman Eluder dimension: New rich classes of RL problems, and sample-efficient algorithms\". In: Advances in Neural Information Processing Systems. 2021.   \n[JYWJ20a] Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. \u201cProvably effcient reinforcement learning with linear function approximation\". In: Conference on Learning Theory. 2020.   \n[JYWJ20b] Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. \u201cProvably effcit reinforcement learning with linear function approximation\". In: Conference on learning theory. PMLR. 2020, pp. 2137-2143.   \n[KJDC24] Pulkit Katdare, Anant Joshi, and Katherine Driggs-Campbell \"Towards Provable Log Density Policy Gradient\". In: arXiv preprint arXiv:2403.01605 (2024).   \n[KU20] Nathan Kallus and Masatoshi Uehara. \u201cStatistically efficient off-policy policy gradients\". In: International Conference on Machine Learning. PMLR. 2020, pp. 5089-5100.   \n[LLTZ18] Qiang Liu, Lihong Li, Ziyang Tang, and Dengyong Zhou. \u201cBreaking the curse of horizon: Infinite-horizon off-policy estimation\". In: Advances in neural information processing systems 31 (2018).   \n[LNSJ23] Qinghua Liu, Praneeth Netrapalli, Csaba Szepesvari, and Chi Jin. \u201cOptimistic mle: A generic model-based algorithm for partially observable sequential decision making\". In: Proceedings of the 5th Annual ACM Symposium on Theory of Computing. 2023, pp. 363-376.   \n[LSAB19] Yao Liu, Adith Swaminathan, Alekh Agarwal, and Emma Brunskill. \u201cOffpolicy policy gradient with state distribution correction\". In: arXiv preprint arXiv: 1904.08473 (2019).   \n[MBFR24] Zak Mhammedi, Adam Block, Dylan J Foster, and Alexander Rakhlin. \u201cEficient model-free exploration in low-rank mdps\". In: Advances in Neural Information Processing Systems 36 (2024).   \n[MDSDBR22]  Mirco Muti, Riccardo De Santi, Piersilvio De Bartolomeis, and Marcello Restelli. \"Challenging common assumptions in convex reinforcement learning\". In: Advances in Neural Information Processing Systems 35 (2022),pp. 4489-4502.   \n[MHKL20] Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy, and John Langford. \u201cKinematic state abstraction and provably effcient rich-observation reinforcement learning\". In: International conference on machine learning. 2020.   \n[MT01] Peter Marbach and John N Tsitsiklis. \u201cSimulation-based optimization of Markov reward processes\". In: IEEE Transactions on Automatic Control 46.2 (2001), pp. 191-209.   \n[NCDL19] Ofir Nachum, Yinlam Chow, Bo Dai, and Lihong Li. Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections\". In: Advances in neural information processing systems 32 (2019).   \n[NDKCLS19] Ofir Nachum, Bo Dai, Ilya Kostrikov, Yinlam Chow, Lihong Li, and Dale Schuuanslgadcoliy graien rmarbiraryxriecI:arXir arXiv: 1912.02074 (2019).   \n[NZJZW22] Chengzhuo Ni, Ruiqi Zhang, Xiang Ji, Xuezhou Zhang, and Mengdi Wang. \u201cOptimal Estimation of Policy Gradient via Double Fitted Iteration\". In: International Conference on Machine Learning. PMLR. 2022, pp. 16724-16783.   \n[SB18] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.   \n[SMSM99] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. \u201cPolicy gradient methods for reinforcement learning with function approximation\". In: Advances in neural information processing systems 12 (1999).   \n[UHJ20] Masatoshi UeharaJiawei Huang,and Nan Jiang.\u201cMinimax weight and q-futn learning for off-policy evaluation\". In: International Conference on Machine Learning. PMLR. 2020, pp. 9659-9668.   \n[UIJKSX21] Masatoshi Uehara, Masaaki Imaizumi, Nan Jiang, Nathan Kallus, Wen Sun, and Tengyang Xie. \u201cFinite sample analysis of minimax offine reinforcement learning: Completeness, fast rates and first-order efficiency\"'. In: arXiv preprint arXiv:2102.02981 (2021).   \n[XCJMA21] Tengyang Xie, Ching-An Cheng, Nan Jiang, Paul Mineiro, and Alekh Agarwal. \"Bellman-consistent pessimism for offine reinforcement learning In: Advances in neural information processing systems 34 (2021).   \n[XFBJK22] Tengyang Xie, Dylan J Foster, Yu Bai, Nan Jiang, and Sham M Kakade.\"The role of coverage in online reinforcement learning\". In: arXiv preprint arXiv:2210.04157 (2022).   \n[XJ21] Tengyang Xie and Nan Jiang. \u201cBatch value-function approximation with only realizability\"\\*. In: International Conference on Machine Learning. 2021.   \n[XYWL21] Tengyu Xu, Zhuoran Yang, Zhaoran Wang, and Yingbin Liang. \u201cDoubly robust off-policy actor-critic: Convergence and optimality\". In: International Conference on Machine Learning. PMLR. 2021, p. 11581-11591.   \n[ZBWK20] Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, and Alec Koppel. \"Cautious reinforcement learning via distributional risk in the dual domain\". In: arXiv preprint arXiv:2002.12475 (2020).   \n[ZHHJL22] Wenhao Zhan, Baihe Huang, Audrey Huang, Nan Jiang, and Jason Lee. \u201c\"Offline reinforcement learning with realizability and single-policy concentrability\"'. In: Conference on Learning Theory. PMLR. 2022, pp. 2730-2775.   \n[ZLKB20] Andrea Zanette, Alessandro Lazaric, Mykel J Kochenderfer, and Emma Brunskill. \"Provably efficient reward-agnostic navigation with linear value iteration\". In: Advances in Neural Information Processing Systems. 2020. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "ARelated work ", "page_idx": 13}, {"type": "text", "text": "B  Additional results and proofs for Sec. 3 15 ", "page_idx": 13}, {"type": "text", "text": "B.1Proofs for Sec. 3.1 15   \nB.2 Proofs for Sec. 3.2 : Estimation and local convergence 16   \nB.3 Proofs for Sec. 3.2: Global convergence 17   \nB.4 Examples of gradient function class $\\mathcal{G}$ 19   \nB.5  Policy optimization of general functionals 20 ", "page_idx": 13}, {"type": "text", "text": "C  Additional results and proofs for Sec. 4 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "C.1 Proofs for Sec. 4.1 21   \nC.2 Proofs for Sec. 4.2 22   \nC.3 Proofs for Sec. 4.3 25   \nC.4 Local convergence of OFF-OcCUPG 30   \nC.5 Global convergence of OFF-OcCUPG 32   \nC.6 Proofs for App. C.5 33 ", "page_idx": 13}, {"type": "text", "text": "D Maximum Likelihood Estimation ", "page_idx": 13}, {"type": "text", "text": "38 ", "page_idx": 13}, {"type": "text", "text": "E  Offline Density Estimation 39 ", "page_idx": 13}, {"type": "text", "text": "FProbabilistic Tools ", "page_idx": 13}, {"type": "text", "text": "G Optimization Tools ", "page_idx": 13}, {"type": "text", "text": "A Related work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we discuss related works in greater detail that concern the convergence and estimation of policy gradient in RL. ", "page_idx": 13}, {"type": "text", "text": "While a handful of recent papers have similarly observed that the gradient of the log density can be utilized to compute the policy gradient, especially in the context of using it to optimize general functionals, none of them have analyzed methods that are sample-efficient under general function approximation. In particular, [KJDC24] requires on-policy sampling from the time-reversed transition $\\bar{(\\boldsymbol{s},a|\\boldsymbol{s}^{\\prime})}$ , which, as they note, is highly restrictive. To overcome this issue they propose a min-max algorithm that converges under linear approximation, which is computationally a far more difficult to solve (under a more stringent structural assumption) than the regression objective in Alg. 1. Similarly, [BFH23] consider only online policy gradient, and to handle large state spaces they use linear function approximation, which may incur a large error through bias in many settings. [ZB WK20] approach the problem of optimizing risk functionals through a primal-dual approach that involves occupancies as dual variables, but they only analyze convergence in tabular settings. ", "page_idx": 13}, {"type": "text", "text": "A number of works on off-policy gradient optimization utilize all three of the density ratio, value, and policy class functions to compute the gradient [NDKCLS19; HJ22b; UIJKSX21; XYWL21]. This is because the density ratios are required to handle distribution mismatches with offline data. The downside, however, is that even max-min optimization is difficult, so performing optimization over all three functions requires complex optimization loops. By using simply projected gradient ascent on a policy class, our algorithms avoid such complexities and are amenable to classical convergence analysis that allow us to focus on the role of coverage coefficients in our final results. ", "page_idx": 13}, {"type": "text", "text": "Because the density ratio is generally not well-defined with arbitrary ofline data, all of these works require some form of all-policy coverage for both estimation and convergence guarantees. The weight gradient calculation in [UIJKSX21] exhibits a recursive decomposition that is related to ours. However, their formulation is not compatible with our data assumptions and they require policy coverage to be well-defined. A follow-up paper in [XYWL21] uses squared-loss regression on the same updates, which is similar in flavor to our gradient estimation objectives. However, they use linear function approximation for weight functions, which is not realizable in general, and also require all-policy coverage for their convergence results. ", "page_idx": 14}, {"type": "text", "text": "One close work of comparison is [LSAB19], whose PG algorithm uses learned density ratios to reweight the data distribution and approximate the expression of the policy gradient theorem [SMSM99]. To handle coverage issues in offline PG, they \u201czero out\"\u201d portions of the trajectory that exceed data coverage, but only do this for $(s,a)$ such that $\\begin{array}{r}{d^{D}(s)\\pi^{D}(\\dot{a}|s)=0}\\end{array}$ . This is done (in the infinite horizon setting) by resampling the dataset based on an augmented MDP where such $(s,a)$ transition to an absorbing state However, this does not control the (potentially extremely large) variance of the estimator, e.g., on states where $d^{D}(s)\\approx0$ Their objective can be seen as a special case of $\\bar{J}(\\pi)$ with finite but extremely large choices of $C^{\\mathbf{s}}$ and $C^{\\mathbf{a}}$ . They show convergence to a stationary point in terms of weight and value estimation errors that are left implicit, and leave the high variance and coverage issues with offine data implicit. ", "page_idx": 14}, {"type": "text", "text": "Another is [DwS12], that takes the complementary approach and simply calculates the gradient averaged on $d^{D}$ . However, this is a biased gradient object and does not express the policy gradient of any specific function, which means its stationary point may not even exist, thus precluding convergence analysis. ", "page_idx": 14}, {"type": "text", "text": "The PSPI algorithm in [XCJMA21] is a policy optimization algorithm based on pessimistic value functions. Their setting is somewhat orthogonal to ours in the sense that they study values and we study occupancies, and we note that they do not perform policy optimization with respect to a standalone policy class but rather an implicit one induced by the value functions, which an be extremely large. In the value function sphere, [NZJZW22] leverage the linear structure of linearMDPS to develop closed-form gradient estimators through the value functions. They largely only analyze estimation errors and additionally require a form of all-policy coverage for their results. ", "page_idx": 14}, {"type": "text", "text": "Lastly, our optimality analysis builds off the results in [BR24] and [AKLM21] that analyze global optimality in the (infinite horizon) online setting. ", "page_idx": 14}, {"type": "text", "text": "B Additional results and proofs for Sec. 3 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Proofs for Sec. 3.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof of Lem. 3.1 First we expand $\\nabla d_{h}^{\\pi}$ using the Bellman flow equation, $\\begin{array}{r l}{d_{h}^{\\pi}(s^{\\prime})}&{{}=}\\end{array}$ $\\begin{array}{r}{\\sum_{s,a}P(s^{\\prime}|s,a)\\pi(a|s)d_{h-1}^{\\pi}(s)}\\end{array}$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla d_{h}^{\\pi}(s^{\\prime})=\\sum_{s,a}P(s^{\\prime}|s,a)(\\nabla\\pi(a|s)d_{h-1}^{\\pi}(s)+\\pi(a|s)\\nabla d_{h-1}^{\\pi}(s))}\\\\ &{\\qquad\\qquad=\\sum_{s,a}P(s^{\\prime}|s,a)\\pi(a|s)d_{h-1}^{\\pi}(s)(\\nabla\\log\\pi(a|s)+\\nabla\\log d_{h-1}^{\\pi}(s)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In the last line above we use the grad-log trick. Note that $\\nabla\\log d^{\\pi}(s)$ is not well-defined when $d^{\\pi}(s)\\,=\\,0$ but the two terms will cancel out in the above expression for this case. From Bayes? theorem, $\\mathbb{P}^{\\pi}(s_{h-1}=s,a_{h-1}=a|s_{h}=s^{\\prime})=P(s^{\\prime}|s,a)\\pi(a|s)\\overline{{d_{h-1}^{\\pi}(s)}}/d_{h}^{\\pi}(s^{\\prime})$ thus ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\log d_{h}^{\\pi}(s^{\\prime})=\\nabla d_{h}^{\\pi}(s^{\\prime})/d_{h}^{\\pi}(s^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}^{\\pi}[\\nabla\\log\\pi(a|s)+\\nabla\\log d_{h-1}^{\\pi}(s)|s_{h}=s^{\\prime}]}\\\\ &{\\qquad\\qquad\\qquad=[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\nabla\\log d_{h-1}^{\\pi})](s^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We use the convention that $0/0=0$ , thus $\\nabla\\log d_{h}^{\\pi}$ is always well-defined. ", "page_idx": 14}, {"type": "text", "text": "Lastly, the second statement results from Lem. B.1, which shows that $\\|\\nabla\\log d_{h}^{\\pi}(s^{\\prime})\\|$ is always bounded and well-defined under Asm. 2.1. ", "page_idx": 14}, {"type": "text", "text": "Lemma B.1. Under Asm. 2.1, we have $\\begin{array}{r}{\\operatorname*{max}_{s,h}\\|\\nabla\\log d_{h}^{\\pi}(s)\\|\\leq h G.}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "Proof. The lemma statement can be derived inductively starting from the observation that Eq. (1) is an expectation over its target functions. As a result, the maximum gradient magnitude should accrue ", "page_idx": 14}, {"type": "text", "text": "additively over horizons. More concretely, fix $h$ and $s$ .Then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s^{\\prime})\\|=\\|\\mathbb{E}^{\\pi}[\\nabla\\log\\pi(a|s)+\\nabla\\log d_{h-1}^{\\pi}(s)|s_{h}=s^{\\prime}]\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\|\\nabla\\log\\pi(a|s)\\|+\\|\\nabla\\log d_{h-1}^{\\pi}(s)\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq G+\\|\\nabla\\log d_{h-1}^{\\pi}(s)\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "using Asm. 2.1 in the last line. Since $\\nabla\\log d_{0}^{\\pi}\\,=\\,{\\bf0}$ by definition, unrolling the above recursion through timesteps gives the stated result. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Lemma B.2. For $g:S\\to\\mathbb{R}^{\\mathsf{p}}$ and $f:S\\times A\\to\\mathbb{R}^{\\mathsf{p}}$ define the squared loss ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{h}(g;f,\\pi)=\\mathbb{E}_{\\pi}[\\|g(s_{h+1})-f(s_{h},a_{h})\\|^{2}].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then for any such $f$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{E}_{h}^{\\pi}(f)=\\operatorname*{argmin}_{g:{\\mathcal{S}}\\to\\mathbb{R}^{\\mathsf{p}}}L_{h}(g;f,\\pi)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla\\log d_{h+1}^{\\pi}=\\operatorname*{argmin}_{g:S\\rightarrow\\mathbb{R}^{\\ p}}L_{h}\\left(g;\\nabla\\log\\pi+\\nabla\\log d_{h}^{\\pi},\\pi\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof of Lem. B.2. Since the objective is convex, can solve for the minimizer in closed form by taking the derivative and setting it to O in an element-wise manner. Fix $s^{\\prime}$ . Taking the gradient of $L_{h}(g;f,\\pi)$ withrespectto $g(s^{\\bar{\\prime}})$ ,wehavethat ", "page_idx": 15}, {"type": "equation", "text": "$$\n0=d_{h}^{\\pi}(s^{\\prime})g(s^{\\prime})-\\sum_{s,a}P(s^{\\prime}|s,a)\\pi(a|s)d_{h-1}^{\\pi}(s)f(s,a).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Rearranging and using the definition of ${\\bf E}_{h}^{\\pi}$ gives the result. The second statement follows from Lem. 3.1. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "B.2  Proofs for Sec. 3.2 : Estimation and local convergence ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of Thm. 3.1  First we split up the errors contributed by regression and the estimation. Fix $\\pi$ then $\\begin{array}{r}{\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat{\\nabla}J(\\pi)]=\\sum_{h}\\mathbb{E}_{s\\sim d_{h}^{\\pi}}[\\widehat{g}_{h}^{\\pi}(s)R_{h}(s)]}\\end{array}$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla J(\\pi)-\\widehat\\nabla J(\\pi)\\|\\leq\\|\\nabla J(\\pi)-\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat\\nabla J(\\pi)]\\|+\\|\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat\\nabla J(\\pi)]-\\widehat\\nabla J(\\pi)\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The first term is related to the regression error in $\\widehat{g}_{h}^{\\pi}$ approximating $\\nabla\\log d_{h}^{\\pi}$ \uff0c ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla J(\\pi)-\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat{\\nabla}J(\\pi)]\\|=\\left\\|\\sum_{h}\\mathbb{E}_{d_{h}^{\\pi}}[\\nabla\\log d_{h}^{\\pi}(s)R_{h}(s)]-\\mathbb{E}_{d_{h}^{\\pi}}[\\widehat{g}_{h}^{\\pi}(s)R_{h}(s)]\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\sum_{h}\\left\\|\\mathbb{E}_{d_{h}^{\\pi}}[\\nabla\\log d_{h}^{\\pi}(s)-\\widehat{g}_{h}^{\\pi}(s)]\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\sum_{h}\\sqrt{\\sum_{p=1}^{\\mathsf{p}}\\|\\nabla^{p}\\log d_{h}^{\\pi}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{1,d_{h}^{\\pi}}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For a fixed $h$ and $p$ , we recursively decompose ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla^{p}\\log d_{h}^{\\pi}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{1,d_{h}^{\\pi}}\\leq\\|\\nabla^{p}\\log d_{h}^{\\pi}-[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi})]^{p}\\|_{1,d_{h}^{\\pi}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\|[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi})]^{p}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{1,d_{h}^{\\pi}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\|\\nabla^{p}\\log d_{h-1}^{\\pi}-[\\widehat{g}_{h-1}^{\\pi}]^{p}\\|_{1,d_{h-1}^{\\pi}}+\\|[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi})]^{p}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{2,d_{h-1}^{\\pi}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "using the fact that $\\nabla\\log d_{h}^{\\pi}={\\bf E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\nabla\\log d_{h-1}^{\\pi})$ in the second line. Then unrolling the recursion, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\nabla^{p}\\log d_{h}^{\\pi}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{1,d_{h}^{\\pi}}\\leq\\sum_{h}\\|[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi})]^{p}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{2,d_{h}^{\\pi}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Applying Lem. F.2 (more exactly, this is an offline version but we invoke it with $\\rho\\,=\\,1$ and no clipping for the online setting) with $\\delta^{\\prime}=\\delta/2H{\\mathfrak{p}}$ and a union bound over all $h$ and $p$ wehave ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi})]^{p}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{2,d_{h}^{\\pi}}^{2}=\\mathbb{E}[\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}^{p}(\\widehat{g}_{h}^{\\pi},\\widehat{g}_{h-1}^{\\pi})-\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}^{p}(\\mathbf{E}_{h-1}^{\\pi}(\\nabla\\log\\pi+\\widehat{g}_{h-1}^{\\pi}),\\widehat{g}_{h}^{\\pi})]^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\leq2(\\varepsilon_{h-1}^{\\mathrm{reg}})^{2},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where Eh-1 $\\begin{array}{r}{\\varepsilon_{h-1}^{\\mathrm{reg}}=\\sqrt{\\frac{c\\mathsf{d}_{\\mathcal{G}}h^{2}G^{2}\\log\\left(2H\\mathsf{p}/\\delta\\right)}{n}}}\\end{array}$ cdgh2G2 log(2Hp/) Then for any h, p we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\nabla^{p}\\log d_{h}^{\\pi}-[\\widehat{g}_{h}^{\\pi}]^{p}\\|_{1,d_{h}^{\\pi}}\\leq\\sqrt{2}\\sum_{g\\leq h}\\varepsilon_{g}^{\\mathrm{reg}}\\leq\\sqrt{2}h\\varepsilon_{h}^{\\mathrm{reg}}=\\sqrt{\\frac{2c\\mathsf{d}_{\\mathcal{G}}h^{4}G^{2}\\log(2H\\mathsf{p}/\\delta)}{n}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Implying ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\nabla J(\\pi)-\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat{\\nabla}J(\\pi)]\\|\\leq\\sqrt{\\mathsf{p}}H\\|\\nabla^{p}\\log d_{H}^{\\pi}-[\\widehat{g}_{H}^{\\pi}]^{p}\\|_{1,d_{H}^{\\pi}}=\\sqrt{\\frac{2c\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H\\mathsf{p}/\\delta)}{n}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For the second term, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat{\\nabla}^{p}J(\\pi)]-\\widehat{\\nabla}^{p}J(\\pi)|\\leq\\sum_{h}\\big|\\mathbb{E}_{s\\sim d_{h}^{\\pi}}[\\widehat{g}_{h}^{\\pi}(s)R_{h}(s)]-\\frac{1}{n}\\sum_{s\\in\\mathcal{D}_{h}}\\widehat{g}_{h}^{\\pi}(s)R_{h}(s)\\big|\\leq H^{2}G\\sqrt{\\frac{\\log(2\\mathrm{p}H/s)}{n}}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we use Hoeffding's inequality with union bound, for all $h\\in[H]$ and $p\\in{\\mathfrak{p}}$ in the last line, given that the randomness of $\\widehat g$ is independent given $\\mathcal{D}_{h}^{\\mathrm{reg}}$ Thus ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\mathbb{E}_{\\mathcal{D}^{\\mathrm{reg}}}[\\widehat{\\nabla}J(\\pi)]-\\widehat{\\nabla}J(\\pi)\\|\\le H^{2}G\\sqrt{\\frac{\\mathfrak{p}\\log(2\\mathfrak{p}H/\\delta)}{n}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Combining the two terms, our final bound is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\nabla J(\\pi)-\\widehat\\nabla J(\\pi)\\|\\lesssim\\sqrt{\\frac{{\\sf p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H{\\sf p}/\\delta)}{n}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with the regression error dominating. ", "page_idx": 16}, {"type": "text", "text": "Proof of Cor. 3.1 For any fixed run of Alg. 1, calling Thm. 3.1 for $\\pi^{(t)}$ with $\\delta^{\\prime}=\\delta/T$ and taking a union bound over $T$ gives with probability at least $1-\\delta$ that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\nabla J(\\pi^{(t)})-\\widehat\\nabla J(\\pi^{(t)})\\|\\lesssim\\sqrt{\\frac{\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H\\mathsf{p}T/\\delta)}{n}},\\,\\forall t\\in[T].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then setting $\\delta=1/\\sqrt{n}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\|\\nabla J(\\pi^{(t)})-\\widehat{\\nabla}J(\\pi^{(t)})\\|\\right]\\lesssim\\sqrt{\\frac{\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log\\left(2H\\mathsf{p}T n\\right)}{n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the expectation is over random samples in $\\mathcal{D}^{\\mathrm{reg}},\\mathcal{D}^{\\mathrm{est}}$ . Finally, plugging this into the PGD stationary convergence bound in Lem. G.1 gives ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t}\\mathbb{E}\\left[\\|G^{\\eta}(\\pi^{(t)},\\nabla J(\\pi^{(t)}))\\|^{2}\\right]\\leq\\frac{4\\beta H}{T}+\\frac{6\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H\\mathsf{p}T n)}{n}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Setting the RHS to $\\varepsilon$ and setting $T,n$ appropriately gives the result. ", "page_idx": 16}, {"type": "text", "text": "B.3  Proofs for Sec. 3.2: Global convergence ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We will establish the conditions under which $J(\\pi)$ satisfies a gradient domination property, meaning that for any $\\theta\\in\\Theta$ , the suboptimality of $\\pi_{\\theta}$ is bounded by some function $S$ that includes a measure of its stationarity, i.e.,. $\\begin{array}{r}{\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\Theta}}\\widetilde{J}(\\pi^{\\prime})-J(\\pi_{\\theta})\\,\\le\\,S(\\dot{\\nabla}\\widetilde{J}(\\pi_{\\theta}))}\\end{array}$ . This combined with the sample complexity bounds for stationary convergence established in Cor. 3.1 enables our global optimality result in Cor. 3.2. ", "page_idx": 16}, {"type": "text", "text": "Though we are concerned with optimizing $J(\\pi)$ induced by running $\\pi$ starting from initial distribution $d_{0}$ , it will be useful to consider performing Alg. 1 using a different exploratory initial distribution $\\mu\\in\\Delta(S)$ . By exploratory, we mean that we allow $\\mu(s)>0$ for all $s\\in S$ , unlike $d_{0}\\in\\Delta(S^{0})$ In the (stationary) infinite horizon this is a common trick for obtaining well-defined gradient domination bounds [AKLM21], but its finite-horizon (nonstationary) counterpart is nontrivial and to our knowledge has not previously been formalized (it is listed as future work in [BR24]). ", "page_idx": 16}, {"type": "text", "text": "We state and prove a more general version of Lem. 3.2: ", "page_idx": 16}, {"type": "text", "text": "Lemma B.3. For any $\\pi$ and $\\pi^{\\prime}$ , define $\\begin{array}{r}{B^{\\pi}(\\pi^{\\prime}):=\\sum_{h,s,a}d_{h}^{\\pi}(s)\\pi^{\\prime}(a|s)Q_{h}^{\\pi}(s,a).}\\end{array}$ Suppose $\\forall\\pi\\in\\Pi_{\\Theta}$ \uff0c ", "page_idx": 17}, {"type": "text", "text": "1. (Policy completeness) There exists $\\pi^{+}\\in\\Pi_{\\Theta}$ suchthat $\\pi^{+}\\in\\mathrm{argmax}_{\\pi^{\\prime}}\\,B^{\\pi}(\\pi^{\\prime}).$   \n2. (Gradient domination) $\\begin{array}{r}{\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\Theta}}B^{\\pi}(\\pi^{\\prime})-B^{\\pi}(\\pi)\\leq m\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\left\\langle\\nabla B^{\\pi}(\\pi),\\theta^{\\prime}-\\theta\\right\\rangle}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "Given $\\nu\\in\\Delta(S)$ define the coverage coefficient $\\begin{array}{r}{\\mathcal{C}^{\\pi^{*}}:=\\left\\|\\sum_{h}d_{h}^{\\pi^{*}}/\\nu\\right\\|_{\\infty}}\\end{array}$ for $\\pi^{*}=\\operatorname{argmax}_{\\pi}J(\\pi).$ Then for any $\\pi_{\\theta}\\in\\Pi_{\\Theta}$ \uff0c ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{J(\\pi^{*})-J(\\pi_{\\theta})\\leq m\\left\\|\\displaystyle\\sum_{h}\\sum_{d_{\\mu,h}^{\\pi_{\\theta}^{*}}}\\left\\|\\operatorname*{max}_{\\omega^{\\prime}\\in\\Pi_{\\Theta}}\\left\\langle\\nabla J_{\\mu}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\right\\rangle\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.\\leq\\boldsymbol{\\mathcal{C}^{\\pi^{*}}}\\displaystyle\\operatorname*{max}_{\\theta^{\\prime}\\in\\Pi_{\\Theta}}\\left\\langle\\nabla J_{\\nu}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\right\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $J_{\\nu}(\\pi):=\\mathbb{E}_{s_{0}\\sim\\nu,\\pi}[\\sum_{h}r_{h}]$ is the expected return of $\\pi$ in $\\mathcal{M}$ with initial state distribution $\\nu$ ", "page_idx": 17}, {"type": "text", "text": "Proof of Lem. B.3 First we note two facts that hold regardless of $\\mathcal{M}$ Wehave $Q_{g}^{\\pi}(s^{h},a^{h})\\,=$ $Q_{h}^{\\pi}(s^{h},a^{h})$ for any $g\\leq h$ and $d_{g}^{\\pi}(s^{h})=0$ $g>h$ ", "page_idx": 17}, {"type": "equation", "text": "$$\nJ(\\pi^{*})-J(\\pi_{\\theta})=\\sum_{h=0}^{H-1}\\sum_{s,a}d_{h}^{\\pi^{*}}(s)\\left(\\pi^{*}(a|s)-\\pi_{\\theta}(a|s)\\right)Q_{h}^{\\pi_{\\theta}}(s,a)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then we will write $Q^{\\pi}(s,a)\\equiv Q_{h}^{\\pi}(s,a)$ , thus ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{J(\\pi^{*})-J(\\pi_{\\theta})=}&{\\displaystyle\\sum_{h=0}^{H-1}d_{h}^{\\pi^{*}}(s)\\left(\\pi^{*}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}\\\\ &{=\\displaystyle\\sum_{s=\\pi}\\left(\\sum_{h}d_{h}^{\\pi^{*}}(s)\\right)\\left(\\pi^{*}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}\\\\ &{\\le\\displaystyle\\operatorname*{max}_{\\pi^{*}+\\frac{\\pi}{s}}\\left(\\sum_{h}d_{h}^{\\pi^{*}}(s)\\right)\\left(\\pi^{*}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}\\\\ &{\\le\\displaystyle\\operatorname*{max}_{\\pi^{*}+\\frac{\\pi}{s}}\\sum_{h,a}d_{h}^{\\pi^{*}}(s)\\left(\\sum_{h}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\right)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}\\\\ &{\\le\\displaystyle\\prod_{\\pi^{*}}\\sum_{\\mu=\\pi}^{H}\\left\\{\\operatorname*{max}_{h}\\sum_{h}d_{\\mu,h}^{\\pi^{*}}(s)\\left(\\sum_{h}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\right)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)\\right.}\\\\ &{\\le\\left.\\left\\lVert\\sum_{\\mu}d_{h}^{\\pi^{*}}\\right\\rVert_{\\infty}^{\\pi}\\displaystyle\\operatorname*{max}_{\\pi^{*}+\\frac{\\pi}{s}}\\left(\\sum_{h}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\right)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For the RHS, observe that $d_{\\mu,g}^{\\pi_{\\theta}}(s^{h})=0$ for $g>h$ . Then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{h\\ s,a}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q^{\\pi_{\\theta}}(s,a)}}\\\\ &{}&{=\\sum_{h\\ s,a}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q_{h}^{\\pi_{\\theta}}(s,a)}\\\\ &{}&{=\\sum_{h\\ s,a}d_{\\mu,h}^{\\pi_{\\theta}}(s)\\left(\\pi^{+}(a|s)-\\pi_{\\theta}(a|s)\\right)Q_{\\mu,h}^{\\pi_{\\theta}}(s,a)}\\\\ &{}&{=B^{\\pi_{\\theta}}(\\pi^{+})-B^{\\pi_{\\theta}}(\\pi_{\\theta})}\\\\ &{}&{\\le m\\operatorname*{max}\\left\\langle\\nabla B^{\\pi_{\\theta}}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\right\\rangle}\\\\ &{}&{=m\\operatorname*{max}_{\\phi\\in\\Theta}\\left\\langle\\nabla J_{\\mu}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\right\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combining the two inequalities results in the final guarantee. ", "page_idx": 17}, {"type": "text", "text": "Proof of Cor. 3.2  Fix $\\{\\pi^{(t)}\\}_{t\\in[T]}$ from Alg. 1. Then for any $t\\in[T]$ , from Lem. 3.2 we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nJ(\\pi^{*})-J(\\pi^{(t)})\\le m\\mathcal{C}^{\\pi^{*}}\\operatorname*{max}_{\\theta^{\\prime}\\in\\Pi_{\\Theta}}\\left\\langle\\nabla J(\\pi^{(t)}),\\theta^{\\prime}-\\theta\\right\\rangle\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\leq B m{\\mathcal{C}}^{\\pi^{*}}\\|G^{\\eta}({\\boldsymbol{\\pi}}^{(t)})\\|\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then summing through $T$ and taking an expectation over the randomness in the algorithm, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\frac{1}{T}\\sum_{t}J(\\pi^{*})-J(\\pi^{(t)})\\right]\\leq B m\\mathcal{C}^{\\pi^{*}}\\mathbb{E}\\left[\\displaystyle\\frac{1}{T}\\sum_{t}\\|G^{\\eta}(\\pi^{(t)})\\|\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq B m\\mathcal{C}^{\\pi^{*}}\\left(\\frac{4\\beta H}{T}+\\frac{6\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H\\mathsf{p}T n)}{n}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "B.4 Examples of gradient function class $\\mathcal{G}$ ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "This section contains formal statements of the claims in Rem. 3.1, and their proofs. We begin by defining the low-rank MDP, noting that for notational compactness we have dropped the features' $h$ -dependence given our assumption that there is a one-to-one correspondence between states and the timestep at which they are visited. ", "page_idx": 18}, {"type": "text", "text": "Definition B.1 (Low-rank MDP). We say $\\mathcal{M}$ is a low-rank MDP with dimension $k$ if $\\forall h\\in[H]$ there exists $\\phi\\,:\\,S\\,\\times\\,A\\,\\to\\,\\mathbb{R}^{k}$ and $\\mu_{h}\\ :\\ S\\ \\to\\ \\mathbb{R}^{k}$ such that $(s,a,s^{\\prime})$ , we have $P(s^{\\prime}|s,a)\\;=\\;$ $\\langle\\phi(\\boldsymbol{x},a),\\mu(\\boldsymbol{x}^{\\prime})\\rangle$ . Further, $\\|\\phi\\|_{\\infty}\\leq C^{\\phi}$ and $\\textstyle\\sum_{s}\\mu(s)\\leq C^{\\mu}$ ", "page_idx": 18}, {"type": "text", "text": "Prop. B.1 shows that, in low-rank MDPs, a linear-over-linear parameterization for the gradient function class satisfies the completeness requirement in Asm. 3.1, with pseudo-dimension linear in the low-rank dimension and the parameter dimension, i.e., $\\mathsf{d}_{\\mathcal{G}_{h}}=O(k\\mathsf{p})$ ", "page_idx": 18}, {"type": "text", "text": "Proposition B.1. Suppose $\\mathcal{M}$ is a low-rank MDP (Def. B.1), and suppose $\\mu$ is known. For each layer $h$ define thefunctionclass ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{G}_{h}=\\left\\{g_{h}=\\frac{\\mu^{\\top}\\Psi}{\\mu^{\\top}\\psi}:\\Psi\\in\\mathbb{R}^{k\\times\\mathtt{p}},\\psi\\in\\mathbb{R}^{k},\\|g_{h}\\|_{\\infty}\\leq h G,\\,\\forall h\\in[H]\\right\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then $\\{\\mathcal{G}_{h}\\}$ satisfies Asm. 3.1 and has pseudodimension $(D e f.\\,F.I)\\;{\\mathsf{d}}_{\\mathcal{G}_{h}}=O(k{\\mathsf{p}})$ ", "page_idx": 18}, {"type": "text", "text": "Proof of Prop. B.1. It suffices to show that, for any function $f:\\mathcal{S}\\times\\mathcal{A}\\to\\mathbb{R}^{\\mathsf{p}}$ and policy $\\pi$ ,its gradient update from Lem. 3.1 is $\\mathbf{E}_{h}^{\\pi}(\\nabla\\log\\pi+f)\\,\\in\\mathcal{G}_{h+1}$ ", "page_idx": 18}, {"type": "text", "text": "Since $[\\mathbf{E}_{h}^{\\pi}(\\nabla\\log\\pi+f)](s^{\\prime})=\\mathbb{E}_{\\pi}[\\nabla\\log\\pi(s,a)+f(s)|s^{\\prime}].$ from Bayes\u2032 rule and the definition of the Bellman flow operator (see proof of Lem. 3.1), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n[\\mathbf{E}_{h}^{\\pi}(\\nabla\\log\\pi+f)](s^{\\prime})=\\frac{[\\mathbf{P}_{h-1}^{\\pi}(\\nabla\\log\\pi+f)](s^{\\prime})}{d_{h}^{\\pi}(s^{\\prime})}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "First, we will show that $[\\mathbf{P}_{h}^{\\pi}f](s^{\\prime})=\\mu(s^{\\prime})^{\\top}\\Psi$ for some $\\Psi\\in\\mathbb{R}^{k\\times\\mathsf{p}}$ and all $s^{\\prime}\\in\\mathcal{S}$ . Below, we use $f^{p}(s)$ to denote the $p$ -th parameter of $f(s)\\in\\mathbb{R}^{\\mathsf{p}}$ . For fixed $p\\in[{\\mathsf{p}}]$ \uff0c ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{[\\mathbf{P}_{h}^{\\pi}f]^{p}(s^{\\prime})=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\pi(a|s)\\left(\\nabla^{p}\\log\\pi(a|s)+f^{p}(s)\\right)}\\\\ &{\\qquad\\qquad=\\mu(s^{\\prime})^{\\top}\\left(\\displaystyle\\sum_{s,a}\\phi(s,a)\\pi(a|s)\\left(\\nabla^{p}\\log\\pi(a|s)+f^{p}(s)\\right)\\right)}\\\\ &{\\qquad\\qquad=\\mu(s^{\\prime})^{\\top}\\psi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{\\psi\\,=\\,\\sum_{s,a}\\phi(s,a)\\pi(a|s)\\,(\\nabla\\log\\pi(a|s)+f^{p}(s))\\,\\in\\,\\mathbb{R}^{k}}\\end{array}$ Stacking this result for each $p$ into the matrix $\\Psi$ shows the desired statement that $[\\mathbf{P}_{h}^{\\pi}f](s^{\\prime})=\\mu(s^{\\prime})^{\\top}\\Psi$ ", "page_idx": 18}, {"type": "text", "text": "We can apply similar reasoning as above in the Bellman flow equation to show that $d_{h}^{\\pi}(s^{\\prime})\\;=\\;$ $\\langle\\mu(s^{\\prime}),\\psi\\rangle$ forsome $\\boldsymbol\\theta\\in\\mathbb{R}^{k}$ . Combined with the above, this shows that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla\\log d_{h}^{\\pi}(s^{\\prime})=\\frac{\\mu^{\\top}\\Psi}{\\mu^{\\top}\\psi},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Combining the linear forms of the numerator and denominator reveal that $\\nabla\\log d_{h}^{\\pi}\\,\\in\\,\\mathcal{G}_{h}$ .Lastly, the pseudo-dimension of $\\mathcal{G}_{h}$ follows directly from applying Lemma 24 of [HCJ23], which bounds the pseudo-dimension of linear-over-linear function classes with ${\\mathsf p}=1$ , in all $\\mathsf{p}$ dimensions. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Algorithm 3 Online Occupancy-based PG for General Functionals ", "page_idx": 19}, {"type": "text", "text": "Input: Functional $F=\\{F_{h}\\}$ ; Samples $n$ ; iterations $T$ ; policy class $\\Pi_{\\Theta}$ ; function class $\\mathcal{G}$ ; learning rate $\\eta$ ; function class $\\mathcal{F}$ .\uff0c   \n1: for $t=0,\\dots,T-1$ do   \n2:For all $h\\in[H]$ , deploy $\\pi^{(t)}$ for $3n$ trajectories. Set $\\mathcal{D}_{h}^{\\mathrm{reg}}=\\{(s_{h},a_{h},s_{h+1})\\}_{i=1}^{n}$ , and similarly for $\\mathcal{D}_{h}^{\\mathrm{grad}}$ and Dmle   \n3:for $h=1,\\ldots,H-1$ do   \n4: Defne $\\begin{array}{r l}{\\mathcal{L}_{h-1}^{(t)^{\\top}}(g_{h},g_{h-1})\\!\\!}&{:=\\ \\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\big\\|g_{h}(s^{\\prime})-\\big(\\nabla\\log\\pi^{(t)}(a|s)+g_{h-1}(s)\\big)\\big\\|^{2},}\\\\ &{\\widehat{g}_{h}^{(t)}=\\operatorname*{argmin}_{g_{h}\\in\\mathcal{G}_{h}}\\mathcal{L}_{h-1}^{(t)}(g_{h},\\widehat{g}_{h-1}^{(t)}).}\\end{array}$ and set   \n5: end for   \n6: Estimate $\\widehat{d_{h}^{\\pi}}\\gets\\mathbf{MLE}(\\mathcal{D}^{\\mathrm{mle}},\\mathcal{F})$ // Alg. 4   \n7: Estimat ", "page_idx": 19}, {"type": "equation", "text": "$\\begin{array}{r l}&{:\\widehat{\\nabla}J_{F}(\\pi)=\\frac{1}{n}\\sum_{h}\\sum_{s\\in{\\mathcal{D}}_{h}^{\\mathrm{est}}}\\widehat{g}_{h}^{\\pi}(s)\\left.\\frac{\\partial F_{h}(d)}{\\partial d(s)}\\right|_{d=\\widehat{d}_{h}^{\\pi}}}\\\\ &{\\:\\:\\widehat{\\nabla}^{(t+1)}=\\mathrm{Proj}_{\\Theta}\\left(\\theta^{(t)}+\\eta\\widehat{\\nabla}J(\\pi^{(t)})\\right).}\\end{array}$ ", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "3: Update ", "page_idx": 19}, {"type": "text", "text": "9: end for ", "page_idx": 19}, {"type": "text", "text": "B.5   Policy optimization of general functionals ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Alg. 3 displays the full algorithm for optimization of general functions (described in Sec. 3.3). It shares its occupancy gradient estimation module with OccuPG. Compared to Alg. 1, the only change is the objective gradient calculation in Line 7, which uses a plug-in estimate of the occupancy (Line 6) to evaluate the partial derivative. ", "page_idx": 19}, {"type": "text", "text": "Since the algorithmic change is small, the analysis for Alg. 3 requires only a few adaptations from the analysis of OccUPG. For smooth and differentiable functionals, we provide the gradient estimation guarantee below. The smoothness ensures that using plug-in occupancy estimates to evaluate the partial derivative leads to consistent gradient estimates, and is in line with the spirit of standard objective smoothness requirements (Asm. 3.2). ", "page_idx": 19}, {"type": "text", "text": "Assumption B.1. Suppose that for all $h$ $F_{h}$ has a smooth gradient, i.e., for any $f,f^{\\prime}\\in\\Delta(S)$ that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{s}\\bigg|\\frac{\\partial F_{h}(d)}{\\partial d(s)}\\bigg|_{d=f}-\\frac{\\partial F_{h}(d)}{\\partial d(s)}\\bigg|_{d=f^{\\prime}}\\bigg|\\le L_{F}\\|f-f^{\\prime}\\|_{1},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and has bounded range $\\|\\partial F_{h}(d)\\|_{\\infty}\\leq C_{F}$ ", "page_idx": 19}, {"type": "text", "text": "Theorem B.1. Suppose that Asm. 2.1 and Asm. B.1 hold. Fix $\\pi\\,\\in\\Pi_{\\Theta}$ .With probability at least $1-\\delta$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\|\\nabla J_{F}(\\pi)-\\widehat\\nabla J_{F}(\\pi)\\|\\lesssim H^{2}G L_{F}\\sqrt{\\frac{\\ p\\log(2\\mathsf{p}H|\\mathcal{F}|/\\delta)}{n}}+C_{F}\\sqrt{\\frac{\\mathsf{p d}_{\\mathcal{G}}H^{6}G^{2}\\log(2H\\mathsf{p}/\\delta)}{n}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "When Asm. 3.2 holds, this result directly leads to a stationary convergence guarantee similar to Cor. 3.1, by union bounding Thm. B.1 over all $T$ then plugging it into Lem. G.5 (see proof of Cor. 3.1). We expect that the global convergence in Cor. 3.2 can also be extended with little overhead When $\\{\\boldsymbol{F}_{h}\\}$ are convex, but leave a full investigation to future work. ", "page_idx": 19}, {"type": "text", "text": "Proof of Thm. B.1 The analysis follows largely the same lines as the proof of Thm. 3.1. However, we must additional account for the errorof approximating $\\left.\\frac{\\partial F_{h}(d)}{\\partial d(s)}\\right|_{d=\\widehat{d_{h}^{\\pi}}}$ with the plug-in occupancy estimate. This was unnecessary for the expected return in Sec. 3.2 since Fa(d = Rn(s) is independent of the occupancy. ", "page_idx": 19}, {"type": "text", "text": "First, for all $h\\in[H]$ , with probability at least $1-\\delta$ we have occupancy estimates from Alg. 4 such that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\|d_{h}^{\\pi}-\\widehat{d_{h}^{\\pi}}\\|_{1}\\leq\\sqrt{\\frac{2\\log(H|\\mathcal{F}|/\\delta)}{n}}:=\\varepsilon^{\\mathrm{mle}},\\;\\forall h\\in[H].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This follows directly from Lem. D.1 with a union bound over $H$ ", "page_idx": 20}, {"type": "text", "text": "Next, we isolate the occupancy estimation-related term from the error we would like to bound. De$\\begin{array}{r}{\\nabla\\widehat{J}_{F}(\\pi):=\\sum_{h}\\mathbb{E}_{s\\sim d_{h}^{\\pi}}\\left[\\frac{\\dot{\\partial}F_{h}(d)}{\\partial d(s)}\\vert_{d=\\widehat{d}_{h}^{\\pi}}\\nabla\\log d_{h}^{\\pi}(s)\\right]}\\end{array}$ a@ la=agV log d(s)] ,and decompose ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\nabla J_{F}(\\pi)-\\widehat\\nabla J_{F}(\\pi)\\|\\leq\\|\\nabla J_{F}(\\pi)-\\nabla\\widehat{J}_{F}(\\pi)\\|+\\|\\nabla\\widehat{J}_{F}(\\pi)-\\widehat{\\nabla}J_{F}(\\pi)\\|\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For the first term, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|\\nabla J_{F}(\\pi)-\\nabla\\widehat{J}_{F}(\\pi)\\|\\leq\\displaystyle\\sum_{h}\\left\\|\\mathbb{E}_{s\\sim d_{h}^{\\pi}}\\left[\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{a=d_{h}^{\\pi}}\\nabla\\log d_{h}^{\\pi}(s)-\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{d=\\widehat{d}_{h}^{\\pi}}\\nabla\\log d_{h}^{\\pi}(s)\\right]\\right\\|}\\\\ &{\\leq H G\\displaystyle\\sum_{h}\\left\\|\\mathbb{E}_{s\\sim d_{h}^{\\pi}}\\left[\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{a=d_{h}^{\\pi}}-\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{a=\\widehat{d}_{h}^{\\pi}}\\right]\\right\\|}\\\\ &{\\leq H G\\displaystyle\\sum_{h,s}\\left|\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{a=d_{h}^{\\pi}}-\\frac{\\partial F_{h}(d)}{\\partial d(s)}|_{d=\\widehat{d}_{h}^{\\pi}}\\right|}\\\\ &{\\leq H^{2}G L_{F}\\operatorname*{max}_{h}\\|d_{h}^{\\pi}-\\widehat{d_{h}^{\\pi}}\\|_{1},}\\\\ &{\\leq H^{2}G L_{F}\\varepsilon^{\\mathrm{mis}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "using Asm. B.1 in the second to last inequality. This takes care of the aforementioned occupancy estimationerror. ", "page_idx": 20}, {"type": "text", "text": "Conditioned on such $\\{\\widehat{d}_{h}^{\\pi}\\}$ , the second pair of terms $\\|\\nabla\\widehat{J}_{F}(\\pi)-\\widehat{\\nabla}J_{F}(\\pi)\\|$ is analogous to the error bounded in Thm. 3.1, and the proof follows identically thereon, but with dependence on the range $C_{F}$ of the functionals. ", "page_idx": 20}, {"type": "text", "text": "C  Additional results and proofs for Sec. 4 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "C.1  Proofs for Sec. 4.1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof of Lem. 4.1 By passing the gradient through the clipped Bellman fow equation in Def. 4.2, wehave ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\bar{d}_{h}^{\\pi}(s^{\\prime})}\\\\ &{\\quad=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\left(\\nabla\\bar{\\pi}_{h-1}(a|s)\\bar{d}_{h-1}^{\\pi}(s)+\\pi(a|s)\\nabla\\left(\\bar{d}_{h-1}^{\\pi}(s)\\wedge C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right)\\right)}\\\\ &{\\quad=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\bar{\\pi}_{h-1}(a|s)\\left(\\bar{d}_{h-1}^{\\pi}(s)\\wedge C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right)\\left(\\nabla\\log\\bar{\\pi}_{h-1}(a|s)\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.+\\left.\\nabla\\log\\left(\\bar{d}_{h-1}^{\\pi}(s)\\wedge C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Next, dropping the $h-1$ subscript for a moment, observe that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla\\log\\big(\\bar{d}^{\\pi}(s)\\wedge C^{\\mathbf{s}}d^{D}(s)\\big)=\\left\\{\\nabla\\log\\bar{d}^{\\pi}(s),\\begin{array}{l l}{\\mathrm{if~}\\bar{d}^{\\pi}(s)<C^{\\mathbf{s}}d^{D}(s),}\\\\ {\\mathrm{if~}\\bar{d}^{\\pi}(s)>C^{\\mathbf{s}}d^{D}(s),}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with a discontinuity at $\\bar{d}^{\\pi}(s)\\:=\\:C^{\\bf s}d^{D}(s)$ .For simplicity, we set $\\nabla\\log\\left(\\bar{d}^{\\pi}(s)\\wedge C^{s}d^{D}(s)\\right)\\,=$ $\\nabla\\log\\bar{d}^{\\pi}(s)\\odot\\mathbf{1}[\\bar{d}^{\\pi}(s)\\leq C^{\\mathbf{s}}d^{D}(s)]$ . Similarly, we have $\\nabla\\log\\bar{\\pi}(a|s)=\\nabla\\log\\pi(a|s)\\odot\\mathbf{1}[\\pi(a|s)\\leq$ $C^{\\mathbf{a}}\\pi^{\\breve{D}}(a|s)]$ \uff1a ", "page_idx": 20}, {"type": "text", "text": "Finally, $\\nabla\\log\\bar{d}_{h}^{\\pi}(s^{\\prime})=\\nabla\\bar{d}_{h}^{\\pi}(s^{\\prime})/\\bar{d}_{h}^{\\pi}(s^{\\prime})$ ,where $\\begin{array}{r}{\\bar{d}_{h}^{\\pi}(s^{\\prime})=\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s)\\bar{\\rho}_{h-1}^{\\pi}.}\\end{array}$ The lemma statement follows from the definition of Eb-1, and the gradient magnitude bound results from invoking Lem. C.2 with $\\sigma\\left(x,c\\right)=(x\\wedge c)$ ", "page_idx": 20}, {"type": "text", "text": "Proof of Prop. 4.1 This result follows from applying Lem. C.7, which is a more general version of the proposition statement that holds for any (smooth-)clipping function, to $\\sigma\\left(x,c\\right)=(x\\wedge c)$ ", "page_idx": 20}, {"type": "text", "text": "Proof of Prop. 4.2  The MDP we will describe corresponds to a multi-armed bandit with 2 actions. Consider an MDP with $H=2$ , and ${\\cal S}^{0}=\\{s_{0}\\},{\\cal S}^{1}=\\dot{\\{s_{L},s_{R}\\}},{\\cal S}^{2}=\\{s_{-},s_{+}\\}$ which are terminal. In any state there are two actions, $\\begin{array}{r}{\\mathcal{A}=\\{L,R\\}}\\end{array}$ , with deterministic transitions. For the first level, we have $s_{0}\\stackrel{L}{\\rightarrow}s_{L}$ and $s_{0}\\stackrel{R}{\\rightarrow}s_{R}$ . For the second level, we have $s_{L}\\to s_{-}$ and $s_{R}\\to s_{+}$ , regardless of action taken. For the reward function, $R(s_{+})=1$ and is O otherwise. ", "page_idx": 21}, {"type": "text", "text": "The policy is parameterized by a single parameter $\\theta$ such that $\\pi(L)=1-\\theta$ , and $\\pi(R)=\\theta$ , such that $d_{1}^{\\pi_{\\theta}}(s_{R})=d_{2}^{\\pi_{\\theta}}(s_{+})=\\theta$ Further, both the offine data and beavior policy are uniform in each level. Consequently, $\\begin{array}{r}{\\pi_{0}^{D}(L)=\\pi_{0}^{D}(R)=\\frac{1}{2}}\\end{array}$ and $d_{1}^{D}=\\operatorname{unif}(S^{1})$ . We set $C_{1}^{\\mathrm{s}}=C_{2}^{\\mathrm{s}}=2$ , and $C_{2}^{\\mathbf{a}}=2$ so that $\\bar{\\pi}_{h}=\\pi_{h}$ for all $h$ ", "page_idx": 21}, {"type": "text", "text": "Fix $\\theta$ and estimated occupancies $\\hat{d}^{\\pi_{\\theta}}$ and $\\hat{d}^{D}$ . For any $s^{\\prime}\\in\\mathcal{S}^{2}$ we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\nabla\\log d_{2}^{\\pi_{\\theta}}(s^{\\prime})-\\widehat\\nabla\\log\\bar{d}_{2}^{\\pi_{\\theta}}(s^{\\prime})\\right\\|=\\left\\|\\nabla\\bar{d}_{1}^{\\pi_{\\theta}}(s^{\\prime})\\left(\\mathbf{1}[\\hat{d}_{1}^{\\pi_{\\theta}}(s^{\\prime})\\leq\\hat{d}_{1}^{D}(s^{\\prime})]-\\mathbf{1}[d_{1}^{\\pi_{\\theta}}(s^{\\prime})\\leq d_{1}^{D}(s^{\\prime})]\\right)\\right\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Next, we instantiate $\\hat{d}^{\\pi_{\\theta}},\\hat{d}^{D}$ for any $\\pi_{\\theta}$ . The preconditions of the proposition are satisfied by an estimated occupancy with $\\hat{d}_{1}^{\\pi_{\\theta}}(s_{L})\\,=\\,\\theta+\\epsilon/2$ and $\\hat{d}_{1}^{\\pi_{\\theta}}(s_{R})\\,=\\,\\theta\\,-\\,\\bar{\\epsilon/2}$ . In addition, we have an estimate $\\hat{d}^{D}$ with $\\hat{d}_{1}^{D}(s_{L})=1/2-\\epsilon/2$ and $\\hat{d}_{1}^{D}(s_{R})=1/2+\\epsilon/2$ ", "page_idx": 21}, {"type": "text", "text": "We will consider $\\theta=1/2$ , so that $d_{1}^{\\pi_{\\theta}}\\leq C_{1}^{\\mathbf{s}}d_{1}^{D}$ . However, $\\hat{d}_{1}^{\\pi_{\\theta}}(s_{L})>\\hat{d}_{1}^{D}(s_{L})$ .As a result, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left\\vert\\left\\vert\\nabla\\log d_{2}^{\\pi_{\\theta}}(s^{\\prime})-\\widehat\\nabla\\log\\bar{d}_{2}^{\\pi_{\\theta}}(s^{\\prime})\\right\\vert\\right\\vert=\\left\\vert\\left\\vert\\nabla\\bar{d}_{1}^{\\pi_{\\theta}}(s^{\\prime})\\right\\vert\\right\\vert=O(1)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "C.2  Proofs for Sec. 4.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "First, we formally state and prove the claim that Lem. 4.2 can be reduced to minimizing a squaredloss regression problem recursively over timesteps, i.e., ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\log\\widetilde{d}_{h+1}^{\\pi}}\\\\ &{=\\underset{g:S\\rightarrow\\mathbb{R}^{p}}{\\operatorname{argmin}}\\mathbb{E}_{\\mathcal{D}_{h}}\\left[\\left\\|g(s^{\\prime})-\\left(\\nabla\\log\\pi\\odot\\widetilde{\\mathbf{1}}\\left(\\pi,C_{h}^{\\mathbf{a}}d_{h}^{D}\\right)+\\nabla\\log\\widetilde{d}_{h-1}^{\\pi}\\odot\\widetilde{\\mathbf{1}}\\left(\\widetilde{d}_{h}^{\\pi},C_{h}^{\\mathbf{s}}d_{h}^{D}\\right)\\right)\\right\\|^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This is a reweighted offline analog of Eq. (2) from the online setting, and a more general version is presented below with proof. ", "page_idx": 21}, {"type": "text", "text": "Lemma C.1. For $g:S\\to\\mathbb{R}^{\\mathsf{p}}$ and $f:S\\times A\\to\\mathbb{R}^{\\mathsf{p}}$ and reweighting function $\\rho:S\\times A\\to\\mathbb{R_{+}}$ define the offline reweighted squared loss regression objective ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widetilde{\\mathscr{L}}_{h}(g;f,\\rho)=\\mathbb{E}_{\\mathscr{D}_{h}}[\\rho(s_{h},a_{h})\\|g(s_{h+1})-f(s_{h},a_{h})\\|^{2}].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then for any such $f$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{E}_{h}^{D,\\rho}(f)=\\underset{g:S\\rightarrow\\mathbb{R}^{\\ p}}{\\mathrm{argmin}}\\,\\widetilde{\\mathcal{L}}_{h}(g;f,\\rho).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "$\\begin{array}{r}{\\widetilde{\\rho}_{h}^{\\pi}\\;=\\;\\frac{\\sigma\\left(\\widetilde{d}_{h}^{\\pi}(s),C_{h}^{\\mathbf{s}}d_{h}^{D}(s)\\right)}{d_{h}^{D}(s)}\\frac{\\widetilde{\\pi}_{h}(a|s)}{\\pi_{h}^{D}(a|s)}}\\end{array}$ andsmooth-clipped target function $y_{h}^{\\pi}:=\\nabla\\log\\pi\\odot\\widetilde{\\mathbf{1}}\\left(\\pi,C_{h}^{\\mathbf{a}}d_{h}^{D}\\right)+\\nabla\\log\\widetilde{d}_{h}^{\\pi}\\odot\\widetilde{\\mathbf{1}}\\left(\\widetilde{d}_{h}^{\\pi},C_{h}^{\\mathbf{s}}d_{h}^{D}\\right),$ from Lem.4.2,we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\nabla\\log\\widetilde{d}_{h+1}^{\\pi}=\\underset{g:S\\rightarrow\\mathbb{R}^{\\mathsf{p}}}{\\mathrm{argmin}}\\,\\widetilde{\\mathcal{L}}_{h}\\left(g;y_{h}^{\\pi},\\widetilde{\\rho}_{h}^{\\pi}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof of Lem. B.2. Since the objective is convex, can solve for the minimizer in closed form by taking the derivative and setting it to O in an element-wise manner. For each $s^{\\prime}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n0=g(s^{\\prime})\\left(\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s)\\rho(s,a)\\right)-\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s)\\rho(s,a)f(s,a).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Rearranging and using the definition of $\\mathbf{E}_{h}^{D,\\rho}$ (Eq. (5) gives the result. The second statement follows from Lem. 4.2. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Proof of Prop. 4.3 Part 1 follows from the gradient formula ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\partial_{x}\\sigma\\left(x,c\\right)=x^{-\\beta-1}\\left(x^{-\\beta}+c^{-\\beta}\\right)^{-1/\\beta-1}=\\left(1+x^{\\beta}c^{-\\beta}\\right)^{-1/\\beta-1}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "It can be seen that $\\partial_{x}\\sigma\\left(x,c\\right)\\,\\in\\,\\left[0,1\\right]$ and is non-increasing in its inputs, thus $\\sigma$ is monotonic. Additionally, $\\left|\\sigma\\left(x,c\\right)-\\sigma\\left(x^{\\prime},c\\right)\\right|\\leq\\left|x-x^{\\prime}\\right|$ .Since $\\sigma$ is symmetric in its arguments, we also have $|\\sigma^{\\mathbf{s}}\\left(x,c\\right)-\\sigma^{\\mathbf{s}}\\left(x,c^{\\prime}\\right)|\\leq|c-c^{\\prime}|$ ", "page_idx": 22}, {"type": "text", "text": "Next, we prove Part 2. Let $z\\,=\\,(x\\wedge c)$ , and observe that $z\\mathrm{~-~}\\sigma\\left(x,c\\right)\\,\\leq\\,z\\mathrm{~-~}\\sigma\\left(z,z\\right)$ since $\\sigma$ is monotonic. Further, ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\frac{z-\\sigma\\left(z,z\\right)}{z}}={\\frac{z-\\left(2z^{-\\beta}\\right)^{-1/\\beta}}{z}}=1-2^{-1/\\beta}\\leq1-e^{-1/\\beta}\\leq{\\frac{1}{\\beta}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Rearranging and plugging in the expression for $z$ gives the result. ", "page_idx": 22}, {"type": "text", "text": "Part 3 can be derived algebraically (but not easily), and is best intuited from the plot of the maximum slope $\\begin{array}{r}{\\operatorname*{sup}_{x,x^{\\prime},c,c^{\\prime}\\in\\left[0,1\\right]}\\bar{|\\Im}\\left(x,c\\right)-\\tilde{\\textbf{1}}(x^{\\prime},c)\\,|/|x-x^{\\prime}|}\\end{array}$ in Figure C.2, which corresponds to $L_{\\sigma}/c$ in the RHS of the bound. The left plot shows that the maximum slope increases linearly in $\\beta$ , and the right plot shows it increases inversely with $c$ . The dashed red line is a \u201cguess\" for the exact constant $\\bar{L_{\\sigma}}/{c}=0.3\\beta/c$ , that upper-bounds the maximum slope. Clearly, $L_{\\sigma}=\\bar{O}(\\beta)$ ", "page_idx": 22}, {"type": "image", "img_path": "Nq8enbbaP2/tmp/e7d1271d63eb5afb0ef008e77a7e89e1a7920a912437e7ee5ca08a75c39797e1.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 2: The y-axis plots the maximum slope supz,z,[0,1] $\\begin{array}{r}{\\operatorname*{sup}_{x,x^{\\prime},c,c^{\\prime}\\in[0,1]}\\frac{|\\tilde{\\mathbf{1}}(x,c)-\\tilde{\\mathbf{1}}\\left(x^{\\prime},c\\right)|}{|x-x^{\\prime}|}=L_{\\sigma}/c.}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "Proof of Lem. 4.2 Using the chain rule, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\tilde{d}_{h}^{\\pi}(s^{\\prime})}\\\\ &{\\quad=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\left(\\nabla\\tilde{\\pi}_{h-1}(a|s)\\tilde{d}_{h-1}^{\\pi}(s)+\\pi(a|s)\\nabla\\sigma\\left(\\tilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)\\right)}\\\\ &{\\quad=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\tilde{\\pi}_{h-1}(a|s)\\sigma\\left(\\tilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)\\left(\\nabla\\log\\tilde{\\pi}_{h-1}(a|s)\\right.}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.+\\nabla\\log\\sigma\\left(\\tilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)\\right)}\\\\ &{\\quad=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s)\\tilde{\\rho}_{h-1}^{\\pi}(s)\\Big(\\nabla\\log\\tilde{\\pi}_{h-1}(a|s)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad+\\nabla\\log\\sigma\\left(\\tilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where in the last line we use the definition of $\\widetilde{\\rho}_{h-1}^{\\pi}$ from Lem. 4.2 to make a change-of-measure. Further, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\log\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)=\\nabla\\widetilde{d}_{h-1}^{\\pi}(s)\\odot\\partial_{x}\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\nabla\\log\\widetilde{d}_{h-1}^{\\pi}(s)\\odot\\left(\\widetilde{d}_{h-1}^{\\pi}(s)\\cdot\\partial_{x}\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}d_{h-1}^{D}(s)\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n=\\nabla\\log\\widetilde{d}_{h-1}^{\\pi}(s)\\odot\\widetilde{\\mathbf{1}}\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "by definition. We can make the analogous statement for $\\nabla\\log\\widetilde{\\pi}_{h-1}$ . Next, using the same change of measure in Def. 4.3, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widetilde{d}_{h}^{\\pi}(s^{\\prime})=\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s)\\widetilde{\\rho}_{h-1}^{\\pi}(s,a).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The lemmastement folows from $\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s^{\\prime})=\\nabla\\widetilde{d}_{h}^{\\pi}(s^{\\prime})/\\widetilde{d}_{h}^{\\pi}(s^{\\prime})$ and the definition of $\\mathbf{E}_{h-1}^{D,\\widetilde{\\rho}}$ 1in Eq. (5). The gradient magnitude bound is proved in Lem. C.2. ", "page_idx": 23}, {"type": "text", "text": "Lemma C.2 (Bounded gradient magnitude). Suppose $\\sigma$ is differentiable almost everywhere. Under Part 1 of Asm. 4.1 and Asm. 2.1, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{h,s}\\left\\|\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s)\\right\\|_{\\infty}\\leq h G.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof of Lem. C.2. As a consequence of Asm. 4.1, which states that the gradient of $\\sigma$ is nonincreasing in the first argument, for any $x,c\\geq0$ wehave ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sigma\\left(x,c\\right)=\\int_{0}^{x}\\;\\partial_{x}\\sigma^{\\mathbf{s}}\\left(z,c\\right)d z\\geq\\int_{0}^{x}\\;\\partial_{x}\\sigma^{\\mathbf{s}}\\left(x,c\\right)d z=x\\;\\partial_{x}\\sigma\\left(x,c\\right)\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then  substituting $\\begin{array}{r l r}{x}&{{}\\leftarrow}&{\\tilde{d}_{h-1}^{\\pi}(s)}\\end{array}$ and $\\begin{array}{r l r}{c}&{{}\\leftarrow}&{d_{h-1}^{D}(s)}\\end{array}$ \uff0cthe above shows that $\\nabla\\log\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),d_{h-1}^{D}(s)\\right)\\ \\leq\\ \\nabla\\log\\widetilde{d}_{h-1}^{\\pi}$ pointwise. Since Lem. 4.2 involves a valid (conditional) expectation, for any $s\\in S$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\lVert\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s^{\\prime})\\right\\rVert_{\\infty}}\\\\ &{\\le\\underset{s,a}{\\operatorname*{max}}\\left\\{\\left\\lVert\\nabla\\log\\sigma\\left(\\pi(a|s),C_{h-1}^{\\mathbf{a}}\\pi_{h-1}^{D}(a|s)\\right)\\right\\rVert_{\\infty}+\\left\\lVert\\nabla\\log\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right)\\right\\rVert_{\\infty}\\right\\}}\\\\ &{\\le G+\\underset{s}{\\operatorname*{max}}\\left\\lVert\\nabla\\log\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}(s)\\right)\\right\\rVert_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we use Asm. 2.1 in the second line, and unroll the same inequalities through levels in the last line. \u25a0 ", "page_idx": 23}, {"type": "text", "text": "Proof of Prop. 4.4 First, we bound the difference between the soft-clipped and clipped density functions: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left\\vert\\widetilde{d}_{h}^{\\pi}-\\bar{d}_{h}^{\\pi}\\right\\vert\\right\\vert_{1}\\leq\\left\\Vert\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)-\\left(\\bar{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right\\Vert_{1}+\\operatorname*{max}_{s}\\left\\Vert\\widetilde{\\pi}_{h-1}(\\cdot|s)-\\bar{\\pi}_{h-1}(\\cdot|s)\\right\\Vert_{1}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For the second term and any $s$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widetilde{\\pi}_{h-1}(\\cdot|s)-\\bar{\\pi}_{h-1}(\\cdot|s)\\|_{1}=\\|\\sigma\\left(\\pi_{h-1}(\\cdot|s),C_{h-1}^{\\mathrm{a}}\\pi_{h-1}^{D}(\\cdot|s)\\right)-\\left(\\pi_{h-1}(\\cdot|s)\\wedge C_{h-1}^{\\mathrm{a}}\\pi_{h-1}^{D}(\\cdot|s)\\right)\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq D_{\\sigma}\\left\\|\\left(\\pi_{h-1}(\\cdot|s)\\wedge C_{h-1}^{\\mathrm{a}}\\pi_{h-1}^{D}(\\cdot|s)\\right)\\right\\|_{1}\\leq D_{\\sigma}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For the first term, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)-\\left(\\widetilde{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right\\|_{1}}\\\\ &{\\leq\\left\\|\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)-\\left(\\widetilde{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right\\|_{1}+\\left\\|\\left(\\widetilde{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)-\\left(\\bar{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right\\|_{1}}\\\\ &{\\leq D_{\\sigma}\\left\\|\\left(\\widetilde{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right\\|_{1}+\\left\\|\\widetilde{d}_{h-1}^{\\pi}-\\overline{{d}}_{h-1}^{\\pi}\\right\\|_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where in the last line we use Asm. 4.1 to upper bound the first term, and the properties of the pointwise minimum $\\wedge$ to upper bound the second term. Since $\\left(\\widetilde{d}_{h-1}^{\\pi}\\wedge C_{h-1}^{\\mathbf{s}}d_{h-1}^{\\bar{D}}\\right)\\,\\leq\\,\\widetilde{d}_{h-1}^{\\pi}\\,\\leq$ $d_{h-1}^{\\pi}$ ,wehave ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widetilde{d}_{h}^{\\pi}-\\bar{d}_{h}^{\\pi}\\right\\|_{1}\\le2D_{\\sigma}+\\left\\|\\widetilde{d}_{h-1}^{\\pi}-\\overline{{d}}_{h-1}^{\\pi}\\right\\|_{1}\\le h(D_{\\sigma}+D_{\\sigma})}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "after rolling out the induction. Then for any $\\pi$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{J}(\\pi)-\\widetilde{J}(\\pi)\\leq\\sum_{h=1}^{H}\\left\\|\\widetilde{d}_{h}^{\\pi}-\\bar{d}_{h}^{\\pi}\\right\\|_{1}\\leq2H^{2}D_{\\sigma}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lastly, let $\\widetilde{\\pi}^{*}=\\mathrm{argmax}_{\\pi\\in\\Pi_{\\Theta}}\\,\\widetilde{J}(\\pi)$ , and define $\\bar{\\pi}^{*}$ similarly. Then ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{J}(\\bar{\\pi}^{*})-\\widetilde{J}(\\widetilde{\\pi}^{*})\\leq\\bar{J}(\\bar{\\pi}^{*})-\\widetilde{J}(\\bar{\\pi}^{*})\\leq2H^{2}D_{\\sigma}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "C.3 Proofs for Sec. 4.3 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "First, we give an example of $\\mathcal{G}$ that satisfies Asm. 4.2 in low-rank MDPs. ", "page_idx": 24}, {"type": "text", "text": "Proposition C.1. Suppose $\\mathcal{M}$ is a low-rank MDP (Def. B.1), and suppose $\\mu$ is known.For each layer $h_{i}$ definethefunctionclass ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{G}_{h}=\\left\\{g_{h}=\\frac{\\mu^{\\top}\\Psi}{\\mu^{\\top}\\psi}:\\Psi\\in\\mathbb{R}^{k\\times\\mathtt{p}},\\psi\\in\\mathbb{R}^{k},\\|g_{h}\\|_{\\infty}\\leq h G,\\,\\forall h\\in[H]\\right\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then $\\{\\mathcal{G}_{h}\\}$ satisfies Asm. 4.2 and has pseudodimension $(D e f.\\,F.I)\\;{\\mathsf{d}}_{\\mathcal{G}_{h}}=O(k{\\mathsf{p}})$ ", "page_idx": 24}, {"type": "text", "text": "Proof of Prop. C.1. It suffices to show that, for any $f:\\mathcal{S}\\times\\mathcal{A}\\to\\mathbb{R}^{\\mathsf{p}}$ , reweighting function $\\rho:$ $S\\times{\\mathcal{A}}\\to\\mathbb{R}_{+}$ , and $h\\in[H]$ , the gradient update in Lem. 4.2 has $[\\mathbf{E}_{h}^{D,\\rho}f]\\in\\mathcal{G}_{h+1}$ ", "page_idx": 24}, {"type": "text", "text": "Fix $\\rho,f$ and $h$ . From the definition of $\\mathbf{E}_{f}^{\\rho}$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n[\\mathbf{E}_{h}^{\\rho}f](s^{\\prime})=\\frac{\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s,a)\\rho(s,a)f(s,a)}{\\sum_{s,a}P(s^{\\prime}|s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s,a)\\rho(s,a)}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then since $P(s^{\\prime}|s,a)=\\langle\\phi(s,a),\\mu(s^{\\prime})\\rangle$ , we can apply the same steps as the proof of Prop. B.1 to show that there exists $\\Psi\\in\\mathbb{R}^{k\\times\\mathsf{p}}$ and $\\psi\\in\\mathbb{R}^{k}$ such that ", "page_idx": 24}, {"type": "equation", "text": "$$\n[\\mathbf{E}_{h}^{\\rho}f](s^{\\prime})=\\frac{\\mu(s^{\\prime})^{\\top}\\Psi}{\\mu(s^{\\prime})^{\\top}\\psi},\\;\\forall s^{\\prime}\\in\\mathcal{S}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Specifically, $\\begin{array}{r l r}{\\psi}&{=}&{\\sum_{s,a}\\phi(s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s,a)\\rho(s,a)}\\end{array}$ . and the $p$ -th column of $\\Psi$ is $\\begin{array}{r l}{\\Psi^{p}}&{{}=}\\end{array}$ $\\begin{array}{r}{\\sum_{s,a}\\phi(s,a)\\pi_{h}^{D}(a|s)d_{h}^{D}(s,a)\\rho(s,a)f^{p}(s,a)}\\end{array}$ \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Proof of Thm. 4.1 For the remainder of this section, we define the constants $\\varepsilon^{\\mathrm{w}}$ and $\\varepsilon^{\\mathrm{{mle}}}$ to be the estimation errors of $\\widetilde{w}^{\\pi}$ and $d^{D}$ , respectively, such that for a given $\\pi$ and any $h\\in[H]$ we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\|_{1,d_{h-1}^{D,\\dagger}}\\leq\\varepsilon^{\\mathrm{w}}}\\\\ &{\\left\\|\\widehat{d}_{h}^{D}-d_{h}^{D}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}\\quad\\mathrm{and}\\quad\\left\\|\\widehat{d}_{h}^{D,\\dagger}-d_{h}^{D,\\dagger}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We can obtain such estimates using Alg. 4 and Alg. 5, and a direct application of Lem. D.1 with union bound gives $\\begin{array}{r}{\\varepsilon^{\\mathrm{mle}}\\,=\\,O\\left(\\sqrt{\\frac{\\log(H|\\mathcal{F}|/\\delta)}{n}}\\right)}\\end{array}$ and similarly Thm. E.1 states that $\\varepsilon^{\\mathrm{wreg}}\\,=$ $\\begin{array}{r}{O\\left(\\sqrt{\\frac{\\log\\left(H\\vert\\mathcal{W}\\vert/\\delta\\right)}{n}}\\right).}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Next, recall that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\widehat{\\nabla}\\tilde{J}(\\pi)=\\frac{1}{|\\mathcal{D}_{h}^{\\mathrm{grad}}|}\\sum_{h=0}^{H-1}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h}^{\\mathrm{grad}}}\\widehat{w}_{h}^{\\pi}(s^{\\prime})R_{h}(s^{\\prime})\\widehat{g}_{h}^{\\pi}(s^{\\prime}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The expected value over draws of $\\mathcal{D}^{\\mathrm{grad}}$ is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}_{h}^{\\mathrm{grad}}}\\left[\\widehat{\\nabla}\\widetilde{J}(\\pi)\\right]=\\sum_{h}\\mathbb{E}_{s^{\\prime}\\sim d_{h-1}^{D,\\dagger}}\\left[\\widehat{w}_{h}^{\\pi}(s^{\\prime})R_{h}(s^{\\prime})\\widehat{g}_{h}^{\\pi}(s^{\\prime})\\right].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "First we bound the statistical error from using samples to approximate $\\nabla\\widetilde J(\\pi)$ , given the gradient estimate. Fix the other datasets, then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\widehat{\\nabla}\\widetilde{J}(\\pi)-\\mathbb{E}_{\\mathcal{D}^{\\mathrm{grad}}}\\left[\\widehat{\\nabla}\\widetilde{J}(\\pi)\\right]\\right\\|}\\\\ &{\\leq\\sqrt{\\mathfrak{p}}\\displaystyle\\operatorname*{max}_{p\\in[\\mathfrak{p}]}\\sum_{h}\\left|\\widehat{\\mathbb{E}}_{s^{\\prime}\\sim d_{h-1}^{D,\\uparrow}}\\left[\\widehat{w}_{h}^{\\pi}(s^{\\prime})R_{h}(s^{\\prime})\\widehat{g}_{h}^{\\pi}(s^{\\prime})\\right]-\\mathbb{E}_{s^{\\prime}\\sim d_{h-1}^{D,\\uparrow}}\\left[\\widehat{w}_{h}^{\\pi}(s^{\\prime})R_{h}(s^{\\prime})\\widehat{g}_{h}^{\\pi}(s^{\\prime})\\right]\\right|}\\\\ &{\\leq\\sqrt{\\mathfrak{p}}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\displaystyle\\operatorname*{max}_{p\\in[\\mathfrak{p}],h\\in[H]}\\left|\\widehat{\\mathbb{E}}_{s^{\\prime}\\sim d_{h-1}^{D,\\downarrow}}\\left[\\widehat{g}_{h}^{\\pi}(s^{\\prime})\\right]-\\mathbb{E}_{s^{\\prime}\\sim d_{h-1}^{D,\\uparrow}}\\left[\\widehat{g}_{h}^{\\pi}(s^{\\prime})\\right]\\right|}\\\\ &{\\leq\\sqrt{\\mathfrak{p}}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{stat}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\begin{array}{r}{\\varepsilon^{\\mathrm{stat}}=H G\\sqrt{\\frac{\\log\\left(8\\mathsf{p}H/\\delta\\right)}{2n}}}\\end{array}$ is obtained by using Hoeffding's with $\\delta^{\\prime}=\\delta/4$ , since the randomness in $\\widehat{w}$ and $\\widehat g$ are fixed. Then for any $p\\in[{\\mathsf{p}}]$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\Vert\\mathbb{E}_{D_{h}^{\\mathrm{grad}}}\\left[\\widehat{\\nabla}\\widetilde{J}(\\pi)\\right]-\\nabla\\widetilde{J}(\\pi)\\right\\Vert}\\\\ &{\\le\\sum_{h}\\left\\Vert\\sum_{s^{\\prime}}d_{h-1}^{D,\\dagger}(s^{\\prime})R_{h}(s^{\\prime})\\left(\\widehat{w}_{h}^{\\pi}(s^{\\prime})\\cdot\\widehat{g}_{h}^{\\pi}(s^{\\prime})-w_{h}^{\\pi}(s^{\\prime})\\cdot\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s^{\\prime})\\right)\\right\\Vert}\\\\ &{\\le\\sum_{h}\\left\\Vert\\sum_{s^{\\prime}}d_{h-1}^{D,\\dagger}(s^{\\prime})R_{h}(s^{\\prime})w_{h}^{\\pi}(s^{\\prime})\\left(\\widehat{g}_{h}^{\\pi}(s^{\\prime})-\\nabla\\log\\widetilde{d}_{h}^{\\pi}(s^{\\prime})\\right)\\right\\Vert+\\left\\Vert\\sum_{s^{\\prime}}d_{h-1}^{D,\\dagger}(s^{\\prime})R_{h}(s^{\\prime})\\widehat{y}_{h}^{\\pi}(s^{\\prime})\\left(\\widehat{w}_{h}^{\\pi}(s^{\\prime})-\\widehat{w}_{h}^{\\pi}(s^{\\prime})\\right)\\right\\Vert}\\\\ &{\\le\\sqrt{9}\\sum_{h}\\left(h G\\left\\Vert\\widehat{w}_{h}^{\\pi}-w_{h}^{\\pi}\\right\\Vert_{1,d_{h-1}^{D,\\dagger}}+\\operatorname*{max}_{p\\in[\\!]}\\left\\Vert\\widehat{g}_{h}^{\\pi}\\right\\Vert^{p}-\\nabla\\log\\widetilde{d}_{h}^{\\pi}\\right\\Vert_{1,\\widetilde{d}_{h}^{\\prime}}\\right)}&{~(13-\\Gamma)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The first term is bounded by Thm. E.1. For the second term, we use the following decomposition, which is proved at the end of this section. ", "page_idx": 25}, {"type": "text", "text": "Lemma C.3 (Gradient estimation error decomposition). Let $\\varepsilon^{\\mathrm{{mle}}}$ and $\\varepsilon^{\\mathrm{w}}$ be such that for all $h\\in[h]$ and $\\pi\\in\\Pi_{\\Theta}$ wehave ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\|\\widehat{d}_{h}^{D}-d_{h}^{D}\\|_{1},\\|\\widehat{d}_{h}^{D,\\dagger}-d_{h}^{D,\\dagger}\\|_{1}\\leq\\varepsilon_{h}^{\\mathrm{mle}}\\quad a n d\\quad\\|\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\|_{1,d_{h-1}^{D,\\dagger}}\\leq\\varepsilon_{h}^{\\mathrm{w}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then under Asm. 2.1 and Asm. 4.1, for any $p\\in[{\\mathfrak{p}}],\\,{\\widehat{g}}_{h}^{\\pi}$ from Alg. 2 satisfies ", "page_idx": 25}, {"type": "text", "text": "nerror) ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\left\\vert\\hat{g}_{h}^{\\pi,p}-\\nabla^{p}\\log\\widetilde{d_{h}^{\\pi}}\\right\\vert\\Bigr\\vert_{1,\\widetilde{d}_{h}^{n}}\\le6h C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}L_{\\sigma}G\\:\\varepsilon_{h-1}^{\\mathrm{mle}}}&{(d a t a\\:d i s t r i b u t i o n\\:e s t i m a t i o n}\\\\ &{+\\:3h L_{\\sigma}G\\:\\varepsilon_{h-1}^{\\mathrm{w}}}&{(o c c u p a n c y\\:e s t i m a t i o n\\:e r r o n\\:e}\\\\ &{+\\:\\left\\|\\hat{g}_{h}^{\\pi,p}-[\\mathbf{E}_{h-1}^{D,\\hat{\\gamma}}(\\nabla\\log\\widetilde{\\pi}_{h-1}+\\hat{g}_{h-1})]^{p}\\right\\|_{1,\\widetilde{d}_{h}^{n}}}&{(s t a t i s t i c a l\\:e g r e s s i o n\\:e r r o n\\left(\\pi\\right.}\\\\ &{+\\:\\|\\hat{g}_{h-1}^{\\pi,p}-\\nabla^{p}\\log\\widetilde{d}_{h-1}^{n}\\|_{1,\\widetilde{d}_{h-1}^{n}}}&{(r e c u r s i v e\\:t e r m)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "From Lem. C.4, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|[\\mathbf{E}_{h-1}^{D,\\widehat{\\rho}}\\widehat{g}_{h-1}]^{p}-\\widehat{g}_{h}^{\\pi,p}\\right\\|_{1,\\widehat{d}_{h}^{\\pi}}\\leq\\sqrt{2\\left(1+C_{h-1}^{\\mathrm{s}}\\varepsilon_{h-1}^{\\mathrm{mle}}\\right)}\\varepsilon_{h}^{\\mathrm{reg}}+2h G\\left(2C_{h-1}^{\\mathrm{s}}\\varepsilon_{h-1}^{\\mathrm{mle}}+\\varepsilon_{h-1}^{\\mathrm{w}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where e're $\\begin{array}{r}{\\varepsilon_{h}^{\\mathrm{reg}}=O(\\sqrt{\\frac{\\mathbf{d}_{\\mathcal{G}}C_{h-1}^{\\mathbf{s}}C_{h-1}^{\\mathbf{a}}h^{2}G^{2}\\log(n\\mathbf{p}H/\\delta)}{n}})}\\end{array}$ .Then pluging the above into the decomposition in Lem. C.3, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\widehat{g}_{h}^{p}-\\nabla^{p}\\log\\widetilde{d}_{h}^{\\pi}\\right\\|_{1,\\widetilde{d}_{h}^{\\pi}}\\leq10C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h G L_{\\sigma}\\,\\varepsilon_{h-1}^{\\mathrm{mle}}+5h G L_{\\sigma}\\,\\varepsilon_{h-1}^{\\mathrm{w}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\sqrt{2\\left(1+C_{h-1}^{\\mathrm{s}}\\varepsilon_{h-1}^{\\mathrm{mle}}\\right)}\\varepsilon_{h}^{\\mathrm{reg}}+\\|\\widehat{g}_{h-1}^{p}-\\nabla^{p}\\log\\widetilde{d}_{h-1}^{\\pi}\\|_{1,\\widetilde{d}_{h-1}^{\\pi}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Unrolling through timesteps, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widehat{g}_{h}^{p}-\\nabla^{p}\\log\\widetilde{d}_{h}^{\\overline{{r}}}\\right|\\biggr|_{1,\\widetilde{d}_{h}^{\\overline{{n}}}}\\leq10h^{2}G L_{\\sigma}\\displaystyle\\sum_{g<h}C_{g}^{\\mathrm{s}}C_{g}^{\\mathrm{a}}\\varepsilon_{g}^{\\mathrm{mle}}+5h^{2}G L_{\\sigma}\\displaystyle\\sum_{g<h}\\varepsilon_{g}^{\\mathrm{w}}+\\sum_{g\\leq h}\\sqrt{2(1+C_{g}^{\\mathrm{s}}\\varepsilon_{g}^{\\mathrm{mle}})}\\varepsilon_{g}^{\\mathrm{reg}}}\\\\ {\\leq10H^{2}G L_{\\sigma}\\left(\\displaystyle\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{mle}}+5H^{3}G L_{\\sigma}\\varepsilon_{H}^{\\mathrm{w}}+\\displaystyle\\sum_{h}\\varepsilon_{h}^{\\mathrm{reg}}\\left(\\sqrt{2}+C_{h}^{\\mathrm{s}}\\varepsilon^{\\mathrm{mle}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{;\\varepsilon_{H}^{\\mathrm{w}}\\leq\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}+2\\sum_{h}C_{h}^{\\mathrm{s}}\\right)\\varepsilon^{\\mathrm{mle}}+\\sqrt{2}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{wreg}},}\\end{array}\n$$Since ", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\widehat{g}_{h}^{p}-\\nabla^{p}\\log d_{h}^{n}\\right|\\right|_{1,\\widetilde{d}_{h}^{\\overline{{n}}}}}\\\\ &{\\quad\\leq25H^{3}G L_{\\sigma}\\left(\\displaystyle\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{mle}}+5\\sqrt{2}H^{3}G L_{\\sigma}\\left(\\displaystyle\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{wreg}}+\\displaystyle\\sum_{h}\\varepsilon_{h}^{\\mathrm{reg}}\\left(\\sqrt{2}+C_{h}^{\\mathrm{s}}\\varepsilon^{\\mathrm{mle}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, combining with Eq. (12) and upper bounding $\\varepsilon^{\\mathrm{{reg}}}$ further, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\nabla\\widetilde{J}(\\pi)-\\widehat{\\nabla}\\widetilde{J}(\\pi)\\right\\|}\\\\ &{\\le\\sqrt{\\mathtt{p}}\\left(\\displaystyle\\sum_{h}C_{h}^{\\mathtt{s o}}C_{h}^{\\mathtt{a}}\\right)\\left(\\varepsilon^{\\mathrm{stat}}+25H^{3}G L_{\\sigma}\\varepsilon^{\\mathrm{mle}}+5\\sqrt{2}H^{3}G L_{\\sigma}\\varepsilon^{\\mathrm{wreg}}\\right)+\\sqrt{\\mathtt{p}}\\left(H\\sqrt{2}+\\varepsilon^{\\mathrm{mle}}\\displaystyle\\sum_{h}C_{h}^{\\mathtt{s o}}\\right)\\left(\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining inequalities and plugging in the expression for each $\\varepsilon$ ,wehave ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\nabla\\widetilde{J}(\\pi)-\\widehat{\\nabla}\\widetilde{J}(\\pi)\\right\\|\\lesssim c\\sqrt{\\frac{\\mathbf{d}_{\\mathcal{G}}\\mathsf{p}H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}\\right)^{2}L_{\\sigma}^{2}\\log(|\\mathcal{W}||\\mathcal{F}|/\\delta)}{n}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Additional results  Lastly, we state and prove the helper lemmas used above. ", "page_idx": 26}, {"type": "text", "text": "Proof of Lem. C.3. First from Lem. C.1, the population minimizer of Eq. (10) given $\\widehat{\\rho}^{\\pi},\\widehat{y}_{h-1}^{\\pi}$ is $g_{h}^{\\pi}=\\zeta_{h}^{\\pi}/f_{h}^{\\pi}$ ,where ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\zeta_{h}^{\\pi}:=\\mathbf{E}_{h-1}^{\\widehat{\\rho}}\\left(\\nabla\\log\\widetilde{\\pi}+\\widehat{y}_{h-1}^{\\pi}\\right)}\\\\ &{f_{h}^{\\pi}:=\\mathbf{E}_{h-1}^{\\widehat{\\rho}}\\left(\\mathbf{1}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Below, we use superscript $p$ to select the $p$ -th parameter of a gradient object. We first separate out the statistical regression error by decomposing ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\|\\nabla^{p}\\log\\widetilde{d}_{h}^{\\pi}-\\widehat{g}_{h}^{\\pi,p}\\right\\|_{1,\\widetilde{d}_{h}^{\\pi}}\\le\\|g_{h}^{\\pi,p}-\\widehat{g}_{h}^{\\pi,p}\\|_{1,\\widetilde{d}_{h}^{\\pi}}+\\left\\|\\nabla^{p}\\log\\widetilde{d}_{h}^{\\pi}-g_{h}^{\\pi,p}\\right\\|_{1,\\widetilde{d}_{h}^{\\pi}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The first term appears as the regression error in Lem. C.3. Since $\\nabla\\log\\widetilde{d}_{h}^{\\pi}\\:=\\:\\nabla\\widetilde{d}_{h}^{\\pi}/\\widetilde{d}_{h}^{\\pi}$ ,for any $p\\in[{\\mathsf{p}}]$ wehave ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\nabla^{p}\\log\\widetilde{d}_{h}^{\\pi}-g_{h}^{\\pi,p}\\right\\|_{1,\\widetilde{d}_{h}^{n}}=\\left\\|\\widetilde{d}_{h}^{\\pi}\\,\\widetilde{\\int}_{h}^{\\pi,p}-\\widetilde{d}_{h}^{\\pi}\\,\\frac{\\nabla^{p}\\widetilde{d}_{h}^{\\pi}}{\\widetilde{d}_{h}^{n}}\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\left\\|\\left(\\widetilde{d}_{h}^{\\pi}-f_{h}^{\\pi}\\right)\\,\\frac{\\zeta_{h}^{\\pi,p}}{f_{h}^{\\pi}}\\right\\|_{1}+\\left\\|\\zeta_{h}^{\\pi,p}-\\nabla^{p}\\widetilde{d}_{h}^{\\pi}\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\|\\mathcal{G}_{h}\\|_{\\infty}\\,\\|\\widetilde{d}_{h}^{\\pi}-f_{h}^{\\pi}\\|_{1}+\\|\\zeta_{h}^{\\pi,p}-\\nabla^{p}\\widetilde{d}_{h}^{\\pi}\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\leq2C_{h-1}^{s}\\|\\mathcal{G}_{h}\\|_{\\infty}\\left\\|\\widehat{d}_{h-1}^{p}-d_{h-1}^{D}\\right\\|_{1}+\\|\\mathcal{G}_{h}\\|_{\\infty}\\left\\|\\widehat{d}_{h-1}^{\\pi}-\\widetilde{d}_{h-1}^{\\pi}\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad+\\left\\|\\zeta_{h}^{\\pi,p}-\\nabla^{p}\\widetilde{d}_{h}^{\\pi}\\right\\|_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The error $\\|\\widetilde{d_{h}^{\\pi}}-f_{h}^{\\pi}\\|_{1}$ bounded by Lem. C.5, and $\\|g_{h}^{\\pi,p}\\|_{\\infty}\\leq\\|\\mathcal{G}_{h}\\|_{\\infty}$ is bounded by Lem. C.2. ", "page_idx": 26}, {"type": "text", "text": "We will bound the second term above. Letting $\\boldsymbol{y}_{h-1}^{\\pi}:=\\nabla\\log\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right)$ be the (true) regression target and using the gradient Bellman equation for $\\nabla\\log\\widetilde{d_{h}^{\\pi}}$ in Lem. 4.2, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widetilde{c}_{h^{\\prime}}^{n}-\\nabla^{\\prime}\\widetilde{c}_{h}^{n}\\|_{1}}\\\\ &{=\\left\\|\\widetilde{c}_{h^{\\prime}}^{n}\\left(\\nabla^{\\prime}\\log\\widetilde{\\tau}+\\widetilde{\\eta}_{h^{\\prime}}^{\\prime\\prime}\\right)-\\widetilde{\\mathbf{b}}_{h^{\\prime}-1}^{\\prime\\prime}\\left(\\nabla^{\\prime}\\log\\widetilde{\\tau}+\\widetilde{\\eta}_{h^{\\prime}}^{\\prime\\prime}\\right)\\right\\|_{1}}\\\\ &{\\le\\left\\|\\frac{\\sqrt{\\eta}(\\widetilde{L}_{h^{\\prime}-1}^{\\prime},C_{h^{\\prime}-1}^{n},\\widetilde{L}_{h^{\\prime}}^{n})}{\\sqrt{\\eta}}\\frac{\\eta}{\\eta}\\widetilde{\\mathbf{b}}_{h^{\\prime}-1}^{\\prime}\\boldsymbol{a}_{h^{\\prime}-1}^{p}\\left(\\nabla^{\\prime}\\log\\widetilde{\\tau}+\\widetilde{\\eta}_{h^{\\prime}-1}^{\\prime\\prime}\\right)-\\sigma\\left(\\widetilde{\\left(\\widetilde{d}_{h^{\\prime}-1}^{\\prime},C_{h^{\\prime}-1}^{n},d_{h^{\\prime}-1}^{p}\\right)}\\widetilde{\\tau}_{h^{\\prime}-1}\\left(\\nabla^{p}\\log\\widetilde{\\tau}\\right)\\right.}\\\\ &{\\le\\left\\|\\sigma\\left(\\widetilde{\\eta}_{h^{\\prime}-1}^{\\prime},C_{h^{\\prime}-1}^{n}\\widetilde{d}_{h^{\\prime}-1}^{n}\\right)\\left(\\nabla^{p}\\log\\widetilde{\\tau}+\\widetilde{\\eta}_{h^{\\prime}-1}^{\\prime\\prime}\\right)-\\sigma\\left(\\widetilde{\\left(\\widetilde{d}_{h^{\\prime}-1}^{\\prime},C_{h^{\\prime}-1}^{n},d_{h^{\\prime}-1}^{p}\\right)}\\left(\\nabla^{p}\\log\\widetilde{\\tau}+\\widetilde{\\eta}_{h^{\\prime}-1}^{\\prime\\prime}\\right)\\right\\|_{1}}\\\\ &{\\qquad\\left.+C_{h^{\\prime}-1}^{n}\\left(G+\\left\\|\\widetilde{\\eta}_{h^{\\prime}-1}^{\\prime\\prime}\\right\\|_{\\infty}\\right)\\left\\|\\sigma_{h^{\\prime}-1}^{\\prime}-\\widetilde{d}_{h^{\\prime}-1}^{n}\\right\\|_{1}}\\\\ &{\\le\\left\\|\\sigma\\left(\\widetilde{\\eta}_{h^{\\prime}-1}^\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Now consider the first term above, where ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{y}_{h-1}^{\\pi}=\\widehat{g}_{h-1}^{\\pi}\\odot\\widetilde{\\mathbf{1}}\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{8}\\widehat{d}_{h-1}^{D}\\right)\\quad\\mathrm{~and~}\\quad y_{h-1}^{\\pi}=\\nabla\\log d_{h-1}^{\\pi}\\odot\\widetilde{\\mathbf{1}}\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{8}d_{h-1}^{D}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then plugging this into the first line from the previous block, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)\\widehat{y}_{h-1}^{\\pi,p}-\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)y_{h-1}^{\\pi,p}\\right\\|_{1}}\\\\ &{=\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)\\widehat{\\mathbf{I}}\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)\\widehat{g}_{h-1}^{\\pi,p}-\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\widehat{\\mathbf{I}}\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\right.}\\\\ &{\\leq\\left\\|\\widehat{g}_{h-1}^{\\pi,p}-\\nabla^{p}\\log d_{h-1}^{\\pi}\\right\\|_{1,\\widetilde{d}_{h-1}^{\\pi}}}\\\\ &{\\qquad+\\left\\|{\\mathcal{G}}_{h-1}\\right\\|_{\\infty}\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)\\widehat{\\mathbf{I}}\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)-\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)\\widehat{\\mathbf{I}}\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where we adand subraet $\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right)\\widetilde{\\mathbf{1}}\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right)\\widehat{g}_{h-1}^{\\pi,p}$ to obtain the inequality. The first error is the recursive term, so it remains to bound the second, for which we will use the smoothnessproperties of $\\Tilde{\\mathbf{1}}\\left(x,c\\right)$ from Asm. 4.1. ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\nu},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)-\\sigma\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\right\\|_{1}}\\\\ &{\\leq\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\widehat{\\mathbf{i}}\\left(\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)-\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\right)\\right\\|_{1}}\\\\ &{\\qquad+\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\left(\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)-\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\right)\\right\\|_{1}}\\\\ &{\\qquad+\\left\\|\\left(\\sigma\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)-\\sigma\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)\\right)\\widehat{\\mathbf{i}}\\left(\\widehat{d}_{h-1}^{\\overline{{\\kappa}}},C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}\\right)\\right\\|_{1} \n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lastly, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{d}_{h}^{\\pi}-\\widetilde{d}_{h}^{\\pi}\\right\\|_{1}\\le C^{\\mathbf{s}}C^{\\mathbf{a}}\\left\\|\\widehat{d}_{h-1}^{D,\\dagger}-d_{h-1}^{D,\\dagger}\\right\\|_{1}+\\left\\|\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\right\\|_{1,d_{h-1}^{D,\\dagger}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Finally, after combining Eq. (14), Eq. (15), Eq. (16), Eq. (17), and Eq. (18), we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|\\nabla^{p}\\log\\widetilde{d_{h}^{n}}-\\widehat{g}_{h}^{\\pi,p}\\right\\|_{1,\\widetilde{d_{h}^{n}}}\\leq\\left\\|\\widehat{g}_{h-1}^{\\pi,p}-\\nabla^{p}\\log d_{h-1}^{\\pi}\\right\\|_{1,\\widetilde{d}_{h-1}^{\\pi}}}&{}\\\\ {+\\ \\left\\|\\zeta_{h}^{\\pi,p}-\\widehat{g}_{h}^{\\pi,p}\\right\\|_{1,\\widetilde{d}_{h}^{\\pi}}}&{}\\\\ {+\\ \\left(G+(L_{\\sigma}+1)\\|\\mathcal{G}_{h-1}\\|_{\\infty}+\\|\\mathcal{G}_{h}\\|_{\\infty}\\right)\\ \\|\\widehat{w}_{h-1}^{\\pi}-\\widetilde{w}_{h-1}^{\\pi}\\|_{1,d_{h-1}^{D,\\uparrow}}}&{}\\\\ {+\\ C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}\\left(G+(L_{\\sigma}+1)\\|\\mathcal{G}_{h-1}\\|_{\\infty}+\\|\\mathcal{G}_{h}\\|_{\\infty}\\right)\\left\\|\\widehat{d}_{h-1}^{D,\\dagger}-d_{h-1}^{D,\\dagger}\\right\\|_{1}}&{}\\\\ {+\\ \\left(2C_{h-1}^{\\mathrm{s}}G+(L_{\\sigma}+C_{h-1}^{\\mathrm{s}})\\|\\mathcal{G}_{h-1}\\|_{\\infty}+\\|\\mathcal{G}_{h}\\|_{\\infty}\\right)\\ \\|\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\|_{1}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Plugging in $\\|{\\mathcal{G}}_{h}\\|_{\\infty}\\leq h G$ and consolidating terms, gives the result. ", "page_idx": 28}, {"type": "text", "text": "Lemma C.4. With probability $\\geq1-\\delta,$ for all $h\\in[H]$ and a fixed $\\pi$ wehave ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widehat{g}_{h}^{\\pi}-\\mathbf{E}_{h-1}^{D,\\widehat{\\rho}^{\\pi}}(\\nabla\\log\\widetilde{\\pi}_{h-1}+\\widehat{g}_{h-1}^{\\pi})\\right|\\right|_{1,\\widehat{d}_{h}^{\\pi}}\\leq\\sqrt{2\\left(1+C_{h-1}^{\\mathrm{s}}\\varepsilon_{h-1}^{\\mathrm{mle}}\\right)}\\varepsilon_{h}^{\\mathrm{reg}}+2h G\\left(2C_{h-1}^{\\mathrm{s}}\\varepsilon_{h-1}^{\\mathrm{mle}}+\\varepsilon_{h-1}^{\\mathrm{w}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{f_{h}^{\\pi}(s^{\\prime})\\,=\\,\\sum_{s,a}P(s^{\\prime}|s,a)\\widehat\\rho^{\\pi}(s,a)d_{h-1}^{D}(s)\\pi^{D}(a|s)}\\end{array}$ be the data distribution reweighted by $\\widehat{\\rho}^{\\pi}$ . For short, we use $y_{h}^{\\pi,p}=[\\mathbf{E}_{h-1}^{D,\\widehat{\\rho}^{\\pi}}(\\nabla\\log\\widetilde{\\pi}_{h-1}+\\widehat{g}_{h-1}^{\\pi})]^{p}$ . For any $p\\in[{\\mathsf{p}}]$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{1,\\widetilde{d}_{h}^{\\pi}}\\le\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{1,f_{h}^{\\pi}}+\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{\\infty}\\cdot\\left\\|f_{h}^{\\pi}-\\widetilde{d}_{h}^{\\pi}\\right\\|_{1}}\\\\ {\\le\\left\\|\\sqrt{f_{h}^{\\pi}}\\right\\|_{2}\\cdot\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{2,f_{h}^{\\pi}}+2h G\\left\\|f_{h}^{\\pi}-\\widetilde{d}_{h}^{\\pi}\\right\\|_{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where in the second line we use Cauchy-Schwarz on the first term and Lem. C.2 on the second term. Consider the first term. One can loosely bound ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\sqrt{f_{h}^{\\pi}}\\right\\|_{2}^{2}=\\displaystyle\\sum_{s,a,s^{\\prime}}P(s^{\\prime}|s,a)\\widehat{\\rho}_{h-1}^{\\pi}(s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s)}\\\\ &{\\qquad\\qquad\\leq C_{h-1}^{\\mathtt{s}}\\displaystyle\\sum_{s,a,s^{\\prime}}P(s^{\\prime}|s,a)\\widetilde{\\pi}_{h-1}(a|s)d_{h-1}^{D}(s)\\leq C_{h-1}^{\\mathtt{s}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "or a get a tighter result with ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\sqrt{f_{h}^{\\pi}}\\right\\|_{2}^{2}=\\displaystyle\\sum_{s,a,s^{\\prime}}P(s^{\\prime}|s,a)\\widehat{\\rho}_{h-1}^{\\pi}(s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s)}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{s,a,s^{\\prime}}P(s^{\\prime}|s,a)\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi}(s),C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}(s)\\right)}{\\widehat{d}_{h-1}^{D}(s)}\\widetilde{\\pi}_{h-1}(a|s)\\left(d_{h-1}^{D}(s)-\\widehat{d}_{h-1}^{D}(s)\\right)}\\\\ &{\\qquad\\quad+\\displaystyle\\sum_{s,a,s^{\\prime}}P(s^{\\prime}|s,a)\\widetilde{\\pi}_{h-1}(a|s)\\sigma\\left(\\widehat{d}_{h-1}^{\\pi}(s),C_{h-1}^{\\mathtt{s}}d_{h-1}^{D}(s)\\right)}\\\\ &{\\qquad\\qquad\\leq C_{h-1}^{\\mathtt{s}}\\left\\|d_{h-1}^{D}-\\widehat{d}_{h-1}^{D}\\right\\|_{1}+1}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Next we bound $\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{2,f_{h}^{\\pi}}.$ Define ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathcal{L}_{h-1}^{p}(g;y,\\rho)=\\widehat{\\mathbb{E}}_{(s,a,s^{\\prime})\\sim\\mathcal{D}_{h-1}}\\left[\\rho(s,a)\\left(g^{p}(s^{\\prime})-(\\nabla\\log\\widetilde{\\pi}_{h-1}(a|s)+y^{p}(s))\\right)^{2}\\right]\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "to be the $p$ -th parameter version of Eq. (10). Recall the regression target $\\widehat{y}_{h-1}^{\\pi}$ , then we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widehat{g}_{h}^{\\pi,p}-y_{h}^{\\pi,p}\\|_{2,f_{h}^{\\pi}}^{2}=\\mathbb{E}\\left[\\mathcal{L}_{h-1}^{p}(\\widehat{g}_{h}^{\\pi};\\widehat{y}_{h-1}^{\\pi},\\widehat{\\rho}_{h-1}^{\\pi})\\right]-\\mathbb{E}\\left[\\mathcal{L}_{h-1}^{p}(y_{h}^{\\pi};\\widehat{y}_{h-1}^{\\pi},\\widehat{\\rho}_{h-1}^{\\pi})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq2\\left(\\mathcal{L}_{h-1}^{p}(\\widehat{g}_{h}^{\\pi};\\widehat{y}_{h-1}^{\\pi},\\widehat{\\rho}_{h-1}^{\\pi})-\\mathcal{L}_{h-1}^{p}(y_{h}^{\\pi};\\widehat{y}_{h-1}^{\\pi},\\widehat{\\rho}_{h-1}^{\\pi})\\right)+2\\varepsilon_{h}^{\\mathrm{reg}}\\quad\\mathrm{(Lem.~F.2)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\|\\hat{y}_{h}^{p}-y_{h}^{p}\\|_{1,\\tilde{d}_{h}^{\\pi}}\\le\\sqrt{2\\left(1+C_{h-1}^{\\mathrm{s}}\\left\\|d_{h-1}^{D}-\\hat{d}_{h-1}^{D}\\right\\|_{1}\\right)\\varepsilon_{h}^{\\mathrm{reg}}}+2h G\\left\\|f_{h}^{\\pi}-\\widetilde{d}_{h}^{\\pi}\\right\\|_{1}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Plugging in the bound from Lem. C.5 for $\\|f_{h}^{\\pi}-\\widetilde d_{h}^{\\pi}\\|_{1}$ gives the result. ", "page_idx": 29}, {"type": "text", "text": "Lemma C.5. For any $\\pi$ and estimates $\\{\\widehat{d}_{h}^{\\pi}\\},\\{\\widehat{d}_{h}^{D}\\}$ let $\\widehat{\\rho}^{\\pi}$ be defined as in Alg. 2, and for any $h\\in[H]$ and $s^{\\prime}\\in\\mathcal{S}$ define ", "page_idx": 29}, {"type": "equation", "text": "$$\nf_{h}^{\\pi}(s^{\\prime}):=\\sum_{s,a}P(s^{\\prime}|s,a){\\widehat{\\rho}}^{\\pi}(s,a)\\pi_{h-1}^{D}(a|s)d_{h-1}^{D}(s),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "to be the next-state marginal distribution induced by reweighting $d^{D}$ with ${\\hat{\\rho}}.$ Wehave ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\left\\|f_{h}^{\\pi}-\\widetilde{d}^{\\pi}\\right\\|_{1}\\le2C_{h-1}^{\\mathrm{s}}\\left\\|\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\right\\|_{1}+\\left\\|\\widehat{d}_{h-1}^{\\pi}-\\widetilde{d}_{h-1}^{\\pi}\\right\\|_{1}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. Using the definition of $\\widehat{\\rho}^{\\pi}$ we first rewrite f\u03c0(s) $\\begin{array}{r}{\\sum_{s,a}P(s^{\\prime}|s,a)\\widetilde{\\pi}_{h-1}(a|s)\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi}(s),C_{h-1}^{s}\\widehat{d}_{h-1}^{D}(s)\\right)}{\\widehat{d}_{h-1}^{D}(s)}d_{h-1}^{D}(s)}\\end{array}$ Thn ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\boldsymbol{J}_{h}^{\\texttt{n}}-\\boldsymbol{d}_{h}^{\\texttt{n}}\\right\\|_{1}}\\\\ &{\\leq\\left\\|\\frac{\\sigma\\left(\\hat{d}_{h-1}^{\\pi},C_{h-1}^{\\texttt{s}}\\hat{d}_{h-1}^{D}\\right)}{\\hat{d}_{h-1}^{D}}d_{h-1}^{D}-\\sigma\\left(\\tilde{d}_{h-1}^{\\pi},C_{h-1}^{\\texttt{s}}d_{h-1}^{D}\\right)\\right\\|_{1}}\\\\ &{\\leq\\left\\|\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\texttt{s}}\\hat{d}_{h-1}^{D}\\right)}{\\hat{d}_{h-1}^{D}}\\left(\\hat{d}_{h-1}^{D}-d_{h-1}^{D}\\right)\\right\\|_{1}+\\left\\|\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\texttt{s}}\\hat{d}_{h-1}^{D}\\right)-\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\texttt{s}}d_{h-1}^{D}\\right)\\right\\|}\\\\ &{\\leq2C_{h-1}^{\\texttt{s}}\\left\\|\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\right\\|_{1}+\\left\\|\\widehat{d}_{h-1}^{\\pi}-\\widetilde{d}_{h-1}^{\\pi}\\right\\|_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where in the last inequality we use Asm. 4.1 to bound the second term. ", "page_idx": 29}, {"type": "text", "text": "C.4  Local convergence of OFF-OccUPG ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We demonstrate that OFF-OcCUPG can converge to a $\\varepsilon,$ -stationary point. In order to establish this result, we will need the guarantee in Thm. 4.1 to hold for all possible policies, i.e., $\\|\\widehat{\\nabla}\\widetilde{J}(\\pi)-$ $\\nabla\\widetilde{J}(\\pi)\\|\\,\\le\\,\\varepsilon$ for all $\\pi~\\in~\\Pi_{\\Theta}$ . This is because the fixed offine data is reused throughout the algorithm, which introduces additional correlations between iterations. In the online setting it was sufficient to simply union bound over iterations, and not functions in our function classes, because we drew fresh trajectories for each policy iterate. ", "page_idx": 29}, {"type": "text", "text": "Since $\\mathcal{G}$ and $\\Pi_{\\Theta}$ are continuous function classes, we will start our result in terms of their covering numbers, defined below. We handle this in the simplest manner by using $\\ell_{\\infty}$ coverings, and leave a more refined analysis to future work. Def. C.1 is a covering on the clipped policy ratio over $\\pi^{D}$ For example, the direct policy parameterization with $\\pi_{\\theta}=\\theta$ has $N_{\\infty}^{D}(\\gamma,\\hat{\\Pi_{\\Theta}})\\stackrel{.}{\\leq}(\\operatorname*{max}_{h}C_{h}^{\\mathbf{a}}/\\gamma)^{H S A}$ (Lem. C.10). In the below definition, we overload the definition of $\\overline{{\\pi}}$ (the clipped policy in Lem. 4.1) temporarily. ", "page_idx": 29}, {"type": "text", "text": "Definition C.1 (Policy ratio $\\gamma.$ -cover). Let $\\overline{{\\Pi}}_{\\Theta}$ be an $\\ell_{\\infty}$ covering of $\\Pi_{\\Theta}$ such that for any $\\pi\\in\\Pi_{\\Theta}$ there exists $\\overline{{\\pi}}\\in\\overline{{\\Pi}}_{\\Theta}$ with $\\begin{array}{r}{\\|\\frac{\\sigma\\left(\\pi,C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\right)}{\\pi_{h}^{D}}-\\frac{\\sigma\\left(\\overline{{\\pi}}_{h},C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\right)}{\\pi_{h}^{D}}\\|\\infty\\leq\\gamma.}\\end{array}$ (C\u2264 LetN(r,) denoteis minimm cardinality. ", "page_idx": 29}, {"type": "text", "text": "Definition C.2 (Gradient function class $\\gamma$ -cover). Denote $\\mathcal{N}_{\\infty}(\\gamma,\\mathcal{G})$ to be the $\\ell_{\\infty}$ covering number of $\\{\\mathcal{G}_{h}\\}$ with resolution $\\gamma$ ", "page_idx": 29}, {"type": "text", "text": "Next, we state the stationary convergence guarantee in terms of these function class complexities, the offline coverage coefficient determined by input clipping constants $\\{C_{h}^{\\mathbf{s}},C_{h}^{\\mathbf{a}}\\}$ ,and $L_{\\sigma}$ thatrepresents the second-order smoothness of $\\sigma$ ", "page_idx": 30}, {"type": "text", "text": "Corollary C.1. Suppose Asm. 3.2 holds. Then under the preconditions of Thm. 4.1, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t}\\mathbb{E}\\left[\\|G^{\\eta}(\\pi^{(t)},\\nabla\\widetilde{J}(\\pi^{(t)}))\\|^{2}\\right]\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "when ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{T=\\widetilde{O}\\left(\\frac{\\beta H}{\\varepsilon}\\right)}\\\\ &{n=\\widetilde{O}\\left(\\frac{\\displaystyle{\\operatorname{p}}H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)^{2}L_{\\sigma}^{2}\\log(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})\\mathcal{N}_{\\infty}^{D}(\\varepsilon,\\Pi_{\\Theta})|\\mathcal{W}||\\mathcal{F}|)}{\\varepsilon}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof of Cor. C.1 First, we invoke a union-bounded version of the ofline regression estimation guarantee in Lem. F.2. For any $\\pi$ $g:S\\to\\mathbb{R}^{\\mathsf{p}}$ , reweighting function $\\rho:S\\times A\\to\\mathbb{R_{+}}$ , and target function $y:S\\to\\mathbb{R}^{\\mathsf{p}}$ , define the $p$ -th parameter squared loss for a fixed policy to be ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)=\\widehat{\\mathbb{E}}_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h}}\\left[\\left(g^{p}(s^{\\prime})-\\left(\\nabla^{p}\\log\\widetilde{\\pi}_{h}(a|s)+y^{p}(s)\\right)\\right)^{2}\\right)\\right]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then from Lem. F.3, With probability at least $1-\\delta^{\\prime}$ ,for all $h\\in[H],p\\in[\\mathsf{p}],\\,g\\in\\mathcal{G}_{h+1},$ and $\\rho,y$ inducedby $\\mathcal{F},\\mathcal{W}$ (see preconditions of Lem. F.3 for more exact statement), we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)]-\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)\\bigr|}\\\\ &{\\qquad\\leq\\frac{1}{2}\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)]+(\\varepsilon_{h+1}^{\\mathrm{reg}})^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{g_{h+1}^{*}=\\mathbf{E}_{h}^{D,\\rho}[\\nabla\\log\\widetilde{\\pi}_{h}+y_{h}]\\;\\mathrm{and}\\;\\varepsilon_{h}^{\\mathrm{reg}}=O\\left(\\sqrt{\\frac{C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\log(N_{\\infty}(n^{-1},\\mathcal{G}))p H|{W_{h}}||\\mathcal{F}_{h}|/\\delta^{\\prime})}{n}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "To complete the regression part of the analysis we need to take a union bound over the result in Lem. F.3 for all $\\pi\\,\\in\\Pi_{\\Theta}$ . For any $\\pi\\in\\Pi_{\\Theta}$ , let $\\overline{{\\pi}}\\in\\overline{{\\Pi}}_{\\Theta}$ of Def. C.1 be its $\\ell_{\\infty}$ cover.Weneed to boundthecoveringapproximationeror $\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\overline{{{\\pi}}},p}(g;y,\\rho)$ Consider fixed $(h,s,a,s^{\\prime})$ and fix the inputs , for which ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)[s,a,s^{\\prime}]-\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)[s,a,s^{\\prime}]}\\\\ &{=\\rho(s)\\frac{\\sigma\\left(\\pi(a|s),C_{h}^{\\pi}\\pi_{h}^{D}(a|s)\\right)}{\\pi_{h}^{D}(a|s)}\\left(g^{p}(s^{\\prime})-2(\\nabla^{p}\\log\\widetilde\\pi(a|s)+y^{p}(s))+g_{h+1}^{*,p}(s^{\\prime})\\right)\\left(g^{p}(s^{\\prime})-g_{h+1}^{*,p}(s^{\\prime})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)]-(\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho))\\right|}\\\\ &{\\le8C^{\\mathrm{s}}h^{2}G^{2}\\left\\|\\frac{\\sigma\\left(\\pi,C_{h}^{\\alpha}\\pi_{h}^{D}\\right)}{\\pi_{h}^{D}}-\\frac{\\sigma\\left(\\overline{\\pi},C_{h}^{\\alpha}\\pi_{h}^{D}\\right)}{\\pi_{h}^{D}}\\right\\|_{\\infty}+8C^{\\mathrm{s}}C^{\\mathrm{a}}h G\\operatorname*{max}_{s,a}\\|\\nabla\\log\\widetilde\\pi(a|s)-\\nabla\\log\\widetilde[\\pi](a|s)\\|_{\\infty}}\\\\ &{\\le8(C^{\\mathrm{s}}C^{\\mathrm{a}}h^{2}G^{2}+C^{\\mathrm{s}}C^{\\mathrm{a}}h G L_{\\sigma}\\beta)\\varepsilon}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we get smoothness of the gradient portion using Asm. 4.1 and Asm. 3.2. Then by setting $\\varepsilon=(8(C^{\\bullet}{\\bar{C}}^{\\mathbf{a}}h^{2}G^{2}+C^{\\mathbf{s}}C^{\\mathbf{a}}h G L_{\\sigma}^{\\bullet}\\beta))n^{-1}$ and combining the above errors with Lem. F.3, we have that with probability at least $1-\\delta$ for all $\\pi\\in\\Pi_{\\Theta}$ that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1},y_{h},\\pi)-\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1}^{*},y_{h},\\pi)]-\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1},y_{h},\\pi)-\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1}^{*},y_{h},\\pi)]}\\\\ &{\\quad\\quad\\leq\\frac{1}{2}\\mathbb{E}[\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1},y_{h},\\pi)-\\mathcal{L}_{D_{h}}^{p}(\\rho_{h},g_{h+1}^{*},y_{h},\\pi)]}\\\\ &{\\quad\\quad+\\tau\\sqrt{\\frac{C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\log(N_{\\infty}^{{D}}(n^{-1},\\Pi_{\\Theta})\\mathcal{N}_{\\infty}(n^{-1},\\mathcal{G})\\mathsf{p}H|\\mathcal{W}_{h}||\\mathcal{F}_{h}|/\\delta)}{n}}:=\\varepsilon_{h}^{\\mathrm{reg}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "for some absolute constant $c$ . The remainder of the proof is identical to the proof of Thm. 4.1 using theabove $\\varepsilon_{h}^{\\mathrm{reg}}$ Whichis then combined with Lem. G togve the resut. ", "page_idx": 30}, {"type": "text", "text": "C.5  Global convergence of OFF-OcCUPG ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We now turn our attention to analyzing gradient domination of the offine objective $\\widetilde{J}(\\pi)$ .The preconditions of our result are written in terms of the smooth-clipped analog of the pessimistic valuefunction $\\bar{Q}^{\\pi}$ (Prop. 4.1), induced by the smooth-clipped occupancy gradient $\\nabla\\widetilde{d}^{\\pi}$ .For each $(h,s,a)$ ,define ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{Q}_{h}^{\\pi}(s,a):=\\left.\\partial_{x}\\sigma\\left(\\pi(a|s),C_{h}^{\\mathbf{a}}\\pi_{h}^{D}(a|s)\\right)\\sum_{s^{\\prime}}P(s^{\\prime}|s,a)\\Big(R(s^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad+\\ \\partial_{x}\\sigma\\left(\\widetilde{d}_{h+1}^{\\pi}(s^{\\prime}),C_{h+1}^{\\mathbf{s}}d_{h+1}^{D}(s^{\\prime})\\right)\\ \\widetilde{Q}_{h+1}^{\\pi}(s^{\\prime},\\widetilde{\\pi}_{h+1})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Lem. C.6 shows that the optimality gap of a policy for the smooth-clipped objective $\\widetilde{J}(\\pi)$ isbounded by a measure of its gradient magnitude, as well as a coverage coefficient. This is because our trick with exploratory $\\mu$ in Lem. 3.2 isn't applicable, as it is not covered by the data in $\\mathcal{D}_{0}$ supported on $S^{0}$ . Without this, our offline gradient domination guarantee in Lem. C.6 has a coverage coefficient that resembles the first inequality of Lem. B.3 when $\\mu=d_{0}$ , the original initial state distribution. ", "page_idx": 31}, {"type": "text", "text": "Lemma C.6. For any $\\pi$ and $\\pi^{\\prime}$ , define $\\begin{array}{r}{\\widetilde B^{\\pi}(\\pi^{\\prime})\\;:=\\;\\sum_{h,s,a}\\widetilde d_{h}^{\\pi}(s)\\widetilde\\pi^{\\prime}(a|s)\\widetilde Q_{h}^{\\pi}(s,a)}\\end{array}$ \uff1aSuppose that $\\forall\\pi\\in\\Pi_{\\Theta}$ \uff0c ", "page_idx": 31}, {"type": "text", "text": "1. (Policy completeness) There exists $\\pi^{+}\\in\\Pi_{\\Theta}$ such that $\\pi^{+}\\in\\mathrm{argmax}_{\\pi^{\\prime}}\\,\\widetilde{B}^{\\pi}(\\pi^{\\prime})$   \n2. (Gradient domination) $\\begin{array}{r}{\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi\\Theta}\\widetilde{B}^{\\pi}(\\pi^{\\prime})-\\widetilde{B}^{\\pi}(\\pi)\\le m\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\Big\\langle\\nabla\\widetilde{B}^{\\pi}(\\pi),\\theta^{\\prime}-\\theta\\Big\\rangle.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Then for any comparator policy $\\pi^{E}$ and $\\pi_{\\theta}\\in\\Pi_{\\Theta}$ ,wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\widetilde{J}(\\pi^{E})-\\widetilde{J}(\\pi_{\\theta})\\leq m\\left(\\operatorname*{max}_{h}\\left\\|\\frac{\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{E}},C_{h}^{\\mathrm{s}}d_{h}^{D}\\right)}{\\sigma\\left(\\widetilde{d}_{h}^{\\pi_{\\theta}},C_{h}^{\\mathrm{s}}d_{h}^{D}\\right)}\\right\\|_{\\infty}\\right)\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\;\\langle\\nabla\\widetilde{J}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\rangle.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Compared to Lem. 3.2, the first precondition of Lem. C.6 may be stronger because $\\pi^{+}$ canbe a stochastic policy, whereas deterministic policies suffice in the online setting. The second precondition is of similar strength. More importantly\u2014as we have previously discussed\u2014\u2014 coverage coefficients of the form in Lem. C.6 are not ideal because they involve $\\pi_{\\theta}$ in the denominator, which are variable over the learning process. ", "page_idx": 31}, {"type": "text", "text": "Offline data as an exploratory initialization Since all occupancies are clipped to some constant of the ofine data, however, we might wonder if the offine data distribution itself might serve as an exploratory initial distribution to use with OFF-OcCUPG (in some sense, this, or some reweighted version of it, is the only thing available to us in the offline setting). Prop. C.2 shows that this is indeed possible when the offline data is exploratory enough, and we use clipping for simplicity. Notably, the coverage coefficient present in the gradient domination bound is the input clipping constant $\\sum_{h}C_{h}^{\\bf s}$ This can be seen as an ofline analog of $\\mathcal{C}^{\\pi^{*}}$ in Lem. 3.2, since all occupancies are clipped to have this ratio over the offline data. ", "page_idx": 31}, {"type": "text", "text": "Proposition C.2. Given $\\{d_{h}^{D}\\}$ defne anew da disribuion where $\\begin{array}{r}{d_{h}^{D^{\\prime}}=\\frac{1}{H}\\sum_{g=0}^{H-1}d_{g}^{D}}\\end{array}$ \uff0c $\\forall h\\in[H]$ Then for any $\\pi$ use $\\{d_{h}^{D^{\\prime}}\\}$ \uff0c $\\sigma=\\wedge,$ and clipping constants $\\{C_{h}^{\\mathbf{s}^{\\prime}},C_{h}^{\\mathbf{a}^{\\prime}}\\}$ to define $[\\widetilde{d_{h}^{\\pi}}]^{\\prime}$ according to Def. 4.3. Let $\\begin{array}{r}{\\widetilde{J}^{\\prime}(\\pi)=\\sum_{h}\\langle[\\widetilde{d}_{h}^{\\pi}]^{\\prime},R\\rangle}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "For any $\\pi$ and $\\pi^{\\prime}$ , recall $\\begin{array}{r}{\\widetilde B^{\\pi}(\\pi^{\\prime}):=\\sum_{h,s,a}[\\widetilde d_{h}^{\\pi}]^{\\prime}(s)\\widetilde\\pi^{\\prime}(a|s)[\\widetilde Q^{\\pi}]_{h}^{\\prime}(s,a)}\\end{array}$ . Ssuppose that $\\forall\\pi\\in\\Pi_{\\Theta}$ ", "page_idx": 31}, {"type": "text", "text": "1.(Policy completeness)Therexists $\\pi^{+}\\in\\Pi_{\\Theta}$ Suchthat $\\pi^{+}\\in\\mathrm{argmax}_{\\pi^{\\prime}}\\,\\widetilde{B}^{\\pi}(\\pi^{\\prime})$   \n2.(Gradient domination) $\\begin{array}{r}{\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\Theta}}\\widetilde{B}^{\\pi}(\\pi^{\\prime})-\\widetilde{B}^{\\pi}(\\pi)\\le m\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\Big\\langle\\nabla\\widetilde{B}^{\\pi}(\\pi),\\theta^{\\prime}-\\theta\\Big\\rangle.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Then if $\\{C_{h}^{\\mathbf{s}^{\\prime}},C_{h}^{\\mathbf{a}^{\\prime}}\\}$ are such that $[\\widetilde{d}_{h}^{\\pi_{\\theta}}]^{\\prime}\\le C_{h}^{\\mathbf{s}^{\\prime}}d_{h}^{D^{\\prime}}$ \uff0c $\\forall h$ for any $\\pi_{\\theta}\\in\\Pi_{\\Theta}$ we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi}\\widetilde{J}(\\pi)-\\widetilde{J}(\\pi_{\\theta})\\leq m H\\left(\\sum_{h}C_{h}^{\\mathrm{s}}\\right)\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\langle\\nabla\\widetilde{J}^{\\prime}(\\pi_{\\theta}),\\theta^{\\prime}-\\theta\\rangle.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "In practice, we can easily generate a new dataset $\\mathcal{D}^{\\prime}$ satisfying Prop. C.2 by first splitting each $\\mathcal{D}_{h}$ into $H$ equal parts $\\{\\dot{\\mathcal{D}}_{h}^{i}\\,\\overline{{\\}}_{i=1}^{H}$ ,then stting $\\mathcal{D}_{h}^{\\prime}=\\cup_{g=1}^{H}\\mathcal{D}_{g}^{\\tilde{h}}$ The sample complexityof running Alg. 2 on $\\mathcal{D}^{\\prime}$ will then scale with $\\sum_{h}C_{h}^{\\bf s}$ , which are input parameters, instead of the coefficient in Lem. C.6, which is $\\theta$ -dependent and cannot be controlled. In exchange, it requires all-policy coverage w.r.t the new $[\\widetilde{d}^{\\pi}]^{\\prime}$ , which, while strong, was insufcient for optimality in Lem. C.6. One justification (formalized in the hardness result of Prop. C.3) is that the exploratory initialization can cause policies to exceed coverage thresholds on reward-generating states, despite being covered on (the original) $d_{0}$ . Clipping causes gradient signals to vanish, so a stationary policy might be far off-support,instead of optimal. While everything works out conceptually if $\\{C_{h}^{\\mathbf{s}},C_{h}^{\\mathbf{a}}\\}$ are set to be high enough, it's unclear whether doing this will require exponentially large coefficients in the worst case. ", "page_idx": 32}, {"type": "text", "text": "Lastly, we combine the above gradient domination claims with the stationary convergence guarantee in Cor. C.1 to state the following global convergence result. Cor. C.2 is stated for $\\bar{J}(\\pi)$ , our original offine optimization objective, and therefore takes into the account of approximating the clipping function with its smooth-clipped version. ", "page_idx": 32}, {"type": "text", "text": "Corollary C.2. Suppose $\\widetilde{J}(\\pi)$ satisfies Asm. 3.2. If Alg. 2_with $\\mathcal{D}^{\\prime}$ as defined in Prop._ C.2 satisfies the preconditions of Prop. C.2, then set $\\begin{array}{r}{\\mathrm{CC}\\;=\\;\\overbar{H}\\sum_{h}C_{h}^{\\bf s}}\\end{array}$ Otherwise, define $\\mathrm{CC}\\,=$ $\\begin{array}{r}{\\operatorname*{max}_{\\pi\\in\\Pi_{\\Theta}}\\operatorname*{max}_{h}\\left\\|\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{*}},C_{h}^{\\mathrm{s}}d_{h}^{D}\\right)/\\sigma\\left(\\widetilde{d}_{h}^{\\pi},C_{h}^{\\mathrm{s}}d_{h}^{D}\\right)\\right\\|_{\\infty}}\\end{array}$ and assume the preconditions of Lem. C.6. Then under Def. C.1 and the preconditions of Thm. 4.1, Alg. 2 satisfies ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t}\\left\\{\\operatorname*{max}_{\\pi}\\bar{J}(\\pi)-\\bar{J}(\\pi^{(t)})\\right\\}\\right]\\leq\\varepsilon+2H^{2}D_{\\sigma}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "when $\\begin{array}{r}{T=\\,\\widetilde{O}\\left(\\frac{B^{2}m^{2}(\\operatorname{CC})^{2}\\beta H}{\\varepsilon^{2}}\\right)}\\end{array}$ and ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{n=\\;\\widetilde{O}\\left(\\frac{B^{2}m^{2}(\\mathrm{CC})^{2}\\mathsf{p}H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)^{2}L_{\\sigma}^{2}\\log(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})\\,\\mathcal{N}_{\\infty}^{D}(\\varepsilon,\\Pi_{\\Theta})|\\mathcal{F}||\\mathcal{W}|)}{\\varepsilon^{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Though we optimize $\\widetilde{J}(\\pi)$ , the guarantee in Cor. C.2 is with respect to our target offline objective $\\bar{J}(\\pi)$ , which implies that the learned policy competes with the best policy fully covered by offline data. Generally $L_{\\sigma}$ and $D_{\\sigma}$ trade-off between ease of convergence (smoothness) and approximation error, respectively. For example, instantiating the bound with $\\sigma$ from Prop. 4.3 with $b\\propto\\varepsilon$ results in a final $\\bar{\\varepsilon^{-1/4}}$ rate. ", "page_idx": 32}, {"type": "text", "text": "C.6 Proofs for App. C.5 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof of Lem. C.6 We will use superscript $h$ to refer to $s^{h}\\,\\in\\,{\\cal S}^{h}$ , the set of states visitable at timestep $h$ , and drop $C_{h}^{\\bf s}$ below to reduce clutter. By the performance difference upper bound for the smooth-clipped objective in Lem. C.8, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{J}(\\pi^{*})-\\widetilde{J}(\\pi_{\\theta})\\leq\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s,a}\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{*}}(s),d_{h}^{D}(s)\\right)\\left(\\widetilde{\\pi}^{*}(a|s)-\\widetilde{\\pi}_{\\theta}(a|s)\\right)\\widetilde{Q}_{h}^{\\pi_{\\theta}}(s,a)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s^{h},a^{h}}\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{*}}(s^{h}),d_{h}^{D}(s^{h})\\right)\\left(\\widetilde{\\pi}^{*}(a^{h}|s^{h})-\\widetilde{\\pi}_{\\theta}(a^{h}|s^{h})\\right)\\widetilde{Q}_{h}^{\\pi_{\\theta}}(s^{h},a^{h})}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "since $d_{h}^{D}(s)\\ \\ >\\ \\ 0$ only if $s\\quad\\in\\quad{\\cal S}^{h}$ .Now define $\\pi^{+}$ such that for any $\\begin{array}{r l}{s,\\ \\ \\widetilde{\\pi}^{+}(\\cdot|s)}&{{}=}\\end{array}$ $\\operatorname{argmax}_{\\pi\\in\\Delta(A)}\\left\\langle{\\widetilde{\\pi}},{\\widetilde{Q}}_{h}^{\\pi_{\\theta}}(s,\\cdot)\\right\\rangle$ Then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{J}(\\pi^{E})-\\widetilde{J}(\\pi_{\\theta})}\\\\ &{\\le\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s^{h},a^{h}}\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{E}}(s^{h}),d_{h}^{D}(s^{h})\\right)\\left(\\widetilde{\\pi}^{E}(a^{h}|s^{h})-\\widetilde{\\pi}_{\\theta}(a^{h}|s^{h})\\right)\\widetilde{Q}_{h}^{\\pi_{\\theta}}(s^{h},a^{h})}\\\\ &{\\le\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s^{h},a^{h}}\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{E}}(s^{h}),d_{h}^{D}(s^{h})\\right)\\left(\\widetilde{\\pi}^{+}(a^{h}|s^{h})-\\widetilde{\\pi}_{\\theta}(a^{h}|s^{h})\\right)\\widetilde{Q}_{h}^{\\pi_{\\theta}}(s^{h},a^{h})}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\underset{h}{\\operatorname*{max}}\\left\\|\\frac{e^{-\\left(\\widehat{H_{h}^{e}}\\cdot C_{h}^{h}\\widehat{H}_{h}^{D}\\right)}}{\\sigma\\left(\\widehat{H_{h}^{e}},C_{h}^{h}\\widehat{H}_{h}^{D}\\right)}\\right\\|\\underset{\\infty}{\\sum}\\underset{h=0}{\\sum}\\sigma\\left(\\widehat{H_{h}^{e}}(s^{h}),d_{h}^{D}(s^{h})\\right)\\left(\\pi^{+}(a^{h}|s^{h})-\\pi_{\\theta}(a^{h}|s^{h})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\frac{\\mathbf{i}}{\\mathbf{i}}\\left(\\pi_{\\theta}(a^{h}|s^{h}),C_{h}^{\\pi}\\pi^{D}(a^{h}|s^{h})\\right)\\widehat{Q}_{h}^{\\pi^{e}}(s^{h},c)}\\\\ &{\\leq\\underset{h}{\\operatorname*{max}}{\\operatorname*{max}}\\left\\|\\frac{e^{\\left(\\widehat{H_{h}^{e}}\\cdot C_{h}^{h}d_{h}^{D}\\right)}}{\\sigma\\left(\\widehat{H_{h}^{e}},C_{h}^{h}d_{h}^{D}\\right)}\\right\\|\\underset{\\infty}{\\sum}\\underset{h=0}{\\overset{H-1}{\\sum}}\\sigma\\left(\\widehat{H_{h}^{e}}(s^{h}),d_{h}^{D}(s^{h})\\right)\\left(\\widehat{\\pi}^{+}(a^{h}|s^{h})-\\widetilde{\\pi}_{\\theta}(a^{h}|s^{h})\\right)\\widehat{Q}_{h}^{\\pi^{e}}(s^{h},\\widehat{H}_{h}^{\\pi})}\\\\ &{=\\underset{h}{\\operatorname*{max}}\\left\\|\\frac{e^{\\left(\\widehat{H_{h}^{e}}\\cdot C_{h}^{h}d_{h}^{D}\\right)}}{\\sigma\\left(\\widehat{H_{h}^{e}},C_{h}^{h}d_{h}^{D}\\right)}\\right\\|\\underset{\\infty}{\\longrightarrow}\\frac{\\operatorname*{max}}{\\varepsilon^{+}}\\left(\\widehat{B}^{\\pi^{+}}(\\pi_{\\theta})-\\widehat{B}^{\\pi}(\\pi_{\\theta})\\right)}\\\\ &{=\\underset{h}{\\operatorname*{max}}\\left\\|\\frac{e^{\\left(\\widehat{H_{h}^{e}}\\cdot C_{h}^{h}d_{h}^{D}\\right\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof of Prop. C.2 Under all-policy coverage, we can apply the result in Lem. 3.2, noting that $\\begin{array}{r}{d_{0}^{\\prime}=\\frac{1}{H}d_{h}^{D}}\\end{array}$ ,and $d_{h}^{\\pi^{*}}\\leq C_{h}^{\\mathbf{s}}d_{h}^{D}$ ", "page_idx": 33}, {"type": "image", "img_path": "Nq8enbbaP2/tmp/a16679c961c3cb6bdccc58cd8b75189d7771043c73b08d4c6a0b70ab0ff76697.jpg", "img_caption": ["Figure 3: Example in Prop. C.3 "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Proposition C.3 (Vanishing gradient from clipping with exploratory data). Consider the MDP in App. C.6, and the data distribution where $d^{D}(\\hat{X})=1/2$ and $\\stackrel{\\triangledown}{d}^{D}(Y)\\stackrel{\\triangledown}{=}\\epsilon$ and $d^{D}(Z)=(1\\!-\\!\\epsilon)/2$ for some $\\epsilon\\in[0,1]$ For any $C$ we have all-policy coverage, i.e., $d_{h}^{\\pi}\\leq C_{h}d_{h}^{D}$ for all $h$ and all policies $\\pi$ . Let $\\pi$ be the stationary (and in this case, optimal) policy of running Alg. 2 with $\\mathcal{D}^{\\prime}$ described in Prop. C.2. Then ", "page_idx": 33}, {"type": "equation", "text": "$$\nJ(\\pi^{*})-J(\\pi)=(1-\\epsilon)\\left(1-2C_{Y}\\epsilon\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "If e is exponentially small, $J(\\pi^{*})-J(\\pi)=O(1)$ unless $C_{Y}$ is exponentially large. ", "page_idx": 33}, {"type": "text", "text": "Proof. The example boils down to a simple bandit problem of choosing either $L$ or $R$ in state $X$ C8 = 2Cye, and \u03c0(R|X) = 1 - \u03c0(L|X). In compariso, \\*(L|X) = 1. Then d) + e(1 - T(L|x). In comparison, J(\u03c0\\*) = 1, so ", "page_idx": 33}, {"type": "equation", "text": "$$\nJ(\\pi^{*})-J(\\pi)=(1-\\epsilon)\\left(1-2C_{Y}\\epsilon\\right)\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "For reasonable choices of $C_{Z}$ (say, 2 or 3), $C_{Y}$ must be proportional to $\\epsilon^{-1}$ for the suboptimality gap to shrink, and in particular if $\\epsilon$ is exponentially small then $C_{Y}$ must be exponentially large, which blows up the RHS of the bound. \u53e3 ", "page_idx": 33}, {"type": "text", "text": "Proof of Cor. C.2  The first step follows the proof of Cor. 3.2. Combining Thm. 4.1 with Lem. G.5 and plugging in above, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t}\\widetilde{J}(\\pi^{*})-\\widetilde{J}(\\pi^{(t)})\\right]}\\\\ {\\displaystyle\\lesssim B m\\mathrm{CC}\\left(\\sqrt{\\frac{\\beta H}{T}}+\\sqrt{\\frac{\\mathsf{p}H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)^{2}L_{\\sigma}^{2}\\log(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})\\,\\mathcal{N}_{\\infty}^{D}(\\varepsilon,\\Pi_{\\Theta})|\\mathcal{F}||\\mathcal{W}|)}{n}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Then we also have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\frac{1}{T}\\sum_{t}\\bar{J}(\\pi^{*})-\\bar{J}(\\pi^{(t)})\\right]}\\\\ &{\\leq\\mathbb{E}\\left[\\displaystyle\\frac{1}{T}\\sum_{t}\\tilde{J}(\\pi^{*})-\\tilde{J}(\\pi^{(t)})\\right]+2H^{2}D_{\\sigma}}\\\\ &{\\lesssim2H^{2}D_{\\sigma}+B m\\mathrm{CC}\\left(\\sqrt{\\frac{\\beta H}{T}}+\\sqrt{\\frac{\\ p H^{6}G^{2}\\left(\\sum_{h}C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}\\right)^{2}L_{\\sigma}^{2}\\log\\left(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})\\,\\mathcal{N}_{\\infty}^{D}(\\varepsilon,\\Pi_{\\Theta})|\\mathcal{F}||\\mathcal{W}|\\right)}{n}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Additional results  Helper lemmas are stated and proved below. ", "page_idx": 34}, {"type": "text", "text": "Lemma C.7. Suppose $\\sigma$ satisfies Parts $^{\\,I}$ and 2 of Asm. 4.1. Then for $\\begin{array}{r}{\\widetilde{J}(\\pi)=\\sum_{h}\\sum_{s}\\widetilde{d}_{h}^{\\pi}(s)R_{h}(s),}\\end{array}$ ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\nabla\\widetilde{J}(\\pi)=\\sum_{h=0}^{H-1}\\sum_{s,a}\\sigma\\left(\\widetilde{d}_{h}^{\\pi}(s),C_{h}^{\\mathbf{s}}d_{h}^{D}(s)\\right)\\nabla\\widetilde{\\pi}_{h}(a|s)\\widetilde{Q}_{h}^{\\pi}(s,a),\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where ", "page_idx": 34}, {"type": "equation", "text": "$$\ns,a)=\\sum_{s^{\\prime}}P_{h}(s^{\\prime}|s,a)\\left(R_{h+1}(s^{\\prime})+\\sum_{a^{\\prime}}\\widetilde{\\pi}_{h+1}(a^{\\prime}|s^{\\prime})\\,\\partial_{x}\\sigma\\left(\\widetilde{d}_{h+1}^{\\pi}(s^{\\prime}),C_{h+1}^{\\mathrm{s}}d_{h+1}^{D}(s^{\\prime})\\right)\\widetilde{Q}_{h+1}^{\\pi}(s^{\\prime},a^{\\prime})\\right).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof of Lem. C.7. For notational clarity we omit $C_{h}^{\\bf s}$ below. Expanding $\\nabla\\widetilde{d}^{\\pi}$ ,we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\widetilde{d}_{h}^{\\pi}(s_{h})=\\displaystyle\\sum_{s_{h-1},a_{h-1}}P(s_{h}|s_{h-1},a_{h-1})\\Big(\\nabla\\widetilde{\\pi}_{h-1}(a_{h-1}|s_{h-1})\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s_{h-1}),d_{h-1}^{D}(s_{h-1})\\right)}\\\\ &{\\qquad\\quad+\\left.\\widetilde{\\pi}_{h-1}(a_{h-1}|s_{h-1})\\,\\partial_{x}\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s_{h-1}),d_{h-1}^{D}(s_{h-1})\\right)\\nabla\\widetilde{d}_{h-1}^{\\pi}(s_{h-1})\\right)}\\\\ &{\\qquad=\\displaystyle\\sum_{g<h}\\sum_{(s_{h-1},a_{h-1},\\dots,s_{g},a_{g})}\\left[\\displaystyle\\prod_{t=g+1}^{h-1}P(s_{t+1}|s_{t},a_{t})\\widetilde{\\pi}_{t}(a_{t}|s_{t})\\;\\partial_{x}\\sigma\\left(\\widetilde{d}_{t}^{\\pi}(s_{t}),d_{t}^{D}(s_{t})\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\left.P(s_{g+1}|s_{g},a_{g})\\sigma\\left(\\widetilde{d}_{g}^{\\pi}(s_{g}),d_{g}^{D}(s_{g})\\right)\\nabla\\widetilde{\\pi}_{g}(a_{g}|s_{g})}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "For short, define ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{\\Xi}}^{\\tilde{\\pi}}(s_{h}|s_{g},a_{g}):=\\sum_{(s_{h-1},a_{h-1},\\ldots,s_{g+1},a_{g+1})}\\left[\\prod_{t=g+1}^{h-1}P(s_{t+1}|s_{t},a_{t})\\tilde{\\pi}_{t}(a_{t}|s_{t})\\;\\partial_{x}\\sigma\\left(\\tilde{d}_{t}^{\\pi}(s_{t}),d_{t}^{D}(s_{t})\\right)\\right]P(s_{h}|\\delta_{g},a_{g})\\;.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "observing if $\\widetilde{\\pi}_{h}=\\pi_{h}$ and $\\partial_{x}\\sigma\\left(\\widetilde{d}_{h}^{\\pi},d_{h}^{D}\\right)=1$ for all $h$ we have $\\widetilde{\\mathbf{P}}^{\\widetilde{\\pi}}(s_{h}|s_{g},a_{g})=\\mathbf{P}^{\\pi}(s_{h}|s_{g},a_{g})$ ,the standard transition kernel from $(s_{g},a_{g})\\to s_{h}$ . This occurs, for example, when $\\sigma^{\\mathbf{s}}$ is hard clipping and $\\pi$ is fully covered by data. Then using the above definition, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\nabla\\widetilde{d}_{h}^{\\pi}(s_{h})=\\sum_{g<h}\\sum_{s_{g},a_{g}}\\sigma\\left(\\widetilde{d}_{g}^{\\pi}(s_{g}),d_{g}^{D}(s_{g})\\right)\\nabla\\widetilde{\\pi}_{g}(a_{g}|s_{g})\\widetilde{\\mathbf{P}}^{\\pi}(s_{h}|s_{g},a_{g}).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Plugging this expression into $\\nabla J(\\pi)$ , we obtain ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla J(\\pi)=\\displaystyle\\sum_{h}\\sum_{s_{h}}\\nabla\\tilde{d}_{h}^{\\pi}(s_{h})R(s_{h})}\\\\ &{\\qquad=\\displaystyle\\sum_{h}\\sum_{s_{h}}\\left(\\sum_{g=0}^{h-1}\\sum_{s_{g},a_{g}}\\sigma\\left(\\tilde{d}_{g}^{\\pi}(s_{g}),d_{g}^{D}(s_{g})\\right)\\nabla\\tilde{\\pi}_{g}(a_{g}|s_{g})\\tilde{\\nabla}^{\\pi}(s_{h}|s_{g},a_{g})\\right)R(s_{h})}\\\\ &{\\qquad=\\displaystyle\\sum_{g=0}^{H-1}\\sum_{s_{g},a_{g}}\\sigma\\left(\\tilde{d}_{g}^{\\pi}(s_{g}),d_{g}^{D}(s_{g})\\right)\\nabla\\tilde{\\pi}_{g}(a_{g}|s_{g})\\left(\\sum_{h=g+1}^{H}\\sum_{s_{h}}\\tilde{\\nabla}^{\\pi}(s_{h}|s_{g},a_{g})R(s_{h})\\right)}\\\\ &{\\qquad=\\displaystyle\\sum_{g=0}^{H-1}\\sum_{s_{g},a_{g}}\\sigma\\left(\\tilde{d}_{g}^{\\pi}(s_{g}),d_{g}^{D}(s_{g})\\right)\\nabla\\tilde{\\pi}_{g}(a_{g}|s_{g})\\tilde{Q}^{\\pi}(s_{g},a_{g})}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where we have defined ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\widetilde{Q}_{g}^{\\pi}(s_{g},a_{g}):=\\sum_{h=g+1}^{H}\\sum_{s_{h}}\\widetilde{\\mathbf{P}}^{\\pi}(s_{h}|s_{g},a_{g})R(s_{h})}}\\\\ {{\\displaystyle=\\sum_{s_{g+1}}P(s_{g+1}|s_{g},a_{g})\\left(R(s_{g+1})+\\sum_{a_{g+1}}\\widetilde{\\pi}_{g+1}(a_{g+1}|s_{g+1})\\,\\partial_{x}\\sigma\\left(\\widetilde{d}_{g+1}^{\\pi}(s_{g+1}),d_{g+1}^{D}(s_{g+1})\\right)\\widetilde{Q}_{g+1}^{\\widetilde{\\pi}}(s_{g})\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma C.8. If $\\sigma$ is concave in its first argument, for any $\\pi^{\\prime}$ and $\\pi$ wehave ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\widetilde{J}(\\pi^{\\prime})-\\widetilde{J}(\\pi)\\leq\\sum_{h=0}^{H-1}\\sum_{s,a}\\sigma\\left(\\widetilde{d}_{h}^{\\pi^{\\prime}}(s),d_{h}^{D}(s)\\right)\\left(\\widetilde{\\pi}_{h}^{\\prime}(a|s)-\\widetilde{\\pi}_{h}(a|s)\\right)\\widetilde{Q}_{h}^{\\pi}(s,a),\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $\\widetilde{Q}_{h}^{\\pi}$ is defined in Lem. C.7. ", "page_idx": 35}, {"type": "text", "text": "Proof. This statement follows straightforwardly from plugging in Lem. C.9 and rearranging, similar to the proof of Lem. C.7. \u53e3 ", "page_idx": 35}, {"type": "text", "text": "Lemma C.9. If $\\sigma$ is concave in its their first arguments, then for any $h$ and $\\pi,\\pi^{\\prime}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{d_{h}^{\\prime}}^{\\prime}(s^{\\prime})-\\widetilde{d_{h}^{\\prime}}(s^{\\prime})}\\\\ &{\\le\\displaystyle\\sum_{g<h}\\sum_{s,a}\\sigma\\left(\\widetilde{d_{g}^{\\prime\\prime}}(s),d_{g}^{D}(s)\\right)\\left(\\sigma\\left(\\pi_{g}^{\\prime}(a|s),\\pi_{g}^{D}(a|s)\\right)-\\sigma\\left(\\pi_{g}(a|s),\\pi_{g}^{D}(a|s)\\right)\\right)\\widetilde{\\mathbf{P}}^{\\pi}(s_{h}=s^{\\prime}|s_{g}=s,a_{g})}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where ", "page_idx": 35}, {"type": "equation", "text": "$$\n5^{\\pi}(s_{h}|s_{g},a_{g}):=\\sum_{s_{h-1:g+1,a_{h-1:g+1}}}\\left[\\prod_{t=g+1}^{h-1}P(s_{t+1}|s_{t},a_{t})\\widetilde{\\pi}_{t}(a_{t}|s_{t})\\,\\partial_{x}\\sigma\\left(\\widetilde{d}_{t}^{\\pi}(s_{t}),d_{t}^{D}(s_{t})\\right)\\right]P(s_{g+1}|s_{g+1}).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof of Lem. C.9. Define $\\pi^{g}\\,=\\,\\{\\pi_{1}^{\\prime},\\dots,\\pi_{g-1}^{\\prime},\\pi_{g},\\dots,\\pi_{H-1}\\}$ i.e, a policy that starts playing $\\pi$ at timestep $g$ , and plays $\\pi^{\\prime}$ for the timesteps before that. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\widetilde{d}_{h}^{\\pi^{\\prime}}(s^{\\prime})-\\widetilde{d}_{h}^{\\pi}(s^{\\prime})=\\widetilde{d}_{h}^{\\pi^{\\prime}}(s^{\\prime})-\\widetilde{d}_{h}^{\\pi^{h-1}}(s^{\\prime})+\\widetilde{d}_{h}^{\\pi^{h-1}}(s^{\\prime})-\\widetilde{d}_{h}^{\\pi}(s^{\\prime})\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For the first pair of terms, $\\pi^{\\prime}$ and $\\pi^{h-1}$ only differ the policy used to take the action $a_{h-1}$ (and both play $\\pi^{\\prime}$ before that), thus $d_{h-1}^{\\pi^{\\prime}}=d_{h-1}^{\\pi^{h-1}}$ and ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{d_{h}^{\\pi^{\\prime}}}(s^{\\prime})-\\widetilde{d_{h}^{\\pi^{h-1}}}(s^{\\prime})}\\\\ &{=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\left(\\sigma\\left(\\pi_{h-1}^{\\prime}(a|s),\\pi_{h-1}^{D}(a|s)\\right)-\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\right)\\sigma\\left(\\widetilde{d_{h-1}^{\\pi^{\\prime}}}(s),d_{h-1}^{D}(s)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For the second pair of terms, $\\pi^{h-1}$ and $\\pi$ both play $\\pi$ at time $h-1$ , but the former uses $\\pi^{\\prime}$ for timesteps $1,\\ldots,h-2$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{d}_{h}^{\\pi^{h-1}}(s^{\\prime})-\\widetilde{d}_{h}^{\\pi}(s^{\\prime})}\\\\ &{=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\left(\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi^{h-1}}(s),d_{h-1}^{D}(s)\\right)-\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),d_{h-1}^{D}(s)\\right)\\right)}\\\\ &{=\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\left(\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi^{\\prime}}(s),d_{h-1}^{D}(s)\\right)-\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),d_{h-1}^{D}(s)\\right)\\right)}\\\\ &{\\le\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\left.\\partial_{x}\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi}(s),d_{h-1}^{D}(s)\\right)\\left(\\widetilde{d}_{h-1}^{\\pi^{\\prime}}(s)-\\widetilde{d}_{h-1}^{\\pi}(s)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the last inequality above uses the concavity of $\\sigma^{\\mathbf{s}}$ in the first argument (recall concave functions $f$ satisfy $f({\\bar{y}})\\leq{\\bar{f}}(x)+f^{\\prime}(x)(y-x))$ . Combining the above two inequalities, we have the recursive relationship ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{d_{h}^{\\pi^{\\prime}}}(s^{\\prime})-\\widetilde{d_{h}^{\\pi}}(s^{\\prime})}\\\\ &{\\le\\displaystyle\\sum_{s,a}P(s^{\\prime}|s,a)\\Bigg(\\left(\\sigma\\left(\\pi_{h-1}^{\\prime}(a|s),\\pi_{h-1}^{D}(a|s)\\right)-\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\right)\\sigma\\left(\\widetilde{d_{h-1}^{\\pi^{\\prime}}}(s),d_{h-1}^{D}(s)\\right)}\\\\ &{\\qquad\\qquad\\qquad+\\sigma\\left(\\pi_{h-1}(a|s),\\pi_{h-1}^{D}(a|s)\\right)\\,\\partial_{x}\\sigma\\left(\\widetilde{d_{h-1}^{\\pi}}(s),d_{h-1}^{D}(s)\\right)\\left(\\widetilde{d_{h-1}^{\\pi^{\\prime}}}(s)-\\widetilde{d_{h-1}^{\\pi}}(s)\\right)\\Bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Unrolling through timesteps gives the lemma statement. ", "page_idx": 36}, {"type": "text", "text": "Lemma C.10. Let $C^{\\mathbf{a}}\\ =\\ \\operatorname*{max}_{h}C_{h}^{\\mathbf{a}}$ Suppose $\\Pi_{\\Theta}$ is the direct policy parameterization, i.e., $\\pi_{\\theta}(a|s)\\:=\\:\\theta_{s,a},$ and $\\sigma$ is such that $D_{\\sigma}\\ \\leq\\ C^{\\mathbf{a}}$ for all $h$ Then for any $\\gamma\\ \\in\\ (0,1],$ . in Def. C.1 we have $N_{\\infty}^{D}(\\gamma,\\Pi_{\\Theta})\\leq(C^{\\mathbf{a}}/\\gamma)^{S A H}$ ", "page_idx": 36}, {"type": "text", "text": "Proof of Lem. C.10. Typical gridding-style arguments discretize the range of $\\pi(a|s)$ for each $(s,a)$ Since we are concerned with creating a cover for the policy ratio, however, a naive argument will incur $1/\\operatorname*{min}_{s,a}\\pi^{D}(a|s)$ in the grid's cardinality. Our solution is to grid $\\Pi_{\\Theta}$ adaptively according to the magnitude of $\\pi^{D}(a|s)$ . Intuitively, we only need to grid up to the threshold ", "page_idx": 36}, {"type": "text", "text": "For each $(h,s,a)$ dene the dative gridding scal t $\\gamma_{h s a}^{\\prime}=\\gamma\\pi_{h}^{D}(a|s)$ . For any $\\pi\\in\\Pi_{\\Theta}$ , set its cover $\\overline{{\\pi}}$ as follows. ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\overline{{\\pi}}_{h}(a|s)=\\left\\{\\!\\!\\left\\lfloor\\frac{\\pi(a|s)}{\\gamma_{h s a}^{\\prime}}\\right\\rfloor\\!,\\!\\!\\begin{array}{l l}{\\mathrm{if}\\ \\pi(a|s)\\le C_{h}^{\\mathbf{a}}\\pi_{h}^{D}(a|s),}\\\\ {C_{h}^{\\mathbf{a}}\\pi_{h}^{D}(a|s),}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Let $\\overline{{\\Pi}}_{\\Theta}=\\{\\overline{{\\pi}}:\\pi\\in\\Pi_{\\Theta}\\}$ . Then $\\begin{array}{r}{|\\overline{\\Pi}_{\\Theta}|\\leq(\\operatorname*{max}_{h}{C_{h}^{\\mathbf a}/\\gamma})^{H S A}}\\end{array}$ . Further, ", "page_idx": 36}, {"type": "equation", "text": "$$\n|\\big(\\pi(a|s)\\wedge C_{h}^{\\mathbf{a}}\\pi_{h}^{D}(a|s)\\big)-\\big(\\overline{{\\pi}}_{h}(a|s)\\wedge C_{h}^{\\mathbf{a}}\\pi_{h}^{D}(a|s)\\big)|\\leq\\gamma\\pi_{h}^{D}(a|s),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "$\\begin{array}{r}{\\big\\|\\frac{\\big(\\pi\\wedge C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\big)-\\big(\\overline{{\\pi}}_{h}\\wedge C_{h}^{\\mathbf{a}}\\pi_{h}^{D}\\big)}{\\pi_{h}^{D}}\\big\\|_{\\infty}\\leq\\gamma}\\end{array}$ , and applying Lem. C.11 gives the result. ", "page_idx": 36}, {"type": "text", "text": "Lemma C.11. Suppose $\\overline{{\\Pi}}_{\\Theta}$ satisfies Def. C.1 with $\\sigma x c\\,=\\,(x\\wedge c)$ .Then for any $\\pi\\ \\in\\Pi_{\\Theta}$ ,let $\\overline{{\\pi}}\\in\\overline{{\\Pi}}_{\\Theta}$ be its cover. Under Asm. 4.1, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\frac{\\sigma\\left(\\pi,C\\pi^{D}\\right)}{\\pi^{D}}-\\frac{\\sigma\\left(\\overline{{\\pi}},C\\pi^{D}\\right)}{\\pi^{D}}\\right\\|_{\\infty}\\leq C(\\gamma+D_{\\sigma}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Proof of Lem. C.11. If $\\pi(a|x)\\le C\\pi^{D}(a|x)$ , using the 1-Lipschitzness of $\\sigma$ we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\sigma\\left(\\pi(a|s),C\\pi^{D}(a|s)\\right)-\\sigma\\left(\\bar{\\pi}(a|s),C\\pi^{D}(a|s)\\right)|}\\\\ &{\\phantom{\\quad}=|\\sigma\\left(\\left(\\pi(a|s)\\wedge C\\pi^{D}(a|s)\\right),C\\pi^{D}(a|s)\\right)-\\sigma\\left(\\bar{\\pi}(a|s),C\\pi^{D}(a|s)\\right)|}\\\\ &{\\phantom{\\quad}\\leq|\\left(\\pi(a|s)\\wedge C\\pi^{D}(a|s)\\right)-\\bar{\\pi}(a|s)|}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Algorithm 4 Maximum Likelihood Estimation ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Input: datasets $\\{\\boldsymbol{D}_{h}\\}$ , function class $\\mathcal{F}$   \n1: for $h=1,\\ldots,H$ do   \n2:  Estimate marginal data distributions $\\widehat{d}_{h-1}^{D}$ and $\\widehat{d}_{h-1}^{D,\\dagger}$ by MLE on dataset $\\ensuremath{\\mathcal \u1e0a D \u1e0c }_{h-1}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{d}_{h-1}^{D}=\\underset{d_{h-1}\\in\\mathcal{F}_{h-1}}{\\operatorname{argmax}}\\frac{1}{|\\mathcal{D}_{h-1}|}\\sum_{(s,\\cdot,\\cdot)\\in\\mathcal{D}_{h-1}}\\log\\left(d_{h-1}(s)\\right)}\\\\ &{\\widehat{d}_{h-1}^{D,\\dagger}=\\underset{d_{h}\\in\\mathcal{F}_{h}}{\\operatorname{argmax}}\\frac{1}{|\\mathcal{D}_{h-1}|}\\sum_{(\\cdot,\\cdot,s^{\\prime})\\in\\mathcal{D}_{h-1}}\\log\\left(d_{h}(s^{\\prime})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "3: end for ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Output: estimated datadistributions $\\{\\widehat{d}_{h}^{D}\\}_{h\\in[H]}$ aind $\\{\\widehat{d}_{h}^{D,\\dagger}\\}_{h\\in[H]}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\leq C\\gamma\\pi^{D}(a|s).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "f $\\pi(a|x)>C\\pi^{D}(a|x)$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma\\left(\\pi(a|s),C\\pi^{D}(a|s)\\right)-\\sigma\\left(\\bar{\\pi}(a|s),C\\pi^{D}(a|s)\\right)|\\le C\\pi^{D}(a|s)-\\sigma\\left(\\bar{\\pi}(a|s),C\\pi^{D}(a|s)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le C\\pi^{D}(a|s)-(1-D_{\\sigma})\\left(\\bar{\\pi}(a|s)\\wedge C\\pi^{D}(a|s)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le C(D_{\\sigma}+\\gamma)\\pi^{D},}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "using Asm. 4.1 in the second inequality. As a result, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\frac{\\sigma\\left(\\pi(a|s),C\\pi^{D}(a|s)\\right)}{\\pi^{D}(a|s)}-\\frac{\\sigma\\left(\\overline{{\\pi}}(a|s),C\\pi^{D}(a|s)\\right)}{\\pi^{D}(a|s)}\\right|\\leq C(\\gamma+D_{\\sigma})}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "D   Maximum Likelihood Estimation ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Algorithm 4 displays the data distribution estimation procedure used in offline gradient estimation (Algorithm 2), which is a direct application of MLE. The general formulation of the MLE problem utilized in this paper is to estimate a probability distribution over the instance space $\\boldsymbol{S}$ .Given an i.i.d. sampled dataset $\\mathcal{D}=\\{s^{(i)}\\}_{i=1}^{n}$ and a function class $\\mathcal{F}$ , we optimize the MLE objective of the form ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\widehat{f}=\\operatorname*{argmin}_{f\\in\\mathcal{F}}\\frac{1}{|\\mathcal{D}|}\\sum_{s\\in\\mathcal{D}}\\log\\left(f(s)\\right).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Weassume $\\mathcal{F}$ is finite, and refer readers to [LNSJ23; HCJ23] for techniques for handling infinite function classes. The general MLE guarantee is stated below, and is a well-established result (for example, a proof can be found in Appendix E of [AKKS20]). ", "page_idx": 37}, {"type": "text", "text": "Lemma D.1 (MLE guarantee). Let $\\mathcal{D}\\,=\\,\\{s^{(i)}\\}_{i=1}^{n}$ be a dataset, where $\\mathbf{\\boldsymbol{s}}^{(i)}$ are drawn i.i.d. from some fixed probability distribution $f^{*}$ over $\\boldsymbol{S}$ .Consider afunction class $\\mathcal{F}$ that satisfies: (i) $f^{*}\\in\\mathcal{F}$ and (i) each function $f\\in\\mathcal F$ is a valid probability distribution over $\\boldsymbol{S}$ (i.e., $f\\,\\in\\,\\Delta(S),$ Thenwith probability at least $1-\\delta$ \uff0c $\\widehat{f}$ from Eq. (23) has $\\ell_{1}$ error guarantee ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\|\\widehat{f}-f^{*}\\|_{1}\\leq\\sqrt{\\frac{2\\log(|\\mathcal{F}|/\\delta)}{n}}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "The formal guarantee of Algorithm 4 is stated below, which is a straightforward application of Lemma D.1 with union bound (over all functions in $\\mathcal{F}$ , and over all timesteps). ", "page_idx": 37}, {"type": "text", "text": "AsMelabita $\\forall h\\,\\in\\,[h]$ we have $d_{h}^{D},d_{h-1}^{D,\\dagger}\\ \\in\\ \\mathcal{F}_{h}$ for $\\mathcal{D}$ defined in Def. 4.1. Additionally, $f\\in\\Delta(S)$ is a valid distribution for all $f\\in\\mathcal{F}_{h}$ ", "page_idx": 37}, {"type": "text", "text": "Algorithm 5 Fitted Occupancy Iteration with Smooth Clipping ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Input: policy $\\pi$ , datasets $\\{\\boldsymbol{D}_{h}\\}$ , function class $\\mathcal{W}$ , clipping thresholds $\\{C_{h}^{\\mathbf{s}},C_{h}^{\\mathbf{a}}\\}$ , data estimates $\\{\\widehat{d}_{h}^{D}\\}$ and $\\{\\widehat{d}_{h}^{D,\\dagger}\\}$   \n1: Initialize $\\widehat{d}_{0}^{\\pi}=\\widehat{d}_{0}^{D}$   \n2: for $h=1,\\ldots,H$ do ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathcal{D}_{h-1}}(w_{h},w_{h-1},\\widetilde{\\pi}_{h-1}):=\\frac{1}{|\\mathcal{D}_{h-1}|}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h-1}}\\Big(w_{h}(s^{\\prime})-w_{h-1}(s)\\frac{\\widetilde{\\pi}_{h-1}(a|s)}{\\pi_{h-1}^{D}(a|s)}\\Big)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{w}_{h}^{\\pi}=\\underset{w_{h}\\in\\mathcal{W}_{h}}{\\operatorname{argmin}}\\,\\mathcal{L}_{\\mathcal{D}_{h-1}}\\left(w_{h},\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)}{\\widehat{d}_{h-1}^{D}},\\sigma\\left(\\pi_{h-1},C_{h-1}^{\\mathbf{a}}\\pi_{h-1}^{D}\\right)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "$\\widehat{d_{h}^{\\pi}}=\\widehat{w}_{h}^{\\pi}\\,\\widehat{d}_{h-1}^{D,\\dagger}$ 5: end for ", "page_idx": 38}, {"type": "text", "text": "Output: estimated state occupancies $\\{\\widehat{w}_{h}^{\\pi}\\}_{h\\in[H]}$ ", "page_idx": 38}, {"type": "text", "text": "Lemma D.2. Suppose $\\{\\mathcal{F}_{h}\\}$ satisfies Asm. D.1. Then with probability at least $1-\\delta$ for all $h\\in[H]$ the outputs of Algorithm $^{4}$ satisfy $\\left\\|\\widehat{d_{h}^{D}}-d_{h}^{D}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}$ and $\\begin{array}{r}{\\left\\|\\widehat{d}_{h}^{D,\\dagger}-d_{h}^{D,\\dagger}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}}\\end{array}$ where ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\varepsilon^{\\mathrm{mle}}:=\\sqrt{\\frac{2\\log(2H|\\mathcal{F}|/\\delta)}{n}}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "E  Offline Density Estimation ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "The algorithm for offline density estimation is displayed in Alg. 5, and is directly copied from Algorithm 1 of [HCJ23], but with two minor modifications. The first is that the densities are clipped using afunction $\\sigma$ , that can take clipping as a special case. The second is that it outputs the learned weights instead of the learned densities. The weight function class completeness assumption is shown Asm. E.1, and is satisfied in low-rank MDPs using linear-over-linear function classes that have pseudo-dimension bounded by MDP rank. It can be seen as a 1-dimensional version of Asm.4.2where $\\rho=1$ and in that sense strictly weaker. ", "page_idx": 38}, {"type": "text", "text": "Assumption E.1 (Weight function completeness). For any $\\pi\\in\\Pi_{\\Theta}$ and $h\\in[H]$ wehave ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{E}_{h-1}^{D,1}\\left(\\frac{\\sigma\\left(w\\cdot f^{\\prime},C_{h-1}^{\\mathrm{s}}f\\right)}{f}\\frac{\\widetilde{\\pi}_{h-1}}{\\pi_{h-1}^{D}}\\right)\\in\\mathcal{W}_{h},\\;\\forall w\\in\\mathcal{W}_{h-1},\\;\\forall f,f^{\\prime}\\in\\mathcal{F}_{h-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Theorem E.1. Suppose $\\sigma$ satisfies Asm. 4.1 and $\\mathcal{W}$ satisfes Asm. E.1. Let $\\{\\widehat{d}_{h}^{D}\\}g$ and $\\{\\widehat{d}_{h}^{D,\\dagger}\\}$ be such that $\\forall h\\in[H]$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{d}_{h}^{D}-d_{h}^{D}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}\\quad a n d\\quad\\left\\|\\widehat{d}_{h}^{D,\\dagger}-d_{h}^{D,\\dagger}\\right\\|_{1}\\leq\\varepsilon^{\\mathrm{mle}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Then with probability at least $1-\\delta$ the outputs $\\{\\widehat{w}_{h}^{\\pi}\\}$ of Algorithm $^{5}$ satisfy for all $h\\in[H]$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\|\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\|_{1,d_{h-1}^{D,\\uparrow}}\\leq\\left(\\sum_{g<h-1}C_{g}^{\\mathrm{s}}C_{g}^{\\mathrm{a}}+2\\sum_{g<h}C_{g}^{\\mathrm{s}}\\right)\\varepsilon^{\\mathrm{mle}}+\\sqrt{2}\\left(\\sum_{g<h}C_{g}^{\\mathrm{s}}C_{g}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{wreg}},\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where $\\begin{array}{r}{\\varepsilon^{\\mathrm{wreg}}:=\\sqrt{\\frac{c\\log(H|\\mathcal{W}|/\\delta)}{n_{\\mathrm{reg}}}}}\\end{array}$ clog(Hwl) for some absolute constant c. ", "page_idx": 38}, {"type": "text", "text": "Proof of Theorem E.1 We begin by stating the following decomposition on the error of $\\widehat{w}_{h}^{\\pi}$ , which is proved at the end of this section. ", "page_idx": 38}, {"type": "text", "text": "Lemma E.1. Suppose $\\sigma$ satisfies Assumption 4.1. Then for any $h\\in[H]$ the error between $\\widehat{w}_{h}^{\\pi}$ and the target $\\widetilde{w}_{h}^{\\pi}=\\widetilde{d_{h}^{\\pi}}/d_{h-1}^{D,\\dagger}$ can be recursvely decomposed as ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\lVert\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\rVert_{1,d_{h-1}^{D,\\dagger}}\\leq\\,\\big\\|\\widehat{w}_{h-1}^{\\pi}-\\widetilde{w}_{h-1}^{\\pi}\\big\\|_{1,d_{h-2}^{D,\\dagger}}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{+\\left.2C_{h-1}^{\\mathbf{s}}\\right\\Vert\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\right\\Vert_{1}+C_{h-2}^{\\mathbf{s}}C_{h-2}^{\\mathbf{a}}\\left\\Vert\\widehat{d}_{h-2}^{D,\\dagger}-d_{h-2}^{D,\\dagger}\\right\\Vert_{1}}\\\\ &{+\\left.\\left\\Vert\\widehat{w}_{h}^{\\pi}-\\mathbf{E}_{h-1}^{\\bar{\\pi}}\\left(d_{h-1}^{D}\\,\\omega_{h-1}^{\\pi}\\right)\\right\\Vert_{2,d_{h-1}^{D,\\dagger}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where $\\begin{array}{r}{\\omega^{\\pi}:=\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathbf{s}}\\widehat{d}_{h-1}^{D}\\right)}{\\widehat{d}_{h-1}^{D}}}\\end{array}$ ", "page_idx": 39}, {"type": "text", "text": "Applying Lem. E.2 with union bound over all $h$ ,wehave ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\lVert\\widehat{w}_{h}^{\\pi}-\\mathbf{E}_{h-1}^{\\pi}\\left(d_{h-1}^{D}\\;\\omega_{h-1}^{\\pi}\\right)\\right\\rVert_{2,d_{h-1}^{D,\\uparrow}}^{2}}\\\\ &{=\\mathbb{E}\\left[\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\left(\\widehat{w}_{h}^{\\pi},\\;\\omega_{h-1}^{\\pi},\\overline{{\\pi}}\\right)\\right]-\\mathbb{E}\\left[\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\left(\\mathbf{E}_{h-1}^{\\pi}\\left(d_{h-1}^{D}\\;\\omega_{h-1}^{\\pi}\\right),\\;\\omega_{h-1}^{\\pi},\\overline{{\\pi}}\\right)\\right]}\\\\ &{\\leq2\\left(\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\left(\\widehat{w}_{h}^{\\pi},\\;\\omega_{h-1}^{\\pi},\\overline{{\\pi}}\\right)-\\mathcal{L}_{\\mathcal{D}_{h-1}^{\\mathrm{reg}}}\\left(\\mathbf{E}_{h-1}^{\\pi}\\left(d_{h-1}^{D}\\;\\omega_{h-1}^{\\pi}\\right),\\;\\omega_{h-1}^{\\pi},\\overline{{\\pi}}\\right)\\right)+2\\left(C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}\\right)^{2}\\left(\\varepsilon^{\\mathrm{wreg}}\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Then unrolling Lemma E.1, for any $h$ ,wehavefor $\\begin{array}{r}{\\varepsilon^{\\mathrm{wreg}}=\\frac{c\\log\\left(H\\left|\\mathcal{W}\\right|n/\\delta\\right)}{n_{\\mathrm{reg}}}}\\end{array}$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\|\\widehat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\|_{1,d_{h-1}^{D,\\uparrow}}\\leq\\;\\left(\\sum_{g<h-1}C_{g}^{\\mathrm{s}}C_{g}^{\\mathrm{a}}+2\\sum_{g<h}C_{g}^{\\mathrm{s}}\\right)\\varepsilon^{\\mathrm{mle}}+\\sqrt{2}\\left(\\sum_{g<h}C_{g}^{\\mathrm{s}}C_{g}^{\\mathrm{a}}\\right)\\varepsilon^{\\mathrm{wreg}}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Lastly, we state and prove the intermediate results below. ", "page_idx": 39}, {"type": "text", "text": "Lemma E.2 (Deviation bound for regression with squared loss from [HCJ23]). If $\\{\\mathcal{W}_{h}\\}$ satisfies Asm. E.1, then with probability $\\geq1-\\delta,$ forany $h\\in[H]$ there exists a universal constant c such that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\mathbb{E}\\left[\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}\\left(w_{h+1},w_{h},\\pi\\right)-\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}(\\mathbf{E}^{\\top}w_{h},w_{h},\\pi)\\right]-\\left(\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}\\left(w_{h+1},w_{h},\\pi\\right)-\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}(\\mathbf{E}^{\\top}w_{h},w_{h},\\pi)\\right)\\right|}\\\\ &{\\leq\\frac{1}{2}\\mathbb{E}\\left[\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}\\left(w_{h+1},w_{h},\\pi\\right)-\\mathcal{L}_{\\mathcal{D}_{h}^{\\mathrm{reg}}}(\\mathbf{E}_{h}^{\\top}w_{h},w_{h},\\pi)\\right]+\\frac{c(C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}})^{2}\\log|H|\\mathcal{W}|/\\delta)}{n_{\\mathrm{reg}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Proof of Lemma $E.l$ . Decompose ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\hat{w}_{h}^{\\pi}-\\widetilde{w}_{h}^{\\pi}\\|_{1,d_{h-1}^{D,\\cdot}}}\\\\ &{\\le\\left\\|\\hat{w}_{h}^{\\pi}-{\\mathbf E}_{h-1}^{\\pi}\\left(d_{h-1}^{D}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)}{\\widehat{d}_{h-1}^{D}}\\right)\\right\\|_{2,d_{h-1}^{D,\\cdot}}+\\left\\|\\widetilde{w}_{h}^{\\pi}-{\\mathbf E}_{h-1}^{\\pi}\\left(d_{h-1}^{D}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathtt{s}}\\widehat{d}_{h-1}^{D}\\right)}{\\widehat{d}_{h-1}^{D}}\\right)\\right\\|_{2,d_{h-1}^{D}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "The first term is the statistical error of regression. The second term reflects the bias between the population regression solution (involving plug-in estimates for the regression target) and our target weight function. Since $\\widetilde{d}_{h}^{\\pi}=\\mathbf{P}_{h-1}\\left(\\sigma\\left(\\widetilde{\\widetilde{d}_{h-1}^{\\pi}},C_{h-1}^{\\mathbf{s}}d_{h-1}^{D}\\right)\\right)$ ,then $\\boldsymbol{\\widetilde{w}}_{h}^{\\overline{{\\pi}}}=\\mathbf{E}_{h-1}\\left\\lceil\\sigma\\left(\\boldsymbol{\\widetilde{d}}_{h-1}^{\\pi},{C}_{h-1}^{\\mathbf{s}}\\boldsymbol{d}_{h-1}^{D}\\right)\\right\\rceil$ for the second term we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\frac{\\widetilde w_{h}^{\\eta}}{\\widetilde w_{h}^{1}}-\\mathbf{E}_{h-1}^{\\frac{\\eta}{8}}\\left(d_{h-1}^{p}\\frac{\\sigma\\left(\\widehat f_{h-1}^{\\eta},C_{h-1}^{\\frac{\\eta}{8}}\\widehat{d}_{h-1}^{p}\\right)}{\\widehat{d}_{h-1}^{p}}\\right)\\right\\|_{1,d_{h-1}^{p,1}}}\\\\ &{=\\left\\|\\mathbf{E}_{h-1}\\left(\\sigma\\left(\\widetilde{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}d_{h-1}^{p}\\right)\\right)-\\mathbf{E}_{h-1}^{\\frac{\\eta}{8}}\\left(d_{h-1}^{p}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}\\widehat{d}_{h-1}^{p}\\right)}{\\widehat{d}_{h-1}^{p}}\\right)\\right\\|_{1,d_{h-1}^{p,1}}}\\\\ &{=\\left\\|\\mathbf{P}_{h-1}\\left(\\sigma\\left(\\widetilde{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}d_{h-1}^{p}\\right)\\right)-\\mathbf{P}_{h-1}^{\\mathfrak{s}}\\left(d_{h-1}^{p}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}\\widehat{d}_{h-1}^{p}\\right)}{\\widehat{d}_{h-1}^{p}}\\right)\\right\\|_{1}}\\\\ &{\\leq\\left\\|\\sigma\\left(\\widetilde{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}d_{h-1}^{p}\\right)-d_{h-1}^{p}\\frac{\\sigma\\left(\\widehat{d}_{h-1}^{\\eta},C_{h-1}^{\\mathfrak{s}}\\widehat{d}_{h-1}^{p}\\right)}{\\widehat{d}_{h-1}^{p}}\\right\\|_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq C_{h-1}^{\\mathrm{s}}\\left\\|\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\right\\|_{1}+\\left\\|\\sigma\\left(\\widetilde{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}d_{h-1}^{D}\\right)-\\sigma\\left(\\widehat{d}_{h-1}^{\\pi},C_{h-1}^{\\mathrm{s}}\\widehat{d}_{h-1}^{D}\\right)\\right\\|_{1}}\\\\ &{\\leq2C_{h-1}^{\\mathrm{s}}\\left\\|\\widehat{d}_{h-1}^{D}-d_{h-1}^{D}\\right\\|_{1}+\\left\\|\\widetilde{d}_{h-1}^{\\pi}-\\widehat{d}_{h-1}^{\\pi}\\right\\|_{1}}&{(\\mathrm{Assumption}\\,4.1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Finally, since dn-1 = W-1@b-2, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\widetilde{d}_{h-1}^{\\pi}-\\widehat{d}_{h-1}^{\\pi}\\right\\|_{1}=\\left\\|\\widetilde{w}_{h-1}^{\\pi}d_{h-2}^{D,\\dagger}-\\widehat{w}_{h-1}^{\\pi}\\widehat{d}_{h-2}^{D,\\dagger}\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{h-2}^{\\mathrm{s}}C_{h-2}^{\\mathrm{a}}\\left\\|d_{h-2}^{D,\\dagger}-\\widehat{d}_{h-2}^{D,\\dagger}\\right\\|_{1}+\\left\\|\\widetilde{w}_{h-1}^{\\pi}-\\widehat{w}_{h-1}^{\\pi}\\right\\|_{1,d_{h-2}^{D,\\dagger}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Combining the inequalities completes the proof. ", "page_idx": 40}, {"type": "text", "text": "F Probabilistic Tools ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Definition F.1 (Pseudodimension). Suppose a function class $\\mathcal{F}\\subseteq\\mathbb{R}^{\\mathcal{X}}$ , and $x_{1}^{n}=\\{x_{i}\\}_{i=1}^{n}\\in\\mathcal{X}^{n}$ We say $x_{1}^{n}$ is pseudo-shattered by $\\mathcal{F}$ if there exists $\\boldsymbol{v}\\in\\mathbb{R}^{n}$ such that for all $y\\in\\{-1,+1\\}^{n}$ , there exists $f\\in\\mathcal F$ such that $\\mathrm{sign}(f(x_{1}^{\\bar{n}}-c))=y$ . The pseudo-dimension of $\\mathcal{F}$ is defined as ", "page_idx": 40}, {"type": "text", "text": "i.e., the cardinality of the largest set of points in $\\mathcal{X}$ that $\\mathcal{F}$ pseudo-shatters. ", "page_idx": 40}, {"type": "text", "text": "Lemma F.1 (Lemma 26 from [HCJ23]). For $b\\geq1$ ,let ${\\mathcal{H}}\\subseteq({\\mathcal{Z}}\\to[-b,b])$ be a hypothesis class and $Z^{n}=(z_{1},\\ldots,z_{n})\\in{\\mathcal{Z}}^{n}$ where $z_{i}$ are id samples drawn from a distribution supported on $\\mathcal{Z}$ Then for any $h\\in\\mathcal H$ we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\mathbb{E}[h(z)]-\\frac{1}{n}\\sum_{i}h(z_{i})\\right|>\\varepsilon\\right)\\le36\\mathcal{N}_{1}\\left(\\frac{\\varepsilon^{3}}{640b},\\varkappa,\\frac{40n b^{2}}{\\varepsilon^{2}}\\right)\\exp\\left(-\\frac{n\\varepsilon^{2}}{128\\mathbb{V}[h(z)]+512\\varepsilon b}\\right)\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Lemma F.2. Fix $\\pi$ For any $\\textit{h}\\in[H]$ consider functions $y_{h}:S\\times A\\to[-h G,h G]^{\\mathfrak{p}}$ and $\\rho_{h}$ \uff1a $S\\times A\\to[0,C_{h}^{\\bf s}C_{h}^{\\bf a}]$ that depend ony onthe daasels $\\mathcal{D}_{<h}^{\\mathrm{mle}}$ and $\\mathcal{D}_{<h}^{\\mathrm{FORC}}$ and $\\mathcal{D}_{<h}^{\\mathrm{grad}}$ Let $\\mathcal{G}=\\{\\mathcal{G}_{h}\\}$ be function classes and with pseudo-dimension ${\\mathsf{d}}_{\\mathcal{G}}$ (Def. $F.I$ ). For any $g_{h+1}\\,\\in\\,\\mathcal{G}_{h+1}$ and $p\\,\\in\\,[{\\mathsf{p}}]$ \uff0c define the loss function ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\mathcal{L}_{h}^{\\pi,p}(g_{h+1};y_{h},\\rho_{h})=\\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h}^{\\mathrm{reg}}}\\rho_{h}(s,a)\\left(g_{h+1}^{p}(s^{\\prime})-(\\nabla\\log\\widetilde{\\pi}_{h}(a|s)+y_{h}^{p}(s,a))\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Then with probability at least $1-\\delta$ for all $g_{h+1}\\in\\mathcal{G}_{h+1}$ and $p\\in[{\\mathsf{p}}]$ and $h\\in[H]$ we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g_{h+1};y_{h},\\rho_{h})-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y_{h},\\rho_{h})]-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1};y_{h},\\rho_{h})-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y_{h},\\rho_{h})\\right|}\\\\ &{\\quad\\quad\\leq\\frac{1}{2}\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g_{h+1};y_{h},\\rho_{h})-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y_{h},\\rho_{h})]+(\\varepsilon_{h+1}^{\\mathrm{reg}})^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where $g_{h+1}^{\\ast}=\\mathbf{E}_{h}^{D,\\rho}(\\nabla\\log\\widetilde{\\pi}_{h}+y_{h})$ and for some absolute constant $c$ ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\varepsilon_{h}^{\\mathrm{reg}}=c\\sqrt{\\frac{\\mathsf{d}_{\\mathcal{G}}C_{h-1}^{\\mathbf{s}}C_{h-1}^{\\mathbf{a}}h^{2}G^{2}\\log(n\\mathsf{p}H/\\delta)}{n}}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Proof. Fix $\\mathcal{D}_{<h}^{\\mathrm{mle}}$ and $\\mathcal{D}_{<h}^{\\mathrm{FORC}}$ and $\\mathcal{D}_{<h}^{\\mathrm{grad}}$ We first provethe staed bound condioned on these datasets, which means $g_{h}^{\\pi}$ and $\\rho_{h}^{\\pi}$ are fixed, and the randomness below comes from random draws of $\\mathcal{D}_{h}^{\\mathrm{grad}}$ Consider the fllowing hypothesclassinducedby $\\mathcal{G}_{h+1}$ \uff1a   \n$\\begin{array}{r}{\\boldsymbol{\\Xi}(\\rho_{h},g_{h+1},y_{h})=\\left\\{\\rho_{h}(s,a)\\left((g_{h+1}(s^{\\prime})-y_{h}(s,a))^{2}-\\left(g_{h+1}^{*}(s^{\\prime})-y_{h}(s,a)\\right)^{2}\\right):g_{h+1}\\in\\mathcal{G}_{h+1}\\right\\}.}\\end{array}$ and for any $Z\\in{\\mathcal{Z}}$ , we have $|Z|\\leq2C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}\\left(\\left\\|g_{h+1}\\right\\|_{\\infty}^{2}+\\left\\|y_{h}\\right\\|_{\\infty}^{2}\\right)\\leq4C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}h^{2}G^{2}$ . We also have $\\mathbb{E}[Z^{p}(\\rho,g_{h+1},y_{h})]=\\big\\lVert y_{h+1}^{p}-g_{h+1}^{*,p}\\big\\rVert_{2,f_{h}^{\\pi}}^{2}\\,.$   \n$\\mathbb{V}\\left[Z^{p}(\\rho_{h},g_{h+1},y_{h})\\right]\\le\\mathbb{E}[Z^{p}(\\rho_{h},g_{h+1},y_{h})^{2}]$ ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\mathbb{E}\\left[\\rho_{h}(s,a)^{2}\\left(\\left(g_{h+1}^{p}(s^{\\prime})-y_{h}(s,a)\\right)^{2}-\\left(g_{h+1}^{*,p}(s^{\\prime})-y_{h}(s,a)\\right)^{2}\\right)^{2}\\right]}\\\\ &{=\\mathbb{E}\\left[\\rho_{h}(s,a)^{2}\\left(g_{h+1}^{p}(s^{\\prime})-2y_{h}(s,a)+g_{h+1}^{*,p}(s^{\\prime})\\right)^{2}\\left(g_{h+1}^{p}(s^{\\prime})-g_{h+1}^{*,p}(s^{\\prime})\\right)^{2}\\right]}\\\\ &{\\leq16C_{h}^{8}C_{h}^{8}h^{2}G^{2}\\mathbb{E}\\left[\\rho_{h}(s,a)\\left(g_{h+1}^{p}(s^{\\prime})-g_{h+1}^{*,p}(s^{\\prime})\\right)^{2}\\right]}\\\\ &{=16C_{h}^{8}C_{h}^{8}h^{2}G^{2}\\mathbb{E}[Z^{p}(\\rho_{h},g_{h+1},y_{h})]}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Next, we show that the uniform covering number of $\\mathcal{Z}$ can be bounded by the uniform covering number of $\\mathcal{G}$ , since for any $g_{h+1},g_{h+1}^{\\prime}\\in\\mathcal{G}_{h+1}$ wehave ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Z^{p}(\\rho_{h},g_{h+1},y_{h})-Z^{p}(\\rho_{h},g_{h+1}^{\\prime},y_{h})\\big|=\\rho_{h}(s,a)\\left|(g_{h+1}(s^{\\prime})-y_{h}(s,a))^{2}-(g_{h+1}^{\\prime}(s^{\\prime})-y_{h}(s,a))^{2}\\right|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq16C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}(h+1)^{2}G^{2}|g_{h+1}(s^{\\prime})-g_{h+1}^{\\prime}(s^{\\prime})|}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "In other words, any $\\gamma/16C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}$ covering of $\\mathcal{G}_{h}$ is a covering of $\\mathcal{Z}_{h}$ . Then combining the above with Lem. F.1, we have? ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\left|\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]-\\frac{1}{n}\\sum_{i}^{p}Z_{i}^{p}(\\rho_{h-1},g_{h},y_{h-1})\\right|>\\varepsilon\\right)}\\\\ &{\\le36N_{1}\\left(\\frac{\\varepsilon^{3}}{10240C_{h}^{8}C_{h}^{8}h^{2}G^{2}},{\\mathcal{Z}}(\\mathcal{G}_{h},\\rho_{h-1},y_{h-1}),\\frac{640n\\left(C_{h-1}^{8}C_{h-1}^{8}\\right)^{2}h^{4}G^{4}}{\\varepsilon^{2}}\\right)}\\\\ &{\\quad\\cdot\\exp\\left(-\\frac{1}{2048C_{h-1}^{8}C_{h-1}^{8}h^{2}G^{2}\\mathbb{E}\\left[Z^{p}(\\rho_{h-1},g_{h},y_{h-1},\\pi)\\right]+2048\\varepsilon C_{h-1}^{8}C_{h-1}^{8}h^{2}G^{2}}\\right)}\\\\ &{\\le36N_{1}\\left(\\frac{\\varepsilon^{3}}{163840(C_{h}^{8}C_{h}^{8})^{2}h^{4}G^{4}},{\\mathcal{Z}}_{h},\\frac{640n\\left(C_{h-1}^{8}C_{h-1}^{8}\\right)^{2}h^{4}G^{4}}{\\varepsilon^{2}}\\right)}\\\\ &{\\quad\\cdot\\exp\\left(-\\frac{n\\varepsilon^{2}}{2048C_{h-1}^{8}C_{h-1}^{8}h^{2}G^{2}\\mathbb{E}\\left[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})\\right]+2048\\varepsilon C_{h-1}^{8}C_{h-1}^{8}h^{2}G^{2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Define $\\begin{array}{r}{N:=\\mathcal{N}_{1}\\left(\\frac{\\varepsilon^{3}}{163840(C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}})^{2}h^{4}G^{4}},\\mathcal{G}_{h},\\frac{640n(C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}})^{2}h^{4}G^{4}}{\\varepsilon^{2}}\\right)}\\end{array}$ 640n(Ch)) Then seting the RHS equal to $\\delta^{\\prime}$ , this implies that ", "page_idx": 41}, {"type": "equation", "text": "$$\nn=\\frac{2048C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\left(\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]+\\varepsilon\\right)\\log\\left(36N/\\delta^{\\prime}\\right)}{\\varepsilon^{2}}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "and ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\cdot\\le\\sqrt{\\frac{2048C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]\\log(36N/\\delta^{\\prime})}{n}}+\\frac{2048C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\log(36N/\\delta^{\\prime})}{n}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Since $n~\\ge~{\\frac{2048C_{h-1}^{\\bf s}C_{h-1}^{\\bf a}h^{2}G^{2}}{\\varepsilon}}$ , there exists an absolute constant $c$ such that $\\log(36N/\\delta^{\\prime})~\\le$ $c\\mathsf{d}_{\\mathcal{G}}\\log(n/\\delta^{\\prime})$ . Then with probability at least $1-\\delta^{\\prime}$ ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg|\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]-\\frac{1}{n}\\sum_{i}Z_{i}^{p}(\\rho_{h-1},g_{h},y_{h-1})\\bigg|}\\\\ &{\\leq\\sqrt{\\frac{2048c\\mathsf{d}_{\\mathcal{G}_{h}}C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]\\log(n/\\delta^{\\prime})}{n}}+\\frac{2048c\\mathsf{d}_{\\mathcal{G}}C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\log(n/\\delta^{\\prime})}{n}}\\\\ &{\\leq\\frac{1}{2}\\mathbb{E}[Z^{p}(\\rho_{h-1},g_{h},y_{h-1})]+\\frac{3072c\\mathsf{d}_{\\mathcal{G}}C_{h-1}^{\\mathrm{s}}C_{h-1}^{\\mathrm{a}}h^{2}G^{2}\\log(n/\\delta^{\\prime})}{n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Since the above bound holds for a fixed datasets, it also holds for the expectation over the datasets. Applying the above bound for all $p\\in[{\\mathsf{p}}]$ and $h\\in[H]$ with $\\delta^{\\prime}=\\delta/H\\mathfrak{p}$ and taking the union bound, then plugging in the definition of $Z^{p}$ , gives the result. \u53e3 ", "page_idx": 41}, {"type": "text", "text": "Lemma F.3. Fix h and denote the product class composed from $\\mathcal{G},\\mathcal{W},\\mathcal{F}$ tobe ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v_{h}\\times\\mathcal{P}_{h}=\\left\\{(y,\\rho):y=g\\odot\\widetilde{\\mathbf{1}}\\left(w f^{\\prime},C_{h}^{\\mathrm{s}}f\\right),\\rho=\\frac{\\sigma\\left(w f^{\\prime},C_{h}^{\\mathrm{s}}f\\right)}{f},g_{h}\\in\\mathcal{G}_{h},w\\in\\mathcal{W}_{h},f\\in\\mathcal{F}_{h+1},f^{\\prime}\\in\\mathcal{F}_{h}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Fix $\\pi$ and $p\\in[{\\mathsf{p}}]$ , and define the loss function ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)=\\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{h}}\\rho(s)\\frac{\\sigma(\\pi(a|s),C_{h}^{a}\\pi_{h}^{D}(a|s))}{\\pi_{h}^{D}(a|s)}\\left(g^{p}(s^{\\prime})-\\left(\\nabla^{p}\\log\\widetilde{\\pi}(a|s)+y^{p}(s)\\right)\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Then with probability at least $1-\\delta_{i}$ for all $h\\in[H],p\\in[{\\mathfrak{p}}]$ and $g\\in\\mathcal{G}_{h+1}$ $(y,\\rho)\\in\\mathcal{D}_{h}\\times\\mathcal{P}_{h}$ we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)]-\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)\\bigr|}\\\\ &{\\qquad\\leq\\frac{1}{2}\\mathbb{E}[\\mathcal{L}_{h}^{\\pi,p}(g;y,\\rho)-\\mathcal{L}_{h}^{\\pi,p}(g_{h+1}^{*};y,\\rho)]+(\\varepsilon_{h+1}^{\\mathrm{reg}})^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Proof of Lem. F.3. Use the same notation for $Z^{p}$ as in the proof of Lem. F.2. Using Bernstein's inequality with a union bound over all $\\mathcal{W}_{h}$ and ${\\mathcal{F}}_{h}$ and the $\\ell_{\\infty}$ covers of $\\mathcal{G}_{h},\\mathcal{G}_{h+1}$ , with probability at least $1-\\delta$ we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}[Z^{p}(\\rho_{h},g_{h+1},y_{h})]-\\frac{1}{n}\\sum_{i=1}^{n}Z_{i}^{p}(\\rho_{h},g_{h+1},y_{h})\\Bigg|}\\quad}&{}\\\\ &{\\leq\\sqrt{\\frac{2\\mathbb{V}\\left[Z^{p}\\left(\\rho_{h},y_{h+1},g_{h}\\right)\\right]\\log(|\\mathcal{W}||\\mathcal{F}|\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})/\\delta)}{n}}+\\frac{4C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\log(|\\mathcal{W}||\\mathcal{F}|\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})/\\delta)}{3n}}\\\\ &{\\leq\\sqrt{\\frac{32C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\mathbb{E}\\left[Z^{p}\\left(\\rho_{h},y_{h+1},g_{h}\\right)\\right]\\log(|\\mathcal{W}||\\mathcal{F}|\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})/\\delta)}{n}}+\\frac{4C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\log(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})/\\delta)}{3n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "By accounting for the $\\ell_{\\infty}$ covering error, we then have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~~\\left|\\mathbb{E}[Z^{p}(\\rho_{h},g_{h+1},y_{h})]-\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}Z_{i}^{p}(\\rho_{h},g_{h+1},y_{h})\\right|}\\\\ &{\\le\\sqrt{\\frac{32C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\mathbb{E}[Z^{p}(\\rho_{h},g_{h+1},y_{h})]\\log(|\\mathcal{W}||\\mathcal{F}|\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})/\\delta)}{n}}}\\\\ &{+\\frac{4C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\log(\\mathcal{N}_{\\infty}(\\varepsilon,\\mathcal{G})|\\mathcal{W}||\\mathcal{F}|/\\delta)}{3n}+16C_{h}^{\\mathrm{s}}C_{h}^{\\mathrm{a}}h^{2}G^{2}\\varepsilon}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Using the AM-GM inequality with $\\varepsilon=O(1/C_{h}^{\\mathbf{s}}C_{h}^{\\mathbf{a}}h^{2}G^{2}n)$ gives the result. ", "page_idx": 42}, {"type": "text", "text": "G Optimization Tools ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Definition G.1 (Gradient mapping). ", "page_idx": 42}, {"type": "equation", "text": "$$\nG^{\\eta}(x,g):=\\frac{1}{\\eta}\\left(x-\\mathrm{Proj}_{X}\\left(x+\\eta g\\right)\\right)\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Lemma G.1 (Stationary convergence of PGD). Suppose $f\\,:\\,\\mathcal{X}\\,\\rightarrow\\,\\mathbb{R}$ is $\\beta$ -smooth over $\\chi,\\:a$ nonempty closed and convex set, and that we have access to a gradient oracle such that $\\mathbb{E}[g(x)|x]=$ $\\nabla f(x)$ and $\\mathbb{E}[\\|g(x)-\\nabla f(x)\\|^{2}|x]\\le\\varepsilon^{2}$ .Then if $\\eta=1/\\beta$ we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t}\\mathbb{E}\\left[\\|G^{\\eta}(x^{(t)},\\nabla f(x^{(t)}))\\|^{2}\\right]\\leq\\frac{4\\beta(f_{0}-f^{*})}{T}+6\\varepsilon^{2}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Proof. For any $x$ , define $x^{+}=\\operatorname{Proj}_{\\mathcal{X}}\\left(x-\\eta g(x)\\right)$ . Since x+ = prox. $_{I_{X}}(x-\\eta g(x))$ , where $I_{\\mathcal{X}}$ .s the indicator function for the set $\\mathcal{X}$ , from Lem. G.2 we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\left\\langle x-\\eta g(x)-x^{+},x-x^{+}\\right\\rangle\\leq0.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Rearranging, this implies ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\left\\langle g(x),x^{+}-x\\right\\rangle+\\frac{1}{\\eta}\\|x-x^{+}\\|^{2}\\leq0.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Next, since $f$ is $\\beta$ -smooth, for any $x$ and $x^{+}$ we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{r}(x^{+})\\le f(x)+\\left\\langle\\nabla f(x),x^{+}-x\\right\\rangle+\\displaystyle\\frac{\\beta}{2}\\left\\|x-x^{+}\\right\\|^{2}}\\\\ &{\\qquad=f(x)+\\left\\langle g(x),x^{+}-x\\right\\rangle+\\left\\langle\\nabla f(x)-g(x),x^{+}-x\\right\\rangle+\\displaystyle\\frac{\\beta}{2}\\left\\|x-x^{+}\\right\\|^{2}}\\\\ &{\\qquad\\le f(x)+\\eta\\left\\langle g(x)-\\nabla f(x),G^{\\eta}(x,g(x))\\right\\rangle+\\left(\\displaystyle\\frac{\\eta^{2}\\beta}{2}-\\eta\\right)\\left\\|G^{\\eta}(x,g(x))\\right\\|^{2}}\\\\ &{\\qquad=f(x)+\\eta\\left\\langle g(x)-\\nabla f(x),G^{\\eta}(x,\\nabla f(x))\\right\\rangle+\\eta\\left\\langle g(x)-\\nabla f(x),G^{\\eta}(x,g(x))-G^{\\eta}(x,\\nabla f(x))\\right\\rangle}\\\\ &{\\qquad\\qquad+\\left(\\displaystyle\\frac{\\eta^{2}\\beta}{2}-\\eta\\right)\\|G^{\\eta}(x,g(x))\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where we substitute the definition of $\\begin{array}{r}{G^{\\eta}(x,g(x))=\\frac{1}{\\eta}(x-x^{+})}\\end{array}$ in the the second to last line. Notice that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{g(x)-\\nabla f(x),G^{\\eta}(x,g(x))-G^{\\eta}(x,\\nabla f(x))\\rangle\\leq\\|g(x)-\\nabla f(x)\\|\\|G^{\\eta}(x,g(x))-G^{\\eta}(x,\\nabla f(x))\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\|g(x)-\\nabla f(x)\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "from the non-expansion of the projection operator. Then we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n{^{\\mathrm{\\scriptsize{\\it~\\tau}}}(x^{+})\\leq f(x)+\\eta\\left\\langle{g(x)-\\nabla f(x)},{G^{\\eta}(x,\\nabla f(x))}\\right\\rangle}+\\eta\\|g(x)-\\nabla f(x)\\|^{2}+\\left({\\frac{\\eta^{2}\\beta}{2}}-\\eta\\right)\\|G^{\\eta}(x,g(x))-\\nabla f(x)\\|^{2},\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Next, we take the expectation of both sides conditioned on $x$ ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[f(x^{+})|x]\\leq f(x)+\\eta\\left\\langle\\mathbb{E}[g(x)|x]-\\nabla f(x),G^{\\eta}(x,\\nabla f(x))\\right\\rangle}\\\\ &{\\qquad\\qquad\\qquad+\\eta\\mathbb{E}[\\|g(x)-\\nabla f(x)\\|^{2}|x]+\\left(\\frac{\\eta^{2}\\beta}{2}-\\eta\\right)\\mathbb{E}[\\|G^{\\eta}(x,g(x))\\|^{2}|x]}\\\\ &{\\qquad\\qquad\\leq f(x)+\\eta\\varepsilon^{2}+\\left(\\frac{\\eta^{2}\\beta}{2}-\\eta\\right)\\mathbb{E}[\\|G^{\\eta}(x,g(x))\\|^{2}|x]}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Then unrolling the recursion through iterations and substituting $\\eta=1/\\beta$ ,wehave ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t}\\mathbb{E}[\\|G^{\\eta}(x^{(t)},g(x^{(t)}))\\|^{2}]\\leq\\frac{2\\beta(f(x^{(0)})-f(x^{(T)}))}{T}+2\\varepsilon^{2}\\leq\\frac{2\\beta(f(x^{(0)})-f(x^{*}))}{T}+2\\varepsilon^{2}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "$f$ is nonnegative. Lastly, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\frac1T\\sum_{t}\\mathbb E[\\|G^{\\eta}(x^{(t)},\\nabla f(x^{(t)}))\\|^{2}]=\\displaystyle\\frac1T\\sum_{t}\\mathbb E[\\|G^{\\eta}(x^{(t)},g(x^{(t)})-G^{\\eta}(x^{(t)},g(x^{(t)})+G^{\\eta}(x^{(t)},\\nabla f(x^{(t)})))\\|^{2}]}&{{}=\\displaystyle\\frac1T\\sum_{t}\\mathbb E[\\|G^{\\eta}(x^{(t)},g(x^{(t)}))-G^{\\eta}(x^{(t)},g(x^{(t)}))\\|^{2}]}\\\\ {\\displaystyle}&{\\le\\displaystyle\\frac2T\\sum_{t}\\mathbb E[\\|G^{\\eta}(x^{(t)},g(x^{(t)}))\\|^{2}+\\displaystyle\\frac2T\\sum_{t}\\mathbb E[\\|G^{\\eta}(x^{(t)},g(x^{(t)})-G^{\\eta}(x^{(t)}))\\|^{2}]}\\\\ {\\displaystyle}&{\\le\\displaystyle\\frac{4\\beta(f(x^{(0)})-f(x^{*}))}T+4\\varepsilon^{2}+\\displaystyle\\frac2T\\sum_{t}\\mathbb E[\\|g(x^{(t)})-\\nabla f(x^{(t)})\\|^{2}]}\\\\ {\\displaystyle}&{\\le\\displaystyle\\frac{4\\beta(f(x^{(0)})-f(x^{*}))}T+6\\varepsilon^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Lemma G.2 (Theorem 6.39 from [Bec17]). Let $g:\\mathcal{E}\\to(\\infty,\\infty]$ be a proper closed and convex function.Thenfor any $x,y\\in\\mathcal{E}$ the following three claims are equivalent: ", "page_idx": 43}, {"type": "equation", "text": "$$\nI.\\ y=\\operatorname{prox}_{g}(x)\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "2. $x-y\\in\\partial g(u)$ ", "page_idx": 44}, {"type": "text", "text": "3. $\\langle x-y,u-y\\rangle\\leq g(u)-g(y)$ for any $u\\in\\mathcal{E}$ ", "page_idx": 44}, {"type": "text", "text": "Lemma G.3. Suppose $f$ is $M$ -gradient dominated and $\\beta$ -smooth,and ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t}\\left\\|G^{\\eta}(x^{(t)},\\nabla f(x^{(t)}))\\right\\|^{2}\\leq\\varepsilon^{2},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $G^{\\eta}(x,g)$ is the gradient mapping defined in Def. G.1. Also, suppose $\\|\\boldsymbol{x}-\\boldsymbol{x}^{\\prime}\\|_{2}\\leq\\boldsymbol{r}$ forall $x,x^{\\prime}\\in\\mathcal{X}$ Then ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{t\\in[T]}\\left\\{f(x^{*})-f(x^{(t)})\\right\\}\\leq r M(\\eta\\beta+1)\\varepsilon.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Proof of Lemma G.3. If $f$ is gradient dominated, for any $t\\in[T]$ we have ", "page_idx": 44}, {"type": "equation", "text": "$$\nf(x^{*})-f(x^{(t)})\\leq M\\operatorname*{max}_{x^{\\prime}\\in\\mathcal{X}}\\left\\langle\\nabla f(x^{(t)}),x^{\\prime}-x^{(t)}\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Applying Lemma G.4 with $-f$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\nabla f(x^{(t)})\\in N x(x^{(t)})+\\mathcal{B}\\left((\\eta\\beta+1)\\|G^{\\eta}(x^{(t-1)},\\nabla f(x^{(t-1)}))\\|\\right)\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "From the defnition of the normal cone, we have $\\left\\langle v,x^{\\prime}-x^{(t)}\\right\\rangle\\leq\\,0$ for any $v\\;\\in\\;N_{\\mathcal{X}}(x^{(t)})$ and $x^{\\prime}\\in\\mathcal{X}$ . Then for any $x^{\\prime}\\in\\mathcal{X}$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left^{\\prime}\\nabla f(x^{(t)}),x^{\\prime}-x^{(t)}\\right\\rangle\\leq(\\eta\\beta+1)\\left\\|G^{\\eta}(x^{(t-1)},\\nabla f(x^{(t-1)}))\\right\\|\\left\\|x-x^{(t)}\\right\\|\\leq(\\eta\\beta+1)r\\left\\|G^{\\eta}(x^{(t-1)},\\nabla f(x^{(t-1)}))\\right\\|\\left\\|x-x^{(t)}\\right\\|\\leq(\\eta\\beta+1)r\\left\\|\\left\\|G^{\\eta}(x^{(t-1)},\\nabla f(x^{(t-1)}))\\right\\|\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Combining the above inequalities, ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{t\\in[T]}\\left\\{f(x^{*})-f(x^{(t)})\\right\\}\\leq(\\eta\\beta+1)M r\\operatorname*{min}_{t\\in[T]}\\|G^{\\eta}(x^{(t-1)},\\nabla f(x^{(t-1)}))\\|\\leq(\\eta\\beta+1)M r\\varepsilon.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Lemma G.4 (Lemma 3 from [GL16]). Let $f:\\mathbb{R}^{d}\\rightarrow(-\\infty,\\infty)$ bebe $\\beta$ smooth over a convex set $\\mathcal{X}$ For any $t\\in[T]$ consider $x^{(t+1)}=\\mathrm{Proj}_{\\mathcal{X}}\\left(x^{(t)}-\\eta\\nabla f(x^{(t)})\\right)$ .Then ", "page_idx": 44}, {"type": "equation", "text": "$$\n-\\nabla f(x^{(t+1)})\\in N_{\\mathcal{X}}(x^{(t+1)})+\\mathcal{B}\\left((\\eta\\beta+1)\\|G^{\\eta}(x^{(t)},-\\nabla f(x^{(t)})\\|\\right),\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $N_{\\mathcal{X}}$ is the normal cone of $\\mathcal{X}$ and $\\mathcal{B}(r)=\\{x\\in\\mathbb{R}^{d}:\\|x\\|_{2}\\leq r\\}$ ", "page_idx": 44}, {"type": "text", "text": "Proof of Lemma G.4. Projected gradient descent can be equivalently written as [Bec17] ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\operatorname{voj}_{\\mathcal{X}}\\left(x^{(t)}-\\eta\\nabla f(x^{(t)})\\right)=\\operatorname{argmin}_{x\\in\\mathbb{R}^{d}}\\left[f(x^{(t)})+\\left\\langle\\nabla f(x^{(t)}),x-x^{(t)}\\right\\rangle+\\frac{1}{2\\eta}\\|x-x^{(t)}\\|_{2}^{2}+I_{X}(x)\\right]\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $I_{\\mathcal{X}}(x)\\;=\\;0$ if $x\\,\\in\\,{\\mathcal{X}}$ ,and $+\\infty$ otherwise, is the indicator function for $\\mathcal{X}$ . Then by the subgradient optimality condition, we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\in\\nabla f(x^{(t)})+\\frac{1}{\\eta}(x^{(t+1)}-x^{(t)})+N_{\\mathcal{X}}(x^{(t+1)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "With some rearrangement, this implies that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{-\\nabla f({x}^{(t+1)})\\in N_{\\mathcal{X}}({x}^{(t+1)})+\\nabla f({x}^{(t)})-\\nabla f({x}^{(t+1)})+\\frac{1}{\\eta}({x}^{(t+1)}-{x}^{(t)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "which implies the lemma statement since ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|\\nabla f(x^{(t)})-\\nabla f(x^{(t+1)})+\\frac{1}{\\eta}(x^{(t+1)}-x^{(t)})\\|\\le\\beta\\|x^{(t)}-x^{(t+1)}\\|+\\frac{1}{\\eta}\\|x^{(t)}-x^{(t+1)}\\|}&{}\\\\ {\\le(\\eta\\beta+1)\\|G^{\\eta}(x^{(t)},\\nabla f(x^{(t)}))\\|}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "using the $\\beta$ -smoothness of $f$ in the first inequality, and Definition G.1 in the second. ", "page_idx": 44}, {"type": "text", "text": "Lemma G.5. Suppose $f$ is $\\beta$ -smooth and that at each iteration $t$ we have $g^{(t)}$ from a gradient oracle such that $\\ddot{\\mathbb{E}}\\left[g^{(t)}\\ddot{|}x^{(t)}\\right]\\,=\\,\\nabla f(x^{(t)})\\;a n d\\;\\mathbb{E}\\left[\\|\\nabla f(x^{(t)})-g^{(t)}\\|^{2}|x^{(t)}\\right]\\,\\stackrel{\\ast}{\\leq}\\,\\varepsilon^{2}$ for all $t\\,\\in\\,[T]$ Then gradient ascent using $\\{g^{(t)}\\}$ satisfies ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left\\lVert\\nabla f(x^{(t)})\\right\\rVert^{2}\\right]\\leq\\frac{2\\beta(f_{0}-f^{*})}{T}+\\varepsilon^{2}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Proof of Lem. G.5. From the $\\beta$ -smoothness of $f$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{}^{\\mathrm{r}}(x^{(t+1)})\\leq f(x^{(t)})+\\left\\langle\\nabla f(x^{(t)}),x^{(t+1)}-x^{(t)}\\right\\rangle+\\frac{\\beta}{2}\\|x^{(t+1)}-x^{(t)}\\|^{2}}\\\\ {\\quad}\\\\ {{}=f(x^{(t)})-\\eta\\left\\langle\\nabla f(x^{(t)}),g^{(t)}\\right\\rangle+\\frac{\\beta\\eta^{2}}{2}\\|g^{(t)}\\|^{2}}\\\\ {{}=f(x^{(t)})-\\eta\\left\\langle\\nabla f(x^{(t)}),\\nabla f(x^{(t)})-\\nabla f(x^{(t)})+g^{(t)}\\right\\rangle+\\frac{\\beta\\eta^{2}}{2}\\|\\nabla f(x^{(t)})-\\nabla f(x^{(t)})+g^{(t)}\\|^{2}}\\\\ {{}=f(x^{(t)})+\\left(\\frac{\\beta\\eta^{2}}{2}-\\eta\\right)\\|\\nabla f(x^{(t)})\\|^{2}+\\left(\\beta\\eta^{2}-\\eta\\right)\\left\\langle\\nabla f(x^{(t)}),g^{(t)}-\\nabla f(x^{(t)})\\right\\rangle+\\frac{\\beta\\eta^{2}}{2}\\|g^{(t)}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Taking the expectations of both sides conditioned on $\\boldsymbol{x}^{(t)}$ (prior histories), we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{E}[f(x^{(t+1)})|x^{(t)}]\\leq f(x^{(t)})+\\left(\\frac{\\beta\\eta^{2}}{2}-\\eta\\right)\\|\\nabla f(x^{(t)})\\|^{2}+\\frac{\\beta\\eta^{2}\\varepsilon^{2}}{2}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Substituting $\\eta=1/\\beta$ , unrolling through iterations, and using the law of total expectation gives the result. \u53e3 ", "page_idx": 45}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Justification: The introduction contains a list of our contributions and matches our theoretical results. The abstract summarizes them. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 46}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Justification: We provide justifications for all of our assumptions, and discuss the ramifications of our theorems. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that infuence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 46}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: We fully disclose all assumptions and discuss their strengths and weaknesses. While theorems/lemmas in the main text are not cross-referenced with pointers to their proofs in the appendix, the appendix is organized with a table of contents according to section, and proofs are clearly labeled with the theorem or lemma they pertain to. We did not have space to provide proof sketches in the main text, but, where possible, we attempted to provide a brief intuition. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 47}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: We do not have experimental results other than the graph in Figure 1, which is a plot of 1-D functions that are fully disclosed in the caption and referenced proposition. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 47}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 48}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: We do not believe that Figure 1 constitutes as an experiment that requires code. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 48}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: Per our answer to the previous question, we do not have experiments. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 48}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: Per the answer to the previous question, we do not have experiments with statistical error. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 49}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: Per the previous answer, we do not have experiments requiring computational resources. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 49}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: We do not believe we deviate from the Code of Ethics. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 49}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: Our paper is purely theoretical, and we do not believe there is a societal impact to be discussed. We do not see a direct path to negative applications. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 50}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Justification: We do not use data or train models. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 50}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: We do not have code, data, or models. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets. \u00b7 The authors should cite the original paper that produced the code package or dataset. \u00b7 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 51}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: There are no new assets. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 51}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: We do not use human subjects. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 51}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: We do not use human subjects. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 51}, {"type": "text", "text": "\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 52}]