{"references": [{"fullname_first_author": "C. Szegedy", "paper_title": "Intriguing properties of neural networks", "publication_date": "2014-04-01", "reason": "This paper is foundational in the field of adversarial machine learning, introducing the concept of adversarial examples and highlighting the vulnerability of neural networks to these attacks."}, {"fullname_first_author": "I. J. Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-05-01", "reason": "This paper is highly influential in establishing the problem of adversarial examples and proposing adversarial training as a defense mechanism, which is an important empirical method in adversarial robustness research."}, {"fullname_first_author": "A. Madry", "paper_title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "publication_date": "2018-05-01", "reason": "This work significantly advanced adversarial training by introducing the use of PGD attacks, improving the robustness of neural networks against stronger attacks."}, {"fullname_first_author": "S. Gowal", "paper_title": "Improving Robustness using Generated Data", "publication_date": "2021-12-01", "reason": "This paper demonstrates that using generated data from diffusion models can substantially improve the robustness of neural networks, which is an important finding in the context of certified and empirical adversarial robustness."}, {"fullname_first_author": "Z. Wang", "paper_title": "Better Diffusion Models Further Improve Adversarial Training", "publication_date": "2023-07-01", "reason": "This paper builds upon previous work by showing that leveraging the latest advancements in diffusion models further improves adversarial robustness, pushing the state-of-the-art in empirical robustness."}]}