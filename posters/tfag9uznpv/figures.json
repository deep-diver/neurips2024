[{"figure_path": "TFAG9UznPv/figures/figures_1_1.jpg", "caption": "Figure 1: Certified and clean accuracy of top-ranked models on CIFAR-10 taken from the SoK Certified Robustness for Deep Neural Networks [10] leaderboard. By using data generated by an elucidating diffusion model (EDM), accuracy significantly improves for four different models and two different norms (l\u221e and l2). Grey arrows indicate improvements stemming from this data augmentation.", "description": "This figure compares the certified and clean accuracy of several top-performing models on the CIFAR-10 dataset, as reported in a state-of-the-art survey on certified robustness.  The models were evaluated under two different threat models (l\u221e and l2).  The key finding is that using data generated by an elucidating diffusion model (EDM) leads to a significant increase in both certified and clean accuracy across all models and threat models.  Grey arrows are used to visually highlight this improvement due to data augmentation.", "section": "1 Introduction"}, {"figure_path": "TFAG9UznPv/figures/figures_4_1.jpg", "caption": "Figure 2: Influence of total CIFAR-10 dataset size |Dorig|+|Dgen| (number of original and generated images) on certified accuracy. p is the dropout rate of SortNet. All models were trained with a large number of epochs, i.e., 1600 for l\u221e-dist Net, 6000 for SortNet, 600 for LOT, and 2400 for GloroNet. Accuracy generally improves little beyond 1m generated images.", "description": "The figure shows how the certified accuracy of four different models (l\u221e-dist Net, SortNet, LOT, and GloroNet) changes with the total number of training images used. The total number of images is the sum of original CIFAR-10 images and generated images from an elucidating diffusion model. The x-axis represents the total number of images (original + generated), while the y-axis represents the certified accuracy. The figure shows that the increase in certified accuracy plateaus after around 1 million generated images, indicating that adding more generated data provides diminishing returns.", "section": "4.2 Sensitivity Analysis"}, {"figure_path": "TFAG9UznPv/figures/figures_6_1.jpg", "caption": "Figure 3: a Correlation between generalization gap and certified accuracy improvement. Generalization gap measures difference between training and testing accuracy. A refers to difference between base model and model trained with auxiliary data. b Generalization gaps by amount of auxiliary data |Dgen| for all models trained with maximal epoch count. c Clean and certified accuracy (%) for different ratios of generated and real data for l\u221e-dist Net and LOT-S. Here, a generated-to-original ratio of 70 means 70% of each batch is generated data and the remaining 30% is real data.", "description": "This figure shows the correlation between generalization gap and certified accuracy improvement.  Panel (a) demonstrates a positive correlation, showing that reducing the generalization gap (difference between training and testing accuracy) leads to greater improvements in certified accuracy. Panel (b) displays the generalization gap for different amounts of auxiliary data used during training across four different models. Panel (c) illustrates the effect of varying the ratio of generated to original data on both clean and certified accuracy for two models, revealing that a 70/30 ratio is optimal for achieving the best certified accuracy.", "section": "4.3 Relationship between Generalization Gap and Certified Robustness"}, {"figure_path": "TFAG9UznPv/figures/figures_7_1.jpg", "caption": "Figure 4: Cumulative distribution of certification radii for the best l\u221e-based model, Sortnet w/o dropout, and the best l2-based model, LOT-L. Note how for SortNet images exhibit overall smaller certification radii for both correct and incorrect classes, yet clean accuracy slightly decreases.", "description": "This figure shows the cumulative distribution of certification radii for the best models (SortNet without dropout and LOT-L) trained with and without auxiliary data generated by diffusion models.  The x-axis represents the certification radius, and the y-axis represents the number of images. Separate curves are shown for correctly and incorrectly classified images. The figure illustrates that for the SortNet model, the use of auxiliary data leads to a wider distribution of certification radii, indicating improved robustness even for misclassified samples, despite a slight decrease in overall clean accuracy. For the LOT-L model, the difference between models trained with and without auxiliary data is less pronounced.", "section": "4.5 Certification Radius Distribution"}, {"figure_path": "TFAG9UznPv/figures/figures_14_1.jpg", "caption": "Figure 5: Relationship between 1) the amount of auxiliary data used, 2) the number of epochs between the epoch where the best certified accuracy was achieved, and 3) the difference in certified accuracy between the best and last epoch.", "description": "This figure visualizes the relationship between the amount of auxiliary data used in training, the number of epochs between the best and last epoch in terms of certified accuracy, and the difference in certified accuracy between those two epochs.  The x-axis shows the number of epochs between the best and last epoch. The y-axis shows the difference in certified accuracy between the best and last epoch. Different colors represent different amounts of auxiliary data used (None, 1m, 5m, and 10m generated images).  The figure aims to show the impact of auxiliary data on overfitting during certified training.  It indicates that the difference between best and last epochs remains relatively small regardless of the amount of auxiliary data used, suggesting that overfitting is not a significant issue in the experimental setup.", "section": "E Robust Overfitting"}, {"figure_path": "TFAG9UznPv/figures/figures_15_1.jpg", "caption": "Figure 6: Influence of model size and increase in the number of epochs for CIFAR-10 (l2,  = 36/255) models. Color shading indicates average absolute improvement across 1m, 5m, and 10m auxiliary data over the same model trained without auxiliary data.", "description": "This figure shows the influence of model size and the number of training epochs on the certified accuracy improvement when using additional generated data.  It presents a heatmap for two architectures, LOT and GloroNet, displaying the percentage point increase in certified accuracy achieved for different model sizes (XS, S, M, L) and numbers of epochs (x1, x2, x3, where x represents the original number of epochs for each model). The color intensity represents the magnitude of improvement, with darker shades indicating larger gains. The results highlight that increasing both model size and the number of training epochs leads to higher improvements in certified robustness when using auxiliary data.", "section": "4.2 Sensitivity Analysis"}, {"figure_path": "TFAG9UznPv/figures/figures_15_2.jpg", "caption": "Figure 7: Confusion matrices for different correctness and certification constellations between models trained with and without auxiliary data. Here,  means not, i.e.,  Cert. means that images were not certified to be within the  -bound.", "description": "This figure shows confusion matrices comparing the classification and certification results for models trained with and without auxiliary data.  It illustrates how many images are correctly classified and certified, correctly classified but not certified, incorrectly classified but certified, and incorrectly classified and not certified for both the models trained with and without auxiliary data. The matrices are shown separately for the L-infinity norm (epsilon=8/255) and L2 norm (epsilon=36/255) threat models, which are used to assess the robustness of the models.", "section": "G Certification"}]