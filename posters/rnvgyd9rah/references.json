{"references": [{"fullname_first_author": "Neil Band", "paper_title": "Linguistic calibration of longform generations", "publication_date": "2024", "reason": "This paper is highly relevant because it directly addresses the issue of calibrating confidence in large language models, which is the central focus of the target paper."}, {"fullname_first_author": "Michael C Frank", "paper_title": "Predicting pragmatic reasoning in language games", "publication_date": "2012-00-00", "reason": "This paper is foundational for the target paper's approach to pragmatic calibration, as it introduces the Rational Speech Acts (RSA) model which is used as a theoretical framework."}, {"fullname_first_author": "Herbert P Grice", "paper_title": "Logic and Conversation", "publication_date": "1975-00-00", "reason": "Grice's maxims of conversation provide a crucial theoretical foundation for understanding the principles of successful communication, which is central to the concept of listener-aware calibration."}, {"fullname_first_author": "Yaniv Ovadia", "paper_title": "Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift", "publication_date": "2019-00-00", "reason": "This paper provides crucial background on the evaluation of model uncertainty, which is a key issue addressed by the target paper's methods and experimental evaluation."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2024", "reason": "This is highly relevant as it introduces the Direct Preference Optimization (DPO) framework, which is the core method used in the target paper for pragmatically calibrating the LLMs."}]}