[{"figure_path": "kpo6ZCgVZH/tables/tables_9_1.jpg", "caption": "Table 1: Results of monotonic Bayesian neural network under different monotonicity threshold. The results are averaged from the last 10 checkpoints for robustness.", "description": "This table presents the results of a monotonic Bayesian neural network experiment under various monotonicity thresholds (0.05, 0.01, and 0.005).  The table shows the test accuracy (TEST ACC), test negative log-likelihood (TEST NLL), and the ratio of particles outside the constrained domain (RATIO OUT (%)).  The results for each metric are presented for four different methods: PD-SVGD, C-SVGD, MIED, and the proposed CFG method. The average results are taken from the last 10 checkpoints to enhance robustness.", "section": "6.3 Monotonic Bayesian Neural Network"}, {"figure_path": "kpo6ZCgVZH/tables/tables_16_1.jpg", "caption": "Table 2: The types of velocities and distributions.", "description": "This table lists the types of velocities and probability distributions used in the verification experiment of the boundary integral estimation.  Three types of velocities and three types of distributions are considered. The velocities are vector fields, and the distributions are either uniform or Gaussian distributions, each defined within the constrained domain \u03a9.", "section": "Simulation Verification of Boundary Integral Estimation"}, {"figure_path": "kpo6ZCgVZH/tables/tables_16_2.jpg", "caption": "Table 3: The true values of boundary integral in the verification experiment.", "description": "This table shows the true values of the boundary integral used in the simulation study to verify the accuracy of the band-wise approximation method for estimating the boundary integral in the constrained domain sampling problem.  Three different velocity fields (v1, v2, v3) and three different probability distributions (p1, p2, p3) are considered. The values in the table represent the true values of the boundary integral for each combination of velocity field and distribution. This data is used to compare against the approximated values calculated using the proposed method, assessing its accuracy in approximating the boundary integral.", "section": "Simulation Verification of Boundary Integral Estimation"}, {"figure_path": "kpo6ZCgVZH/tables/tables_17_1.jpg", "caption": "Table 4: Four 2-D constrained distributions implemented in the toy experiments.", "description": "This table lists four 2D constrained distributions used in the toy experiments of the paper.  For each distribution, it provides the name, probability density function (defined up to a proportionality constant), and the mathematical description of the constrained domain (\u03a9). The distributions represent different shapes of constrained regions, including a ring, cardioid, double-moon, and a block.", "section": "D.1 Toy Experiments"}, {"figure_path": "kpo6ZCgVZH/tables/tables_18_1.jpg", "caption": "Table 5: Wasserstein-2 distance and energy distance between the target distribution and the variational approximation on the three toy datasets.", "description": "This table presents a comparison of the Wasserstein-2 distance and energy distance between the target distribution and the approximation achieved by MIED and CFG methods on three different 2D constrained distributions (Ring, Cardioid, and Double-moon).  The results show that CFG generally outperforms MIED in terms of both metrics, indicating its superior approximation capability for these specific tasks.", "section": "6.1 Toy Experiments"}, {"figure_path": "kpo6ZCgVZH/tables/tables_18_2.jpg", "caption": "Table 6: Ablation results of not estimating boundary integral, with and without Znet.", "description": "This table presents ablation study results comparing the performance of the proposed CFG method with and without two key components: boundary integral estimation and the Znet neural network.  It shows the Wasserstein-2 distance and energy distance for four different toy datasets (Ring, Cardioid, Double-moon, Block) under three different settings: without boundary integral estimation, without Znet, and with both Znet and boundary integral estimation. The results demonstrate the importance of both components for effective constrained sampling.", "section": "Additional Ablation Studies"}, {"figure_path": "kpo6ZCgVZH/tables/tables_22_1.jpg", "caption": "Table 7: Results of a larger monotonic Bayesian neural network on COMPAS dataset under different monotonicity threshold. The results are averaged from the last 10 checkpoints for robustness. For each monotonicity threshold, the best result is marked in black bold font and the second best result is marked in brown bold font. Positive proportion of particles outside the constrained domain is marked in red.", "description": "This table presents the results of a larger monotonic Bayesian neural network experiment on the COMPAS dataset. It compares different methods (PD-SVGD, C-SVGD, MIED, and CFG) under varying monotonicity thresholds (0.05, 0.01, 0.005).  The metrics evaluated are test accuracy, test negative log-likelihood (NLL), and the ratio of particles outside the constrained domain. The best and second-best results for each threshold are highlighted, along with any instances where a significant proportion of particles fall outside the constrained region.", "section": "Additional Experiments on Scaling Up to Higher Dimensions"}, {"figure_path": "kpo6ZCgVZH/tables/tables_22_2.jpg", "caption": "Table 8: Results of monotonic BNN on a higher 276-dimensional dataset Blog Feedback. The particle dimension is 13903. The results are averaged from the last 10 checkpoints for robustness.", "description": "This table presents the results of a monotonic Bayesian neural network on a high-dimensional dataset (Blog Feedback, 276 dimensions). The model uses 13903 particles.  The results (test RMSE and ratio of particles outside the constrained domain) are averaged over the last 10 checkpoints to ensure robustness and reliability.  It shows the performance of different methods on this challenging high-dimensional problem.", "section": "Additional Experiments on Scaling Up to Higher Dimensions"}]