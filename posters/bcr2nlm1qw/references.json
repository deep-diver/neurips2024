{"references": [{"fullname_first_author": "Omer Bar-Tal", "paper_title": "Text2live: Text-driven layered image and video editing", "publication_date": "2022-00-00", "reason": "This paper proposes a text-driven layered image and video editing approach, which is highly relevant to the current paper's focus on video editing using diffusion models."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Align your latents: High-resolution video synthesis with latent diffusion models", "publication_date": "2023-00-00", "reason": "This paper explores high-resolution video synthesis using latent diffusion models, directly contributing to the techniques used for video editing in the current paper."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "This paper introduces a method for learning to follow image editing instructions, which is highly relevant to the current paper's goal of improving the quality and naturalness of video editing results."}, {"fullname_first_author": "Duygu Ceylan", "paper_title": "Pix2video: Video editing using image diffusion", "publication_date": "2023-00-00", "reason": "This paper directly addresses video editing using image diffusion, providing a strong foundation for the current paper's approach."}, {"fullname_first_author": "Cheng-Hung Chan", "paper_title": "Hashing neural video decomposition with multiplicative residuals in space-time", "publication_date": "2023-00-00", "reason": "This paper focuses on neural video decomposition, which is a crucial component of the current paper's video representation and editing framework."}]}