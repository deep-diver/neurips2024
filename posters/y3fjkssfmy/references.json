{"references": [{"fullname_first_author": "Grill, J.-B.", "paper_title": "Bootstrap your own latent-a new approach to self-supervised learning", "publication_date": "2020-12-01", "reason": "This paper introduces Bootstrap Your Own Latent (BYOL), a highly influential self-supervised learning method that avoids the use of negative samples, significantly advancing the field."}, {"fullname_first_author": "Chen, T.", "paper_title": "A simple framework for contrastive learning of visual representations", "publication_date": "2020-06-01", "reason": "This work provides a foundational framework for contrastive learning, a widely adopted self-supervised learning technique, with its simplicity and effectiveness impacting numerous subsequent studies."}, {"fullname_first_author": "He, K.", "paper_title": "Momentum contrast for unsupervised visual representation learning", "publication_date": "2020-06-01", "reason": "This paper introduces MoCo, a highly influential method for contrastive self-supervised learning, which addresses the limitations of previous methods by employing a momentum queue to maintain a large and dynamic dictionary of negative samples, impacting the design of many future methods."}, {"fullname_first_author": "Caron, M.", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-08-01", "reason": "This paper explores self-supervised learning in the context of Vision Transformers, a significant advancement in computer vision, offering novel insights and pushing the boundaries of the field."}, {"fullname_first_author": "Bardes, A.", "paper_title": "Variance-invariance-covariance regularization for self-supervised learning", "publication_date": "2022-01-01", "reason": "This paper introduces VICReg, a novel self-supervised learning method that utilizes variance, invariance and covariance regularization, addressing the issue of dimensional collapse and demonstrating strong performance."}]}