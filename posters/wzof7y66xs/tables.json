[{"figure_path": "wzof7Y66xs/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of mean hAURC and hierarchical gain results for the selective, Max-Coverage (MC) and Climbing inference rules applied to 1,115 models trained on ImageNet1k, and 6 models trained on iNat21.", "description": "This table presents a comparison of the performance of three different hierarchical selective inference rules (Selective, Max-Coverage, and Climbing) on two image classification datasets: ImageNet-1k and iNat21.  The performance is measured using the hierarchical Area Under the Risk-Coverage curve (hAURC) and the hierarchical gain, representing the improvement in hAURC compared to the standard selective method. The results show that the Climbing inference rule significantly outperforms the other methods on both datasets.", "section": "Inference Rules"}, {"figure_path": "wzof7Y66xs/tables/tables_6_2.jpg", "caption": "Table 2: Results (mean scores) comparing the hierarchical selective threshold algorithm (Algorithm 2) with DARTS, repeated 1000 times for each model and target accuracy with a randomly drawn calibration set of 5,000 samples, applied to 1,115 models trained on ImageNet1k (meaning we evaluated each algorithm 1,115,000 times). 1 \u2013 \u03b4 is set at 0.9.", "description": "This table presents the results of comparing two algorithms for finding the optimal confidence threshold for hierarchical selective classification.  The algorithms are the proposed algorithm (Algorithm 2) and DARTS [12].  The comparison is done across 1,115 ImageNet models, with 1000 runs for each model at various target accuracies. The metrics used for comparison are the target accuracy error and the coverage achieved by each algorithm. Each run uses a randomly selected calibration set of 5000 samples, with a 90% confidence interval (1-\u03b4 = 0.9).", "section": "Optimal Selective Threshold Algorithm"}, {"figure_path": "wzof7Y66xs/tables/tables_15_1.jpg", "caption": "Table 3: Comparison of mean hAURC and hierarchical gain results for the selective, Max-Coverage (MC) and Climbing inference rules applied to 1,115 models trained on ImageNet1k, using the hierarchical severity risk.", "description": "This table presents the results of comparing three different hierarchical selective inference rules (Selective, Max-Coverage, and Climbing) on 1,115 ImageNet1k-trained models.  The comparison uses a hierarchical severity risk metric, which takes into account the severity of misclassifications based on their position in the class hierarchy. The table shows the mean hAURC (hierarchical Area Under the Risk-Coverage curve) and the hierarchical gain (the improvement in hAURC compared to the baseline Selective inference rule) for each inference rule.", "section": "A Hierarchical Severity Risk"}, {"figure_path": "wzof7Y66xs/tables/tables_15_2.jpg", "caption": "Table 1: Comparison of mean hAURC and hierarchical gain results for the selective, Max-Coverage (MC) and Climbing inference rules applied to 1,115 models trained on ImageNet1k, and 6 models trained on iNat21.", "description": "This table presents a comparison of the hierarchical Area Under the Risk-Coverage curve (hAURC) and hierarchical gain for three different inference rules: Selective, Max-Coverage, and Climbing.  The comparison is made across two datasets: ImageNet1k (1115 models) and iNat21 (6 models). The hAURC metric quantifies the performance of hierarchical selective classification, while the hierarchical gain represents the improvement achieved by using hierarchical inference compared to a non-hierarchical approach.", "section": "Inference Rules"}, {"figure_path": "wzof7Y66xs/tables/tables_17_1.jpg", "caption": "Table 1: Comparison of mean hAURC and hierarchical gain results for the selective, Max-Coverage (MC) and Climbing inference rules applied to 1,115 models trained on ImageNet1k, and 6 models trained on iNat21.", "description": "This table presents a comparison of the hierarchical selective classification performance using three different inference rules: Selective, Max-Coverage, and Climbing.  The comparison is made across two datasets: ImageNet1k (1115 models) and iNat21 (6 models).  For each inference rule, the mean hAURC (hierarchical area under the risk-coverage curve) and the hierarchical gain (percentage improvement compared to the selective baseline) are reported.", "section": "Inference Rules"}, {"figure_path": "wzof7Y66xs/tables/tables_18_1.jpg", "caption": "Table 5: Comparison of hierarchical selective threshold algorithm (Algorithm 2) with DARTS, repeated 100 times for each model and target accuracy with a randomly drawn calibration set of 10,000 samples, applied to 6 models trained on iNat21. 1 \u2013 \u03b4 is set at 0.9.", "description": "This table compares the performance of the proposed optimal hierarchical selective threshold algorithm (Algorithm 2) against the DARTS algorithm.  The comparison is based on two key metrics: target accuracy error and coverage.  The results were obtained by running each algorithm 100 times for six models trained on the iNat21 dataset, with each run using a different randomly selected calibration set of 10,000 samples.  The confidence level (1-\u03b4) was fixed at 0.9. The table shows the mean and standard deviation for each metric across the 100 runs, for several target accuracies (70%, 80%, 90%, 95%, 99%, and 99.5%).", "section": "G Threshold Algorithm Results on iNat21"}, {"figure_path": "wzof7Y66xs/tables/tables_19_1.jpg", "caption": "Table 1: Comparison of mean hAURC and hierarchical gain results for the selective, Max-Coverage (MC) and Climbing inference rules applied to 1,115 models trained on ImageNet1k, and 6 models trained on iNat21.", "description": "This table presents the comparison of three different inference rules: Selective, Max-Coverage, and Climbing.  The comparison is based on the mean hierarchical Area Under the Risk-Coverage curve (hAURC) and the hierarchical gain (%).  The hAURC measures the overall performance of a hierarchical selective classifier, while the hierarchical gain shows the improvement in performance by using a hierarchical approach over a non-hierarchical one.  Two datasets are used: ImageNet1k (1,115 models) and iNat21 (6 models), allowing for a broader evaluation of the inference rules' effectiveness across different models and datasets.  The results show Climbing outperforms other inference rules in most cases.", "section": "Inference Rules"}]