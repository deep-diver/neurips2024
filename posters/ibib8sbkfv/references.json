{"references": [{"fullname_first_author": "A. Madry", "paper_title": "Towards deep learning models resistant to adversarial attacks", "publication_date": "2017-06-01", "reason": "This paper is foundational to the understanding of adversarial attacks against deep learning models, which are central to the circuit breaker approach's context."}, {"fullname_first_author": "D. Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-09-01", "reason": "This paper introduces a benchmark for evaluating large language models' understanding across various tasks, crucial for assessing the circuit breaker's impact on model capabilities."}, {"fullname_first_author": "P. F. Christiano", "paper_title": "Deep reinforcement learning from human preferences", "publication_date": "2017-12-01", "reason": "This paper details reinforcement learning from human preferences, a technique relevant to the alignment problem that the circuit breaker approach aims to improve."}, {"fullname_first_author": "A. Zou", "paper_title": "Representation engineering: A top-down approach to AI transparency", "publication_date": "2023-10-01", "reason": "This paper introduces the concept of representation engineering, which directly inspires the circuit breaker method used in the main paper."}, {"fullname_first_author": "M. Mazeika", "paper_title": "Harmbench: A standardized evaluation framework for automated red teaming and robust refusal", "publication_date": "2024-01-01", "reason": "This paper introduces a standardized benchmark for evaluating harmful outputs of language models, essential for evaluating the circuit breaker's effectiveness in mitigating harmful behavior."}]}