[{"figure_path": "m2DaXpCoIi/figures/figures_4_1.jpg", "caption": "Figure 1: Iterations for autoregressive shuffle coding during encoding of (a) a multiset and (b) an unlabeled undirected graph. Dotted placeholders indicate deleted information. Decoding an orbit allows to 'pin' an element in the last position. The pinned element is subsequently 'popped' from the object and encoded, and the process is repeated recursively on the remaining unordered prefix.", "description": "This figure illustrates the autoregressive shuffle coding process for both multisets and graphs.  The dotted lines represent the deletion of information as the algorithm proceeds.  In both cases, an element is \"pinned\" (selected) and then \"popped\" (removed and encoded), iteratively processing the remaining structure until all elements are handled.", "section": "Autoregressive shuffle coding"}, {"figure_path": "m2DaXpCoIi/figures/figures_18_1.jpg", "caption": "Figure 2: Expected slice information Elog P(fi) by slice index i for (a) i.i.d. strings using the prefixing chain from Example 4.1 and (b) simple Erd\u0151s-R\u00e9nyi graphs using Example 4.2.", "description": "This figure visualizes the expected information content (in bits) of each slice (fi) in a sequence of ordered objects, as a function of the slice index (i).  Panel (a) shows the uniform distribution of information content across slices for independent and identically distributed (i.i.d.) strings, reflecting the equal probability of each character in the string.  Panel (b) illustrates a linearly decreasing information content for slices of simple Erd\u0151s-R\u00e9nyi graphs.  This is because the number of edges represented by each slice decreases linearly as the index (i) increases. This difference in information distribution across slices has implications for the efficiency of autoregressive shuffle coding, especially concerning the initial bit cost.", "section": "E Chunking"}, {"figure_path": "m2DaXpCoIi/figures/figures_20_1.jpg", "caption": "Figure 3: Compression speeds (dotted lines) and decompression speeds (solid lines) of multisets of varying size using joint and autoregressive shuffle coding with 1 chunk ('joint AR') and n chunks ('full AR'), compared to the full autoregressive implementation from Severo et al. (2023a). All results are based on the (ordered) string rate as the reference uncompressed size averaged across 10 runs (100 runs for sizes <1M for our implementations).", "description": "This figure compares the compression and decompression speeds of different shuffle coding methods (joint, joint autoregressive, full autoregressive) on multisets of varying sizes.  It demonstrates that the authors' implementations are significantly faster than a previous state-of-the-art method while achieving comparable compression ratios. The speed improvements are particularly noticeable for larger multisets.", "section": "G Multiset compression results"}, {"figure_path": "m2DaXpCoIi/figures/figures_21_1.jpg", "caption": "Figure 4: Rate increase from Equation (4) relative to the (optimal) discount from Equation (3) for incomplete shuffle coding on graphs, depending on the number of color refinement convolutions k, for each SZIP graph. The results are independent of the employed ordered model.", "description": "This figure shows how the rate increases as the number of convolutions increases for incomplete shuffle coding.  The x-axis represents the number of convolutions used in the color refinement process, and the y-axis shows the relative increase in rate compared to the optimal discount achievable with complete shuffle coding. Each line represents a different graph from the SZIP dataset.  The key takeaway is that a small number of convolutions is sufficient to achieve near-optimal compression rates, while significantly improving the runtime compared to the computationally expensive complete method.", "section": "H Joint graph shuffle coding results"}, {"figure_path": "m2DaXpCoIi/figures/figures_24_1.jpg", "caption": "Figure 5: Results for incomplete autoregressive shuffle coding for various numbers of chunks on SZIP graphs, based on the AP model and color refinement with 3 convolutions, averaged across 100 repeated runs per data point. The top and middle plots respectively show the increase of the net rate and rate over the optimal rate, relative to the discount given by Equation (3). The bottom plots shows compression speeds (dotted lines) and decompression speeds (solid lines), based on the (ordered) Erd\u0151s-R\u00e9nyi rate as the reference uncompressed size.", "description": "This figure displays the results of incomplete autoregressive shuffle coding applied to SZIP graphs.  Three plots show the effect of varying the number of chunks used in the algorithm. The top plot shows the relative increase in the net rate (accounting for the initial bits cost) compared to the optimal rate, highlighting how the unrealized discount changes with the number of chunks. The middle plot displays the relative increase in the rate compared to the optimal rate.  The bottom plot illustrates the compression and decompression speeds for different chunk sizes.  Each line represents a different graph from the dataset.", "section": "Autoregressive graph shuffle coding results"}]