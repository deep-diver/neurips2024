[{"type": "text", "text": "Conformal Classification with Equalized Coverage for Adaptively Selected Groups ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yanfei Zhou ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Matteo Sesia ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Data Sciences and Operations University of Southern California Los Angeles, California, USA yanfei.zhou@marshall.usc.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Data Sciences and Operations University of Southern California Los Angeles, California, USA sesia@marshall.usc.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This paper introduces a conformal inference method to evaluate uncertainty in classification by generating prediction sets with valid coverage conditional on adaptively chosen features. These features are carefully selected to reflect potential model limitations or biases. This can be useful to find a practical compromise between efficiency\u2014by providing informative predictions\u2014and algorithmic fairness\u2014 by ensuring equalized coverage for the most sensitive groups. We demonstrate the validity and effectiveness of this method on simulated and real data sets. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1.1 Uncertainty, Fairness, and Efficiency in Machine Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Increasingly sophisticated machine learning (ML) models, like deep neural networks, are revolutionizing decision-making in many high-stakes domains, including medical diagnostics [1], job screening [2], and recidivism prediction [3, 4]. However, serious concerns related to uncertainty quantification [5, 6] and algorithmic fairness [7\u201310] underscore the need for novel methods that can provide reliable and unbiased measures of confidence, applicable to any model. ", "page_idx": 0}, {"type": "text", "text": "Uncertainty quantification is crucial because ML models, although effective on average, can make errors while displaying overconfidence [11]. Consequently, in some situations users may lack sufficient warning about the potential unreliability of a prediction, raising trust and safety concerns. A promising solution is conformal inference [12\u201314], which enables converting the output of any model into prediction sets with precise coverage guarantees. These sets reflect the model\u2019s confidence on a case-by-case basis, with smaller sets indicating higher confidence in a specific prediction. ", "page_idx": 0}, {"type": "text", "text": "Algorithmic fairness focuses on the challenges of prediction inaccuracies that disproportionately impact specific groups, often identified by sensitive attributes like race, sex, and age. Among the many sources of algorithmic bias are training data that do not adequately represent the population\u2019s heterogeneity and a focus on maximizing average performance. However, fairness is partly subjective and lacks a universally accepted definition [15], leading to sometimes confilcting interpretations [16]. ", "page_idx": 0}, {"type": "text", "text": "This complexity makes conformal inference with equalized coverage [17] an appealing approach. Equalized coverage aims to ensure that the prediction sets attain their coverage not only on average for the whole population (e.g., above $90\\%$ ) but also at the same level within each group of interest. While this does not necessarily imply that the prediction sets will have equal size on average across different groups\u2014since it is possible the predictive model may be more or less accurate for different groups\u2014it objectively communicates the possible limitations of a model. This transparency helps decisionmakers recognize when predictions may be less reliable for specific subgroups, allowing them to either avoid unnecessary actions or adopt more cautious strategies in cases of higher uncertainty, thereby minimizing the potential harm from inaccurate predictions. ", "page_idx": 0}, {"type": "text", "text": "A limitation of the method developed in [17] for conformal inference with equalized coverage is that it does not scale well to situations involving diverse populations with multiple sensitive attributes. In such cases, it necessitates splitting the data into exponentially many subsets, significantly reducing the effective sample size and leading to less informative predictions. Balancing this trade-off [18] between efficiency\u2014aiming for highly informative predictions with small set sizes\u2014and fairness\u2014 ensuring unbiased treatment\u2014is challenging and requires novel approaches. This paper introduces a method to address this by providing equalized coverage conditional on carefully chosen features, informed by the model and data. While it cannot guarantee equalized coverage for all sensitive groups, it seeks a reasonable compromise with finite data sets, mitigating significant biases while retaining predictive power. ", "page_idx": 1}, {"type": "text", "text": "1.2 Background on Conformal Inference for Classification ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Consider a data set comprising $n$ exchangeable (e.g., i.i.d.) observations $Z_{i}$ for $i\\in{\\mathcal{D}}:=[n]:=$ $\\{1,\\ldots,n\\}$ , sampled from an arbitrary and unknown distribution $P_{Z}$ . In classification, one can write $Z_{i}\\,=\\,(X_{i},Y_{i})$ , where $Y_{i}\\,\\in\\,[L]\\,:=\\,^{\\cdot}\\{1,\\dots,L\\}$ is a categorical label and $X_{i}\\,\\in\\,{\\mathcal{X}}$ represents the individual\u2019s features, taking values in some space $\\mathcal{X}$ . As explained below, we will assume these features include some sensitive attributes. Further, we consider a test point $Z_{n+1}=(X_{n+1},Y_{n+1})$ , also sampled exchangeably from $P_{Z}$ , and whose label $Y_{n+1}\\in[L]$ has not yet been observed. ", "page_idx": 1}, {"type": "text", "text": "A standard goal for split conformal prediction methods is to quantify the predictive uncertainty of a given \u201cblack-box\u201d ML model (e.g., pre-trained on an independent data set) by constructing a prediction set ${\\hat{C}}(X_{n+1})$ for $Y_{n+1}$ , guaranteeing marginal coverage at some desired level $\\alpha\\in(0,1)$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})]\\geq1-\\alpha.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "This probability is taken over the randomness in $Y_{n+1}$ and $X_{n+1}$ , as well as in the data indexed by $\\mathcal{D}$ . Intuitively, marginal coverage means the prediction sets are expected to cover the correct outcomes for a fraction $1\\mathrm{~-~}\\alpha$ of the population. However, this is not always satisfactory, especially if the miscoverage errors may disproportionately affect individuals characterized by well-defined features. ", "page_idx": 1}, {"type": "text", "text": "To address these concerns, one might consider feature-conditional coverage, $\\mathbb{P}[Y_{n+1}\\in{\\hat{C}}(X_{n+1})\\mid$ $X_{n+1}=x]\\geq1\\!-\\!\\alpha$ for all $x\\in\\mathscr{X}$ . This would ensure consistent coverage for all possible test features $X_{n+1}$ . However, it is impossible to achieve without additional assumptions, such as modeling the distribution $P_{Z}$ [19] or significantly restricting the feature space $\\mathcal{X}$ [20]. Given that such assumptions may be unrealistic in real-world settings, exact feature-conditional coverage is typically unachievable. ", "page_idx": 1}, {"type": "text", "text": "Equalized coverage [17] seeks a practical middle ground between the two extremes of marginal and feature-conditional coverage, focusing on accounting for specific discrete attributes encapsulated by $X_{n+1}$ . To facilitate the subsequent exposition of our method, it is useful to recall the definition of equalized coverage with the following notation. ", "page_idx": 1}, {"type": "text", "text": "Let $K$ denote the number of sensitive attributes, and for each $k\\ \\in\\ [K]$ let $M_{k}~\\in~\\mathbb{N}$ count the possible values of the $k$ -th attribute. Consider a function $\\phi:\\mathcal{X}\\times\\{0,1\\}^{K}\\to\\mathbb{N}^{d}$ for any subset $\\mathbf{\\bar{A}}\\subseteq[K]$ with $|A|=d$ elements, so that $\\phi(x,A)$ is a vector of length $|A|$ representing the values of all attributes indexed by $A$ for an individual with features $x$ . In the special case where $A$ is an empty set, $\\phi$ returns a constant. If $A$ is a singleton, e.g., $A\\,=\\,\\{k\\}$ for some $k\\ \\in[K]$ , then $\\phi(x,\\{\\bar{k}\\})\\in[M_{k}]$ denotes the value of the $k$ -th attribute; e.g., someone\u2019s academic degree. More generally, $\\phi(\\bar{x},\\{\\dot{k},l\\})\\in[M_{k}]\\times[M_{l}]$ , for any distinct $k,l\\in[K]$ , denotes the joint values of two attributes, characterizing a smaller group, such as \u201cmales with a bachelor\u2019s degree.\u201d. ", "page_idx": 1}, {"type": "text", "text": "When multiple sensitive attributes are involved, i.e., $K>1$ , the concept of equalized coverage introduced by [17] can be naturally extended to exhaustive equalized coverage, defined as: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in{\\hat{C}}(X_{n+1})\\mid{\\boldsymbol{\\phi}}(X_{n+1},[K])]\\geq1-\\alpha.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "In words, this says ${\\hat{C}}(X_{n+1})$ has valid coverage conditional on all $K$ sensitive attributes. Prediction sets satisfying (2) can be obtained by applying the standard conformal calibration method separately within each of the $\\begin{array}{r}{M=\\prod_{k=1}^{K}M_{k}}\\end{array}$ groups characterized by a specific combination of the protected attributes represented b y $\\phi(X_{i},[K])$ ; see Appendix A1 for details. However, a downside of this approach is that the calibration subsets may be too small if $M$ is large, leading to uninformative predictions for even moderate values of $K$ . This limitation forms the starting point of our work. ", "page_idx": 1}, {"type": "text", "text": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In practice, for a given model and data set, different groups may not exhibit the same need for rigorous equalized coverage guarantees (2), as conformal predictions may be able to approximately achieve the desired coverage even without explicit constraints. Algorithmic bias typically affects only a minority of the population, so standard prediction sets with marginal coverage (1) may approximately satisfy (2) for most groups. Therefore, we propose Adaptively Fair Conformal Prediction (AFCP), a new method that efficiently identifies and addresses groups suffering from algorithmic bias in a data-driven way, adjusting their prediction sets to equalize coverage without sacrificing informativeness. ", "page_idx": 2}, {"type": "text", "text": "AFCP involves two main steps. First, as sketched in Figure 1, it carefully selects a sensitive attribute ${\\hat{A}}(X_{n+1})\\in\\{\\emptyset,\\{1\\},\\ldots,\\{\\dot{K}\\}\\}$ , based on $X_{n+1}$ and the data in $\\mathcal{D}$ . Although AFCP can be extended to select multiple attributes, we begin by focusing on this simpler version for clarity. Intuitively, AFCP searches for the attribute corresponding to the group most negatively affected by algorithmic bias. It may also opt to select no attribute $({\\hat{A}}(X_{n+1})=\\varnothing)$ ) in the absence of significant biases. ", "page_idx": 2}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/763c9ff5e0a291b7d55df347a66ba5ca43a408ab13e4df1256eafa7d3eec4ff1.jpg", "img_caption": ["Figure 1: Schematic visualization of the automatic sensitive attribute selection carried out by our Adaptively Fair Conformal Prediction (AFCP) method. This method is designed to find the attribute corresponding to the group most negatively affected by algorithmic bias, on a case-by-case basis. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Next, AFCP constructs a prediction set ${\\hat{C}}(X_{n+1})$ for $Y_{n+1}$ that guarantees the following notion of adaptive equalized coverage at the desired level $\\alpha\\in(0,1)$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in{\\hat{C}}(X_{n+1})\\mid{\\boldsymbol{\\phi}}(X_{n+1},{\\hat{A}}(X_{n+1}))]\\geq1-\\alpha.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In words, this tells us ${\\hat{C}}(X_{n+1})$ is well-calibrated for the groups defined by the selected attribute $\\hat{A}(X_{n+1})$ . It is worth highlighting the key distinctions between (3) and the existing notions of coverage reviewed above. On the one hand, if AFCP identifies no significant bias, selecting ${\\hat{A}}(X_{n+1})=\\emptyset$ , then (3) reduces to marginal coverage (1), following the convention that $\\phi(X_{n+1},\\emptyset)$ is a constant. On the other hand, exhaustive equalized coverage (2) would correspond to simultaneously selecting all possible sensitive attributes instead of only that identified by $\\bar{A}(\\bar{X}_{n+1})$ . To clarify the terminology, in this paper we will say that an attribute is sensitive if it may identify a group affected by algorithmic bias. By contrast, a protected attribute is one for which equalized coverage is explicitly sought. ", "page_idx": 2}, {"type": "text", "text": "Figure 2 illustrates this intuition through a simulated example. In this scenario, we generate synthetic medical diagnosis data, considering six possible diagnosis labels, and designate race, sex, and age group as potentially sensitive attributes alongside other demographic factors. Notably, the female group, identified by sex, is characterized by fewer samples and higher algorithmic bias, resulting in marginal prediction sets with low group-conditional coverage. By contrast, the model leads to no significant disparities across races and age groups in this dataset. ", "page_idx": 2}, {"type": "text", "text": "For two example patients from the critical group, the standard marginal prediction sets fail to cover the true label. Conversely, sets calibrated for exhaustive equalized coverage are too conservative to be informative. By contrast, AFCP generates prediction sets that are both efficient and fair. ", "page_idx": 2}, {"type": "text", "text": "Without additional sample splitting, which would be inefficient, constructing informative prediction sets that satisfy (3) is challenging due to potential selection bias from using the same data for attribute selection and conformal calibration. This paper presents a novel solution to address this challenge. ", "page_idx": 2}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/94c682aba42c9e6be609fd76f62f1cd789c958adf0ca56bd636de2ca529ce473.jpg", "img_caption": ["Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "1.4 Table of Contents ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Section 2 presents our AFCP method, focusing on the special case in which at most one sensitive attribute may be selected. Section 3 demonstrates the empirical performance of AFCP on synthetic and real data. Section 4 discusses some limitations and suggests ideas for future work. ", "page_idx": 3}, {"type": "text", "text": "Additional content is presented in the Appendices. Appendix A1 reviews relevant details of existing approaches. Appendices A2 and A3 present two extensions of our method, respectively enabling the selection of more than one sensitive attribute and providing valid coverage also conditional on the true test label; both extensions involve distinct technical challenges. Additionally, a variation of AFCP designed for outlier detection tasks is detailed in Appendix A4. Appendix A5 contains all mathematical proofs. Appendix A6 explains how to implement our method efficiently and studies its computational cost. Appendix A7 describes the results of numerous additional experiments. ", "page_idx": 3}, {"type": "text", "text": "1.5 Related Works ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Conformal inference is a very active research area, with numerous methods addressing diverse tasks, including outlier detection [21\u201323], classification [24\u201328], and regression [29\u201331]. Overcoming the limitations of the standard marginal coverage guarantees (1) is a main interest in this field. ", "page_idx": 3}, {"type": "text", "text": "Some works have proposed conformity scores designed to seek high feature-conditional coverage while calibrating prediction sets for marginal coverage [27, 30]. Others attempt to mitigate overconfidence while training the ML model [32, 33], and several have developed calibration methods for non-exchangeable data, accounting for possible distribution shifts [34\u201338]. These works are complementary to ours, as we focus on guaranteeing a new adaptive notion of equalized coverage. ", "page_idx": 3}, {"type": "text", "text": "In addition to [17], several other works have considered constructing prediction sets adhering to various notions of equalized coverage and have empirically investigated the performance of conformal predictors in this regard [39]. In the context of regression, [40] and [41] proposed strategies to enhance conditional coverage given several protected attributes, but they targeted a different notion of equalized coverage designed for continuous outcomes. In classification, a classical approach to move beyond marginal coverage is label-conditional coverage, where the \u201cprotected\u201d groups are defined not based on the features $X_{n+1}$ but by the label itself, $Y_{n+1}$ [42\u201344]. As explained in Appendix A3, the method proposed in this paper can also be extended to provide label-conditional coverage. ", "page_idx": 3}, {"type": "text", "text": "More closely related to the notion of equalized coverage [17] are the works of [45, 46], which differ from ours as they do not consider the automatic selection of the sensitive groups. To tackle a related challenge due to unknown biased attributes, [47] studied how to identify unfairly treated groups by establishing a simultaneously valid confidence bound on group-wise disparities. In principle, their approach can be integrated within the selection component of our method. Very recently, [48] proposed an elegant method to obtain valid conformal prediction sets for adaptively selected subsets of test cases. While their perspective aligns more closely with ours, their approach and focus differ as they study different selection rules not specifically aimed at mitigating algorithmic bias. ", "page_idx": 3}, {"type": "text", "text": "2 Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "2.1 Automatic Attribute Selection ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Given a pre-trained classifier, an independent calibration data set $\\mathcal{D}$ , and a test point $Z_{n+1}\\ =$ $(X_{n+1},\\Bar{Y_{n+1}})$ with an unknown label $Y_{n+1}$ , we will select (at most) one sensitive attribute, $\\hat{A}(X_{n+1})\\in\\{\\varnothing,\\{1\\},\\ldots,\\{K\\}\\}$ , according to the following leave-one-out procedure. ", "page_idx": 4}, {"type": "text", "text": "For each $y\\,\\in\\,[L]$ , imagine $Y_{n+1}$ is equal to $y$ , and define an augmented calibration set $\\mathcal{D}_{y}^{\\prime}\\;:=\\;$ $D\\cup\\{(X_{n+1},y)\\}$ . For each $i\\in[n+1]$ , define also the leave-one-out set $\\mathcal{D}_{y,i}^{\\prime}:=\\mathcal{D}_{y}^{\\prime}\\setminus\\{(X_{i},\\bar{Y}_{i})\\}$ , with $y$ acting as a placeholder for $Y_{n+1}$ . Then, for each $i\\,\\in\\,[n+1]$ , we construct a conformal prediction set $\\hat{C}_{y}^{\\mathrm{loo}}(X_{i})$ for $Y_{i}$ given $X_{i}$ by calibrating the classifier using the data in $\\mathcal{D}_{y,i}^{\\prime}$ . Any method can be applied for this purpose, although it may be helpful for concreteness to focus on employing the standard approach seeking marginal coverage (1) using the adaptive conformity scores proposed by [27]. Let $E_{y,i}$ denote the binary indicator of whether $\\hat{C}_{y}^{\\mathrm{loo}}(X_{i})$ fails to cover $Y_{i}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nE_{y,i}:=\\mathbf{1}\\{Y_{i}\\notin\\hat{C}_{y}^{\\mathrm{loo}}(X_{i})\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "After evaluating $E_{y,i}$ for all $i\\in[n+1]$ , we will assess the leave-one-out miscoverage rate for the worst-off group identified by each sensitive attribute $k\\in[K]$ . That is, we evaluate ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\delta_{y,k}:=\\operatorname*{max}_{m\\in[M_{k}]}\\frac{\\sum_{i=1}^{n+1}E_{y,i}\\cdot\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}{\\sum_{i=1}^{n+1}\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Intuitively, $\\delta_{y,k}$ denotes the maximum miscoverage rate across all groups identified by the $k$ -th attribute. Large values of $\\delta_{y,k}$ suggest that the $k$ -th attribute may be a sensitive attribute corresponding to at least one group suffering from algorithmic bias. ", "page_idx": 4}, {"type": "text", "text": "To assess whether there is evidence of significant algorithmic bias, we can perform a statistical test for the null hypothesis that no algorithmic bias exists. Note that this test can be heuristic since it does not need to be exact for our method to rigorously guarantee (3). Therefore, we do not need to carefully consider the assumptions underlying this test. As a useful heuristic, we define: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{q}_{y}:=\\operatorname*{max}_{k\\in[K]}\\delta_{y,k},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and carry out a one-sided t-test for the null hypothesis $H_{0}:\\hat{q}_{y}\\le\\alpha$ against $H_{1}:\\hat{q}_{y}>\\alpha$ . ", "page_idx": 4}, {"type": "text", "text": "If $H_{0}$ is rejected (at any desired level, like $5\\%$ ), we conclude there exists a group suffering from significant algorithmic bias, and we identify the corresponding attribute through ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{A}(X_{n+1},y)=\\underset{k\\in[K]}{\\arg\\operatorname*{max}}\\,\\delta_{y,k}\\Bigr\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Otherwise, we set $\\hat{A}(X_{n+1},y)=\\emptyset$ , which corresponds to selecting no attribute. See Algorithm 1 for an outline of this procedure, as a function of the placeholder label $y$ . ", "page_idx": 4}, {"type": "text", "text": "After repeating this procedure for each $y\\in[L]$ , the final selected attribute $\\hat{A}(X_{n+1})$ is: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{A}(X_{n+1})=\\cap_{y\\in[L]}\\hat{A}(X_{n+1},y).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Therefore, an attribute is selected if and only if it is consistently flagged by our leave-one-out procedure for all values of the placeholder label $y\\in[L]$ . This approach minimizes the potential arbitrariness due to the use of a placeholder label and is necessary to guarantee that our method constructs prediction sets achieving (3), as discussed in the next section. ", "page_idx": 4}, {"type": "text", "text": "Before explaining how our method utilizes the selected sensitive attribute obtained in (7) to construct prediction sets satisfying (3), we pause to make two remarks. First, as long as $n$ is large enough, $\\hat{A}(X_{n+1},y)$ is quite stable with respect to both $X_{n+1}$ and $y$ , as each of these variables plays a relatively small role in determining the leave-one-out miscoverage rates. Therefore, the selected attribute $\\hat{A}(X_{n+1})$ given by (7) is also quite stable for different values of $X_{n+1}$ . This stability will be demonstrated empirically in Section 3. Second, despite its iterative nature, our method can be implemented efficiently; see Appendix A6. Further, if $n$ is very large, our method could be streamlined using cross-validation instead of a leave-one-out approach. ", "page_idx": 4}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/4b9324435bb857d7190a992044145f8a880763950270ba8779aa04af5aa0f7b1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "2.2 Constructing the Adaptive Prediction Sets ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "After evaluating $\\hat{A}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ for $Y_{n+1}$ for all $y\\in[L]$ , and selecting either an empty set or a single attribute $\\hat{A}(X_{n+1})$ using (7), AFCP constructs an adaptive prediction set for $Y_{n+1}$ that satisfies (3) as follows. ", "page_idx": 5}, {"type": "text", "text": "First, it constructs a marginal conformal prediction set $\\hat{C}^{\\mathrm{m}}(X_{n+1})$ targeting (1), by applying the standard approach reviewed in Appendix A1. Then, for each $y\\in[L]$ , it constructs a conformal prediction set $\\hat{C}(\\bar{X}_{n+1},\\hat{A}(X_{n+1},y))$ with equalized coverage for the group identified by attribute $\\hat{A}(X_{n+1},y)$ , as if it had been fixed. This is achieved by applying the standard marginal method based on a restricted calibration sample indexed by $\\{i\\in\\bar{[n]}:\\dot{\\phi}(X_{i},\\hat{A}(X_{n+1},y))=\\bar{\\phi}(X_{n+1},\\hat{A}(X_{n+1},y))\\}$ ; see Algorithm A1 in Appendix A1 for further details. Therefore, note that $\\phi(X_{i},\\hat{A}(X_{n+1},y))$ becomes equivalent to ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})$ if $\\hat{A}(X_{n+1},y)=\\varnothing$ . Finally, the AFCP prediction set for $Y_{n+1}$ is given by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{C}(X_{n+1})=\\hat{C}^{\\mathrm{m}}(X_{n+1})\\cup\\left\\{\\cup_{y=1}^{L}\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))\\right\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "See Algorithm 2 for an outline of this procedure. ", "page_idx": 5}, {"type": "text", "text": "Note that the AFCP set ${\\hat{C}}(X_{n+1})$ given by (8) always contains the marginal set ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})$ ; this is essential to prove the validity of our approach. Second, in practice the selection $\\hat{A}(X_{n+1},y)$ tends to be very consistent for different values of the placeholder label $y$ , as long as the sample size $n$ is large enough; therefore, the union in (8) will typically not lead to a very large prediction set. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 2 Adaptively Fair Conformal Prediction (AFCP). ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point with features $X_{n+1}$ ; list of $K$ sensitive attributes;   \n2: pre-trained classifier $\\hat{f}$ ; fixed rule for computing nonconformity scores; level $\\alpha\\in(0,1)$ .   \n3: for $y\\in[L]$ do   \n4: Select an attribute $\\hat{A}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ .   \n5: Construct ${\\hat{C}}(X_{n+1},A)$ by applying Algorithm A1 with the attribute $A=\\hat{A}(X_{n+1},y)$ .   \n6: end for   \n7: Construct ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})$ by applying Algorithm A1 without protected attributes.   \n8: Output: selected attribute $\\hat{A}(X_{n+1})$ given by (7) and prediction set ${\\hat{C}}(X_{n+1})$ given by (8). ", "page_idx": 5}, {"type": "text", "text": "The following result, proved in Appendix A5, establishes that the prediction sets ${\\hat{C}}(X_{n+1})$ output by AFCP guarantee adaptive equalized coverage (3) with respect to the adaptively selected attribute $\\hat{A}(X_{n+1})$ . It is worth emphasizing this result is not straightforward and involves an innovative proof technique to address the lack of exchangeability introduced by the adaptive selection step. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. If $\\{(X_{i},Y_{i})\\}_{i=1}^{n+1}$ are exchangeable, the prediction set ${\\hat{C}}(X_{n+1})$ and the selected attribute $\\hat{A}(X_{n+1})$ output by Algorithm 2 satisfy the adaptive equalized coverage defined in (3). ", "page_idx": 5}, {"type": "text", "text": "3 Numerical Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "3.1 Setup and Benchmarks ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section demonstrates the empirical performance of AFCP, focusing on the implementation described in Section 2, which selects at most one sensitive attribute. Our method is compared with three existing approaches, which utilize the same data, ML model, and conformity scores but produce prediction sets with different guarantees. The first is the marginal benchmark, which constructs prediction sets guaranteeing (1) by applying Algorithm A1 without protected attributes. The second is the exhaustive equalized benchmark, which constructs prediction sets guaranteeing (2) by applying Algorithm A1 with all $K$ sensitive attributes simultaneously protected. The third is a partial equalized benchmark that separately applies Algorithm A1 with each possible protected attribute $k\\in[K]$ , and then takes the union of all such prediction sets. This is an intuitive approach that can be easily verified to provide a coverage guarantee intermediate between (2) and (3), namely: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid\\phi(X_{n+1},\\{k\\})]\\ge1-\\alpha,\\quad\\forall k\\in[K].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "However, we will see that these prediction sets are often still too conservative in practice. ", "page_idx": 6}, {"type": "text", "text": "In addition, we apply a variation of AFCP that always selects one sensitive attribute, regardless of the outcome of the significance test. This method is denoted as AFCP1 in our experiments. ", "page_idx": 6}, {"type": "text", "text": "For all methods considered, the classifier is based on a five-layer neural network with linear layers interconnected via a ReLU activation function. The output layer uses a softmax function to estimate the conditional label probabilities. The Adam optimizer and cross-entropy loss function are used in the training process, with a learning rate set at 0.0001. The loss values demonstrate convergence after 100 epochs of training. For all methods, the miscoverage target level is set at $\\alpha=0.1$ . ", "page_idx": 6}, {"type": "text", "text": "3.2 Synthetic Data ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We generate synthetic classification data to mimic a medical diagnosis task with six possible labels: Skin cancer, Diabetes, Asthma, Stroke, Flu, and Epilepsy. The available features include three sensitive attributes\u2014Age Group, Region, and Color\u2014and six additional non-sensitive covariates. Color is categorized as Blue or Grey, with $10\\%$ and $90\\%$ marginal frequencies, respectively. The Age Group is cyclically repeated as $<18,18-24,25-40,41-65,>65$ , and Region is sampled from an i.i.d. multinomial distribution across $\\{\\mathrm{West}$ , East, North, South $\\}$ with equal probabilities. The six non-sensitive features are i.i.d. random samples from a uniform distribution on $[0,1]$ . For simplicity, Color is denoted as $X_{0}$ and the first non-sensitive feature as $X_{1}$ . Conditional on $X$ , the label $Y$ is generated based on a decision tree model that depends only on $X_{0}$ and $X_{1}$ , as detailed in Appendix A7. This model is designed so that the diagnosis label for individuals with Color equal to Blue is intrinsically harder to predict, mimicking the presence of algorithmic bias. ", "page_idx": 6}, {"type": "text", "text": "Figure 3 shows the performance of all methods as a function of the total sample size, ranging from 200 to 2000. In each case, $50\\%$ of the samples are used for training and the remaining $5\\bar{0}\\%$ for calibration. Results are averaged over 500 test points and 100 independent experiments. ", "page_idx": 6}, {"type": "text", "text": "While the marginal benchmark produces the smallest prediction sets on average, it leads to significant empirical undercoverage within the Blue group. In contrast, the exhaustive benchmark, which achieves the highest coverage overall, tends to lead to overly conservative and thus uninformative prediction sets, especially for the Blue group. The partial benchmark, though less conservative than the exhaustive method, still generates prediction sets that are too large when the sample size is small. ", "page_idx": 6}, {"type": "text", "text": "Our AFCP method and its simpler variation, AFCP1, not only achieve valid coverage for the Blue group but do so with prediction sets that, on average, are not much larger than the marginal ones. AFCP1 is slightly more robust than AFCP when the sample size is very small, as it never fails to select a sensitive attribute. This is advantageous in scenarios where we know there is a sensitive attribute worth equalizing coverage for, though this may not always be the case in practice. See Figure A1 and Table A1 for detailed results with standard errors. ", "page_idx": 6}, {"type": "text", "text": "Figure 4 provides additional insight into our method\u2019s performance by plotting the selection frequencies of each sensitive attribute as a function of sample size, within the same experiments described in Figure 3. These results show that our method behaves as anticipated. When the sample size and algorithmic bias are both small, AFCP shows more variability in selecting the sensitive attribute, often selecting no attributes. However, as the sample size grows and the undercoverage affecting the Blue group becomes more pronounced, AFCP consistently selects Color as the most sensitive attribute, correctly identifying the main manifestation of algorithmic bias in these data. ", "page_idx": 6}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/47fed4a0586843272886f8d147ed2fd891dda517175f895d352c5b5a723baf0e.jpg", "img_caption": ["Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/022a24969f541b175d5c32f780a577d223a5e5c82be204ccc36cd28d33a1eabf.jpg", "img_caption": ["Figure 4: Selection frequency of different attributes using our AFCP method and its variation, AFCP1, in the experiments of Figure 3. As the sample size increases, AFCP becomes more consistent in selecting the most relevant attribute, Color. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Additional results are presented in Appendix A7.1.1. Figures A1\u2013A3 and Tables A2\u2013A4 summarize the average coverage and prediction set size conditional on each protected attribute. Figures A4\u2013A7 and Tables A5\u2013A8 study the performance of an extension of our method that also provides valid coverage conditional on the true label of the test point. ", "page_idx": 7}, {"type": "text", "text": "3.3 Nursery data ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We apply AFCP and its benchmarks to the open-domain Nursery data set [49], which was derived from a hierarchical decision model originally developed to rank applications for nursery schools for social science studies. The data encompass 12,960 instances with eight categorical features: Parents\u2019 occupation (3 levels), Child\u2019s nursery (5 levels), Family form (4 levels), Number of children (1, 2, 3, or more), Housing conditions (3 levels), Financial standing (2 levels), Social conditions (3 levels), and Health status (3 levels). These features are used to predict application ranks across five categories. The variables \u201cParents\u2019 occupation\", \u201cNumber of children\", \u201cFinancial standing\", \u201cSocial conditions\", and \u201cHealth status\" are marked as possible sensitive attributes. ", "page_idx": 7}, {"type": "text", "text": "To prepare for model training, we executed several pre-processing steps. First, two instances labeled \u201crecommend\" were removed due to the minimal occurrence of this outcome label. Subsequently, we utilized the LabelEncoder function in the sklearn Python package to numerically encode all features and labels. To make the problem more interesting and allow control over the strength of algorithmic bias, we added independent, uniformly distributed noise to the labels of samples with Parents\u2019 occupation in the first category, rounding these perturbed labels to the nearest integer. This makes the group corresponding to the first category of Parents\u2019 occupation intrinsically more unpredictable and hence more prone to algorithmic bias. To enhance the challenge of making accurate predictions for this group, it was further down-sampled to $10\\%$ of its original size. ", "page_idx": 7}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/d11b1f96d5e84e59d39bfb7d4ace12c3090ea36aaf4eabf6bc002836260963d1.jpg", "img_caption": ["Figure 5: Performance of prediction sets constructed by different methods on the Nursery data, as a function of the sample size. AFCP leads to more informative predictions with higher coverage conditional on the sensitive attribute, Parents\u2019 occupation (shown explicitly for level one). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 5 summarizes the performance of all approaches as a function of the total number of training and calibration data points, which varies between 200 and 5000. The results are averaged over 500 randomly chosen test points and 100 repeated experiments. In each experiment, $50\\%$ of the samples are randomly assigned for training and the remaining $50\\%$ for calibration. The marginal benchmark is heavily biased, leading to prediction sets with very low coverage for samples with Parents\u2019 occupation in the first category. The exhaustive benchmark is too conservative and results in very large prediction sets unless the sample size is very large. The partial benchmark performs better than the other two benchmarks, but our AFCP method still outperforms it, producing smaller prediction sets with valid coverage even for the hardest-to-predict group. See Table A9 for detailed results. ", "page_idx": 8}, {"type": "text", "text": "The results of additional experiments are presented in Appendix A7.1.2. Figures A8\u2013A12 and Tables A10\u2013A14 detail the average coverage and prediction set size for each sensitive attribute. Additionally, Figures A13\u2013A18 and Tables A15\u2013A20 report on the performance of an extended version of AFCP which also ensured valid coverage conditional on the true test label. ", "page_idx": 8}, {"type": "text", "text": "3.4 Additional Numerical Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Figures A19\u2013A21 and Table A21 in Appendix A7.1.3 summarize additional experimental results using the open-source COMPAS dataset [50]. Moreover, Appendix A7.2 demonstrates the empirical performance of our AFCP extension for outlier detection; see Figures A22\u2013A36 and Tables A22\u2013A34. These demonstrations involve both synthetic data and the open-domain Adult Income dataset [51]. The experiments with the real-world Adult Income data also include an AFCP extension that allows for the selection of multiple sensitive attributes at the same time. ", "page_idx": 8}, {"type": "text", "text": "3.5 Performance of AFCP with Different Sample Sizes ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Constructing informative prediction sets that achieve high conditional coverage is inherently more challenging when dealing with smaller sample sizes. By experimenting with different sample sizes, we demonstrate that our AFCP method consistently performs well across different scenarios. For instance, in the experiments depicted in Figures 3\u20134, when the sample size is as small as 200, it is difficult to fit an accurate predictive model, assess conditional coverage, and reliably identify the sensitive attribute associated with the lowest coverage. This difficulty is reflected in the relatively large sizes of the prediction sets produced by all methods and the substantial discrepancies between the nominal and empirical conditional coverage. Despite these challenges, our method often succeeds in selecting the correct sensitive attribute, achieving significantly higher conditional coverage compared to the Marginal benchmark, with only a slight increase in average prediction set size. ", "page_idx": 8}, {"type": "text", "text": "Moreover, as the sample size increases, our method becomes highly effective at identifying the attribute associated with the lowest conditional coverage, as illustrated in Figure 4. Consequently, our method is able to achieve high conditional coverage with relatively small prediction sets. Overall, these experiments demonstrate that our method offers distinct advantages over existing approaches in both large-sample and small-sample settings. ", "page_idx": 8}, {"type": "text", "text": "3.6 Comparison between AFCP and AFCP1 ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Both AFCP and AFCP1 outperform the benchmark approaches when applied to datasets with small sample sizes, each excelling in different scenarios. AFCP is better suited to situations where there is uncertainty regarding the presence of significant algorithmic bias, while AFCP1 is more effective when prior knowledge suggests that at least one attribute may be biased. For example, in Figure 3, which illustrates a case where one group (Color-Blue) is consistently biased, AFCP1 achieves slightly higher conditional coverage than AFCP. While AFCP exhibits slight undercoverage for the blue group with small sample sizes, it still outperforms the Marginal approach. The occasional inability of AFCP to select a sensitive attribute in small samples reflects the inherent challenges posed by limited datasets. When the method does not select an attribute, it often signifies a lack of sufficient evidence of algorithmic bias, making it reasonable to calibrate the prediction sets solely for marginal coverage. ", "page_idx": 9}, {"type": "text", "text": "4 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper presents a practical and statistically principled method to construct informative conformal prediction sets with valid coverage conditional on adaptively selected features. This approach balances efficiency and equalized coverage, which may be particularly useful in applications involving multiple sensitive attributes. While we believe it offers substantial beneftis, a potential limitation of this method is that it does not always identify the most relevant sensitive attribute, particularly when working with limited sample sizes. Nevertheless, our empirical results are quite encouraging, demonstrating that AFCP effectively mitigates significant instances of algorithmic bias when the sample size is adequate. Moreover, our method is flexible, allowing for the integration of prior knowledge about which sensitive attributes might require protection against algorithmic bias. ", "page_idx": 9}, {"type": "text", "text": "This paper creates several opportunities for further work. Future research could focus on theoretically studying the conditions under which our method can be guaranteed to select the correct sensitive attribute with high probability. Additionally, future extensions might explore implementing different attribute selection procedures, such as those inspired by [47] - within our flexible AFCP framework to delve into the subtle trade-offs associated with different selection algorithms. Moreover, adapting our approach to accommodate different fairness criteria by adaptively adjusting the coverage rate target for each subgroup is another promising area of study. Extending our method to more efficiently handle scenarios with an extremely high number of possible classes is also worthwhile, potentially drawing inspiration from [43]. Furthermore, investigating extensions for classification tasks where the target variable is ordered could be both intriguing and practically useful. In such cases, a naive modification of our method would involve utilizing the discrete convex hull of all components instead of unions of subintervals on the right-hand side of Equation (8). However, developing a more refined approach would be a valuable contribution for future work. Future extensions of our work could focus on adapting to distributional shifts or enhancing the robustness and efficiency of our method under adversarial attacks or contaminated data, potentially drawing connections with [52\u201356]. Finally, extending our method to accommodate regression tasks with continuous outcomes presents additional computational challenges, but potential solutions could be inspired by [33]. ", "page_idx": 9}, {"type": "text", "text": "The numerical experiments described in this paper were carried out on a computing cluster. Individual experiments, involving 1000 calibration samples and 500 test samples, required less than 25 minutes and 5GB of memory on a single CPU. The entire project took approximately 100 hours of computing time, and did not involve preliminary or failed experiments. ", "page_idx": 9}, {"type": "text", "text": "Software implementing the algorithms and data experiments are available online at https://github.   \ncom/FionaZ3696/Adaptively-Fair-Conformal-Prediction. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The authors thank anonymous reviewers for helpful comments, and the Center for Advanced Research Computing at the University of Southern California for providing computing resources. M. S. and Y. Z. were partly supported by NSF grant DMS 2210637. M. S. was also partly supported by an Amazon Research Award. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] A. Jones, B. Smith, and C. Johnson. Deep learning models for medical diagnosis. Journal of Medical Imaging, 7(2):021008, 2020.   \n[2] J. K. Brown et al. Using machine learning for job application screening: A comparative analysis. In International Conference on Artificial Intelligence in HR, pages 12\u201321, 2021.   \n[3] Jiaming Zeng, Berk Ustun, and Cynthia Rudin. Interpretable classification models for recidivism prediction. J. R. Stat. Soc. (A), 180(3):689\u2013722, 2017.   \n[4] Arun K Kuchibhotla and Richard A Berk. Nested conformal prediction sets for classification with applications to probation data. Ann. Appl. Stat., 17(1):761\u2013785, 2023.   \n[5] Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In IEEE Conference on Computer Vision and Pattern Recognition, pages 427\u2013436, 2015.   \n[6] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In Int. Conf. Mach. Learn., pages 1321\u20131330. PMLR, 2017.   \n[7] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness. In Innovations in Theoretical Computer Science Conference, page 214\u2013226. Association for Computing Machinery, 2012.   \n[8] Richard Zemel, Yu (Ledell) Wu, Kevin Swersky, Toniann Pitassi, and Cyntia Dwork. Learning fair representations. In Int. Conf. Mach. Learn., 2013.   \n[9] Moritz Hardt, Eric Price, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In Adv. Neural. Inf. Process. Syst., volume 29, 2016.   \n[10] Richard A Berk, Arun Kumar Kuchibhotla, and Eric Tchetgen Tchetgen. Improving fairness in criminal justice algorithmic risk assessments using optimal transport and conformal prediction sets. Sociological Methods & Research, 2021.   \n[11] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model\u2019s uncertainty? evaluating predictive uncertainty under dataset shift. Adv. Neural Inf. Process. Syst., 32, 2019.   \n[12] Harris Papadopoulos, Kostas Proedrou, Vladimir Vovk, and Alex Gammerman. Inductive confidence machines for regression. In Eur. Conf. Mach. Learn., pages 345\u2013356, 2002.   \n[13] Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic learning in a random world. Springer, 2005.   \n[14] Jing Lei, Max G\u2019Sell, Alessandro Rinaldo, Ryan J. Tibshirani, and Larry Wasserman. Distribution-free predictive inference for regression. J. Am. Stat. Assoc., 113(523):1094\u20131111, 2018.   \n[15] Deborah Hellman. Measuring algorithmic fairness. Virginia Law Review, 106(4):811\u2013866, 2020.   \n[16] Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data, 5(2):153\u2013163, 2017.   \n[17] Yaniv Romano, Rina Foygel Barber, Chiara Sabatti, and Emmanuel Cand\u00e8s. With malice toward none: Assessing uncertainty via equalized coverage. Harvard Data Science Review, 2020.   \n[18] Jianqing Fan, Xin Tong, Yanhui Wu, and Shunan Yao. Neyman-Pearson and equal opportunity: when efficiency meets fairness in classification. arXiv preprint arXiv:2310.01009, 2023.   \n[19] Rina Foygel Barber, Emmanuel J Cand\u00e8s, Aaditya Ramdas, and Ryan J Tibshirani. The limits of distribution-free conditional predictive inference. Information and Inference, 10(2):455\u2013482, 2021.   \n[20] Yonghoon Lee and Rina Barber. Distribution-free inference for regression: discrete, continuous, and in between. Adv. Neural Inf. Process. Syst., 34:7448\u20137459, 2021.   \n[21] Stephen Bates, Emmanuel Cand\u00e8s, Lihua Lei, Yaniv Romano, and Matteo Sesia. Testing for outliers with conformal p-values. Ann. Stat., 51(1):149 \u2013 178, 2023.   \n[22] Ariane Marandon, Lihua Lei, David Mary, and Etienne Roquain. Adaptive novelty detection with false discovery rate guarantee. Ann. Stat., 52(1):157\u2013183, 2024.   \n[23] Ziyi Liang, Matteo Sesia, and Wenguang Sun. Integrative conformal p-values for out-ofdistribution testing with labelled outliers. J. R. Stat. Soc. (B), page qkad138, 2024.   \n[24] Jing Lei, James Robins, and Larry Wasserman. Distribution-free prediction sets. J. Am. Stat. Assoc., 108(501):278\u2013287, 2013.   \n[25] Mauricio Sadinle, Jing Lei, and Larry Wasserman. Least ambiguous set-valued classifiers with bounded error levels. J. Am. Stat. Assoc., 114(525):223\u2013234, 2019.   \n[26] Aleksandr Podkopaev and Aaditya Ramdas. Distribution-free uncertainty quantification for classification under label shift. In Uncertainty in Artificial Intelligence, pages 844\u2013853. PMLR, 2021.   \n[27] Yaniv Romano, Matteo Sesia, and Emmanuel J. Cand\u00e8s. Classification with valid and adaptive coverage. Adv. Neural Inf. Process. Syst., 33, 2020.   \n[28] Anastasios Nikolas Angelopoulos, Stephen Bates, Michael Jordan, and Jitendra Malik. Uncertainty sets for image classifiers using conformal prediction. In Int. Conf. Learn. Represent., 2021.   \n[29] Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression. J. R. Stat. Soc. (B), 76(1):71\u201396, 2014.   \n[30] Yaniv Romano, Evan Patterson, and Emmanuel J Cand\u00e8s. Conformalized quantile regression. In Adv. Neural Inf. Process. Syst., pages 3538\u20133548, 2019.   \n[31] Matteo Sesia and Yaniv Romano. Conformal prediction using conditional histograms. Adv. Neural Inf. Process. Syst., 34, 2021.   \n[32] Bat-Sheva Einbinder, Yaniv Romano, Matteo Sesia, and Yanfei Zhou. Training uncertaintyaware classifiers with conformalized deep learning. In Adv. Neural Inf. Process. Syst., volume 35, 2022.   \n[33] Ziyi Liang, Yanfei Zhou, and Matteo Sesia. Conformal inference is (almost) free for neural networks trained with early stopping. In Int. Conf. Mach. Learn., 2023.   \n[34] Rina Foygel Barber, Emmanuel J Cand\u00e8s, Aaditya Ramdas, and Ryan J Tibshirani. Conformal prediction beyond exchangeability. Ann. Stat., 51(2):816\u2013845, 2023.   \n[35] Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Cand\u00e8s, and Aaditya Ramdas. Conformal prediction under covariate shift. Adv. Neural Inf. Process. Syst., 32, 2019.   \n[36] Isaac Gibbs and Emmanuel Cand\u00e8s. Conformal inference for online prediction with arbitrary distribution shifts. arXiv preprint arXiv:2208.08401, 2022.   \n[37] Yachong Yang, Arun Kumar Kuchibhotla, and Eric Tchetgen Tchetgen. Doubly robust calibration of prediction sets under covariate shift. J. R. Stat. Soc. (B), page qkae009, 2024.   \n[38] Ziyi Liang, Tianmin Xie, Xin Tong, and Matteo Sesia. Structured conformal inference for matrix completion with applications to group recommender systems. arXiv preprint arXiv:2404.17561, 2024.   \n[39] Charles Lu, Andreanne Lemay, Ken Chang, Katharina Hoebel, and Jayashree Kalpathy-Cramer. Fair conformal predictors for applications in medical imaging. AAAI Conference on Artificial Intelligence, 36:12008\u201312016, 06 2022.   \n[40] Fangxin Wang, Lu Cheng, Ruocheng Guo, Kay Liu, and Philip S. Yu. Equal opportunity of coverage in fair regression. In Adv. Neural Inf. Process. Syst, 2023.   \n[41] Meichen Liu, Lei Ding, Dengdeng Yu, Wulong Liu, Linglong Kong, and Bei Jiang. Conformalized fairness via quantile regression. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Adv. Neural Inf. Process. Syst., 2022.   \n[42] Vladimir Vovk, David Lindsay, Ilia Nouretdinov, and Alex Gammerman. Mondrian confidence machine. Technical report, Royal Holloway, University of London, 2003. On-line Compression Modelling project.   \n[43] Tiffany Ding, Anastasios Nikolas Angelopoulos, Stephen Bates, Michael Jordan, and Ryan Tibshirani. Class-conditional conformal prediction with many classes. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview. net/forum?id=mYz6ApeU4J.   \n[44] Tuve L\u00f6fstr\u00f6m, Henrik Bostr\u00f6m, Henrik Linusson, and Ulf Johansson. Bias reduction through conditional conformal prediction. Intell. Data Anal., 19(6):1355\u20131375, nov 2015. ISSN 1088-467X.   \n[45] Christopher Jung, Georgy Noarov, Ramya Ramalingam, and Aaron Roth. Batch multivalid conformal prediction. In Int. Conf. Learn. Represent., 2023.   \n[46] Isaac Gibbs, John J Cherian, and Emmanuel J Cand\u00e8s. Conformal prediction with conditional guarantees. arXiv preprint arXiv:2305.12616, 2023.   \n[47] John J. Cherian and Emmanuel J. Cand\u00e8s. Statistical inference for fairness auditing. arXiv preprint arXiv:2305.03712, 2023.   \n[48] Ying Jin and Zhimei Ren. Confidence on the focal: Conformal prediction with selectionconditional coverage. arXiv preprint arXiv:2403.03868, 2024.   \n[49] Vladislav Rajkovic. Nursery. UCI Machine Learning Repository, 1997. DOI: https://doi.org/10.24432/C5P88W, License: CC-BY 4.0.   \n[50] Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. How we analyzed the compas recidivism algorithm. https://www.propublica.org/article/ how-we-analyzed-the-compas-recidivism-algorithm, 2016.   \n[51] Barry Becker and Ronny Kohavi. Adult. UCI Machine Learning Repository, 1996. DOI: https://doi.org/10.24432/C5XW20, License: CC-BY 4.0.   \n[52] Bat-Sheva Einbinder, Stephen Bates, Anastasios N Angelopoulos, Asaf Gendler, and Yaniv Romano. Conformal prediction is robust to label noise. arXiv preprint arXiv:2209.14295, 2022.   \n[53] Ge Yan, Yaniv Romano, and Tsui-Wei Weng. Provably robust conformal prediction with improved efficiency. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $\\equiv$ BWAhEjXjeG.   \n[54] Asaf Gendler, Tsui-Wei Weng, Luca Daniel, and Yaniv Romano. Adversarially robust conformal prediction. In International Conference on Learning Representations, 2022. URL https: //openreview.net/forum?id $\\cdot$ 9L1BsI4wP1H.   \n[55] Shai Feldman, Bat-Sheva Einbinder, Stephen Bates, Anastasios N. Angelopoulos, Asaf Gendler, and Yaniv Romano. Conformal prediction is robust to dispersive label noise. In Harris Papadopoulos, Khuong An Nguyen, Henrik Bostr\u00f6m, and Lars Carlsson, editors, Proceedings of the Twelfth Symposium on Conformal and Probabilistic Prediction with Applications, volume 204 of Proceedings of Machine Learning Research, pages 624\u2013626. PMLR, 13\u201315 Sep 2023. URL https://proceedings.mlr.press/v204/feldman23a.html.   \n[56] Matteo Sesia, Y. X. Rachel Wang, and Xin Tong. Adaptive conformal classification with noisy labels, 2024. URL https://arxiv.org/abs/2309.05092.   \n[57] Glenn Shafer and Vladimir Vovk. A tutorial on conformal inference. J. Mach. Learn. Res., 9(3), 2008.   \n[58] Tuve L\u00f6fstr\u00f6m, Henrik Bostr\u00f6m, Henrik Linusson, and Ulf Johansson. Bias reduction through conditional conformal prediction. Intell. Data Anal., 19(6):1355\u20131375, 11 2015.   \n[59] COMPAS Data Set. https://github.com/propublica/compas-analysis. Accessed: July, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A1 Review of Existing Conformal Classification Methods ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Algorithm A1 outlines the standard approach for constructing conformal prediction sets with equalized coverage with respect to a fixed list of protected attributes [17]. In the special case where the list of protected attributes is empty, this method reduces to the standard approach for constructing prediction sets with marginal coverage. ", "page_idx": 14}, {"type": "text", "text": "Algorithm A1 Conformal classification with equalized coverage for fixed protected attributes. ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point with features $X_{n+1}$ ; list of protected attributes $A$ ;   \n2: pre-trained classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ .   \n4: Define the calibration subset ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\mathcal{Z}}(X_{n+1},A)=\\left\\{i\\in[n]:\\phi(X_{i},A)=\\phi(X_{n+1},A)\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "5: for $y\\in[L]$ do   \n6: Compute the nonconformity scores $\\hat{S}_{i}^{y}$ for $i\\in\\mathcal{T}(X_{n+1},A)\\cup\\{(X_{n+1},y)\\}$ using $\\hat{f}$ .   \n7: Compute the conformal p-value: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\hat{u}^{y}(X_{n+1})=\\frac{1+|i\\in\\mathbb{Z}(X_{n+1},A):\\hat{S}_{i}^{y}\\leq\\hat{S}_{n+1}^{y}|}{1+|\\mathbb{Z}(X_{n+1},A)|}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "8: end for ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "9: Construct a prediction set using ${\\hat{C}}(X_{n+1})=\\{y\\in[L]:{\\hat{u}}^{y}(X_{n+1})\\geq\\alpha\\}.$   \n10: Output: a prediction set ${\\hat{C}}(X_{n+1})$ . ", "page_idx": 14}, {"type": "text", "text": "In the context of outlier detection, Algorithm A2 reviews the standard approach for computing conformal ${\\bf p}$ -values achieving valid false positive rate (FPR) control conditional a fixed list of protected attributes. ", "page_idx": 14}, {"type": "text", "text": "Algorithm A2 Conformal p-value with equalized FPR for fixed protected attributes. ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point $Z_{n+1}$ ; list of protected attributes $A$ ;   \n2: pre-trained one-class classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ .   \n4: Define the calibration subset ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\mathcal{Z}}(Z_{n+1},A)=\\left\\{i\\in[n]:\\phi(Z_{i},A)=\\phi(Z_{n+1},A)\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "5: Compute the nonconformity scores ${\\hat{S}}_{i}$ for $i\\in{\\mathcal{I}}(Z_{n+1},A)\\cup\\{Z_{n+1}\\}$ using $\\hat{f}$ .   \n6: Compute the conformal p-value: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\hat{u}(Z_{n+1})=\\frac{1+|i\\in\\mathcal{Z}(Z_{n+1},A):\\hat{S}_{i}\\leq\\hat{S}_{n+1}|}{1+|\\mathcal{Z}(Z_{n+1},A)|}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "7: Output: a conformal p-value $\\hat{u}(Z_{n+1})$ . ", "page_idx": 14}, {"type": "text", "text": "A2 Methodology Extension: AFCP with Multiple Selected Attributes ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "This section introduces an extension of AFCP that enables the selection of more than one sensitive attribute. For simplicity, we focus on the selection of up to two attributes. The methodology for selecting more than two attributes can be extended in a similar manner, as explained later. ", "page_idx": 14}, {"type": "text", "text": "A2.1 Automatic Multiple Attribute Selections ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Given a pre-trained classification model, an independent calibration data set $\\mathcal{D}$ with size $n$ , and a test point $\\bar{Z_{n+1}}=(X_{n+1},Y_{n+1})$ with an unknown label $Y_{n+1}$ , Algorithm 1 in Section 2.1 introduces the AFCP component to select one sensitive attribute according to the leave-one-out procedure. Intuitively, selecting two sensitive attributes requires executing Algorithm 1 twice. However, during the second iteration, the sensitive attribute list is restricted to exclude the most critical protected attribute selected in the first round. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Specifically, for each placeholder label $y\\,\\in\\,[L]$ , assuming $Y_{n+1}\\,=\\,y$ , Algorithm 1 is run with all $K$ sensitive attributes for the first iteration to obtain the first selected attribute $\\hat{A}^{1}(X_{n+1},y)\\in$ $\\{\\varnothing,\\{1\\},\\ldots,\\{K\\}\\}$ . If ${\\hat{A}}^{1}(X_{n+1},y)\\neq\\emptyset$ , Algorithm 1 is run again using the sensitive attributes $[K]\\backslash\\hat{A}^{1}(X_{n+1},y)$ and one can get the second selected attribute $\\hat{A}^{2}(X_{n+1},y)\\in\\{\\varnothing,\\{1\\},\\ldots,\\{K\\}\\}\\backslash$ $\\hat{A}^{1}(X_{n+1},y)$ . Therefore, the identified attributes for test feature $X_{n+1}$ with placeholder $y$ for the test label is the union of the two $\\hat{A}(X_{n+1},y)=\\hat{A}^{1}(X_{n+1},y)\\cup\\hat{A}^{2}(X_{n+1},y)$ . This procedure is outlined in Algorithm A3. ", "page_idx": 15}, {"type": "text", "text": "After repeating this procedure for each $y\\in[L]$ , the final selected attribute $\\hat{A}(X_{n+1})$ is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{A}(X_{n+1})=\\cap_{y\\in[L]}\\hat{A}(X_{n+1},y).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Algorithm A3 Two attributes selection using a placeholder test label. ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point with features $X_{n+1}$ ; list of $K$ sensitive attributes;   \n2: pre-trained classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ , placeholder label $y\\in[L]$ .   \n4: Select the first attribute $\\hat{A}^{1}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ and sensitive attributes $[K]$ .   \n5: if $\\hat{A}^{1}(X_{n+1},y)\\neq\\emptyset$ then   \n6: Select the second attribute $\\hat{A}^{2}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ and sensitive attributes $[K]\\setminus{\\hat{A}}^{1}(X_{n+1},y)$ . ", "page_idx": 15}, {"type": "text", "text": "7: end if ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "8: Output: $\\hat{A}(X_{n+1},y)=\\hat{A}^{1}(X_{n+1},y)\\cup\\hat{A}^{2}(X_{n+1},y)$ , which is a set of an empty set, or a set including one or two selected sensitive attribute(s). ", "page_idx": 15}, {"type": "text", "text": "A2.2 Constructing the Adaptive Prediction Sets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "After selecting a subset of attributes $\\hat{A}(X_{n+1})$ using (A10), which may be empty, or include one or two attributes, AFCP constructs an adaptive prediction set for $Y_{n+1}$ that satisfies (3) as follows. ", "page_idx": 15}, {"type": "text", "text": "First, it constructs a marginal conformal prediction set $\\hat{C}^{\\mathrm{m}}(X_{n+1})$ targeting (1), by applying Algorithm A1 without protected attributes. Then, for each $y\\in[L]$ , it constructs a conformal prediction set $\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))$ with equalized coverage for the group jointly identified by attributes $\\hat{A}(X_{n+1},y)$ . This can be achieved by applying Algorithm A1 with protected attributes $\\hat{A}(X_{n+1},y)$ . Lastly, it constructs a conformal prediction set $\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)$ with equalized coverage separately for each protected attribute $\\ell\\in\\cup_{y\\in[L]}\\hat{A}(X_{n+1},y)$ , by applying the standard approach in Algorithm A1 on the subsets indexed by $\\{i\\in[n]:\\phi(X_{i},\\{\\ell\\})=\\phi(X_{n+1},\\{\\ell\\})\\}$ . ", "page_idx": 15}, {"type": "text", "text": "Finally, the AFCP prediction set constructed using up to two selected attributes is given as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{C}(X_{n+1})=\\hat{C}^{\\mathsf{m}}(X_{n+1})\\cup\\left\\{\\cup_{y=1}^{L}\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))\\right\\}\\cup\\left\\{\\cup_{\\ell\\in\\cup_{y}\\hat{A}(X_{n+1},y)}\\hat{C}^{\\mathsf{e q}}(X_{n+1},\\ell)\\right\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "See Algorithm A4 for an outline of this AFCP extension. ", "page_idx": 15}, {"type": "text", "text": "Theorem A1. If $\\{(X_{i},Y_{i})\\}_{i=1}^{n+1}$ are exchangeable random samples, then the conformal prediction set ${\\hat{C}}(X_{n+1})$ and the selected attributes $\\hat{A}(X_{n+1})$ output by Algorithm A4 satisfy the adaptive equalized coverage defined in (3). ", "page_idx": 15}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point with features $X_{n+1}$ ; list of $K$ sensitive attributes;   \n2: pre-trained classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ .   \n4: for $y\\in[L]$ do   \n5: Select attribute(s) $\\hat{A}(X_{n+1},y)$ by applying Algorithm A3 with placeholder label $y$ .   \n6: Construct ${\\hat{C}}(X_{n+1},A)$ by applying Algorithm A1 with protected attribute(s) ${\\cal A}\\quad=\\quad$   \n$\\hat{A}(X_{n+1},y)$ .   \n7: end for   \n8: for $\\ell\\in\\cup_{y\\in[L]}\\hat{A}(X_{n+1},y)$ do   \n9: Construct $\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)$ by applying Algorithm A1 with protected attribute $\\{\\ell\\}$ .   \n10: end for   \n11: Construct ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})$ by applying Algorithm A1 without protected attributes.   \n12: Define the final selected attribute(s) $\\hat{A}(X_{n+1})$ using Equation (A10).   \n13: Define the final prediction set ${\\hat{C}}(X_{n+1})$ using Equation (A11).   \n14: Output: $\\hat{A}(X_{n+1})$ and $\\hat{C}(X_{n+1})$ . ", "page_idx": 16}, {"type": "text", "text": "A3 Methodology Extension: AFCP with Label Conditional Coverage ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "This section extends the AFCP method with adaptive equalized coverage that is also conditional on the true test label. We focus on the main implementation of AFCP, where it can select up to one sensitive attribute. ", "page_idx": 16}, {"type": "text", "text": "First, the label conditional counterparts of the marginal coverage, the exhaustive equalized coverage, and the adaptive equalized coverage are defined. The label-conditional counterpart of marginal coverage is defined as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y]\\ge1-\\alpha,\\quad\\forall y\\in[L].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Intuitively, this coverage ensures that the prediction sets constructed are valid for each group with the test label $y$ for all possible values of $\\bar{y}\\in[L]$ . This coverage offers a stronger assurance than marginal coverage in classification contexts. However, it overlooks scenarios where groups, identified by feature attributes, may suffer adverse effects from prediction biases. To address these concerns, one can aim for label-conditional exhaustive equalized coverage [17], defined as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},[K])]\\ge1-\\alpha,\\quad\\forall y\\in[L].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Achieving this label conditional exhaustive equalized coverage involves applying the standard conformal classification method (outlined in Algorithm A1) separately within each of the groups characterized by every possible combination of sensitive attributes and test labels. Hence, this approach can become overly conservative when a large number of sensitive attributes or response labels are presented. ", "page_idx": 16}, {"type": "text", "text": "Our AFCP method strikes a balance between the two approaches to achieve label-conditional adaptive equalized coverage: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{A}(X_{n+1}))]\\ge1-\\alpha,\\quad\\forall y\\in[L],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which guarantees that the true test label is contained within the prediction sets with high probability for the groups defined by the selected attribute $\\hat{A}(X_{n+1})$ and the test label $y$ for every $y\\in[L]$ . ", "page_idx": 16}, {"type": "text", "text": "A3.1 Automatic Attribute Selection ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Given a pre-trained classification model and an independent calibration data set $\\mathcal{D}$ with size $n$ , for each placeholder label $y\\in[L]$ for $Y_{n+1}$ , the AFCP method with label-conditional adaptive equalized coverage (A14) selects the sensitive attribute $\\hat{A}(X_{n+1},y)$ by simply applying Algorithm 1 using the label-restricted calibration data $\\mathcal{D}_{y}\\,=\\,\\{i\\,\\in\\,[n]\\,:\\,Y_{i}\\,=\\,y\\}$ . After repeating this process for each $y\\in[L]$ , the final selected attribute $\\hat{A}(X_{n+1})$ is again given by ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{A}(X_{n+1})=\\cap_{y\\in[L]}\\hat{A}(X_{n+1},y).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "A3.2 Constructing the Adaptive Prediction Sets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "After selecting $\\hat{A}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ based on the labelrestricted calibration data $\\mathcal{D}_{y}=\\{i\\in[n]:Y_{i}=y\\}$ , and selecting a sensitive attribute $\\hat{A}(X_{n+1})$ , AFCP constructs an adaptive prediction set for $Y_{n+1}$ that satisfies (A14) as follows. ", "page_idx": 17}, {"type": "text", "text": "For each $y\\ \\in\\ [L]$ , it firstly construct a conformal prediction set $\\hat{C}^{\\mathrm{lc}}(X_{n+1},y)$ by applying Algorithm A1 using the label-restricted calibration set $\\mathcal{D}_{y}$ without considering protected attributes. Then, it constructs another conformal prediction set $\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))$ with equalized coverage for the group identified by both the selected attribute $\\hat{A}(X_{n+1},y)$ and label $y$ . This can be achieved by applying Algorithm A1 based on a subset of the calibration samples indexed by $\\begin{array}{r}{\\mathbb{Z}(X_{n+1},y)=\\{i\\stackrel{\\cdot}{\\in}\\mathbb{\\tilde{D}}_{y}\\colon\\phi(X_{i},\\hat{A}(X_{n+1},y))=\\phi(X_{n+1},\\hat{A}(X_{n+1},y))\\}}\\end{array}$ . Lemma A1 shows that, for any given placeholder label, the prediction set constructed in this step satisfies the label conditional adaptive equalized coverage as long as the selected variable using that placeholder label is fixed. ", "page_idx": 17}, {"type": "text", "text": "Lemma A1. If $\\{(X_{i},Y_{i})\\}_{i=1}^{n+1}$ are exchangeable and the selected attribute $\\hat{A}(X_{n+1},y)$ is fixed for some placeholder label $y$ , then, the prediction set $\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))$ constructed by calibrating on $\\mathbb{Z}(X_{n+1},y)$ satisfies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))\\mid Y_{n+1}=\\tilde{y},\\phi(X_{n+1},\\hat{A}(X_{n+1},y))]\\ge1-\\alpha,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for any $\\tilde{y}\\in[L]$ . ", "page_idx": 17}, {"type": "text", "text": "Lastly, the final AFCP prediction set is obtained by: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\hat{C}(X_{n+1})=\\left\\{\\cup_{y=1}^{L}\\hat{C}^{\\mathrm{lc}}(X_{n+1},y)\\right\\}\\cup\\left\\{\\cup_{y=1}^{L}\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))\\right\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The procedures to form AFCP prediction sets with the label-conditional adaptive equalized coverage (A14) is summarized in Algorithm A5. ", "page_idx": 17}, {"type": "text", "text": "Algorithm A5 AFCP with label-conditional adaptive equalized coverage (A14). ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point with features $X_{n+1}$ ; list of $K$ sensitive attributes;   \n2: pre-trained classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ .   \n4: for $y\\in[L]$ do   \n5: Define the label-restricted calibration set $\\mathcal{D}_{y}=\\{i\\in[n]:Y_{i}=y\\}$ .   \n6: Select an attribute $\\hat{A}(X_{n+1},y)$ by applying Algorithm 1 with placeholder label $y$ on $\\mathcal{D}_{y}$ .   \n7: Construct $\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))$ by applying Algorithm A1 with protected attributes   \n$\\hat{A}(X_{n+1},y)$ on $\\mathcal{D}_{y}$ .   \n8: Construct $\\hat{C}^{\\mathrm{lc}}(X_{n+1},y)$ by applying Algorithm A1 on $\\mathcal{D}_{y}$ .   \n9: end for   \n10: Define the final selected attribute $\\hat{A}(X_{n+1})$ using Equation (A15).   \n11: Define the final prediction set ${\\hat{C}}(X_{n+1})$ using Equation (A16).   \n12: Output: $\\hat{A}(X_{n+1})$ and ${\\hat{C}}(X_{n+1})$ . ", "page_idx": 17}, {"type": "text", "text": "Theorem A2. If $\\{(X_{i},Y_{i})\\}_{i=1}^{n+1}$ are exchangeable random samples, then the conformal prediction set ${\\hat{C}}(X_{n+1})$ and the selected attribute $\\hat{A}(X_{n+1})$ output by Algorithm A5 satisfy the label-conditional adaptive equalized coverage defined in (A14). ", "page_idx": 17}, {"type": "text", "text": "A4 Methodology Extension: AFCP for Outlier Detection ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Consider a dataset $\\mathcal{D}=\\{Z_{i}\\}_{i=1}^{n}$ containing $n$ sample points drawn exchangeably from an unknown distribution $P_{Z}$ . Consider an additional test point $Z_{n+1}$ . In the outlier detection problems, our AFCP method aims to study whether $Z_{n+1}\\sim P_{Z}$ by constructing a valid conformal p-value $\\hat{u}(Z_{n+1})$ conditional on the group identified by the selected attribute $\\hat{A}(Z_{n+1})$ , that is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\hat{u}(Z_{n+1})\\le\\alpha\\ |\\ \\phi(Z_{n+1},\\hat{A}(Z_{n+1}))]\\le\\alpha,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for any $\\alpha\\,\\in\\,(0,1)$ . Intuitively, this guarantees that, on groups defined by the selected attribute $\\hat{A}(Z_{n+1})$ , the conformal p-value is super-uniform, therefore controlling the FPR (the probability of rejecting the null hypothesis that $Z_{n+1}$ is an inlier when it is true) below $\\alpha$ . ", "page_idx": 18}, {"type": "text", "text": "A4.1 Automatic Attribute Selection ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Given a pre-trained one-class classifier $\\hat{f}$ , an independent calibration dataset $\\mathcal{D}$ , and a test point $Z_{n+1}$ , our method selects a sensitive attribute $\\hat{A}(Z_{n+1})\\in\\{\\varnothing,\\{1\\},\\ldots,\\{K\\}\\}$ according to the following leave-one-out procedure. Sometimes, no attribute may be selected, as denoted by $\\hat{A}(Z_{n+1})=\\emptyset$ . ", "page_idx": 18}, {"type": "text", "text": "Define an augmented calibration set ${\\cal D}^{\\prime}:=\\ensuremath{\\mathcal{D}}\\cup\\{Z_{n+1}\\}$ . For each $i\\,\\in\\,[n+1]$ , define also the leave-one-out set $D_{i}^{\\prime}:=D^{\\prime}\\setminus\\{Z_{i}\\}$ . Then, for each $i\\in[n+1]$ , we compute a conformal p-value $\\hat{u}^{\\mathrm{loo}}(Z_{i})$ for $Z_{i}$ using the data in $\\mathcal{D}_{i}^{\\prime}$ to test if $Z_{i}$ is an outlier. This can be accomplished by running Algorithm A2, using $\\mathcal{D}_{i}^{\\prime}$ as the calibration data and $Z_{i}$ as the test point, and with the convention that smaller nonconformity scores suggest $Z_{i}$ is more likely to be an outlier. Any nonconformity scores can be utilized here. For concreteness, we focus on using the adaptive conformity scores proposed by [27]. Small $\\hat{u}^{\\mathrm{loo}}(Z_{i})$ provides stronger evidence to reject the null hypothesis $H_{0,i}:Z_{i}$ is an inlier. Let $E_{i}$ denote the binary indicator of whether $H_{0,i}$ is rejected: ", "page_idx": 18}, {"type": "equation", "text": "$$\nE_{i}:=\\mathbf{1}\\{\\hat{u}^{100}(Z_{i})\\leq\\alpha\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "After evaluating $E_{i}$ for all $i\\in[n+1]$ , we will assess the leave-one-out FPR for the worst-off group identified by each sensitive attribute $\\bar{k}\\in[K]$ . That is, we evaluate ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\delta_{k}:=\\operatorname*{max}_{m\\in[M_{k}]}\\frac{\\sum_{i=1}^{n+1}E_{i}\\cdot\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}{\\sum_{i=1}^{n+1}\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Intuitively, $\\delta_{k}$ denotes the maximum FPR across all groups identified by the $k$ -th attribute, as estimated by the leave-one-out simulation carried out under the assumption that $Z_{n+1}$ is an inlier. Large values of $\\delta_{k}$ suggest that the $k$ -th attribute may be a sensitive attribute corresponding to at least one group suffering from algorithmic bias. ", "page_idx": 18}, {"type": "text", "text": "To assess whether there is evidence of significant algorithmic bias, we can perform a statistical test for the null hypothesis that no algorithmic bias exists. We define: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{q}:=\\operatorname*{max}_{k\\in[K]}\\delta_{k},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and carry out a one-sided t-test for the null hypothesis $H_{0}:\\hat{q}\\le\\alpha$ against $H_{1}:{\\hat{q}}>\\alpha$ . ", "page_idx": 18}, {"type": "text", "text": "If $H_{0}$ is rejected (at any desired level, such as $5\\%$ ), we conclude there exists a group suffering from significant algorithmic bias, and we identify the corresponding attribute through ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{A}(Z_{n+1})=\\{\\underset{k\\in[K]}{\\mathrm{arg\\,max}}\\,\\delta_{k}\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Otherwise, we set ${\\hat{A}}(Z_{n+1})=\\emptyset$ , which corresponds to selecting no attribute. See Algorithm A6 for an outline of this procedure. ", "page_idx": 18}, {"type": "text", "text": "A4.2 Evaluating the Adaptive Conformal P-Value ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "After selecting either a single attribute or an empty set $\\hat{A}(X_{n+1})$ that corresponds to at least one group suffering from algorithmic bias, the next step of our AFCP method is to compute an adaptive conformal $\\mathbf{p}$ -value for testing whether $Z_{n+1}$ is an outlier that satisfies (A17). This can be simply achieved by applying the standard conformal method outlined in Algorithm A2 based on a restricted calibration sample indexed by $\\begin{array}{r}{\\small\\mathcal{Z}(\\hat{A}(Z_{n+1}))=\\{i\\in[n]:\\phi(Z_{i},\\hat{A}(Z_{n+1}))=\\phi(Z_{n+1},\\hat{A}(Z_{n+1}))\\}}\\end{array}$ , See Algorithm A7 for a summary of AFCP for outlier detection tasks. ", "page_idx": 18}, {"type": "text", "text": "Theorem A3. If $\\{Z_{i}\\}_{i=1}^{n+1}$ are exchangeable random samples, the conformal $p$ -value $\\hat{u}(Z_{n+1})$ and the selected attribute $\\hat{A}(Z_{n+1})$ output by Algorithm $A7$ satisfy (A17). ", "page_idx": 18}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/778451c3b4388cb8f9e1607fa8e35208b11b5467e371415cac58206ff20440ad.jpg", "table_caption": ["Algorithm A6 Automatic attribute selection for outlier detection. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Algorithm A7 AFCP for outlier detection. ", "text_level": 1, "page_idx": 19}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/13341d7be4805aafa9af6537dc4cebbdf8f41a370d6623e8db7fc8f9c240e2e6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "A4.3 AFCP for Outlier Detection with Multiple Selected Attributes ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "AFCP for outlier detection problems can be readily extended to select $J$ sensitive attributes where $J>1$ . This is achieved by repeatedly applying the single attribute selection procedure described in Algorithm A6 $J$ times. Each time, the algorithm selects a (possibly empty) subset of attributes $\\hat{A}(Z_{n+1})^{j}$ from the list of sensitive attributes excluding the previously selected attribute ${\\hat{A}}(Z_{n+1})^{j-1}$ . The final set of selected attributes is given by $\\hat{A}(Z_{n+1})=\\cup_{j=1}^{J}\\hat{A}(Z_{n+1})^{j}$ . See Algorithm A8 for an outline of this procedure. ", "page_idx": 19}, {"type": "text", "text": "Algorithm A8 Multiple attributes selection for outlier detection. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1: Input: calibration data $\\mathcal{D}$ ; test point $Z_{n+1}$ ; list of $K$ sensitive attributes;   \n2: pre-trained one-class classifier $\\hat{f}$ ; pre-defined rule for computing nonconformity scores;   \n3: nominal level $\\alpha\\in(0,1)$ ; number of selected attributes $J$ .   \n4: Denote $K^{0}=[K]$ .   \n5: for $j\\in\\{1,\\dotsc,J\\}$ do   \n6: Select an attribute $\\hat{A}(Z_{n+1})^{j}$ by applying Algorithm A6 with sensitive attributes $K^{j-1}$ .   \n7: Update the list of sensitive attributes $K^{j}=K^{j-1}\\setminus\\hat{A}(Z_{n+1})^{j}$ .   \n8: end for   \n9: Output: $\\hat{A}(Z_{n+1})=\\cup_{j=1}^{J}\\hat{A}(Z_{n+1})^{j}$ , an empty set or a set of selected attributes. ", "page_idx": 19}, {"type": "text", "text": "After selecting a set of attributes $\\hat{A}(Z_{n+1})$ , which might be empty or include one or more sensitive attributes, AFCP constructs an adaptive conformal $\\mathbf{p}$ -value satisfying (A17). This can be easily achieved by applying Algorithm A2 with protected attributes $\\hat{A}(Z_{n+1})$ . Algorithm A9 summarizes the AFCP implementation for outlier detection that allows selecting multiple protected attributes. ", "page_idx": 19}, {"type": "text", "text": "Theorem A4. If $\\{Z_{i}\\}_{i=1}^{n+1}$ are exchangeable random samples, the conformal $p$ -value $\\hat{u}(Z_{n+1})$ and selected attributes $\\hat{A}(Z_{n+1})$ output by Algorithm $A9$ satisfy (A17). ", "page_idx": 19}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/5e884639d4efff8eade9f43fae7b8d58ceb8bb8f0faf1e3a5391fb971ef964a4.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "A5 Mathematical Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof of Theorem $^{\\,l}$ . Consider an imaginary oracle that has access to the true value of $Y_{n+1}$ . Denote ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ as the sensitive attribute selected by this oracle by applying Algorithm 1 with the true $Y_{n+1}$ instead of a placeholder label. Let ${\\hat{C}}^{\\circ}(X_{n+1},{\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1}))$ represent the corresponding output prediction set by applying Algorithm A1 with the protected attribute ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ . Consider also $\\hat{C}^{\\mathrm{m}}(X_{n+1})$ , the standard prediction set with marginal coverage (1). ", "page_idx": 20}, {"type": "text", "text": "The main idea of our proof is to connect the output prediction set ${\\hat{C}}(X_{n+1})$ and selected attribute $\\hat{A}(X_{n+1})$ from Algorithm 2 to those of the imaginary oracle described above. Throughout this proof, we adopt the convention that $\\phi(X_{n+1},\\emptyset)=0$ . ", "page_idx": 20}, {"type": "text", "text": "To establish this connection, note that the attribute $\\hat{A}(X_{n+1})$ selected by Algorithm 2 is either empty, ${\\hat{A}}(X_{n+1})=\\emptyset$ , or a singleton, $\\hat{A}(X_{n+1})=\\{k\\}$ for some $k\\in[K]$ . In the latter case, ${\\hat{A}}(X_{n+1})=$ $\\hat{A}(X_{n+1},\\tilde{y}),\\forall\\tilde{y}\\in[L]$ , and thus ${\\hat{A}}(X_{n+1})={\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1})$ almost-surely. Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{r}_{n+1}\\in\\hat{C}(X_{n+1})\\mid\\phi(X_{n+1},\\hat{A}(X_{n+1}))\\mid}\\\\ &{\\qquad\\geq\\operatorname*{min}\\biggl\\{\\mathcal{F}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid\\phi(X_{n+1},\\theta)],}\\\\ &{\\qquad\\qquad\\qquad\\mathbb{F}\\{Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid\\phi(X_{n+1},\\hat{A}^{\\prime}(X_{n+1},Y_{n+1}))\\}\\biggr\\}}\\\\ &{\\qquad=\\operatorname*{min}\\biggl\\{\\mathcal{F}[Y_{n+1}\\in\\hat{C}(X_{n+1})],}\\\\ &{\\qquad\\qquad\\geq\\operatorname*{min}\\biggl\\{\\mathcal{F}[Y_{n+1}\\in\\hat{C}(X_{n+1})]\\:\\phi(X_{n+1},\\hat{A}^{\\prime}(X_{n+1},Y_{n+1}))\\biggr\\}}\\\\ &{\\qquad\\qquad\\geq\\operatorname*{min}\\biggl\\{\\mathcal{F}[Y_{n+1}\\in\\hat{C}^{m}(X_{n+1})],}\\\\ &{\\qquad\\qquad\\geq\\operatorname*{min}\\biggl\\{\\mathcal{F}[Y_{n+1}\\in\\hat{C}^{m}(X_{n+1},\\hat{A}^{\\prime}(X_{n+1}))]\\:\\phi(X_{n+1},\\hat{A}^{\\prime}(X_{n+1},Y_{n+1}))\\biggr\\}\\biggr\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the last inequality follows from the facts that $\\begin{array}{r l r}{\\hat{C}^{\\mathrm{m}}(X_{n+1})}&{{}\\subseteq}&{\\hat{C}(X_{n+1})}\\end{array}$ and $\\hat{C}^{\\mathrm{o}}(X_{n+1},\\hat{A}^{\\mathrm{o}}(X_{n+1},Y_{n+1}))\\subseteq\\hat{C}(X_{n+1})$ almost-surely. Next, we only need to separately lowerbound by $1-\\alpha$ the two terms on the right-hand-side of (A22). ", "page_idx": 20}, {"type": "text", "text": "The first part of the remaining task is trivial. It is already well-known that $\\mathbb{P}(Y_{n+1}\\in{\\hat{C}}^{\\mathrm{m}}(X_{n+1}))\\geq$ $1-\\alpha$ ; see [13, 57]. ", "page_idx": 20}, {"type": "text", "text": "To complete the second part of the remaining task, note that the oracle-selected attribute ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ is invariant to any permutations of the exchangeable data indexed by $[n+1]$ . Therefore, the data points are also exchangeable conditional on the groups defined by ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ . This means we can imagine the protected attribute ${\\hat{A}}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1})$ is fixed, and the oracle prediction set ${\\hat{C}}^{\\circ}(X_{n+1},{\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1}))$ is simply obtained by applying Algorithm A1 to exchangeable data using a fixed protected attribute. This procedure is the same as the main algorithm in [17] and has guaranteed coverage above $1-\\alpha$ ; see Theorem 1 in [17]. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Proof of Theorem A1. Similar to the proof of Theorem 1, consider an imaginary oracle that has access to the true value of $Y_{n+1}$ . Denote ${\\hat{A}}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1})$ as the (possibly empty, one, or two) sensitive attribute(s) selected by this oracle by applying Algorithm A3 with the true $Y_{n+1}$ . Let ${\\hat{C}}^{\\circ}(X_{n+1},{\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1}))$ represent the output prediction set by applying Algorithm A1 with the protected attribute(s) ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ . Consider also ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})$ , the standard prediction set with marginal coverage (1), and $\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)$ the prediction set with valid coverage conditional on groups identified by a fixed attribute $\\{\\ell\\}$ . ", "page_idx": 21}, {"type": "text", "text": "The key idea of our proof is again to connect the practical prediction set ${\\hat{C}}(X_{n+1})$ and selected protected attributes $\\hat{A}(X_{n+1})$ of Algorithm A4 to those of the imaginary oracle described above. Throughout this proof, we adopt the convention that $\\phi(X_{n+1},\\emptyset)=0$ . ", "page_idx": 21}, {"type": "text", "text": "To establish this connection, note that the attribute(s) $\\hat{A}(X_{n+1})$ selected by applying Algorithm A3 falls into one of the three possible cases almost surely: (a) ${\\hat{A}}(X_{n+1})\\ =\\ \\emptyset$ , (b) $\\hat{A}(X_{n+1})\\;=\\;$ ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ , and (c) ${\\dot{A}}(X_{n+1})={\\hat{A}}(X_{n+1})\\,\\subset\\,{\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1})$ . The last scenario happens when the oracle selects two attributes, and the $\\hat{A}(X_{n+1})$ contains only one of them. For clarify of the notation, we denote the last case using $\\dot{A}(X_{n+1})$ . ", "page_idx": 21}, {"type": "text", "text": "Therefore, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{1}+_{2}C(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+\\frac{1}{\\alpha}}))\\mid}\\\\ &{\\geq\\operatorname*{min}\\Biggl\\{\\nabla\\gamma_{1+1}(\\epsilon\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda)),}\\\\ &{\\qquad\\qquad\\nabla\\gamma_{1+1}(\\epsilon\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}),\\gamma_{++1}))\\Biggr\\},}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}))\\Biggr\\}}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1})\\parallel\\alpha(X_{t+1},\\lambda(X_{t+1}))\\Biggr\\}}\\\\ &{=\\operatorname*{min}\\Biggl\\{\\nabla\\gamma_{1+1}(\\epsilon\\bar{C}(X_{t+1})),}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}),\\gamma_{++1})\\Biggr\\},}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}))\\Biggr\\}}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}))\\Biggr\\}}\\\\ &{\\geq\\operatorname*{min}\\Biggl\\{\\nabla\\gamma_{1+1}(\\epsilon\\bar{C}(X_{t+1}),\\gamma_{1+1}),}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1},\\lambda(X_{t+1}),\\gamma_{1+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}),\\gamma_{+1})}\\\\ &{\\qquad\\qquad\\quad_{|T|\\gamma_{1+1}}\\in\\bar{C}(X_{t+1},\\gamma_{1+1},\\gamma_{1+1})\\mid\\alpha(X_{t+1},\\lambda(X_{t+1}))\\Biggr\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last inequality follows from the facts that ${\\hat{C}}^{\\mathrm{m}}(X_{n+1})\\quad\\subseteq\\quad{\\hat{C}}(X_{n+1}),$ $\\hat{C}^{\\mathrm{{o}}}(X_{n+1},\\hat{A}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1}))~\\subseteq~\\hat{C}(X_{n+1})$ , and $\\cup_{\\ell\\in\\hat{A}^{\\mathrm{o}}(X_{n+1},Y_{n+1})}\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)\\;\\;\\subseteq\\;\\;\\hat{C}(X_{n+1})$ almost-surely. ", "page_idx": 21}, {"type": "text", "text": "Next, we show how to separately lower-bound by $1\\mathrm{~-~}\\alpha$ the three terms on the right-hand-side of (A23). ", "page_idx": 21}, {"type": "text", "text": "The lower bounds of the first and second terms have been proved in theorem 1. We will focus on lowerbounding the coverage of the third term. Because the oracle-selected attribute(s) ${\\hat{A}}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1})$ are invariant to any permutation of the exchangeable data indexed by $[n+1]$ , we can treat each of the two elements in ${\\hat{A}}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1})$ as fixed. Without loss of generality, let $\\ell_{1}$ and $\\ell_{2}$ denote the first and the second element respectively, $\\dot{A}(X_{n+1})=\\ell_{1}$ or $\\dot{A}(X_{n+1})=\\ell_{2}$ with probability 1. Then, ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}[Y_{n+1}\\in\\cup_{\\ell\\in\\mathring{\\mathcal{A}}^{\\ast}(X_{n+1},Y_{n+1})}\\widehat{C}^{\\otimes}(X_{n+1},\\ell)\\ |\\ \\phi(X_{n+1},\\mathring{k}(X_{n+1}))]}\\\\ &{\\qquad\\geq\\operatorname*{min}\\Bigg\\{\\mathbb{P}[Y_{n+1}\\in\\cup_{\\ell\\in\\mathring{\\mathcal{A}}^{\\ast}(X_{n+1},Y_{n+1})}\\widehat{C}^{\\otimes}(X_{n+1},\\ell)\\ |\\ \\phi(X_{n+1},\\ell_{1})],}\\\\ &{\\qquad\\qquad\\mathbb{P}[Y_{n+1}\\in\\cup_{\\ell\\in\\mathring{\\mathcal{A}}^{\\ast}(X_{n+1},Y_{n+1})}\\widehat{C}^{\\otimes}(X_{n+1},\\ell)\\ |\\ \\phi(X_{n+1},\\ell_{2})]\\Bigg\\}}\\\\ &{\\qquad\\geq\\operatorname*{min}\\Bigg\\{\\mathbb{P}[Y_{n+1}\\in\\widehat{C}^{\\otimes}(X_{n+1},\\ell_{1})\\ |\\ \\phi(X_{n+1},\\ell_{1})],}\\\\ &{\\qquad\\qquad\\mathbb{P}[Y_{n+1}\\in\\widehat{C}^{\\otimes}(X_{n+1},\\ell_{2})\\ |\\ \\phi(X_{n+1},\\ell_{2})]\\Bigg\\}}\\\\ &{\\qquad\\geq\\operatorname*{min}\\{1-\\alpha,1-\\alpha\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the inequality of the last line of (A24) is proved in [17] with fixed attribute $\\ell_{1}$ and $\\ell_{2}$ respectively. Lastly, realize that $\\cup_{\\ell\\in\\hat{A}^{0}(X_{n+1},Y_{n+1})}\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)\\subseteq\\cup_{\\ell\\in\\cup_{y=1}^{L}\\hat{A}(X_{n+1,y})}\\hat{C}^{\\mathrm{eq}}(X_{n+1},\\ell)\\subseteq\\hat{C}(X_{n+1})$ almost-surely, the proof is completed. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Proof of Theorem A2. Similar to the proof of Theorem 1, consider an imaginary oracle that has access to the true value of $Y_{n+1}$ . Denote ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ as the sensitive attribute selected by this oracle by applying Algorithm 1 based on a subset of the calibration data indexed by $\\mathcal{D}_{Y_{n+1}}=\\{i\\in$ $[n]:Y_{i}=Y_{n+1}\\}$ . Let ${\\hat{C}}^{\\circ}(X_{n+1},{\\hat{A}}^{\\circ}(X_{n+1},Y_{n+1}))$ represent the output prediction set by applying Algorithm A1 with the protected attribute ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ . Consider also ${\\hat{C}}^{\\mathrm{lc}}(X_{n+1},Y_{n+1})$ , the prediction set with label-conditional coverage obtained by running Algorithm A1 using $\\mathcal{D}_{Y_{n+1}}$ without any protected attributes. ", "page_idx": 22}, {"type": "text", "text": "To establish this connection between the output prediction set ${\\hat{C}}(X_{n+1})$ and the selected attribute $\\hat{A}(X_{n+1})$ of Algorithm A5 and these of the imaginary oracle, note that the selected attribute $\\hat{A}(X_{n+1})$ must be ${\\hat{A}}(X_{n+1})=\\emptyset$ or ${\\hat{A}}(X_{n+1})={\\hat{A}}^{\\circ}({\\dot{X_{n+1}}},{\\dot{Y_{n+1}}})$ . ", "page_idx": 22}, {"type": "text", "text": "Therefore, for any $y\\in[L]$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{A}(X_{n+1}))]}\\\\ &{\\phantom{\\hat{=}}\\ge\\operatorname*{min}\\Biggl\\{\\mathbb{P}(Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{\\mathbb{U}})),}\\\\ &{\\phantom{\\hat{=}}\\mathbb{P}(Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{\\mathbb{U}}^{\\circ}(X_{n+1},Y_{n+1})))\\Biggr\\}}\\\\ &{\\phantom{\\hat{=}}\\mathbb{P}(Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{\\mathbb{U}}^{\\circ}(X_{n+1},Y_{n+1})))\\Biggr\\}}\\\\ &{\\phantom{\\hat{=}}=\\operatorname*{min}\\Biggl\\{\\mathbb{P}(Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y),}\\\\ &{\\phantom{\\hat{=}}\\mathbb{P}(Y_{n+1}\\in\\hat{C}(X_{n+1})\\mid Y_{n+1}=y,\\phi(X_{n+1},\\hat{\\mathbb{U}}^{\\circ}(X_{n+1},Y_{n+1})))\\Biggr\\}}\\\\ &{\\phantom{\\hat{=}}\\ge\\operatorname*{min}\\Biggl\\{\\mathbb{P}(Y_{n+1}\\in\\hat{C}^{\\hat{\\mathbb{X}}}(X_{n+1},Y_{n+1})\\mid Y_{n+1}=y),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the last inequality follows from the facts that ${\\hat{C}}^{\\mathrm{lc}}(X_{n+1},Y_{n+1})\\;\\;\\subseteq\\;\\;{\\hat{C}}(X_{n+1})$ and $\\hat{C}^{\\mathrm{o}}(X_{n+1},\\hat{A}^{\\mathrm{o}}(X_{n+1},Y_{n+1}))\\subseteq\\hat{C}(X_{n+1})$ almost-surely. ", "page_idx": 22}, {"type": "text", "text": "Next, we only need to separately lower-bound by $1-\\alpha$ the two terms on the right-hand-side of (A25). ", "page_idx": 23}, {"type": "text", "text": "The first part of the remaining task is trivial. It is already well-known that $\\mathbb{P}(Y_{n+1}\\mathrm{~\\textbf~{~\\in~}~}$ $\\hat{C}^{\\mathrm{lc}}(X_{n+1},Y_{n+1})\\mid Y_{n+1}=y)\\geq1-\\alpha$ ; see [13, 47, 58]. ", "page_idx": 23}, {"type": "text", "text": "Next, we prove the lower bound for the second term. Fix any $y\\,\\in\\,[L]$ , and assume $Y_{n+1}\\,=\\,y$ First, note that the oracle-selected attribute ${\\hat{A}}^{\\mathrm{{o}}}(X_{n+1},Y_{n+1})$ is invariant to any permutations of the exchangeable data indexed by $\\mathcal{D}_{y}\\cup\\{X_{n+1},y\\}$ . Therefore, the data points are exchangeable conditional on the group identified by the oracle-selected attribute ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ . This means that we can imagine the protected attribute ${\\hat{A}}^{\\mathrm{o}}(X_{n+1},Y_{n+1})$ is fixed, and the oracle prediction set ${\\hat{C}}^{\\scriptscriptstyle0}(X_{n+1},{\\hat{A}}^{\\scriptscriptstyle0}(X_{n+1},Y_{n+1}))$ is simply obtained by applying Algorithm A1 to exchangeable data using a fixed protected attribute. This procedure has guaranteed coverage above $1\\mathrm{~-~}\\alpha$ ; see Lemma A1. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Proof of Theorem A3. The strategy of this proof is very standard in the conformal inference literature.   \nWe add this proof for completeness. ", "page_idx": 23}, {"type": "text", "text": "Recall that $\\mathcal{T}(\\hat{A}(Z_{n+1}))$ denotes a subset of the calibration data $\\mathcal{D}$ that has the same value of the selected attribute as the test point. To prove (A17), it suffices to show that the nonconformity scores $\\{\\hat{S}_{i}:i\\in\\mathcal{I}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}$ are exchangeable. Indeed, if the scores are exchangeable and almost surely distinct (which can be easily achieved by adding continuous random noises), then the rank of $\\hat{S}_{n+1}$ is uniformly distributed over the discrete values $\\{1,2,\\ldots,{\\mathcal{I}}({\\hat{A}}(Z_{n+1}))+1\\}$ Consequently, the conformal p-value $\\hat{u}(Z_{n+1})$ constructed by Algorithm A7 follows a uniform distribution $\\begin{array}{r}{\\mathrm{{Unif}}(\\{\\frac{1}{|\\mathcal{Z}(\\hat{A}(Z_{n+1}))|+1},\\frac{\\hat{\\Sigma}}{|\\mathcal{Z}(\\hat{A}(Z_{n+1}))|+1},\\dots,1\\})}\\end{array}$ . This implies that $\\mathbb{P}(\\hat{u}(Z_{n+1})\\,\\le\\,\\alpha\\,\\mid$ $\\phi(Z_{n+1},\\hat{A}(Z_{n+1})))\\,=\\,\\alpha$ . Even if the nonconformity scores are not almost surely distinct, one can still verify that the distribution of $\\hat{u}(Z_{n+1})$ is super-uniform. Combining both cases, we have $\\mathbb{P}(\\hat{u}(Z_{n+1})\\le\\alpha|\\phi(Z_{n+1},\\hat{A}(Z_{n+1})))\\le\\alpha$ for any $\\alpha\\in(0,1)$ . ", "page_idx": 23}, {"type": "text", "text": "We complete the proof by showing that the nonconformity scores $\\{\\hat{S}_{i}:i\\in\\mathcal{T}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}$ are exchangeable. Define $\\sigma$ as an arbitrary permutation function applied on $\\mathcal{D}\\cup\\{Z_{n+1}\\}$ and denote the permuted dataset as $\\sigma(\\mathcal{D})$ . We first run Algorithm A7 based on $\\mathcal{D}$ to select the sensitive attribute $\\hat{A}(Z_{n+1})$ . Next, assume in a parallel world, we repeat Algorithm A7 with the same parameters and seed settings but based on the permuted data $\\sigma(\\mathcal{D})$ . Denote the selected attribute in the parallel world as $\\hat{A}^{'}(Z_{n+1})$ . Essentially, ${\\hat{A}}^{\\prime}(Z_{n+1})={\\hat{A}}(Z_{n+1})$ . This is because the computation of conformal pvalues and the procedure of selecting the attribute with the worst FPR in Algorithm A6 are not affected by the order of the calibration and test data. Therefore, the attribute selection process is invariant to the order of $\\mathcal{D}\\cup\\{Z_{n+1}\\}$ . This implies that the attribute selected by Algorithm A6 $\\hat{A}(Z_{n+1})$ can be treated as fixed, and the nonconformity scores computed on the subset $\\mathbb{Z}({\\hat{A}}(Z_{n+1}))\\cup\\{Z_{n+1}\\}$ are simply reordered in the parallel world, i.e., ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\{\\hat{S}_{\\sigma(i)}^{'}:i\\in\\mathbb{Z}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}=\\bar{\\sigma}(\\{\\hat{S}_{i}:i\\in\\mathbb{Z}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\bar{\\sigma}$ is the permutation obtained by restricting $\\sigma$ on $\\mathbb{Z}({\\hat{A}}(Z_{n+1}))\\cup\\{Z_{n+1}\\}.$ . Hence, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\{\\hat{S}_{i}:i\\in\\mathbb{Z}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}\\stackrel{d}{=}\\{\\hat{S}_{\\sigma(i)}^{'}:i\\in\\mathbb{Z}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\bar{\\sigma}(\\{\\hat{S}_{i}:i\\in\\mathbb{Z}(\\hat{A}(Z_{n+1}))\\cup\\{Z_{n+1}\\}\\}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the equality in distribution is implied by $D\\stackrel{d}{=}\\sigma(\\mathcal{D})$ . ", "page_idx": 23}, {"type": "text", "text": "Proof of Theorem A4. This proof is the same as the proof of Theorem A3 since the multiple selected attributes $\\hat{A}(Z_{n+1})$ are invariant to any permutation of the calibration and test data. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Proof of Lemma $A l$ . This proof is a minor extension of the proof of Theorem 1 in [17], with the difference that we additionally condition on the true test label. ", "page_idx": 23}, {"type": "text", "text": "Fix any $\\tilde{y}\\in[L]$ , and suppose $Y_{n+1}=\\tilde{y}$ . For a placeholder label $y$ , consider a subset of the calibration data $\\mathcal{D}$ indexed by $\\begin{array}{r}{\\mathbb{Z}(X_{n+1},y)=\\{i\\in\\mathcal{D}:Y_{i}=\\tilde{y},\\phi(X_{i},\\hat{A}(X_{n+1},y))=\\phi(X_{n+1},\\hat{A}(X_{n+1},y))\\}}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "Since $\\{(X_{i},Y_{i})\\}_{i=1}^{n+1}$ are exchangeable and the protected attribute $\\hat{A}(X_{n+1},y)$ is fixed, the nonconformity scores ${\\hat{S}}_{i}$ evaluated on the subset ${\\mathcal{T}}(X_{n+1},y)\\cup\\{(X_{n+1},y)\\}$ are also exchangeable. ", "page_idx": 24}, {"type": "text", "text": "Further, denote $\\hat{Q}(X_{n+1},y)$ as the $\\lceil(1-\\alpha)\\cdot|1+\\mathcal{T}(X_{n+1},y)|\\rceil$ -th smallest value of $\\{\\hat{S}_{i}\\}_{i\\in\\mathcal{I}(X_{n+1},y)}$ . By the quantile lemma [13, 17, 57], for any $\\alpha\\in(0,1)$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}[Y_{n+1}\\in\\hat{C}(X_{n+1},\\hat{A}(X_{n+1},y))\\mid Y_{n+1}=\\tilde{y},\\phi(X_{n+1},\\hat{A}(X_{n+1},y))]}\\\\ &{\\quad\\quad\\quad=\\mathbb{P}[\\hat{S}_{n+1}\\leq\\hat{Q}(X_{n+1},y)\\mid Y_{n+1}=\\tilde{y},\\phi(X_{n+1},\\hat{A}(X_{n+1},y))]}\\\\ &{\\quad\\quad\\quad\\geq1-\\alpha.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "A6 Computational Shortcuts and Efficient Implementation ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "A6.1 Outlier Detection ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Given a pre-trained one-class classifier, consider a calibration dataset $\\mathcal{D}$ of size $n$ . Let $K$ denote the number of sensitive attributes, and for each attribute $k\\in[K]$ , let $M_{k}\\in\\mathbb{N}$ denote the count of its possible values. Denote $M=\\operatorname*{max}_{k}M_{k}$ as the maximum count across all attributes. ", "page_idx": 24}, {"type": "text", "text": "AFCP for outlier detection outlined in Algorithm A7 has the following computational cost. ", "page_idx": 24}, {"type": "text", "text": "Analysis for a single test point ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The cost of computing the false positive indicators for every sample in $\\mathcal{D}\\cup\\{Z_{n+1}\\}$ takes $O(n{\\cdot}\\log n)$ . Breaking into steps, for every data in $\\mathcal{D}\\cup\\{Z_{n+1}\\}$ , compute their nonconformity scores takes ${\\mathcal{O}}(n)$ . Their associated conformal $\\mathfrak{p}$ -value can be computed at once by sorting all scores and keeping track of their ranks, which takes $O(n\\cdot\\log{n})$ .   \n\u2022 Then, selecting the sensitive attributes requires $O(n\\cdot K\\cdot M)$ .   \n\u2022 Once the attribute is selected, the cost of applying conformal prediction conditional on the group identified by the selected attribute is $O(1)$ because the subset of the group has been found in the last step. ", "page_idx": 24}, {"type": "text", "text": "Hence, the total cost of running Algorithm A7 for a single test point is $\\mathcal{O}(n\\log n+n K M)$ ", "page_idx": 24}, {"type": "text", "text": "Analysis for $m$ test points ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The cost of computing the false positive indicators for every sample in $\\mathcal{D}\\cup\\{Z_{n+t}\\}_{t=1}^{m}$ takes $\\mathcal{O}(n\\cdot(m\\,\\Bar{+}\\log\\Bar{n}))$ . This can be derived by rewriting the conformal p-values for all $j\\in\\mathcal{D}\\cup\\{Z_{n+t}\\}$ and for all $t\\in[m]$ as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{u}_{j,t}=\\displaystyle\\frac{1}{1+n}\\Big(\\sum_{i\\in\\mathcal{D}\\cup\\{Z_{n+t}\\}}\\mathbf{1}(\\hat{S}_{i}\\leq\\hat{S}_{j})\\Big)}\\\\ &{\\quad=\\displaystyle\\frac{1}{1+n}\\Big(\\mathrm{rank}(\\hat{S}_{j})\\;\\mathrm{among}\\;\\{\\hat{S}_{i}\\}_{i\\in\\mathcal{D}}+\\mathbf{1}(\\hat{S}_{n+t}\\leq\\hat{S}_{j})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Computing the nonconformity scores for all samples in $\\mathcal{D}\\cup\\{Z_{n+t}\\}_{t=1}^{m}$ costs $O(n+m)$ , evaluating the ranks takes $\\mathcal{O}(n\\log n)$ , and comparing $\\hat{S}_{n+t}$ and $\\hat{S}_{j}$ costs ${\\mathcal{O}}(n\\cdot m)$ . ", "page_idx": 24}, {"type": "text", "text": "\u2022 Selecting the sensitive attribute costs $\\mathcal{O}(n\\cdot m+M\\cdot K\\cdot(n+m))$ . Breaking in steps, for each test sample $Z_{n+t}$ , the worst FPR for attribute $k$ , as defined in (A20), can be rewritten as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta_{k,t}:=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\,\\frac{\\sum_{i\\in\\mathcal{D}\\cup\\{Z_{n+t}\\}}E_{i,t}\\cdot\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}{\\sum_{i\\in\\mathcal{D}\\cup\\{Z_{n+t}\\}}{\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}}}\\\\ &{\\qquad=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\frac{\\sum_{i\\in\\mathcal{D}}E_{i,t}\\cdot\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}+E_{t,t}\\cdot\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}{\\sum_{i\\in\\mathcal{D}}\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}+\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}}\\\\ &{\\qquad=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\frac{\\sum_{i\\in\\mathcal{D}(k,m)}E_{i,t}+E_{t,t}\\cdot\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}}{|\\mathcal{D}(k,m)|+\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ represents a subset of the calibration data indexed by $\\{i\\in\\mathcal{D}:\\phi(Z_{i},\\{k\\})=$ $m\\}$ . The trick we use is that the identification of subset $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ does not depend on the test sample $t$ and can be reused to calculate the FPR for every test sample $\\{Z_{n+t}\\}_{t=1}^{m}$ . In specific, identifying $\\mathcal{D}(k,m),\\forall k\\in[K]$ , $m\\in[M_{k}]$ takes ${\\mathcal{O}}(n{\\cdot}M{\\cdot}K)$ . For each $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ , computing $\\begin{array}{r}{\\sum_{i\\in\\mathcal{D}(k,m)}\\breve{E_{i,t}},\\forall i\\in[m]}\\end{array}$ takes ${\\mathcal{O}}(|{\\bar{D}}(k,{\\bar{m}})|\\cdot m)$ , and computing $E_{t,t}\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}$ takes $\\mathcal{O}(m)$ . Therefore, repeating this process for all $\\mathcal{D}(k,m),k\\in[K],m\\in[M_{k}]$ in total takes $O(n\\cdot m)$ . Lastly, finding the maximum FPR across all attributes takes $\\mathcal{O}\\dot{(}m\\cdot\\!M\\cdot K)$ . ", "page_idx": 25}, {"type": "text", "text": "Hence, the total cost of running Algorithm A7 for $m$ test samples is ${\\mathcal{O}}(n\\log n\\!+\\!n m\\!+\\!M K(n\\!+\\!m))$ . ", "page_idx": 25}, {"type": "text", "text": "A6.2 Multi-Class Classification ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Given a pre-trained multi-class classifier, consider a calibration dataset $\\mathcal{D}$ of size $n$ . Let $L$ denote the total number of possible labels to predict, and let $K$ denote the number of sensitive attributes. For each attribute $k\\in[K]$ , let $M_{k}\\in\\mathbb{N}$ denote the count of its possible values. Denote $M=\\operatorname*{max}_{k}M_{k}$ as the maximum count across all attributes. ", "page_idx": 25}, {"type": "text", "text": "AFCP for multi-class classification outlined in Algorithm 2 has the following computational cost. ", "page_idx": 25}, {"type": "text", "text": "Analysis for a single test point ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The cost of constructing prediction sets and computing miscoverage indicators within the leave-one-out procedure is $O(L\\cdot n\\cdot\\log n)$ .   \n\u2022 Then, selecting the sensitive attributes requires $\\mathcal{O}(n\\cdot K\\cdot M+L\\cdot(n+M\\cdot K))$ .   \n\u2022 Once the attribute is selected, the cost of applying conformal prediction conditional on the group identified by the selected attribute is $O(1)$ because the subset of the group has been found in the last step. ", "page_idx": 25}, {"type": "text", "text": "Hence, the total cost of running Algorithm 2 for a single test point is $\\mathcal{O}(L(n\\log n+K M)+n K M)$ . ", "page_idx": 25}, {"type": "text", "text": "Analysis for $m$ test points ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The cost of computing miscoverage indicators is $\\mathcal{O}(L\\cdot n\\cdot(m+\\log n))$ . This can be derived by rewriting the conformal p-values for all $j\\in\\mathcal{D}\\cup\\{(X_{n+t},y)\\}\\ \\forall y\\in[L]$ , and $\\forall t\\in[m]$ as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{u}_{j,t}^{y}=\\frac{1}{1+n}\\Big(\\sum_{i\\in\\mathcal{D}\\cup\\{Z_{n+t}\\}}\\mathbf{1}(\\hat{S}_{i}^{y}\\leq\\hat{S}_{j}^{y})\\Big)}\\\\ &{\\quad=\\frac{1}{1+n}\\Big(\\mathrm{rank}(\\hat{S}_{j}^{y})\\;\\mathrm{among}\\;\\{\\hat{S}_{i}^{y}\\}_{i\\in\\mathcal{D}}+\\mathbf{1}(\\hat{S}_{n+t}^{y}\\leq\\hat{S}_{j}^{y})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For each placeholder label $y\\in[L]$ , computing the nonconformity scores for all samples in $\\scriptstyle{\\mathcal{D}}\\cup\\{(X_{n+t},y)\\}_{t=1}^{m}$ costs $\\mathcal{O}(n\\!+\\!m)$ , evaluating the ranks takes $\\mathcal{O}(n\\log n)$ , and comparing $\\hat{S}_{n+t}^{y}$ with $\\hat{S}_{j}^{y}$ costs ${\\mathcal{O}}(n\\!\\cdot\\!m)$ . This process needs to be conducted for each $y\\in[L]$ , therefore the total cost of this step is $\\mathcal{O}(L\\cdot(n+m+n\\log n+n m))=\\mathcal{O}(L\\cdot n\\cdot(\\log n+m))$ . ", "page_idx": 25}, {"type": "text", "text": "\u2022 Selecting the sensitive attribute costs $\\mathcal{O}(n\\cdot M\\cdot K+L\\cdot m(n+M\\cdot K)$ . Breaking in steps, for each test sample $(X_{n+t},y),y\\in[L]$ , the worst miscoverage rate for attribute $k$ , as defined in (5), can be rewritten as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta_{y,k,t}:=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\frac{\\sum_{i\\in\\mathcal{D}\\cup\\{(X_{n+t},y)\\}}E_{y,i,t}\\cdot\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}{\\sum_{i\\in\\mathcal{D}\\cup\\{(X_{n+t},y)\\}}\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}}\\\\ &{\\qquad=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\frac{\\sum_{i\\in\\mathcal{D}}E_{y,i,t}\\cdot\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}+E_{y,t,t}\\cdot\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}{\\sum_{i\\in\\mathcal{D}}\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}+\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}}\\\\ &{\\qquad=\\underset{m\\in[M_{k}]}{\\operatorname*{max}}\\frac{\\sum_{i\\in\\mathcal{D}(k,m)}E_{y,i,t}+E_{y,t,t}\\cdot\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}}{|\\mathcal{D}(k,m)|+\\mathbf{1}\\{\\phi(X_{i},\\{k\\})=m\\}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ represents a subset of the calibration data indexed by $\\{i\\in\\mathcal{D}:\\phi(Z_{i},\\{k\\})=$ $m\\}$ . The trick we use is that the identification of subset $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ does not depend on the test sample $t$ and the placeholder label $y$ , therefore can be reused to calculate the miscoverage rate for every test sample $\\{(X_{n+t},y)\\}_{t=1}^{m}$ . In specific, identifying $\\mathcal{D}(k,m),\\forall k\\in[K],m\\in$ $\\left[M_{k}\\right]$ takes ${\\dot{O}}(n\\cdot M\\cdot{\\dot{K}})$ . For each $\\ensuremath{\\mathcal \u1e0a D \u1e0c }(k,m)$ , computing $\\begin{array}{r}{\\sum_{i\\in\\mathcal{D}(k,m)}E_{y,i,t},\\forall t\\in[m],\\forall y\\in}\\end{array}$ $[L]$ takes ${\\mathcal{O}}(L\\cdot|{\\mathcal{D}}(k,m)|\\cdot m)$ , and computing $E_{y,t,t}\\mathbf{1}\\{\\phi(Z_{i},\\{k\\})=m\\}$ takes $\\mathcal{O}(L\\cdot m)$ . Therefore, repeating this process for all $\\mathcal{D}(k,m),k\\in[K],m\\in[M_{k}]$ and for all $y\\in[L]$ in total takes $O(L\\cdot n\\cdot m)$ . Lastly, finding the maximum miscoverage across all attributes takes ${\\mathcal{O}}(L\\cdot m\\cdot M\\cdot K)$ . ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "Hence, the total cost of running Algorithm 2 for $m$ test samples is $\\mathcal{O}(n\\log n{+}L n m{+}M K(n{+}L m))$ . ", "page_idx": 26}, {"type": "text", "text": "A7 Additional Results from Numerical Experiments ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "A7.1 AFCP for Multiclass Classification ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "A7.1.1 Synthetic Data ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Recall from Section 3.2 that Color is denoted as $X_{0}$ and the first one of the non-sensitive features as $X_{1}$ . The distribution of $Y$ conditional on $X$ is modeled by a simple decision tree, where $X_{0}$ and $X_{1}$ are the only useful predictors for $Y$ , formulated as the following: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}[Y\\mid X]=\\left\\{\\begin{array}{l l}{\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3},0,0,0\\right),}&{\\mathrm{if~}X_{0}\\mathrm{=}\\mathrm{Blue~and~}X_{1}<0.5,}\\\\ {\\left(0,0,0,\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right),}&{\\mathrm{if~}X_{0}\\mathrm{=}\\mathrm{Blue~and~},X_{1}\\geq0.5,}\\\\ {\\left(1,0,0,0,0,0\\right),}&{\\mathrm{if~}X_{0}\\mathrm{=}\\mathrm{Grey~and~},0\\leq X_{1}\\leq\\frac{1}{6},}\\\\ {\\left(0,1,0,0,0,0\\right),}&{\\mathrm{if~}X_{0}\\mathrm{=}\\mathrm{Grey~and~},\\frac{1}{6}\\leq X_{1}\\leq\\frac{2}{6},}\\\\ {\\vdots}&{\\vdots}\\\\ {\\left(0,0,0,0,0,1\\right),}&{\\mathrm{if~}X_{0}\\mathrm{=}\\mathrm{Grey~and~},\\frac{5}{6}\\leq X_{1}\\leq1.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The detailed numerical experiments results of AFCP with the adaptive equalized coverage (see Equation (3)) are presented and compared with other benchmark methods. ", "page_idx": 26}, {"type": "text", "text": "Table A1: Average coverage and average size of prediction sets for all test samples constructed by different methods as a function of the training and calibration size. All methods obtain coverage beyond 0.9, while our AFCP and AFCP1 methods, along with the Marginal method, produce the smallest, thus, the most informative, prediction sets. Red numbers indicate the small size of prediction sets. See corresponding plots in Figure 3. ", "page_idx": 26}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/e888e129a8e06a4ebcfc34d94c9853da2755829ac67832996e4782c57649aef9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/8c4047b6eb3a386764ea72aea15b0f0327024acd19d27ccee94876f3a97d47c6.jpg", "img_caption": ["Figure A1: Coverage and size of prediction sets constructed with different methods for groups formed by Color. For the Blue group, the Marginal method (dashed orange lines) fails to detect and correct for its undercoverage, and the Exhaustive method produces prediction sets that are too conservative to be helpful. In contrast, our AFCP and AFCP1 methods correct the undercoverage and maintain small prediction sets. See Table A2 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/174bf0cd2e9d677b9b307fcb33e0ac542f578616a54dfdc39a2d614d7ee967c9.jpg", "img_caption": ["Figure A2: Coverage and size of prediction sets constructed with different methods for groups formed by Age group. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A3 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/725e2d98571eb9d09edbb8abfc791f2c7c1cc945f1e73d8f92466bdd2e115fa7.jpg", "img_caption": ["Figure A3: Coverage and size of prediction sets constructed with different methods for groups formed by Region. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A4 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/86022e3317ccaa80e4662ea426a89163e9058697c54ef57ddfd53ba27c36ed54.jpg", "table_caption": ["Table A2: Coverage and size of prediction sets constructed with different methods for groups formed by Color. Green numbers indicate low coverage and red numbers indicate the small size of prediction sets. See corresponding plots in Figure A1. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table A3: Coverage and size of prediction sets constructed with different methods for groups formed by Age Group. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A2. ", "page_idx": 28}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/7fa3e1e276190675e5c294c92d4fed6d5295593a524be3a8d097f11abd795c93.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table A4: Coverage and size of prediction sets constructed with different methods for groups formed by Region. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A3. ", "page_idx": 29}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/f51985768e74cc2e10a104da6f17945a5a7aeca24e306f2c05f3679abbe806ab.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Next, we provide numerical experimental results comparing AFCP with the label-conditional adaptive equalized coverage (see Equation (A14)) with other benchmark methods. ", "page_idx": 30}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/b2606b2f0d90de1a2486e346c45df589d52475b4fa96ca14a22d77c54cca5455.jpg", "img_caption": ["Figure A4: Performance on prediction sets constructed by different methods on synthetic medical diagnosis data as a function of the total number of training and calibration points. Our method (AFCP) leads to more informative sets with lower average width and higher conditional coverage on the Blue group. The error bars indicate 2 standard errors. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table A5: Average coverage and average size of prediction sets for all test samples constructed by different methods as a function of the training and calibration size. All methods obtain coverage beyond 0.9, while our AFCP and AFCP1 methods, along with the Marginal method, produce the smallest, thus, the most informative, prediction sets. Red numbers indicate the small size of prediction sets. See corresponding plots in Figure A4. ", "page_idx": 30}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/17aa1b1306f11df91b70a8e25239296fec240d811d8f3a5ee8ddc154e2f06315.jpg", "img_caption": ["Figure A5: Coverage and size of prediction sets constructed with different methods for groups formed by Color. For the Blue group, the Marginal method (dashed orange lines) fails to detect and correct for its undercoverage, and the Exhaustive method produces prediction sets that are too conservative to be helpful. In contrast, our AFCP and AFCP1 methods correct the undercoverage and maintain small prediction sets. See Table A6 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/d38fefae26d2ecf17a84b9880bd9643806ed934bf0fd7b77e8ac05f7190d42be.jpg", "img_caption": ["Figure A6: Coverage and size of prediction sets constructed with different methods for groups formed by Age group. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A7 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/9ba8cd46ef97183d2ef0824e90fc55b01537444254f9a3d8f5aa090e22019f95.jpg", "img_caption": ["Figure A7: Coverage and size of prediction sets constructed with different methods for groups formed by Region. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A8 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 31}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/24b73194692b9086b63e66d0283d4c54f8d03c3d212b7aa5b62fbb045c3ba370.jpg", "table_caption": ["Table A6: Coverage and size of prediction sets constructed with different methods for groups formed by Color. Green numbers indicate low coverage and red numbers indicate the small size of prediction sets. See corresponding plots in Figure A5. "], "table_footnote": [], "page_idx": 31}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/74856bb8e8202c10ac8a932f24c09bd45ba95aef0b67b90ed8c2e4196d1b65f1.jpg", "table_caption": ["Table A7: Coverage and size of prediction sets constructed with different methods for groups formed by Age Group. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A6. "], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "Table A8: Coverage and size of prediction sets constructed with different methods for groups formed by Region. By design, all groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A7. ", "page_idx": 33}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/27cf166e671bce780f158ade3611218375963b21971ad23ad46ee04b1064fea1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "A7.1.2 Nursery Data ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Table A9: Average coverage and average size of prediction sets for all test samples constructed by different methods as a function of the training and calibration size. All methods obtain coverage beyond 0.9, while our AFCP and AFCP1 methods, along with the Marginal method, produce the smallest, thus, the most informative, prediction sets. Red numbers indicate the small size of prediction sets. See corresponding plots in Figure 5. ", "page_idx": 34}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/1e3148567874ac22298161043d73e28e7a16d03ca699978065994bf72bf7fd33.jpg", "img_caption": ["Figure A8: Coverage and size of prediction sets constructed with different methods for groups formed by Parents\u2019 Occupation. For the Occupation 1 group, the Marginal method (dashed orange lines) fails to detect and correct for its undercoverage, and the Exhaustive method produces prediction sets that are too conservative to be helpful. In contrast, our AFCP and AFCP1 methods correct the undercoverage and maintain small prediction sets. See Table A10 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/9af7be4b17e2a0f915659cd09487632dd863593258c2052db05698e42f5189aa.jpg", "img_caption": ["Figure A9: Coverage and size of prediction sets constructed with different methods for groups formed by Children. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A11 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/2daf7bd77bafa5a9478daed567f37705e14f9867aa3031758c1d89640ff56319.jpg", "img_caption": ["Figure A10: Coverage and size of prediction sets constructed with different methods for groups formed by Finance. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A12 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/16acc75df56fe849ada856520527329a3588eb9f751d445a66391f93d73b8154.jpg", "img_caption": ["Figure A11: Coverage and size of prediction sets constructed with different methods for groups formed by Social. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A13 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/9c8ad763ae2dcfe54ff0ca1d34ce0283bb20d66c32cb64e5bfc71f8170d349b5.jpg", "img_caption": ["Figure A12: Coverage and size of prediction sets constructed with different methods for groups formed by Health. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A14 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 35}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/a697376fdef52a4a54faebaf30f0c5190e6887aee86906a182e6b152972e14f3.jpg", "table_caption": ["Table A10: Coverage and size of prediction sets constructed with different methods for groups formed by Parents\u2019 Occupation. Green numbers indicate low coverage and red numbers indicate the small size of prediction sets. See corresponding plots in Figure A8. "], "table_footnote": [], "page_idx": 36}, {"type": "text", "text": "Table A11: Coverage and size of prediction sets constructed with different methods for groups formed by Children. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A9. ", "page_idx": 36}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/28ee687c46ef17b6e69101c2a7550e95c913270e356b36ddebf2c6ab16aa7dbd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 36}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/cd715762b203b7281faaf7f0b74c2e372580df217c457befca341f456c54ba0e.jpg", "table_caption": ["Table A12: Coverage and size of prediction sets constructed with different methods for groups formed by Finance. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A10. "], "table_footnote": [], "page_idx": 37}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/e9a6968c34f8da2cf1054fe54400c1979a69ce0a874997bfcfc3c1083d181111.jpg", "table_caption": ["Table A13: Coverage and size of prediction sets constructed with different methods for groups formed by Social. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A11. "], "table_footnote": [], "page_idx": 37}, {"type": "text", "text": "Table A14: Coverage and size of prediction sets constructed with different methods for groups formed by Health. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A12. ", "page_idx": 38}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/d26cca1e349839fc31a89fcb681ffaff445d518b811aa225f9207e9a53f5488a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 38}, {"type": "text", "text": "Next, we provide numerical experimental results comparing AFCP with the label-conditional adaptive equalized coverage (see Equation (A14)) with other benchmark methods. ", "page_idx": 39}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/c4293a0d1d3d0bf8412e1971149c7f4bc7222aed5e105ebfe6af4a32e1713032.jpg", "img_caption": ["Figure A13: Performance on prediction sets constructed by different methods on the nursery data as a function of the total number of training and calibration points. Our method (AFCP) leads to more informative sets with a lower average width and higher conditional coverage on the Pretentious group. The error bars indicate 2 standard errors. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "Table A15: Average coverage and average size of prediction sets for all test samples constructed by different methods as a function of the training and calibration size. All methods obtain coverage beyond 0.9, while our AFCP and AFCP1 methods, along with the Marginal method, produce the smallest, thus, the most informative, prediction sets. Red numbers indicate the small size of prediction sets. See corresponding plots in Figure A13. ", "page_idx": 39}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/eefa13ca15b3b4a2f482d19f3f39163784a19aec3500db16d006dd2271704fe0.jpg", "img_caption": ["Figure A14: Coverage and size of prediction sets constructed with different methods for groups formed by Parents\u2019 Occupation. For the Occupation 1 group, the Marginal method (dashed orange lines) fails to detect and correct for its undercoverage, and the Exhaustive method produces prediction sets that are too conservative to be helpful. In contrast, our AFCP and AFCP1 methods correct the undercoverage and maintain small prediction sets. See Table A16 for details and standard errors. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/ff35cbe545504bb3ae0d1c3da697bf559d8ac710389835636cf413a9e925821f.jpg", "img_caption": ["Figure A15: Coverage and size of prediction sets constructed with different methods for groups formed by Children. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A17 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/d97bf5b044f16bd6c318830f6607c03d9c507667fbedea7f0bdaa44e322e5bcb.jpg", "img_caption": ["Figure A16: Coverage and size of prediction sets constructed with different methods for groups formed by Finance. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A18 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/e1b260c07103c3f5e9f8a2f4068f06e05ccfcfb00896865f4618d077e25ff499.jpg", "img_caption": ["Figure A17: Coverage and size of prediction sets constructed with different methods for groups formed by Social. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See Table A19 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/5491795efeb8843fdb7b5f518dc3254746c83f88c0725d7fb555d7b997a00d4b.jpg", "img_caption": ["Figure A18: Coverage and size of prediction sets constructed with different methods for groups formed by Health. All groups have similar performances, and none of them are subject to unfairness/undercoverage. See Table A20 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 40}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/e05533a09bd5ea5408e3afced320a91e420e21a54c791a2e31bd8a8310936b0e.jpg", "table_caption": ["Table A16: Coverage and size of prediction sets constructed with different methods for groups formed by Parents\u2019 Occupation. Green numbers indicate low coverage and red numbers indicate the small size of prediction sets. See corresponding plots in Figure A14. "], "table_footnote": [], "page_idx": 41}, {"type": "text", "text": "Table A17: Coverage and size of prediction sets constructed with different methods for groups formed by Children. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A15. ", "page_idx": 41}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/464b1d0a3a36e080fd1655a1dc6be28e10800a31f4e0d3b0b312127f597695d5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 41}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/e38ba4e9031bc8ecce936cfbc7fe6d5fd54b4e575a30ea3ff8ee6e981edef133.jpg", "table_caption": ["Table A18: Coverage and size of prediction sets constructed with different methods for groups formed by Finance. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A16. "], "table_footnote": [], "page_idx": 42}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/f1e0c54e38c816c34e73c47a5b2d9d3a779c4dfa2c221ee4211475cb6c709561.jpg", "table_caption": ["Table A19: Coverage and size of prediction sets constructed with different methods for groups formed by Social. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A17. "], "table_footnote": [], "page_idx": 42}, {"type": "text", "text": "Table A20: Coverage and size of prediction sets constructed with different methods for groups formed by Health. All groups have similar performance, and none of them are subject to unfairness/undercoverage. See corresponding plots in Figure A18. ", "page_idx": 43}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/c6007d2d7fd2144fc827b37fe48a946fed85de67da6c583f575c41ad98f42f72.jpg", "table_caption": [], "table_footnote": [], "page_idx": 43}, {"type": "text", "text": "A7.1.3 COMPAS data ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "We extend our experiments to investigate the effectiveness of AFCP using the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) dataset [50]. The COMPAS dataset is widely studied in the fairness literature for multi-class classification tasks, predicting the risk of recidivism across three categories: \u2019High\u2019, \u2019Medium\u2019, and \u2019Low\u2019. Following the data preprocessing steps outlined in [59], we exclude rows with missing or low-quality data and compute the length of stay in jail. Additionally, we merge the race groups Asian and Native American, both of which have few occurrences, into the \u2019Others\u2019 category. After preprocessing, the dataset comprises 6,172 instances with five categorical features: charge degree of defendants (2 levels), race (4 levels), age category (3 levels), sex (2 levels), and score category of defendants (3 levels). We regard the first four features as potentially sensitive attributes. ", "page_idx": 44}, {"type": "text", "text": "Similar to the Nursery dataset case, we utilize the LabelEncoder function to numerically encode categorical features and outcome labels. To increase prediction difficulty and emphasize algorithmic bias, we introduce independent, uniformly distributed noise to the labels of samples identified as African-American. Additionally, we undersample the African-American group to 200 samples, while the Caucasian group contains 2,103 samples, Hispanic 509, and Others 385. ", "page_idx": 44}, {"type": "text", "text": "Figure A19 summarizes the performance of all methods as a function of the total number of training and calibration data points, which range from 200 to 1000. Figure A20 narrows the focus by analyzing the performance relative to the number of restricted calibration data points, as defined in Section 2.2. The results are averaged over 500 randomly selected test points and 100 repeated experiments. In each experiment, $50\\%$ of the samples are randomly assigned for training and the remaining $50\\%$ for calibration. Once again, we conclude that our AFCP methods outperform the other benchmarks considered, resulting in more informative prediction sets with higher conditional coverage for the African-American subgroup. ", "page_idx": 44}, {"type": "text", "text": "Figure A21 shows the selection frequencies of the protected attribute Race as a function of sample size within the same experiment described in Figure A19. This plot demonstrates that both AFCP and AFCP 1 consistently select Race as the most sensitive attribute as the number of samples increases. Also, we report the prediction accuracy in Table A21. The results confirm that the African-American group is disproportionately affected by algorithmic bias, not only in terms of uncertainty estimates but also in prediction accuracy, as they experience significantly lower-than-average test accuracy. ", "page_idx": 44}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/9d96c0c41975e694679e80c833937e6ae91361341c78ebf9d83dea58f76d057a.jpg", "img_caption": ["Figure A19: Performance of prediction sets constructed by different methods on the COMPAS data, as a function of the sample size. AFCP leads to more informative predictions with higher coverage conditional on the sensitive attribute, Race (shown for level African-American). "], "img_footnote": [], "page_idx": 44}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/f0cd655e0bbea9471f9f683553da31a82f3612719ba213f9eec49d27fee6b458.jpg", "img_caption": ["Figure A20: Conditional coverage for the African-American group using different methods on the COMPAS data, as a function of the sample sizes in the restricted calibration data. "], "img_footnote": [], "page_idx": 44}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/096ec3b1677b65b19d594a5196074eedeafe9f16dcc9d63e9b0a053ee5d31ded.jpg", "img_caption": ["Figure A21: Selection frequency of the relevant attribute Race, using our AFCP method and its variation, AFCP1, in the COMPAS experiments of Figure A19. As the sample size increases, AFCP and AFCP1 become more consistent in selecting the most relevant attribute, Race. "], "img_footnote": [], "page_idx": 45}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/2f3fd687f4af62493c0df39339b9e55a7bda2c77e0877988bf3cd16f73cb751a.jpg", "table_caption": ["Table A21: Average prediction accuracy and prediction accuracy for African-American group on the COMPAS data, as a function of the sample size. "], "table_footnote": [], "page_idx": 45}, {"type": "text", "text": "A7.2 AFCP for Outlier Detection ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "A7.2.1 Setup and Benchmarks ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "This section demonstrates the empirical performance of our AFCP extension for outlier detection. Firstly, we focus on the implementation described in Algorithm A7, which selects at most one sensitive attribute. Similar to the multi-class classification cases, Our method is compared with three existing approaches, which utilize the same data, ML model, and conformity scores but compute conformal p-values with different guarantees. The first is the marginal benchmark, which constructs conformal p-value guaranteeing $\\bar{\\mathbb{P}}(\\hat{u}^{\\mathrm{marginal}}(Z_{n+1})\\le\\alpha)\\le\\alpha$ by applying Algorithm A2 without protected attributes. The second is the exhaustive equalized benchmark, which evaluates conformal p-values guaranteeing $\\mathbb{P}({\\hat{u}}^{\\mathrm{exhaustive}}(Z_{n+1})\\leq\\alpha\\mid\\phi({\\bar{Z}}_{n+1},[K]))\\leq\\alpha$ by applying Algorithm A2 with all $K$ sensitive attributes simultaneously protected. The third is a partial equalized benchmark that separately applies Algorithm A2 with each possible protected attribute $k\\in[K]$ , and then takes the maximum of all such p values. This is an intuitive approach that can be easily verified to provide a coverage guarantee $\\mathbb{P}\\!\\left(\\hat{u}^{\\mathrm{partial}}(Z_{n+1})\\le\\alpha\\mid\\phi(Z_{n+1},\\Bar{\\{k\\}}))\\le\\alpha\\quad\\forall k\\in[K].$ ", "page_idx": 45}, {"type": "text", "text": "In addition, similar to the multiclass classification experiments, we consider AFCP1 - the AFCP implementation that always selects the most critical protected attribute without conducting the significance test. ", "page_idx": 45}, {"type": "text", "text": "For all methods considered, the outlier detection model is based on a three-layer neural network, and the outputs from each layer are batch-normalized. The Adam optimizer and the BCEWithLogitsLoss loss function are used in the training process, with a learning rate set at 0.0001. The loss values demonstrate convergence after 100 epochs of training. For all methods, the miscoverage target level is set at $\\alpha=0.1$ . Note that the training and testing data contain both inliers and outliers, while the calibration data only contains inliers. ", "page_idx": 45}, {"type": "text", "text": "We assess the performance of the methods based on the False Positive Rate (FPR) and the True Positive Rate (TPR). Ideally, the objective is to achieve a higher conditional FPR for groups experiencing unfairness, thereby maintaining the average FPR below the target threshold of 0.1 while simultaneously achieving a higher TPR. The results presented are averaged over 500 independent test points and 30 experiments. ", "page_idx": 45}, {"type": "text", "text": "A7.2.2 Synthetic Data ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "We employ the same data settings as in the multi-class classification example, designating Color as the sensitive attribute associated with the Blue group, which suffers from undercoverage. While Age Group and Region are also sensitive attributes, they are not subject to biases in this context. The outcome labels $Y$ have two possible values: $Y=0$ if the unit is properly treated and $Y=1$ otherwise. In our experiment, we treat $Y=1$ as an outlier and $Y=0$ as an inlier, with the data generation process described as: ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\,Y\\mid X]={\\left\\{\\begin{array}{l l}{\\left({\\frac{1}{2}},{\\frac{1}{2}}\\right),}&{{\\mathrm{if~Color}}=\\mathrm{Blue},}\\\\ {\\left(1,0\\right){\\mathrm{~or~}}(0,1){\\mathrm{~w.~equal~prob}},}&{{\\mathrm{if~Color}}=\\mathrm{Grey}.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Figure A22 and Table A22 illustrate the performance of conformal p-values generated by various methods on synthetic data, showcasing how performance varies with the number of samples in training and calibration datasets. Figures A23\u2013A24 and Tables A23\u2013A25 separately evaluate the False Positive Rate (FPR) and True Positive Rate (TPR) for each protected attribute. Additionally, Figure A26 explores how the severity of bias affecting groups impacts the selection frequency of our method at various levels. The severity of bias is controlled by the varying percentage of Blue samples, with higher levels indicating less samples and more significant biases in the Blue group. ", "page_idx": 46}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/11594d41b471c310c0031f95d7eccdef630fb6f70fe83cbeaf191b857edec674.jpg", "img_caption": ["Figure A22: Performance on conformal p-values constructed by different methods on the synthetic data as a function of the total number of training and calibration points. Our method (AFCP) leads to higher TPR and lower FPR on the Blue group. The error bars indicate 2 standard errors. "], "img_footnote": [], "page_idx": 46}, {"type": "text", "text": "Table A22: Average FPR and TPR of conformal p-values for all test samples constructed by different methods as a function of the training and calibration size. All methods control FPR under 0.1, while our AFCP and AFCP1 methods, along with the Marginal method, produce the highest TPR. Red numbers indicate high TPR. See corresponding plots in Figure A22. ", "page_idx": 46}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/3a84e21b5c654bdf4e007d83bb997c180ee7981d2e4a4936e26d19d0496025f3.jpg", "img_caption": ["Figure A23: Performance on conformal p-values constructed by different methods for groups formed by Color. See Table A23 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/76ca7ddd0210dd7ea0e9ff3adf3a62d0f1314c475ed6a28b230092c69a6cceac.jpg", "img_caption": ["Figure A24: Performance on conformal p-values constructed by different methods for groups formed by Region. See Table A25 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 47}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/02358b2085c88ef35640420c01175157bb075f34f683c78f29c39824580f76ae.jpg", "img_caption": ["Figure A25: Performance on conformal p-values constructed by different methods for groups formed by Age Group. See Table A24 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 47}, {"type": "text", "text": "Table A23: Coverage and size of prediction sets constructed with different methods for groups formed by Color. See corresponding plots in Figure A23. ", "page_idx": 47}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/5e923a682d75b0c1a1bf1359289d13391a2483832f4ef5303ff31d05dea9c4f0.jpg", "img_caption": ["Figure A26: Selection frequencies of each protected attribute as a function of severity level of bias. "], "img_footnote": [], "page_idx": 47}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/4909e754a360cdbd8c368629d2e301d8ef7e8dacce48e2cae8c58d042ee828f2.jpg", "table_caption": ["Table A24: Coverage and size of prediction sets constructed with different methods for groups formed by Age Group. See corresponding plots in Figure A25. "], "table_footnote": [], "page_idx": 48}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/a2380e8b59925f83bb67d0e5083ea39e8a3f28498d1a5d26ec2ef6989a58bd57.jpg", "table_caption": ["Table A25: Coverage and size of prediction sets constructed with different methods for groups formed by Region. See corresponding plots in Figure A24. "], "table_footnote": [], "page_idx": 48}, {"type": "text", "text": "A7.2.3 Adult Income Data ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "We apply our method to the open-domain Adult Income dataset [51], a widely utilized resource in fairness studies. In this dataset, individuals with an income exceeding $\\mathbb{S}50{,}000$ are treated as outliers, while those with an income of $\\mathbb{S}50{,}000$ or less are considered inliers. All categorical variables in this dataset are treated as sensitive attributes, with levels that have small sample sizes grouped together during the pre-processing stages. After pre-processing, the sensitive attributes and their associated levels are as follows: Native-country (United-States, Others); Education (Bachelors, Somecollege, HS-grad, Others); Work Class (Private, Non-private); Marital-status (Divorced, Married-civspouse, Never-married, Others); Occupation (Adm-clerical, Craft-repair, Other-service, Sales, Execmanagerial, Prof-specialty, Others); Relationship (Own-child, Husband, Not-in-family, Unmarried, Others); Race (White, Others); and Sex (female, male). ", "page_idx": 49}, {"type": "text", "text": "This section evaluates and compares the performance of AFCP, AFCP1, and $\\mathrm{AFCP+}$ , which is the AFCP implementation capable of selecting multiple protected attributes, along with other benchmark methods described in Appendix A7.2.1. All results presented in this section average over 500 test points and 30 independent experiments. ", "page_idx": 49}, {"type": "text", "text": "For this dataset, the groups suffering from algorithmic biases are unknown. Figure A27 evaluates the performance of different methods on several groups that are observed to exhibit higher FPR using the Marginal method. In all such cases, our AFCP, AFPC1, and $\\mathrm{AFCP+}$ methods effectively identify and correct for the protected attributes corresponding to at least one group suffering from significantly higher FPR. ", "page_idx": 49}, {"type": "text", "text": "Figure A28 and Table A26 present the average FPR and TPR of conformal p-values computed using different methods across all test samples. On average, all methods can control the FPR below the target level of 0.1, while our AFCP methods generally achieve higher TPR. ", "page_idx": 49}, {"type": "text", "text": "In addition, Figures A29\u2013A36 and Table A27\u2013A34 separately assess the FPR and TPR of conformal p-values for each protected attribute. ", "page_idx": 49}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/db960aff85cf10f7fd2cc3fd6b2e23afe2a2378e51bc985c914412aaf342b10a.jpg", "img_caption": ["Figure A27: FPR of conformal p-values constructed with different methods for groups that are observed to have significantly higher FPR when using the Marginal method. On average, our methods identify those groups and perform corrections on the FPR. "], "img_footnote": [], "page_idx": 49}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/684674c00696d524635c03feb917067bef08770e7f56d5681388cc6ff7ecefda.jpg", "img_caption": ["Figure A28: Average FPR and TPR of conformal p-values constructed with different methods on all test samples. All methods control FPR under the target level 0.1. Our AFCP methods can produce generally higher TPR than other methods except the Marginal one. However, as depicted in Figure A27, the Marginal method suffers from unfairness. ", "Sample size "], "img_footnote": [], "page_idx": 50}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/4b46880b058b679ca02cbc252a0747fa43f673d5c4af3f7ab3431efc87af3077.jpg", "table_caption": ["Table A26: Average FPR and TPR of conformal p-values constructed with different methods on all test samples. All methods control FPR under the target level 0.1. Red numbers indicate high TPR. See corresponding plots in Figure A28. "], "table_footnote": [], "page_idx": 50}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/97d587760cb2c6392b1c4eba0d7a7f1b762a3fae8c8f1901fde32cf8f776473a.jpg", "img_caption": ["Figure A29: Performance on conformal p-values constructed by different methods for groups formed by Work Class. See Table A27 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 50}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/01f556e17700bb5bab93f0ca273f7adb0f3e588bca220c018a8962071387179d.jpg", "img_caption": ["Figure A30: Performance on conformal p-values constructed by different methods for groups formed by Education. See Table A28 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 50}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/09affbe374b68a29450add6ba646ba354a8e243ac6025d3ceac931aa39d9237e.jpg", "table_caption": ["Table A27: Coverage and size of prediction sets constructed with different methods for groups formed by Work Class. See corresponding plots in Figure A29. "], "table_footnote": [], "page_idx": 51}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/c87efa36a0faee8ab58fe909f26639fcbaffee586ea1abad7e15f938fbae79a4.jpg", "table_caption": ["Table A28: Coverage and size of prediction sets constructed with different methods for groups formed by Education. See corresponding plots in Figure A30. "], "table_footnote": [], "page_idx": 51}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/382b4e1ff7539ba8345c6998d5c0392906a154f49d871e72249b1baaf7382a7f.jpg", "img_caption": ["Figure A31: Performance on conformal p-values constructed by different methods for groups formed by Marital Status. See Table A29 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 51}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/cc8f00cfda031a0063fdbd8ea6b86c56c9f0c922d414c82bf522be6696c6da05.jpg", "table_caption": ["Table A29: Coverage and size of prediction sets constructed with different methods for groups formed by Marital Status. See corresponding plots in Figure A31. "], "table_footnote": [], "page_idx": 52}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/446771eba3603f7c901a0d839da652e18b246c7c6d97c896b3146134d4d110cc.jpg", "img_caption": ["Figure A32: Performance on conformal p-values constructed by different methods for groups formed by Occupation. See Table A30 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 52}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/f11437036fd2f834e86fa3e6c348899bddd611005f2137d0a0fb2f1f0778d922.jpg", "img_caption": ["Figure A33: Performance on conformal p-values constructed by different methods for groups formed by Relationship. See Table A31 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 52}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/e00eabebdc95938af026cfb1838792adf44528b7aae7107810b7550a61d09e31.jpg", "table_caption": ["Table A30: Coverage and size of prediction sets constructed with different methods for groups formed by Occupation. See corresponding plots in Figure A32. "], "table_footnote": [], "page_idx": 53}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/f6989e9e10f3f66157e7a876ef3803dc5a2c981ece6874fb7d09beb69e5bbae0.jpg", "img_caption": ["Figure A34: Performance on conformal p-values constructed by different methods for groups formed by Race. See Table A32 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 53}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/fdaf2f3da2926cf1b93f82c9d55de64065aad0a2f34ca6890af1249d139ae29f.jpg", "table_caption": ["Table A31: Coverage and size of prediction sets constructed with different methods for groups formed by Relationship. See corresponding plots in Figure A33. "], "table_footnote": [], "page_idx": 54}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/30625b1228b3df45eb484592a2c6b9663c7f43d6ed7521bef36ccf0ecb605e55.jpg", "table_caption": ["Table A32: Coverage and size of prediction sets constructed with different methods for groups formed by Race. See corresponding plots in Figure A34. "], "table_footnote": [], "page_idx": 54}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/56e8b52f0a7aed5616a7bba884f2046a093e8395d28454d3075e5b09a3ff79e1.jpg", "img_caption": ["Figure A35: Performance on conformal p-values constructed by different methods for groups formed by Sex. See Table A33 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 55}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/5d6a112d5f02e0929efd3a382b3a0c4890db06c716498451af5da9efbf99ddfc.jpg", "table_caption": ["Table A33: Coverage and size of prediction sets constructed with different methods for groups formed by Sex. See corresponding plots in Figure A35. "], "table_footnote": [], "page_idx": 55}, {"type": "image", "img_path": "3pWHKxK1sC/tmp/27e009c25c6e33dbaa914f51a8bf261e3d133174b0c5bf6758ee5108506652d5.jpg", "img_caption": ["Figure A36: Performance on conformal p-values constructed by different methods for groups formed by Country. See Table A34 for numerical details and standard errors. "], "img_footnote": [], "page_idx": 55}, {"type": "table", "img_path": "3pWHKxK1sC/tmp/8adb5b4c6099c92acd5c88c7792e5a5b08d7cf6bd7571dc2ffa9fd374210cd44.jpg", "table_caption": ["Table A34: Coverage and size of prediction sets constructed with different methods for groups formed by Country. See corresponding plots in Figure A36. "], "table_footnote": [], "page_idx": 56}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 57}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 57}, {"type": "text", "text": "Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 57}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Justification: The paper discusses the limitations of this work in the Discussion section. Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 57}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 57}, {"type": "text", "text": "Justification: All assumptions are stated in the paper and all proofs are provided in the Appendix. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 58}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: The paper fully discloses all the information needed to reproduce the main experimental results. Additionally, code is provided. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 58}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 59}, {"type": "text", "text": "Justification: The paper provides open access to the code needed to reproduce the main experimental results, and precise information about how the open-domain data were obtained. Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 59}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Justification: The paper specify all the training and test details necessary to understand the results. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 59}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Justification: The paper reports error bars or standard deviations where appropriate, along with suitable explanations. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 59}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 60}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 60}, {"type": "text", "text": "Justification: The paper provides information on the computer resources in the Discussion section. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 60}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Justification: The research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 60}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 60}, {"type": "text", "text": "Justification: This work is motivated by the need to address algorithmic bias issues, which is a topic with potentially broad impacts, as discussed in the paper. However, this paper focuses on foundational research that is not tied to a particular application. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 61}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 61}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 61}, {"type": "text", "text": "Justification: This paper describes foundational research and does not release new data or models. ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 61}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: This paper uses open-domain data, properly crediting the license and creators. Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 61}, {"type": "text", "text": "", "page_idx": 62}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 62}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 62}, {"type": "text", "text": "Justification: The new code accompanying this paper is well documented. ", "page_idx": 62}, {"type": "text", "text": "Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 62}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 62}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 62}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 62}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 62}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 62}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 62}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 63}]