[{"type": "text", "text": "Pre-trained Large Language Models Use Fourier Features to Compute Addition ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tianyi Zhou Deqing Fu Vatsal Sharan Robin Jia Department of Computer Science University of Southern California Los Angeles, CA 90089   \n{tzhou029,deqingfu,vsharan,robinjia}@usc.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pre-trained large language models (LLMs) exhibit impressive mathematical reasoning capabilities, yet how they compute basic arithmetic, such as addition, remains unclear. This paper shows that pre-trained LLMs add numbers using Fourier features\u2014dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain. Within the model, MLP and attention layers use Fourier features in complementary ways: MLP layers primarily approximate the magnitude of the answer using low-frequency features, while attention layers primarily perform modular addition (e.g., computing whether the answer is even or odd) using high-frequency features. Pre-training is crucial for this mechanism: models trained from scratch to add numbers only exploit low-frequency features, leading to lower accuracy. Introducing pre-trained token embeddings to a randomly initialized model rescues its performance. Overall, our analysis demonstrates that appropriate pre-trained representations (e.g., Fourier features) can unlock the ability of Transformers to learn precise mechanisms for algorithmic tasks. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mathematical problem solving has become a crucial task for evaluating the reasoning capabilities of large language models (LLMs) [20, 7, 23, 13]. While LLMs exhibit impressive mathematical abilities [34, 17, 1, 45, 40, 4, 11], it remains unclear how they perform even basic mathematical tasks. Do LLMs apply mathematical principles when solving math problems, or do they merely reproduce memorized patterns from the training data? ", "page_idx": 0}, {"type": "text", "text": "In this work, we unravel how pre-trained language models solve simple mathematical problems such as \u201cPut together 15 and 93. Answer: \u201d. Prior work has studied how Transformers, the underlying architecture of LLMs, perform certain mathematical tasks. Most studies [5, 14, 42, 2, 12, 28, 18, 36] focus on Transformers with a limited number of layers or those trained from scratch; [19] analyzes how the pre-trained GPT-2-small performs the greater-than task. Our work focuses on a different task from prior interpretability work\u2014integer addition\u2014and shows that pre-trained LLMs learn distinct mechanisms from randomly initialized Transformers. ", "page_idx": 0}, {"type": "text", "text": "In $\\S3$ , we show that pre-trained language models compute addition with Fourier features\u2014dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain. First, we analyze the behavior of pre-trained LLMs on the addition task after fine-tuning, which leads to almost perfect accuracy on the task. Rather than merely memorizing answers from the training data, the models progressively compute the final answer layer by layer. Next, we analyze the contributions of individual model components using Logit Lens [3]. We observe that some components primarily approximate the answer\u2014they promote all numbers close to the correct answer in magnitude\u2014 while other components primarily classify the answer modulo $m$ for various numbers $m$ . Then, we use Fourier analysis to isolate features in the residual stream responsible for the low-frequency \u201capproximation\u201d and high-frequency \u201cclassification\u201d subtasks. Identifying these features allows us to precisely ablate the ability of the model to perform either approximation or classification by applying a low-pass or high-pass filter, respectively, to the outputs of different model components. We find that MLP layers contribute primarily to approximation, whereas attention layers contribute primarily to classification. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In $\\S4$ , we show that pre-training is crucial for learning this mechanism. The same network trained from scratch with random initialization not only shows no signs of Fourier features, but also has lower accuracy. We identify pre-trained token embeddings as a key source of inductive bias that help the pre-trained model learn a more precise mechanism for addition. Across the pre-trained token embeddings of many different pre-trained models, Fourier analysis uncovers large magnitudes of components with periods 2, 5, and 10. Introducing pre-trained token embeddings when training the model from scratch enables the model to achieve perfect test accuracy. Finally, we show that the same Fourier feature mechanism is present not only in models that were pre-trained and then fine-tuned, but also in frozen pre-trained LLMs when prompted with arithmetic problems. ", "page_idx": 1}, {"type": "text", "text": "Overall, our work provides a mechanistic perspective on how pre-trained LLMs compute addition through the lens of Fourier analysis. It not only broadens the scope from only investigating few-layer Transformers trained to fti a particular data distribution to understanding LLMs as a whole, but also hints at how pre-training can lead to more precise model capabilities. ", "page_idx": 1}, {"type": "text", "text": "2 Problem Setup ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Task and Dataset. We constructed a synthetic addition dataset for fine-tuning and evaluation purposes. Each example involves adding two numbers $\\leq260$ , chosen because the maximum number that can be represented by a single token in the GPT-2-XL tokenizer is 520. For each pair of numbers between 0 and 260, we randomly sample one of five natural language question templates and combine it with the two numbers. The dataset is shuffled and then split into training $(80\\%)$ , validation $(10\\%)$ , and test $(10\\%)$ sets. More details are provided in Appendix F. In Appendix C.3, we show our that results generalize to a different dataset formatted with reverse Polish notation. ", "page_idx": 1}, {"type": "text", "text": "Model. Unless otherwise stated, all experiments focus on the pre-trained GPT-2-XL model that has been fine-tuned on our addition dataset. This model, which consists of 48 layers and approximately 1.5 billion parameters, learns the task almost perfectly, with an accuracy of $\\mathrm{{99.74\\%}}$ on the held-out test set. We examine other models in $\\S4.2$ and $\\S4.3$ . ", "page_idx": 1}, {"type": "text", "text": "Transformers. We focus on decoder-only Transformer models [41], which process text sequentially, token by token, from left to right. Each layer $\\ell$ in the Transformer has an attention module with output $\\bar{\\mathrm{Attn}}^{(\\ell)}$ and an MLP module with output $\\mathrm{MLP}^{(\\ell)}$ . Their outputs are added together to create a continuous residual stream $h$ [9], meaning that the token representation accumulates all additive updates within the residual stream, with the representation $h^{(\\bar{\\ell})}$ in the $\\ell\\cdot$ -th layer given by: ", "page_idx": 1}, {"type": "equation", "text": "$$\nh^{(\\ell)}=h^{(\\ell-1)}+\\mathrm{Attn}^{(\\ell)}+\\mathrm{MLP}^{(\\ell)}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The output embedding $W^{U}$ projects the residual stream to the space of the vocabulary; applying the softmax function then yields the model\u2019s prediction. We provide formal definitions in Appendix A. ", "page_idx": 1}, {"type": "text", "text": "3 Language Models Solve Addition with Fourier Features ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we analyze the internal mechanisms of LLMs when solving addition tasks, employing a Fourier analysis framework. We first show that the model initially approximates the solution before iteratively converging to the correct answer (\u00a73.1). We then show that the model refines its initial approximation by computing the exact answer modulo 2, 5, and 10, employing Fourier components of those same periods (\u00a73.2). Finally, we demonstrate through targeted ablations that the identified Fourier components are causally important for the model\u2019s computational processes (\u00a73.3). Specifically, we show that MLP layers primarily approximate the magnitude of the answer, using lowfrequency features, while attention layers primarily perform modular addition using high-frequency components. ", "page_idx": 1}, {"type": "image", "img_path": "i4MutM2TZb/tmp/afdf9ed5c643a31fd7d6fb3d4e91da2881584c99ba935f54c012ca4773e38367.jpg", "img_caption": ["Figure 1: (a) Visualization of predictions extracted from fine-tuned GPT-2-XL at intermediate layers. Between layers 20 and 30, the model\u2019s accuracy is low, but its prediction is often within 10 of the correct answer: the model first approximates the answer, then refines it. (b) Heatmap of the logits from different MLP layers for the running example, \u201cPut together 15 and 93. Answer: $108^{\\circ}$ . The $y$ -axis represents the subset of the number space around the correct prediction, while the $x$ -axis represents the layer index. The 33-rd layer performs mod 2 operations (favoring even numbers), while other layers perform other modular addition operations, such as mod 10 (45-th layer). Additionally, most layers allocate more weight to numbers closer to the correct answer, 108. (c) Analogous plot for attention layers. Nearly all attention modules perform modular addition. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "3.1 Behavioral Analysis ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our first goal is to understand whether the model merely memorizes and recombines pieces of information learned during training, or it performs calculations to add two numbers. ", "page_idx": 2}, {"type": "text", "text": "Extracting intermediate predictions. To elucidate how LLMs perform computations and progressively refine their outputs towards the correct answer, we extract model predictions at each layer from the residual stream. Let $L$ denote the number of layers. Using the Logit Lens method [3], instead of generating predictions by computing logits $W^{\\bar{U}}h^{(L)}$ , predictions are derived through $W^{U}h^{(\\ell)}$ where $\\ell\\in[L]$ . We compute the accuracy of the prediction using each intermediate state $h^{(\\ell)}$ . If the models merely retrieve and recombine pieces of information learned during training, certain layers will directly map this information to predictions. For instance, [25] demonstrates that there is a specific MLP module directly maps a country to its capital. ", "page_idx": 2}, {"type": "text", "text": "LLMs progressively compute the final answers. Figure 1a instead shows that the model progressively approaches the correct answer, layer by layer. The model is capable of making predictions that fall within the range of $\\pm2$ and $\\pm10$ relative to the correct answer in the earlier layers, compared to the exact-match accuracy. This observation implies that the Transformer\u2019s layer-wise processing structure is beneficial for gradually refining predictions through a series of transformations and updates applied to the token representations. ", "page_idx": 2}, {"type": "text", "text": "3.2 Fourier Features in MLP & Attention Outputs ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Logits for MLP and attention have periodic structures. We now analyze how each MLP and attention module contributes to the final prediction. We transform the output of the attention and MLP output at layer $\\ell$ into the token space using $W^{U}\\mathrm{Attn}^{(\\ell)}$ and $W^{U}\\mathrm{MLP}^{(\\ell)}$ at each layer, thereby obtaining the logits $\\mathcal{L}$ for each MLP and attention module. We use the running example \u201cPut together 15 and 93. Answer: $108^{\\circ}$ to demonstrate how the fine-tuned GPT-2-XL performs the computation. As illustrated in Figure 1b and Figure 1c, both the MLP and attention modules exhibit a periodic pattern in their logits across the output number space, e.g., the MLP in layer 33, outlined in green, promotes all numbers that are congruent to 108 mod 2 (in Figure 20 in the appendix, we zoom into such layers to make this clearer). Overall, we observe two distinct types of computation within these components. Some components predominantly assign a high weight to numbers around the correct answer, which we term approximation. Meanwhile, other components predominantly assign a high weight to all numbers congruent to $a+b$ mod $c$ for some constant $c$ , which we term classification. ", "page_idx": 2}, {"type": "text", "text": "Logits for MLP and attention are approximately sparse in the Fourier space. It is natural to transform the logits into Fourier space to gain a better understanding of their properties such as the periodic pattern. We apply the discrete Fourier transform to represent the logits as the sum of ", "page_idx": 2}, {"type": "image", "img_path": "i4MutM2TZb/tmp/c5534efa39cebf1af440039f78de143c6500bea4a5206941dbb8e22830cc9ee3.jpg", "img_caption": ["(a) Logits for the MLP output in Fourier space "], "img_footnote": [], "page_idx": 3}, {"type": "image", "img_path": "i4MutM2TZb/tmp/ba416ffe871c88fd33ed4f615b746c20e4d0ace975f1fb450f546365654d1b5a.jpg", "img_caption": ["(b) Logits for the attention output in Fourier space "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 2: The intermediate logits in Fourier space. We annotate the top-10 outlier high-frequency Fourier components based on their magnitudes. $T$ stands for the period of that Fourier component. (a) The logits in Fourier space for the MLP output of the 33-rd layer, i.e., L (M33L)P. The component with period 2 has the largest magnitude, aligning with the observations in Fig ures 1b and 20a. (b) The logits in Fourier space for the attention output of the 40-th layer, i.e., $\\widehat{\\mathcal{L}}_{\\mathrm{Attn}}^{(40\\overline{{\\cdot}})}$ . The components with periods 5 and 10 have the largest magnitude, aligning with the observations in Figures 1c and $20\\mathfrak{b}$ . ", "page_idx": 3}, {"type": "text", "text": "sine and cosine waves of different periods: the $k$ -th component in Fourier space has period $520/k$ and frequency $k/520$ (see Appendix A for more details). Let $\\widehat{\\mathcal{L}}$ denote the logits in Fourier space. Figure 2 shows the Fourier space logits for two layers from Fig ure 1b and Figure 1c that have a clear periodic pattern. We find that the high-frequency components in Fourier space, which we define as components with index greater or equal to 50, are approximately sparse as depicted in Figure 2. This observation aligns with [28], which found that a one-layer Transformer utilizes particular Fourier components within the Fourier space to solve the modular addition task. ", "page_idx": 3}, {"type": "text", "text": "In Figure 3, we show that similar sparsity patterns in Fourier space hold across the entire dataset. We compute the logits in Fourier space for the last 15 layers, i.e., $\\bar{\\widehat{C}}_{\\mathrm{Attn}}^{(\\ell)}$ and $\\widehat{C}_{\\mathrm{MLP}}^{(\\ell)}$ where $\\ell\\in[32,47]$ , for all test examples and average them. We annotate the top-10 o utlier high -frequency components based on their magnitude. The MLPs also exhibit some strong low-frequency components; the attention modules do not exhibit strong low-frequency components, only high-frequency components. ", "page_idx": 3}, {"type": "image", "img_path": "i4MutM2TZb/tmp/b5fff43af2961ace6c79b9844911b9560038b0b66ad21c440de386b42a576d02.jpg", "img_caption": ["(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 3}, {"type": "image", "img_path": "i4MutM2TZb/tmp/494a42a6344be5cd9eba466cb7d496695997af1091bef208efb2f7e2d2644ac6.jpg", "img_caption": ["(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 3: Analysis of logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules, outlier Fourier components have periods around 2, 2.5, 5, and 10. ", "page_idx": 3}, {"type": "text", "text": "Final logits are superpositions of these outlier Fourier components. The final logits, $\\mathcal{L}^{(L)}$ , are the sum of all LMLP and LAtt across all layers $l\\in[L]$ . Figure 4 elucidates how these distinct Fourier components contribute to the final prediction, for the example \u201cPut together 15 and 93. Answer: $108^{\\circ}$ . ", "page_idx": 3}, {"type": "image", "img_path": "i4MutM2TZb/tmp/9c6ef9f0db3707fb932b506cb81c0f8b98af63c82c5420718e58045a32c830f9.jpg", "img_caption": ["(a) Final logits for top Fourier components "], "img_footnote": [], "page_idx": 4}, {"type": "image", "img_path": "i4MutM2TZb/tmp/5c77aea3e58d99765917c1f625329e74ecf292cadc6cfe44e99306cb3395a8d2.jpg", "img_caption": ["Figure 4: Visualization of how a sparse subset Fourier components can identify the correct answer. (a) Shows the top-5 Fourier components for the final logits. (b) Shows the sum of these top-5 Fourier components, highlighting how the cumulative effect identifies the correct answer, 108. ", "(b) Summation of the Top-5 Fourier components "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "We select the top-5 Fourier components of $\\widehat{\\mathcal{L}}^{\\left(L\\right)}$ based on their magnitudes and transfer them back to logits in number space via the inverse di screte Fourier transform (Figure 4a). The large-period (low-frequency) components approximate the magnitude while the small-period (high-frequency) components are crucial for modular addition. Figure 4b shows that aggregating these 5 waves is sufficient to predict the correct answer. ", "page_idx": 4}, {"type": "text", "text": "Why is high-frequency classification helpful? The Fourier basis comprises both cos and sin waves (see Definition A.3). By adjusting the coefficients of cos and sin, the trained model can manipulate the phase of the logits in Fourier space (number shift in number space), aligning the peak of the wave more closely with the correct answer. As shown in Figure 4a, consider a wave with a period of 2. Here, the peak occurs at every even number in the number space, corresponding to the mod 2 task. In contrast, for components with a large period such as 520, the model struggles to accurately position the peak at 108 (also see Figure 14 in the appendix for the plot of this component with period 520 in the full number space). This scenario can be interpreted as solving a \u201cmod $520^{\\circ}$ task\u2014a classification task among 520 classes\u2014which is challenging for the model to learn accurately. Nevertheless, even though the component with a period of 520 does not solve the \u201cmod $520^{\\circ}$ task precisely, it does succeed in assigning more weight to numbers near 108. The classification results from the high-frequency components can then provide finer-grained resolution to distinguish between all the numbers around 108 assigned a large weight by the lower frequencies. Due to this, the lowfrequency components need not be perfectly aligned with the answer to make accurate predictions. ", "page_idx": 4}, {"type": "text", "text": "3.3 Fourier Features are Causally Important for Model Predictions ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In the previous section, we demonstrated that there are outlier Fourier components in the logits generated by both the MLP and attention modules, as shown in Figure 3. We also illustrated that, in one example, the low-frequency components primarily approximate the magnitude, while the high-frequency components are crucial for modular addition tasks, as depicted in Figure 4. In this section, through an ablation study conducted across the entire test dataset, we show that both types of components are essential for correctly computing sums. Moreover, we reveal that the MLP layers primarily approximate the magnitude of the answer using low-frequency features, whereas the attention layers are responsible for modular addition using high-frequency features. ", "page_idx": 4}, {"type": "text", "text": "Filtering out Fourier components. To understand the role various frequency components play for the addition task, we introduce low-pass and high-pass filters $\\mathcal{F}$ . For an intermediate state $h$ , and a set of frequencies $\\Gamma=\\{\\gamma_{1},\\ldots,\\gamma_{k}\\}$ , the filter $\\mathcal{F}(h;\\Gamma)$ returns the vector $\\widetilde{h}$ that is closest in $L_{2}$ distance to $h$ subject to the constraint that the Fourier decomposition of $W^{U}\\widetilde{h}$ at every frequency $\\gamma_{i}$ is 0. We show in Appendix A that this has a simple closed-form solution involving a linear projection. We then apply either a low-pass filter by taking $\\Gamma$ to be all the components whose frequencies are greater than the frequency of the $\\tau$ -th component for some threshold $\\tau$ (i.e., removing high-frequency components), and a high-pass fliter by taking $\\Gamma$ to be all the components whose frequencies are less than the frequency of the $\\tau$ -th component (i.e., removing low-frequency components). As in the previous subsection, we take the high-frequency threshold $\\tau=50$ for the following experiments (see Appendix B for more details). ", "page_idx": 4}, {"type": "table", "img_path": "i4MutM2TZb/tmp/b96cc86524c368b1a11c4700cf6409a043a03effd5f2de58d7a59a2b43c9ab30.jpg", "table_caption": ["Table 1: Impact of Filtering out Fourier Components on Model Performance. Removing lowfrequency components from attention modules (blue) or high-frequency components from MLP modules (red) does not impact performance "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Different roles of frequency components in approximation and classification tasks. We evaluated the fine-tuned GPT-2-XL model on the test dataset with different frequency fliters applied to all of the output of MLP and attention modules. The results, presented in Table 1, indicate that removing lowfrequency components from attention modules or high-frequency components from MLP modules does not impact performance. This observation suggests that attention modules are not crucial for approximation tasks, and MLP modules are less significant for classification tasks. ", "page_idx": 5}, {"type": "text", "text": "Eliminating high-frequency components from attention results in a noticeable decrease in accuracy. Furthermore, removing high-frequency components from both the attention and MLP modules simultaneously leads to an even greater reduction in accuracy. This finding corresponds with observations from Figure 1b,c and Figure 3, which indicate that both MLP and attention modules are involved in classification tasks due to the presence of high-frequency components in the logits. As shown in Table 1, the approximation tasks are primarily performed by the MLP modules, with contributions from the attention modules as well. ", "page_idx": 5}, {"type": "text", "text": "The errors induced by these ablations align with our mechanistic understanding. Ablating lowfrequency parts of MLPs leads to off-by 10, 50, and 100 errors: the model fails to perform the approximation subtask, though it still accurately predicts the unit digit. Conversely, ablating highfrequency parts of attention leads to small errors less than 6 in magnitude: the model struggles to accurately predict the units digit, but it can still estimate the overall magnitude of the answer. See Figure 21 in the Appendix for more details. These observations validate our hypothesis that low-frequency components are crucial for approximation, while high-frequency components are vital for classification. The primary function of MLP modules is to approximate the magnitude of outcomes using low-frequency components, while the primary role of attention modules is to ensure accurate classification by determining the correct unit digit. ", "page_idx": 5}, {"type": "text", "text": "4 Effects of Pre-training ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The previous section shows that pre-trained LLMs leverage Fourier features to solve the addition problem. Now, we study where the models\u2019 reliance on Fourier features comes from. In this section, we demonstrate that LLMs learn Fourier features in the token embeddings for numbers during pre-training. These token embeddings are important for achieving high accuracy on the addition task: models trained from scratch achieve lower accuracy, but adding just the pre-trained token embeddings fixes this problem. We also show that pre-trained models leverage Fourier features not only when fine-tuned, but also when prompted. ", "page_idx": 5}, {"type": "text", "text": "4.1 Fourier features in Token Embedding ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Number embedding exhibits approximate sparsity in the Fourier space. Let $W^{E}\\in\\mathbb{R}^{p\\times D}$ , where $p=521$ and $D$ is the size of the token embeddings, denote the token embedding for numbers. We apply the discrete Fourier transform to each column of $W^{E}$ to obtain a matrix $V\\in\\mathbf{\\overline{{R}}}^{p\\times D}$ , where each row represents a different Fourier component. Then we take the $L_{2}$ norm of each row to yield a $p$ -dimensional vector. Each component $j$ in this vector measures the overall magnitude of the $j$ -th Fourier component across all the token embedding dimensions. Figure 5a shows the magnitude of different Fourier components in the token embedding of GPT-2-XL. We see that the token embedding has outlier components whose periods are 2, 2.5, 5, and 10. Therefore, similar to how the model uses different Fourier components to represent its prediction (as shown in Section 3.2), the token embeddings represent numbers with different Fourier components. Figure 15 in the Appendix shows that the token embeddings of other pre-trained models have similar patterns the Fourier space. This suggests that Fourier features are a common attribute in the token embedding of pre-trained LLMs. In Figure 5b, we use t-SNE and $k$ -means to visualize the token embedding clustering. We can see that numbers cluster not only by magnitude but also by their multiples of 10. ", "page_idx": 5}, {"type": "image", "img_path": "i4MutM2TZb/tmp/7d20cfe970b35b43aaeb1f8a4c5101325a779994b4f517c611604629ec1c3526.jpg", "img_caption": ["Figure 5: (a) Number embedding in Fourier space for fine-tuned GPT-2-XL. $T$ stands for the period of that Fourier component.(b) Visualization of token embedding clustering of GPT-2 using T-SNE and $k$ -means with 10 clusters. The numbers are clustered based on their magnitude and whether they are multiples of 10. "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "i4MutM2TZb/tmp/f23276c024516707eb4f2c2c39bbe08e21dbc6a03d69a29ff141e875d14cf2df.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "i4MutM2TZb/tmp/6c80d55f9fff51a1512ba5aa254fe8d7c92ef8b1bbc107024395347d70ca0bb5.jpg", "img_caption": ["4.2 Contrasting Pre-trained Models with Models Trained from Scratch "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 6: Visualization of the logits in Fourier space on the test dataset from the last 15 layers for the GPT-2-XL model trained from scratch. For both the MLP and attention modules, there are no outlier Fourier components, in contrast with the clear outlier components in the fine-tuned model (Figure 3). ", "page_idx": 6}, {"type": "text", "text": "To understand the necessity of Fourier features for the addition problem, we trained the GPT-2-XL model from scratch on the addition task with random initialization. After convergence, it achieved only $94.44\\%$ test accuracy (recall that the fine-tuned GPT-2-XL model achieved $\\bar{99}.74\\%$ accuracy). ", "page_idx": 6}, {"type": "text", "text": "Fourier features are learned during pre-training. Figure 6 shows that there are no Fourier features in the intermediate logits of the GPT-2-XL model trained from scratch on the addition task. Furthermore, Figure 7a shows that the token embeddings also have no Fourier features. Without leveraging Fourier features, the model merely approximates the correct answer without performing modular addition, resulting in frequent off-by-one errors between the prediction and the correct answer (see details in Figure 23). ", "page_idx": 7}, {"type": "image", "img_path": "i4MutM2TZb/tmp/b67fc182bb7e56742a17beb07629580eb31abb79109b0f441f7951fadf36fec9.jpg", "img_caption": ["(a) Embedding: GPT-2-XL Trained from Scratch (b) Validation Accuracy Comparison for GPT-2 "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 7: (a) The number embedding in Fourier space for GPT-2-XL trained from scratch. There are no high-frequency outlier components, in contrast with the pre-trained embeddings (Figure 5a). (b) Validation accuracy of GPT-2-small trained from scratch either with or without pre-trained token embeddings. We show the mean and the standard deviation of the validation accuracy across 5 random seeds. GPT-2-small with pre-trained token embedding consistently achieves $100\\%$ accuracy, while GPT-2-small without pre-trained token embedding only achieves less than $60\\%$ accuracy. ", "page_idx": 7}, {"type": "text", "text": "Pre-trained token embeddings improve model training. We also trained GPT-2-small, with 124 million parameters and 12 layers, from scratch on the addition task. GPT-2-small often struggles with mathematical tasks [26]. This model achieved a test accuracy of only $53.95\\%$ after convergence. However, when we freeze the token embedding layer and randomly initialize the weights for all other layers before training on the addition task, the test accuracy increases to $100\\%$ , with a significantly faster convergence rate. This outcome was consistently observed across five different random seeds, as illustrated in Figure 7b. Following Section 3.2, to validate that the model learn to leverage the Fourier feature to solve addition, we analyze the logits in Fourier space for all the test data across all 12 layers In Figure 8, we can clearly observe that, with solely the pre-trained number embedding, the Fourier features appear in the MLP and attention modules\u2019 output for most layers. This demonstrates that given the number embeddings with Fourier features, the model can effectively learn to leverage these features to solve the addition task. ", "page_idx": 7}, {"type": "text", "text": "4.3 Fourier Features in Prompted Pre-Trained Models ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Finally, we ask whether larger language models use similar Fourier features during prompting. ", "page_idx": 7}, {"type": "text", "text": "Pre-trained LLMs use Fourier features to compute addition during in-context learning. We first test on the open-source models GPT-J [43] with 6B parameters, and Phi-2 [21] with 2.7B parameters on the test dataset. Without in-context learning, the model cannot perform addition tasks. Therefore, we use 4-shot in-context learning to test its performance. Their absolute errors are predominantly multiples of 10: $93\\%$ of the time for GPT-J, and $73\\%$ for Phi-2 . Using the Fourier analysis framework proposed in Section 3.2, we demonstrate that for Phi-2 and GPT-J, the outputs of MLP and attention modules exhibit approximate sparsity in Fourier space across the last 15 layers (Figure 9 and Figure 19). This evidence strongly suggests that these models leverage Fourier features to compute additions. ", "page_idx": 7}, {"type": "text", "text": "Closed-source models exhibit similar behavior. We study the closed-source models GPT-3.5 [33], GPT-4 [34], and PaLM-2 [16]. While we cannot analyze their internal representations, we can study whether their behavior on addition problems is consistent with reliance on Fourier features. Since closed-source LLMs are instruction tuned and perform well without in-context learning, we conduct error analysis with 0-shot. Most absolute errors by these models are also multiples of 10: $100\\%$ of the time for GPT-3.5 and GPT-4, and $87\\%$ for PaLM-2. The similarity in error distribution to ", "page_idx": 7}, {"type": "image", "img_path": "i4MutM2TZb/tmp/ed17db1b9769de1233594cf7a3317790721f005fea63c57a3a3098afc109a50a.jpg", "img_caption": ["(a) Logits for MLP output in Fourier space without pre-trained number embeddings "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "i4MutM2TZb/tmp/e56ceac736897ff369da9112984b8df08919f3d708e4d59b89cf6e808808395d.jpg", "img_caption": ["(b) Logits for attention output in Fourier space without pre-trained number embeddings "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "i4MutM2TZb/tmp/4595fada9ffe835900ccdce319b290d46e67afb6db7b855f1315b497b8f02654.jpg", "img_caption": ["(c) Logits for MLP output in Fourier space with pretrained number embeddings "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "i4MutM2TZb/tmp/3eb878ce85e5ffbe33cee7c0130b4f2a3176048daefef6e1984c722e3d25d162.jpg", "img_caption": ["(d) Logits for attention output in Fourier space with pre-trained number embeddings "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 8: Analysis of logits in Fourier space for all the test data across the 12 layers. (a,b) GPT-2- small trained from scratch fail to learn to leverage the Fourier feature to solve addition. (c,d) However, with solely the pre-trained number embeddings, GPT-2-small is able to learn to leverage the Fourier features to solve the addition as the fine-tuned models. ", "page_idx": 8}, {"type": "image", "img_path": "i4MutM2TZb/tmp/25699b3fae3666a75b3d13ef96825f0690954c628b069bc997bbaf05f3d122cf.jpg", "img_caption": ["(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "i4MutM2TZb/tmp/8328d9e9e145c2d2d3f19cb229481014d4a0b034d6c5451cb37c7bfbb8ff14e8.jpg", "img_caption": ["Figure 9: For Phi-2 (4-shot), we analyzed the logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules, the outlier Fourier components have periods around 2, 2.5, 5, and 10, similar to the fine-tuned GPT-2-XL logits (Figure 3). ", "(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "that of open-source models leads us to hypothesize that Fourier features play a critical role in their computational mechanism. ", "page_idx": 8}, {"type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Learning mathematical tasks. Previous studies primarily explore what pre-trained LMs can achieve on arithmetic tasks, with less emphasis on the underlying mechanisms [29, 37]. For instance, [22] demonstrates that small Transformer models can effectively learn arithmetic by altering the question format and utilizing a scratchpad method [30]. [19] identifies activation patterns for the \u201cgreater-than\u201d operation in GPT-2, and [5] focuses on the enumeration and selection processes in GCD computation. In this paper, we dive into the specific roles of MLP and attention layers in solving mathematical tasks. Our research analyzes these components\u2019 distinct contributions to integer addition tasks. ", "page_idx": 9}, {"type": "text", "text": "Mechanisms of pre-trained LMs. Recent studies have significantly advanced our understanding of the underlying mechanisms of pre-trained Transformer models. For instance, research on \u201cskill neurons\u201d by [44] and \u201cknowledge neurons\u201d by [8] underscores the development of specialized neural components that encode task-specific capabilities or hold explicit factual information in the pre-trained LMs, enhancing model performance on related tasks. [25] and [15] discuss how MLPs and FFNs transform and update token representations for general language tasks. In contrast, we show that the pre-trained LMs use multiple layers to compute addition by combining the results of approximation and classification. Additionally, [46] demonstrated the capacity of GPT-2 to consolidate similar information through pre-training in the model weights, which aligns with our observations on the importance of pre-training in developing effective number embedding and arithmetic computation strategies in LMs. ", "page_idx": 9}, {"type": "text", "text": "Fourier features in Neural Networks. Fourier features are commonly observed in image models, particularly in the early layers of vision models [32, 31, 10]. These features enable the model to detect edges, textures, and other spatial patterns effectively. Recently, Fourier features have been noted in networks trained for tasks that allow cyclic wraparound, such as modular addition [28, 27], general group compositions [6], or invariance to cyclic translations [38]. [28] demonstrates that learning Fourier features can induce \u2018grokking\u2019 [35]. Furthermore, [24] provides a mathematical framework explaining the emergence of Fourier features when the network exhibits invariance to a finite group. We extend these insights by observing Fourier features in tasks that do not involve cyclic wraparound. [39] found that by selecting problem-specific Fourier features, the performance of MLPs can be improved on a computer vision-related task. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we provide a comprehensive analysis of how pre-trained LLMs compute numerical sums, revealing a nuanced interplay of Fourier features within their architecture. Our findings demonstrate that LLMs do not simply memorize answers from training data but actively compute solutions through a combination of approximation and classification processes encoded in the frequency domain of their hidden states. Specifically, MLP layers contribute to approximating the magnitude of sums, while attention layers contribute to modular operations. ", "page_idx": 9}, {"type": "text", "text": "Our work also shows that pre-training plays a critical role in equipping LLMs with the Fourier features necessary for executing arithmetic operations. Models trained from scratch lack these crucial features and achieve lower accuracy; introducing pre-trained token embeddings greatly improves their convergence rate and accuracy. This insight into the arithmetic problem-solving capabilities of LLMs through Fourier features sets the stage for potential modifications to training approaches. By imposing specific constraints on model training, we could further enhance the ability of LLMs to learn and leverage these Fourier features, thereby improving their performance in mathematical tasks. ", "page_idx": 9}, {"type": "text", "text": "7 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We note that our contributions are limited by the size of the dataset. As the maximum number that can be represented by one token for GPT-2-XL is 520, we analyze on the dataset whose operands are less than 260. However, as the Fourier features commonly exist in many different pre-trained models as shown in Section 4, we believe different models still use Fourier features, possibly with a more complicated strategy. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "DF and RJ were supported by a Google Research Scholar Award. RJ was also supported by an Open Philanthropy research grant. VS was supported by NSF CAREER Award CCF-2239265 and an Amazon Research Award. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of the funding agencies. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Anthropic. The claude 3 model family: Opus, sonnet, haiku. 2024.   \n[2] Yu Bai, Fan Chen, Haiquan Wang, Caiming Xiong, and Song Mei. Transformers as statisticians: Provable in-context learning with in-context algorithm selection. ArXiv, abs/2306.04637, 2023.   \n[3] Nora Belrose, Zach Furman, Logan Smith, Danny Halawi, Igor Ostrovsky, Lev McKinney, Stella Biderman, and Jacob Steinhardt. Eliciting latent predictions from transformers with the tuned lens. arXiv preprint arXiv:2303.08112, 2023.   \n[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.   \n[5] Fran\u00b8cois Charton. Can transformers learn the greatest common divisor? arXiv preprint arXiv:2308.15594, 2023.   \n[6] Bilal Chughtai, Lawrence Chan, and Neel Nanda. A toy model of universality: Reverse engineering how networks learn group operations. In International Conference on Machine Learning, pages 6243\u20136267. PMLR, 2023.   \n[7] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems, 2021.   \n[8] Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained transformers. arXiv preprint arXiv:2104.08696, 2021.   \n[9] Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. A mathematical framework for transformer circuits. Transformer Circuits Thread, 2021. https://transformer-circuits.pub/2021/framework/index.html.   \n[10] Pierre-E\u00b4tienne Fiquet and Eero Simoncelli. A polar prediction model for learning to represent visual transformations. Advances in Neural Information Processing Systems, 36, 2024.   \n[11] Simon Frieder, Luca Pinchetti, Ryan-Rhys Grifftihs, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Petersen, and Julius Berner. Mathematical capabilities of chatgpt. Advances in Neural Information Processing Systems, 36, 2024.   \n[12] Deqing Fu, Tian-Qi Chen, Robin Jia, and Vatsal Sharan. Transformers learn higher-order optimization methods for in-context learning: A study with linear models, 2023.   \n[13] Deqing Fu, Ghazal Khalighinejad, Ollie Liu, Bhuwan Dhingra, Dani Yogatama, Robin Jia, and Willie Neiswanger. Isobench: Benchmarking multimodal foundation models on isomorphic representations, 2024.   \n[14] Shivam Garg, Dimitris Tsipras, Percy Liang, and Gregory Valiant. What can transformers learn in-context? a case study of simple function classes. ArXiv, abs/2208.01066, 2022.   \n[15] Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space. arXiv preprint arXiv:2203.14680, 2022. ", "page_idx": 10}, {"type": "text", "text": "[16] Google. Palm 2 technical report, 2023. ", "page_idx": 11}, {"type": "text", "text": "[17] Gemini Team Google. Gemini: A family of highly capable multimodal models, 2023. ", "page_idx": 11}, {"type": "text", "text": "[18] Jiuxiang Gu, Chenyang Li, Yingyu Liang, Zhenmei Shi, Zhao Song, and Tianyi Zhou. Fourier circuits in neural networks: Unlocking the potential of large language models in mathematical reasoning and modular arithmetic, 2024.   \n[19] Michael Hanna, Ollie Liu, and Alexandre Variengien. How does gpt-2 compute greaterthan?: Interpreting mathematical abilities in a pre-trained language model. arXiv preprint arXiv:2305.00586, 2023.   \n[20] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021.   \n[21] Mojan Javaheripi, Sebastien Bubeck, Marah Abdin, Jyoti Anejaand Caio Cesar Teodoro Mendes, Allie Del Giorno Weizhu Chen, Ronen Eldan, Sivakanth Gopi, Suriya Gunasekar, Piero Kauffmann, Yin Tat Lee, Yuanzhi L, Anh Nguyen, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Michael Santacroce, Harkirat Singh Behl, Adam Taumann Kalai, Xin Wang, Rachel Ward, Philipp Witte, Cyril Zhang, and Yi Zhang. Phi-2: The surprising power of small language models, 2023.   \n[22] Nayoung Lee, Kartik Sreenivasan, Jason D Lee, Kangwook Lee, and Dimitris Papailiopoulos. Teaching arithmetic to small transformers. arXiv preprint arXiv:2307.03381, 2023.   \n[23] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts, 2024.   \n[24] Giovanni Luca Marchetti, Christopher Hillar, Danica Kragic, and Sophia Sanborn. Harmonics of learning: Universal fourier features emerge in invariant networks. arXiv preprint arXiv:2312.08550, 2023.   \n[25] Jack Merullo, Carsten Eickhoff, and Ellie Pavlick. Language models implement simple word2vec-style vector arithmetic. arXiv preprint arXiv:2305.16130, 2023.   \n[26] Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. Numglue: A suite of fundamental yet challenging mathematical reasoning tasks. arXiv preprint arXiv:2204.05660, 2022.   \n[27] Depen Morwani, Benjamin L Edelman, Costin-Andrei Oncescu, Rosie Zhao, and Sham Kakade. Feature emergence via margin maximization: case studies in algebraic tasks. arXiv preprint arXiv:2311.07568, 2023.   \n[28] Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures for grokking via mechanistic interpretability. arXiv preprint arXiv:2301.05217, 2023.   \n[29] Rodrigo Nogueira, Zhiying Jiang, and Jimmy Lin. Investigating the limitations of transformers with simple arithmetic tasks. arXiv preprint arXiv:2102.13019, 2021.   \n[30] Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114, 2021.   \n[31] Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. An overview of early vision in inceptionv1. Distill, 5(4):e00024\u2013002, 2020.   \n[32] Bruno A Olshausen and David J Field. Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research, 37(23):3311\u20133325, 1997.   \n[33] OpenAI. Introducing ChatGPT. https://openai.com/blog/chatgpt, 2022. Accessed: 2023-09-10. ", "page_idx": 11}, {"type": "text", "text": "[34] OpenAI. Gpt-4 technical report, 2023. ", "page_idx": 12}, {"type": "text", "text": "[35] Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra. Grokking: Generalization beyond overftiting on small algorithmic datasets. arXiv preprint arXiv:2201.02177, 2022.   \n[36] Alethea Power, Yuri Burda, Harrison Edwards, Igor Babuschkin, and Vedant Misra. Grokking: Generalization beyond overftiting on small algorithmic datasets. ArXiv, abs/2201.02177, 2022.   \n[37] Jing Qian, Hong Wang, Zekun Li, Shiyang Li, and Xifeng Yan. Limitations of language models in arithmetic and symbolic induction. arXiv preprint arXiv:2208.05051, 2022.   \n[38] Sophia Sanborn, Christian Shewmake, Bruno Olshausen, and Christopher Hillar. Bispectral neural networks. arXiv preprint arXiv:2209.03416, 2022.   \n[39] Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. Advances in neural information processing systems, 33:7537\u20137547, 2020.   \n[40] Avijit Thawani, Jay Pujara, Pedro A Szekely, and Filip Ilievski. Representing numbers in nlp: a survey and a vision. arXiv preprint arXiv:2103.13136, 2021.   \n[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. arXiv:1706.03762, 2017.   \n[42] Johannes von Oswald, Eyvind Niklasson, E. Randazzo, Jo\u02dcao Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. Transformers learn in-context by gradient descent. In International Conference on Machine Learning, 2022.   \n[43] Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.   \n[44] Xiaozhi Wang, Kaiyue Wen, Zhengyan Zhang, Lei Hou, Zhiyuan Liu, and Juanzi Li. Finding skill neurons in pre-trained transformer-based language models. arXiv preprint arXiv:2211.07349, 2022.   \n[45] Yan Wang, Xiaojiang Liu, and Shuming Shi. Deep neural solver for math word problems. In Proceedings of the 2017 conference on empirical methods in natural language processing, pages 845\u2013854, 2017.   \n[46] Zeyuan Allen Zhu and Yuanzhi Li. Physics of language models: Part 3.1, knowledge storage and extraction. arXiv preprint arXiv:2309.14316, 2023. ", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Roadmap. In Appendix A, we introduce some formal definitions that used in our main content. In Appendix B, we show why we separate the Fourier components into the high-frequency part and the low-frequency part and why we choose $\\tau$ to be 50. In Appendix C, we show our observation generalizes to another format of dataset, another arithmetic task and other models. In Appendix D, we provide more evidence that shows the Fourier features in the model when computing addition. In Appendix E, we provide more evidence that shows the GPT-2-XL trained from scratch does not use Fourier feature to solve the addition task. In Appendix F, we give the details of our experimental settings. ", "page_idx": 13}, {"type": "text", "text": "A Formal Definition of Transformer and Logits in Fourier Space ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We first introduce the formal definition of the Transformer structure that we used in this paper. ", "page_idx": 13}, {"type": "text", "text": "Definition A.1 (Transformer). An autoregressive Transformer language model $G\\ :\\ \\mathcal{X}\\ \\rightarrow\\ \\mathcal{Y}$ over vocabulary Vocab maps a token sequence $x\\,=\\,[x_{1},\\ldots,x_{N}]\\,\\in\\,{\\mathcal{X}},x_{t}\\,\\in$ Vocab to a probability distribution $y\\,\\in\\,\\mathcal{V}\\,\\subset\\,\\mathbb{R}^{|\\mathrm{Vocab}|}$ that predicts next-token continuations of $x$ . Within the Transformer, the $i$ -th token is embedded as a series of hidden state vectors $h_{t}^{(\\ell)}$ , beginning with $h_{t}^{(0)}=\\operatorname{emb}\\left(x_{t}\\right)+\\operatorname{pos}(i)\\in\\mathbb{R}^{D}$ . Let $W^{U}\\in\\mathbb{R}^{|\\mathrm{Vocab}|\\times D}$ denote the output embedding. The final output $\\boldsymbol{y}\\,=\\,\\mathrm{softmax}(\\boldsymbol{W}^{U}\\left(h_{N}^{(L)}\\right))$ is read from the last hidden state. In the autoregressive case, tokens only draw information from past tokens: ", "page_idx": 13}, {"type": "equation", "text": "$$\nh_{t}^{(\\ell)}=h_{t}^{(\\ell-1)}+{\\mathrm{Attn}}_{t}^{(\\ell)}+{\\mathrm{MLP}}_{t}^{(\\ell)}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{Attn}_{t}^{(\\ell)}:=\\mathrm{Attn}^{(\\ell)}\\left(h_{1}^{(\\ell-1)},h_{2}^{(\\ell-1)},\\ldots,h_{t}^{(\\ell-1)}\\right)\\quad a n d\\quad\\mathrm{MLP}_{t}^{(\\ell)}:=\\mathrm{MLP}_{t}^{(\\ell)}(\\mathrm{Attn}_{t}^{(\\ell)},h_{t}^{(\\ell-1)}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In this paper, we only consider the output tokens to be numbers. Hence, we have the unembedding matrix $\\dot{\\boldsymbol{W}}^{U}\\in\\mathbb{R}^{p\\times D}$ , where $p$ is the size of the number space. As we are given the length- $\\mathcal{N}$ input sequences and predict the $(N+1)$ h, we only consider $h_{N}^{(\\ell)}=h_{N}^{(\\ell-1)}+\\mathrm{Attn}_{N}^{(\\ell)}+\\mathrm{\\dot{M}L P}_{N}^{(\\ell)}$ . For simplicity, we ignore the subscript $N$ in the following paper, so we get Eq. (1). ", "page_idx": 13}, {"type": "text", "text": "Definition A.2 (Intermediate Logits). Let L(A\u2113t)tn := W UAttn(\u2113) denote the intermediate logits of the attention module at the -th layer. Let $\\mathcal{L}_{\\mathrm{MLP}}^{(\\ell)}:=W^{U}\\mathrm{MLP}^{(\\ell)}$ denote the intermediate logits of the MLP module at the \u2113-th layer. Let $\\mathcal{L}^{(\\ell)}:=W^{U}h^{(\\ell)}$ denote the logits on intermediate state $h^{(\\ell)}$ . ", "page_idx": 13}, {"type": "text", "text": "Throughout the model, $h$ undergoes only additive updates (Eq. (1)), creating a continuous residual stream [9], meaning that the token representation $h$ accumulates all additive updates within the residual stream up to layer $t$ . ", "page_idx": 13}, {"type": "text", "text": "To analyze the logits in Fourier space, we give the formal definition of the Fourier basis as follows: Definition A.3 (Fourier Basis). Let $p$ denote the size of the number space. Let $\\overrightarrow{\\mathbf{x}}:=(0,1,\\ldots,(p-$ 1)). Let \u03c9k := p2\u03c0\u2212k1 . We denote the normalized Fourier basis $F$ as the $p\\times p$ matrix: ", "page_idx": 13}, {"type": "equation", "text": "$$\nF:=\\left[\\begin{array}{c}{\\sqrt{\\frac{1}{p-1}}\\cdot\\overrightarrow{1}}\\\\ {\\sqrt{\\frac{2}{p-1}}\\cdot\\sin\\left(\\omega_{1}\\overrightarrow{\\mathbf{x}}\\right)}\\\\ {\\sqrt{\\frac{2}{p-1}}\\cdot\\cos\\left(\\omega_{1}\\overrightarrow{\\mathbf{x}}\\right)}\\\\ {\\sqrt{\\frac{2}{p-1}}\\cdot\\sin\\left(\\omega_{2}\\overrightarrow{\\mathbf{x}}\\right)}\\\\ {\\vdots}\\\\ {\\sqrt{\\frac{2}{p-1}}\\cdot\\cos\\left(\\omega_{\\left(p-1\\right)/2}\\overrightarrow{\\mathbf{x}}\\right)}\\end{array}\\right]\\in\\mathbb{R}^{p\\times p}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The first component $F[0]$ is defined as a constant component. For $i\\in[0,p-1],\\,F[i]$ is defined as the $k$ -th component in Fourier space, where $\\begin{array}{r}{k=\\lfloor\\frac{i+1}{2}\\rfloor}\\end{array}$ . The frequency of the $k$ -th component is fk :=pk\u22121. The period of the k-th component is Tk := pk\u22121 ", "page_idx": 13}, {"type": "text", "text": "We can compute the discrete Fourier transform under that Fourier basis as follows: ", "page_idx": 14}, {"type": "text", "text": "Remark A.4 (Discrete Fourier transformer (DFT) and inverse DFT). We can transform any logits $u\\in\\mathbb{R}^{p}$ to Fourier space by computing $\\widehat{u}=F\\cdot u$ . We can transform $\\widehat{u}$ back to u by $\\dot{\\boldsymbol{u}}=\\boldsymbol{F}^{\\top}\\cdot\\boldsymbol{\\widehat{u}}$ ", "page_idx": 14}, {"type": "text", "text": "Next, we define the logits in Fourier space. ", "page_idx": 14}, {"type": "text", "text": "Definition A.5 (Logits in Fourier Space). Let L(L), L(A\u2113t)t and $\\mathcal{L}_{\\mathrm{MLP}}^{(\\ell)}$ denote the logits (Definition A.2). The output logits before softmax in Fourier space is defined as: ${\\widehat{\\mathcal{L}}}^{(L)}=F\\cdot{\\mathcal{L}}^{(L)}$ . The logits of the MLP and attention modules in Fourier space are defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\mathcal{L}}_{\\mathrm{Attn}}^{(\\ell)}=F\\cdot\\mathcal{L}_{\\mathrm{Attn}}^{(\\ell)}\\quad a n d\\quad\\widehat{\\mathcal{L}}_{\\mathrm{MLP}}^{(\\ell)}=F\\cdot\\mathcal{L}_{\\mathrm{MLP}}^{(\\ell)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We ignore the first elements inL (L),L (A\u2113t)t and $\\widehat{C}_{\\mathrm{MLP}}^{(\\ell)}$ for the Fourier analysis in this paper as they are the constant terms. Adding a constant to the logits will not change the prediction. ", "page_idx": 14}, {"type": "text", "text": "Let $\\tau\\,\\in\\,\\mathbb{R}$ denote a constant threshold. The low-frequency components for the logits in Fourier space are defined as $\\widehat{C}^{(\\ell)}[1:2\\tau]$ . The high-frequency components for the logits in Fourier space are defined as $\\widehat{\\mathcal{L}}^{(\\ell)}[2\\tau:]$ . For the following analysis, we choose $\\tau=50$ (the specific choice of $\\tau=50$ is explained in Appendix B). ", "page_idx": 14}, {"type": "text", "text": "Next, we propose the formal definition of low-pass/high-pass filter that is used in the following ablation study. ", "page_idx": 14}, {"type": "text", "text": "Definition A.6 (Loss-pass / High-pass Filter). Let $x\\in\\mathbb{R}^{D}$ denote the output of MLP or attention modules. Let $F$ denote the Fourier Basis (Definition A.3). Let $\\tau\\in R$ denote the frequency threshold. Let $W^{U}\\,\\in\\,R^{p\\times D}$ denote the output embedding. For low-pass filter, we define a diagonal binary matrix $B\\in\\{0,1\\}^{p\\times p}\\,a s\\,b_{i i}={\\left\\{\\begin{array}{l l}{1}&{i f\\,i\\geq\\tau}\\\\ {0}&{o t h e r w i s}\\end{array}\\right.}$ 01 ioft ih e\u2265rw\u03c4ise . For high-pass filter, we define a diagonal binary matrix $B\\in\\{0,1\\}^{p\\times p}$ as 01 ioft h1 er\u2264wii s<e \u03c4. Note that we retain the constant component, so $b_{i,i}=0$ . The output of the filter $\\mathcal{F}(\\boldsymbol{x}):\\mathbb{R}^{D}\\rightarrow\\mathbb{R}^{D}$ is defined by the following objective function: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{y}{\\mathrm{min}}}&{\\|x-y\\|_{2}^{2}}\\\\ {\\mathrm{subject~to}}&{B F W^{U}y=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The solution to the above optimization problem is given by a linear projection. ", "page_idx": 14}, {"type": "text", "text": "Remark A.7. The result of the optimization problem defined in Definition A.6 is the projection of $x$ to the null space of $B F W^{\\check{U}}$ . Let $\\mathcal{N}(B F W^{U})$ denote the null space of $B F W^{U}$ . We have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{F}(x)=\\mathcal{N}(B F W^{U})\\cdot\\mathcal{N}(B F W^{U})^{\\top}\\cdot x^{\\top}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "image", "img_path": "i4MutM2TZb/tmp/6d1ff04056be06beb2637690a9f6b3998aebb68c9a7d58650e4a570e10d80cca.jpg", "img_caption": ["B Fourier Components Separation and Selection of $\\tau$ ", "(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "i4MutM2TZb/tmp/2de8593de7b3b4e6cc704c996cf5c680deb5af2b90d63ff6df5a0622f541f85f.jpg", "img_caption": ["(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure 10: We analyzed the logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules. We only plot the first 50 Fourier components (a) The MLP exhibits some outlier low-frequency Fourier components. (b) The attention module\u2019s low-frequency Fourier components are not as obvious as the ones in MLP. ", "page_idx": 15}, {"type": "text", "text": "Following Definition A.6, we define single-pass filter as follows: ", "page_idx": 15}, {"type": "text", "text": "Definition B.1 (Single-Pass Filter). Let $\\boldsymbol{x}\\in\\mathbb{R}^{D}$ denote the output of MLP or attention modules. Let $F$ denote the Fourier Basis (Definition $A.3.$ ). Let $\\gamma\\,\\in\\,R$ denote the $\\gamma$ -th Fourier component (Definition A.3) that we want to retain. Let $W^{U}\\in R^{V\\times{\\dot{D}}}$ denote the output embedding. We define a diagonal binary matrix ", "page_idx": 15}, {"type": "text", "text": "$B\\in\\{0,1\\}^{V\\times V}\\,a s\\,b_{i i}=\\left\\{0\\quad i f\\lfloor\\frac{i+1}{2}\\rfloor=\\gamma\\,o r\\,i=0,\\right.$ ", "page_idx": 15}, {"type": "text", "text": "The output of the filter $\\mathcal{F}_{\\gamma}(x):\\mathbb{R}^{D}\\to\\mathbb{R}^{D}$ is defined as the following objective function: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{y}{\\mathrm{min}}}&{\\|x-y\\|_{2}^{2}}\\\\ {\\mathrm{subject~to}}&{B F W^{U}y=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Remark B.2. The result of the optimization problem defined in Definition B.1 is the projection of $x$ to the null space of $B F W^{U}$ . Let $\\mathcal{N}(B F W^{U})$ denote the null space of $B F W^{U}$ . We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{F}_{\\gamma}(x)=\\mathcal{N}(B F W^{U})\\cdot\\mathcal{N}(B F W^{U})^{\\top}\\cdot x^{\\top}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For the single-pass filter, we only retrain one Fourier component and analyze how this component affects the model\u2019s prediction. The residual stream is then updated as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nh^{(\\ell)}=h^{(\\ell-1)}+\\mathcal{F}_{\\gamma}(\\mathrm{Attn}^{(\\ell-1)})+\\mathcal{F}_{\\gamma}(\\mathrm{MLP}^{(\\ell-1)})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We evaluated the fine-tuned GPT-2-XL model on the addition dataset with the Fourier components period 520 and 2. Given that $\\begin{array}{r}{T_{k}:=\\frac{V-1}{k}}\\end{array}$ (Definition A.3), we retained only the Fourier components with $\\gamma=1$ and 260, respectively. ", "page_idx": 15}, {"type": "text", "text": "As shown in Figure 11a, with only one frequency component, whose period is 2, the model accurately predicts the parity with $99.59\\%$ accuracy. As depicted in Figure 11b, with a single frequency component of period 520, the model fails to accurately predict with $96.51\\%$ accuracy. We consider the frequency component with a period of 2 as the model\u2019s prediction for the mod 2 task, and the frequency component with a period of 520 as its prediction for the mod 520 task. Figures 11 and 12 suggest that the model effectively learns the mod 2 task, as it involves a two-class classification, but struggles with the mod 520 task, which requires classifying among 520 classes. As the model does not need to be trained to converge to the optimal for these low-frequency components as explained at the end of Section 3.2, predicting with the period-520 component leads to predictions that normally distributed around the correct answers. ", "page_idx": 15}, {"type": "image", "img_path": "i4MutM2TZb/tmp/4d14c224644c548c489e9cf1a2e00ecd5bad579edb9a9c8a9adb9450011cbe57.jpg", "img_caption": ["(a) Retaining Period-2 Frequency Components "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "i4MutM2TZb/tmp/55162ce11681964185b3ce4a33f09060d5d175497e00fde0753413c562b3e8bc.jpg", "img_caption": ["(b) Retaining Period-520 Frequency Components "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 11: The prediction analysis when predicting with only one Fourier component. (a) Retaining only the Period-2 Fourier component makes the prediction $99.59\\%$ accurate for mod 2 task (b) Retaining only the Period-520 Fourier component makes the prediction $96.61\\%$ inaccurate for the mod 520 task. ", "page_idx": 16}, {"type": "image", "img_path": "i4MutM2TZb/tmp/440ff98a651e5276e30579e569ab8d7d4d2e778af67b17c5fefcb00fc4056c0d.jpg", "img_caption": ["Figure 12: Retaining only the Period-520 Fourier component makes the model\u2019s predictions normally distributed around the correct answers. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "The Fourier components with larger periods present greater difficulty in solving the corresponding modular addition task compared to those with smaller periods. As demonstrated in Figure 12, components with large periods serve primarily as approximations of the correct answer. Consequently, we categorize the Fourier components into low-frequency and high-frequency groups. The low-frequency components approximate the magnitude of the answer, whereas the high-frequency components are employed to enhance the precision of the predictions. ", "page_idx": 16}, {"type": "text", "text": "In reference to Figure 4, to elucidate the contribution of these distinct Fourier components to our final prediction and the rationale behind their separation, consider the example: \u201cPut together 15 and 93. Answer: $108^{\\circ}$ . We selected the top-10 Fourier components of $\\widehat{\\mathcal{L}}^{\\left(L\\right)}$ based on their magnitudes and converted them back to logits in the numerical space by mu ltiplying with $F^{\\top}$ . We plotted the components with components index less than 50 in Figure 13a and those with components index greater than 50 in Figure 13b. Leveraging the constructive and destructive inference for different waves, the components with low periods assign more weight to the correct answer, 108, and less weight to numbers close to 108. These high-frequency (low-period) components ensure the prediction\u2019s accuracy at the unit place. For the low-frequency (large-period) components, the model fails to precisely learn the magnitude of the factor between the cos and sin components, which results in failing to peak at the correct answer. Thus, the low-frequency (large-period) components are used to approximate the magnitude of the addition results. ", "page_idx": 16}, {"type": "image", "img_path": "i4MutM2TZb/tmp/2c8f6a10aa40a381857a1db283651d4e206994a90b4e61d20ff76aeb33cdac1f.jpg", "img_caption": ["(a) Final Logits for Components whose index Less (b) Final Logits for Components whose index Greater than 50 than 50 "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 13: Visualization of tthe individual final logits for the top-10 Fourier components with example \u201cPut together 15 and 93. Answer: $108^{\\circ}$ (a) The components index less than 50. (b) The components index greater than 50. ", "page_idx": 17}, {"type": "image", "img_path": "i4MutM2TZb/tmp/24d6e25195f3aa6cd10ac75a6fd4cb86fe67ef7e90956eeea70595a9a6e1d0cc.jpg", "img_caption": ["Figure 14: Visualization of the Fourier component whose period is 520 analysis for the final logits. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "C Does Fourier Features Generalize? ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Token Embedding for Other LMs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We first show that other pre-trained LMs also have Fourier features in their token embedding for the numbers [0, 520]. ", "page_idx": 18}, {"type": "image", "img_path": "i4MutM2TZb/tmp/7362bd66aebd322b69a2790e00dcc0a975f27361626a30d0a9dcc21b68733c10.jpg", "img_caption": ["Figure 15: Number embedding in Fourier space for different pre-trained models. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "C.2 Multiplication Task ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "A key question is whether pre-trained models utilize Fourier Features solely for solving addition tasks or if they generalize to other arithmetic tasks. We hypothesize the latter, knowing that numbers are represented by their Fourier features in the token embeddings after pre-training. Consequently, this Fourier representation should be leveraged in a variety of number-related tasks. To validate this hypothesis, we perform a Fourier analysis on the GPT-2-XL model fine-tuned for the multiplication task. ", "page_idx": 19}, {"type": "text", "text": "Considering a maximum number of 520 for multiplication would result in an insufficient dataset size.   \nTherefore, we set the maximum allowable product to 10000. ", "page_idx": 19}, {"type": "text", "text": "For each pair of numbers where the product does not exceed this limit, we used a distinct phrasing for each pair of numbers, selecting one template from five available templates. This ensures that every unique pair of numbers between 0 and 260 is presented with a consistent phrasing from these templates. We have fixed that typo in the revised version. The different phrasings used include: \u201cWhat is the product of num1 and num2?\u201d, \u201cFind the product of num1 multiplied by num2.\u201d, \u201cCalculate num1 times num2.\u201d, \u201cnum1 multiplied by num2 equals what?\u201d, and \u201cMultiplication of num1 with num2.\u201d The dataset is then shuffled to ensure randomness and split into training $(80\\%)$ , validation $(10\\%)$ , and test $(10\\%)$ sets. We finetune the model for 25 epochs with a learning rate of $1e-4$ . Upon convergence, the validation accuracy reaches $74.58\\%$ . ", "page_idx": 19}, {"type": "text", "text": "As the primary objective is to determine whether the Fourier features are utilized in tasks other than addition, Figure 16 displays the logits in Fourier space for each layer, as in Figure 3. It is evident that the logits are sparse in Fourier space. ", "page_idx": 19}, {"type": "image", "img_path": "i4MutM2TZb/tmp/35bc3dc86e199e4eb5e37aad635de55c77a534dcf71a60f723821faeeb0b68f1.jpg", "img_caption": ["Figure 16: We analyzed the logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules, the outlier Fourier components have periods around 2, 2.5, 3.3, 5, and 10. ", "(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "i4MutM2TZb/tmp/e374c54a0b725f41f385c2c4128890df78208156e712b04a99f2f1423f6b0684.jpg", "img_caption": ["(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "C.3 Same Results for other format ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "To demonstrate that our observations are not confined to a specific description of the mathematical problem, we conducted experiments on another format of addition problem and obtained consistent results. From Figure 17, we can see that there are also periodic structures in the intermediate logits. ", "page_idx": 20}, {"type": "image", "img_path": "i4MutM2TZb/tmp/2afc88ac74877d420b0e01b92dbf1536848ce187d6c0e6ffc2cbe30ddd45c8d4.jpg", "img_caption": ["Figure 17: Heatmap of the logits across different layers. The y-axis represents the subset of the number space around the correct prediction, while the x-axis represents the layer index. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "i4MutM2TZb/tmp/fc9ba3cfdbe161edf6b147f53aaaae498d7d6d2526caa02be771d2ead009ef2b.jpg", "img_caption": ["(b) Attention output logits for the last 15 layers "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "From Figure 18, we can also see the Fourier features for the MLP and attention output. These two experiments validate that our observations are not confined to a specific format of the addition problems. ", "page_idx": 20}, {"type": "image", "img_path": "i4MutM2TZb/tmp/0c167a5400ad81fdb669a1236e8a0941866021f00d9b2d11859f271b5ca25d28.jpg", "img_caption": ["(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "i4MutM2TZb/tmp/90e649709ea206bc175e83897e6e00bfe09b368f4605e0c58da086dfc9e127d6.jpg", "img_caption": ["(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 18: We analyzed the logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules, the outlier Fourier components have periods around 2, 2.5, 5, and 10. (a) The MLP exhibits some outlier low-frequency Fourier components. (b) The attention module does not exhibit any outlier low-frequency Fourier components, but it has stronger high-frequency components. ", "page_idx": 20}, {"type": "text", "text": "C.4 Fourier Features in Other Pre-trained LM ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Using the Fourier analysis framework proposed in Section 3.2, we demonstrate that for GPT-J, the outputs of MLP and attention modules exhibit approximate sparsity in Fourier space across the last 15 layers (Figure 19) ", "page_idx": 20}, {"type": "image", "img_path": "i4MutM2TZb/tmp/1222e0555a4ed73ed784c77da565de502e14889bada12740ba4ae33256da48b6.jpg", "img_caption": ["Figure 19: For GPT-J (4-shot), we analyzed the logits in Fourier space for all the test data across the last 15 layers. For both the MLP and attention modules, the outlier Fourier components have periods around 2, 2.5, 5, and 10. ", "(a) Logits for MLP output in Fourier space "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "i4MutM2TZb/tmp/0ff0888d45bbfb316f5ad057b75b821f9c54be447baeff37d64e06a7fb2b87aa.jpg", "img_caption": ["(b) Logits for attention output in Fourier space "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "D Supporting Evidence For the Fourier Features ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We selected the layers that clearly show the periodic pattern in Figure 1b and Figure 1c and plot their logits in Figure 20. ", "page_idx": 21}, {"type": "image", "img_path": "i4MutM2TZb/tmp/92e75a520cec867c263c87b39ad1cb8a08c69981f37638d8d3668f877efbff88.jpg", "img_caption": ["(a) Logits for the 33-th layer\u2019s MLP output "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "i4MutM2TZb/tmp/193afbe19a6a63109b75ed58356eac91d100d32b1f8e059802424fa18e2ee517.jpg", "img_caption": ["(b) Logits for the 40-th layer\u2019s attention output "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure 20: The $\\mathbf{X}$ -axis represents the number space, and the y-axis represents the logits value. (a) The lmoogidtus lew faavve ofrosr t thhee  anMsLwPe ro tuot $33^{\\mathrm{rd}}$ .a (ybe)r , $\\mathcal{L}_{\\mathrm{MLP}}^{(33)}$ g. itTs hwe aMveL fPo rf atvhoe ras tteevnetni onnu omubtperust.  oTf hteh e $15+93\\;\\mathrm{mod}\\;2$ $40^{\\mathrm{th}}$ layer,  Attn L(40) . The attention module favors the answer to $15+93$ mod 10 and $\\mathrm{15+93\\;mod\\;5}$ . ", "page_idx": 21}, {"type": "text", "text": "Figure 21 illustrates that the errors resulting from the ablation study (Section 3.3) correspond with our theoretical insights. Removing low-frequency parts from the MLP results in errors such as off-by 10, 50, and 100. Without these low-frequency components, the MLP is unable to accurately approximate, although it still correctly predicts the unit digit. In contrast, removing high-frequency components from the attention modules results in smaller errors, all less than 6 in magnitude. These findings support our statement that low-frequency components are essential for accurate approximation, whereas high-frequency components are key for precise classification tasks. Consequently, the primary function of MLP modules is to approximate numerical magnitudes using low-frequency components, and the essential function of attention modules is to facilitate precise classification by identifying the correct unit digit. ", "page_idx": 21}, {"type": "image", "img_path": "i4MutM2TZb/tmp/1a574c34860b52d75cc3b8a6fc5a526746c178fd06f5fe08b6578f0f24bb15a1.jpg", "img_caption": ["(a) Filtering out low-frequency components of MLP (b) Filtering out high-frequency components of attention "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 21: (a) Across all the test data, the difference between predictions and labels are all the multiple of 10. (b) Across all the test data, the differences between predictions and labels are all below 6. ", "page_idx": 22}, {"type": "text", "text": "E More Experiments on GPT-2-XL Trained from Scratch ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Following the methodology proposed in Section 3, we plotted the logits of the MLP and attention modules for each layer, as shown in Figure 22. The prediction is solely determined by the 40-th layer MLP. Unlike Figure 3, there is no observable periodic structure across all layers. ", "page_idx": 22}, {"type": "image", "img_path": "i4MutM2TZb/tmp/6f0e9503697fecee4ca08acca01601a7ccfd6adf109e301ecbd3dab68eddfb58.jpg", "img_caption": ["(a) MLP output logits for the last 15 layers "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "i4MutM2TZb/tmp/2e060a8ea7d85eb0fa01a22e4bd2e4a0a725768eb89d4ec0566c008678d0e11f.jpg", "img_caption": ["(b) Attention output logits for the last 15 layers "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 22: Heatmap of the logits across different layers. The y-axis represents the subset of the number space around the correct prediction, while the ${\\bf X}$ -axis represents the layer index. The final prediction is solely decided by the 40-th layer MLP. ", "page_idx": 22}, {"type": "text", "text": "For the model trained from scratch on the created addition dataset, all of the predictions on the test dataset deviate from the correct answer within 2 as shown in Figure 23. ", "page_idx": 22}, {"type": "image", "img_path": "i4MutM2TZb/tmp/a8e8fab7e39fbabc02877c42e2075e83eaccef89f65747ea6ec8f8eef8982d17.jpg", "img_caption": ["Figure 23: Error distribution for GPT-2-XL trained from scratch. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "F Details of Experimental Settings ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Fine-tuned GPT-2-XL We finetune GPT-2-XL on the \u201clanguage-math-dataset\u201d with 50 epochs and a batch size of 16. The dataset consists of 27, 400 training samples, 3, 420 validation samples, and 3, 420 test samples. We use the AdamW optimizer, scheduling the learning rate linearly from $1\\times10^{-5}$ to 0 without warmup. ", "page_idx": 23}, {"type": "text", "text": "Train GPT-2-XL from scratch We train GPT-2-XL on the \u201clanguage-math-dataset\u201d from scratch with 500 epochs and a batch size of 16. The dataset consists of 27, 400 training samples, 3, 420 validation samples, and 3, 420 test samples. We use the AdamW optimizer, scheduling the learning rate linearly from $1\\times10^{\\dot{-}4}$ to 0 without warmup. ", "page_idx": 23}, {"type": "text", "text": "Train GPT-2 from scratch For both with pre-trained token embedding and without token embedding, we train GPT-2 on the \u201clanguage-math-dataset\u201d with 700 epochs and a batch size of 16. The dataset consists of 27, 400 training samples, 3, 420 validation samples, and 3, 420 test samples. We use the AdamW optimizer, scheduling the learning rate linearly from $5\\times10^{-5}$ to 0 without warmup. In Figure 7b, we train the model with five different seeds and plot the mean and deviation for them. ", "page_idx": 23}, {"type": "text", "text": "Create the addition dataset in main content We consider numbers in base $10\\;\\mathrm{up}$ to a maximum value of 260. For each pair of numbers between 0 and 260, we used a distinct phrasing for each pair of numbers, selecting one template from five available templates. This ensures that every unique pair of numbers between 0 and 260 is presented with a consistent phrasing from these templates. We have fixed that typo in the revised version. The different phrasings used are: \u201cTotal of num1 and num2.\u201d, \u201cAdd together num1 and num2.\u201d, \u201cCalculate $\\mathrm{num}1+\\mathrm{num}2.$ .\u201d, \u201cWhat is the sum of num1 and num2?\u201d, and \u201cPut together num1 and num2.\u201d. The dataset is shuffled to ensure randomness and then split into training $(80\\%)$ , validation $(10\\%)$ , and test $(10\\%)$ sets. ", "page_idx": 23}, {"type": "text", "text": "Create the addition dataset in Appendix C.3 with different format We consider numbers in base 10 up to a maximum value of 260. We generate all possible pairs of numbers within this range using combinations with replacement. For each pair, we convert the numbers to the specified base and create questions formatted as \u201cnum1, $,\\mathsf{n u m}2\\!+\\!^{\\circ}$ with their corresponding answers. The dataset is then split into training $(80\\%)$ , validation $(10\\%)$ , and test $(10\\%)$ sets. ", "page_idx": 23}, {"type": "text", "text": "Experiments Compute Resources All experiments involving fine-tuning and training from scratch in this paper were conducted on one NVIDIA A6000 GPU with 48GB of video memory. The fine-tuning process required less than 10 hours, while training from scratch took less than 3 days. Other experiments, such as those involving Logit Lens, were completed in less than 1 hour. ", "page_idx": 23}, {"type": "text", "text": "Licenses for Existing Assets & Open Access to Data and Code. For the following models, we use the checkpoints provided by Huggingface. For all the trained models, we use default hyperparameters during all the training but with different random seeds. ", "page_idx": 23}, {"type": "text", "text": "\u2022 GPT-2-XL: https://huggingface.co/openai-community/gpt2-xl, Modified MIT License \u2022 GPT-2: https://huggingface.co/openai-community/gpt2, Modified MIT License \u2022 GPT-J: https://huggingface.co/EleutherAI/gpt-j-6b, Apache-2.0 License \u2022 Phi2: https://huggingface.co/microsoft/phi-2, MIT License ", "page_idx": 23}, {"type": "text", "text": "G Impact Statement ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Our work aims to understand the potential of large language models in solving arithmetic tasks. Our paper is an interpretability paper and thus we foresee no immediate negative ethical impact. We believe improved understanding and enhancement of LLMs can lead to more robust AI systems that are capable of performing complex tasks more reliably. This can benefti areas such as automated data analysis, financial forecasting, and more. ", "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: In the introduction (Section 1), we explicitly state the observations and their implications. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: The limitations is discussed in Section 7. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is an interpretation paper without any theoretical results. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide the details of experimental settings in Section F. By following these settings, our results can be reproduced. The detail process about the interpretability methods can be found in Section A. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 27}, {"type": "text", "text": "Answer:[No] ", "page_idx": 27}, {"type": "text", "text": "Justification: The goal of this paper is to understand how LLMs compute addition. We believe the code is not central to our contribution. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer:[Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We show all the details in Section F. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We run the experiments with 5 random seeds. In Figure 7, we show the plot the error bar with the mean and the standard deviation of the validation accuracy. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The detail of the computing resourse is provided at the end of Section F. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The authors have read the NeurIPS Code of Ethies and made sure the paper followsthe NeurIPS Code of Ethics in every aspect. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The potential societal impact is discussed in Section G. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 28}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our paper works on simple addition task and dataset. We belive there is no such risks. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer:[Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The details are listed in Section F ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: We did not introduce any new assets in this paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}]