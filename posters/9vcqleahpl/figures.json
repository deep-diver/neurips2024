[{"figure_path": "9vcqleAHPl/figures/figures_1_1.jpg", "caption": "Figure 1: Different few-shot learning paradigms for WSI classification. (a) The instance few-shot method divides all WSIs into a series of patches, then selects a few samples at the patch level and annotates them at the patch level. The red box represents positive samples, and the blue box represents negative samples. (b) The bag few-shot method directly selects a few WSIs at the slide level and annotates them weakly at the slide level. (c) Our method first selects a few WSIs at the slide level, then annotates a few patches for each selected WSI. Compared to (a) and (b), our method significantly reduces annotation costs while providing patch-level supervision information.", "description": "This figure illustrates three different few-shot learning approaches for Whole Slide Image (WSI) classification.  (a) shows the instance few-shot method, which divides WSIs into patches and annotates a small subset. (b) depicts the bag few-shot method, annotating only a few whole slides. (c) presents the proposed 'Instance and Bag' few-shot method, which combines slide-level selection with patch-level annotation for improved efficiency and performance.", "section": "1 Introduction"}, {"figure_path": "9vcqleAHPl/figures/figures_4_1.jpg", "caption": "Figure 2: The structure of the FAST classification framework.", "description": "The figure illustrates the FAST classification framework, which consists of two branches: a cache branch and a prior branch. The cache branch utilizes the image encoder of the V-L model CLIP to extract features of all patches, constructs a cache model using the labeled instances, and classifies each instance through knowledge retrieval. It also incorporates unlabeled instances, treating their labels as learnable parameters. The prior branch uses GPT4-V to obtain task-related prompts and uses CLIP's text-image matching prior and prompt-learning techniques to design a learnable visual-language classifier.  Both branches' outputs are integrated to produce WSI classifications at the patch and slide levels.", "section": "3.2 Classification Framework"}, {"figure_path": "9vcqleAHPl/figures/figures_7_1.jpg", "caption": "Figure 3: Results of FAST on CAMELYON16 dataset under different annotation ratio.", "description": "This figure shows the performance of the FAST model on the CAMELYON16 dataset under various annotation ratios.  The x-axis represents the ratio of annotated instances, and the y-axis represents the AUC (Area Under the Curve) score, a measure of the model's performance.  Two lines are plotted: one for FAST and one for a fully supervised method. The shaded area represents the standard deviation across multiple runs. The figure demonstrates that FAST achieves comparable performance to the fully supervised method with a significantly lower annotation ratio, highlighting its efficiency.", "section": "4.3 Experimental Results"}, {"figure_path": "9vcqleAHPl/figures/figures_8_1.jpg", "caption": "Figure 2: The structure of the FAST classification framework.", "description": "The figure illustrates the dual-branch few-shot WSI classification framework of FAST.  The framework consists of a cache branch and a prior branch, which work in conjunction to classify WSIs using a dual-tier annotation strategy. The cache branch is built using all available patches, where labelled patches guide the learning of unlabelled patches.  The prior branch leverages visual-language models and learnable prompt vectors for patch classification. Finally, the outputs from both branches are integrated for a final WSI-level classification.  The figure highlights the flow of data through both branches, showing feature extraction, knowledge retrieval in the cache branch and prompt generation/classification in the prior branch. The dual-level annotation is visually depicted at the top of the figure.", "section": "3.2 Classification Framework"}, {"figure_path": "9vcqleAHPl/figures/figures_16_1.jpg", "caption": "Figure 2: The structure of the FAST classification framework.", "description": "This figure illustrates the dual-branch framework of FAST. The dual-tier few-shot annotation strategy is used to select a subset of WSIs and patches for labeling. The cache branch uses all patches and available patch labels to build a cache model via knowledge retrieval to improve the model's performance. The prior branch incorporates the text encoder of a vision-language model (e.g., CLIP) to generate task-related prompts, combining both branches' results for final WSI classification. The figure also depicts the feature cache, label cache, and few-shot knowledge retrieval processes, as well as the fusion of results from the cache and prior branches.", "section": "3.2 Classification Framework"}, {"figure_path": "9vcqleAHPl/figures/figures_17_1.jpg", "caption": "Figure 6: Results of FAST on CAMELYON16 dataset under different instance shots.", "description": "This figure shows the performance of the FAST model on the CAMELYON16 dataset under different numbers of annotated instances per bag.  The results are displayed as instance-level AUC and bag-level AUC, with different line colors representing different numbers of instance shots (1, 2, 4, 16, and 64). The x-axis represents the number of bag shots. This graph demonstrates the impact of changing the number of instances on the overall performance of the model, showing the tradeoff between annotation effort and classification accuracy. The shaded region around each line represents the standard deviation, highlighting the impact of randomness in few-shot learning.", "section": "4.3 Experimental Results"}]