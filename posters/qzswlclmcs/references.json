{"references": [{"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "publication_date": "2023", "reason": "This paper introduces Qwen-VL, a large vision-language model that is used extensively by Kaleido for generating various forms of latent tokens, enriching the image generation process."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2021", "reason": "This paper introduces classifier-free guidance (CFG), a technique crucial to Kaleido's approach, allowing high-quality image generation while simultaneously enhancing diversity."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022", "reason": "This work is highly relevant as it details the architecture of diffusion models, providing a foundation for Kaleido's latent-augmented diffusion model."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This paper introduces the T5 model, which forms the base of the autoregressive decoder used in Kaleido's latent generation, greatly impacting the model's ability to generate interpretable latents."}, {"fullname_first_author": "Jascha Sohl-Dickstein", "paper_title": "Deep unsupervised learning using nonequilibrium thermodynamics", "publication_date": "2015", "reason": "This foundational paper details the theory and framework of diffusion models, providing the theoretical underpinning of the core approach leveraged by Kaleido."}]}