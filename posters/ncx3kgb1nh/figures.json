[{"figure_path": "NCX3Kgb1nh/figures/figures_7_1.jpg", "caption": "Figure 1: Convergence of \u03b5log,\u03bb>0 towards \u03b5hinge,0 in the synthetic dataset introduced in this section. Left panel: for a fixed parameter \u03b2 = 8 of the logistic cost, \u03b5log,\u03bb>0 converge towards \u03b5hinge,0 as \u03bb is decreased toward 0. Right panel: for a fixed entropic regularization parameter \u03bb = 0.1, \u03b5log,\u03bb converges towards \u03b5hinge,0 as the gain of the logistic cost \u03b2 increases. All simulations were generated for d = 5, \u03bc = 0, \u03c3\u00b2 = 1.0 and N = 100. Points and error bars indicate average and standard deviation across 100 repetitions.", "description": "This figure shows the convergence of the entropic regularized violation ratio (\u03b5log,\u03bb) towards the unregularized one (\u03b5hinge,0) as a function of the entropic regularization parameter (\u03bb) and the gain of the logistic cost (\u03b2).  The left panel shows convergence with varying \u03bb and fixed \u03b2, while the right panel illustrates convergence with varying \u03b2 and fixed \u03bb. The results demonstrate that as \u03bb approaches 0 and \u03b2 increases, the regularized ratio closely approximates the unregularized ratio.", "section": "5.1 Synthetic Data Experiment"}, {"figure_path": "NCX3Kgb1nh/figures/figures_8_1.jpg", "caption": "Figure 2: Type I and type II error of the relative test statistic as a function of the sample size n in dimension d \u2208 {10, 20, 50}. Here, \u03b2 = 8 and \u03bb = 0.01d.", "description": "This figure shows the Type I and Type II error rates for a relative test statistic used in multivariate stochastic dominance testing.  The error rates are plotted against the sample size (n) for different dimensions (d = 10, 20, and 50). The parameters \u03b2 and \u03bb are held constant at \u03b2=8 and \u03bb=0.01d.  The figure illustrates how the error rates behave as the sample size increases, for varying dimensions, providing insights into the test's performance.", "section": "5.1 Synthetic Data Experiment"}, {"figure_path": "NCX3Kgb1nh/figures/figures_8_2.jpg", "caption": "Figure 3. Mix Instruct Results: Comparison of Multivariate FSD to Reduction to univariate FSD with aggregation across the dimensions.", "description": "This figure compares the performance of three different methods for ranking large language models (LLMs) based on multiple evaluation metrics.  The x-axis represents the sample size used in the experiment. The y-axis shows the Kendall Tau similarity between the rankings produced by each method and the rankings produced by ChatGPT, used as a human-proxy ranking. The three methods are:\n\n1. **Relative Testing FSD w/ P(IC):** This method reduces the multivariate ranking problem to a univariate problem using independent copula aggregation across the dimensions before applying univariate first-order stochastic dominance.\n2. **Relative Testing FSD w/ P(EC):** This method also reduces the problem to a univariate one using empirical copula aggregation before applying first-order stochastic dominance.\n3. **Multivariate Relative Testing:** This method directly utilizes the multivariate first-order stochastic dominance framework, incorporating the dependencies between the metrics.\n\nThe figure demonstrates that the multivariate relative testing approach outperforms the two univariate reduction methods in terms of Kendall Tau similarity with the human-generated rankings, especially with larger sample sizes. This indicates that accounting for dependencies between metrics through multivariate analysis yields a more accurate and robust ranking of LLMs.", "section": "5.2 LLM Benchmarking"}]