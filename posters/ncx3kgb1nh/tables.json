[{"figure_path": "NCX3Kgb1nh/tables/tables_14_1.jpg", "caption": "Figure 4: This table ranks the 12 models tested in the LLM benchmarking experiment using n = 5000 samples according to their one-versus-all violation ratio, \u03b5<sup>(h,\u03bb)</sup><sub>i</sub>(M) = \u03a3<sub>j\u2260i</sub> \u03b5<sup>(h,\u03bb)</sup><sub>ij</sub>, where \u03b5<sup>(h,\u03bb)</sup><sub>ij</sub> is the pairwise violation ration of model i compared with model j (lower is better).", "description": "This table presents the ranking of 12 large language models (LLMs) based on their one-versus-all violation ratios.  The ranking is determined using the entropic multivariate first-order stochastic dominance (FSD) test described in the paper.  A lower violation ratio indicates a more dominant model, suggesting better overall performance across multiple evaluation metrics.  The sample size (n) used for the ranking is 5000.", "section": "5.2 LLM Benchmarking"}]