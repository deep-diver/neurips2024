[{"figure_path": "KjNEzWRIqn/tables/tables_6_1.jpg", "caption": "Table 1: Performance of various models in three web-based task benchmarks. We measure step accuracy (%) for Mind2Web, and task success rate (%) for MiniWoB++ and WebArena. The numbers of FireAct-7b is taken from [5]; AutoWebGLM-7b(S1) represents the model trained with only synthetic data in [19]. All other numbers are produced by our work.", "description": "This table presents the performance comparison of various large language models (LLMs) on three web-based benchmarks: Mind2Web, MiniWoB++, and WebArena.  The models are categorized into API-based models, open-source instructed models, and open-source interactive data finetuned models. For each benchmark, the table shows the performance of each model using different metrics (step accuracy for Mind2Web and task success rate for MiniWoB++ and WebArena).  The table also notes the source of data used for training each model (e.g., synthetic, human annotated) and highlights the model Synatra-CodeLlama-7b, which is the focus of the paper.", "section": "6 Results"}, {"figure_path": "KjNEzWRIqn/tables/tables_7_1.jpg", "caption": "Table 1: Performance of various models in three web-based task benchmarks. We measure step accuracy (%) for Mind2Web, and task success rate (%) for MiniWoB++ and WebArena. The numbers of FireAct-7b is taken from [3]; AutoWebGLM-7b(S1) represents the model trained with only synthetic data in [19]. All other numbers are produced by our work.", "description": "This table compares the performance of various Language Models (LLMs) on three web-based benchmark tasks: Mind2Web, MiniWoB++, and WebArena.  It shows step accuracy for Mind2Web and task success rate for the other two benchmarks.  The table includes both API-based models (like GPT-3.5 and GPT-4), open-source instructed models (like CodeLlama), and open-source models fine-tuned with interactive data.  The table highlights the superior performance of the Synatra-CodeLlama model compared to other models of a similar size and even some larger models, demonstrating the effectiveness of the Synatra data synthesis approach.", "section": "6 Results"}, {"figure_path": "KjNEzWRIqn/tables/tables_15_1.jpg", "caption": "Table 1: Performance of various models in three web-based task benchmarks. We measure step accuracy (%) for Mind2Web, and task success rate (%) for MiniWoB++ and WebArena. The numbers of FireAct-7b is taken from [3]; AutoWebGLM-7b(S1) represents the model trained with only synthetic data in [19]. All other numbers are produced by our work.", "description": "This table compares the performance of various models (including GPT-3.5 and GPT-4) across three web-based benchmark tasks (Mind2Web, MiniWoB++, and WebArena).  For Mind2Web, step accuracy is reported; for MiniWoB++ and WebArena, task success rate is reported.  The table highlights the performance of Synatra-CodeLlama in comparison to other models, particularly those of comparable size and those trained using interactive data.  It notes that some results for comparison models were obtained from other publications.", "section": "6 Results"}]