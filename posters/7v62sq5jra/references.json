{"references": [{"fullname_first_author": "S\u00e9bastien Bubeck", "paper_title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4", "publication_date": "2023-03-12", "reason": "This paper is a seminal work on GPT-4, providing early insights into its capabilities and potential, which is highly relevant to the topic of large language model evaluation."}, {"fullname_first_author": "Lianmin Zheng", "paper_title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "publication_date": "2023-00-00", "reason": "This paper introduces the Chatbot Arena dataset, a crucial resource for evaluating LLMs using human preferences, directly addressing the paper's focus on LLM ranking."}, {"fullname_first_author": "Anastasios N. Angelopoulos", "paper_title": "Prediction-Powered Inference", "publication_date": "2023-00-00", "reason": "This paper introduces prediction-powered inference, a core methodological framework used in this paper to handle uncertainty in LLM ranking."}, {"fullname_first_author": "Yuntao Bai", "paper_title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback", "publication_date": "2022-04-05", "reason": "This work is highly relevant to the concept of aligning LLMs with human preferences, a key aspect of the proposed ranking methodology."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training Language Models to Follow Instructions with Human Feedback", "publication_date": "2022-00-00", "reason": "This paper details a method of training LLMs to better follow instructions, which is foundational for creating the strong LLMs used as comparators in this paper's ranking framework."}]}