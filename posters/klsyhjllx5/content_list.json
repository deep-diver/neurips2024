[{"type": "text", "text": "Group-wise oracle-efficient algorithms for online multi-group learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Samuel Deng Department of Computer Science Columbia University samdeng@cs.columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Daniel Hsu Department of Computer Science Columbia University djhsu@cs.columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Jingwen Liu   \nDepartment of Computer Science Columbia University   \njingwenliu@cs.columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the problem of online multi-group learning, a learning model in which an online learner must simultaneously achieve small prediction regret on a large collection of (possibly overlapping) subsequences corresponding to a family of groups. Groups are subsets of the context space, and in fairness applications, they may correspond to subpopulations defined by expressive functions of demographic attributes. In contrast to previous work on this learning model, we consider scenarios in which the family of groups is too large to explicitly enumerate, and hence we seek algorithms that only access groups via an optimization oracle. In this paper, we design such oracle-efficient algorithms with sublinear regret under a variety of settings, including: (i) the i.i.d. setting, (ii) the adversarial setting with smoothed context distributions, and (iii) the adversarial transductive setting. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the problem of online multi-group learning, originally introduced by [BL20] (adapting the specialists/time-selection setup of [Blu97; Fre $+97$ ; BM07]). In this learning model, we consider a collection of groups $\\mathcal{G}$ , which are (possibly intersecting) subsets of a context space $\\mathcal{X}$ , as well as a hypothesis class $\\mathcal{H}$ of functions defined on $\\mathcal{X}$ . Contexts $x_{1},x_{2},\\ldots,x_{T}$ arrive one-by-one over a sequence of $T$ rounds, and the learner must make a prediction associated with each $x_{t}$ . The learner\u2019s goal is to perform well on every subsequence of rounds corresponding to each group $g\\in{\\mathcal{G}}$ . Here, performance is measured relative to the predictions of the best-in-hindsight hypothesis $h\\in\\mathcal H$ for the specific subsequence under consideration. ", "page_idx": 0}, {"type": "text", "text": "A common interpretation of multi-group learning\u2014which is natural when considering fairness in machine learning (ML)\u2014identifies contexts $x\\,\\in\\,{\\mathcal{X}}$ with individuals, each group $g\\,\\in\\,{\\mathcal{G}}$ with a subpopulation (perhaps defined by a combination of various demographic features such as age and gender), and each hypothesis $h\\in\\mathcal H$ with a classifier that makes predictions about individuals [RY21]. The goal of the learner, then, is to predict as well as the best subpopulation-specific hypothesis, for all subpopulations simultaneously. ", "page_idx": 0}, {"type": "text", "text": "The standard benchmark in online learning is regret, which compares the performance of the learner on all rounds to that of the single best hypothesis in hindsight. But such a benchmark is only meaningful if there is a hypothesis that performs well in all contexts. At the other extreme, we may hope that the learner performs as well as using the best context-specific hypothesis in every round. However, this may be impossible if no context is ever repeated. The group-wise notion of regret in online multi-group learning naturally interpolates between these two extremes: the former is recovered when $\\mathcal{G}=\\bar{\\{}}\\mathcal{X}\\}$ , and the latter when ${\\mathcal{G}}=\\{\\{x\\}:x\\in\\lambda\\}$ . ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We are particularly interested in scenarios where $\\mathcal{G}$ may be extremely large (and perhaps even infinite). In such cases, it is too time-consuming to explicitly enumerate the groups in $\\mathcal{G}$ , and this precludes the use of the algorithmic solutions from prior works [BL20; Ach $+23$ ]. ", "page_idx": 1}, {"type": "text", "text": "The use of highly expressive families of groups has been a recent focus in the ML fairness literature, where fairness with respect to such rich families of groups is seen as compromise between coarse notions of statistical fairness that ignore intersectionality, and individualized notions of fairness that are typically difficult to ensure $[\\mathrm{Kea}+18$ ; Heb $+18$ ; KGZ19; GKR22; $\\mathrm{Glo}{+23}$ ]. For example, if groups are defined by simple combinations of demographic attributes (e.g., linear threshold functions), then the number of subsequences determined by these groups may grow exponentially with the number of attributes. To deal with the intractability of explicit enumeration of groups, these prior works rely on optimization oracles that implicitly search through the family of groups. In this work, we seek to do the same, but for the online (as opposed to batch) problem at hand. ", "page_idx": 1}, {"type": "text", "text": "Another motivation for multi-group learning with rich families of groups comes from the literature on \u201csubgroup robustness\u201d $[\\mathrm{Sag}+20]$ , where one is concerned with the test-time distribution shifting from the training distribution by restricting to subsets (or \u201csubgroups\u201d) of the feature space. Such scenarios have been practically motivated, for instance, in medical domains where training data sets are constructed to include data from all patients (healthy and sick) as a matter of convenience, but the population relevant to the application is only a subset of the sick patients for which an intervention is potentially possible $[\\mathrm{Oak}+20]$ . It may be difficult to anticipate which subgroup will ultimately be relevant (or even to provide an explicit shortlist of such subgroups), but multi-group learning with a very rich and expressive family of groups $\\mathcal{G}$ ensures that, as long as a subgroup is well-approximated or within the collection $\\mathcal{G}$ , it obtains our theoretical guarantees. This motivates dealing with large or potentially infinite $\\mathcal{G}$ to provide guarantees for as many subgroups as possible. ", "page_idx": 1}, {"type": "text", "text": "1.1 Summary of Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We construct an end-to-end oracle-efficient online learning algorithm that is oracle-efficient in all the problem parameters. Namely, it is oracle-efficient in both $\\mathcal{H}$ and $\\mathcal{G}$ . In the case of finite $\\mathcal{H}$ or $\\mathcal{G}$ , this admits an exponential computational speedup over the previous algorithms; in the case of infinite $\\mathcal{G}$ , this is the first algorithm that achieves multi-group online learning. With this in mind, we can even think of $\\mathcal{G}$ as representing a binary-valued function class that takes in contexts and selects subsequences $S\\subseteq[T]$ based on those contexts in possibly complex ways. ", "page_idx": 1}, {"type": "text", "text": "Previous work has shown that the basic goal of designing a computationally efficient algorithm (in all problem parameters) to achieve $o(T)$ regret for fully worst-case adversaries is impossible [HK16; $\\mathrm{Blo}{+}22\\$ . Research has therefore focused on natural structural assumptions in which computational efficiency and sublinear regret is possible, albeit in the traditional setting without groups [SKS16; $\\mathrm{Hag}+22$ ; HRS22; $\\mathrm{Blo}{+}22$ ]. Because the multi-group online adversarial setting is strictly harder than the standard setting in which this lower bound applies (simply consider multi-group learning with one group: the entire sequence), we must also take similar assumptions to circumvent the computational hardness result. In this work, we consider the same structural assumptions in the multi-group scenario. Specifically, we make the following contributions (with $\\tilde{O}(\\cdot)$ suppressing log factors): ", "page_idx": 1}, {"type": "text", "text": "1. Group-wise oracle efficiency for the smoothed setting. We present an oracle-efficient algorithm that achieves $\\tilde{O}(\\sqrt{d T/\\sigma})$ regret on every group $g\\in{\\mathcal{G}}$ for a binary-valued action space for the smoothed online learning setting of [HRS22; $\\mathrm{Blo}{+22}]$ ], where $d$ is a bound on the VC dimension of $\\mathcal{H}$ and $\\mathcal{G}$ , and $\\sigma$ is a parameter interpolating between the scenarios in which contexts are generated by a worst-case adversary and a benign, fully i.i.d. adversary. ", "page_idx": 1}, {"type": "text", "text": "2. Group-wise oracle-efficiency through generalized follow-the-perturbed leader. If a sufficient condition referred to as $\\gamma$ -approximability in previous literature $([\\mathrm{Wan}{+}22])$ is met, a variant of our oracle-efficient algorithm achieves, for each particular $g\\in{\\mathcal{G}}$ , a regret of $\\tilde{O}(\\sqrt{N T_{g}\\log|\\mathcal{H}||\\mathcal{G}|})$ for finite $\\mathcal{H}$ and $\\mathcal{G}$ , where $N$ corresponds roughly to a required number of perturbations, and $T_{g}$ is the number of rounds $t\\,\\in\\,[T]$ in which $x_{t}\\in\\mathbf{\\Sigma}_{g}$ . The dependence on $T_{g}$ as opposed to $T$ is preferable if some groups do not appear frequently over the $T$ rounds. As a special case, our algorithm also achieves $\\tilde{O}(N^{1/4}\\sqrt{T_{g}\\log|\\mathcal{H}||\\mathcal{G}|})$ in the transductive setting of [BKM97; KK05], where the adversary must reveal a set of $N$ future contexts before learning begins. ", "page_idx": 1}, {"type": "table", "img_path": "klsyhjLlX5/tmp/314aa20d9ea4c541081f727819cb81b2dfe7b39fe13954dd52d9105ddcfcb887.jpg", "table_caption": [], "table_footnote": ["Table 1: In the table above, $T$ is the number of rounds of online learning, $T_{g}$ is the number of rounds for a particular group $g,\\mathcal{H}$ is the hypothesis class, $\\mathcal{G}$ is the collection of groups, and $\\sigma$ is the smoothness parameter defined in Definition 4.1. $d$ is an upper bound on the VC dimension of $\\mathcal{H}$ . In our $\\sigma$ -smooth result in the fifth row, $d$ is also an upper bound on the VC dimension of a possibly infinite collection of groups, $\\mathcal{G}$ . In the $\\gamma.$ -approximable setting of the sixth row, $N$ is the number of perturbations. "], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Table 1 summarizes our results in relation to existing work. Our algorithms follow a more general algorithm design template based on the adversary moves first (AMF) framework of $[\\mathrm{Lee}{+22}]$ . We extend this framework with the following technical enhancements: sparsifying the implicit distributions over the hypothesis spaces used by follow-the-perturbed-leader (FTPL) algorithms, and simplifying the min-max game that is solved in every iteration of AMF. ", "page_idx": 2}, {"type": "text", "text": "In particular, the AMF framework allows us to have low-regret with respect to all group-hypothesis pairs; the multi-objective regret guarantees are useful for our purposes because we want to guarantee simultaneous low regret over all $g\\in{\\mathcal{G}}$ . However, naively applying AMF requires us to enumerate these objectives, in turn enumerating $\\mathcal{G}$ , the main issue we want to avoid. FTPL comes to the rescue and allows us to have low-regret to all pairs implicitly without enumerating them. So AMF allows us to compete with all $g\\,\\in\\,{\\mathcal{G}}$ ; FTPL ensures this is efficient. The algorithmic details and main technical challenges can be found in Section 4.2. These techniques allow us to adapt this framework to the scenario where the number of groups is too large to enumerate, and they may find use in other multi-objective learning problems. ", "page_idx": 2}, {"type": "text", "text": "1.2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "[BL20] showed that it is possible to achieve sublinear multi-group regret by reducing to the specialists framework of [Blu97; Fre $+97$ ; BM07] (a.k.a. sleeping experts). The multi-group regret they achieve scales logarithmically in both $\\mathcal{H}$ and $\\mathcal{G}$ ; this recovers the minimax regret when specializing to the standard online learning setting (with finite $\\mathcal{H}$ ) with only a single group. The paper focuses on regret rather than computational considerations; a direct implementation of their algorithm uses time and space linear in $|\\bar{\\mathcal{H}}|\\times|\\mathcal{G}|$ , and there are no stated guarantees for infinite $\\mathcal{H}$ or $\\mathcal{G}$ . ", "page_idx": 2}, {"type": "text", "text": "$[\\mathrm{Ach}{+}23]$ show how to avoid enumeration of $\\mathcal{H}$ using an optimization oracle for $\\mathcal{H}$ . They achieve this by applying a meta-algorithm atop a black-box oracle-efficient online learning algorithm, but this meta-algorithm ultimately requires explicit enumeration of $\\mathcal{G}$ . Our work, in contrast, uses an optimization oracle for ${\\mathcal{G}}\\times{\\mathcal{H}}$ jointly and hence avoids explicit enumeration of either $\\mathcal{G}$ or $\\mathcal{H}$ . ", "page_idx": 3}, {"type": "text", "text": "Multi-group (agnostic) learning has also been studied in the batch setting [RY21; TH22; GKR22; HJZ24]. In this setting, training data is drawn i.i.d. from a fixed distribution, and the learner\u2019s goal is to find a single hypothesis \u02c6h (possibly outside of $\\mathcal{H}$ ) that ensures small excess risk $\\mathbb{E}[\\ell(\\hat{h}(x),y)\\mid$ $x\\;\\in\\;g]\\,-\\,\\operatorname*{inf}_{h\\in{\\mathcal{H}}}\\mathbb{E}[\\ell(\\hat{h}(x),y)\\;\\mid\\;x\\;\\in\\;g]$ for every group $g\\,\\in\\,{\\mathcal{G}}$ simultaneously. The works of [RY21; HJZ24] design algorithms for achieving this learning criterion under a certain \u201cmulti-PAC compatibility\u201d assumption on $\\mathcal{H}$ and $\\mathcal{G}$ . [GKR22; TH22] design multi-group learning algorithms that remove the need for this assumption. One of the algorithms of [TH22], which enjoys near optimal sample complexity for general but finite $\\mathcal{H}$ and $\\mathcal{G}$ , is based on the the online multi-group learning approach of [BL20] combined with online-to-batch conversion. ", "page_idx": 3}, {"type": "text", "text": "The proof of our algorithm builds on two primary technical frameworks studied in previous literature: the adversary moves first $(A M F)$ framework of $[\\mathrm{Lee}{+22}]$ , and a line of work designing followthe-perturbed leader style algorithms [KV05] for adversarial online learning in the oracle-efficient learning model [KK05; SKS16; Hag $+22$ ; $\\scriptstyle\\mathrm{Blo}+22$ ; Wan $^{+22}$ ]. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "2.1 Notation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Throughout, $\\mathcal{X}$ denotes a context space, and $\\boldsymbol{\\wp}$ denotes an action space. For example, in a typical (online) supervised learning setup, $\\mathcal{X}$ is the feature space, and $\\boldsymbol{\\wp}$ is the label space. A group $g$ is a subset of the context space $\\mathcal{X}$ . We overload the notation $g$ for a group by using it as an indicator function $g(x):=\\mathbf{1}\\left\\{x\\in g\\right\\}$ for group membership. Let $2^{\\mathcal{X}}$ denote all subsets of the context space $\\mathcal{X}$ , and let $y^{\\chi}$ denote all possible mappings from $\\mathcal{X}$ to $\\boldsymbol{\\wp}$ . For an integer $n$ , denote $[n]:=\\{1,2,\\overline{{.}}\\,.\\,.\\,,n\\}$ . ", "page_idx": 3}, {"type": "text", "text": "For simplicity of exposition, we will focus on the setting where $\\boldsymbol{\\wp}$ is binary throughout, i.e. $y=$ $\\{-1,1\\}$ . We note that our techniques are more general, however, and may be adapted to the case of finite, multi-class action spaces (see Appendix C for details). ", "page_idx": 3}, {"type": "text", "text": "2.2 Online Multi-Group Learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We formally define the multi-group learning model as follows. Let $\\mathcal{G}\\subset2^{\\mathcal{X}}$ be a collection of (possibly non-disjoint) groups, and let $\\mathcal{H}\\subset\\mathcal{V}^{\\mathcal{X}}$ be a hypothesis class of functions $h:\\mathcal{X}\\to\\mathcal{Y}$ mapping from contexts to actions. Let $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow[0,1]$ be a bounded loss function. In each round $t\\in[T]$ : ", "page_idx": 3}, {"type": "text", "text": "1. Nature chooses $(x_{t},y_{t})\\in\\mathcal{X}\\times\\mathcal{Y}$ and reveals $x_{t}$ .   \n2. The learner chooses an action $\\hat{y}_{t}\\in\\mathcal{Y}$ .   \n3. Nature reveals $y_{t}\\in\\mathcal{V}$ .   \n4. The learner incurs loss $\\ell(\\hat{y}_{t},y_{t})\\in[0,1]$ . ", "page_idx": 3}, {"type": "text", "text": "The choices of Nature and the learner may be randomized. In the standard online prediction setting, the regret of the learner is the difference between the cumulative loss of the learner and that of the best-in-hindsight hypothesis from $\\mathcal{H}$ : $\\begin{array}{r}{\\mathrm{Reg}_{T}(\\mathcal{H}):=\\sum_{t=1}^{T}\\ell(\\hat{y}_{t},y_{t})-\\operatorname*{min}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\ell(h(x_{t}),y_{t})}\\end{array}$ The goal of the learner is to achieve sublinear (in $T$ ) expected regret. ", "page_idx": 3}, {"type": "text", "text": "In multi-group online learning, we consider the regret of the learner on subsequences of rounds $(t\\in[T]:x_{t}\\in g)$ defined by the groups $g\\in{\\mathcal{G}}$ and the sequence of contexts $x_{1},\\ldots,x_{T}$ . Specifically, the (multi-group) regret of the learner on group $g$ is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}(\\mathcal{H},g):=\\sum_{t=1}^{T}g(x_{t})\\ell(\\hat{y}_{t},y_{t})-\\operatorname*{min}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}g(x_{t})\\ell(h(x_{t}),y_{t}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Crucially, the best hypothesis for one group may differ from that of another group. Further, groups may intersect, precluding the strategy of simply running a separate no-regret algorithm for each group. The learner seeks to achieve achieve sublinear expected regret, on all groups $g\\in{\\mathcal{G}}$ simultaneously. ", "page_idx": 3}, {"type": "text", "text": "2.3 Group Oracle-Efficiency ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The main challenge posed in this work is to design computationally efficient algorithms that work with both large hypothesis classes $\\mathcal{H}$ and large collections of groups $\\mathcal{G}$ . The prior work of $[\\operatorname{Ach}\\!+\\!23]$ shows how to use the following optimization oracle to avoid explicitly enumerating the hypothesis class $\\mathcal{H}$ (but still require enumerating $\\mathcal{G}$ ). ", "page_idx": 4}, {"type": "text", "text": "Definition 2.1 (Optimization Oracle). For some error parameter $\\alpha\\geq0$ and function class $\\mathcal{F}\\in\\overline{{\\mathcal{Z}}}^{\\mathcal{X}}$ , an $\\alpha$ -approximate optimization oracle OPT takes a collection of pairs $(x_{1},z_{1}),\\ldots,(x_{m},z_{m})\\in{\\mathcal{X}}\\times$ $\\mathcal{Z}$ , a sequence of weights $w_{1},\\ldots,w_{m}\\in\\mathbb{R},$ , and a sequence of m loss functions $\\ell_{i}:\\overline{{\\mathcal{Z}}}\\times\\mathcal{Z}\\to[-1,1]$ and outputs a function $\\hat{f}:=\\mathrm{OPT}(\\{(x_{i},z_{i},w_{i})\\}_{i=1}^{m})\\in\\mathcal{F}$ satisfying: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}w_{i}\\ell_{i}(\\hat{f}(x_{i}),z_{i})\\leq\\operatorname*{inf}_{f\\in\\mathcal F}\\sum_{i=1}^{m}w_{i}\\ell_{i}(f(x_{i}),z_{i})+\\alpha.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Instantiating (in Definition 2.1) $\\mathcal{Z}$ as our action space $\\boldsymbol{\\wp}$ , each $\\ell_{i}$ as the given loss $\\ell$ of our problem, and $\\mathcal{F}$ as our hypothesis class $\\mathcal{H}$ gives a standard empirical risk minimization (ERM) oracle over a dataset $\\{(x_{i},y_{i})\\}_{i=1}^{m}$ . We present this more general definition to distinguish the action space $\\boldsymbol{\\wp}$ of the problem from the output space of the oracle (see Definition 2.2). ", "page_idx": 4}, {"type": "text", "text": "The optimization oracle is regarded as a natural computational primitive because, for many problems in machine learning, various heuristic methods (e.g., stochastic gradient descent) appear to routinely solve such problem instances despite the worst-case intractability of such problems. ", "page_idx": 4}, {"type": "text", "text": "The work of $[\\operatorname{Ach}\\!+\\!23]$ still relies on explicit enumeration of $\\mathcal{G}$ . We show how this can be avoided using a joint optimization oracle for ${\\mathcal{G}}\\times{\\mathcal{H}}$ , defined as follows. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.2 $(\\mathcal{G},\\mathcal{H})$ -optimization oracle). Fix an error parameter $\\alpha~\\geq~0$ . For a collection of groups $\\mathcal{G}\\,\\in\\,2^{\\mathcal{X}}$ , a collection of hypotheses $\\mathcal{H}\\subseteq\\,\\mathcal{V}^{\\mathcal{X}}$ , and a sequence of m loss functions $\\ell_{i}:(\\{0,1\\}\\times\\mathcal{Y})\\times(\\mathcal{Y}\\times\\mathcal{Y})\\rightarrow[-1,1]$ , an $\\alpha$ -approximate $(\\mathcal{G},\\mathcal{H})$ -optimization oracle $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ is an $\\alpha$ -approximation optimization oracle (Definition 2.1) that outputs a pair $(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}$ satisfying: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}w_{i}\\ell_{i}((\\tilde{g}(x_{i}),\\tilde{h}(x_{i})),(y_{i},y_{i}^{\\prime}))\\geq\\operatorname*{sup}_{(g^{*},h^{*})\\in\\mathcal{Q}\\times\\mathcal{H}}\\sum_{i=1}^{m}w_{i}\\ell_{i}((g^{*}(x_{i}),h^{*}(x_{i})),(y_{i},y_{i}^{\\prime}))-\\alpha.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "If ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ (which we assume in the main paper body), this oracle outputs a group-hypothesis pair $(\\tilde{g},\\tilde{h})$ that maximizes the batch loss over $m$ examples $(x_{i},(y_{i},y_{i}^{\\prime}))$ in $\\mathcal{X}\\times\\{-1,1\\}^{2}$ . [GKR22] also made such an assumption and gave two implementations: one based on cost-sensitive classification oracles for $\\mathcal{G}$ and $\\mathcal{H}$ separately, the other a heuristic algorithm that is empirically effective. Details of these oracle instantiations are included in Appendix B.3. ", "page_idx": 4}, {"type": "text", "text": "We also require an optimization oracle for $\\mathcal{H}$ itself, defined similarly. This can be thought of simply as (exact) empirical risk minimization over $\\mathcal{H}$ .1 ", "page_idx": 4}, {"type": "text", "text": "Definition 2.3 ( $\\mathcal{H}$ -optimization oracle). For a collection of hypotheses $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , and a sequence of m loss functions $\\ell_{i}:\\mathcal{V}\\times\\mathcal{V}\\to[-1,1]$ , an $\\mathcal{H}$ -optimization oracle $\\mathrm{OPT}_{\\mathcal{H}}$ is a 0-approximation optimization oracle (Definition 2.1, with $\\alpha\\:=\\:0.$ ) that outputs a hypothesis $h\\ \\in\\ \\mathcal H$ satisfying $\\begin{array}{r}{\\sum_{i=1}^{m}w_{i}\\ell_{i}(h(x_{i}),y_{i})\\leq\\operatorname*{inf}_{h^{*}\\in\\mathcal{H}}\\sum_{i=1}^{m}w_{i}\\ell_{i}(h^{*}(x_{i}),y_{i})}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "3 Warm-up: I.I.D. Setting ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, as a warm-up, we consider a setting where Nature is stochastic and oblivious: the $(x_{t},y_{t})$ are drawn i.i.d. from a single fixed (but unknown) distribution $\\mu$ , independent of any choices of the learner. In a standard online prediction setting with i.i.d. data, it suffices to use a \u201cfollow-theleader\u201d (FTL) strategy (see, e.g., [Haz22]), which can be easily implemented using an optimization oracle for $\\mathcal{H}$ . However, such a strategy only guarantees low regret on $g=\\mathcal{X}$ . To achieve low regret on all (possibly intersecting) groups $g\\in{\\mathcal{G}}$ simultaneously, we need a multi-group analogue of FTL. ", "page_idx": 4}, {"type": "text", "text": "What makes FTL work in the standard online prediction setting is the instantaneous expected regret bound of empirical risk minimization (ERM) on i.i.d. data. Therefore, it is natural to replace ERM with a batch multi-group algorithm [TH22; GKR22]; this will ensure the requisite instantaneous guarantee on all groups $g\\in{\\mathcal{G}}$ . We show how to use the oracle-efficient algorithm LISTUPDATE of [GKR22] for the online multi-group problem. ", "page_idx": 5}, {"type": "text", "text": "Throughout this section, we assume $\\ell$ is the zero-one loss (for simplicity), and that $\\mathcal{H}$ and $\\mathcal{G}$ both have VC dimension at most $d\\geq1$ . For any $g\\in{\\mathcal{G}}$ , let $P(g):=\\mathbb{E}_{(x,y)\\sim\\mu}[g(x)]$ be the probability mass of group $g$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.1 (Theorem 16 of [GKR22]). For any $\\delta~\\in~(0,1)$ , given n i.i.d. training samples $\\{(x_{i},y_{i})\\}_{i=1}^{n}$ from $\\mu_{\\cdot}$ , the LISTUPDATE algorithm2 returns a function $f:\\mathcal{X}\\to\\mathcal{Y}$ such that, with probability $1-\\delta,$ , for any group $g\\in{\\mathcal{G}}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\ell(f(x),y)\\mid x\\in g]\\leq\\operatorname*{min}_{h\\in\\mathcal{H}}\\mathbb{E}[\\ell(h(x),y)\\mid x\\in g]+\\frac{1}{P(g)}\\cdot O\\left(\\left(\\frac{d\\log n+\\log(1/\\delta)}{n}\\right)^{1/3}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Moreover, LISTUPDATE makes poly $(n,d,\\log(1/\\delta))$ calls to a $(\\mathcal{G},\\mathcal{H})$ optimization oracle. ", "page_idx": 5}, {"type": "text", "text": "Our algorithm, ONLINE LISTUPDATE, forms its prediction $\\hat{y}_{t}$ in round $t$ as follows: ", "page_idx": 5}, {"type": "text", "text": "\u2022 Run LISTUPDATE on the samples from previous rounds $(x_{1},y_{1}),\\ldots,(x_{t-1},y_{t-1})$ .   \n\u2022 Let $f_{t}$ denote the function returned by LISTUPDATE, and predict ${\\hat{y}}_{t}:=f_{t}(x_{t})$ . ", "page_idx": 5}, {"type": "text", "text": "Using Theorem 3.1, we obtain the following multi-group regret bound for ONLINE LISTUPDATE. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2. $I f(x_{t},y_{t})$ are drawn i.i.d. from a fixed distribution $\\mu$ over $\\mathcal X\\times\\mathcal X$ , ONLINE LISTUPDATE achieves the following expected multi-group regret bound: for all $g\\in{\\mathcal{G}}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]=O\\left((d\\log T)^{1/3}\\,T^{2/3}+\\sqrt{d T\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proof of Theorem 3.2 is given in Appendix A. ", "page_idx": 5}, {"type": "text", "text": "4 Group Oracle-Efficiency with Smooth Contexts ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we first describe a natural problem setting in which oracle-efficient online multi-group learning is possible: the smoothed online learning setting (Section 4.1), for which the i.i.d. setting of Section 3 is a special case. We then present our main algorithm, Algorithm 1, for achieving oracleefficient online multi-group learning (Section 4.2). Easy modifications of this main algorithm will admit oracle-efficient online multi-group learning for other common online learning specifications, as described in Section 5. ", "page_idx": 5}, {"type": "text", "text": "4.1 Smoothed Online Learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now describe smoothed online learning, a prevalent model in recent literature in computationally efficient online learning that formalizes the natural relaxation that Nature is not maximally adversarial [RST11; HRS22; $\\mathrm{Hag}+22$ ; $\\mathrm{Blo}{+22}]$ . The main assumption is that, instead of choosing arbitrary (possibly worst-case) examples $(x_{t},y_{t})\\in\\mathcal{X}\\times\\mathcal{Y}$ at every round, Nature adversarially fixes a distribution $\\mu_{t}$ over $\\mathcal{X}$ and draws $x_{t}\\sim\\mu_{t}$ , while still drawing $y_{t}$ adversarially. Formally, we restrict such distributions to be $\\sigma$ -smooth, following the definitions of $[\\mathrm{Blo}{+}22$ ; HRS22]. ", "page_idx": 5}, {"type": "text", "text": "Definition 4.1 ( $\\sigma$ -smooth distribution). Let $\\mu$ be some probability measure on $\\mathcal{X}$ , and let $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ be a base measure on $\\mathcal{X}$ . The distribution $\\mu$ is $\\sigma$ -smooth (with respect to $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ ) if $\\mu$ is absolutely continuous3 with respect to $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\exp{\\frac{d\\mu}{d B}}\\leq{\\frac{1}{\\sigma}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We denote the set of all $\\sigma$ -smooth distributions on $\\mathcal{X}$ with respect to the measure $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ as $S_{\\sigma}(\\mathcal{X},\\mathcal{B})$ . If $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ is clear from context, we simply write $\\mathcal{S}_{\\sigma}(\\mathcal{X})$ . We assume that we have sample access to $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ throughout. For simplicity, one may assume $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ is uniform on $\\mathcal{X}$ . ", "page_idx": 5}, {"type": "text", "text": "Definition 4.1 interpolates between the benign setting where $x_{t}$ are drawn i.i.d. from $\\mu$ when $\\sigma=1$ , and the fully adversarial setting when $\\sigma$ approaches 0. In this sense, the warm-up result of Section 3 is a special case of this setting when $\\sigma=1$ and $\\mu$ is fixed for all rounds. Note that this definition does not restrict the choice of $y_{t}$ at all; $y_{t}$ may still be chosen adversarially. ", "page_idx": 6}, {"type": "text", "text": "With this definition in hand, consider the following specification of the learning game outlined in Section 2.2, henceforth refered to as the $\\sigma$ -smooth online learning setting. For each round $t\\in[T]$ : ", "page_idx": 6}, {"type": "text", "text": "1. Nature fixes a distribution $\\mu_{t}\\in{\\cal S}_{\\sigma}(\\mathcal{X})$ that may depend in any way on the entire history prior to round $t$ . Nature samples $x_{t}\\sim\\mu_{t}$ and chooses $y_{t}\\in\\mathcal{V}$ adversarially; $x_{t}$ is revealed to the learner. 2. The learner (randomly) chooses an action $\\hat{y}_{t}\\in\\mathcal{Y}$ . 3. Nature reveals $y_{t}\\in\\mathcal{V}$ , and the learner incurs the loss $\\ell(\\hat{y}_{t},y_{t})\\in[0,1]$ . ", "page_idx": 6}, {"type": "text", "text": "We now depart from the previous literature that considers oracle-efficient algorithms in this setting ([HRS22; $\\mathrm{Blo}{+}22]$ ), as we focus on the more difficult objective of minimizing multi-group regret over a collection $\\mathcal{G}$ , as in Equation (1). This setting will allow us to employ our $(\\mathcal{G},\\mathcal{H})$ -optimization oracle in Definition 2.2; a full description of our algorithm is now in order in Section 4.2. ", "page_idx": 6}, {"type": "text", "text": "4.2 Algorithm for Smooth Contexts ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we present Algorithm 1, our main algorithm for multi-group online learning for the $\\sigma$ -smooth setting. At a high level, our algorithm takes inspiration from the very general adversarymoves-first (AMF) framework for multiobjective online learning of $[\\mathrm{Lee}{+22}]$ . Our algorithm can be thought of as a sequential game between two competing players: an adversarial $(\\mathcal{G},\\mathcal{H})$ -player and the learner, referred to, in the context of Algorithm 1 as the $\\mathcal{H}$ -player. On each round $t$ , the $(\\mathcal{G},\\mathcal{H})$ -player employs a $(\\mathcal{G},\\mathcal{H})$ -optimization oracle, $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ , to play a distribution over group-hypothesis pairs that maximizes the misfortune of the $\\mathcal{H}$ -player, based on the history up until $t$ . Upon receiving this distribution (and the context $x_{t}$ from Nature), the $\\mathcal{H}$ -player chooses $\\hat{y}_{t}$ randomly according to a distribution obtained by solving a simple constant-size linear program, and then incurs the loss $\\ell(\\hat{y}_{t},y_{t})$ . The $(\\mathcal{G},\\mathcal{H})$ -player, taking this new loss into account, can now adjust his strategy to foil the $\\mathcal{H}$ -player in the next round by putting mass on the groups on which the $\\mathcal{H}$ -player performs poorly. Crucially, neither $\\mathcal{G}$ nor $\\mathcal{H}$ is ever accessed directly, although our proofs need to maintain a distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ . In order to do this, we make the crucial observation that FTPL maintains an implicit distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ and we sparsely approximate that distribution through repeatedly querying the $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ oracle. (For clarity, we use the tilde decoration, $\\tilde{h}$ and $\\tilde{g}$ , on hypotheses and groups obtained by the $(\\mathcal{G},\\mathcal{H})$ -player using $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ .) ", "page_idx": 6}, {"type": "text", "text": "Main algorithm. For any $x\\in\\mathscr{X}$ , define $\\tilde{\\ell}_{x}:(\\{0,1\\}\\times\\mathcal{Y})\\times(\\mathcal{Y}\\times\\mathcal{Y})\\rightarrow[-1,1]\\,\\mathrm{as}:$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\tilde{\\ell}_{x}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)):=\\tilde{g}(x)\\left(\\ell(y^{\\prime},y)-\\ell(\\tilde{h}(x),y)\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\ell(\\cdot,\\cdot)$ is the loss given by the learning problem. The quantity $\\tilde{\\ell}_{x}$ is the loss that the $(\\mathcal{G},\\mathcal{H})$ - player is maximizing; it corresponds to the single-round regret of the learner on group $g$ to the hypothesis $h$ if the context on that round is $x$ . ", "page_idx": 6}, {"type": "text", "text": "The $(\\mathcal{G},\\mathcal{H})$ -player will employ the FTPL style strategy of $[\\mathrm{Blo}{+}22]$ , adapted to our setting. For each round $t$ , this requires generating $n$ perturbation examples as extra input to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . To generate these hallucinated perturbation examples, we independently draw $z_{t,j}\\,\\sim\\,B$ and $\\gamma_{t,j}\\,\\sim\\,N(0,1)$ , samples $j\\,\\in\\,[n]$ from the base measure and the standard Gaussian, respectively. In this section, ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ and $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ , so we use the perturbations in their FTPL variant for binary-valued action spaces (outlined in Appendix B.6), ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\pi_{t,n}^{\\mathrm{bin}}(g,h,\\eta):=\\sum_{j=1}^{n}\\frac{\\eta\\gamma_{t,j}g(z_{t,j})h(z_{t,j})}{\\sqrt{n}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Remark. We focus on the setting where ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ for ease of exposition, but settings in which $\\boldsymbol{\\wp}$ is a general finite set can be handled with easy modifications. See Appendix $C$ for details. ", "page_idx": 6}, {"type": "text", "text": "Remark. Multi-group online learning settings other than the $\\sigma$ -smooth setting can be handled appropriately simply by replacing the strategy of the $(\\mathcal{G},\\mathcal{H})$ -player by an appropriate no-regret ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 Algorithm for Group-wise Oracle Efficiency (for smoothed online learning) ", "page_idx": 7}, {"type": "text", "text": "Input: Perturbation strength $\\eta>0$ ; perturbation count $n\\in\\mathbb N$ ; number of oracle calls $M\\in\\mathbb{N}$ .   \n1: for $t=1,2,3,\\dots,T$ do   \n2: Receive a context $x_{t}\\sim\\mu_{t}$ from Nature.   \n3: for $i=1,2,3,\\dots,M$ do   \n4: $(\\mathcal{G},\\mathcal{H})$ -player: Draw $n$ hallucinated examples as in Equation (4) to construct $\\pi_{t,n}^{\\mathrm{bin}}$ . ", "page_idx": 7}, {"type": "text", "text": "5: $(\\mathcal{G},\\mathcal{H})$ -player: Using the entire history $\\{(\\hat{y}_{s},y_{s})\\}_{s=1}^{t-1}$ so far, call $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ to obtain $(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)})\\in\\mathcal{G}\\times\\mathcal{H}$ satisfying: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{s=1}^{t-1}\\tilde{\\ell}_{x_{s}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(\\hat{y}_{s},y_{s}))+\\pi_{t,n}^{\\mathrm{bin}}(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)},\\eta)}}\\\\ &{}&{\\geq\\operatorname*{sup}_{(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}}\\sum_{s=1}^{t-1}\\tilde{\\ell}_{x_{s}}((g^{*},h^{*}),(\\hat{y}_{s},y_{s}))+\\pi_{t,n}^{\\mathrm{bin}}(g^{*},h^{*},\\eta)-\\alpha}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "6: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "7: $\\mathcal{H}$ -player: Call $\\mathrm{OPT}_{\\mathcal{H}}$ twice on the singleton datasets $\\{(x_{t},1)\\}$ and $\\{(x_{t},-1)\\}$ , with the 0-1 loss, obtaining: ", "page_idx": 7}, {"type": "equation", "text": "$$\nh_{1}^{\\prime}\\in\\mathop{\\arg\\operatorname*{min}}_{h^{*}\\in\\mathcal{H}}\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq1\\right\\},\\quad h_{-1}^{\\prime}\\in\\mathop{\\arg\\operatorname*{min}}_{h^{*}\\in\\mathcal{H}}\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq-1\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "8: $\\mathcal{H}$ -player: Solve the linear program ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{p,\\lambda\\in\\mathbb{R}}{\\operatorname*{min}}}&{\\lambda}\\\\ {\\mathrm{subj.~to}}&{\\displaystyle\\sum_{i=1}^{M}p\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{1}^{\\prime}(x_{t}),y))+(1-p)\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{-1}^{\\prime}(x_{t}),y))\\leq\\lambda}\\\\ &{\\qquad\\forall y\\in\\{-1,1\\}}\\\\ &{0\\leq p\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "9: Sample $b\\sim\\mathrm{Ber}(p)$ where $b\\in\\{-1,1\\}$ , let $h_{t}=h_{b}^{\\prime}$ . ", "page_idx": 7}, {"type": "text", "text": "10: Learner commits to the action ${\\hat{y}}_{t}=h_{t}(x_{t})$ ; Nature reveals $y_{t}$ .   \n11: Learner incurs the loss $\\ell(\\hat{y}_{t},y_{t})$ . ", "page_idx": 7}, {"type": "text", "text": "12: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "algorithm with access to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . Examples of such variants are given in Section 5, and the general framework for such modifications is given in Appendix $B$ . ", "page_idx": 7}, {"type": "text", "text": "Remark. With appropriate modifications, one can instantiate the $(\\mathcal{G},\\mathcal{H})$ -player with the FTPL style strategy of [Hag $+22J$ instead, inheriting the $\\sigma^{-1/4}$ dependence summarized in Table 1. Our focus in this paper is not on the dependence on $\\sigma$ , however, so our main exposition centers around the similar algorithmic techniques of $[B l o+22]$ . ", "page_idx": 7}, {"type": "text", "text": "It is clear that $\\mathcal{G}$ and $\\mathcal{H}$ are never accessed except through $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ and $\\mathrm{OPT}_{\\mathcal{H}}$ . We make $M$ oracle calls to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ and two oracle calls to $\\mathrm{OPT}_{\\mathcal{H}}$ at each round. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.1. Let $y=\\{-1,1\\}$ be a binary action space, $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ be a binary-valued hypothesis class, $\\mathcal{G}\\subseteq2^{\\mathcal{X}}$ be a (possibly infinite) collection of groups, and $\\ell:\\{-1,1\\}\\times\\{-1,1\\}\\to$ $[0,1]$ be a bounded loss function. Let the VC dimensions of $\\mathcal{H}$ and $\\mathcal{G}$ both be bounded by $d$ . Let $\\alpha\\geq0$ be the approximation error of the oracle $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . $I f$ we are in the $\\sigma$ -smooth online learning setting, then, for $M=\\mathrm{poly}(T),n=\\mathrm{poly}(T/\\sigma)$ , and $\\dot{\\eta}=\\mathrm{poly}(T/\\sigma)$ , Algorithm $^{\\,l}$ achieves, for each $g\\in{\\mathcal{G}}$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the expectation is over all the randomness of the $(\\mathcal{G},\\mathcal{H})$ -player\u2019s perturbations and the $\\mathcal{H}$ -player\u2019s Bernoulli choices. (See Corollary B.7.1 for precise settings of $M$ , $n_{i}$ , and $\\eta$ .) ", "page_idx": 8}, {"type": "text", "text": "Technical details. We solve three main difficulties toward ensuring that our algorithm achieves diminishing multi-group regret while maintaining computational efficiency for large or infinite $\\mathcal{G}$ , which we outline here. The full proof of Theorem 4.1 is in Appendix B. ", "page_idx": 8}, {"type": "text", "text": "First, although the general framework of casting online learning problems with multiple objectives as two-player games is not new ([Lee $+22$ ; HJZ24; HPY23]), previous works have employed a multiplicative weights algorithm to hedge against the multiple objectives, requiring explicit enumeration. Departing from previous literature, however, our $(\\mathcal{G},\\mathcal{H})$ -player uses a follow-the-perturbed leader (FTPL) style algorithm (see, e.g., [KV05]) with $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}$ . The particular follow-the-perturbed leader variant of $[\\mathrm{Blo}{+}22]$ constructs \u201cperturbations\u201d via a set of fake examples drawn from the the base measure $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ on $\\mathcal{X}$ , and, is thus suitable for our oracle and problem setting. ", "page_idx": 8}, {"type": "text", "text": "Second, a key property needed by the proof of Algorithm 1 is that the $\\mathcal{H}$ -player must receive a distribution over $\\mathcal{G}\\times\\mathcal{H}$ to reduce the complex multi-objective criterion of performing well against all $(g,h)\\in\\mathcal{G}\\times\\mathcal{H}$ to a scalar quantity. Previous work directly supplied this distribution through the multiplicative weights algorithm. However, this would involve explicitly enumerating $\\mathcal{G}$ and $\\mathcal{H}$ . On the other hand, using an FTPL algorithm as is would only output a single action from ${\\mathcal{G}}\\times{\\mathcal{H}}$ , which is insufficient. To remedy this, we make the crucial observation that FTPL algorithms implicitly maintain a distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ through the randomness of their perturbations, and, thus, we construct the empirical approximation of this distribution through repeatedly calling $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}$ . Standard uniform convergence arguments are used to bound the number of oracle calls needed. An argument employing the minimax theorem shows that the final regret guarantee of the entire algorithm essentially inherits the regret of the FTPL algorithm, plus sublinear error terms. ", "page_idx": 8}, {"type": "text", "text": "Finally, the $\\mathcal{H}$ -player chooses a distribution over $\\boldsymbol{\\wp}$ by by solving an exceedingly simple linear program (LP) with two optimization variables, $p$ and $\\lambda$ . The value $p\\in[0,1]$ corresponds to the parameter of a Bernoulli distribution from which we sample to choose $\\hat{y}_{t}$ . This choice of action corresponds exactly to choosing the minimax optimal strategy against the worst-case $y$ that Nature could select. We employ similar techniques as $[\\mathrm{Lee}{+22}]$ , analyzing the value of this min-max game as if Nature (the max in the min-max) had gone first instead. The two calls to $\\mathrm{OPT}_{\\mathcal{H}}$ are used just to find the actions achievable by $\\mathcal{H}$ on $x_{t}$ . (Note that it is possible that $h_{y^{\\prime}}^{\\prime}(x_{t})\\neq y^{\\prime}$ for some $\\bar{y^{\\prime}}\\in\\mathcal{Y}$ , in which case the Learner will always play $-y^{\\prime}$ , regardless of the value of $p$ .) ", "page_idx": 8}, {"type": "text", "text": "5 Group Oracle-Efficiency in Other Settings ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In the previous section, we presented an algorithm that achieves $o(T)$ expected regret for all $g\\in{\\mathcal{G}}$ , satisfying our main desideratum from Section 2.2. However, in some cases, we may want something emnosruer.e  Sau sptproosneg etrh a\u201cta sdoamptei vger\u201do ruepgsr eb roaurnerd  tthhaant  iontshteeras;d  isnc tahliess  cwaisteh, $\\begin{array}{r}{T_{g}:=\\sum_{t=1}^{T}g(x_{t})}\\end{array}$ ,  twhoeu lndu bmeb teor of times group appeared in the $T$ rounds. We note that the algorithm of [BL20] achieves such a multi-group regret guarantee (for finite $\\mathcal{H}$ and $\\mathcal{G}$ ), but their algorithm is not oracle-efficient. So a question that remains is whether such guarantees can be achieved in an oracle-efficient manner. ", "page_idx": 8}, {"type": "text", "text": "In this section, we are back in the general fully adversarial multi-group online learning setting of Section 2.2 (without i.i.d. or smoothness assumptions). We discuss how to modify Algorithm 1 via the Generalized Follow-the Perturbed-Leader (GFTPL) framework of $[\\mathrm{Dud}+20$ ; Wan $+22$ ] to obtain regret guarantees on group $g$ where the dependence on $T$ is replaced (at least in part) with $T_{g}$ . Due to space limitations, we give a sketch here; the full details are in Appendix C. ", "page_idx": 8}, {"type": "text", "text": "We first make a simple observation that motivates our use of more advanced oracle-efficient online learning techniques. Recall the $\\tilde{g}$ -specific per-round regret to $\\tilde{h}$ of playing $h(x_{t})$ at round $t\\in[T]$ : ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(h(x_{t}),y))=\\tilde{g}(x_{t})\\left(\\ell(h(x_{t}),y)-\\ell(\\tilde{h}(x_{t}),y)\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The job of the $(\\mathcal{G},\\mathcal{H})$ -player is to run a no-regret algorithm to maximize this quantity in aggregate, as described in Section 4.2 and detailed in Appendix B.5. The online learning literature for small-loss regret focuses on developing algorithms that have regret depending on cumulative loss in hindsight instead of the number of rounds $T$ [HP05; CL06; GSV14]; this has the advantage of giving a tighter regret bound when losses are small in magnitude. It is immediate that $\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(h(x_{t}),y))=0$ whenever $\\tilde{g}(\\boldsymbol{x}_{t})=0$ , so a small-loss regret would immediately give a $o(T_{g})$ guarantee. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "We focus on the case where $\\mathcal{G}$ and $\\mathcal{H}$ are finite, and ${\\mathcal{G}}\\times{\\mathcal{H}}$ is the set of experts the $(\\mathcal{G},\\mathcal{H})$ -player has access to. Most small-loss regret algorithms would require prohibitive enumeration of ${\\mathcal{G}}\\times{\\mathcal{H}}$ [HP05; CL06; GSV14; LS15], but the GFTPL with small-loss bound algorithm of $[\\mathrm{Wan}{+}22]$ has the property that it is oracle-efficient and enjoys small-loss regret. This algorithm follows the GFTPL design template of $[\\mathrm{Dud}{+}20]$ , which, similar to the classic FTPL algorithm of [KV05], generates a noise vector to perturb each each decision of expert. However, whereas the classic FTPL algorithm generates $\\left\\vert\\boldsymbol{\\mathcal{G}}\\right\\vert\\times\\left\\vert\\boldsymbol{\\mathcal{H}}\\right\\vert$ independent random noise variables, GFTPL only generates $N\\ll|\\bar{\\mathcal{G}}|\\times|\\mathcal{H}|$ independent random variables and uses a perturbation matrix (PM) $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$ to translate the noise vector back to $|{\\mathcal{G}}|\\times|{\\mathcal{H}}|$ dependent perturbations. ", "page_idx": 9}, {"type": "text", "text": "The main challenge in instantiating a GFTPL algorithm is to construct a suitable $\\Gamma$ for the problem at hand. $[\\mathrm{Wan}{+}22]$ provide two sufficient conditions for $\\Gamma$ that, respectively, imbue the GFTPL algorithm with oracle-efficiency and small-loss regret: implementability and approximability. In our setting, implementability requires that every column of $\\Gamma$ correspond to a dataset of \u201cfake examples\u201d suitable to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . Approximability with parameter $\\gamma>0$ guarantees the stability property that the ratio $\\mathbb{P}[(\\tilde{g}_{t},\\tilde{h}_{t})\\stackrel{}{=}(g,h)]/\\mathbb{P}[(\\tilde{g}_{t+1},\\tilde{h}_{t+1})=(g,h)]\\le\\exp(\\gamma\\eta_{t})$ for all $(g,h)\\in\\mathcal{G}\\times\\mathcal{H}$ , where $\\eta_{t}>0$ is the per-round learning rate of GFTPL. If such a $\\Gamma$ exists, then instantiating the $(\\mathcal{G},\\mathcal{H})$ -player in Algorithm 1 with GFTPL (instead of the algorithm of $[\\mathrm{Blo}+22]$ ) gives us the stronger $o(T_{g})$ regret guarantee. Full definitions and the proof, with the precise setting of $M$ , can be found in Appendix C and Proposition C.3.1. ", "page_idx": 9}, {"type": "text", "text": "Theorem 5.1. Assume $\\mathcal{H},\\mathcal{G}$ are finite and there exists a $\\gamma$ -approximable and implementable perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\check{\\times}N}$ . Let $\\alpha\\geq0$ be the approximation parameter of $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . Let the no-regret algorithm for the $(\\mathcal{G},\\mathcal{H})$ -player in Algorithm 1 be the GFTPL algorithm of $I W a n{+}22J$ instantiated with $\\Gamma$ , with parameter $\\dot{M}=\\mathrm{poly}(T)$ . Then, for each $g\\in{\\mathcal{G}}$ : ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{T_{g}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{H}||\\mathcal{G}|,\\sqrt{N\\log|\\mathcal{H}||\\mathcal{G}|}\\right\\}+\\alpha T\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "We give a particular setting in which one can easily construct an approximable and implementable $\\Gamma$ . ", "page_idx": 9}, {"type": "text", "text": "Transductive Setting. In the transductive setting of [SKS16; Dud $+20$ ], Nature reveals a set $X\\subset\\mathcal{X}$ to the Learner at the beginning of the learning process; then at each round $t\\in[T]$ , Nature can only choose $x_{t}$ from $X$ . Let $N:=|X|$ denote the number of different contexts that Nature chooses from. For this setting, we can explicitly construct $\\Gamma$ to get the following result. ", "page_idx": 9}, {"type": "text", "text": "Corollary 5.1.1 (Transductive setting). In the transductive setting, there exists a perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times4N}$ such that Algorithm $^{\\,l}$ with GFTPL parameterized with $M=\\mathrm{poly}(T)$ and $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ with error parameter $\\alpha\\geq0$ satisfies: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{T_{g}}\\sqrt{\\operatorname*{max}\\left\\{\\log\\left|\\mathcal{H}\\right|\\left|\\mathcal{G}\\right|,\\sqrt{N\\log\\left|\\mathcal{H}\\right|\\left|\\mathcal{G}\\right|}\\right\\}}+\\alpha T\\right)\\quad{\\mathrm{~for~}}a l l\\;g\\in\\mathcal{G}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Suppose that $N\\leq T$ (which is the case in the transductive learning setting from [KK05]). Then the regret bound (ignoring the dependence on $\\log(|\\mathcal{H}||\\mathcal{G}|)$ on group $g$ is $O(\\sqrt{T_{g}}T^{1/4})$ , which is asymptotically smaller than $\\sqrt{T}$ whenever $T_{g}=o(\\sqrt{T})$ . If $N$ is fixed independent of $T$ , then the regret bound is $O(\\sqrt{T_{g}})$ . ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we design algorithms for online multi-group learning that are oracle-efficient and achieve diminishing $o(T)$ expected regret for all groups $g\\in{\\mathcal{G}}$ simultaneously, even when $\\mathcal{G}$ is too large to explicitly enumerate. The most interesting future directions that we leave open in this work include designing oracle-efficient algorithms that achieve $o(T_{g})$ group-specific regret for infinite $\\mathcal{H}$ and $\\mathcal{G}$ and in more general settings. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We are grateful to Abhishek Shetty for pointing out possible improvements to the dependence on $\\sigma$ We acknowledge funding support from a Google Faculty Research Award to Daniel Hsu, the NSF under grants IIS-2040971 and CCF-2008733, and the ONR under grants N00014-24-1-2700 and N00014-22-1-2713. Samuel Deng acknowledges funding from the Avanessians Doctoral Fellowship for Engineering Thought Leaders and Innovators in Data Science. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[Ach+23] Krishna Acharya, Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, and Juba Ziani. Oracle Efficient Algorithms for Groupwise Regret. arXiv:2310.04652 [cs]. Oct. 2023.   \n[BKM97] Shai Ben-David, Eyal Kushilevitz, and Yishay Mansour. \u201cOnline Learning versus Offilne Learning\u201d. In: Machine Learning 29.1 (Oct. 1997), pp. 45\u201363.   \n[BL20] Avrim Blum and Thodoris Lykouris. \u201cAdvancing Subgroup Fairness via Sleeping Experts\u201d. In: 11th Innovations in Theoretical Computer Science Conference (ITCS 2020). Ed. by Thomas Vidick. Vol. 151. Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, 2020, 55:1\u201355:24.   \n$[\\mathrm{Blo}{+}22]$ Adam Block, Yuval Dagan, Noah Golowich, and Alexander Rakhlin. \u201cSmoothed Online Learning is as Easy as Statistical Learning\u201d. In: Proceedings of Thirty Fifth Conference on Learning Theory. Ed. by Po-Ling Loh and Maxim Raginsky. Vol. 178. Proceedings of Machine Learning Research. PMLR, July 2022, pp. 1716\u20131786.   \n[Blu97] Avrim Blum. \u201cEmpirical support for winnow and weighted-majority algorithms: Results on a calendar sched uling domain\u201d. In: Machine Learning 26.1 (1997), pp. 5\u201323.   \n[BM07] Avrim Blum and Yishay Mansour. \u201cFrom External to Internal Regret\u201d. In: Journal of Machine Learning Research 8.47 (2007), pp. 1307\u20131324.   \n[BT97] Dimitris Bertsimas and John N. Tsitsiklis. Introduction to linear optimization. Vol. 6. Athena scientific optimization and computation series. Athena Scientific, 1997, pp. I\u2013XV, 1\u2013587.   \n[CL06] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University Press, 2006.   \n$[\\mathrm{Dud}\\!+\\!20]$ Miroslav Dud\u00edk, Nika Haghtalab, Haipeng Luo, Robert E. Schapire, Vasilis Syrgkanis, and Jennifer Wortman Vaughan. \u201cOracle-efficient Online Learning and Auction Design\u201d. In: J. ACM 67.5 (Sept. 2020).   \n[Fre+97] Yoav Freund, Robert E Schapire, Yoram Singer, and Manfred K Warmuth. \u201cUsing and combining predictors that specialize\u201d. In: Proceedings of the twenty-ninth annual ACM Symposium on Theory of Computing. 1997, pp. 334\u2013343.   \n[GKR22] Ira Globus-Harris, Michael Kearns, and Aaron Roth. \u201cAn Algorithmic Framework for Bias Bounties\u201d. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency. FAccT \u201922. New York, NY, USA: Association for Computing Machinery, June 2022, pp. 1106\u20131124.   \n$[\\mathrm{Glo}+23]$ Ira Globus-Harris, Declan Harrison, Michael Kearns, Aaron Roth, and Jessica Sorrell. \u201cMulticalibration as boosting for regression\u201d. In: Proceedings of the 40th International Conference on Machine Learning. ICML\u201923. JMLR.org, 2023.   \n[GSV14] Pierre Gaillard, Gilles Stoltz, and Tim Van Erven. \u201cA second-order bound with excess losses\u201d. In: Conference on Learning Theory. PMLR. 2014, pp. 176\u2013196.   \n$[\\mathrm{Hag}+22]$ Nika Haghtalab, Yanjun Han, Abhishek Shetty, and Kunhe Yang. \u201cOracle-efficient online learning for smoothed adversaries\u201d. In: Advances in Neural Information Processing Systems 35 (2022), pp. 4072\u20134084.   \n[Haz22] Elad Hazan. Introduction to Online Convex Optimization. 2nd ed. MIT Press, Sept. 2022.   \n$[\\mathrm{Heb}{+}18]$ Ursula Hebert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. \u201cMulticalibration: Calibration for the (Computationally-Identifiable) Masses\u201d. In: Proceedings of the 35th International Conference on Machine Learning. PMLR, July 2018, pp. 1939\u2013 1948.   \n[HJZ24] Nika Haghtalab, Michael Jordan, and Eric Zhao. \u201cA unifying perspective on multicalibration: Game dynamics for multi-objective learning\u201d. In: Advances in Neural Information Processing Systems 36 (2024).   \n[HK16] Elad Hazan and Tomer Koren. \u201cThe computational power of optimization in online learning\u201d. In: Proceedings of the forty-eighth annual ACM symposium on Theory of Computing. STOC \u201916. New York, NY, USA: Association for Computing Machinery, June 2016, pp. 128\u2013141.   \n[HP05] Marcus Hutter and Jan Poland. \u201cAdaptive Online Prediction by Following the Perturbed Leader\u201d. In: Journal of Machine Learning Research 6.22 (2005), pp. 639\u2013660.   \n[HPY23] Nika Haghtalab, Chara Podimata, and Kunhe Yang. \u201cCalibrated Stackelberg Games: Learning Optimal Commitments Against Calibrated Agents\u201d. In: Advances in Neural Information Processing Systems 36 (Dec. 2023), pp. 61645\u201361677.   \n[HRS22] Nika Haghtalab, Tim Roughgarden, and Abhishek Shetty. \u201cSmoothed Analysis with Adaptive Adversaries\u201d. In: 2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS). Feb. 2022, pp. 942\u2013953.   \n$[\\mathrm{Kea}+18]$ Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. \u201cPreventing fairness gerrymandering: Auditing and learning for subgroup fairness\u201d. In: International conference on machine learning. PMLR. 2018, pp. 2564\u20132572.   \n[KGZ19] Michael P Kim, Amirata Ghorbani, and James Zou. \u201cMultiaccuracy: Black-box postprocessing for fairness in classification\u201d. In: Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 2019, pp. 247\u2013254.   \n[KK05] Sham Kakade and Adam Tauman Kalai. \u201cFrom Batch to Transductive Online Learning\u201d. In: Advances in Neural Information Processing Systems. Vol. 18. MIT Press, 2005.   \n[KV05] Adam Kalai and Santosh Vempala. \u201cEfficient algorithms for online decision problems\u201d. In: Journal of Computer and System Sciences 71.3 (Oct. 2005), pp. 291\u2013307.   \n[Lee+22] Daniel Lee, Georgy Noarov, Mallesh Pai, and Aaron Roth. \u201cOnline minimax multiobjective optimization: Multicalibeating and other applications\u201d. In: Advances in Neural Information Processing Systems 35 (2022), pp. 29051\u201329063.   \n[LS15] Haipeng Luo and Robert E Schapire. \u201cAchieving all with no parameters: Adanormalhedge\u201d. In: Conference on Learning Theory. PMLR. 2015, pp. 1286\u20131304.   \n[Nat89] B. K. Natarajan. \u201cOn learning sets and functions\u201d. In: Machine Learning 4.1 (Oct. 1989), pp. 67\u201397.   \n[NMR44] John von Neumann, Oskar Morgenstern, and Ariel Rubinstein. Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition). Princeton University Press, 1944.   \n[Oak+20] Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, and Christopher R\u00e9. \u201cHidden stratification causes clinically meaningful failures in machine learning for medical imaging\u201d. In: Proceedings of the ACM conference on health, inference, and learning. 2020, pp. 151\u2013159.   \n[RST11] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. \u201cOnline Learning: Stochastic, Constrained, and Smoothed Adversaries\u201d. In: Advances in Neural Information Processing Systems. Vol. 24. Curran Associates, Inc., 2011.   \n[RY21] Guy N. Rothblum and Gal Yona. \u201cMulti-group Agnostic PAC Learnability\u201d. In: Proceedings of the 38th International Conference on Machine Learning. PMLR, July 2021, pp. 9107\u20139115.   \n$[\\mathrm{Sag}+20]$ Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. \u201cDistributionally robust neural networks for group shifts: On the importance of regularizat ion for worst-case generalization\u201d. In: International Conference on Learning Representations. 2020.   \n[SKS16] Vasilis Syrgkanis, Akshay Krishnamurthy, and Robert Schapire. \u201cEfficient Algorithms for Adversarial Contextual Learning\u201d. In: Proceedings of The 33rd International Conference on Machine Learning. Ed. by Maria Florina Balcan and Kilian Q. Weinberger. Vol. 48. Proceedings of Machine Learning Research. New York, New York, USA: PMLR, June 2016, pp. 2159\u20132168.   \n[TH22] Christopher J. Tosh and Daniel Hsu. \u201cSimple and near-optimal algorithms for hidden stratification and multi-group learning\u201d. In: Proceedings of the 39th International Conference on Machine Learning. PMLR, June 2022, pp. 21633\u201321657. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "[Wan+22] Guanghui Wang, Zihao Hu, Vidya Muthukumar, and Jacob D. Abernethy. \u201cAdaptive Oracle-Efficient Online Learning\u201d. In: Advances in Neural Information Processing Systems 35 (Dec. 2022), pp. 23398\u201323411. ", "page_idx": 12}, {"type": "text", "text": "A Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The goal is to prove that ONLINE LISTUPDATE satisfies, for all $g\\in{\\mathcal{G}}$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left((d\\log T)^{1/3}T^{2/3}+\\sqrt{d T\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Fix any $g\\in{\\mathcal{G}}$ . For each $h\\in\\mathcal H$ , define ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname{Reg}_{T}(h,g):=\\sum_{t=1}^{T}g(x_{t})(\\ell({\\hat{y}}_{t},y_{t})-\\ell(h(x_{t}),y_{t})).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By linearity of expectation, Theorem 3.1, and an elementary integral bound, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathrm{Reg}_{T}(h,g)]=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[g(x_{t})\\ell(\\hat{y}_{t},y_{t})-\\mathbb{E}[g(x_{t})\\ell(h(x_{t}),y_{t})]}\\\\ &{\\phantom{\\sum{\\mathbb{E}}[\\mathrm{Reg}_{T}(h,g)]}\\leq1+\\displaystyle\\sum_{t=2}^{T}P(g)\\cdot(\\mathbb{E}[\\ell(f_{t}(x_{t}),y_{t})\\mid x_{t}\\in g]-\\mathbb{E}[g(x_{t})\\ell(h(x_{t}),y_{t})\\mid x_{t}\\in g])}\\\\ &{\\leq1+\\displaystyle\\sum_{t=2}^{T}\\left((1-\\delta)\\cdot O\\left(\\left(\\frac{d\\log(t-1)+\\log(1/\\delta)}{t-1}\\right)^{1/3}\\right)+\\delta\\right)}\\\\ &{=1+O\\left((d\\log T+\\log(1/\\delta))^{1/3}T^{2/3}+\\delta T\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Plug-in $\\delta=1/T$ to obtain ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(h,g)]\\leq O\\left((d\\log T)^{1/3}T^{2/3}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "It remains to relate $\\mathrm{max}_{h\\in\\mathcal{H}}\\mathbb{E}[\\mathrm{Reg}_{T}(h,g)]$ to $\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]$ . Define ", "page_idx": 13}, {"type": "equation", "text": "$$\nh_{g}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\mathbb{E}_{(x,y)\\sim\\mu}[g(x)\\ell(h(x),y)]\\quad\\mathrm{and}\\quad\\hat{h}_{g}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\sum_{t=1}^{T}g(x_{t})\\ell(h(x_{t}),y_{t}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Then ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]=\\operatorname*{max}_{h\\in\\mathcal{H}}\\mathbb{E}[\\mathrm{Reg}_{T}(h,g)]+\\mathbb{E}\\left[\\sum_{t=1}^{T}g(x_{t})(\\ell(h_{g}(x_{t},y_{t})-\\ell(\\hat{h}_{g}(x_{t}),y_{t}))\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Since $\\mathcal{H}$ has VC dimension at most $d$ , a standard uniform convergence argument implies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\operatorname*{max}_{h\\in\\mathcal{H}}T\\mathbb{E}_{(x,y)\\sim\\mu}[g(x)\\ell(h(x),y)]-\\sum_{t=1}^{T}g(x_{t})\\ell(h(x_{t}),y_{t})\\right]\\leq O\\left(\\sqrt{d T\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using the definitions of $h_{g}$ and $\\hat{h}_{g}$ , we obtain ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}g(x_{t})(\\ell(h_{g}(x_{t},y_{t})-\\ell(\\hat{h}_{g}(x_{t}),y_{t}))\\right]\\leq O\\left(\\sqrt{d T\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, we conclude that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left((d\\log T)^{1/3}T^{2/3}+\\sqrt{d T\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "This finishes the proof of Theorem 3.2. ", "page_idx": 13}, {"type": "text", "text": "B Proof of Main Theorem 4.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we prove the multi-group regret guarantee of our main algorithm, Algorithm 1. To restate the theorem, we aim to show, for all $g\\in{\\mathcal{G}}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "More explicitly, we aim to show that: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}[g(x_{t})\\left(\\ell(h_{t}(x_{t}),y_{t})-\\ell(h^{*}(x_{t}),y_{t})\\right)]\\leq O\\left(\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T\\right),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\begin{array}{r}{\\boldsymbol{h}^{*}\\in\\operatorname*{min}_{\\boldsymbol{h}\\in\\mathcal{H}}\\sum_{t=1}^{T}g(\\boldsymbol{x}_{t})\\ell(\\boldsymbol{h}(\\boldsymbol{x}_{t}),\\boldsymbol{y}_{t})}\\end{array}$ . We follow a generalization of the online minimax multiobjective optimization framework of $[\\mathrm{Lee}+22]$ , with techniques inspired by [HPY23]. ", "page_idx": 14}, {"type": "text", "text": "B.1 The AMF Algorithm Framework ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We first restate their \u201cadversary-moves-first\u201d AMF algorithm of $[\\mathrm{Lee}{+22}]$ and its main regret guarantee for convenience, as we will need to adapt and generalize it to our setting. Let $\\boldsymbol{A}_{t}$ denote a general action space of the learner, and let $\\mathcal{Z}_{t}$ denote the general action space of the adversary at round $t\\in[T]$ . In full generality, $\\boldsymbol{A}_{t}$ and $\\mathcal{Z}_{t}$ are allowed to change with the rounds $t\\in[T]$ . We differentiate this from the action space $\\boldsymbol{\\wp}$ of the main body. For each round $t=1,\\dots,T$ , consider the following setting, which we refer to as the multiobjective online optimization problem: ", "page_idx": 14}, {"type": "text", "text": "1. The adversary selects a continuous, $d_{\\cdot}$ -dimensional loss function $r_{t}:A_{t}\\times\\mathcal{Z}_{t}\\to[-1,1]^{d}$ . Each   \ncomponent $r_{t}^{j}:\\mathcal{A}_{t}\\times\\mathcal{Z}_{t}\\rightarrow[-1,1]$ is convex in $\\boldsymbol{\\mathcal{A}}_{t}$ and concave in $\\mathcal{Z}_{t}$ .   \n2. The learner selects an action $a_{t}\\in\\mathcal A_{t}$ .   \n3. Nature observes the learner\u2019s action $a_{t}$ and responds with $z_{t}\\in\\mathcal{Z}_{t}$ .   \n4. The learner incurs the $d$ -dimensional loss $r_{t}(a_{t},z_{t})$ . ", "page_idx": 14}, {"type": "text", "text": "In this setting, the learner\u2019s goal is to minimize the value of the maximum dimension of the accumulated loss vector after $T$ rounds: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{j\\in[d]}\\sum_{t=1}^{T}r_{t}^{j}\\big(a_{t},z_{t}\\big).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To benchmark the learner\u2019s performance, we consider the following quantity, which we refer to as the adversary-moves-first (AMF) value at round $t$ . ", "page_idx": 14}, {"type": "text", "text": "Definition B.1 (Adversary-Moves-First (AMF) Value at Round $t,[\\mathrm{Lee}{+22}]$ ). The adversary-movesfirst (AMF) value at round $t$ is the value: ", "page_idx": 14}, {"type": "equation", "text": "$$\nv_{t}^{A}:=\\operatorname*{max}_{z_{t}\\in\\mathcal{Z}_{t}}\\operatorname*{min}_{a_{t}\\in A_{t}}\\left(\\operatorname*{max}_{j\\in[d]}r_{t}^{j}(a_{t},z_{t})\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We conceive of the value $v_{t}^{A}$ in (6) as the aspirational smallest value of the maximium coordinate of $r_{t}$ the learner could guarantee $i f$ the adversary had to reveal $z_{t}$ first and the learner could best respond with $a_{t}$ . Per how the multiobjective online optimization problem is set up, however, the opposite is true \u2014 the learner must commit to an action $a_{t}\\in\\mathcal A_{t}$ first, and then the adversary is allowed to play $z_{t}\\,\\in\\,\\mathcal{Z}_{t}$ in response to maximize the learner\u2019s misfortune. Regardless, we can define a notion of regret with respect to this particular benchmark. ", "page_idx": 14}, {"type": "text", "text": "Definition B.2 (Adversary-Moves-First (AMF) Regret). Over $T$ rounds of the above multiobjective online optimization problem, the adversary-moves-first regret of the learner is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{AMFReg}_{T}:=\\operatorname*{max}_{j\\in[d]}\\left(\\sum_{t=1}^{T}r_{t}^{j}(a_{t},z_{t})-v_{t}^{A}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This notion measures the cumulative regret the learner has for not playing the action $a_{t}\\ \\in\\ A_{t}$ achieving the aspirational value $v_{t}^{A}$ at round $t$ over all $d$ coordinates of the loss vector. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 2 AMF Algorithm of $[\\mathrm{Lee}{+22}]$ ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1: for $t=1,2,3,\\dots,T$ do   \n2: Receive adversarially chosen action spaces $A_{t}$ and $\\mathcal{Z}_{t}$ and the $d$ -dimensional loss function $r_{t}:\\mathcal{A}_{t}\\times\\mathcal{Z}_{t}\\to[-1,1]^{d}$ .   \n3: Let ", "page_idx": 15}, {"type": "equation", "text": "$$\nq_{t}^{j}:=\\frac{\\exp\\left(\\eta\\sum_{s=1}^{t-1}r_{s}^{j}(a_{s},z_{s})\\right)}{\\sum_{i\\in[d]}\\exp\\left(\\eta\\sum_{s=1}^{t-1}r_{s}^{i}(a_{s},z_{s})\\right)}\\;\\;\\mathrm{for}\\;j\\in[d].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For $t=1$ , let $q_{t}^{j}=1/d$ for all $j\\in[d]$ . 4: Solve the min-max optimization problem: ", "page_idx": 15}, {"type": "equation", "text": "$$\na_{t}\\in\\arg\\operatorname*{min}_{a\\in A_{t}}\\operatorname*{max}_{z\\in{\\mathcal{Z}}_{t}}\\sum_{j\\in[d]}q_{t}^{j}r_{t}^{j}(a,z).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "5: Commit to the action $a_{t}\\in\\mathcal A_{t}$ , observe Nature\u2019s choice $z_{t}\\in\\mathcal{Z}_{t}$ , and incur loss $r_{t}(a_{t},z_{t})$ .   \n6: end for ", "page_idx": 15}, {"type": "text", "text": "A natural question, then, is to wonder if such a regret can be made to diminish sublinearly. That is, does there exist an algorithm such that $\\mathrm{AMFReg}_{T}\\leq o(T)?$ [Lee+22] answer this in the affirmative, presenting Algorithm 2. ", "page_idx": 15}, {"type": "text", "text": "It is not immediately clear at first glance how Algorithm 2 translates to our multi-group online learning setting. In the next section, we will show a reduction from our setting to the this AMF framework. We will specialize Algorithm 2 to our setting and prove a \u201cmeta-theorem\u201d similar to the original guarantee of Algorithm 2 and proceed to control the regret via that meta-theorem in subsequent sections. ", "page_idx": 15}, {"type": "text", "text": "B.2 Reduction of multi-group online learning to AMF Framework ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Recall that, in this paper, we actually care about the online multi-group learning setting described in Section 2.2. We restate the objective here for convenience. ", "page_idx": 15}, {"type": "text", "text": "In multi-group online learning, the learner has access to a hypothesis class $\\mathcal{H}$ taking contexts from $\\mathcal{X}$ and outputting actions in $\\boldsymbol{\\wp}$ , a common action space for the learner and Nature. There is a common loss function for the problem, $\\ell(\\cdot,\\cdot):\\mathcal{V}\\times\\mathcal{V}\\rightarrow[0,1]$ . To allay confusion, we refer to the adversary in the multi-group online setting of Section 2.2 as \u201cNature\u201d and the adversary in the online multiobjective optimization problem of Section B.1 as \u201cthe adversary.\u201d The learners in both settings correspond to one another, so we just use \u201cthe learner.\u201d For clarity of exposition, we let ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ be a binary action space for the remainder of Appendix B. The generalization to the case where $\\boldsymbol{\\wp}$ takes $K$ discrete values is sketched in Appendix C. ", "page_idx": 15}, {"type": "text", "text": "We consider the regret of the learner on subsequences of rounds $(t\\in[T]:x_{t}\\in g)$ defined by the groups $g\\in{\\mathcal{G}}$ and the sequence of contexts $x_{1},\\ldots,x_{T}$ . Specifically, the (multi-group) regret of the learner on group $g$ is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}(\\mathcal{H},g):=\\sum_{t=1}^{T}g(x_{t})\\ell(\\hat{y}_{t},y_{t})-\\operatorname*{min}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}g(x_{t})\\ell(h(x_{t}),y_{t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Crucially, the best hypothesis for one group may differ from that of another group. The learner seeks to achieve achieve sublinear expected regret, on all groups $g\\in{\\mathcal{G}}$ simultaneously. ", "page_idx": 15}, {"type": "text", "text": "We now show a reduction from the multi-group online learning setting to the general multiobjective online optimization problem of the previous Section B.1. An important observation is that, when ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ , varying $h_{t}\\in\\mathcal{H}$ only affects the regret at round $t\\in[T]$ insofar as its behavior on $x_{t}$ . That is, for a fixed $x_{t}\\in\\mathscr{X}$ and $y\\in\\mathcal{V}$ , $\\ell(h_{t}(x_{t}),y)\\in\\{\\ell(-1,y),\\ell(\\dot{1},\\dot{y})\\}$ . Note that it is possible for the set $\\{h(x_{t}):h\\in\\mathcal{H}\\}\\subseteq\\mathcal{V}$ to be a singleton set, in which case the learner will always take this unique action. ", "page_idx": 15}, {"type": "text", "text": "\u2022 Let $\\boldsymbol{A}_{t}$ , the learner\u2019s action space for round $t\\in[T]$ in Section B.1, be the simplex $\\Delta(\\mathcal{Y})$ . ", "page_idx": 15}, {"type": "text", "text": "\u2022 Let $\\mathcal{Z}_{t}$ , the adversary\u2019s action space in Section B.1, be $\\mathcal{Z}_{t}=[0,1]$ for all $t\\in[T]$ , which will correspond to the parameter of a Bernoulli distribution over the binary-valued action space $\\boldsymbol{\\wp}$ of Nature in the multi-group online learning problem. \u2022 Let $r_{t}:\\mathcal{A}_{t}\\times\\mathcal{Z}_{t}\\to[-1,1]^{d}$ , the adversarially chosen loss function, be ${\\mathcal{G}}\\times{\\mathcal{H}}$ -dimensional, with each coordinate corresponding to a pair $(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}$ . Consider any $p,\\gamma\\in[0,1]$ , each determining a Bernoulli distribution over ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ . As in Section 4.2, for any $x\\in\\mathscr{X}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\tilde{\\ell}_{x}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)):=\\tilde{g}(x)\\left(\\ell(y^{\\prime},y)-\\ell(\\tilde{h}(x),y)\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then, define: ", "page_idx": 16}, {"type": "equation", "text": "$$\nr_{t}^{(\\tilde{g},\\tilde{h})}(p,\\gamma):=\\mathbb{E}_{y^{\\prime}\\sim p}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Above, the loss $\\ell(\\cdot,\\cdot)$ is the fixed loss of the multi-group online learning problem, and $x_{t}\\in\\mathcal{X}$ is the context chosen by Nature at round $t$ , which indexes $r_{t}$ . ", "page_idx": 16}, {"type": "text", "text": "It may now be slightly clearer how Algorithm 1 maps to Algorithm 2, but we provide a high-level overview here to prepare the reader for the subsequent sections. ", "page_idx": 16}, {"type": "text", "text": "\u2022 The distribution $q_{t}\\,\\in\\,\\Delta[d]$ in Line 3 of Algorithm 2 corresponds to the implicit distribution formed by querying $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ $M$ times to generate $\\{(\\tilde{g}_{i},\\tilde{h}_{i})\\}_{i=1}^{M}$ , i.e. the $(\\mathcal{G},\\mathcal{H})$ -player. \u2022 Solving the min-max optimization problem in Line 4, Equation (7) of Algorithm 2 corresponds to the two calls to the simple optimization problem solved by the $\\mathcal{H}$ -player and solving the simple one-dimensional linear program in Line 8 of Algorithm 1. ", "page_idx": 16}, {"type": "text", "text": "We make these correspondences formal in the subsequent sections. To organize this, we first formally show the correspondence between the $(\\mathcal{G},\\mathcal{H})$ -player and the construction of $q_{t}$ , and the $\\mathcal{H}$ -player and Equation (7) in Algorithm 2. ", "page_idx": 16}, {"type": "text", "text": "B.3 Instantiations of the $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ oracle ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The computational primitive our algorithm assumes access to is a $(\\mathcal{G},\\mathcal{H})$ -optimization oracle, defined in Definition 2.2, and requoted here for ease of reference. ", "page_idx": 16}, {"type": "text", "text": "Definition B.3 $\\left(\\mathcal{G},\\mathcal{H}\\right)$ -optimization oracle). Fix an error parameter $\\alpha\\,\\geq\\,0$ . For a collection of groups $\\mathcal{G}\\,\\in\\,2^{\\mathcal{X}}$ , a collection of hypotheses $\\mathcal{H}\\subseteq\\,\\mathcal{V}^{\\mathcal{X}}$ , and a sequence of m loss functions $\\bar{\\ell_{i}}:(\\{0,1\\}\\times\\mathcal{Y})\\times(\\mathcal{Y}\\times\\mathcal{Y})\\rightarrow[-1,1]$ , an $\\alpha$ -approximate $(\\mathcal{G},\\mathcal{H})$ -optimization oracle $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ is an $\\alpha$ -approximation optimization oracle (Definition 2.1) that outputs a pair $(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}$ satisfying: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}w_{i}\\ell_{i}((\\tilde{g}(x_{i}),\\tilde{h}(x_{i})),(y_{i},y_{i}^{\\prime}))\\geq\\operatorname*{sup}_{(g^{*},h^{*})\\in\\mathcal{Q}\\times\\mathcal{H}}\\sum_{i=1}^{m}w_{i}\\ell_{i}((g^{*}(x_{i}),h^{*}(x_{i})),(y_{i},y_{i}^{\\prime}))-\\alpha.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "A common assumption in the literature on oracle-efficient online learning is positing the existence of some reasonable optimization oracle, typically commensurate to the ability to solve ERM. Although it is well-known that ERM is computationally hard in the worst-case, a bedrock of modern machine learning is the assumption that ERM is at least heuristically and approximately solvable. Although, for the purposes of our work, we assume access to this oracle as a black-box, it is natural to wonder if such an oracle can be instantiated. [GKR22] gives two such instantiations which we quote here for completeness. ", "page_idx": 16}, {"type": "text", "text": "We consider the specific instantiation of the $(\\mathcal{G},\\mathcal{H})$ -oracle in Algorithm 1 for a specific round $t\\in[T]$ , which aims to solve the following optimization problem for some $(\\tilde{g}_{t},\\tilde{h}_{t})\\in\\mathcal{G}\\times\\mathcal{H}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{s=1}^{t-1}\\tilde{g}_{t}(x_{s})\\left(\\ell(\\hat{y}_{s},y_{s})-\\ell(\\tilde{h}_{t}(x_{s}),y_{s})\\right)\\geq\\mathrm{OPT}-\\alpha,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{OPT}:=\\operatorname*{sup}_{g^{*},h^{*}\\in(\\mathcal{G},\\mathcal{H})}\\sum_{s=1}^{t-1}g^{*}(x_{s})\\,\\big(\\ell\\big(\\hat{y}_{s},y_{s}\\big)-\\ell\\big(h_{t}^{*}(x_{s}),y_{s}\\big)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In both instantiations of the oracle in [GKR22], the oracle aims to find a $(g,h)\\in(\\mathcal{G},\\mathcal{H})$ competitive to some reference model, $f:\\mathcal{X}\\to\\{0,1\\}$ . For simplicity, as in the main body, we assume that ", "page_idx": 16}, {"type": "text", "text": "${\\mathcal{D}}=\\{0,1\\}$ , and the \u201creference model\u201d we compete with is given by the Learner\u2019s history of actions up to round $t$ : $(x_{1},\\hat{y}_{1}),\\dots,(x_{t-1},\\hat{y}_{t-1})$ . That is, we compare with the function $f:\\mathcal{X}\\overset{}{\\rightarrow}\\{0,1\\}$ that maps $f(x_{s})=\\hat{y}_{s}$ for all $s=1,\\ldots,t-1$ . ", "page_idx": 17}, {"type": "text", "text": "Reduction to ternary classification. The first instantiation of a $(\\mathcal{G},\\mathcal{H})$ oracle in [GKR22] reduces the optimization oracle to the existence of a solver for a weighted ternary classification problem. The exposition here is quoted directly from [GKR22]. ", "page_idx": 17}, {"type": "text", "text": "Start with a class $\\kappa$ of ternary valued functions $p:\\mathcal{X}\\to\\{0,1,?\\}$ . For each $p\\in\\mathcal K$ , define the $p$ -derived group and $p$ -derived hypothesis as: ", "page_idx": 17}, {"type": "equation", "text": "$$\ng_{p}(x)={\\left\\{\\begin{array}{l l}{1}&{{\\mathrm{if~}}p(x)\\in\\{0,1\\}}\\\\ {0}&{{\\mathrm{if~}}p(x)=?}\\end{array}\\right.}\\quad h_{p}(x)={\\left\\{\\begin{array}{l l}{p(x)}&{{\\mathrm{if~}}p(x)\\in\\{0,1\\}}\\\\ {0}&{{\\mathrm{if~}}p(x)=?}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This class $\\kappa$ induces a set of pairs $(g_{p},h_{p})$ and a product class $(\\mathcal G,\\mathcal H)_{K}:=\\{(g_{p},h_{p}):p\\in K\\}$ . We may now define a cost-sensitive classification problem over $\\kappa$ as follows, given an existing model $f:{\\dot{\\boldsymbol{x}}}\\to\\{0,1\\}$ , with the following costs: ", "page_idx": 17}, {"type": "equation", "text": "$$\nc_{f}((x,y),z):=\\left\\{{\\begin{array}{l l}{0}&{{\\mathrm{if~}}z=!}\\\\ {1}&{{\\mathrm{if~}}f(x)=y\\neq z}\\\\ {-1}&{{\\mathrm{if~}}z=y\\neq f(x)}\\\\ {0}&{{\\mathrm{otherwise}}}\\end{array}}\\right..\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For any distribution $\\mu$ over ${\\mathcal{X}}\\times\\{0,1\\}$ , the associated cost-sensitive classification problem for costs $c_{f}((x,\\dot{y}),z)$ defined above is: ", "page_idx": 17}, {"type": "equation", "text": "$$\np^{*}\\in\\underset{p\\in\\mathcal{K}}{\\arg\\operatorname*{min}}\\,\\mathbb{E}_{(x,y)\\sim\\mu}[c_{f}((x,y),p(x))].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Many efficient algorithms that heuristically solve such optimization problems exist. ", "page_idx": 17}, {"type": "text", "text": "The main theorem from [GKR22], restated here, is the following: ", "page_idx": 17}, {"type": "text", "text": "Theorem B.1. Fix any arbitrary distribution $\\mu$ over ${\\mathcal{X}}\\times\\{0,1\\}$ . Let $\\kappa$ be a class of ternary-valued functions $p:\\mathcal{X}\\to\\{0,1,?\\}$ and let $f:\\mathcal{X}\\to\\{0,1\\}$ be any binary-valued model. Let $p^{*}$ be the solution to the cost-sensitive classification problem in Equation (12). Then, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left(g_{p}^{*},h_{p}^{*}\\right)\\in\\underset{(g,h)\\in(\\mathcal{G},\\mathcal{H})\\kappa}{\\arg\\operatorname*{max}}\\mathbb{E}_{(x,y)\\sim\\mu}\\left[g(x)\\left(\\ell(f(x),y)-\\ell(h(x),y)\\right)\\right].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "When $\\mu$ is the empirical distribution over $x_{1},\\ldots,x_{t-1}$ , the solution $(g_{p}^{*},h_{p}^{*})$ forms a solution to the optimization problem in Equation (11) when $(\\mathcal{G},\\mathcal{H})_{\\mathcal{K}}=\\mathcal{G}\\times\\mathcal{H}$ . ", "page_idx": 17}, {"type": "text", "text": "We refer the reader to Section 4.2 in [GKR22] for a proof. ", "page_idx": 17}, {"type": "text", "text": "Reduction to alternating maximization. Another instantiation of the $(\\mathcal{G},\\mathcal{H})$ -oracle in [GKR22] is an alternating maximization approach. The reduction to ternary classification quoted above relies on an oracle for the class $\\kappa$ and supplies guarantees for the derived class $(\\mathcal{G},\\mathcal{H})_{\\mathcal{K}}$ . However, if we wish to begin with ${\\mathcal{G}}\\times{\\mathcal{H}}$ , we can take an \u201cEM-style\u201d alternating maximization approach that only requires ERM oracles for $\\mathcal{G}$ and $\\mathcal{H}$ separately. This approach only guarantees a saddle point local optimum. ", "page_idx": 17}, {"type": "text", "text": "The main idea is that, by holding $g$ fixed and solving for $h^{*}$ , and vice versa, the following optimization problems are no harder than ERM over $\\mathcal{G}$ and $\\mathcal{H}$ individually: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{g^{*}\\in\\underset{g^{*}\\in\\mathcal{G}}{\\arg\\operatorname*{max}}\\,\\mathbb{E}_{(x,y)\\sim\\mu}[g^{*}(x)\\left(\\ell(f(x),y)-\\ell(h(x),y)\\right)]}\\\\ {h^{*}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{max}}\\,\\mathbb{E}_{(x,y)\\sim\\mu}[g(x)\\left(\\ell(f(x),y)-\\ell(h^{*}(x),y)\\right)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In Equation (13), $h$ is fixed and we solve for $g^{\\ast}$ ; in Equation (14), $g$ is fixed, and we solve for $h^{*}$ . With appropriate modifications to the distribution $\\mu$ we can construct ERM problems for $g^{*}$ and $h^{*}$ comensurate to solving Equations (13) and (14). We refer the reader to Lemmas 21 and 22 in [GKR22] for the proofs. ", "page_idx": 17}, {"type": "text", "text": "This allows us to state an alternating maximization algorithm for finding a saddle point $(g,h)\\in\\mathcal{G}\\!\\times\\!\\mathcal{H}$ that gives a local optimum to Equation (11) in Algorithm 3. The corresponding theorem, restated from [GKR22] is: ", "page_idx": 17}, {"type": "text", "text": "Theorem B.2. Let $\\epsilon>0$ . Fix any empirical distribution over $(x_{1},y_{1}),\\dotsc,(x_{m},y_{m}),$ , let $f:\\mathcal X\\to$ $\\{0,1\\}$ be an arbitrary model, and let $\\mathcal{G}$ and $\\mathcal{H}$ be arbitrary group and hypothesis classes. After solving at most $2/\\epsilon$ ERM problems over each of $\\mathcal{G}$ and $\\mathcal{H}$ (in Equations (13) and (14), respectively), Algorithm 3 returns a pair $(g^{*},h^{*})$ with the properties that: ", "page_idx": 18}, {"type": "text", "text": "1. For every $h\\in\\mathcal H$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}g^{*}(x_{i})\\left(\\ell(f(x_{i}),y_{i})-\\ell(h(x_{i}),y_{i})\\right)\\leq\\sum_{i=1}^{m}g^{*}(x_{i})\\left(\\ell(f(x_{i}),y_{i})-\\ell(h^{*}(x_{i}),y_{i})\\right)+\\epsilon.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "2. For every $g\\in{\\mathcal{G}}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}g(x_{i})\\left(\\ell(f(x_{i}),y_{i})-\\ell(h^{*}(x_{i}),y_{i})\\right)\\leq\\sum_{i=1}^{m}g^{*}(x_{i})\\left(\\ell(f(x_{i}),y_{i})-\\ell(h^{*}(x_{i}),y_{i})\\right)+\\epsilon.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Algorithm 3 Alternating Maximization for ${\\mathcal{G}}\\times{\\mathcal{H}}$ Oracle ", "page_idx": 18}, {"type": "text", "text": "Input: Dataset $\\{(x_{i},y_{i})\\}_{i=1}^{m}$ , a model $f:\\mathcal{X}\\to\\{0,1\\}$ , error parameter $\\epsilon$ . 1: Initialize $(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}$ arbitrarily.   \n2: Let ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{VAL}:=\\sum_{i=1}^{m}g^{*}(x_{i})\\left(\\ell(f(x_{i}),y_{i})\\right)-\\ell(h^{*}(x_{i}),y_{i}))\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "3: Use ERM oracle for Equations (13) and (14) to solve for: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\boldsymbol{g}^{*}\\in\\underset{g\\in\\mathcal{G}}{\\arg\\operatorname*{max}}\\sum_{i=1}^{m}\\boldsymbol{g}(\\boldsymbol{x})\\left(\\ell(f(\\boldsymbol{x}),\\boldsymbol{y})-\\ell(h^{*}(\\boldsymbol{x}),\\boldsymbol{y})\\right)}\\\\ &{h^{*}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{max}}\\sum_{i=1}^{m}\\boldsymbol{g}^{*}(\\boldsymbol{x})\\left(\\ell(f(\\boldsymbol{x}),\\boldsymbol{y})-\\ell(h(\\boldsymbol{x}),\\boldsymbol{y})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "4: while $\\begin{array}{r}{\\sum_{i=1}^{m}g^{*}(x)\\left(\\ell(f(x),y)-\\ell(h^{*}(x),y)\\right)\\ge\\mathrm{VAL}+\\epsilon\\,\\mathbf{do}}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "5: Let ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{VAL}:=\\sum_{i=1}^{m}g^{*}(x_{i})\\left(\\ell(f(x_{i}),y_{i})\\right)-\\ell(h^{*}(x_{i}),y_{i}))\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "6: Use ERM oracle for Equations (13) and (14) to solve for: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\boldsymbol{g}^{*}\\in\\underset{g\\in\\mathcal{G}}{\\arg\\operatorname*{max}}\\sum_{i=1}^{m}\\boldsymbol{g}(\\boldsymbol{x})\\left(\\ell(f(\\boldsymbol{x}),\\boldsymbol{y})-\\ell(h^{*}(\\boldsymbol{x}),\\boldsymbol{y})\\right)}\\\\ &{h^{*}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{max}}\\sum_{i=1}^{m}\\boldsymbol{g}^{*}(\\boldsymbol{x})\\left(\\ell(f(\\boldsymbol{x}),\\boldsymbol{y})-\\ell(h(\\boldsymbol{x}),\\boldsymbol{y})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "7: end while ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "8: Return $(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}$ . ", "page_idx": 18}, {"type": "text", "text": "We believe that it is an interesting and worthwhile open question to develop more specific instantiations of this $(\\mathcal{G},\\mathcal{H})$ -oracle for more specific problem settings that are computationally efficient and have provable optimization guarantees. ", "page_idx": 18}, {"type": "text", "text": "B.4 The group-hypothesis and hypothesis players ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We formally define how the $(\\mathcal{G},\\mathcal{H})$ -player corresponds to the weights $q_{t}\\in\\Delta[d]$ in Algorithm 2. The crucial observation here is that the perturbations of the FTPL algorithm of $[\\mathrm{Blo}{+}22]$ used in our setting form an implicit distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ that can be approximated by calling the $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ oracle $M$ times. ", "page_idx": 18}, {"type": "text", "text": "In the proceeding sections, we denote $\\Delta(\\mathcal{G}\\times\\mathcal{H})$ as the (possibly infinite-dimensional) space of measures over the functions ${\\mathcal{G}}\\times{\\mathcal{H}}$ . However, we will always only access sparse distributions on this space, with a finite number of $(g,h)$ pairs in $\\mathcal G\\times\\mathcal H$ obtaining nonzero mass. The following definition should make this clear. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Definition B.4 (The distribution of the $(\\mathcal{G},\\mathcal{H})$ -player). For any round $t\\,\\in\\,[T]_{*}$ , let $\\{(\\tilde{g}_{i},\\tilde{h}_{i})\\}_{i=1}^{M}$ be the $M$ samples drawn from querying $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ in Algorithm $^{\\,l}$ . Let the empirical distribution $\\tilde{q}_{t}\\in\\Delta(\\mathcal{G}\\times\\mathcal{H})$ be the distribution of the $(\\mathcal{G},\\mathcal{H})$ -player at round $t$ . ", "page_idx": 19}, {"type": "text", "text": "It is easy to see that ${\\tilde{q}}_{t}$ is a valid distribution over $(\\mathcal{G},\\mathcal{H})$ , with measure over $A\\subseteq{\\mathcal{G}}\\times{\\mathcal{H}}$ , defined by: ", "page_idx": 19}, {"type": "equation", "text": "$$\nP_{M}(A):=\\frac{1}{M}\\sum_{i=1}^{M}\\delta_{(\\tilde{g}_{i},\\tilde{h}_{i})}(A),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\delta_{(\\tilde{g}_{i},\\tilde{h}_{i})}$ is the Dirac measure of $(\\tilde{g}_{i},\\tilde{h}_{i})$ falling into the set $A$ . The stochasticity of $(\\tilde{g}_{i},\\tilde{h}_{i})$ is over the random perturbations described in Section 4.2, Equation (4). Equipped with this definition, we can take empirical expectations over $\\tilde{q}_{t}\\in\\Delta(\\mathcal{G}\\times\\mathcal{H})$ in the usual way. Observe that, in Algorithm 2, Equation (7), the optimization problem at round $t$ , is equivalent to: ", "page_idx": 19}, {"type": "equation", "text": "$$\na_{t}\\in\\underset{a\\in\\mathcal{A}}{\\arg\\operatorname*{min}}\\operatorname*{max}_{z\\in\\mathcal{Z}}\\mathbb{E}_{j\\sim q_{t}}\\left[r_{t}^{j}(a,z)\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Because the $d$ objectives in our reduction (Section B.2) correspond to each group-hypothesis pair $(g,h)\\in\\mathcal{G}\\times\\mathcal{H},$ $A_{t}$ corresponds to $\\Delta(\\mathcal{Y})$ , and $\\mathcal{Z}_{t}$ always corresponds to $[0,1]$ , we can equivalently consider the min-max optimization problem at round $t\\in[T]$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\np_{t}\\in\\underset{p\\in\\Delta(\\mathcal{Y})}{\\arg\\operatorname*{min}}\\,\\operatorname*{max}_{\\gamma\\in[0,1]}\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}\\left[r_{t}^{(\\tilde{g},\\tilde{h})}(p,\\gamma)\\right],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where rt(g\u02dc,\u02dch)is defined in Equation 9. The next lemma relates the optimization procedure of the $\\mathcal{H}$ -player in Algorithm 1 to the min-max optimization procedure of Equation (7) in Algorithm 2. ", "page_idx": 19}, {"type": "text", "text": "Lemma B.3 (The optimization of the $\\mathcal{H}$ -player). For any round $t\\in[T]$ , let $\\{(\\tilde{g}_{i},\\tilde{h}_{i})\\}_{i=1}^{M}$ denote the $M$ samples obtained by calling $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}\\ .$ $M$ times in Algorithm $^{\\,l}$ , and denote $\\tilde{q}_{t}\\in\\Delta(\\mathcal{G}\\times\\mathcal{H})$ denote the corresponding empirical distribution (Definition B.4). Then, $p_{t}\\;\\in\\;\\Delta(\\mathcal{D})$ defined in Equation (15) above is equivalent to the distribution $(p,1-p)\\in\\Delta(\\{-1,1\\})$ obtained from solving the linear program of the $\\mathcal{H}$ -player in Algorithm $^{\\,I}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. Consider any round $t\\in[T]$ . Observe that Line 8 of Algorithm 1 is equivalent to solving the linear program for $\\lambda\\in\\mathbb{R}$ and $\\pmb{p}:=(p,1-p)\\in\\mathbb{R}^{2}$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{min}_{\\mathbf{\\epsilon}{\\lambda}}~\\lambda}\\\\ &{\\mathrm{~s.t.~}\\sum_{p^{\\intercal}\\tilde{L}e_{i}\\leq\\lambda}p_{i}=1}\\\\ &{\\qquad p^{\\intercal}\\tilde{L}e_{i}\\leq\\lambda\\quad\\forall i\\in[2]}\\\\ &{\\qquad p_{i}\\geq0\\quad\\forall i\\in[2]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the payoff matrix $\\tilde{L}\\in[-1,1]^{2\\times2}$ has the coordinates $(y^{\\prime},y)$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tilde{L}_{(y^{\\prime},y)}:=\\frac{1}{M}\\sum_{i=1}^{M}\\tilde{\\ell}_{x_{t}}\\big((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(y^{\\prime},y)\\big),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and $e_{i}$ is the $i$ th coordinate vector of $\\mathbb{R}^{2}$ . Let $\\Delta(\\mathcal{Y})$ denote the space of probability distributions over $\\boldsymbol{\\wp}$ . Let $\\pmb{p}=(p,1-p)$ and $z=(\\gamma,1-\\gamma)$ , and, as shorthand, denote $p(-1)=1-p,p(1)=p$ , $z(-1)=1-\\gamma$ , and $z(1)=\\gamma$ . ", "page_idx": 19}, {"type": "text", "text": "By the equivalence of linear programs (LPs) to zero-sum min-max games (see, e.g., [BT97; Haz22]), obtaining the optimal $\\textbf{\\emph{p}}$ for this LP is the equivalent to solving: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{p\\in\\Delta(\\mathcal{Y})}{\\operatorname*{min}}\\quad\\underset{z\\in\\Delta(\\mathcal{Y})}{\\operatorname*{max}}\\ p^{\\top}\\bar{L}z=\\underset{p\\in\\Delta(\\mathcal{Y})}{\\operatorname*{min}}\\ \\underset{z\\in\\Delta(\\mathcal{Y})}{\\operatorname*{max}}\\ \\frac{1}{M}\\underset{y\\in\\mathcal{Y}}{\\sum}\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\sum}p(y^{\\prime})z(y)\\tilde{\\varepsilon}_{\\varepsilon}((\\tilde{g}_{t}^{i},\\tilde{h}_{t}^{(i)}),(y^{\\prime},y))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\operatorname*{min}\\quad\\underset{y\\in\\Delta(\\mathcal{Y})}{\\operatorname*{max}}\\ \\underset{y^{\\prime}\\in\\mathcal{Y}}{\\sum}p(y^{\\prime})z(y)\\mathbb{E}_{(\\tilde{g}_{t}^{i},\\tilde{h})\\sim\\tilde{q}_{t}}\\ \\Big[\\tilde{\\varepsilon}_{\\varepsilon}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))\\Big]}\\\\ &{=\\underset{p\\in\\Delta(\\mathcal{Y})}{\\operatorname*{min}}\\ \\underset{z\\in\\Delta(\\mathcal{Y})}{\\operatorname*{max}}\\ \\frac{\\mathbb{E}_{y^{\\prime}\\sim\\rho}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}}{y^{\\prime}\\sim\\rho}\\left[\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}\\left[\\tilde{\\varepsilon}_{\\varepsilon}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)\\right]\\right]}\\\\ &{=\\underset{p\\in\\Delta(\\mathcal{Y})}{\\operatorname*{min}}\\ \\underset{\\gamma\\in\\mathrm{[0,1]}}{\\operatorname*{max}}\\ \\mathbb{E}_{y^{\\prime}\\sim\\mathrm{Ber}(p)}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}\\left[\\tilde{\\varepsilon}_{\\varepsilon}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)\\right]\\right]}\\\\ &{=\\underset{p\\in\\Delta(\\mathcal{Y})}{\\operatorname*{min}}\\ \\underset{\\gamma\\in\\mathrm{[0,1]}}{\\operatorname*{max}}\\ \\mathbb{E}_{(\\tilde{g}_{t}^{i},\\tilde{h})\\sim\\tilde{q}_{t}}\\left[r(\\tilde{\\varepsilon}_{t}^{\\tilde{g},\\tilde{h}})(p,\\gamma\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Above, the first equality just comes from definition of $\\tilde{L}$ , the second equality is from the Definition B.4 of the empirical distribution ${\\tilde{q}}_{t}$ , the third and fourth equalities are from the definition of $\\pmb{p}$ and $_{z}$ in the previous paragraph. The final equality is just from interchanging the order of expectation and the definition of rt(g\u02dc, $r_{t}^{(\\tilde{g},\\tilde{h})}(p,\\gamma)$ in Equation (9). By this chain of inequalities, we see that obtaining the optimal $\\textbf{\\emph{p}}$ for the original LP corresponds exactly to the choice of $p_{t}$ in Equation (15). \u53e3 ", "page_idx": 20}, {"type": "text", "text": "Lemma B.3 tells us that the strategy of the $\\mathcal{H}$ -player (i.e., Lines 8 and 9 in Algorithm 1) to obtain $h_{t}$ is exactly the same as obtaining the minimizing $p_{t}$ in Equation (15). From the exposition above, this corresponds to the min-max optimization problem in Equation (7) when $q_{t}$ is ${\\tilde{q}}_{t}$ , the distribution over $\\mathcal{G}\\times\\mathcal{H}$ . We now proceed to prove a more general \u201cmeta-theorem\u201d from which the regret guarantee of Algorithm 1 will follow once we plug in a specific FTPL algorithm for the $(\\mathcal{G},\\mathcal{H})$ -player. ", "page_idx": 20}, {"type": "text", "text": "B.5 Meta-algorithm for Online Multi-group Learning ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We now present a meta-algorithm, Algorithm 4, and its corresponding Theorem B.4, the \u201cmetatheorem\u201d for online multi-group learning from which Theorem 4.1 follows. This is more general, however, than the guarantee in Theorem 4.1, and we emphasize that, through changing the no-regret algorithm for the $(\\mathcal{G},\\mathcal{H})$ -player, we can obtain regret guarantees for settings other than the smoothed online learning setting of Theorem 4.1. Section 5 gives a couple of examples, which we elaborate in Appendix C. ", "page_idx": 20}, {"type": "text", "text": "Note that approximating the distribution of the $(\\mathcal{G},\\mathcal{H})$ -player is crucial to obtain computational efficiency, as we cannot hope to enumerate $\\mathcal{G}$ and $\\mathcal{H}$ by explicitly representing $q_{t}$ in Algorithm 4. Thus, sampling $M$ times is a crucial \u201csparsification\u201d step that allows us to implicitly access the distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ that the $(\\mathcal{G},\\mathcal{H})$ -player maintains. ", "page_idx": 20}, {"type": "text", "text": "We prove Theorem B.4 through techniques similar to the regret guarantee proof of Algorithm 2 in $[\\mathrm{Lee}{+22}]$ . Namely, we observe that by using the reduction outlined in Section B.2 with the ${\\mathcal{G}}\\times{\\mathcal{H}}$ -dimensional loss ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{t}^{(\\tilde{g},\\tilde{h})}(p,\\gamma)=\\mathbb{E}_{h(x_{t})\\sim p}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}(x_{t})\\left(\\ell(h(x_{t}),y)-\\ell(\\tilde{h}(x_{t}),y)\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}_{h(x_{t})\\sim p}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{\\ell}\\left((\\tilde{g},\\tilde{h}),(h(x_{t}),y)\\right)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "we may obtain a bound on the multi-group regret of our Algorithm 4 by obtaining an adversarymoves-first regret guarantee (Definition B.2). For simplicity, we prove this for the case of binary actions ${\\boldsymbol{\\mathcal{V}}}=\\{-1,\\bar{1}\\}$ ; we outline how to obtain a similar theorem for multi-class action spaces in Appendix C. ", "page_idx": 20}, {"type": "text", "text": "Theorem B.4 (Meta-Theorem for Online Multi-group Learning). Let $\\mathcal{X}$ be a context space, let ${\\mathcal{V}}:=\\{-1,1\\}$ be a binary action space, and let $\\mathcal{H}$ be a hypothesis class of functions $h:\\mathcal{X}\\to\\mathcal{Y}$ , and let $\\mathcal{G}$ be a collection of groups, $g:\\mathcal{X}\\to\\{0,1\\}$ . Let $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow[0,1]$ be a bounded loss function. Suppose the $(\\mathcal{G},\\mathcal{H})$ -player of Algorithm $^{4}$ is instantiated with a no-regret (maximization) algorithm operating over $\\mathcal{H}\\times\\mathcal{G}$ that has the guarantee that for any sequence of losses of length $T$ bounded in $[-1,1]$ , by playing (a possibly implicit distribution) $q_{t}$ , it has regret at most $R(T)$ in expectation. ", "page_idx": 20}, {"type": "text", "text": "Algorithm 4 Meta-algorithm for Online Multi-group Learning $(\\mathcal{Y}=\\{-1,1\\})$ ) ", "page_idx": 21}, {"type": "text", "text": "Input: $M\\in\\mathbb{N}$ , the number of samples to take from $q_{t}$ at each step. 1: for $t=1,2,3,\\dots,T$ do   \n2: Receive a context $x_{t}$ from Nature.   \n3: For any $y^{\\prime},y\\in\\mathcal{Y}$ , construct the loss: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)):=\\tilde{g}(x_{t})\\left(\\ell(y^{\\prime},y)-\\ell(\\tilde{h}(x_{t}),y)\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "4: $(\\mathcal{G},\\mathcal{H})$ -player: With access to the entire history of the past $t-1$ rounds and $x_{t}$ , with access to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ , run a no-regret algorithm over the benchmark class ${\\mathcal{G}}\\times{\\mathcal{H}}$ to output a distribution $q_{t}\\in\\Delta(\\mathcal{G}\\times\\mathcal{H})$ . ", "page_idx": 21}, {"type": "text", "text": "5: Construct an empirical approximation ${\\tilde{q}}_{t}$ of $q_{t}$ by sampling from $q_{t}~M$ times, obtaining a collection of pairs $\\{(\\widetilde{h}_{t}^{(i)},\\widetilde{g}_{t}^{(i)})\\}_{i=1}^{M}$ from ${\\mathcal{G}}\\times{\\mathcal{H}}$ . ", "page_idx": 21}, {"type": "text", "text": "6: $\\mathcal{H}$ -player: Call $\\mathrm{OPT}_{\\mathcal{H}}$ twice on the singleton datasets $\\{(x_{t},-1)\\}$ and $\\{(x_{t},1)\\}$ with the 0-1 loss, obtaining: ", "page_idx": 21}, {"type": "equation", "text": "$$\nh_{1}^{\\prime}\\in\\mathop{\\arg\\operatorname*{min}}_{h^{*}\\in\\mathcal{H}}\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq1\\right\\},\\quad h_{-1}^{\\prime}\\in\\mathop{\\arg\\operatorname*{min}}_{h^{*}\\in\\mathcal{H}}\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq-1\\right\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "7: $\\mathcal{H}$ -player: Solve the linear program ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{p,\\lambda\\in\\mathbb{R}}{\\operatorname*{min}}}&{\\lambda}\\\\ {\\mathrm{subj.to}}&{\\displaystyle\\sum_{i=1}^{M}p\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{1}^{\\prime}(x_{t}),y))+(1-p)\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{-1}^{\\prime}(x_{t}),y))\\leq\\lambda}\\\\ &{\\quad\\forall y\\in\\{-1,1\\}}\\\\ &{\\displaystyle0\\leq p\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "8: Sample $b\\sim\\mathrm{Ber}(p)$ , where $b\\in\\{-1,1\\}$ , let $h_{t}=h_{b}^{\\prime}$ . ", "page_idx": 21}, {"type": "text", "text": "9: Learner commits to the action ${\\hat{y}}_{t}=h_{t}(x_{t})$ ; Nature reveals $y_{t}$ . ", "page_idx": 21}, {"type": "text", "text": "10: Learner incurs the loss $\\ell(\\hat{y}_{t},y_{t})$ . ", "page_idx": 21}, {"type": "text", "text": "11: The $(\\mathcal{G},\\mathcal{H})$ -player draws $(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}$ and incurs the loss $\\tilde{\\ell}_{x_{t}}\\big((\\tilde{g},\\tilde{h}),(\\hat{y}_{t},y_{t})\\big)$ .   \n12: end for ", "page_idx": 21}, {"type": "text", "text": "Then, with expectation over any randomness of the $(\\mathcal{G},\\mathcal{H})$ -player and Nature, Algorithm 1 obtains the multi-group regret guarantee of: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq\\sum_{t=1}^{T}v_{t}^{A}+\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]+R(T),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for all $g\\in{\\mathcal{G}}$ , where ", "page_idx": 21}, {"type": "equation", "text": "$$\nv_{t}^{A}:=\\operatorname*{max}_{\\substack{\\gamma\\in[0,1]\\,p_{t}\\in\\Delta(\\mathcal{H})\\,(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}}}\\mathbb{E}_{h\\sim p_{t},y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}(x_{t})(\\ell(h(x_{t}),y)-\\ell(\\tilde{h}(x_{t}),y))\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and $\\epsilon_{t}(M)$ is the error incurred from estimating $q_{t}$ with ${\\tilde{q}}_{t}$ with $M$ samples at step $t\\in[T]$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. From the perspective of the $(\\mathcal{G},\\mathcal{H})$ -player, who is running a regret maximization algorithm, the following game is being played. For $t=1,2,3,\\ldots,T$ : ", "page_idx": 21}, {"type": "text", "text": "\u2022 Receive a context $x_{t}\\in\\mathscr{X}$ from Nature, possibly adversarially and depending on the past $t-1$ rounds. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Play a pair $(\\tilde{h}_{t},\\tilde{g}_{t})\\in\\mathcal{H}\\times\\mathcal{G}$ , possibly randomly and dependent on the last $t-1$ rounds, where pairs are functions ", "page_idx": 21}, {"type": "equation", "text": "$$\n(h,g):\\mathcal{X}\\to\\mathcal{Y}\\times\\{0,1\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "\u2022 Commit to the action $\\tilde{y}_{t}:=(\\tilde{h}_{t}(x_{t}),\\tilde{g}_{t}(x_{t}))\\in\\mathcal{Y}\\times\\{0,1\\}.$ . ", "page_idx": 21}, {"type": "text", "text": "\u2022 An adversary (the $\\mathcal{H}$ -player\u2019s prediction and Nature) reveals $(\\hat{y}_{t},y_{t})\\in\\mathcal{Y}\\times\\mathcal{Y}$ , and we incur the loss: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tilde{\\ell}((\\tilde{g},\\tilde{h}),(\\hat{y}_{t},y_{t})):=\\tilde{g}(x_{t})\\left(\\ell(\\hat{y}_{t},y_{t})-\\ell(\\tilde{h}_{t}(x_{t}),y_{t})\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Here, ${\\hat{y}}_{t}=h_{t}(x_{t})$ , which is a random variable depending on sampling from $p_{t}$ , the Bernoulli distribution of the $\\mathcal{H}$ -player at round $t$ . ", "page_idx": 22}, {"type": "text", "text": "Note that the $(\\mathcal{G},\\mathcal{H})$ -player is attempting to maximize this loss. ", "page_idx": 22}, {"type": "text", "text": "Let $h_{1},\\ldots,h_{T}$ be the sequence of hypotheses chosen by the $\\mathcal{H}$ -player, and let $y_{1},\\dots,y_{T}$ be the sequence of adversarially chosen outcomes. Then, by the regret guarantee of the $(\\mathcal{G},\\mathcal{H})$ -player\u2019s no-regret algorithm algorithm, for any $(h^{\\ast},g^{\\ast})\\in\\mathcal{H}\\times\\mathcal{G}$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}\\left[\\tilde{\\ell}((g^{*},h^{*}),(h_{t}(x_{t}),y_{t}))\\right]-\\sum_{t=1}^{T}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim q_{t}}\\left[\\tilde{\\ell}((\\tilde{g}_{t},\\tilde{h}_{t}),(h_{t}(x_{t}),y_{t}))\\right]\\le R(T),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the expectation is over the distributions $q_{t}$ over $\\Delta({\\mathcal{H}}\\times{\\mathcal{G}})$ that the $(\\mathcal{G},\\mathcal{H})$ -player commits to at each round and the random choices of Nature and the $\\mathcal{H}$ -player\u2019s random choice of $\\hat{y}_{t}$ at each round. To ease notation, we keep the subscript in the expectation over $h_{t}$ hidden, noting that $h_{t}(x_{t})\\sim p_{t}$ is a random variable throughout. For instance, in the case of Theorem 4.1, this is a random process determined by the $(\\mathcal{G},\\mathcal{H})$ -player sampling $n$ perturbation terms and calling the $(\\mathcal{G},\\mathcal{H})$ -oracle to obtain the random variable $(\\tilde{g}_{t},\\tilde{h}_{t})$ . Instantiating the regret bound for all $(h^{*},g^{*})$ gives us: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{h^{*},g^{*}\\}\\in\\mathcal{H}\\times\\mathcal{Q}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\widetilde{\\ell}((g^{*},h^{*}),(h_{t}(x_{t}),y_{t}))\\right]\\leq\\sum_{t=1}^{T}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim q_{t}}\\left[\\widetilde{\\ell}((\\tilde{g}_{t},\\tilde{h}_{t}),(h_{t}(x_{t}),y_{t}))\\right]+R(T).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "However, we do not have direct access to $q_{t}$ , the implicit distribution over ${\\mathcal{G}}\\times{\\mathcal{H}}$ , but we have an approximation ${\\tilde{q}}_{t}$ . In Algorithm 2, $(\\tilde{g}_{t},\\tilde{h}_{t})$ is drawn according to ${\\tilde{q}}_{t}$ , the empirical distribution over $\\Delta({\\mathcal{H}}\\times{\\mathcal{G}})$ formed by drawing $M$ samples $\\{(\\tilde{h}_{t}^{(i)},\\tilde{g}_{t}^{(i)}\\}_{i=1}^{M}$ from ${\\tilde{q}}_{t}$ . Fixing $x_{t},y_{t}$ , and $h_{t}(x_{t})$ , let $\\epsilon_{t}(M)$ be the error we incur from replacing the true distribution $q_{t}$ by the empirical distribution which we can handle through uniform convergence on the samples $\\{(\\tilde{h}_{t}^{(i)},\\tilde{g}_{t}^{(i)}\\}_{i=1}^{M}$ (see Lemma B.6): ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}[\\tilde{\\ell}((\\tilde{g},\\tilde{h}),(h_{t}(x_{t}),y_{t}))]-\\mathbb{E}_{(g,h)\\sim q_{t}}[\\tilde{\\ell}((g,h),(h_{t}(x_{t}),y_{t}))]\\right|\\le\\epsilon_{t}(M).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Adding the estimation error at each $t\\in[T]$ , our regret bound becomes: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{h^{*},g^{*}\\in\\mathcal{H}\\times\\mathcal{G}}{\\operatorname*{max}}\\underset{t=1}{\\overset{T}{\\sum}}\\mathbb{E}\\left[\\tilde{\\ell}((g^{*},h^{*}),(h_{t}(x_{t}),y_{t}))\\right]\\leq\\underset{t=1}{\\overset{T}{\\sum}}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim q_{t}}\\left[\\tilde{\\ell}((\\tilde{g}_{t},\\tilde{h}_{t}),(h_{t}(x_{t}),y_{t}))\\right]+R(T)}\\\\ &{\\qquad\\qquad\\leq\\underset{t=1}{\\overset{T}{\\sum}}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[\\tilde{\\ell}((\\tilde{g}_{t},\\tilde{h}_{t}),(h_{t}(x_{t}),y_{t}))\\right]+\\underset{t=1}{\\overset{T}{\\sum}}\\epsilon_{t}(M)+R(T).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now, we aim to bound the terms E(g\u02dct,\u02dcht)\u223cq\u02dct $\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[\\tilde{\\ell}\\big((\\tilde{g}_{t},\\tilde{h}_{t}),(h_{t}(x_{t}),y_{t})\\big)\\right]$ . At round $t\\in[T]$ , Algorithm 4 chooses the best response $h_{t}\\in\\mathcal{H}$ by solving a linear program for a Bernoulli parameter $p$ and then sampling $h$ from $\\mathrm{Ber}(p)$ . This is equivalent to sampling $h_{t}(x_{t})\\sim p_{t}$ , where $p_{t}:=(p,1-p)$ on $\\Delta(\\mathcal{Y})$ . We use sampling from this Bernoulli distribution and sampling from $p_{t}$ interchangeably. By Lemma B.3, this is equivalent to solving the min-max optimization problem in Equation (15) ", "page_idx": 22}, {"type": "equation", "text": "$$\np_{t}\\in\\underset{p\\in\\Delta(\\mathcal{Y})}{\\arg\\operatorname*{min}}\\,\\underset{\\gamma\\in[0,1]}{\\operatorname*{max}}\\,\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[r_{t}^{(\\tilde{g}_{t},\\tilde{h}_{t})}(p,\\gamma)\\right],\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which, by definition of $r_{t}^{(\\tilde{g},\\tilde{h})}(p,\\gamma)$ , is equivalent to: ", "page_idx": 22}, {"type": "equation", "text": "$$\np_{t}\\in\\underset{p_{t}\\in\\Delta(y)}{\\mathrm{arg\\,min}}\\,\\operatorname*{max}_{\\gamma\\in[0,1]}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[\\mathbb{E}_{h_{t}(x_{t})\\sim p_{t}}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}_{t}(x_{t})\\left(\\ell(h_{t}(x_{t}),y)-\\ell(\\tilde{h}_{t}(x_{t}),y)\\right)\\right)\\right]\\right].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The inner expectations are linear in $p_{t}$ and $\\gamma$ , and taking the outer expectation over ${\\tilde{q}}_{t}$ maintains linearity. Therefore, this is a convex and concave min-max optimization problem, and von Neumann\u2019s ", "page_idx": 22}, {"type": "text", "text": "minimax theorem [NMR44] applies, allowing us to swap the order of minimization and maximization. Therefore ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{p_{t}\\in\\Delta(y)}{\\operatorname*{min}}\\underset{\\gamma\\in[0,1]}{\\operatorname*{max}}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[\\mathbb{E}_{h_{t}(x_{t})\\sim p_{t}}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}_{t}(x_{t})\\left(\\ell(h_{t}(x_{t}),y)-\\ell(\\tilde{h}_{t}(x_{t}),y))\\right)\\right]\\right]}\\\\ &{=\\underset{\\gamma\\in[0,1]}{\\operatorname*{max}}\\underset{p_{t}\\in\\Delta(y)}{\\operatorname*{min}}\\mathbb{E}_{(\\tilde{g}_{t},\\tilde{h}_{t})\\sim\\tilde{q}_{t}}\\left[\\mathbb{E}_{h_{t}(x_{t})\\sim p_{t}}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}_{t}(x_{t})\\left(\\ell(h_{t}(x_{t}),y)-\\ell(\\tilde{h}_{t}(x_{t}),y))\\right)\\right)\\right]\\right]}\\\\ &{\\le\\underset{\\gamma\\in[0,1]}{\\operatorname*{max}}\\underset{p_{t}\\in\\Delta(y)}{\\operatorname*{min}}\\underset{(\\tilde{g},\\tilde{h}_{t})\\in\\mathcal{C}\\times\\mathcal{H}}{\\operatorname*{max}}\\mathbb{E}_{h_{t}(x_{t})\\sim p_{t},y\\sim\\mathrm{Ber}(\\gamma)}\\left[\\tilde{g}(x_{t})\\left(\\ell(h_{t}(x_{t}),y)-\\ell(\\tilde{h}(x_{t}),y)\\right)\\right]=v_{t}^{A}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the first equality is from the minimax theorem and the second inequality is just because averages are less than or equal to maximums. Combining all the inequalities, we obtain ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{(h^{*},g^{*})\\in\\mathcal{H}\\times\\mathcal{G}}\\sum_{t=1}^{T}\\tilde{\\ell}((g^{*},h^{*}),(h_{t}(x_{t}),y_{t}))\\le\\sum_{t=1}^{T}v_{t}^{A}+\\sum_{t=1}^{T}\\epsilon_{t}(M)+R(T),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and our theorem follows from taking an expectation on both sides and substituting back the definition of ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widetilde{\\ell}((g^{*},h^{*}),(h(x_{t}),y_{t})):=g^{*}(x_{t})\\left(\\ell(h(x_{t}),y_{t})-\\ell(h^{*}(x_{t}),y_{t})\\right),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "because each $\\tilde{\\ell}((g^{*},h^{*}),(h(x_{t}),y_{t}))$ is simply the per-round regret. ", "page_idx": 23}, {"type": "text", "text": "With Theorem B.4 in hand, it remains to make sure that the two terms $\\textstyle\\sum_{t=1}^{T}v_{t}^{A}$ and $\\textstyle\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]$ are both $o(T)$ . Then, if we have a no-regret algorithm with $o(T)$ regret while only accessing $\\mathcal{G}$ and $\\mathcal{H}$ through the $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ oracle, we will have a multi-group online learning algorithm. The next two lemmas show that both terms are, indeed, $o(T)$ . ", "page_idx": 23}, {"type": "text", "text": "First, we bound the values $v_{t}^{A}$ , which are known as the \u201cAMF values\u201d in the framework of $[\\mathrm{Lee}{+22}]$ .   \nLemma B.5. For any $t\\in[T]$ , the AMF value of the game at round $t$ , is nonpositive, i.e. ", "page_idx": 23}, {"type": "equation", "text": "$$\nv_{t}^{A}:=\\operatorname*{max}_{\\gamma\\in[0,1]}\\operatorname*{min}_{p_{t}\\in\\Delta(\\mathcal{H})}\\operatorname*{max}_{(h,g)\\in\\mathcal{H}\\times\\mathcal{G}}\\mathbb{E}[g(x_{t})(\\ell(h_{t}(x_{t}),y)-\\ell(h(x_{t}),y))]\\leq0,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the expectation is taken over $h_{t}\\sim p_{t}$ and $y\\sim\\operatorname{Ber}(\\gamma)$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. Fix any parameter $\\gamma\\in[0,1]$ for the max player. Then, for any $(h,g)\\in\\mathcal{H}\\times\\mathcal{G},$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[g(x_{t})(\\ell(h_{t}(x_{t}),y)-\\ell(h(x_{t}),y))\\right]=\\gamma\\mathbb{E}_{h_{t}\\sim p_{t}}[g(x_{t})(\\ell(h_{t}(x_{t}),1)-\\ell(h(x_{t}),1))]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\,(1-\\gamma)\\mathbb{E}_{h_{t}\\sim p_{t}}[g(x_{t})(\\ell(h_{t}(x_{t}),-1)-\\ell(h(x_{t}),-1))].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Expanding the expectation over $h_{t}\\sim p_{t}$ , this is equivalent to: ", "page_idx": 23}, {"type": "equation", "text": "$$\ng(x_{t})\\sum_{h^{\\prime}\\in\\mathcal{H}}p_{h^{\\prime}}^{t}(\\gamma\\ell(h^{\\prime}(x_{t}),1)+(1-\\gamma)\\ell(h^{\\prime}(x_{t}),0))-g(x_{t})(\\gamma\\ell(h(x_{t}),1)+(1-\\gamma)\\ell(h(x_{t}),0)),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "so it suffices to find $p_{t}\\in\\Delta(\\mathcal{H})$ such that, for all $(h,g)\\in\\mathcal{H}\\times\\mathcal{G}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\ng(x_{t})\\sum_{h^{\\prime}\\in\\mathcal{H}}p_{h^{\\prime}}^{t}(\\gamma\\ell(h^{\\prime}(x_{t}),1)+(1-\\gamma)\\ell(h^{\\prime}(x_{t}),0))\\leq g(x_{t})(\\gamma\\ell(h(x_{t}),1)+(1-\\gamma)\\ell(h(x_{t}),0)).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The $g(x_{t})$ value is the same for both sides, so it really suffices to find the $p_{t}\\in\\Delta(\\mathcal{H})$ such that, for all $h\\in\\mathcal H$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\np_{h^{\\prime}}^{t}(\\gamma\\ell(h^{\\prime}(x_{t}),1)+(1-\\gamma)\\ell(h^{\\prime}(x_{t}),0))\\leq\\gamma\\ell(h(x_{t}),1)+(1-\\gamma)\\ell(h(x_{t}),0).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Because we know $\\gamma$ , the Bernoulli parameter for the true distribution of $y\\mid x_{t}$ , we can choose $p^{t}\\in\\Delta(\\mathcal{H})$ to put all its mass on the $h^{*}\\in\\mathcal{H}$ that minimizes this risk, i.e. ", "page_idx": 23}, {"type": "equation", "text": "$$\nh^{\\ast}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\mathbb{E}_{y}[\\ell(h(x_{t}),y)\\mid x_{t}].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This is, by definition, exactly the $h^{*}$ such that, for any $h\\in\\mathcal H$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\gamma\\ell(h^{*}(x_{t}),1)+(1-\\gamma)\\ell(h^{*}(x_{t}),-1)\\leq\\gamma\\ell(h(x_{t}),1)+(1-\\gamma)\\ell(h(x_{t}),-1).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Therefore, we have that: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v_{t}^{A}=\\underset{\\gamma\\in[0,1]}{\\operatorname*{max}}\\underset{p_{t}\\in\\Delta(\\mathcal{H})}{\\operatorname*{min}}\\underset{(h,g)\\in\\mathcal{H}\\times\\mathcal{G}}{\\operatorname*{max}}\\mathbb{E}_{h^{\\prime}\\sim p_{t},y\\sim\\mathrm{Ber}(\\gamma)}[g(x_{t})(\\ell(h^{\\prime}(x_{t}),y)-\\ell(h(x_{t}),y))]}\\\\ &{\\quad\\leq\\underset{\\gamma\\in[0,1],(h,g)\\in\\mathcal{H}\\times\\mathcal{G}}{\\operatorname*{max}}\\mathbb{E}_{y\\sim\\mathrm{Ber}(\\gamma)}[g(x_{t})(\\ell(h^{*}(x_{t}),y)-\\ell(h(x_{t}),y))]}\\\\ &{\\quad\\leq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The final inequality follows from our argument above. ", "page_idx": 24}, {"type": "text", "text": "Next, we bound the expected approximation error we incur from replacing $q_{t}$ with the empirical distribution ${\\tilde{q}}_{t}$ obtained from the $M$ samples $\\{(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}\\}_{i=1}^{M}$ t(i )}iM=1, which we denoted as \u03f5t(M). This comes from a standard uniform convergence argument. ", "page_idx": 24}, {"type": "text", "text": "Lemma B.6. Let $t\\,\\in\\,[T]$ and $x_{t}\\,\\in\\,\\mathcal{X}$ be fixed, and consider the function $\\tilde{\\ell}_{x_{t}}((g,h),(y^{\\prime},y)):=$ $g(x_{t})(\\ell(y^{\\prime},y)-\\ell(h(x_{t}),y))$ . Let $|\\mathcal{D}|=k<\\infty$ . If $M\\geq T^{1+\\delta}$ , where $\\begin{array}{r}{\\delta=\\Omega(\\frac{\\log(\\log T+\\log k)}{\\log T})}\\end{array}$ , then over the randomness of drawing $M$ samples $\\{(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}\\}_{i=1}^{M}$ to construct the empirical distribution ${\\tilde{q}}_{t}$ described in Definition B.4, for all $y^{\\prime},y\\in\\mathcal{Y},$ , let $\\epsilon_{t}(M)$ be defined as the supremum ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\epsilon_{t}(M):=\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}\\times\\mathcal{Y}}\\left|\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}[\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))]-\\mathbb{E}_{(g,h)\\sim q_{t}}[\\tilde{\\ell}_{x_{t}}((g,h),(y^{\\prime},y))]\\right|,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and, over all $T$ rounds, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{i=1}^{T}\\epsilon_{t}(M)\\right]\\leq2\\sqrt{T}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Fix any round $t\\in[T]$ . We use a standard uniform convergence argument to ensure that the empirical distribution ${\\tilde{q}}_{t}$ and the true distribution $q_{t}$ are close for the function $\\tilde{\\ell}_{x_{t}}((g,h),(y^{\\prime},y))$ for all $y^{\\prime},y\\in\\mathcal{Y}$ . We assume that $\\boldsymbol{\\wp}$ is finite, and denote $k:=|\\mathcal{V}|$ . ", "page_idx": 24}, {"type": "text", "text": "Let $\\{(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)})\\}_{i=1}^{M}$ denote the $M$ random samples from ${\\mathcal{G}}\\times{\\mathcal{H}}$ . We note that the expectation over ${\\tilde{q}}_{t}$ is the same as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}\\left[\\tilde{\\ell}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))\\right]=\\frac{1}{M}\\sum_{i=1}^{M}\\tilde{\\ell}\\left((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(y^{\\prime},y)\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Consider the empirical process ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}\\tilde{\\ell}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(y^{\\prime},y))-\\mathbb{E}_{(g,h)\\sim q_{t}}\\left[\\tilde{\\ell}((g,h),(y^{\\prime},y))\\right]\\right|.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "For notational simplicity, let us refer to this empirical process as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|=\\epsilon_{t}(M).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Because $\\ell(\\cdot,\\cdot)\\in[0,1]$ , we know $\\tilde{\\ell}\\in[-1,1]$ . Moreover, $|\\mathcal{D}^{2}|=k^{2}$ . We can now use Hoeffding\u2019s inequality and a union bound to obtain: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{y}^{2}}\\left\\lvert\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right\\rvert\\geq\\varepsilon\\right]\\leq k^{2}\\exp(-2M\\varepsilon^{2})\\leq k^{2}\\exp(-2T^{1+\\delta}\\varepsilon^{2}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By the elementary integral inequality $\\begin{array}{r}{\\mathbb{E}[X]\\leq\\int_{0}^{\\infty}\\mathbb{P}[X\\geq t]d t}\\end{array}$ , we obtain: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\Sigma}\\displaystyle\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\right]\\leq\\int_{0}^{\\infty}\\mathbb{P}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\geq t\\right]d t}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\int_{0}^{w}\\mathbb{P}\\left[\\displaystyle\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\geq t\\right]d t+\\int_{w}^{\\infty}k^{2}\\exp(-2T^{1+\\delta}y^{2})d t}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq w+\\int_{w}^{\\infty}k^{2}\\exp(-2T^{1+\\delta}t^{2})d t}\\\\ &{\\qquad\\qquad\\qquad\\leq w+k^{2}\\exp(-2T^{1+\\delta}w^{2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $w>0$ is an arbitrary parameter. Set $w=\\sqrt{\\frac{1}{T}}$ . If $\\begin{array}{r}{\\delta\\geq\\frac{\\log\\left(2\\log\\left(k\\right)+\\frac{1}{2}\\log\\left(T\\right)\\right)}{2\\log T}}\\end{array}$ , then: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\right]=\\mathbb{E}[\\epsilon_{t}(M)]\\leq2\\sqrt{\\frac{1}{T}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Therefore, summing up over all $T$ rounds, we obtain $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]\\leq2\\sqrt{T}}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "B.6 Instantiating the meta-algorithm for Theorem 4.1 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Finally, we instantiate Theorem B.4 with a concrete no-regret algorithm for the $(\\mathcal{G},\\mathcal{H})$ -player to obtain Theorem 4.1. We employ the specific no-regret algorithm of $[\\mathrm{Blo}{+}22]$ for our $(\\mathcal{G},\\mathcal{H})$ -player, restated here for reference. ", "page_idx": 25}, {"type": "text", "text": "Theorem B.7 (Smoothed FTPL of $[\\mathrm{Blo}{+}22]$ ). Let $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ be a function class and let \u2113be a loss function that is $L$ -Lipscchitz in both arguments. Suppose further that we are in the smoothed online learning setting (see Section 4.1) where each $x_{i}$ are drawn from a distribution that is $\\sigma$ -smooth with respect ot some base measure $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ on $\\mathcal{X}$ . Let ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\pi_{t,n}(f):=\\sum_{i=1}^{n}\\frac{f(z_{t,i})\\gamma_{t,i}}{\\sqrt{n}},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $z_{t,i}\\sim\\boldsymbol{B}$ are independent and the $\\gamma_{t,i}$ are independent standard Gaussian variables. Suppose that $\\alpha\\geq0$ and consider the algorithm which uses an $\\alpha$ -approximate oracle for $\\mathcal{F}$ (see Definition 2.1) to choose $f_{t}$ according to ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{s=1}^{t-1}\\ell(f_{t}(x_{s}),y_{s})+\\eta\\pi_{t,n}(f_{t})\\leq\\operatorname*{inf}_{f^{*}\\in\\mathcal{F}}\\sum_{s=1}^{t-1}\\ell(f^{*}(x_{s}),y_{s})+\\pi_{t,n}(f^{*})+\\alpha,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and let ${\\hat{y}}_{t}=f_{t}(x_{t})$ . If $\\mathcal{F}$ and $y_{t}$ are binary valued, with the $V C$ dimension of $\\mathcal{F}$ bounded by $d\\geq1$ , then for $n=T/\\sqrt{\\sigma}$ and $\\begin{array}{r}{\\eta=\\sqrt{\\frac{T\\log(T L/\\sigma)}{\\sigma}}}\\end{array}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(f_{t})]\\le C\\left(\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $C>0$ is some absolute constant. ", "page_idx": 25}, {"type": "text", "text": "This is precisely what the $(\\mathcal{G},\\mathcal{H})$ -player does in Algorithm 1. Let ${\\mathcal{G}}:=\\{g\\subseteq\\lambda:g\\in{\\mathcal{G}}\\}$ be a collection of groups, represented as Boolean functions $g:\\mathcal{X}\\to\\{0,1\\}$ . Let $\\mathcal{H}$ be a hypothesis class of binary-valued functions $h:\\mathcal{X}\\to\\{-1,1\\}$ . To be clear, the we map Theorem B.7 to our Algorithm 1 in the following way: ", "page_idx": 25}, {"type": "text", "text": "\u2022 Let $\\mathcal{F}$ of Theorem B.7 be the class of functions in $[-1,1]^{\\mathcal{X}}$ defined by: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathcal{F}:=\\{x\\mapsto\\tilde{g}(x)\\tilde{h}(x):\\tilde{g}\\in\\mathcal{G},\\tilde{h}\\in\\mathcal{H}\\}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Note that each $f\\in\\mathcal F$ maps to $\\{-1,0,1\\}$ . ", "page_idx": 25}, {"type": "text", "text": "\u2022 Let the loss function in Theorem B.7 be the loss of the $(\\mathcal{G},\\mathcal{H})$ -player on $x\\in\\mathscr{X}$ : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\widetilde{\\ell}((\\widetilde{g},\\widetilde{h}),(h(x),y)):=\\widetilde{g}(x)\\left(\\ell(h(x),y)-\\ell(\\widetilde{h}(x),y)\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In terms of $\\mathcal{F}$ above, we can rewrite this as: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\tilde{\\ell}(f(x),(y^{\\prime},y)):=\\left\\{\\!\\!\\begin{array}{l l}{0}&{\\mathrm{~if~}f(x)=0}\\\\ {\\ell(y^{\\prime},y)-\\ell(-1,y)}&{\\mathrm{~if~}f(x)=-1}\\\\ {\\ell(y^{\\prime},y)-\\ell(1,y)}&{\\mathrm{~if~}f(x)=1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "This loss function has the signature $\\tilde{\\ell}:\\{-1,0,1\\}\\times\\{-1,1\\}^{2}\\to[-1,1]$ because $\\ell(\\cdot,\\cdot)\\in[0,1]$ .   \nIt is also 2-Lipschitz in both arguments. ", "page_idx": 26}, {"type": "text", "text": "\u2022 It remains to make sure that ternary-valued functions taking values in $\\{-1,0,1\\}$ do not break the proof of Theorem B.7. In the proof of Theorem B.7 in $[\\mathrm{Blo}{+}22]$ , the binary-valued function case where $f$ has range $\\{-1,1\\}$ is handled by embedding $\\{-1,1\\}$ into the real line. There are two main parts of the proof that rely on this assumption that $f$ has range $\\{-1,1\\}$ that easily maintain when $f$ has range $\\{-1,0,1\\}$ . ", "page_idx": 26}, {"type": "text", "text": "\u2013 First, in Lemma 34 of $[\\mathrm{Blo}{+}22]$ , the authors use $L$ -Lipschitzness and the simple fact that $|f(x)-f^{\\prime}(x)|\\leq(f(x)-f^{\\prime}(x))^{2}$ when $f\\in\\{-1,1\\}$ . This still holds when $f\\bar{\\in}\\left\\{-1,0,1\\right\\}$ . \u2013 Second, $[\\mathrm{Blo}{+}22]$ also use the fact that $\\|f\\|_{L_{2}}\\,=\\,1$ for all $f\\,\\in\\,{\\mathcal{F}}$ , which is also true for $f\\in\\{-1,0,1\\}$ . ", "page_idx": 26}, {"type": "text", "text": "Finally, the rest of the proof in Lemma 35 of $[\\mathrm{Blo}{+}22]$ relies only on the Lipschitzneess of $\\tilde{\\ell}$ to employ standard smoothness arguments and Rademacher contraction, which we have already established. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Putting all this together, the $(\\mathcal{G},\\mathcal{H})$ -player in Algorithm 1 essentially runs the algorithm of B.7, with the caveat that it calls the $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ oracle $M$ times to get the empirical approximation ${\\tilde{q}}_{t}$ of the true implicit distribution $q_{t}$ over ${\\mathcal{G}}\\times{\\mathcal{H}}$ . This implicit distribution is defined by the random process of drawing the $n$ perturbations and calling the optimization oracle. ", "page_idx": 26}, {"type": "text", "text": "Therefore, by Lemmas B.6, B.5, and Theorem B.7 applied to the \u201cmeta-theorem\u201d Theorem B.4, we immediately obtain our main theorem, Theorem 4.1. We now restate Theorem 4.1 as Corollary B.7.1 with the specified choices of parameters. ", "page_idx": 26}, {"type": "text", "text": "Corollary B.7.1 (Theorem 4.1, with parameters specified). Let $\\mathcal{D}=\\{-1,1\\}$ be a binary action space, $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\chi}$ be a binary-valued hypothesis class, ${\\mathcal{G}}\\subseteq2^{\\mathcal{X}}$ be a (possibly infinite) collection of groups, and $\\ell:\\{-1,1\\}\\times\\{-1,1\\}\\to[0,\\bar{1}]$ be a bounded loss function. Let the $V C$ dimensions of $\\mathcal{H}$ and $\\mathcal{G}$ both be bounded by $d$ . Let $\\alpha\\geq0$ be the approximation error of the oracle $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . If we are in the $\\sigma$ -smooth online learning setting, then, for $\\begin{array}{r}{M\\ge T^{1+\\delta},\\delta\\ge\\frac{\\log\\left(2\\log(k)+\\frac{1}{2}\\log(T)\\right)}{2\\log T},n=T/\\sqrt{\\sigma}}\\end{array}$ and \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{T\\log(T/\\sigma)}{\\sigma}}}\\end{array}$ T log\u03c3(T/\u03c3), Algorithm 1 achieves, for each g \u2208G: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the expectation is over all the randomness of the $(\\mathcal{G},\\mathcal{H})$ -player\u2019s perturbations and the $\\mathcal{H}$ -player\u2019s Bernoulli choices. ", "page_idx": 26}, {"type": "text", "text": "C Other instantiations of the meta-algorithm ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "It is be clear from the statement of Theorem B.4 that our \u201cmeta-algorithm\u201d Algorithm 4 straightforwardly applies for other online learning settings as well, so long as we adopt an appropriate strategy for the $(\\mathcal{G},\\mathcal{H})$ -player. In this section, we give a few examples of this flexibility for discrete action spaces in the smoothed online setting and the ", "page_idx": 26}, {"type": "text", "text": "C.1 Multi-class action spaces ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Instead of $|\\mathcal{V}|=2$ , we can let $|\\mathcal{Y}|=K$ , more generally. In this case, a straightforward extension of Theorem B.7 allows us to embed ${\\mathcal{V}}\\cup\\{0,1\\}$ into the real line, and we generalize to considering the Natarajan dimension [Nat89] of $\\mathcal{H}$ instead of the VC dimension. Rademacher contraction and Lipschitzness still apply to $\\tilde{\\ell}$ , so with just a difference in the absolute constant, we obtain the following multi-class analogue of Theorem 4.1 as a corollary. Thus, for the $(\\mathcal{G},\\mathcal{H})$ -player in Algorithm 1, we can just use the same exact algorithm outlined in Theorem B.7. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "We make a small change to the $\\mathcal{H}$ -player in Algorithm 1. In the multi-class action space setting, we need to make $K$ calls to the $\\mathrm{OPT}_{\\mathcal{H}}$ oracle and solve a $K\\times K$ size linear program for the $\\mathcal{H}$ -player at each step. For completeness, we present the algorithm for the $K$ -class action spaces here, as Algorithm 5. ", "page_idx": 27}, {"type": "text", "text": "Algorithm 5 Algorithm for Group Oracle Efficiency (multi-class) ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Input: Perturbation strength $\\eta>0$ ; number of $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ calls $M\\in\\mathbb{N}$ .   \n1: for $t=1,2,3,\\dots,T$ do   \n2: Receive a context $x_{t}\\sim\\mu_{t}$ from Nature.   \n34:: fo $(\\mathcal{G},\\mathcal{H})$ $i=1,2,3,\\dots,M$ wd $n$ hallucinated examples as in Equation (4) to construct $\\pi_{t,n}^{\\mathrm{bin}}$ .   \n5: $(\\mathcal{G},\\mathcal{H})$ -player: Using the entire history $\\{(\\hat{y}_{s},y_{s})\\}_{s=1}^{t-1}$ so far, call $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ to obtain $(\\tilde{g}_{t}(i),\\tilde{h}_{t}^{(i)})\\in\\mathcal{G}\\times\\mathcal{H}$ satisfying: $\\begin{array}{r l}{\\lefteqn{\\sum_{s=1}^{t-1}\\tilde{\\ell}_{x_{s}}((\\tilde{g},\\tilde{h}),(\\hat{y}_{s},y_{s}))+\\pi_{t,n}^{\\mathrm{bin}}(\\tilde{g},\\tilde{h},\\eta)}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\operatorname*{sup}_{(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}}\\sum_{s=1}^{t-1}\\tilde{\\ell}_{x_{s}}((g^{*},h^{*}),(\\hat{y}_{s},y_{s}))+\\pi_{t,n}^{\\mathrm{bin}}(g^{*},h^{*},\\eta)-\\alpha}\\end{array}$ (19)   \n6: end for   \n7: $\\mathcal{H}$ -player: Call $\\mathrm{OPT}_{\\mathcal{H}}\\:K$ times on the singleton datasets $\\{(x_{t},k)\\}$ for action $k\\in[K]$ with the 0-1 loss, obtaining: ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "equation", "text": "$$\nh_{k}^{\\prime}\\in\\underset{h^{\\ast}\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\mathbf{1}\\left\\{h^{\\ast}(x_{t})\\neq k\\right\\}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "8: $\\mathcal{H}$ -player: Using the $M$ samples $\\{(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)})\\}_{i=1}^{M}$ , construct the $K\\times K$ payoff matrix $\\tilde{L}\\in$ $[-1,1]^{K\\times K}$ indexed by $(k,y)\\in[K]\\times[K]$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\tilde{L}_{k,y}:=\\sum_{i=1}^{M}\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{k}^{\\prime}(x_{t}),y)).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "9: $\\mathcal{H}$ -player: Solve the linear program ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{p\\in\\mathbb{R}^{K},\\lambda\\in\\mathbb{R}}{\\operatorname*{min}}\\,\\lambda}\\\\ &{\\qquad\\qquad\\mathrm{s.t.}\\;p^{\\top}\\tilde{L}e_{y}\\leq\\lambda\\quad\\forall y\\in[K]}\\\\ &{\\qquad\\qquad p_{k}\\geq0\\qquad\\forall k\\in[K]}\\\\ &{\\qquad\\qquad\\sum p_{i}=1}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(where $e_{y}$ is the $y$ -th coordinate vector in $\\mathbb{R}^{K}$ ) ", "page_idx": 27}, {"type": "text", "text": "10: Sample $k\\sim p$ , let $h_{t}=h_{k}^{\\prime}$ .   \n11: Learner commits to the action ${\\hat{y}}_{t}=h_{t}(x_{t})$ ; Nature reveals $y_{t}$ .   \n12: Learner incurs the loss $\\ell(\\hat{y}_{t},y_{t})$ . ", "page_idx": 27}, {"type": "text", "text": "13: end for ", "page_idx": 27}, {"type": "text", "text": "Theorem C.1. Let $\\mathcal{V}=\\{1,\\ldots,K\\}$ be a $K$ -class action space, $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ be a $K$ -valued hypothesis class, $\\mathcal{G}\\subseteq2^{\\mathcal{X}}$ be a (possibly infinite) collection of groups, and $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow[0,1]$ be a bounded loss function. Let the Natarajan dimension [Nat89] of $\\mathcal{H}$ and the VC dimension of $\\mathcal{G}$ both be bounded by $d$ . Let $\\alpha\\geq0$ be the approximation error of the oracle $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . ${\\cal I}f$ we are in the $\\sigma$ -smooth online learning setting, then, for appropriate choices of $M\\in\\mathbb{N},n\\in\\mathbb{N}$ , and $\\eta>0$ , Algorithm 5 achieves, ", "page_idx": 27}, {"type": "text", "text": "for each $g\\in{\\mathcal{G}}$ : ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{\\frac{d T\\log T}{\\sigma}}+\\alpha T\\right),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the expectation is over all the randomness of the $(\\mathcal{G},\\mathcal{H})$ -player\u2019s perturbations. ", "page_idx": 28}, {"type": "text", "text": "C.2 Group-dependent regret ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In this section, we give the details on how to achieve the desired group-dependent regret guarantees of Section 5. Throughout this section, for any $g\\,\\in\\,{\\mathcal{G}}$ , let $\\begin{array}{r}{T_{g}:=\\sum_{t=1}^{T}g(x_{t})}\\end{array}$ . The results in this section hinge on the GFTPL with small-loss bound algorithm of $[\\mathrm{Wan}{+}22]$ . The main idea will be to instantiate the $(\\mathcal{G},\\mathcal{H})$ -player in our meta-algorithm, Algorithm 4 using the GFTPL with small-loss bound algorithm so Theorem B.4 allows us to directly inherit its regret guarantee. We quote the algorithm here, adapted to our setting, for reference. Throughout this section, we use the familiar notation from Section 4.2 of the main body: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\tilde{\\ell}_{x}((\\tilde{g},\\tilde{h}),(y^{\\prime},y)):=\\tilde{g}(x)\\left(\\ell(y^{\\prime},y)-\\ell(\\tilde{h}(x),y)\\right),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\ell(\\cdot,\\cdot)$ is the fixed loss of the entire multi-group online learning setting. ", "page_idx": 28}, {"type": "text", "text": "", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Algorithm 6 GFTPL with small-loss bound   \nInput: Perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$   \n1: Draw i.i.d. vector $\\begin{array}{r}{\\nu=(\\nu^{(1)},\\cdot\\cdot\\cdot,\\nu^{(N)})\\sim\\mathrm{Lap}(1)^{N}.}\\end{array}$ , i.e., $\\begin{array}{r}{p(\\ensuremath{\\boldsymbol\\nu}^{(i)})=\\frac{1}{2}\\exp(-|\\ensuremath{\\boldsymbol\\nu}^{(i)}|)}\\end{array}$ .   \n2: for $t=1,2,3,\\dots,T$ do   \n3: Set $\\nu_{t}\\gets\\frac{\\nu}{\\eta_{t}}$ where $\\eta_{t}>0$ is a parameter computed online.   \n4: Using the entire history up to $t-1$ so far, call $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ to obtain $(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}$ sastisying: $\\begin{array}{r l}{\\lefteqn{\\sum_{s=1}^{t-1}\\tilde{\\ell}_{x_{s}}\\bigl((\\tilde{g},\\tilde{h}),(\\hat{y}_{s},y_{s})\\bigr)+\\langle\\Gamma^{(\\tilde{g},\\tilde{h})},\\nu_{t}\\rangle}\\qquad}&{}\\\\ &{\\geq\\underset{(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}}{\\operatorname*{sup}}\\underset{s=1}{\\overset{t-1}{\\sum}}\\tilde{\\ell}_{x_{s}}\\bigl((g^{*},h^{*}),(\\hat{y}_{s},y_{s})\\bigr)+\\langle\\Gamma^{(\\tilde{g},\\tilde{h})},\\nu_{t}\\rangle-\\alpha,}\\end{array}$ (21) where $\\Gamma^{(\\tilde{g},\\tilde{h})}$ is the $(\\tilde{g},\\tilde{h})$ th row of $\\Gamma$ . ", "page_idx": 28}, {"type": "text", "text": "5: end for ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In our setting, the classical FTPL algorithm of [KV05] draws $|{\\mathcal{G}}|\\times|{\\mathcal{H}}|$ independent perturbations at each round, which requires enumeration of both $\\mathcal{G}$ and $\\mathcal{H}$ . In order to remedy this, the GFTPL algorithm of $[\\mathrm{Dud}{+}20]$ uses a $|\\mathcal{G}||\\mathcal{H}|\\times N$ perturbation matrix $\\Gamma$ to generate dependent \u201cshared randomness.\u201d The transformation $\\Gamma$ applies to a perturbation vector $\\bar{\\boldsymbol\\nu}\\in\\mathbb{R}^{N}$ , where $N$ is much smaller than $|\\mathcal G||\\mathcal H|$ . Running FTPL with these perturbations, then, results on an oracle-efficient algorithm. $[\\mathrm{Wan}{+}22]$ ] extends this by showing that, under certain conditions on $\\Gamma$ , this oracleefficient algorithm can also achieve a small-loss regret, where the regret diminishes based on the total magnitude of the losses over the $T$ rounds instead of the number of rounds. ", "page_idx": 28}, {"type": "text", "text": "Specifically, a small loss regret looks like the following. It is well-known that, in the worst-case, a regret of $O\\left({\\sqrt{T\\log|{\\mathcal{G}}||{\\mathcal{H}}|}}\\right)$ is minimax optimal [CL06]. However, stronger bounds have been obtained for problems with \u201csmall losses\u201d (see, e.g., [HP05; GSV14; LS15]), where, for a loss function $f:(\\bar{\\mathcal{G}}\\times\\mathcal{H})\\times\\mathcal{Y}\\rightarrow[0,1]$ , one can achieve: ", "page_idx": 28}, {"type": "equation", "text": "$$\nO\\left(\\sqrt{\\sum_{t=1}^{T}f((h_{t},g_{t}),y_{t})\\log|\\mathcal{H}||\\mathcal{G}|}\\right),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "which is sharper than the $O\\left(\\sqrt{T\\log\\left|\\mathcal{H}\\right|\\left|\\mathcal{G}\\right|}\\right)$ bound when $f((h_{t},g_{t}),y_{t})\\,<\\,1$ on some rounds. We desire this property to achieve a regret bound in the multi-group online learning setting that is sublinear in terms of the number of rounds a group appears $T_{g}$ . ", "page_idx": 28}, {"type": "text", "text": "Following $[\\mathrm{Wan}{+}22]$ , we require the perturbation matrix $\\Gamma$ to have two sufficient conditions for Algorithm 6 to obtain the desired small-loss regret. The first is $\\gamma.$ -approximability, which is a condition that ensures the stability choices of $(\\tilde{g}_{t},\\tilde{h}_{t})$ and $(\\tilde{g}_{t+1},\\tilde{h}_{t+1})$ across rounds. In particular, the stability needed is a bound on the ratio: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mathbb{P}[(\\tilde{g}_{t},\\tilde{h}_{t})=(g,h)]}{\\mathbb{P}[(\\tilde{g}_{t+1},\\tilde{h}_{t+1})=(g,h)]}\\le\\exp(\\gamma\\eta_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for all $(g,h)\\,\\in\\,\\mathcal{G}\\,\\times\\,\\mathcal{H}$ , where $\\eta_{t}\\,>\\,0$ is the per-round leraning rate of GFTPL. By Lemma 2 of $[\\mathrm{Wan}{+}22]$ , the following condition is sufficient to ensure this property. We restate it here, translated to our setting. ", "page_idx": 29}, {"type": "text", "text": "Definition C.1 ( $\\gamma$ -approximability $[\\mathrm{Wan}{+}22]]$ ). Let $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$ , where $N$ is the dimension of the noise vector, $\\nu$ in Algorithm $^{\\sc6}$ . Define $B_{\\gamma}^{1}:=\\{s\\in\\mathbb{R}^{N}:\\|s\\|_{1}\\leq\\gamma\\}$ . \u0393 is $\\gamma.$ -approximable $i f,$ for all $(g,h)\\in\\mathcal{G}\\times\\mathcal{H}$ and $(x,y^{\\prime},y)\\in\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{Y},$ , there exists $s\\in\\mathbb{R}^{N}$ with $\\|s\\|_{1}\\leq\\gamma$ such that the following holds for all $(g^{\\prime},h^{\\prime})\\in\\mathcal{G}\\times\\mathcal{H}$ : ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\langle\\Gamma^{(g,h)}-\\Gamma^{(g^{\\prime},h^{\\prime})},s\\rangle\\geq\\widetilde{\\ell}_{x}((g,h),(y^{\\prime},y))-\\widetilde{\\ell}_{x}((g^{\\prime},h^{\\prime}),(y^{\\prime},y)).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The second property is implementability. This property actually allows us to use our optimization oracle (in our case, $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha})$ to access $\\Gamma$ without explicitly representing it. In essence, it requires that we can generate a small number of \u201cfake examples\u201d that effectively implement the perturbation needed by Algorithm 6. ", "page_idx": 29}, {"type": "text", "text": "Definition C.2 (Implementability $[\\mathrm{Dud}{+}20]$ ). A matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$ is implementable with complexity $M$ if for each $j\\in[N]$ there exists a dataset $S_{j}$ with $|S_{j}|\\leq M$ such that, for all pairs of rows $(g,h),(g^{\\prime},h^{\\prime})\\in\\mathcal{G}\\times\\mathcal{H}_{\\mathbf{\\varepsilon}}$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Gamma^{((g,h),j)}-\\Gamma^{((g^{\\prime},h^{\\prime}),j)}=\\sum_{(w,(x,y,y^{\\prime}))\\in S_{j}}w\\left(\\tilde{\\ell}_{x}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))-\\tilde{\\ell}_{x}((\\tilde{g}^{\\prime},\\tilde{h}^{\\prime}),(y^{\\prime},y))\\right).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "In the above definition, the fake examples are tuples of a context $x\\in\\mathscr{X}$ and two outcomes $y,y^{\\prime}\\in\\mathcal{Y}$ . Finally, with the sufficient conditions of implementability and approximability, we quote the main regret guarantee of Algorithm 6in $[\\mathrm{Wan}{+}22]$ here. ", "page_idx": 29}, {"type": "text", "text": "Theorem C.2 (Regret guarantee of $6\\ [\\mathrm{Wan}{+}22]$ ). Let $\\{1,\\ldots,K\\}$ be the action space of the Learner and let $\\mathcal{Z}$ be the action space of the adversary. Suppose that, at each round, the Learner chooses action $x_{t}\\in[K]$ , the adversary chooses action $z_{t}\\in\\mathcal{Z}$ , and the loss function is $f:[K]\\times\\mathcal{Z}\\to[0,1]$ . Let $\\begin{array}{r}{L_{T}^{*}=\\operatorname*{min}_{k\\in[K]}\\sum_{t=1}^{T}f(k,y_{t})}\\end{array}$ . Then, if there exists a $\\gamma$ -approximable matrix \u0393, Algorithm $^{\\sc6}$ instantiated with $\\Gamma$ and $\\begin{array}{r}{\\eta_{t}:=\\operatorname*{min}\\left\\{\\frac{1}{\\gamma},\\frac{C}{\\sqrt{L_{t-1}^{*}+1}}\\right\\}}\\end{array}$ achieves the following regret bound: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathrm{Reg}_{T}]\\leq\\left(\\frac{4\\sqrt{2}\\operatorname*{max}\\{2\\log K,\\sqrt{N\\log K}\\}}{C}+2\\gamma\\left(C+\\frac{1}{C}\\right)\\right)\\sqrt{L_{T}^{*}+1}}\\\\ &{\\qquad\\qquad+\\,8\\gamma\\log\\left(\\frac{1}{C}\\sqrt{L_{T}^{*}+1}+\\gamma\\right)+2\\gamma^{2}+4\\sqrt{2}\\operatorname*{max}\\{2\\log K,\\sqrt{N\\log K}\\}\\gamma.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "With an appropriate choice of $C>0$ , we may obtain the regret bound: ", "page_idx": 29}, {"type": "equation", "text": "$$\nO\\left(\\sqrt{L_{T}^{*}}\\operatorname*{max}\\left\\{\\gamma,\\log K,\\sqrt{N\\log K}\\right\\}\\right)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "If \u0393 is also implementable with complexity $M$ , then Algorithm $^{\\sc6}$ is oracle-efficient, making $O(T+$ $N M)$ oracle calls per round, where $N$ is the number of columns of $\\Gamma$ . ", "page_idx": 29}, {"type": "text", "text": "Finally, we need one more lemma using a standard uniform convergence argument to bound the approximation error from sampling with $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}\\;M$ times. This is essentially the same as Lemma B.6, but we obtain a sharper bound on $\\mathbb{E}\\left[\\sum_{t=1}^{T}\\epsilon_{t}(M)\\right]$ at the cost of making polynomially $\\sin T)$ more calls to the oracle. ", "page_idx": 29}, {"type": "text", "text": "Lemma C.3. Let $t\\,\\in\\,[T]$ and $x_{t}\\,\\in\\,\\mathcal{X}$ be fixed, and consider the function $\\tilde{\\ell}_{x_{t}}((g,h),(y^{\\prime},y)):=$ $g(x_{t})(\\ell(y^{\\prime},y)-\\ell(h(x_{t}),\\dot{y}))$ . Let $|\\mathcal{D}|=k<\\infty$ . If $M\\geq T^{2}\\log(k^{2}{\\bar{T}}),$ , then over the randomness of drawing $M$ samples $\\{(\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}\\}_{i=1}^{M}$ to construct the empirical distribution ${\\tilde{q}}_{t}$ described in Definition B.4, for all $y^{\\prime},y\\in\\mathcal{Y}$ , let $\\epsilon_{t}(M)$ be defined as the supremum ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\epsilon_{t}(M):=\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}\\times\\mathcal{Y}}\\left|\\mathbb{E}_{(\\tilde{g},\\tilde{h})\\sim\\tilde{q}_{t}}[\\tilde{\\ell}_{x_{t}}((\\tilde{g},\\tilde{h}),(y^{\\prime},y))]-\\mathbb{E}_{(g,h)\\sim q_{t}}[\\tilde{\\ell}_{x_{t}}((g,h),(y^{\\prime},y))]\\right|,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "and, over all $T$ rounds, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{i=1}^{T}\\epsilon_{t}(M)\\right]\\leq2.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. The proof of this lemma follows the proof of Lemma B.6 exactly, except for the choice of $M$ . Therefore, just using the exact same notation as Lemma B.6, we have: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\geq\\varepsilon\\right]\\leq k^{2}\\exp(-2M\\varepsilon^{2})\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By the same exact argument using $\\begin{array}{r}{\\mathbb{E}[X]\\leq\\int_{0}^{\\infty}\\mathbb{P}[X\\geq t]d t}\\end{array}$ , we obtain ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\right]\\leq w+k^{2}\\exp(-2M w^{2}),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $w>0$ is an arbitrary parameter. Set $\\begin{array}{r}{w=\\frac{1}{T^{2}}}\\end{array}$ . Then, if $M\\geq T^{2}\\log(k T)$ , we get ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\epsilon_{t}(M)]=\\mathbb{E}\\left[\\operatorname*{sup}_{(y^{\\prime},y)\\in\\mathcal{Y}^{2}}\\left|\\frac{1}{M}\\sum_{i=1}^{M}Z_{i}(y^{\\prime},y)\\right|\\right]\\le2/T.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The lemma follows from summing over $T$ . ", "page_idx": 30}, {"type": "text", "text": "Proof of Theorem 5.1. We can now prove Theorem 5.1. The main idea is that the small loss regret translates directly into a $o(T_{g})$ regret due to how we defined our loss function, $\\tilde{\\ell}_{x}$ , so we simply instantiate the $(\\mathcal{G},\\mathcal{H})$ -player in the general algorithm template of Algorithm 4 with Algorithm 6. This allows us to directly inherit the $o(T_{g})$ regret guarantee. We restate it here, with parameters specified, as Proposition C.3.1. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "Proposition C.3.1 (Theorem 5.1, with parameters specified). Assume $\\mathcal{H},\\mathcal{G}$ are finite and there exists a $\\gamma$ -approximable and implementable perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$ . Let $|\\mathcal{V}|=k$ . Let $\\alpha\\geq0$ be the approximation parameter of $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ . Let the no-regret algorithm for the $(\\mathcal{G},\\mathcal{H})$ - player in Algorithm $^{\\,l}$ be the GFTPL algorithm of [Wan $+22J$ instantiated with $\\Gamma$ , with parameter $\\bar{M}=T^{2}\\log(k^{2}T)$ . Then, for each $g\\in{\\mathcal{G}}$ : ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq O\\left(\\sqrt{T_{g}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{H}||\\mathcal{G}|,\\sqrt{N\\log|\\mathcal{H}||\\mathcal{G}|}\\right\\}+\\alpha T\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. Armed with approximability and implementability, we are ready to prove Theorem 5.1. Suppose that there exists a $\\gamma$ -approximable and implementable perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times\\bar{N}}$ . In the setting of Theorem C.2, we instantiate $K=|\\mathcal G||\\mathcal{H}|$ , $\\mathcal{Z}=\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{Y}$ , and the loss function $f(\\cdot,\\cdot)$ as: ", "page_idx": 30}, {"type": "equation", "text": "$$\nf((g,h),(x,y^{\\prime},y)):=\\widetilde{\\ell}_{x}((g,h),(y^{\\prime},y))=g(x)\\left(\\ell(y^{\\prime},y)-\\ell(h(x),y)\\right).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Observe that, with the loss instantiated as $\\tilde{\\ell}_{x}$ , we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{T}^{*}=\\underset{(g,h)\\in\\mathcal{G}\\times\\mathcal{H}}{\\mathrm{min}}\\sum_{t=1}^{T}\\tilde{\\ell}_{x}((g,h),(x_{t},y_{t}^{\\prime},y_{t}))}\\\\ &{\\quad\\le\\underset{t=1}{\\overset{T}{\\sum}}\\tilde{\\ell}_{x}((g,h),(x_{t},y_{t}^{\\prime},y_{t}))\\quad\\mathrm{~for~all~}(g,h)\\in\\mathcal{G}\\times\\mathcal{H}}\\\\ &{\\quad=\\underset{t=1}{\\overset{T}{\\sum}}g(x_{t})(\\ell(y_{t}^{\\prime},y_{t})-\\ell(h(x_{t}),y_{t}))\\quad\\mathrm{~for~all~}(g,h)\\in\\mathcal{G}\\times\\mathcal{H}.}\\\\ &{\\quad\\le\\underset{t=1}{\\overset{T}{\\sum}}g(x_{t})=T_{g},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "for all $g\\in{\\mathcal{G}}$ . The last inequality just comes from the fact that $\\ell(\\cdot,\\cdot)\\in[0,1]$ . By directly applying Theorem C.2, we obtain the regret guarantee for Algorithm 6 of ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Reg}_{T}]\\leq O\\left(\\sqrt{L_{T}^{*}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{G}||\\mathcal{H}|,\\sqrt{N\\log|\\mathcal{G}||\\mathcal{H}|}\\right\\}\\right)}\\\\ {\\leq O\\left(\\sqrt{T_{g}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{G}||\\mathcal{H}|,\\sqrt{N\\log|\\mathcal{G}||\\mathcal{H}|}\\right\\}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "However, this is just the regret guarantee of Algorithm 6, not the regret guarantee of our end-toend multi-group online learning algorithm, Algorithm 1. We replace the algorithm of $[\\mathrm{Blo}{+}22]$ in Algorithm 1 with Algorithm 6. That is, we use the Algorithm 6 for the $(\\mathcal{G},\\bar{\\mathcal{H}})$ -player in Algorithm 4; a full description of this substitution is in Algorithm 7. By our meta-theorem, Theorem B.4, this entire algorithm achieves the multi-group regret guarantee, for all $g\\in{\\mathcal{G}}$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq\\displaystyle\\sum_{t=1}^{T}v_{t}^{A}+\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]+R(T).}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]+O\\left(\\sqrt{T_{g}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{G}||\\mathcal{H}|,\\sqrt{N\\log|\\mathcal{G}||\\mathcal{H}|}\\right\\}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Equation (24) follows from applying Lemma B.5 and using the regret bound for Algorithm 6 established above. It remains t\u221ao ensure that $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]\\leq o(T_{g})}\\end{array}$ . Simply applying Lemma B.6 results in $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]=2\\sqrt{T}}\\end{array}$ , which is insufficient for our purposes. Instead, we use Lemma C.3, which ensures that $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}[\\epsilon_{t}(M)]\\leq O(1)}\\end{array}$ at the cost of increasing $M$ to be $M\\geq T^{2}\\log(k^{2}T)$ making polynomia lly more oracle calls to $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ per-round. This gives us the final regret guarantee of ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Reg}_{T}(\\mathcal{H},g)]\\leq2+O\\left(\\sqrt{T_{g}}\\operatorname*{max}\\left\\{\\gamma,\\log|\\mathcal{G}||\\mathcal{H}|,\\sqrt{N\\log|\\mathcal{G}||\\mathcal{H}|}\\right\\}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "as desired. ", "page_idx": 31}, {"type": "text", "text": "One possible setting in which a $\\Gamma$ matrix is easily constructible is the transductive setting. Here, we explicitly show how to construct $\\Gamma$ to obtain Corollary 5.1.1. ", "page_idx": 31}, {"type": "text", "text": "Proof of Corollary 5.1.1. Let $X\\subseteq\\mathcal{X}$ be the set the adversary fixes beforehand in the transductive setting, where $N:=|X|$ . We can construct a 1-approximable and implementable $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times4N}$ by creating a row for each $(g,h)\\in\\mathcal{G}\\times\\mathcal{H}$ and a column for each $(\\bar{x},y,y^{\\prime})\\in X\\times\\bar{y^{\\prime}}\\times\\mathcal{Y}$ , and setting each entry as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\Gamma^{((g,h),(x,y,y^{\\prime}))}:=\\tilde{\\ell}_{x}((g,h),(y^{\\prime},y)).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Algorithm 7 Algorithm for Group Oracle Efficiency (with GFTPL) ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Input: Perturbation matrix $\\Gamma\\in[-1,1]^{|\\mathcal{G}||\\mathcal{H}|\\times N}$ ; number of $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ calls $M\\in\\mathbb{N}$ .   \n1: for $t=1,2,3,\\dots,T$ do   \n2: Receive a (possibly adversarial) context $x_{t}\\sim\\mu_{t}$ from Nature.   \n3: for $i=1,2,3,\\dots,M$ do   \n4: $(\\mathcal{G},\\mathcal{H})$ -player: Draw i.i.d. vector $\\nu\\;=\\;(\\nu^{(1)},\\ldots,\\nu^{(N)})\\;\\sim\\;\\mathrm{Lap}(1)^{N}$ , i.e., $p(\\nu^{(i)})\\;=\\;$ $\\textstyle\\frac12\\exp(-|\\nu^{(i)}|)$ .   \n5: $(\\mathcal{G},\\mathcal{H})$ -player: Set $\\nu_{t}\\gets\\frac{\\nu}{\\eta_{t}}$ where $\\begin{array}{r}{\\eta_{t}:=\\operatorname*{min}\\left\\{\\frac{1}{\\gamma},\\frac{C}{\\sqrt{L_{t-1}^{*}+1}}\\right\\}}\\end{array}$   \n6: $(\\mathcal{G},\\mathcal{H})$ -player: Using the entire history $\\{(\\hat{y}_{s},y_{s})\\}_{s=1}^{t-1}$ so far, call $\\mathrm{OPT}_{(\\mathcal{G},\\mathcal{H})}^{\\alpha}$ to obtain $(\\tilde{g},\\tilde{h})\\in\\mathcal{G}\\times\\mathcal{H}$ satisfying: $\\begin{array}{r l}&{\\displaystyle\\sum_{s=1}^{t-1}\\widetilde{\\ell}_{x_{s}}((\\widetilde{g},\\widetilde{h}),(\\widehat{y}_{s},y_{s}))+\\langle\\Gamma^{(\\widetilde{g},\\widetilde{h})},\\nu_{t}\\rangle}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\displaystyle\\geq\\operatorname*{sup}_{(g^{*},h^{*})\\in\\mathcal{G}\\times\\mathcal{H}}\\sum_{s=1}^{t-1}\\widetilde{\\ell}_{x_{s}}((g^{*},h^{*}),(\\widehat{y}_{s},y_{s}))+\\langle\\Gamma^{(\\widetilde{g},\\widetilde{h})},\\nu_{t}\\rangle-\\alpha,}\\end{array}$ (25) where $\\Gamma^{(\\tilde{g},\\tilde{h})}$ is the $(\\tilde{g},\\tilde{h})$ th row of $\\Gamma$ .   \n7: end for ", "page_idx": 32}, {"type": "text", "text": "8: $\\mathcal{H}$ -player: Call $\\mathrm{OPT}_{\\mathcal{H}}$ twice on the singleton datasets $\\{(x_{t},-1)\\}$ and $\\{(x_{t},1)\\}$ with the 0-1 loss, obtaining: ", "page_idx": 32}, {"type": "equation", "text": "$$\nh_{1}^{\\prime}\\in\\underset{h^{*}\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq1\\right\\}\\quad h_{-1}^{\\prime}\\in\\underset{h^{*}\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\mathbf{1}\\left\\{h^{*}(x_{t})\\neq-1\\right\\}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "9: $\\mathcal{H}$ -player: Solve the linear program ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{p,\\lambda\\in\\mathbb{R}}{\\operatorname*{min}}\\,\\,\\lambda}\\\\ &{\\quad\\mathrm{s.t.}\\,\\,\\displaystyle\\sum_{i=1}^{M}p\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{1}^{\\prime}(x_{t}),y))+(1-p)\\tilde{\\ell}_{x_{t}}((\\tilde{g}_{t}^{(i)},\\tilde{h}_{t}^{(i)}),(h_{-1}^{\\prime}(x_{t}),y))\\leq\\lambda\\quad\\forall y\\in\\{-1,2,...,N\\}}\\\\ &{\\quad\\quad0\\leq p\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "10: Sample $b\\sim\\mathrm{Ber}(p)$ where $b\\in\\{-1,1\\}$ , let $h_{t}=h_{b}^{\\prime}$ .   \n11: Learner commits to the action ${\\hat{y}}_{t}=h_{t}(x_{t})$ ; Nature reveals $y_{t}$ .   \n12: Learner incurs the loss $\\ell(\\hat{y}_{t},y_{t})$ . ", "page_idx": 32}, {"type": "text", "text": "13: end for ", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The three main theorems of the paper and their respective problem settings are laid out in the abstract and Section 1.1, the Summary of Results section, of the introduction. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: We discuss the technical assumptions needed to design oracle-efficient algorithms in Sections 3, 4, and 5 (respectively, i.i.d. assumption, smooth assumption, and existence of perturbation matrix assumption). We also note that our work does not address group-dependent $\\bar{o}(T_{g})$ regret for infinite $\\mathcal{G}$ and $\\mathcal{H}$ , as mentioned in Section 6. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: All theorems are formally stated in the main body and proved in the Appendix. Each main theorem, Theorem 3.2, Theorem 4.1, and Theorem 5.1, are stated in the main body and proven in the Appendix. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This is a theory paper, where the main contributions are towards novel algorithmic design principles for a learning-theoretic model. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] Justification: This is a theory paper (see above). ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Justification: This is a theory paper (see above). Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Justification: This is a theory paper (see above). Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: This is a theory paper (see above). Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: This paper mainly focuses on a theoretical problem that does not involve the use of any real-world datasets. Insofar as the proofs go, we have attempted to make them clear and easily checkable. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The main contribution of this work is towards algorithmic techniques for a learning theory problem. We see the societal impacts of such techniques as minimal. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 36}, {"type": "text", "text": "\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: Our paper does not include any trained models or data. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA]   \nJustification: Our paper does not use any licensed code, data, or models. Guidelines:   \n\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA]   \nJustification: Our paper does not use any new assets (no experiments). Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: Our paper does not conduct any experiments on human subjects.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: Our paper does not conduct any experiments on human subjects. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]