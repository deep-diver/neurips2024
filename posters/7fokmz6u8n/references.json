{"references": [{"fullname_first_author": "Z. Allen-Zhu", "paper_title": "Physics of language models: Part 3.2, knowledge manipulation", "publication_date": "2023-09-14", "reason": "This paper provides theoretical grounding for the phenomenon of inductive out-of-context reasoning, which is the central focus of the current study."}, {"fullname_first_author": "Z. Allen-Zhu", "paper_title": "Physics of language models: Part 3.3, knowledge capacity scaling laws", "publication_date": "2024-01-01", "reason": "This paper delves into the scaling properties of LLMs' knowledge capacity, directly relevant to the study of inductive out-of-context reasoning."}, {"fullname_first_author": "Y. Bengio", "paper_title": "Managing AI risks in an era of rapid progress", "publication_date": "2023-10-17", "reason": "This paper addresses the broader safety concerns regarding large language models, providing context for the safety implications of OOCR."}, {"fullname_first_author": "L. Berglund", "paper_title": "Taken out of context: On measuring situational awareness in LLMs", "publication_date": "2023-09-01", "reason": "This paper explores related concepts of out-of-context reasoning, offering a comparative perspective on the findings and implications of this study."}, {"fullname_first_author": "L. Berglund", "paper_title": "The reversal curse: LLMs trained on \"a is b\" fail to learn \"b is a\"", "publication_date": "2023-09-12", "reason": "This study investigates the limitations of LLMs' ability to learn bidirectional relationships, offering a valuable counterpoint to the capabilities of OOCR demonstrated in the present study."}]}