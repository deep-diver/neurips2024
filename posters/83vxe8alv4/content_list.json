[{"type": "text", "text": "FSP-LAPLACE: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tristan Cinquin\u2217 T\u00fcbingen AI Center, University of T\u00fcbingen tristan.cinquin@uni-tuebingen.de ", "page_idx": 0}, {"type": "text", "text": "Marvin Pf\u00f6rtner\u2217 T\u00fcbingen AI Center, University of T\u00fcbingen marvin.pfoertner@uni-tuebingen.de ", "page_idx": 0}, {"type": "text", "text": "Vincent Fortuin Helmholtz AI, TU Munich vincent.fortuin@tum.de ", "page_idx": 0}, {"type": "text", "text": "Philipp Hennig T\u00fcbingen AI Center, University of T\u00fcbingen philipp.hennig@uni-tuebingen.de ", "page_idx": 0}, {"type": "text", "text": "Robert Bamler T\u00fcbingen AI Center, University of T\u00fcbingen robert.bamler@uni-tuebingen.de ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Laplace approximations are popular techniques for endowing deep networks with epistemic uncertainty estimates as they can be applied without altering the predictions of the trained network, and they scale to large models and datasets. While the choice of prior strongly affects the resulting posterior distribution, computational tractability and lack of interpretability of the weight space typically limit the Laplace approximation to isotropic Gaussian priors, which are known to cause pathological behavior as depth increases. As a remedy, we directly place a prior on function space. More precisely, since Lebesgue densities do not exist on infinitedimensional function spaces, we recast training as finding the so-called weak mode of the posterior measure under a Gaussian process (GP) prior restricted to the space of functions representable by the neural network. Through the GP prior, one can express structured and interpretable inductive biases, such as regularity or periodicity, directly in function space, while still exploiting the implicit inductive biases that allow deep networks to generalize. After model linearization, the training objective induces a negative log-posterior density to which we apply a Laplace approximation, leveraging highly scalable methods from matrix-free linear algebra. Our method provides improved results where prior knowledge is abundant (as is the case in many scientific inference tasks). At the same time, it stays competitive for black-box supervised learning problems, where neural networks typically excel. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Neural networks (NNs) have become the workhorse for many machine learning tasks, but they do not quantify the uncertainty arising from data scarcity\u2014the epistemic uncertainty. NNs therefore cannot estimate their confidence in their predictions, which is needed for safety-critical applications, decision making, and scientific modeling [1\u20133]. As a solution, Bayesian neural networks (BNNs) cast training as approximating the Bayesian posterior distribution over the weights (i.e., the distribution of the model parameters given the training data), thus naturally capturing epistemic uncertainty. Various methods exist for approximating the (intractable) posterior, either by a set of samples (e.g., MCMC) or by a parametric distribution (e.g., variational inference or Laplace approximations). While sampling methods can be asymptotically exact for large numbers of samples, they are typically expensive for large models, whereas variational inference (VI) and the Laplace approximation are more scalable. The Laplace approximation is particularly appealing as it does not alter maximum-a-posteriori (MAP) predictions. Compared to VI, its differential nature allows the Laplace approximation to scale to large datasets and models, and it has been shown to provide well-calibrated uncertainty estimates [4, 5]. ", "page_idx": 0}, {"type": "image", "img_path": "83vxe8alV4/tmp/265b456c2f9bd2ed9833c69f3dde00589771eb49324545211c2731c9d9bff611.jpg", "img_caption": ["Figure 1: FSP-LAPLACE allows for efficient approximate Bayesian neural network (BNN) inference under interpretable function space priors. Using our method, it is possible to encode functional properties like smoothness, lengthscale, or periodicity through a Gaussian process (GP) prior. The gray data points in the plots are noisy observations of a periodic function. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The need for function-space priors in BNNs. While the choice of prior strongly influences the uncertainty estimates obtained from the posterior [6, 7], there are hardly any methods for elicitation of informative priors in the literature on BNNs, with the notable exceptions of Sun et al. [8] and Tran et al. [9]. This is not just a conceptual issue. For instance, the default isotropic Gaussian prior, commonly thought of as uninformative, actually carries incorrect beliefs about the posterior (uni-modality, independent weights, etc.) [6, 10] and has known pathologies in deep NNs [9]. As network weights are not interpretable, formulating a good prior on them is virtually impossible. Current methods work around this issue by model selection, either through expensive cross-validation, or type-II maximum likelihood estimation with a Laplace approximation under an isotropic Gaussian prior, which can only be computed exactly for small networks, and has known issues with normalization layers [11, 12]. As a solution, Sun et al. [8] proposed a VI method to specify priors directly on the function implemented by the BNN, with promising results. Function-space priors incorporate interpretable knowledge about the variance, regularity, periodicity, or length scale, building on the extensive Gaussian Process (GP) literature [13]. But it turns out that the method by Sun et al. [8] is difficult to use in practice: the Kullback-Leibler (KL) divergence regularizing VI is infinite for most function-space priors of interest [14], and estimating finite variants of it is challenging [15]. ", "page_idx": 1}, {"type": "text", "text": "This paper addresses the lack of a procedure to specify informative priors in the Laplace approximation by proposing a method to use interpretable GP priors. Motivated by MAP estimation theory, we first derive an objective function that regularizes the neural network in function space using a GP prior, and whose minimizer corresponds to the MAP estimator of a GP on the space of functions represented by the network. We then apply the Laplace approximation to the log-posterior density induced by the objective, allowing us to effectively incorporate beliefs from a GP prior into a deep network (see Figure 1). Efficient matrix-free methods from numerical linear algebra allow scaling our method to large models and datasets. We show the effectiveness of our method by showing improved results in cases where prior knowledge is available, and competitive performance for black-box regression and classification tasks, where neural networks typically excel. We make the following contributions: ", "page_idx": 1}, {"type": "text", "text": "1. We propose a novel objective function for deep neural networks that allows incorporating interpretable prior knowledge through a GP prior in function space. 2. We develop an efficient and scalable Laplace approximation that endows the neural network with epistemic uncertainty reflecting the beliefs specified by the GP prior in function space. 3. A range of experiments shows that our method improves performance on tasks with prior knowledge in the form of a kernel, while showing competitive performance for black-box regression, classification, out-of-distribution detection, and Bayesian optimization tasks. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries: Laplace approximation in weight space ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For a given dataset $\\mathbb{D}=(X,Y)$ of inputs $\\pmb{X}=(\\pmb{x}^{(i)})_{i=1}^{n}\\in\\mathbb{X}^{n}$ and targets $\\pmb{Y}=(\\pmb{y}^{(i)})_{i=1}^{n}\\in\\mathbb{Y}^{n}$ , we consider a model of the data that is parameterized by a neural network $\\pmb{f}\\colon\\mathbb{X}\\times\\mathbb{W}\\rightarrow\\mathbb{R}^{d^{\\prime}}$ with weights $\\pmb{w}\\in\\mathbb{W}\\subset\\mathbb{R}^{p}$ , a likelihood $\\begin{array}{r}{p(\\pmb{Y}|\\,\\pmb{f}(\\pmb{X},\\pmb{w})):=\\prod_{i=1}^{n}p(\\pmb{y}^{(i)}\\,|\\,\\pmb{f}(\\pmb{x}^{(i)},\\pmb{w}))}\\end{array}$ , and a prior $p(w)$ . We seek the Bayesian posterior $p(\\pmb{w}\\mid\\mathbb{D})\\,\\propto\\,p(\\pmb{Y}\\mid f(\\pmb{X},\\pmb{w}))\\,p(\\pmb{w})$ . As it is intractable in BNNs, approximate inference methods have been developed. Among these, the Laplace approximation [16] to the posterior is given by a Gaussian distribution $q(\\mathbf{w}\\,=\\,\\pmb{w})\\,=\\,\\mathcal{N}\\left(\\pmb{\\dot{w}};\\pmb{w}^{\\star},\\pmb{\\dot{\\Lambda}}^{-1}\\right)$ , whose parameters are found by MAP estimation $w^{\\star}\\in\\arg\\operatorname*{min}_{{\\pmb w}\\in\\mathbb{W}}R_{\\mathbb{W}^{\\mathrm{S}}}({\\pmb w})$ of the weights, where ", "page_idx": 2}, {"type": "equation", "text": "$$\nR_{\\operatorname{WS}}(\\pmb{w}):=-\\log p(\\pmb{w}\\mid\\mathbb{D})=-\\log p(\\pmb{w})-\\sum_{i=1}^{n}\\log p(\\pmb{y}^{(i)}\\mid\\pmb{f}(\\pmb{x}^{(i)},\\pmb{w}))+\\operatorname{const}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "and computing the Hessian of the negative log-posterior $\\begin{array}{r}{\\mathbf{A}:=-\\left.\\mathbf{H}_{w}\\log p(\\pmb{w}\\mid\\mathbb{D})\\right\\vert_{\\pmb{w}=\\pmb{w}^{\\star}}\\in\\mathbb{R}^{p\\times p}}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "The linearized Laplace approximation. Computing $\\Lambda$ involves the Hessian of the neural network w.r.t. its weights which is generally expensive. To make the Laplace approximation scalable, it is common to linearize the network around $\\boldsymbol{w^{\\star}}$ before computing $\\pmb{\\Lambda}$ [17], ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(x,w)\\approx f(x,w^{\\star})+J_{w^{\\star}}(x)(w-w^{\\star})=:f^{\\mathrm{lin}}(x,w)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with Jacobian $J_{w^{\\star}}(x)=\\mathbf{D}_{w}\\,f(x,w)|_{w=w^{\\star}}$ . Thus, the approximate posterior precision matrix $\\Lambda$ is ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Lambda\\approx-\\left.\\mathbf{H}_{w}\\log p(\\pmb{w})\\right|_{w=w^{\\star}}-\\sum_{i=1}^{n}J_{w^{\\star}}(\\pmb{x}^{(i)})^{\\top}H_{w^{\\star}}^{(i)}J_{w^{\\star}}(\\pmb{x}^{(i)}),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "twhhe enree $\\begin{array}{r}{H_{\\pmb{w}^{\\star}}^{(i)}=\\mathbf{H}_{f}\\,\\log p(\\pmb{y}^{(i)}\\mid\\pmb{f})\\big|_{\\pmb{f}=\\pmb{f}(\\pmb{x}^{(i)},\\pmb{w}^{\\star})}.}\\end{array}$ thTeh ugse,n uernadleirz etdh e Glianuesasr-iNzeedw tnoent wmoartkri, xt h(eG GHeNs)s ioafn t hoef NLL. Crucially, the GGN is positive-(semi)definite even if \u2212 $\\mathbf{H}_{w}\\log p(\\boldsymbol{Y}\\mid f(\\boldsymbol{X},\\boldsymbol{w}))|_{\\boldsymbol{w}=\\boldsymbol{w}^{\\star}}$ is not. ", "page_idx": 2}, {"type": "text", "text": "3 FSP-LAPLACE: Laplace approximation under function-space priors ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A conventional Laplace approximation in neural networks requires a prior in weight space, with the issues discussed in Section 1. We now present FSP-LAPLACE, a method for computing Laplace approximations under interpretable GP priors in function space. Section 3.1 introduces an objective function that is a log-density under local linearization. Section 3.2 proposes a scalable algorithm for the linearized Laplace approximation with a function-space prior using matrix-free linear algebra. ", "page_idx": 2}, {"type": "text", "text": "3.1 Laplace approximations in function space ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We motivate our Laplace approximation in function space through the lens of MAP estimation in an (infinite-dimensional) function space under a GP prior. As Lebesgue densities do not exist in (infinite-dimensional) function spaces, we cannot minimize Equation (2.1) to find the MAP estimate. We address this issue using a generalized notion of MAP estimation, resulting in a minimizer of a regularized objective on the reproducing kernel Hilbert space $\\mathbb{H}_{\\pmb{\\Sigma}}$ . We then constrain the objective to the set of functions representable by the neural network and minimize it using tools from deep learning. Finally, local linearization of the neural network turns this objective into a valid negative log-density, from which we obtain the posterior covariance by computing its Hessian. ", "page_idx": 2}, {"type": "text", "text": "MAP estimation in neural networks under Gaussian process priors. The first step of the Laplace approximation is to find a MAP estimate of the neural network weights $\\pmb{w}$ , i.e., the minimizer of the negative log-density function in Equation (2.1) w.r.t. the Lebesgue measure as a \u201cneutral\u201d reference measure. In our method, we regularize the neural network in function space using a $d^{\\prime}$ -output GP prior $\\mathbf{f}\\,\\sim\\,{\\mathcal{G P}}\\left({\\pmb{\\mu}},{\\pmb{\\Sigma}}\\right)$ with index set $\\mathbb{X}$ . However, a (nonparametric) GP takes its values in an infinite-dimensional (Banach) space $\\mathbb{B}$ of functions, where no such reference Lebesgue measure exists [18]. Rather, the GP induces a prior measure $\\mathrm{P_{\\mathbb{B}}}$ on $\\mathbb{B}$ [19, Section B.2]. We are thus interested in the \u201cmode\u201d of the posterior measure $\\mathrm{P_{\\mathbb{B}}^{Y}}$ under $\\mathrm{P_{\\mathbb{B}}}$ defined by the Radon-Nikodym derivative $\\mathrm{P}_{\\mathbb{B}}^{Y}(\\mathrm{d}f)\\propto\\exp\\left(-\\Phi^{Y}(\\mathrm{d}f)\\right)\\mathrm{P}_{\\mathbb{B}}(\\mathrm{d}f)$ where $\\Phi^{Y}$ is the potential, in essence the negative log-likelihood functional of the model. In our case, $\\begin{array}{r}{\\Phi^{Y}(f)=-\\sum_{i=1}^{n}\\log p(\\pmb{y}^{(i)}\\mid\\pmb{f}(\\pmb{x}^{(i)}))}\\end{array}$ . Similar to Bayes\u2019 rule in finite dimensions, this Radon-Nikodym derivative relates the prior measure to the posterior measure by reweighting. Since there is no Lebesgue measure, the (standard) mode is undefined, and we therefore follow Lambley [20], using so-called weak modes. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Definition 1 (Weak Mode [see e.g., 20, Definition 2.1]). Let $\\mathbb{B}$ be a separable Banach space and let $\\mathrm{P}$ be a probability measure on $\\left(\\mathbb{B},B\\left(\\mathbb{B}\\right)\\right)$ . A weak mode of $\\mathrm{P}$ is any point $f^{\\star}\\in\\operatorname{supp}\\mathrm{P}$ such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{r\\downarrow0}\\operatorname*{sup}_{\\mathbf{P}}\\frac{\\mathrm{P}(B_{r}(\\pmb{f}))}{\\mathrm{P}(B_{r}(\\pmb{f}^{\\star}))}\\leq1\\qquad\\mathrm{for}\\,\\mathrm{all}\\,\\pmb{f}\\in\\mathbb{B}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Above, $\\beta\\left({\\mathbb{B}}\\right)$ denotes the Borel $\\sigma$ -algebra on $\\mathbb{B}$ and $B_{r}(\\pmb{f})\\subset\\mathbb{B}$ is an open ball with radius $r$ centered at a point $\\boldsymbol{f}\\in\\mathbb{B}$ . The intuition for the weak mode is the same as for the finite-dimensional mode (indeed they coincide when a Lebesgue measure exists), but the weak mode generalizes this notion to infinite-dimensional (separable) Banach spaces. Under certain technical assumptions on the potential $\\Phi^{Y}$ (see Assumption A.2 in the appendix), Lambley [20] shows that any solution to ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\arg\\operatorname*{min}_{\\pmb{f}\\in\\mathbb{H}_{\\pmb{\\Sigma}}}\\underbrace{\\Phi^{\\pmb{Y}}(\\pmb{f})+\\frac{1}{2}\\|\\pmb{f}-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\pmb{\\Sigma}}}^{2}}_{=:R_{\\mathrm{FSP}}(\\pmb{f})}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "is a weak mode of the posterior probability measure $\\mathrm{P_{\\mathbb{B}}^{Y}}$ ", "page_idx": 3}, {"type": "text", "text": "Equation (3.2) casts the weak mode of the posterior measure $\\mathrm{P_{\\mathbb{B}}^{Y}}$ as the solution of an optimization problem in the RKHS $\\mathbb{H}_{\\pmb{\\Sigma}}$ . We can now relate it to an optimization problem in weight space $\\mathbb{W}$ , and apply tools from deep learning. Informally speaking, we assume that the intersection of the set of functions represented by the neural network $\\mathbb{F}:=\\{\\pmb{f}(\\mathbf{\\cdot},\\pmb{w})\\colon\\pmb{w}\\in\\mathbb{W}\\}\\subset\\mathbb{B}\\subset(\\mathbb{R}^{d^{\\prime}})^{\\mathbb{X}}$ and $\\mathbb{H}_{\\pmb{\\Sigma}}$ is non-empty, and constrain the optimization problem in Equation (3.2) such that $\\pmb{f}$ belongs to both sets ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\underset{\\pmb{f}\\in\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}}{\\arg\\operatorname*{min}}\\,R_{\\mathrm{FSP}}(\\pmb{f}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Unfortunately, the framework by Lambley [20] cannot give probabilistic meaning to optimization problems with hard constraints of the form $\\pmb{f}\\in\\mathbb{F}$ . To address this, we adopt and elaborate on the informal strategy from Chen et al. [21, Remark 2.4]. Denote by $d_{\\mathbb{B}}(\\pmb{f},\\mathbb{F}):=\\operatorname*{inf}_{\\pmb{f}_{0}\\in\\mathbb{F}}\\lVert\\pmb{f}_{0}-\\pmb{f}\\rVert_{\\mathbb{B}}$ the distance of a function $\\pmb{f}\\in\\mathbb{B}$ to the set $\\mathbb{F}\\subset\\mathbb{B}$ . Under Assumption A.3, $d_{\\mathbb{B}}(f,\\mathbb{F})=0$ if and only if $\\pmb{f}\\in\\mathbb{F}$ by Lemma A.2. Hence, we can relax the constraint $\\pmb{f}\\in\\mathbb{F}$ by adding $\\frac{1}{2\\lambda^{2}}d_{\\mathbb{B}}^{2}(f,\\mathbb{F})$ with $\\lambda>0$ to the objective in Equation (3.2). Intuitively, the resulting optimization problem is the MAP problem for the measure PY ,\u03bb obtained by conditioning $\\mathrm{P_{\\mathbb{B}}^{Y}}$ on the observation that $d_{\\mathbb{B}}(\\mathbf{f},\\mathbb{F})+\\pmb{\\epsilon}_{\\lambda}=0$ , where $\\epsilon_{\\lambda}$ is independent centered Gaussian measurement noise with variance $\\lambda^{2}$ . Formally: ", "page_idx": 3}, {"type": "text", "text": "Proposition 1. Let Assumptions A.1 to A.3 hold. For $\\lambda>0$ , define $\\Phi^{Y,\\lambda}$ : $\\mathbb{B}\\to\\mathbb{R}$ , $f\\mapsto\\Phi^{Y}(f)+$ $\\textstyle{\\frac{1}{2\\lambda^{2}}}d_{\\mathbb{B}}^{2}(f,\\mathbb{F})$ . Then the posterior measure $\\mathrm{P}_{\\mathbb{B}}^{{\\cal Y},\\lambda}(\\mathrm{d}{\\pmb{f}})\\propto\\exp\\left(-\\Phi^{{\\cal Y},\\lambda}(\\mathrm{d}{\\pmb{f}})\\right)\\mathrm{P}_{\\mathbb{B}}(\\mathrm{d}{\\pmb{f}})$ has at least one weak mode $f^{\\star}\\in\\mathbb{H}_{\\Sigma}$ , and the weak modes of $\\mathrm{P_{\\mathbb{B}}^{Y,\\lambda}}$ coincide with the minimizers of ", "page_idx": 3}, {"type": "equation", "text": "$$\nR_{F S P}^{\\lambda}\\colon\\mathbb{H}_{\\Sigma}\\to\\mathbb{R},f\\mapsto\\Phi^{Y,\\lambda}(f)+\\frac{1}{2}\\|f-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\Sigma}}^{2}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As $\\lambda\\to0$ , the term $\\textstyle{\\frac{1}{2\\lambda^{2}}}d_{\\mathbb{B}}^{2}(f,\\mathbb{F})$ forces the minimizers of $R_{\\mathrm{FSP}}^{\\lambda}$ to converge to functions in $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ that minimize $R_{\\mathrm{FSP}}$ : ", "page_idx": 3}, {"type": "text", "text": "Proposition 2. Let Assumptions A.1 to A.3 hold. Let $\\{\\lambda_{n}\\}_{n\\in\\mathbb{N}}\\subset\\mathbb{R}_{>0}$ with $\\lambda_{n}\\to0,$ , and $\\{f_{n}^{\\star}\\}_{n\\in\\mathbb{N}}\\subset$ $\\mathbb{H}_{\\pmb{\\Sigma}}$ such that $f_{n}^{\\star}$ is a minimizer of $R_{F S P}^{\\lambda_{n}}$ . Then $\\{f_{n}^{\\star}\\}_{n\\in\\mathbb{N}}$ has an $\\mathbb{H}_{\\pmb{\\Sigma}}$ -weakly convergent subsequence with limit $f^{\\star}\\in\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ . Moreover, $f^{\\star}$ is a minimizer of RFSP on $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ . ", "page_idx": 3}, {"type": "text", "text": "We prove Propositions 1 and 2 in Appendix A.2. To provide some intuition about the mode of convergence in Proposition 2, we point out that $\\mathbb{H}_{\\pmb{\\Sigma}}$ -weak convergence of the subsequence $\\{f_{n_{k}}^{\\star}\\}_{k\\in\\mathbb{N}}$ implies both (strong/norm) convergence in the path space $\\mathbb{B}$ of the Gaussian process f (i.e., $\\begin{array}{r}{\\operatorname*{lim}_{k\\to\\infty}\\lVert f_{n_{k}}^{\\star}-f^{\\star}\\rVert_{\\mathbb{B}}=0)}\\end{array}$ and pointwise convergence (i.e., $\\begin{array}{r}{\\operatorname*{lim}_{k\\rightarrow\\infty}f_{n_{k}}^{\\star}({\\pmb x})=f^{\\star}({\\pmb x})\\,\\forall{\\pmb x}\\in\\mathbb{X})}\\end{array}$ . Finally, under certain technical assumptions, Theorem 4.4 from Cockayne et al. [22] can be used to show that, as $\\lambda\\to0$ , $\\mathrm{P_{\\mathbb{B}}^{Y,\\lambda}}$ converges2 to $\\mathrm{P_{\\mathbb{F}}^{Y}}$ defined by the Radon-Nikodym derivative $\\mathrm{P_{F}^{\\pmb{Y}}}(\\mathrm{d}{\\pmb{f}})\\propto$ $\\exp\\left(-\\Phi^{Y}(\\mathrm{d}f)\\right)\\mathrm{P_{F}}(\\mathrm{d}\\bar{f})$ where $\\mathrm{P_{\\mathbb{F}}}$ is the regular conditional probability measure $\\mathrm{P_{\\mathbb{B}}}(\\cdot\\mid\\mathbf{f}\\in\\mathbb{F})$ . ", "page_idx": 3}, {"type": "text", "text": "Summarizing informally, we address the nonexistence of a density-based MAP estimator by constructing a family $\\{f_{\\lambda}^{\\star}\\}_{\\lambda>0}$ of weak modes of the related \u201crelaxed\u201d posteriors $\\mathrm{P}_{\\mathbb{B}}^{Y,\\lambda}(\\mathrm{d}f)=\\mathrm{P}_{\\mathbb{B}}^{\\bar{Y}}(\\mathrm{d}f\\mid$ $d_{\\mathbb{B}}(\\mathbf{f},\\mathbb{F})\\!+\\!\\epsilon_{\\lambda}=0\\rangle$ (Proposition 1). These weak modes converge to minimizers $f^{\\star}$ of the optimization problem in Equation (3.3) as $\\lambda\\to0$ (Proposition 2). Moreover, under certain technical assumptions, the relaxed posteriors PY ,\u03bb converge to the \u201ctrue\u201d posterior $\\mathrm{P_{\\mathbb{F}}^{Y}}$ as $\\lambda\\rightarrow0$ . Given the above, we conjecture that the $f^{\\star}$ are weak modes of $\\mathrm{P_{\\mathbb{F}}^{Y}}$ , and leave the proof for future work. This motivates using the objective in Equation (3.3) to find the weak mode of the posterior measure $\\mathrm{P_{\\mathbb{F}}^{Y}}$ that we wish to Laplace-approximate. The next paragraph shows how this objective becomes a valid log-density. ", "page_idx": 4}, {"type": "text", "text": "The FSP-LAPLACE objective as an unnormalized log-density. As a first step, we use Algorithm 1, discussed in detail below, to train the neural network using the objective function3 ", "text_level": 1, "page_idx": 4}, {"type": "equation", "text": "$$\nR_{\\mathrm{FSP}}(\\pmb{w}):=R_{\\mathrm{FSP}}(\\pmb{f}(\\,\\cdot\\,,\\pmb{w}))=-\\sum_{i=1}^{n}\\log p(\\pmb{y}^{(i)}\\mid\\pmb{f}(\\pmb{x}^{(i)},\\pmb{w}))+\\frac{1}{2}\\|\\pmb{f}(\\,\\cdot\\,,\\pmb{w})-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\pmb{x}}}^{2}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We then intuitively want to use the same objective function to compute an approximate posterior over the weights using a Laplace approximation. For this to be well-defined, $R_{\\mathrm{FSP}}(w)$ needs to be a valid unnormalized negative log-density, i.e., $w\\mapsto\\exp(-R_{\\mathrm{FSP}}(w))$ needs to be integrable. However, without weight-space regularization, this often fails to be the case (e.g., due to continuous symmetries in weight space). Our method works around this issue by linearizing the network locally around $\\pmb{w}^{\\star}$ after training (see Equation (2.2)) and then applying a Laplace approximation to $R_{\\mathrm{FSP}}^{\\mathrm{lin}}(\\pmb{w}):=R_{\\mathrm{FSP}}(\\pmb{f}^{\\mathrm{lin}}(\\,\\cdot\\,,\\pmb{w}))$ . In this case, the RKHS regularizer in $\\bar{R}_{\\mathrm{FSP}}^{\\mathrm{lin}}$ can be rewritten as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\|\\pmb{f}^{\\mathrm{lin}}(\\,\\cdot\\,,\\pmb{w})-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\Sigma}}^{2}=\\frac{1}{2}(\\pmb{w}-\\pmb{\\mu}_{w^{\\star}})^{\\top}\\pmb{\\Sigma}_{w^{\\star}}^{\\dagger}(\\pmb{w}-\\pmb{\\mu}_{w^{\\star}})+\\mathrm{const.},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $(\\Sigma_{w^{\\star}}^{\\dagger})_{i j}:=\\langle(J_{w^{\\star}})_{i},(J_{w^{\\star}})_{j}\\rangle_{\\mathbb{H}_{\\Sigma}}$ (here, $\\pmb{\\Sigma}_{\\pmb{w}^{\\star}}^{\\dagger}$ is the Moore\u2013Penrose pseudoinverse), $v_{i}=$ $\\langle(J_{w^{\\star}})_{i},f(\\,\\cdot\\,,\\,\\mathbf{\\bar{w}}^{\\star})-\\mu\\rangle_{\\mathbb{H}_{\\Sigma}}$ , $\\mu_{w^{\\star}}:=w^{\\star}-\\Sigma_{w^{\\star}}v$ . Crucially, $\\Sigma_{w^{\\star}}$ is positive-(semi)definite. This means that $\\exp(-R_{\\mathrm{FSP}}^{\\mathrm{lin}}(\\,\\cdot\\,))$ is normalizable over $\\operatorname{im}\\left(\\Sigma_{w^{\\star}}\\right)$ , i.e., we don\u2019t integrate over the null space. Note that this approximation also induces a (potentially degenerate) Gaussian \u201cprior\u201d w $\\sim$ $\\bar{\\mathcal{N}}\\left(\\mu_{w^{\\star}},\\Sigma_{w^{\\star}}\\right)$ over the weights. ", "page_idx": 4}, {"type": "text", "text": "Using model linearization, we can also establish a correspondence between the Gaussian process prior in function space and the induced prior over the weights. Namely, the resulting expression is the Lebesgue density of the $\\mathbb{H}_{\\pmb{\\Sigma}}$ -orthogonal projection of the GP prior onto the finite-dimensional subspace spanned by the \u201cfeature functions\u201d $\\bar{(J_{w^{\\star}})_{i}}$ learned by the neural network. Hence, our model inherits the prior structure in function space on the features induced by the Jacobian, zeroing out the probability mass in the remaining directions. ", "page_idx": 4}, {"type": "text", "text": "3.2 Algorithmic Considerations ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Training with the FSP-LAPLACE objective function. Evaluating the FSP-LAPLACE objective proposed in the previous section requires computing the RKHS norm of the neural network. Unfortunately, this does not admit a closed-form expression in general. Hence, we use the approximation ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Vert f(\\cdot,w)-\\mu\\Vert_{\\mathbb{H}_{\\Sigma}}^{2}\\approx\\underbrace{\\left(f(C,w)-\\mu(C)\\right)^{\\top}\\Sigma(C,C)^{-1}(f(C,w)-\\mu(C))}_{=\\Vert h_{C}(\\cdot,w)\\Vert_{\\mathbb{H}_{\\Sigma}}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $C\\in\\mathbb{X}^{n_{C}}$ is a set of $n_{C}$ context points and $h_{C}(x,w):=\\Sigma(x,C)\\Sigma(C,C)^{-1}(f(C,w)-$ $\\mu(C))\\in\\mathbb{H}_{\\Sigma}$ . The function $h_{C}$ is the minimum-norm interpolant of $f(\\mathbf{\\Gamma}\\cdot,w)\\!-\\!\\mu$ at $_{C}$ in $\\mathbb{H}_{\\pmb{\\Sigma}}$ . Hence, the estimator of the RKHS norm provably underestimates, i.e., $\\|h_{C}(\\mathbf{\\cdot},\\mathbf{\\cdot}w)\\|_{\\mathbb{H}_{\\Sigma}}^{2}\\leq\\|f(\\mathbf{\\cdot},w)-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\Sigma}}^{2}$ . ", "page_idx": 4}, {"type": "text", "text": "During training, we need to compute $\\|h_{C}(\\cdot,\\pmb{w})\\|_{\\mathbb{H}_{\\Sigma}}^{2}$ at every optimizer step. Since this involves solving a linear system in $n_{C}$ unknowns and, more importantly, evaluating the neural network on the $n_{C}$ context points, we need to keep $n_{C}$ small for computational efficiency. We find that sampling an i.i.d. set of context points at every training iteration from a distribution $\\mathrm{P}_{C}$ is an effective strategy for keeping $n_{C}$ small while ensuring that the neural network is appropriately regularized. The resulting training procedure is outlined in Algorithm 1. ", "page_idx": 4}, {"type": "table", "img_path": "83vxe8alV4/tmp/05a8dbf5082d950878dc8ff854b3b6d678efb856d688115a7e9bd92e941a1330.jpg", "table_caption": ["Algorithm 1 RKHS-regularized model training ", "Algorithm 2 Linearized Laplace approximation with Gaussian process priors "], "table_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "83vxe8alV4/tmp/adb66dbd69d0b735cdf436102fb6a3d7401eb80d1007b3c5913bcb5fe5cd000f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Efficient linearized Laplace approximations of the FSP-LAPLACE objective. Once a minimum $w^{\\star}$ of $R_{\\mathrm{FSP}}$ is found, we compute a linearized Laplace approximation at $w^{\\star}$ . The Hessian of $R_{\\mathrm{FSP}}$ is then ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{A}={\\boldsymbol{\\Sigma}}_{w^{\\star}}^{\\dagger}-\\sum_{i=1}^{n}{\\boldsymbol{J}}_{w^{\\star}}({\\boldsymbol{x}}^{(i)})^{\\top}{\\boldsymbol{H}}_{w^{\\star}}^{(i)}{\\boldsymbol{J}}_{w^{\\star}}({\\boldsymbol{x}}^{(i)}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Again, the RKHS inner products in the entries of $\\pmb{\\Sigma}_{\\pmb{w}^{\\star}}^{\\dagger}$ do not admit general closed-form expressions. Hence, we use the same strategy as before to estimate $\\Sigma_{w^{\\star}}^{\\dagger}\\approx J_{w^{\\star}}(C)^{\\top}\\Sigma(C,C)^{-1}J_{w^{\\star}}(C)$ at another set $_{C}$ of context points. Unlike above, for a Laplace approximation, it is vital to use a large number of context points to capture the prior beliefs well. Luckily, $\\pmb{\\Sigma}_{w^{\\star}}^{\\dag}$ only needs to be computed once, at the end of training. But for large networks and large numbers of context points, it is still infeasible to compute or even represent $\\pmb{\\Sigma}_{w^{\\star}}^{\\dag}$ in memory. To address this problem, we devise an efficient routine for computing (a square root of) the approximate posterior covariance matrix $\\Lambda^{\\dagger}$ , outlined in Algorithm 2. Our method is matrix-free, i.e. it never explicitly constructs any big (i.e., $p\\times p,p\\times n_{C}$ , or $n_{C}\\times n_{C})$ ) matrices in memory. This allows the method to scale to large models. ", "page_idx": 5}, {"type": "text", "text": "We start by computing a rank $r\\,\\ll\\,\\operatorname*{min}(n_{C}d^{\\prime},p)$ approximation of the (pseudo-)inverted kernel Gram matrix $\\Sigma(C,C)^{\\dagger}\\approx L L^{\\top}$ using fully-reorthogonalized Lanczos iteration [23, Section 10.1] with an embedded $L D L^{\\top}$ -factorization [23, Section 11.3.5]. This only needs access to matrix-vector products with $\\Sigma(C,C)$ , which can be implemented efficiently without materializing the matrix in memory. Moreover, kernel Gramians typically exhibit rapid spectral decay [see e.g., 24], which makes the low-rank approximation particularly accurate. The low-rank factors $\\textbf{\\emph{L}}$ then yield a rank $r$ approximation of $\\Sigma_{w^{\\star}}^{\\dagger}\\approx M M^{\\top}$ with $M:=J_{w^{\\star}}(C)^{\\top}L$ , which is embarassingly parallel and can be computed using backward-mode autodiff to avoid materializing the network Jacobians in memory. An eigendecomposition of $M M^{\\top}=U_{M}D_{M}^{2}U_{M}^{\\top}$ can be computed in $\\mathcal{O}(p r^{2})$ time from a thin SVD of $M=U_{M}D_{M}V_{M}^{\\top}$ . The eigenvectors $U_{M}$ define an orthogonal projector $P:=U_{M}U_{M}^{\\top}$ onto the range and an orthogonal projector $P_{0}:=I-U_{M}U_{M}^{\\top}$ onto the nullspace of $M M^{\\top}$ . This means that we have the decomposition $\\Lambda=P\\Lambda P^{\\top}+P_{0}\\Lambda P_{0}^{\\top}=U_{M}A U_{M}^{\\top}+P_{0}\\Lambda P_{0}^{\\top}$ with ", "page_idx": 5}, {"type": "equation", "text": "$$\nA:=U_{M}^{\\top}\\Lambda U_{M}=D_{M}^{2}-\\sum_{i=1}^{n}U_{M}^{\\top}J_{w^{\\star}}(x^{(i)})^{\\top}H_{w^{\\star}}^{(i)}J_{w^{\\star}}(x^{(i)})U_{M}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Finally, by computing an eigendecomposition of $\\pmb{A}=\\pmb{U}_{\\pmb{A}}\\pmb{D}_{\\pmb{A}}\\pmb{U}_{\\pmb{A}}^{\\top}\\in\\mathbb{R}^{r\\times r}$ in $\\mathcal{O}(r^{3})$ time, we obtain an eigendecomposition of $\\mathbf{A}\\approx U_{M}A U_{M}^{\\top}\\,=\\,(U_{M}U_{A})D_{A}\\bar{(U_{M}U_{A})^{\\top}}$ , which can be used to obtain a matrix-free representation of (a square root of) the (pseudo-)inverse of $\\pmb{\\Lambda}$ . Unfortunately, due to numerical imprecision, it is difficult to distinguish between zero eigenvalues of $\\pmb{A}$ and those with small positive magnitudes. Since we need to pseudo-invert the matrix to obtain the covariance matrix, this can explode predictive variance. As a remedy, we use a heuristic based on the observation that, in a linear-Gaussian model, the marginal variance of the posterior is always upper-bounded by the marginal variance of the prior. Hence, we impose that diag $\\left(J_{w^{\\star}}(C_{i})\\Lambda^{\\dagger}\\dot{J}_{w^{\\star}}(\\dot{C}_{i})\\right)\\leq\\,\\mathrm{diag}\\,\\dot{\\Sigma}(C_{i},C_{i})$ for all $i=1,\\dots,n_{C}$ by successively truncating the smallest eigenvalues in $\\dot{D}_{A}$ until the condition is fulfliled. This turns out to be an effective strategy to combat exploding predictive variance in practice. ", "page_idx": 6}, {"type": "text", "text": "Choice of context points. Methods for regularizing neural networks in function space rely on a set of context points to evaluate the regularizer [8, 9, 25, 26]. The context points should cover the set of input locations where it is plausible that the model might be evaluated when deployed. Popular strategies include uniform sampling from a bounded subset of the input space [8, 9, 25, 26], from the training data [8], and from additional (possibly unlabeled) datasets [25, 26]. For MAP estimation, we choose a uniform context point distribution $\\mathrm{P}_{C}$ or sample from other datasets for high-dimensional inputs. We compute the posterior covariance using samples $_{C}$ from a low-discrepancy sequence, which effectively cover high-dimensional spaces. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate FSP-LAPLACE on synthetic and real-world data, demonstrating that our method effectively incorporates beliefs specified through a GP prior; that it improves performance on regression tasks for which we have prior knowledge in the form of a kernel (Mauna Loa and ocean current modeling); and that it shows competitive performance on regression, classification, out-of-distribution detection, and Bayesian optimization tasks compared to baselines. ", "page_idx": 6}, {"type": "text", "text": "Baselines. We compare FSP-LAPLACE to a deterministic neural network fit using maximum a-posteriori estimation with an isotropic Gaussian prior on the weights (MAP) and a neural network for which we additionally compute the standard linearized Laplace approximation (Laplace) [17]. We further compare our method to FVI [8], which uses GP priors with VI, to a Gaussian process (GP) [13] when the size of the dataset allows it, and to a sparse Gaussian process (sparse GP) [27]. We use the full Laplace approximation when the size of the neural network allows it, and otherwise consider the K-FAC or diagonal approximations [28]. All neural networks share the same architecture. ", "page_idx": 6}, {"type": "text", "text": "Qualitative evaluation on synthetic data. We consider two synthetic data tasks: a 1-dimensional regression task with randomly drawn noisy measurements of the function $y=\\sin(2\\pi x)$ , and the 2-dimensional two-moons classification task from the scikit-learn library [29]. For the regression task, data points are shown as gray circles, functions drawn from the posterior as green lines and the inferred mean function as a red line (see Figures 1 and C.1 to C.4). For the classification task, we plot the predictive mean and 2-standard-deviations of the predictions for class 1 (blue circles) in Figures C.5 and C.6. We apply FSP-LAPLACE to the data with different GP priors and find that it successfully adapts to the specified beliefs. For instance, by varying the GP prior, we can make our method generate functions that are periodic within the support of the context points (Figure C.2), and control their smoothness (Figure 1) and length scale (Figure C.3) without modifying the network\u2019s architecture, or adding features. Such flexibility is impossible with the isotropic Gaussian weightspace priors used in the Laplace and MAP baselines. These results carry over to classification, where our method shows a smooth decision boundary when equipped with an RBF kernel (Figure C.6), and a rough decision boundary when equipped with a Matern-1/2 kernel (Figure C.5). Unlike the Laplace and MAP baselines, whose predictions remain confident beyond the support of the data, the FSP-LAPLACE\u2019s posterior mean reverts to the zero-mean prior, and its posterior variance increases. Our method also captures the properties specified by the GP prior better than FVI, especially for rougher Matern-1/2 kernels (Figures 1 and C.5). While a sufficient number of context points is necessary to capture the beliefs specified by the GP prior, we find that, even with a very small number ", "page_idx": 6}, {"type": "image", "img_path": "83vxe8alV4/tmp/45e5c2fca42ffd94832ce8b0163609ed3a6ae14fa7e3538b4f3fde45d3ec83ae.jpg", "img_caption": ["Figure 2: Results for the ocean current modeling experiment. We report the mean velocity vectors, the norm of their standard-deviation and the squared errors of compared methods. Unlike the Laplace, we find that FSP-LAPLACE accurately captures ocean current dynamics. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 1: Results for the Mauna Loa $\\mathrm{CO_{2}}$ prediction and ocean current modeling tasks. Incorporating knowledge via the GP prior in our FSP-LAPLACE improves performance over the standard Laplace. ", "page_idx": 7}, {"type": "table", "img_path": "83vxe8alV4/tmp/4f903e9e1b07e7577725c0a74ec913a81e6774965dc354b3950dd6b8101c55b7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "of context points, our method produces useful uncertainty estimates and reverts to the prior mean (Figures C.7 and C.8). ", "page_idx": 7}, {"type": "text", "text": "4.1 Quantitative evaluation on real-world data ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now move on to investigate FSP-LAPLACE on two real-world scientific modeling tasks: forecasting the concentration of $\\mathrm{CO_{2}}$ at the Mauna Loa observatory and predicting ocean currents in the Gulf of Mexico. We then assess the performance of our method on standard benchmark regression, classification, out-of-distribution detection, and Bayesian optimization tasks. When reporting results, we bold the score with the highest mean as well as any scores whose standard-error bars overlap. ", "page_idx": 7}, {"type": "text", "text": "Mauna Loa dataset. We consider the task of modeling the monthly average atmospheric $\\mathrm{CO_{2}}$ concentration at the Mauna Loa observatory in Hawaii from 1974 to 2024 using data collected from the NORA global monitoring laboratory4 [30]. This 1-dimensional dataset is very accurately modeled by a combination of multiple kernels proposed in Rasmussen and Williams [13, Section 5.4.3]. We equip FSP-LAPLACE with this informative kernel and with additional periodic features, and compare to FVI with the same prior and additional periodic features, to a GP with the same prior, and to the linearized Laplace with the same additional periodic features. Using periodic features (partially) reflects the prior knowledge carried by the kernel. Results are presented by Table 1 and Figure C.9 in the Appendix. We find that incorporating prior beliefs both via an informative prior and periodic features in FSP-LAPLACE significantly reduces the mean squared error (MSE) compared to Laplace and GP baselines, and that our method is also more accurate than FVI, which uses variational inference. In terms of expected log-likelihood, all neural networks under-estimate the likelihood scale, which results in poorer scores than the GP. ", "page_idx": 7}, {"type": "text", "text": "Ocean current modeling. We further evaluate FSP-LAPLACE\u2019s ability to take into account prior knowledge by considering an ocean current modeling task where we are given sparse 2-dimensional observations of velocities of ocean drifter buoys, and we are interested in estimating ocean currents further away from the buoys. For this, we consider the GulfDrifters dataset [31] and we follow the setup by Shalashilin [32]. We incorporate known physical properties of ocean currents into the considered models by applying the Helmholtz decomposition to the GP prior\u2019s kernel [33] as well as to the neural network. Results are shown in Table 1 and in Figure 2. We find that FSP-LAPLACE strongly improves over Laplace, FVI and GP in terms of expected log-likelihood, and performs competitively in terms of mean squared error (MSE). FSP-LAPLACE also improves MSE and test expected log-likelihood over FVI, which strongly underestimates the predictive variance. ", "page_idx": 7}, {"type": "image", "img_path": "83vxe8alV4/tmp/1b528e7f0ed63185464d5c4006dbc2b4a865c473f83ca7b9b37a4ab610ba4b6c.jpg", "img_caption": ["Figure 3: Results using our method (FSP-LAPLACE) as a surrogate model for Bayesian optimization. We find that FSP-LAPLACE performs particularly well on lower-dimensional problems, where it converges more quickly and to higher rewards than the Laplace, obtaining comparable scores as the Gaussian process (GP). "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "83vxe8alV4/tmp/8d0c10d3e80cd64ee274d74af12ff61e6b2ec315089b3b61b36521a3b23510e4.jpg", "table_caption": ["Table 2: Test expected log-likelihood, accuracy, expected calibration error and OOD detection accuracy on MNIST and FashionMNIST. FSP-LAPLACE performs strongly among baselines matching the accuracy of best-performing baselines and obtaining the highest expected log-likelihood and out-of-distribution detection accuracy. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Image classification. We further evaluate our method on the MNIST [34] and FashionMNIST [35] image classification datasets using a convolutional neural network. We compare our model to FVI, Laplace, MAP, and Sparse GP baselines, as the scale of the datasets forbids exact GP inference. For FSP-LAPLACE and FVI, we compare using context points drawn from a uniform distribution (RND) and drawn from the Kuzushiji-MNIST dataset (KMNIST) following the setup by Rudner et al. [25]. Results are presented in Table 2. Although these datasets are particularly challenging to our method, which is regularized in function space, we find that FSP-LAPLACE performs strongly and matches or exceeds the expected log-likelihood and predictive accuracy of best-performing baselines. It also yields well-calibrated models with low expected calibration error (ECE). ", "page_idx": 8}, {"type": "text", "text": "Out-of-distribution detection. We now investigate whether the epistemic uncertainty of FSPLAPLACE is predictive for out-of-distribution detection (OOD). We follow the setup by Osawa et al. [36] and report the accuracy of a single threshold to classify OOD from in-distribution (ID) data based on the predictive uncertainty. Additional details are provided in Appendix B.2. FSP-LAPLACE with context points sampled from KMNIST performs strongly, obtaining the highest out-of-distribution detection accuracy (see Table 2, note that FSP-LAPLACE makes no assumption on whether context points are in or out of distribution). This can be further observed in Figure C.10 in the Appendix, where the predictive entropy of ID data points is tightly peaked around 0, whereas the predictive entropy of OOD data points is highly concentrated around the maximum entropy of the softmax distribution $(\\ln(10)\\approx2.3)$ . With RND context points, our method performs comparably to the Laplace baseline. ", "page_idx": 8}, {"type": "text", "text": "Bayesian optimization. We finally evaluate the epistemic uncertainty of FSP-LAPLACE as a surrogate model for Bayesian optimization. We consider a setup derived from Li et al. [7], comparing to FVI, the linearized Laplace, and to a GP. Results are summarized in Figure 3. We find that our method performs particularly well on lower-dimensional tasks, where it converges both faster and to higher rewards than Laplace, and noticeably strongly improves over a Gaussian process on PDE. On higher-dimensional tasks, our method performs comparatively well to Laplace and GP baselines. ", "page_idx": 8}, {"type": "text", "text": "5 Related work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Laplace approximation in neural networks. First introduced by MacKay [37], the Laplace approximation gained strong traction in the Bayesian deep learning community with the introduction of scalable log-posterior Hessian approximations [28, 38], and the so-called linearized Laplace, which solves the underfitting issue observed with standard Laplace [17, 39\u201341]. In addition to epistemic uncertainty estimates, the Laplace approximation also provides a method to select prior parameters via marginal likelihood estimation [11, 12]. Recent work has made the linearized Laplace more scalable by restricting inference to a subset of parameters [42], by exploiting its GP formulation [17] to apply methods from the scalable GP literature [43\u201345], or by directly sampling from the Laplace approximation without explicitly computing the covariance matrix [46]. While these approaches use the GP formulation to make the linearized Laplace more scalable, we are unaware of any method that uses GP priors to incorporate interpretable prior beliefs within the Laplace approximation. ", "page_idx": 9}, {"type": "text", "text": "BNNs with function-space priors. In the context of variational inference, function-space priors in BNNs demonstrate improvements in predictive performance compared to weight-space priors [8]. While this idea might seem sound, it turns out that the KL divergence in the VI objective is infinite for most cases of interest due to mismatching supports between the function-space prior and BNN\u2019s predictive posterior [14], which therefore requires additional regularization to be well defined [8]. Due to this issue, other work [47] considers generalized VI [10] using the regularized KL divergence [48] or abandons approximating the neural network\u2019s posterior and instead uses deterministic neural networks as basis functions for Bayesian linear regression [15] or for the mean of a sparse GP [49]. In contrast, our method does not compute a divergence in function space, but only the RKHS norm under the prior\u2019s kernel, thus circumventing the issue of mismatching support. Alternatively, rather than directly placing a prior on the function generated by a BNN, researchers have investigated methods to find weight-space priors whose pushforward approximates a target function-space measure by minimizing a divergence [9, 50], using the Ridgelet transform [51], or changing the BNN\u2019s architecture [52]. ", "page_idx": 9}, {"type": "text", "text": "Regularizing neural networks in function space. Arguing that one ultimately only cares about the output function of the neural network, it has been proposed to regularize neural networks in function space, both showing that norms could be efficiently estimated and that such regularization schemes performed well in practice [26, 53\u201355]. Unlike FSP-LAPLACE, none of these methods allow to specify informative beliefs via a GP prior. Our method uses the same RKHS norm estimator as Chen et al. [54] (however, under a different kernel) by sampling a new batch of context points at each update step. Similarly, Rudner et al. [26] propose an empirical prior on the weights that regularizes the neural network in function space, which they use for MAP estimation or approximate posterior inference. The MAP objective resembles ours, but unlike our method, uses the kernel induced by the last layer of the neural network and includes an additional Gaussian prior on the weights. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We propose a method for applying the Laplace approximation to neural networks with interpretable Gaussian process priors in function space. This addresses the issue that conventional applications of approximate Bayesian inference methods to neural networks require posing a prior in weight space, which is virtually impossible because weight space is not interpretable. We address the non-existence of densities in (infinite-dimensional) function space by generalizing the notion of a MAP estimate to the limit of a sequence of weak modes of related posterior measures, leading us to propose a simple objective function. We further mitigate the computational cost of calculating high-dimensional curvature matrices using scalable methods from matrix-free linear algebra. By design, our method works best in application domains where prior information can be encoded in the language of Gaussian processes. This is confirmed by experiments on scientific data and Bayesian optimization. In high-dimensional spaces, where explicit prior knowledge is difficult to state, Gaussian process priors are naturally at a disadvantage. While we do demonstrate superior performance on image data, it is yet unclear how to find good function-space priors in such high-dimensional spaces. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "TC, MP, PH, and RB are funded by the DFG Cluster of Excellence \u201cMachine Learning - New Perspectives for Science\u201d, EXC 2064/1, project number 390727645; the German Federal Ministry of Education and Research (BMBF) through the T\u00fcbingen AI Center (FKZ: 01IS18039A); and funds from the Ministry of Science, Research and Arts of the State of Baden-W\u00fcrttemberg. MP and PH gratefully acknowledge financial support by the European Research Council through ERC StG Action 757275 / PANAMA, and ERC CoG Action 101123955 ANUBIS. VF was supported by a Branco Weiss Fellowship. RB further acknowledges funding by the German Research Foundation (DFG) for project 448588364 of the Emmy Noether Programme. The authors thank the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for supporting TC and MP. ", "page_idx": 10}, {"type": "text", "text": "Bibliography ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Nina Effenberger, Marvin Pf\u00f6rtner, Philipp Hennig, and Nicole Ludwig. Probabilistic wind speed downscaling for future wind power assessment. URL https://meetingorganizer. copernicus.org/EGU24/EGU24-2034.html.   \n[2] Abhaya Indrayan. Aleatory and epistemic uncertainties can completely derail medical research results. Journal of postgraduate medicine, 66, 03 2020. doi:10.4103/jpgm.JPGM_585_19.   \n[3] Kenza Tazi, Jihao Andreas Lin, Alex S Gardner, ST John, Hong Ge, and Richard E Turner. Towards more interpretable and robust geospatial modelling with gaussian processes. AGU23, 2023.   \n[4] Alexander Immer, Maciej Korzepa, and Matthias Bauer. Improving predictions of bayesian neural nets via local linearization, 2021. [5] Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. Laplace redux \u2013 effortless bayesian deep learning, 2022.   \n[6] Vincent Fortuin. Priors in bayesian deep learning: A review, 2022.   \n[7] Yucen Lily Li, Tim G. J. Rudner, and Andrew Gordon Wilson. A study of bayesian neural network surrogates for bayesian optimization, 2024.   \n[8] Shengyang Sun, Guodong Zhang, Jiaxin Shi, and Roger Grosse. Functional variational bayesian neural networks, 2019.   \n[9] Ba-Hien Tran, Simone Rossi, Dimitrios Milios, and Maurizio Filippone. All you need is a good functional prior for bayesian deep learning, 2022.   \n[10] Jeremias Knoblauch, Jack Jewson, and Theodoros Damoulas. Generalized variational inference: Three arguments for deriving new posteriors, 2019.   \n[11] Alexander Immer, Matthias Bauer, Vincent Fortuin, Gunnar R\u00e4tsch, and Mohammad Emtiyaz Khan. Scalable marginal likelihood estimation for model selection in deep learning, 2021.   \n[12] Javier Antor\u00e1n, David Janz, James Urquhart Allingham, Erik Daxberger, Riccardo Barbano, Eric Nalisnick, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Adapting the linearised laplace model evidence for modern deep learning, 2022.   \n[13] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine learning. Adaptive computation and machine learning. MIT Press, 2006. ISBN 026218253X.   \n[14] David R. Burt, Sebastian W. Ober, Adri\u00e0 Garriga-Alonso, and Mark van der Wilk. Understanding variational inference in function-space, 2020.   \n[15] Chao Ma and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Functional variational inference based on stochastic process generators. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 21795\u201321807. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/ paper_files/paper/2021/file/b613e70fd9f59310cf0a8d33de3f2800-Paper.pdf.   \n[16] David J. C. MacKay. The Evidence Framework Applied to Classification Networks. Neural Computation, 4(5):720\u2013736, 09 1992. ISSN 0899-7667. doi:10.1162/neco.1992.4.5.720. URL https://doi.org/10.1162/neco.1992.4.5.720.   \n[17] Alexander Immer, Maciej Korzepa, and Matthias Bauer. Improving predictions of bayesian neural nets via local linearization, 2021.   \n[18] John C. Oxtoby. Invariant measures in groups which are not locally compact. Transactions of the American Mathematical Society, 60:215\u2013237, 1946. doi:10.1090/S0002-9947-1946-0018188-5.   \n[19] Marvin Pf\u00f6rtner, Ingo Steinwart, Philipp Hennig, and Jonathan Wenger. Physics-informed Gaussian process regression generalizes linear PDE solvers, 2022.   \n[20] Hefin Lambley. Strong maximum a posteriori estimation in Banach spaces with Gaussian priors. Inverse Problems, 39(12):125010, 2023. doi:10.1088/1361-6420/ad07a4.   \n[21] Yifan Chen, Bamdad Hosseini, Houman Owhadi, and Andrew M. Stuart. Solving and learning nonlinear PDEs with Gaussian processes. Journal of Computational Physics, 447, 2021. doi:10.1016/j.jcp.2021.110668.   \n[22] Jon Cockayne, Chris J. Oates, T. J. Sullivan, and Mark Girolami. Bayesian probabilistic numerical methods. SIAM Review, 61(4):756\u2013789, 2019. doi:10.1137/17M1139357.   \n[23] Gene H. Golub and Charles F. Van Loan. Matrix Computations. Johns Hopkins Studies in the Mathematical Sciences. The Johns Hopkins University Press, Baltimore, fourth edition, 2013.   \n[24] Francis Bach. Unraveling spectral properties of kernel matrices \u2013 I, 2024. URL https: //francisbach.com/spectrum-kernel-matrices-i/.   \n[25] Tim G. J. Rudner, Zonghao Chen, Yee Whye Teh, and Yarin Gal. Tractable function-space variational inference in bayesian neural networks, 2023.   \n[26] Tim G. J. Rudner, Sanyam Kapoor, Shikai Qiu, and Andrew Gordon Wilson. Function-space regularization in neural networks: A probabilistic perspective, 2023.   \n[27] James Hensman, Nicolo Fusi, and Neil D. Lawrence. Gaussian processes for big data, 2013.   \n[28] Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id $=$ Skdvd2xAZ.   \n[29] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.   \n[30] Charles D Keeling and T P Whorf. Monthly carbon dioxide measurements on Mauna Loa, Hawaii from 1958 to 1998, 2000. URL https://doi.org/10.1594/PANGAEA.56536.   \n[31] Jonathan M. Lilly and Paula P\u00e9rez-Brunius. GulfDrifters: A consolidated surface drifter dataset for the Gulf of Mexico, January 2021. URL https://doi.org/10.5281/zenodo.4421585.   \n[32] Ivan Shalashilin. Gaussian processes for vector fields and ocean current modelling, March 2024. URL https://docs.jaxgaussianprocesses.com/examples/oceanmodelling/.   \n[33] Renato Berlinghieri, Brian L. Trippe, David R. Burt, Ryan Giordano, Kaushik Srinivasan, Tamay \u00d6zg\u00f6kmen, Junfei Xia, and Tamara Broderick. Gaussian processes at the helm(holtz): A more fluid model for ocean currents, 2023.   \n[34] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http: //yann.lecun.com/exdb/mnist/.   \n[35] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, 2017.   \n[36] Kazuki Osawa, Siddharth Swaroop, Anirudh Jain, Runa Eschenhagen, Richard E. Turner, Rio Yokota, and Mohammad Emtiyaz Khan. Practical deep learning with bayesian principles, 2019.   \n[37] David John Cameron MacKay. Bayesian methods for adaptive models. 1992. URL https: //api.semanticscholar.org/CorpusID:123141880.   \n[38] James Martens. New insights and perspectives on the natural gradient method, 2020.   \n[39] Mohammad Emtiyaz Khan, Alexander Immer, Ehsan Abedi, and Maciej Korzepa. Approximate inference turns deep networks into gaussian processes, 2020. URL https://arxiv.org/ abs/1906.01930.   \n[40] Andrew Y. K. Foong, Yingzhen Li, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, and Richard E. Turner. \u2019in-between\u2019 uncertainty in bayesian neural networks, 2019.   \n[41] Mohammad Emtiyaz Khan and Siddharth Swaroop. Knowledge-adaptation priors, 2021. URL https://arxiv.org/abs/2106.08769.   \n[42] Erik Daxberger, Eric Nalisnick, James Urquhart Allingham, Javier Antor\u00e1n, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Bayesian deep learning via subnetwork inference, 2022.   \n[43] Zhijie Deng, Feng Zhou, and Jun Zhu. Accelerated linearized laplace approximation for bayesian deep learning, 2022.   \n[44] Luis A. Ortega, Sim\u00f3n Rodr\u00edguez Santana, and Daniel Hern\u00e1ndez-Lobato. Variational linearized laplace approximation for bayesian deep learning, 2024.   \n[45] Aidan Scannell, Riccardo Mereu, Paul Edmund Chang, Ella Tamir, Joni Pajarinen, and Arno Solin. Function-space parameterization of neural networks for sequential learning. In The Twelfth International Conference on Learning Representations, 2024. URL https: //openreview.net/forum?id $\\equiv$ 2dhxxIKhqz.   \n[46] Javier Antor\u00e1n, Shreyas Padhy, Riccardo Barbano, Eric Nalisnick, David Janz, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Sampling-based inference for large linear models, with application to linearised laplace, 2023.   \n[47] Tristan Cinquin and Robert Bamler. Regularized kl-divergence for well-defined function-space variational inference in bayesian neural networks, 2024. URL https://arxiv.org/abs/ 2406.04317.   \n[48] Minh Ha Quang. Regularized divergences between covariance operators and gaussian measures on hilbert spaces, 2019.   \n[49] Veit D. Wild, Robert Hu, and Dino Sejdinovic. Generalized variational inference in function spaces: Gaussian measures meet bayesian deep learning, 2022.   \n[50] Daniel Flam-Shepherd. Mapping gaussian process priors to bayesian neural networks. 2017. URL https://api.semanticscholar.org/CorpusID:160026812.   \n[51] Takuo Matsubara, Chris J. Oates, and Fran\u00e7ois-Xavier Briol. The ridgelet prior: A covariance function approach to prior specification for bayesian neural networks, 2022.   \n[52] Tim Pearce, Russell Tsuchida, Mohamed Zaki, Alexandra Brintrup, and Andy Neely. Expressive priors in bayesian neural networks: Kernel combinations and periodic functions, 2019.   \n[53] Ari S. Benjamin, David Rolnick, and Konrad Kording. Measuring and regularizing networks in function space, 2019.   \n[54] Zonghao Chen, Xupeng Shi, Tim G. J. Rudner, Qixuan Feng, WEIZHONG ZHANG, and Tong Zhang. A neural tangent kernel perspective on function-space regularization in neural networks. In OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop), 2022. URL https://openreview.net/forum?id $=$ E6MGIXQlKw.   \n[55] Shikai Qiu, Tim G. J. Rudner, Sanyam Kapoor, and Andrew Gordon Wilson. Should we learn most likely functions or parameters?, 2023.   \n[56] Natha\u00ebl Da Costa, Marvin Pf\u00f6rtner, Lancelot Da Costa, and Philipp Hennig. Sample path regularity of Gaussian processes from the covariance kernel, 2023.   \n[57] Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, and Bharath K. Sriperumbudur. Gaussian processes and kernel methods: A review on connections and equivalences, 2018.   \n[58] M. Dashti, K. J. H. Law, A. M. Stuart, and J. Voss. MAP estimators and their consistency in Bayesian nonparametric inverse problems. Inverse Problems, 29(9), September 2013. doi:10.1088/0266-5611/29/9/095017.   \n[59] John B. Conway. A Course in Functional Analysis, volume 96 of Graduate Texts in Mathematics. Springer, New York, NY, second edition, 1997. doi:10.1007/978-1-4757-4383-8.   \n[60] Vladimir Igorevich Bogachev. Gaussian Measures, volume 62 of Mathematical Surveys and Monographs. American Mathematical Society, Providence, Rhode Island, 1998.   \n[61] Dimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo Rosasco, and Maurizio Filippone. Dirichlet-based gaussian processes for large-scale calibrated classification. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper_files/paper/2018/file/ b6617980ce90f637e68c3ebe8b9be745-Paper.pdf.   \n[62] Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Yamamoto Kazuaki, and David Ha. Deep learning for classical japanese literature, 12 2018.   \n[63] J.H. HALTON. On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals. Numerische Mathematik, 2:84\u201390, 1960. URL http://eudml. org/doc/131448.   \n[64] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.   \n[65] Lukas Biewald. Experiment tracking with weights and biases, 2020. URL https://www. wandb.com/. Software available from wandb.com.   \n[66] Hao Chen, Lili Zheng, Raed Al Kontar, and Garvesh Raskutti. Gaussian process inference using mini-batch stochastic gradient descent: Convergence guarantees and empirical benefits, 2021.   \n[67] M. Mckay, Richard Beckman, and William Conover. A comparison of three methods for selecting vales of input variables in the analysis of output from a computer code. Technometrics, 21:239\u2013245, 05 1979. doi:10.1080/00401706.1979.10489755.   \n[68] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020. URL http://arxiv.org/abs/1910.06403.   \n[69] Dheeru Dua and Casey Graff. Uci machine learning repository, 2017. URL http://archive. ics.uci.edu/ml.   \n[70] Andrey Malinin, Liudmila Prokhorenkova, and Aleksei Ustimenko. Uncertainty in gradient boosting via ensembles, 2021.   \n[71] Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The million song dataset. In Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR 2011), 2011.   \n[72] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL http://github.com/google/jax.   \n[73] Tom Hennigan, Trevor Cai, Tamara Norman, Lena Martens, and Igor Babuschkin. Haiku: Sonnet for JAX, 2020. URL http://github.com/deepmind/dm-haiku.   \n[74] Aleksandar Botev and James Martens. KFAC-JAX, 2022. URL https://github.com/ google-deepmind/kfac-jax.   \n[75] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty, 2018. URL https://arxiv.org/abs/1806.01768. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A Theory ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Assumptions and their applicability ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Assumption A.1. f $\\sim\\mathcal{G P}\\left(\\pmb{\\mu},\\pmb{\\Sigma}\\right)$ is a $d^{\\prime}$ -output Gaussian process with index set $\\mathbb{X}$ on $\\textstyle(\\Omega,A,\\operatorname{P})$ such that ", "page_idx": 14}, {"type": "text", "text": "(i) the paths of f lie (P-almost surely) in a real separable Banach space $\\mathbb{B}$ of $\\mathbb{R}^{d^{\\prime}}$ -valued functions on $\\mathbb{X}$ with continuous point evaluation maps $\\delta_{\\mathbf{x}}\\colon\\mathbb{B}\\to\\ensuremath{\\mathbb{R}}^{d^{\\prime}}$ , and (ii) $\\omega\\mapsto\\mathbf{f}(\\cdot,\\omega)$ is a Gaussian random variable with values in $\\left(\\mathbb{B},\\beta\\left(\\mathbb{B}\\right)\\right)$ . ", "page_idx": 14}, {"type": "text", "text": "We denote the law of $\\omega\\mapsto\\mathbf{f}(\\cdot,\\omega)$ by $\\mathrm{P_{\\mathbb{B}}}$ . ", "page_idx": 14}, {"type": "text", "text": "For this paper, we focus on $\\mathbb{B}\\;=\\;C(\\mathbb{X})$ , with $\\mathbb{X}$ being a compact metric space. In this case, Assumption A.1(i) can be verified from regularity properties of the prior covariance function $\\Sigma$ [see, e.g., 56]. Moreover, the sufficient criteria from Pf\u00f6rtner et al. [19, Section B.2] show that Assumption A.1(ii) also holds in this case. ", "page_idx": 14}, {"type": "text", "text": "Assumption A.2. The potential $\\Phi^{Y}\\colon\\mathbb{B}\\rightarrow\\mathbb{R}$ is (norm-)continuous and, for each $\\eta>0$ , there is $K(\\eta)\\in\\mathbb{R}$ such that $\\Phi^{Y}\\!({\\pmb f})\\geq K(\\eta)-\\eta\\|{\\pmb f}\\|_{\\mathbb{B}}^{2}$ for all $\\pmb{f}\\in\\mathbb{B}$ . ", "page_idx": 14}, {"type": "text", "text": "This holds if the negative log-likelihood functions $\\ell^{(i)}\\colon\\ensuremath{\\mathbb{R}}^{d^{\\prime}}\\to\\ensuremath{\\mathbb{R}}$ , $\\pmb{f}^{(i)}\\mapsto-\\log p(\\pmb{y}^{(i)}\\mid\\pmb{f}^{(i)})$ are continuous and, for all $\\eta>0$ , there is $K(\\eta)\\in\\mathbb{R}$ such that $\\ell^{(i)}(\\pmb{f}^{(i)})>K(\\pmb{f}^{(i)})+\\eta\\|\\pmb{f}^{(i)}\\|^{2}$ for all $\\pmb{f}^{(i)}\\in\\mathbb{R}^{d^{\\prime}}$ . For instance, this is true for a Gaussian likelihood $\\begin{array}{r}{\\ell^{(i)}(\\pmb{f}^{(i)})=\\frac{1}{2\\lambda_{i}^{2}}\\|\\pmb{y}^{(i)}-\\pmb{f}^{(i)}\\|_{2}^{2}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Assumption A.3. (i) $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ is nonempty, (ii) $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ is closed in $\\mathbb{B}\\supset\\mathbb{H}_{\\Sigma}$ , and (iii) $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}\\subset\\mathbb{B}$ has the Heine-Borel property, i.e., all closed and bounded subsets of $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ are compact in $\\mathbb{B}$ . ", "page_idx": 14}, {"type": "text", "text": "Assumption A.3(i) can be verified using a plethora of results from RKHS theory. For instance, for Sobolev kernels like the Mat\u00e9rn family used in the experiments, the RKHS is norm-equivalent to a Sobolev space [see, e.g., 57]. In this case, we only need the NN to be sufficiently often (weakly) differentiable on the interior of its compact domain $\\mathbb{X}$ . The closure property from Assumption A.3(ii) is more difficult to verify directly. However, if we assume that W is compact and that the map $\\mathbb{W}\\to\\mathbb{B}$ , ${\\pmb w}\\mapsto{\\pmb f}(\\cdot,{\\pmb w})$ is continuous, then $\\mathbb{F}$ is compact (and hence closed) as the image of a compact set under a continuous function. This is a reasonable assumption, since, in practice, the weights of a neural network are represented as machine numbers with a maximal magnitude, meaning that W is always contained in an $\\ell_{\\infty}$ ball of fixed radius. Incidentally, compactness of $\\mathbb{F}$ also entails the Heine-Borel property from Assumption A.3(iii). Alternatively, $\\mathbb{F}$ also has the Heine-Borel property if it is a topological manifold (e.g., a Banach manifold), since it is necessarily finite-dimensional. ", "page_idx": 14}, {"type": "text", "text": "A.2 Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma A.1. Let $(\\mathbb{X},d)$ be a metric space, $\\mathbb{A}\\subseteq\\mathbb{X}$ nonempty, and ", "page_idx": 14}, {"type": "equation", "text": "$$\nd(\\cdot,\\mathbb{A})\\colon\\mathbb{X}\\to\\mathbb{R}_{\\geq0},x\\mapsto\\operatorname*{inf}_{a\\in\\mathbb{A}}d(x,a).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then $d(\\cdot,\\mathbb{A})$ is $^{\\,I}$ -Lipschitz. ", "page_idx": 14}, {"type": "text", "text": "Proof. For all $x_{1},x_{2}\\in\\mathbb{X}$ we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d(x_{2},\\mathbb{A})=\\underset{a\\in\\mathbb{A}}{\\operatorname*{inf}}\\;d(x_{2},a)}\\\\ &{\\qquad\\qquad\\leq d(x_{2},x_{1})+\\underset{a\\in\\mathbb{A}}{\\operatorname*{inf}}\\;d(x_{1},a)}\\\\ &{\\qquad\\qquad=d(x_{1},x_{2})+d(x_{1},\\mathbb{A})}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "by the triangle inequality and hence $d(x_{2},\\mathbb{A})\\,-\\,d(x_{1},\\mathbb{A})\\,\\le\\,d(x_{1},x_{2})$ . Since this argument is symmetric in $x_{1}$ and $x_{2}$ , this also shows that ", "page_idx": 14}, {"type": "equation", "text": "$$\n-(d(x_{2},\\mathbb{A})-d(x_{1},\\mathbb{A}))=d(x_{1},\\mathbb{A})-d(x_{2},\\mathbb{A})\\leq d(x_{2},x_{1})=d(x_{1},x_{2}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "All in all, we obtain $|d(x_{2},\\mathbb{A})-d(x_{1},\\mathbb{A})|\\leq d(x_{1},x_{2})$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma A.2. Let $(\\mathbb{X},d)$ be a metric space and $\\mathbb{A}\\subseteq\\mathbb{X}a$ closed, nonempty subset with the Heine-Borel property. Then $\\operatorname{inf}_{a\\in\\mathbb{A}}d(x,a)$ is attained for all $x\\in\\mathbb{X}$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. Let $x\\in\\mathbb{X}$ and $r>r_{x}:=\\operatorname*{inf}_{a\\in\\mathbb{A}}d(x,a)$ . Then $\\mathbb{A}\\cap\\bar{B}_{r}(x)\\neq\\emptyset$ as well as $d(x,a)>r$ for all $a\\in\\bar{\\mathbb{A}}\\setminus\\bar{B}_{r}(x)$ and thus $\\operatorname*{inf}_{a\\in\\mathbb{A}}d(x,a)=\\operatorname*{inf}_{a\\in\\mathbb{A}\\cap{\\bar{B}}_{r}(x)}d(x,a)$ . Moreover, $\\mathbb{A}\\cap\\bar{B}_{r}(\\bar{x})$ is compact by the Heine-Borel property and $d(x,\\cdot)$ is continuous. Hence, the claim follows from the Weierstrass extreme value theorem. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proposition 1. Let Assumptions A.1 to A.3 hold. For $\\lambda>0$ , define $\\Phi^{Y,\\lambda}$ : $\\mathbb{B}\\to\\mathbb{R}$ , $f\\mapsto\\Phi^{Y}(f)+$ $\\textstyle{\\frac{1}{2\\lambda^{2}}}d_{\\mathbb{B}}^{2}(f,\\mathbb{F})$ . Then the posterior measure $\\mathrm{P}_{\\mathbb{B}}^{{\\cal Y},\\lambda}(\\mathrm{d}{\\pmb{f}})\\propto\\exp\\left(-\\Phi^{{\\cal Y},\\lambda}(\\mathrm{d}{\\pmb{f}})\\right)\\mathrm{P}_{\\mathbb{B}}(\\mathrm{d}{\\pmb{f}})$ has at least one weak mode $f^{\\star}\\in\\mathbb{H}_{\\Sigma}$ , and the weak modes of $\\mathrm{P_{\\mathbb{B}}^{Y,\\lambda}}$ coincide with the minimizers of ", "page_idx": 15}, {"type": "equation", "text": "$$\nR_{F S P}^{\\lambda}\\colon\\mathbb{H}_{\\Sigma}\\to\\mathbb{R},f\\mapsto\\Phi^{{\\mathbf Y},\\lambda}(f)+\\frac{1}{2}\\|f-\\pmb{\\mu}\\|_{\\mathbb{H}_{\\Sigma}}^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. $d_{\\mathbb{B}}(\\mathbf{\\nabla}\\cdot,\\mathbb{F})$ is (globally) 1-Lipschitz by Lemma A.1 and bounded from below by 0. Hence, $\\begin{array}{r}{\\Phi^{Y,\\lambda}=\\Phi^{Y}+\\frac{1}{2\\lambda^{2}}d_{\\mathbb{B}}^{2}(\\,\\cdot\\,,\\mathbb{F})}\\end{array}$ is continuous and for all $\\eta>0$ , there is $K(\\eta)\\in\\mathbb{R}$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Phi^{{\\cal Y},\\lambda}(f)\\geq K(\\eta)-\\eta\\|f\\|_{\\mathbb{B}}^{2}+\\underbrace{\\frac{1}{2\\lambda^{2}}d_{\\mathbb{B}}^{2}(f,\\mathbb{F})}_{\\geq0}\\geq K(\\eta)-\\eta\\|f\\|_{\\mathbb{B}}^{2}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "by Assumption A.2. The statement then follows from Theorem 1.1 in Lambley [20]. ", "page_idx": 15}, {"type": "text", "text": "Proposition 2. Let Assumptions A.1 to $A.3$ hold. Let $\\{\\lambda_{n}\\}_{n\\in\\mathbb{N}}\\subset\\mathbb{R}_{>0}$ with $\\lambda_{n}\\to0,$ , and $\\{f_{n}^{\\star}\\}_{n\\in\\mathbb{N}}\\subset$ $\\mathbb{H}_{\\pmb{\\Sigma}}$ such that $f_{n}^{\\star}$ is a minimizer of $R_{F S P}^{\\lambda_{n}}$ . Then $\\{f_{n}^{\\star}\\}_{n\\in\\mathbb{N}}$ has an $\\mathbb{H}_{\\pmb{\\Sigma}}$ -weakly convergent subsequence with limit $f^{\\star}\\in\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ . Moreover, $f^{\\star}$ is a minimizer of $R_{F S P}$ on $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ . ", "page_idx": 15}, {"type": "text", "text": "Our proof makes use of ideas from Dashti et al. [58] and Lambley [20]. ", "page_idx": 15}, {"type": "text", "text": "Proof. Without loss of generality, we assume $\\pmb{\\mu}=\\mathbf{0}$ . By Assumption A.2, there are constants $K,\\alpha>0$ such that $R_{\\mathrm{FSP}}(\\pmb{f})\\geq\\pmb{\\dot{K}}+\\alpha\\|\\pmb{f}\\|_{\\mathbb{H}_{\\Sigma}}^{2}$ for all $f\\in\\mathbb{H}_{\\Sigma}$ [20, Section 4.1]. Now fix an arbitrary $\\pmb{f}\\in\\mathbb{H}_{\\pmb{\\Sigma}}\\cap\\mathbb{F}$ . Then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle R_{\\mathrm{FSP}}(f)=R_{\\mathrm{FSP}}^{\\lambda_{n}}(f)}\\\\ &{\\quad\\quad\\quad\\geq R_{\\mathrm{FSP}}^{\\lambda_{n}}(f_{n}^{\\star})}\\\\ &{\\quad\\quad\\quad=R_{\\mathrm{FSP}}(f_{n}^{\\star})+\\displaystyle\\frac{1}{2\\lambda_{n}^{2}}d_{\\mathbb{B}}^{2}(f_{n}^{\\star},\\mathbb{F})}\\\\ &{\\quad\\quad\\quad\\geq K+\\alpha\\|f_{n}^{\\star}\\|_{\\mathbb{H_{\\Sigma}}}^{2}+\\displaystyle\\frac{1}{2\\lambda_{n}^{2}}d_{\\mathbb{B}}^{2}(f_{n}^{\\star},\\mathbb{F})}\\\\ &{\\quad\\quad\\quad\\geq K+\\alpha\\|f_{n}^{\\star}\\|_{\\mathbb{H_{\\Sigma}}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and hence ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\pmb{f}_{n}^{\\star}\\|_{\\mathbb{H}_{\\Sigma}}^{2}\\leq\\frac{1}{\\alpha}\\left(R_{\\mathrm{FSP}}(\\pmb{f})-K\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "i.e. the sequence $\\{f_{n}^{\\star}\\}_{n\\in\\mathbb{N}}\\subset\\mathbb{H}_{\\Sigma}$ is bounded. By the Banach-Alaoglu theorem [59, Theorems V.3.1 and V.4.2(d)] and the Eberlein-\u0160mulian theorem [59, Theorem V.13.1], there is a weakly convergent subsequence $\\{f_{n_{k}}^{\\star}\\}_{k\\in\\mathbb{N}}$ with limit $f^{\\star}\\in\\mathbb{H}_{\\Sigma}$ . ", "page_idx": 15}, {"type": "text", "text": "We need to show that $f^{\\star}\\in\\mathbb{F}$ . From Equation (A.2), it follows that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\leq d_{\\mathbb{B}}(f_{n_{k}}^{\\star},\\mathbb{F})\\leq\\lambda_{n_{k}}\\sqrt{2(R_{\\mathrm{FSP}}(f)-K-\\alpha\\|f_{n_{k}}^{\\star}\\|_{\\mathbb{H}_{\\Sigma}}^{2})}\\leq\\lambda_{n_{k}}\\sqrt{2(R_{\\mathrm{FSP}}(f)-K)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the right-hand side converges to 0 as $k\\ \\rightarrow\\ \\infty$ . Hence, $\\begin{array}{r}{\\operatorname*{lim}_{k\\to\\infty}d_{\\mathbb{B}}(f_{n_{k}}^{\\star},\\mathbb{F})\\;=\\;0}\\end{array}$ . The embedding $\\iota\\colon\\mathbb{H}_{\\Sigma}\\rightarrow\\mathbb{B}$ is compact [60, Corollary 3.2.4] and, by Lemma A.1, $d_{\\mathbb{B}}(\\,\\cdot\\,,\\mathbb{F})\\colon\\mathbb{B}\\to\\mathbb{R}$ is continuous, which implies that $d_{\\mathbb{B}}(\\iota[\\,\\cdot\\,],\\mathbb{F})\\colon\\mathbb{H}_{\\Sigma}\\to\\mathbb{R}$ is sequentially weakly continuous. Hence, $\\begin{array}{r}{d_{\\mathbb{B}}(\\pmb{f}^{\\star},\\mathbb{F})\\,=\\,\\operatorname*{lim}_{k\\rightarrow\\infty}d_{\\mathbb{B}}(\\pmb{f}_{n_{k}}^{\\star},\\mathbb{F})\\,=\\,\\bar{0}}\\end{array}$ and, by Assumption A.3 and Lemma A.2, it follows that $f^{\\star}\\in\\mathbb{F}$ . ", "page_idx": 15}, {"type": "text", "text": "Finally, we show that $f^{\\star}$ is a minimizer of $R_{\\mathrm{FSP}}$ on $\\mathbb{H}_{\\Sigma}\\cap\\mathbb{F}$ . Since $\\Phi^{Y}\\colon\\mathbb{B}\\ \\rightarrow\\ \\mathbb{R}$ is continuous and $\\iota$ is compact, $\\Phi^{Y}\\,\\circ\\,\\iota\\colon\\mathbb{H}_{\\Sigma}\\ \\to\\ \\mathbb{R}$ is sequentially weakly continuous. Moreover, we have $\\begin{array}{r}{\\operatorname*{lim}\\operatorname*{sup}_{k\\to\\infty}\\bar{\\|}\\pmb{f}_{n_{k}}^{\\star}\\|_{\\mathbb H_{\\Sigma}}^{2}\\;\\geq\\;\\|\\pmb{f}^{\\star}\\|_{\\mathbb H_{\\Sigma}}^{2}}\\end{array}$ , since Hilbert norms are sequentially weakly lowersemicontinuous. Hence, lim $\\begin{array}{r}{\\quad\\tilde{\\mathrm{sup}}_{k\\to\\infty}\\,R_{\\mathrm{FSP}}(\\pmb{f}_{n_{k}}^{\\star})\\geq R_{\\mathrm{FSP}}(\\pmb{f}^{\\star})}\\end{array}$ . Now, by Equation (A.1), ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{\\mathrm{FSP}}(f)\\geq R_{\\mathrm{FSP}}(f^{\\star})+\\operatorname*{lim}_{k\\rightarrow\\infty}\\operatorname*{sup}_{2\\lambda_{n_{k}}^{2}}\\!d_{\\mathbb{B}}^{2}(f_{n_{k}}^{\\star},\\mathbb{F}),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for all f \u2208H\u03a3 \u2229F. For f = f \u22c6this implies that lim supk\u2192\u221e2\u03bb12nk d $\\begin{array}{r}{\\operatorname*{lim}\\operatorname*{sup}_{k\\to\\infty}\\frac{1}{2\\lambda_{n_{k}}^{2}}d_{\\mathbb{B}}^{2}(f_{n_{k}}^{\\star},\\mathbb{F})=0}\\end{array}$ 2B(f n\u22c6k, F) = 0. All in all, we arrive at $R_{\\mathrm{FSP}}(f)\\geq R_{\\mathrm{FSP}}(f^{\\star})$ for all $\\pmb{f}\\in\\mathbb{H}_{\\pmb{\\Sigma}}\\cap\\mathbb{F}$ , i.e. $f^{\\star}$ is a minimizer of $R_{\\mathrm{FSP}}$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B Experimental setup ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "B.1 Qualitative experiments with synthetic data ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Regression. We sample points from the corresponding generative model ", "page_idx": 16}, {"type": "equation", "text": "$$\ny_{i}=\\sin(2\\pi x_{i})+\\epsilon\\quad\\mathrm{with}\\quad\\epsilon\\sim\\mathcal{N}\\left(0,\\sigma_{n}^{2}\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "using $\\sigma_{n}=0.1$ and draw $x_{i}\\sim\\mathcal{U}([-1,-0.5]\\cup[0.5,1])$ . We plot data points as gray circles, functions sampled from the approximate posterior as green lines, the empirical mean function as a red line and its empirical 2-standard-deviation interval around the mean as a green surface. All neural networks have the same two hidden-layer architecture with 50 neurons per layer and hyperbolic tangent (tanh) activation functions. For FSP-LAPLACE, we use 100 context points placed on a regular grid and run a maximum of 500 Lanczos iterations. For FVI, we sample 100 context points drawn from $\\mathcal{U}([-2,2])$ at each update. Except when stated otherwise, we consider a centered GP prior and find the parameters of the covariance function by maximizing the log-marginal likelihood [13]. For the Laplace, we use the full generalized Gauss-Newton matrix and an isotropic Gaussian prior with scale $\\sigma_{p}=1$ . The MAP estimate uses the same prior. We find the parameters of the Gaussian process priors by maximizing the log-marginal likelihood and the parameters of the sparse GP by maximizing the evidence lower bound [13]. ", "page_idx": 16}, {"type": "text", "text": "Classification. We sample randomly perturbed data points from the two moons data [29] with noise level $\\sigma_{n}=0.1$ . We plot the the data points from class 0 as red dots and those from class 1 as blue dots. We show the mean (upper row) and 2-standard-deviation (bottom row) of the probability that a sample $\\textbf{\\em x}$ belongs to class 1 under the approximate posterior, which we estimate using $K=100$ samples. We consider a two hidden-layer neural network with 100 neurons per layer and hyperbolic tangent activation functions. For FSP-LAPLACE, we use 100 context points placed on a regular grid over $[-3.75,3.75]\\times[-3.75,3.75]$ and limit Lanczos to run for at most 500 iterations. For FVI, we sample 100 context points from $\\mathcal{U}([-3.75,3.75]^{2})$ at each update. We consider a centered GP prior and find the parameters of the covariance function by maximizing the log-marginal likelihood [13] using the reparameterization of classifications labels into regression targets from Milios et al. [61]. For the Laplace, we use the full generalized Gauss-Newton matrix and an isotropic Gaussian prior with scale $\\sigma_{p}=1$ . The MAP estimate uses the same prior. For the Gaussian process, we Laplace-approximate the intractable GP posterior and find the prior parameters by maximizing the log-marginal likelihood [13]. Sparse GP parameters are found by maximizing the ELBO [13]. ", "page_idx": 16}, {"type": "text", "text": "B.2 Quantitative experiments with real-world data ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Mauna Loa. We consider the Mauna Loa dataset which tracks the monthly average atmospheric $\\mathrm{CO_{2}}$ concentration at the Mauna Loa observatory in Hawaii from 1974 to 2024 [30]. We consider the first $70\\%$ of the data in chronological order as the train set (from 1974 to 2005) and the last $30\\%$ as the test set (from 2009 to 2024). We standardize the features (time) and regression targets $\\mathrm{{CO}_{2}}$ concentration). We use two hidden-layer neural networks with hyperbolic tangent activations and 50 units each. We augment the input of the neural networks with an additional sine and cosine transformation of the features i.e., we use the feature vectors $(t_{i},\\sin(2\\pi t_{i}/T)$ , $\\cos(2\\pi t_{i}/T)]$ ) where $t_{i}$ is the time index and $T$ is the period used in Rasmussen and Williams [13]. For FSP-LAPLACE, we use 100 context points placed on a regular grid and limit Lanczos to run at most 500 iterations. For FVI, we draw uniformly 100 context points at each update. For Laplace, we use the full generalized Gauss-Newton matrix and find the prior scale by maximizing the marginal likelihood [11]. ", "page_idx": 16}, {"type": "text", "text": "Ocean current modeling. We consider the GulfDrifters dataset [31] and we follow the setup by Shalashilin [32]. We use as training data 20 simulated velocity measurements (red arrows in Figure 2), and consider as testing data 544 average velocity measurements (blue arrows in Figure 2) computed over a regular grid on the $[-90.8,-83.8]\\times[24.0,27.5]$ longitude-latitude interval. We standardize both features and regression targets. We incorporate physical properties of ocean currents into the models by applying the Helmholtz decomposition to the GP prior\u2019s covariance function [33] as well as to the neural network $f$ using the following parameterization ", "page_idx": 17}, {"type": "equation", "text": "$$\nf(\\cdot,\\pmb{w})=\\operatorname{grad}\\Phi(\\cdot,\\pmb{w}_{1})+\\operatorname{rot}\\Psi(\\cdot,\\pmb{w}_{2})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\pmb{w}~=~\\{\\pmb{w}_{1},\\pmb{w}_{2}\\}$ and $\\Phi(\\cdot,w_{1})$ and $\\Psi(\\cdot,w_{2})$ are two hidden-layer fully-connected neural networks with hyperbolic tangent activation functions and 100 hidden units per layer. We use 96 context points placed on a regular grid for the FSP-LAPLACE and limit Lanczos to run at most 500 iterations. For FVI, we use the same 96 context points. For the linearized Laplace, we use the full generalized Gauss-Newton (GGN) and fix the prior scale to $\\sigma_{p}=1$ . ", "page_idx": 17}, {"type": "text", "text": "Image classification. We consider the MNIST [34] and FashionMNIST [35] image classification datasets. We standardizing the images, fit the models on a random partition of $90\\%$ of the provided train splits, keeping the remaining $10\\%$ as validation data, and evaluate the models on the test data. We report mean and standard-errors across 5 such random partitions of the train data with different random seeds. We compare our model to FVI, Laplace, MAP, and Sparse GP baselines, as the scale of the datasets forbids exact GP inference. The expected log-likelihood and expected calibration error are estimated by Monte Carlo integration with 10 posterior samples. All neural networks have the same convolutional neural network architecture with three convolutional layers $\\mathrm{3\\times3}$ kernels and output channels 16, 32 and 64) interleaved with a max-pooling layer, before two fully connected layers (with output size 128 and 10). For FSP-LAPLACE, we sample context points from the Kuzushiji-MNIST (KMNIST) dataset [62] of $28\\times28$ gray-scale images during training following Rudner et al. [26] and use $25^{\\prime}000$ points from the Halton low discrepancy sequence [63] to compute the covariance. We also consider sample context points uniformly over the range [phm,iwn, c, phm,awx,c ]hH=,W1,,wC=1,c=1, where H, W and C are respectively the height, width and number of channels of the images, and phm,iwn,c $p_{m i n}^{h,w,c}=v_{m i n}^{h,w,c}-0.5\\times\\Delta^{h,w,c}$ and $p_{m a x}^{h,w,c}=v_{m a x}^{h,w,c}+0.5\\times\\Delta^{h,w,c}$ where \u2206h,w,c = vhm,awx,c \u2212 vmin is the difference between the minimal $(v_{m i n}^{h,w,c})$ and maximal $(v_{m a x}^{h,w,c})$ values of the data set at pixel index . For FVI, we use the same context point distributions as FSP-LAPLACE. For the Laplace, we use the K-FAC approximation of the generalized Gauss-Newton matrix. We use a Categorical likelihood, the Adam optimizer [64] with a batch size of 100 and stop training early when the validation loss stops decreasing. We optimize hyper-parameters using the Bayesian optimization tool provided by Weights and Biases [65] and select the parameters which maximize the average validation expected log-likelihood across 1 random partitioning of the provided training split into training and validation data. We find covariance function parameters by maximizing the log-marginal likelihood from batches [66] using the reparameterization of classifications labels into regression targets from Milios et al. [61]. We optimize over kernel, prior scale, learning-rate, $\\alpha_{\\epsilon}$ (introduced by Milios et al. [61]) and activation function and select covariance functions among the RBF, Matern-1/2, Matern- $3/2$ , Matern-5/2 and Rational Quadratic. ", "page_idx": 17}, {"type": "text", "text": "Out-of-distribution detection with image data. We consider out-of-distribution detection with image data and a Categorical likelihood following the setup by Osawa et al. [36]. We aim to partition in-distribution (ID) data from out-of-distribution (OOD) based on the mean of entropy of the predictive distribution with respect to 10 posterior samples using a single threshold found by ftiting a decision stump. We evaluate a model fti on MNIST using its test data set as in-distribution data (ID) and the test data set of FashionMNIST as out-of-distribution (OOD), and vice-versa for a model fit on FashionMNIST. We use the same models and hyper-parameters as for image classification and report mean and standard-error of our scores across the same 5 random partitions of the data. ", "page_idx": 17}, {"type": "text", "text": "Bayesian optimization. We consider Bayesian optimization (BO) problems derived from Li et al. [7]. More specifically, we use the same setup but change the dimension of the feature space of the tasks. We report mean and standard error of 5 repetitions of the tasks across different random seeds. We use two hidden layer neural networks with hyperbolic tangent activations and 50 hidden units each. FSP-LAPLACE uses a Matern-5/2 covariance function with constant zero mean function whose parameters are found by maximizing the marginal likelihood [13]. We use 400 context points during training and $10^{\\prime}000$ to compute the posterior covariance sampled using latin hypercube sampling [67]. We use the same prior for FVI and the same number of context points during training. The Gaussian process uses a zero mean function and a Matern-5/2 covariance function following Li et al. [7]. For the Laplace approximation, we find the prior scale by maximizing the marginal likelihood [11]. Unlike FSP-LAPLACE which uses low-rank factors to parameterize the posterior covariance, we found that repeatedly computing the covariance and predictive posterior of the linearized Laplace with the full and K-FAC generalized Gauss-Newton (GGN) matrices was often prohibitively slow in the BO setup. We therefore use the K-FAC approximation to the GGN where possible (Branin and PDE) and the diagonal approximation otherwise (Ackley, Hartmann, Polynomial and BNN). We implemented this experiment using the BO Torch library [68]. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Regression with UCI datasets. We consider tabular regression datasets from the UCI repository [69]. Specifically, we perform leave-one-out 5-fold cross validation, considering $10\\%$ of the training folds as validation data, and we report the mean and standard-error of the average expected loglikelihood on the test fold. We report the mean rank of the methods across all datasets by assigning rank 1 to the best scoring method as well as any method who\u2019s standard error overlaps with the highest score\u2019s error bars, and recursively apply this procedure to the methods not having yet been assigned a rank. We estimate the expected log-likelihood using 10 posterior samples. We encoding categorical features as one-hot vectors and standardizing the features and labels. We consider two hidden-layer neural networks with 50 hidden units each and hyperbolic tangent activations. All models have a homoskedastic noise model with a learned scale parameter. FSP-LAPLACE uses context points drawn uniformly over the r ange [pimin, pimax]id=1, where  d is the d imension of the feature space, and $p_{m i n}^{i}=v_{m i n}^{i}-0.5\\times\\Delta^{i}$ and $p_{m a x}^{i}=v_{m a x}^{i}+0.5\\times\\Delta^{i}$ where $\\Delta^{i}=v_{m a x}^{i}-v_{m i n}^{i}$ is the difference between the minimal $(v_{m i n}^{i})$ and maximal $(v_{m a x}^{i})$ values of the data set at feature index $i$ . For the Laplace, we use the full generalized Gauss-Newton matrix. FVI uses the same context points as FSP-LAPLACE. Neural networks are fti using the Adam optimizer [64] and we stop training early when the validation loss stops decreasing. Hyper-parameters are found just as for the image classification experiment. ", "page_idx": 18}, {"type": "text", "text": "Out-of-distribution detection with regression data. We consider out-of-distribution (OOD) detection with tabular regression data from the UCI datasets [69] following the setup from Malinin et al. [70]. We aim to separate test data (in-distribution) from a subset of the song dataset [71] (outof-distribution) with the same number of features based on the variance of the predictive posterior estimated from 10 posterior samples using a single threshold obtained via a decision stump. We process the data just like in the regression experiments, use the same model hyper-parameters and report mean and standard-error of the scores across the same 5 random partitions of the data. ", "page_idx": 18}, {"type": "text", "text": "B.2.1 Software ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We use the JAX [72] and DM-Haiku [73] Python libraries to implement neural networks. The generalized Gauss-Newton matrices used in the Laplace approximations are computed using the KFAC-JAX library [74]. We implemented the GPs and sparse GPs using the GPyTorch library [68]. We conducted experiments the Bayesian optimization experiments using the BOTorch library [68]. ", "page_idx": 18}, {"type": "text", "text": "B.2.2 Hardware ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "All models were fit using a single NVIDIA RTX 2080Ti GPU with 11GB of memory. ", "page_idx": 18}, {"type": "text", "text": "C Additional experimental results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Additional qualitative results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Regression. We show additional results for the synthetic regression task described in Section 4. We find that FSP-LAPLACE successfully adapts to the beliefs specified by different Gaussian process priors in terms of periodicity (Figure C.2), smoothness (Figure 1) and length scale (Figure C.3) without modifying the neural network\u2019s architecture or adding features. We also find that our method effectively regularizes the model when the data is very noisy (Figure C.4). ", "page_idx": 18}, {"type": "image", "img_path": "83vxe8alV4/tmp/b21d62113f29c2f2c4242400b4b7a73bd0ce87bdc27c69740cbf897800b197bf.jpg", "img_caption": ["Figure C.1: Just like the Gaussian process (GP) and sparse GP, FSP-LAPLACE captures the smoothness behavior specified by the RBF covariance function of the Gaussian process prior. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "83vxe8alV4/tmp/5b8332c6a07d215ba89ca01ce8b6e499ba420cf954bc7e28619d68e27255695c.jpg", "img_caption": ["Figure C.2: Unlike the linearized Laplace, FSP-LAPLACE allows to incorporate periodicity within the support of the data using a periodic prior covariance function and without additional periodic features. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "83vxe8alV4/tmp/eaceb7c1954805c17a9c5b1011173d2df2babee286934662a9e6390879008bfb.jpg", "img_caption": ["Figure C.3: FSP-LAPLACE adapts to the length scale provided by the RBF covariance function of the Gaussian process prior. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "83vxe8alV4/tmp/93f93fee47e8f5c728721b76eaa5ff00b132d4f0770def3f08657b10aecc625b.jpg", "img_caption": ["Figure C.4: FSP-LAPLACE is effectively regularized under strong label noise. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Classification. We show additional results for the two-moons classification task described in Section 4. Similar to the GP and sparse GP baselines, we find that our method captures the behavior of the prior, showing a smooth decision boundary when equipped with a RBF covariance function (Figure C.6) and a rough decision boundary when equipped with a Matern-1/2 covariance function (Figure C.5). FSP-LAPLACE also reverts to the zero-valued mean outside of the data support. ", "page_idx": 19}, {"type": "text", "text": "Effect of context points. We provide additional details on the role of the context points in FSPLAPLACE. The goal of the context points is to regularize the neural network on a finite set of input locations which includes any point where we would like to evaluate the model. During MAP estimation (see Algorithm 1), context points are resampled at each update step to amortize the coverage of the feature space. During the posterior covariance computation (see Algorithm 2), context points are fixed and define where we regularize the model. Context points bare similarity with inducing points in variational GPs [27] in this later step as both define where the model is regularized. ", "page_idx": 19}, {"type": "text", "text": "We show additional results demonstrating the behavior of our model in the low context point regime. Figure C.7 shows the effect of the number of context points on a 1-dimensional regression task with GP priors equipped with a RBF and a Matern 1/2 kernel. Figure C.8 shows the same experiment but on a 2-dimensional classification task. The $M$ context points are randomly sampled uniformly during training, and we use the Halton low discrepancy sequence as context points to compute the covariance. Even with a very small number of context points ( $M=3$ and $M=5)$ ), our model still produces useful uncertainty estimates even if it cannot accurately capture the beliefs specified by the prior. We also note that our method requires more context points to capture the beliefs of rougher priors than smooth priors (see Figure C.7). ", "page_idx": 19}, {"type": "image", "img_path": "83vxe8alV4/tmp/cfbe8bcd73d62de6f1ade550b389ddeb24b7f1dd3cce54a0218e0acfb04fbb84.jpg", "img_caption": ["Figure C.5: FSP-LAPLACE with a Matern-1/2 covariance function against baselines in the two-moons classification task. Similar to the Gaussian process (GP) and sparse GP, our method shows a rough decision boundary. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "83vxe8alV4/tmp/231465e052baea53624377a0f7ac5028e8300bbeb596e32007c4ed282fbfd2dc.jpg", "img_caption": ["Figure C.6: FSP-LAPLACE with a RBF covariance function against baselines in the two-moons classification task. Similar to the Gaussian process (GP) and sparse GP, our method shows a smooth decision boundary. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "C.2 Additional quantitative results ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Mauna Loa. We here show the figure associated with the Mauna Loa dataset experiment in Section 4.1. Figure C.9 shows the predictions of FSP-LAPLACE and the baselines on the Mauna Loa dataset. We find that incorporating prior beliefs both via an informative prior and periodic features in FSP-LAPLACE results in an improved fit over FVI, Laplace and GP baselines. ", "page_idx": 20}, {"type": "image", "img_path": "83vxe8alV4/tmp/af36ad09e46190d963c02e0e7371de42a4a6bee4676bc62390eeffbdec496d59.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure C.7: FSP-LAPLACE with a smooth RBF covariance function and a rough Matern-1/2 with varying amounts of context points $M$ . Given a very small number of context points, our method still produces useful uncertainty estimates. ", "page_idx": 20}, {"type": "image", "img_path": "83vxe8alV4/tmp/06b565c114b2ca4661ff77b1008fcbe59c90df3f833757bbf47a8c8e86573a40.jpg", "img_caption": ["Figure C.8: FSP-LAPLACE with a smooth RBF covariance function and a rough Matern-1/2 with varying amounts of context points $M$ . Given a very small number of context points, our method still produces useful uncertainty estimates and reverts to the prior\u2019s zero valued mean. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "83vxe8alV4/tmp/9082f0d76522da7021877e16c623ea6091dd22c435780ce6666b7bdbd56c543d.jpg", "img_caption": ["Figure C.9: Regression on the Mauna Loa dataset. Incorporating prior knowledge via a kernel tailored specifically to the dataset, our method (FSP-LAPLACE) results in a strong decrease in mean square error over baselines. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Out-of-distribution detection with image data. We present additional results for the out-ofdistribution detection experiment presented in Section 4.1. Figure C.10 shows the distribution of the predictive entropy of in-distribution (ID) and out-of-distribution (OOD) data under the sparse GP, FSP-LAPLACE, FVI and Laplace models. For both MNIST and FashionMNIST, we find that the predictive entropy of ID data under FSP-LAPLACE is tightly peaked around 0 nats and that the predictive entropy of OOD data strongly concentrates around its maximum $\\ln10\\approx2.3$ nats. ", "page_idx": 21}, {"type": "text", "text": "Rotated MNIST and FashionMNIST. We provide an additional experiment studying the behavior of FSP-LAPLACE under out-of-distribution data. We consider the setup by Rudner et al. [25], Sensoy et al. [75] and track the predictive entropy of models trained on MNIST and FashionMNIST for increasing angles of rotation of the test images. We expect the predictive entropy of a well-calibrated neural network to grow as the inputs become increasingly dissimilar to the training data with higher angles of rotation. Similar to FVI, sparse GP and the linearized Laplace baselines, we find that FSP-LAPLACE yields low predictive entropy for small rotation angles and that the predictive entropy increases with the angle on both MNIST and FashionMNIST which is what we expect from a well calibrated Bayesian model. ", "page_idx": 21}, {"type": "text", "text": "Regression with UCI datasets. We further evaluate our method on regression datasets from the UCI repository [69] and compare FSP-LAPLACE to FVI, Laplace, MAP, GP, and Sparse GP baselines. We perform leave-one-out 5-fold cross-validation, keeping $20\\%$ of the remaining train folds as validation data. We report the mean and standard-error of the expected log-likelihood with respect to samples from the posterior across the 5-folds. Additional details can be found in Appendix B.2. Results are presented in Table C.1. We find that our method performs well compared to baselines, matching or improving over the mean rank of all Bayesian methods (FVI, Laplace, GP, and Sparse GP) but a slightly lower mean rank than the MAP baseline (1.636 vs. 1.363). In particular, our method is noticeably more accurate than the Laplace. ", "page_idx": 21}, {"type": "image", "img_path": "83vxe8alV4/tmp/37ca33a74fca30e394d305fc2d5ebf9de22287e86a3d0d0f6fc3a0b539278dfc.jpg", "img_caption": ["Figure C.10: Distribution of in-distribution (ID) and out-of-distribution (OOD) samples for the MNIST and Fashion MNIST image datasets. The predictive entropy produced by FSP-LAPLACE nearly perfectly partition ID and OOD data. This is reflected in OOD accuracy in Table 2. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "83vxe8alV4/tmp/76fdbdb639ec6bf3773df2f3c3332a128830aaa80d92890cff062ee1e2ae36ab.jpg", "img_caption": ["Figure C.11: Input distribution shift experiment. We find that FSP-LAPLACE shows greater predictive entropy as the input becomes increasingly dissimilar to the training data. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Table C.1: Test log-likelihood and out-of-distribution accuracy of evaluated methods on regression datasets from the UCI repository. We find that our method matches or improves over the mean rank of Bayesian baselines in terms of expected log-likelihood, and obtains out-of-distribution detection accuracies similar to the best performing BNN. ", "page_idx": 22}, {"type": "table", "img_path": "83vxe8alV4/tmp/f27edc7c7582c900730eb6667c285c32e333a1abe72fcd778605dc653607f0be.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Out-of-distribution detection on tabular data. We also investigate whether the epistemic uncertainty of FSP-LAPLACE is predictive of out-of-distribution data in the regression setting by evaluating it on out-of-distribution detection following Malinin et al. [70]. We report the accuracy of a single threshold to classify OOD from in-distribution (ID) data based on the predictive uncertainty. More details are presented in Appendix B.2. In the context of tabular data, we find that FSP-LAPLACE performs second best among BNNs and is almost as accurate as the Laplace approximation (see Table C.1) which is first. We note that FSP-LAPLACE systematically outperforms FVI in terms of out-of-distribution detection and obtains a higher mean rank (1.818 vs. 3.091). ", "page_idx": 22}, {"type": "text", "text": "$\\|P_{0}\\Lambda P_{0}^{\\top}\\|_{F}$ is negligible. We provide evidence that the term $\\|P_{0}\\Lambda P_{0}^{\\top}\\|_{F}$ in Section 3.2 is negligible compared to $\\|\\Lambda\\|_{F}$ in four different configurations. We consider the synthetic regression and classification setups described in Appendix B.1. ", "page_idx": 23}, {"type": "table", "img_path": "83vxe8alV4/tmp/6891c804b02e9908fff9a61aa5938a5a334751b5e4e57ed25e1a5b4f3df7af50.jpg", "table_caption": ["Table C.2: $\\|P_{0}\\Lambda P_{0}^{\\top}\\|_{F}/\\|\\Lambda\\|_{F}$ for different combinations of priors and tasks. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our experimental results support the fact that the our methods captures beliefs specified by the GP prior. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: We discuss limitations in sections Sections 3, 4 and 6. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We rigorously detail assumptions in Appendix A.1 and proofs can be found in Appendix A.2 and the references. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We do so in Appendix B. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: Code will be published at https://github.com/tristancinquin/ fsplaplace. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: See Appendix B. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We report standard error along the mean scores across cross validation folds. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: See Appendix Appendix B. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: To the best of our knowledge, we have fully conformed with the code of ethics. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [No] ", "page_idx": 27}, {"type": "text", "text": "Justification: We believe that there is no direct societal impact of the work perform that needs discussion. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The methods developed in the paper have no risk for misuse. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All external assets (code and data) used in this publication are publicly available, cited in Section 4 and Appendix C.1, and their respective licenses are, to the best of our knowledge, properly respected. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not conduct any research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not conduct any research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]