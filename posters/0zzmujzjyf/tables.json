[{"figure_path": "0ZZMUjZJYF/tables/tables_1_1.jpg", "caption": "Table 1: The explored M1, M2, M3 methods.", "description": "This table summarizes the three methods (M1, M2, and M3) used in the paper, each corresponding to one of the three levels of learning by teaching (LbT).  For each method, the table specifies the objective (what the method aims to improve), the pipeline used (the steps involved in the method), and the LbT implementation (how the LbT concept is applied).  The table also provides the section abbreviation for where each method is described in detail in the paper.", "section": "1 Introduction"}, {"figure_path": "0ZZMUjZJYF/tables/tables_4_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (one of three methods proposed in the paper for improving LLMs' reasoning abilities through learning by teaching) on a subset of 181 MATH test problems.  The table compares the performance of M1 against a greedy baseline and Self-Consistency (SC) using different teacher and student LLM combinations.  The \"Improv\" column shows the percentage improvement in average performance achieved by the M1 (SUM) method compared to SC.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_5_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (SUM) on 181 MATH test problems using 256 teacher-student pairs (TR-TA).  The table compares the average performance of method M1 against a baseline method (Greedy SC) across several different teacher and student LLM models.  The \"Improv\" column shows the percentage improvement achieved by M1 over the baseline. The best-performing model for each row is highlighted in green.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_6_1.jpg", "caption": "Table 4: Results on 500 MATH test problems with greedy decoding.", "description": "This table presents the results of the M2 method on 500 MATH test problems using greedy decoding.  It compares the original performance of the LLaMA3-8B model ('Original') against two fine-tuned versions: one using correctness-based direct preference optimization ('Correctness-DPO') and another incorporating the LbT (Learning by Teaching) score ('M2'). The 'M2' column shows that incorporating the LbT score into the fine-tuning process leads to further improvement in performance compared to using only the correctness score.", "section": "4 Method (M2) for LbT Level 2: Learning from the Feedback"}, {"figure_path": "0ZZMUjZJYF/tables/tables_7_1.jpg", "caption": "Table 5: Teacher's F\u2081 score of M3 on combined Liar dev and test set at the end of iteration T, where LLaMa3-70B is used as the teacher for all settings. The best results are in bold.", "description": "This table presents the results of experiment M3 on the Liar dataset.  It shows the F1 score achieved by the teacher model (LLaMa3-70B) across five iterations (T=1 to T=5) of the iterative refinement process.  The results are presented for three different student configurations: only LLaMa3-70B as a student, only LLaMa3-8B as a student, and both LLaMa3-70B and Mistral-7B as students. The table highlights the best-performing student configuration in each iteration.", "section": "Method (M3) for LbT Level 3: Learning from the Feedback Iteratively"}, {"figure_path": "0ZZMUjZJYF/tables/tables_18_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (SUM) to 181 MATH test problems, using 256 teacher-student pairs (TR-TA).  The table compares the average performance of M1 (SUM) against a self-consistency (SC) baseline.  The best performance for each model configuration is highlighted in green.  The \"Improv\" column shows the percentage improvement of M1 (SUM) over SC.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_20_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (Observing Students\u2019 Feedback) on 181 MATH test problems.  The experiment used 256 teacher-student pairs (TR-TA).  The table shows the performance of various teacher and student LLM models (GPT-4, GPT-3.5, LLaMA, and Mistral) using Greedy, Self-Consistency (SC), and two variants of M1 (M1 (MAX) and M1 (SUM)). The \"Improv\" column indicates the improvement in average performance of M1 (SUM) compared to SC.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_20_2.jpg", "caption": "Table A7: Results on 70 MATH problems with 16 TR-TA pairs.", "description": "This table presents the results of applying method M1 (MAX) and M1 (SUM) on a smaller subset of the MATH dataset, consisting of 70 problems with 16 teaching rationale-teaching answer pairs (TR-TA) sampled for each problem. It compares the performance of M1 with Self-Consistency (SC) and self-evaluation methods.  The improvements are calculated as the difference in performance between M1 (SUM) and SC.", "section": "A.2.3 Additional Results"}, {"figure_path": "0ZZMUjZJYF/tables/tables_20_3.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (SUM) on 181 MATH test problems, using 256 teacher-student pairs (TR-TA).  The table compares the performance of M1 (SUM) against a greedy self-consistency (SC) baseline.  The best performance for each row is highlighted, showing the improvements achieved by M1 (SUM) over the SC baseline.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_22_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (Observing Students\u2019 Feedback) on 181 MATH test problems.  Each row represents a different teacher-student LLM pair, with the teacher generating 256 teaching rationale-answer pairs.  The student uses these pairs to answer similar problems. The table compares the average performance of the student using greedy self-consistency (SC) against the performance of the student when using M1.  The \"Improv\" column shows the percentage improvement in average performance achieved by M1 (SUM) over SC.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_22_2.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method on 181 MATH test problems, using 256 teacher-student pairs (TR-TA).  The table compares the performance of M1 (using both the MAX and SUM methods for aggregating rationales) with a greedy self-consistency (SC) baseline, showing the percentage improvement achieved by M1.  The best result for each row is highlighted in green.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_23_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (Observing Students' Feedback) on 181 MATH test problems.  The experiment used 256 teacher-student pairs (TR-TA). The table compares the average performance of using greedy self-consistency (SC) with the M1 method (using both MAX and SUM approaches).  The \"Improv\" column shows the percentage improvement of M1 (SUM) over SC. The best result in each row is highlighted in green.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_23_2.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (SUM) to 181 MATH test problems, using 256 teacher-student pairs (TR-TA).  The table compares the performance of M1 (SUM) against a baseline method (Greedy SC).  The best performance for each teacher-student combination is highlighted in green.  The \"Improv\" column shows the percentage improvement of M1 (SUM) over the Greedy SC baseline. This illustrates the effectiveness of M1 in improving the answer accuracy on mathematical reasoning tasks.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_24_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (Observing Students' Feedback) on 181 MATH test problems.  Each row represents a different teacher-student LLM pair, using 256 teaching rationale-teaching answer (TR-TA) pairs. The table shows the average performance of the student LLMs using greedy self-consistency (SC) and M1 (MAX) and M1 (SUM). The \"Improv\" column displays the percentage improvement in average performance achieved by M1 (SUM) compared to SC. The best result for each row is highlighted in green.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_24_2.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (Observing Students' Feedback) on 181 MATH test problems, using 256 teacher-rationale/teacher-answer (TR-TA) pairs.  The best-performing method for each model configuration is highlighted in green. The \"Improv\" column indicates the percentage improvement of the M1 (SUM) method compared to the Self-Consistency (SC) baseline.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_25_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying Method 1 (M1) on 181 MATH test problems, using 256 Teacher-Rationale/Teacher-Answer (TR-TA) pairs.  The best performance for each model combination (teacher and student) is highlighted in green. The \"Improv\" column shows the percentage improvement in the average accuracy achieved by using the sum of LbT scores (M1(SUM)) compared to the Self-Consistency (SC) baseline method.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_36_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method on 181 MATH test problems, using 256 teacher-rationale/answer (TR-TA) pairs for each problem.  It compares the performance of three variants of M1 against a Self-Consistency (SC) baseline. The best result for each row is highlighted in green. The \"Improv\" column shows the percentage improvement in average performance of M1 (SUM) (a specific variant of M1) over the SC baseline.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_37_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of applying method M1 (SUM) on 181 MATH test problems.  Each row shows the results using different teacher and student LLMs, with the best performance highlighted.  The \"Greedy SC\" column represents the baseline using self-consistency.  The \"Improv\" column shows the percentage improvement achieved by M1 (SUM) compared to the baseline.", "section": "3.2 Evaluation on Mathematical Reasoning"}, {"figure_path": "0ZZMUjZJYF/tables/tables_40_1.jpg", "caption": "Table 5: Teacher's F1 score of M3 on combined Liar dev and test set at the end of iteration T, where LLaMa3-70B is used as the teacher for all settings. The best results are in bold.", "description": "This table presents the results of experiment M3, focusing on iterative learning by teaching.  It shows the F1 score achieved by the teacher model (LLaMa3-70B) across different iterations (T=1 to T=5) and using different student models (LLaMa3-70B alone, LLaMa3-8B alone, and a combination of LLaMa3-70B/8B and Mistral-7B). The best F1 score for each iteration is highlighted in bold, indicating the impact of iterative refinement based on student feedback.", "section": "Method (M3) for LbT Level 3: Learning from the Feedback Iteratively"}, {"figure_path": "0ZZMUjZJYF/tables/tables_41_1.jpg", "caption": "Table 2: Results on 181 MATH test problems with 256 TR-TA pairs. The best results of each row are highlighted in green. The \u201cImprov\u201d column calculates the improvements of average performance achieved by M1 (SUM) over SC.", "description": "This table presents the results of the M1 method (SUM) on 181 MATH test problems, using 256 teacher-student pairs (TR-TA).  The best-performing model for each teacher is highlighted in green. The \"Improv\" column shows the percentage improvement in average performance achieved by the M1 (SUM) method compared to the self-consistency (SC) baseline. The table allows comparison of performance across different teacher and student models.", "section": "3.2 Evaluation on Mathematical Reasoning"}]