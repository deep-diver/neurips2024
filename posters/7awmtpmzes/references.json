{"references": [{"fullname_first_author": "Jacob Austin", "paper_title": "Structured denoising diffusion models in discrete state-spaces", "publication_date": "2021", "reason": "This paper is foundational for adapting continuous diffusion models to discrete data, directly addressing a core challenge tackled in the target paper."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020", "reason": "This highly influential work established the power of large language models, providing a key comparative baseline for the target paper's language modeling results."}, {"fullname_first_author": "Alex Krizhevsky", "paper_title": "Learning multiple layers of features from tiny images", "publication_date": "2009", "reason": "This paper introduced the CIFAR-10 dataset, a crucial benchmark for image generation that is used for experimental validation in the target paper."}, {"fullname_first_author": "Jascha Sohl-Dickstein", "paper_title": "Deep unsupervised learning using nonequilibrium thermodynamics", "publication_date": "2015", "reason": "This is a seminal work on diffusion models, which forms the theoretical foundation for many subsequent advancements, including the techniques explored in the target paper."}, {"fullname_first_author": "Diederik P. Kingma", "paper_title": "Auto-encoding variational bayes", "publication_date": "2014", "reason": "This paper introduced variational autoencoders (VAEs), a prominent generative model class that is related to the target paper's methodology and provides a comparative approach for discrete data generation."}]}