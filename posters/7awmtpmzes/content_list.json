[{"type": "text", "text": "Discrete Modeling via Boundary Conditional Diffusion Processes ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuxuan Gu\u2020 Xiaocheng Feng\u2020\u2021 Lei Huang\u2020 Yingsheng Wu\u2020 Zekun Zhou\u2020 Weihong Zhong\u2020 Kun Zhu\u2020 Bing Qin\u2020\u2021 \u2020Harbin Institute of Technology \u2021 Peng Cheng Laboratory {yxgu,xcfeng,lhuang,yswu,zkzhou,whzhong,kzhu,qinb}@ir.hit.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present an novel framework for efficiently and effectively extending the powerful continuous diffusion processes to discrete modeling. Previous approaches have suffered from the discrepancy between discrete data and continuous modeling. Our study reveals that the absence of guidance from discrete boundaries in learning probability contours is one of the main reasons. To address this issue, we propose a two-step forward process that first estimates the boundary as a prior distribution and then rescales the forward trajectory to construct a boundary conditional diffusion model. The reverse process is proportionally adjusted to guarantee that the learned contours yield more precise discrete data. Experimental results indicate that our approach achieves strong performance in both language modeling and discrete image generation tasks. In language modeling, our approach surpasses previous state-of-the-art continuous diffusion language models in three translation tasks and a summarization task, while also demonstrating competitive performance compared to auto-regressive transformers. Moreover, our method achieves comparable results to continuous diffusion models when using discrete ordinal pixels and establishes a new state-of-the-art for categorical image generation on the CIFAR-10 dataset. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Discrete modeling is essential due to the natural prevalence of discreteness in numerous domains, including proteins [Madani et al., 2020, 2023], images [Parmar et al., 2018, Dosovitskiy et al., 2021], and natural language [Sutskever et al., 2014, Brown et al., 2020]. Recent dominant framework for discrete modeling is the Transformer [Vaswani et al., 2017] with an autoregressive manner. While achieving impressive performance, it does suffer from a slow step-by-step generation process, especially for long sequences. Continuous Diffusion models [Sohl-Dickstein et al., 2015, Ho et al., 2020], on the contrary, exhibit the ability to recover high-dimensional data from noise in parallel with limited iteration steps. Although proved to be effective in continuous data generation [Rombach et al., 2022, Kong et al., 2021], they continue to encounter challenges in discrete modeling [Austin et al., 2021, Chen et al., 2023b, Li et al., 2022, Gong et al., 2023b]. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we reveal a significant discrepancy pertaining to the modeling of discrete data using continuous diffusion models. Current approaches represent a discrete sample with a vector point in the continuous space. The diffusion process learns a neural network to model the probability distributions that recovers this continuous point from Gaussian noise. However, the discrete data actually corresponds to an area in the continuous space rather than a single point, where the oversimplified assumption leads to a mismatch between learned probability contours and the boundary of the discrete area. Take language generation as an example, a word is represented with an embedding vector in the embedding space. To generate this word, it is impractical to strictly enforce the predicted vector to be an exact match to the embedding. On the contrary, vectors around this embedding can also generate the same word, thereby defining the collective area they encompass as a discrete area of this word. As illustrated in Figure 1A, suppose the learned probability density function is $p_{\\theta}(\\mathbf{x})$ and two points $\\mathbf{x}^{i}$ and $\\mathbf{x}^{o}$ are sampled in the same density contour where $\\dot{p}_{\\theta}(\\mathbf{x}^{i})\\overset{\\cdot}{=}p_{\\theta}(\\mathbf{x}^{o})$ . It is obvious that $\\mathbf{x}^{i}$ lies in the discrete area and is able to recover the discrete data while $\\mathbf{x}^{o}$ can not. This means that the diffusion model only learns a simplified scenario that does not match the real probability distribution. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To address the issues above, we proposed to take the boundaries of discrete areas as priors, as shown in Figure 1B, where boundary curves are regarded as oracle contours. As it gradually approaches the discrete boundary, the learned density contours of diffusion models are expected to transform from Gaussian distributions to the boundary distribution. Therefore, we propose to divide the forward process into two steps. First is the boundary estimation where we precisely calculate the stopping time $t_{0}$ and position $\\mathbf{x}_{t_{0}}$ at which the forward trajectory cross the boundary. Then we rescale the trajectory for both training and inference stages to make the sampling probability of noisy point $\\mathbf{x}_{t}$ conditioned on the boundary. To make the boundary estimation tractable (appendix A) and eliminate randomness in conditional state transitions $\\mathbf{x}_{t_{0}}\\rightarrow$ ", "page_idx": 1}, {"type": "image", "img_path": "7AWMTPMZES/tmp/d5ea24e784ed5e511cbd5083dcc134018bb030abbaadb06d2fc159dda8c78400.jpg", "img_caption": [], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: (A) Blue and green curves are the learned probability density contours of the diffusion model for two data points. The red area is the discrete area of the blue data $\\mathbf{x}_{\\mathrm{0}}$ and the boundary of this area is naturally a density contour. The discrete boundary is a complex hypersurface in the highdimensional continuous space and we simplify it into a red line for convenience of description. As observed in the magnified part, the learned contours deviate from the boundary contour, resulting in inconsistent probability densities and gradient directions. (B) We consider the discrete boundary as priors for the diffusion process to estimate a more appropriate probability distribution, where the learned contours are expected to follow the shape of the discrete boundary. ", "page_idx": 1}, {"type": "text", "text": "$\\mathbf{x}_{t}$ , we utilize the Ordinary Differential Equations (ODEs) to describe the forward trajectory. ", "page_idx": 1}, {"type": "text", "text": "Our approach is experimented in both language modeling and discrete image generation. On three machine translation datasets (IWSLT14 DE-EN [Cettolo et al., 2012], WMT14 EN-DE, WMT16 EN-RO) and a text summarization dataset (GIGAWORD [Rush et al., 2015]) for language modeling, our proposed approach not only significantly improves existing diffusion models to at most $7.8\\bar{\\%}$ but also achieves competitive performance to autoregressive transformers. For image generation on CIFAR-10 [Krizhevsky et al., 2009], our model realizes a comparable result to continuous diffusion models with discrete ordinal pixels and establishes a new state-of-the-art for categorical pixels. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Diffusion Models To model a real distribution $q(\\mathbf{x}_{0})$ , diffusion models utilize a forward process $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ with $T$ steps to gradually add Gaussian noise $\\pi(\\mathbf{x})=\\mathcal{N}(\\mathbf{0,I})$ into the data distribution, where $\\dot{p_{T}}(\\mathbf{x}|\\mathbf{x}_{0})=\\mathbf{\\dot{\\pi}}\\big(\\mathbf{x}\\big)$ . There are different architectures for the forward process. A common approach $[\\mathrm{Ho}$ et al., 2020] considers the forward process as the Markovian process, where $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})=$ $\\begin{array}{r}{\\prod_{s=1}^{t}p_{s}({\\bf x}_{s}|{\\bf x}_{s-1})}\\end{array}$ combines a series of Gaussian distributions. Thus the forward process follows a Gaussian distribution that $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})=\\mathcal{N}(\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0},(1-\\bar{\\alpha}_{t})\\mathbf{I})$ (Variance Preserving) or $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})=$ $\\mathcal{N}(\\mathbf{x}_{0},\\sigma_{t}^{2}\\mathbf{I})$ (Variance Exploding) [Song et al., 2021b], where noise scheduler ${\\bar{\\alpha}}_{t}$ monotonically decreases from 1 to 0 and $\\sigma_{t}$ increases from sufficiently small to the maximum pairwise distance between all training data points. To recover data from noise, diffusion processes train neural networks $\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t)$ to predict $\\mathbf{x}_{\\mathrm{0}}$ (other equivalent targets include $\\epsilon$ and $\\nabla\\log p(\\mathbf{x}_{t}))$ from $\\mathbf{x}_{t}\\sim p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\theta}=\\mathbb{E}_{t\\sim\\mathcal{U}_{(1,T)},\\mathbf{x}_{0}\\sim q(\\mathbf{x}_{0}),\\mathbf{x}_{t}\\sim p_{t}(\\mathbf{x}|\\mathbf{x}_{0})}\\left[\\|\\mathbf{x}_{0}-\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t)\\|^{2}\\right].\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Samples are generated with a series of reverse state transition $p(\\mathbf{x}_{t-1}\\vert\\mathbf{x}_{t},\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t))$ . ", "page_idx": 1}, {"type": "text", "text": "Flow Matching Another architecture [Lipman et al., 2023] utilizes the ODEs and defines a time-dependent flow function $\\phi_{t}(\\mathbf{x})\\;=\\;\\sigma_{t}(\\mathbf{\\bar{x}}_{0})\\mathbf{x}+\\mu_{t}(\\mathbf{x}_{0})$ that maps $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})\\;=\\;[\\phi_{t}]_{*}\\pi(\\mathbf{x})\\;=$ $\\begin{array}{r}{\\pi(\\phi_{t}^{-1}(\\mathbf{x}))\\left|\\operatorname*{det}\\!\\frac{\\mathrm{d}\\phi_{t}^{-1}(\\mathbf{x})}{\\mathrm{d}\\mathbf{x}}\\right|=\\mathcal{N}(\\mu_{t}(\\mathbf{x}_{0}),\\sigma_{t}^{2}(\\mathbf{x}_{0})\\mathbf{I})}\\end{array}$ , where $\\mu_{t}$ and $\\sigma_{t}$ can be the same as in diffusion ", "page_idx": 1}, {"type": "image", "img_path": "7AWMTPMZES/tmp/d9115aa125591b9dace4531ee79fb4b0c0b28da0b5504940417df8b1d2043a2a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 2: (A) Rescaled Probability Contours. The bold curve $1\\sigma$ is the density contour of one standard deviation. As the time $t$ decreases from $T$ to 0, the rescaled contours will gradually fit the discrete boundary and probability densities will also concentrate to this boundary. (B) Rescaled Forward Trajectory. Original forward trajectory $\\mathbf{x}_{0}\\rightarrow\\mathbf{x}_{t_{0}}\\rightarrow\\mathbf{x}_{\\tau}$ is rescaled to be a boundary conditional trajectory $\\tilde{\\mathbf{x}}_{1}\\!\\to\\!\\tilde{\\mathbf{x}}_{t}$ that starts from $\\tilde{\\mathbf{x}}_{1}=\\mathbf{x}_{t_{0}}$ . The rescaled forward distribution $\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0}\\big)$ is transformed from the discrete boundary to Gaussian distributions. ", "page_idx": 2}, {"type": "text", "text": "models or a more straightforward form that $\\begin{array}{r}{\\mu_{t}\\,=\\,(1\\,-\\,\\frac{t}{T}){\\bf x}_{0}}\\end{array}$ and $\\sigma_{t}~=~{\\frac{t}{T}}$ . Recovering data from noises relies on the vector field $u_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ that generates the probability path with the ODE $\\mathrm{d}\\phi_{T-t}(\\mathbf{x})=u_{T-t}(\\phi_{T-t}(\\mathbf{x})|\\mathbf{x}_{0})\\mathrm{d}t,t:0\\rightarrow T$ . Neural networks ${u_{\\theta}}(\\mathbf{x},t)$ are trained to estimate the vector field $u_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ via the following objective: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\theta}=\\mathbb{E}_{t\\sim\\mathcal{U}_{(1,T)},\\mathbf{x}_{0}\\sim q(\\mathbf{x}_{0}),\\mathbf{x}_{T}\\sim\\pi(\\mathbf{x})}\\left[\\left\\|u_{\\theta}(\\phi_{t}(\\mathbf{x}_{T}),t)-\\frac{\\mathrm{d}\\phi_{t}(\\mathbf{x}_{T})}{\\mathrm{d}t}\\right\\|^{2}\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Besides, the vector field is proved to have the form: ", "page_idx": 2}, {"type": "equation", "text": "$u_{t}(\\mathbf{x}|\\mathbf{x}_{0})={\\frac{\\sigma_{t}^{\\prime}(\\mathbf{x}_{0})}{\\sigma_{t}(\\mathbf{x}_{0})}}\\left(\\mathbf{x}-\\mu_{t}(\\mathbf{x}_{0})\\right)+\\mu_{t}^{\\prime}(\\mathbf{x}_{0})$ ", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As illustrated in Figure 2, our objective is to refine the probability density contours of $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ so that they better fti the boundaries of discrete samples while still allowing for the ease of sampling. Let $\\mathbf{x}_{\\mathrm{0}}$ denote the samples from a real distribution $q(\\mathbf{x}_{0})$ . Obtaining a boundary-aware corresponding noisy data $\\mathbf{x}$ at time $\\bar{t}\\in[1,T]$ is $\\begin{array}{r}{p_{t}(\\mathbf{x}|\\mathbf{x}_{0})=\\int p_{t}(\\mathbf{x},\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})\\mathrm{d}\\mathbf{x}_{t_{0}}\\mathrm{d}t_{0}}\\end{array}$ , where $t_{0}$ is a random variable distributed according to when the diffusion trajectory and the discrete boundary intersect, and $\\mathbf{x}_{t_{0}}$ is the corresponding sample point at $t_{0}$ . Then the forward process is rescaled in two steps: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\tilde{p}_{t}(\\mathbf{x}|\\mathbf{x}_{0})=\\int\\underbrace{\\tilde{p}_{t}(\\mathbf{x}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})}_{\\mathrm{Trajectory\\,Rescaling}}\\;\\;\\;\\;\\underbrace{p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})}_{\\mathrm{Boundary\\,Estimation}}\\;\\mathrm{d}\\mathbf{x}_{t_{0}}\\mathrm{d}t_{0},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the latter term is to calculate the discrete boundaries and the former term is to rescale the forward trajectory. In order to make the equation tractable and ensure that $\\mathbf{x}$ and $\\mathbf{x}_{t_{0}}$ are on the same trajectory, we model the forward process with flow functions $\\phi_{t}(\\mathbf{x})$ and extend the notation as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\psi_{t}(\\mathbf{x})=\\mathbf{u}(\\mathbf{x}_{0},t)\\;\\mathbf{x}_{0}+\\mathbf{v}(\\mathbf{x}_{0},t)\\;\\mathbf{x},\\quad p_{t}(\\mathbf{x}|\\mathbf{x}_{0})=[\\psi_{t}]_{*}\\pi(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbf{u}(\\cdot)$ and $\\mathbf{v}(\\cdot)$ are coefficient functions and sampling $\\mathbf{x}_{t}$ from $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ equals to ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t}=\\psi_{t}(\\epsilon),\\quad\\epsilon\\sim\\pi(\\mathbf{x})=\\mathcal{N}(\\mathbf{0},\\mathbf{I}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "3.1 Estimate Discrete Boundaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Before figuring out the joint distribution $p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})$ , let\u2019s start by discussing how to verify whether an arbitrary point $\\mathbf{x}$ in the continuous space belongs to the discrete area of $\\mathbf{x}_{\\mathrm{0}}$ . Suppose $\\mathbf{x}_{\\mathrm{0}}$ , which exists in the continuous space $S$ , is the representation vector of a discrete random variable $\\mathcal{T}$ in a discrete space with $K$ states. Besides, $\\mathcal{I}$ is another discrete random variable i.i.d. with $\\mathcal{T}$ . We define the discrete area of $\\mathbf{x}_{\\mathrm{0}}$ in the continuous space $S$ as: ", "page_idx": 2}, {"type": "equation", "text": "$$\nC_{\\mathcal{Z}}=\\{\\forall\\mathbf{x}\\in S|f(\\mathbf{x},\\mathcal{Z})>f(\\mathbf{x},\\mathcal{I}),\\forall\\mathcal{I}\\neq\\mathcal{I}\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $f(\\mathbf{x},\\mathcal{T})$ is a function assessing the likelihood of an arbitrary continuous point $\\mathbf{x}$ inside the discrete area of $\\mathbf{x}_{\\mathrm{0}}$ . For instance, in language modeling, $K$ is the vocabulary size. $\\mathcal{T},\\mathcal{I}\\in K^{n}$ are two different sequences of $n$ tokens and $\\mathbf{x}_{0}\\in\\bar{\\mathbb{R}}^{[n,m]}$ is a sequence of $m$ -dimensional vector embeddings for $\\mathcal{T}$ . $f(\\mathbf{x},\\mathcal{T})$ is the dot similarity function. $C_{\\mathbb{Z}}$ collects all vectors in the embedding space that will be decoded to generate $\\mathcal{T}$ and excludes vectors associated with any other token sequences $\\mathcal{I}$ . ", "page_idx": 3}, {"type": "text", "text": "Given a noisy point $\\mathbf{x}_{t_{0}}$ locating at the boundary between $C_{\\mathbb{Z}}$ and $C_{\\mathcal{I}}$ , we can get $|f(\\mathbf{x}_{t_{0}},\\mathcal{T})-$ $f(\\mathbf{x}_{t_{0}},\\mathcal{I})|=0$ based on previous definition. Replacing $\\mathbf{x}_{t_{0}}$ with eqs. (5) and (6), there is: ", "page_idx": 3}, {"type": "equation", "text": "$$\nf(\\mathbf{u}_{t_{0}}\\mathbf{x}_{0}+\\mathbf{v}_{t_{0}}\\epsilon,\\mathcal{T})=f(\\mathbf{u}_{t_{0}}\\mathbf{x}_{0}+\\mathbf{v}_{t_{0}}\\epsilon,\\mathcal{T}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In language modeling and categorical images, $f(\\cdot)$ is a linear projection function that: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t_{0}}(f(\\mathbf{x}_{0},\\mathcal{Z})-f(\\mathbf{x}_{0},\\mathcal{T}))=\\mathbf{v}_{t_{0}}(f(\\epsilon,\\mathcal{I})-f(\\epsilon,\\mathcal{Z})).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Further simplification of this equation can not be universally applied to all arbitrary forms of $\\mathbf{u}_{t_{0}}$ and $\\mathbf{v}_{t_{0}}$ . Therefore, we calculate separately for several commonly occurring special cases. ", "page_idx": 3}, {"type": "text", "text": "Diffusion Process For variance preserving, there is $\\mathbf{u}_{t}^{2}+\\mathbf{v}_{t}^{2}=1$ and we have: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t_{0}}=1{\\Biggl/}{\\sqrt{1+\\left({\\frac{f(\\mathbf{x}_{0},Z)-f(\\mathbf{x}_{0},{\\mathcal{T}})}{f(\\epsilon,{\\mathcal{T}})-f(\\epsilon,Z)}}\\right)^{2}}}\\mathrm{~and~}\\mathbf{v}_{t_{0}}=1{\\Biggl/}{\\sqrt{1+\\left({\\frac{f(\\epsilon,{\\mathcal{T}})-f(\\epsilon,{\\mathcal{T}})}{f(\\mathbf{x}_{0},Z)-f(\\mathbf{x}_{0},{\\mathcal{T}})}}\\right)^{2}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "For variance exploding, there are $\\mathbf{u}_{t}=1$ and $\\mathbf{v}_{t}=\\sigma_{t}$ . We can obtain: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\boldsymbol{\\mathbf{u}}_{t_{0}}=1\\;\\mathrm{and}\\;\\boldsymbol{\\mathbf{v}}_{t_{0}}=\\left(f(\\epsilon,\\mathcal{I})-f(\\epsilon,\\mathcal{Z})\\right)/\\left(f(\\boldsymbol{\\mathbf{x}}_{0},\\mathcal{Z})-f(\\boldsymbol{\\mathbf{x}}_{0},\\mathcal{I})\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Flow Matching For optimal transport, there is $\\mathbf{u}_{t}+\\mathbf{v}_{t}=1$ and similarly we get: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t_{0}}=1\\Bigg/\\left(1+\\frac{f(\\mathbf{x}_{0},Z)-f(\\mathbf{x}_{0},\\mathcal{T})}{f(\\epsilon,\\mathcal{T})-f(\\epsilon,Z)}\\right)\\mathrm{~and~}\\mathbf{v}_{t_{0}}=1\\Bigg/\\left(1+\\frac{f(\\epsilon,\\mathcal{T})-f(\\epsilon,Z)}{f(\\mathbf{x}_{0},Z)-f(\\mathbf{x}_{0},\\mathcal{T})}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As a result, $t_{0}$ can be directly derived by inverting the coefficient function $\\mathbf{u}_{t}$ or $\\mathbf{v}_{t}$ , which depends on the choice of noise scheduling strategies. Since their differences do not affect our results, we omit the detailed calculation (appendix E) and denote this process with a function $G(\\cdot)$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\nt_{0}=G(\\mathbf{x}_{0},\\epsilon),\\,\\mathrm{where}\\,\\mathbf{u}(\\mathbf{x}_{0},G(\\mathbf{x}_{0},\\epsilon))=\\mathbf{u}_{t_{0}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "It\u2019s worth noting that $t_{0}$ is not a scalar but a vector, where the dimension is the number of elements in $\\mathbf{x}_{\\mathrm{0}}$ . If $\\mathbf{x}_{\\mathrm{0}}$ is a sequence of $n$ tokens, $t_{0}\\in[1,T]^{n}$ . If $\\mathbf{x}_{\\mathrm{0}}$ is a RGB image with 3-channel $\\times\\ h$ -height $\\times$ $w$ -width of pixels, $t_{0}\\in[1,T]^{3\\times h\\times w}$ . Furthermore, the corresponding noisy sample $\\mathbf{x}_{t_{0}}$ is derived as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t_{0}}=\\mathbf{u}(\\mathbf{x}_{0},G(\\mathbf{x}_{0},\\epsilon))\\mathbf{x}_{0}+\\mathbf{v}(\\mathbf{x}_{0},G(\\mathbf{x}_{0},\\epsilon))\\epsilon=\\psi_{G(\\mathbf{x}_{0},\\epsilon)}(\\epsilon),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is a time-independent function of the Gaussian noise $\\epsilon$ . It\u2019s worth mentioning that both $p(t_{0}|\\mathbf{x}_{0})$ and $p(\\mathbf{x}_{t_{0}}|\\mathbf{x}_{0})$ are intractable, since $G(\\mathbf{x}_{0},\\epsilon)$ and $\\psi_{G(\\mathbf{x}_{0},\\epsilon)}(\\epsilon)$ are not invertible to $\\epsilon$ . Different \u03f5s can be mapped to a same $t_{0}$ or $\\mathbf{x}_{t_{0}}$ . Fortunately, there is an one-to-one mapping between $\\epsilon$ and the $[\\mathbf{x}_{t_{0}};t_{0}]$ pair. We denote the boundary flow function and the corresponding inversion as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Psi(\\epsilon)=[\\psi_{G(\\mathbf{x}_{0},\\epsilon)}(\\epsilon);G(\\mathbf{x}_{0},\\epsilon)],\\qquad\\Psi^{-1}([\\mathbf{x}_{t_{0}};t_{0}])=(\\mathbf{x}_{t_{0}}-\\mathbf{u}(\\mathbf{x}_{0},t_{0})\\mathbf{x}_{0})/\\mathbf{v}(\\mathbf{x}_{0},t_{0}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "and the joint boundary distribution is calculated as ", "page_idx": 3}, {"type": "equation", "text": "$$\np(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})=[\\Psi]_{*}\\pi([\\mathbf{x}_{t_{0}};t_{0}]).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The support set of $\\mathbf{x}_{t_{0}}$ is restricted to the boundary contour, while other regions in the space are assigned a probability of 0. To obtain the complete boundary, it is necessary to iterate over all possible choices of $\\mathcal{I}$ and perform pairwise comparisons with $\\mathcal{T}$ . The complexity is $O(n\\times K)$ , where $n$ elements in $\\mathbf{x}_{\\mathrm{0}}$ is independently iterated. In practical implementation, obtaining the tightest boundary only requires one step of parallel calculation and an extra $\\operatorname*{min}(\\cdot)$ function over all $t_{0}$ candidates. ", "page_idx": 3}, {"type": "text", "text": "Confidence Factor The discrete area defined by eq. (7) represents an ideal scenario in which the confidence of the boundary is insufficiently reliable for practical application. Due to the intractability of obtaining the probability density function across the entire discrete area and calculating its confidence interval, we employ an empirical strategy. This approach involves utilizing a confidence factor, denoted as $r$ , ranging from 0 to 1, which is multiplied by $t_{0}$ to strike a balance between confidence and discreteness. Therefore, $r\\,=\\,0$ implies the exclusion of discrete priors, causing the discrete area to collapse into a single point, which is the original diffusion process. As the value of $r$ increases, the modeling of discrete boundaries improves at the expense of reliability. Empirically, when the model is conditioned with good guidance, setting a larger value for $r$ allows us to obtain better discrete priors. However, in the case of unconditional modeling, maintaining reliability becomes more crucial to prevent oscillations and even collapses during training. ", "page_idx": 4}, {"type": "text", "text": "3.2 Rescale the Forward Trajectory ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we introduce how to formulate the forward trajectory conditioned on discrete boundaries and derive the rescaled noisy sampling distribution. We start with the boundary-independent forward process $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ . Let $\\mathbf{x}_{t}$ denote a noisy point at time $t$ sampled from $p_{t}(\\mathbf{x}|\\mathbf{x}_{0})$ , there is $\\boldsymbol{\\epsilon}_{t}=\\left(\\mathbf{x}_{t}-\\mathbf{u}(\\mathbf{x}_{0},t)\\mathbf{\\dot{x}}_{0}\\right)/\\mathbf{v}(\\mathbf{x}_{0},t)$ given eq. (5). Equations (13) and (14) provide the corresponding $[\\mathbf{x}_{t_{0}};t_{0}]$ pair on the same trajectory, which is deterministically calculated with no randomness: ", "page_idx": 4}, {"type": "text", "text": "To model the transition probability $p_{t}(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{t},\\mathbf{x}_{0})$ , we utilize the Dirac delta function $\\delta(\\mathbf{x})\\,\\simeq$ $\\textstyle\\operatorname*{lim}_{\\sigma\\rightarrow0}\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$ , which can be loosely thought of as aggregating all probability densities toward the origin, assigning an infinite density at the origin and zero densities elsewhere. Therefore, we have $p_{t}(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{t},\\bar{\\mathbf{x}_{0}})\\,\\stackrel{!}{=}\\,\\delta\\left([\\mathbf{x}_{t_{0}};t_{0}]-\\bar{\\Psi(\\epsilon_{t})}\\right)$ . Then the forward process, conditioned on the discrete boundary, is simply derived via Bayes\u2019 rule: ", "page_idx": 4}, {"type": "equation", "text": "$$\np_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})=p_{t}(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\frac{p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})}{p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})}=\\left\\{\\begin{array}{c c}{0,}&{[\\mathbf{x}_{t_{0}};t_{0}]\\neq\\Psi(\\epsilon_{t})}\\\\ {+\\infty\\times\\frac{p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})}{p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})},}&{\\mathrm{otherwise}}\\end{array}\\right..\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Since $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})>0$ and $p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})>0$ , $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})$ is also a delta function that ", "page_idx": 4}, {"type": "equation", "text": "$$\np_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})=\\delta\\left(\\mathbf{x}_{t}-\\mathbf{u}(\\mathbf{x}_{0},t)\\mathbf{x}_{0}-\\mathbf{v}(\\mathbf{x}_{0},t)\\Psi^{-1}([\\mathbf{x}_{t_{0}};t_{0}])\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Based on the translation property of the Dirac delta function, i.e. $\\begin{array}{r}{\\int f(x)\\delta(x-a)\\mathrm{d}x=f(a)}\\end{array}$ , the original forward process $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\,=\\,[\\psi_{t}\\circ\\Psi^{-1}\\circ\\Psi]_{*}\\pi(\\mathbf{x}_{t})\\,=\\,[\\dot{\\psi}_{t}]_{*}\\pi(\\mathbf{x}_{t})$ naturally ignores the influence of discrete boundaries, even if the boundary information is explicitly added as a condition. ", "page_idx": 4}, {"type": "text", "text": "To enable the discrete priors, we propose a simple and intuitive approach: rescale the forward trajectory. As shown in Figure 2B, the original forward process flows from $\\mathbf{x}_{\\mathrm{0}}$ to a random noise $\\epsilon$ , and we reset the starting point to $\\mathbf{x}_{t_{0}}$ . Accordingly, the intermediate noisy points $\\mathbf{x}_{t},t\\in[1,T]$ will be proportionally mapped on this new path, which is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{\\mathbf{x}}_{t}=\\mathbf{x}_{\\tau},\\quad\\tau=\\mathcal{T}(t,t_{0})=r\\times t_{0}+t\\times(T-r\\times t_{0})/T}\\\\ {=\\mathbf{u}(\\mathbf{x}_{0},\\mathcal{T}(t,t_{0}))\\mathbf{x}_{0}+\\mathbf{v}(\\mathbf{x}_{0},\\mathcal{T}(t,t_{0}))\\Psi^{-1}\\left([\\mathbf{x}_{t_{0}};t_{0}]\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Similar to eq. (19), the rescaled conditional forward process is a Dirac delta function: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})=\\delta\\left(\\tilde{\\mathbf{x}}_{t}-\\mathbf{u}(\\mathbf{x}_{0},\\mathcal{T}(t,t_{0}))\\mathbf{x}_{0}-\\mathbf{v}(\\mathbf{x}_{0},\\mathcal{T}(t,t_{0}))\\Psi^{-1}\\left([\\mathbf{x}_{t_{0}};t_{0}]\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "However, $\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})$ faces the same problem of irreversibility as in eq. (14) and we derive it as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})=\\displaystyle\\int\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t},\\tau|\\mathbf{x}_{0})\\mathrm{d}\\tau=\\int\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t},\\tau|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})p(\\mathbf{x}_{t_{0}},t_{0}|\\mathbf{x}_{0})\\mathrm{d}[\\mathbf{x}_{t_{0}};t_{0}]\\mathrm{d}\\tau}\\\\ &{\\quad\\quad\\quad\\quad=\\displaystyle\\int[\\psi_{\\tau}\\circ\\Psi^{-1}\\circ\\Psi]_{*}\\pi([\\tilde{\\mathbf{x}}_{t};\\tau])\\mathrm{d}\\tau=\\displaystyle\\int[\\psi_{\\tau}]_{*}\\pi([\\tilde{\\mathbf{x}}_{t};\\tau])\\mathrm{d}\\tau.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Obtaining the probability density function requires gathering together the probability densities of the same location $\\tilde{\\mathbf{x}}_{t}$ with different $\\tau$ , which is intractable. Fortunately, we only need to sample noiy points from this probability distribution $\\tilde{\\mathbf{x}}_{t}\\sim\\tilde{p}_{t}\\big(\\tilde{\\mathbf{x}}_{t}\\big|\\mathbf{x}_{0}\\big)$ , which is easy to implement: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{x}}_{t}=\\mathbf{u}\\left(\\mathbf{x}_{0},\\mathcal{T}(t,G(\\mathbf{x}_{0},\\epsilon))\\right)\\mathbf{x}_{0}+\\mathbf{v}(\\mathbf{x}_{0},\\mathcal{T}(t,G(\\mathbf{x}_{0},\\epsilon)))\\epsilon,\\quad\\epsilon\\sim\\pi(\\mathbf{x}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "3.3 Recover Data from Noise ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Training Objective Theoretically, the diffusion neural networks can be trained as in eq. (2), where the rescaled vector field is derived as $\\begin{array}{r}{\\tilde{u}_{t}\\ =\\ \\frac{\\mathrm{d}\\tilde{\\mathbf{x}}_{t}}{\\mathrm{d}t}\\ =\\ \\frac{\\mathrm{d}\\tilde{\\mathbf{x}}_{t}}{\\mathrm{d}\\tau}\\frac{\\mathrm{d}\\tau}{\\mathrm{d}t}}\\end{array}$ ddx\u02dc\u03c4tdd\u03c4t . However, since a low error estimation on $\\mathbf{x}_{\\mathrm{0}}$ is of significant importance to our trajectory rescaling method, according to eqs. (10) to (13), we convert the objective to an upper bound of the eq. (2) (See appendix $\\boldsymbol{\\mathrm F}$ for more details) and train a neural network $\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t},t)$ to predict $\\mathbf{x}_{\\mathrm{0}}$ directly: ", "page_idx": 5}, {"type": "table", "img_path": "7AWMTPMZES/tmp/5b33cf9409446a9fd70742c6162fdd253dad1121cec951c90d64f4ade2fbb395.jpg", "table_caption": ["Algorithm 1 Training "], "table_footnote": [], "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\theta}=\\mathbb{E}_{\\mathbf{x}_{0}\\sim q(\\mathbf{x}_{0}),t\\sim\\mathcal{U}_{(1,T)},\\tilde{\\mathbf{x}}_{t}\\sim\\tilde{p}_{t}(\\mathbf{x}|\\mathbf{x}_{0})}\\left[\\|\\mathbf{x}_{0}-\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t},t)\\|^{2}\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The training procedure is demonstrated in algorithm 1 and key steps are summarized in the line 4. ", "page_idx": 5}, {"type": "text", "text": "Reverse Process A direct approach that follows the flow matching is to solve the ODE of $\\mathrm{d}\\psi_{T-t}(\\mathbf{x})\\,=\\,\\widetilde{u}_{T-t}(\\psi_{T-t}(\\mathbf{x})|\\mathbf{x}_{0})\\mathrm{d}t,\\psi_{T}(\\mathbf{x})\\,\\sim$ $\\pi(\\mathbf{x})$ . This form of transformation is inefficient with $\\mathbf{x}_{\\mathrm{0}}$ -prediction during inference because we have to solve the equation of $\\tau=$ $\\begin{array}{r}{\\mathcal{T}\\left(t,G\\left(\\mathbf{x}_{\\theta},\\frac{\\tilde{\\mathbf{x}}_{t}-\\mathbf{u}\\left(\\mathbf{x}_{\\theta},\\tau\\right)\\mathbf{x}_{\\theta}}{\\mathbf{v}\\left(\\mathbf{x}_{\\theta},\\tau\\right)}\\right)\\right)}\\end{array}$ to get the $\\tau$ with respect to the change of $\\tilde{{\\bf x}}_{t}$ and $\\mathbf{x}_{\\theta}$ in real time. Therefore, we provide a deterministic reverse process as an alternative, which is a special case of DDIM [Song et al., 2021a] or the ODE with discrete timesteps. Given the time intervals $\\Delta t\\in[\\Delta t_{1},\\ldots\\Delta t_{s}],\\sum\\Delta t=T$ , we general", "page_idx": 5}, {"type": "table", "img_path": "7AWMTPMZES/tmp/ad7853c7bbfe548fdf23c8ae587efa95ca29eb2ccfc1275d80d5a321044b60bd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "ize the boundary cond itions $[\\mathbf{x}_{t_{0}};t_{0}]$ in $\\tilde{p}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{t_{0}},t_{0},\\mathbf{x}_{0})$ of eq. (21) and $\\Psi^{-1}\\big([\\mathbf{x}_{t_{0}};t_{0}]\\big)$ of eq. (15) to any arbitrary condition pairs $[\\tilde{\\mathbf{x}}_{t};\\tau]$ and obtain the reverse process: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{p}([\\tilde{\\mathbf{x}}_{t-\\Delta t};\\tau_{\\Delta}]|[\\tilde{\\mathbf{x}}_{t};\\tau],\\hat{\\mathbf{x}}_{0})=}\\\\ &{\\quad\\delta\\left(\\left[\\tilde{\\mathbf{x}}_{t-\\Delta t}\\right]-\\left[\\mathbf{u}(\\hat{\\mathbf{x}}_{0},\\tau_{\\Delta})\\hat{\\mathbf{x}}_{0}+\\mathbf{v}(\\hat{\\mathbf{x}}_{0},\\tau_{\\Delta})\\hat{\\pmb{\\epsilon}}\\right]\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\hat{\\mathbf{x}}_{0}=\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t},t)$ and $\\tau_{\\Delta}$ is the previous timestep of $\\tau$ on the same rescaled trajectory. ", "page_idx": 5}, {"type": "text", "text": "Sampling from the reverse process is illustrated in algorithm 2. Similar to the sampling process of DDIM [Song et al., 2021a], it starts from the Gaussian noise, iteratively predicts the pseudo target $\\hat{\\mathbf{x}}_{0}$ , and updates the reverse trajectory. However, since the $\\tau$ and $\\hat{\\epsilon}$ are mutually conditioned, we have to keep track of the $t,\\tau,\\tilde{\\mathbf{x}}_{t}$ , and $\\hat{\\epsilon}$ during each iteration and split the update of $\\hat{\\epsilon}$ into an asynchronous step (line 8). Because reverse trajectory keeps changing due to different pseudo targets $\\hat{\\mathbf{x}}_{0}$ predicted by learned neural networks, which brings severe instability, sometimes simply fixing the initial path (removing the line 8) exhibits better performance in experiments. ", "page_idx": 5}, {"type": "text", "text": "4 Language Modeling ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Recent diffusion language models [Li et al., 2022, Gong et al., 2023b] inherit the embedding-rounding framework that a sentence with $n$ discrete tokens $W=[w_{1},\\ldots,w_{n}]$ is embedded to a continuous space via a trainable embedding layer $\\operatorname{EMB}(W)=[\\operatorname{EMB}(w_{1}),\\dots,\\operatorname{EMB}(w_{n})]$ . The vocabulary set is $K$ that $\\forall w_{n}\\in K$ . Besides, the token embeddings are used as the target points $\\mathbf{x}_{0}=[\\mathbf{x}_{0}^{1},\\ldots\\bar{,\\mathbf{x}}_{0}^{n}]$ , $\\mathbf{x}_{0}^{n}=\\operatorname{EMB}\\bigl(w_{n}\\bigr)$ , for continuous diffusion trajectories. Hence, generating tokens from embeddings is: ", "page_idx": 5}, {"type": "equation", "text": "$$\np(W|\\mathbf{x}_{0})=\\sum_{i=1}^{n}p(w_{i}|\\mathbf{x}_{0}^{i})=\\sum_{i=1}^{n}\\frac{\\exp(f(\\mathbf{x}_{0}^{i},w_{i}))}{\\sum_{j\\in K}\\exp(f(\\mathbf{x}_{0}^{i},j))},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $f(\\mathbf{x},j)\\,=\\,\\mathrm{EMB}(j)\\cdot\\mathbf{x}$ is the dot production distance. It\u2019s also the function assessing the likelihood of point $\\mathbf{x}$ inside the discrete area of $j$ . The coefficient functions follow the DDPM [Ho et al., 2020], which are $\\mathbf{u}(\\mathbf{x}_{0},t)=\\sqrt{\\bar{\\alpha}_{t}}$ and $\\mathbf{v}(\\bar{\\mathbf{x}}_{0},t)=\\sqrt{1-\\bar{\\alpha}_{t}}$ . Besides, the objectives are ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\theta}=\\mathbb{E}_{W,t,\\tilde{\\mathbf{x}}_{t}}\\left[\\sum_{i=1}^{n}\\lVert\\mathrm{EMB}(w_{i})-\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t}^{i},t)\\rVert^{2}/n\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "table", "img_path": "7AWMTPMZES/tmp/911afc9c95bcb05874958b8480a84148e44978b76205028b4f80f99a37483abb.jpg", "table_caption": ["Table 1: Result of BLEU scores on machine translation and ROUGE scores on text summarization. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "and an additional rounding objective, which is commonly used in language modeling, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{L}_{r}=-\\log p_{\\theta}(W|\\mathbf{x}_{0})=-\\log p_{\\theta}(W|\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t},t)).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The final training target is given by ${\\mathcal{L}}={\\mathcal{L}}_{\\theta}+{\\mathcal{L}}_{r}$ , where the $\\mathbf{x}_{\\mathrm{0}}$ of the same token sequence $W$ keeps changing because the embedding layer EMB is trainable, which makes the model hard to be trained. Since previous work does not model discrete areas, a large number of noisy samples inside this area will make ${\\mathcal{L}}_{r}$ too small to guide the training of the embedding layer, leading to a mode collapse. ", "page_idx": 6}, {"type": "text", "text": "Experimental Setup Datasets used for experiments include three translation tasks (IWSLT14 DE-EN [Cettolo et al., 2012], WMT14 EN-DE, and $\\mathrm{WMT}16~\\mathrm{EN-RO}^{1}\\mathrm{~}$ ) and one text summarization task (GIGAWORD [Rush et al., 2015]). We mainly follow the setting of Gao et al. [2022], which is inherited from previous non-auto-regressive text generation works [Gu et al., 2018, 2019, Ghazvininejad et al., 2019], where translation datasets are distilled [Kim and Rush, 2016]. Baselines are mainly continuous diffusion language models. DiffuSeq [Gong et al., 2023b] and SeqDiffuSeq [Yuan et al., 2022] are derived from Diffusion-LM [Li et al., 2022]. Difformer [Gao et al., 2022] and Dinoiser [Ye et al., 2023] are recent empirical studies highlighting that scaling up the noise is beneficial for language modeling. We also compare with discrete diffusion language models, including D3PM [Austin et al., 2021] and SEDD [Lou et al., 2023]. Since SEDD is a pre-trained language model, we configure its framework and train it from scratch specifically for our tasks. In addition, auto-regressive transformer [Vaswani et al., 2017] is still one of the most powerful architectures for language generation. ", "page_idx": 6}, {"type": "text", "text": "Our boundary conditional diffusion language model is constructed from Difformer [Gao et al., 2022], where the model configuration is transformer-iwslt-de-en in FAIRSEQ framework [Ott et al., 2019] for IWSLT14 DE-EN and transformer-base for other datasets. Sentences are tokenized with Byte-Pair Encoding [Sennrich et al., 2016] and evaluated by detokenized BLEU [Papineni et al., 2002] for machine translation and ROUGE [Lin, 2004] for summarization. During training, the diffusion step is $T=2000$ and the confidence factor $r=1$ for translation tasks since they have strong conditions, while $r=0.5$ for summarization. Sentences are generated deterministically with 20 steps. ", "page_idx": 6}, {"type": "text", "text": "Results Performances are demonstrated in Table 1. Our approach achieves the state-of-the-art compared with continuous diffusion language models and outperforms the two discrete baselines on three machine translation and one text summarization tasks. Our method shows advantages, with a $73.6\\%$ significant improvement at most on WMT14 EN-DE, over DiffuSeq [Gong et al., 2023b] and SeqDiffuSeq [Yuan et al., 2022], which are two basic methods directly applying diffusion process to language modeling. Compared with recent strong diffusion language models like Difformer [Gao et al., 2022] and Dinoiser [Ye et al., 2023], which have deployed various effective noise scheduling strategies on diffusion processes from the empirical perspective, our model is still superior with at most 3.07 advancement of BLEU score on WMT16 EN-RO. This implies the effectiveness of modeling discrete priors. In addition, we illustrate the performance of auto-regressive modeling, where we use the transformer [Vaswani et al., 2017] to rerank the generated sentence candidates (7 length beam $\\times\\ 3$ sentence beams) of our model. The reranked performance can even outperform transformers on IWSLT14 DE-EN and WMT16 EN-RO. ", "page_idx": 6}, {"type": "table", "img_path": "7AWMTPMZES/tmp/af94b666fcb67698641502b21d307031371fa0d91fff84dce79c52487c05a0d5.jpg", "table_caption": ["Table 3: Analysis on the training objectives. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Ablation Our approach is a general framework applicable to almost all continuous diffusion models, providing them with discrete boundaries as priors. We choose Difformer [Gao et al., 2022] as the base model and follow the configurations. As proved in eq. (19), the original forward process will ignore the discrete pri", "page_idx": 7}, {"type": "table", "img_path": "7AWMTPMZES/tmp/d50ae336534388594ac90c3326a0c6ec5fdf0f3a4df8dfded25f3ef9b94e7848.jpg", "table_caption": ["Table 2: Ablation studies. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "ors although explicitly demonstrated. We conduct ablation experiments on the rescaling module. As illustrated in Table 2, our approach rescales the trajectory of both forward and reverse processes on Difformer. Only rescaling the forward trajectory is also effective but sub-optimal due to the inconsistent distribution during inference. Due to computational cost and fair comparison, our method leaves room for improvement. For example, replacing the forward trajectory with optimal transport in Flow Matching, $\\bar{\\mathbf{u}}(\\mathbf{x}_{0},t)=1-t/T$ and $\\mathbf{v}(\\overline{{\\mathbf{x}_{0}}},t)=t/T$ , achieves better performance on WMT16. ", "page_idx": 7}, {"type": "text", "text": "Analysis Our training objective, eq. (24), is an upper bound of the eq. (2). We demonstrate the influence of this approximation in Table 3 on IWSLT14 DE-EN to reveal the thought of our formula. On the one hand, $\\mathcal{L}_{\\mathbf{x}_{0}}$ brings theoretical errors at a constant scale. On the other hand, $\\mathcal{L}_{\\mathbf{x}_{0}}$ mitigates isno meqe.  e(x2p4e) rianmde ntthael  seerrcoornsd f rroomw $\\begin{array}{r}{\\mathcal{L}_{\\tilde{u}_{t}}\\,=\\,\\mathbb{E}_{\\{t,\\mathbf{x}_{0},\\tilde{\\mathbf{x}}_{t}\\}}\\,\\left[\\|\\tilde{u}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{\\theta}(\\tilde{\\mathbf{x}}_{t},t))-\\frac{\\mathrm{d}\\tilde{\\mathbf{x}}_{t}}{\\mathrm{d}t}\\|^{2}\\right]\\,}\\end{array}$ $\\mathcal{L}_{\\mathbf{x}_{0}}$ iosb jdei vtley  wdee ruivseedd $\\mathbf{x}_{\\mathrm{0}}$ $\\tilde{u}_{t}$ set. It is easy to observe that, with the dynamic coefficient T \u2212r\u00d7G(x0,\u03f5) (appendix F), the value of $\\mathbf{x}_{\\mathrm{0}}$ \u2019s error (8.44) is much larger than the $\\tilde{u}_{t}$ \u2019s error (1.56). Therefore, $\\mathcal{L}_{\\mathbf{x}_{0}}$ is beneficial for reducing the impact of the prediction error from the neural network. The third column in Table 3 illustrates the one-step accuracy of predicting $\\mathbf{x}_{\\mathrm{0}}$ and the fourth column is the BLEU score on the test set. Experimental results show that optimizing the upper bound has a negligible impact on the final performance (only a $0.2\\%$ drop of the BLEU score), while can improve the efficiency of the loss calculation during the training phase. ", "page_idx": 7}, {"type": "text", "text": "5 Discrete Image Generation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Image pixels are usually treated as real numbers in continuous space since adjacent pixel values exhibit linear continuity.They are essentially discrete and quantized data with a finite state space, such as 256 states in RGB format. We utilize two discrete image representations. One is binary coding provided by Bit Diffusion [Chen et al., 2023b] that converts a sub-pixel with 256 integers to a 8-bit binary code. It is more efficient as it stores ordinal relationships, but the representation space it constructs will be sparse. Another is pixel embedding, which is a more discrete form of representation because the relationships between pixels are thoroughly broken down and reconstructed by learning the embedding representation. Each pixel is regarded as a one-hot vector and transformed with an embedding layer EMB as used in language. Furthermore, we design an intermediate state to demonstrate the correlation between discreteness and modeling difficulty, which is initializing a fixed embedding with binary coding. The optimization target for binary coding is the MSE loss, and pixel embeddings take the same objective as in language. ", "page_idx": 7}, {"type": "text", "text": "Experimental Setup We use CIFAR-10 [Krizhevsky et al., 2009] for discrete image generation. The evaluation metric is FID [Heusel et al., 2017], which compares 50K generated samples with the training set. Our image generation model is constructed on Bit Diffusion [Chen et al., 2023b], where the architecture is U-Net [Ronneberger et al., 2015] with 3 stages, 256 channels and 3 residual blocks ", "page_idx": 7}, {"type": "image", "img_path": "7AWMTPMZES/tmp/e8e6b021668d2fbd11af25cc6c218ed86ef5b0240c0978c0b673911d8989d2b3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 3: Generated images of Bit Diffusion repro, DDIM, and Ours on CIFAR-10. ", "page_idx": 8}, {"type": "text", "text": "per stage. Diffusion steps are $T=1000$ for both the training and inference stages. The model is trained for $1.5\\mathrm{M}$ steps with the learning rate of $1e\\!-\\!4$ and batch size of 128. Since the training script and detailed hyperparameters of Bit Diffusion are not available, we have to reproduce it by ourselves and our boundary conditional diffusion model shares exactly the same configuration. Our confidence factors are $r=0.5$ for all three settings. Other baselines include D3PM [Austin et al., 2021] and $\\tau\\mathrm{LDR}$ [Campbell et al., 2022] which are discrete diffusion models. SDDM [Sun et al., 2023] utilizes vector quantization from VQGAN [Esser et al., 2021] as a continuous space for discrete data. We also compare with DDPM [Ho et al., 2020] and DDIM [Song et al., 2021a] on continuous pixels. ", "page_idx": 8}, {"type": "text", "text": "Results For binary coding, as shown in Table 4, our approach outperforms the reproduced Bit Diffusion and attains competitive results to state-of-the-art models. For pixel embedding where ordinal information is deconstructed and reconstituted, our method exhibits a notable improvement of 3.81 FID score over replicated Bit Diffusion. Moreover, in the case of categorical pixels, this advantage increases to 8.25, positioning our approach with trainable embedding as a new state-of-the-art solution. Additionally, as deterministic diffusion processes, our model with binary coding can slightly exceed the performance of DDIM, where the generated samples are in Figure 3. ", "page_idx": 8}, {"type": "text", "text": "Analysis We analyze the influence of the confidence factor $r$ in Table 5. The factor $r$ is selected from $[0,0.2,0.3,0.5]$ , where $r=0$ is the reproduced Bit Diffusion that discards the discrete priors. As the confidence factor increases, the impact of discreteness gradually improves, simultaneously enhancing the model\u2019s performance across all three settings. Since there is no guidance for unconditional image generation, we do not use a larger factor to prevent mode collapses. ", "page_idx": 8}, {"type": "table", "img_path": "7AWMTPMZES/tmp/e169dcdd9fde77c94ffa064a2295dd55725f0843959d734d5edec7fe7a39bfa0.jpg", "table_caption": ["Table 4: FID scores on CIFAR-10. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Discrete Modeling Auto-regressive models have demonstrated a domination over discrete modeling, especially for text generation [Vaswani et al., 2017, Brown et al., 2020, Achiam et al., 2023]. However, the computation ", "page_idx": 8}, {"type": "table", "img_path": "7AWMTPMZES/tmp/2db1baf885b81ffdaf2c576413c3daab52738356fedc5d4dd8094b28ef0eacfc.jpg", "table_caption": ["Table 5: Confidence factors. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "cost increases drastically as the size of sentence length or the image resolution increases. Diffusion models [Sohl-Dickstein et al., 2015, Ho et al., 2020, Dhariwal and Nichol, 2021, Saharia et al., 2022] can generate data in parallel, but are tailored for continuous problems. To generalize diffusion models for discrete data, the most straightforward methods define discrete processes in discrete spaces [Sohl-Dickstein et al., 2015, Hoogeboom et al., 2021b, Austin et al., 2021, Campbell et al., 2022, Zhang et al., 2023, Sun et al., 2023, Lou et al., 2023], which will be bothered by large number of discrete status. Besides, a simplified version of discrete diffusion processes is recently used in language modeling [He et al., 2023, Chen et al., 2023a]. Approaches in another line argue to located discrete data in continuous spaces, which is more flexible and efficient, with the mapping functions including binary bits [Chen et al., 2023b] and embeddings [Li et al., 2022, Gong et al., 2023b,a, Yuan et al., 2022, Gulrajani and Hashimoto, 2023, Han et al., 2023]. Other generative models adapted for discrete modeling includes Variational Autoencoders [Kingma and Welling, 2014], Generative Adversarial Networks [Hjelm et al., 2018, Fedus et al., 2018], and Normalizing Flows [Lindt and Hoogeboom, 2021, Hoogeboom et al., 2021a, Tan et al., 2022]. ", "page_idx": 9}, {"type": "text", "text": "Diffusion Models with Deterministic Trajectory Deterministic diffusion process is usually used in the inference stage to speed up sampling, where DDIM [Song et al., 2021a] derives a serial of non-Markovian diffusion processes and the deterministic one is a special case from this implicit perspective. Additionally, deterministic diffusion processes can be converted to ordinary differential equations [Song et al., 2021b], which is utilized by recent sampling acceleration approaches such as DEIS [Zhang and Chen, 2023] and DPM-Solvers [Lu et al., 2022b,a, Zheng et al., 2023]. Our approach requires a deterministic forward trajectory to eliminate the randomness between the boundary point and sampled point. Flow matching [Liu, 2022, Lipman et al., 2023, Albergo and Vanden-Eijnden, 2023, Liu et al., 2023] is a collection of generative models that employ ordinary differential equations to facilitate both forward and reverse processes. They can be regarded as generally equivalent to Diffusion models. Therefore, we extend the framework of flow matching for our method. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We studied the gap between discrete modeling and continuous spaces, focusing on the inconsistency between probability density contours learned by continuous diffusion models and discrete boundaries. We have proposed a novel and general approach to address this issue by enabling continuous diffusion models to be conditioned on discrete priors, which is achieved via discrete boundary estimation and trajectory rescaling. An important limitation is that our method is designed for continuous diffusion models, where discrete diffusion models constructed specially on the discrete state space would not encounter the problem. However, discrete diffusion models also possess their own shortcomings, and the practical applications of continuous diffusion models are more extensive. We believe that our method has the potential to advance the development of unified and general diffusion models. By bridging the gap between discrete and continuous modeling, we hope to inspire new possibilities for modeling complex systems and phenomena. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Bing Qin is the corresponding author of this work, We thank the anonymous reviewers for their insightful comments. This work was supported by the National Natural Science Foundation of China (NSFC) (U22B2059, grant 62276078), the Key R&D Program of Heilongjiang via grant 2022ZX01A32, the International Cooperation Project of PCL, PCL2022D01 and the Fundamental Research Funds for the Central Universities (Grant No.HIT.OCEF.2023018). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. ", "page_idx": 9}, {"type": "text", "text": "Michael Samuel Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=li7qeBbCR1t. ", "page_idx": 9}, {"type": "text", "text": "Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, 2021. ", "page_idx": 10}, {"type": "text", "text": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 1877\u20131901. Curran Associates, Inc., 2020.   \nAndrew Campbell, Joe Benton, Valentin De Bortoli, Tom Rainforth, George Deligiannidis, and Arnaud Doucet. A continuous time framework for discrete denoising models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.   \nMauro Cettolo, Christian Girardi, and Marcello Federico. WIT3: Web inventory of transcribed and translated talks. In Mauro Cettolo, Marcello Federico, Lucia Specia, and Andy Way, editors, Proceedings of the 16th Annual Conference of the European Association for Machine Translation, pages 261\u2013268, Trento, Italy, May 28\u201330 2012. European Association for Machine Translation.   \nJiaao Chen, Aston Zhang, Mu Li, Alex Smola, and Diyi Yang. A cheaper and better diffusion language model with soft-masked noise. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4765\u20134775, Singapore, December 2023a. Association for Computational Linguistics.   \nTing Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog bits: Generating discrete data using diffusion models with self-conditioning. In The Eleventh International Conference on Learning Representations, 2023b.   \nPrafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 8780\u20138794. Curran Associates, Inc., 2021.   \nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021. URL https://openreview. net/forum?id $\\equiv$ YicbFdNTTy.   \nPatrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12873\u201312883, 2021.   \nWilliam Fedus, Ian Goodfellow, and Andrew M. Dai. Maskgan: Better text generation via filling in the _. In International Conference on Learning Representations, 2018.   \nZhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, and Linli $\\mathrm{\\DeltaXu}$ . Difformer: Empowering diffusion model on embedding space for text generation. arXiv preprint arXiv:2212.09412, 2022.   \nMarjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer. Mask-predict: Parallel decoding of conditional masked language models. In Kentaro Inui, Jing Jiang, Vincent $\\mathrm{Ng}$ , and Xiaojun Wan, editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6112\u20136121, Hong Kong, China, November 2019. Association for Computational Linguistics.   \nShansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. DiffuSeq-v2: Bridging discrete and continuous text spaces for accelerated Seq2Seq diffusion models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9868\u20139875, Singapore, December 2023a. Association for Computational Linguistics.   \nShansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. Diffuseq: Sequence to sequence text generation with diffusion models. In The Eleventh International Conference on Learning Representations, 2023b.   \nJiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. Non-autoregressive neural machine translation. In International Conference on Learning Representations, 2018.   \nJiatao Gu, Changhan Wang, and Junbo Zhao. Levenshtein transformer. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.   \nIshaan Gulrajani and Tatsunori Hashimoto. Likelihood-based diffusion language models. In Thirtyseventh Conference on Neural Information Processing Systems, 2023.   \nXiaochuang Han, Sachin Kumar, and Yulia Tsvetkov. SSD-LM: Semi-autoregressive simplex-based diffusion language model for text generation and modular control. In Anna Rogers, Jordan BoydGraber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11575\u201311596, Toronto, Canada, July 2023. Association for Computational Linguistics.   \nZhengfu He, Tianxiang Sun, Qiong Tang, Kuanning Wang, Xuanjing Huang, and Xipeng Qiu. DiffusionBERT: Improving generative masked language models with diffusion models. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4521\u20134534, Toronto, Canada, July 2023. Association for Computational Linguistics.   \nMartin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.   \nR Devon Hjelm, Athul Paul Jacob, Adam Trischler, Gerry Che, Kyunghyun Cho, and Yoshua Bengio. Boundary seeking gans. In International Conference on Learning Representations, 2018.   \nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 6840\u20136851. Curran Associates, Inc., 2020.   \nEmiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr\u00e9, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 12454\u201312465. Curran Associates, Inc., 2021a.   \nEmiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr\u00e9, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, 2021b.   \nYoon Kim and Alexander M. Rush. Sequence-level knowledge distillation. In Jian Su, Kevin Duh, and Xavier Carreras, editors, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1317\u20131327, Austin, Texas, November 2016. Association for Computational Linguistics.   \nDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. In International Conference on Learning Representations, 2014.   \nZhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis. In International Conference on Learning Representations, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. ", "page_idx": 12}, {"type": "text", "text": "Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori Hashimoto. DiffusionLM improves controllable text generation. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.   \nChin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain, July 2004. Association for Computational Linguistics.   \nAlexandra Lindt and Emiel Hoogeboom. Discrete denoising flows. In ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models, 2021.   \nYaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. In The Eleventh International Conference on Learning Representations, 2023.   \nQiang Liu. Rectified flow: A marginal preserving approach to optimal transport. arXiv preprint arXiv:2209.14577, 2022.   \nXingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. In International conference on learning representations (ICLR), 2023.   \nAaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion language modeling by estimating the ratios of the data distribution. arXiv preprint arXiv:2310.16834, 2023.   \nCheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. arXiv preprint arXiv:2211.01095, 2022a.   \nCheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022b.   \nAli Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata Anand, Raphael R Eguchi, Po-Ssu Huang, and Richard Socher. Progen: Language modeling for protein generation. arXiv preprint arXiv:2004.03497, 2020.   \nAli Madani, Ben Krause, Eric R Greene, Subu Subramanian, Benjamin P Mohr, James M Holton, Jose Luis Olmos, Caiming Xiong, Zachary Z Sun, Richard Socher, et al. Large language models generate functional protein sequences across diverse families. Nature Biotechnology, 41(8): 1099\u20131106, 2023.   \nMyle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of NAACL-HLT 2019: Demonstrations, 2019.   \nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Pierre Isabelle, Eugene Charniak, and Dekang Lin, editors, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics.   \nNiki J. Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Image transformer. In International Conference on Machine Learning (ICML), 2018. URL http://proceedings.mlr.press/v80/parmar18a.html.   \nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 10684\u201310695, June 2022.   \nOlaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18, pages 234\u2013241. Springer, 2015.   \nAlexander M. Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization. In Llu\u00eds M\u00e0rquez, Chris Callison-Burch, and Jian Su, editors, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 379\u2013389, Lisbon, Portugal, September 2015. Association for Computational Linguistics.   \nChitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 36479\u201336494. Curran Associates, Inc., 2022.   \nRico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In Katrin Erk and Noah A. Smith, editors, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715\u20131725, Berlin, Germany, August 2016. Association for Computational Linguistics.   \nJascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 2256\u20132265, Lille, France, 07\u201309 Jul 2015. PMLR.   \nJiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2021a.   \nYang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021b.   \nHaoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, and Hanjun Dai. Score-based continuous-time discrete diffusion models. In The Eleventh International Conference on Learning Representations, 2023.   \nIlya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27, 2014.   \nShawn Tan, Chin-Wei Huang, Alessandro Sordoni, and Aaron Courville. Learning to dequantise with truncated flows. In International Conference on Learning Representations, 2022.   \nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.   \nJiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, and Mingxuan Wang. Dinoiser: Diffused conditional sequence learning by manipulating noises. arXiv preprint arXiv:2302.10025, 2023.   \nHongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, and Songfang Huang. Seqdiffuseq: Text diffusion with encoder-decoder transformers. ArXiv, abs/2212.10325, 2022.   \nPengze Zhang, Hubery Yin, Chen Li, and Xiaohua Xie. Formulating discrete probability flow through optimal transport. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \nQinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator. In The Eleventh International Conference on Learning Representations, 2023.   \nKaiwen Zheng, Cheng Lu, Jianfei Chen, and Jun Zhu. Dpm-solver-v3: Improved diffusion ode solver with empirical model statistics. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Stopping Time for Forward Process ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The forward diffusion process $\\mathbf{X}=\\{\\mathbf{x}_{n},n\\geq0\\}$ is a markovian stochastic process with a transition probability $p(\\mathbf{x}_{i}|\\mathbf{x}_{i-1})=\\mathcal{N}\\left(\\mathbf{x}_{i};\\sqrt{\\alpha_{i}}\\mathbf{x}_{i-1},(1-\\alpha_{i})\\,\\mathbf{I}\\right)$ . And a stopping time $t_{0}$ with respect to $\\mathbf{X}$ is a random time such that for each $n\\,\\geq\\,0$ , the event $\\{t_{0}\\,=\\,n\\}$ is completely determined by the total information known up to time $n$ , $\\{\\mathbf{x}_{0},\\ldots,\\mathbf{x}_{n}\\}$ . Suppose the random variables $\\{\\mathbf{x}_{n}\\}$ are in a one-dimensional space and the forward process starts with $\\mathbf{x}_{0}\\,=\\,0$ . Besides, let $A,\\mathbf{x}_{0}\\in A$ be the discrete area belonging to $\\mathbf{x}_{\\mathrm{0}}$ that for each points in area $A$ will be regarded as $\\mathbf{x}_{\\mathrm{0}}$ during data generation. Our expected stopping time is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nt_{0}=\\operatorname*{min}\\{n\\geq0,\\mathbf{x}_{n}\\notin A\\},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which represents the first time ${\\bf x}_{n}$ leaves area $A$ . We can write the probability of stopping time as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(t_{0}=0)=P(\\mathbf{x}_{0}\\notin A)=0}\\\\ &{P(t_{0}=1)=P(\\mathbf{x}_{0}\\in A,\\mathbf{x}_{1}\\notin A)}\\\\ &{\\quad=\\int_{\\mathbf{x}_{1}\\notin A}N(\\mathbf{x}_{1};\\sqrt{\\alpha_{1}}\\mathbf{x}_{0},(1-\\alpha_{1})\\mathbf{I})\\,\\mathrm{d}\\mathbf{x}_{1}}\\\\ &{P(t_{0}=2)=P(\\mathbf{x}_{0}\\in A,\\mathbf{x}_{1}\\in A,\\mathbf{x}_{2}\\notin A)}\\\\ &{\\quad=P(\\mathbf{x}_{0}\\in A,\\mathbf{x}_{1}\\in A)\\times P(\\mathbf{x}_{2}\\notin A|\\mathbf{x}_{1}\\in A)}\\\\ &{\\quad=\\int_{\\mathbf{x}_{2}\\notin A}\\Big[\\int_{\\mathbf{x}_{1}\\in A}N(\\mathbf{x}_{1};\\sqrt{\\alpha_{1}}\\mathbf{x}_{0},(1-\\alpha_{1})\\mathbf{I})\\times}\\\\ &{\\quad\\quad\\times\\big(\\mathbf{x}_{2};\\sqrt{\\alpha_{2}}\\mathbf{x}_{1},(1-\\alpha_{2})\\mathbf{I})\\,\\mathrm{d}\\mathbf{x}_{1}\\Big]\\,\\mathrm{d}\\mathbf{x}_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{P(t_{0}=n)=P(\\mathbf{x}_{0}\\in A,\\ldots,\\mathbf{x}_{n-1}\\in A,\\mathbf{x}_{n}\\not\\in A)}\\\\ {\\displaystyle=\\int_{\\mathbf{x}_{n}\\not\\in A}\\int_{\\mathbf{x}_{\\leq n}\\in A}\\prod_{i=1}^{n-1}\\mathcal{N}\\left(\\mathbf{x}_{i};\\sqrt{\\alpha_{i}}\\mathbf{x}_{i-1},(1-\\alpha_{i})\\,\\mathbf{I}\\right)\\mathrm{d}\\mathbf{x}_{1:n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since the diffusion process is established in continuous space, calculating the probability of the stopping time requires integrating over each intermediate state $\\mathbf{x}_{1:n-1}$ , rather than a simple state transfer as in the discrete space. Hence, directly obtain the stopping time is intractable. Additionally, even if we are able to get probability of the stopping time, we can only get a distribution over the time dimension, without knowing the exact time of ${\\bf x}_{n}$ leaving area $A$ . Therefore, we need to eliminate randomness from the state transition $\\mathbf{x}_{i-1}\\to\\mathbf{x}_{i}$ and find a deterministic forward trajectory to estimate the stopping time. ", "page_idx": 14}, {"type": "text", "text": "B Properties of Dirac Delta Function ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "There are several useful properties of Dirac delta function: ", "page_idx": 14}, {"type": "text", "text": "\u2022 Symmetry Property: $\\delta(-x)=\\delta(x)$ \u2022 Scaling Property: $\\begin{array}{r}{\\delta(a x)=\\frac{\\delta(x)}{|a|}}\\end{array}$ \u2022 Translation Property: $\\begin{array}{r}{\\int f(x)\\delta(x-a)\\mathrm{d}x=f(a)}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "C Bridging Flow Matching and DDPM ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this work, we utilizes the framework of Flow Matching to model the diffusion processes, where the forward process is defined by flow functions in eq. (5). Although having different mathematical forms, it is essentially equivalent to traditional diffusion processes. Here, we provide an alternative form from the perspective of state transfer $p_{t}\\big(\\mathbf{x}_{t}\\big|\\mathbf{x}_{t-1}\\big)$ . ", "page_idx": 14}, {"type": "text", "text": "C.1 Deterministic Forward Process ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Equation (5) gives the definition $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\,=\\,[\\psi_{t}]_{*}\\pi(\\mathbf{x})$ , where $\\psi_{t}(\\mathbf{x})=\\mathbf{u}_{t}\\mathbf{x}_{0}+\\mathbf{v}_{t}\\mathbf{x}$ . Here we provide the equivalent derivation of $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})$ from the perspective of diffusion processes: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle p_{t}({\\bf x}_{t}|{\\bf x}_{0})=\\int p_{t}({\\bf x}_{1:t}|{\\bf x}_{0})\\mathrm{d}{\\bf x}_{1:t-1}}\\ ~}\\\\ {{\\displaystyle~~~=\\int p({\\bf x}_{1}|{\\bf x}_{0})\\prod_{s=2}^{t}p_{s}({\\bf x}_{s}|{\\bf x}_{s-1},{\\bf x}_{0})\\mathrm{d}{\\bf x}_{1:t-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $p(\\mathbf{x}_{1}|\\mathbf{x}_{0})\\;=\\;\\mathcal{N}(\\mathbf{u}_{1}\\mathbf{x}_{0},\\mathbf{v}_{1}^{2}\\mathbf{I})$ is the first step of the forward process at which the global noise is introduced into the forward trajectory. The state transfer probability of forward process $p_{s}(\\mathbf{x}_{s}|\\mathbf{x}_{s-1},\\mathbf{x}_{0})=\\delta(\\mathbf{x}_{s}-\\mathbf{u}_{s}\\mathbf{x}_{0}-\\mathbf{v}_{s}\\psi_{s-1}^{-1}(\\dot{\\mathbf{x}_{s-1}}))$ is a Dirac delta function. Therefore, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p_{t}(\\mathbf{x}_{t}\\vert\\mathbf{x}_{0})=\\int\\prod_{s=3}^{t}p_{s}(\\mathbf{x}_{s}\\vert\\mathbf{x}_{s-1},\\mathbf{x}_{0})\\mathbf{d}\\mathbf{x}_{2:t-1}}\\\\ &{\\qquad\\times\\underbrace{\\int p_{2}(\\mathbf{x}_{2}\\vert\\mathbf{x}_{1},\\mathbf{x}_{0})p(\\mathbf{x}_{1}\\vert\\mathbf{x}_{0})\\mathrm{d}\\mathbf{x}_{1}}_{Q_{1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where we denote the integral of $\\mathbf{x}_{1}$ as $Q_{1}$ . Based on ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{0}=q(\\mathbf{x}_{1}|\\mathbf{x}_{0})={\\mathcal{N}}(\\mathbf{u}_{1}\\mathbf{x}_{0},\\mathbf{v}_{1}^{2}\\mathbf{I})}\\\\ &{q_{2}(\\mathbf{x}_{2}|\\mathbf{x}_{1},\\mathbf{x}_{0})=\\delta\\left(\\mathbf{x}_{2}-\\mathbf{u}_{2}\\mathbf{x}_{0}-\\mathbf{v}_{2}\\psi_{1}^{-1}(\\mathbf{x}_{1})\\right)}\\\\ &{\\qquad=\\delta\\left[\\mathbf{x}_{2}-\\frac{\\mathbf{v}_{2}}{\\mathbf{v}_{1}}\\mathbf{x}_{1}-\\left(\\mathbf{u}_{2}-\\frac{\\mathbf{v}_{2}\\mathbf{u}_{1}}{\\mathbf{v}_{1}}\\right)\\mathbf{x}_{0}\\right]}\\\\ &{\\qquad=\\delta\\left[\\mathbf{x}_{1}-\\frac{\\mathbf{v}_{1}}{\\mathbf{v}_{2}}\\mathbf{x}_{2}-\\left(\\mathbf{u}_{1}-\\frac{\\mathbf{v}_{1}\\mathbf{u}_{2}}{\\mathbf{v}_{2}}\\right)\\mathbf{x}_{0}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and the Translation Property of the Dirac delta function, we can calculate $Q_{1}$ as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nQ_{1}=\\int\\underbrace{p_{2}(\\mathbf{x}_{2}|\\mathbf{x}_{1},\\mathbf{x}_{0})}_{\\delta(x-a)}\\underbrace{p(\\mathbf{x}_{1}|\\mathbf{x}_{0})}_{f(x)}\\mathrm{d}\\mathbf{x}_{1},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{where}\\;\\left\\{{\\boldsymbol{x}}:\\mathbf{x}_{1}\\right.}\\\\ &{\\qquad\\mathrm{where}\\;\\left\\{{\\boldsymbol{a}}:\\frac{\\mathbf{v}_{1}}{\\mathbf{v}_{2}}\\mathbf{x}_{2}+\\left(\\mathbf{u}_{1}-\\frac{\\mathbf{v}_{1}\\mathbf{u}_{2}}{\\mathbf{v}_{2}}\\right)\\mathbf{x}_{0}\\right.}\\\\ &{\\qquad\\Longrightarrow Q_{1}=\\mathcal{N}(\\mathbf{u}_{2}\\mathbf{x}_{0},\\mathbf{v}_{2}^{2}\\mathbf{I}.)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we can continue the deviation of $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})$ as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})=\\int Q_{0}\\prod_{s=2}^{t}p_{s}(\\mathbf{x}_{s}|\\mathbf{x}_{s-1},\\mathbf{x}_{0})\\mathrm{d}\\mathbf{x}_{1:t-1}}\\\\ {\\displaystyle\\qquad\\qquad=\\int Q_{1}\\prod_{s=3}^{t}p_{s}(\\mathbf{x}_{s}|\\mathbf{x}_{s-1},\\mathbf{x}_{0})\\mathrm{d}\\mathbf{x}_{2:t-1}}\\\\ {\\displaystyle\\qquad\\qquad=\\cdots\\cdots}\\\\ {\\displaystyle\\qquad\\qquad=\\int p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})Q_{t-2}\\mathrm{d}\\mathbf{x}_{t-1}}\\\\ {\\displaystyle\\qquad\\qquad=Q_{t-1}=\\mathcal{N}(\\mathbf{u}_{t}\\mathbf{x}_{0},\\mathbf{v}_{t}^{2}\\mathbf{I})}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, the probability distribution of $\\mathbf{x}_{t}$ conditioned on $\\mathbf{x}_{\\mathrm{0}}$ follows a Gaussian distribution $\\mathcal{N}(\\mathbf{u}_{t}\\mathbf{x}_{0},\\mathbf{v}_{t}^{2}\\mathbf{I})$ , which is the same as in original DDPMs when the coefficient functions are defined as $\\mathbf{u}_{t}=\\sqrt{\\bar{\\alpha}_{t}}$ and $\\mathbf{v}_{t}={\\sqrt{1-{\\bar{\\alpha}}_{t}}}$ . This provides an important benefit that the Flow Matching and diffusion models share the same training procedure. ", "page_idx": 15}, {"type": "text", "text": "C.2 Deterministic Reverse Process ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The reverse tranfer probability follows Bayes\u2019 rule: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})=p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t-1},\\mathbf{x}_{0})\\frac{p_{t-1}\\left(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_{0}\\right)}{p_{t}\\left(\\mathbf{x}_{t}\\mid\\mathbf{x}_{0}\\right)}}\\\\ &{\\quad=\\frac{p_{t-1}\\left(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_{0}\\right)}{p_{t}\\left(\\mathbf{x}_{t}\\mid\\mathbf{x}_{0}\\right)}\\times\\delta\\Bigg[\\mathbf{x}_{t}-\\frac{\\mathbf{v}_{t}}{\\mathbf{v}_{t-1}}\\mathbf{x}_{t-1}-\\left(\\mathbf{u}_{t}-\\frac{\\mathbf{v}_{t}\\mathbf{u}_{t-1}}{\\mathbf{v}_{t-1}}\\right)\\mathbf{x}_{0}\\Bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since Dirac delta function has another form of ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\delta(x)=\\left\\{{+\\infty,x=0}\\atop0,x\\neq0}\\right.,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})>0$ , $p_{t-1}\\bigl(\\mathbf{x}_{t-1}\\bigl|\\mathbf{x}_{t}\\bigr)>0$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{a})=p(\\mathbf{x}|\\mathbf{x}_{t-1},\\mathbf{x}_{a})\\frac{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{a})}{p(\\mathbf{x}|\\mathbf{x}_{a})}}&{}\\\\ {=}&{\\left\\{\\begin{array}{l l}{+\\infty\\times\\frac{N(\\mathbf{x}_{t})}{p(\\mathbf{x}_{t}|\\mathbf{x}_{a})},}&{x_{a}=\\left[\\begin{array}{l}{\\mathbf{v}_{t}}\\\\ {\\mathbf{v}_{t-1}\\mathbf{x}_{t-1}+\\left(\\mathbf{u}_{t}-\\frac{\\mathbf{v}_{t}\\mathbf{u}_{t-1}}{\\mathbf{v}_{t-1}}\\right)\\mathbf{x}_{a}\\right]}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbf{0},}\\\\ {\\qquad\\qquad\\qquad\\qquad\\mathbf{0},}\\end{array}\\right.}\\\\ &{\\qquad\\times\\left\\{\\begin{array}{l l}{+\\infty\\times\\frac{1}{\\mathbf{x}_{t-1}}=\\left[\\begin{array}{l}{\\mathbf{v}_{t-1}\\mathbf{x}_{t}+\\left(\\mathbf{u}_{t}-\\frac{\\mathbf{v}_{t}\\mathbf{u}_{t-1}}{\\mathbf{v}_{t-1}}\\right)\\mathbf{x}_{a}\\right]}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbf{0}}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbf{0}}\\end{array}\\right]}\\\\ &{=\\delta\\left[\\begin{array}{l}{0\\leq\\mathbf{x}_{1}-\\left[\\begin{array}{l}{\\mathbf{v}_{t-1}}\\\\ {\\mathbf{v}_{t}}\\end{array}\\right]\\Bigl(\\frac{\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\mathbf{x}_{t}+\\Bigl(\\mathbf{u}_{t-1}-\\frac{\\mathbf{u}_{t}\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\Bigr)\\mathbf{x}_{a}\\Bigr)}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbf{0}}\\end{array}\\right]}\\\\ &{=\\delta\\left[\\begin{array}{l}{\\mathbf{x}_{1}-\\frac{\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\mathbf{x}_{t}-\\left(\\mathbf{u}_{t-1}-\\frac{\\mathbf{u}_{t}\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\right)\\mathbf{x}_{a}\\Bigr] \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "C.3 Deterministic Optimization Objective ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We first include the derivation of the variational bound for diffusion models provided by SohlDickstein et al. [2015]. The probability the generative model assigns to the data is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p(\\mathbf{x}_{0})=\\displaystyle\\int p(\\mathbf{x}_{0:T})\\mathrm{d}\\mathbf{x}_{1:T}}\\\\ &{\\phantom{\\sum}=\\displaystyle\\int p(\\mathbf{x}_{0:T})\\frac{p_{T}(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})}{p_{T}\\big(\\mathbf{x}_{1:T}|\\mathbf{x}_{0}\\big)}\\mathrm{d}\\mathbf{x}_{1:T}}\\\\ &{\\phantom{\\sum}=\\displaystyle\\int p_{T}\\big(\\mathbf{x}_{1:T}|\\mathbf{x}_{0}\\big)\\frac{p\\big(\\mathbf{x}_{0:T}\\big)}{p_{T}\\big(\\mathbf{x}_{1:T}|\\mathbf{x}_{0}\\big)}\\mathrm{d}\\mathbf{x}_{1:T}}\\\\ &{\\phantom{\\sum}=\\displaystyle\\int p_{T}\\big(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})p(\\mathbf{x}_{T})\\prod_{t=1}^{T}\\frac{p\\big(\\mathbf{x}_{t-1}|\\mathbf{x}_{t}\\big)}{p_{t}\\big(\\mathbf{x}_{t}|\\mathbf{x}_{t-1}\\big)}\\mathrm{d}\\mathbf{x}_{1:T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "image", "img_path": "7AWMTPMZES/tmp/1646c55622e42483c216cad519683863163f72e177371239a67ccd60e24ff442.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 4: We demonstrate the trajectory differences among Markovian Diffusion Process, Deterministic Diffusion and Flow Matching. ", "page_idx": 17}, {"type": "text", "text": "Training amounts to minimizing the negative log likelihood: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}=-\\int p(\\mathbf{x}_{0})\\log p(\\mathbf{x}_{0})\\mathrm{d}\\mathbf{x}_{0}}\\\\ &{\\phantom{=}-\\int p(\\mathbf{x}_{0})\\log\\left[\\int p_{T}(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})p(\\mathbf{x}_{T})\\prod_{t=1}^{T}\\frac{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})}{p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})}\\mathrm{d}\\mathbf{x}_{1:T}\\right]\\mathrm{d}\\mathbf{x}_{0}}\\\\ &{\\phantom{=}\\le-\\int p_{T}(\\mathbf{x}_{0:T})\\log\\left[p(\\mathbf{x}_{T})\\prod_{t=1}^{T}\\frac{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})}{p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})}\\right]\\mathrm{d}\\mathbf{x}_{0:T}}\\\\ &{=\\mathbb{E}_{p_{T}(\\mathbf{x}_{0:T})}\\left[-\\log p(\\mathbf{x}_{T})+\\sum_{t=1}^{T}\\log\\frac{p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})}{p_{t}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})}\\right]}\\\\ &{=\\mathbb{E}_{p_{T}}\\left[\\log\\frac{p(\\mathbf{x}_{T}|\\mathbf{x}_{0})}{p(\\mathbf{x}_{T})}-\\log p(\\mathbf{x}_{0}|\\mathbf{x}_{1})+\\sum_{t=2}^{T}\\log\\frac{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})}{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})}\\right]}\\\\ &{=\\mathbb{E}_{p_{T}}\\left[\\underbrace{p_{T}(\\mathbf{x}_{T}|\\mathbf{x}_{0})|p(\\mathbf{x}_{T})}_{\\in\\mathbf{x}_{T}}\\right]-\\log p(\\mathbf{x}_{0}|\\mathbf{x}_{1})+\\sum_{t=2}^{T}D_{k_{1}}(p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})|)\\left[\\phantom{\\frac{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})}{p_{t}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathcal{L}_{T}$ is usually ignored as a constant and $p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})$ is parameterized with a neural network $p_{\\theta}\\big(\\mathbf{x}_{t-1}\\big|\\mathbf{x}_{t}\\big)$ to approximate the conditioned probability distributions in the reverse process. Since $\\begin{array}{r}{p(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\;=\\;\\underset{\\sigma\\rightarrow0}{\\operatorname*{lim}}\\mathcal{N}\\left(\\frac{\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\mathbf{x}_{t}+\\left(\\mathbf{u}_{t-1}-\\frac{\\mathbf{u}_{t}\\mathbf{v}_{t-1}}{\\mathbf{v}_{t}}\\mathbf{x}_{0}\\right),\\sigma^{2}\\mathbf{I}\\right)}\\end{array}$ , the parameterized $p_{\\theta}\\big(\\mathbf{x}_{t-1}\\big|\\mathbf{x}_{t}\\big)$ can take the same form $\\mathcal{N}(\\mu_{\\theta}(\\mathbf{x}_{t},t),\\sigma_{t}^{2}\\mathbf{I})$ because the Dirac delta function is a special case of Gaussian distribution and the KL divergence of two Gaussians can be simplified. Finally, the training objective for the deterministic diffusion process is divided as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\left\\{\\begin{array}{r l}{\\mathcal{L}_{T}:\\mathrm{a~constant}\\quad\\quad}&{}\\\\ {\\mathcal{L}_{0}:-\\log\\delta\\left(\\mathbf{x}_{0}-\\mathbf{x}_{\\theta}(\\mathbf{x}_{1},1)\\right)}&{}\\\\ {\\mathcal{L}_{t-1}:c\\|\\mathbf{x}_{0}-\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t)\\|^{2}+\\displaystyle\\operatorname*{lim}_{\\sigma\\to0}\\log\\frac{\\sigma_{t}}{\\sigma}}&{}\\\\ {c=\\displaystyle\\frac{1}{2\\sigma_{t}^{2}}\\left(\\mathbf{u}_{t-1}-\\frac{\\mathbf{u}_{t}\\mathbf{v}_{t-1}}{\\mathbf{v}_{t-1}}\\right)^{2},}&{}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the simplified version $\\|\\mathbf{x}_{0}-\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t)\\|^{2}$ is the same as DDPMs but with different coefficients. ", "page_idx": 17}, {"type": "text", "text": "D Different Diffusion Trajectories ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We illustrate the trajectories of different diffusion processes in Figure 4. The forward and reverse generation for the Markovian diffusion process is: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{c}{\\mathbf{x}_{t}=\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon_{t}}\\\\ {\\mathbf{x}_{t-1}=\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\left(1-\\alpha_{t}\\right)}{1-\\bar{\\alpha}_{t}}\\mathbf{x}_{0}+\\frac{\\sqrt{\\alpha_{t}}\\left(1-\\bar{\\alpha}_{t-1}\\right)}{1-\\bar{\\alpha}_{t}}\\mathbf{x}_{t}}\\\\ {+\\,\\frac{\\sqrt{\\left(1-\\bar{\\alpha}_{t-1}\\right)\\left(1-\\alpha_{t}\\right)}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{t-1}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The deterministic diffusion process: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l}{\\displaystyle\\mathbf{x}_{t}=\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon}\\\\ {\\displaystyle\\mathbf{x}_{t-1}=\\left(\\sqrt{\\bar{\\alpha}_{t-1}}-\\frac{\\sqrt{\\bar{\\alpha}_{t}\\bigl(1-\\bar{\\alpha}_{t-1}\\bigr)}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\right)\\mathbf{x}_{0}}\\\\ {\\displaystyle\\qquad\\qquad\\qquad+\\,\\frac{\\sqrt{1-\\bar{\\alpha}_{t-1}}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\mathbf{x}_{t}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The deterministic flow matching with optimal transport: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{c}{\\displaystyle\\mathbf{x}_{t}=(1-\\frac{t}{T})\\mathbf{x}_{0}+\\frac{t}{T}\\epsilon}\\\\ {\\displaystyle\\mathbf{x}_{t-1}=\\frac{1}{t}\\mathbf{x}_{0}+\\frac{t-1}{t}\\mathbf{x}_{t}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "E Details of the Function $G$ ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Equation (13) defines the function $G(\\mathbf{x},\\epsilon)$ as the inversion of coefficient function. ", "page_idx": 18}, {"type": "text", "text": "Flow Matching The coefficient is $\\mathbf{u}_{t}=1-t/T$ , where $t=T\\times\\left(1-\\mathbf{u}_{t}\\right)$ . Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\nG(\\mathbf{x}_{0},\\epsilon)=t_{0}=T\\times(1-\\mathbf{u}_{t_{0}})=T\\Bigg/\\left(1+\\frac{f(\\epsilon,\\mathcal{I})-f(\\epsilon,\\mathcal{I})}{f(\\mathbf{x}_{0},\\mathcal{Z})-f(\\mathbf{x}_{0},\\mathcal{I})}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Diffusion The coefficient for Variance Exploding is $\\begin{array}{r}{{\\bf v}_{T}=\\sigma_{0}\\left(\\frac{\\sigma_{T}}{\\sigma_{0}}\\right)^{\\frac{t}{T}}}\\end{array}$ , where $\\begin{array}{r}{t=T\\times\\frac{\\log{\\mathbf{v}_{t}}-\\log{\\sigma_{0}}}{\\log{\\sigma_{T}}-\\log{\\sigma_{0}}}}\\end{array}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\nG(\\mathbf{x}_{0},\\epsilon)=t_{0}=\\mathbf{v}_{t_{0}}=T\\times{\\frac{\\log{\\mathbf{v}_{t}}-\\log{\\sigma_{0}}}{\\log{\\sigma_{T}}-\\log{\\sigma_{0}}}}=T\\times{\\frac{\\log{\\frac{f(\\epsilon,\\mathcal{I})-f(\\epsilon,\\mathcal{I})}{f(\\mathbf{x}_{0},T)-f(\\mathbf{x}_{0},\\mathcal{T})}}-\\log{\\sigma_{0}}}{\\log{\\sigma_{T}}-\\log{\\sigma_{0}}}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For Variance Preserving, the function $G(\\mathbf{x}_{0},\\epsilon)$ is more difficult to calculate since $\\mathbf{u}_{t}=\\sqrt{\\bar{\\alpha}_{t}}$ , where $\\textstyle{\\bar{\\alpha}}=\\prod_{i=1}^{t}\\alpha_{i}$ , $\\alpha_{t}=1-\\beta_{t}$ , and $\\beta_{t}$ is also influenced by noise schedulers. This makes $G(\\mathbf{x}_{0},\\epsilon)$ hard to calculate. Fortunately, we can bypass this function and provide the corresponding pseudo code. ", "page_idx": 18}, {"type": "text", "text": "F Details of the Training Objective ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The rescaled vector field is calculated as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{u}_{t}=\\displaystyle\\frac{\\mathrm{d}\\tilde{\\mathbf{x}}_{t}}{\\mathrm{d}t}=\\frac{\\mathrm{d}\\tilde{\\mathbf{x}}_{t}}{\\mathrm{d}\\tau}\\frac{\\mathrm{d}\\tau}{\\mathrm{d}t}}\\\\ &{\\quad=\\left[\\mathbf{u}^{\\prime}\\left(\\mathbf{x}_{0},\\tau\\right)\\mathbf{x}_{0}+\\mathbf{v}^{\\prime}(\\mathbf{x}_{0},\\tau)\\mathbf{\\epsilon}\\right]\\frac{T-r\\times G(\\mathbf{x}_{0},\\epsilon)}{T}}\\\\ &{\\quad=u_{\\tau}\\times\\frac{T-r\\times G(\\mathbf{x}_{0},\\epsilon)}{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Considering the expectation form of $\\tilde{u}_{t}$ , there is: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\hat{\\mathbf{x}}_{t}}\\left[\\tilde{u}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})\\right]=\\sum p(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})\\tilde{u}_{t}(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})}\\\\ &{\\qquad\\qquad\\qquad=\\sum p(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})\\bigg[\\mathbf{u}^{\\prime}\\left(\\mathbf{x}_{0},\\tau\\right)\\mathbf{x}_{0}+\\mathbf{v}^{\\prime}(\\mathbf{x}_{0},\\tau)\\epsilon\\biggr]\\underbrace{\\frac{T-r\\times G(\\mathbf{x}_{0},\\epsilon)}{T}}_{\\geq\\mathrm{coedpicient\\:}\\leq1}}\\\\ &{\\qquad\\qquad\\leq\\sum p(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})\\bigg[\\mathbf{u}^{\\prime}\\left(\\mathbf{x}_{0},\\tau\\right)\\mathbf{x}_{0}+\\mathbf{v}^{\\prime}(\\mathbf{x}_{0},\\tau)\\epsilon\\biggr]}\\\\ &{\\qquad\\qquad=\\mathbf{u}^{\\prime}\\left(\\mathbf{x}_{0},\\tau\\right)\\left[\\sum p(\\tilde{\\mathbf{x}}_{t}|\\mathbf{x}_{0})\\mathbf{x}_{0}\\right]+\\mathbf{v}^{\\prime}(\\mathbf{x}_{0},\\tau)\\epsilon}\\\\ &{\\qquad\\qquad=\\tilde{u}_{t}(\\tilde{\\mathbf{x}}_{0}|\\mathbb{E}_{\\tilde{\\mathbf{x}}_{t}}[\\mathbf{x}_{0}]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, the training objective $\\mathbb{E}\\|\\tilde{u}_{t}-\\tilde{u}_{\\theta}\\|^{2}\\leq c\\,\\mathbb{E}\\|{\\mathbf{x}}_{0}-{\\mathbf{x}}_{\\theta}\\|^{2}$ , where $c$ is the coefficient. ", "page_idx": 19}, {"type": "text", "text": "G Code Implementations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Our framework is a module constructed on current diffusion models. We demonstrate our kernel part rescale diffusion trajectory with pseudo python code as below: ", "page_idx": 19}, {"type": "text", "text": "def rescale_diffusion_trajectory(x_0, epsilon , embedding , labels, alphas_cumprod , timesteps , mode): #embedding: embedding matrix , f $(\\mathtt{x}\\,,\\mathtt{i})\\!=$ (embedding \\* x)[i] #labels: I #alphas_cumprod: list of all u_t #timesteps: t #mode: noising or denoising ", "page_idx": 19}, {"type": "text", "text": "#1. get $\\pounds(\\mathtt{x}\\,,\\mathtt{i}\\,)$ :   \nself_dot $=$ torch.sum(embedding \\* embedding , dim $=-1$ )   \n$\\tt f_{-X-i}=$ self_dot[labels][..., None]   \nlabels $=$ labels[..., None]   \n#2. get $\\ f(\\mathtt{x}\\,,\\,\\mathrm{j}\\,)$ and f(eps,j):   \nembedding $=$ embedding.permute(1, 0)   \n$\\tt f_{-X-j}=$ torch.matmul(x_0, embedding)   \nf_eps_j $=$ torch.matmul(epsilon , embedding) ", "page_idx": 19}, {"type": "text", "text": "#3. get f(x,i) \u2212 f(x,j): (usually $>=0$ ; smaller $->$ closer) #filter out $\\mathbf{f}\\left(\\mathbf{x}\\,,{\\dot{\\mathbf{1}}}\\right){-}\\mathbf{f}\\left(\\mathbf{x}\\,,{\\dot{\\mathbf{1}}}\\right)$ with a large positive number 100 fxi_min $\\bf{u s\\mathrm{\\tiny~\\underline{{{\\sfI}}}\\,}}\\bf{x\\mathrm{\\tiny~\\underline{{{\\sfI}}}\\,}}=\\omega\\gamma(\\bf{\\nabla\\mathrm{f_{\\mathrm{-}}}}\\bf{x\\mathrm{\\tiny~\\underline{{{\\sfI}}}\\,}}-\\omega\\gamma\\bf{\\nabla\\mathrm{\\tiny~\\underline{{{f}}}\\ldots~}})$ ).scatter(\u22121, labels , 100) ", "page_idx": 19}, {"type": "text", "text": "#4. get f(eps,i) and f(eps,j) \u2212 f(eps,i): (larger $->$ more noise) f_eps_i $=$ torch.gather(f_eps_j , \u22121, labels) #filter out f(eps,i)\u2212f(eps,i) with a large negative number \u2212100 fepsj_minus_fepsi $=$ (f_eps_j \u2212 f_eps_i).scatter(\u22121, labels , \u2212100) ", "page_idx": 19}, {"type": "text", "text": "#5. get fraction and ${\\bf u}_{-}{\\sf t}_{-}\\uptheta$   \n#mask results outside the support set   \ninfo_mask $=$ (fepsj_minus_fepsi $<\\ \\mathfrak{d}.$ ) | (fxi_minus_fxj < 0)   \nfraction $=$ fix_minus_fjx / fjeps_minus_fieps   \nfraction[info_mask] $=~100$   \nmin_frac , $\\mathbf{\\varepsilon}=$ fraction.min(dim $=-1$ ) # minimum   \n#Diffusion Variance Preserving eq. (9)   \n${\\sf u\\_t}_{-}\\mathfrak{O}_{\\mathrm{~\\tiny~=~}}$ torch.sqrt(1 / (1 $^+$ min_frac \\*\\* 2))[..., None] ", "page_idx": 19}, {"type": "text", "text": "#6. rescale timesteps sqrt_alphas_cumprod $=$ torch.sqrt(alphas_cumprod) ", "page_idx": 19}, {"type": "text", "text": "###!!!important trick!!!### #We do not need to calculate the function ${\\sf G}({\\sf x}_{-}\\mathbb{0}\\ ,{\\sf t})$ (eq. (12)). #Timesteps of diffusion processes are discrete and # we just iterate over and compare with all coefficient functions. #Besides , function G is easy to calculate for Flow Matching. index $=$ torch.sum(u_t_0 $<$ sqrt_alphas_cumprod , ${\\tt d i m}{=}{-1}$ ) ", "page_idx": 20}, {"type": "text", "text": "#T is the maximum timestep , for example $\\scriptstyle\\ T=2\\,\\Theta\\,\\mathbb{O}\\,\\mathbb{O}$ . #confactor is the confidency factor #tau is the rescaled timestep #delta_tau is the rescaled decoding velocity ", "page_idx": 20}, {"type": "text", "text": "if mode $==$ \u2019noising\u2019:tau $=$ (timesteps $^+$ index \u2212 \\(((timesteps $^+$ 1) / T) \\* index)).long().clamp(0, T)tau $=$ (confactor \\* tau.float() + \\(1.0 \u2212 confactor) $^*$ timesteps.float()).long().clamp(0, T)return tau  \nelif mode $==$ \u2019denoising\u2019:delta_tau $=$ (T \u2212 index) / Tdelta_tau $=$ (confactor \\* delta_tau + \\(1 \u2212 confactor) \\* 1.0).clamp(0, 1)return delta_tau", "page_idx": 20}, {"type": "table", "img_path": "7AWMTPMZES/tmp/75b143c25826b1aca4bd285d42f249c539e453b2f47ed061737652eebf82d729.jpg", "table_caption": ["Table 6: FID of difference sampling strategies. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "H Analysis ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Gaussian Sampling Our framework is compatible with the Gaussian sampling in DDPM, where random noises can be added into each iteration step. Algorithm 3 demonstrates the Gaussian sampling procedure. Compared with algorithm 2, a Gaussian noise $\\mathbf{z}\\sim\\dot{\\mathcal{N}}(\\mathbf{0},\\sigma_{t}^{2}\\mathbf{I})$ with a decreasing variance $\\sigma_{t}$ is injected to the estimated next state $\\tilde{\\mathbf{x}}_{t}$ . This noise ${\\bf z}$ will be mapped as changing the initial sampling $\\tilde{\\bf x}_{T}$ through the trajectory alteration step. We illustrate the deterministic and Gaussian sampling for our model on CIFAR-10 in Table 6, where the deterministic sampling can achieve a much better performance of FID. We assume this is because our coefficient functions $\\mathbf{u}(\\mathbf{x}_{0},t)$ and ", "page_idx": 21}, {"type": "table", "img_path": "7AWMTPMZES/tmp/b5f446e228fc8f2a993a251b84521d525c8a31d0566146e485336384d9c1b49c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "$\\mathbf{v}(\\mathbf{x}_{0},t)$ are dynamically calculated to rescale the deterministic trajectory in the training stage. In the inference stage, $\\mathbf{x}_{\\mathrm{0}}$ is replaced by $\\mathbf{x}_{\\theta}(\\mathbf{x}_{t},t)$ , where errors will accumulate if the predicted pseudo target changes frequently. Moreover, Gaussian sampling will further introduce random noises at each reverse step, making our rescaled timestep $\\tau$ far away from the training situation. Therefore, errors in the calculations of trajectory scaling will explode over iterations. ", "page_idx": 21}, {"type": "text", "text": "I Limitations ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Our framework is proposed to migrate the powerful continuous diffusion models to discrete problems. There is another technical route that directly designs the diffusion process on the discrete state space and our method is not useful for this scenario. However, we believe the continuous diffusion models can be a general framework for generative modeling and our effort can advance this target. ", "page_idx": 21}, {"type": "text", "text": "We prefer $\\mathbf{x}_{\\mathrm{0}}$ as the training target because we highly depend on the reliability of the predicted $\\hat{\\mathbf{x}}_{\\mathrm{0}}$ during inference. Although it is possible to use other targets, the modeling effect will decrease in practical use, which limits the flexibility of diffusion modeling. For example, predicting the \u03f5\u02c6 and recovering $\\hat{\\mathbf{x}}_{0}$ with eq. (23) is inefficient, because a small error in predicting \u03f5\u02c6 will be amplified by eq. (23) and lead to the collapse of $G(\\hat{\\mathbf{x}}_{0},\\hat{\\mathbf{\\epsilon}})$ . ", "page_idx": 21}, {"type": "text", "text": "Our approach requires extra computational cost. But they are acceptable since our rescaling process is a series of parallel matrix computations. Considering that our approach is compatible with the Self-Conditioning [Chen et al., 2023b], our overhead is negligible when it is used. ", "page_idx": 21}, {"type": "text", "text": "J Other Experimental Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "For language modeling, we utilize the model configuration transformer-iwslt-de-en in FAIRSEQ framework [Ott et al., 2019] for IWSLT14 DE-EN, which has 6 transformer layers, 4 attention heads, 512 hidden dimensions, and 1024 feed forward layer dimensions. For other datasets, the configuration is transformer-base, which has 6 transformer layers, 8 attention heads, 512 hidden dimensions, and 2048 feed forward layer dimensions. The embedding dimension is 128. The beam size is 1 length prediction beam $\\times\\,5$ generation beam, since the length prediction is unstable for diffusion language models. For reranking, we take 7 length prediction beam $\\times\\:3$ generation beam as Difformer to let the transformer choose the best one. ", "page_idx": 21}, {"type": "image", "img_path": "7AWMTPMZES/tmp/e44dd04818e8d83161062e7e21fb1cac1476a8c1ba32a5bb9fbd8a84a52b2289.jpg", "img_caption": ["Figure 5: Generated BINARY CODING images of reproduced Bit Diffusion and Ours on CIFAR-10. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "For image generation, we set the scaling factor $r=0.5$ for training. Besides, we find that a smaller factor for inference is sometime useful. We set $r=0.45$ on binary coding and $r\\,=\\,0.2$ on fixed embedding during inference. When the pixel embedding is learnable, the scaling factor is $r=0.5$ , which is the same as training. ", "page_idx": 22}, {"type": "text", "text": "Our experiments are performed with Nvidia 80G A100. Each language result requires about 2 days on one single A100. Each image result requires about a week on one single A100. ", "page_idx": 22}, {"type": "text", "text": "K Impact Statements ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "This paper presents work whose goal is to advance the field of Deep Learning. The datasets we used has been widely deployed for many years and has basically no negative impact. Our approach is a framework that migrates existing diffusion models to discrete problems, which does not provide a large pre-trained model that can be used to generate fake contents. ", "page_idx": 22}, {"type": "text", "text": "L Case Study ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Generated sentences on IWSLT14 DE-EN and GIGAWORD are illustrated in Table 7 and Table 8.   \nGenerated images on CIFAR-10 are depicted in Figure 5, 6, and 7. ", "page_idx": 22}, {"type": "table", "img_path": "7AWMTPMZES/tmp/382d51fbca930048e12adb7848f281b9c744ff532ec7b982f1402cbb6b7a25e5.jpg", "table_caption": ["Table 7: Cases of translation on IWSLT14 DE-EN. "], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "7AWMTPMZES/tmp/4c9510cbfb8d5c2802efa15e917e780ca58324b8646ea1bc51848fd3824f4364.jpg", "table_caption": ["Table 8: Cases of summarization on GIGAWORD. "], "table_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "7AWMTPMZES/tmp/dce5fee370c9c3eb1a24d60a65248962de95910778f129fa37572bf4033739d2.jpg", "img_caption": ["Figure 6: Generated FIXED EMBEDDING images of reproduced Bit Diffusion and Ours on CIFAR-10. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "7AWMTPMZES/tmp/667482b42253772d6e4fd2324269d7498845ea032d5da7fc55b85f9ad7d5275b.jpg", "img_caption": ["Figure 7: Generated TRAINABLE EMBEDDING images of reproduced Bit Diffusion and Ours on CIFAR-10. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Contributions and scope are in abstract and introduction. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: Discussed in (7) Conclusion and (H) Limitations sections ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: From sections (A) to (E) in appendices. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We use algorithms 1 and 2 to demonstrate how to reproduce our algorithm. We provide a paragraph of Experimental Setup in (4) Language Modeling and (5) Discrete Image Generation sections. Other details are in section (I) and pseudo code of our kernel process is in (F). ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The pseudo code of our kernel process is demonstrated in (F) and we will public our code on github.com. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide a paragraph of Experimental Setup in (4) Language Modeling and (5) Discrete Image Generation sections. Other details are in section (I). We provide ablation studies on the hyperparameters. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: Error bars are not reported because it would be too computationally expensive. Each result in the experiment table needs to be run on an 80G A100 for at least 2 days. The huge overhead required to obtain a statistically significant error bar makes it impossible for us to achieve it. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Details are in section (I). Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Discussed in section (J). Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 29}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Our approach is a framework involves algorithms but not pre-trained models. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: We provide the link or citation of each asset, where licenses are in the link. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: No new assets introduced. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: No crowdsourcing. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: No crowdsourcing. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 31}]