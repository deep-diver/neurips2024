[{"figure_path": "OUXnnPJzXJ/figures/figures_1_1.jpg", "caption": "Figure 1: We evaluated various robust alignment methods under different proportions of noisy preferences using the Llama2-7B model, on the Golden HH dataset. The reward accuracy of both the vanilla DPO and PPO method significantly decreases as the proportion of noisy preferences increases. Our method, perplexity-aware correction (PerpCorrect), outperforms both the DPO and PPO series baselines across different proportions of noisy preferences.", "description": "This figure shows the performance of different robust alignment methods (vanilla DPO, cDPO, rDPO, and PerpCorrect-DPO; vanilla PPO, cPPO, rPPO, and PerpCorrect-PPO) under varying proportions of noisy preferences (NPs). The reward accuracy is used as a metric. As the proportion of NPs increases, the reward accuracy of vanilla DPO and PPO methods decreases significantly. In contrast, PerpCorrect consistently outperforms the baselines across all NP proportions, demonstrating its robustness to noisy preferences.", "section": "Abstract"}, {"figure_path": "OUXnnPJzXJ/figures/figures_3_1.jpg", "caption": "Figure 2: We visualized the PPLDiff under the entire PerpCorrect process using Llama2-7B on Golden HH dataset with 20% noisy preferences. We use the green dotted line to represent the normal distribution formed by clean data, the red dotted line represents the normal distribution formed by noisy data, and the black dotted line represents the threshold.", "description": "This figure visualizes how the perplexity difference (PPLDiff) between chosen and rejected responses changes throughout the PerpCorrect process.  Initially, the PPLDiff distributions for clean and noisy preferences significantly overlap (Figure 2a), making discrimination difficult. After aligning a surrogate LLM on clean data, the distributions separate somewhat (Figure 2b), but still have considerable overlap. Further iterative alignment using highly reliable clean and noisy data greatly enhances the separability (Figure 2c and 2d), allowing for more accurate identification and correction of noisy preferences based on a threshold.", "section": "3 Perplexity-aware Correction for Robust Alignment"}, {"figure_path": "OUXnnPJzXJ/figures/figures_3_2.jpg", "caption": "Figure 2: We visualized the PPLDiff under the entire PerpCorrect process using Llama2-7B on Golden HH dataset with 20% noisy preferences. We use the green dotted line to represent the normal distribution formed by clean data, the red dotted line represents the normal distribution formed by noisy data, and the black dotted line represents the threshold.", "description": "This figure visualizes the distribution of PPLDiff (the difference in perplexity between chosen and rejected responses) for clean and noisy preferences throughout the PerpCorrect process.  The Llama2-7B model is used on the Golden HH dataset with 20% noisy preferences.  It demonstrates how the alignment process separates clean and noisy preferences, allowing for effective detection and correction of noisy preferences based on the PPLDiff threshold.", "section": "3 Perplexity-aware Correction for Robust Alignment"}, {"figure_path": "OUXnnPJzXJ/figures/figures_3_3.jpg", "caption": "Figure 2: We visualized the PPLDiff under the entire PerpCorrect process using Llama2-7B on Golden HH dataset with 20% noisy preferences. We use the green dotted line to represent the normal distribution formed by clean data, the red dotted line represents the normal distribution formed by noisy data, and the black dotted line represents the threshold.", "description": "This figure visualizes the distribution of PPLDiff (perplexity difference between chosen and rejected responses) at different stages of the PerpCorrect process.  It shows how aligning a surrogate LLM on clean data helps separate the distributions of PPLDiff for clean preferences (CPs) and noisy preferences (NPs).  Further alignment using reliable data (with extremely low and high PPLDiff) improves the separation. Finally, a threshold on PPLDiff is used to detect and correct NPs.", "section": "3 Perplexity-aware Correction for Robust Alignment"}, {"figure_path": "OUXnnPJzXJ/figures/figures_3_4.jpg", "caption": "Figure 2: We visualized the PPLDiff under the entire PerpCorrect process using Llama2-7B on Golden HH dataset with 20% noisy preferences. We use the green dotted line to represent the normal distribution formed by clean data, the red dotted line represents the normal distribution formed by noisy data, and the black dotted line represents the threshold.", "description": "This figure shows the distribution of PPLDiff (the difference in perplexity between chosen and rejected responses) for clean and noisy preferences at different stages of the PerpCorrect process.  Initially, the distributions overlap significantly, making it hard to distinguish clean from noisy preferences. After aligning the surrogate LLM with clean data, the distributions separate somewhat but still overlap. Finally, after further alignment using both reliable clean and noisy data, the distributions are clearly separated, enabling effective identification of noisy preferences.", "section": "3 Perplexity-aware Correction for Robust Alignment"}]