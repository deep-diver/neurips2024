[{"figure_path": "02HWT9c4Lp/figures/figures_2_1.jpg", "caption": "Figure 1: The architecture of VPNet. It consists of BEV and 3D completion branches. CVP in the 3D branch proposes confident voxels to present possibilities for voxels and model the semantic uncertainty of voxels implicitly. Moreover, we construct a multi-frame network and employ MFKD to enhance the accuracy of uncertainty modeling. We represent free voxels as transparent.", "description": "This figure illustrates the overall architecture of the proposed Voxel Proposal Network (VPNet).  VPNet is a dual-branch network (BEV and 3D) designed for semantic scene completion. The 3D branch uses Confident Voxel Proposal (CVP) to identify confident voxels, representing multiple possibilities for each voxel and implicitly modeling semantic uncertainty.  A multi-frame network and Multi-Frame Knowledge Distillation (MFKD) are integrated to improve the accuracy of voxel label prediction.  The BEV branch processes the bird's-eye-view perspective.  The two branches are fused to generate the final completion result.  Transparent voxels represent unoccupied space.", "section": "3 Method Overview"}, {"figure_path": "02HWT9c4Lp/figures/figures_3_1.jpg", "caption": "Figure 2: The pipeline of CVP and MFKD. The semantics feature maps are produced with a segmentation subnetwork in the 3D branch.", "description": "This figure illustrates the process of Confident Voxel Proposal (CVP) and Multi-Frame Knowledge Distillation (MFKD). In the single-frame network, the segmentation subnetwork generates semantics embedded feature maps.  CVP then uses these maps to generate confident feature maps, modeling semantic uncertainty through multiple branches.  The multi-frame network processes multiple frames, each generating an augmented feature map. MFKD distills knowledge from this multi-frame network to enhance the single-frame network's predictions in two stages. Stage-1 aligns the multi-frame feature maps with the single-frame branches. Stage-2 condenses multi-frame possibilities into the single-frame augmented feature map.", "section": "4 Architecture of VPNet"}, {"figure_path": "02HWT9c4Lp/figures/figures_4_1.jpg", "caption": "Figure 3: Branch i of confident voxel proposal (CVP), we divide it into two steps: (a) offset learning and (b) voxel proposal.", "description": "This figure illustrates the process of confident voxel proposal (CVP) in the 3D completion branch of VPNet.  The CVP aims to identify confident voxels with high reliability, implicitly representing voxel-wise semantic uncertainty. The process is split into two stages: (a) Offset learning, where random noise is introduced to the occupied voxel coordinates and features to generate a set of offsets using an MLP (F\u1d62).  (b) Voxel proposal, where these offsets are used to propagate features to neighboring voxels. The figure shows how feature interpolation, concatenation, and weighting are used to create the confident voxel coordinates (Gq) and features (Yq), which form the confident feature map (Eq).", "section": "4.2 Confident Voxel Proposal"}, {"figure_path": "02HWT9c4Lp/figures/figures_5_1.jpg", "caption": "Figure 4: Architecture of the multi-branch fusion.", "description": "This figure shows the architecture of multi-branch fusion used in the Confident Voxel Proposal (CVP) module.  Multiple confident feature maps (E<sup>0</sup> to E<sup>Q-1</sup>) from different branches are first summed using an addition operation. Then, local average pooling (\u00c3) is applied to compress the feature maps. Finally, a fully connected layer (fc <sup>q</sup><sub>i</sub>) is used for each branch, followed by weighted multiplication (X) with weights W<sup>q</sup><sub>i</sub>. The results are summed again, producing the final augmented feature map (A<sub>i</sub>). This process effectively combines information from multiple branches, modeling the uncertainty of voxel semantic labels.", "section": "4.2 Confident Voxel Proposal"}, {"figure_path": "02HWT9c4Lp/figures/figures_5_2.jpg", "caption": "Figure 2: The pipeline of CVP and MFKD. The semantics feature maps are produced with a segmentation subnetwork in the 3D branch.", "description": "This figure illustrates the process of Confident Voxel Proposal (CVP) and Multi-Frame Knowledge Distillation (MFKD).  The 3D branch's segmentation subnetwork generates semantic feature maps. CVP then uses these maps to propose confident voxels, representing multiple semantic label possibilities. MFKD, a two-stage distillation process, condenses information from multiple frames to enhance the single-frame network's accuracy. Stage-1 compares multi-frame and single-frame confident feature maps to guide the single-frame CVP branches. Stage-2 further refines the single-frame representation by distilling the fused multi-frame augmented feature map.", "section": "3 Method Overview"}, {"figure_path": "02HWT9c4Lp/figures/figures_8_1.jpg", "caption": "Figure 6: Completion results of different methods on SemanticKITTI validation set.", "description": "This figure compares the semantic scene completion results of different methods on the SemanticKITTI validation set.  It shows input point clouds and the results generated by LMSCNet, SSA-SC, VPNet (the authors' method), and the ground truth.  Each row represents a different scene, and the color-coding indicates different semantic classes (e.g., car, person, building, road).  The figure visually demonstrates VPNet's improved performance in completing the scene and correctly classifying objects compared to the other methods. Orange boxes highlight specific areas where VPNet shows more accurate or complete results.", "section": "5.4 State-of-the-art Comparison"}]