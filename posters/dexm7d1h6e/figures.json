[{"figure_path": "DexM7d1H6e/figures/figures_1_1.jpg", "caption": "Figure 1: Previous benchmarks (left) relied on limited agent and the scenarios of editing-based benchmarks are unrealistic. Our proposed Animal-Bench (right) includes diverse animal agents, various realistic scenarios, and encompasses 13 different tasks.", "description": "This figure compares previous human-centric video understanding benchmarks with the proposed Animal-Bench.  Previous benchmarks are shown to have limited animal representation and often employ simplified or unrealistic scenarios. In contrast, Animal-Bench is designed to be animal-centric, featuring diverse animal species in various realistic scenarios, encompassing 13 diverse tasks, including both common and special animal-specific tasks.", "section": "1 Introduction"}, {"figure_path": "DexM7d1H6e/figures/figures_3_1.jpg", "caption": "Figure 1: Previous benchmarks (left) relied on limited agent and the scenarios of editing-based benchmarks are unrealistic. Our proposed Animal-Bench (right) includes diverse animal agents, various realistic scenarios, and encompasses 13 different tasks.", "description": "This figure compares previous video understanding benchmarks with the newly proposed Animal-Bench.  The left side shows that previous benchmarks largely focused on humans and objects, with limited representation of animals and often using simplified, unrealistic scenarios. The right side illustrates Animal-Bench, highlighting its strengths: a diverse range of animal agents, inclusion of various realistic scenarios, and a comprehensive set of 13 tasks encompassing common tasks shared with human-centric benchmarks and additional tasks specifically relevant to animal conservation.", "section": "1 Introduction"}, {"figure_path": "DexM7d1H6e/figures/figures_4_1.jpg", "caption": "Figure 3: The diagram of our animal-centric data processing pipeline: Firstly, choose dataset and identify tasks, then establish rules to filter data, and finally automatically generate QA pairs.", "description": "This figure illustrates the Animal-centric Data Processing Pipeline.  It begins with selecting various datasets and identifying the relevant tasks (common and special). Then, data filtering is applied based on data diversity and temporal sensitivity, ensuring animal-centric data and appropriate video lengths for time-related tasks. Finally, a question-answer pair generation process is undertaken, utilizing automated question generation and task-based option design to ensure effective evaluation.", "section": "3.1.2 Animal-Centric Data Processing Pipeline"}, {"figure_path": "DexM7d1H6e/figures/figures_6_1.jpg", "caption": "Figure 4: The diagram of simulation process for shooting parameters. Firstly, the transformed images along with their masks are encoded, and then passed through the diffusion model for denoising. After decoding, the final simulated video is obtained through the guided frame selection module and frame blending module.", "description": "This figure illustrates the process of simulating variations in shooting parameters using a diffusion model.  The process begins with encoding transformed images and their masks using a Variational Autoencoder (VAE). These encodings are then passed through a diffusion model for denoising, resulting in a refined representation. Finally, a guided frame selection module and frame blending module are used to generate the final simulated video, which incorporates realistic variations in shooting parameters like camera distance and angle.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_8_1.jpg", "caption": "Figure 5: Average decrease in model accuracy(%) across four types of variations.", "description": "This figure shows the average decrease in model accuracy across four types of variations (snow, frost, direction, and distance) for four different multimodal video models.  The models are tested on simulated real-world scenarios to evaluate their robustness. The chart displays the relative accuracy drop for each variation.  It helps illustrate the models' sensitivity to different kinds of changes in the video data.", "section": "4.3 Further discussion"}, {"figure_path": "DexM7d1H6e/figures/figures_8_2.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure visualizes the results of simulating changes in shooting parameters using video editing techniques.  It shows the original frames, the frames selected as guides, and the final edited frames, highlighting the effects of simulated distance and direction variations on the video's appearance.  The red boxes in the guided and final frames help focus on the key areas where changes were applied.  The overall effect is to simulate more realistic, less controlled video-recording conditions.", "section": "4.3 Further discussion"}, {"figure_path": "DexM7d1H6e/figures/figures_9_1.jpg", "caption": "Figure 7: The radar map illustrates the accuracy on \"object recognition\" and \"action recognition\" tasks across 7 animal categories.", "description": "This radar chart visualizes the performance of different multimodal video models on object and action recognition tasks, categorized across seven major animal categories (mammal, bird, reptile, amphibian, fish, insect, and sea animal). Each axis represents a category, and the radial distance from the center indicates the accuracy achieved by a specific model for that category.  The chart facilitates a comparison of model performance across diverse animal types, highlighting strengths and weaknesses in recognizing particular animal categories.", "section": "4.3 Further discussion"}, {"figure_path": "DexM7d1H6e/figures/figures_9_2.jpg", "caption": "Figure 1: Previous benchmarks (left) relied on limited agent and the scenarios of editing-based benchmarks are unrealistic. Our proposed Animal-Bench (right) includes diverse animal agents, various realistic scenarios, and encompasses 13 different tasks.", "description": "This figure compares previous benchmarks with the Animal-Bench proposed in the paper.  The left side shows that existing benchmarks have limitations, focusing primarily on humans and objects with simplified, unrealistic scenarios.  Animal-Bench, on the other hand (right side), is designed to evaluate multimodal video models in real-world contexts using diverse animal agents and realistic scenarios, including 13 distinct tasks.", "section": "1 Introduction"}, {"figure_path": "DexM7d1H6e/figures/figures_19_1.jpg", "caption": "Figure 1: Previous benchmarks (left) relied on limited agent and the scenarios of editing-based benchmarks are unrealistic. Our proposed Animal-Bench (right) includes diverse animal agents, various realistic scenarios, and encompasses 13 different tasks.", "description": "This figure compares previous human-centric video understanding benchmarks with the newly proposed Animal-Bench.  It highlights the limitations of existing benchmarks, such as limited animal representation and unrealistic scenarios.  In contrast, Animal-Bench offers a more comprehensive and realistic evaluation, encompassing diverse animal agents, various realistic scenarios, and 13 diverse tasks.", "section": "1 Introduction"}, {"figure_path": "DexM7d1H6e/figures/figures_19_2.jpg", "caption": "Figure 1: Previous benchmarks (left) relied on limited agent and the scenarios of editing-based benchmarks are unrealistic. Our proposed Animal-Bench (right) includes diverse animal agents, various realistic scenarios, and encompasses 13 different tasks.", "description": "This figure compares previous benchmarks with the proposed Animal-Bench.  Previous benchmarks are criticized for their limited representation of animal agents (only 1% animal data in MVBench example) and use of unrealistic, simplified scenarios (often created through artificial image editing). In contrast, Animal-Bench features diverse animal agents across various realistic scenarios and 13 diverse tasks designed to comprehensively evaluate multimodal video models in animal-centric video understanding.", "section": "1 Introduction"}, {"figure_path": "DexM7d1H6e/figures/figures_21_1.jpg", "caption": "Figure 11: Visualization of simulated changes mimicking real shooting scenarios", "description": "This figure shows example frames from videos used in the Animal-Bench benchmark.  It demonstrates how the researchers simulated real-world filming conditions by applying video editing techniques to add simulated snow, frost, variations in camera distance and direction. The original frames are shown alongside the edited versions to illustrate the changes.", "section": "4 Experiments"}, {"figure_path": "DexM7d1H6e/figures/figures_22_1.jpg", "caption": "Figure 11: Visualization of simulated changes mimicking real shooting scenarios", "description": "This figure shows examples of simulated video frames to demonstrate the effects of varying weather conditions (snow and frost) and shooting parameters (distance and direction) on video quality.  The goal was to enhance the realism of the Animal-Bench benchmark by simulating the variability encountered in real-world animal video recordings.", "section": "4 Experiments"}, {"figure_path": "DexM7d1H6e/figures/figures_22_2.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the results of simulating changes in shooting parameters (distance and direction) using video editing techniques. It demonstrates how these changes affect the appearance of the video frames, showing the original frames, the frames after applying the guided frame selection and the final frames.  The images showcase the process of simulating realistic scenarios like changes in shooting distance, potentially due to animal movements.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_22_3.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the effects of simulating changes in shooting parameters (distance and direction) using video editing techniques.  The left side shows the original video frames, while the right illustrates the modified frames after applying the editing process to simulate changes in proximity to the camera and the direction of shooting. These changes are designed to make the video evaluation more realistic and robust, reflecting conditions found in real-world animal video recordings.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_22_4.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the results of simulating changes in shooting parameters using video editing techniques.  It visually demonstrates the effects of varying shooting distance and direction on the resulting videos. The \"Original\" column shows the original frames.  The \"Distance variation\" column demonstrates the effect of simulated changes in camera distance to the subject (closer or farther). The \"Direction variation\" column illustrates how changes in camera angle alter the captured video.  The image demonstrates the use of a diffusion model to simulate realistic scenarios, such as weather conditions and shooting parameters, for evaluating the robustness of multimodal video models.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_23_1.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the results of simulating changes in shooting parameters (distance and direction) using video editing techniques.  The original frames are shown alongside frames with simulated changes, demonstrating the effects of varying camera proximity and angle on the captured video.  Each row represents a different animal, showing how the simulation alters the appearance of the video.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_23_2.jpg", "caption": "Figure 11: Visualization of simulated changes mimicking real shooting scenarios", "description": "This figure shows examples of simulated video frames to illustrate the effects of various video editing techniques.  Specifically, it displays how the simulated changes in weather (snow and frost) and shooting parameters (distance and direction) alter the appearance of the original video frames. The goal is to create more realistic and challenging video data for evaluating the robustness of multimodal video models.", "section": "4 Experiments"}, {"figure_path": "DexM7d1H6e/figures/figures_23_3.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the effects of simulating changes in shooting parameters (distance and direction) using video editing techniques. The left side displays the original video frames, and the right side shows the frames after applying the simulation.  The results illustrate how the simulated changes affect the appearance of the animal in the video, which can impact the model's ability to accurately recognize and classify the animal.", "section": "3.2 Realistic simulation based on video editing"}, {"figure_path": "DexM7d1H6e/figures/figures_23_4.jpg", "caption": "Figure 6: The visualization results of simulated changes in shooting parameters. Zoom in to view details.", "description": "This figure shows the results of simulating changes in shooting parameters using video editing techniques.  The left side shows the original video frames, followed by examples of the \"distance variation\" and \"direction variation.\" These variations simulate realistic scenarios where the camera distance and angle change due to animal movement or other real-world conditions. The right side shows simulated snowy and frosty weather conditions, demonstrating how the model's performance is affected by varied shooting parameters and environmental factors. By examining these variations, researchers aim to better understand the model's robustness in real-world situations.", "section": "4.3 Further discussion"}]