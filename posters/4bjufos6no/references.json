{"references": [{"fullname_first_author": "Sami Abu-El-Haija", "paper_title": "Youtube-8m: A large-scale video classification benchmark", "publication_date": "2016-09-08", "reason": "This paper is foundational for video research, providing a large-scale dataset crucial for training and evaluating video models."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-31", "reason": "This paper introduces Flamingo, a powerful visual language model that is leveraged in the proposed MM-Det framework, enhancing the model's ability to understand and reason about visual content."}, {"fullname_first_author": "Anurag Arnab", "paper_title": "Vivit: A video vision transformer", "publication_date": "2021-12-31", "reason": "This paper proposes a video vision transformer (ViViT), which is used as a baseline in the proposed MM-Det model to analyze video data."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces Stable Video Diffusion, one of the video generation models used for creating the DVF dataset, which is essential for evaluating the algorithm's performance."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-10-19", "reason": "This paper introduces Videocrafter1, one of the video generation models that are used in the DVF dataset and is an important reference due to the quality of videos generated by this model."}]}