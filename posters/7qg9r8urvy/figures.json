[{"figure_path": "7QG9R8urVy/figures/figures_8_1.jpg", "caption": "Figure 1: Performance and Q values of DMG with varying mixture coefficient \u03bb over 5 random seeds. The crosses \u00d7 mean that the value functions diverge in several seeds. As \u03bb increases, DMG enables stronger generalization propagation, resulting in higher and probably divergent learned Q values. Mild generalization propagation plays a crucial role in achieving strong performance.", "description": "This figure shows the performance and Q-values of the Doubly Mild Generalization (DMG) algorithm as the mixture coefficient \u03bb varies.  The x-axis represents \u03bb, ranging from 0 to 1.  The y-axis shows both the normalized return (performance) and the Q-value.  Multiple lines represent different locomotion tasks.  The crosses indicate divergence of the value functions.  The figure demonstrates that a moderate value of \u03bb (mild generalization propagation) is crucial for optimal performance, while excessively high values of \u03bb lead to divergence.", "section": "5.3 Ablation Study for Performance and Value Estimation"}, {"figure_path": "7QG9R8urVy/figures/figures_8_2.jpg", "caption": "Figure 2: Performance and Q values of DMG with varying penalty coefficient v over 5 random seeds. As v decreases, DMG allows broader action generalization, leading to larger learned Q values. Mild action generalization is also critical for attaining superior performance.", "description": "The figure displays the performance and Q-values of the Doubly Mild Generalization (DMG) algorithm with varying penalty coefficient (v).  It shows that as the penalty coefficient decreases, the algorithm allows for broader action generalization, leading to higher Q-values. However, the optimal performance is achieved with a moderate level of action generalization, demonstrating the importance of balancing generalization for achieving optimal results. The results are averaged across five random seeds, enhancing the reliability of the observations. The plots highlight the relationship between the penalty coefficient, the resulting Q values, and the overall performance of the algorithm.", "section": "5.3 Ablation Study for Performance and Value Estimation"}, {"figure_path": "7QG9R8urVy/figures/figures_29_1.jpg", "caption": "Figure 3: Runtime of algorithms on halfcheetah-medium-replay-v2 on a GeForce RTX 3090.", "description": "This figure shows the runtime of different offline reinforcement learning algorithms on a specific task, halfcheetah-medium-replay-v2, using a GeForce RTX 3090 GPU.  The algorithms compared are Decision Transformer (DT), MOPO, CQL, AWAC, the proposed Doubly Mild Generalization (DMG), IQL, and TD3BC. The bar chart visually represents the runtime of each algorithm, with DMG showing a runtime comparable to TD3BC, one of the faster methods.", "section": "D.1 Computational Cost"}, {"figure_path": "7QG9R8urVy/figures/figures_30_1.jpg", "caption": "Figure 4: Learning curves of DMG on Gym locomotion tasks during offline training. The curves are averaged over 5 random seeds, with the shaded area representing the standard deviation across seeds.", "description": "This figure displays the learning curves of the Doubly Mild Generalization (DMG) algorithm during offline training on various Gym locomotion tasks.  The performance, measured as episode return, is plotted against the number of gradient steps. Each line represents the average performance over 5 different random seeds, with the shaded region indicating the standard deviation. This visualization allows for assessing the stability and convergence speed of the DMG algorithm across different random initializations for each task. The x-axis shows the number of gradient steps (in millions), and the y-axis shows the episode return.", "section": "D.3 Learning Curves of DMG during Offline Training"}, {"figure_path": "7QG9R8urVy/figures/figures_31_1.jpg", "caption": "Figure 5: Learning curves of DMG on Antmaze tasks during offline training. The curves are averaged over 5 random seeds, with the shaded area representing the standard deviation across seeds.", "description": "This figure shows the learning curves of the Doubly Mild Generalization (DMG) algorithm on six AntMaze tasks from the D4RL benchmark.  Each curve represents the average episode return over five random seeds, and the shaded region shows the standard deviation. The x-axis represents the number of gradient steps during offline training, and the y-axis represents the average episode return.  The figure demonstrates the performance of DMG on various AntMaze environments, revealing its learning progress and stability across different scenarios.", "section": "D.3 Learning Curves of DMG during Offline Training"}, {"figure_path": "7QG9R8urVy/figures/figures_31_2.jpg", "caption": "Figure 5: Learning curves of DMG on Antmaze tasks during offline training. The curves are averaged over 5 random seeds, with the shaded area representing the standard deviation across seeds.", "description": "This figure shows the learning curves of the Doubly Mild Generalization (DMG) algorithm on six different AntMaze tasks during offline training.  Each curve represents the average episode return over five random seeds, and the shaded region indicates the standard deviation. The x-axis represents the number of gradient steps (in millions), and the y-axis represents the average episode return. The figure illustrates the learning progress of DMG across various AntMaze environments with different levels of complexity and data distributions.", "section": "5.1 Main Results on Offline RL Benchmarks"}]