[{"type": "text", "text": "Investigating Variance Definitions for Stochastic Mirror Descent with Relative Smoothness ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Mirror Descent is a popular algorithm, that extends Gradients Descent (GD) beyond   \n2 the Euclidean geometry. One of its benefits is to enable strong convergence   \n3 guarantees through smooth-like analyses, even for objectives with exploding or   \n4 vanishing curvature. This is achieved through the introduction of the notion of   \n5 relative smoothness, which holds in many of the common use-cases of Mirror   \n6 descent. While basic deterministic results extend well to the relative setting, most   \n7 existing stochastic analyses require additional assumptions on the mirror, such as   \n8 strong convexity (in the usual sense), to ensure bounded variance. In this work, we   \n9 revisit Stochastic Mirror Descent (SMD) proofs in the (relatively-strongly-) convex   \n10 and relatively-smooth setting, and introduce a new (less restrictive) definition   \n11 of variance which can generally be bounded (globally) under mild regularity   \n12 assumptions. We then investigate this notion in more details, and show that it   \n13 naturally leads to strong convergence guarantees for stochastic mirror descent.   \n14 Finally, we leverage this new analysis to obtain convergence guarantees for the   \n15 Maximum Likelihood Estimator of a Gaussian with unknown mean and variance. ", "page_idx": 0}, {"type": "text", "text": "16 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "17 The central problem of this paper is to solve optimization problems of the following form: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x\\in C}f(x),{\\mathrm{~where~}}f(x)=\\mathbb{E}\\left[f_{\\xi}(x)\\right],\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "18 where $C$ is a closed convex subset of $\\mathbb{R}^{d}$ , and $f_{\\xi}$ are differentiable convex functions (stochasticity   \n19 is on the variable $\\xi,$ ). The problems that we will consider typically arise from machine-learning   \n20 use-cases, meaning that the dimension $d$ can be very large. Therefore, first-order methods are popular   \n21 for solving these problems, since they usually scale well with the dimension.   \n22 In standard machine learning setups, computing a gradient of $f$ is very costly (or even impossible),   \n23 since it requires computing gradients for all individual examples in the dataset. Yet, gradients of $f_{\\xi}$   \n24 are relatively cheap, and arbitrarily high precisions are generally not required. This makes Stochastic   \n25 Gradient Descent (SGD) the method of choice [4]. Using a step-size $\\eta>0$ , the SGD update from   \n26 point x \u2208Rd can be written as xS+GD $\\begin{array}{r}{x_{\\mathrm{SGD}}^{+}=\\arg\\operatorname*{min}_{u\\in C}\\left\\{\\eta\\bar{\\nabla}f_{\\xi}(x)^{\\top}u+\\frac{1}{2}\\|u-x\\|^{2}\\right\\}}\\end{array}$ .   \n27 While the standard Euclidean geometry leading to Gradient Descent (GD) ftis many use-cases quite   \n28 well, several applications are better solved with Mirror Descent (MD), a generalization of GD which   \n29 allows to better capture the geometry of the problem. For instance, the Kullback-Leibler divergence   \n30 might be better suited to discriminating between probability distributions than the (squared) Euclidean   \n31 norm, and this is something that one can leverage using MD with entropy as a mirror. As a matter   \n32 of fact, many standard algorithms can be interpreted as MD, i.e., as generalized first-order methods.   \n33 This is for instance the case in statistics, where Expectation Minimization and Maximum A Posteriori   \n34 estimators can be interpreted as running MD with specific mirror and step-sizes [15, 17]. Mirror   \n35 descent can also be used to solve Poisson inverse problems, which have many applications in   \n36 astronomy and medicine [3], to reduce the communication cost of distributed algorithms [24, 12],   \n37 or to solve convex quartic problems [6]. In the online learning community as well, many standard   \n38 algorithms such as Exponential Weight Updates or Follow-The-Regularized-Leader can be interpreted   \n39 as running mirror descent [21, 13]. There are still many open questions regarding the convergence   \n40 guarantees for most of the algorithms mentioned above. Therefore, progress on the understanding of   \n41 MD can lead to a plethora of results on these applications, and more generally to a more consistent   \n42 theory for Majorization-Minimization algorithms. This paper is a stepping stone in this direction.   \n43 Let us now introduce the mirror map, or potential function $h$ , together with the Bregman divergence   \n44 with respect to $h$ , which is defined for $x,y\\in\\operatorname{dom}h$ as $D_{h}(x,y)\\stackrel{*}{=}h(x)\\!-\\!h(y)\\!-\\!\\nabla\\bar{h(y)^{\\top}}(x\\!-\\!\\bar{y)}$ . We   \n45 now introduce the Stochastic Mirror Descent (SMD) update, which can be found in its deterministic   \n46 form in, e.g., Nemirovskij and Yudin [22]. SMD consists in replacing the squared Euclidean norm   \n47 from the SGD update by the Bregman divergence with respect to the mirror map $h$ : ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\boldsymbol{x}^{+}(\\eta,\\xi)=\\arg\\operatorname*{min}_{u\\in C}\\left\\{\\eta\\nabla f_{\\xi}(x)^{\\top}u+D_{h}(u,x)\\right\\}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "48 Note that since $D_{\\|\\cdot\\|^{2}}(x,y)=\\|x-y\\|^{2}$ , one can recover SGD by taking $h=\\textstyle{\\frac{1}{2}}\\|\\cdot\\|^{2}$ . In this sense,   \n49 SMD can be viewed as standard SGD, but changing the way distances are computed, and so the   \n50 geometry of the problem. Yet, this change significantly complicates the convergence analysis of the   \n51 method, since the Bregman divergence, in general: $(i)$ does not satisfy the triangular inequality, $(i i)$ is   \n52 not symmetric, $(i i i)$ is not translation-invariant, $(i\\nu)$ is not convex in its second argument.   \n53 This means that analyzing mirror descent methods requires quite some care, and that many standard   \n54 (S)GD results do not extend to the mirror setting. For instance, one can prove that mirror descent   \n55 cannot be accelerated in general [8]. Similarly, applying techniques such as variance-reduction   \n56 requires additional assumptions [7]. To ensure that $\\bar{x^{+}}(\\eta,\\bar{\\xi})$ exists and is unique, we first make the   \n57 following blanket assumption throughout the paper:   \n58 Assumption 1. Function $h:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}\\cup\\{\\infty\\}$ is twice continuously differentiable and strictly convex   \n59 on $C$ . For every $\\boldsymbol{y}\\in\\mathbb{R}^{d}$ , the problem $\\mathrm{min}_{x\\in C}\\,h(x)-x^{\\top}y$ has a unique solution, which lies in int $C$ ,   \n60 and all $f_{\\xi}$ are convex.   \n61 Note that the regularity assumption on $h$ could be relaxed, as discussed in Section 3, but we choose a   \n62 rather strong one to make sure all the objects we will manipulate are well-defined. Interestingly, while   \n63 mirror descent changes the way distances are computed to move away from the Euclidean geometry,   \n64 standard analyses of mirror descent methods, and in particular in the online learning community,   \n65 still require strong convexity and Lipschitz continuity with respect to norms [5, Chapter 4]. It is   \n66 only recently that a relative smoothness assumption was introduced to study mirror descent [2, 20],   \n67 together with the corresponding relative strong convexity.   \n68 Definition 1. The function $f$ is said to be $L$ -relatively smooth and $\\mu$ -relatively strongly convex with   \n69 respect to $h$ if for all $x,y\\in C$ : $\\mu D_{h}(x,y)\\leq D_{f}(x,y)\\leq L D_{h}(x,y)$ . To lighten notation, we will   \n70 omit the dependence on $h$ and simply write that $f$ is $L$ -rel.-smooth unless clearly specified.   \n71 Definition 1 extends the standard smooth and strongly convex assumptions that correspond to the case   \n72 $h=\\textstyle{\\frac{1}{2}}\\|\\cdot\\|^{2}$ , so that for all $x\\in C$ , $\\nabla^{2}h(x)=I$ the identity matrix. These assumptions allow MD   \n73 analyses to generalize standard GD analyses, and in particular to obtain similar linear and sublinear   \n74 rates, with constant step-size and conditions adapted to the relative assumptions.   \n75 While the basic deterministic setting is now well-understood under relative assumptions, a good   \n76 understanding of the stochastic setting remains elusive. In particular, as we will see in more details in   \n77 the related work section, all existing proofs somehow require the mirror h to be globally strongly   \n78 convex with respect to a norm, or have non-vanishing variance. The only case that can be analyzed   \n79 tightly is under interpolation (there exists a point that minimizes all stochastic functions), or when   \n80 using Coordinate Descent instead of SMD [10, 11]. This is a major weakness, as the goal of relative   \n81 smoothness is precisely to avoid comparisons to norms. Indeed, even when these \u201cabsolute\u201d regularity   \n82 assumptions hold, the smoothness and strong convexity constants are typically very loose, and the   \n83 theory is not representative of the observed behaviour of the algorithms.   \n84 However, as hinted at earlier, this was expected: acceleration is notoriously hard to achieve for mirror   \n85 descent (and even impossible in general [8]), and variance reduction typically encounters the same   \n86 problems [7]. For stochastic updates, this comes from the fact that it is impossible to disentangle the   \n87 stochastic gradient from the effect of the curvature of $h$ at the point at which it is applied.   \n88 Contribution and outline. The main contribution of this paper is to introduce a new analysis for   \n89 mirror descent, with a variance notion which is provably bounded under mild regularity assumptions:   \n90 typically, the same as those required for the deterministic case. We introduce our new variance   \n91 notion, and compare it with standard ones from the literature in Section 2. This new analysis is both   \n92 simpler and tighter than existing ones, as shown in Section 3. Finally, we use our results to analyse   \n93 the convergence of the Maximum Likelihood and Maximum A Posteriori estimators for a Gaussian   \n94 with unknown mean and variance in Section 4, and show that it is the first generic stochastic mirror   \n95 descent analysis that obtains meaningful finite-time convergence guarantees in this case. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "96 2 Variance Assumptions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "97 We now focus on the various variance assumptions under which Stochastic Mirror Descent is analyzed.   \n98 Some manipulations require technical lemmas, such as the duality property of the Bregman divergence   \n99 or the Bregman co-coercivity lemma, which can be found in Appendix A.   \n100 We start by introducing our variance definition, prove a few good properties for it, and then compare   \n101 it with the existing ones to highlight their shortcomings. The two key properties we would like to   \n102 ensure (and which are not satisfied by other definitions) are: (i) boundedness without strong convexity   \n103 of $h$ or restricting the SMD iterates, and (ii) finiteness for $\\eta\\rightarrow0$ (with the appropriate scaling). ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "104 2.1 New variance definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "105 Let $\\eta>0$ , and recall that $x^{+}(\\eta,\\xi)$ is the result of a SMD step from $x$ using function $f_{\\xi}$ with step-size   \n106 $\\eta$ (Equation (2)). From now on, when clear from the context, we will simply denote this point $x^{+}$ .   \n107 Yet, although the dependence is now implicit, do keep in mind that $x^{+}$ is a stochastic quantity that is   \n108 not independent from $\\xi$ nor $\\eta$ , as this is critical in most results. Under Assumption 1, $\\bar{x}^{+}$ writes: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\nabla h(x^{+})=\\nabla h(x)-\\eta\\nabla f_{\\xi}(x).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "109 Similarly, we denote by $\\overline{{x^{+}}}$ the deterministic Mirror Descent update, which is such that $\\nabla h(\\overline{{x^{+}}})=$   \n110 $\\nabla h(x)-\\eta\\nabla f(x)$ . We also introduce $h^{*}:y\\mapsto\\arg\\operatorname*{max}_{x\\in C}x^{\\top}y-h(x)$ the convex conjugate of $h$ ,   \n111 which verifies $\\dot{\\nabla}h^{*}(\\nabla h(x))=x$ . Let us now define the key function ", "page_idx": 2}, {"type": "equation", "text": "$$\nf_{\\eta}(x)=f(x)-\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(x,x^{+})\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "112 Definition 2. We define the variance of the stochastic mirror descent iterates given by (2) as   \n113 \u03c3\u22c62,\u03b7 = \u03b71 supx\u2208C (f(x\u22c6) \u2212f\u03b7(x)) =f  \u03b7\u2212f \u03b7, where $f^{\\star}$ and $f_{\\eta}^{\\star}$ are respectively the inf. of $f$ and $f_{\\eta}$ .   \n114 We now state various bounds on $\\sigma_{\\star,\\eta}^{2}$ , to help understand its behaviour. We start by positivity, which   \n115 is an essential property that justifies the square in the definition. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "116 Proposition 2.1 (Positivity). For all $\\eta>0$ , $\\sigma_{\\star,\\eta}\\geq0$ . ", "page_idx": 2}, {"type": "text", "text": "117 This result follows from $f_{\\eta}(x)\\leq f(x)$ , since $D_{h}(x,x^{+})\\geq0$ for all $x\\in C$ by convexity of $h$ . ", "page_idx": 2}, {"type": "text", "text": "118 Stochastic functions after a step. We first upper bound $\\sigma_{\\star,\\eta}^{2}$ directly in terms of $f_{\\xi}$ ", "page_idx": 2}, {"type": "text", "text": "119 Proposition 2.2. If $f_{\\xi}$ is $L$ -rel.-smooth and $\\eta\\leq1/L,$ then $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\le\\frac{1}{\\eta}\\left(f(x_{\\star})-\\operatorname*{min}_{x\\in C}\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]\\right)}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "120 Proof. Since $D_{h}(x,x^{+})~=~\\langle\\nabla h(x^{+})\\,-\\,\\nabla h(x),x^{+}\\,-\\,x\\rangle\\,-\\,D_{h}(x^{+},x).$ , then $D_{h}(x,x^{+})\\;\\;=\\;\\;$   \n121 $-\\eta\\dot{\\nabla}f_{\\xi}(x)^{\\top}(x^{+}-x)-\\dot{D}_{h}(x^{+},x)=\\stackrel{\\prime}{\\eta}\\left(D_{f_{\\xi}}(x^{+},x)-f_{\\xi}(\\dot{x}^{+})+f_{\\xi}(x)\\right)\\stackrel{\\prime}{-}D_{h}(x^{+},x),$ , x). The rela  \n122 tive smoothness of $f_{\\xi}$ and the step-size condition imply that $\\eta D_{f_{\\xi}}(x^{+},x)\\leq D_{h}(x^{+},x)$ , leading to   \n123 $\\begin{array}{r}{\\frac{1}{\\eta}D_{h}(x,x^{+})\\leq f_{\\xi}(x)-f_{\\xi}(x^{+})}\\end{array}$ , and the result follows. \u53e3   \n124 This bound offers a new point of view on the variance, which can be bounded as the difference   \n125 between the optimum of $f$ , and the optimum of a related function, in which we make one mirror   \n126 descent step before evaluating each $f_{\\xi}$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "127 Finiteness. Proposition 2.2 implies the following: ", "page_idx": 2}, {"type": "text", "text": "128 Corollary 2.3. If $f_{\\xi}$ is $L$ -relatively-smooth w.r.t. h and admits a minimum $x_{\\star}^{\\xi}\\in$ int $C$ a.s., then for   \n129 all $\\begin{array}{r}{\\eta\\le1/L,\\,\\sigma_{\\star,\\eta}^{2}\\le\\frac{f(x_{\\star})-\\mathbb{E}\\left[f_{\\xi}(x_{\\star}^{\\xi})\\right]}{\\eta}}\\end{array}$ \u2264 f(x\u22c6)\u2212E\u03b7[f\u03be(x\u03be\u22c6)]. In particular, \u03c3\u22c62,\u03b7 is finite.   \n130 This result directly comes from the fact that $\\begin{array}{r l r}{\\operatorname*{min}_{x\\in{\\cal C}}\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]}&{\\ge}&{\\mathbb{E}\\left[\\operatorname*{min}_{x\\in{\\cal C}}f_{\\xi}(x^{+})\\right]\\;\\;\\ge\\;}\\end{array}$   \n131 $\\mathbb{E}\\left[f_{\\xi}(x_{\\star}^{\\xi})\\right]$ . It shows that the standard regularity assumptions for the convergence of stochastic   \n132 mirror descent guarantee that the variance as introduced in Definition 2 remains bounded. This is a   \n133 strong result, that justifies the supremum in the variance definition. Indeed, most other variance   \n134 definitions require additional assumptions for the variance to remain bounded after the supre  \n135 mum. Instead, we globalize the variance definition, by taking the supremum over the right quantity   \n136 to ensure that it remains bounded over the whole domain without having to explicitly assume it. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "137 Note that the bound from Corollary 2.3 has already been investigating in other settings for stochastic 138 optimization [19], as discussed in Section 2.2. While useful to show boundedness, this bound has a 114309 hmaapjpoer ndsr ainw pbraacckt,i cwe,h iwchh iicsh t ihsa tw ith ye xwple oidnevse swtihgeant et hfein estr ebpo-suinzde $\\eta$ o vn .es. This does not reflect what $\\sigma_{\\star,\\eta}^{2}$ ", "page_idx": 3}, {"type": "text", "text": "141 Gradient norm at optimum. A usual way of formulating variance is to express it as the norm   \n142 of the difference between stochastic gradients and the deterministic gradients. While the previous   \n143 bounds highlight dependencies on the gradient steps (through evaluations at $x^{+}$ ), none of them really   \n144 corresponds to \u201cthe size of the stochastic gradients at optimum\u201d. The key subtlety is that when using   \n145 mirror descent, it is important to also specify the point at which these gradients are applied, and the   \n146 following proposition gives a bound of this flavor on $\\sigma_{\\star,\\eta}^{2}$ . In this section, $x_{\\eta}$ denotes the minimizer   \n147 of $f_{\\eta}$ when it exists and is in int $C$ . Otherwise, unless explicitly stated, results involving $x_{\\eta}$ can be   \n148 replaced by a limit for $x\\rightarrow x_{\\eta}$ . ", "page_idx": 3}, {"type": "text", "text": "149 Proposition 2.4. If $f$ is $L$ -rel.-smooth, $\\eta\\leq1/L$ and $\\begin{array}{r}{x_{\\star}\\in\\mathrm{int}\\;C,\\,\\sigma_{\\star,\\eta}^{2}\\leq\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h}\\left(\\overline{{x_{\\eta}^{+}}},x_{\\eta}^{+}\\right)\\right].}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "150 This can be considered as the Mirror Descent equivalent of $\\Xi\\left[\\|\\nabla f_{\\xi}(x_{\\star})\\|^{2}\\right]$ . Yet, a key difference is   \n151 that stochastic gradients are evaluated at point $x_{\\eta}$ instead of $x_{\\star}$ , and $\\nabla f(x_{\\eta})\\neq0$ in general. ", "page_idx": 3}, {"type": "text", "text": "152 Proof. For all $x$ , applying the duality property of the Bregman divergence leads to: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]=\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x^{+}),\\nabla h(x))\\right]=\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x)-\\eta\\nabla f_{\\xi}(x),\\nabla h(x))\\right]}\\\\ &{\\ =\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x)-\\eta\\nabla f(x),\\nabla h(x))\\right]+\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x)-\\eta\\nabla f_{\\xi}(x),\\nabla h(x)-\\eta\\nabla f(x))\\right]}\\\\ &{\\ =\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x)-\\eta\\left[\\nabla f(x)-\\nabla f(x_{\\star})\\right],\\nabla h(x))\\right]+\\mathbb{E}\\left[D_{h}\\left(\\overline{{x^{+}}},x^{+}\\right)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "153 where the last equality comes from the Bregman bias-variance decomposition Lemma [23].   \n154 We then use the Bregman cocoercivity Lemma [7] to obtain: $\\mathbb{E}\\left[D_{h}(x,\\bar{x}^{+})\\right]\\;\\le\\;\\eta D_{f}(x,x_{\\star})\\;+$   \n155 $\\mathbb{E}\\left[D_{h}\\left(\\overline{{x^{+}}},x^{+}\\right)\\right]$ . All these technical results can be found in Appendix A. In the end, $f_{\\eta}(x)\\geq$   \n156 $\\begin{array}{r l}{f(x_{\\star})-\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(\\overline{{x^{+}}},x^{+})\\right]}&{{}}\\end{array}$ , and this is in particular true for $x=x_{\\eta}$ .   \n157 Limit behaviour. A first observation is that both the $D_{h}(x,x^{+})$ term in the definition of $f_{\\eta}$ and our   \n158 variance definition are scaled by $\\eta^{-1}$ . Yet, they remain finite when $\\eta\\rightarrow0$ . While this is clear in the   \n159 Euclidean setting, this property holds more generally, as shown in the two following results. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "160 Proposition 2.5. Let $x\\in C$ and $\\eta_{0}>0$ s.t. $\\begin{array}{r}{\\mathbb{E}D_{h}(x,x^{+}(\\eta_{0},\\xi))<\\infty.\\ T h e n,\\ f_{\\eta}(x)\\xrightarrow{\\eta\\rightarrow0}f(x).}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "161 Note that uniform convergence of $f_{\\eta}$ to $f$ would require that there exists $\\eta~>~0$ such that   \n162 $\\operatorname*{sup}_{x\\in C}D_{h}(x,x^{+})$ is finite, which we cannot guarantee in general (it does not hold for $f=g=$   \n163 ${\\frac{1}{2}}\\parallel\\cdot\\parallel^{2}$ defined on $\\mathbb{R}^{d}$ for instance). Denote $\\|x\\|_{A}^{2}=x^{\\top}A x$ , then:   \n164 Proposition 2.6 (Small step-sizes limit). If $f_{\\xi}$ are $L$ -rel.-smooth and $f$ has a unique minimizer $x_{\\star}$   \n165 and for some $\\eta_{0}>0$ , $x_{\\eta}=\\arg\\operatorname*{min}f_{\\eta}(x)$ exists and is in int $C$ for $\\eta\\leq\\eta_{0}$ , ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{\\eta\\to0}\\sigma_{\\star,\\eta}^{2}=\\operatorname*{lim}_{\\eta\\to0}\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h}(x_{\\star}^{+},x_{\\star})\\right]=\\frac{1}{2}\\mathbb{E}\\left[\\|\\nabla f_{\\xi}(x_{\\star})\\|_{\\nabla^{2}h(x_{\\star})^{-1}}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "166 This variance is actually the best we can hope for in the Bregman setting, which indicates the   \n167 relevance of Definition 2. Indeed, this term exactly correspond to the variance one would obtain   \n168 when making infinitesimal SMD steps from $x_{\\star}$ , i.e., the norm of the stochastic gradients at optimum   \n169 in the geometry given by $\\nabla^{2}h(x_{\\star})^{-1}$ . ", "page_idx": 4}, {"type": "text", "text": "170 2.2 Standard Assumptions ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "171 We now compare Definition 2 with several variance assumptions from the literature. Note that they   \n172 typically \u201conly\u201d require the bounds to hold for all iterates over the trajectory. However, in the absence   \n173 of proof that the iterates stay in certain regions of the space, suprema over the whole domain are   \n174 required for all variance definitions.   \n175 Euclidean case. Let us now take a step back and look at the Euclidean case, $h=\\textstyle{\\frac{1}{2}}\\|\\cdot\\|^{2}$ , and assume   \n176 that $f$ is $L$ -smooth. Writing Equation (3) with this specific $h$ and replacing $x_{\\eta}$ by a supremum, we   \n177 obtain $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\,\\le\\,\\operatorname*{sup}_{x\\in C}\\mathbb{E}\\left[\\frac{1}{2}\\|\\nabla f(x)-\\nabla f_{\\xi}(x)\\|^{2}\\right]}\\end{array}$ , which is a common though debatable variance   \n178 assumption. Indeed, it involves a maximum over the domain, and is in particular not bounded in   \n179 general even for simple examples like Linear Regression. Yet, we can recover another standard   \n180 variance assumption by assuming the smoothness of all $f_{\\xi}$ [9], which writes $\\sigma_{\\star,\\eta}^{2}\\leq\\mathbb{E}\\left[\\|\\nabla f_{\\xi}(x_{\\star})\\|^{2}\\right]$   \n181 This result is obtained by writing that $\\|\\nabla f_{\\xi}(x)\\|^{2}\\leq2\\|\\nabla f_{\\xi}(x)-\\nabla f_{\\xi}(x_{\\star})\\|^{2}+2\\|\\nabla f_{\\xi}(x_{\\star})\\|^{2}$ , and   \n182 bounding the first term using smoothness. In particular, we see that standard Euclidean variance   \n183 definitions are natural bounds of $\\sigma_{\\star,\\eta}^{2}$ . Detailed derivations can be found in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "184 Divergence between stochastic and deterministic gradients. An early variance definition for SMD 185 in the relative setting comes from Hanzely and Richt\u00e1rik [10], who define $\\sigma_{\\mathrm{sym}}^{2}$ as: ", "text_level": 1, "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{\\mathrm{sym}}^{2}=\\displaystyle\\frac{1}{\\eta}\\operatorname*{sup}_{x\\in C}\\mathbb{E}\\left[\\left\\langle\\nabla f(x)-\\nabla f_{\\xi}(x),x^{+}-\\overline{{x^{+}}}\\right\\rangle\\right]=\\displaystyle\\frac{1}{\\eta^{2}}\\operatorname*{sup}_{x\\in C}\\mathbb{E}\\left[D_{h}\\left(x^{+},\\overline{{x^{+}}}\\right)+D_{h}\\left(\\overline{{x^{+}}},x^{+}\\right)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "186 where we recall that $\\overline{{x^{+}}}$ is such that $\\nabla h(\\overline{{x^{+}}})=\\nabla h(x)-\\eta\\nabla f(x)$ . We remark two main things when   \n187 comparing \u03c3s2ym with Proposition 2.4: (i) $\\sigma_{\\star,\\eta}^{2}$ is not symmetrized, and contains only one of the two   \n188 terms, and (ii) the bound only needs to hold at $x_{\\eta}$ instead of for all $x\\in C$ . As a result, we directly   \n189 obtain that $\\sigma_{\\star,\\eta}^{2}\\le\\sigma_{\\mathrm{sym}}^{2}$ , and $\\sigma_{\\mathrm{sym}}^{2}$ is actually infinite in most cases, whereas $\\sigma_{\\star,\\eta}^{2}$ is usually finite, as   \n190 seen above. ", "page_idx": 4}, {"type": "text", "text": "191 Stochastic gradients at optimum. Dragomir et al. [7] define the variance as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sigma_{D E H}^{2}=\\operatorname*{sup}_{x\\in C}\\frac{1}{2\\eta^{2}}\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x)-2\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x))\\right]=\\operatorname*{sup}_{x\\in C}\\mathbb{E}\\left[\\|\\nabla f_{\\xi}(x_{\\star})\\|_{\\nabla^{2}h^{*}(z(x))}^{2}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "192 where $z(x)\\in[\\nabla h(x),\\nabla h(x)-\\eta\\nabla f_{\\xi}(x_{\\star})]$ The main interest of this definition is that stochastic   \n193 gradients are only taken at $x_{\\star}$ . In particular, this variance is 0 in case there is interpolation (all   \n194 stochastic functions share a common minimum). However, this quantity can blow up if $h$ is not   \n195 strongly convex, since in this case $\\nabla^{2}h^{*}$ is not upper bounded (indeed, smoothness of the conjugate   \n196 is ensured by strong convexity of the primal function [14]). Following similar derivations, but after   \n197 the supremum has been taken, we arrive at:   \n198 Proposition 2.7. If $f$ is $L$ -relatively-smooth w.r.t. $h_{i}$ , then for $\\eta\\ <\\ 1/(2L)$ and some $z_{\\eta}\\;\\;\\in$   \n199 [\u2207h(x\u03b7), \u2207h(x\u03b7) \u2212\u03b7\u2207f\u03be(x\u22c6)], the variance can be bounded as \u03c3\u22c62,\u03b7 \u2264E \u2225\u2207f\u03be(x\u22c6)\u22252\u22072h\u2217(z\u03b7) . ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "200 In particular, we obtain a finite bound without having to restrict the space. ", "page_idx": 4}, {"type": "text", "text": "201 Functions variance. Another variance definition that appears in the SGD literature is of the form   \n202 $f(x_{\\star})-\\mathbb{E}\\left[f_{\\xi}(x_{\\star}^{\\xi})\\right]\\!.$ , using the optima of the stochastic functions [19]. Unfortunately, the results   \n203 derived with this definition do not obtain a vanishing variance term when $\\eta\\rightarrow0$ , unlike most other   \n204 variance definitions, and contrary to what is observed in practice, that smaller step-sizes reduce   \n205 the variance. The vanishing variance term can be obtained by rescaling by $1/\\eta$ (so considering   \n206 $\\left(f(x_{\\star})-\\mathbb{E}\\left[f_{\\xi}(x_{\\star}^{\\xi})\\right]\\right)/\\eta$ instead), but this variance definition would explode for $\\eta\\rightarrow0$ . This is   \n207 because using such a definition would come down to performing the supremum step within the   \n208 expectation from Proposition 2.2, using that $f_{\\xi}(x^{+})\\geq f_{\\xi}(x_{\\star}^{\\xi})$ , which is a very crude bound. Instead,   \n209 Corolary 2.3 directly shows that our variance definition is tighter than this one, and in particular (i) it is   \n210 bounded for all $\\eta>0$ , (ii) it remains finite as $\\eta\\rightarrow0$ even with the proper rescaling (Proposition 2.6).   \n211 Relation to $c$ -transform. Mirror descent can be viewed as an alternate minimization method on   \n212 transforms of $f$ [18]. This point of view subsumes many methods, including the Newton Method or   \n213 Mirror Descent. Central to their analysis is the notion of $c$ -transform $f^{c}(y)=\\operatorname*{sup}_{x\\in C}f(x)-c(x,y)$ ,   \n214 a standard quantity from optimal transport [25]. It turns out that for $\\eta\\,\\leq\\,1/L$ , $f_{\\eta}$ is actually   \n215 linked to the $c$ -transform as $f_{\\eta}(x)\\,=\\,\\mathbb{E}\\left[f_{\\xi}^{c}(x^{+})\\right]$ , where we use the cost $\\begin{array}{r}{c(x,y)\\,=\\,\\frac{1}{\\eta}D_{h}(x,y)}\\end{array}$ .   \n216 Since $f(x_{\\star})=f^{c}(x_{\\star})=\\arg\\operatorname*{min}_{x\\in C}f(\\overline{{x^{+}}})$ , denoting $T_{c}(g)=g^{c}(\\nabla h^{*}(\\nabla h(x)-\\eta\\nabla g(x)))$ , we   \n217 have that \u03c3\u22c62,\u03b7 = $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\!=\\!\\frac{1}{\\eta}(\\operatorname*{min}_{x\\in C}\\mathcal{T}_{c}(\\mathbb{E}\\left[f_{\\xi}\\right])(x)\\!-\\operatorname*{min}_{x\\in C}\\mathbb{E}\\left[\\mathcal{T}_{c}(f_{\\xi})\\right](x))}\\end{array}$ . We recognize the structure of a   \n218 variance, as the difference between an operator applied to the expectation of a random variable, and   \n219 the expectation of the operator applied to the random variable. Yet, compared to standard (Euclidean)   \n220 analyses of SGD, it does not simply corresponds to the variance of the stochastic gradients (at   \n221 optimum), and bears a more complex form.   \n222 In this section, we have highlighted the connections with other definitions, and argued that $f_{\\eta}$ (and   \n223 its minimum) is a relevant quantity. In particular, Definition 2 is the only definition that allows   \n224 boundedness of the variance notion both after a supremum step over the iterates (and without strong   \n225 convexity of $h$ ) and in the $\\eta\\rightarrow0$ limit with the proper rescaling. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "226 3 Convergence Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "227 Now that we have (extensively) investigated $\\sigma_{\\star,\\eta}^{2}$ , and the various interpretations that come from   \n228 different bounds, we are ready to state the convergence results. Some proofs in this section are just   \n229 sketched, but complete derivations can be found in Appendix C. ", "page_idx": 5}, {"type": "text", "text": "230 3.1 Relatively Strongly Convex setting. ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "231 Recall that $f_{\\eta}^{\\star}=\\operatorname*{inf}_{x\\in C}f_{\\eta}(x)$ . Starting from an arbitrary $x^{(0)}$ , the sequence $(\\boldsymbol x^{(k)})_{k\\ge0}$ is built as   \n232 $x^{(k+1)}=(x^{(\\dot{k})})^{+}$ for $k\\in\\{0,T\\}$ for some $T>0$   \n233 Theorem 3.1. If $f$ is $\\mu$ -relatively-strongly-convex with respect to $h_{i}$ , under a constant step-size $\\eta$ , the   \n234 iterates obtained by SMD (Equation (3)) verify ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\eta\\left[\\mathbb{E}\\left[f_{\\eta}(x^{(T)})\\right]-f_{\\eta}^{\\star}\\right]+\\mathbb{E}\\left[D_{h}(x_{\\star},x^{(T+1)})\\right]\\leq(1-\\eta\\mu)^{T+1}D_{h}(x_{\\star},x^{(0)})+\\frac{\\eta\\sigma_{\\star,\\eta}^{2}}{\\mu}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "235 Note that the (relatively) strongly-convex theorem has a standard form, and recovers usual MD results   \n236 if we remove the variance, and standard SGD results if we take $h=\\textstyle{\\frac{1}{2}}\\|\\cdot\\|^{2}$ . ", "page_idx": 5}, {"type": "text", "text": "237 Proof of Theorem 3.1. We start from a variation of Dragomir et al. [7, Lemma 4]: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{E}\\left[D_{h}(x_{\\star},x^{+})\\right]-D_{h}(x_{\\star},x)+\\eta D_{f}(x_{\\star},x)=-\\eta[f(x)-f(x_{\\star})]+\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]}\\\\ {=\\eta\\left[f(x_{\\star})-\\left(f(x)-\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]\\right)\\right]=\\eta\\left[f(x_{\\star})-f_{\\eta}(x)\\right]}\\\\ {=-\\eta\\left[f_{\\eta}(x)-f_{\\eta}^{\\star}\\right]+\\eta\\left[f(x_{\\star})-f_{\\eta}^{\\star}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "238 Using that $D_{f}(x_{\\star},x)\\geq\\mu D_{h}(x_{\\star},x)$ , and remarking that $f(x_{\\star})-f_{\\eta}^{\\star}=\\eta\\sigma_{\\star,\\eta}^{2}.$ , we obtain: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\eta\\left[f_{\\eta}(x)-f_{\\eta}^{\\star}\\right]+\\mathbb{E}\\left[D_{h}(x_{\\star},x^{+})\\right]\\leq(1-\\eta\\mu)D_{h}(x_{\\star},x)+\\eta^{2}\\sigma_{\\star,\\eta}^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "239 At this point, we can neglect the $\\eta\\left[f_{\\eta}(x)-f_{\\eta}^{\\star}\\right]\\geq0$ terms and chain the inequalities for $x=x^{(t)}$   \n240 for $t$ from 0 to $T$ to obtain the result.   \n241 This proof is quite simple, and naturally follows from Lemma C.1. One can also note that relative   \n242 smoothness of $f$ is not required to obtain Theorem 3.1, which has no condition on the step-size. This   \n243 is not a typo, but reflects the fact that step-size conditions are needed to obtain a bounded variance.   \n244 Indeed, the variance as defined here entangles aspects tied with the error due to discretization (which   \n245 is usually dealt with using smoothness), and the error due to stochasticity. This is natural, as the   \n246 stochastic noise vanishes in the continuous limit $(\\eta\\rightarrow0)$ ). Besides, the magnitude of the updates   \n247 depends both on where the stochastic gradient is applied and on the step-size. Yet, the simplicity of   \n248 the proof is partly due to this entanglement, meaning that we have deferred some of the complexity   \n249 to the bounding of the variance term.   \n250 Also note that Theorem 3.1 uses constant step-sizes, but Equation (10) can be used with time-varying   \n251 step-sizes, as is done for instance in the proof of Theorem 4.3. A variant of Theorem 3.1 in which the   \n252 discretization error is partly removed from the notion of variance writes:   \n253 Corollary 3.2. Let $f$ be $\\mu$ -strongly-convex and $L$ -relatively-smooth with respect to $h$ , and $f_{+}^{\\star}=$   \n254 $\\operatorname{inf}_{x\\in C}$ E $\\left[f_{\\xi}(x^{+})\\right]$ . If $\\eta\\leq1/L,$ , the SMD iterates (Equation (3)) with constant step-size $\\eta$ verify ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\gamma\\left[\\mathbb{E}\\left[f_{\\xi}((x^{(T)})^{+})\\right]-f_{+}^{\\star}\\right]+\\mathbb{E}\\left[D_{h}(x_{\\star},x^{(T+1)})\\right]\\le(1-\\eta\\mu)^{T+1}D_{h}(x_{\\star},x^{(0)})+\\frac{\\eta}{\\mu}\\left[\\frac{f(x_{\\star})-f_{+}^{\\star}}{\\eta}\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "255 This alternate version is obtained using that $f_{\\eta}(x)\\;\\geq\\;\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]$ , a key step from the proof of   \n256 Proposition 2.2 (see (8)). In the deterministic case, $f_{+}^{\\star}=f(x_{\\star})$ , and we recover standard results. ", "page_idx": 6}, {"type": "text", "text": "257 3.2 Convex setting. ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "258 Let us now consider the convex case, meaning that $\\mu=0$ . ", "page_idx": 6}, {"type": "text", "text": "259 Theorem 3.3. If $f$ is convex, the iterates obtained by SMD using a constant step-size $\\eta>0$ verify ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{1}{T+1}\\sum_{k=0}^{T}\\mathbb{E}\\left[f_{\\eta}(x^{(k)})-f_{\\eta}^{\\star}+D_{f}(x_{\\star},x^{(k)})\\right]\\leq\\frac{D_{h}(x_{\\star},x^{(0)})}{\\eta(T+1)}+\\eta\\sigma_{\\star,\\eta}^{2}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "260 This theorem is obtained by summing Equation (9) for $x\\;=\\;x^{(k)}$ for all $k\\ \\in\\ \\{1,\\ldots,T\\}$ and   \n261 rearranging the terms. Note that varying step-size results can be obtained in the same way.   \n262 This case differs from standard convex analyses, in that we obtain a control on $f_{\\eta}(x^{(k)})-f_{\\eta}^{\\star}+$   \n263 $D_{f}(x_{\\star},x^{(k)})$ instead of the usual $f(x^{(k)})-f(x_{\\star})$ . One of the main consequences is that we cannot   \n264 get a control on the average iterate since Bregman divergences are in general not convex in their   \n265 second argument, and $f_{\\eta}$ is not necessarily convex. This non-standard result is a direct consequence   \n266 of our choice of variance definition, but it is actually a quantity that naturally arises in the analysis.   \n267 Note that a variant involving $f_{+}^{\\star}$ can be obtained in the same lines as Corollary 3.2.   \n268 Controlling $f_{\\eta}$ . The results in this section do not directly control the function gap $f(x)-f^{*}$ , but   \n269 rather the transformed one $f_{\\eta}(x)-f_{\\eta}^{\\star}$ . Yet, the continuity result (in $\\eta$ ) from Proposition 2.5 shows   \n270 that the bounds we provide can still be interpreted as relevant function values for small $\\eta$ .   \n271 Controlling $D_{f}(x_{\\star},x^{(k)})$ . An interesting property of $D_{f}(x_{\\star},x^{(k)})$ is that it can be linked with the   \n272 size of the gradients of $f$ , as shown by the following result.   \n273 Proposition 3.4. If $\\nabla f(x_{\\star})=0$ and $f$ is $L$ -relatively smooth with respect to h then for all $x\\ne x_{\\star}$ ,   \n274 $\\begin{array}{r}{D_{f}(x_{\\star},x)\\ge L D_{h^{*}}\\Big(\\nabla h(x_{\\star})+\\frac{\\nabla f(x)}{L},\\nabla h(x_{\\star})\\Big)>0.}\\end{array}$ .   \n275 This is a Bregman equivalent of controlling the gradient squared norm, with the additional benefit   \n276 that the reference point at which we apply the gradient is the optimum $x_{\\star}$ . Besides, Proposition 3.4   \n277 shows that $D_{f}(x_{\\star},x)>0$ for $x\\ne x_{\\star}$ without requiring $f$ to be strictly convex (only $h$ ).   \n278 Minimal assumptions on $h$ . Note that the theorems in this section do not actually require $h$ to satisfy   \n279 Assumption 1, but only that iterations can be written in the form of Equation 3 (which is guaranteed   \n280 by Assumption 1). While Assumption 1 allows for instance to use the Bregman cocoercivity lemma   \n281 with any points, or ensures that $\\dot{\\nabla}^{2}h$ is well-defined, which we leverage extensively in Section 2, our   \n282 theorems are much more general than this, and include applications such as proximal gradient mirror   \n283 descent (next remark) or the MAP for Gaussian Parameters Estimation (next section).   \n284 Stochastic Mirror Descent with a Proximal term. Note that our results can be directly extended to   \n285 handle a proximal term (similarly to the Euclidean proximal gradient algorithm), to handle composite   \n286 objectives of the form $f+g$ (and in particular projections, for cases in which $g$ is the indicator of a   \n287 convex set). More details can be found in Appendix E.   \n289 So far, we have proposed new variance definitions for the analysis of stochastic mirror descent, and   \n290 we have shown that they compare favorably to existing ones, while leading to simple convergence   \n291 proofs. In this section, we investigate the open problem formulated by Le Priol et al. [17], which is to   \n292 find non-asymptotic convergence guarantees for the KL-divergence of the Maximum A Posteriori   \n293 (MAP) estimator. In particular, this example highlights the relevance of the infimum step on $f_{\\eta}$ , since   \n294 it gives the first generic analysis that obtains meaningful finite time convergence rates. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "295 4.1 MAP and MLE of exponential families. ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "296 We now rapidly review the formalism of exponential families. More details can be found in Le Priol   \n297 et al. [17], and Wainwright et al. [26, Chapter 3]. Let $X$ be a random variable, and $T$ a deterministic   \n298 function, then the density of an exponential family for a sample $x$ writes $p_{\\theta}(x)~=~p(x|\\theta)~=$   \n299 $\\exp(\\langle\\theta,T(x)\\rangle\\!-\\!A(\\theta))$ , where $A$ is often refered to as the log-partition function. In this case, $\\theta$ is called   \n300 the natural parameter, and $T$ is the sufficient statistic. Function $A$ is convex, and we can thus establish   \n301 a form of duality through convex conjugacy. The entropy writes $A^{*}(\\mu)=\\operatorname*{max}_{\\theta^{\\prime}\\in\\Theta}\\langle\\mu,\\theta^{\\prime}\\rangle-A(\\theta^{\\prime})$ .   \n302 Parameter $\\mu$ is called the mean parameter, and the standard MAP estimator can be derived for $n_{0}\\in\\mathbb{N}$ ,   \n303 $\\mu_{0}\\in\\mathbb{R}$ as n0\u00b5(0)+n +in=n1 T (Xi). The Maximum Likelihood Estimator (MLE) corresponds to   \n304 taking $n_{0}=0$ . An interesting observation is that $\\mu_{\\mathrm{MAP}}^{(n)}$ can be obtained recursively for $n>0$ , as   \n305 $\\mu_{\\mathrm{MAP}}^{(0)}=\\mu^{(0)}$ , $\\eta_{n}=(n\\!+\\!n_{0})^{-1}$ , $\\mu_{\\mathrm{MAP}}^{(n+1)}=\\mu_{\\mathrm{MAP}}^{(n)}\\!-\\!\\eta_{n}\\nabla g_{X_{n}}(\\mu_{\\mathrm{MAP}}^{(n)})$ , with $\\nabla g_{X_{n}}(\\mu)=\\mu\\!-\\!T(X_{n})$   \n306 In terms of primal variable $\\theta^{(n)}=\\nabla A^{*}(\\mu_{\\mathrm{MAP}}^{(n)})$ , the MAP writes: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\nabla A(\\boldsymbol{\\theta}^{(n+1)})=\\nabla A(\\boldsymbol{\\theta}^{(n)})-\\eta\\nabla f_{X_{n}}(\\boldsymbol{\\theta}^{(n)}),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "307 where $f_{X_{n}}(\\theta)=A(\\theta)-\\langle\\theta,T(X_{n})\\rangle$ , so that $f(\\theta)=A(\\theta)-\\left\\langle\\theta,\\mu_{\\star}\\right\\rangle$ . We recognize stochastic mirror   \n308 descent iterations, with mirror $A$ and stochastic gradients $\\nabla f_{X}$ . Similar results on the MLE can be   \n309 obtained by taking $n_{0}=0$ . This key observation implies that convergence guarantees on the MAP   \n310 and the MLE can be deduced from stochastic mirror descent convergence guarantees.   \n311 While this appears as an appealing way to obtain convergence guarantees for the MAP, Le Priol et al.   \n312 [17] observe that none of the existing SMD results obtain meaningful rates for the convergence of the   \n313 MAP for general exponential families. In particular, none of them recover the ${\\cal O}(1/n)$ asymptotic   \n314 convergence rate for estimating a Gaussian with unknown mean and covariance.   \n315 This is due to the variance definitions used in the existing analyses, that all have issues (not uniformly   \n316 bounded over the domain, not decreasing with the step-size...) as discussed in Section 2. Our analysis   \n317 fixes this problem, and thus yields finite-time guarantees for the MAP estimator for the estimation of   \n318 a Gaussian with unknown mean and covariance. This shows the relevance of Assumption 2. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "319 4.2 Full Gaussian (unknown mean and covariance) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "320 The main problem studied in Le Priol et al. [17] is that of the one-dimensional full-Gaussian   \n321 case, where the goal is to estimate the mean and covariance of a Gaussian from i.i.d. samples   \n322 $X_{1},\\ldots,X_{n}\\sim{\\mathcal{N}}(m_{\\star},\\Sigma_{\\star})$ , with $\\Sigma_{\\star}\\,>\\,0$ . Note that although notation $\\Sigma$ is usually reserved for   \n323 the covariance matrix of a multivariate Gaussian, we use it for a scalar value here to highlight the   \n324 distinction with $\\sigma_{\\star,\\eta}^{2}$ , the variance from stochastic mirror descent. In this case, the sufficient statistics   \n325 write $T(X)=(X,X^{2})$ , and the log-partition and entropy functions are, up to constants, $A(\\theta)=$   \n326 $\\frac{\\theta_{1}^{2}}{-4\\theta_{2}}\\,-\\,\\textstyle{\\frac{1}{2}}\\log(-\\theta_{2})$ , $\\begin{array}{r}{A^{*}(\\mu)=-\\frac{1}{2}\\log(\\mu_{2}-\\mu_{1}^{2})}\\end{array}$ , for $\\theta\\in\\Theta=\\mathbb{R}\\times\\mathbb{R}_{-}^{*}$ and $\\mu\\in\\{(u,v),u^{2}<v\\}$ .   \n327 The goal is to estimate $D_{A}(\\theta,\\theta_{\\star})$ , for which Le Priol et al. [17] show that only partial solutions   \n328 exist: results are either asymptotic, or rely on the objective being (approximately) quadratic. Note   \n329 that there is a relationship between natural parameters, mean parameters, and $(m,\\Sigma^{2})$ , the mean and   \n330 covariance of the Gaussian we would like to estimate. In the following, we will often abuse notations,   \n331 and write for instance $D_{A}(\\tilde{\\theta},\\theta)$ in terms of $(m,\\Sigma^{2})$ and $(\\tilde{m},\\tilde{\\Sigma}^{2})$ rather than $\\theta$ and $\\tilde{\\theta}$ . We now state a   \n332 few results, for which detailed derivations can be found in Appendix F. More specifically: ", "page_idx": 7}, {"type": "equation", "text": "$$\nD_{A}(\\tilde{\\theta},\\theta)=-\\frac{1}{2}\\log\\left(\\frac{\\Sigma^{2}}{\\tilde{\\Sigma}^{2}}\\right)-\\frac{\\tilde{\\Sigma}^{2}-\\Sigma^{2}}{2\\tilde{\\Sigma}^{2}}+\\frac{(\\tilde{m}-m)^{2}}{2\\tilde{\\Sigma}^{2}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "333 The update formulas for the parameters are given by: ", "page_idx": 8}, {"type": "equation", "text": "$$\nm^{+}=(1-\\eta)m+\\eta X,\\;\\;\\;\\;\\;\\;\\;(\\Sigma^{2})^{+}=(1-\\eta)\\left[\\Sigma^{2}+\\eta(m-X)^{2}\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "334 Therefore, MAP iterations are well-defined although $A$ does not verify Assumption 1. ", "page_idx": 8}, {"type": "text", "text": "335 Proposition 4.1. The iterations (12) are well-defined for $\\eta<1$ in the sense that if $\\mathbf{\\nabla}\\theta^{(n)}\\in\\Theta=\\mathbb{R}\\!\\times\\!\\mathbb{R}_{-}^{*}$ ,   \n336 then $\\nabla A(\\theta^{(n)})-\\eta\\nabla f_{X_{n}}(\\theta^{(n)})\\in\\operatorname{Range}(\\nabla A)$ almost surely, so that $\\theta^{(n+1)}\\in\\Theta$ is well-defined   \n337 almost surely. Besides, $f_{\\xi}$ is 1-relatively-smooth and 1-relatively-strongly-convex with respect to $A$ .   \n338 This result is a direct consequence of the fact that $D_{f_{\\xi}}\\,=\\,D_{f}\\,=\\,D_{A}$ for all $\\xi$ , and the fact that   \n340 Proposition 4.1 mneans that we can apply Theorem 3.1, so the next step is to bound the variance 339 $\\nabla A(\\theta)-\\eta\\nabla f_{X_{n}}(\\theta)=(1-\\eta)\\nabla A(\\theta)+\\eta T(X_{n})\\in\\{(\\bar{u},v),u^{2}<v\\}$ if $\\nabla A(\\theta)\\in\\{(u,v),u^{2}<v\\}$ $\\sigma_{\\star,\\eta}^{2}$ . ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "equation", "text": "$$\nf_{\\eta}(\\theta)-f(\\theta_{\\star})=\\frac{1}{2\\eta}\\mathbb{E}\\left[\\log\\left((1-\\eta)\\left(1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right)\\right)\\right]-\\frac{1}{2}\\log\\left(\\frac{\\Sigma_{\\star}^{2}}{\\Sigma^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "341 We now use this expression to to lower bound $f_{\\eta}^{\\star}$ and so upper bound $\\sigma_{\\star,\\eta}^{2}$ ", "page_idx": 8}, {"type": "text", "text": "342 Lemma 4.2. Let $(m_{\\eta},\\Sigma_{\\eta}^{2})$ be the minimizer of $f_{\\eta}$ . Then, for $\\eta<1/3$ , $m_{\\eta}\\,=\\,m_{\\star}$ , $\\Sigma_{\\star}^{2}\\,\\geq\\,\\Sigma_{\\eta}^{2}\\,\\geq$   \n343 $(1-3\\eta)\\,\\Sigma_{\\star}^{2}$ . In particular, the variance $\\sigma_{\\star,\\eta}^{2}$ verifies $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\le-\\frac{1}{2\\eta}\\log\\left(1-3\\eta\\right)}\\end{array}$ . For $1/3<\\eta\\leq1-\\varepsilon$ ,   \n344 $\\sigma_{\\star,\\eta}^{2}\\leq c_{\\varepsilon}$ , where $c_{\\varepsilon}$ is a numerical constant that only depends on $\\varepsilon$ .   \n345 Note that we show in this example that $\\Sigma_{\\eta}^{2}$ is arbitrarily close to $\\Sigma_{\\star}^{2}$ as $\\eta\\rightarrow0$ , which is expected.   \n346 Theorem 4.3. Let $\\Gamma\\geq0$ be a numerical constant and $\\Gamma=0$ if $n_{0}>3$ . The MAP estimator satisfies: ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[D_{A}(\\theta_{\\star},\\theta^{(n)})\\right]\\leq\\frac{n_{0}D_{A}(\\theta_{\\star},\\theta^{(0)})+\\frac{3}{2}\\log(1+\\frac{n+1}{n_{0}})+\\Gamma}{n+n_{0}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "347 Numerical constants are not optimized. Theorem 4.3 gives an anytime result on the convergence of   \n348 the MAP estimator for all $n\\geq0,n_{0}\\geq1$ directly from the general SMD convergence theorem. Yet,   \n349 the open problem from Le Priol et al. [17] is not completely solved still, as discussed below.   \n350 Reverse KL bound. We obtain a bound on $D_{A}(\\theta_{\\star},\\theta^{(n)})$ , instead of $D_{A}(\\boldsymbol{\\theta}^{(n)},\\boldsymbol{\\theta}_{\\star})=f(\\boldsymbol{\\theta})-f(\\boldsymbol{\\theta}_{\\star})$ .   \n351 $D_{A}(\\theta^{(n)},\\theta_{\\star})$ can be controlled asymptotically thanks to the bound on $f_{\\eta}(\\theta^{(n)})-f_{\\eta}(\\theta_{\\eta})$ , and $f_{\\eta}\\rightarrow f$   \n352 when $\\eta=1/n\\to0$ , but we might also be able to exploit this control over the course of the iterations.   \n353 Asymptotic convergence. Theorem 4.3 leads to a $O(\\log n/n)$ asymptotic convergence rate instead   \n354 of the expected $O(1/n)$ [17]. This indicates that the $f_{\\eta_{n}}(\\theta^{(n)})-f_{\\eta_{n}}^{\\star}$ terms should not be neglected.   \n355 Indeed, $\\theta^{(n)}$ actually has a lot of structure in this example, since $\\begin{array}{r}{\\nabla\\dot{A}(\\theta^{(n)})=\\frac{1}{n}\\sum_{k=1}^{n}T(X_{k})}\\end{array}$ . The   \n356 SMD analysis is oblivious to this structure, hence the gap. Note that we can get rid of the $\\log n$ factor   \n357 and recover the right ${\\cal O}(1/n)$ rate from the same analysis by using a slightly different estimator than   \n358 the MAP (or MLE). This is done by setting the step-size as \u03b7n =n2+1 for $n>1$ , and the analysis of   \n359 this variant follows Lacoste-Julien et al. [16], as detailed in Appendix F.3.   \n360 The special case of the MLE. The MLE corresponds to $n_{0}=0$ , which is not handled in our analysis   \n361 since the first step corresponds to \u03b7 = 1, which necessarily results in \u03b8(21) $\\theta_{2}^{(1)}=-\\infty$ (which corresponds   \n362 to $\\Sigma^{2}=0$ , as can be seen from (13)). If we consider that mirror descent is run from $\\theta^{(1)}$ , then we   \n363 obtain $\\mathbb{E}\\left[D_{A}(\\theta_{\\star},\\theta^{(1)})\\right]=\\infty$ in general, where the expectation is over the value of the first sample   \n364 drawn. Therefore, we need to start the SMD analysis at $\\theta^{(2)}$ to fti the MLE into this framework, and in   \n365 particular we need to be able to evaluate $\\mathbb{E}\\left[D_{A}(\\theta_{\\star},\\theta^{(2)})\\right]$ . This is further discussed in Appendix F.4. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "366 5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "367 This paper introduces a new notion of variance for the analysis of stochastic mirror descent. This   \n368 notion, based on the fact that a certain function $f_{\\eta}$ admits a minimum, is less restrictive than existing   \n369 ones, has the right asymptotic scaling with the step-size and is bounded regardless of the trajectory of   \n370 the iterates without further assumptions.   \n371 We strongly believe that our analysis of SMD opens up new perspectives. As an example, we use our   \n372 SMD results to show convergence of the MAP for estimating a Gaussian with unknown mean and   \n373 covariance. As evidenced in Le Priol et al. [17], all existing generic analyses of stochastic mirror   \n374 descent failed to obtain such results. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "375 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "376 [1] H. H. Bauschke, J. M. Borwein, et al. Legendre functions and the method of random bregman   \n377 projections. Journal of convex analysis, 4(1):27\u201367, 1997.   \n378 [2] H. H. Bauschke, J. Bolte, and M. Teboulle. A descent lemma beyond lipschitz gradient   \n379 continuity: first-order methods revisited and applications. Mathematics of Operations Research,   \n380 42(2):330\u2013348, 2017.   \n381 [3] M. Bertero, P. Boccacci, G. Desider\u00e0, and G. Vicidomini. Image deblurring with poisson data:   \n382 from cells to galaxies. Inverse Problems, 25(12):123006, 2009.   \n383 [4] L. Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of   \n384 COMPSTAT\u20192010: 19th International Conference on Computational StatisticsParis France,   \n385 August 22-27, 2010 Keynote, Invited and Contributed Papers, pages 177\u2013186. Springer, 2010.   \n386 [5] S. Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends\u00ae   \n387 in Machine Learning, 8(3-4):231\u2013357, 2015.   \n388 [6] R.-A. Dragomir and Y. Nesterov. Convex quartic problems: homogenized gradient method and   \n389 preconditioning. arXiv preprint arXiv:2306.17683, 2023.   \n390 [7] R. A. Dragomir, M. Even, and H. Hendrikx. Fast stochastic bregman gradient methods: Sharp   \n391 analysis and variance reduction. In International Conference on Machine Learning, pages   \n392 2815\u20132825. PMLR, 2021.   \n393 [8] R.-A. Dragomir, A. B. Taylor, A. d\u2019Aspremont, and J. Bolte. Optimal complexity and certifica  \n394 tion of bregman first-order methods. Mathematical Programming, pages 1\u201343, 2021.   \n395 [9] R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richt\u00e1rik. Sgd: General   \n396 analysis and improved rates. In International conference on machine learning, pages 5200\u20135209.   \n397 PMLR, 2019.   \n398 [10] F. Hanzely and P. Richt\u00e1rik. Fastest rates for stochastic mirror descent methods. Computational   \n399 Optimization and Applications, 79:717\u2013766, 2021.   \n400 [11] H. Hendrikx, F. Bach, and L. Massouli\u00e9. Dual-free stochastic decentralized optimization with   \n401 variance reduction. Advances in neural information processing systems, 33:19455\u201319466, 2020.   \n402 [12] H. Hendrikx, L. Xiao, S. Bubeck, F. Bach, and L. Massoulie. Statistically preconditioned   \n403 accelerated gradient method for distributed optimization. In International conference on   \n404 machine learning, pages 4203\u20134227. PMLR, 2020.   \n405 [13] D. Hoeven, T. Erven, and W. Kot\u0142owski. The many faces of exponential weights in online   \n406 learning. In Conference On Learning Theory, pages 2067\u20132092. PMLR, 2018.   \n407 [14] S. Kakade, S. Shalev-Shwartz, A. Tewari, et al. On the duality of strong convexity and   \n408 strong smoothness: Learning applications and matrix regularization. Unpublished Manuscript,   \n409 http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf, 2(1):35, 2009.   \n410 [15] F. Kunstner, R. Kumar, and M. Schmidt. Homeomorphic-invariance of em: Non-asymptotic   \n411 convergence in kl divergence for exponential families via mirror descent. In International   \n412 Conference on Artificial Intelligence and Statistics, pages 3295\u20133303. PMLR, 2021.   \n413 [16] S. Lacoste-Julien, M. Schmidt, and F. Bach. A simpler approach to obtaining an o $(1/\\mathrm{t})$ conver  \n414 gence rate for the projected stochastic subgradient method. arXiv preprint arXiv:1212.2002,   \n415 2012.   \n416 [17] R. Le Priol, F. Kunstner, D. Scieur, and S. Lacoste-Julien. Convergence rates for the map   \n417 of an exponential family and stochastic mirror descent\u2013an open problem. arXiv preprint   \n418 arXiv:2111.06826, 2021.   \n419 [18] F. L\u00e9ger and P.-C. Aubin-Frankowski. Gradient descent with a general cost. arXiv preprint   \n420 arXiv:2305.04917, 2023.   \n421 [19] N. Loizou, S. Vaswani, I. H. Laradji, and S. Lacoste-Julien. Stochastic polyak step-size for   \n422 sgd: An adaptive learning rate for fast convergence. In International Conference on Artificial   \n423 Intelligence and Statistics, pages 1306\u20131314. PMLR, 2021.   \n424 [20] H. Lu, R. M. Freund, and Y. Nesterov. Relatively smooth convex optimization by first-order   \n425 methods, and applications. SIAM Journal on Optimization, 28(1):333\u2013354, 2018.   \n426 [21] B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and   \n427 l1 regularization. In Proceedings of the Fourteenth International Conference on Artificial   \n428 Intelligence and Statistics, pages 525\u2013533. JMLR Workshop and Conference Proceedings,   \n429 2011.   \n430 [22] A. S. Nemirovskij and D. B. Yudin. Problem complexity and method efficiency in optimization.   \n431 1983.   \n432 [23] D. Pfau. A generalized bias-variance decomposition for bregman divergences. Unpublished   \n433 Manuscript, 2013.   \n434 [24] O. Shamir, N. Srebro, and T. Zhang. Communication-efficient distributed optimization using   \n435 an approximate newton-type method. In International conference on machine learning, pages   \n436 1000\u20131008. PMLR, 2014.   \n437 [25] C. Villani et al. Optimal transport: old and new, volume 338. Springer, 2009.   \n438 [26] M. J. Wainwright, M. I. Jordan, et al. Graphical models, exponential families, and variational   \n439 inference. Foundations and Trends\u00ae in Machine Learning, 1(1\u20132):1\u2013305, 2008. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "440 A Technical results on Bregman divergences ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "441 As for the rest of this paper, Assumption 1 is assumed throughout this section. However, some of   \n442 these results hold even with less regularity, and in particular do not require second order continuous   \n443 differentiability. ", "page_idx": 11}, {"type": "text", "text": "444 Lemma A.1 (Duality). For all $x,y\\in C$ , it holds that: ", "page_idx": 11}, {"type": "equation", "text": "$$\nD_{h}(x,y)=D_{h^{*}}(\\nabla h(y),\\nabla h(x))\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "445 See, e.g. Bauschke et al. [1, Theorem 3.7] for the proof. ", "page_idx": 11}, {"type": "text", "text": "446 Lemma A.2 (Symmetrized Bregman). For all $x,y\\in C$ , it holds that: ", "page_idx": 11}, {"type": "equation", "text": "$$\nD_{h}(x,y)+D_{h}(y,x)=\\langle\\nabla h(x)-\\nabla h(y),x-y\\rangle\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "447 The proof immediately follows from the definition of the Bregman divergence. The following result   \n448 corresponds to Dragomir et al. [7, Lemma 3].   \n449 Lemma A.3 (Bregman cocoercivity). If a convex function $f$ is $L$ -relatively-smooth with respect to $h_{i}$ ,   \n450 then for all $\\eta\\leq1/L$ , ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "equation", "text": "$$\nD_{h^{*}}(\\nabla h(x)-\\eta\\left[\\nabla f(x)-\\nabla f(y)\\right],\\nabla h(x))\\leq\\eta D_{f}(x,y).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "451 Denoting $x^{+y}=\\nabla h^{*}(\\nabla h(x)-\\eta\\left[\\nabla f(x)-\\nabla f(y)\\right])$ , a tighter result actually writes: ", "page_idx": 11}, {"type": "equation", "text": "$$\nD_{h}(x,x^{+y})+\\eta D_{f}(x^{+y},y)\\leq\\eta D_{f}(x,y).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "452 The proof of the tighter version is simply obtained by not using that $D_{f}(x^{+y},y)\\ge0$ in the original   \n453 proof. While we don\u2019t directly use it in this paper, it is sometimes useful. We now introduce the   \n454 generalized bias-variance decomposition Lemma [23, Theorem 0.1]. ", "page_idx": 11}, {"type": "text", "text": "455 Lemma A.4. If $X$ is a random variable, then for all $u\\in C$ , ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\operatorname{\\mathbb{E}}\\left[D_{h^{*}}(X,u)\\right]=D_{h^{*}}(\\operatorname{\\mathbb{E}}\\left[X\\right],u)+D_{h^{*}}(X,\\operatorname{\\mathbb{E}}\\left[X\\right]).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "456 B Missing results on the variances ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "457 We start this section by proving the following lemma, which in particular ensures that $D_{h}(x,x^{+})/\\eta$   \n458 increases with $\\eta$ (and so decreases as $\\eta\\rightarrow0$ ). ", "page_idx": 11}, {"type": "text", "text": "459 Lemma B.1. Let $\\phi_{\\xi}:\\eta\\mapsto\\textstyle\\frac1\\eta D_{h}(x,x^{+}(\\eta,\\xi))$ . Then, $\\begin{array}{r}{\\nabla\\phi_{\\xi}(\\eta)=\\frac{1}{\\eta^{2}}D_{h}(x^{+}(\\eta,\\xi),x)\\ge0.}\\end{array}$ . ", "page_idx": 11}, {"type": "text", "text": "460 Proof. First remark that since $\\nabla h(x^{+})=\\nabla h(x)-\\eta\\nabla f_{\\xi}(x)$ , we can write ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\eta}\\left[D_{h}(x,x^{+})\\right]=\\nabla_{\\eta}\\left[h(x)-h(x^{+})-\\nabla h(x^{+})^{\\top}(x-x^{+})\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad=-\\nabla h(x^{+})^{\\top}\\nabla_{\\eta}x^{+}+\\nabla f_{\\xi}(x)^{\\top}(x-x^{+})+\\nabla h(x^{+})^{\\top}\\nabla_{\\eta}x^{+}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\nabla f_{\\xi}(x)^{\\top}(x-x^{+})}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\frac{1}{\\eta}\\left(\\nabla h(x)-\\nabla h(x^{+})\\right)^{\\top}(x-x^{+})=\\frac{D_{h}(x,x^{+})+D_{h}(x^{+},x)}{\\eta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "461 Then, the expression follows from ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\nabla\\phi_{\\xi}(\\eta)=\\nabla_{\\eta}\\left[\\frac{1}{\\eta}D_{h}(x,x^{+})\\right]=\\frac{1}{\\eta}\\nabla_{\\eta}\\left[D_{h}(x,x^{+})\\right]-\\frac{1}{\\eta^{2}}D_{h}(x,x^{+})=\\frac{1}{\\eta^{2}}D_{h}(x^{+},x).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "462 ", "page_idx": 11}, {"type": "text", "text": "463 Proof of Proposition 2.5. We now prove that $f_{\\eta}\\rightarrow f$ when $\\eta\\rightarrow0$ . To show this, we note that for   \n464 any fixed $x\\in\\operatorname{int}C$ : ", "page_idx": 11}, {"type": "text", "text": "465 ", "page_idx": 11}, {"type": "text", "text": "466 ", "page_idx": 11}, {"type": "text", "text": "\u2022 For any fixed $\\xi$ , $\\begin{array}{r}{\\frac{1}{\\eta}D_{h}(x,x^{+})=\\frac{\\eta}{2}||\\nabla f_{\\xi}(x)||_{\\nabla^{2}h^{*}(z)}^{2}}\\end{array}$ for $z\\in[\\nabla h(x),\\nabla h(x)-\\eta\\nabla f_{\\xi}(x)]$ . Therefore, $\\scriptstyle{\\frac{1}{\\eta}}D_{h}(x,x^{+})\\;\\to\\;0$ for $\\eta\\rightarrow0$ since $\\nabla^{2}h^{\\ast}(\\nabla h(x))=(\\nabla^{2}h(x))^{-1}<\\infty$ by strict convexity of $h$ . ", "page_idx": 11}, {"type": "text", "text": "467 ", "page_idx": 11}, {"type": "text", "text": "\u2022 Let $\\eta\\leq\\eta_{0}$ . Then, for all $\\xi$ , $\\begin{array}{r}{\\frac{1}{\\eta}D_{h}(x,x^{+}(\\eta,\\xi))\\,\\le\\,\\frac{1}{\\eta_{0}}D_{h}(x,x^{+}(\\eta_{0},\\xi))}\\end{array}$ since the function $\\begin{array}{r}{\\eta\\mapsto\\frac{1}{\\eta}D_{h}(x,x^{+}(\\eta,\\xi))}\\end{array}$ is an increasing function (positive gradient using Lemma B.1). \u2022 $\\begin{array}{r}{\\frac{1}{\\eta_{0}}\\mathbb{E}\\left[D_{h}(x,x^{+}(\\eta_{0},\\xi))\\right]}\\end{array}$ is finite. ", "page_idx": 12}, {"type": "text", "text": "471 Then, using the dominated convergence theorem, we obtain that we can invert the integral (expecta  \n472 tion) and the limit, so that $\\begin{array}{r}{\\operatorname*{lim}_{\\eta\\rightarrow0}\\mathbf{\\bar{E}}\\frac{1}{\\eta}D_{h}(x,x^{+})=\\mathbb{E}\\operatorname*{lim}_{\\eta\\rightarrow0}\\frac{1}{\\eta}D_{h}(x,x^{+})=0}\\end{array}$ . \u53e3   \n473 Proof of Proposition 2.6. We prove this result by successively upper bounding and lower bounding   \n474 $\\sigma_{\\star,\\eta}^{2}.$ , and making $\\eta\\rightarrow0$ . ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "475 1 - Upper bound on \u03c3\u22c62,\u03b7 . One side is direct, by writing that $f(x_{\\eta})\\geq f(x_{\\star})$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sigma_{\\star,\\eta}^{2}=\\frac{1}{\\eta}\\left(f(x_{\\star})-f(x_{\\eta})+\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(x_{\\eta},x_{\\eta}^{+})\\right]\\right)\\leq\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h}(x_{\\eta},x_{\\eta}^{+})\\right].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "476 From the proof of Proposition 2.5 we have pointwise convergence of $f_{\\eta}$ to $f$ . Since $f$ is convex and   \n477 has a unique minimizer $x_{\\star}$ , then $x_{\\eta}\\rightarrow x_{\\star}$ for $\\eta\\rightarrow0$ , which leads to the result.   \n478 2 - Lower bound on $\\sigma_{\\star,\\eta}^{2}.$ By definition of $x_{\\eta}$ as the minimizer of $f_{\\eta}$ , we have $f_{\\eta}(x_{\\eta})\\leq f_{\\eta}(x_{\\star})$ , and   \n479 so: ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sigma_{\\star,\\eta}^{2}=\\frac{f(x_{\\star})-f_{\\eta}(x_{\\eta})}{\\eta}\\geq\\frac{f(x_{\\star})-f_{\\eta}(x_{\\star})}{\\eta}=\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h}(x_{\\star},x_{\\star}^{+})\\right].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "480 ", "page_idx": 12}, {"type": "text", "text": "481 Let us now prove the following proposition, which follows the proof from Dragomir et al. [7]. ", "page_idx": 12}, {"type": "text", "text": "482 Proof of Proposition 2.7. Let us prove that $\\sigma_{\\star,\\eta}^{2}\\leq\\mathbb{E}\\left[\\|\\nabla f_{\\xi}(x_{\\star})\\|_{\\nabla^{2}h^{*}(z_{\\eta})}^{2}\\right]$ . We start by ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{h}(x,x^{+})=D_{h^{*}}(\\nabla h(x)-\\eta\\nabla f_{\\xi}(x),\\nabla h(x))}\\\\ &{\\qquad\\qquad=D_{h^{*}}(\\nabla h(x)-\\eta\\left[\\nabla f_{\\xi}(x)-\\nabla f_{\\xi}(x_{\\star})\\right]-\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x))}\\\\ &{\\qquad\\qquad=D_{h^{*}}(\\frac{\\left(\\nabla h(x)-2\\eta\\left[\\nabla f_{\\xi}(x)-\\nabla f_{\\xi}(x_{\\star})\\right]\\right)+\\left(\\nabla h(x)-2\\eta\\nabla f_{\\xi}(x_{\\star})\\right)}{2},\\nabla h(x)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "483 Using the convexity of $D_{h^{*}}$ in its first argument and then the Bregman cocoercivity lemma, we obtain   \n484 for $\\bar{\\eta}\\leq1/2L$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{D_{h}(x,x^{+})\\leq\\frac{1}{2}D_{h^{*}}(\\nabla h(x)-2\\eta\\left[\\nabla f_{\\xi}(x)-\\nabla f_{\\xi}(x_{\\star})\\right]),\\nabla h(x))}}\\\\ &{}&{+\\,\\frac{1}{2}D_{h^{*}}(\\nabla h(x)-2\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x))}\\\\ &{}&{\\leq\\eta D_{f_{\\xi}}(x,x_{\\star})+\\frac{1}{2}D_{h^{*}}(\\nabla h(x)-2\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "485 Using that E $\\left[D_{f_{\\xi}}(x,x_{\\star})\\right]=D_{f}(x,x_{\\star})$ and applying this to $x=x_{\\eta}$ , we obtain ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{\\star,\\eta}^{2}=\\frac{f(x_{\\star})-f_{\\eta}(x_{\\eta})}{\\eta}}\\\\ &{\\phantom{\\quad=\\frac{1}{\\eta}}=\\frac{\\mathbb{E}\\left[D_{h}(x_{\\eta},x_{\\eta}^{+})\\right]+\\eta f(x_{\\star})-\\eta f(x_{\\eta})}{\\eta^{2}}}\\\\ &{\\phantom{\\quad=\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x_{\\eta})-2\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x_{\\eta}))\\right]+\\frac{D_{f}(x_{\\eta},x_{\\star})+f(x_{\\star})-f(x_{\\eta})}{\\eta}}\\\\ &{\\phantom{\\quad=\\frac{1}{\\eta^{2}}\\mathbb{E}\\left[D_{h^{*}}(\\nabla h(x_{\\eta})-2\\eta\\nabla f_{\\xi}(x_{\\star}),\\nabla h(x_{\\eta}))\\right]=\\frac{1}{2\\eta^{2}}\\times\\mathbb{E}\\left[\\frac{1}{2}\\|2\\eta\\nabla f_{\\xi}(x_{\\star})\\|_{\\nabla^{2}h^{*}(z_{\\eta})}^{2}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "486 and the result follows. The last inequality comes from the fact that if $x_{\\star}=\\arg\\operatorname*{min}_{x\\in C}f(x)$ , then   \n487 $-\\nabla f(x_{\\star})$ is normal to $C$ so $-\\nabla f(x_{\\star})^{\\top}(x_{\\eta}-x_{\\star})\\leq0.$ . . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "488 C Convergence results. ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "489 In this section, we detail the proofs of the various convergence theorems that were only sketched in   \n490 the main text. We start by proving the first identity, which is a variation of e.g., Dragomir et al. [7,   \n491 Lemma 4], which we detail here for the sake of completeness.   \n492 Lemma C.1. Let $x^{+}\\in C$ be such that $\\nabla h(x^{+})=\\nabla h(x)\\!-\\!\\eta\\nabla f_{\\xi}(x),$ , with $f_{\\xi}$ a random differentiable   \n493 function such that $\\mathbb{E}\\left[f_{\\xi}\\right]=f$ . Then, for all points $y\\in C$ , ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[D_{h}(y,x^{+})\\right]-D_{h}(y,x)+\\eta D_{f}(y,x)=-\\eta[f(x)-f(y)]+\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "494 In particular, we can apply the result to $y=x_{\\star}$ . ", "page_idx": 13}, {"type": "text", "text": "495 Proof. We give a slightly different proof than Dragomir et al. [7], and in particular this version of the   \n496 identity is slightly more direct (though maybe less insightful) and does not require $\\nabla f(y)=0$ . We   \n497 write: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h}(y,x^{+})\\right]=\\mathbb{E}\\left[h(y)-h(x^{+})-\\nabla h(x^{+})^{\\top}(y-x^{+})\\right]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}\\left[h(y)-h(x^{+})-\\nabla h(x^{+})^{\\top}(y-x)-\\nabla h(x^{+})^{\\top}(x-x^{+})\\right]}\\\\ &{\\qquad\\qquad\\quad=\\mathbb{E}\\bigl[h(y)-h(x)-\\nabla h(x)^{\\top}(y-x)+\\eta\\nabla f_{\\xi}(x)^{\\top}(y-x)}\\\\ &{\\qquad\\qquad\\qquad\\quad\\nabla h(x^{+})^{\\top}(x-x^{+})+h(x)-h(x^{+})\\bigr]}\\\\ &{\\qquad\\qquad\\quad=D_{h}(y,x)+\\eta\\nabla f(x)^{\\top}(y-x)+\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]}\\\\ &{\\quad=D_{h}(y,x)-\\eta D_{f}(y,x)+\\eta\\left[f(y)-f(x)\\right]+\\mathbb{E}\\left[D_{h}(x,x^{+})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "498 ", "page_idx": 13}, {"type": "text", "text": "499 Proof of Corollary 3.2. We start back from Equation (8), and write, using that $f_{\\eta}(x)\\geq\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]$   \n500 (proof of Proposition 2.2): ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h}(x_{\\star},x^{+})\\right]-D_{h}(x_{\\star},x)\\!+\\!\\eta D_{f}(x_{\\star},x)=\\eta\\left[f(x_{\\star})-f_{\\eta}(x)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\eta\\left[f(x_{\\star})-\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq-\\eta\\left[\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]-f_{\\star}^{+}\\right]+\\eta^{2}\\left(\\frac{f(x_{\\star})-f_{\\star}^{+}}{\\eta}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "501 The result follows naturally from using the relative strong convexity of $f$ , leading to: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\eta[\\mathbb{E}\\left[f_{\\xi}(x^{+})\\right]-f_{+}^{\\star}]+\\mathbb{E}\\left[D_{h}(x_{\\star},x^{+})\\right]\\leq(1-\\eta\\mu)D_{h}(x_{\\star},x)+\\eta^{2}\\left[\\frac{f(x_{\\star})-f_{+}^{\\star}}{\\eta}\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "502 Then, we chain iterations as done for Theorem 3.1 ", "page_idx": 13}, {"type": "text", "text": "503 Proof of Theorem 3.3. We also start from the same result as above, and write it for $x=x^{(k)}$ , so that   \n504 x+ = x(k+1): ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}\\left[D_{h}(x_{\\star},x^{(k+1)})\\right]-D_{h}(x_{\\star},x^{(k)})\\!+\\!\\eta D_{f}(x_{\\star},x^{(k)})=\\eta\\left[f(x_{\\star})-f_{\\eta}(x^{(k)})\\right]}\\\\ &{}&{\\quad\\le-\\eta\\left[f_{\\eta}(x^{(k)})-f_{\\eta}(x_{\\eta})\\right]+\\eta^{2}\\sigma_{\\star,\\eta}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "505 Moving the $f_{\\eta}$ terms to the left, and summing this for $k=0$ to $T$ leads to: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\eta\\sum_{k=0}^{T}\\Big[f_{\\eta}\\big(x^{(k)}\\big)-f_{\\eta}\\big(x_{\\eta}\\big)+D_{f}\\big(x_{\\star},x^{(k)}\\big)\\Big]\\leq D_{h}\\big(x_{\\star},x^{(0)}\\big)-\\mathbb{E}\\left[D_{h}\\big(x_{\\star},x^{(k+1)}\\big)\\right]+T\\eta^{2}\\sigma_{\\star,\\eta}^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "506 The final result is obtained by dividing by $\\eta T$ , and the fact that $\\mathbb{E}\\left[D_{h}(x_{\\star},x^{(k+1)})\\right]\\ge0$ . ", "page_idx": 13}, {"type": "text", "text": "507 Proof of Proposition 3.4. We use Bregman cocoercivity (Lemma A.3) with $\\begin{array}{r}{\\eta=\\frac{1}{L}}\\end{array}$ between $x_{\\star}$ and   \n508 $x$ (instead of $x$ and $x_{\\star}$ as it had been done previously), which directly leads to: ", "page_idx": 13}, {"type": "equation", "text": "$$\nD_{h^{*}}\\left(\\nabla h^{*}(x_{\\star})-\\frac{1}{L}\\left[\\nabla f(x_{\\star})-\\nabla f(x)\\right]\\right)\\le\\frac{1}{L}D_{f}(x_{\\star},x).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "509 The first part of the proposition follows from the fact that $\\nabla f(x_{\\star})=0$ . For the rest proof, we start   \n510 with Inequality (32), which gives: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{0=D_{h^{*}}(\\nabla h(x_{\\star})-\\displaystyle\\frac{1}{L}\\nabla f(x),\\nabla h(x_{\\star}))}\\\\ &{\\quad=D_{h}\\left(x_{\\star},\\nabla h^{*}\\left(\\nabla h(x_{\\star})-\\displaystyle\\frac{1}{L}\\nabla f(x)\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "511 At this point, strict convexity of $h$ leads to $\\begin{array}{r}{\\nabla h^{*}\\left(\\nabla h(x_{\\star})-\\frac{1}{L}\\nabla f(x)\\right)=x_{\\star}}\\end{array}$ , so that $\\nabla f(x)=0$ by   \n512 applying $\\nabla h$ on both sides. ", "page_idx": 14}, {"type": "text", "text": "513 D Variation on the convex case ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "514 In this section, we quickly illustrate that the result we obtain is tightly linked to the notion of variance   \n515 that we define. As an example, a variation of Theorem 3.3 can be obtained with a control on   \n516 $f(x)-f(x_{\\star})$ , but this requires a different notion of variance: ", "page_idx": 14}, {"type": "text", "text": "517 Theorem D.1. If $f$ is convex, the iterates obtained by SMD using a constant step-sizes $\\eta>0$ verify ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f\\left(\\frac{1}{T}\\sum_{k=0}^{T}x^{(k)}\\right)\\right]-f(x_{\\star})\\le\\frac{D_{h}(x_{\\star},x^{(0)})}{\\eta T}+\\eta\\tilde{\\sigma}_{\\star,\\eta}^{2},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "518 where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\tilde{\\sigma}_{\\star,\\eta}^{2}=\\frac{1}{\\eta}\\operatorname*{max}_{x\\in C}\\left\\{\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]-D_{f}(x_{\\star},x)\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "519 cNaostee  ftohra ti ntshtias naclet eirnn atthiev eG vaaursisainacne  MdeAfiPn iteixoan mcpalne .b eB eusnibdoesu,n idt eddo eesv enno tw ihnehne $\\sigma_{\\star,\\eta}^{2}$ oism  bomuonstd eodf ,t ahse  igs otohde   \n521 properties of \u03c3\u22c62, presented in Section 2, and cannot be compared to the other standard variance   \n522 notions. The main case in which this alternative definition makes sense is the Euclidean case, in   \n523 which \u03c3\u02dc\u22c62,\u03b7 can be bounded using cocoercivity. ", "page_idx": 14}, {"type": "text", "text": "524 Proof of Theorem $D.I$ . This proof directly starts from Lemma C.1: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h}(x_{\\star},x^{(k+1)})\\right]}\\\\ &{=D_{h}(x_{\\star},x^{(k)})-\\eta D_{f}(x_{\\star},x^{(k)})-\\eta[f(x^{(k)})-f(x_{\\star})]+\\mathbb{E}\\left[D_{h}(x^{(k)},(x^{(k)})^{+})\\right]}\\\\ &{=D_{h}(x_{\\star},x^{(k)})-\\eta[f(x^{(k)})-f(x_{\\star})]+\\eta\\left[\\frac{1}{\\eta}\\mathbb{E}\\left[D_{h}(x^{(k)},(x^{(k)})^{+})\\right]-D_{f}(x_{\\star},x^{(k)})\\right]}\\\\ &{\\leq D_{h}(x_{\\star},x^{(k)})-\\eta[f(x^{(k)})-f(x_{\\star})]+\\eta^{2}\\tilde{\\sigma}_{\\star,\\eta}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "525 Summing this for $k=0$ to $T$ , and dividing by $\\eta T$ we obtain: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{k=0}^{T}f(x^{(k)})-f(x_{\\star})\\le\\frac{D_{h}(x_{\\star},x^{(0)})}{\\eta T}+\\eta\\tilde{\\sigma}_{\\star,\\eta}^{2}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "526 The result on the average iterate then follows from convexity of $f$ and taking expectation on $x^{(k)}$ . ", "page_idx": 14}, {"type": "text", "text": "527 E Stochastic Mirror Descent with a Proximal term ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "528 We are interested in this section in a variation of the original problem, where we would like to solve   \n529 the following problem: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x\\in C}f(x)+g(x),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "530 where $g$ is a convex proper lower semi-continuous function (but not necessarily differentiable). This   \n531 problem can be solved using the following stochastic proximal mirror descent algorithm: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\boldsymbol{x}^{+}=\\arg\\operatorname*{min}_{\\boldsymbol{u}\\in C}g(\\boldsymbol{u})+\\boldsymbol{\\nabla}f_{\\xi}(\\boldsymbol{x})^{\\top}\\boldsymbol{u}+\\frac{1}{\\eta}D_{h}(\\boldsymbol{u},\\boldsymbol{x}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "532 This is a \u201cproximal\u201d version, which for instance corresponds to projected stochastic mirror descent if   \n533 $g$ is the indicator of a convex set. Under Assumption 1, the iterations write: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla h(x^{+})=\\nabla h(x)-\\eta\\left[\\nabla f_{\\xi}(x)+\\omega\\right]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "534 where $\\omega\\in\\partial g(x^{+})$ , the subgradient of $g$ at point $x^{+}$ . Equation (47) can be rewritten as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla h(x^{+})+\\eta\\omega=\\nabla h(x)+\\eta\\omega_{x}-\\eta\\left[\\nabla f_{\\xi}(x)+\\omega_{x}\\right]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "535 for any $\\omega_{x}\\in\\partial g(x)$ . In particular, (47) can be interpreted as a Stochastic mirror descent step with   \n536 objective $f_{\\xi}+g$ and mirror $h+\\eta g$ . While the mirror does not satisfy Assumption 1 (and in particular   \n537 twice differentiability in case $g$ is the indicator of a set), the iterations can still be written in the form   \n538 of Equation (3). In particular, the theorems from Section 3 still apply, with the adapted variance   \n539 definition involving function $f+g$ and mirror $h+\\eta g$ . Similarly, $f+g$ is $1/\\eta$ relatively-smooth with   \n540 respect to $h+\\eta g$ as long as $f$ is $L$ -relatively-smooth with respect to $h$ and $\\eta\\leq1/L$ . ", "page_idx": 15}, {"type": "text", "text": "541 We now prove an equivalent for Lemma C.1. ", "page_idx": 15}, {"type": "text", "text": "542 Lemma E.1. Let $x^{+}\\in C$ be such that $\\nabla h(x^{+})=\\nabla h(x)-\\eta\\,[\\nabla f_{\\xi}(x)+\\omega],$ , with $f_{\\xi}$ a random   \n543 differentiable function such that $\\mathbb{E}\\left[f_{\\xi}\\right]\\;=\\;f$ and $\\omega\\,\\in\\,\\partial g(x^{+})$ where $g$ is a convex proper lower   \n544 semi-continuous function. Then, for all $y\\in C\\cap\\mathrm{dom}g$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h}(y,x^{+})\\right]=D_{h}(y,x)-\\eta D_{f}(y,x)-\\eta[f(x)-f(y)]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\mathbb{E}\\left[D_{h}(x,x^{+f})-D_{h}(x^{+},x^{+f})\\right]+\\eta\\omega^{\\top}(y-x^{+}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "545 where $x^{+f}$ is the point such that $\\nabla h(x^{+f})=\\nabla h(x)-\\eta\\nabla f_{\\xi}(x)$ . ", "page_idx": 15}, {"type": "text", "text": "546 Proof. We write: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{h}(y,x^{+})=h(y)-h(x^{+})-\\nabla h(x^{+})^{\\top}(y-x^{+})}\\\\ &{\\qquad\\qquad=h(y)-h(x^{+f})-\\nabla h(x^{+f})^{\\top}(y-x^{+})+\\eta\\omega^{\\top}(y-x^{+})-h(x^{+})+h(x^{+f})}\\\\ &{\\qquad\\qquad=D_{h}(y,x^{+f})-\\nabla h(x^{+f})^{\\top}(x^{+f}-x^{+})+\\eta\\omega^{\\top}(y-x^{+})-h(x^{+})+h(x^{+f})}\\\\ &{\\qquad\\qquad=D_{h}(y,x^{+f})-D_{h}(x^{+},x^{+f})+\\eta\\omega^{\\top}(y-x^{+})}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "547 The result follows from applying Lemma C.1 to $D_{h}(y,x^{+f})$ . ", "page_idx": 15}, {"type": "text", "text": "548 Note that by abuse of notation, if we denote $D_{g}(y,x^{+})\\,=\\,g(y)\\,-\\,g(x^{+})\\,-\\,\\omega^{\\top}(y\\,-\\,x^{+})$ , and   \n549 $D_{g}(y,x)=g(y)-g(x)-\\omega_{x}^{\\top}(y-x)$ for any $\\omega_{x}\\in\\partial g(x)$ , then with a few lines of computations, and   \n550 noting in particular that $D_{h}(x,x^{+f})-D_{h}(x^{+},x^{+f})=D_{h}(x,x^{+})-\\left[\\nabla h(x^{+f})-\\nabla h(x^{+})\\right]^{\\top}(x-x^{+}).$   \n551 $x^{+}$ ) we obtain: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[D_{h+\\eta g}(y,x^{+})\\right]=D_{h}(y,x)-\\eta D_{f}(y,x)-\\eta[f(x)-f(y)]}\\\\ &{\\qquad\\qquad\\qquad+\\mathbb{E}\\left[D_{h}(x,x^{+})\\right]-\\eta\\mathbb{E}\\left[\\omega^{\\top}(x-x^{+})\\right]+\\eta\\mathbb{E}\\left[g(y)-g(x^{+})\\right]}\\\\ &{\\qquad\\qquad\\qquad=D_{h+\\eta g}(y,x)-\\eta D_{g}(y,x)-\\eta D_{f}(y,x)-\\eta[f(x)-f(y)]}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\mathbb{E}\\left[D_{h+\\eta g}(x,x^{+})\\right]+\\eta\\left[g(y)-g(x)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "552 In particular, we exactly recover the result of Lemma C.1 applied to the iterations in which we take   \n553 (sub)-gradients of $f+g$ with mirror $h+\\eta g,i.e.$ ., ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\natural\\left[D_{h+\\eta g}(y,x^{+})\\right]\\!=\\!D_{h+\\eta g}(y,x)-\\eta D_{f+g}(y,x)-\\eta[(f+g)(x)-(f+g)(y)]+\\mathbb{E}D_{h+g}(x,x^{+}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "554 Therefore, using the same sequence of derivations, Theorems 3.1 and 3.3 can be transposed directly   \n555 to the composite $(f+g)$ setting by simply defining generalized Bregman divergences where the   \n556 gradient parts are replaced by the subgradients picked in the actual SMD steps.   \n557 While $h+\\eta g$ does not necessarily satisfy Assumption 1, the key point is that iterations can be written   \n558 in the form of Equation (47), which is the case for instance if $g$ is the indicator of a convex set.   \n559 Note that Corollary 3.2 also holds in the same way, since relative smoothness is only needed to obtain   \n560 that $\\eta D_{f_{\\xi}+g}(x,x^{+})\\,\\le\\,D_{h+\\eta g}(x,x^{+})$ , which is equivalent to $\\eta D_{f_{\\xi}}(x,x^{+})\\,\\le\\,\\dot{D}_{h}(x,x^{+})$ , which   \n561 holds by $L$ -relative smoothness of $f$ with respect to $h$ for $\\eta\\leq1/L$ . ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "562 F Gaussian case with unknown covariance. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "563 In this section, we prove the various results for Gaussian estimation with unknown mean and   \n564 covariance. For the sake of brevity, we only prove the propositions, and refer the interested reader to,   \n565 e.g., Le Priol et al. [17] for standard results about the setting. ", "page_idx": 16}, {"type": "text", "text": "566 F.1 Instanciation in the Stochastic mirror descent setting ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "567 We first write what the various divergences are in our setting, together with the mirror updates and   \n568 finally the form of $f_{\\eta}$ . Following Le Priol et al. [17, Section 4.2], we write that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\theta_{1}=\\frac{m}{\\Sigma^{2}},\\qquad\\theta_{2}=-\\frac{1}{2\\Sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "569 This allows us to express $A(\\theta)$ in terms of $(m,\\Sigma^{2})$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nA(\\theta)=-{\\frac{1}{2}}\\log(-\\theta_{2})-{\\frac{\\theta_{1}^{2}}{4\\theta_{2}}}={\\frac{1}{2}}\\log(2\\Sigma^{2})+{\\frac{1}{2}}{\\frac{m^{2}}{\\Sigma^{2}}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "570 Proposition F.1. The Bregman divergence with respect to $\\tilde{\\theta},\\theta$ writes: ", "page_idx": 16}, {"type": "equation", "text": "$$\nD_{A}(\\tilde{\\theta},\\theta)=-\\frac{1}{2}\\log\\left(\\frac{\\Sigma^{2}}{\\tilde{\\Sigma}^{2}}\\right)-\\frac{\\tilde{\\Sigma}^{2}-\\Sigma^{2}}{2\\tilde{\\Sigma}^{2}}+\\frac{(\\tilde{m}-m)^{2}}{2\\tilde{\\Sigma}^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "571 Proof. We know that $\\nabla A(\\theta)=\\mu=(m,m^{2}+\\Sigma^{2})$ . Therefore, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla A(\\theta)^{\\top}(\\tilde{\\theta}-\\theta)=m\\left(\\frac{\\tilde{m}}{\\tilde{\\Sigma}^{2}}-\\frac{m}{\\Sigma^{2}}\\right)-\\frac{1}{2}(m^{2}+\\Sigma^{2})\\left(\\frac{1}{\\tilde{\\Sigma}^{2}}-\\frac{1}{\\Sigma^{2}}\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{m\\tilde{m}}{\\tilde{\\Sigma}^{2}}-\\frac{m^{2}}{2\\Sigma^{2}}-\\frac{m^{2}}{2\\tilde{\\Sigma}^{2}}-\\frac{1}{2}\\left(\\frac{\\Sigma^{2}}{\\tilde{\\Sigma}^{2}}-1\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\frac{\\left(m-\\tilde{m}\\right)^{2}}{2\\tilde{\\Sigma}^{2}}+\\frac{\\tilde{m}^{2}}{2\\tilde{\\Sigma}^{2}}-\\frac{m^{2}}{2\\Sigma^{2}}-\\frac{\\Sigma^{2}-\\tilde{\\Sigma}^{2}}{2\\tilde{\\Sigma}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "572 Using Equation (50), we obtain: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{D_{A}}(\\tilde{\\theta},\\theta)=A(\\tilde{\\theta})-A(\\theta)-\\nabla A(\\theta)^{\\top}(\\tilde{\\theta}-\\theta)}\\ ~}\\\\ {{\\displaystyle~~~~~~~~~~~=\\frac12\\log(2\\tilde{\\Sigma}^{2})-\\frac12\\log(2\\Sigma^{2})+\\frac{\\Sigma^{2}-\\tilde{\\Sigma}^{2}}{2\\tilde{\\Sigma}^{2}}+\\frac{(m-\\tilde{m})^{2}}{2\\tilde{\\Sigma}^{2}},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "573 which finishes the proof. ", "page_idx": 16}, {"type": "text", "text": "574 In the Gaussian with unknown covariance, the sufficient statistics are: ", "page_idx": 16}, {"type": "equation", "text": "$$\nT(X)=(X,X^{2}),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "575 where $x\\in\\mathbb R$ is an observation drawn from $\\mathcal{N}(m_{\\star},\\Sigma_{\\star})$ . ", "page_idx": 16}, {"type": "text", "text": "576 Let us now prove the form on the updates, which corresponds to (13): ", "page_idx": 16}, {"type": "text", "text": "577 Proposition F.2. In $(m,\\Sigma^{2})$ parameters, the updates write: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{m^{+}=(1-\\eta)m+\\eta X,}}\\\\ {{(\\Sigma^{2})^{+}=(1-\\eta)\\left[\\Sigma^{2}+\\eta(m-X)^{2}\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "578 Proof. Since the (stochastic) gradients write $g(\\mu)=\\mu-T(X)$ , the iterations are defined by: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mu_{1}^{+}=(1-\\eta)\\mu_{1}+\\eta X}\\\\ {\\mu_{2}^{+}=(1-\\eta)\\mu_{2}+\\eta X^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "579 Since $(\\mu_{1},\\mu_{2})=(m,m^{2}+\\Sigma^{2})$ , the update on $m$ is immediate. For the update on $\\Sigma^{2}$ , we write: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{(\\Sigma^{2})^{+}=\\mu_{2}^{+}-(m^{+})^{2}}}\\\\ {{\\ ~~~~~~~=(1-\\eta)\\mu_{2}+\\eta X^{2}-((1-\\eta)m+\\eta X)^{2}}}\\\\ {{\\ ~~~~~~=(1-\\eta)\\Sigma^{2}+(1-\\eta)m^{2}+\\eta X^{2}-(1-\\eta)^{2}m^{2}-2\\eta(1-\\eta)X m-\\eta^{2}X^{2}}}\\\\ {{\\ ~~~~~=(1-\\eta)\\Sigma^{2}+\\eta(1-\\eta)(m-X)^{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "580 ", "page_idx": 17}, {"type": "text", "text": "581 We now use this to show that updates are well-defined. ", "page_idx": 17}, {"type": "text", "text": "582 Proof of Proposition 4.1. If $\\theta_{2}<0$ then $\\Sigma^{2}\\,>\\,0$ so for $\\eta<1$ , $(\\Sigma^{2})^{+}>0$ almost surely so that   \n583 $\\theta_{2}^{+}<0$ and $|\\theta_{1}^{+}|<\\infty$ . In particular, $\\theta^{+}\\in\\mathbb{R}\\times\\mathbb{R}_{-}^{*}$ so the update is well-defined. The rest of the   \n584 proposition comes from the fact that $\\nabla^{2}f_{\\xi}=\\nabla^{2}f=\\nabla^{2}A$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "585 We can now proceed to proving the form of $f_{\\eta}$ . We first start by writing that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle f(\\theta)=A(\\theta)-\\theta^{\\top}(m_{\\star},m_{\\star}^{2}+\\Sigma_{\\star}^{2})}}\\\\ {{\\displaystyle\\qquad=\\frac{1}{2}\\log(2\\Sigma^{2})+\\frac{1}{2}\\frac{m^{2}}{\\Sigma^{2}}-\\frac{m m_{\\star}}{\\Sigma^{2}}+\\frac{m_{\\star}^{2}+\\Sigma_{\\star}^{2}}{2\\Sigma^{2}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "586 Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\nf(\\theta)=\\frac{1}{2}\\log(2\\Sigma^{2})+\\frac{\\Sigma_{\\star}^{2}}{2\\Sigma^{2}}+\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "587 In particular, ", "page_idx": 17}, {"type": "equation", "text": "$$\nf(\\theta)-f(\\theta_{\\star})=\\frac{1}{2}\\log\\left(\\frac{\\Sigma^{2}}{\\Sigma_{\\star}^{2}}\\right)+\\frac{\\Sigma_{\\star}^{2}-\\Sigma^{2}}{2\\Sigma^{2}}+\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "588 Note that, as expected, this corresponds to $D_{A}(\\theta,\\theta_{\\star})$ , that we can also compute through Proposi  \n589 tion F.1. We now write: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{A}(\\theta,\\theta^{+})=-\\displaystyle\\frac{1}{2}\\log\\left(\\frac{(\\Sigma^{2})^{+}}{\\Sigma^{2}}\\right)-\\frac{\\Sigma^{2}-(\\Sigma^{2})^{+}}{2\\Sigma^{2}}+\\frac{(m-m^{+})^{2}}{2\\Sigma^{2}}\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(64\\,\\mathrm{~G}^{2})}\\\\ &{\\qquad\\qquad=-\\displaystyle\\frac{1}{2}\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)+\\frac{(1-\\eta)(\\Sigma^{2}+\\eta(m-X)^{2})-\\Sigma^{2}}{2\\Sigma^{2}}+\\frac{\\eta^{2}(m-m^{+})^{2}}{\\Sigma^{2}}\\qquad\\qquad\\qquad\\quad}\\\\ &{\\qquad=-\\displaystyle\\frac{1}{2}\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)-\\frac{\\eta}{2}+\\eta(1-\\eta)\\frac{(m-X)^{2}}{2\\Sigma^{2}}+\\frac{\\eta^{2}(m-X)^{2}}{2\\Sigma^{2}}}\\\\ &{\\qquad\\qquad=-\\displaystyle\\frac{1}{2}\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)-\\frac{\\eta}{2}+\\eta\\frac{(m-X)^{2}}{2\\Sigma^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "590 Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\theta)-\\displaystyle\\frac{D_{A}(\\theta,\\theta^{+})}{\\eta}-f(\\theta_{\\star})}\\\\ &{=\\displaystyle\\frac{1}{2}\\log\\left(\\frac{\\sum^{2}}{\\sum_{\\star}^{2}}\\right)+\\frac{\\sum_{\\star}^{2}-\\Sigma^{2}}{2\\Sigma^{2}}+\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}+\\frac{1}{2\\eta}\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)+\\frac{1}{2}-\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}+\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}}\\\\ &{=\\displaystyle\\frac{1}{2}\\log\\left(\\frac{\\sum^{2}}{\\Sigma_{\\star}^{2}}\\right)+\\frac{1}{2\\eta}\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)+\\frac{\\sum_{\\star}^{2}}{2\\Sigma^{2}}+\\frac{(m-m_{\\star})^{2}}{2\\Sigma^{2}}-\\frac{(m-X)^{2}}{2\\Sigma^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "591 Finally, $\\mathbb{E}\\left[(m-X)^{2}\\right]=(m-m_{\\star})^{2}+\\Sigma_{\\star}^{2}$ , and so: ", "page_idx": 17}, {"type": "equation", "text": "$$\nf_{\\eta}(\\theta)-f(\\theta_{\\star})=\\frac{1}{2}\\log\\left(\\frac{\\Sigma^{2}}{\\Sigma_{\\star}^{2}}\\right)+\\frac{1}{2\\eta}\\mathbb{E}\\left[\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)\\right],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "592 which precisely corresponds to Equation (14). We now proceed to proving bounds on $\\theta_{\\eta}$ for $\\eta<1$ . ", "page_idx": 17}, {"type": "text", "text": "593 F.2 Bounding the stochastic mirror descent variance $\\sigma_{\\star,\\eta}^{2}$ . ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "594 Now that we have an explicit form for $f_{\\eta}$ , we can characterize its minimizer $\\theta_{\\eta}$ , and use this to prove   \n595 results on $f_{\\eta}(\\theta_{\\eta})$ , which will in turn lead to bounds on $\\sigma_{\\star,\\eta}^{2}$ . This is the core of Lemma 4.2. ", "page_idx": 18}, {"type": "text", "text": "596 Proof. Proof of Lemma 4.2. The proof will proceed in three different stages: ", "page_idx": 18}, {"type": "text", "text": "597 ", "page_idx": 18}, {"type": "text", "text": "598 ", "page_idx": 18}, {"type": "text", "text": "\u2022 Differentiating $f_{\\eta}$ with respect to $m$ and $\\Sigma^{2}$ .   \n\u2022 Using these expressions to obtain bounds on the $(m_{\\eta},\\Sigma_{\\eta}^{2})$ for which $\\nabla f_{\\eta}$ is $0$ .   \n\u2022 Plugging these bounds into the expression of $f_{\\eta}$ to bound $\\Sigma_{\\eta}^{2}$ . ", "page_idx": 18}, {"type": "text", "text": "599 ", "page_idx": 18}, {"type": "text", "text": "600 1 - Differentiating $f_{\\eta}$ . Before differentiating, we rewrite: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{f_{\\eta}(\\theta)-f(\\theta_{\\star})=\\displaystyle\\frac{1}{2}\\log\\left(\\Sigma^{2}\\right)+\\frac{1}{2\\eta}\\mathbb{E}\\left[\\log\\left(1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right)\\right]-\\displaystyle\\frac{1}{2}\\log\\left(\\Sigma_{\\star}^{2}\\right)+\\frac{1}{2\\eta}\\log(1-\\eta)}}\\\\ {{={-\\frac{1-\\eta}{2\\eta}\\log\\left(\\Sigma^{2}\\right)}+\\frac{1}{2\\eta}\\mathbb{E}\\left[\\log\\left(\\Sigma^{2}+\\eta(m-X)^{2}\\right)\\right]-\\displaystyle\\frac{1}{2}\\log\\left(\\Sigma_{\\star}^{2}\\right)+\\frac{1}{2\\eta}\\log(1-\\eta).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "601 Indeed, the two terms on the right are constant and so do not matter. If we differentiate in $m$ , we   \n602 obtain: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{m}f_{\\eta}(\\theta)=\\mathbb{E}\\left[\\frac{1}{2\\eta}2\\eta\\frac{m-X}{\\Sigma^{2}}\\frac{1}{\\Sigma^{2}+\\eta(m-X)^{2}}\\right]=\\mathbb{E}\\left[\\frac{m-X}{\\Sigma^{2}+\\eta(m-X)^{2}}\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "603 Now, differentiating in $\\Sigma^{2}$ yields: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\Sigma^{2}}f_{\\eta}(\\theta)=-\\frac{1-\\eta}{2\\eta\\Sigma^{2}}+\\frac{1}{2\\eta}\\mathbb{E}\\left[\\frac{1}{\\Sigma^{2}+\\eta(m-X)^{2}}\\right]=\\frac{1}{2\\Sigma^{2}}-\\mathbb{E}\\left[\\frac{(m-X)^{2}}{2\\Sigma^{2}(\\Sigma^{2}+\\eta(m-X)^{2})}\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "604 2 - Obtaining bounds on $(m_{\\eta},\\Sigma_{\\eta}^{2})$ . The solution to $\\nabla_{m}f_{\\eta}(\\theta)=0$ is $m=m_{\\star}$ . Indeed, it is direct   \n605 to verify that in this case, $\\begin{array}{r}{\\mathbb{E}\\left[\\frac{\\tilde{X}}{\\Sigma^{2}+\\eta\\tilde{X}^{2}}\\right]=0}\\end{array}$ since $\\tilde{X}=m_{\\star}-X$ is symmetric (with respect to 0). For   \n606 $m>m_{\\star}$ , $\\begin{array}{r}{\\mathbb{E}\\left[\\frac{\\tilde{X}}{\\Sigma^{2}+\\eta\\tilde{X}^{2}}\\right]>0}\\end{array}$ since we integrate the same values as the previous case, but now more   \n607 mass is put on the positive values (and similarly for $m<m_{\\star}$ ). Note that this is the case regardless of   \n608 \u03a32. \u03b7   \n609 We are now interested in $\\Sigma_{\\eta}^{2}$ . Note that we will not get such a clean expression as for $m_{\\eta}$ , but only   \n610 bounds. From its expression, we deduce that $\\nabla_{\\Sigma^{2}}f_{\\eta}(\\theta_{\\eta})=0$ can be reformulated as: ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta_{\\eta}(m-X)^{2}}\\right]=1\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "611 For the upper bound, we simply write that: ", "page_idx": 18}, {"type": "equation", "text": "$$\n1=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta_{\\eta}(m-X)^{2}}\\right]\\leq\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]=\\frac{\\Sigma_{\\star}^{2}}{\\Sigma_{\\eta}^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "612 from which we deduce that $\\Sigma_{\\eta}^{2}\\le\\Sigma_{\\star}^{2}$ . Let us now introduce some $\\alpha>0$ . We have that: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathfrak{L}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\alpha-\\alpha+\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\alpha}\\frac{1}{1-1+\\frac{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}{\\alpha}}\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "613 We now use that for $u\\geq-1$ , $\\begin{array}{r}{\\frac{1}{1+u}\\geq1-u}\\end{array}$ , and so: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]\\ge\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\alpha}\\left(1-\\left[-1+\\frac{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}{\\alpha}\\right]\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\alpha}\\left(2-\\frac{\\Sigma_{\\eta}^{2}}{\\alpha}\\right)-\\eta\\frac{(m_{\\eta}-X)^{4}}{\\alpha^{2}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "614 Now, recall that $m_{\\eta}=m_{\\star}$ , so $X-m_{\\eta}\\sim\\mathcal{N}(0,\\Sigma_{\\star})$ , leading to ", "page_idx": 19}, {"type": "equation", "text": "$$\n1=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]\\geq\\frac{\\Sigma_{\\star}^{2}}{\\alpha}\\left(2-\\frac{\\Sigma_{\\eta}^{2}}{\\alpha}\\right)-\\eta\\frac{3\\Sigma_{\\star}^{4}}{\\alpha^{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "615 Rearranging terms, we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\alpha^{2}}{\\Sigma_{\\star}^{2}}-2\\alpha\\geq-\\Sigma_{\\eta}^{2}-3\\Sigma_{\\star}^{2},\\;\\mathrm{so}\\;\\Sigma_{\\eta}^{2}\\geq\\frac{2\\alpha\\Sigma_{\\star}^{2}-\\alpha^{2}}{\\Sigma_{\\star}^{2}}-3\\eta\\Sigma_{\\star}^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "616 We see that $\\alpha=\\Sigma_{\\star}^{2}$ maximizes the right term, and we obtain the desired result, i.e.: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Sigma_{\\eta}^{2}\\geq(1-3\\eta)\\Sigma_{\\star}^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "617 Unfortunately, we see that this bound is only informative for $3\\eta<1$ . For the rest of the cases, we   \n618 will use the Markov inequality instead, which writes for all $a>0$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\geq a\\right)\\leq\\frac{1}{a}\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]=\\frac{1}{a}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "619 Yet, ", "page_idx": 19}, {"type": "equation", "text": "$$\n>\\left({\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}}\\geq a\\right)=\\mathbb{P}\\left({\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\star}^{2}}}\\geq{\\frac{a}{1-\\eta a}}{\\frac{\\Sigma_{\\eta}^{2}}{\\Sigma_{\\star}^{2}}}\\right)=2\\mathbb{P}\\left({\\frac{X-m_{\\star}}{\\Sigma_{\\star}}}\\geq{\\sqrt{\\frac{a}{1-\\eta a}}}{\\frac{\\Sigma_{\\eta}}{\\Sigma_{\\star}}}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "620 Therefore, denoting $\\Phi$ the cumulative distribution function of the standard Gaussian, we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n2\\left(1-\\Phi\\left(\\sqrt{\\frac{a}{1-\\eta a}}\\frac{\\Sigma_{\\eta}}{\\Sigma_{\\star}}\\right)\\right)\\leq\\frac{1}{a},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "621 and since $\\Phi^{-1}$ is an increasing function, this leads to: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sqrt{\\frac{a}{1-\\eta a}}\\frac{\\Sigma_{\\eta}}{\\Sigma_{\\star}}\\geq\\Phi^{-1}\\left(1-\\frac{1}{2a}\\right),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "622 so that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Sigma_{\\eta}\\geq\\sqrt{1-\\eta a}\\frac{\\Phi^{-1}\\left(1-\\frac{1}{2a}\\right)}{\\sqrt{a}}\\Sigma_{\\star}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "623 One can check that $\\begin{array}{r}{\\Phi^{-1}\\left(1-\\frac{1}{2a}\\right)/\\sqrt{a}<1}\\end{array}$ for all $a$ , which is consistent with the fact that $\\Sigma_{\\eta}^{2}\\leq\\Sigma_{\\star}^{2}$ .   \n624 Also note that for $\\eta=1$ , a non-trivial bound would require $a<1$ , but then $\\begin{array}{r}{\\Phi^{-1}\\left(1-\\frac{1}{2a}\\right)\\overset{\\cdot}{\\leq}0}\\end{array}$ so   \n625 (as expected), we cannot get better than $\\Sigma_{\\eta}^{2}\\geq0$ . However, the previous bounding (Equation (83)) is   \n626 more precise for small $\\eta$ since $\\textstyle\\Phi^{-1}\\left(1-{\\frac{1}{2a}}\\right)/{\\sqrt{a}}<1-c$ with $c>0$ a constant regardless of $a$ . In   \n627 particular, for any $\\varepsilon$ , by using any $1<a<1/(1-\\varepsilon)$ , we obtain that $\\Sigma_{\\eta}^{2}\\geq\\alpha_{\\varepsilon}\\Sigma_{\\star}^{2}$ for some constant   \n628 $\\alpha_{\\varepsilon}$ that only depends on the $a$ that we choose. In particular, we can handle the cases $\\eta=1/2$ and   \n629 $\\eta=1/3$ that gave trivial results $\\Sigma_{\\eta}^{2}\\geq0$ with the previous bounds. ", "page_idx": 19}, {"type": "text", "text": "630 The last part consists in proving that $\\begin{array}{r}{f_{\\eta}(\\theta_{\\eta})-f(\\theta_{\\star})\\ge\\frac{1}{2}\\log\\left(\\frac{\\Sigma_{\\eta}^{2}}{\\Sigma_{\\star}^{2}}\\right)}\\end{array}$ . To do so, we start back from ", "page_idx": 19}, {"type": "equation", "text": "$$\nf_{\\eta}(\\theta)-f(\\theta_{\\star})=\\frac{1}{2}\\log\\left(\\frac{\\Sigma^{2}}{\\Sigma_{\\star}^{2}}\\right)+\\frac{1}{2\\eta}\\mathbb{E}\\left[\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m-X)^{2}}{\\Sigma^{2}}\\right]\\right)\\right],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "631 and show that $\\begin{array}{r}{\\mathbb{E}\\left[\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]\\right)\\right]\\geq0}\\end{array}$ . We start by the inequality $\\textstyle\\log(1\\!+\\!x)\\geq{\\frac{x}{1+x}}$ ,   \n632 leading to: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\log\\left((1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]\\right)\\right]\\ge\\mathbb{E}\\left[\\frac{(1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]-1}{(1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\left[\\frac{\\eta(1-\\eta)\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}-\\eta}{(1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\eta\\mathbb{E}\\left[\\frac{(1-\\eta)(m_{\\eta}-X)^{2}-\\Sigma_{\\eta}^{2}}{(1-\\eta)\\left[\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}\\right]}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "633 Recall that the optimality conditions for $(m_{\\eta},\\Sigma_{\\eta}^{2})$ write: ", "page_idx": 20}, {"type": "equation", "text": "$$\n1=\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]=\\frac{1}{\\eta}\\mathbb{E}\\left[1-\\frac{\\Sigma_{\\eta}^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right],\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "634 so that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{\\Sigma_{\\eta}^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]=1-\\eta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "635 Combining these, we obtain that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\Bigg[\\log\\Bigg((1-\\eta)\\left[1+\\eta\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}}\\right]\\Bigg)\\Bigg]\\geq\\eta\\mathbb{E}\\left[\\frac{(1-\\eta)(m_{\\eta}-X)^{2}-\\Sigma_{\\eta}^{2}}{(1-\\eta)\\left[\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}\\right]}\\right]}&{}\\\\ {=\\eta\\left(\\mathbb{E}\\left[\\frac{(m_{\\eta}-X)^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]-\\frac{1}{1-\\eta}\\mathbb{E}\\left[\\frac{\\Sigma_{\\eta}^{2}}{\\Sigma_{\\eta}^{2}+\\eta(m_{\\eta}-X)^{2}}\\right]\\right)=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "636 which is the desired result. ", "page_idx": 20}, {"type": "text", "text": "637 The final result is obtained by plugging the lower bounds for $\\Sigma_{\\eta}^{2}$ into this bound, leading to either   \n638 $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\le-\\frac{1}{2\\eta}\\log(1-3\\eta)}\\end{array}$ for $\\eta<1/3$ or $\\begin{array}{r}{\\sigma_{\\star,\\eta}^{2}\\leq-\\frac{1}{2\\eta}\\log\\alpha_{\\varepsilon}}\\end{array}$ for $\\eta<1-\\varepsilon$ . ", "page_idx": 20}, {"type": "text", "text": "639 ", "page_idx": 20}, {"type": "text", "text": "640 F.3 Unrolling the recursions to derive actual convergence results. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "641 F.3.1 Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "642 Now that we have bounded the stochastic mirror descent variance $\\sigma_{\\star,\\eta}^{2}$ in this setting, we can plug it   \n643 into Theorem 3.1 to obtain finite-time convergence guarantees on the MAP and MLE estimators. ", "page_idx": 20}, {"type": "text", "text": "644 Proof of Theorem 4.3. Starting from Theorem 3.1, we obtain: ", "page_idx": 20}, {"type": "equation", "text": "$$\nD_{A}(\\theta_{\\star},\\theta^{(k+1)})\\leq(1-\\eta)D_{A}(\\theta_{\\star},\\theta^{(k)})-\\frac{\\eta}{2}\\log{(1-3\\eta)}\\leq(1-\\eta)D_{A}(\\theta_{\\star},\\theta^{(k)})+\\frac{3\\eta^{2}}{2},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "645 where the right term is replaced by $c_{\\varepsilon}$ (where $c_{\\epsilon}=-\\textstyle{\\frac{1}{2}}\\log{\\alpha_{\\varepsilon}})$ for $k\\leq3$ . Taking $\\eta=1/k$ for $k>1$   \n646 and multiplying by $k$ leads for $k>3$ to: ", "page_idx": 20}, {"type": "equation", "text": "$$\nk D_{A}(\\theta_{\\star},\\theta^{(k+1)})\\leq(k-1)D_{A}(\\theta_{\\star},\\theta^{(k)})+\\frac{3}{2k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "647 Therefore, a telescopic sum leads to, for $n_{0}>0$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n(n+n_{0})D_{A}(\\theta_{\\star},\\theta^{(n)})\\leq n_{0}D_{A}(\\theta_{\\star},\\theta^{(0)})+\\frac{3}{2}\\sum_{k=n_{0}}^{n+n_{0}}\\frac{1}{k}+2c_{1/2},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "648 and so, since $\\begin{array}{r}{\\sum_{k=n_{0}}^{n}\\frac{1}{k}\\le\\log(n+n_{0}+1)-\\log(n_{0});}\\end{array}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\nD_{A}(\\theta_{\\star},\\theta^{(n)})\\leq\\frac{n_{0}D_{A}(\\theta_{\\star},\\theta^{(0)})+(3/2)\\log(1+(n+1)/n_{0})+\\Gamma}{n+n_{0}},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "649 where $\\Gamma=2c_{1/2}$ and we actually have $\\Gamma=0$ for $n_{0}>3$ . ", "page_idx": 20}, {"type": "text", "text": "650 F.3.2 $O(1/n)$ convergence result. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "651 We now consider a different estimator (from the MAP and the MLE), which we construct in the   \n652 following way: ", "page_idx": 20}, {"type": "text", "text": "653 ", "page_idx": 20}, {"type": "text", "text": "\u2022 Choose $n_{0}\\geq6$ and initial parameter $\\tilde{\\theta}^{(n_{0})}$ .   \n\u2022 Obtain ${\\tilde{\\theta}}^{(n)}$ by performing $n-n_{0}$ stochastic mirror descent steps from $\\tilde{\\theta}^{(n_{0})}$ with step-sizes $\\eta_{k}=2/(k+1)$ for $k\\in\\{n_{0},...,n\\}$ . ", "page_idx": 20}, {"type": "text", "text": "656 This estimator is a modified version of the MAP, where $n_{0}$ controls how much weight we would like   \n657 to put on the prior, and $\\tilde{\\theta}^{(n_{0})}$ would typically be the same starting parameter as for the MAP estimator.   \n658 This estimator is built so that we can use the convergence analysis from Lacoste-Julien et al. [16] and   \n659 obtain a $O(1/n)$ convergence rate. Note that we make the $n_{0}\\geq6$ restriction for simplicity to ensure   \n660 that $\\sigma_{\\star,\\eta}^{2}\\leq3/2$ , but the result can be easily adapted to $n_{0}\\geq2$ . ", "page_idx": 21}, {"type": "text", "text": "661 Proposition F.3. After $n-n_{0}$ steps, this modified estimator \u03b8\u02dc(n)verifies: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}D_{h}(\\theta_{\\star},\\tilde{\\theta}^{(n)})\\leq\\frac{2n_{0}(n_{0}-1)}{n(n-1)}D_{h}(\\theta_{\\star},\\tilde{\\theta}^{(n_{0})})+\\frac{6}{n}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "662 Proof. Let us note $D_{k}=\\mathbb{E}\\left[D_{h}\\big(\\theta_{\\star},\\tilde{\\theta}^{(k)}\\big)\\right]$ . In this case, using that $\\sigma_{\\star,\\eta}^{2}\\leq3/2$ , Theorem 3.1 writes   \n663 (since $\\mu=1$ ): ", "page_idx": 21}, {"type": "equation", "text": "$$\nD_{k+1}\\leq(1-\\eta_{k})D_{k}+\\frac{3\\eta_{k}^{2}}{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "664 At this point, we can multiply by $k(k+1)$ on both sides, and take $\\begin{array}{r}{\\eta_{k}=\\frac{2}{k+1}}\\end{array}$ for $k\\geq n_{0}$ . Remarking   \n665 that $\\begin{array}{r}{1-\\eta_{k}=1-\\frac{2}{k+1}=\\frac{k-1}{k+1}}\\end{array}$ k2+1 = kk\u2212+11, we obtain that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n(k+1)k D_{k+1}\\leq k(k-1)D_{k}+\\frac{6k}{k+1}\\leq k(k-1)D_{k}+6.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "666 Unrolling this recursion from $k=n_{0}$ to $k=n-1$ (since $(k+1)k D_{k+1}=L_{k+1}$ , where $L_{k}=$   \n667 $k(k-1)D_{k})$ , we obtain: ", "page_idx": 21}, {"type": "equation", "text": "$$\nn(n-1)D_{n}\\leq n_{0}(n_{0}-1)D_{n_{0}}+\\sum_{k=n_{0}}^{n-1}6,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "668 and the result follows by dividing by $n(n-1)$ , and using that $(n-n_{0})/(n-1)\\leq1$ . ", "page_idx": 21}, {"type": "text", "text": "669 F.4 The case of the MLE ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "670 For the MLE estimator, directly applying the mirror descent approach would require using $\\eta_{0}=1$ ,   \n671 starting from an arbitrary $\\theta^{(0)}$ (that would not affect the results anyway). The problem in this case   \n672 is that $D_{h}(\\theta_{\\star},\\theta^{(1)})$ is infinite since $\\Sigma^{(2)}=0$ . This also means that we cannot start the stochastic   \n673 mirror descent algorithm from $\\theta^{(1)}$ , since the recursion would still involve the infinite $D_{h}(\\theta_{\\star},\\theta^{(1)})$ .   \n674 Therefore, in the case of the MLE, considering that the first two samples are $X^{(1)}$ and $X^{(2)}$ , then the   \n675 first two points are: ", "page_idx": 21}, {"type": "equation", "text": "$$\nm^{(1)}=X^{(1)},\\Sigma^{(1)}=0\\;\\mathrm{and}\\;m^{(2)}=\\frac{X^{(1)}+X^{(2)}}{2},(\\Sigma^{(2)})^{2}=\\frac{(X^{(1)}-X^{(2)})^{2}}{4}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "676 More generally, a direct recursion for the MLE leads to: ", "page_idx": 21}, {"type": "equation", "text": "$$\nm^{(n)}=\\frac{1}{n}\\sum_{k=1}^{n}X^{(k)},\\;\\;(\\Sigma^{(n)})^{2}=\\frac{1}{n}\\sum_{k=1}^{n}(X^{(k)}-m^{(n)})^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "677 From this, we derive that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[(\\Sigma^{(n)})^{2}\\right]=\\mathbb{E}\\left[(X^{(n)}-m^{(n)})^{2}\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[\\left(\\left(1-\\frac{1}{n}\\right)X^{(n)}-\\frac{n-1}{n}m^{(n-1)}\\right)^{2}\\right]}\\\\ &{\\qquad\\qquad=\\left(\\frac{n-1}{n}\\right)^{2}\\mathbb{E}\\left[\\left(X^{(n)}-m_{\\star}-(m^{(n-1)}-m_{\\star})\\right)^{2}\\right]}\\\\ &{\\qquad\\qquad=\\left(\\frac{n-1}{n}\\right)^{2}\\mathbb{E}\\left[\\left(X^{(n)}-m_{\\star}\\right)^{2}+\\left(m^{(n-1)}-m_{\\star}\\right)^{2}\\right]}\\\\ &{\\qquad\\qquad=\\left(\\frac{n-1}{n}\\right)^{2}\\left(\\Sigma_{\\star}^{2}+\\frac{1}{n-1}\\Sigma_{\\star}^{2}\\right)=\\left(1-\\frac{1}{n}\\right)\\Sigma_{\\star}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "678 where (107) comes from the fact that $X^{(n)}$ and $m^{(n-1)}$ are independent with mean $m_{\\star}$ . Plugging   \n679 this into the expression of $D_{h}(\\theta_{\\star},\\theta)$ for the MLE after $n$ steps, we obtain: ", "page_idx": 22}, {"type": "equation", "text": "$$\nD_{h}(\\theta_{\\star},\\theta^{(n)})=-\\frac{1}{2}\\mathbb{E}\\left[\\log\\frac{(\\Sigma^{(n)})^{2}}{\\Sigma_{\\star}^{2}}\\right].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "680 Unfortunately, there is no closed-form for this expression for arbitrary $n$ , hence the need for a more   \n681 involved analysis, for instance through the mirror descent framework. For the case $n=2$ however   \n682 (which is the one we are interested in), we obtain that ", "page_idx": 22}, {"type": "equation", "text": "$$\nD_{h}(\\theta_{\\star},\\theta^{(2)})=-\\frac{1}{2}\\mathbb{E}\\left[\\log\\left(\\frac{X^{(1)}-X^{(2)}}{2\\Sigma_{\\star}}\\right)^{2}\\right]=-\\frac{1}{2}\\mathbb{E}\\left[\\log\\frac{Y^{2}}{2}\\right],\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "683 where Y = X(1\u221a)\u2212X(2) $\\begin{array}{r}{Y=\\frac{X^{(1)}-X^{(2)}}{\\sqrt{2}\\Sigma_{\\star}}\\sim\\mathcal{N}(0,1)}\\end{array}$ . Therefore, this can simply be treated as a constant that we can   \n684 precisely evaluate numerically (for instance remarking that $Y^{2}$ is gamma distributed and using results   \n685 on logarithmic expectations of gamma distributions).   \n686 For $n>2$ , it is tempting to use the convexity of $-\\log$ to use a similar reasoning, but this only leads   \n687 to a constant bound on $\\bar{D}_{h}(\\theta_{\\star},\\theta^{(n)})$ . ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "688 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "5 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n6 made in the paper. \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n8 contributions made in the paper and important assumptions and limitations. A No or   \n9 NA answer to this question will not be perceived well by the reviewers.   \n0 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n1 much the results can be expected to generalize to other settings.   \n2 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "704 2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Limitations for each result are discussed after they are introduced, in particular the fact that Theorem 4.3 does not completely solve the problem from Le Priol et. al. (2021). Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "736 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "737 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n738 a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Assumptions are clearly introduced, and all proofs can be found in the appendix. 42 Guidelines: 43 \u2022 The answer NA means that the paper does not include theoretical results. 44 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross45 referenced. 46 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. 47 \u2022 The proofs can either appear in the main paper or the supplemental material, but if 48 they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. 50 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented 51 by formal proofs provided in appendix or supplemental material. 52 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "53 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "57 Answer: [NA]   \n58 Justification: No experimental results.   \n59 Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "795 Answer: [NA]   \n796 Justification: No experimental results.   \n797 Guidelines:   \n798 \u2022 The answer NA means that paper does not include experiments requiring code.   \n799 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n800 public/guides/CodeSubmissionPolicy) for more details.   \n801 \u2022 While we encourage the release of code and data, we understand that this might not be   \n802 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n803 including code, unless this is central to the contribution (e.g., for a new open-source   \n804 benchmark).   \n805 \u2022 The instructions should contain the exact command and environment needed to run to   \n806 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n807 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n808 \u2022 The authors should provide instructions on data access and preparation, including how   \n809 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n810 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n811 proposed method and baselines. If only a subset of experiments are reproducible, they   \n812 should state which ones are omitted from the script and why.   \n813 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n814 versions (if applicable).   \n815 \u2022 Providing as much information as possible in supplemental material (appended to the   \n816 paper) is recommended, but including URLs to data and code is permitted.   \n817 6. Experimental Setting/Details   \n818 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n819 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n820 results?   \n821 Answer: [NA]   \n822 Justification: No experiments.   \n823 Guidelines:   \n824 \u2022 The answer NA means that the paper does not include experiments.   \n825 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n826 that is necessary to appreciate the results and make sense of them.   \n827 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n828 material.   \n829 7. Experiment Statistical Significance   \n830 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n831 information about the statistical significance of the experiments?   \n832 Answer: [NA]   \n833 Justification: No experimental results.   \n834 Guidelines:   \n835 \u2022 The answer NA means that the paper does not include experiments.   \n836 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n837 dence intervals, or statistical significance tests, at least for the experiments that support   \n838 the main claims of the paper.   \n839 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n840 example, train/test split, initialization, random drawing of some parameter, or overall   \n841 run with given experimental conditions).   \n842 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n843 call to a library function, bootstrap, etc.)   \n844 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n845 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n846 of the mean.   \n847 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n848 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n849 of Normality of errors is not verified.   \n850 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n851 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n852 error rates).   \n853 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n854 they were calculated and reference the corresponding figures or tables in the text.   \n855 8. Experiments Compute Resources   \n856 Question: For each experiment, does the paper provide sufficient information on the com  \n857 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n858 the experiments?   \n859 Answer: [NA]   \n860 Justification: No experimental results.   \n861 Guidelines:   \n862 \u2022 The answer NA means that the paper does not include experiments.   \n863 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n864 or cloud provider, including relevant memory and storage.   \n865 \u2022 The paper should provide the amount of compute required for each of the individual   \n866 experimental runs as well as estimate the total compute.   \n867 \u2022 The paper should disclose whether the full research project required more compute   \n868 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n869 didn\u2019t make it into the paper).   \n870 9. Code Of Ethics   \n871 Question: Does the research conducted in the paper conform, in every respect, with the   \n872 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n873 Answer: [Yes]   \n874 Justification: Only theoretical results for the convergence of an optimization algorithm, with   \n875 no foreseeable societal impact.   \n876 Guidelines:   \n877 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n878 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n879 deviation from the Code of Ethics.   \n880 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n881 eration due to laws or regulations in their jurisdiction).   \n882 10. Broader Impacts   \n883 Question: Does the paper discuss both potential positive societal impacts and negative   \n884 societal impacts of the work performed?   \n885 Answer: [NA]   \n886 Justification: This is a theoretical work on an optimization algorithm, it has no foreseeable   \n887 societal impact bey   \n888 Guidelines:   \n889 \u2022 The answer NA means that there is no societal impact of the work performed.   \n890 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n891 impact or why the paper does not address societal impact.   \n892 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n893 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n894 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n895 groups), privacy considerations, and security considerations.   \n896 \u2022 The conference expects that many papers will be foundational research and not tied   \n897 to particular applications, let alone deployments. However, if there is a direct path to   \n898 any negative applications, the authors should point it out. For example, it is legitimate   \n899 to point out that an improvement in the quality of generative models could be used to   \n900 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n901 that a generic algorithm for optimizing neural networks could enable people to train   \n902 models that generate Deepfakes faster.   \n903 \u2022 The authors should consider possible harms that could arise when the technology is   \n904 being used as intended and functioning correctly, harms that could arise when the   \n905 technology is being used as intended but gives incorrect results, and harms following   \n906 from (intentional or unintentional) misuse of the technology.   \n907 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n908 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n909 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n910 feedback over time, improving the efficiency and accessibility of ML).   \n911 11. Safeguards   \n912 Question: Does the paper describe safeguards that have been put in place for responsible   \n913 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n914 image generators, or scraped datasets)?   \n915 Answer: [NA]   \n916 Justification: No model release.   \n917 Guidelines:   \n918 \u2022 The answer NA means that the paper poses no such risks.   \n919 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n920 necessary safeguards to allow for controlled use of the model, for example by requiring   \n921 that users adhere to usage guidelines or restrictions to access the model or implementing   \n922 safety filters.   \n923 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n924 should describe how they avoided releasing unsafe images.   \n925 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n926 not require this, but we encourage authors to take this into account and make a best   \n927 faith effort.   \n928 12. Licenses for existing assets   \n929 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n930 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n931 properly respected?   \n932 Answer: [NA]   \n933 Justification: Not using existing assets.   \n934 Guidelines:   \n935 \u2022 The answer NA means that the paper does not use existing assets.   \n936 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n937 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n938 URL.   \n939 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n940 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n941 service of that source should be provided.   \n942 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n943 package should be provided. For popular datasets, paperswithcode.com/datasets   \n944 has curated licenses for some datasets. Their licensing guide can help determine the   \n945 license of a dataset.   \n946 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n947 the derived asset (if it has changed) should be provided. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "948 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n949 the asset\u2019s creators.   \n950 13. New Assets   \n951 Question: Are new assets introduced in the paper well documented and is the documentation   \n952 provided alongside the assets?   \n953 Answer: [NA]   \n954 Justification: No new assets.   \n955 Guidelines:   \n956 \u2022 The answer NA means that the paper does not release new assets.   \n957 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n958 submissions via structured templates. This includes details about training, license,   \n959 limitations, etc.   \n960 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n961 asset is used.   \n962 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n963 create an anonymized URL or include an anonymized zip file.   \n964 14. Crowdsourcing and Research with Human Subjects   \n965 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n966 include the full text of instructions given to participants and screenshots, if applicable, as   \n967 well as details about compensation (if any)?   \n968 Answer: [NA]   \n969 Justification: No human subjects or crowdsourcing.   \n970 Guidelines:   \n971 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n972 human subjects.   \n973 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n974 tion of the paper involves human subjects, then as much detail as possible should be   \n975 included in the main paper.   \n976 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n977 or other labor should be paid at least the minimum wage in the country of the data   \n978 collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Guidelines \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. \u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. \u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]