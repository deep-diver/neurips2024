{"references": [{"fullname_first_author": "Sergey Levine", "paper_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems", "publication_date": "2020-05-01", "reason": "This paper provides a foundational overview of offline reinforcement learning, a core concept in the field and the basis for many of the other cited papers."}, {"fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "publication_date": "2021-00-00", "reason": "This paper introduces the Decision Transformer, a key architecture upon which much of the current research, including this paper, is built."}, {"fullname_first_author": "Mengdi Xu", "paper_title": "Prompting decision transformer for few-shot policy generalization", "publication_date": "2022-00-00", "reason": "This paper directly inspired the current work by introducing Prompt-DT, a method that this paper builds upon and improves."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper highlights the power of pre-trained language models, a crucial element in the current paper's approach."}, {"fullname_first_author": "Dian Chen", "paper_title": "Contrastive test-time adaptation", "publication_date": "2022-00-00", "reason": "This paper introduces Test-Time Adaptation (TTA), a technique used in the current paper for improving performance on unseen tasks."}]}