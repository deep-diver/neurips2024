[{"figure_path": "0l9yGPTHAU/tables/tables_2_1.jpg", "caption": "Table 1: Comparisons with prior results (up to log terms) regarding finding an \u025b-optimal policy for the distributionally RMDP, where \u03c3 is the radius of the uncertainty set and max defined in Theorem 1.", "description": "This table compares the sample complexity upper and lower bounds from this paper with those from several previous papers.  The comparison is made across different distance functions (Total Variation, general Lp norms), and under both sa-rectangularity and s-rectangularity conditions.  The results highlight the near-optimality of the new bounds derived in this work and show that solving distributionally robust reinforcement learning problems can be more sample efficient than solving standard RL problems in certain settings.", "section": "4 Theoretical guarantees"}]