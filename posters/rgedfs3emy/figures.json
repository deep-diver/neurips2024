[{"figure_path": "rGEDFS3emy/figures/figures_2_1.jpg", "caption": "Figure 1: This diagram illustrates the learning agenda of F-OAL. In the encoder, features from each block of the ViT are extracted, summed, and averaged to form a composite feature. This feature is then randomly projected into a higher-dimensional space and normalized using the sigmoid function, serving as the activation for updating the classifier. All parameters in the encoder remain frozen. In the analytic classifier section, we introduce R to retain historical information and update the linear classifier using recursive least squares. This process is forward-only with no gradients.", "description": "This figure shows the architecture of the proposed F-OAL method.  It consists of a frozen pre-trained encoder (using Vision Transformers - ViT blocks) that extracts features. These features are fused, expanded into a higher dimension, and used to update a linear classifier. The key is that the encoder is frozen and the classifier is updated using recursive least squares, making the process forward-only and memory efficient. The R matrix stores historical information for updating the classifier.", "section": "3 Methodology"}, {"figure_path": "rGEDFS3emy/figures/figures_8_1.jpg", "caption": "Figure 2: Peak GPU memory footprint in GB with 10 batch size on CIFAR-100. Replay-based methods are with 5,000 buffer size. F-OAL has low GPU footprint since it does not require gradients.", "description": "The figure is a bar chart showing the peak GPU memory usage (in GB) for various online class incremental learning (OCIL) methods on the CIFAR-100 dataset.  The chart compares F-OAL against several baseline methods, highlighting the significantly lower memory footprint of F-OAL due to its exemplar-free and gradient-free nature.  Replay-based methods (those with 5000 buffer size) are shown for comparison, illustrating their substantially higher memory consumption.", "section": "4.5 Resource Consumption"}, {"figure_path": "rGEDFS3emy/figures/figures_8_2.jpg", "caption": "Figure 3: Visualization of the weights of a linear classifier. The result comes from F-OAL on DTD. Based on [15], when recency bias happens, L2 norm of current task is significantly larger. In F-OAL, the L2 norm of current task is in an average level.", "description": "This figure visualizes the weights of a linear classifier trained using the proposed F-OAL method on the DTD dataset.  It compares the L2 norm of weights for the current task being learned against the L2 norm of weights for previously learned tasks (completed tasks).  The goal is to show that F-OAL mitigates the \"recency bias\" problem; a common issue in incremental learning where the model overemphasizes recently seen data and forgets previously learned information.  The graph shows that in F-OAL, the weights of the current task are not significantly larger than those of previous tasks, indicating successful mitigation of recency bias.", "section": "4.6 Countering Recency Bias"}, {"figure_path": "rGEDFS3emy/figures/figures_15_1.jpg", "caption": "Figure 4: Average accuracy measured in different projection sizes. Due to the time complexity in computing Equation 11, higher projection sizes escalate training time while increase little performance. On small datasets, higher projection sizes may even lead to reduction.", "description": "This figure shows the impact of different projection sizes on the average accuracy of the model across six different datasets.  Higher projection sizes increase training time significantly due to the computational cost of the recursive update formula, but do not proportionally improve accuracy.  In fact, for smaller datasets, increasing the projection size can even slightly reduce accuracy.", "section": "4.7 Ablation Study"}]