[{"figure_path": "x2zY4hZcmg/tables/tables_5_1.jpg", "caption": "Table 1: Safety Results", "description": "This table presents the safety performance of different reinforcement learning algorithms across various benchmark environments. For provably safe reinforcement learning (PSRL) methods like DMPS, MPS, and REVEL, the table shows the average number of times the safety shield was activated per episode, indicating how often the learned policy needed intervention to maintain safety. For statistically safe reinforcement learning (SRL) methods such as TD3, PPO-Lag, and CPO, the table presents the average number of safety violations per episode.  A lower number of shield invocations or safety violations signifies better safety performance.", "section": "6.1 Safety Results"}, {"figure_path": "x2zY4hZcmg/tables/tables_7_1.jpg", "caption": "Table 1: Safety Results", "description": "This table presents the results of safety experiments conducted across various benchmarks. For provably safe reinforcement learning (PSRL) methods (DMPS, MPS, and REVEL), which guarantee worst-case safety, the average number of shield invocations per episode is reported.  Fewer shield invocations indicate better performance. For statistically safe reinforcement learning (SRL) methods (TD3, PPO-Lag, and CPO), which aim to reduce safety violations, the average number of safety violations per episode is reported.  Lower numbers of violations represent better safety performance. The results are averaged over five independent random seeds.  Standard deviations are also provided.", "section": "6.1 Safety Results"}, {"figure_path": "x2zY4hZcmg/tables/tables_8_1.jpg", "caption": "Table 1: Safety Results", "description": "This table presents the safety performance results of different reinforcement learning algorithms. For provably safe reinforcement learning (PSRL) methods, it shows the average number of shield invocations per episode, indicating how often the safety mechanism intervened. Lower numbers suggest better safety performance. For statistically safe reinforcement learning (SRL) methods, it presents the average number of safety violations per episode, with higher numbers indicating poorer safety performance.  The results are categorized by benchmark environment (static or dynamic) and agent dynamics (differential drive or double integrator).", "section": "6.1 Safety Results"}, {"figure_path": "x2zY4hZcmg/tables/tables_18_1.jpg", "caption": "Table 1: Safety Results", "description": "This table presents a comparison of safety performance metrics across different reinforcement learning algorithms on various benchmark tasks. For provably safe reinforcement learning (PSRL) methods, the average number of shield invocations per episode is reported.  For statistically safe reinforcement learning (SRL) methods, the average number of safety violations per episode is shown. Lower numbers in both columns indicate better safety performance.", "section": "6.1 Safety Results"}]