[{"figure_path": "Hew2JSDycr/figures/figures_3_1.jpg", "caption": "Figure 1: Comparison of detection F1 scores when utilizing the rank and cross-entropy loss regarding next token, preceding token or both. The surrogate detection model is Llama-2-7B.", "description": "This figure compares the performance of AI-generated text detection using different features.  The features compared include the rank and cross-entropy loss of the next token, the preceding token, and both combined.  The results show that using both the next and preceding token features yields significantly better detection accuracy (F1 score).  The Llama-2-7B model is used as the surrogate model for this analysis.", "section": "3 Methodology of BISCO\u0420\u0415"}, {"figure_path": "Hew2JSDycr/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of BISCOPE. Arrows and texts in brown indicate text summarization.", "description": "This figure presents a flowchart illustrating the four main steps of the BISCOPE AI-generated text detection system.  Step 1 involves generating a completion prompt using a text summarization technique to provide contextual information to a Language Model (LLM). This prompt includes a summary of the input text and a portion of the input text itself, acting as a prompt for the LLM to complete the remaining text.  Step 2 involves computing bi-directional cross-entropy losses within the LLM, measuring how well the output logits predict the next token (forward) and memorize the preceding token (backward). Step 3 involves extracting statistical features from the losses by splitting the input text into multiple segments and collecting loss statistics for each segment. Finally, Step 4 utilizes a binary classifier trained on these statistical features to determine if the input text is AI-generated or human-written.", "section": "3.2 Overview of BISCOPE"}, {"figure_path": "Hew2JSDycr/figures/figures_6_1.jpg", "caption": "Figure 4: ROC curves of BISCOPE and all the baselines.", "description": "This figure presents the Receiver Operating Characteristic (ROC) curves for BISCOPE and nine other baseline methods.  Each subfigure (a-e) shows the ROC curve for a different large language model (LLM): GPT-3.5-Turbo, GPT-4-Turbo, Claude-3-Sonnet, Claude-3-Opus, and Gemini-1.0-Pro. The curves illustrate the trade-off between the true positive rate (TPR) and the false positive rate (FPR) for each method, allowing for a comparison of their performance in detecting AI-generated text. BISCOPE consistently demonstrates superior performance compared to the baselines, exhibiting higher TPR at similar FPR values.", "section": "4 Evaluation Results"}, {"figure_path": "Hew2JSDycr/figures/figures_8_1.jpg", "caption": "Figure 5: Comparison with GPTZero on five datasets using five latest commercial generative AI models. The metric used in the figure is the detection F1 score.", "description": "This figure compares the performance of BISCOPE and BISCOPE* (with and without text summarization) against GPTZero, a commercial AI-generated text detection tool, across five datasets generated using five different commercial LLMs.  The comparison is made using the F1 score as a metric. Each subfigure represents a different LLM and displays the F1 score achieved by each method across the five datasets: Arxiv, Yelp, Creative, Essay, and Code. This visualization allows for a clear comparison of the relative performance of each method across various datasets and LLMs, demonstrating BISCOPE's effectiveness in detecting AI-generated text.", "section": "4 Evaluation Results"}, {"figure_path": "Hew2JSDycr/figures/figures_8_2.jpg", "caption": "Figure 4: ROC curves of BISCOPE and all the baselines.", "description": "This figure presents the Receiver Operating Characteristic (ROC) curves for BISCOPE and nine other baseline methods.  ROC curves illustrate the performance of a binary classifier system as its discrimination threshold is varied. The x-axis represents the false positive rate (FPR), and the y-axis represents the true positive rate (TPR). A curve closer to the top-left corner indicates better performance, with a higher area under the curve (AUC) signifying improved classification accuracy. Each line represents the performance of a different method, allowing for direct comparison of their effectiveness in detecting AI-generated text.  The results shown are for the Yelp dataset, but similar plots would exist for the other datasets mentioned in the study.", "section": "Evaluation Results"}, {"figure_path": "Hew2JSDycr/figures/figures_13_1.jpg", "caption": "Figure 1: Comparison of detection F1 scores when utilizing the rank and cross-entropy loss regarding next token, preceding token or both. The surrogate detection model is Llama-2-7B.", "description": "This figure compares the performance (F1 score) of AI-generated text detection models using different features.  The features used are based on token rank (how easily the LLM predicts a token) and cross-entropy loss (how well the LLM's prediction matches the actual token).  It shows a comparison between using only the next token's information, only the preceding token's information, and both next and preceding token information. The results demonstrate that incorporating both next and preceding token information significantly improves the detection accuracy.  The Llama-2-7B model served as the surrogate model for this experiment.", "section": "3.1 Design Motivation"}]