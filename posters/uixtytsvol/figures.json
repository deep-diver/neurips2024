[{"figure_path": "UixTytSVOl/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Flat minima on loss landscape generalize better than sharp minima with domain shift. (b) Multi-modal joint training leads to larger loss for each modality compared with independent uni-modal training. (c) The flat minima between modalities are usually inconsistent, making it hard to obtain flat minima for each modality simultaneously in a multi-modal network. (d) We optimize the cross-modal interpolations on representation-space loss landscape to get consistent flat region.", "description": "This figure illustrates the key concepts and challenges in multi-modal domain generalization (MMDG).  (a) Shows the advantage of flat minima in generalization over sharp minima when domain shift occurs. (b) Highlights the problem of modality competition where joint training leads to increased loss for each modality compared to independent training. (c) Depicts the issue of discrepant flatness where inconsistent flat minima across modalities hinder effective generalization. (d) Presents the proposed solution, which optimizes cross-modal interpolations in representation space to create consistent flat loss regions and improve generalization.", "section": "3.2 MMDG Analysis"}, {"figure_path": "UixTytSVOl/figures/figures_4_1.jpg", "caption": "Figure 2: The overall framework of our method. The projectors map features with different dimensions to the same representation space. The teacher model is moving averaged from online model and generates cross-modal mixed representations as interpolations to distill the student representations. Uni-modal classifier is used to lower the loss of distilled features for each modality and a contrastive loss aims to alleviate gap between modalities. Only the online student model back propagates gradients. The teacher model is used for evaluation finally.", "description": "This figure illustrates the architecture of the proposed Cross-Modal Representation Flattening (CMRF) method.  It shows two networks: a student network and a teacher network. The student network consists of modality-specific feature extractors, projectors mapping features into a shared representation space, modality-specific classifiers, and a fusion and classification layer. The teacher network is a moving average of the student network and generates mixed representations by interpolating representations from different modalities. These mixed representations are then used to distill knowledge into the student network, helping to flatten the loss landscape and improve generalization.  The figure also highlights the use of contrastive loss to reduce the gap between modalities.", "section": "3.3 Cross-Modal Representation Flattening"}, {"figure_path": "UixTytSVOl/figures/figures_8_1.jpg", "caption": "Figure 3: Parameter sensitivity analysis on HAC with video and audio data under A, C \u2192 H.", "description": "This figure shows the performance of the proposed CMRF method and the baseline method on the HAC dataset with video and audio modalities, under the A, C \u2192 H setting.  The x-axis represents different values for the hyperparameters \u03bb1, \u03bb2, and \u03bb3 which control the weight of the distillation loss, uni-modal classification loss, and contrastive loss, respectively. The y-axis represents the accuracy.  The figure demonstrates the impact of each hyperparameter on the model's performance and highlights the robustness of CMRF across a range of hyperparameter values.", "section": "4.3 Ablation Studies"}, {"figure_path": "UixTytSVOl/figures/figures_14_1.jpg", "caption": "Figure 4: Representation space loss flatness evaluation. We apply gaussian noise to the extracted representations to be the domain shifts. The perturbation variance measures the distance between the perturbed representation and the original representation. We use the performance drop against perturbation variance to measure the sharpness of the landscapes around the minimum, where a larger drop indicates a sharp minimum. The experiments are on EPIC-Kitchens with D2, D3 \u2192 D1 of video-audio modalities. Left is the performance drop of video while right is the result of audio.", "description": "This figure shows the representation space loss flatness evaluation. Gaussian noise is applied to the extracted representations to simulate domain shifts.  The performance drop against perturbation variance is used to measure the sharpness of loss landscapes. Larger drops indicate sharper minima. The experiments involve EPIC-Kitchens dataset, specifically using domains D2 and D3 to test on domain D1 with video and audio modalities. The left subplot shows results for video, and the right subplot for audio.", "section": "3.3 Cross-Modal Representation Flattening"}, {"figure_path": "UixTytSVOl/figures/figures_14_2.jpg", "caption": "Figure 4: Representation space loss flatness evaluation. We apply gaussian noise to the extracted representations to be the domain shifts. The perturbation variance measures the distance between the perturbed representation and the original representation. We use the performance drop against perturbation variance to measure the sharpness of the landscapes around the minimum, where a larger drop indicates a sharp minimum. The experiments are on EPIC-Kitchens with D2, D3 \u2192 D1 of video-audio modalities. Left is the performance drop of video while right is the result of audio.", "description": "This figure shows the results of representation space loss flatness evaluation. Gaussian noise with varying variance was applied to the extracted representations to simulate domain shifts.  The performance drop relative to the variance is plotted for both video and audio modalities, separately, on EPIC-Kitchens dataset using the D2, D3 \u2192 D1 setup (where the model is trained on domains D2 and D3, and tested on domain D1). A larger performance drop with increasing variance indicates a sharper minimum, revealing that the proposed CMRF method achieves flatter minima compared to the baselines.", "section": "3.3 Cross-Modal Representation Flattening"}]