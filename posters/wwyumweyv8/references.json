{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model for the field of vision-language models, which is the central focus of the current research."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-12-01", "reason": "This paper introduces LAION-5B, a large-scale dataset used to train many of the vision-language models, including CLIP, that are evaluated in this study."}, {"fullname_first_author": "Alex Fang", "paper_title": "Data determines distributional robustness in contrastive language image pre-training (CLIP)", "publication_date": "2022-07-01", "reason": "This paper investigates the role of training data in the robustness of CLIP models, a key theme of the current work."}, {"fullname_first_author": "Zhouxing Shi", "paper_title": "Effective robustness against natural distribution shifts for models with different training data", "publication_date": "2023-12-01", "reason": "This paper studies robustness against distribution shifts, providing a relevant comparison for evaluating the robustness of CLIP models, a focus of the current research."}, {"fullname_first_author": "Yihao Xue", "paper_title": "Understanding the robustness of multi-modal contrastive learning to distribution shift", "publication_date": "2023-10-26", "reason": "This paper delves into the theoretical understanding of robustness in multi-modal contrastive learning, complementing the empirical analysis of the current study."}]}