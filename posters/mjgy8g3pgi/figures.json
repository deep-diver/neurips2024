[{"figure_path": "mjGy8g3pgi/figures/figures_0_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the personalization capability of Yo'LLaVA.  Given only a few images of a novel subject (in this case, a dog), Yo'LLaVA can engage in both text-based and visual conversations about that specific subject.  It contrasts its responses with those of a standard LLM (LLaVA), highlighting Yo'LLaVA's ability to handle personalized queries and visual recognition tasks beyond the capabilities of generic LLMs.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_3_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure illustrates the core concept of Yo'LLaVA.  Given only a small number of images of a specific object or person (in this case, a dog named '<bo>'), Yo'LLaVA is able to engage in both text-based and image-based conversations about that specific subject.  The figure shows examples of both types of conversations, demonstrating Yo'LLaVA's ability to personalize its responses based on the provided images.  This contrasts with traditional LLMs which lack this ability to handle personalized subjects.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_4_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows an overview of Yo'LLaVA's capabilities.  Given only a few images of a new subject (in this example, a dog named '<bo>'), the system learns to engage in both text-based and image-based conversations about that specific subject.  It highlights the contrast with existing Large Multimodal Models (LMMs), which struggle with personalized scenarios, showing how Yo'LLaVA surpasses them in understanding and responding to questions about this novel subject.  The text conversation example demonstrates understanding of the subject's characteristics, while the visual conversation example shows object recognition within an image.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_4_2.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure illustrates the core idea of the YoLLaVA model.  It shows how, given only a few images of a new subject (in this example, a dog), the model learns to understand and respond to both text and image-based questions about that specific subject.  The example shows personalized text conversations, where the model answers questions about the dog's birthday, as well as personalized visual conversations, where it identifies the dog in a picture and describes what the dog is doing. This highlights YoLLaVA's ability to go beyond generic object recognition and engage in personalized interactions.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_5_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the core functionality of Yo'LLaVA.  Given only a small number of images of a novel subject (in this case, a dog), Yo'LLaVA can engage in both text and image-based conversations about that subject.  It shows how Yo'LLaVA personalizes the interaction by understanding the specific subject, unlike general LMMs which would only offer generic responses. The figure contrasts the responses of Yo'LLaVA with those from a standard LLM (LLaVA), highlighting the improvement in personalization.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_8_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows how Yo'LLaVA, given a small number of images of a novel subject (in this case, a dog), is able to hold both text and visual conversations about that subject. The example shows text conversations where questions about the dog's birthday present are answered,  and visual conversations where the model is asked if the dog is in a picture and describes what the dog is doing in the picture.  This illustrates the key concept of personalization for LMMs.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_13_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows examples of how Yo'LLaVA, a personalized language and vision assistant, can engage in both textual and visual conversations about a novel subject given only a few images.  The left side demonstrates a text-based conversation about buying a birthday gift for the subject, while the right side shows a visual conversation identifying the subject within a photograph and describing their actions.  The figure highlights Yo'LLaVA's ability to handle personalized subjects, unlike generic LMMs.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_14_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure shows how Yo'LLaVA, a personalized language and vision assistant, can engage in both textual and visual conversations about a specific subject given only a few images.  The example shown involves a dog named '<bo>'. The left side displays the personalized concepts, training images used to personalize the model for <bo>, and the textual conversation about <bo>. The right side depicts a visual conversation where the model correctly identifies <bo> in an image and answers a question about its activity.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_14_2.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the capabilities of Yo'LLaVA. Given only a small number of images of a new subject (in this case, a dog), Yo'LLaVA is able to engage in both text-based and visual conversations about that subject.  The left side shows text-based conversations where Yo'LLaVA provides personalized answers to questions about the subject, while the right side illustrates visual conversations where Yo'LLaVA correctly identifies and comments on the subject within an image.  This highlights Yo'LLaVA's ability to learn and apply knowledge about specific, personalized subjects.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_14_3.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows the overall functionality of Yo'LLaVA.  Given only a few images of an object (like a dog), Yo'LLaVA can learn to answer questions about it through both text and image-based conversation.  The example shows both a text-based conversation (asking for birthday gift recommendations) and a visual conversation (identifying the dog in an image).  This demonstrates Yo'LLaVA's ability to personalize its responses around a specific subject rather than giving generic answers.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_14_4.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows examples of how Yo'LLaVA, a personalized language and vision assistant, can engage in both text-based and visual conversations about a novel subject, given only a few images of that subject.  The example uses a dog named '<bo>' as the subject.  The figure demonstrates that Yo'LLaVA can not only identify the subject in images but also answer questions and generate relevant text about the subject, demonstrating an ability to personalize LMM knowledge beyond generic object recognition.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_14_5.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates Yo'LLaVA's ability to personalize conversations using only a few images of a new subject.  The top part shows the input of personalized concepts and training images. The middle part shows how Yo'LLaVA handles personalized text conversations and how it answers questions about the subject.  The bottom part shows how it performs personalized visual conversations, using the input image and answering the questions more effectively than baselines like LLaVA.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_15_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows three example conversations using Yo'LLaVA.  The first conversation involves asking a question about the subject (a dog named <bo>) using text. The second is asking whether the subject appears in a photo, also using text. The third conversation involves the same question as the second but uses an image as input to Yo'LLaVA. Each conversation includes a comparison between Yo'LLaVA and the original LLaVA model. The key takeaway is that Yo'LLaVA, given a few images of a novel subject, can handle personalized queries and provide answers grounded in the visual attributes of the subject, unlike the generic responses from the original LLaVA.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_15_2.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure shows how Yo'LLaVA, a personalized language and vision assistant, uses a few images of a novel subject to learn and engage in both textual and visual conversations about that subject.  The example given is a dog named '<bo>'.  The left side depicts personalized concept training (images of the dog), the middle shows a text-based conversation about buying a gift for the dog, and the right side shows a visual conversation involving an image of the dog, where Yo'LLaVA correctly identifies the dog in the photo and even provides a descriptive caption. This demonstrates Yo'LLaVA's ability to personalize its knowledge and conversation skills.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_15_3.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows how Yo'LLaVA, a personalized language and vision assistant, can be used to have conversations about a specific subject, even with just a few images of that subject.  The example shows a personalized text conversation and a personalized visual conversation, both centered around a dog named '<bo>'.  It highlights Yo'LLaVA's ability to answer questions about '<bo>'s' appearance, activities, and preferences, contrasting with the generic responses of a non-personalized language and vision model (LLaVA).", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_15_4.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure shows how Yo'LLaVA, given only a few images of a novel subject (in this case, a dog), can successfully engage in both text-based and image-based conversations about that specific subject.  It highlights Yo'LLaVA's ability to move beyond generic LLM capabilities and personalize responses based on the provided images. The figure showcases examples of personalized text conversations (where the model gives relevant advice considering the dog's identity) and image-based conversations (where the model correctly identifies the dog in a photo).", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_15_5.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows how Yo'LLaVA, a personalized language and vision assistant, can engage in conversations about a novel subject (in this case, a dog) using only a few images of that subject. The figure illustrates that Yo'LLaVA can handle both textual and visual conversations, understanding the context and providing personalized responses.  It compares Yo'LLaVA's responses to those of a general LLM (LLaVA), highlighting the improvements achieved by personalization.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_16_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the core functionality of Yo'LLaVA.  Given only a few images of a new subject (in this case, a dog named '<bo>'), Yo'LLaVA is able to understand and respond to both textual and visual questions about that subject.  The example shows how Yo'LLaVA is able to answer questions like \"What do you recommend?\" regarding a birthday gift, and correctly identify the subject in images.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_17_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure shows a visual example of Yo'LLaVA's capability. Using only a few images of a novel subject (a dog named <bo>), Yo'LLaVA can perform both text and visual conversations related to that subject. It demonstrates the system's ability to personalize the interaction by recognizing the subject in new images and generating relevant responses to questions about it.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_18_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure illustrates the core functionality of Yo'LLaVA.  Given only a small number of images of a novel subject (in this case, a dog), Yo'LLaVA is able to engage in both textual and visual conversations about that subject.  The example shows how Yo'LLaVA can answer questions about the dog's appearance, activities, and even suggest birthday gifts, showcasing its ability to personalize interactions beyond simple object recognition.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_19_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "The figure shows examples of how Yo'LLaVA, a personalized language and vision assistant, can engage in conversations about a novel subject given only a few images of that subject.  The left side demonstrates a textual conversation where the user asks about buying a gift for their dog and Yo'LLaVA provides relevant suggestions. The right side shows a visual conversation where the user asks if their dog is in a photo, and Yo'LLaVA correctly identifies and describes the dog's presence in the image.  These examples highlight Yo'LLaVA's ability to learn and utilize personalized information about a specific subject, unlike generic LMMs that only handle general concepts.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_22_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure illustrates the core functionality of Yo'LLaVA. Given a small set of images of a new subject (in this case, a dog named <bo>), the system learns to understand and respond to both text-based and image-based questions about that subject.  The example shows how Yo'LLaVA can answer questions about the dog's appearance, activities, and even suggest birthday gifts, demonstrating its ability to personalize conversations beyond generic knowledge.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_22_2.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates Yo'LLaVA's ability to personalize conversations using only a few images of a novel subject.  It shows examples of both text and visual conversations, highlighting how Yo'LLaVA is able to answer questions and engage in conversations about the specific subject, which is a dog in this case, far beyond the capabilities of standard LLMs. The figure showcases the personalization of the LLM with regards to a specific subject and contrasts it with the generic approach of existing LLMs.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_23_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows examples of how Yo'LLaVA, a personalized language and vision assistant, can engage in both textual and visual conversations about a specific subject given only a few images of that subject.  The left side shows personalized text conversations where the model responds appropriately to questions about a dog's birthday gift, demonstrating an understanding of the dog's identity and characteristics. The right side illustrates personalized visual conversations where the model correctly identifies the subject in an image and answers questions about its actions and appearance.  This illustrates Yo'LLaVA's ability to handle personalized subjects compared to generic LLM models.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_25_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the personalization capabilities of Yo'LLaVA.  Given only a small number of images of a new subject (in this case, a dog), Yo'LLaVA can engage in both text-based and visual conversations about that subject.  The examples show how Yo'LLaVA correctly identifies the subject in images and answers questions related to the subject's appearance, activities, and other attributes, going beyond the capabilities of generic large multimodal models.", "section": "1 Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_26_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates the core functionality of Yo'LLaVA.  Given only a small number of images of a novel subject (in this case, a dog), Yo'LLaVA is able to personalize its responses to questions about the subject.  The figure shows examples of both text-based conversations and image-based conversations, highlighting the model's ability to understand and respond appropriately in both modalities.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_27_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure illustrates the personalization capability of Yo'LLaVA.  Given only a small number of images of a new subject (in this case, a dog), the model is able to understand and engage in both text-based and image-based conversations about that specific subject.  This demonstrates a move beyond the generic knowledge found in standard Large Multimodal Models (LMMs) toward a personalized understanding of individual entities. The example shows that Yo'LLaVA can answer questions about the dog's birthday gift ideas or whether the dog is present in a given image, demonstrating its enhanced understanding and personalized response capability.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_27_2.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows examples of how Yo'LLaVA, a personalized language and vision assistant, can engage in conversations about a specific subject using only a few images of that subject.  It highlights the personalization aspect by contrasting Yo'LLaVA's responses to those of a generic LLM (LLaVA) on questions related to the subject.  Yo'LLaVA accurately identifies the subject in images and answers questions about the subject's characteristics and activities, demonstrating its capacity to go beyond generic knowledge.", "section": "Abstract"}, {"figure_path": "mjGy8g3pgi/figures/figures_28_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure demonstrates Yo'LLaVA's ability to conduct personalized conversations using both text and images.  Given only a small number of images of a specific subject (in this case, a dog), Yo'LLaVA learns to recognize that subject in new images and answer questions about it. The top half shows text-based conversation examples, where the model successfully answers questions about the dog's birthday gift. The bottom half shows image-based conversation examples, where the model successfully identifies the dog within a picture.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_29_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure shows an overview of Yo'LLaVA's capabilities. Given only a few images of a novel subject (in this case, a dog), Yo'LLaVA can engage in both text-based and visual conversations about that subject. The text-based conversation demonstrates Yo'LLaVA's ability to provide personalized recommendations (e.g., suggesting a birthday gift for the dog). The visual conversation showcases Yo'LLaVA's capacity to identify and provide details about the subject within an image.", "section": "Introduction"}, {"figure_path": "mjGy8g3pgi/figures/figures_30_1.jpg", "caption": "Figure 1: Given just a few images of a novel subject (e.g., a dog named <bo>), Yo'LLaVA learns to facilitate textual/visual conversations centered around that subject.", "description": "This figure illustrates the core concept of Yo'LLaVA. Using only a few images of a new subject (in this case, a dog named <bo>), Yo'LLaVA learns to engage in both text-based and image-based conversations about that specific subject.  The figure shows examples of personalized text conversations (e.g., recommending a birthday gift for <bo>), and personalized visual conversations (e.g., identifying <bo> in a photograph).  This demonstrates Yo'LLaVA's ability to move beyond generic knowledge and understand and interact with user-specific concepts.", "section": "Introduction"}]