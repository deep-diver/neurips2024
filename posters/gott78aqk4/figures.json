[{"figure_path": "gOtt78AQk4/figures/figures_2_1.jpg", "caption": "Figure 1: The overall pipeline of our adaptive domain learning (ADL) algorithm. The network parameter \u03b80 is first initialized, then the small target domain training set will be used to train a model with parameter \u03b81. In the source domain adaptive learning stage, in iteration t, data from the source domain will be used to update the network parameter from \u03b8t\u22121 to \u03b8'. Then a dynamic validation set will judge whether the data is useful. If so, set \u03b8t = \u03b8' and repeat the process. If not, retrieve the network parameter from \u03b8' to \u03b8t\u22121. Finally, the target domain data will be used to fine-tune \u03b8' to \u03b8T.", "description": "This figure illustrates the three steps in the adaptive domain learning (ADL) pipeline proposed in the paper: 1) Target domain pretraining: a model is pre-trained using a small amount of data from the target domain; 2) Source domain adaptive learning: data from source domains are iteratively used to fine-tune the model, with a dynamic validation set determining whether each data batch improves performance on the target domain; and 3) Target domain fine-tuning: the model is fine-tuned using the remaining data from the target domain.", "section": "3 Method"}, {"figure_path": "gOtt78AQk4/figures/figures_5_1.jpg", "caption": "Figure 2: The error map of our method compares against state-of-the-art approaches. The first row is the result from the SIDD dataset, and the second row is the result from the SID dataset. We can see that our method is able to generate the image with smaller errors and less noise compared to previous work.", "description": "This figure showcases a comparison of error maps between the proposed method and two other state-of-the-art approaches (Blind2Unblind and Transfer Learning) on two different datasets (SIDD and SID).  The error maps visually represent the difference between the ground truth images and the denoised images produced by each method. The results show that the proposed method produces images with significantly fewer errors and less noise compared to the other two methods, indicating its superior performance in cross-domain image denoising.", "section": "4 Experiments"}, {"figure_path": "gOtt78AQk4/figures/figures_8_1.jpg", "caption": "Figure 3: The ablation study of the size of the validation set. Our dynamic validation set strategy can overcome the overfitting problem when the size of the target domain dataset is extremely small.", "description": "The figure shows the ablation study of the size of the validation set.  It compares the performance of the proposed adaptive domain learning (ADL) method against a baseline (fine-tuning) and variations of ADL.  Specifically, it shows the impact of removing different components of ADL (division of ISO, data shuffling, and dynamic validation set) on the PSNR across different sizes of the target domain dataset. The results demonstrate that the dynamic validation set is crucial for preventing overfitting, especially when only a small amount of target domain data is available. The graphs shows PSNR (dB) against the size of the target domain data for Sony and G4 sensors.", "section": "4.5 Ablation Study"}, {"figure_path": "gOtt78AQk4/figures/figures_13_1.jpg", "caption": "Figure 4: The heatmap of the training process of our model. The x-axis is the number of epochs, and the y-axis is the sensor. The value in each block ranging from 0-1 indicates the percentage that is judged to have contributed to the training of the target domain. (a) is the training process of sensor G4 in the SIDD dataset. (b) is the training process of sensor Sony in SID dataset.", "description": "This figure shows heatmaps visualizing the contribution of data from different source domains (sensors) to the training of the target domain model over epochs. Each cell's color intensity represents the percentage contribution of a specific sensor's data to the target domain's model at a particular epoch.  The heatmaps illustrate how the ADL algorithm selectively uses data from different sensors to effectively train the target domain's model, adapting to each sensor's unique characteristics and data distribution. (a) shows this for sensor G4 in the SIDD dataset, and (b) for sensor Sony in the SID dataset.", "section": "3.1 Adaptive Domain Learning Algorithm"}, {"figure_path": "gOtt78AQk4/figures/figures_15_1.jpg", "caption": "Figure 5: The error map of our method compares against state-of-the-art approaches. The first row is the result from the SIDD dataset, and the second row is the result from the SID dataset. We can see that our method is able to generate the image with smaller errors and less noise compared to previous work.", "description": "This figure compares the error maps of the proposed method against two state-of-the-art methods (Blind2Unblind [41] and Transfer learning [17]) on two datasets (SIDD and SID).  Each row shows results from a different dataset.  The error maps visually represent the difference between the denoised images produced by each method and the ground truth images. The brighter the color in an error map, the greater the error.  This visualization shows that the proposed method produces denoised images with significantly lower errors (less bright colors) compared to the other two methods.", "section": "4 Experiments"}, {"figure_path": "gOtt78AQk4/figures/figures_15_2.jpg", "caption": "Figure 6: The illustration of modulation strategy. The camera-specific metadata p and s (denote the phone code and ISO in our experiments) are transformed into a channel-wise scale \u03b2 and shift \u03b3 by MLP. Then the convolutional feature F in the network is multiplied by \u03b2 and added by \u03b3 and obtain F'. Note that our modulation strategy is more flexible and can provide more hyper information than the prior work [17, 13, 24, 33].", "description": "This figure illustrates the channel-wise modulation network architecture.  Sensor-specific metadata (sensor type and ISO) is input into a Multi-Layer Perceptron (MLP). The MLP outputs channel-wise scaling (\u03b3) and shifting (\u03b2) parameters. These parameters modulate the convolutional feature maps (F) to produce adjusted feature maps (F') that are better adapted to sensor-specific noise characteristics.", "section": "3.2 Channel-wise Modulation Network"}, {"figure_path": "gOtt78AQk4/figures/figures_16_1.jpg", "caption": "Figure 7: Comparison between our framework and the fine-tuning pipeline on image deblurring and image dehazing. Our method is able to generate an image that is much clearer. Zoom in for details.", "description": "This figure shows a qualitative comparison of the proposed method against a baseline fine-tuning approach on image deblurring and dehazing tasks.  The results suggest that the proposed method produces clearer and more detailed images compared to the fine-tuning method.  Two example images are shown for each task (deblurring and dehazing) showing input, fine-tuned, and proposed method results, respectively. The enhanced clarity in the output of the proposed method is visually evident.", "section": "A.4 Additional Qualitative Result"}, {"figure_path": "gOtt78AQk4/figures/figures_16_2.jpg", "caption": "Figure 3: The ablation study of the size of the validation set. Our dynamic validation set strategy can overcome the overfitting problem when the size of the target domain dataset is extremely small.", "description": "This figure shows the ablation study on the impact of the validation set size on the model performance. It compares the SSIM (structural similarity index metric) scores achieved by four different model training approaches with varying sizes of the target domain dataset and validation set: the proposed approach ('Ours'), the approach without diversity in ISO ('W/O div ISO'), the approach without shuffling data ('W/O shuffle'), and a simple fine-tuning approach.  The results clearly indicate that using a dynamic validation set, as proposed by the authors, is crucial in mitigating overfitting when limited target domain data is available.", "section": "4.5 Ablation Study"}]