[{"figure_path": "tGozvLTDY3/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of DG-SLAM. Given a series of RGB-D frames, we reconstruct the static high-fidelity 3D Gaussian map and optimize the camera pose represented with lie algebra \u03bei.", "description": "This figure provides a detailed overview of the DG-SLAM system. It illustrates the process flow, starting from the input RGB-D stream and culminating in the final 3D Gaussian map and optimized camera poses. Key components such as motion mask generation, hybrid pose optimization (coarse and fine stages), adaptive Gaussian point management, and mapping optimization are visually represented.  The figure highlights the interplay between different modules and their contributions to achieving robust and accurate SLAM in dynamic environments.", "section": "3 Approach"}, {"figure_path": "tGozvLTDY3/figures/figures_5_1.jpg", "caption": "Figure 2: Qualitative results of the motion mask generation. By fusing the semantic mask and depth warp mask, the final mask will be more precise.", "description": "This figure shows the qualitative results of the motion mask generation process.  It displays two rows, each depicting a different scene from the dataset. Each row has five columns: Input RGB, Input Depth, DepWarp Mask, Semantic Mask, and Final Mask.  The input RGB and depth images show the raw data. The DepWarp Mask highlights regions identified as moving based on depth differences between frames. The Semantic Mask shows the segmentation of moving objects from the input image. Finally, the Final Mask combines the depth and semantic masks, providing a more accurate representation of the moving parts of the scene. The fusion of depth information and semantic segmentation refines the mask to accurately identify and separate dynamic objects, improving the accuracy of the motion mask. This is crucial for robust pose estimation in dynamic environments.", "section": "3.2 Motion mask generation"}, {"figure_path": "tGozvLTDY3/figures/figures_6_1.jpg", "caption": "Figure 3: Visual comparison of the rendering image on the TUM and BONN datasets. Our results are more complete and accurate without the dynamic object floaters.", "description": "This figure compares the visual results of several state-of-the-art visual SLAM systems on the TUM and BONN datasets. It showcases the rendering quality of each system when dealing with dynamic scenes containing moving objects. The results highlight DG-SLAM's ability to produce more accurate and detailed 3D reconstructions by effectively filtering out dynamic objects. This leads to clearer and more visually appealing reconstructions compared to the other methods.", "section": "4 Experiments"}]