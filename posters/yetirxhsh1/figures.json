[{"figure_path": "YEtirXhsh1/figures/figures_1_1.jpg", "caption": "Figure 1: Several factors causing the inter-domain gap, such as the point density and object volume in NuScenes (Target) and Waymo (Source) datasets are illustrated with the fitted multivariate Gaussian distribution (left). The baseline [43] adaptation primarily detects objects having features near the mean of the distributions indicated by red circles. On the other hand, the proposed adaptation first groups objects and explores the target domain to reduce the false negative. The heatmaps show average recall (right). Objects with extreme sparsity are excluded for clear visualization.", "description": "This figure shows how the proposed method addresses the inter-domain gap in 3D object detection. The left panel displays the distributions of point density and object volume in the source (Waymo) and target (NuScenes) domains, highlighting the differences. The middle panel shows the recall of the baseline method, which struggles with objects outside the mean of the source domain distribution. The right panel shows how the proposed method improves recall by grouping objects and exploring the target domain, addressing the false negatives.  The heatmaps visualize the average recall for different object volumes and foreground densities.", "section": "1 Introduction"}, {"figure_path": "YEtirXhsh1/figures/figures_3_1.jpg", "caption": "Figure 2: Overall pipeline of our proposed method. During training, we extract foreground points from existing 3D box labels and feed them to the Object Descriptor Extraction module to acquire object descriptors. The descriptors are used for grouping & exploration and fed into the Group-Correlation module to generate RPN to detect objects similar to each group.", "description": "This figure illustrates the overall pipeline of the proposed Group Explorer Domain Adaptation (GroupEXP-DA) method for 3D object detection. It starts with a point cloud as input, then extracts foreground points from existing 3D bounding boxes. These points are fed into an Object Descriptor Extraction module, which generates object descriptors.  These descriptors are then used in a Grouping & Exploration module to group similar objects and refine these groupings.  The grouped features are then input into a Group-Region Correlation module, which generates region proposals for object detection. Finally, the proposed system utilizes a Regional Proposal Network (RPN) to generate 3D bounding boxes for detected objects. The figure clearly shows how the different components of the proposed method interact with each other, and highlights the modules that are used during training and those used during both training and testing.", "section": "3 Method"}, {"figure_path": "YEtirXhsh1/figures/figures_4_1.jpg", "caption": "Figure 3: Conceptual diagram comparing pseudo-label generation processes of (a) baseline [44, 43] with our (b) grouping followed by (c) the explorative update using pseudo-labels.", "description": "This figure illustrates the differences in pseudo-label generation between the baseline method and the proposed Group Explorer Domain Adaptation (GroupEXP-DA) method. (a) Baseline: Shows how the baseline method generates pseudo-labels without considering the distribution of objects in the target domain. This leads to an over-reliance on dominant object types. (b) Grouping: Illustrates how GroupEXP-DA groups similar objects together, creating a more balanced representation of the target domain. This helps in reducing the bias towards dominant object types. (c) Explorative Update: Shows how GroupEXP-DA further refines the grouping by using an explorative update strategy. This strategy aims to reduce false negatives in the target domain by redistributing labels according to the characteristics of the groups identified in the target domain.", "section": "3.3 Progressive Grouping"}, {"figure_path": "YEtirXhsh1/figures/figures_8_1.jpg", "caption": "Figure 5: Impact of ng on three adaptation scenarios in AP3D. Here W \u2192 K, N \u2192 K, and W \u2192 N refer to Waymo\u2192KITTI, NuScenes\u2192KITTI, and Waymo\u2192NuScenes adaptations.", "description": "This figure shows how the number of groups (ng) affects the 3D Average Precision (AP3D) performance across three different domain adaptation scenarios: Waymo to KITTI, NuScenes to KITTI, and Waymo to NuScenes.  The x-axis represents the number of groups, and the y-axis represents the AP3D.  Each line represents a different adaptation scenario, illustrating the optimal number of groups for achieving the best performance in each setting.", "section": "4.5 Ablations"}, {"figure_path": "YEtirXhsh1/figures/figures_8_2.jpg", "caption": "Figure 6: Comparison of DTS [8] (left), ours without explorative update (middle), and ours with explorative update (right) in Waymo \u2192 NuScenes with t-SNE visualization. Here, the foreground features are extracted using ground-truth boxes using Fbev for DTS and Fcbev for ours.", "description": "This figure uses t-SNE to visualize the foreground features extracted from the Waymo to NuScenes adaptation.  It compares the results of three methods: DTS [8] (a baseline), the proposed method without explorative update, and the proposed method with explorative update. The visualization shows how the explorative update in the proposed method improves the grouping of similar objects, reducing false negatives.", "section": "4.5 Ablations"}, {"figure_path": "YEtirXhsh1/figures/figures_13_1.jpg", "caption": "Figure 4: Qualitative comparison of Baseline ST3D [44], DTS [8] and ours on NuScenes to KITTI adaptation scenario (top) and Waymo to NuScenes(bottom) adaptation scenarios.", "description": "This figure compares the qualitative 3D detection results of three different methods: the baseline (ST3D), DTS, and the proposed GroupEXP-DA method. The top row shows the results for the NuScenes to KITTI adaptation, while the bottom row displays the results for the Waymo to NuScenes adaptation. Each column represents a different method, showing the ground truth, baseline results, DTS results, and the results of the proposed method. The visualizations highlight the differences in detection performance between the methods, particularly in terms of false positives and false negatives, demonstrating the superior performance of the proposed approach in handling inter-domain variations.", "section": "4.4.2 Qualitative Result"}]