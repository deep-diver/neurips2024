[{"figure_path": "ivCX2cjwcT/tables/tables_7_1.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results on the target domain (Office-31 dataset) using ResNet50 embeddings.  Different domain adaptation methods are compared: DANN, MDD, MCC, SDAT, ELS, and the proposed method. The results are shown for various source-target domain pairs (A-W, D-W, W-D, A-D, D-A, W-A), along with the average accuracy across all pairs. The table highlights the performance of the proposed method in comparison to existing state-of-the-art domain adaptation techniques.", "section": "6 Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_8_1.jpg", "caption": "Table 2: Classification accuracy on the target domain of office-Home dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results on the Office-Home dataset's target domain.  The ResNet50 embedding is used as input features.  Different domain adaptation methods (DANN, MDD, MCC, SDAT, ELS, and the proposed method) are compared, showing the average accuracy and standard deviation across various source-to-target domain transfer tasks (Ar\u2192Cl, Ar\u2192Pr, Ar\u2192Rw, Cl\u2192Ar, Cl\u2192Pr, Cl\u2192Rw, Pr\u2192Ar, Pr\u2192Cl, Pr\u2192Rw, Rw\u2192Ar, Rw\u2192Cl, Rw\u2192Pr).", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_8_2.jpg", "caption": "Table 3: Average precision P@1 of cross-language information retrieval.", "description": "This table presents the average precision at rank 1 (P@1) for cross-language information retrieval, comparing the proposed method against a baseline (Adv).  The results are broken down by language pairs (e.g., en-es for English to Spanish, es-en for Spanish to English), showing the performance using both nearest neighbor (NN) and cross-domain similarity local scaling (CSLS) methods.  The average P@1 scores across all language pairs are also provided.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_14_1.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results for domain adaptation experiments using the Office-31 dataset.  The ResNet50 embedding is used as the image feature. The table shows the accuracy of different domain adaptation methods (DANN, MDD, MCC, SDAT, ELS, and the proposed method) for various source-target domain pairs (A-W, D-W, W-D, A-D, D-A, W-A).  The results highlight the performance of each method on different cross-domain tasks, indicating its effectiveness in transferring knowledge from source to target domains.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_22_1.jpg", "caption": "Table 5: Shared component identification performance over different N.", "description": "This table presents the results of a numerical experiment conducted to validate Theorem 1 under different sample sizes. It shows the performance of Shared Component Analysis (SCA) and Canonical Correlation Analysis (CCA) in identifying shared components when the number of samples (N) varies from 100,000 to 20.  Two metrics are used to evaluate performance: the Frobenius norm of the difference between the estimated linear transformations of the two modalities, and a second metric that measures how well the private components are discarded in the low dimensional space.  The results indicate that the SCA method effectively identifies shared components even when the sample size is small, while CCA's performance is less robust.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_22_2.jpg", "caption": "Table 6: Shared component identification performance under imbalanced multi-modal data sizes.", "description": "This table presents the results of experiments evaluating the performance of shared component identification under different sample sizes in the two modalities.  The number of samples in the first modality is held constant at 100,000, while the number of samples in the second modality is varied (10,000, 1,000, 100, and 10). The table shows two key metrics: the Frobenius norm of the difference between the estimated shared components from the two modalities, and the average Frobenius norm of the private components across the two modalities. Smaller values for both metrics indicate better performance in identifying the shared components.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_23_1.jpg", "caption": "Table 7: Hyperparameter settings for domain adaptation.", "description": "This table lists the hyperparameters used in the domain adaptation experiments.  The optimizer used is Adam.  Learning rates are specified for the Q matrices, discriminator f, and the classifier, along with a decay rate for the classifier learning rate.  Lambda and gamma are parameters from the loss functions, the batch size, and number of epochs are also indicated. The discriminator's architecture is detailed, showing a 6-layer MLP with specified hidden units and activation functions (leaky ReLU and sigmoid). Finally, a label smoothing coefficient is given.", "section": "6 Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_23_2.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results for the Office-31 dataset's domain adaptation task using ResNet50 embeddings.  It compares the proposed method against several baselines (DANN, MDD, MCC, SDAT, ELS) across different source-target domain combinations (A-W, D-W, W-D, A-D, D-A, W-A). The accuracy is reported as a mean \u00b1 standard deviation, showcasing the performance of each method in transferring knowledge from the source domain to the target domain.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_24_1.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results for domain adaptation experiments using the Office-31 dataset and ResNet50 embeddings.  It compares the performance of the proposed method against several existing domain adaptation techniques (DANN, MDD, MCC, SDAT, ELS) across various source-target domain combinations (A-W, D-W, W-D, A-D, D-A, W-A). The accuracy is reported as a mean \u00b1 standard deviation, highlighting the performance variation across multiple trials.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_25_1.jpg", "caption": "Table 7: Hyperparameter settings for domain adaptation.", "description": "This table lists the hyperparameters used in the domain adaptation experiments.  It includes the optimizer used (Adam), learning rates for the Q matrices, the discriminator f, and the classifier, the batch size, number of epochs, the discriminator's architecture (6-layer MLP with specified hidden units), activation functions (Leaky ReLU and sigmoid), and a label smoothing coefficient.", "section": "6 Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_25_2.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results for the Office-31 dataset's domain adaptation task using ResNet50 embeddings.  It compares the performance of the proposed method against several baselines (DANN, MDD, MCC, SDAT, ELS) across different source-target domain combinations (A-W, D-W, W-D, A-D, D-A, W-A). The accuracy is presented as mean \u00b1 standard deviation, highlighting the performance variability and offering a comprehensive comparison of the proposed approach against established domain adaptation techniques.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/tables/tables_26_1.jpg", "caption": "Table 1: Classification accuracy on the target domain of office-31 dataset (ResNet50 embedding).", "description": "This table presents the classification accuracy results on the target domain (Office-31 dataset) using ResNet50 embeddings as features.  It compares the performance of the proposed method against several state-of-the-art domain adaptation techniques (DANN, MDD, MCC, SDAT, ELS). The results are shown for different source-target domain combinations (e.g., A-W represents Amazon to Webcam). The table demonstrates that the proposed approach achieves higher accuracy in most of the domain adaptation tasks compared to existing methods.", "section": "Numerical Validation"}]