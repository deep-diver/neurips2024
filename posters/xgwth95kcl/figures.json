[{"figure_path": "XgwTH95kCl/figures/figures_1_1.jpg", "caption": "Figure 1: A case of incorrect prediction by the traditional model with missing modalities. The pink and yellow areas indicate intra- and inter-modality missingness, respectively.", "description": "This figure shows an example of how missing modalities can lead to incorrect predictions in traditional multimodal sentiment analysis models. In the top example, all modalities (language, audio, and visual) are present, and the model correctly predicts a negative sentiment. In the bottom example, parts of the language and audio modalities, and some visual frames, are missing, causing the model to incorrectly predict a positive sentiment. The pink areas highlight intra-modality missingness (missing frames within a modality), while the yellow areas show inter-modality missingness (entire modalities missing).  This illustrates the challenge of handling incomplete data in multimodal sentiment analysis.", "section": "1 Introduction"}, {"figure_path": "XgwTH95kCl/figures/figures_2_1.jpg", "caption": "Figure 2: The structure of our HRLF, which consists of three core components: Fine-grained Representation Factorization (FRF) module, Hierarchical Mutual Information (HMI) maximization mechanism, and Hierarchical Adversarial Learning (HAL) mechanism.", "description": "This figure illustrates the architecture of the Hierarchical Representation Learning Framework (HRLF) for robust incomplete multimodal sentiment analysis.  It shows three main modules: Fine-grained Representation Factorization (FRF), which disentangles modality representations into sentiment-relevant and modality-specific parts; Hierarchical Mutual Information (HMI) maximization, which aligns multi-scale representations between teacher and student networks; and Hierarchical Adversarial Learning (HAL), which refines the latent distributions of these representations. The figure depicts the data flow during training (teacher branch and student branch learning together) and inference (only student branch).  The FRF module is central, showing how it processes both complete and incomplete samples (with intra- and inter-modality missing data), using intra- and inter-modality translations and reconstruction to extract sentiment information even with missing data.", "section": "3 Methodology"}, {"figure_path": "XgwTH95kCl/figures/figures_6_1.jpg", "caption": "Figure 3: Comparison results of intra-modality missingness on IEMOCAP. We report on the F1 score metric for the happy, sad, angry, and neutral categories.", "description": "This figure shows the performance of different models on the IEMOCAP dataset when facing intra-modality missingness. The x-axis represents the missing ratio (from 0 to 1), and the y-axis represents the F1 score for each of the four emotion categories (happy, sad, angry, and neutral).  The lines represent different models, showing how their performance degrades as the missing ratio increases.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "XgwTH95kCl/figures/figures_6_2.jpg", "caption": "Figure 3: Comparison results of intra-modality missingness on IEMOCAP. We report on the F1 score metric for the happy, sad, angry, and neutral categories.", "description": "This figure shows the performance of different models on the IEMOCAP dataset under varying levels of intra-modality missingness.  Intra-modality missingness refers to situations where some frames within a given modality (language, audio, or visual) are missing. The x-axis represents the missing ratio (from 0 to 1), and the y-axis shows the F1 score, a common metric for evaluating the accuracy of classification models. The results are broken down by emotion category (happy, sad, angry, neutral). This graph helps to visualize and understand the robustness of each model when facing incomplete data. HRLF, the proposed model, is highlighted in red.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "XgwTH95kCl/figures/figures_7_1.jpg", "caption": "Figure 5: Ablation results of intra-modality missingness case on the MOSI dataset.", "description": "This figure shows the ablation study results on the MOSI dataset for intra-modality missingness.  It compares the performance of the proposed HRLF model against versions where key components (Fine-grained Representation Factorization (FRF), Hierarchical Mutual Information (HMI) maximization, and Hierarchical Adversarial Learning (HAL)) have been removed. The x-axis represents the missing ratio (percentage of missing features), and the y-axis represents the F1 score.  The plot shows that removing any one of the three components significantly reduces the F1 score, demonstrating their importance to the overall performance of HRLF. The HRLF model consistently achieves the highest F1 score across all missing ratios.", "section": "4.4 Ablation Studies"}, {"figure_path": "XgwTH95kCl/figures/figures_9_1.jpg", "caption": "Figure 6: Visualization of representations from different methods with four emotion categories on the IEMOCAP testing set. The default testing conditions contain intra-modality missingness (i.e., missing rate p = 0.5 ) and inter-modality missingness (i.e., only the language modality is available).", "description": "This figure visualizes the representations learned by four different models (CubeMLP, TransM, GCNet, and HRLF) for four emotion categories on the IEMOCAP dataset. The visualization uses t-SNE to project the high-dimensional representations into a 2D space. The results show that HRLF produces more distinct and separable clusters for each emotion category, suggesting better performance in distinguishing emotions, especially under the condition of missing modalities.", "section": "4.5 Qualitative Analysis"}]