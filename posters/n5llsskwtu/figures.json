[{"figure_path": "n5lLSskwtu/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of evidential mixture machines", "description": "This figure illustrates the architecture of the Evidential Mixture Machines (EMM) model proposed in the paper.  The model consists of an encoder that processes input features, and two decoders that predict mixture coefficients and mixture components, respectively. The mixture coefficients are predicted using an evidential regression model, which provides uncertainty information. The mixture components model the correlations between labels. The model combines evidential uncertainty with predicted label embedding covariances for active sample selection.  The entire model is trained by minimizing an evidential loss and a soft margin loss.", "section": "1 Introduction"}, {"figure_path": "n5lLSskwtu/figures/figures_6_1.jpg", "caption": "Figure 2: Visualization of label composition in the synthetic dataset. For visualization we show the geometric clusters in 2D, while they are high dimensional Gaussians in practice.", "description": "This figure visualizes the composition of labels in a synthetic dataset used for experiments.  The dataset features input data points clustered in a high-dimensional feature space, represented here in a simplified 2D view.  The labels are categorized into geometric-based labels (reflecting cluster membership), non-geometric labels (independent of cluster structure), and labels of interest.  The labels of interest include a rare label (L1, present in only 5% of samples), highly correlated labels (L2 and L3, sharing similar features and often co-occurring), and a label (L4) derived from the logical combination of L2 and L3 (L4 = L2 \u222a L3). This controlled dataset allows for testing of the EMM model's ability to capture correlations between different types of labels.", "section": "4.1 Synthetic Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_7_1.jpg", "caption": "Figure 3: (a) A visualization of the labels clusters concerning L2, L3, and L4; (b) A visualization of the labels clusters concerning L1 with and without updating with proxy pseudo-counts. \u201cfixed\u201d is the original unsupervisedly trained \u00b5\u2081,L\u2081, \u201cupdated\u201d is an updated \u00b5\u2081,L\u2081(x\u2081) where \u03c0\u2081(x\u2081) = 0.83 meaning \u00b5\u2081,. is dominant, and \u201cirrelevant\u201d is an updated \u00b5\u2081,L\u2081(x\u2082) where \u03c0\u2081(x\u2082) = 0.18 meaning this cluster \u03bc\u2081,. does not contribute much to the prediction of x2.", "description": "This figure visualizes the label clusters learned by the EMM model.  Subfigure (a) shows clusters related to labels L2, L3, and L4, highlighting their correlations.  Subfigure (b) focuses on label L1 (a rare label), comparing the original cluster with updated clusters after incorporating proxy pseudo-counts.  The 'updated' cluster demonstrates the model's adaptation to new data, while the 'irrelevant' cluster shows how the model adjusts when a cluster is less relevant to a specific data point.", "section": "4.1 Synthetic Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_8_1.jpg", "caption": "Figure 4: Performances on real-world datasets (AU-ROC increases as we sample 5 rounds with 100 samples in each round)", "description": "This figure presents the results of experiments conducted on four real-world multi-label datasets (Delicious, Corel 5k, BibTex, and NUS-WIDE) to evaluate the performance of the proposed Evidential Mixture Machines (EMM) model against several baseline methods in an active learning setting.  The x-axis represents the active learning rounds (5 rounds with 100 samples added in each round), and the y-axis displays the micro-AUC (Area Under the ROC Curve), a common metric for evaluating multi-label classification performance.  Each line in the graph represents a different method: EMM (the proposed model), GP-B2M, MMC, Adaptive, CVIRS, and EMM-entropy (a variant of EMM using a simple entropy-based sampling strategy). The results show how the AU-ROC of each model improves over the 5 rounds of active learning, indicating the effectiveness of active learning and the comparative performance of the EMM model. The error bars represent the standard deviation of the results across multiple runs.", "section": "4 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_8_2.jpg", "caption": "Figure 5: Average precision improvement (API) for rare labels", "description": "This figure shows the average precision improvement (API) for the 50 rarest labels in four real-world multi-label datasets: Corel5k, Delicious, BibTex, and NUS-WIDE.  The x-axis represents the frequency of each label, and the y-axis shows the API, which is calculated as the percentage increase in average precision for the rare labels using the proposed EMM model compared to a baseline GP-B2M model.  Positive API values indicate improvement by EMM, while negative values indicate worse performance. The bars represent the API for each label, with error bars showing variability. The figure visually demonstrates the effectiveness of EMM in improving the prediction of rare labels across different datasets, particularly those with lower frequencies.", "section": "4.2 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_9_1.jpg", "caption": "Figure 4: Performances on real-world datasets (AU-ROC increases as we sample 5 rounds with 100 samples in each round)", "description": "This figure displays the performance comparison of EMM against other state-of-the-art multi-label active learning methods (GP-B2M, MMC, Adaptive, CVIRS) on four real-world datasets: Delicious, Corel5k, Bibtex, and NUS-WIDE.  The x-axis represents the number of AL rounds (5 rounds total, with 100 samples added per round). The y-axis shows the micro-averaged AUC (Area Under the ROC Curve), a common metric for evaluating the performance of multi-label classifiers. Each line represents a different algorithm, showing its AUC performance as more labeled samples are added via the active learning process.  The results demonstrate EMM's improved performance compared to the baselines across various datasets.", "section": "4 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_9_2.jpg", "caption": "Figure 4: Performances on real-world datasets (AU-ROC increases as we sample 5 rounds with 100 samples in each round)", "description": "This figure displays the performance of the EMM model and several baseline methods across four real-world multi-label datasets: Delicious, Corel 5k, BibTex, and NUS-WIDE.  The y-axis represents the AU-ROC score, a measure of the model's performance. The x-axis indicates the number of active learning rounds, with 100 samples added in each round. The lines represent different models: EMM, GP-B2M, MMC, Adaptive, CVIRS, and EMM-entropy (EMM using entropy-based sampling). The results show that EMM consistently outperforms the other methods across all four datasets. The error bars indicate standard deviation, suggesting the statistical significance of the findings.", "section": "4 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_15_1.jpg", "caption": "Figure 4: Performances on real-world datasets (AU-ROC increases as we sample 5 rounds with 100 samples in each round)", "description": "This figure presents the results of the active learning experiments on four real-world multi-label datasets (Delicious, Corel 5k, BibTex, and NUS-WIDE).  The AU-ROC (Area Under the Receiver Operating Characteristic curve) is plotted for each dataset across five rounds of active learning, with 100 samples selected in each round.  The graph shows the performance of the proposed EMM model compared to several baselines (GP-B2M, MMC, Adaptive, CVIRS, EMM-entropy).  The AU-ROC is used as a performance measure, showing how well the model classifies instances after each round of additional label acquisition. Higher values indicate better performance. The EMM model consistently performs competitively with or better than the other methods.", "section": "4 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_16_1.jpg", "caption": "Figure 7: Ablation study on balancing parameters", "description": "This figure presents ablation studies on the balancing parameters (\u03bb and \u03b7) used in the multi-source uncertainty-based sample selection strategy.  Different combinations of \u03bb and \u03b7 are tested to determine their impact on the active learning performance.  \u03bb weights the uncertainty from the weight coefficient predictor, and \u03b7 weights the uncertainty from the label prediction and proxy pseudo-count predictor. The results, presented as micro-AUC across several active learning rounds, illustrate how the choice of these parameters influences the overall active learning performance. The graph shows that a balance needs to be struck; excessively high values of \u03bb and \u03b7 lead to a drop in performance.", "section": "4.2 Real Data Experiments"}, {"figure_path": "n5lLSskwtu/figures/figures_16_2.jpg", "caption": "Figure 9: Additional ablation study on balancing parameters: different values", "description": "This figure displays the results of an ablation study on the balancing parameters (\u03bb and \u03b7) used in the active learning strategy of the EMM model.  It shows the micro-AUC scores across multiple rounds of active learning for two datasets (Corel 5k and BibTex). Different lines represent different combinations of \u03bb and \u03b7 values, demonstrating how the choice of these parameters impacts the model's performance.", "section": "D.3 Additional Ablation Study"}, {"figure_path": "n5lLSskwtu/figures/figures_17_1.jpg", "caption": "Figure 11: Additional ablation study on number of clusters K", "description": "This figure displays the results of an ablation study on the impact of varying the number of clusters (K) in the EMM model.  The micro-AUC metric is plotted against the number of active learning rounds for different values of K (3, 6, and 10). The plots show the performance on the Corel 5k and BibTex datasets, illustrating how the choice of K affects the model's performance in active learning scenarios. Error bars are included to indicate variability.", "section": "4.2 Real Data Experiments"}]