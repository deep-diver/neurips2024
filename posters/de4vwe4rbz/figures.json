[{"figure_path": "De4VWE4rbz/figures/figures_0_1.jpg", "caption": "Figure 1: The proposed HiCoM framework for streamable dynamic scene reconstruction achieves competitive rendering quality with significantly shorter training time, faster rendering speed, and substantially reduced storage and transmission requirements. The left figures show results of our HiCoM on N3DV [1] and Meet Room [2] datasets, where \u201cRes\u201d indicates video resolution. The right figure is tested on the N3DV [1] dataset, where the radius of the circle corresponds to the average storage per frame and the method in the top left corner demonstrates the best performance.", "description": "This figure showcases the performance of the HiCoM framework in comparison to other state-of-the-art methods for streamable dynamic scene reconstruction. The left panels display results on two different datasets (N3DV and Meet Room), highlighting the video resolution, training time, rendering speed, storage, and PSNR (Peak Signal-to-Noise Ratio) achieved by HiCoM.  The right panel presents a comparison of various methods based on their training time and average storage per frame (represented by circle size), with HiCoM demonstrating superior performance in both aspects.", "section": "Introduction"}, {"figure_path": "De4VWE4rbz/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of our HiCoM framework. We first construct a compact and robust initial 3DGS representation from the first frame of the video streams with the perturbation smoothing strategy (a). Then, we learn each subsequent frame based on the previous 3DGS with our proposed Hierarchical Coherent Motion mechanism (b) and Continual Refinement (c) with additional new Gaussians. This learning process continues until the final frame.", "description": "This figure illustrates the HiCoM framework's three main stages: 1. Initial 3DGS representation learning uses perturbation smoothing for a compact and robust starting point. 2. Hierarchical Coherent Motion efficiently learns motion across frames using a hierarchical approach, leveraging consistency within and between regions.  3. Continual Refinement refines the 3DGS with additional Gaussians and removes low-impact ones to maintain model compactness and accuracy, adapting to evolving scenes.  This process iteratively refines the model for each new frame.", "section": "4 Methodology"}, {"figure_path": "De4VWE4rbz/figures/figures_7_1.jpg", "caption": "Figure 3: Qualitative results of Coffee Martini scene. Frames shown are the 1st, 61st, 121st, 181st, 241st, and 300th from the test video. Red boxes highlight areas with significant temporal motions. Our method achieves temporal coherence more closely matching the ground truth (GT).", "description": "This figure compares the results of the proposed HiCoM method with those of 3DGStream and ground truth on the Coffee Martini scene. It shows six frames (1st, 61st, 121st, 181st, 241st, and 300th) from the test video. Red boxes highlight areas with significant temporal motion to illustrate the improved temporal coherence of HiCoM compared to 3DGStream and ground truth.", "section": "5.2 Experimental Results"}, {"figure_path": "De4VWE4rbz/figures/figures_13_1.jpg", "caption": "Figure 2: Illustration of our HiCoM framework. We first construct a compact and robust initial 3DGS representation from the first frame of the video streams with the perturbation smoothing strategy (a). Then, we learn each subsequent frame based on the previous 3DGS with our proposed Hierarchical Coherent Motion mechanism (b) and Continual Refinement (c) with additional new Gaussians. This learning process continues until the final frame.", "description": "This figure illustrates the HiCoM framework's workflow. It starts by creating a compact initial 3D Gaussian Splatting (3DGS) representation using perturbation smoothing.  Subsequent frames are processed iteratively. The Hierarchical Coherent Motion mechanism efficiently updates the 3DGS based on learned motion, and the Continual Refinement step adds and merges Gaussians to maintain accuracy. This iterative process continues until the entire video is processed.", "section": "4 Methodology"}, {"figure_path": "De4VWE4rbz/figures/figures_16_1.jpg", "caption": "Figure 5: Qualitative results of additional scenes from N3DV dataset. Frames shown are the 1st, 61st, 121st, 181st, 241st, and 300th from the test video. Red boxes highlight areas with significant temporal motions.", "description": "This figure presents a qualitative comparison of video frames generated by the proposed HiCoM method and the 3DGStream method against ground truth (GT) data for five different scenes from the N3DV dataset. The selected frames (1st, 61st, 121st, 181st, 241st, and 300th) showcase the temporal coherence and motion handling capabilities of each method. Red boxes highlight regions with significant temporal changes to facilitate visual comparison.", "section": "5.2 Experimental Results"}, {"figure_path": "De4VWE4rbz/figures/figures_17_1.jpg", "caption": "Figure 3: Qualitative results of Coffee Martini scene. Frames shown are the 1st, 61st, 121st, 181st, 241st, and 300th from the test video. Red boxes highlight areas with significant temporal motions. Our method achieves temporal coherence more closely matching the ground truth (GT).", "description": "This figure compares the visual quality of the Coffee Martini scene reconstruction from three methods: the proposed HiCoM, 3DGStream, and the ground truth. It shows six frames (1st, 61st, 121st, 181st, 241st, and 300th) from the test video. Red boxes highlight regions with significant dynamic motions, such as a person's head and hands, demonstrating HiCoM's improved temporal coherence and closer match to the ground truth compared to 3DGStream.", "section": "5.2 Experimental Results"}, {"figure_path": "De4VWE4rbz/figures/figures_17_2.jpg", "caption": "Figure 3: Qualitative results of Coffee Martini scene. Frames shown are the 1st, 61st, 121st, 181st, 241st, and 300th from the test video. Red boxes highlight areas with significant temporal motions. Our method achieves temporal coherence more closely matching the ground truth (GT).", "description": "This figure shows a qualitative comparison of the Coffee Martini scene reconstruction results between the proposed HiCoM method, the 3DGStream method, and the ground truth.  It displays six frames (1st, 61st, 121st, 181st, 241st, and 300th) from the video sequence. Red boxes highlight areas with significant motion to emphasize the temporal coherence achieved by HiCoM in comparison to 3DGStream.  The results demonstrate HiCoM's superior performance in capturing dynamic elements and maintaining temporal consistency.", "section": "5.2 Experimental Results"}, {"figure_path": "De4VWE4rbz/figures/figures_17_3.jpg", "caption": "Figure 3: Qualitative results of Coffee Martini scene. Frames shown are the 1<sup>st</sup>, 61<sup>st</sup>, 121<sup>st</sup>, 181<sup>st</sup>, 241<sup>st</sup>, and 300<sup>th</sup> from the test video. Red boxes highlight areas with significant temporal motions. Our method achieves temporal coherence more closely matching the ground truth (GT).", "description": "This figure compares the qualitative results of the Coffee Martini scene reconstruction using three different methods: ground truth (GT), 3DGStream, and the proposed HiCoM method. Six frames (1st, 61st, 121st, 181st, 241st, and 300th) from the test video are shown, highlighting areas with significant temporal motion using red boxes. The results demonstrate that the HiCoM method achieves better temporal coherence and more closely matches the ground truth compared to 3DGStream.", "section": "5.2 Experimental Results"}, {"figure_path": "De4VWE4rbz/figures/figures_18_1.jpg", "caption": "Figure 2: Illustration of our HiCoM framework. We first construct a compact and robust initial 3DGS representation from the first frame of the video streams with the perturbation smoothing strategy (a). Then, we learn each subsequent frame based on the previous 3DGS with our proposed Hierarchical Coherent Motion mechanism (b) and Continual Refinement (c) with additional new Gaussians. This learning process continues until the final frame.", "description": "This figure illustrates the HiCoM framework's three main stages: 1. Initial 3DGS representation learning using a perturbation smoothing strategy to obtain a compact and robust initial representation. 2. Hierarchical Coherent Motion, which leverages the non-uniform distribution and local consistency of 3D Gaussians to efficiently learn motion across frames. 3. Continual Refinement, which involves adding and merging Gaussians to maintain consistency with evolving scenes. The figure shows the workflow and data flow for each stage.", "section": "4 Methodology"}]