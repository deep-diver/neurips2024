[{"figure_path": "7xhwE7VH4S/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "The figure illustrates the QUEEN framework for online free-viewpoint video (FVV) streaming.  It shows how Gaussian attributes are updated incrementally at each time step by learning and compressing residuals between frames.  A quantization-sparsity framework is employed to efficiently compress these residuals.  Only dynamic Gaussians are rendered, which speeds up the training process. The different colored blocks in the diagram highlight the different stages of the process. ", "section": "3 QUEEN: Quantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_5_1.jpg", "caption": "Figure 2: Viewspace Gradient Difference. We use the difference of viewspace gradients between consecutive frames to identify dynamic scene content.", "description": "This figure illustrates the concept of Viewspace Gradient Difference used in QUEEN for adaptive training.  It shows how the difference in viewspace gradients between consecutive frames (t and t-1) is used to identify dynamic regions in the scene. A gradient vector is calculated representing the change. A threshold (td) is applied; differences above this threshold are considered dynamic and are used to selectively render only dynamic parts of the scene, improving training efficiency and focusing on the parts of the scene which have changed, ignoring static parts.", "section": "3.3 Viewspace Gradient Difference for Adaptive Training"}, {"figure_path": "7xhwE7VH4S/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative Results. A visualization of various scenes in the N3DV and Immersive datasets. PSNR (\u2191) values are shown. We include additional video results in the supplement.", "description": "This figure shows a qualitative comparison of the reconstruction quality of different methods on several scenes from the N3DV and Immersive datasets.  For each scene, the figure presents four images: the result from TeTriRF, the result from 3DGStream, the result from QUEEN, and the ground truth. The PSNR value for each reconstruction is displayed above the corresponding image, which allows for a quantitative comparison alongside the visual comparison of details in the reconstruction.", "section": "4 Experiments"}, {"figure_path": "7xhwE7VH4S/figures/figures_8_2.jpg", "caption": "Figure 4: Effect of Updating Appearance Attributes. QUEEN updates all Gaussian attributes, resulting in improved quality versus keeping appearance attributes fixed across a video.", "description": "This figure compares the visual quality of videos reconstructed using QUEEN with different settings for updating Gaussian attributes.  The \"Ground Truth\" shows the original video.  \"Update All Attributes\" shows the results when QUEEN updates all Gaussian attributes (position, scale, rotation, opacity, color) at each frame. This leads to the highest quality reconstruction (PSNR: 33.95 dB).  \"Fixed Opacity\" shows the results when only position, scale, rotation, and color are updated, while opacity remains fixed across the video.  The reconstruction quality is slightly lower (PSNR: 33.77 dB). \"Fixed Opacity + Color\" shows the results when only position and scale and rotation are updated while both opacity and color are fixed. This shows a further drop in reconstruction quality (PSNR: 33.34 dB). The red box highlights a region where the visual differences are most noticeable. The results demonstrate that updating all Gaussian attributes improves visual quality.", "section": "4.4 Ablations"}, {"figure_path": "7xhwE7VH4S/figures/figures_9_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure illustrates the QUEEN framework for online free-viewpoint video (FVV) streaming.  It shows how Gaussian attributes are updated incrementally at each time step, with residuals between consecutive frames being learned and compressed using a quantization and sparsity framework.  The figure highlights the key components: incremental attribute updates, quantization, sparsity, and adaptive masked training for efficiency. The adaptive rendering only processes dynamic Gaussians, leading to faster training times.", "section": "3 QUEEN: Quantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_9_2.jpg", "caption": "Figure 3: Qualitative Results. A visualization of various scenes in the N3DV and Immersive datasets. PSNR (\u2191) values are shown. We include additional video results in the supplement.", "description": "This figure shows a comparison of the reconstruction results of different methods (TeTriRF, 3DGStream, and QUEEN) against the ground truth for several scenes from the N3DV and Immersive datasets.  The PSNR values are displayed for each reconstruction, indicating the quality of the reconstruction.  The supplement contains additional videos showcasing the results.", "section": "4.3 Qualitative Comparisons"}, {"figure_path": "7xhwE7VH4S/figures/figures_17_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure illustrates the QUEEN framework for online free-viewpoint video (FVV) streaming. It shows how Gaussian attributes are updated incrementally at each time step by learning and compressing residuals between consecutive frames.  The framework uses a quantization-sparsity approach to compress the residuals and an adaptive masked training method to speed up training by rendering only dynamic Gaussians. ", "section": "3 QUEEN: Quantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_18_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure illustrates the QUEEN (QUantized Efficient ENcoding) framework for online free-viewpoint video (FVV) streaming.  It shows how Gaussian attributes are updated incrementally at each time step. The core of the method involves learning and compressing residuals between consecutive frames using a two-pronged approach: quantization and sparsity. Quantization compresses attributes, while sparsity focuses on positional residuals, dynamically adapting to scene changes for efficiency. Adaptive masked training is used to accelerate the process by rendering only the dynamic parts of the scene. This results in faster training times and smaller model sizes.", "section": "3 QUEEN: Quantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_19_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure illustrates the QUEEN framework for online free-viewpoint video (FVV) streaming.  It shows how Gaussian attributes are updated incrementally at each time step. The key components are: learning and compressing residuals between frames, quantizing attributes, sparsifying position residuals using a gating mechanism, and selectively rendering dynamic Gaussians for faster training.  The diagram visually depicts the flow of data and processes in the model.", "section": "3 QUEEN: QUantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_20_1.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure shows the overall architecture of the QUEEN framework for online free-viewpoint video (FVV) streaming.  It illustrates how the system incrementally updates Gaussian attributes at each time step by learning and compressing residuals between consecutive frames.  The process involves a quantization framework for attribute residuals, a sparsity framework for position residuals, and adaptive masked training to focus computation on dynamic scene content. This results in efficient compression and faster training and rendering.", "section": "3 QUEEN: Quantized Efficient Encoding for Streaming FVV"}, {"figure_path": "7xhwE7VH4S/figures/figures_20_2.jpg", "caption": "Figure 1: Overview of QUEEN for online FVV. We incrementally update Gaussian attributes at each time-step (gray block) by simultaneously learning and compressing residuals between consecutive time-steps via a quantization (orange block) and sparsity (yellow block) framework. We additionally render only the dynamic Gaussians for masked regions to achieve faster convergence (green block).", "description": "This figure shows a detailed overview of the QUEEN framework for online free-viewpoint video (FVV) streaming.  It illustrates how the system incrementally updates Gaussian attributes at each time step, leveraging a quantization and sparsity framework to compress residuals between frames. The system also selectively renders only dynamic Gaussians to speed up training and improve efficiency.", "section": "3 QUEEN: QUantized Efficient Encoding for Streaming FVV"}]