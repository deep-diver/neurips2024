[{"figure_path": "YfLzYczAo3/tables/tables_3_1.jpg", "caption": "Table 2: Optimizer Runtimes (s) on CIFAR-10 and ImageNet", "description": "This table shows the runtime in seconds for different optimizers on CIFAR-10 and ImageNet datasets.  It compares the runtime of CRONOS-AM to other popular optimizers like Adam, AdamW, SGD, Shampoo, and Yogi.  The results highlight that despite CRONOS-AM performing more computation, its runtime remains comparable to standard optimizers.", "section": "7 Experiments"}, {"figure_path": "YfLzYczAo3/tables/tables_7_1.jpg", "caption": "Table 1: Results for CIFAR-10 and ImageNet Datasets", "description": "The table compares the performance of CRONOS-AM against other optimizers (Adam, AdamW, Yogi, SGD, and Shampoo) on CIFAR-10 and ImageNet datasets for a binary classification task using a deep ReLU MLP.  For each optimizer, the table shows the range of peak validation accuracy achieved across different learning rates and the best learning rate found.  It highlights CRONOS-AM's consistent high performance and lack of sensitivity to hyperparameter tuning compared to other methods.", "section": "7 Experiments"}, {"figure_path": "YfLzYczAo3/tables/tables_8_1.jpg", "caption": "Table 2: Optimizer Runtimes (s) on CIFAR-10 and ImageNet", "description": "This table presents the runtime in seconds for various optimizers on the CIFAR-10 and ImageNet datasets.  It compares the time taken by CRONOS-AM against popular optimizers like Adam, AdamW, D-Adapted Adam, SGD, Shampoo, and Yogi. The table highlights the relative computational efficiency of the different optimizers.", "section": "7 Experiments"}, {"figure_path": "YfLzYczAo3/tables/tables_8_2.jpg", "caption": "Table 2: Optimizer Runtimes (s) on CIFAR-10 and ImageNet", "description": "This table presents the runtime in seconds for various optimizers on two datasets: CIFAR-10 and ImageNet.  The optimizers compared are CRONOS-AM, Adam, AdamW, D-Adapted Adam, SGD, Shampoo, and Yogi.  The table shows that CRONOS-AM, despite performing more work than some competitors, has comparable runtime. This highlights the efficiency of the CRONOS-AM algorithm.", "section": "7 Experiments"}, {"figure_path": "YfLzYczAo3/tables/tables_20_1.jpg", "caption": "Table 4: Validation accuracy achieved by CRONOS on IMDB, across three different settings, with multiple varying batches averaged across seeds.", "description": "This table presents the validation accuracy results obtained by the CRONOS algorithm on the IMDB dataset under three different experimental settings: IMDB-NFT (no fine-tuning), IMDB-FT (one epoch of fine-tuning with AdamW), and IMDB-DA (unsupervised domain adaptation).  The results represent averages across multiple batches and random seeds, providing a robust measure of the algorithm's performance under various conditions.  The IMDB-FT setting shows particularly high accuracy, likely due to the benefit of the initial fine-tuning step.", "section": "7.2 Natural Language Classification with CRONOS"}, {"figure_path": "YfLzYczAo3/tables/tables_22_1.jpg", "caption": "Table 5: Results for Fashion MNIST", "description": "This table presents the results of a multiclass classification experiment using a two-layer ReLU MLP with 64 neurons on the Fashion MNIST dataset.  It compares the performance of CRONOS against Adam, AdamW, SGD, Shampoo, and Yogi optimizers. The table shows the peak validation accuracy range achieved by each optimizer across a range of learning rates and the best learning rate found for each optimizer. Notably, CRONOS achieves the highest peak validation accuracy without requiring any hyperparameter tuning (learning rate).", "section": "F.7 Multiclass Classification Experiment"}]