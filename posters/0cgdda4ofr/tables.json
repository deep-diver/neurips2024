[{"figure_path": "0cgDDa4OFr/tables/tables_5_1.jpg", "caption": "Table 1: Numerical benchmark results for Sourcerer. We show the mean and standard deviation over five runs for differentiable simulators and surrogates of Sourcerer on the benchmark tasks, and compare to NEB. All approaches achieve C2ST accuracies close to 50%. For the Sliced-Wasserstein-based approach, the entropies of the estimated sources are substantially higher (bold) with the entropy regularization (\u03bb = 0.35 for TM, IK, SLCP, \u03bb = 0.062 for GM, gray line in Fig. 3).", "description": "This table presents a quantitative comparison of the proposed Sourcerer method against a state-of-the-art approach (NEB) for source distribution estimation.  The comparison is performed across four benchmark tasks, using both original differentiable simulators and learned surrogates.  The table shows the mean and standard deviation of C2ST accuracy (a measure of how well the estimated source distribution reproduces the observed data distribution) and the entropy of the estimated source distributions over five independent runs.  The results highlight Sourcerer's ability to achieve high entropy without sacrificing accuracy, especially when using entropy regularization.", "section": "3 Experiments"}, {"figure_path": "0cgDDa4OFr/tables/tables_7_1.jpg", "caption": "Table 1: Numerical benchmark results for Sourcerer. We show the mean and standard deviation over five runs for differentiable simulators and surrogates of Sourcerer on the benchmark tasks, and compare to NEB. All approaches achieve C2ST accuracies close to 50%. For the Sliced-Wasserstein-based approach, the entropies of the estimated sources are substantially higher (bold) with the entropy regularization (\u03bb = 0.35 for TM, IK, SLCP, \u03bb = 0.062 for GM, gray line in Fig. 3).", "description": "This table presents a quantitative comparison of the Sourcerer algorithm against the Neural Empirical Bayes (NEB) method across four benchmark tasks.  The table displays the mean and standard deviation of the C2ST accuracy (a measure of how well the estimated source distribution reproduces the observed data) and the entropy (a measure of uncertainty) of the estimated source distributions for both differentiable simulators and surrogate models.  The results highlight the ability of Sourcerer to achieve higher entropy without sacrificing accuracy, particularly when using entropy regularization.", "section": "3 Experiments"}, {"figure_path": "0cgDDa4OFr/tables/tables_20_1.jpg", "caption": "Table 1: Numerical benchmark results for Sourcerer. We show the mean and standard deviation over five runs for differentiable simulators and surrogates of Sourcerer on the benchmark tasks, and compare to NEB. All approaches achieve C2ST accuracies close to 50%. For the Sliced-Wasserstein-based approach, the entropies of the estimated sources are substantially higher (bold) with the entropy regularization (\u03bb = 0.35 for TM, IK, SLCP, \u03bb = 0.062 for GM, gray line in Fig. 3).", "description": "This table presents a quantitative comparison of Sourcerer's performance against Neural Empirical Bayes (NEB) across four benchmark tasks.  It shows the mean and standard deviation of C2ST accuracy (a measure of how well the simulations match the observations) and entropy (a measure of uncertainty) for both differentiable simulators and their learned surrogates, with and without entropy regularization.  The results highlight Sourcerer's ability to achieve high entropy without sacrificing simulation fidelity, especially when entropy regularization is used.", "section": "3 Experiments"}]