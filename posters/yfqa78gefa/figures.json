[{"figure_path": "YfQA78gEFA/figures/figures_1_1.jpg", "caption": "Figure 1: (a-b) Performance of POMO [38] on TSP100 against the attacker in [87]. The value in brackets denotes the number of trained models. We report the average optimality (opt.) gap over 1000 test instances. (c) Solution visualizations on an adversarial instance. These results reveal the vulnerability of existing neural methods to adversarial attacks, and the existence of undesirable trade-off between standard generalization (a) and adversarial robustness (b) in VRPs. Details of the attacker and experimental setups can be found in Appendix B.1 and Section 5, respectively.", "description": "This figure demonstrates the vulnerability of existing neural vehicle routing problem (VRP) methods to adversarial attacks and the trade-off between standard generalization and adversarial robustness.  Subfigure (a) shows the performance of the POMO method on clean TSP100 instances, while (b) shows the performance against adversarial attacks from [87].  Subfigure (c) visually compares solutions on adversarial instances.  The results highlight that the performance significantly deteriorates on instances with even slight perturbations.", "section": "Introduction"}, {"figure_path": "YfQA78gEFA/figures/figures_4_1.jpg", "caption": "Figure 2: The overview of CNF. Suppose we train M = 3 models (\u0398 = {\u03b8\u2081, \u03b8\u2082, \u03b8\u2083}) on a batch (B = 3) of clean instances. The inner maximization generates local (x<sup>(T)</sup><sub>i,j</sub>) and global (x<sup>(T)</sup><sub>i</sub>) adversarial instances within T steps. In the outer minimization, a neural router \u03b8<sub>r</sub> is jointly trained to distribute instances to the M models for training. Specifically, based on the logit matrix P predicted by the neural router, each model selects the instances with TopK-largest logits (e.g., red ones). The neural router is optimized to maximize the improvement of collaborative performance after each training step of \u03b8.", "description": "This figure illustrates the Collaborative Neural Framework (CNF).  The framework uses multiple models (\u03b8\u2081, \u03b8\u2082, \u03b8\u2083) to improve robustness against adversarial attacks. The inner maximization step generates adversarial instances (local and global), while the outer minimization step uses a neural router (\u03b8<sub>r</sub>) to distribute these instances among the models for more efficient and effective training. The neural router's goal is to improve the overall collaborative performance.", "section": "4 Collaborative Neural Framework"}, {"figure_path": "YfQA78gEFA/figures/figures_8_1.jpg", "caption": "Figure 3: Ablation studies on TSP100. The metrics of Uniform and Fixed Adv. are reported.", "description": "This figure presents the results of ablation studies conducted on the TSP100 dataset to analyze the impact of different components and hyperparameters within the Collaborative Neural Framework (CNF).  Subfigure (a) shows the effect of removing the global attack mechanism and the neural router. Subfigure (b) demonstrates how the number of trained models influences performance. Subfigure (c) compares various routing strategies for distributing training instances among the models, including those based on top-K selection and sampling.", "section": "5.2 Ablation Study"}, {"figure_path": "YfQA78gEFA/figures/figures_19_1.jpg", "caption": "Figure 4: An illustration of generated adversarial instances (i.e., the grey ones). (a) An adversarial instance generated by [87] on CVRP, where the triangle represents the depot node. A deeper color denotes a heavier node demand; (b) An adversarial instance generated by [20] on TSP, where the red nodes represent the newly inserted adversarial nodes; (c) An adversarial instance generated by [42] on asymmetric TSP, where the cost of an edge is in half.", "description": "This figure shows examples of adversarial instances generated by three different attack methods described in the paper.  Each subfigure illustrates a different attack strategy: (a) perturbing node attributes (node demands in this case) in a Capacitated Vehicle Routing Problem (CVRP) instance; (b) inserting new nodes into a Traveling Salesperson Problem (TSP) instance; (c) reducing the cost of edges in an Asymmetric TSP instance.  The gray nodes represent the adversarial instances, highlighting how these attacks modify the original clean instances.", "section": "B Attack Methods"}, {"figure_path": "YfQA78gEFA/figures/figures_24_1.jpg", "caption": "Figure 6: The generated TSP instances following the (a) Uniform distribution; (b) Rotation distribution; (c) Explosion distribution.", "description": "This figure shows three different distributions of nodes for generating TSP instances.  (a) Uniform distribution shows nodes randomly scattered across a square area. (b) Rotation distribution shows nodes clustered, as if rotated from a uniform distribution. (c) Explosion distribution shows nodes distributed with a void in the center, simulating an explosion effect. These different node distributions provide varying levels of complexity for testing the robustness of the neural VRP methods.", "section": "D.2 Data Generation"}, {"figure_path": "YfQA78gEFA/figures/figures_25_1.jpg", "caption": "Figure 3: Ablation studies on TSP100. The metrics of Uniform and Fixed Adv. are reported.", "description": "This figure presents the results of ablation studies conducted on the TSP100 dataset to analyze the impact of different components and hyperparameters within the Collaborative Neural Framework (CNF).  The ablation studies assess the model's performance on both clean instances ('Uniform') and adversarial instances ('Fixed Adv.').  Subplots (a), (b), and (c) show the effects of removing components (global attack and neural router), varying the number of models, and testing different instance routing strategies, respectively, demonstrating the importance of each component and design choice for improving robustness and generalization.", "section": "5.2 Ablation Study"}, {"figure_path": "YfQA78gEFA/figures/figures_26_1.jpg", "caption": "Figure 5: Left panel: Performance of each model \u03b8i \u2208 \u0398 in CNF (M = 3), and the overall collaboration performance of \u0398. Right panel: A demonstration (i.e., attention map) of the learned routing policy for \u03b80. The horizontal axis is the index of the training instance. Concretely, 0-2: clean instances x; 3-11: local adversarial instances ; 12-14: global adversarial instances x. The vertical axis is the epoch of the checkpoint. A deeper color represents a higher probability to be selected.", "description": "The left panel of the figure shows the performance of each individual model in the ensemble, compared to the overall performance of the ensemble. The right panel illustrates how the neural router assigns training instances to each of the models.  The color intensity indicates the probability that an instance will be assigned to a model for training.  This visualization helps to understand the learned routing policy and its impact on load balancing across the models.", "section": "5.2 Ablation Study"}]