[{"figure_path": "2n1Ysn1EDl/figures/figures_1_1.jpg", "caption": "Figure 1: Conceptual steps involved in the design of MambaLRP. (a) Take as a starting point a basic LRP procedure, equivalent to Gradient \u00d7 Input. (b) Analyze layers in which the conservation property is violated. (c) Rework the relevance propagation strategy at those layers to achieve conservation. The resulting MambaLRP method enables efficient and faithful explanations.", "description": "This figure illustrates the three main steps in the development of MambaLRP.  Panel (a) shows a basic LRP (Layer-wise Relevance Propagation) approach, which is analogous to multiplying the gradient by the input. Panel (b) demonstrates how the basic LRP method fails in some layers of the Mamba architecture, leading to a violation of the relevance conservation principle and ultimately, noisy explanations (shown via an example image). Panel (c) presents the improved MambaLRP method. This method corrects the issues identified in (b), ensuring that the relevance is conserved across all layers, leading to more accurate and faithful explanations.", "section": "1 Introduction"}, {"figure_path": "2n1Ysn1EDl/figures/figures_3_1.jpg", "caption": "Figure 2: Unfolded view of SSM, highlighting two subsets of nodes, the relevance of which should be conserved throughout relevance propagation.", "description": "This figure illustrates the unfolded selective state space sequence model (SSM) which is a crucial component of the Mamba architecture.  The figure highlights two groups of nodes (red and orange) to simplify the analysis of relevance propagation. The connections within these groups and between them highlight how the conservation property of relevance scores can be violated during the backpropagation process. The key idea is that within each group there are no connections between nodes, making the relevance calculation simpler. The figure serves as a visual aid to understand how the selective SSM works and how it can be addressed to achieve the conservation of relevance during the backward propagation used by the LRP method.", "section": "Relevance propagation in selective SSMs (S6)"}, {"figure_path": "2n1Ysn1EDl/figures/figures_5_1.jpg", "caption": "Figure 3: Conservation property. The x-axis represents the sum of relevance scores across the input features and the y-axis shows the network's output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation.", "description": "This figure compares the conservation property (i.e., whether the sum of relevance scores attributed to the input features equals the network's output score) between the Gradient \u00d7 Input (GI) baseline and the proposed MambaLRP method.  The plots show the sum of relevance scores (\u03a3_i R(x_i)) versus the output score (f) for Mamba-130M on SST-2 and Vim-S on ImageNet.  MambaLRP demonstrates significantly improved conservation compared to GI, indicating more faithful explanations.", "section": "5.1 Conservation property"}, {"figure_path": "2n1Ysn1EDl/figures/figures_6_1.jpg", "caption": "Figure 4: Explanations generated for a sentence of the SST-2 dataset. Shades of red represent words that positively influence the model's prediction. Conversely, shades of blue reflect negative contributions. The heatmaps of attention-based methods are constrained to non-negative values.", "description": "This figure compares the explanations generated by different methods for a single sentence from the SST-2 dataset.  The sentence expresses a negative sentiment.  The heatmaps show which words contribute positively (red) or negatively (blue) to the model's prediction.  Notice that MambaLRP's explanation is more sparse than the other methods, focusing on the most relevant words. Attention-based methods (AttnRoll and MambaAttr) only show positive contributions (no blue).", "section": "5.2 Qualitative evaluation"}, {"figure_path": "2n1Ysn1EDl/figures/figures_6_2.jpg", "caption": "Figure 5: Explanations produced by different explanation methods for images of the ImageNet dataset. AttnRoll and MambaAttr are limited to non-negative heatmap values.", "description": "This figure compares the explanations generated by various methods (Gradient \u00d7 Input, SmoothGrad, Integrated Gradients, Attention Rollout, MambaAttr, and MambaLRP) for three example images from the ImageNet dataset. Each row shows a different image and its corresponding explanations produced by each method, visually represented as heatmaps.  The heatmaps show which parts of the image the model focused on when making a prediction.  MambaAttr and Attention Rollout are constrained to positive values only, whereas the others allow for both positive and negative contributions, indicating whether a feature increased or decreased the model's confidence in its prediction. The color bar at the bottom indicates the scale of relevance scores. MambaLRP produces more focused explanations by highlighting key features.", "section": "5.2 Qualitative evaluation"}, {"figure_path": "2n1Ysn1EDl/figures/figures_8_1.jpg", "caption": "Figure 6: Analysis of the position of tokens relevant for next token generation. Left: Distribution of absolute position of the ten most relevant tokens for the prediction of the next word. Right: Long-range dependency between tokens of the input and the predicted next token (here: 1972).", "description": "This figure analyzes the positional relationship between tokens in the input sequence and the predicted next token, specifically focusing on long-range dependencies. The left panel shows the distribution of the positions of the ten most relevant tokens for predicting the next word, revealing that the most relevant tokens are not always those nearest in the sequence.  The right panel demonstrates a long-range dependency example, illustrating how the model uses information from a token far from the point of generation to generate the next token (the year 1972, in this case).", "section": "5.3 Quantitative evaluation"}, {"figure_path": "2n1Ysn1EDl/figures/figures_8_2.jpg", "caption": "Figure 3: Conservation property. The x-axis represents the sum of relevance scores across the input features and the y-axis shows the network's output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation.", "description": "This figure shows the conservation property of the proposed MambaLRP method against a baseline method (GI) on two different datasets (SST-2 and ImageNet).  The x-axis represents the sum of relevance scores for all input features, while the y-axis shows the model's output prediction score.  Ideally, the points should fall on the blue identity line (perfect conservation), indicating that the relevance scores perfectly match the output. The figure demonstrates that MambaLRP achieves significantly better conservation than the baseline method.", "section": "5.1 Conservation property"}, {"figure_path": "2n1Ysn1EDl/figures/figures_21_1.jpg", "caption": "Figure 5: Explanations produced by different explanation methods for images of the ImageNet dataset. AttnRoll and MambaAttr are limited to non-negative heatmap values.", "description": "This figure compares the visualizations generated by different explanation methods (Gradient \u00d7 Input, SmoothGrad, Integrated Gradients, Attention Rollout, MambaAttr, and MambaLRP) for several images from the ImageNet dataset. Each row represents a different image, and each column shows the heatmap generated by a specific method, highlighting the regions of the image that were deemed most relevant to the model's prediction.  Note that AttnRoll and MambaAttr are constrained to produce non-negative heatmaps, unlike the other methods which show both positive and negative contributions.", "section": "5.2 Qualitative evaluation"}, {"figure_path": "2n1Ysn1EDl/figures/figures_22_1.jpg", "caption": "Figure 3: Conservation property. The x-axis represents the sum of relevance scores across the input features and the y-axis shows the network's output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation.", "description": "This figure displays the results of a conservation property analysis for the GI baseline and the proposed MambaLRP.  The x-axis shows the sum of relevance scores across all input features, and the y-axis represents the network's output score. Each data point represents a single example. Points near the blue identity line (y=x) indicate that the conservation property is well preserved, meaning that the relevance scores accurately reflect the model's prediction. Deviations from the identity line signify a violation of this property.  The plot visually demonstrates how MambaLRP substantially improves the conservation property compared to the GI baseline. This is an important property for faithful explanations, as violations can lead to unreliable attributions.", "section": "5.1 Conservation property"}, {"figure_path": "2n1Ysn1EDl/figures/figures_23_1.jpg", "caption": "Figure 3: Conservation property. The x-axis represents the sum of relevance scores across the input features and the y-axis shows the network's output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation.", "description": "This figure compares the conservation property of two different methods: GI baseline and the proposed MambaLRP, for two models trained on different datasets. The x-axis represents the sum of relevance scores across input features, while the y-axis represents the network's output score.  Each point represents a single data point. Points closer to the blue identity line (perfect conservation) indicate better conservation of relevance scores. MambaLRP shows significantly better adherence to the conservation property than GI.", "section": "5.1 Conservation property"}]