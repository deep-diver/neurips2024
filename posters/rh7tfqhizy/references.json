{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces a high-resolution image synthesis method using latent diffusion models, which is foundational to the proposed YOUDREAM model."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper introduces a method for generating photorealistic images from text prompts using diffusion models and deep language understanding, which is a key component of YOUDREAM."}, {"fullname_first_author": "Ben Poole", "paper_title": "DreamFusion: Text-to-3D using 2D diffusion", "publication_date": "2022-00-00", "reason": "This paper introduces DreamFusion, a method for generating 3D models from text prompts using 2D diffusion models, which is a significant inspiration for YOUDREAM."}, {"fullname_first_author": "Ajay Jain", "paper_title": "Zero-shot text-guided object generation with dream fields", "publication_date": "2022-00-00", "reason": "This paper introduces a method for generating 3D objects from text prompts without requiring explicit 3D training data, addressing a key challenge in text-to-3D generation that YOUDREAM also tackles."}, {"fullname_first_author": "Yukun Huang", "paper_title": "DreamWaltz: Make a scene with complex 3D animatable avatars", "publication_date": "2024-00-00", "reason": "This paper introduces a method for generating complex 3D animatable avatars from text prompts, demonstrating the feasibility of generating high-quality 3D assets with detailed animations, which aligns with the goals of YOUDREAM."}]}