{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a visual language model that is highly relevant to the study of multi-modal contrastive learning and is cited multiple times in the current work."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, a foundational model for multi-modal contrastive learning, is introduced in this paper and is central to the current study."}, {"fullname_first_author": "Ting Chen", "paper_title": "A simple framework for contrastive learning of visual representations", "publication_date": "2020-07-01", "reason": "This paper introduces SimCLR, a highly influential method for contrastive learning, forming a key comparison point for multi-modal methods."}, {"fullname_first_author": "Sanjeev Arora", "paper_title": "A theoretical analysis of contrastive unsupervised representation learning", "publication_date": "2019-02-28", "reason": "This paper provides a foundational theoretical understanding of contrastive learning, which is extended in the current work to encompass multi-modal scenarios."}, {"fullname_first_author": "Zixin Wen", "paper_title": "Toward understanding the feature learning process of self-supervised contrastive learning", "publication_date": "2021-07-01", "reason": "This paper offers a theoretical analysis of single-modal contrastive learning, providing a crucial comparison point for the current study's multi-modal analysis."}]}