[{"figure_path": "nxumYwxJPB/figures/figures_7_1.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure displays the impact of the number of training epochs on a model's robustness against adversarial attacks.  Subplots (a) and (b) show the results for the Cora dataset, while (c) and (d) show the results for the CiteSeer dataset. Each subplot contains two graphs. The top graph shows the test accuracy (clean accuracy and accuracy under attack) as a function of the number of epochs. The bottom graph shows the success rate of adversarial attacks (difference between clean accuracy and attacked accuracy) as a function of the number of epochs. The results demonstrate a trade-off between clean accuracy and robustness: increasing the number of epochs initially improves clean accuracy but eventually leads to reduced robustness against attacks.", "section": "6.2 Effect Of Training Epochs"}, {"figure_path": "nxumYwxJPB/figures/figures_7_2.jpg", "caption": "Figure 2: Effect of the variance parameter on the model's robustness in the case of Gaussian Initialization on PGD [on Cora (a) and Citeseer (b)] and Mettack [on Cora (a) and Citeseer (b)].", "description": "This figure displays the results of experiments evaluating the impact of the variance parameter (\u03c3) of a Gaussian weight initialization on the model's robustness against adversarial attacks.  The experiments are performed using two different attack methods (PGD and Mettack) and on two different datasets (Cora and Citeseer).  Each sub-figure shows the success rate of the attacks for different perturbation budgets (10%, 20%, 30%, and 40%).  The x-axis represents the value of \u03c3, and the y-axis represents the success rate.  The figure shows that increasing the variance generally leads to a higher success rate for the attacks, indicating that the model is less robust when the initial weights have higher variance.", "section": "6.3 Effect Of Initial Weight Distribution"}, {"figure_path": "nxumYwxJPB/figures/figures_8_1.jpg", "caption": "Figure 3: Effect of the scaling parameter \u03b2 on the model's robustness in the case of Uniform (a-d) and Orthogonal (e-h) Initialization when subject to PGD and Mettack using Cora and CiteSeer.", "description": "This figure displays the impact of the scaling parameter (\u03b2) on the model's robustness against adversarial attacks when using uniform and orthogonal weight initializations. The plots show success rates (the discrepancy between clean and attacked accuracy) for various attack budgets (10%, 20%, 30%, 40%) on the Cora and Citeseer datasets for both PGD and Mettack attacks. Each subplot shows how success rate changes with the scaling parameter in a specific setting.", "section": "6.3 Effect Of Initial Weight Distribution"}, {"figure_path": "nxumYwxJPB/figures/figures_8_2.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure shows the impact of the number of training epochs on a GCN's robustness against adversarial attacks. Subplots (a) and (b) display the results for the Cora dataset, while subplots (c) and (d) present results for the CiteSeer dataset. Each subplot includes two graphs: one showing the clean and attacked accuracy, and the other showing the success rate (difference between clean and attacked accuracy). The results demonstrate a trade-off between clean accuracy and robustness, with increased epochs initially improving clean accuracy but eventually leading to higher vulnerability under attack.", "section": "6.2 Effect Of Training Epochs"}, {"figure_path": "nxumYwxJPB/figures/figures_16_1.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure displays the impact of the number of training epochs on a GCN's robustness against adversarial attacks using the Cora and CiteSeer datasets.  Subplots (a) and (b) show the results for Cora, while (c) and (d) present the results for CiteSeer. Each subplot includes two graphs: one showing the clean and attacked accuracy over epochs, and another showing the success rate (difference between clean and attacked accuracy) for different attack budgets (10%, 20%, 30%, 40%). The plots illustrate the trade-off between achieving high clean accuracy and maintaining robustness against attacks as the number of epochs increases.", "section": "6.2 Effect Of Training Epochs"}, {"figure_path": "nxumYwxJPB/figures/figures_17_1.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure displays the impact of varying the number of training epochs on the robustness of a graph convolutional network (GCN) against adversarial attacks. The plots show the trade-off between clean accuracy (performance on non-attacked data) and attacked accuracy (performance under adversarial attacks) as the number of epochs increases.  Subplots (a) and (b) present results for the Cora dataset, while subplots (c) and (d) show results for the CiteSeer dataset.  The plots illustrate that while clean accuracy generally improves with more epochs, attacked accuracy initially improves but then plateaus and eventually decreases, highlighting a trade-off between model performance and robustness to attacks.", "section": "6.2 Effect Of Training Epochs"}, {"figure_path": "nxumYwxJPB/figures/figures_18_1.jpg", "caption": "Figure 2: Effect of the variance parameter on the model's robustness in the case of Gaussian Initialization on PGD [on Cora (a) and Citeseer (b)] and Mettack [on Cora (a) and Citeseer (b)].", "description": "This figure displays the results of experiments conducted to assess the impact of the variance parameter (\u03c3) in a Gaussian weight initialization on model robustness against adversarial attacks.  Two adversarial attack methods were employed: PGD and Mettack. The experiments were performed on two datasets: Cora and CiteSeer. For each dataset and attack method, the success rate of the attack across varying values of \u03c3 is shown. The success rate represents the discrepancy between the clean and attacked accuracy for a given attack budget.  This visualizes the relationship between the variance in initial weights and the robustness of the model.", "section": "6.3 Effect Of Initial Weight Distribution"}, {"figure_path": "nxumYwxJPB/figures/figures_19_1.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure displays the impact of the number of training epochs on a GCN's robustness against adversarial attacks.  Subplots (a) and (b) show the results for the Cora dataset, while (c) and (d) show the results for the CiteSeer dataset. Each subplot includes two graphs: one showing clean and attacked accuracy and another showing the success rate of the attack (difference between clean and attacked accuracy). The results demonstrate a trade-off between clean accuracy and robustness as the number of epochs increases.  Initially, both clean and attacked accuracy rise, but at a certain point, continued training results in reduced robustness, despite improved clean accuracy. ", "section": "6.2 Effect Of Training Epochs"}, {"figure_path": "nxumYwxJPB/figures/figures_20_1.jpg", "caption": "Figure 1: Effect of training epochs on the model's robustness on Cora (a,b) and CiteSeer (c,d).", "description": "This figure displays the impact of the number of training epochs on a graph convolutional neural network's (GCN) robustness against adversarial attacks.  Subplots (a) and (b) show the results for the Cora dataset, while (c) and (d) show the results for the CiteSeer dataset. Each subplot contains two graphs. The top graph shows the clean accuracy and attacked accuracy as the number of epochs increases. The bottom graph shows the success rate of adversarial attacks, which is the difference between the clean accuracy and attacked accuracy,  for various attack budgets. The figure demonstrates that a trade-off exists between clean accuracy and robustness to adversarial attacks: Increasing the number of training epochs increases clean accuracy but decreases adversarial robustness.", "section": "6.2 Effect Of Training Epochs"}]