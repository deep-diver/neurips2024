{"references": [{"fullname_first_author": "Chuan Guo", "paper_title": "On calibration of modern neural networks", "publication_date": "2017-00-00", "reason": "This paper is foundational for the concept of confidence calibration in neural networks, which is a central theme of the target paper."}, {"fullname_first_author": "Mitchell Wortsman", "paper_title": "Robust fine-tuning of zero-shot models", "publication_date": "2022-00-00", "reason": "This paper introduces a robust fine-tuning method that improves the generalization capabilities of zero-shot models which the target paper builds upon."}, {"fullname_first_author": "Sachin Goyal", "paper_title": "Finetune like you pretrain: Improved finetuning of zero-shot vision models", "publication_date": "2023-00-00", "reason": "This paper provides a novel training framework for vision-language models, which the target paper extends for better calibration."}, {"fullname_first_author": "Ananya Kumar", "paper_title": "Fine-tuning can distort pretrained features and underperform out-of-distribution", "publication_date": "2022-00-00", "reason": "This paper highlights the issues of fine-tuning in the context of out-of-distribution generalization and motivates the need for robust fine-tuning methods, providing background for the target paper."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Benchmarking neural network robustness to common corruptions and perturbations", "publication_date": "2019-00-00", "reason": "This paper introduces a benchmark dataset for evaluating the robustness of neural networks against common corruptions, which is used for experimental validation in the target paper."}]}