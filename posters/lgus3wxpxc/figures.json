[{"figure_path": "LGus3wXPxc/figures/figures_1_1.jpg", "caption": "Figure 1: Difference between existing networks and our network. (a) Qualitative comparisons between HRNet (left) and our pose estimator (right). (b) t-SNE Visualization of keypoint-specific prompt embeddings. The different colours represent whether they are upper-body or lower-body joints, with red representing upper-body joints, blue representing lower-body joints and green representing the hip joints. From the figure, it is evident that while these embeddings maintain positional structure within the upper-body joints (the shoulders are placed above the elbows which are placed above the wrists, following the pose of a human standing normally) and the lower-body joints (knees placed above ankles), they fail to maintain positional structure between the upper-body and lower-body joints (elbows and wrists are placed below knees and ankles in the plot which does not follow the pose of a human being).", "description": "This figure compares the performance of existing pose estimation networks (HRNet) with the proposed TokenCLIPose method.  Panel (a) shows a qualitative comparison of pose estimations on ice hockey images; TokenCLIPose better captures the pose, particularly the position of the hockey stick (which is considered an 'extension' in the paper). Panel (b) visualizes t-SNE embeddings of keypoint prompts, highlighting how TokenCLIPose maintains better spatial relationships between upper and lower body keypoints than HRNet.", "section": "1 Introduction"}, {"figure_path": "LGus3wXPxc/figures/figures_3_1.jpg", "caption": "Figure 2: TokenCLIPose Architecture: We first incorporate an image encoder to extract multi-scale image features and coarse human keypoint locations \u00eef, and project them onto a joint multimodal embedding space obtaining image tokens Fvis and location tokens Floc respectively. Then, we leverage a text-based keypoint encoder to extract keypoint-specific text tokens Ftext from VLMs. These multimodal tokens are fed to a transformer decoder to capture spatial dependencies between them and predict all the 2D keypoints p\u00eed. The coarse human keypoint predictions and the final keypoint predictions are supervised using the RLE loss.", "description": "This figure illustrates the architecture of the TokenCLIPose model.  It shows a pipeline where an image encoder extracts features from the input image, which are then used to generate coarse human keypoint predictions. A text-based keypoint encoder extracts keypoint-specific text tokens (using Vision Language Models).  These features, along with the coarse keypoint locations, are combined and fed to a transformer decoder. This decoder outputs the final 2D keypoint predictions, which are then used with the RLE (Run-Length Encoding) loss to train the model. This shows how the model integrates both image and text information to improve the accuracy of keypoint predictions, particularly for those keypoints outside the bounding box.", "section": "3 Method"}, {"figure_path": "LGus3wXPxc/figures/figures_5_1.jpg", "caption": "Figure 3: Qualitative Comparison of TokenCLIPose with HRNet-W48 on our ice hockey dataset.", "description": "This figure shows a qualitative comparison of the proposed TokenCLIPose method against the HRNet-W48 baseline.  The comparison is performed on the ice hockey dataset, highlighting the superior performance of TokenCLIPose in accurately predicting keypoints, particularly in challenging scenarios such as those involving motion blur and occlusion. The images demonstrate that TokenCLIPose more accurately captures the pose of the hockey players and sticks even when there is significant motion blur and occlusion compared to the baseline HRNet-W48.", "section": "4.1 Ice Hockey Dataset"}, {"figure_path": "LGus3wXPxc/figures/figures_8_1.jpg", "caption": "Figure 4: Qualitative Results of our TokenCLIPose on the CrowdPose dataset.", "description": "This figure shows qualitative results of the TokenCLIPose model on the CrowdPose dataset. It visually demonstrates the model's ability to accurately predict human poses, even in challenging scenarios with significant occlusions and complex interactions. Each image shows a person in various poses and activities with the predicted keypoints overlaid in red. The accuracy and detail of the predicted keypoints highlight the effectiveness of the proposed TokenCLIPose approach in handling complex real-world scenarios.", "section": "4 Experiments"}, {"figure_path": "LGus3wXPxc/figures/figures_13_1.jpg", "caption": "Figure 5: Qualitative Results of TokenCLIPose for the extension pose estimation task on our ice hockey and Lacrosse datasets. We plot the pose of extensions outside the cropped image to understand how TokenCLIPose works.", "description": "This figure shows qualitative results of the proposed TokenCLIPose method for extension pose estimation on ice hockey and Lacrosse datasets.  The key aspect highlighted is the prediction of keypoints (pose) of the hockey stick and Lacrosse stick, which extend beyond the cropped image bounding box.  The images showcase the accuracy of the model in estimating the pose of these extensions, even when parts of the extension are outside the area typically used for pose estimation. This demonstrates the model's ability to effectively \u2018see beyond the crop\u2019 and leverage context even for unseen keypoints.", "section": "A.2 Qualitative Results"}]