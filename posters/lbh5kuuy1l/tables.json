[{"figure_path": "lBh5kuuY1L/tables/tables_6_1.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling.Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of three different models: DiffHopp, TurboHopp with different numbers of steps (50, 100, 150), and TurboHopp with metric-based sampling.  The comparison is based on several key molecular metrics including connectivity, diversity, novelty, QED (quantitative estimate of drug-likeness), synthetic accessibility (SA), and QVina binding affinity scores.  The table also shows the number of steps in the generation process and the average generation time for each model.  Bold numbers indicate the best result for a given metric, while underlined numbers represent the second-best.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_7_1.jpg", "caption": "Table 2: TurboHopp VS TurboHopp-RLCM with Metric Sampling. We optimized TurboHopp-100 with RLCM using 'docking score. Single optimization task is based on multiple reference protein-ligand complexes of the PDBBind testset; we do not optimize one protein at a time. To fully support faster parallel multi ligand - multi protein docking, we used AutoDockGPU instead of QVina2. Binding affinity scores surpassed reference docking scores without losing drug-likeliness and synthesizability.", "description": "This table compares the performance of the TurboHopp-100 model with and without reinforcement learning (RLCM) optimization, using metric-based sampling.  The RLCM-optimized model (TurboHoppRL-50metric) shows improved binding affinity (Vina score), while maintaining good drug-likeness (QED and SA scores) and connectivity. The faster inference speed of the consistency model enables the application of RLCM, which would be computationally expensive for diffusion models.", "section": "4.2 Performance Optimization using RLCM"}, {"figure_path": "lBh5kuuY1L/tables/tables_8_1.jpg", "caption": "Table 3: TurboHopp VS 3D-SBDD inpainting models. Results on models trained on CrossDocked. \"Inpainting\" refers to models using inpainting method explained in Algorithm 1. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of TurboHopp with two other diffusion-based 3D-SBDD inpainting models (TargetDiffInpainting and DecompDiffInpainting) on the CrossDocked dataset.  The metrics evaluated include Validity, Connectivity, Diversity, Novelty, QED, SA, QVina score, and generation Time.  The table highlights TurboHopp's superior performance in most metrics, particularly its significantly faster generation time.", "section": "4.3 Performance Comparison with diffusion-based 3D-SBDD inpainting models"}, {"figure_path": "lBh5kuuY1L/tables/tables_15_1.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling.Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of three different models: DiffHopp, TurboHopp with different numbers of generation steps (50, 100, 150), and TurboHopp with metric-based sampling.  The models were trained on the PDBBind dataset.  The table shows the mean and standard deviation of several key molecular metrics including connectivity, diversity, novelty, QED (quantitative estimate of drug-likeness), synthetic accessibility (SA), and QVina score (binding affinity). The number of generation steps and the average generation time are also shown.  Bold values indicate the best performance for each metric, while underlined values indicate the second-best performance.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_15_2.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling. Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table presents a comparison of the performance of three different models: DiffHopp, TurboHopp with various numbers of generation steps, and TurboHopp using metric-based sampling.  The performance is evaluated using several metrics: Connectivity, Diversity, Novelty, QED, SA, QVina score, and generation time.  The table highlights that TurboHopp, especially with metric-based sampling, significantly outperforms DiffHopp in terms of speed and various molecular properties.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_21_1.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling.Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of DiffHopp, TurboHopp with different numbers of steps (50, 100, 150), and TurboHopp using metric-based sampling.  The metrics evaluated include connectivity, diversity, novelty, QED, synthetic accessibility (SA), QVina score (binding affinity), number of steps in the generation process, and inference time.  The results highlight TurboHopp's superior efficiency and comparable or better quality compared to DiffHopp.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_21_2.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling.Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of three different models: DiffHopp, TurboHopp with different numbers of generation steps (50, 100, 150), and TurboHopp using metric-based sampling.  It shows the mean and standard deviation for several key molecular metrics (Connectivity, Diversity, Novelty, QED, SA, QVina score) and the average inference time.  The results highlight TurboHopp's superior speed and comparable or improved quality compared to DiffHopp.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_21_3.jpg", "caption": "Table 1: DiffHopp VS TurboHopp VS TurboHopp Metric Sampling.Results on models trained on PDBBind. Mean and standard deviation of the common molecular metrics for the molecules from the baseline models as well as time-step variations of our model. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of three different models: DiffHopp, TurboHopp with different numbers of generation steps (50, 100, 150), and TurboHopp using metric-based sampling.  The models are evaluated using several metrics: connectivity, diversity, novelty, QED, synthetic accessibility (SA), QVina score (binding affinity), number of generation steps, and the average inference time.  The results highlight that TurboHopp, particularly with metric-based sampling, achieves faster generation speeds and improved scores in various metrics compared to DiffHopp.", "section": "4.1 Performance Comparison with DDPM-based baseline"}, {"figure_path": "lBh5kuuY1L/tables/tables_21_4.jpg", "caption": "Table 7: Jensen-Shannon Divergence of Top 3 Torsion Angle Distributions (CrossDocked)", "description": "This table presents the Jensen-Shannon divergence values, which quantify the difference in the distributions of top three torsion angles between molecules generated by different models (TargetDiffInpainting, DecompDiffInpainting, and TurboHopp) and the reference molecules from the CrossDocked dataset. Lower divergence values indicate higher similarity between the generated and reference molecule distributions.  The torsion angles are characterized by four atom types (e.g., CCNC).", "section": "4.3 Performance Comparison with diffusion-based 3D-SBDD inpainting models"}, {"figure_path": "lBh5kuuY1L/tables/tables_21_5.jpg", "caption": "Table 3: TurboHopp VS 3D-SBDD inpainting models. Results on models trained on CrossDocked. \"Inpainting\" refers to models using inpainting method explained in Algorithm 1. \"metric\" refers that inference was done with metric-based sampling. QVina score (kcal/mol) refers to estimated binding affinity measured by QVina2. Time refers to average time (seconds) required to generate a batch of molecules per complex. Best metrics are in bold. 2nd best are underlined.", "description": "This table compares the performance of TurboHopp with two other diffusion-based 3D-SBDD inpainting models (TargetDiff and DecompDiff) on the CrossDocked dataset.  The comparison includes various metrics such as connectivity, diversity, novelty, QED, synthetic accessibility (SA), QVina score (binding affinity), and generation time. The table highlights TurboHopp's superior performance in many metrics, particularly its speed, while acknowledging that other models might excel in specific areas like diversity.", "section": "4.3 Performance Comparison with diffusion-based 3D-SBDD inpainting models"}]