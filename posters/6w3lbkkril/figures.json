[{"figure_path": "6W3LbkKriL/figures/figures_0_1.jpg", "caption": "Figure 1: LE3D reconstructs a 3DGS representation of a scene from a set of multi-view noisy RAW images. As shown on the left, LE3D features fast training and real-time rendering capabilities compared to RawNeRF [36]. Moreover, compared to RawGS (a 3DGS [25] we trained with RawNeRF's strategy), LE3D demonstrates superior noise resistance and the ability to represent HDR linear colors. The right side highlights the variety of real-time downstream tasks LE3D can perform, including (a) exposure variation, (b, d) changing White Balance (WB), (b) HDR rendering, and (c, d) refocus.", "description": "This figure showcases LE3D's capabilities in reconstructing 3D scenes from noisy RAW images.  The left side compares LE3D's training time and rendering speed to RawNeRF, highlighting LE3D's significant speed advantage. It also compares LE3D's noise resistance and HDR color representation to a baseline method (RawGS). The right side demonstrates LE3D's ability to perform real-time downstream tasks such as exposure variation, white balance adjustment, HDR rendering, and refocusing.", "section": "Abstract"}, {"figure_path": "6W3LbkKriL/figures/figures_3_1.jpg", "caption": "Figure 2: Pipeline of our proposed LE3D. 1) Using COLMAP to obtain the initial point cloud and camera poses. 2) Employing Cone Scatter Initialization to enrich the point clouds of distant scenes. 3) The standard 3DGS training, where we replace the original SH with our tiny Color MLP to represent the RAW linear color space. 4) We use RawNeRF's weighted L2 loss L (Eqn. (3)) as image-level supervision, and our proposed Rdist (Eqn. (8)) as well as Rnf (Eqn. (9)) as scene structure regularizations. In this context, fi, bi, and ci respectively represent the color feature, bias, and final rendered color of each gaussian i. Similarly, oi, ri, si, and pi denote the opacity, rotation, scale, and position of them.", "description": "This figure illustrates the pipeline of LE3D, highlighting key stages: 1) Initial point cloud and camera pose estimation using COLMAP; 2) Enhancement of distant points via Cone Scatter Initialization; 3) 3DGS training with a Color MLP replacing spherical harmonics; 4) Loss function incorporating RawNeRF's weighted L2 loss and novel regularizations (Rdist and Rnf) for scene structure refinement.  The figure also shows the representation of individual gaussians and the rendering process.", "section": "4 Proposed method"}, {"figure_path": "6W3LbkKriL/figures/figures_7_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the performance of LE3D against other reconstruction methods (LDR-NeRF, LDR-3DGS, RawNeRF, RawGS).  It shows example images from four different scenes, highlighting LE3D's superior ability to recover details, particularly in distant parts of the scene, and its noise resilience when compared to 3DGS-based methods. The comparison also demonstrates a massive speed improvement (3000-6000x) over NeRF-based methods.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_8_1.jpg", "caption": "Figure 4: Ablation studies on our purposed methods (Zoom-in for best view). CSI in (b) and Regs in (d) denote Cone Scatter Initialization and Regularizations, respectively. (e) shows the rendering result of LE3D w/ or w/o Color MLP in the early stages of training.", "description": "This figure demonstrates the ablation study of the proposed LE3D method. It shows the results of LE3D with and without each component of the proposed method (Cone Scatter Initialization (CSI), Color MLP, and Regularizations (Regs)). It also shows the results at an early stage (7k iterations) of training.", "section": "5.3 Ablation studies"}, {"figure_path": "6W3LbkKriL/figures/figures_8_2.jpg", "caption": "Figure 5: LE3D supports various applications. RawGS* in (d) denotes using LE3D's rendered image and RawGS's structure information as input for refocusing. (c, e) are the weighted depth rendered by LE3D and RawGS, respectively. (f) shows the same scene rendered by LE3D with different exposure settings. In (g), the \"\u2192\" denotes global tone-mapping, while the \"\u2192\" represents local tone-mapping.", "description": "This figure demonstrates various applications of the LE3D model, showcasing its capabilities in refocusing, exposure variation, and tone mapping.  Panel (a) shows the LE3D output, (b) shows the refocused image using LE3D, (c) depicts the depth map from LE3D.  For comparison, panels (d) and (e) illustrate the results of using RawGS for refocusing and its corresponding depth map. Panels (f) and (g) illustrate the capabilities of LE3D for exposure variation and combined global/local tone mapping, highlighting the flexibility and real-time processing potential.", "section": "More applications"}, {"figure_path": "6W3LbkKriL/figures/figures_15_1.jpg", "caption": "Figure 4: Ablation studies on our purposed methods (Zoom-in for best view). CSI in (b) and Regs in (d) denote Cone Scatter Initialization and Regularizations, respectively. (e) shows the rendering result of LE3D w/ or w/o Color MLP in the early stages of training.", "description": "This figure presents an ablation study of the proposed LE3D method. It shows the impact of different components of LE3D on the final rendering result.  The ablation study investigates the effect of removing the Cone Scatter Initialization (CSI), the Color MLP, and the depth distortion and near-far regularizations. The results demonstrate the importance of each component for achieving high-quality results.", "section": "5.3 Ablation studies"}, {"figure_path": "6W3LbkKriL/figures/figures_15_2.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the performance of LE3D against other novel view synthesis methods.  It showcases the superior noise resistance and detail preservation of LE3D, especially in distant scene elements.  The speed improvements are highlighted, with LE3D rendering up to 6000x faster than other methods.  The top row displays post-processed images for better comparison, while the bottom row shows the direct output images.", "section": "5. Experiments"}, {"figure_path": "6W3LbkKriL/figures/figures_16_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the performance of LE3D against other reconstruction methods (LDR-NeRF, LDR-3DGS, RawNeRF, and RawGS). The top row shows the training view images, including the post-processed linear brightness enhanced images and the device output images. The bottom row shows the reconstruction results from each method. LE3D outperforms other methods in terms of detail preservation in distant areas and noise resistance while achieving 3000-6000x faster rendering speed compared to NeRF-based methods.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_17_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the results of LE3D with other methods such as LDR-NeRF, LDR-3DGS, RawNeRF, and RawGS.  The top row shows the training view, which is a post-processed RAW image with linear brightness enhancement and the actual image output from the device. The bottom row shows the results of novel view synthesis. LE3D shows superior detail preservation in the distant scene, better noise resistance compared to 3DGS methods, and comparable performance to NeRF-based methods but with significantly higher rendering speed (3000x-6000x).", "section": "5.3 Ablation studies"}, {"figure_path": "6W3LbkKriL/figures/figures_17_2.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the visual results of LE3D against other reconstruction methods like RawNeRF, LDR-GS, HDR-GS, and LDR-NeRF. It demonstrates that LE3D shows improved detail in distant scenes and better noise resistance compared to 3DGS-based methods.  Furthermore, LE3D matches the performance of NeRF-based methods while achieving significantly faster rendering speeds.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_18_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the performance of LE3D with other reconstruction methods (LDR-NeRF, LDR-3DGS, RawNeRF, RawGS). The top row shows the training views, which consist of a preprocessed RAW image and the image directly output from the device. Subsequent rows compare the results from each method for the same scene, highlighting LE3D's superior detail preservation in distant views, noise resilience, and significant speed advantage over volumetric rendering-based approaches.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_20_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the results of LE3D with other reconstruction methods (LDR-NeRF, LDR-3DGS, RawNeRF, RawGS). It showcases the training view (post-processed RAW image and directly output image from device), rendered images and rendered depth maps for each method.  LE3D shows improvements over other methods in terms of detail preservation in distant scenes, noise resistance and rendering speed.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_21_1.jpg", "caption": "Figure 3: Visual comparison between LE3D and other reconstruction methods (Zoom-in for best view). The training view contains two parts: the post-processed RAW image with linear brightness enhancement (up) and the image directly output by the device (down). By comparison to the 3DGS-based method, LE3D recovers sharper details in the distant scene and is more resistant to noise. Additionally, compared to NeRF-based methods, LE3D achieves comparable results with 3000\u00d7-6000\u00d7 improvement in rendering speed.", "description": "This figure compares the visual results of LE3D with other reconstruction methods. The top row shows the training view, including both the preprocessed RAW images and images directly from the device. The following rows show results from LDR-NeRF, LDR-3DGS, RawNeRF, RawGS, and LE3D, demonstrating LE3D's superior detail preservation in distant scenes and noise resistance, along with its significantly faster rendering speed compared to other methods.", "section": "5.2 Datasets and comparisons"}, {"figure_path": "6W3LbkKriL/figures/figures_22_1.jpg", "caption": "Figure 14: Comparison between LE3D and other 3DGS-based methods (Zoom-in for best view). All the results are the direct output of each model, not being applied by affine alignment. The Ground Truth denotes the raw image averaged from a burst set with a slow shutter to perform denoising.", "description": "This figure compares the performance of LE3D against other 3DGS-based methods.  The comparison shows rendered images, rendered depth maps and a ground truth image (averaged from multiple exposures to reduce noise). LE3D demonstrates superior noise resistance and color representation, especially in low-light conditions.  It also provides smoother and more accurate depth map reconstruction.", "section": "More qualitative results"}]