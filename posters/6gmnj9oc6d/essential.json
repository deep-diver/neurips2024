{"importance": "This paper is crucial because **it challenges the common practice of using shuffling in DP-SGD**, offering a more accurate privacy analysis and a scalable solution for Poisson subsampling.  This impacts the reliability and utility of differentially private machine learning models, opening avenues for improved privacy-preserving algorithms and applications.", "summary": "This paper reveals significant privacy gaps in shuffling-based DP-SGD, proposes a scalable Poisson subsampling method, and demonstrates its superior utility for private model training.", "takeaways": ["Shuffling-based DP-SGD offers weaker privacy guarantees than previously assumed.", "A scalable method for implementing Poisson subsampling in DP-SGD is introduced and shown to be superior.", "New lower bounds on the privacy guarantee of ABLQ with shuffling provide a more accurate privacy analysis."], "tldr": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a common approach for training machine learning models while preserving data privacy.  A standard technique involves shuffling the data to improve privacy analysis, assuming the privacy is equivalent to Poisson subsampling. However, prior research has only compared these methods with a single epoch, leaving the multi-epoch analysis unclear. This also creates issues with the existing privacy analysis, as shuffling and Poisson subsampling often provide different privacy guarantees, especially when scaled for multiple epochs. This lack of precise privacy accounting impacts the utility and the reliability of DP-SGD algorithms.\nThis research directly addresses this problem by providing a comprehensive multi-epoch privacy analysis comparing shuffling and Poisson subsampling methods. **They introduce a novel, scalable approach to implement Poisson subsampling at scale**, overcoming previous limitations. **Their findings reveal substantial gaps in the privacy guarantees of shuffling-based DP-SGD when compared to Poisson subsampling**, particularly in multiple epochs. The study provides lower bounds on shuffling privacy that show how much lower the real privacy guarantees are than previously assumed. They support these findings with extensive experiments showing Poisson subsampling outperforms shuffling-based approaches in many practical scenarios. This work contributes significantly to the field by improving the accuracy of privacy accounting for DP-SGD and suggesting better methods for training private models.", "affiliation": "Google Research", "categories": {"main_category": "AI Theory", "sub_category": "Privacy"}, "podcast_path": "6gMnj9oc6d/podcast.wav"}