{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is extensively used and cited as a baseline in the current paper's experiments."}, {"fullname_first_author": "Chao Jia", "paper_title": "Scaling up visual and vision-language representation learning with noisy text supervision", "publication_date": "2021-07-01", "reason": "This paper introduces ALIGN, another significant vision-language model that is frequently used as a comparison model in the current paper's experiments."}, {"fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "publication_date": "2022-09-01", "reason": "This paper is highly influential in introducing and popularizing prompt tuning methods, a key technique discussed and implemented in the current paper."}, {"fullname_first_author": "Peng Gao", "paper_title": "CLIP-Adapter: Better vision-language models with feature adapters", "publication_date": "2023-01-01", "reason": "This paper proposes CLIP-Adapter, a prominent adapter-based method for efficient vision-language model tuning which is directly compared and improved upon in this paper."}, {"fullname_first_author": "Tao Yu", "paper_title": "Task residual for tuning vision-language models", "publication_date": "2023-06-01", "reason": "This paper introduces TaskRes, another important adapter-based method for efficient vision-language model tuning that is used as a baseline and further improved by the current paper."}]}