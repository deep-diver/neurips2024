[{"type": "text", "text": "Guided Trajectory Generation with Diffusion Models for Offline Model-based Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Taeyoung $\\mathbf{Y}\\mathbf{u}\\mathbf{n}^{1}$ Sujin $\\mathbf{Y}\\mathbf{u}\\mathbf{n}^{1}$ Jaewoo Lee1 Jinkyoo Park1,2 1Korea Advanced Institute of Science and Technology (KAIST) 2Omelet.ai {99yty, yunsj0625, jaewoo, jinkyoo.park}@kaist.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Optimizing complex and high-dimensional black-box functions is ubiquitous in science and engineering fields. Unfortunately, the online evaluation of these functions is restricted due to time and safety constraints in most cases. In offline model-based optimization (MBO), we aim to find a design that maximizes the target function using only a pre-existing offline dataset. While prior methods consider forward or inverse approaches to address the problem, these approaches are limited by conservatism and the difficulty of learning highly multi-modal mappings. Recently, there has been an emerging paradigm of learning to improve solutions with synthetic trajectories constructed from the offline dataset. In this paper, we introduce a novel conditional generative modeling approach to produce trajectories toward high-scoring regions. First, we construct synthetic trajectories toward high-scoring regions using the dataset while injecting locality bias for consistent improvement directions. Then, we train a conditional diffusion model to generate trajectories conditioned on their scores. Lastly, we sample multiple trajectories from the trained model with guidance to explore high-scoring regions beyond the dataset and select high-fidelity designs among generated trajectories with the proxy function. Extensive experiment results demonstrate that our method outperforms competitive baselines on Design-Bench and its practical variants. The code is publicly available in https://github.com/dbsxodud-11/GTG. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Optimizing complex and high-dimensional black-box functions is ubiquitous in science and engineering fields, including biological sequence design [1], materials discovery [2], and mechanical design [3, 4]. Traditional methods like Bayesian optimization have been developed to solve the problem by iteratively querying a black-box function. However, the online evaluation of the black-box function is restricted in most real-world situations due to time and safety constraints. ", "page_idx": 0}, {"type": "text", "text": "Fortunately, we often have access to a previously collected offline dataset. This problem setting is referred to as offline model-based optimization (MBO), and our objective is to find a design that maximizes a target function using solely an offline dataset [5]. As no online evaluation is available, a key challenge of MBO is the out-of-distribution (OOD) issue arising from limited data coverage. Suppose we train a proxy that predicts function values given input designs and naively apply a gradient-based optimizer based on the proxy to identify the optimal design. It would fall into sub-optimal results due to inaccurate predictions of the proxy in unseen regions. ", "page_idx": 0}, {"type": "text", "text": "To mitigate this issue, forward approaches mostly consider training a robust surrogate model against adversarial optimization of inputs and applying gradient-based maximization. Trabucco et al. [6] train a proxy with the regularization term to prevent overestimation on OOD designs. Fu and Levine [7] leverage normalized maximum likelihood estimator to handle uncertainty on unseen regions. ", "page_idx": 0}, {"type": "text", "text": "There are also several works that focus on fine-tuning the proxy for robustness on unexplored regions [8, 9, 10]. However, the generalization of the proxy outside of the dataset still remains challenging. ", "page_idx": 1}, {"type": "text", "text": "On the other hand, inverse approaches learn a mapping from function values to the input domain. Then, they generate high-scoring designs by querying the learned mapping with a high score. Prior approaches utilize expressive generative models to learn a mapping, such as variational autoencoders [11, 12], generative adversarial nets [13], autoregressive models [14] or diffusion models [15]. While these methods show promising results, they still suffer from the difficulty of learning highly unsmooth distributions and utilizing valuable information about the landscape of the black-box function. ", "page_idx": 1}, {"type": "text", "text": "Recently, a new perspective has emerged on tackling the MBO by learning to improve solutions with synthetic trajectories constructed from the dataset [16, 17]. These methods aim to generate a sequence of designs toward high-scoring regions. It seems more promising than learning an inverse mapping that generates only a single design, as we can utilize information from sequences of designs that can help better understand the landscape of the target function. However, there is still room for improvement in this perspective. First, prior approaches construct trajectories with simple heuristics, which may lead to generating trajectories with inconsistent directions of improvement. Furthermore, the sequential nature of autoregressive models may lead to error accumulation during sampling [18]. ", "page_idx": 1}, {"type": "text", "text": "To this end, we propose a novel conditional generative modeling approach to solve the MBO problem. Unlike prior inverse approaches, which generate a single design, we generate a sequence of designs toward high-scoring regions with guided sampling. Our method consists of four stages. First, we construct trajectories from the dataset while incorporating locality bias to distill the knowledge of the landscape of the target function into the generator. Then, we train a conditional diffusion model that generates the whole trajectory at once to bypass error accumulation and an auxiliary proxy. After training, we sample multiple trajectories conditioned on context data points and high score values. Finally, we select high-fidelity designs among generated trajectories by filtering with the proxy. ", "page_idx": 1}, {"type": "text", "text": "We empirically demonstrate that our method achieves superior performance on Design-Bench, a well-known benchmark for MBO with a variety of real-world tasks. Furthermore, we explore more practical settings, such as sparse or noisy datasets, verifying the generalizability of our method. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Problem setup ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In offline model-based optimization (MBO), we aim to find a design $\\mathbf{x}$ that maximizes the target black-box function $f$ . Unlike the typical black-box optimization setting, we can only access an offilne dataset $\\mathcal{D}$ , and online evaluations are unavailable. The problem setup can be described as follows: ", "page_idx": 1}, {"type": "text", "text": "where $\\mathbf{x}$ is a decision variable and $y=f(\\mathbf{x})$ is a target property we want to maximize. ", "page_idx": 1}, {"type": "text", "text": "2.2 Diffusion probabilistic models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Diffusion probabilistic models [19, 20] are a class of generative models that approximate the true distribution $q_{0}$ with a parametrized model of the form: $\\begin{array}{r}{p_{\\theta}(x_{0})=\\int p_{\\theta}(x_{0:T})d\\bar{x_{1:T}}}\\end{array}$ , where $x_{0}\\sim q_{0}$ and $x_{1},\\cdot\\cdot\\cdot,x_{T}$ are latents with the same dimensionality. The joint distribution $p_{\\theta}(x_{0:T})$ is called the reverse process, defined as a Markov chain starting from standard Gaussian $p_{T}(x_{T})=\\mathcal{N}(0,I)$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\np_{\\theta}(x_{0:T})=p_{T}(x_{T})\\prod_{t=1}^{T}p_{\\theta}(x_{t-1}|x_{t}),\\quad p_{\\theta}(x_{t-1}|x_{t})=\\mathcal{N}(\\mu_{\\theta}(x_{t},t),\\Sigma_{t})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $p_{\\theta}(x_{t-1}|x_{t})$ is parametrized Gaussian transition from timestep $t$ to $t-1$ . ", "page_idx": 1}, {"type": "text", "text": "We define a forward process, which is also fixed as a Markov chain that adds Gaussian noise to the data with the variance schedule $\\beta_{1},\\cdot\\cdot\\cdot,\\beta_{T}$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\nq(x_{1:T}|x_{0})=\\prod_{t=1}^{T}q(x_{t}|x_{t-1}),\\quad q(x_{t}|x_{t-1})=\\mathcal{N}(\\sqrt{1-\\beta_{t}}x_{t-1},\\beta_{t}I)\n$$", "text_format": "latex", "page_idx": 1}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/7398bf7df19ee97abf78cebb34ead8ed120ae50b1501e1001a9112f26d736acd.jpg", "table_caption": ["Step 1: Trajectory Construction "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 1: Overview of our method. Step 1: Construct trajectories from the dataset. Step 2: Train diffusion model and proxy. Step 3: Sample trajectories from the diffusion model with classifier-free guidance and context conditioning. Step 4: Select candidates for evaluation by flitering with proxy. ", "page_idx": 2}, {"type": "text", "text": "Training diffusion models can be performed by maximizing the variational lower bound on the log-likelihood $\\mathbb{E}_{q_{0}}\\left[\\log p_{\\theta}(x_{0})\\right]$ , which is equivalent to minimizing the following loss: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\theta)=\\mathbb{E}_{x_{0}\\sim q_{0},t\\sim U(1,T),\\epsilon\\sim\\mathcal{N}(0,I)}\\left[\\|\\epsilon-\\epsilon_{\\theta}(x_{t},t)\\|^{2}\\right]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\epsilon_{\\theta}(x_{t},t)$ is the parameterization suggested by [20], $\\begin{array}{r}{\\mu_{\\theta}(x_{t},t)=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(x_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha_{t}}}}\\epsilon_{\\theta}(x_{t},t)\\right)}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "For modeling conditional distribution $q(x|y)$ , we can use classifier-free guidance [21]. In classifierfree guidance, we train both a conditional $\\epsilon_{\\theta}(x_{t},y,t)$ and unconditional model $\\epsilon_{\\theta}(x_{t},t)$ with the following loss: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\theta)=\\mathbb{E}_{x_{0},y\\sim q(x,y),t\\sim U(1,T),\\epsilon\\sim\\mathcal{N}(0,I),\\beta\\sim\\mathtt{B e r n}(p)}\\left[\\|\\epsilon-\\epsilon_{\\theta}(x_{t},(1-\\beta)y+\\beta\\emptyset,t)\\|^{2}\\right]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "For sampling, we start from Gaussian noise $x_{T}$ and refine $x_{t}$ into $x_{t-1}$ with the perturbed noise from the learned model $\\epsilon_{\\theta}$ at each diffusion timestep $t$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{\\epsilon}(t)=\\epsilon_{\\theta}(x_{t},\\emptyset,t)+\\omega\\big(\\epsilon_{\\theta}(x_{t},y,t)-\\epsilon_{\\theta}(x_{t},\\emptyset,t)\\big)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\omega$ is a scalar value that controls the guidance scale. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we introduce GTG, Guided Trajectory Generation, a conditional generative modeling approach for solving MBO problem by learning to improve solutions using the offline dataset. We first construct trajectories towards high-scoring regions while incorporating locality bias for consistent improvement directions. Then, we train the conditional diffusion model to generate trajectories and a proxy model. Finally, we sample multiple trajectories using the diffusion model with guided sampling and fliter high-fidelity designs with the proxy. Figure 1 shows the overview of the proposed method. ", "page_idx": 2}, {"type": "text", "text": "3.1 Constructing trajectories ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We construct a set of trajectories $\\mathcal{D}_{\\mathrm{traj}}$ from the offilne dataset $\\mathcal{D}$ to gather information on learning to improve designs. In this paper, each trajectory $\\tau\\in\\mathcal{D}_{\\mathrm{traj}}$ is a set of $H$ input-output pairs and can be represented as a two-dimensional array: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\tau=\\left[\\begin{array}{l l l l}{\\mathbf{x}_{1}}&{\\mathbf{x}_{2}}&{\\cdot\\cdot\\cdot}&{\\mathbf{x}_{H}}\\\\ {y_{1}}&{y_{2}}&{\\cdot\\cdot\\cdot}&{y_{H}}\\end{array}\\right],\\quad(\\mathbf{x}_{h},y_{h})\\in\\mathcal{D}\\ \\forall h=1,\\cdot\\cdot\\cdot,H\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "While prior works construct trajectories via sorting heuristics or sampling from high-scoring regions, we focus on constructing trajectories that give us more valuable information for learning to improve designs towards higher scores. To achieve this, we develop a novel method to construct trajectories based on two desiderata. ", "page_idx": 2}, {"type": "text", "text": "First, the trajectory should be towards high-scoring regions while containing information on the landscape of the target black-box function. Second, the trajectories should be diverse and not converge to a single data point with the highest score of the dataset, as our objective is to discover high-scoring designs beyond the offline dataset by generalizing the knowledge of learning to improve solutions. ", "page_idx": 2}, {"type": "text", "text": "Algorithm 1 Trajectory construction procedure of GTG ", "page_idx": 3}, {"type": "text", "text": "Input: Offilne dataset $\\mathcal{D}$ , Trajectory length $H$ , Number of trajectories $N$ , initial percentile $p$ , number of nearest neighbors $K$ , and perturbation coefficient $\\epsilon$ . ", "page_idx": 3}, {"type": "text", "text": "Output: $\\mathcal{D}_{\\mathrm{traj}}$   \n1: Initialize trajectory dataset $\\mathcal{D}_{\\mathrm{traj}}\\longleftarrow\\emptyset$   \n2: for $n=1,\\cdot\\cdot\\cdot\\,,N$ do   \n3: Sample $\\left(\\mathbf{x}_{1},y_{1}\\right)$ from pth percentile of $\\mathcal{D}$ and initialize trajectory $\\tau\\longleftarrow\\{(\\mathbf{x}_{1},y_{1})\\}$   \n4: for $h=1,\\cdot\\cdot\\cdot,H-1$ do   \n5: Find $K$ nearest neighbors of $\\mathbf{x}_{h}$ whose score is higher than $\\operatorname*{max}\\{y_{1},\\cdots,y_{h}\\}-\\epsilon$   \n6: Sample $\\left(\\mathbf{x}_{h+1},y_{h+1}\\right)$ from the $K$ neighbors and update $\\tau\\longleftarrow\\tau\\cup\\left\\{\\left(\\mathbf{x}_{h+1},y_{h+1}\\right)\\right\\}$   \n7: end for   \n8: Update $\\mathcal{D}_{\\mathrm{traj}}\\longleftarrow\\mathcal{D}_{\\mathrm{traj}}\\cup\\{\\tau\\}$   \n9: end for ", "page_idx": 3}, {"type": "text", "text": "To this end, we introduce a novel strategy to construct trajectories from the dataset. We illustrate the procedure in Algorithm 1. For each trajectory, we first sample an initial data point $\\left(\\mathbf{x}_{1},y_{1}\\right)$ from a relatively low score distribution, pth percentile of $\\mathcal{D}$ . After initialization, we employ a local search strategy to select the next data point to generate a smooth trajectory toward high-scoring regions that contain the information on the landscape of the target function. Specifically, for each round $h$ , we find $K$ nearest neighbors of $\\mathbf{x}_{h}$ whose score is higher than $\\operatorname*{max}\\{y_{1},\\cdots,y_{h}\\}-\\epsilon$ , where $\\epsilon$ is a small, non-negative real number. By allowing small perturbations using $\\epsilon$ , we can prevent generated trajectories from converging a single maximum of the offilne dataset. Then, we sample $({\\bf x}_{h},y_{h})$ from the $K$ neighbors randomly to generate diverse trajectories. We repeat the procedure until constructing a trajectory of length $H$ . By moving towards high-scoring regions while staying in a local region, we can effectively guide the generator to learn diverse and consistent paths for improving solutions. ", "page_idx": 3}, {"type": "text", "text": "Note that identifying $K$ nearest neighbors of a data point whose values are above a certain threshold does not require substantial computational time compared to training and evaluation. We explain in more detail our trajectory construction procedure in Appendix B.1 ", "page_idx": 3}, {"type": "text", "text": "3.2 Training models ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Given our trajectory dataset $\\mathcal{D}_{\\mathrm{traj}}$ , our objective is to learn the conditional distribution of trajectories towards high-scoring regions. We choose diffusion models, which have a powerful capability to learn the distribution of complex and high-dimensional data [22, 23], to generate trajectories. Our objective is then transformed from searching high-scoring designs to maximizing the conditional likelihood of trajectories, which can be achieved by minimizing the loss in Equation (5): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\theta^{*}=\\arg\\operatorname*{max}_{\\theta}\\mathbb{E}_{\\tau\\sim\\mathcal{D}_{\\mathrm{traj}}}\\left[\\log p_{\\theta}(\\tau|y(\\tau))\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "gwehneerrea $\\begin{array}{r}{y(\\tau)=\\sum_{h=1}^{H}y_{h}}\\end{array}$ eissi gtnhse  isnustme aodf  osfc oa rseisn ignl et hdee stirganj,e cwtoer cy $\\tau$ .e fBfyic iternatilnyi ndgis tai ldl itfhfeu skinoon wmleoddgeel  toof the complex landscape of the target function into the diffusion model. ", "page_idx": 3}, {"type": "text", "text": "In addition, we also train a forward proxy $f_{\\phi}$ using the dataset $\\mathcal{D}$ . We can use the proxy to filter high-scoring designs from the trajectories generated by the trained diffusion model. ", "page_idx": 3}, {"type": "text", "text": "3.3 Sampling trajectories from the diffusion model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "After training, we sample trajectories with guided sampling. We use classifier-free guidance to generate trajectories. To be specific, we sample $\\tau$ from the diffusion model using Equation (6), where $y^{*}(\\tau)$ is the target conditioning value. Following prior works [13, 16], we assume that we know the maximum score $y^{\\ast}$ and set $y^{*}(\\tau)=\\alpha\\cdot(H\\bar{y^{*}})$ , where $\\alpha$ controls the exploration level of the generated trajectories. We discuss the role of $\\alpha$ in more detail in the subsequent section. ", "page_idx": 3}, {"type": "text", "text": "To fully utilize the expressive power of diffusion models, we introduce an additional strategy, context conditioning, during the sampling. We generate trajectory with diffusion model while inpainting the $C$ context data points of the trajectory with $\\tau_{\\mathrm{ctx}}$ , which is a subtrajectory sampled from $\\mathcal{D}_{\\mathrm{traj}}$ . By conditioning trajectories in different contexts, we can effectively explore diverse high-scoring regions. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 2 Sampling procedure of GTG ", "page_idx": 4}, {"type": "text", "text": "Input: Offilne dataset $\\mathcal{D}$ , Trajectory dataset $\\mathcal{D}_{\\mathrm{traj}}$ , Conditional diffusion model $p_{\\theta}$ , Proxy model $f_{\\phi}$ , Context length $C$ , Trajectory length $H$ , Evaluation budget $Q$ . ", "page_idx": 4}, {"type": "text", "text": "Output: $\\mathcal{D}_{\\mathrm{cand}}$   \n1: Initialize $\\mathcal{D}_{\\mathrm{cand}}\\leftarrow\\emptyset$   \n2: for $n=1,\\cdot\\cdot\\cdot\\,,N$ do   \n3: Initialize $\\tau^{(T)}\\sim\\mathcal{N}(0,I)$ and $\\tau_{\\mathrm{ctx}}\\sim\\mathcal{D}_{\\mathrm{traj}}$   \n4: for $t=T,\\cdots,1$ do   \n5: Compute $\\hat{\\epsilon}(t)$ using $p_{\\theta}(\\tau|y^{\\ast}(\\tau))$ by Equation (6) \u25b7Classifier-free Guidance   \n6: Compute $\\tau^{(t-1)}$ using $\\tau_{\\mathrm{ctx}}$ , $\\hat{\\epsilon}(t)$ and $\\tau^{(t)}$ by Equation (9) \u25b7Context-Conditioning   \n7: end for   \n8: Update $\\begin{array}{r}{\\mathcal{D}_{\\mathrm{cand}}\\longleftarrow\\mathcal{D}_{\\mathrm{cand}}\\cup\\left\\{\\mathbf{x}_{C+1},\\cdot\\cdot\\cdot\\cdot,\\mathbf{x}_{H}\\right\\}\\mathrm{from}\\,\\tau(=\\tau^{(0)})}\\end{array}$   \n9: end for   \n10: Set $\\mathcal{D}_{\\mathrm{cand}}$ as top- $\\cdot Q$ scoring samples filtering by $f_{\\phi}$ \u25b7Filtering ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/664ec70c29437494d448465c2634ad05b6efe505a7db69a6cfb1cad451676ac9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 2: (a) Trajectories constructed by BONET (blue) and PGS (green). (b) Diverse trajectories constructed by GTG (red). (c) Trajectories generated by trained diffusion model with guided sampling. Red dots indicate context data points, and blue dots represent generated data points. ", "page_idx": 4}, {"type": "text", "text": "Formally, for each denoising timestep $t$ , we refine $\\tau^{(t)}$ into $\\tau^{(t-1)}$ with the following procedure: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tau^{(t-1)}=\\mathbf{m}\\odot\\tau_{\\mathrm{ctx}}+(1-\\mathbf{m})\\odot\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\tau^{(t)}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\hat{\\epsilon}(t)\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{m}$ is the mask for the first $C$ context data points and $\\hat{\\epsilon}(t)$ is computed from the Equation (6). ", "page_idx": 4}, {"type": "text", "text": "3.4 Selecting candidates ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "After generating trajectories, we introduce flitering to select candidates for evaluation. In other words, we select top- $\\cdot Q$ samples in terms of the predicted score from the proxy. By filtering with the proxy, we can exploit the knowledge from the dataset to search high-scoring designs [13, 14, 24]. ", "page_idx": 4}, {"type": "text", "text": "4 Experimental evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we present the results of our experiments on various tasks. First, we analyze our method in a toy 2D experiment. Then, we present the results on the Design-Bench and its practical variants to verify the effectiveness of the method. We also conduct extensive analyses on various aspects to deepen our understanding of the proposed method. ", "page_idx": 4}, {"type": "text", "text": "4.1 Toy 2D experiment ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We first evaluate our method using a toy setting to analyze each component of our method thoroughly. We choose Branin, a synthetic 2D function with three distinct global maxima. Figure 2 shows the contour plot of the Branin function. The analytical form of the Branin function is as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nf(x_{1},x_{2})=-a\\left(x_{2}-b x_{1}^{2}+c x_{1}-r\\right)^{2}-s\\left(1-t\\right)\\cos(x_{1})-s\n$$", "text_format": "latex", "page_idx": 4}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/2da829cc03cc7253cdc004796da0be96798ccde7dd87394ddf68bdc4fbc01ff8.jpg", "table_caption": ["Table 1: Experiments on Design-Bench Tasks. We report max score $\\mathrm{100}^{t h}$ percentile) among $Q{=}128$ candidates. Blue denotes the best entry in the column, and Violet denotes the second best. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "$a=1$ $\\textstyle b={\\frac{5.1}{4\\pi^{2}}}$ $\\textstyle c={\\frac{5}{\\pi}}$ $s=10$ $\\textstyle t={\\frac{1}{8\\pi}}$ $(x_{1},x_{2})$ $[-5,10]\\times[0,15]$ ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For the MBO setting, we uniformly sample 5000 data points and remove the top $10\\%$ percentile to make the task more challenging. We construct trajectories with a length of 64 using our trajectory construction strategy and other strategies suggested by prior methods, BONET [16] and PGS [17]. ", "page_idx": 5}, {"type": "text", "text": "Figure 2a shows the trajectories generated from prior methods. As shown in the figure, we find that constructed trajectories show uncorrelated movements, which makes the model hard to capture knowledge on the landscape of the target black-box function. Unlike prior methods, our method constructs trajectories that improve the solution with the local movements, as illustrated in Figure 2b. Such trajectories help the diffusion model to learn how to improve solutions efficiently. We also find that trajectories do not converge into a single data point and toward diverse high-scoring regions via random sampling from $K$ neighbors and perturbations from $\\epsilon$ . ", "page_idx": 5}, {"type": "text", "text": "Figure 2c shows the trajectories generated by the trained diffusion model with context conditioning and classifier-free guidance. As shown in the figure, GTG can generalize the knowledge on improving solutions to find diverse high-scoring solutions. GTG achieves a maximum score of $-0.490\\pm0.070$ , which is near-optimal compared to the global optimum $\\left(-0.398\\right)$ and far beyond the maximum value of the dataset $(-6.031)$ . Please refer to Appendix A.1 for more details of the toy experiment. ", "page_idx": 5}, {"type": "text", "text": "4.2 Design-Bench tasks ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present the experiment results of our method on Design-Bench tasks [5]. We conduct experiments on two discrete tasks and three continuous tasks. For each task, we have an offline dataset from an unknown oracle function. We present the detailed task description below. ", "page_idx": 5}, {"type": "text", "text": "TFBind8 and TFBind10 [1]. We aim to find a DNA sequence of lengths 8 and 10 with maximum binding affinity with a particular transcription factor. ", "page_idx": 5}, {"type": "text", "text": "Superconductor [2]. We aim to design a chemical formula, represented by an 86-dimensional vector, for a superconducting material with a high critical temperature. ", "page_idx": 5}, {"type": "text", "text": "Ant and D\u2019Kitty Morphology [4, 25]. We aim to optimize the morphological structure of two simulated robots. The morphology parameters include size, orientation, and the location of the limbs. Ant has 60 continuous parameters, and D\u2019Kitty has 56 continuous parameters. ", "page_idx": 5}, {"type": "text", "text": "4.3 Baselines ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For baselines, we prepare four main categories to solve MBO problems. First, we compare our method with traditional methods widely used in online black-box optimization settings, such as BO-qEI [26], CMA-ES [27], REINFORCE [28], and Gradient Ascent. ", "page_idx": 5}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/49b91a79561dea0021e4cc15da37983ba0aa317c7569a2b09a83c7cce709a3a5.jpg", "table_caption": ["Table 2: Experiments on Sparse Datasets. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "The second category comprises recently proposed forward approaches, including COMs [6], NEMO [7], RoMA [8], BDI [24], and ICT [9]. The third category encompasses inverse approaches, and we select CbAS [11], MINs [13], and DDOM [15] as our baselines. Finally, we also compare with baselines which construct synthetic trajectories and generalize the knowledge of learning to improve solutions, BONET [16] and PGS [17]. ", "page_idx": 6}, {"type": "text", "text": "4.4 Evaluation metrics ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For evaluation, we follow the protocol of prior works. We identify $Q=128$ designs selected by the algorithm and report a normalized score of $100^{t h}$ percentile design. For all algorithms, we run experiments over 8 different seeds and report mean and standard errors. ", "page_idx": 6}, {"type": "text", "text": "To evaluate our method, we construct trajectories of length $H=64$ and train a conditional diffusion model for each task. After training, we sample $N=128$ trajectories conditioning on $C=32$ context data points and setting $\\alpha=0.8$ across all tasks. Finally, we fliter top-128 candidates among generated designs with the predicted score from the proxy for evaluation. ", "page_idx": 6}, {"type": "text", "text": "4.5 Main results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "As shown in the Table 1, GTG achieves an average rank of 1.6, the best among all competitive baselines. It performs best on two tasks and is runner-up on three tasks, demonstrating superior performance across different tasks. We observe that GTG generally surpasses forward approaches, which struggle to fall into OOD designs, especially in high-dimensional settings. We also observe that our method outperforms inverse approaches, including DDOM, which also utilizes a diffusion model. It demonstrates that generating trajectories towards high-scoring regions can be more effective than generating a single design, as we can distill the knowledge of the landscape of the target function into the generator. Our method achieves higher performance compared to BONET, which also generates trajectories. It indicates that our novel trajectory construction strategy effectively guides the diffusion model to explore diverse paths toward high-scoring regions. ", "page_idx": 6}, {"type": "text", "text": "4.6 Practical variants of Design-Bench tasks ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we present experiment results in a more practical setting of Design-Bench tasks. While Design-Bench assumes a large, unbiased offilne dataset containing thousands of data points for the training model, such a setting is impractical in most cases. Therefore, we prepare two additional practical settings, sparse and noisy datasets, to verify the robustness of our method in such extreme cases. In a sparse setting, we only provide $x\\%$ of the original dataset for training. For the noisy setting, we add $x\\%$ of standard Gaussian noise to the normalized score values. We choose recent papers published after 2022, BDI, ICT, DDOM, and BONET for primary baselines. Please refer to Appendix A.2 for detailed experiment settings and Appendix D.5 for results with more baselines. ", "page_idx": 6}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/aba10e489e2cdfcac66274b6ee2bd68b0507e686dcd1cedc93c995e78a26404a.jpg", "table_caption": ["Table 4: Ablation study on trajectory construction strategy. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/7f56d4cce4f2a9388507f4cf553826d7df8ec1a0612e70ff77c97d433b07623f.jpg", "table_caption": ["Table 5: Ablation study on sampling procedure of GTG. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 2 shows the results of our method and recent baselines in sparse datasets. The table shows that our method mostly outperforms other baselines even in sparse datasets, demonstrating the superiority of exploiting knowledge of the target function by constructing diverse trajectories from the dataset. Table 3 reports the experiment results on the noisy settings. We find that even with $50\\%$ of noise, our method can find relatively high-scoring designs, demonstrating its robustness in practical settings. ", "page_idx": 7}, {"type": "text", "text": "5 Additional analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we carefully analyze the effectiveness of each component in our method. ", "page_idx": 7}, {"type": "text", "text": "Ablation on trajectory construction. We propose a novel trajectory construction strategy by incorporating locality bias. To verify the effectiveness of the strategy, we compare our strategy with prior approaches, SORT-SAMPLE and Top- $\\boldsymbol{p}$ Percentile, suggested by BONET and PGS, respectively. Table 4 shows that our strategy outperforms prior strategies across various tasks. We conduct additional analysis on trajectory construction strategies in Appendix D.1. ", "page_idx": 7}, {"type": "text", "text": "Ablation on sampling procedure. We analyze the effectiveness of strategies we introduced during the sampling procedure, namely context conditioning (CC), classified-free guidance (CF), and flitering (F). Across various tasks, it is evident that all components are crucial for improving performance as demonstrated in Table 5. We conduct further analysis on sampling strategies in Appendix D.2. ", "page_idx": 7}, {"type": "text", "text": "Hyperparameter sensitivity. We also conduct experiments on the effect of various hyperparameters we introduced in this paper. We first train a conditional diffusion model with various lengths $(H)$ . As shown in Figure 3a, increasing $H$ leads to achieving higher performance. We also conduct experiments by varying the number of contexts $(C)$ and the exploration level $(\\alpha)$ . Figure 3b shows that $C=32$ achieves superior performance while conditioning with too many contexts degrades performance. Finally, Figure 3b shows a strong correlation between $\\alpha$ and the score, demonstrating the effectiveness of guided sampling. We conduct further analysis on hyperparameters in Appendix D.2. ", "page_idx": 7}, {"type": "text", "text": "Varying evaluation budget. We provide experiment results with a small number of evaluation budgets $(Q)$ . As shown in Figure 4, we generally outperform most baselines even with a relatively low evaluation budget. ", "page_idx": 7}, {"type": "text", "text": "Assumption on optimal score. We assume that the optimal value $y^{\\ast}$ is known, following prior works [13, 16]. We conduct experiments by relaxing the aforementioned assumption in Appendix D.2 and find that GTG can achieve comparable performance even without knowing $y^{\\ast}$ . ", "page_idx": 7}, {"type": "text", "text": "Effect of unsupervised pretraining. It might be beneficial to pretrain the diffusion model when we have a large-scale unlabeled dataset and a few designs of labeled points [29]. To this end, we discuss the effectiveness of pretraining diffusion models with unlabeled datasets in Appendix D.3. ", "page_idx": 7}, {"type": "text", "text": "Time complexity of sampling procedure. We also conduct analysis on the time complexity of the sampling procedure of our method in Appendix D.4. Experiment results demonstrate that we can decrease the number of denoising timesteps even one-tenth with minimal loss in performance. ", "page_idx": 7}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/c654173d67f2e833d1d927bed363409587fd362e7569fa078df47013b835c2a7.jpg", "img_caption": ["Figure 3: Ablation on hyperparameters of GTG. Experiments are conducted on D\u2019Kitty task. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/250d82a5d1265a4786c0a334c2ce40e1abdfc32539debffee2bd723fbd6680b0.jpg", "img_caption": ["Figure 4: Ablation on varying evaluation budget $Q$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "6 Related works ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "6.1 Offline model-based optimization ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In offline MBO, generalization outside the offline dataset is crucial for success. While there have been attempts to train a robust surrogate model to achieve accurate predictions on unseen regions [8, 9, 10], effectively exploring high-scoring regions remains challenging. ", "page_idx": 8}, {"type": "text", "text": "Recently, a new perspective on solving the MBO problem has emerged by learning to improve solutions from synthetic trajectories and generalizing the knowledge to find designs beyond the dataset [16, 17]. BONET [16] trains an autoregressive model to generate optimal trajectories conditioned on a low regret budget. PGS [17] trains RL policy with trajectories consisting of high-scoring designs to roll out optimal trajectories. MATCH-OPT [30] also constructs monotonic trajectories and matches the gradient field with the proxy. GTG falls under this category but adopts a unique approach to constructing trajectories with local search and utilizing diffusion models to enhance performance. ", "page_idx": 8}, {"type": "text", "text": "6.2 Generative models for decision making ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Generative models have emerged as a powerful tool for decision-making problems, including bandit problems [31], reinforcement learning [18, 32, 33, 34, 35], and optimization [15, 36]. In offline MBO, there are inverse approaches to learning a mapping from function values to input domains with generative models and sample designs from high-scoring regions [11, 12, 14, 15]. DDOM [15] utilizes a conditional diffusion model and generates high-scoring samples with reweighted training and classifier-free guidance. DiffOPT [36] considers a constrained optimization setting and introduces a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dynamics stage for further correction. ", "page_idx": 8}, {"type": "text", "text": "As concurrent works, DEMO [37] trains a diffusion model to match a pseudo-target distribution constructed by gradient ascent and uses the model to edit designs in the offline dataset. Diff-BBO [38] measures the uncertainty of generated designs to select the optimal target value for conditioning the diffusion model. Our method distinguishes itself from prior works by utilizing diffusion models to generate trajectories toward high-scoring regions by learning to improve solutions from the dataset. ", "page_idx": 8}, {"type": "text", "text": "7 Discussion and conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduce GTG, a novel conditional generative modeling approach for learning to improve solutions from synthetic trajectories constructed with the dataset. First, we construct diverse trajectories toward high-scoring regions while incorporating locality bias. Then, we train the conditional diffusion model and proxy function. After training, we generate trajectories with classifier-free guidance and context-conditioning to generalize the knowledge on how to improve solutions. Lastly, our filtering strategy for selecting candidates further improves the performance. Our extensive experiments demonstrate the generalizability of GTG. ", "page_idx": 9}, {"type": "text", "text": "Limitation and future work. While our method shows powerful generalizability on Design-Bench tasks, some evaluation methods may not fully capture real-world complexities. For example, in the superconductor task, we find that the offline dataset has multiple copies of the same inputs but with different outputs. As a result, the random forest oracle which is fti on this offilne data is not reliable. Moreover, we resort to filtering designs with the proxy function, which may result in inaccurate predictions on OOD regions. Although our flitering strategy works well in sparse and noisy settings, one may consider constructing a robust proxy model to handle the uncertainty of its predictions. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank the anonymous reviewers for their insightful comments and suggestions which significantly improve our manuscript. This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (No. RS-2024-00410082). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Luis A Barrera, Anastasia Vedenko, Jesse V Kurland, Julia M Rogers, Stephen S Gisselbrecht, Elizabeth J Rossin, Jaie Woodard, Luca Mariani, Kian Hong Kock, Sachi Inukai, et al. Survey of variation in human transcription factors reveals prevalent dna binding changes. Science, 2016. [2] Kam Hamidieh. A data-driven statistical model for predicting the critical temperature of a superconductor. Computational Materials Science, 2018.   \n[3] Felix Berkenkamp, Angela P Schoellig, and Andreas Krause. Safe controller optimization for quadrotors with gaussian processes. In International conference on robotics and automation (ICRA), 2016.   \n[4] Thomas Liao, Grant Wang, Brian Yang, Rene Lee, Kristofer Pister, Sergey Levine, and Roberto Calandra. Data-efficient learning of morphology and controller for a microrobot. In International Conference on Robotics and Automation (ICRA), 2019.   \n[5] Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey Levine. Design-bench: Benchmarks for data-driven offilne model-based optimization. In International Conference on Machine Learning (ICML), 2022.   \n[6] Brandon Trabucco, Aviral Kumar, Xinyang Geng, and Sergey Levine. Conservative objective models for effective offilne model-based optimization. In International Conference on Machine Learning (ICML), 2021.   \n[7] Justin Fu and Sergey Levine. Offline model-based optimization via normalized maximum likelihood estimation. In International Conference on Learning Representations (ICLR), 2021.   \n[8] Sihyun Yu, Sungsoo Ahn, Le Song, and Jinwoo Shin. Roma: Robust model adaptation for offline model-based optimization. In Advances in Neural Information Processing Systems (NeurIPS), 2021. [9] Ye Yuan, Can Sam Chen, Zixuan Liu, Willie Neiswanger, and Xue Steve Liu. Importanceaware co-teaching for offline model-based optimization. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[10] Can Sam Chen, Christopher Beckham, Zixuan Liu, Xue Steve Liu, and Chris Pal. Parallelmentoring for offilne model-based optimization. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[11] David Brookes, Hahnbeom Park, and Jennifer Listgarten. Conditioning by adaptive sampling for robust design. In International Conference on Machine Learning (ICML), 2019.   \n[12] Clara Fannjiang and Jennifer Listgarten. Autofocused oracles for model-based design. In Advances in Neural Information Processing Systems (NeurIPS), 2020.   \n[13] Aviral Kumar and Sergey Levine. Model inversion networks for model-based optimization. In Advances in Neural Information Processing Systems (NeurIPS), 2020.   \n[14] Minsu Kim, Federico Berto, Sungsoo Ahn, and Jinkyoo Park. Bootstrapped training of scoreconditioned generator for offline design of biological sequences. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[15] Siddarth Krishnamoorthy, Satvik Mehul Mashkaria, and Aditya Grover. Diffusion models for black-box optimization. In International Conference on Machine Learning (ICML), 2023.   \n[16] Satvik Mehul Mashkaria, Siddarth Krishnamoorthy, and Aditya Grover. Generative pretraining for black-box optimization. In International Conference on Machine Learning (ICML), 2023.   \n[17] Yassine Chemingui, Aryan Deshwal, Trong Nghia Hoang, and Janardhan Rao Doppa. Offline model-based optimization via policy-guided gradient search. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2024.   \n[18] Michael Janner, Yilun Du, Joshua Tenenbaum, and Sergey Levine. Planning with diffusion for flexible behavior synthesis. In International Conference on Machine Learning (ICML), 2022.   \n[19] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International Conference on Machine Learning (ICML), 2015.   \n[20] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Advances in Neural Information Processing Systems (NeurIPS), 2020.   \n[21] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. In NeurIPS Workshop on Deep Generative Models and Downstream Applications, 2021.   \n[22] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.   \n[23] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. Imagen video: High definition video generation with diffusion models. arXiv preprint arXiv:2210.02303, 2022.   \n[24] Can Chen, Yingxueff Zhang, Jie Fu, Xue Steve Liu, and Mark Coates. Bidirectional learning for offilne infinite-width model-based optimization. In Advances in Neural Information Processing Systems (NeurIPS), 2022.   \n[25] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016.   \n[26] James T Wilson, Riccardo Moriconi, Frank Hutter, and Marc Peter Deisenroth. The reparameterization trick for acquisition functions. arXiv preprint arXiv:1712.00424, 2017.   \n[27] Nikolaus Hansen. The cma evolution strategy: a comparing review. Towards a new evolutionary computation: Advances in the estimation of distribution algorithms, pages 75\u2013102, 2006.   \n[28] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8:229\u2013256, 1992.   \n[29] Tung Nguyen, Sudhanshu Agrawal, and Aditya Grover. Expt: Synthetic pretraining for few-shot experimental design. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[30] Minh Hoang, Azza Fadhel, Aryan Deshwal, Jana Doppa, and Trong Nghia Hoang. Learning surrogates for offilne black-box optimization via gradient matching. In International Conference on Machine Learning (ICML), 2024.   \n[31] Yu-Guan Hsieh, Shiva Prasad Kasiviswanathan, Branislav Kveton, and Patrick Bl\u00f6baum. Thompson sampling with diffusion generative prior. In International Conference on Machine Learning (ICML), 2023.   \n[32] Anurag Ajay, Yilun Du, Abhi Gupta, Joshua B Tenenbaum, Tommi S Jaakkola, and Pulkit Agrawal. Is conditional generative modeling all you need for decision making? In International Conference on Learning Representations (ICLR), 2023.   \n[33] Zhixuan Liang, Yao Mu, Mingyu Ding, Fei Ni, Masayoshi Tomizuka, and Ping Luo. Adaptdiffuser: Diffusion models as adaptive self-evolving planners. In International Conference on Machine Learning (ICML), 2023.   \n[34] Haoran He, Chenjia Bai, Kang Xu, Zhuoran Yang, Weinan Zhang, Dong Wang, Bin Zhao, and Xuelong Li. Diffusion model is an effective planner and data synthesizer for multi-task reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[35] Jaewoo Lee, Sujin Yun, Taeyoung Yun, and Jinkyoo Park. Gta: Generative trajectory augmentation with guidance for offline reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2024.   \n[36] Lingkai Kong, Yuanqi Du, Wenhao Mu, Kirill Neklyudov, Valentin De Bortol, Haorui Wang, Dongxia Wu, Aaron Ferber, Yi-An Ma, Carla P Gomes, et al. Diffusion models as constrained samplers for optimization with unknown constraints. arXiv preprint arXiv:2402.18012, 2024.   \n[37] Ye Yuan, Youyuan Zhang, Can Chen, Haolun Wu, Zixuan Li, Jianmo Li, James J Clark, and Xue Liu. Design editing for offilne model-based optimization. arXiv preprint arXiv:2405.13964, 2024.   \n[38] Dongxia Wu, Nikki Lijing Kuang, Ruijia Niu, Yi-An Ma, and Rose Yu. Diff-bbo: Diffusionbased inverse modeling for black-box optimization. arXiv preprint arXiv:2407.00610, 2024.   \n[39] Anna Gaulton, Louisa J Bellis, A Patricia Bento, Jon Chambers, Mark Davies, Anne Hersey, Yvonne Light, Shaun McGlinchey, David Michalovich, Bissan Al-Lazikani, et al. Chembl: a large-scale bioactivity database for drug discovery. Nucleic acids research, 40(D1):D1100\u2013 D1107, 2012.   \n[40] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015.   \n[41] Jacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state-spaces. In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \n[42] Nate Gruver, Samuel Stanton, Nathan Frey, Tim GJ Rudner, Isidro Hotzel, Julien LafranceVanasse, Arvind Rajpal, Kyunghyun Cho, and Andrew G Wilson. Protein design with guided discrete diffusion. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[43] Austin Tripp, Erik Daxberger, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Sample-efficient optimization in the latent space of deep generative models via weighted retraining. In Advances in Neural Information Processing Systems (NeurIPS), 2020.   \n[44] Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine. Conservative q-learning for offline reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2020.   \n[45] Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow network based generative models for non-iterative diverse candidate generation. In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \n[46] Christopher Williams and Carl Rasmussen. Gaussian processes for regression. In Advances in Neural Information Processing Systems (NeurIPS), 1995.   \n[47] Zecheng Wang, Che Wang, Zixuan Dong, and Keith W Ross. Pre-training with synthetic data helps offilne reinforcement learning. In International Conference on Learning Representations (ICLR), 2024.   \n[48] Zi Wang, George E Dahl, Kevin Swersky, Chansoo Lee, Zelda Mariet, Zachary Nado, Justin Gilmer, Jasper Snoek, and Zoubin Ghahramani. Pre-training helps bayesian optimization too. In ICML Workshop on Adaptive Experimental Design and Active Learning in the Real World, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Task Details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We present additional information on Branin and Design-Bench tasks. ", "page_idx": 13}, {"type": "text", "text": "A.1 Toy Branin Task ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Branin is a well-known synthetic function for benchmarking black-box optimization methods. It has three distinct global maxima, $(-\\pi,12.275)$ , $(\\pi,2.275)$ , and (9.42478, 2.475) with a maximum value of $-0.398$ . We create a synthetic offilne dataset by uniform sample $N=5000$ data points and remove the top $10\\%$ percentile. Figure 5 shows the visualization of the dataset used for evaluation. ", "page_idx": 13}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/52199848fe467695107afce476237b993c6362379e1578e33ad906edcade7eeb.jpg", "img_caption": ["Figure 5: Visualization of the offline dataset used for Branin task. "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "We compare GTG with competitive baselines, BONET, and PGS for the Branin task. For all methods, we generate 400 trajectories with horizon 64 using construction strategies suggested by each method. For GTG, we train the diffusion model with a length $H=64$ and apply context-conditioning with $C=32$ and classifier-free guidance with $\\alpha=0.8$ for guided sampling. We generate four trajectories for evaluation. Table 6 shows the best function values achieved by each method on the Branin task. As shown in the table, GTG successfully generalizes the knowledge to improve solutions and achieve better performance compared to baselines. ", "page_idx": 13}, {"type": "text", "text": "Table 6: Experiment results on Branin task. We report $100\\mathrm{th}$ percentile among $Q=128$ samples from each method. Experiments are conducted with three different random seeds. ", "page_idx": 13}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/4db10eda733e819791a584ed641125ab3763c86be2c558f611944d45d757d62e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "A.2 Design-Bench Tasks ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Design-Bench [5] is the most widely used benchmark for evaluating MBO algorithms. Table 7 shows the details of each task. For discrete tasks, we convert discrete input into a continuous vector by approximating logits with soft interpolation between one-hot encoding and uniform distribution using a mixing factor of 0.6. We present detailed statistics of each task in Table 7. ", "page_idx": 14}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/8b20d16ab90900dd0f2e154ee2ce3a02b086b5afa914c2d25e6e46201c5ad2dc.jpg", "table_caption": ["Table 7: Detail Setting of Design-Bench Tasks. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "A.2.1 Excluded Design-Bench Tasks ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Following from prior works [15, 16, 29], we exclude Hopper [25] and ChEMBL [39] tasks for evaluation. As noted in previous works, the oracle for the Hopper task is heavily skewed towards low-function values and gives inconsistent results. For the ChEMBL task, all methods already produce nearly the same results, which makes it not a meaningful task for evaluation. ", "page_idx": 14}, {"type": "text", "text": "A.2.2 Practical Variants of Design-Bench Tasks ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We prepare two practical variants of Design-Bench tasks to verify the robustness of GTG in terms of data sparsity and label noise. We present the distribution of function values in the original offline dataset and its practical variants on the TFBind8 task and D\u2019Kitty tasks. As shown in the figure, the score distributions of sparse and noisy datasets significantly differ from the original ones, making the task more challenging. ", "page_idx": 14}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/446da463dc0bd1ae74f6b1a017ae1efccacd3300baca209b90001e2c9b50e7e2.jpg", "img_caption": ["Figure 6: Distribution of function values in the original offline dataset and its pratical variants. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "B Methodology Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we present the method details, including model implementations and architectures, training schemes, hyperparameter configurations, and computing resources. ", "page_idx": 15}, {"type": "text", "text": "B.1 Trajectory Construction ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In terms of constructing trajectories, we introduce two variables, $K$ and $\\epsilon$ , which control the level of locality and optimality of the trajectories. For too large value of $K$ , we construct trajectories with inconsistent directions of improvement, while the extremely small value of $K$ leads to trajectories wandering the initial data point. If we lower the $\\epsilon$ close to zero, we only allow monotonic improvement, while large $\\epsilon$ values lead to suboptimal trajectories. We present the hyperparameters for our experiments in the Table 8. We also conduct additional analysis on trajectory construction in Appendix D.1. ", "page_idx": 15}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/40d104e438ceb30fb200aef7225da375b038761341c85e6b9528438059eeebf2.jpg", "table_caption": ["Table 8: Hyperparameters for Trajectory Construction. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "To identify $K$ nearest neighbors of a certain data point, we pre-compute the distance matrix between pairwise designs. For discrete tasks, we use hamming-ball distance as a distance metric, and for continuous tasks, we use Euclidean distance to measure the similarity between designs. Table 9 shows the computational time for pre-computing distance matrix and constructing trajectory dataset from the offline dataset. As shown in the table, constructing trajectories does not require a significantly large amount of time, even in high-dimensional settings. ", "page_idx": 15}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/834fd826db96a5e4562f952104750c66b1509c6950b8f97fe3381a856c7eac19.jpg", "table_caption": ["Table 9: Time complexity of trajectory construction on Design-Bench Tasks. We use Inte $\\textsuperscript{\\textregistered}$ Xeon\u00ae Gold 5317 CPU $\\textcircled{a}3.00\\mathrm{GHz}$ and report mean and standard deviation across five different runs. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "B.2 Training Models ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "B.2.1 Training Diffusion Model ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We use temporal U-Net architecture from Diffuser [18] as a backbone of the diffusion model. For discrete tasks, we train the model using Adam optimizer [40] for $1\\times10^{4}$ training steps with the learning rate of $1\\times10^{-3}$ . While one could use discrete diffusion models [41, 42] for discrete tasks, we use continuous diffusion models with continuous relaxation of discrete inputs for simplicity. For continuous tasks, we train the model for $5\\times10^{4}$ steps with a learning rate of $1\\times10^{-\\bar{4}}$ . The hyperparameters we used for modeling and training are listed in Table 10. ", "page_idx": 16}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/bb95421e7398240cf8f26f466e365d24391d806b04d1ed8c6e2b22160dfed3eb.jpg", "table_caption": ["Table 10: Hyperparameters for Training Diffusion Models "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "B.2.2 Training Proxy Model ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We use MLP with 2 hidden layers with 1024 hidden units and ReLU activations to implement the proxy function. As our objective is flitering high-fidelity designs with the proxy, we introduce a rankbased reweighting suggested by [43] during training to make the proxy model focus on high-scoring regions. For discrete tasks, we train a proxy model using Adam optimizer for $1\\times10^{3}$ training steps with a learning rate of $1\\times10^{-3}$ . For continuous tasks, we train the model for $5\\times10^{3}$ training steps with a learning rate of $1\\times10^{-3}$ . The hyperparameters we used for modeling and training are listed in Table 11. ", "page_idx": 16}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/1d825ee0981aca99546a360c9209202f4c4fc378cc1257f4ccad06ee905e685b.jpg", "table_caption": ["Table 11: Hyperparameters for Training Proxy "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "All training is done with a single NVIDIA RTX 3090 GPU and takes approximately 30 minutes for discrete tasks and 2 hours for continuous tasks. ", "page_idx": 16}, {"type": "text", "text": "B.3 Sampling Procedure ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We sample trajectories with $T=200$ denoising steps across all tasks. For classifier-free guidance, we set the guidance scale $\\omega$ as 1.2. In practice, we sample a batch of trajectories to generate multiple trajectories in parallel. We analyze the time complexity of sampling trajectories from the diffusion model in Appendix D.4 ", "page_idx": 16}, {"type": "text", "text": "C Baseline Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we provide more details on the baselines used for our experiments. ", "page_idx": 17}, {"type": "text", "text": "Baselines from Design-Bench [5]. We take the implementations of most baselines from open-source code1. It contains baselines of BO-qEI [26], CMA-ES [27], REINFORCE [28], Gradient Ascent, CbAS [11], MINs [13], and COMs [44]. We reproduce the results with 8 independent random seeds. ", "page_idx": 17}, {"type": "text", "text": "NEMO [7]. NEMO leverages a normalized maximum likelihood estimator to handle uncertainty in unseen regions and prevent adversarial optimization while performing gradient ascent. As there is no open-source code, we refer to the results of NEMO from [9]. ", "page_idx": 17}, {"type": "text", "text": "BDI [24]. BDI learns forward mapping from low-scoring regions to high-scoring regions, and its backward mapping distills the knowledge of the offline dataset to search for optimal designs. We follow the hyperparameter setting of the paper and reproduce the results with the open-source code2. ", "page_idx": 17}, {"type": "text", "text": "ICT [9]. ICT maintains three symmetric proxies and enhances the performance of the ensemble by co-teaching and importance-aware sample reweighting. We follow the hyperparameter setting of the paper and reproduce the results with the open-source code3. ", "page_idx": 17}, {"type": "text", "text": "DDOM [15]. DDOM leverages diffusion models to model distribution over high-scoring regions and sample designs with classifier-free guidance. We follow the hyperparameter setting of the paper except for the evaluation budget $Q$ for a fair comparison. We find that there is a performance drop in several tasks when we use $Q=128$ instead of 256. We reproduce the results with the open-source code4. ", "page_idx": 17}, {"type": "text", "text": "BONET [16]. BONET trains an autoregressive model with trajectories constructed from the offilne dataset and generalizes the knowledge to explore high-scoring regions. We follow the hyperparameter setting of the paper except for the evaluation budget $Q$ for a fair comparison. We find that there is a performance drop in several tasks when we use $Q=128$ instead of 256. We reproduce the results with the open-source code5. ", "page_idx": 17}, {"type": "text", "text": "PGS [17]. PGS trains a policy to guide gradient-based optimization by reformulating the MBO problem as an offilne RL problem. We follow the hyperparameter setting of the paper and reproduce the results with the open-source code6. ", "page_idx": 17}, {"type": "text", "text": "D Extended Additional Analysis ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we present additional analysis on GTG which is not included in the main section due to the page limit. ", "page_idx": 18}, {"type": "text", "text": "D.1 Additional Analysis on Trajectory Construction ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "D.1.1 Analysis on Score Distribution of Trajectories ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We conduct additional analysis on our trajectory construction method. We try to generate diverse trajectories toward high-scoring regions by randomly selecting subsequent designs from $K$ neighbors and allowing local perturbations. To this end, we visualize the shift in the distribution of function values via various trajectory construction strategies in the Superconductor task. As shown in Figure 7, the SORT-SAMPLE strategy suggested by BONET constructs trajectories solely on high-scoring designs, which can be easily trapped into local optima. Unlike SORT-SAMPLE, our method shifts distribution towards high-scoring regions while using the information of low-scoring regions to distill the knowledge of the landscape of the target function to the generator. ", "page_idx": 18}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/0a674faa62814b465247e8b329e883a3538f9b4e4a5e94fe7b9b3f0e0578d784.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 7: Distribution of function values in the offilne dataset and trajectory datasets constructed by different strategies. ", "page_idx": 18}, {"type": "text", "text": "D.1.2 Analysis on Hyperparameters in Trajectory Construction ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We also conduct additional analysis on hyperparameters in trajectory construction, $K$ and $\\epsilon$ . Figure 8 shows the performance of GTG in TFBind8 task by varying $K$ and $\\epsilon$ . While using too large $K$ or too small $\\epsilon$ may lead to a relatively low performance, we do not see much variation with different values. ", "page_idx": 18}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/71440d7356a0498240168065caa2cb2ab173e7bca4c9290d8b73d62d2f904b39.jpg", "img_caption": ["Figure 8: Performance of GTG in TFBind8 task by varying $K$ and $\\epsilon$ . Experiments are conducted with 8 random seeds and mean and standard deviation are reported. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "D.2 Additional Analysis on Sampling Procedure ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "D.2.1 Various Strategies for Guided Sampling ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we explore various strategies for guiding diffusion models to generate high-scoring designs. As we also generate score values, it could be possible to guide diffusion models to generate high-scoring designs by inpainting score values with the desired values. To this end, we conduct additional experiments on Design-Bench tasks by generating trajectories with inpainting instead of classifier-free guidance. Specifically, we inpaint the $y$ values of the generated trajectories as $y^{\\ast}$ , the normalized score of the optimal design. ", "page_idx": 19}, {"type": "text", "text": "Table 12 shows the performance of different guiding strategies. It confirms that conditioning by classifier-free guidance performs better than the inpainting strategy, justifying our decision choice. ", "page_idx": 19}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/221717d27ab5dc92b0df5cef927ec67300b1c2958e04916c74e439c6571e934f.jpg", "table_caption": ["Table 12: Exploring various guiding strategies. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "D.2.2 Diversity Analysis ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we explore the trade-off between performance and diversity via filtering strategy. While the filtering strategy boosts the performance of our method by eliminating potentially suboptimal designs, it may reduce the diversity of candidates, which may be crucial in tasks such as drug discovery due to proxy misspecification [45]. ", "page_idx": 19}, {"type": "text", "text": "To this end, we measure the diversity of the candidates, following the procedure of [14]. For measurement, we use the average of the pairwise distance between candidates as below. ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Diversity}({\\mathcal D})=\\frac{1}{|{\\mathcal D}|(|{\\mathcal D}|-1)}\\sum_{\\mathbf x\\in{\\mathcal D}}\\sum_{\\mathbf x^{\\prime}\\in{\\mathcal D}\\backslash\\{\\mathbf x\\}}d(\\mathbf x,\\mathbf x^{\\prime})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $d(\\mathbf{x},\\mathbf{x}^{\\prime})$ is a pairwise distance between samples. For discrete tasks, we use the hamming-ball distance metric. For continuous tasks, we compute L2 distance. ", "page_idx": 19}, {"type": "text", "text": "Table 13 illustrates the effect of filtering on performance and diversity. As expected, we achieve higher performance through filtering while sacrificing the diversity of the candidate set. It might be beneficial to automatically balance performance and diversity trade-off by measuring the uncertainty of the proxy function. We leave it as a future work. ", "page_idx": 19}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/704dc8ded2cfae7bb2a4f2e3885b86d24d99c750bee9732c1812902013d3af80.jpg", "table_caption": ["Table 13: Impact of filtering on performance and diversity of designs "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "D.2.3 Impact of Exploration Level $(\\alpha)$ ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we explore the impact of the exploration level $(\\alpha)$ on the generated samples. As depicted in Figure 3c, increasing $\\alpha$ leads to higher performance, indicating the importance of classifierfree guidance. However, we observe that conditioning on extremely high $\\alpha$ leads to sub-optimal performance, as illustrated in Figure 9. Conditioning on extremely high $\\alpha$ guides the diffusion model to over-exploration, resulting in sub-optimal out-of-distribution designs. Note that we do not fine-tune $\\alpha$ for each task and fix it with the value of 0.8 across all tasks, which generally exhibits good performance. ", "page_idx": 20}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/4723fd587932031e9b7d875450b504b64bb13dfcb449762f4a03f5fe62c8ca71.jpg", "img_caption": ["Figure 9: Performance of GTG in Ant and D\u2019Kitty tasks with extremely high $\\alpha$ values "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "D.2.4 Assumption on $y^{\\ast}$ ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We assume that the optimal value $y^{\\ast}$ of each task is known, following prior works [13, 16]. However, it is not always possible to know the exact optima. To this end, we estimate $y^{\\ast}$ with $\\gamma\\cdot y_{\\mathrm{max}}$ , where $y_{\\mathrm{{max}}}$ is the maximum value of the dataset and evaluate GTG by conditioning on the estimated value. As depicted in Table 14, conditioning on $\\gamma\\cdot y_{\\mathrm{max}}$ achieves comparable performance and even outperforms the performance of conditioned on exact optima in the TFBind8 task. However, it introduces an additional hyperparameter $\\gamma$ , whose optimal value varies across tasks. Therefore, we rely on assuming the exact optima, which is not an issue in many problems. ", "page_idx": 20}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/17f5179178213ec1dce640855641c6e1eb2db7b51880915dc431805a12301da2.jpg", "table_caption": ["Table 14: Analysis on relaxing assumption of known $y^{\\ast}$ . "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "D.3 Effect of Unsupervised Pretraining ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "It might be beneficial to pretrain the diffusion model with unlabeled data when we have limited data points. Specifically, there is a recent work EXPT [29], which trains an autoregressive model using synthetic trajectories constructed from the large-scale unlabeled dataset and adapts new tasks by conditioning on a few labeled points. To this end, we discuss the effect of pre-training GTG with unlabeled datasets. We follow a similar procedure of EXPT to generate a synthetic dataset. Formally, we sample synthetic functions from Gaussian Processes [46] with an RBF kernel and assign pseudo values to the unlabeled data points from synthetic functions. Please refer to [29] for a more detailed setting. Given a synthetic dataset, we pretrain diffusion models with trajectories constructed from the dataset using the proposed method. Then, we generate samples by conditioning on context data points from the labeled dataset. For labeled dataset, we randomly select $1\\%$ of the original dataset. ", "page_idx": 21}, {"type": "text", "text": "Table 15 shows the experiment results on various Design-Bench tasks. As shown in the table, pretraining generally improves the performance of GTG in the sparse data setting. We also find that GTG with pretraining outperforms ExPT in 3 of 5 tasks. While we do not assume the existence of the large-scale unlabeled dataset in the main experiment and pretraining is not a main focus of our research, it might be beneficial to analyze the effect of pretraining with synthetic datasets in offline MBO thoroughly as in other problems [47, 48]. ", "page_idx": 21}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/5aaa9f3283e005d4597f2ce253742ffc964dee4d4d9671f31fa219939321ea21.jpg", "table_caption": ["Table 15: Impact of pretraining with a synthetic dataset on performance. Experiments are conducted with three random seeds. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "D.4 Time Complexity of Sampling Procedure ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we analyze the time complexity of the sampling procedure of GTG. To generate trajectories, we run $T=200$ denoising timesteps with classifier-free guidance and context-conditioning to sample $N=128$ trajectories, which takes approximately 9.41s and 9.47s in wall clock time for the Ant and D\u2019Kitty tasks, respectively. We visualize the trade-off between the performance and runtime of sampling by varying the number of denoising timesteps. As shown in Figure 10, we can decrease the number of denoising timesteps even one-tenth with minimal loss in performance. Please note that sampling time is negligible compared to evaluating black-box functions, which is mostly expensive in real-world settings. ", "page_idx": 21}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/5a20971b1f032bbf698bd8d2b4ab3373a63817e44ebf24bb1465c37447462e91.jpg", "img_caption": ["Figure 10: Trade-off between Performance and Sampling time in Ant and D\u2019Kitty tasks. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "D.5 Extended Experiment Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we present extended experiment results in sparse and noisy datasets. As shown in Tables 16 and 17, our method outperforms most baselines in various practical settings. Note that we cannot conduct experiments with NEMO and RoMA, as there is no code publicly available. ", "page_idx": 22}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/68e333c05a24e639830b85831ab596ac8e65dbf0029a4207cc4c4dffa9e9f320.jpg", "table_caption": ["Table 16: Experiments on Sparse Datasets. "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "ioKQzb8SMr/tmp/c93e273409755f5e1d6d1f1866d2dcfac8dd3af0a26783d16ca4b254f83eb635.jpg", "table_caption": ["Table 17: Experiments on Noisy Datasets. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "D.6 Additional Visualization on Toy 2D Experiment ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We present additional visualization results from the Toy 2D experiment. As shown in Figure 11, GTG is able to generate diverse trajectories toward high-scoring designs by conditioning on different context points and classifier-free guidance. ", "page_idx": 23}, {"type": "image", "img_path": "ioKQzb8SMr/tmp/459bef64066637f8ac34ff240a9135071946a0360c65a7d7eb78df57cd47fe4e.jpg", "img_caption": ["Figure 11: Extra visualization of generated trajectories with GTG in Branin Task. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "E Broader Impact ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Optimization for real-world designs presents both opportunities and risks. For instance, while the design of new pharmaceuticals holds the promise of curing previously untreatable diseases, there is the potential for misuse, such as creating harmful biochemical agents. Researchers should be diligent to ensure that their innovations are employed in ways that contribute positively to societal welfare. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We clearly state the main claims in the abstract and introduction. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: We discuss limitations in Section 7. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: We do not include theoretical results. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We provide detailed experiment settings in the Appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide open access to the data and code to reproduce the paper. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: All of these can be found in the Appendix. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We conduct all experiments with multiple random seeds and report error bars. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We provide information on the computer resources in the Appendix. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We use Design-Bench, which does not contain harmful or offensive contents. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We discuss the broader impact of the paper in Appendix E. ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 27}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We do not use controversial dataset. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We mention the license in the README.md of our code. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We provide our code publicly available. \u2022 The answer NA means that the paper does not release new assets. ", "page_idx": 28}, {"type": "text", "text": "\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We do not conduct crowdsourcing experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We do not conduct experiments with human subjects. ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]