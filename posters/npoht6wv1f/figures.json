[{"figure_path": "npoHt6WV1F/figures/figures_1_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure illustrates the NeuralFuse framework. (a) shows the pipeline of NeuralFuse at inference, transforming input samples to be robust to bit errors introduced by low voltage.  It compares the accuracy at nominal and low voltage with and without NeuralFuse. (b) shows the energy-accuracy tradeoff for six different NeuralFuse implementations, highlighting the energy savings while maintaining accuracy at a 1% bit-error rate.", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_3_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows the NeuralFuse framework. (a) illustrates the pipeline at inference, highlighting input transformation for robustness to bit errors at low voltage.  (b) presents an energy-accuracy tradeoff example for different NeuralFuse implementations on a ResNet18 model, demonstrating the balance achieved between energy savings and accuracy recovery at a 1% bit error rate.", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_6_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows the NeuralFuse framework's pipeline during inference and its energy-accuracy tradeoff example. (a) illustrates how NeuralFuse processes input samples and generates robust representations to mitigate bit errors induced by low voltage.  The accuracy of a pre-trained ResNet18 model is compared with and without NeuralFuse at nominal and low voltages. (b) presents the energy-accuracy tradeoff for different NeuralFuse implementations on the same ResNet18 model, showing the balance between energy saving (x-axis) and accuracy at low voltage (y-axis).", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_8_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of the relaxed-access scenario experiments. It compares the test accuracies of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) with and without NeuralFuse under nominal voltage (0% bit-error rate) and low voltage conditions (with specified bit-error rates of 0.5% and 1%).  The results show NeuralFuse consistently improves the accuracy when bit errors are present, demonstrating its effectiveness in mitigating the impact of low voltage on model performance.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_14_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of experiments conducted under the relaxed-access scenario.  It compares the test accuracies of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) with and without NeuralFuse enabled, at both nominal voltage (no bit errors) and low voltage (with specified bit error rates of 0.5% and 1%). The results visually demonstrate NeuralFuse's effectiveness in recovering accuracy lost due to low voltage-induced bit errors.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_15_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of experiments conducted in the relaxed-access scenario, where the base model information is not fully transparent but backpropagation through the model is possible.  The experiments evaluated various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) on three datasets (CIFAR-10, GTSRB, ImageNet-10) with and without NeuralFuse enabled.  The x-axis represents the nominal voltage (0% bit-error rate) and different low-voltage settings with specified bit-error rates (BER). The y-axis represents the test accuracy. For each model and voltage setting, the accuracy is displayed with and without NeuralFuse. The figure demonstrates NeuralFuse's effectiveness in recovering accuracy at low voltages by consistently improving the perturbed accuracy. ", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_16_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "The figure shows the performance of NeuralFuse in a relaxed-access scenario where the model details are known, but not the internal workings. The experiment is performed with three different datasets (CIFAR-10, GTSRB, and ImageNet-10) and various pre-trained models.  The figure compares the test accuracies at nominal voltage (without bit errors) and low voltage (with specified bit-error rates) with and without NeuralFuse enabled. The results demonstrate NeuralFuse's effectiveness in recovering accuracy losses caused by low-voltage induced bit errors.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_18_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows two parts: (a) illustrates how NeuralFuse works during inference. It transforms input data to make it robust to bit errors at low voltage. The example shows the accuracy of a CIFAR-10 pre-trained ResNet18 model with and without NeuralFuse at normal and low voltages.  (b) Presents energy/accuracy tradeoffs of different NeuralFuse architectures. The X-axis shows energy savings and Y-axis shows accuracy at a 1% bit error rate.  It demonstrates how NeuralFuse can recover accuracy while reducing energy consumption at low voltage.", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_19_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows the pipeline of NeuralFuse and its impact on energy-accuracy tradeoff. (a) illustrates how NeuralFuse processes input data to generate robust representations that are resistant to bit errors induced by low voltage. It compares the accuracy of a ResNet18 model with and without NeuralFuse at nominal and low voltages. (b) presents the energy-accuracy tradeoff curves for six different NeuralFuse architectures, highlighting the energy savings achieved while maintaining accuracy at a 1% bit error rate.", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_20_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of experiments conducted under the relaxed-access scenario.  It compares the accuracy of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) with and without the NeuralFuse module applied. The accuracy is evaluated at both nominal voltage (0% bit error rate) and low voltage (with specified bit-error rates of 0.5% and 1%).  The results highlight the ability of NeuralFuse to significantly improve the accuracy of the base models when operating under low-voltage conditions that introduce bit errors.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_21_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure presents the results of experiments conducted in a relaxed-access scenario where the base models' details were not entirely transparent but backpropagation was possible. It compares the test accuracies of various pre-trained models with and without NeuralFuse under different bit-error rates (BERs) at both nominal and low voltages. The results show the consistent accuracy recovery offered by NeuralFuse, showcasing its effectiveness in mitigating the negative impact of low voltage on model accuracy.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_26_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows the pipeline of the NeuralFuse framework during inference and an example of the energy/accuracy tradeoff.  (a) illustrates how NeuralFuse transforms inputs to create robust representations that are resilient to bit errors introduced at low voltage. It compares the accuracy of a ResNet18 model with and without NeuralFuse under nominal and low-voltage conditions, highlighting the accuracy loss due to bit errors. (b) displays the energy-accuracy tradeoff for different NeuralFuse implementations on the same ResNet18 model, showing the potential for energy savings while maintaining high accuracy. The x-axis represents the energy savings, and the y-axis represents the accuracy under a 1% bit error rate.", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_26_2.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the test accuracies of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) on three datasets (CIFAR-10, GTSRB, ImageNet-10) under different bit error rates (0%, 0.5%, 1%).  The results are displayed for both scenarios: without NeuralFuse and with NeuralFuse.  The figure demonstrates how NeuralFuse consistently improves the accuracy of models under low voltage conditions by mitigating bit-flip errors caused by undervoltage.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_26_3.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of the experiments conducted in the relaxed-access scenario.  The experiment evaluated various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) on CIFAR-10, GTSRB, and ImageNet-10 datasets. Each model was tested under nominal voltage (0% bit error rate) and low voltage conditions (with 0.5% or 1% bit error rates). The accuracy was measured with and without the NeuralFuse module enabled. The figure illustrates that NeuralFuse consistently increased the perturbed accuracy (accuracy under bit errors) across various models and datasets, highlighting the effectiveness of the proposed method in mitigating bit errors caused by low voltage.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_26_4.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of experiments conducted under the relaxed-access scenario.  It compares the test accuracies of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, and VGG19) with and without NeuralFuse enabled.  The accuracies are measured at both nominal voltage (0% bit-error rate) and low voltage (with specified bit error rates of 0.5% and 1%). The results presented illustrate that NeuralFuse consistently improves accuracy, particularly under low-voltage conditions where bit errors occur.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_26_5.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the results of the relaxed-access scenario experiments, where the accuracy of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, and VGG19) is evaluated under both nominal voltage (no bit errors) and low-voltage conditions (with 0.5% or 1% bit error rate).  It compares the accuracy with and without the NeuralFuse module. The results demonstrate NeuralFuse's effectiveness in improving the accuracy of these models, especially under low-voltage conditions with bit errors.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_27_1.jpg", "caption": "Figure 3: Relaxed-access scenario test accuracies (%) of various pre-trained models with and without NeuralFuse, compared at nominal voltage (0% bit-error rate) or low voltage (with specified bit-error rates). The results demonstrate that NeuralFuse consistently recovered perturbation accuracy.", "description": "This figure shows the accuracy of various pre-trained models (ResNet18, ResNet50, VGG11, VGG16, VGG19) on three datasets (CIFAR-10, GTSRB, ImageNet-10) under both nominal voltage (no bit errors) and low voltage (with 0.5% or 1% bit error rates).  It compares the performance of the models with and without NeuralFuse enabled.  The results show that NeuralFuse consistently improves the accuracy of the models under low voltage conditions.", "section": "4.2 Performance Evaluation, Relaxed-access Scenario"}, {"figure_path": "npoHt6WV1F/figures/figures_29_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows the pipeline of NeuralFuse framework during inference, and the energy/accuracy tradeoff example using CIFAR-10 pre-trained ResNet18 model at different voltage settings and NeuralFuse implementations. The left panel shows how NeuralFuse improves the robustness of the model to bit errors induced by low voltage. The right panel shows the energy savings and accuracy recovery achieved by different NeuralFuse implementations at 1% bit-error rate.", "section": "3 NeuralFuse: Framework and Algorithms"}, {"figure_path": "npoHt6WV1F/figures/figures_30_1.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows NeuralFuse's framework and its energy/accuracy tradeoff.  (a) illustrates how NeuralFuse processes inputs to generate robust representations, protecting against bit errors introduced at low voltage.  The example uses a pre-trained ResNet18 on CIFAR-10, showing accuracy improvements with NeuralFuse enabled under both nominal and low-voltage conditions. (b) displays the energy-accuracy trade-off achieved using six different NeuralFuse implementations; the graph showcases the balance between reduced memory access energy and maintained accuracy at a 1% bit error rate. ", "section": "1 Introduction"}, {"figure_path": "npoHt6WV1F/figures/figures_30_2.jpg", "caption": "Figure 1: (a) At inference, NeuralFuse transforms input samples x into robust data representations. The nominal voltage allows models to work as expected, whereas at low voltage, one would encounter bit errors (e.g., 1%) that cause incorrect inferences. The percentages reflect the accuracy of a CIFAR-10 pre-trained ResNet18 with and without NeuralFuse in both those voltage cases. (b) On the same base model (ResNet18), we illustrate the energy/accuracy tradeoff of six NeuralFuse implementations. The x-axis represents the percentage reduction in dynamic-memory access energy at low-voltage settings (base model protected by NeuralFuse), as compared to the bit-error-free (nominal) voltage. The y-axis represents the perturbed accuracy (evaluated at low voltage) with a 1% bit-error rate.", "description": "This figure shows two subfigures. Subfigure (a) illustrates the NeuralFuse framework pipeline during inference, highlighting the input transformation to create robust representations and the impact of bit errors at low voltage on model accuracy. Subfigure (b) presents the energy-accuracy trade-off achieved by six different NeuralFuse implementations, demonstrating the ability of NeuralFuse to reduce energy consumption at low voltage while maintaining accuracy.", "section": "1 Introduction"}]