[{"figure_path": "r70jUOpDCM/figures/figures_1_1.jpg", "caption": "Figure 1: FLOPs and latency comparison on ImageNet. The latency was tested on a RTX 4090 GPU with a batch size of 128 using FP32 precision at an image resolution of 224.", "description": "This figure compares the performance of different vision models (ConvNeXt, VMamba, MSVMamba, and Swin) on the ImageNet dataset in terms of FLOPs (floating point operations) and latency.  It shows the trade-off between computational cost and accuracy. MSVMamba demonstrates a better balance of accuracy and efficiency compared to other models.", "section": "4.1 ImageNet Classification"}, {"figure_path": "r70jUOpDCM/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of decay along horizontal, vertical scanning routes and their ratio.", "description": "This figure visualizes the decay rate of influence along horizontal and vertical scanning routes in the VMamba model. The decay rate represents how quickly the influence of a token diminishes as the distance from the central token increases. The horizontal and vertical scan plots show this decay along each scan direction. The decay ratio plot shows the ratio between the decay rates of the horizontal and vertical scans, and the binary decay ratio plot displays a binarized version of this ratio. These plots illustrate the long-range forgetting problem faced by the VMamba model and motivate the use of the multi-scan strategy to alleviate this issue.", "section": "3.2 Analysis of Multi-Scan Strategy"}, {"figure_path": "r70jUOpDCM/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of the Multi-Scale 2D-Selective-Scan on an image", "description": "This figure illustrates the multi-scale 2D selective scan.  The input image is processed via two depthwise convolutions (DW Conv) with different kernel sizes (K) and strides (S). The first DW Conv (K=3, S=1) maintains the original resolution, while the second (K=7, S=2) downsamples the input. Each resulting feature map is then processed by an S6 block. The outputs of these S6 blocks are subsequently interpolated to enhance the feature representation.", "section": "3.3 Multi-Scale 2D Scanning"}, {"figure_path": "r70jUOpDCM/figures/figures_5_1.jpg", "caption": "Figure 5: Detailed architecture of Multi-Scale State Space (MS3) block, consisting of a Multi-Scale Vision Space State (MSVSS) block and a Convolutional Feed-Forward Network (ConvFFN) block.", "description": "The MS3 block is a core component of the proposed MSVMamba model. It integrates a Multi-Scale Vision Space State (MSVSS) block and a Convolutional Feed-Forward Network (ConvFFN) block to enhance feature extraction and information flow. The MSVSS block utilizes a multi-scale 2D scanning technique to capture both fine-grained and coarse-grained features from multi-scale feature maps.  The ConvFFN block then facilitates information exchange across different channels, improving the model's capacity to capture richer feature representations.  This hierarchical design improves accuracy and efficiency compared to previous approaches like VMamba.", "section": "3.4 Overall Model Architecture"}, {"figure_path": "r70jUOpDCM/figures/figures_5_2.jpg", "caption": "Figure 6: Attention maps from four distinct scanning directions, generated by SS2D and our MS2D in the last layer of the second stage. In the second row, full-resolution scan (first scan) captures fine-grained features, whereas scans at half resolution capture coarse-grained features. Maps are rendered at a higher resolution to enhance visualization quality.", "description": "The figure shows attention maps for SS2D and MS2D scanning strategies used in the VMamba model.  It visualizes how different scanning routes capture features at different scales.  The left side (a) shows the SS2D strategy, where all four scans operate on the full-resolution feature map, resulting in detailed features. The right side (b) illustrates MS2D, which uses downsampled feature maps for three scans, resulting in attention that captures broader structural features while still preserving fine-grained detail from the full resolution scan.", "section": "Qualitative Analysis"}, {"figure_path": "r70jUOpDCM/figures/figures_14_1.jpg", "caption": "Figure 6: Attention maps from four distinct scanning directions, generated by SS2D and our MS2D in the last layer of the second stage. In the second row, full-resolution scan (first scan) captures fine-grained features, whereas scans at half resolution capture coarse-grained features. Maps are rendered at a higher resolution to enhance visualization quality.", "description": "This figure compares attention maps generated by SS2D and MS2D methods in the second stage of the model.  The top row shows the attention maps from four different scanning directions using the SS2D method, and the bottom row shows the maps generated using the MS2D method. The MS2D method uses both full-resolution and half-resolution scans, allowing it to capture both fine-grained and coarse-grained features. The figure demonstrates the superior ability of the MS2D method to capture the relevant information.", "section": "D Qualitative Analysis"}]