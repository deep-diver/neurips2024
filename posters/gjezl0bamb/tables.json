[{"figure_path": "gjEzL0bamb/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative results of all methods. Time. and Mem. denote training time and GPU memory used for adaptation on a A100 GPU. StyleTalk is a one-shot method, so the Time. and Mem. are 0.", "description": "This table presents a quantitative comparison of different talking face generation methods.  Metrics include CSIM (identity similarity), PSNR (peak signal-to-noise ratio), FID (Fr\u00e9chet inception distance), AED (audio-expression distance), and Sync. (lip synchronization accuracy). It also shows the training time (in hours) and GPU memory (in GB) required for model adaptation. The results highlight that MimicTalk achieves high performance with significantly reduced computational demands.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "gjEzL0bamb/tables/tables_7_2.jpg", "caption": "Table 2: MOS score of different methods. The error bars are 95% confidence interval.", "description": "This table presents the Mean Opinion Score (MOS) results for different talking face generation methods across three aspects: identity similarity, visual quality, and lip synchronization.  Higher scores indicate better performance. The error bars represent the 95% confidence intervals, showing the variability of the ratings.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "gjEzL0bamb/tables/tables_8_1.jpg", "caption": "Table 3: CMOS results on the style controllability and identity similarity of MimicTalk and StyleTalk. CMOS score ranges from -3 to +3. Error bars are 95% confidence intervals.", "description": "This table presents the CMOS scores for style controllability and identity similarity, comparing MimicTalk with StyleTalk.  Higher scores indicate better performance.  The CMOS scale ranges from -3 to +3, with error bars representing 95% confidence intervals.", "section": "4.3.2 User study"}, {"figure_path": "gjEzL0bamb/tables/tables_8_2.jpg", "caption": "Table 4: Ablation studies on different settings in the SD-hybrid adaptation.", "description": "This table presents the ablation study results for the Static-Dynamic hybrid adaptation pipeline.  It shows the impact of different components on the performance of the model in terms of CSIM (identity similarity), PSNR (peak signal-to-noise ratio), FID (Fr\u00e9chet inception distance), AED (average expression distance), and APD (average pose distance).  Comparing the full SD-Hybrid model to versions with the tri-plane inversion and LoRAs removed individually illustrates the contribution of each component.", "section": "4.3.3 Ablation study"}, {"figure_path": "gjEzL0bamb/tables/tables_9_1.jpg", "caption": "Table 5: Ablation studies on different settings in ICS-A2M. L2Landmark denotes the L2 reconstruction error on the 68 3D landmarks, and Lsync denotes a audio-expression synchronization contrastive loss provided by (Chung and Zisserman, 2017). and (Ye et al., 2023)", "description": "This table presents the ablation study of the In-Context Stylized Audio-to-Motion (ICS-A2M) model. It shows the impact of different components of the model on the L2 landmark reconstruction error and audio-expression synchronization contrastive loss. The results demonstrate the effectiveness of the flow matching mechanism, the in-context learning of talking styles, and the audio-expression synchronization loss in improving the performance of the model.", "section": "4.3.3 Ablation study"}, {"figure_path": "gjEzL0bamb/tables/tables_16_1.jpg", "caption": "Table 6: Model Configuration", "description": "This table shows the hyperparameter settings used in the MimicTalk model.  It is divided into two sections: SD-Hybrid Adaptation and ICS-A2M Model. The SD-Hybrid Adaptation section specifies parameters related to adapting the person-agnostic model to a specific identity, including the LoRA rank and the learnable tri-plane shape. The ICS-A2M Model section details parameters for the in-context stylized audio-to-motion model, encompassing transformer settings (hidden size, layers, norm type, etc.) and parameters for the flow-matching process (final sigma, ODE method, and inference steps).", "section": "C.1 Model Configuration"}]