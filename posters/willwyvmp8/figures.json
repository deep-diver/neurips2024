[{"figure_path": "WILLwyVmP8/figures/figures_2_1.jpg", "caption": "Figure 1: Probabilistic graphical model of CMR", "description": "The figure shows the probabilistic graphical model used in CMR.  There are four nodes representing four variables:  The input data (x), the concept encoding (c), the selected rule (r), and the task prediction (y).  Arrows indicate the probabilistic dependencies between the variables. The input x influences both the concept encoding c and the rule selection r. The concept encoding c and the selected rule r together determine the task prediction y. The model shows how the concepts and the selected rule combine to produce a final prediction.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_3_1.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure illustrates the process of making a prediction using the Concept-based Memory Reasoner (CMR) model.  The image is input (A) and converted into concept predictions. These predictions are then used by the rule selector (B) to determine a probability distribution over the rules in the rulebook. A rule embedding is then selected (C) based on this distribution, decoded (D) to obtain a logical rule, and finally the task prediction is made (E) using the concept predictions and the decoded rule. The black boxes in the figure represent neural network components, and the white box indicates a symbolic logic operation.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_8_1.jpg", "caption": "Figure 3: Task accuracy on CelebA with varying numbers of employed concepts.", "description": "This figure shows the task accuracy on the CelebA dataset when varying the number of concepts used.  It compares the performance of CMR against other concept-based models (CBM+DT, CBM+MLP, CBM+XG, CEM) and a black-box model. The results demonstrate that CMR maintains high accuracy even with a reduced number of concepts, while the accuracy of other concept-based models significantly degrades due to the concept bottleneck.", "section": "6.2.2 Explanations and intervention"}, {"figure_path": "WILLwyVmP8/figures/figures_15_1.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure illustrates the process of CMR's task prediction using an example with two rules and three concepts.  It visually breaks down the process into five steps, each represented by a block.  The image is input, and each neural network block (black) performs a transformation, culminating in the final symbolic (white) evaluation block determining the prediction (apple). It highlights the selection of a logical rule from the rulebook and its subsequent symbolic evaluation on concept predictions.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_21_1.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure illustrates the prediction process of the Concept-based Memory Reasoner (CMR) model.  It shows how an input image is processed through the three main components: concept encoder, rule selector, and task predictor. The concept encoder maps the image to concept predictions (e.g., \"red\", \"square\", \"table\"). The rule selector probabilistically selects a rule from the rulebook (memory of logic rules). This selected rule is then symbolically evaluated based on the concept predictions to produce a final prediction (e.g., \"apple = 1\"). The figure highlights the interplay between neural (black boxes) and symbolic (white box) components in CMR's reasoning process.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_21_2.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure illustrates the prediction process of the Concept-Based Memory Reasoner (CMR) model. It shows how an input image is processed through different components of the CMR model: concept encoder, rule selector, and task predictor.  The concept encoder maps the image to concept predictions. The rule selector probabilistically selects a rule from a rulebook. The rule embedding is decoded into a logical rule, and this rule is symbolically evaluated on the concept predictions to give the final task prediction.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_24_1.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure illustrates the process of CMR's prediction. It shows how an input image is first processed by a concept encoder to obtain concept predictions.  Then, a rule selector chooses a rule from a learned rulebook. This selected rule is symbolically evaluated using the concept predictions to generate a final task prediction (e.g., classifying an image as an apple). The figure uses a simplified example with two rules and three concepts for clarity.", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_24_2.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure shows an example prediction process of the Concept-based Memory Reasoning (CMR) model.  It illustrates the model's three main components: a concept encoder, a rule selector, and a task predictor. The process begins with an image (an apple in this example) that is fed into the concept encoder (A).  The encoder outputs a probability distribution over concepts representing the image's features (e.g., 'red', 'square', 'table'). The rule selector (B) takes the image as input and selects a rule from the rulebook, which is a set of human-understandable logical rules. A probability distribution over the possible rules is shown. Based on the probability distribution over rules, a rule embedding is chosen from the rulebook (C). This rule embedding is then decoded (D) to provide a logical rule such as 'apple is red and not square'. The task predictor (E) then applies this logical rule to the concept probabilities to arrive at a final prediction for the image (apple=1).  The diagram visually separates the neural network components (black boxes) from the symbolic logic evaluation (white box).", "section": "3.1 Probabilistic graphical model"}, {"figure_path": "WILLwyVmP8/figures/figures_24_3.jpg", "caption": "Figure 2: Example prediction of CMR with a rulebook of two rules and three concepts (i.e. red (R), square (S), table (T)). In this figure, we sample (~) for clarity, but in practice, we compute every probability exactly. Every black box is implemented by a neural network, while the white box is a pure symbolic logic evaluation. (A) The image is mapped to a concept prediction. (B) The image is mapped by the component selector to a distribution over rules. (C) This distribution is used to select a rule embedding from the encoded rulebook. (D) The rule embedding is decoded into a logic rule by assigning to each of the concepts its role in the rule, i.e. whether it is positive (P), negative (N), or irrelevant (I). Finally, (E) the rule is evaluated on the concept prediction to provide the task prediction on the task apple.", "description": "This figure shows an example prediction process of the Concept-based Memory Reasoner (CMR) model.  The process is broken down into five steps, each represented by a block in the figure.  It illustrates how CMR uses a concept encoder, rule selector, and task predictor to make a prediction, highlighting the interplay between neural networks (black boxes) and symbolic logic evaluation (white box). The figure helps visualize how an input image is converted to a concept prediction, then how a rule is selected and evaluated, resulting in the final classification prediction (apple, in this case).", "section": "3.1 Probabilistic graphical model"}]