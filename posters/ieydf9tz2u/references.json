{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a model used for text-to-image generation in many models including Lumina-T2X, demonstrating its importance as a foundational model in the field."}, {"fullname_first_author": "Hyung Won Chung", "paper_title": "Scaling instruction-finetuned language models", "publication_date": "2022-10-11", "reason": "This paper introduces FLAN, a large language model that Lumina-Next uses as a text encoder, showing its significance in enabling multilingual and efficient text-to-image generation."}, {"fullname_first_author": "Peng Gao", "paper_title": "Lumina-t2x: Transforming text into any modality, resolution, and duration via flow-based large diffusion transformers", "publication_date": "2024-05-05", "reason": "This paper introduces Lumina-T2X, the precursor to Lumina-Next, establishing the foundational architecture and methodology upon which Lumina-Next is built."}, {"fullname_first_author": "Ntk-aware", "paper_title": "Scaled Rope Allows Llama Models to Have Extended (8k+) Context Size Without Any Fine-tuning and Minimal Perplexity Degradation", "publication_date": "2024-04-10", "reason": "This paper introduces NTK-Aware Scaled RoPE, a technique used in Lumina-Next to improve the efficiency and quality of text-to-image generation, particularly in generating higher resolution images."}, {"fullname_first_author": "Junsong Chen", "paper_title": "Pixart-\u03c3: Weak-to-strong training of diffusion transformer for 4k text-to-image generation", "publication_date": "2024-03-04", "reason": "This paper introduces PixArt-\u03c3, a model which Lumina-Next is compared against, highlighting the ongoing development and competition in high-quality text-to-image generation models."}]}