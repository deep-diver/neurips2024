[{"figure_path": "uXuObobJHO/tables/tables_3_1.jpg", "caption": "Table 1: Time complexities of different HMC approaches for the submodel involved in marginalization. Initialization is done once before the HMC loop. The log density is computed within each step of the leapfrog integrator. Recovery is performed for each sample from HMC. N is the number of observations, M is the dimension for one class of random effects, D is the dimension for all classes of random effects, L is the number of classes, d is the dimension for an effect of a group in a class.", "description": "This table compares the time complexities of different Hamiltonian Monte Carlo (HMC) approaches used for marginalizing random effects in linear mixed-effects models (LMMs). It breaks down the computational cost into three phases: initialization (done once before the main HMC loop), log density computation (repeated in each step of the leapfrog integrator within the HMC algorithm), and recovery (performed for each sample generated by HMC).  The complexities are expressed in terms of N (number of observations), M (dimension of one class of random effects), D (dimension of all classes of random effects), L (number of classes), and d (dimension of random effects per group). Three approaches are compared: standard HMC on the original model, naive marginalization, and marginalization with the proposed linear algebra optimizations.", "section": "Challenges of multivariate marginalization"}, {"figure_path": "uXuObobJHO/tables/tables_4_1.jpg", "caption": "Table 1: Time complexities of different HMC approaches for the submodel involved in marginalization. Initialization is done once before the HMC loop. The log density is computed within each step of the leapfrog integrator. Recovery is performed for each sample from HMC. N is the number of observations, M is the dimension for one class of random effects, D is the dimension for all classes of random effects, L is the number of classes, d is the dimension for an effect of a group in a class.", "description": "This table compares the time complexities of different Hamiltonian Monte Carlo (HMC) approaches for marginalizing random effects in linear mixed-effects models (LMMs). It breaks down the computational cost of initialization, log density evaluation, and recovery steps for various marginalization methods, highlighting the impact of model structure and algorithm choices on efficiency. The complexities are expressed in terms of N (number of observations), M (dimension of one class of random effects), D (dimension of all classes), L (number of classes), and d (dimension of an effect in a group).", "section": "Challenges of multivariate marginalization"}, {"figure_path": "uXuObobJHO/tables/tables_6_1.jpg", "caption": "Table 2: Running time in seconds for HMC, with or without marginalization. Mean and standard deviation over 5 independent runs are reported. Experiments are run on NVIDIA A40.", "description": "This table presents the average running time (in seconds) of the Hamiltonian Monte Carlo (HMC) algorithm for different marginalization strategies on the ETH instructor evaluation model.  It compares the original model (No marginalization) with four other variations where either u1, u2, u3, or all random effects (u) are marginalized. The results are averages across five independent runs, with standard deviations included in parentheses.", "section": "6.1 Marginalization in cross-effects models"}, {"figure_path": "uXuObobJHO/tables/tables_7_1.jpg", "caption": "Table 3: Compilation time Te and running time Tr in seconds for marginalized MCMC [35], with or without vectorization. Mean and std across 5 independ runs are reported.", "description": "This table compares the compilation time (Te) and running time (Tr) of the marginalized MCMC method proposed in the paper [35] with the authors' vectorized approach. The comparison is done for two models: Electric company and Pulmonary fibrosis.  The results show significant improvements in both compilation and running times using the proposed vectorized approach.", "section": "6.3 Benefits from vectorization"}, {"figure_path": "uXuObobJHO/tables/tables_14_1.jpg", "caption": "Table 1: Time complexities of different HMC approaches for the submodel involved in marginalization. Initialization is done once before the HMC loop. The log density is computed within each step of the leapfrog integrator. Recovery is performed for each sample from HMC. N is the number of observations, M is the dimension for one class of random effects, D is the dimension for all classes of random effects, L is the number of classes, d is the dimension for an effect of a group in a class.", "description": "This table compares the time complexities of different Hamiltonian Monte Carlo (HMC) approaches for performing marginalization in linear mixed-effects models. It breaks down the complexities for initialization, computing the log density (within each step of the leapfrog integrator), and the recovery step (for each sample from HMC).  The complexities are expressed in terms of N (number of observations), M (dimension of one class of random effects), D (dimension of all classes of random effects), L (number of classes of random effects), and d (dimension of an effect of a group in a class).", "section": "Challenges of multivariate marginalization"}, {"figure_path": "uXuObobJHO/tables/tables_16_1.jpg", "caption": "Table 1: Time complexities of different HMC approaches for the submodel involved in marginalization. Initialization is done once before the HMC loop. The log density is computed within each step of the leapfrog integrator. Recovery is performed for each sample from HMC. N is the number of observations, M is the dimension for one class of random effects, D is the dimension for all classes of random effects, L is the number of classes, d is the dimension for an effect of a group in a class.", "description": "This table compares the time complexities of different Hamiltonian Monte Carlo (HMC) approaches for marginalizing random effects in linear mixed-effects models (LMMs). It breaks down the computational cost of initialization, computing the log density (within each leapfrog step of the HMC algorithm), and recovering marginalized variables for each sample. The complexities are expressed in terms of N (number of observations), M (dimension of one class of random effects), D (dimension of all random effects), L (number of classes), and d (dimension of an effect in a group).", "section": "Challenges of multivariate marginalization"}, {"figure_path": "uXuObobJHO/tables/tables_19_1.jpg", "caption": "Table 1: Time complexities of different HMC approaches for the submodel involved in marginalization. Initialization is done once before the HMC loop. The log density is computed within each step of the leapfrog integrator. Recovery is performed for each sample from HMC. N is the number of observations, M is the dimension for one class of random effects, D is the dimension for all classes of random effects, L is the number of classes, d is the dimension for an effect of a group in a class.", "description": "This table compares the computational complexities of different Hamiltonian Monte Carlo (HMC) approaches used for marginalizing random effects in linear mixed-effects models. It breaks down the complexities for initialization, computing the log density (which is done repeatedly within the HMC algorithm), and the recovery step (which is done once per sample). The complexities are expressed in terms of N (number of observations), M (dimension of one class of random effects), D (dimension of all classes), L (number of classes), and d (dimension of one effect).", "section": "Challenges of multivariate marginalization"}, {"figure_path": "uXuObobJHO/tables/tables_19_2.jpg", "caption": "Table 6: Divergence (mean and standard deviation) out of 10,000 samples with different strategies on the grouseticks model across 5 random seeds under different target probabilities. We use M1 to represent marginalizing u\u2081, M2 to represent marginalizing u\u2082, R1 to represent reparameterizing u\u2081, R2 to represent reparameterizing u\u2082.", "description": "This table shows the number of divergences encountered during Hamiltonian Monte Carlo (HMC) sampling for the grouse ticks model under various conditions.  The conditions involve different combinations of marginalizing (M1, M2) and reparameterizing (R1, R2) two different random effects (u1 and u2) in the model.  The results are averaged over five independent runs with different random seeds, illustrating the impact of these transformations on HMC's sampling performance in terms of divergences, which are a measure of problematic steps taken by the sampler.", "section": "6.2 Marginalization vs reparameterization"}]