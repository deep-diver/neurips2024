[{"figure_path": "uXuObobJHO/figures/figures_1_1.jpg", "caption": "Figure 1: A tree-structured model conditioned on \u0398.", "description": "This figure is a graphical model showing the conditional independence structure of a linear mixed-effects model.  The nodes represent variables, and the edges represent conditional dependencies.  \u0398 represents the global variables (fixed effects and hyperparameters), u1 and u2 are random effects (e.g., for different subjects or groups), and y1, y2, and y3 are observations. The tree structure is crucial for efficient computations in the marginalization algorithm.", "section": "2 Background"}, {"figure_path": "uXuObobJHO/figures/figures_6_1.jpg", "caption": "Figure 2: Average ESS for each variable on the instruction evaluation model with different HMC strategies. Numbers above the sample size 100,000 indicate effective sampling.", "description": "This figure compares the Effective Sample Size (ESS) per variable for different Hamiltonian Monte Carlo (HMC) sampling strategies applied to the ETH instructor evaluation model.  The strategies include no marginalization and marginalizing different groups of random effects (u1, u2, u3, or all u's).  The higher the ESS, the more efficient the sampling for that variable. Numbers above the bars indicate that effective sample size is above the 100,000 samples collected.", "section": "6.1 Marginalization in cross-effects models"}, {"figure_path": "uXuObobJHO/figures/figures_7_1.jpg", "caption": "Figure 3: Distribution of 10,000 samples for variable pairs (\u03c31, u1,1) and (\u03c32, u2,61) on the grouse-ticks model with different methods. We use M1 to represent marginalizing u1, M2 to represent marginalizing u2, R1 to represent reparameterizing u\u2081, R2 to represent reparameterizing u2. The number of divergences for each case are reported, with locations shown as red dots. We choose u2,61 to demonstrate the distribution of divergences when reparameterizing u2.", "description": "This figure compares the performance of marginalization and reparameterization on the grouse ticks model by visualizing the distributions of 10,000 samples for variable pairs (\u03c31, u1,1) and (\u03c32, u2,61).  Different methods are compared: no marginalization, marginalizing u1, marginalizing u2, marginalizing u1 and reparameterizing u2, marginalizing u2 and reparameterizing u1, and reparameterizing u1 and u2.  Red dots represent divergences. The figure shows that marginalization generally leads to better sampling behavior with fewer divergences, especially when marginalizing u2.", "section": "6.2 Marginalization vs reparameterization"}, {"figure_path": "uXuObobJHO/figures/figures_8_1.jpg", "caption": "Figure 4: Experimental results for the 9 cognitive science datasets with and without marginalization. Each experiment is performed 5 times with different random seeds. Marginalization usually improves sampling speed measured by iterations per second (iter/s) and sample efficiency measured by ESS per iteration (ESS/iter).", "description": "This figure presents the experimental results of applying the proposed marginalization technique to nine different cognitive science datasets.  The results are compared against the standard Hamiltonian Monte Carlo (HMC) approach without marginalization. The figure displays two key metrics: iterations per second (iter/s) representing sampling speed, and effective sample size per iteration (ESS/iter) indicating sample efficiency.  Error bars are included to show variability across the five runs with different random seeds for each dataset and method. The results demonstrate that marginalization generally leads to faster sampling (higher iter/s) and more efficient sampling (higher ESS/iter) in most cases.", "section": "6.4 Applications in cognitive sciences"}, {"figure_path": "uXuObobJHO/figures/figures_15_1.jpg", "caption": "Figure 1: A tree-structured model conditioned on \u0398.", "description": "This figure is a graphical representation of a linear mixed-effects model (LMM) with a tree structure.  The nodes represent variables, with \u0398 representing global variables (like hyperparameters), u1 and u2 representing random effects, and y1, y2, and y3 representing observations.  The arrows indicate conditional dependencies: the observations depend on the random effects, and the random effects depend on the global variables. This tree structure is crucial for the efficiency of the marginalization algorithm described in the paper, as it allows for computationally efficient matrix operations.", "section": "2 Background"}, {"figure_path": "uXuObobJHO/figures/figures_19_1.jpg", "caption": "Figure 6: Trace plots for \u03b12,1, \u03b13,1 and \u03c3 of an interval of 1,000 sampling steps after warmup on the ETH instructor evaluation model, using the same data as Figure 2 in the paper.", "description": "This figure shows the trace plots of three variables (\u03b12,1, \u03b13,1, and \u03c3) from the ETH instructor evaluation model after a 1000 sampling steps warmup period.  The trace plots illustrate the convergence behavior of the Markov chain Monte Carlo (MCMC) sampling process for these parameters under different marginalization strategies. The purpose is to visually assess the mixing properties and stability of the MCMC sampler when marginalizing different sets of random effects (u1, u2, u3, or all of them).", "section": "Additional experimental results"}, {"figure_path": "uXuObobJHO/figures/figures_20_1.jpg", "caption": "Figure 3: Distribution of 10,000 samples for variable pairs (\u03c31, u1,1) and (\u03c32, u2,61) on the grouse-ticks model with different methods. We use M1 to represent marginalizing u1, M2 to represent marginalizing u2, R1 to represent reparameterizing u\u2081, R2 to represent reparameterizing u2. The number of divergences for each case are reported, with locations shown as red dots. We choose u2,61 to demonstrate the distribution of divergences when reparameterizing u2.", "description": "This figure compares the performance of marginalization and reparameterization on the grouse ticks model. It shows the distribution of 10,000 samples for two pairs of variables, (\u03c31, u1,1) and (\u03c32, u2,61), under different sampling strategies: marginalizing u1 (M1), marginalizing u2 (M2), reparameterizing u1 (R1), and reparameterizing u2 (R2).  The number of divergences (HMC sampling failures) is also reported for each case, highlighted with red dots.  The plots illustrate how marginalization effectively addresses the problematic correlations that hinder efficient sampling in the original model, while reparameterization is less successful in this regard.", "section": "6.2 Marginalization vs reparameterization"}, {"figure_path": "uXuObobJHO/figures/figures_20_2.jpg", "caption": "Figure 3: Distribution of 10,000 samples for variable pairs (\u03c31, u1,1) and (\u03c32, u2,61) on the grouse-ticks model with different methods. We use M1 to represent marginalizing u1, M2 to represent marginalizing u2, R1 to represent reparameterizing u\u2081, R2 to represent reparameterizing u2. The number of divergences for each case are reported, with locations shown as red dots. We choose u2,61 to demonstrate the distribution of divergences when reparameterizing u2.", "description": "This figure compares the performance of marginalization and reparameterization in handling the funnel shape pathology in the grouse ticks model.  It shows the distributions of samples for two pairs of variables, highlighting the impact of each method on sampling efficiency and the occurrence of divergences (indicated by red dots). The results demonstrate that marginalization effectively addresses the funnel problem and reduces divergences, whereas reparameterization may still suffer from some pathologies, leading to a higher number of divergences.", "section": "6.2 Marginalization vs reparameterization"}, {"figure_path": "uXuObobJHO/figures/figures_20_3.jpg", "caption": "Figure 3: Distribution of 10,000 samples for variable pairs (\u03c31, u1,1) and (\u03c32, u2,61) on the grouse-ticks model with different methods. We use M1 to represent marginalizing u1, M2 to represent marginalizing u2, R1 to represent reparameterizing u\u2081, R2 to represent reparameterizing u2. The number of divergences for each case are reported, with locations shown as red dots. We choose u2,61 to demonstrate the distribution of divergences when reparameterizing u2.", "description": "This figure compares the performance of marginalization and reparameterization on a specific model (grouse ticks model) by visualizing the distribution of samples for selected variable pairs (\u03c31, u1,1) and (\u03c32, u2,61). The different methods used are marginalization of u1 (M1), marginalization of u2 (M2), reparameterization of u1 (R1), and reparameterization of u2 (R2).  Red dots indicate divergences. The plots reveal that marginalization is better at avoiding divergences than reparameterization in this model.", "section": "6.2 Marginalization vs reparameterization"}]