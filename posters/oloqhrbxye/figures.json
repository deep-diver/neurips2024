[{"figure_path": "oLoqHRbXYE/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of unsupervised domain adaptation (UDA) and source-free UDA frameworks. (i) UDA problem. (ii) Source-free UDA by self-training. STAR works by selecting high-quality pseudo labels and guiding the ASR foundation model's adaptation at the token level.", "description": "This figure illustrates two scenarios of unsupervised domain adaptation (UDA) for automatic speech recognition (ASR). The left panel (i) shows the standard UDA problem, where labeled source data and unlabeled target domain data are used to adapt the ASR model. The right panel (ii) shows the source-free UDA approach proposed in the paper, called STAR. In this scenario, only unlabeled data from the target domain is used. The STAR framework selects high-quality pseudo labels from the unlabeled target data and uses them to guide the model's adaptation at the token level, enhancing the model's robustness in diverse target domains such as noise and accents.", "section": "1 Introduction"}, {"figure_path": "oLoqHRbXYE/figures/figures_4_1.jpg", "caption": "Figure 2: (Left): An example of pseudo label, ground-truth transcription, confidence scores, attention matrix and attentive scores. (Right-Up): Confusion matrix of confidence and attentive scores, where the y-axis denotes the pseudo token is correct or wrong, and the x-axis denotes the corresponding score is high or low (with 1 as the threshold, more analysis is in Fig. 6), so that the diagonal values indicate the score\u2019s reliability in assessing the quality of pseudo-label. (Right-Down): Variance of the two scores of correct and wrong pseudo tokens.", "description": "This figure presents a detailed analysis of pseudo-label quality assessment using confidence and attentive scores. The left panel shows an example with pseudo label, ground truth, confidence scores, attention matrix and attentive scores.  The top-right panel is a confusion matrix comparing confidence and attentive scores against the correctness of pseudo tokens. The bottom-right panel shows the variance of the two scores for both correct and incorrect pseudo tokens, highlighting the reliability and stability of each score in evaluating pseudo-label quality.", "section": "3.2 Token-level Assessment and Re-weighting"}, {"figure_path": "oLoqHRbXYE/figures/figures_8_1.jpg", "caption": "Figure 3: WER (%) results with different numbers of unlabeled training samples. The minimum required data amount (in hours) to obtain the best performance is highlighted in the star mark.", "description": "This figure shows the word error rate (WER) achieved by the STAR model on four different datasets (CHiME-4 test-real, Common Voice African, TED-LIUM 3, and ATIS) as a function of the amount of unlabeled training data used.  The x-axis represents the number of unlabeled training samples, and the y-axis represents the WER.  Each line represents a different dataset. The figure demonstrates the data efficiency of the STAR model;  the minimum amount of data needed to achieve the best performance (indicated by a star) is quite small for each dataset, suggesting that STAR can effectively adapt to various domains with limited unlabeled data.", "section": "5.3 Generality of STAR"}, {"figure_path": "oLoqHRbXYE/figures/figures_16_1.jpg", "caption": "Figure 4: Spectrograms of parallel clean and noisy speech samples, where we select two noise types for visualization, i.e., airport station and babble (used in our experiments). The speech samples are selected from the LS-FreeSound test set, and the sample ID is \u201c1089-134686-0003\u201d.", "description": "This figure visualizes spectrograms of clean speech and noisy speech with two types of noise: airport and babble. The clean speech shows clear patterns, while the noisy speech shows significant corruption, especially babble noise which masks the speech patterns more completely than airport noise. This visual comparison highlights the distinct acoustic differences between clean and noisy speech domains, which are important factors influencing ASR performance.", "section": "Visualization of Speech Domains Distinction"}, {"figure_path": "oLoqHRbXYE/figures/figures_17_1.jpg", "caption": "Figure 2: (Left): An example of pseudo label, ground-truth transcription, confidence scores, attention matrix and attentive scores. (Right-Up): Confusion matrix of confidence and attentive scores, where the y-axis denotes the pseudo token is correct or wrong, and the x-axis denotes the corresponding score is high or low (with 1 as the threshold, more analysis is in Fig. 6), so that the diagonal values indicate the score's reliability in assessing the quality of pseudo-label. (Right-Down): Variance of the two scores of correct and wrong pseudo tokens.", "description": "This figure demonstrates the difference between confidence scores and attentive scores in evaluating the quality of pseudo labels.  The left panel shows an example of a pseudo label, ground truth, confidence scores, the attention matrix and derived attentive scores.  The top-right panel provides a confusion matrix visualizing the relationship between confidence and attentive scores and the quality of pseudo labels. The bottom-right panel compares the variance of both scores for correct and incorrect pseudo tokens.", "section": "3.2 Token-level Assessment and Re-weighting"}, {"figure_path": "oLoqHRbXYE/figures/figures_18_1.jpg", "caption": "Figure 2: (Left): An example of pseudo label, ground-truth transcription, confidence scores, attention matrix and attentive scores. (Right-Up): Confusion matrix of confidence and attentive scores, where the y-axis denotes the pseudo token is correct or wrong, and the x-axis denotes the corresponding score is high or low (with 1 as the threshold, more analysis is in Fig. 6), so that the diagonal values indicate the score's reliability in assessing the quality of pseudo-label. (Right-Down): Variance of the two scores of correct and wrong pseudo tokens.", "description": "This figure shows a comparison of different metrics for evaluating the quality of pseudo-labels generated by the ASR model.  The left panel shows an example of a pseudo-label, the ground truth, confidence scores, attention matrix, and attentive scores for a single utterance. The top-right panel presents a confusion matrix comparing confidence scores and attentive scores to the accuracy of the pseudo-labels (correct/incorrect). The bottom-right panel displays the variance of both scores for correct versus incorrect pseudo-labels.  This demonstrates the reliability and stability of the proposed attentive score in assessing pseudo-label quality for guiding model adaptation.", "section": "3.2 Token-level Assessment and Re-weighting"}, {"figure_path": "oLoqHRbXYE/figures/figures_18_2.jpg", "caption": "Figure 6: Confusion matrix of confidence score and attentive score in terms of different thresholds for separating large and small groups.", "description": "This figure displays three confusion matrices, each showing the performance of confidence scores and attentive scores at different thresholds.  Each matrix compares the accuracy of classifying pseudo-labels as either correct or incorrect based on the values of the scores. The three matrices represent different approaches to aggregating the attention weights: using only history tokens, only future tokens, or both history and future tokens. The color intensity represents the proportion of correctly or incorrectly classified tokens.  This helps illustrate the relative strengths and weaknesses of each scoring method in assessing the quality of the pseudo-labels for guiding model adaptation.", "section": "3.2 Token-level Assessment and Re-weighting"}, {"figure_path": "oLoqHRbXYE/figures/figures_21_1.jpg", "caption": "Figure 1: Illustration of unsupervised domain adaptation (UDA) and source-free UDA frameworks. (i) UDA problem. (ii) Source-free UDA by self-training. STAR works by selecting high-quality pseudo labels and guiding the ASR foundation model's adaptation at the token level.", "description": "This figure illustrates the difference between unsupervised domain adaptation (UDA) and source-free UDA. The left side shows a typical UDA setting where both labeled source data and unlabeled target data are used to train a model. In contrast, the right side depicts a source-free UDA setting where only unlabeled target data is used. The STAR method is shown as a way to select high-quality pseudo-labels and guide model adaptation at the token level in a source-free setting.", "section": "1 Introduction"}]