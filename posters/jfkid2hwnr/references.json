{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduced the transformer architecture, which is foundational to the Medformer model and many other time series models."}, {"fullname_first_author": "Haixu Wu", "paper_title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting", "publication_date": "2021-12-01", "reason": "Autoformer is a key baseline model in this paper and a prominent transformer-based time series model."}, {"fullname_first_author": "Yunhao Zhang", "paper_title": "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting", "publication_date": "2022-05-01", "reason": "Crossformer is another important baseline and a direct comparison for Medformer, showcasing a different approach to handling multivariate time series."}, {"fullname_first_author": "Tian Zhou", "paper_title": "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting", "publication_date": "2022-07-01", "reason": "FEDformer represents another strong baseline method incorporating frequency domain information, a concept relevant to Medformer's multi-granularity approach."}, {"fullname_first_author": "Yihe Wang", "paper_title": "Contrast everything: A hierarchical contrastive framework for medical time-series", "publication_date": "2024-01-01", "reason": "This paper by the same authors introduces a related method and shares similar problem setups, providing context for the Medformer approach."}]}