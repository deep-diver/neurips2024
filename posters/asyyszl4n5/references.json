{"references": [{"fullname_first_author": "Tianyu Gu", "paper_title": "Badnets: Evaluating backdooring attacks on deep neural networks", "publication_date": "2019-00-00", "reason": "This paper is foundational for the field of backdoor attacks on deep neural networks, introducing the concept and providing an initial benchmark for future work."}, {"fullname_first_author": "Zhenting Wang", "paper_title": "Rethinking the reverse-engineering of trojan triggers", "publication_date": "2022-00-00", "reason": "This paper significantly improves upon feature space trigger inversion, offering a more efficient and robust approach to backdoor detection than previous methods."}, {"fullname_first_author": "Zhenting Wang", "paper_title": "UNICORN: A unified backdoor trigger inversion framework", "publication_date": "2023-00-00", "reason": "This paper proposes a more general and effective trigger inversion approach that works across various trigger types and attacks, leading to a more widely applicable method for backdoor detection."}, {"fullname_first_author": "Xiong Xu", "paper_title": "Towards reliable and efficient backdoor trigger inversion via decoupling benign features", "publication_date": "2024-00-00", "reason": "This paper introduces a novel decoupling technique that improves the efficiency and effectiveness of feature space trigger inversion, resulting in a state-of-the-art defense against backdoor attacks."}, {"fullname_first_author": "Yingqi Liu", "paper_title": "Trojaning attack on neural networks", "publication_date": "2018-00-00", "reason": "This paper is among the first to introduce the concept of backdoor attacks on neural networks, demonstrating that carefully crafted poisoned data can be used to create malicious models with hidden functionalities."}]}