[{"figure_path": "TADTT9ughN/tables/tables_16_1.jpg", "caption": "Table 1: Training Hyperparameters.", "description": "This table lists all the hyperparameters used in the training process of the BAL-PM model and other baselines.  It includes values for batch sizes, network architecture parameters (layers, activation function), learning rate and scheduler, optimizer, and parameters for the entropy term in the BAL-PM objective function, as well as hyperparameters for other baseline methods (SoftmaxBALD, SoftRankBALD, PowerBALD).", "section": "C Hyperparameters"}, {"figure_path": "TADTT9ughN/tables/tables_16_2.jpg", "caption": "Table 2: Hyperparameters search space.", "description": "This table shows the range of values explored for each hyperparameter during the hyperparameter search.  The hyperparameters control various aspects of the BAL-PM algorithm, including the balance between epistemic uncertainty and entropy, and parameters for the baseline methods (SoftmaxBALD, SoftRankBALD, PowerBALD). The search was conducted to find optimal values that maximize performance on a held-out validation set.", "section": "C Hyperparameters"}]