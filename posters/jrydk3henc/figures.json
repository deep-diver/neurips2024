[{"figure_path": "JrYdk3HEnc/figures/figures_6_1.jpg", "caption": "Figure 1: Bounding the states and their derivatives separately. We employ Gronwall's inequality with the induction method to bound the states.", "description": "The figure illustrates the method used to bound the states and their derivatives in a continuous-time system.  It shows three concentric circles representing bounds on previous states, previous state derivatives, and the current state and its derivative.  The iterative application of Gronwall's inequality with induction allows for bounding of the states, a key step in proving sublinear regret for the continuous online control algorithm.", "section": "Challenge and Proof Sketch"}, {"figure_path": "JrYdk3HEnc/figures/figures_7_1.jpg", "caption": "Figure 2: Leverage past observation of states with some skip.", "description": "This figure shows the architecture of the proposed method. The replay buffer stores past observations. The observation augmentation module processes the observations using a stack and skip mechanism, augmenting the current observation with past observations. The augmented observation is fed to the RL agent, which interacts with the randomized environment to learn an optimal policy. This module simulates the non-stochastic environment by randomizing parameters at the start of each episode.", "section": "6 Experiments"}, {"figure_path": "JrYdk3HEnc/figures/figures_8_1.jpg", "caption": "Figure 3: Impact of frame stack number.", "description": "This figure shows the impact of the frame stack number on the agent's performance in the hopper environment. The x-axis represents the foot friction parameter, and the y-axis represents the reward.  Different lines represent different frame stack numbers (1, 2, 3, and 5). The shaded area around each line represents the standard deviation across multiple trials. The results suggest that increasing the frame stack number improves performance, and the optimal performance occurs with a frame stack number of 3. Using more than 3 frames does not further improve performance.", "section": "6 Experiments"}, {"figure_path": "JrYdk3HEnc/figures/figures_8_2.jpg", "caption": "Figure 4: Impact of frame skip number.", "description": "This figure shows the impact of varying the frame skip number (m) on the agent's performance in the Hopper environment. The x-axis represents the foot friction, while the y-axis shows the average reward obtained.  Three different frame skip numbers (1, 3, and 5) are compared against a standard SAC agent. The shaded areas represent the standard deviation across three random seeds.  The results indicate that a frame skip number of 3 yields the best performance, while both larger and smaller values result in suboptimal rewards.", "section": "6 Experiments"}, {"figure_path": "JrYdk3HEnc/figures/figures_8_3.jpg", "caption": "Figure 6: Performance in half-cheetah(Top) and walker2d(Bottom).", "description": "This figure displays the performance comparison between the standard SAC algorithm and the proposed SAC with history algorithm on the HalfCheetah and Walker2d environments.  The x-axis represents the value of a specific domain randomization parameter (joint damping for the top row and foot friction for the bottom row), while the y-axis represents the reward achieved by each algorithm.  Each data point represents the average reward obtained over three independent trials.  The figure visually demonstrates that the algorithm with history consistently outperforms the baseline.", "section": "6 Experiments"}, {"figure_path": "JrYdk3HEnc/figures/figures_8_4.jpg", "caption": "Figure 6: Performance in half-cheetah(Top) and walker2d(Bottom).", "description": "This figure shows the performance comparison between the standard SAC algorithm and the proposed algorithm with the frame stack and skip mechanism.  The results are presented for two different MuJoCo environments: Half-Cheetah (top) and Walker2D (bottom).  Each environment has different parameters (joint damping, foot friction, torso size, density) that are individually varied and tested, showing the reward obtained under various conditions.  The shaded regions represent the standard deviation across multiple training runs.", "section": "Experiments"}, {"figure_path": "JrYdk3HEnc/figures/figures_8_5.jpg", "caption": "Figure 6: Performance in half-cheetah(Top) and walker2d(Bottom).", "description": "This figure displays the performance comparison between the standard SAC algorithm and the proposed algorithm incorporating frame stacking and skipping techniques. The results are shown across three different environments (half-cheetah and walker2d) and various hyperparameter settings, showcasing the consistent superiority of the proposed algorithm in diverse conditions.", "section": "6 Experiments"}]