[{"figure_path": "Kcsj9FGnKR/figures/figures_1_1.jpg", "caption": "Figure 1: The samples generated by diffusion models improve long-tail classification on CIFAR100-LT, showing a correlation between FID and accuracy and a stronger correlation between the proportion of AID samples and accuracy. Our method significantly boosts classifier accuracy compared with others (left). Feature space visualization reveals that different diffusion models generate samples with varying distributions, and our model biases the generative process toward AID samples (right).", "description": "The figure shows two plots demonstrating the effectiveness of the proposed method (DiffuLT) in improving long-tail image classification. The left plot shows a strong correlation between the FID score (a measure of generated image quality) and classification accuracy, with DiffuLT achieving the highest accuracy at the lowest FID.  The right plot is a feature space visualization showing how DiffuLT generates samples that are closer to \"approximately in-distribution\" (AID) samples (samples slightly deviating from the real data distribution but containing blended class information) compared to other methods.  AID samples are considered crucial for improving the classifier's performance on long-tail data.", "section": "1 Introduction"}, {"figure_path": "Kcsj9FGnKR/figures/figures_4_1.jpg", "caption": "Figure 2: Visualization of generated samples for class 90 in feature space using t-SNE. The associated model is indicated in the upper-left corner.", "description": "This figure visualizes the generated samples for class 90 (truck) of the CIFAR100-LT dataset using t-SNE, a dimensionality reduction technique.  It shows how different diffusion models generate samples with varying distributions in the feature space.  The four subplots represent samples generated by four different models: DDPM, and CBDM with different hyperparameters (\u03c4=3, \u03c4=2, \u03c4=1). The visualization helps understand how modifying the model affects the distribution of generated samples and their proximity to real samples of the same class.  The goal is to identify which samples are most beneficial for improving the accuracy of a classifier trained on the generated samples.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/figures/figures_5_1.jpg", "caption": "Figure 3: Examples of three groups of generated samples.", "description": "This figure shows example images of samples generated by the DiffuLT model, categorized into three groups: In-distribution (ID), Approximately In-distribution (AID), and Out-of-distribution (OOD).  The ID samples closely resemble real images from the dataset. AID samples show a blend of features from multiple classes, exhibiting a mix of characteristics from both head and tail classes.  OOD samples are significantly different from the original images and appear less realistic or contain significant artifacts. The figure visually demonstrates how the AID samples effectively bridge the gap between head and tail classes, highlighting their importance in improving long-tail recognition performance. This image is part of the explanation of how the AID samples (a blend of head and tail class features) generated by the model are instrumental to the improved classifier accuracy.", "section": "Mechanisms behind the AID samples"}, {"figure_path": "Kcsj9FGnKR/figures/figures_6_1.jpg", "caption": "Figure 4: The overall pipeline of our method DiffuLT.", "description": "This figure illustrates the overall pipeline of the DiffuLT method. It begins with training a feature extractor and an AID-biased diffusion model using the original imbalanced dataset. The trained diffusion model then generates new samples that are subsequently filtered using the feature extractor, resulting in a refined dataset. Finally, a classifier is trained using the augmented dataset, with a weighted cross-entropy loss, to enhance performance. The figure visually represents the flow of the process, highlighting the key steps and components involved.", "section": "3.3 Overall Pipeline and Discussion"}, {"figure_path": "Kcsj9FGnKR/figures/figures_14_1.jpg", "caption": "Figure 5: Generated images for CIFAR100-LT", "description": "This figure shows example images generated by the DiffuLT model for CIFAR100-LT.  The images represent various classes from the dataset, with a focus on those classes with few examples in the original dataset.  This demonstrates the model's ability to synthesize plausible images even for under-represented categories, effectively augmenting the training data to improve the classification performance of a long-tailed recognition model.", "section": "A.2 Generated Images"}, {"figure_path": "Kcsj9FGnKR/figures/figures_14_2.jpg", "caption": "Figure 3: Examples of three groups of generated samples.", "description": "This figure shows example images generated by a diffusion model and categorized into three groups: in-distribution (ID), approximately in-distribution (AID), and out-of-distribution (OOD).  The ID samples closely resemble real images from the dataset. AID samples blend features from multiple classes, representing a combination of head and tail class characteristics, demonstrating a fusion of information crucial for improving the classifier's accuracy. The OOD samples show noticeable deviations or anomalies compared to the real images.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/figures/figures_15_1.jpg", "caption": "Figure 3: Examples of three groups of generated samples.", "description": "This figure shows example images generated by the DiffuLT model, categorized into three groups: in-distribution (ID), approximately in-distribution (AID), and out-of-distribution (OOD).  ID samples closely resemble real images from the dataset. AID samples blend features from both head and tail classes, exhibiting a fusion of characteristics.  OOD samples deviate significantly from the original data distribution, often appearing as anomalies or unrealistic combinations of features. The figure visually demonstrates the model's ability to generate a range of samples with varying degrees of similarity to the real data, highlighting the importance of AID samples for improving long-tail classification performance.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/figures/figures_17_1.jpg", "caption": "Figure 8: Main caption describing all images", "description": "This figure compares three approaches to long-tail recognition. (a) shows traditional methods that focus on training, (b) illustrates data synthesis methods that augment the data with additional images, and (c) presents the proposed DiffuLT method that uses a diffusion model to generate additional AID samples to enhance the classification performance of long-tail datasets.  The bar chart shows the imbalanced nature of a long-tailed dataset, highlighting the scarcity of samples in tail classes.", "section": "B Discussion"}]