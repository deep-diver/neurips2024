{"references": [{"fullname_first_author": "Pang Wei Koh", "paper_title": "Concept bottleneck models", "publication_date": "2020-07-13", "reason": "This paper introduces the core concept bottleneck model, which is the foundational model for the current research."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "CLIP model is used as a fundamental component for generating concepts and embeddings in this research."}, {"fullname_first_author": "Ranjay Krishna", "paper_title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations", "publication_date": "2017-05-01", "reason": "Visual Genome dataset is used for the MetaShift dataset, which is used for evaluating robustness of models."}, {"fullname_first_author": "Weixin Liang", "paper_title": "Metashift: A dataset of datasets for evaluating contextual distribution shifts and training conflicts", "publication_date": "2022-00-00", "reason": "MetaShift dataset is used for evaluating the robustness of the proposed model under distribution shifts."}, {"fullname_first_author": "Alex Krizhevsky", "paper_title": "Learning multiple layers of features from tiny images", "publication_date": "2009-00-00", "reason": "CIFAR-10 dataset, used for evaluating data efficiency of the proposed model, is based on this work."}]}