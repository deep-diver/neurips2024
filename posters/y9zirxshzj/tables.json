[{"figure_path": "y9zIRxshzj/tables/tables_19_1.jpg", "caption": "Table 1: Average F1 score on Multiple Parents experiment with multiple colliders.", "description": "This table shows the average F1 score achieved by the CASCADE algorithm in an experiment designed to evaluate its performance under conditions with multiple colliders.  The experiment manipulates the number of colliders (nodes where multiple parent nodes converge), ranging from 5 to 20.  The F1 score measures the effectiveness of the algorithm in correctly identifying the causal relationships.", "section": "6.2 Synthetic Data"}, {"figure_path": "y9zIRxshzj/tables/tables_19_2.jpg", "caption": "Table 2: Average results on 90% instant data", "description": "This table shows the performance of four different causal discovery methods (CASCADE, CAUSE, NPHC, and THP) on a dataset where 90% of the causal effects are instantaneous.  The metrics used for evaluation include F1 score (a measure of accuracy), SHD (Structural Hamming Distance, which measures the difference in graph structure), SID (Structural Intervention Distance, which quantifies the difference in causal effects), and normalized versions of SHD and SID.  The NaN values likely indicate that a particular method did not produce a DAG (directed acyclic graph) which is needed for SID calculation. The results suggest that CASCADE outperforms the other methods in this setting.", "section": "6.2 Synthetic Data"}, {"figure_path": "y9zIRxshzj/tables/tables_19_3.jpg", "caption": "Table 2: Average results on 90% instant data", "description": "This table presents the average results for four different methods (CASCADE, CAUSE, NPHC, and THP) on a dataset where 90% of the causal effects are instantaneous.  The metrics used for evaluation are F1 score, Structural Hamming Distance (SHD), Structural Intervention Distance (SID), normalized SHD, and normalized SID.  The NaN values likely indicate that a specific metric could not be calculated for that method due to the structure of the DAGs recovered.", "section": "6.2 Synthetic Data"}, {"figure_path": "y9zIRxshzj/tables/tables_20_1.jpg", "caption": "Table 4: Mean runtime, in seconds, of Increase Event Types Experiment", "description": "This table presents the average runtime (in seconds) for the \"Increase of Event Types\" experiment. It shows how the runtime of different causal discovery methods (CASCADE, CAUSE, NPHC, THP, MDLH) varies with the number of event types (5, 10, 15, 20, 30, 40).  The results highlight the scalability of each method, showing how runtime increases as the number of event types grows. Note that MDLH did not finish within the allocated time for experiments with more than 10 event types.", "section": "6 Experiments"}, {"figure_path": "y9zIRxshzj/tables/tables_20_2.jpg", "caption": "Table 5: Mean runtime, in seconds, under increasing Noise.", "description": "This table presents the average runtime in seconds for different algorithms (CASCADE, CAUSE, NPHC, THP) under varying noise levels (0.10 to 0.90).  It demonstrates how the runtime of each algorithm changes as the amount of noise in the data increases.  The results highlight the relative computational efficiency or scalability of the different methods.", "section": "6.2 Synthetic Data"}, {"figure_path": "y9zIRxshzj/tables/tables_20_3.jpg", "caption": "Table 6: Mean runtime, in seconds, of Increase Event Types (Collider Experiment)", "description": "This table shows the runtime of different causal discovery methods (CASCADE, CAUSE, NPHC, THP) on synthetic datasets with varying numbers of event types. The experiment involves increasing the number of event types from 50 to 200, while introducing colliders in the causal graph to make the causal discovery more challenging. The results show the mean runtime in seconds for each method and event type.  Note that THP and MDLH did not complete within the allotted time for larger datasets.", "section": "6.2 Synthetic Data"}]