[{"type": "text", "text": "Causal vs. Anticausal merging of predictors ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Patrick Bl\u00f6baum Amazon T\u00fcbingen, Germany ", "page_idx": 0}, {"type": "text", "text": "Sergio Hernan Garrido Mejia Max Planck Institute for Intelligent Systems Amazon T\u00fcbingen, Germany shgm@tuebingen.mpg.de ", "page_idx": 0}, {"type": "text", "text": "Bernhard Sch\u00f6lkopf Max Planck Institute for Intelligent Systems T\u00fcbingen, Germany ", "page_idx": 0}, {"type": "text", "text": "Dominik Janzing Amazon T\u00fcbingen, Germany ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the differences arising from merging predictors in the causal and anticausal directions using the same data. In particular we study the asymmetries that arise in a simple model where we merge the predictors using one binary variable as target and two continuous variables as predictors. We use Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors, however, we expect similar differences to hold also when we use other merging methods that take into account asymmetries between cause and effect. We show that if we observe all bivariate distributions, the CMAXENT solution reduces to a logistic regression in the causal direction and Linear Discriminant Analysis (LDA) in the anticausal direction. Furthermore, we study how the decision boundaries of these two solutions differ whenever we observe only some of the bivariate distributions implications for Out-Of-Variable (OOV) generalisation. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "A common problem in machine learning and statistics consists of estimating or combining models or (expert opinions) of a target variable of interest into a single, hopefully better, model [14]. There are several reasons of why this problem is important. For example, experts might have access to different data when creating their models, but might not have access to the data available to other experts, while there might be a modeller who can access the expert\u2019s opinions and put them together into a single model. Furthermore, experts might specialise in certain areas of the support of the input space, so that a modeller with access to the expert\u2019s opinions could potentially produce a single model exploiting the strengths of each modeller. This problem is commonly known as \u201cmixture of experts\u201d, \u201cexpert aggregation\u201d, \u201cmerging of experts\u201d or \u201cexpert pooling\u201d [40, 22, 6, 31, 30]. ", "page_idx": 0}, {"type": "text", "text": "The merging of experts problem is usually ill-defined, in the sense that there are multiple joint models (that is, models that include all covariates) that after marginalisation would render the same prediction as the individual experts (that is, those which include only some of the covariates). This ill-definedness of the problem requires strong inductive biases. One way to provide this inductive bias in a principled way is through the Maximum Entropy (MAXENT) principle [20]. In brief, MAXENT suggests finding the distribution with maximum Shannon entropy subject to moment constraints. This turns out to be the same as choosing the distribution closest to the uniform distribution having the same moments as those given by the constraints. In Section 2.2 we introduce MAXENT and Causal MAXENT (CMAXENT) in more detail, the latter being an extension that allows to include causal information when available [17]. ", "page_idx": 0}, {"type": "text", "text": "Most of the research on the merging of predictors focuses on finding a meta-predictor that uses the given models and best ftis to the data [41], whereas the focus of the present article is understanding the implications of causal assumptions in the merging of experts instead of aiming for models with best performance. Furthermore, most of this research focuses on predictors that use the same predicting variables for each of the models. To the best of our knowledge, the only exception is the random subspace method, notable for being the basis of random forests [15]. ", "page_idx": 1}, {"type": "text", "text": "What if in addition to the different models, a researcher has some causal knowledge of the underlying system? For example, they could know whether a variable or set of variables used in a particular model are causes or effects of the target variable, potentially changing the resulting predictor of interest. Causal knowledge produces asymmetries that have been exploited in the past to understand some common machine learning tasks like transfer learning, semi-supervised learning or distribution shift [35, 39, 18, 21]. ", "page_idx": 1}, {"type": "text", "text": "In the present work, we investigate how including causal knowledge produces asymmetric results when merging predictors. In particular, we are interested in how solutions to the CMAXENT principle [17] differ when we assume different causal relations for the same data. That is, we are interested in the asymmetries produced by causal assumptions on CMAXENT inferences. In particular, we will study the differences in the solutions when we assume the causal data generation process (so that the covariates or predictors are causal parents of our target variable) in contrast with the anticausal generation process (so that the predictors are causal children of our target variable). We are going to study these asymmetries in the case where we do not observe all the variables jointly; one of the differentiating characteristics of this research with respect to other merging of predictors work. ", "page_idx": 1}, {"type": "text", "text": "Including the right causal assumptions when merging predictors is relevant, for instance, in the medical domain. Suppose we are interested in the presence or absence of a disease, and we have models from hospitals and labs relating risk factors and symptoms to the disease we are interested in. Combining the predictors would be valuable to predict the disease but it also requires to include the right causal assumptions, if the direction matters for the merging of predictors: risk factors cause diseases and diseases cause symptoms. The literature of merging of predictors has focused on important aspects of the resulting models like generalisation bounds or speed of estimation but the relation to causality has remained largely unexplored. ", "page_idx": 1}, {"type": "text", "text": "Previous approaches have considered the problem of merging of experts using MAXENT [25, 27, 34]. However, such research considers the problem from a purely statistical perspective and does not study the ramifications of different causal assumptions. In fact, the way they study the aggregation problem is by merging the probability of the outcome given by each expert without regarding how these probabilities were produced. ", "page_idx": 1}, {"type": "text", "text": "The main contributions of this article can be summarised as follows ", "page_idx": 1}, {"type": "text", "text": "\u2022 We study the differences in causal and anticausal merging of predictors whenever the inductive bias used to merge the predictors allows causal information to be included.   \n\u2022 In particular, we find that CMAXENT with a binary target and continuous covariates, reduces to logistic regression and LDA, two classic classification algorithms, when merging predictors in causal and anticausal directions, respectively.   \n\u2022 Furthermore, we study the implications of these asymmetries Out Of Variable (OOV) generalisation whenever we do not observe all the first and second moments as constraints in the CMAXENT problem. ", "page_idx": 1}, {"type": "text", "text": "The remainder of the paper is organised as follows. In Section 2 we introduce basic notation and give a brief overview of MAXENT and CMAXENT. Then, in Section 3 we present the optimisation problem in the causal and anticausal direction and give the explicit solutions of the problems, thereby connecting the solutions of CMAXENT to well-known classification algorithms. In addition, we prove that the decision boundary in the causal and anticausal directions, with full knowledge of the moments (as defined in the section itself) renders equal slopes of the predictors. In Section 4 we weaken the assumption of full knowledge of the moments and instead assume knowledge of a subset of the moments in Section 3. Partial knowledge of the moments have implications for Out Of Variable (OOV) generalisation and resulting in differences in decision boundaries. We close with Section 5 with some discussion and concluding remarks. All the proofs are left to the appendix for the sake of brevity and clarity of the main text. ", "page_idx": 1}, {"type": "text", "text": "2 Notation and preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Notation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $Y$ be a binary random variable taking values in ${\\boldsymbol{\\mathcal{V}}}=\\{-1,1\\}$ , and $\\mathbf{X}=\\{X_{1},X_{2}\\}$ be a pair of continuous variables, so that $x_{i}\\in\\mathbb{R}$ . Let $f:\\mathcal{V}\\times\\mathbb{R}^{2}\\stackrel{}{\\rightarrow}\\mathbb{R}$ be a measurable function and $P$ a measure on $\\mathcal{V}\\times\\mathbb{R}^{2}$ . We denote $\\mathbb{E}_{P}[f(Y,\\mathbf{X})]$ the expectation of $f$ with respect to $P$ . We restrict ourselves to the scenario with two continuous variables and one binary outcome given that we can already observe asymmetries in the merging of experts, and can visualise such asymmetries without having to project such space into 2 dimensions. The results here can be easily generalised into a discrete outcome variable (and indeed we do, in Corollary 7) Throughout the article we will care about finding a predictor of $Y$ using $\\mathbf{X}$ as covariates. That is, we are interested in the conditional distribution $P(Y\\mid\\mathbf{X})$ . ", "page_idx": 2}, {"type": "text", "text": "2.2 Maximum Entropy and Causal Maximum Entropy ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The Maximum Entropy (MAXENT) principle was born in the statistical mechanics literature as a way to find a distribution consistent with a set of expectation constraints [20]. That is, given observed sample averages $\\begin{array}{r}{\\tilde{f}=\\frac{1}{N}\\sum_{i=1}^{N}f(y_{i},x_{i})}\\end{array}$ we want to find a distribution $P(Y,\\mathbf{X})$ so that the expectations with respect to $P({\\dot{Y}},\\mathbf{X})$ are equal to those observed. ", "page_idx": 2}, {"type": "text", "text": "Notice that MAXENT does not attempt to find the \u2018true\u2019 distribution of the data, but instead the distribution closest to the uniform distribution so that the expectation constraints are satisfied. We will see examples of such optimisation problems in subsequent sections. Using the Lagrange multiplier formalism for constrained optimisation, one can prove that the solution to the MAXENT problem belongs to the exponential family. The MAXENT distribution and its properties have been studied widely, see Gr\u00fcnwald and Dawid [10] and Wainwright et al. [38] and references therein. ", "page_idx": 2}, {"type": "text", "text": "In Causal MAXENT (CMAXENT, Janzing [17]), the optimisation is performed in an assumed causal order; that is, we first find the MAXENT distribution of causes and then the Maximum Conditional Entropy of the effects given the inferred distribution of the causes. As argued in [36] this typically results in distributions that are more plausible for the respective causal direction. One can think of CMAXENT as usual MAXENT with the distribution of the cause as additional constraint, where the latter has been obtained via separate entropy maximization. ", "page_idx": 2}, {"type": "text", "text": "3 Known predictor covariances ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We will begin by studying the solution of the CMAXENT problem when we observe all the bivariate distributions and summarise them with first and second moments. The restriction to first and second moments has several reasons: First, these simple constraints are already sufficient to explain the interesting asymmetries between causal and anticausal. Second, including higher order moments makes the problem computationally harder and increases the risk of overftiting on noisy finite sample results. Last, including more moments decreases the asymmetries between the causal directions. Mathematically, we have the following (estimated) expectations and their respective sample averages: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\hat{\\mathbb{E}}[Y]=p,\\qquad}&&{\\hat{\\mathbb{E}}[\\mathbf{X}Y]=\\phi=\\left[\\phi_{2}\\right],}\\\\ &{\\hat{\\mathbb{E}}[\\mathbf{X}]=\\bar{\\mathbf{x}}=\\left[\\bar{x}_{1}\\right]=\\left[0\\right],\\qquad}&&{\\hat{\\mathbb{E}}[\\mathbf{X}\\mathbf{X}^{\\top}]=\\Sigma_{\\mathbf{X}}=\\left(\\bar{s}_{1,2}^{2}\\quad\\bar{s}_{2}2\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where we assumed the mean of $\\mathbf{X}$ is zero. ", "page_idx": 2}, {"type": "text", "text": "3.1 The causal direction ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Consider the causal graph in Figure 1a and the expectations given in Equations (1) and (2). As mentioned on Section 2.2, CMAXENT suggests finding the distribution $P(\\mathbf{X})$ that maximises the entropy consistent with the first and second moments of $\\mathbf{X}$ , and then finding the conditional distribution $P(Y\\mid\\mathbf{X})$ that maximises the conditional entropy consistent with the estimated $P(\\mathbf{X})$ and the moments that involve $Y$ . ", "page_idx": 2}, {"type": "image", "img_path": "xZKXGvLB0c/tmp/f9ec2b6cd3f857f65bbd45f406f3da457775a2ebba3400ec791f1d3f7942ddc0.jpg", "img_caption": ["Figure 1: Causal graphs analysed throughout the article "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "These steps can be summarised in the following optimisation problems. First, for $P(\\mathbf{X})$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{P(\\mathbf{x})}}&{H(\\mathbf{X})=-\\int_{\\mathbb{R}^{2}}P(\\mathbf{x})\\log P(\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}}\\\\ {\\mathrm{s.t.}\\quad}&{\\mathbb{E}[X_{i}]=\\bar{x}_{i},\\,\\mathrm{with}\\,i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[X_{i}^{2}]=\\bar{s}_{i}^{2},\\,\\mathrm{with}\\,i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[X_{1}X_{2}]=\\bar{s}_{1,2}}\\\\ &{\\int_{\\mathbb{R}^{2}}P(\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "On the other hand, the Maximum Conditional Entropy optimisation problem is as follows ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{P(y\\mid\\mathbf{x})}}&{H(Y\\mid\\mathbf{X})=-\\int_{\\mathbb{R}^{2}}\\displaystyle\\sum_{y}P(y\\mid\\mathbf{x})P(\\mathbf{x})\\log P(y\\mid\\mathbf{x})\\,\\mathrm{d}\\mathbf{x}}\\\\ {\\mathrm{s.t.}}&{\\mathbb{E}[Y X_{i}]=\\phi_{i},\\,\\mathrm{with}\\,\\,i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[Y]=p}\\\\ &{\\displaystyle\\sum_{y}P(y\\mid\\mathbf{x})=1,\\quad\\mathrm{for\\,each\\,\\mathbf{x}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Where $P(\\mathbf{X})$ is the one we found by solving Equation (3). ", "page_idx": 3}, {"type": "text", "text": "Proposition 1 (Resulting distribution in the causal direction). Using the Lagrange multiplier formalism for the optimisation problems in Equations (3) and (4) we obtain: (i) a multivariate Gaussian distribution for $P(\\mathbf{X})$ , and $(i i)$ the distribution of $Y$ conditioned on $\\mathbf{X}$ given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{c}{P_{\\lambda}(y\\mid x_{1},x_{2})=\\exp\\left(\\lambda_{0}y+\\lambda_{1}y x_{1}+\\lambda_{2}y x_{2}+\\alpha(x_{1},x_{2})\\right)}\\\\ {\\alpha(x_{1},x_{2})=\\displaystyle\\log\\sum_{y}\\exp\\left(\\lambda_{0}y+\\lambda_{1}y x_{1}+\\lambda_{2}y x_{2}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\alpha(\\mathbf{x})$ is a normalising constant. ", "page_idx": 3}, {"type": "text", "text": "The conditional distribution can be written as ", "page_idx": 3}, {"type": "equation", "text": "$$\nP_{\\lambda}(Y=1\\mid x_{1},x_{2})=\\frac{1}{2}(1+\\operatorname{tanh}(\\lambda_{0}+\\lambda_{1}x_{1}+\\lambda_{2}x_{2})).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The proof of this result can be found in [19, Section 3.1 and 3.2]. ", "page_idx": 3}, {"type": "text", "text": "Remark 2 Notice that Equation (7), our predictor of interest, is just a rescaled version of a sigmoid function. That is, we can estimate $P(Y\\,\\,|\\,\\,\\mathbf{X})$ with a logistic regression. A similar observation was done in [8] in the context of using an exponential loss for boosting. This relation was further explored in [24], where a more direct relation to maximum likelihood and exponential families was established. In Section 5 we discuss how these results in the statistical literature can be interpreted as making causal assumptions about the relation between the predictor and target variables. ", "page_idx": 3}, {"type": "text", "text": "3.2 The anticausal direction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Now consider the graph in Figure 1b. In this scenario, covariates of our predictor of interest are the effects of our target variable. Following the CMAXENT principle, we first find the distribution ", "page_idx": 3}, {"type": "text", "text": "$P(Y)$ that maximises entropy and is consistent with first moment of $Y$ and then find the distribution $P(\\mathbf{X}\\mid Y)$ that maximises conditional entropy consistent with the moments that involve $\\mathbf{X}$ . After this two-step process, we are left with the joint distribution $P(Y,\\mathbf{X})$ from which we can derive a predictor of $Y$ , $P(Y\\mid\\mathbf{X})$ using Bayes\u2019 Theorem (Section 3.3). The whole procedure can be summarised with the following optimisation problems. For the cause, we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{P(y)}}&{H(Y)=-\\sum_{y}P(y)\\log P(y)}\\\\ {\\mathrm{s.t.}}&{\\mathbb{E}[Y]=p}\\\\ &{\\displaystyle\\sum_{y}P(y)=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "And for the effects, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{P(\\mathbf{x}\\mid y)}}&{H(\\mathbf{X}\\mid Y)=-\\int_{\\mathbb{R}^{2}}\\sum_{y}P(\\mathbf{x}\\mid y)P(y)\\log P(\\mathbf{x}\\mid y)d\\mathbf{x}}\\\\ {\\mathrm{s.t.}}&{\\mathbb{E}[Y X_{i}]=\\phi_{i},\\mathrm{~with~}i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[X_{i}]=\\bar{x}_{i},\\mathrm{~with~}i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[X_{i}^{2}]=\\bar{s}_{i}^{2},\\mathrm{~with~}i\\in\\{1,2\\}}\\\\ &{\\mathbb{E}[X_{1}X_{2}]=\\bar{s}_{1,2}}\\\\ &{\\int_{\\mathbb{R}^{2}}P(\\mathbf{x}\\mid y)d\\mathbf{x}=1,\\quad\\mathrm{for~each~}y.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proposition 3 (Resulting distribution in the anticausal direction). Using the Lagrange multiplier formalism for the optimisation problems in Equations (8) and (9), we obtain a Bernoulli distribution for $Y$ with $P(Y=1)=p$ , and $P_{\\lambda}(\\mathbf{x}\\mid y)$ given by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{P_{\\lambda}({\\bf x}\\mid y)=\\exp[\\lambda_{1}y x_{1}+\\lambda_{2}y x_{2}+\\lambda_{3}x_{1}+\\lambda_{4}x_{2}}}\\\\ {{\\qquad\\qquad\\qquad\\,+\\lambda_{5}x_{1}^{2}+\\lambda_{6}x_{2}^{2}+\\lambda_{7}x_{1}x_{2}+\\beta(y)]}}\\\\ {{\\qquad\\qquad=\\exp\\left[\\displaystyle\\sum_{k}\\lambda_{k}h_{k}({\\bf x},y)+\\beta(y)\\right]}}\\\\ {{\\qquad\\beta(y)=\\log\\displaystyle\\int_{{\\mathbb R}^{2}}\\exp\\left[\\displaystyle\\sum_{k}\\lambda_{k}h_{k}({\\bf x},y)\\right]d{\\bf x}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $h_{k}$ are the different functions for which we have the sample averages. The distribution $P_{\\lambda}(\\mathbf{X}\\mid Y)$ is a mixture of multivariate Gaussian distributions. Both components $P_{\\lambda}(\\mathbf{X}\\mid Y=-1)$ and $P_{\\lambda}(\\mathbf{X}\\mid Y=1)$ ) have the same covariance matrix. ", "page_idx": 4}, {"type": "text", "text": "For the following sections, we introduce the following notation for the expectations of the mixture of Gaussians. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathbf{X}\\mid y]=\\mu_{y}=\\left[{\\mu_{y,1}\\atop\\mu_{y,2}}\\right],\\qquad\\qquad\\qquad\\quad\\mathbb{E}[\\mathbf{X}\\mathbf{X}^{\\top}\\mid Y]=\\Sigma_{\\mathbf{X}\\mid Y}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In addition, we will include the subscripts \u201ccausal\u201d and \u201canticausal\u201d where it might be ambiguous (e.g., $\\Sigma_{\\mathbf{X}|Y,\\mathrm{causal}}$ represents the conditional covariance in the causal scenario and $\\Sigma_{\\mathbf{X|}Y,\\mathrm{anticausal}}$ in the anticausal scenario). As mentioned in Propostion 3, the conditional covariance $\\Sigma_{{\\bf X}\\mid Y}$ is the same for both values of $y$ . However, we keep the conditional notation to distinguish it from the marginal covariance of $\\mathbf{X}$ , $\\pmb{\\Sigma}\\mathbf{x}$ introduced in Equation (2). In Appendix A we derive the conditional expectations in Equation (13) and the marginal expectations used as constraints. ", "page_idx": 4}, {"type": "text", "text": "Remark 4 Even though the causal graph in the anticausal direction implies that the conditional covariance $\\Sigma_{{\\bf X}Y}$ is diagonal, the CMAXENT solution does not result in a diagonal conditional covariance. This is true because of the constraints in Equations (1) and (2) and the law of total covariance. Note that the CMAXENT distribution is not necessarily Markov relative to the given DAG. As shown in [17, Section 5], CMAXENT only provides the best guess and may therefore mix over different Markovian distributions such that the result is no longer Markovian. ", "page_idx": 4}, {"type": "text", "text": "This relation between the marginal and conditional expectations will be essential in the subsequent sections where we explore the difference in the decision boundaries of the two resulting predictors of $Y$ . ", "page_idx": 5}, {"type": "text", "text": "3.3 The predictor of $Y$ in the anticausal direction ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Recall that our main goal is to produce a predictor of $Y$ as a function of the covariates X. In Section 3.1 we obtain the predictor of $Y$ directly as a result of the CMAXENT principle, given that the predictor is already in the direction of the causal mechanism. On the other hand, in Section 3.2, we have to derive the predictor of $Y$ using the found conditional distributions and Bayes\u2019 rule. The main result of this section is that with the constraints we have used, CMAXENT in the anticausal direction is equivalent to Linear Discriminant Analysis [14, Section 4.3]. Furthermore, we generalise this result to Quadratic Discriminant Analysis, and to an exponential family version of discriminant analysis. ", "page_idx": 5}, {"type": "text", "text": "Theorem 5 (Predictor of $Y$ using Bayes\u2019 rule). Using the results from Propostion 3, the distribution $P_{\\lambda}(Y=y\\mid\\mathbf{X})$ is the ratio of the product of the Gaussian component with $P_{\\lambda}(Y=y)$ and the mixture of Gaussians resulting from Propostion 3. Minimising the expected 0-1 loss, the optimal decision rule arising from this distribution is equivalent to Linear Discriminant Analysis $(L D A)$ . ", "page_idx": 5}, {"type": "text", "text": "Corollary 6 (Quadratic Discriminant Analysis (QDA)). Quadratic Discriminant Analysis can be interpreted as CMAXENT in the anticausal direction. This is achieved by replacing ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{i}^{2}]=\\bar{s}_{i}^{2}\\ w i t h\\ i\\in\\{1,2\\},\\,a n d\\ \\mathbb{E}[X_{1}X_{2}]=\\bar{s}_{1,2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "in Equation (9) with the following constraints: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{i}^{2}\\mid y]=\\bar{s}_{i,y}^{2}\\ w i t h\\ i\\in\\{1,2\\},a n d\\ \\mathbb{E}[X_{1}X_{2}\\mid y]=\\bar{s}_{1,2,y}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We will now extend this idea, where instead of modelling $P({\\bf X})$ as a mixture of Multivariate Gaussians (with equal covariance in LDA or unequal covariance in QDA), $P(\\mathbf{X})$ now becomes a mixture of distributions, each coming from an exponential family of distributions corresponding to a more general set of constraints. ", "page_idx": 5}, {"type": "text", "text": "Corollary 7 (Exponential family discriminant analysis). Let $f_{i}$ be an arbitrary measurable function and $\\tilde{f}$ its corresponding sample average. In the general case where $Y$ is a discrete variable and we have d covariates $\\mathbf{X}$ in the anticausal direction, the CMAXENT problem with constraints of the form: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[f_{i}(\\mathbf{X})\\mid y]=\\tilde{f}_{i,y},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\tilde{f}_{i,y}$ are the sample averages of $f_{i}$ for a specific y as in Section 2.2, results in $P_{\\lambda}(\\mathbf{X}\\mid Y)$ being a mixture of exponential family distributions which then can be inverted (using Bayes\u2019 rule) to $a$ predictor of $Y$ . ", "page_idx": 5}, {"type": "text", "text": "Remark 8 In the previous corollary, the functions $f_{i}$ can be constant on any of the variables in $\\mathbf{X}$ . ", "page_idx": 5}, {"type": "text", "text": "This idea has been extended to use kernels as a way to map $\\mathbf{X}$ into more complex feature spaces. The resulting algorithm is called Kernel Fisher discriminant analysis [26, 32, 9]. ", "page_idx": 5}, {"type": "text", "text": "3.4 The geometry of the decision boundaries ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Hastie et al. [14, Chapter 4.4.5] conclude that the log-posterior odds of the logistic regression and LDA are both linear in x, but with different parameters defining the linear relation. In this section, we revisit these results in more detail and explore whether the CMAXENT solution in causal direction differs from the solution in anticausal direction. From a statistical decision theory perspective, the log-posterior odds correspond to the Maximum A Posteriori (MAP) rule, the optimal decision boundary of a classifier when minimising the expected 0-1 loss [3, Ch. 4.3.3]. ", "page_idx": 5}, {"type": "text", "text": "Proposition 9 (Normal vector to the decision boundaries in causal and anticausal direction). Under the 0-1 loss, the normal vector to the decision boundary of the CMAXENT predictor is proportional to ", "page_idx": 5}, {"type": "text", "text": "We will now prove that in the case where we know all the expectations in Equations (1) and (2), the slope of the decision boundaries in causal and anticausal direction are the same. ", "page_idx": 6}, {"type": "text", "text": "Theorem 10 (Slope of the decision boundary is the same in causal and anticausal direction). Using the constraints in Equations (1) and (2), the slope of $P_{\\lambda}(Y\\mid\\mathbf{X})$ inferred using CMAXENT is the same in causal and anticausal direction. ", "page_idx": 6}, {"type": "text", "text": "Although it might seem from the above result that there is no asymmetry between the logistic regression and LDA even when we include causal information, this is not entirely true. To begin with, the decision boundaries may be unequal although they are parallel, but more importantly learning the parameters of certain model might be easier. In the next section we explore the differences that persist even under the light of Theorem 10. ", "page_idx": 6}, {"type": "text", "text": "3.5 What are the differences? ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In the previous sections we found that the slopes of the decision boundary of CMAXENT in both the causal and anticausal direction are linear and agree, whenever we have the first and second moments as in Equations (1) and (2). This implies that, if the test data will come from the same distribution as the training data, either algorithm will work equally well. Previous research has studied the advantages and disadvantages [14, 33, Chapter 4.4.5] of each method and their properties such as asymptotic relative efficiency [7], parameter bias [13], asymptotic error under label noise [4] and online learning performance [1]. All of these analyses base their results on the fact that the logistic regression does not make an assumption on how the covariates $\\mathbf{X}$ are distributed, whereas LDA does. ", "page_idx": 6}, {"type": "text", "text": "An alternative way of viewing this distinction is through the lens of generative and discriminative models. LDA is a generative model since it models both covariates and target variable and logistic regression only models the target as a function of the input. $\\mathrm{Ng}$ and Jordan [28] analyse the difference in efficiency between the Naive Bayes algorithm (a generative model similar to LDA) and logistic regression, and find that both models have regimes in which they perform better than the other. Using the same models, Bl\u00f6baum et al. [5] and data from [35], find empirically that generative models perform better in anticausal than in causal direction. ", "page_idx": 6}, {"type": "text", "text": "4 Partially known covariances ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section we explore variations of the solution of the CMAXENT solution in causal and anticausal direction when some of the sample averages are not known. In Section 4.1 we explore the case where the covariance between a particular predictor and the target is not known, and in Section 4.2 the case where we do not know the covariance between the predictors. In both cases we will see that the models we can infer (that is, $P(Y\\mid\\mathbf{X})!$ ) with CMAXENT will depend on the underlying causal assumptions. ", "page_idx": 6}, {"type": "text", "text": "4.1 Unknown predictor-target covariance ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Without loss of generality, suppose we do not have the sample covariance between $X_{2}$ and $Y$ , that is, we do not know $\\phi_{2}$ in Equation (1). ", "page_idx": 6}, {"type": "text", "text": "In the causal direction, the CMAXENT solution of the distribution of the causes $\\mathbf{X}$ will still be a multivariate normal distribution with expectations given by the constraints relating $\\mathbf{X}$ . The conditional distribution of the effects is the logistic-like regression of Equation (7), however, $\\lambda_{2}$ will be 0, as this is the parameter corresponding to the covariance between $X_{2}$ and $Y$ . In other words, $X_{2}$ becomes irrelevant in the estimation of our target predictor. ", "page_idx": 6}, {"type": "text", "text": "In the anticausal direction, the distribution of the cause $Y$ is unchanged because $P(Y)$ is determined by the constraints and thus does not depend on $\\phi_{2}$ . However, using the fact that the Gaussian distribution maximises the entropy over all distributions with the same variance [37, Theorem 8.6.5.], we can derive a bound on $\\phi_{2}$ . We use the entropy of the Gaussian distribution because we do not know a closed form expression for the conditional covariance of $P(Y\\mid\\mathbf{X})$ as given by Theorem 5. ", "page_idx": 6}, {"type": "text", "text": "Proposition 11 (Bounds on unknown covariance between predictor and target). Assuming the causal graph in Figure 1b and we do not know $\\phi_{2}$ , an upper bound for $\\phi_{2}$ is given by: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{p(1-p)\\bar{s}_{1,2}\\phi_{1}}{p(1-p)\\bar{s}_{1}^{2}-\\phi_{1}^{2}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The bound in Propostion 11 is found by differentiating the determinant of the conditional covariance (to which the differential entropy of the multivariate Gaussian is proportional to) with respect to the unknown covariance, $\\phi_{2}$ in this case, and finding the value for $\\phi_{2}$ for which this derivative is 0. ", "page_idx": 7}, {"type": "text", "text": "The implication of the previous result is that even when we have not observed any joint data between $X_{2}$ and $Y$ we can still build a model of $Y$ that depends on $X_{2}$ , as long as we can assume the data generation process is anticausal. We can consider this an instance of Out Of Variable (OOV) generalisation studied in [16, 12], where we can exploit causal information and partial data to make models including variables that were never observed jointly with the target. ", "page_idx": 7}, {"type": "text", "text": "4.2 Unknown predictor covariance ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Now suppose we observe all the sample averages in Equations (1) and (2) but we do not observe $\\bar{s}_{1,2}$ ", "page_idx": 7}, {"type": "text", "text": "In the causal direction this implies that the multivariate Gaussian distribution resulting from the MAXENT problem on $\\mathbf{X}$ is diagonal, that is, $\\mathbf{X}$ are marginally independent. The exponential form of $P_{\\lambda}(Y\\mid{\\bar{X}})$ does not change, as we still observed $\\hat{p}$ and $\\phi$ , nevertheless, the parameters of the exponential family do change, as the distribution of $\\mathbf{X}$ changed so that the resulting $P_{\\lambda}(Y\\mid\\mathbf{X})$ needs to adapt in order to match $\\phi$ . ", "page_idx": 7}, {"type": "text", "text": "Now we will explore the anticausal case. We will proceed as in Sections 3.1 and 3.2. First we find $P(Y)$ by maximising the entropy subject to the empirical average of $Y$ , which is trivial because $P(Y)$ is already determined by its moments, and then we find $P({\\bar{\\mathbf{X}}}\\mid Y)$ subject to all the moments in Equations (1) and (2) with the exception of $\\bar{s}_{1,2}$ . We obtain the following result from solving the CMAXENT optimisation problem ", "page_idx": 7}, {"type": "text", "text": "Proposition 12 (Diagonal conditional covariance in the anticausal direction with unknown predictor covariance). The distribution $P(\\mathbf{X}\\mid Y)$ that maximises the conditional entropy subject to the following constraints: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\hat{\\mathbb{E}}[\\mathbf{X}Y]=\\left[\\phi_{1}\\right],\\quad\\hat{\\mathbb{E}}[\\mathbf{X}]=\\left[0\\right],\\quad\\hat{\\mathbb{E}}[X_{1}^{2}]=\\bar{s}_{1}^{2},\\quad\\hat{\\mathbb{E}}[X_{2}^{2}]=\\bar{s}_{2}^{2},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "and $P(Y)$ inferred on the first step of CMAXENT, is independent after choosing a value of $y$ ; that is, $\\mathbf{X}$ is conditionally independent given $Y$ . ", "page_idx": 7}, {"type": "text", "text": "Remark $^{13}$ This result is reassuring given that under these moment constraints, $P(\\mathbf{X}\\mid\\boldsymbol{y})$ turns out to be Markov relative to the DAG in the anticausal direction. Contrary to Remark 4, where we concluded that CMAXENT is not always Markov relative to a DAG. ", "page_idx": 7}, {"type": "text", "text": "In Appendix E we derive the slopes of the decision boundaries in the causal and anticausal direction when we do not know the covariance between the predictors. We also find necessary and sufficient conditions for which the slopes are the same. From this simple example, we have learned the following: in causal direction, our inductive bias tells us that the covariates are not correlated and hence, the decision boundary depends only on the marginal variance of each $\\mathbf{X}_{i}$ and the covariance between $Y$ and $\\mathbf{X}$ . In the anticausal direction, CMAXENT infers $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ to be marginally correlated because they need to be conditionally independent (this fact can proved using the law of total covariance). Hence, the marginal covariance of X, $\\pmb{\\Sigma}_{\\mathbf{X}}$ is different in both scenarios. This is something we did not observe in the case with full information (Section 3). ", "page_idx": 7}, {"type": "text", "text": "In addition, we derive the expressions of the decision boundaries in the causal and anticausal direction (see Appendix E). That is, as proved in Propostion 9, we have that the decision boundaries of the predictors in causal and anticausal direction will differ with the same moments, but different causal assumptions. In Figure 2, we showcase this phenomenon with synthetic data. ", "page_idx": 7}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this article we have studied the differences arising from merging of predictors in the causal and anticausal directions. In particular, we have studied a simple case with a binary target variable and two continuous variables. Although in this simple example we have already found connections with classical classification algorithms, and differences in the solutions in causal and anticausal direction, the example can be easily extended to more covariates (where the resulting distribution of the covariates would be a $d$ -dimensional Gaussian instead of bivarate Gaussian), a discrete target variable (as in Corollary 7), and a causal graph that contains both parents and children as predictors. ", "page_idx": 7}, {"type": "image", "img_path": "xZKXGvLB0c/tmp/3cb2ef025984d610bc278ac2d93199e95f6c25dc06514266238140add132cf93.jpg", "img_caption": ["Figure 2: Decision boundaries of the solution of CMAXENT in the causal (left) and anticausal (right) direction when we do not have the covariance between the predictor variables $\\bar{s}_{1,2}$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "As stated at the end of Section 3.1, the relation between merging of experts and logistic regression has been explored in the past. Friedman et al. [8] interpret the solution to the AdaBoost procedureas as additive logistic regression. They arrive at this interpretation starting from an exponential loss function. They then propose likelihood based estimator of the AdaBoost procedure. Thus, since our results align with those in Friedman et al. [8], we give yet another interpretation of AdaBoost as the solution of the merging of experts in causal direction using the CMAXENT principle. ", "page_idx": 8}, {"type": "text", "text": "Even though we have used CMAXENT as inductive bias to merge the predictors throughout the article, we believe that the asymmetries we found here (in particular, the geometry of the decision boundaries) would hold when using any other inductive bias that allows causal information to be included. Whatever method we use to merge predictors, the following asymmetry seems natural: In anticausal direction we try to explain correlations between $X_{1},X_{2}$ as a result of $Y$ influencing both components. In causal direction, correlations between $X_{1}$ and $X_{2}$ do not tell us anything about the relation between $X$ and $Y$ , following the principle of Independent Mechanisms (see [29] for an overview and [11] for a recent Bayesian view). ", "page_idx": 8}, {"type": "text", "text": "The previous observation is useful in straightforward scenarios where we are merging data from different sources for a supervised learning task, say datasets with overlapping variables, or datasets produced from different experimental conditions (also called environments); but also in cases where the merging of data is more subtle, for example, in federated learning where the notion of horizontal and vertical federated learning [42] coincides precisely with the data sources described above but where causality is underexplored. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We thank William R. Orchard and Yuchen Zhu for their valuable comments in a previous version of this article. ", "page_idx": 8}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] A. Banerjee. An analysis of logistic models: Exponential family connections and online performance. In Proceedings of the 2007 SIAM International Conference on Data Mining, pages 204\u2013215. SIAM, 2007.   \n[2] M. S. Bartlett. An inverse matrix adjustment arising in discriminant analysis. The Annals of Mathematical Statistics, 22(1):107\u2013111, 1951.   \n[3] J. O. Berger. Statistical decision theory and Bayesian analysis. Springer Science & Business Media, 2013.   \n[4] Y. Bi and D. R. Jeske. The efficiency of logistic regression compared to normal discriminant analysis under class-conditional classification noise. Journal of Multivariate Analysis, 101(7): 1622\u20131637, 2010.   \n[5] P. Bl\u00f6baum, S. Shimizu, and T. Washio. Discriminative and generative models in causal and anticausal settings. In Advanced Methodologies for Bayesian Networks: Second International Workshop, AMBN 2015, Yokohama, Japan, November 16-18, 2015. Proceedings 2, pages 209\u2013221. Springer, 2015.   \n[6] L. Breiman. Bagging predictors. Machine learning, 24:123\u2013140, 1996.   \n[7] B. Efron. The efficiency of logistic regression compared to normal discriminant analysis. Journal of the American Statistical Association, 70(352):892\u2013898, 1975.   \n[8] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). The annals of statistics, 28(2): 337\u2013407, 2000.   \n[9] B. Ghojogh, F. Karray, and M. Crowley. Fisher and kernel fisher discriminant analysis: Tutorial. arXiv preprint arXiv:1906.09436, 2019.   \n[10] P. D. Gr\u00fcnwald and A. P. Dawid. Game theory, maximum entropy, minimum discrepancy and robust bayesian decision theory. Annals of Statistics, pages 1367\u20131433, 2004.   \n[11] S. Guo, V. Toth, B. Sch\u00f6lkopf, and F. Huszar. Causal de Finetti: On the identification of invariant causal structure in exchangeable data. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36, pages 36463\u201336475. Curran Associates, Inc., 2023.   \n[12] S. Guo, J. Wildberger, and B. Sch\u00f6lkopf. Out-of-variable generalization for discriminative models. In The Twelfth International Conference on Learning Representations (ICLR), May 2024.   \n[13] M. Halperin, W. C. Blackwelder, and J. I. Verter. Estimation of the multivariate logistic risk function: a comparison of the discriminant function and maximum likelihood approaches. Journal of chronic diseases, 24(2-3):125\u2013158, 1971.   \n[14] T. Hastie, R. Tibshirani, J. H. Friedman, and J. H. Friedman. The elements of statistical learning: data mining, inference, and prediction, volume 2. Springer, 2009.   \n[15] T. K. Ho. The random subspace method for constructing decision forests. IEEE transactions on pattern analysis and machine intelligence, 20(8):832\u2013844, 1998.   \n[16] D. Janzing. Merging joint distributions via causal model classes with low VC dimension. arXiv preprint arXiv:1804.03206, 2018.   \n[17] D. Janzing. Causal versions of maximum entropy and principle of insufficient reason. Journal of Causal Inference, 9(1):285\u2013301, 2021.   \n[18] D. Janzing and B. Sch\u00f6lkopf. Semi-supervised interpolation in an anticausal learning scenario. Journal of Machine Learning Research, 16:1923\u20131948, 2015. URL http://jmlr.org/ papers/v16/janzing15a.html.   \n[19] D. Janzing, X. Sun, and B. Sch\u00f6lkopf. Distinguishing cause and effect via second order exponential models. arXiv preprint arXiv:0910.5561, 2009.   \n[20] E. T. Jaynes. Information theory and statistical mechanics. Physical review, 106(4):620, 1957.   \n[21] Z. Jin, J. von K\u00fcgelgen, J. Ni, T. Vaidhya, A. Kaushal, M. Sachan, and B. Schoelkopf. Causal direction of data collection matters: Implications of causal and anticausal learning for nlp. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9499\u20139513, 2021.   \n[22] M. I. Jordan and R. A. Jacobs. Hierarchical mixtures of experts and the em algorithm. Neural computation, 6(2):181\u2013214, 1994.   \n[23] S. L. Lauritzen. Graphical models, volume 17. Clarendon Press, 1996.   \n[24] G. Lebanon and J. Lafferty. Boosting and maximum likelihood for exponential models. Advances in neural information processing systems, 14, 2001.   \n[25] W. B. Levy and H. Deli\u00e7. Maximum entropy aggregation of individual opinions. IEEE transactions on systems, man, and cybernetics, 24(4):606\u2013613, 1994.   \n[26] S. Mika, G. Ratsch, J. Weston, B. Sch\u00f6lkopf, and K.-R. M\u00fcller. Fisher discriminant analysis with kernels. In Neural networks for signal processing IX: Proceedings of the 1999 IEEE signal processing society workshop (cat. no. 98th8468), pages 41\u201348. Ieee, 1999.   \n[27] I. J. Myung, S. Ramamoorti, and A. D. Bailey Jr. Maximum entropy aggregation of expert predictions. Management Science, 42(10):1420\u20131436, 1996.   \n[28] A. $\\mathrm{Ng}$ and M. Jordan. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. Advances in neural information processing systems, 14, 2001.   \n[29] J. Peters, D. Janzing, and B. Sch\u00f6lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.   \n[30] D. Poole and A. E. Raftery. Inference for deterministic simulation models: the bayesian melding approach. Journal of the American Statistical Association, 95(452):1244\u20131255, 2000.   \n[31] A. E. Raftery, D. Madigan, and J. A. Hoeting. Bayesian model averaging for linear regression models. Journal of the American Statistical Association, 92(437):179\u2013191, 1997.   \n[32] V. Roth and V. Steinhage. Nonlinear discriminant analysis using kernel functions. Advances in neural information processing systems, 12, 1999.   \n[33] Y. D. Rubinstein, T. Hastie, et al. Discriminative vs informative learning. In KDD, volume 5, pages 49\u201353, 1997.   \n[34] M. Saerens and F. Fouss. Yet another method for combining classifiers outputs: a maximum entropy approach. In International Workshop on Multiple Classifier Systems, pages 82\u201391. Springer, 2004.   \n[35] B. Sch\u00f6lkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. Mooij. On causal and anticausal learning. In 29th International Conference on Machine Learning (ICML 2012), pages 1255\u20131262. International Machine Learning Society, 2012.   \n[36] X. Sun, D. Janzing, and B. Sch\u00f6lkopf. Causal inference by choosing graphs with most plausible markov kernels. In Ninth International Symposium on Artificial Intelligence and Mathematics (AIMath 2006), pages 1\u201311, 2006.   \n[37] Thomas M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley & Sons, Nashville, TN, 2 edition, June 2006.   \n[38] M. J. Wainwright, M. I. Jordan, et al. Graphical models, exponential families, and variational inference. Foundations and Trends\u00ae in Machine Learning, 1(1\u20132):1\u2013305, 2008.   \n[39] S. Weichwald, B. Sch\u00f6lkopf, T. Ball, and M. Grosse-Wentrup. Causal and anti-causal learning in pattern recognition for neuroimaging. In 2014 International Workshop on Pattern Recognition in Neuroimaging, pages 1\u20134. IEEE, 2014.   \n[40] D. H. Wolpert. Stacked generalization. Neural networks, 5(2):241\u2013259, 1992.   \n[41] Y. Yao, L. M. Carvalho, and D. Mesquita. Locking and quacking: Stacking bayesian models predictions by log-pooling and superposition. In NeurIPS 2022 Workshop on Score-Based Methods, 2022.   \n[42] C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao. A survey on federated learning. KnowledgeBased Systems, 216:106775, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Relation between the expectations of the Mixture of Gaussians and the known marginal expectations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In Propostion 3 we proved that the distribution resulting from the constraints in Equations (1) and (2) and the anticausal optimisation problem in Equation (9) result in a mixture of Gaussian distributions. Now we are going to explore the relation between the moments of the resulting distribution and the constraints used in the MAXENT optimisation problem. ", "page_idx": 12}, {"type": "text", "text": "We have the following expectations under Gaussian mixture model ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathbf{X}Y\\right]=\\!p\\pmb{\\mu}_{1}-(1-p)\\pmb{\\mu}_{-1}}\\\\ &{\\quad\\quad\\mathbb{E}\\left[\\mathbf{X}\\right]=\\!p\\pmb{\\mu}_{1}+(1-p)\\pmb{\\mu}_{-1}}\\\\ &{\\mathbb{E}\\left[\\mathbf{X}\\mathbf{X}^{\\top}\\right]=\\!\\pmb{\\Sigma}_{X}}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\mathbb{E}\\left[\\mathrm{Var}(\\mathbf{X}\\mid Y)\\right]+\\mathrm{Var}(\\mathbb{E}\\left[\\mathbf{X}\\mid Y\\right]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Where Equation (22) follows from the law of total covariance. We have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathrm{Var}(\\mathbf{X}\\mid Y)\\right]=p\\pmb{\\Sigma}_{X\\mid Y}+(1-p)\\pmb{\\Sigma}_{X\\mid Y}}\\\\ &{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=\\pmb{\\Sigma}_{X\\mid Y},}\\\\ &{~~~~~~~~~~~~~~~~~~~~\\mathrm{Var}(\\mathbb{E}\\left[\\mathbf{X}\\mid Y\\right])=\\mathbb{E}[\\mathbb{E}[\\mathbf{X}\\mid Y]^{2}]-\\mathbb{E}[\\mathbb{E}[\\mathbf{X}\\mid Y]]^{2}}\\\\ &{~~~~~\\mathbb{E}[\\mathbb{E}[\\mathbf{X}\\mid Y]^{2}]=p\\mu_{1}\\mu_{1}^{\\top}+(1-p)\\pmb{\\mu}_{-1}\\pmb{\\mu}_{-1}^{\\top}}\\\\ &{~~~~~~~~~~~~~~~~\\mathbb{E}[\\mathbb{E}[\\mathbf{X}\\mid Y]]^{2}=(p\\mu_{1}+(1-p)\\pmb{\\mu}_{-1})(p\\mu_{1}+(1-p)\\pmb{\\mu}_{-1})^{\\top}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "So that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}\\left[\\mathbf{X}\\mathbf{X}^{\\top}\\right]=\\pmb{\\Sigma}_{X|Y}+p\\mu_{1}\\mu_{1}^{\\top}+(1-p)\\mu_{-1}\\mu_{-1}^{\\top}}&{{}}&{(2s)}\\\\ {-\\left(p\\mu_{1}+(1-p)\\mu_{-1})(p\\mu_{1}+(1-p)\\mu_{-1})^{\\top}}&{{}}&{(2s)}\\\\ {=\\pmb{\\Sigma}_{X|Y}+(1-p)p\\mu_{1}\\mu_{1}^{\\top}+(1-p)p\\mu_{-1}\\mu_{-1}^{\\top}-(1-p)p\\mu_{-1}\\mu_{1}^{\\top}-(1-p)p\\mu_{1}\\mu_{-1}^{\\top}}&{{}}&{(2s)}\\\\ {=\\pmb{\\Sigma}_{X|Y}+(1-p)p[\\mu_{1}\\mu_{1}^{\\top}+\\mu_{-1}\\mu_{-1}^{\\top}-\\mu_{-1}\\mu_{1}^{\\top}-\\mu_{1}\\mu_{-1}^{\\top}]}&{{}}&{(3\\sigma_{1}+\\mu_{1})}\\\\ {=\\pmb{\\Sigma}_{X|Y}+(1-p)p(\\mu_{1}-\\mu_{-1})(\\mu_{1}-\\mu_{-1})^{\\top}.}&{{}}&{(3\\sigma_{1}+\\mu_{1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Recall that the empirical averages used as constraints in the maximum entropy optimisation problem are coincide with the expectations under the resulting exponential family distribution. Then, using the equations above and the constraints, the means of the multivariate Gaussian distribution are ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mu_{1}=\\frac{\\bar{\\mathbf{x}}+\\phi}{2p}}\\\\ {\\displaystyle\\mu_{-1}=\\frac{\\bar{\\mathbf{x}}-\\phi}{2(1-p)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "And the conditional covariance, which is the same for both components, is ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Delta(x,y^{2})}&{=\\left[\\begin{array}{l}{\\Delta(x)}\\\\ {1}\\end{array}\\right]}\\\\ &{\\phantom{=}-\\gamma\\left(1-\\rho\\right)\\left(\\frac{\\left(1-\\rho\\right)^{2}}{2}(1-\\rho\\right)^{1/2}-\\frac{4(x-y)\\left(y-1\\right)}{\\rho}\\right)^{1/2}}\\\\ &{\\phantom{=}-\\left(1-\\rho\\right)\\left(\\frac{\\left(1-\\rho\\right)^{2}}{2}(1-\\rho)^{1/2}-\\frac{4(x-y)\\left(y-1\\right)}{\\rho}\\right)^{1/2}}\\\\ &{\\phantom{=}-\\left(\\frac{\\left(1-\\rho\\right)(1-\\rho)}{2}-\\frac{\\left(1-\\rho\\right)(1-\\rho)}{2}-\\frac{\\left(1-\\rho\\right)}{2}\\rho\\right)^{1/2}}\\\\ &{\\phantom{=}\\Delta(x,y^{2})}\\\\ {\\Delta(x,y^{2})}&{=\\left[\\begin{array}{l}{2\\left(-\\frac{x}{2}\\right)^{3/2}\\left(1-\\rho\\right)^{1/2}}\\\\ {1-\\rho\\left(1-\\rho\\right)}\\\\ {\\rho}\\end{array}\\right]}\\\\ &{\\phantom{=}-\\left(1-\\rho\\right)\\left(\\frac{\\left(1-\\rho\\right)^{2}}{2}-\\frac{4(x-y)}{2}+\\frac{\\left(1-\\rho\\right)^{2}}{\\rho}+\\frac{4x^{2}}{2}-3\\rho^{2}-\\rho\\right)^{1/2}+4\\rho^{1/2}}\\\\ &{\\phantom{=}-\\left(1-\\rho\\right)^{2/2}\\left(1-\\rho\\right)^{1/2}+\\frac{4x^{2}}{2}\\left(1-\\rho\\right)^{1/2}+4\\rho^{1/2}}\\\\ &{\\phantom{=}-\\frac{4(x-y)}{2}+\\frac{\\left(1-\\rho\\right)^{2}}{\\rho}-\\frac{4x^{2}}{2}+\\frac{\\left(1-\\rho\\right)^{2}}{\\rho}-\\frac{4x^{2}}{2}+2\\rho^{1/2}}\\\\ &{\\phantom{=}\\Delta(x,y^{2})}\\\\ {\\Delta(x,y^{2})}&{=\\left[\\begin{array}{l}{2\\left(-\\frac{x}{2}\\right)^{3/2}}\\\\ {1-\\rho\\left(1-\\rho\\right)}\\\\ {\\rho}\\end{array}\\right]}\\\\ &{\\phantom{=}-\\frac{2(x-y)}{2}(1-\\rho)^{1 \n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We enumerate the individual elements: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{X|Y,(i,i)}=\\displaystyle\\frac{1}{2^{2}p(1-p)}\\big[\\bar{s}_{i}^{2}-(2p-1)^{2}\\bar{x}_{i}^{2}-2(2p-1)\\bar{x}_{i}\\phi_{i}-\\phi_{i}^{2}\\big]}\\\\ &{\\Sigma_{X|Y,(1,2)}=\\displaystyle\\frac{1}{2^{2}p(1-p)}\\big[\\bar{s}_{1,2}-(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}-(2p-1)\\bar{x}_{1}\\phi_{2}-(2p-1)\\bar{x}_{2}\\phi_{1}-\\phi_{1}\\phi_{2}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "B Predictor in the anticausal direction ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Theorem 5 (Predictor of $Y$ using Bayes\u2019 rule). Using the results from Propostion 3, the distribution $P_{\\lambda}(Y=y\\mid\\mathbf{X})$ is the ratio of the product of the Gaussian component with $P_{\\lambda}(Y=y)$ and the mixture of Gaussians resulting from Propostion 3. Minimising the expected 0-1 loss, the optimal decision rule arising from this distribution is equivalent to Linear Discriminant Analysis $(L D A)$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. We prove this for the case $Y=1$ . the case for $Y=-1$ can be derived in an analogous way. The result follows from the application of Bayes\u2019 rule: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(Y=1\\mid\\mathbf x)=\\frac{P(\\mathbf x\\mid Y=1)P(Y=1)}{P(\\mathbf x)}}\\\\ &{\\qquad=\\frac{p\\exp\\Big(-\\frac12(\\mathbf x-\\mu_{1})^{\\top}\\mathbf Z_{\\mathbf X\\mid Y}^{-1}(\\mathbf x-\\mu_{1})\\Big)}{p\\exp\\Big(-\\frac12(\\mathbf x-\\mu_{1})^{\\top}\\mathbf Z_{\\mathbf X\\mid Y}^{-1}(\\mathbf x-\\mu_{1})\\Big)+(1-p)\\exp\\Big(-\\frac12(\\mathbf x-\\mu_{-1})^{\\top}\\mathbf Z_{\\mathbf X\\mid Y}^{-1}(\\mathbf x-\\mu_{-1})\\Big)}}\\\\ &{\\qquad=\\frac{1}{1+\\frac{(1-p)}{p}\\exp\\Big(-\\frac12(\\mathbf x^{\\top}\\Sigma_{\\mathbf X\\mid Y}^{-1}(\\mu_{1}-\\mu_{-1})+\\mu_{1}^{\\top}\\Sigma_{\\mathbf X\\mid Y}^{-1}\\mu_{1}-\\mu_{-1}^{\\top}\\Sigma_{\\mathbf X\\mid Y}^{-1}\\mu_{-1}\\Big)}}\\\\ &{\\qquad=\\frac{1}{1+\\frac{(1-p)}{p}\\exp\\Big((\\mathbf x-\\frac{\\mu_{-1}}{2})^{\\top}\\Sigma_{\\mathbf X\\mid Y}^{-1}\\mu_{-1}-(\\mathbf x-\\frac{\\mu_{1}}{2})^{\\top}\\Sigma_{\\mathbf X\\mid Y}^{-1}\\mu_{1}\\Big)}}\\end{array}\\quad\\mathrm{(4)}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "C Derivation of the decision boundary ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In the following two sections we give the proof of Propostion 9 for the causal and anticausal direction separately. First, we restate the proposition ", "page_idx": 14}, {"type": "text", "text": "Proposition 9 (Normal vector to the decision boundaries in causal and anticausal direction). Under the 0-1 loss, the normal vector to the decision boundary of the CMAXENT predictor is proportional to ", "page_idx": 14}, {"type": "text", "text": "As mentioned on the proposition, we frame these results within the statistical decision theory framework [3], choosing a particular loss function $L(h(\\mathbf{x}),y)$ , where $h(\\mathbf{x})$ is the predictor of $y$ we want to evaluate. We consider the 0-1 loss function. That is, $L(h(\\mathbf{x}),y)=1$ if $h(\\mathbf{x})=y$ , and 0 otherwise. The optimal decision rule for this loss is the well-known Maximum A Posteriori (MAP) rule from which we can derive our decision boundary. ", "page_idx": 14}, {"type": "text", "text": "C.1 Proof of Propostion 9 in the causal direction ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In the causal direction, the Maximum A Posteriori (MAP) rule, results in the decision boundary given by the following equation ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{P(Y=1\\mid\\mathbf{x})=P(Y=-1\\mid\\mathbf{x})}}\\\\ {{\\displaystyle\\frac{1}{2}(1+\\operatorname{tanh}(\\lambda_{0}+\\lambda_{1}x_{1}+\\lambda_{2}x_{2}))=\\frac{1}{2}(1+\\operatorname{tanh}(-\\lambda_{0}-\\lambda_{1}x_{1}-\\lambda_{2}x_{2}))}}\\\\ {{\\lambda_{0}+\\lambda_{1}x_{1}+\\lambda_{2}x_{2}=-\\lambda_{0}-\\lambda_{1}x_{1}-\\lambda_{2}x_{2}}}\\\\ {{\\lambda_{0}+\\lambda_{1}x_{1}+\\lambda_{2}x_{2}=0.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In words, the decision boundary in the causal direction is a linear function of the covariates. Using this result, we proceed to prove the relation between the marginal covariance matrix and the normal to the decision boundary as in Item 1 of Propostion 9 ", "page_idx": 14}, {"type": "text", "text": "We want to prove $\\pmb{\\lambda}\\propto\\pmb{\\Sigma}_{\\mathbf{X}}^{-1}\\pmb{\\Sigma}_{\\mathbf{X},Y}=\\pmb{\\Sigma}_{\\mathbf{X}}^{-1}\\pmb{\\phi}.$ . ", "page_idx": 14}, {"type": "text", "text": "First, we define the random variable $Z:=\\lambda_{1}X_{1}+\\lambda_{2}X_{2}$ . We can write $P(Y=1|\\mathbf{x})$ entirely as function of $Z$ , thus $\\mathbf{X}\\perp\\!\\!\\!\\perp Y\\,|Z$ . ", "page_idx": 14}, {"type": "text", "text": "To continue with the proof, we consider the Hilbert space of centered random variables with basis given by span $(\\mathbf{X})$ and covariance as inner product. Following this geometric interpretation, we define $W_{j}\\,:=\\,X_{j}\\,-\\,\\alpha_{j}Z$ , where $\\alpha_{j}Z$ is the projection of $X_{j}$ onto the span of $Z$ . That is, $\\alpha_{j}=\\mathrm{Cov}[X_{j},Z]\\mathrm{Var}(Z)^{-1}$ . We have that $\\mathbf{W}=\\left\\{W_{1},W_{2}\\right\\}\\in\\mathrm{span}\\left(\\mathbf{X}\\right)$ , so that $\\mathrm{Cov}[Z,\\mathbf{W}]=0$ . As a result, W \u22a5\u22a5 $Z$ because all variables in the span of $\\mathbf{X}$ are Gaussian. Together with $\\mathring{\\mathbf{W}}\\perp\\!\\!\\!\\perp\\,\\dot{Y}\\mid Z$ , this implies via the semi-graphoid axioms [23] that W \u22a5\u22a5 $(Y,Z)$ , so that W \u22a5\u22a5 $Y$ and thus $\\mathrm{Cov}[\\mathbf{W},Y]=0$ . ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Taking the inner product with $Y$ on both sides of $X_{j}\\;=\\;\\alpha_{j}Z\\,+\\,W_{j}$ gives us $\\operatorname{Cov}[X_{j},Y]\\;=\\;$ $\\alpha_{j}\\mathrm{Cov}[Z,Y]+\\mathrm{Cov}[W_{j},Y]\\,=\\,\\alpha_{j}\\mathrm{Cov}[Z,Y]\\,=\\,\\mathrm{Cov}[X_{j},Z]\\mathrm{Var}(Z)^{-1}\\mathrm{Cov}[Z,Y]$ . This is valid for $j\\,=\\,1,2$ , hence $\\Sigma_{{\\bf X},Y}\\;=\\;\\Sigma_{{\\bf X},Z}\\sigma_{Z}^{-2}\\Sigma_{Z,Y}$ . By definition, $\\Sigma_{{\\bf X},Z}\\;=\\;\\lambda\\Sigma_{{\\bf X}}$ , so that $\\Sigma{\\bf x},Y\\;=\\;$ $\\lambda\\Sigma_{\\mathbf{X}}\\sigma_{Z}^{-2}\\sigma_{Z,Y}$ and finally $(\\Sigma_{\\bf X}\\sigma_{Z}^{-2}\\sigma_{Z,Y})^{-1}\\Sigma_{\\bf X,\\scriptscriptstyle Y}=\\lambda$ , as required. ", "page_idx": 15}, {"type": "text", "text": "C.2 Proof of Propostion 9 in the anticausal direction ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The normal to the decision boundary using the MAP rule in anticausal direction is derived in a similar way to Appendix C.1. In particular, the normal is given by the points of $\\mathbf{x}$ where we are indifferent between choosing $Y=1$ and $Y=-1$ . To find such a vector, we solve for $\\mathbf{x}$ in ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{P(Y=1\\mid\\mathbf{x})=P(Y=-1\\mid\\mathbf{x})}\\\\ {P(\\mathbf{x}\\mid Y=1)P(Y=1)=P(\\mathbf{x}\\mid Y=-1)P(Y=-1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In the second line of the above equation, we used $P(Y=y\\mid\\mathbf{x})\\propto P(\\mathbf{x}\\mid Y=y)P(Y=y).$ ", "page_idx": 15}, {"type": "text", "text": "We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p\\exp\\left(-\\frac{1}{2}({\\bf x}-{\\mu}_{1})^{\\top}{\\bf\\Sigma}_{{\\bf X}|Y}^{-1}({\\bf x}-{\\mu}_{1})\\right)=(1-p)\\exp\\left(-\\frac{1}{2}({\\bf x}-{\\mu}_{-1})^{\\top}{\\bf\\Sigma}_{{\\bf X}|Y}^{-1}({\\bf x}-{\\mu}_{-1})\\right)}\\\\ {\\log\\left(\\frac{p}{1-p}\\right)=-\\frac{1}{2}(2{\\bf x}^{\\top}{\\bf\\Sigma}_{{\\bf X}|Y}^{-1}({\\mu}_{1}-{\\mu}_{-1})+{\\mu}_{1}^{\\top}{\\bf\\Sigma}_{{\\bf X}|Y}^{-1}{\\mu}_{1}-{\\mu}_{-1}^{\\top}{\\bf\\Sigma}_{{\\bf X}|Y}^{-1}{\\mu}_{-1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The above equation is linear in $\\mathbf{x}$ , giving us a linear decision rule, and we would choose $Y=1$ if ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbf{x}^{\\top}\\mathbf{\\Sigma}_{\\mathbf{X}|Y}^{-1}(\\mu_{1}-\\mu_{-1})>\\frac{1}{2}\\mu_{-1}^{\\top}\\Sigma_{\\mathbf{X}|Y}^{-1}\\mu_{-1}-\\frac{1}{2}\\mu_{1}^{\\top}\\Sigma_{\\mathbf{X}|Y}^{-1}\\mu_{1}-\\log\\left(\\frac{p}{1-p}\\right)}}\\\\ &{}&{\\mathrm{~=\\frac{1}{2}(}\\mu_{-1}-\\mu_{1})^{\\top}\\Sigma_{\\mathbf{X}|Y}^{-1}(\\mu_{-1}+\\mu_{1})-\\log\\left(\\frac{p}{1-p}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Remark $^{l4}$ As mentioned in Theorem 5, the decision rule in Equation (53) is known as the Gaussian discriminant analysis [14]. This is a special case of Linear Discriminant Analysis. The family of LDA algorithms also contains Naive Bayes (if all the $\\mathbf{x}$ are conditionally independent) and Quadratic Discriminant Analysis (QDA) (if the covariance matrices for each $Y$ are not equal, giving a curved decision rule). ", "page_idx": 15}, {"type": "text", "text": "Now we will prove that if we have use all the moments in Equations (1) and (2) as constraints, the slope of the two decision boundaries are the same. ", "page_idx": 15}, {"type": "text", "text": "Theorem 10 (Slope of the decision boundary is the same in causal and anticausal direction). Using the constraints in Equations (1) and (2), the slope of $P_{\\lambda}(Y\\mid\\mathbf{X})$ inferred using CMAXENT is the same in causal and anticausal direction. ", "page_idx": 15}, {"type": "text", "text": "Proof. In Propostion 9 we proved that in the causal direction, the normal vector to the decision boundary in the causal direction is $\\Sigma_{\\mathbf{X}}^{-1}\\phi$ . Furthermore, using the law of total covariance (and the assumption that $\\bar{x}\\,=\\,0$ ), we can write $\\pmb{\\Sigma}_{\\mathbf{X}}\\,=\\,\\pmb{\\Sigma}_{\\mathbf{X}|Y}\\,+\\,c\\phi\\phi^{\\top}$ , where $c\\,=\\,1/(2^{2}p(1\\,-\\,p))$ (see Equation (38)). Using the Sherman-Morrison formula [2], we can write ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\phantom{\\sum_{\\mathbf{X}}^{-1}}\\!\\!\\!\\!}&{=\\!\\!\\!\\!}&{\\!\\!\\!\\!\\!\\sum_{\\mathbf{X}}^{-1}\\!\\!\\!\\!\\!}\\\\ &{}&{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\!\\Sigma_{\\mathbf{X}|Y}^{-1}-\\frac{c\\pmb{\\Sigma}_{\\mathbf{X}|Y}^{-1}\\phi\\phi^{\\top}\\Sigma_{\\mathbf{X}|Y}^{-1}}{1+c\\phi^{\\top}\\Sigma_{\\mathbf{X}|Y}^{-1}\\phi}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Applying this operator to $\\phi$ , and noticing that $\\phi^{\\top}\\Sigma_{\\mathbf{X}\\mid Y}^{-1}\\phi$ is a scalar, we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\Sigma}_{\\mathbf{X}}^{-1}=\\pmb{\\Sigma}_{\\mathbf{X}|\\gamma}^{-1}\\phi+k\\pmb{\\Sigma}_{\\mathbf{X}|\\gamma}^{-1}\\phi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $k=(-c\\phi^{\\top}\\Sigma_{\\mathbf{x}|Y}^{-1}\\phi)/(1+c\\phi^{\\top}\\Sigma_{\\mathbf{x}|Y}\\phi)$ . Thus $\\Sigma_{\\mathbf{X}}^{-1}\\phi\\propto\\Sigma_{\\mathbf{X}|Y}\\phi$ , as required. ", "page_idx": 15}, {"type": "text", "text": "D Missing covariance between the outcome variable and one of the covariates ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Suppose we do not observe $\\mathbb{E}[Y X_{2}]=\\phi_{2}$ . Can CMAXENT say anything about the distribution $P({\\bar{Y}}\\mid\\mathbf{x})?$ The answer is positive under the assumption that $Y$ and $X_{2}$ are correlated. To see this, we will use the following result in information theory: The entropy of a distribution with given first and second moments is always less than the entropy of a multivariate Gaussian given the same first and second moments [37, Theorem 8.6.5]. Hence, we can analytically compute the maximum entropy solution of $\\phi_{2}$ via the entropy of the multivariate Gaussian as an upper bound on the entropy of $\\mathbf{X}$ given $Y$ . ", "page_idx": 16}, {"type": "text", "text": "To do this, we will use the results of Appendix A, where we found an expression of $\\Sigma_{{\\bf X}\\mid Y}$ as a function of $\\phi_{2}$ . Since $\\phi_{2}$ appears on several elements of the $\\Sigma_{{\\bf X}\\mid Y}$ , we first compute the determinant of $\\Sigma_{{\\bf X}|{\\cal Y}}$ , differentiate with respect to $\\phi_{2}$ and equate to 0 to find the optimal $\\phi_{2}$ . ", "page_idx": 16}, {"type": "text", "text": "For reference, the differential entropy of a multivariate Gaussian of $k$ dimensions and covariance matrix $\\Sigma$ is ", "page_idx": 16}, {"type": "equation", "text": "$$\nH(f)={\\frac{k}{2}}+{\\frac{k}{2}}\\log(2\\pi)+{\\frac{1}{2}}\\log(\\operatorname*{det}(\\Sigma))\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\zeta_{\\lambda\\lambda^{\\prime}}\\approx}&{\\frac{a^{2}}{\\sqrt{2}}\\frac{a^{2}}{\\sqrt{2}}\\frac{12\\tilde{\\lambda}^{2}-16\\tilde{\\lambda}^{2}}{2}-\\frac{3\\tilde{\\lambda}^{2}(2-2p)}{2}\\frac{112\\tilde{\\lambda}^{2}-112\\tilde{\\lambda}^{2}}{2}-\\frac{a^{2}}{\\sqrt{2}}\\frac{12\\tilde{\\lambda}^{2}}{2}}\\\\ &{-\\frac{(2p-1)^{2}\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}}{2}+\\frac{(2p-1)^{2}\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}+22\\tilde{\\lambda}^{2}}{2}-\\frac{12\\tilde{\\lambda}^{2}}{2}\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\mu_{2}+(2p-1)^{2}\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}^{2}}\\\\ &{-\\frac{2(2p-1)\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}}{2}+\\frac{2(2p-1)\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\tilde{\\lambda}^{2}}{2}+\\frac{(2p-1)^{2}\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\tilde{\\lambda}^{2}+22\\tilde{\\lambda}^{2}-12\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\tilde{\\lambda}^{2}}{2\\tilde{\\lambda}^{2}}}\\\\ &{-\\frac{2\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}}{2}-\\frac{12\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}}{2}+\\frac{(2p-1)^{2}\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\tilde{\\lambda}^{2}}{2\\tilde{\\lambda}^{2}}+\\frac{12\\tilde{\\lambda}^{2}}{2}\\frac{12\\tilde{\\lambda}^{2}\\tilde{\\mu}_{2}\\tilde{\\lambda}^{2}}{2}}\\\\ &{- \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Now we differentiate det $\\left(\\Sigma_{X\\mid Y}\\right)$ with respect to $\\phi_{2}$ , equate to 0 and solve for $\\phi_{2}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\partial\\operatorname*{det}\\Sigma_{X|Y}}{\\partial\\phi_{2}}=-\\frac{\\tilde{s}_{1}^{2}(2p-1)\\bar{x}_{2}}{2p(1-p)}-\\frac{2\\tilde{s}_{1}^{2}\\phi_{2}}{2p(1-p)}+\\frac{2(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}}{(2p(1-p))^{2}}+\\frac{2(2p-1)^{2}\\bar{x}_{1}^{2}\\phi_{2}}{(2p(1-p))^{2}}}\\\\ {+\\frac{2^{2}(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}}{(2p(1-p))^{2}}+\\frac{2^{2}(2p-1)\\bar{x}_{1}\\phi_{1}\\phi_{2}}{(2p(1-p))^{2}}+\\frac{2(2p-1)\\bar{x}_{2}\\phi_{1}^{2}}{(2(2p-1))^{2}}+\\frac{2\\phi_{1}^{2}\\phi_{2}}{(2(2p-1))^{2}}}\\\\ {+\\frac{\\bar{s}_{1,2}(2p-1)\\bar{x}_{1}}{2p(1-p)}+\\frac{\\bar{s}_{1,2}\\phi_{1}}{2p(1-p)}-\\frac{(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}}{(2(2p-1))^{2}}-\\frac{(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}}{(2(2p-1))^{2}}}\\\\ {+\\frac{(2p-1)\\bar{x}_{1}\\bar{s}_{1,2}}{2p(1-p)}-\\frac{(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}}{(2p(1-p))^{2}}-\\frac{2(2p-1)^{2}\\bar{x}_{1}^{2}\\phi_{2}}{(2p(1-p))^{2}}-\\frac{(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}}{(2p(1-p))^{2}}}\\\\ {-\\frac{2(2p-1)\\bar{x}_{1}\\phi_{1}\\phi_{2}}{(2p \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Equating the above derivative to 0, we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi_{2}[-2\\bar{s}_{1}^{2}p(1-p)+2(2p-1)^{2}\\bar{x}_{1}^{2}+2^{2}(2p-1)\\bar{x}_{1}\\phi_{1}+2\\phi_{1}^{2}-2(2p-1)^{2}\\bar{x}_{1}^{2}-2(2p-1)\\bar{x}_{1}\\phi_{1}]}\\\\ &{\\quad=\\bar{s}_{1}^{2}2^{2}2p(1-p)(2p-1)\\bar{x}_{2}-2(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}-2^{2}(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}}\\\\ &{\\quad-\\,2(2p-1)\\bar{x}_{2}\\phi_{1}^{2}-\\bar{s}_{1,2}2p(1-p)(2p-1)\\bar{x}_{1}-2p(1-p)\\bar{s}_{1,2}\\phi_{1}}\\\\ &{\\quad+\\,(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}+(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}-(2p-1)\\bar{x}_{1}\\bar{s}_{1,2}}\\\\ &{\\quad+\\,(2p-1)^{3}\\bar{x}_{1}^{2}\\bar{x}_{2}+(2p-1)^{2}\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}+(2p-1)2\\bar{x}_{1}\\bar{x}_{2}\\phi_{1}+(2p-1)\\bar{x}_{2}\\phi_{1}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Which can be simplified to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\phi_{2}=\\displaystyle\\frac{1}{2\\phi_{1}^{2}+2(2p-1)\\bar{x}_{1}\\phi_{1}-2\\bar{s}_{1}^{2}p(1-p)}\\cdot}}\\\\ {{\\displaystyle\\qquad[2^{2}p(1-p)(2p-1)\\bar{s}_{1}^{2}\\bar{x}_{2}-(2p-1)\\bar{x}_{2}\\phi_{1}^{2}-2p(1-p)(2p-1)\\bar{s}_{1,2}\\bar{x}_{1}}}\\\\ {{-\\,2p(1-p)\\bar{s}_{1,2}\\phi_{1}-(2p-1)\\bar{x}_{1}\\bar{s}_{1,2}+(2p-1)^{2}p(1-p)].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Although we have derived here the general case where the sample means are not zero, we will continue the analysis by coming back to such assumption. That is, $\\bar{x}_{1}\\,=\\,\\bar{x}_{2}\\,=\\,0$ , giving us the following expression for $\\phi_{2}$ which is easier to interpret ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\phi_{2}=\\frac{p(1-p)\\bar{s}_{1,2}\\phi_{1}}{p(1-p)\\bar{s}_{1}^{2}-\\phi_{1}^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In the numerator, we have that as the covariance between $X_{1}$ and $X_{2}$ increases, the MAXENT covariance between $X_{2}$ and $Y$ increases too. Furthermore, we see that the denominator is always greater than 1 by the Cauchy-Schwarz inequality of random variables, $\\operatorname{Cov}(X_{1},Y)^{2}\\leq\\operatorname{Var}(X_{1}^{\\cdot}){\\tilde{\\operatorname{Var}}}(Y)$ , given that $p(1-p)$ is the variance of $\\dot{Y},\\,\\bar{s}_{1}^{2}$ is the sample variance of $X_{1}$ , and $\\phi_{1}$ is the sample covariance between $X_{1}$ and $Y$ . ", "page_idx": 17}, {"type": "text", "text": "E Derivation of the decision boundary with unknown predictor covariance ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Causal. In the causal case, we have that the distribution of the causes is a multivariate Gaussian with diagonal covariance matrix, and the conditional distribution of the target variable given the covariates is the same as in Equation (7). ", "page_idx": 17}, {"type": "text", "text": "As a result, we have that the decision boundary is still proportional to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{\\Sigma}_{\\mathbf{X},c a u s a l}^{-1}\\phi=\\left[\\bar{s}_{1}^{-2}\\phi_{1}\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "as derived in section Appendix C.1. ", "page_idx": 17}, {"type": "text", "text": "Anticausal. In the anticausal direction, we have that the target variable follows a Bernoulli distribution, and the conditional distribution of the covariates given the target variable is again a mixture of Gaussians with diagonal conditional covariance matrix. We first prove Propostion 12. ", "page_idx": 18}, {"type": "text", "text": "Proposition 12 (Diagonal conditional covariance in the anticausal direction with unknown predictor covariance). The distribution $P(\\mathbf{X}\\mid Y)$ that maximises the conditional entropy subject to the following constraints: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{\\mathbb{E}}[\\mathbf{X}Y]=\\left[\\phi_{1}\\right],\\quad\\hat{\\mathbb{E}}[\\mathbf{X}]=\\left[0\\right],\\quad\\hat{\\mathbb{E}}[X_{1}^{2}]=\\bar{s}_{1}^{2},\\quad\\hat{\\mathbb{E}}[X_{2}^{2}]=\\bar{s}_{2}^{2},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and $P(Y)$ inferred on the first step of CMAXENT, is independent after choosing a value of $y$ ; that is, $\\mathbf{X}$ is conditionally independent given $Y$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. The solution to the constrained optimisation problem has the same form as in Equation (10), without the cross term: ", "page_idx": 18}, {"type": "equation", "text": "$$\nP_{\\lambda}(\\mathbf{x}\\mid y)=\\exp[\\lambda_{1}y x_{1}+\\lambda_{2}y x_{2}+\\lambda_{3}x_{1}+\\lambda_{4}x_{2}+\\lambda_{5}x_{1}^{2}+\\lambda_{6}x_{2}^{2}+\\beta(y)].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Conditioning on any specific value of $Y$ , gives us an uncorrelated multivariate Gaussian, as required. ", "page_idx": 18}, {"type": "text", "text": "Using Equation (31) we can express the conditional covariance as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{\\mathbf{X}|Y}=\\Sigma_{\\mathbf{X}}-(1-p)p(\\mu_{1}-\\mu_{-1})(\\mu_{1}-\\mu_{-1})^{\\top}\\qquad\\qquad\\qquad\\qquad\\qquad(66^{2}\\mu_{1}-\\mu_{-1})^{\\top}}\\\\ &{\\qquad=\\left[\\!\\!\\begin{array}{l l}{\\bar{s}_{1}^{2}}&{\\psi}\\\\ {\\psi}&{\\bar{s}_{2}^{2}\\right]-p(1-p)\\left[(\\mu_{1,2}-\\mu_{-1,2})(\\mu_{1,1}-\\mu_{-1,1})^{2}\\qquad\\qquad\\qquad(\\mu_{1,1}-\\mu_{-1,1})(\\mu_{1,2}-\\mu_{-1,2})\\!\\!\\right].}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since we know that $\\Sigma_{{\\bf X}\\mid Y}$ is diagonal, then $\\psi\\,=\\,p(1\\,-\\,p)(\\mu_{1,1}\\,-\\,\\mu_{-1,1})(\\mu_{1,2}\\,-\\,\\mu_{-1,2})$ . From Equations (32) and (33), we can conclude that $p(1-p)(\\mu_{1,i}-\\mu_{-1,i})^{2}\\propto\\phi_{i}^{2}$ . Wit this, we find an expression of $\\Sigma_{{\\bf X}\\mid Y}$ as a function of the constraints ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Sigma_{\\mathbf{X}|Y}=\\left[\\overset{\\bar{s}_{1}^{2}-\\phi_{1}^{2}}{0}\\quad\\quad0\\atop\\bar{s}_{2}^{2}-\\phi_{2}^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "On Appendix C.2 (see also Hastie et al. [14, Sec. 4.4.5]) we proved that the slope of the decision boundary in the anticausal direction is proportional to ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Sigma_{\\mathbf{X}|Y}^{-1}\\phi,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and using Equations (32) and (33), we have that the slope of the decision boundary is proportional to ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Sigma_{\\mathbf{x}|Y}^{-1}\\phi\\propto\\left[(\\bar{s}_{1}^{2}-\\phi_{1}^{2})^{-1}\\phi_{1}\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "A natural question arises: when are these slopes the same? in other words, when are Equations (64) and (70) linearly dependent? This question can be answered be equating ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{(\\bar{s}_{1}^{2}-\\phi_{1}^{2})^{-1}\\phi_{1}\\bar{s}_{2}^{2}\\phi_{2}}{\\bar{s}_{1}^{2}\\phi_{1}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "to ", "page_idx": 18}, {"type": "equation", "text": "$$\n(\\bar{s}_{2}^{2}-\\phi_{2}^{2})^{-1}\\phi_{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{(\\bar{s}_{1}^{2}-\\phi_{1}^{2})^{-1}\\phi_{1}\\bar{s}_{2}^{2}\\phi_{2}}{\\bar{s}_{1}^{2}\\phi_{1}}=(\\bar{s}_{2}^{2}-\\phi_{2}^{2})^{-1}\\phi_{2}}\\\\ &{(\\bar{s}_{2}^{2}-\\phi_{2}^{2})\\phi_{1}\\bar{s}_{2}^{2}\\phi_{2}=(\\bar{s}_{1}^{2}-\\phi_{1}^{2})\\phi_{2}\\bar{s}_{1}^{2}\\phi_{1}}\\\\ &{\\frac{(\\bar{s}_{2}^{2}-\\phi_{2}^{2})\\phi_{1}\\bar{s}_{2}^{2}\\phi_{2}}{(\\bar{s}_{1}^{2}-\\phi_{1}^{2})\\phi_{2}\\bar{s}_{1}^{2}\\phi_{1}}=1}\\\\ &{\\frac{(\\bar{s}_{2}^{2}-\\phi_{2}^{2})\\bar{s}_{2}^{2}}{(\\bar{s}_{1}^{2}-\\phi_{1}^{2})\\bar{s}_{1}^{2}}=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: All the theoretical claims in the abstract and introduction are part of the main article. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Since this is a theoretical paper, most of the limitations come from the assumptions made to obtain the theoretical results. In addition we discuss some potential computational problems, when applying these results in real world problems. These limitations are discussed in the main article, in any case. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: This is the bulk of the paper. We provide clear assumptions and proofs of every result (except corollaries) on the paper. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper does not contain any empirical results. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper does not include any data or code, besides a very small toy example. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: As above. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: As above. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: As above. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Due its theoretical nature, the paper adheres to NeurIPS Code of Ethics. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: We briefly discussed that practitioners should take some of these results into account but there is no broad impact in the potential application of the ideas outlined in the paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: There are no major risks posed by the paper. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not use any licensed assets. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not involve human subjects. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]