[{"figure_path": "XErWgdxaFU/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of HFTT and competitive baselines with and without in-distribution image requirements on the ImageNet-1K dataset. The best and second-best results are indicated in bold and underlined, respectively. Our method surpasses even strong baselines that utilize in-distribution images. This complements our analysis in Section 3.1, demonstrating that textual data can substitute for visual data in such tasks.", "description": "This table compares the performance of the proposed Hassle-Free Textual Training (HFTT) method against several other state-of-the-art methods for out-of-distribution (OOD) detection on the ImageNet-1k dataset.  It highlights the effectiveness of HFTT, which uses only textual data for training, even when compared to methods that require in-distribution images. The results support the paper's claim that textual data can effectively substitute for visual data in certain tasks.", "section": "4 Experimental Results and Discussion"}, {"figure_path": "XErWgdxaFU/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of HFTT with state-of-the-art methods for OOD detection that do not require in-distribution images, conducted on the Hate dataset. The best result in each column is in bold. HFTT outperforms baseline approaches, showing that it can effectively be used for the general purpose of unwanted data detection.", "description": "This table compares the performance of the Hassle-Free Textual Training (HFTT) method against other state-of-the-art out-of-distribution (OOD) detection methods on a dataset focused on hateful images.  It highlights that HFTT, which doesn't need in-distribution images for training, still surpasses methods that do require such images. This demonstrates HFTT's effectiveness in detecting unwanted visual data.", "section": "4.2 Out-of-Distribution Detection"}, {"figure_path": "XErWgdxaFU/tables/tables_14_1.jpg", "caption": "Table 3: Comparison of HFTT with baselines on the low-quality image detection.", "description": "This table compares the performance of the proposed Hassle-Free Textual Training (HFTT) method against existing baselines on a low-quality image detection task.  It shows the False Positive Rate (FPR) and Area Under the Receiver Operating Characteristic curve (AUROC) for each method, demonstrating HFTT's superior performance in identifying corrupted images.  The results highlight HFTT's effectiveness even compared to methods that utilize in-distribution images.", "section": "4.2 Out-of-Distribution Detection"}, {"figure_path": "XErWgdxaFU/tables/tables_14_2.jpg", "caption": "Table 4: Comparison of HFTT with MCM on the medical image datasets.", "description": "This table compares the performance of HFTT and MCM on two medical image datasets (PVQA and PCAM), using the ISIC-18 dataset as in-distribution data.  It shows the false positive rate (FPR) and area under the receiver operating characteristic curve (AUROC) for each method,  with and without additional descriptions and corpus engineering.  The results demonstrate that HFTT outperforms MCM, especially when incorporating additional context.", "section": "4.2 Out-of-Distribution Detection"}, {"figure_path": "XErWgdxaFU/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of HFTT and competitive baselines with and without in-distribution image requirements on the ImageNet-1K dataset. The best and second-best results are indicated in bold and underlined, respectively. Our method surpasses even strong baselines that utilize in-distribution images. This complements our analysis in Section 3.1, demonstrating that textual data can substitute for visual data in such tasks.", "description": "This table compares the performance of the proposed Hassle-Free Textual Training (HFTT) method against several other state-of-the-art methods for out-of-distribution (OOD) detection on the ImageNet-1k dataset.  It highlights the performance of HFTT even when compared to methods that require in-distribution images, thereby supporting the paper's claim that textual data can effectively replace visual data for OOD detection.", "section": "Experimental Results and Discussion"}, {"figure_path": "XErWgdxaFU/tables/tables_15_2.jpg", "caption": "Table 4: Comparison of HFTT with MCM on the medical image datasets.", "description": "This table compares the performance of the proposed Hassle-Free Textual Training (HFTT) method against the Maximum Mean Discrepancy (MMD) method for out-of-distribution (OOD) detection in medical image datasets.  The datasets used are PVQA (visual question answering) and PCAM (breast cancer detection).  The metrics used for comparison are the False Positive Rate (FPR) and Area Under the Receiver Operating Characteristic curve (AUROC).  The table shows HFTT significantly outperforms MCM on both datasets, indicating its superior performance for OOD detection in medical image analysis.", "section": "4.2 Out-of-Distribution Detection"}, {"figure_path": "XErWgdxaFU/tables/tables_16_1.jpg", "caption": "Table 7: OOD detection performance on ImageNet in-distribution (average for Texture, Places, SUN, and iNaturalist).", "description": "This table presents the results of out-of-distribution (OOD) detection experiments performed on the ImageNet dataset.  Specifically, it shows the False Positive Rate (FPR) and Area Under the Receiver Operating Characteristic curve (AUROC) for three different methods: CLIPN, NegLabel, and the authors' proposed method, HFTT.  The results are averaged across four different out-of-distribution datasets: Texture, Places, SUN, and iNaturalist. This table demonstrates the relative performance of the three methods in identifying out-of-distribution samples within the ImageNet dataset.", "section": "4 Experimental Results and Discussion"}, {"figure_path": "XErWgdxaFU/tables/tables_16_2.jpg", "caption": "Table 1: Comparison of HFTT and competitive baselines with and without in-distribution image requirements on the ImageNet-1K dataset. The best and second-best results are indicated in bold and underlined, respectively. Our method surpasses even strong baselines that utilize in-distribution images. This complements our analysis in Section 3.1, demonstrating that textual data can substitute for visual data in such tasks.", "description": "This table compares the performance of the proposed Hassle-Free Textual Training (HFTT) method against other state-of-the-art Out-of-Distribution (OOD) detection methods on the ImageNet-1k dataset.  It shows that HFTT achieves better results than methods that require in-distribution images, supporting the paper's claim that textual data can replace visual data in OOD detection.", "section": "Experimental Results and Discussion"}, {"figure_path": "XErWgdxaFU/tables/tables_17_1.jpg", "caption": "Table 9: Results of using different values of \u03b3 for the focal loss. The performance of HFTT appears to be relatively robust to changes in the choice of \u03b3, with the adoption of focal loss with \u03b3 > 0 generally leading to improved results.", "description": "This table presents the results of an ablation study on the effect of the focal loss hyperparameter (\u03b3) on the performance of the Hassle-Free Textual Training (HFTT) method.  It shows the AUROC and FPR values for different \u03b3 values (0, 1, 2, and 3) across five different OOD datasets (iNaturalist, SUN, Places, Texture, and NINCO).  The results suggest that while the performance is relatively stable across different \u03b3 values, using a focal loss (\u03b3 > 0) generally leads to better performance compared to not using it (\u03b3 = 0).", "section": "C Ablation Study"}, {"figure_path": "XErWgdxaFU/tables/tables_17_2.jpg", "caption": "Table 10: Results of changing the temperature of the final Softmax layer.", "description": "This table presents the results of an ablation study on the effect of the temperature parameter in the final Softmax layer of the proposed Hassle-Free Textual Training (HFTT) model.  Different temperature values (1.0, 0.1, and 0.01) were tested on the OOD detection task using five different OOD datasets (iNaturalist, SUN, Places, Texture, and NINCO), along with the ImageNet-1k dataset as the in-distribution data. The table shows the False Positive Rate (FPR) and Area Under the ROC Curve (AUROC) for each temperature setting and dataset.  The purpose is to evaluate how sensitive the model's performance is to this hyperparameter and how it impacts the balance between in-distribution and out-distribution detection. ", "section": "4.1 Experimental Setup"}, {"figure_path": "XErWgdxaFU/tables/tables_17_3.jpg", "caption": "Table 11: Results of shrinking or expanding the number of trainable embeddings (N).", "description": "This table presents the results of an ablation study on the number of trainable embeddings (N) used in the Hassle-Free Textual Training (HFTT) method. It shows how the performance of HFTT in out-of-distribution (OOD) detection varies with different values of N, across five different OOD datasets and an average performance.  The results demonstrate that HFTT can achieve good performance even with a small number of trainable embeddings.", "section": "4 Experimental Results and Discussion"}]