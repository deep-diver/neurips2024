{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-09", "reason": "This paper introduces chain-of-thought prompting, a highly influential technique for improving the reasoning capabilities of LLMs, which is directly relevant to the core methodology of AUTOPSV."}, {"fullname_first_author": "Jonathan Uesato", "paper_title": "Solving math word problems with process- and outcome-based feedback", "publication_date": "2022-11-14", "reason": "This paper explores the use of both process and outcome supervision for improving reasoning, directly informing the design and training paradigms used in AUTOPSV."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper introduces the concept of using verification models to improve LLM reasoning, a key component and inspiration for the AUTOPSV approach."}, {"fullname_first_author": "Peiyi Wang", "paper_title": "Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations", "publication_date": "2023-12-27", "reason": "This paper presents a method for automatically annotating reasoning steps, a core function also implemented and improved upon by AUTOPSV, which further reduces human effort."}, {"fullname_first_author": "Zihan Wang", "paper_title": "Multi-step problem solving through a verifier: An empirical analysis on model-induced process supervision", "publication_date": "2024-02-27", "reason": "This paper investigates model-induced process supervision for improving reasoning, a related approach that informs AUTOPSV's methodology and is compared against for evaluation."}]}