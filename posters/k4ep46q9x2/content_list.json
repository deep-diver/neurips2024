[{"type": "text", "text": "Unveiling the Potential of Robustness in Selecting Conditional Average Treatment Effect Estimators ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yiyan Huang \\* The Hong Kong Polytechnic University yiyhuang3-c@my.cityu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Cheuk Hang Leung \\* City University of Hong Kong chleung87@cityu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Siyi Wang City University of Hong Kong siyi.wang@my.cityu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Yijun Li City University of Hong Kong yijunli5-c@my.cityu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Qi Wu t City University of Hong Kong qi.wu@cityu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). Various types of CATE estimators have been developed with advancements in machine learning and causal inference. However, selecting the desirable CATE estimator through a conventional model validation procedure remains impractical due to the absence of counterfactual outcomes in observational data. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two challenges. First, they must determine the metric form and the underlying machine learning models for fitting nuisance parameters (e.g., outcome function, propensity function, and plug-in learner). Second, they lack a specific focus on selecting a robust CATE estimator. To address these challenges, this paper introduces a Distributionally Robust Metric (DRM) for CATE estimator selection. The proposed DRM is nuisance-free, eliminating the need to fit models for nuisance parameters, and it effectively prioritizes the selection of a distributionally robust CATE estimator. The experimental results validate the effectiveness of the DRM method in selecting CATE estimators that are robust to the distribution shift incurred by covariate shift and hidden confounders. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The escalating demand for decision-making has sparked an increasing interest in Causal Inference across various research domains, such as economics [23, 13, 43, 1], statistics [70, 49, 26, 41], healthcare [78, 27, 61, 9, 42], and financial application [11, 15, 37, 21, 35, 24, 50]. The primary goal in personalized decision-making is to quantify the causal effect of a specific treatment (or policy/intervention) on the target outcome, and understanding such causal effects is closely connected with identifying the Conditional Average Treatment Effect (CATE). In observational studies, identifying the CATE faces a significant and fundamental challenge: the absence of counterfactual knowledge. According to Rubin Causal Model [64], the CATE is determined by comparing potential outcomes under different treatment assignments (i.e., treat and control) for a specific covariate. Nonetheless, in real-world applications, we can only observe the potential outcome under the actual treatment (i.e., factual outcome), while the potential outcome under the alternative treatment (i.e., counterfactual outcome) remains unobserved. The unavailability of the counterfactual outcome is widely recognized as the fundamental problem in causal inference [33], making it difficult to accurately determine the truevalueoftheCATE. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The advancement of machine learning (ML) has opened up a promising opportunity to improve the CATE estimation from observational data. Several innovative CATE estimation approaches, such as meta-learners and causal ML models, have been proposed to tackle the fundamental challenge in causal inference and enhance the predictive accuracy of CATE estimates (as discussed in Section 3). Nevertheless, the emergence of various CATE estimation methods has brought forth a new question: Given multifarious options for CATE estimators, which should be chosen? In observational data, treatment is often non-random and propensity scores remain unknown. Conventional model validation procedures, unfortunately, are not suitable for CATE estimator selection in this case due to the absence of ground truth CATE labels. Therefore, exploring proper metrics for CATE estimator selection remains an essential yet challenging research topic in causal inference. ", "page_idx": 1}, {"type": "text", "text": "Recent research has emphasized the significance of model selection for CATE estimators, as highlighted in [66, 20, 53]. These works have proposed and summarized two types of criteria for CATE estimatorseletion,theplugin metricr $\\mathcal{R}_{\\tilde{\\tau}}^{p l u g}(\\hat{\\tau})$ and thepsudoucomemtric $\\mathcal{R}_{\\tilde{Y}}^{p s e u d o}(\\hat{\\tau})$ ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\tilde{\\tau}}^{p l u g}(\\hat{\\tau})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{\\tau}(X_{i})-\\tilde{\\tau}(X_{i}))^{2}},\\quad\\mathcal{R}_{\\hat{Y}}^{p s e u d o}(\\hat{\\tau})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{\\tau}(X_{i})-\\tilde{Y}_{i})^{2}}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "One can establish a plug-in estimator $\\tilde{\\tau}$ or construct a pseudo-outcome estimator Y using the validation data to select CATE estimator $\\hat{\\tau}$ . The previous studies [66, 20, 53] have shown that these metrics offer some assistance in identifying well-performing CATE estimators. However, two additional challenges are still encountered in these two metrics. ", "page_idx": 1}, {"type": "text", "text": "Challenge 1: How to determine the metric form and underlying ML models for nuisance parameters? As previously discussed, plug-in and pseudo-outcome metrics have various forms, and both of them rely on estimating nuisance parameters $\\tilde{\\eta}$ using ML algorithms such as linear models, tree-based models, etc. Plug-in metrics even need to fit an additional ML model for the plug-in learner $\\tilde{\\tau}$ . However, selecting the suitable metric form and ML algorithms can be very difficult without the knowledge of true data generating process. Consequently, we might go round in circles as this challenge leads us back to the original estimator selection problem [20]. ", "page_idx": 1}, {"type": "text", "text": "Challenge 2: These metrics are not well-targeted for selecting robust a CATE estimator. In potential outcome framework [64], the factual distribution $P^{F}$ and the counterfactual distribution $\\stackrel{\\triangledown}{P}^{C F}$ for $t\\in\\{0,1\\}$ canbe defined asfollows: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{P^{F}:=P(X,Y^{t}|T=t)=P(Y^{t}|X,T=t)P(X|T=t);\\quad\\quad}\\\\ &{}&{P^{C F}:=P(X,Y^{t}|T=1-t)=P(Y^{t}|X,T=1-t)P(X|T=1-t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The above (2) reveals that the covariate shift $P(X|T=t)\\neq P(X|T=1-t)$ leads to a distribution shift between $P^{F}$ and $P^{C F}$ - and such distribution shift can be further exacerbated once the unconfoundedness assumption $P(Y^{t}|X,T=t)=P(Y^{t}|X,T=1-t)$ is violated. It is widely recognized that ML models often struggle when the training and test data do not adhere to the same distribution. Therefore, it becomes essential to select a CATE estimator learned on $P^{F}$ that demonstrates robust performance to the counterfactual distribution $P^{C F}$ . This need for robustness holds even greater significance than the pursuit of an ideal \u201cstellar\u2019 estimator because striving for the perfect estimator can be futile in the absence of ground truth counterfactual labels. ", "page_idx": 1}, {"type": "text", "text": "Contributions. In this paper, we propose a Distributionally Robust Metric (DRM) for CATE estimator selection. The main contributions are summarized as follows: (1) The proposed DRM method is nuisance-free, eliminating the need to fit models for nuisance parameters (outcome function, propensity function, and plug-in learner). (2) The DRM method is designed to prioritize selecting a distributionally robust CATE estimator. (3) We provide a finite sample analysis of the proposed distributionally robust value $\\hat{\\mathcal{V}}^{t}(\\hat{\\tau})$ for $t\\in\\{0,1\\}$ showing it decaysto $\\mathcal{V}^{t}(\\hat{\\tau})$ at a rate of $n^{-1/2}$ (4) Experimental results validate the effectiveness of the DRM method in selecting a CATE estimator that is robust to the distribution shift incurred by covariate shift and hidden confounders. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2 Background of CATE Estimator Selection ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Suppose the observational data contain $n$ i.i.d. samples $\\{(x_{i},t_{i},y_{i})\\}_{i=1}^{n}$ , with the associated random variables being $\\{(X_{i},T_{i},Y_{i})\\}_{i=1}^{n}$ . For each unit $i$ $X_{i}\\in\\mathcal{X}\\subset\\mathbb{R}^{d}$ is $d$ -dimensional covariates and $T_{i}\\,\\in\\,\\{0,1\\}$ is the binary treatment. Potential outcomes for treat $T=1$ )and control $(T=0)$ are denoted by $Y^{1},Y^{0}\\in\\dot{\\mathcal{Y}}\\subset\\mathbb{R}$ . The observed (factual) outcome is $Y=T Y^{1}+(1-\\stackrel{.}{T})Y^{0}$ . The propensity score [63] is defined as $\\pi(x):=P(T=1\\mid X=x)$ . The conditional mean potential outcome surface is defined as $\\mu_{t}(x):=\\mathbb{E}\\left[Y^{t}\\mid X=x\\right]$ for $t\\in\\{0,1\\}$ . The true CATE is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\tau_{t r u e}(x):=\\mathbb{E}\\left[Y^{1}-Y^{0}\\mid X=x\\right]=\\mu_{1}(x)-\\mu_{0}(x).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Following the standard and necessary assumptions in potential outcome framework [64], we impose Assumption 2.1 that ensure treatment effects are identifiable. ", "page_idx": 2}, {"type": "text", "text": "Assumption 2.1 (Consistency, Overlap, and Unconfoundedness). Consistency: If the treatment is $t$ then the observed outcome $Y$ equals $Y^{t}$ . Overlap: The propensity score is bounded away from O to 1, i.e., $0<\\pi(x)<1,\\forall x\\in\\mathcal{X}$ . Unconfoundedness 3 : $\\gamma^{t}\\overset{\\cdot}{\\perp}\\!\\!\\!\\!\\perp\\!\\!\\!\\!\\!^{\\prime}\\,|\\,\\dot{X},\\,\\forall t\\in\\{0,1\\}$ ", "page_idx": 2}, {"type": "text", "text": "The goal of CATE estimator selection is to select the best CATE estimator, denoted by $\\hat{\\tau}_{b e s t}$ , from a setof $J$ candidate estimators $\\{\\hat{\\tau}_{1},\\hdots,\\hat{\\tau}_{J}\\}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{b e s t}=\\operatorname*{arg\\,min}_{\\hat{\\tau}\\in\\{\\hat{\\tau}_{1},\\dots,\\hat{\\tau}_{J}\\}}\\mathcal{R}^{o r a c l e}(\\hat{\\tau}),\\quad\\mathcal{R}^{o r a c l e}(\\hat{\\tau}):=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{\\tau}(X_{i})-\\tau_{t r u e}(X_{i}))^{2}}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here, $\\mathcal{R}^{o r a c l e}(\\hat{\\tau})$ is associated with $\\mathbb{E}[(\\hat{\\tau}(X)-\\tau_{t r u e}(X))^{2}]$ known as the Precision of Estimating Heterogeneous Effects (PEHE) w.r.t. $\\hat{\\tau}$ [32, 68]. Note that $\\mathcal{R}^{o r a c l e}(\\hat{\\tau})$ cannot be employed to evaluate CATE estimators? performances in real applications as we do not have access to $\\tau_{t r u e}$ . Previous studies have introduced plug-in and pseudo-outcome metrics to aid in CATE estimator selection, as shown in equation (1). Then, the CATE estimator $\\hat{\\tau}_{s e l e c t}$ is selected on validation data by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{s e l e c t}=\\operatorname*{arg\\,min}_{\\hat{\\tau}\\in\\{\\hat{\\tau}_{1},\\dots,\\hat{\\tau}_{J}\\}}\\mathcal{R}_{\\hat{\\tau}}^{p l u g}(\\hat{\\tau})\\quad\\mathrm{or}\\quad\\hat{\\tau}_{s e l e c t}=\\operatorname*{arg\\,min}_{\\hat{\\tau}\\in\\{\\hat{\\tau}_{1},\\dots,\\hat{\\tau}_{J}\\}}\\mathcal{R}_{\\tilde{Y}}^{p s e u d o}(\\hat{\\tau}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Notably, both the plug-in and pseudo-outcome metrics necessitate the fitting of nuisance parameters $\\tilde{\\eta}$ (e.g, $\\tilde{\\eta}=(\\tilde{\\mu}_{1},\\tilde{\\mu}_{0},\\tilde{\\pi}))$ using off-the-shelf ML models. While some papers like [16] address the selection of nuisance parameters for Averate Treatment Effect (ATE) estimators, e.g., the doubly robust estimator [23, 13, 36], our paper focuses on the selection of CATE estimators rather than nuisance parameters. For the plug-in metric, $\\tilde{\\tau}$ can be constructed using any CATE estimator discussed in Appendix A.1, yielding metrics such as plug-T, plug-DR, etc. For the pseudo-outcome metric, $\\tilde{Y}$ can be constructed using a specific formula discussed in Appendix A.2, yielding metrics such as pseudo-DR, pseudo-R, etc. The metrics based on the influence function [5] and the R-learner objective [55] are categorized into the pseudo-outcome metric. The categorization of plug-in and pseudo-outcome metrics maintains consistency with [20, 53]. ", "page_idx": 2}, {"type": "text", "text": "3 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "CATE estimation. Recent advancements in ML have emerged as powerful tools for estimating CATE from observational data, and researchers pay particular attention to meta-learners and causal ML models. Existing meta-learners mainly include traditional learners such as S-learner, T-learner, PS-learner, and IPW-learner, as well as new learners such as X-learner [47], U-learner [25, 55], DR-learner [41, 26], R-learner [55], and RA-learner [18]. The specific details of these meta-learners are stated in Appendix A.1. Additionally, some studies also focus on developing innovative causal ML models for CATE estimation, such as Causal BART [30], Causal Forest [70, 8, 58], generative models like CEVAE [51] and GANITE [77], representation learning nets including SITE [76], TARNet [68], Dragonnet [69], FlexTENet [19], and HTCE [10], disentangled learning nets like $\\mathrm{\\bar{D}^{2}V D}$ [44, 45], DeR-CFR [74], and DR-CFR [31], and representation balancing nets such as BNN [39], CFRNet [68], DKLITE [79], IGNITE [29], BWCFR [6], DRRB [35], and DIGNet [38]. Recent surveys [28, 75, 56] have also conducted a systematic review of various causal inference methods. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "CATE estimator selection. Compared to the diverse range of CATE estimation methods, selecting CATE estimators has received limited attention in existing causal inference research. Current methods for selecting CATE estimators can be broadly classified into two main categories. The first category, which is also considered in this paper, involves using plug-in and pseudo-outcome methods to evaluate CATE estimators. These methods share two common characteristics: 1) Both methods require fitting ML models for nuisances (e.g., outcome function, propensity function, CATE function) on a validation set and then implementing the learned ML models in either the plug-in surrogate or the pseudo-outcome surrogate; 2) Both methods serve as surrogates for the expected error between the CATE estimator and the true CATE,i.e, $\\mathcal{R}^{o r a c l e}(\\hat{\\tau})$ in equation (3).Thediferencebetweenthe two methods is that the plug-in method directly approximates the true CATE function, where only covariate variables are involved, while the pseudo-outcome method typically constructs a specific formula incorporating covariates, treatment, and outcome variables. For example, the pseudo-DR proposed in [65] is constructed by the outcome predictors learned with representation balancing objective [68, 40]. Recent research [66, 20, 53] has conducted thorough empirical investigations into exploring these two methods for selecting CATE estimators. Their findings suggest that no single selection criterion can universally outperform others in all scenarios in the task of selecting CATE estimators. More details of the two selection methods are stated in Appendix A.2. The second category considers leveraging the data generating process (DGP) to generate synthetic data with the known true CATE function, allowing the validation of CATE estimators\u2019 performance on this synthetic data. For example, authors in [2] find that placebo and structured empirical Monte Carlo methods are helpful for estimator selection under some restrictive conditions. In addition, researchers in [67, 7, 59] focus on training generative models to enforce the generated data to approximate the distribution of the observed data. However, the DGP-based method still faces some limitations in CATE estimator selection: 1) it only guarantees the resemblance of the generated data to the factual distribution, without considering the counterfactual distribution; and ii) there is a potential risk of the method favoring estimators that closely resemble the generative models [17]. ", "page_idx": 3}, {"type": "text", "text": "4   The Distributionally Robust Metric ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce the Distributionally Robust Metric (DRM) for CATE estimator selection. First, we capture the uncertainty in PEHE in a distributionally robust manner (Section 4.1). We then establish the DRM based on the distributionally robust value of PEHE (Section 4.2). ", "page_idx": 3}, {"type": "text", "text": "4.1  Capturing the Uncertainty in PEHE ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Proposition 4.1. The PEHE w.rt. the CATE estimator $\\hat{\\tau}$ can be decomposed as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[(\\hat{\\tau}(X)-\\tau_{t r u e}(X))^{2}]=\\mathbb{E}[\\hat{\\tau}(X)^{2}]+2\\mathbb{E}[\\hat{\\tau}(X)Y^{0}]+2\\mathbb{E}[-\\hat{\\tau}(X)Y^{1}]+\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\zeta=\\mathbb{E}[(\\mu_{1}(X)-\\mu_{0}(X))^{2}]$ . The proof is deferred to Appendix B.1. ", "page_idx": 3}, {"type": "text", "text": "Proposition 4.1 indicates that the PEHE is equal to four terms, where $\\mathbb{E}[\\hat{\\tau}(X)^{2}]$ \uff0c $\\mathbb{E}[\\hat{\\tau}(X)Y^{0}]$ , and $\\mathbb{E}[-\\hat{\\tau}(X)Y^{1}]$ depend on $\\hat{\\tau}$ , while $\\zeta$ is a constant that is independent of $\\hat{\\tau}$ . The term $\\mathbb{E}[\\hat{\\tau}(X)Y^{t}]$ for $t\\in\\{0,1\\}$ can be further decomposed as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\hat{\\tau}(X)Y^{t}]=\\underbrace{\\mathbb{E}[\\hat{\\tau}(X)Y^{t}|T=t]}_{\\mathrm{(a)~Empirically~computable}}P(T=t)+\\underbrace{\\mathbb{E}[\\hat{\\tau}(X)Y^{t}|T=1-t]}_{\\mathrm{(b)~Empirically~uncomputable}}P(T=1-t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Equation (6a) can be computed empirically since the potential outcome $Y^{t}$ is observable in the group of $T=t$ . However, equation (6b) is empirically uncomputable due to the unavailability of $Y^{t}$ in the group of $T=1-t$ . The unknown term $\\mathbb{E}[\\hat{\\tau}(\\bar{X})Y^{t}|T=1-t]$ therefore determines the uncertainty in PEHE. To capture such an uncertainty, we therefore establish distributionally robust values for $\\mathbb{E}[\\hat{\\tau}(X)Y^{0}|T=1]$ and $\\mathbb{E}[-\\hat{\\tau}(X)Y^{1}|T\\stackrel{>}{=}0]$ based on a Kullback-Leibler (KL) ambiguity set. ", "page_idx": 3}, {"type": "text", "text": "Definition 4.2 (KL ambiguity set). Given two distributions $Q$ and $P$ and the ambiguity radius $\\epsilon>0$ The KL ambiguity (uncertainty) set $B_{\\epsilon}(P)$ is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{B}_{\\epsilon}(P):=\\{Q:D_{K L}(Q||P)\\leq\\epsilon\\},\\quad\\mathrm{where~}D_{K L}(Q||P)=\\int_{\\mathcal{X}}q(x)\\log\\frac{q(x)}{p(x)}d x.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, $D_{K L}(Q||P)$ denotes the KL divergence of some arbitrary distribution $Q$ from the reference distribution $P$ . Now we define the distribution of $(X,Y^{0},Y^{1})$ in the treated and controlled groups as ", "page_idx": 4}, {"type": "equation", "text": "$$\nP_{T}:=P(X,Y^{0},Y^{1}|T=1);\\;P_{C}:=P(X,Y^{0},Y^{1}|T=0).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "By setting an adequately large ambiguity radius in Definition 4.2, the following inequalities hold for $\\mathbb{E}\\bar{[}\\hat{\\tau}(X)\\bar{Y^{0}}|T=\\hat{1]}=\\check{\\mathbb{E}}^{P_{T}}[\\bar{\\hat{\\tau}}(X)Y^{0}]$ and $\\mathbb{E}[-\\hat{\\tau}(X)Y^{1}|T=0]=\\mathbb{E}^{P_{C}}[-\\hat{\\tau}(X)\\bar{Y}^{1}]$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\hat{\\tau}(X)Y^{0}|T=1]=\\mathbb{E}^{P_{T}}[\\hat{\\tau}(X)Y^{0}]\\leq\\underset{Q\\in B_{\\epsilon_{0}}(P_{C})}{\\operatorname*{sup}}\\mathbb{E}^{Q}[\\hat{\\tau}(X)Y^{0}]=:\\mathcal{V}^{0}(\\hat{\\tau});}\\\\ {\\mathbb{E}[-\\hat{\\tau}(X)Y^{1}|T=0]=\\mathbb{E}^{P_{C}}[-\\hat{\\tau}(X)Y^{1}]\\leq\\underset{Q\\in B_{\\epsilon_{1}}(P_{T})}{\\operatorname*{sup}}\\mathbb{E}^{Q}[-\\hat{\\tau}(X)Y^{1}]=:\\mathcal{V}^{1}(\\hat{\\tau}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To provide a clearer understanding, let us consider the example of $\\mathbb{E}^{P_{T}}[\\hat{\\tau}(X)Y^{0}]$ . Since the term $\\mathbb{E}[\\bar{\\hat{\\tau}}(X)Y^{0}]$ is computable on its factual distribution $P_{C}$ but uncomputable on its counterfactual distribution $P_{T}$ , we can construct an ambiguity set centered around the distribution $P_{C}$ such that it is large enough to contain the distribution $P_{T}$ . By doing so, we can capture the uncertainty of $\\mathbb{E}^{P_{T}}[\\hat{\\tau}(\\bar{X})Y^{0}]$ w.r.t. $\\hat{\\tau}$ . In other words,the value of the uncomputable quantity $\\mathbb{E}^{P_{T}}[\\hat{\\tau}(X)Y^{0}]$ will be at most $\\mathcal{\\hat{V}}^{0}(\\hat{\\tau})$ . Similarly, the value of the uncomputable quantity $\\mathbb{E}^{\\hat{P_{C}}}[-\\hat{\\tau}(X)Y^{1}]$ will be at most $\\mathcal{V}^{1}(\\hat{\\tau})$ . Obviously, the uncertainty in PEHE will be larger if the distribution shift between factual and counterfactual distribution is severer. Consequently, we can obtain the distributionally robust value of PEHE in Corollary 4.3, which measures the uncertainty in PEHE. ", "page_idx": 4}, {"type": "text", "text": "Corollary 4.3. Let $\\mathcal{V}^{0}(\\hat{\\tau})$ and $\\mathcal{V}^{1}(\\hat{\\tau})$ be the quantities defined in equation (9), $\\zeta$ be the constant given in Proposition 4.1, $u_{1}:=P(T=1)$ ,and $u_{0}=1-u_{1}=P(T=0)$ .The distributionally robust value of PEHE w.r.t. $\\hat{\\tau}$ is defined as $\\mathcal{\\ V}_{P E H E}(\\hat{\\tau})$ such that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[(\\hat{\\tau}(X)-\\tau_{t r u e}(X))^{2}]\\leq\\mathcal{V}_{P E H E}(\\hat{\\tau})}\\\\ &{\\ =\\mathbb{E}[\\hat{\\tau}(X)^{2}]+2\\left(u_{0}\\mathbb{E}^{P_{C}}[\\hat{\\tau}(X)Y^{0}]+u_{1}\\mathbb{E}^{P_{T}}[-\\hat{\\tau}(X)Y^{1}]\\right)+2\\left(u_{0}\\mathcal{V}^{1}(\\hat{\\tau})+u_{1}\\mathcal{V}^{0}(\\hat{\\tau})\\right)+\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "4.2  Establishing Distributionally Robust Metric ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "As Corollary 4.3 provides the distributionally robust (worst-case) value of PEHE, it can naturally measure the robustness of the CATE estimator $\\hat{\\tau}$ against distribution shift between counterfactual distribution and factual distribution. In this section, we will provide two steps involved in using Corollary 4.3 to construct the DRM method for CATE estimator selection. ", "page_idx": 4}, {"type": "text", "text": "Step 1: Establishing computational tractability of $\\gamma^{t}(\\hat{\\tau})$ .The distributionally robust values $\\mathcal{V}^{0}\\bar{(\\tau})$ and $\\mathcal{V}^{1}(\\hat{\\tau})$ in equation (10) are initially defined as supremum problems over infinite support, presenting a substantial computational challenge. Theorem 4.4 reformulates the infeasible supremum problems into tractable minimum problems. ", "page_idx": 4}, {"type": "text", "text": "Theorem 4.4. The distributionally robust values $\\mathcal{V}^{0}(\\hat{\\tau})$ and $\\mathcal{V}^{1}(\\hat{\\tau})$ in equation (9) are equivalent to ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{V}^{0}(\\hat{\\tau})=\\underset{\\lambda_{0}>0}{\\mathrm{min}}\\,\\lambda_{0}\\epsilon_{0}+\\lambda_{0}\\log\\mathbb{E}^{P_{C}}[\\exp(\\hat{\\tau}(X)Y^{0}/\\lambda_{0})];}\\\\ &{\\mathcal{V}^{1}(\\hat{\\tau})=\\underset{\\lambda_{1}>0}{\\mathrm{min}}\\,\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log\\mathbb{E}^{P_{T}}[\\exp(-\\hat{\\tau}(X)Y^{1}/\\lambda_{1})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The proof is deferred to Appendix B.3. ", "page_idx": 4}, {"type": "text", "text": "In the finite-sample scenario, $\\mathcal{V}^{0}(\\hat{\\tau})$ and $\\mathcal{V}^{1}(\\hat{\\tau})$ can be empirically approximated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\mathcal{V}}^{0}(\\hat{\\tau})=\\displaystyle\\operatorname*{min}_{\\lambda_{0}>0}\\lambda_{0}\\epsilon_{0}+\\lambda_{0}\\log\\displaystyle\\frac{1}{n_{c}}\\sum_{i=1}^{n}(1-T_{i})\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{0});}\\\\ &{\\hat{\\mathcal{V}}^{1}(\\hat{\\tau})=\\displaystyle\\operatorname*{min}_{\\lambda_{1}>0}\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log\\displaystyle\\frac{1}{n_{t}}\\sum_{i=1}^{n}T_{i}\\exp(-\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Using DRM for CATE Estimator Selection ", "page_idx": 5}, {"type": "text", "text": "Input: The candidate CATE estimators $\\{\\hat{\\tau}_{1},\\dotsc,\\hat{\\tau}_{J}\\}$ . The validation dataset with $n$ i.i.d. observational samples $\\{(X_{i},T_{i},Y_{i})\\}_{i=1}^{n}$ . The number of iterations $K$ The initialization $\\lambda_{0}^{(0)}$ and $\\lambda_{1}^{(0)}$ The ambiguity radius $\\epsilon_{0}$ and $\\epsilon_{1}$ ", "page_idx": 5}, {"type": "text", "text": "1: for $j=1$ to $J$ do 2: for $k=0$ to $K-1$ do 3: Compute $\\hat{F}_{t}(\\lambda_{t}^{(k)},\\epsilon_{t};\\hat{\\tau}_{j})$ for $t\\in\\{0,1\\}$ by equatio (14a). 4: Compute $\\partial\\hat{F}_{t}(\\lambda_{t}^{(k)},\\epsilon_{t};\\hat{\\tau}_{j})/\\partial\\lambda_{t}^{(k)}$ for $t\\in\\{0,1\\}$ by equation (14b). $\\lambda_{t}^{(k+1)}\\gets\\operatorname*{max}\\{\\lambda_{t}^{(k)}-\\hat{F}_{t}(\\lambda_{t}^{(k)},\\epsilon_{t};\\hat{\\tau}_{j})/(\\partial\\hat{F}_{t}(\\lambda_{t}^{(k)},\\epsilon_{t};\\hat{\\tau}_{j})/\\partial\\lambda_{t}^{(k)}),0\\}$ $t\\in\\{0,1\\}$ 6: Save $\\hat{\\mathcal{V}}^{t}(\\hat{\\tau}_{j})[k]=\\hat{F}_{t}(\\lambda_{t}^{(k+1)},\\epsilon_{t};\\hat{\\tau}_{j})$ for $t\\in\\{0,1\\}$ 7: Return $\\begin{array}{r}{\\hat{\\mathcal{V}}^{t}(\\hat{\\tau}_{j})=\\arg\\operatorname*{min}_{k\\in\\{0,\\dots,K-1\\}}\\hat{\\mathcal{V}}^{t}(\\hat{\\tau}_{j})[k]}\\end{array}$ for $t\\in\\{0,1\\}$ 8: Use $\\hat{\\mathcal{V}}^{0}(\\hat{\\tau}_{j})$ and $\\hat{\\mathcal{V}}^{1}(\\hat{\\tau}_{j})$ to compute $\\mathcal{R}^{D R M}(\\hat{\\tau}_{j})$ by equation (15). Output: $\\begin{array}{r}{\\hat{\\tau}_{s e l e c t}=\\arg\\operatorname*{min}_{\\hat{\\tau}\\in\\{\\hat{\\tau}_{1},\\dots,\\hat{\\tau}_{J}\\}}\\mathcal{R}^{D R M}(\\hat{\\tau})}\\end{array}$ ", "page_idx": 5}, {"type": "text", "text": "Note that in equation (12), the potential outcomes $Y^{0}$ and $Y^{1}$ are replaced by the observed outcome $Y$ due to the fact that $(1-T)\\bar{Y}^{0}=(1-T)Y$ and $T Y^{1}=T Y$ , which aligns with the Consistency assumption in Assumption 2.1. We then provide a finite-sample analysis of the gap between $\\hat{\\mathcal{V}}^{t}(\\hat{\\tau})$ and $\\gamma^{t}(\\hat{\\tau})$ in the following Theorem 4.5, which suggests the gap decays at a rate of $n^{-1/2}$ ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.5.Let $u_{t}:=P(T=t)$ for $t\\,\\in\\,\\{0,1\\}$ .Assume $0\\,<\\,\\lambda\\,\\leq\\,\\lambda_{0},\\lambda_{1}\\,\\leq\\,\\bar{\\lambda}$ and $\\hat{\\tau}(X)Y$ isboundedwithintherange of $M$ to $\\bar{M}$ Define $C_{e x p}\\;=\\;{\\bf1}_{\\{\\underline{{M}}\\leq\\bar{M}\\leq0\\}}\\exp\\left(\\bar{M}/\\bar{\\lambda}-{\\underline{{M}}}/{\\underline{{\\lambda}}}\\right)\\;+$ $\\mathbf{1}_{\\{\\underline{{M}}\\leq0,\\bar{M}\\geq0\\}}\\exp\\left(\\bar{M}/\\underline{{\\lambda}}-\\underline{{M}}/\\underline{{\\lambda}}\\right)+\\mathbf{1}_{\\{0\\leq\\underline{{M}}\\leq\\bar{M}\\}}\\exp\\left(\\bar{M}/\\underline{{\\lambda}}-\\underline{{M}}/\\bar{\\lambda}\\right)$ For $n\\geq2/u^{2}\\log(2/\\delta)$ and $t\\in\\{0,1\\}$ withprobability $1-\\delta$ wehave ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\hat{\\mathcal{V}}^{t}(\\hat{\\tau})-\\mathcal{V}^{t}(\\hat{\\tau})|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n u_{t}^{2}}C_{e x p}^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log\\left(\\frac{2}{\\delta}\\right)}{n u_{t}^{2}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proof is deferred to Appendix B.4. ", "page_idx": 5}, {"type": "text", "text": "Step 2: Finalizing Distributionally Robust Metric for CATE estimator selection.  We first define two functions that are useful in obtaining $\\mathcal{V}^{0}(\\hat{\\tau})$ and $\\mathcal{V}^{1}\\big(\\hat{\\tau}\\big)$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{F}_{0}(\\lambda_{0},\\epsilon_{0};\\hat{\\tau})=\\lambda_{0}\\epsilon_{0}+\\lambda_{0}\\log\\frac{1}{n_{c}}\\displaystyle\\sum_{i=1}^{n_{c}}e^{\\frac{z_{i}}{\\lambda_{0}}},\\ \\hat{F}_{1}(\\lambda_{1},\\epsilon_{1};\\hat{\\tau})=\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log\\frac{1}{n_{t}}\\displaystyle\\sum_{i=1}^{n_{t}}e^{\\frac{-z_{i}}{\\lambda_{1}}};}\\\\ &{\\displaystyle\\frac{\\partial\\hat{F}_{0}}{\\partial\\lambda_{0}}=\\epsilon_{0}+\\log\\sum_{i=1}^{n_{c}}\\frac{\\underline{{{z}}}_{i}}{n_{c}}-\\frac{\\sum_{i=1}^{n_{c}}Z_{i}e^{\\frac{z_{i}}{\\lambda_{0}}}}{\\lambda_{0}\\sum_{i=1}^{n_{c}}e^{\\frac{z_{i}}{\\lambda_{0}}}},\\ \\frac{\\partial\\hat{F}_{1}}{\\partial\\lambda_{1}}=\\epsilon_{1}+\\log\\displaystyle\\sum_{i=1}^{n_{t}}\\frac{e^{\\frac{-z_{i}}{\\lambda_{1}}}}{n_{t}}-\\frac{\\sum_{i=1}^{n_{t}}-Z_{i}e^{\\frac{-z_{i}}{\\lambda_{1}}}}{\\lambda_{1}\\sum_{i=1}^{n_{t}}e^{\\frac{-z_{i}}{\\lambda_{1}}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $Z$ denotes $\\hat{\\tau}(X)Y$ for notational simplicity. We then use the Newton-Raphson method to find the empirical solution for $\\hat{\\boldsymbol{\\nu}}^{t}(\\hat{\\boldsymbol{\\tau}})$ , exploiting the convexity of $\\hat{F}_{t}(\\lambda_{t},\\epsilon_{t};\\hat{\\tau})$ w.r.t. $\\lambda_{t}$ . Based on the distributionally robust value of PEHE, i.e., $\\mathcal{\\sum}_{P E H E}(\\hat{\\tau})$ in equation (10), we finally obtain the selected estimator $\\begin{array}{r}{\\hat{\\tau}_{s e l e c t}=\\arg\\operatorname*{min}_{\\hat{\\tau}\\in\\{\\hat{\\tau}_{1},\\dots,\\hat{\\tau}_{J}\\}}\\mathcal{R}^{D R M}(\\hat{\\tau})}\\end{array}$ such that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{R}^{D R M}(\\hat{\\tau})=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\tau}(X_{i})^{2}+\\frac{2}{n}\\left(\\sum_{i=1}^{n_{c}}\\hat{\\tau}(X_{i})Y_{i}+\\sum_{i=1}^{n_{t}}-\\hat{\\tau}(X_{i})Y_{i}+n_{c}\\hat{\\mathcal{V}}^{1}(\\hat{\\tau})+n_{t}\\hat{\\mathcal{V}}^{0}(\\hat{\\tau})\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 provides complete procedure of using the DRM method for CATE estimator selection. ", "page_idx": 5}, {"type": "text", "text": "Discussion on the ambiguity radius $\\epsilon$ . The ambiguity radius $\\epsilon$ plays a critical role in real-world applications [54, 52, 60]. However, determining an appropriate value for $\\epsilon$ can be challenging as it requires striking a balance between ensuring the bound in equation (9) holds and maintaining its tightness. Specifically, if $\\epsilon$ is set too small, it fails to guarantee that the counterfactual distribution is contained within the ambiguity set centered at factual distribution (the bound in Corollary 4.3 can hold). On the other hand, if $\\epsilon$ is set too large, even though the ambiguity set can encompass more distributions to ensure the counterfactual distribution is contained, the bound in Corollary 4.3 can be less tight. In general, selecting a proper ambiguity radius is an open problem in distributioanlly robust optimization (DRO) literature [34, 54, 46, 48, 72]. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "In this paper, we provide a guidance for determining the ambiguity radius for our DRM method. Based on the above discussion, an ideal radius should be $\\epsilon_{1}^{*}=\\bar{D_{K L}}\\dot{(P_{C}||P_{T})}$ and $\\epsilon_{0}^{*}=D_{K L}(P_{T}||P_{C})$ which ensures that the bound in Corollary 4.3 holds and is tight. However, as defined in equation (8), both $P_{C}$ and $P_{T}$ involve counterfactual information, making it unattainable to directly compute $D_{K L}(P_{C}||P_{T})$ and $D_{K L}(P_{T}||P_{C})$ . To overcome this challenge, we demonstrate that Proposition 4.6 provides an intriguing alternative approach to acquire $D_{K L}\\bar{(P_{C}||P_{T})}$ and $D_{K L}(P_{T}||P_{C}^{\\bar{}})$ when unconfoundedness in Assumption 2.1 is satisfied. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.6. Let $P_{X}^{T}:=P(X|T=1)$ and $P_{X}^{C}:=P(X|T=0)$ denote the covariates distribution in the treat and control group,respectively.Assuming that random variables $(X,T,Y^{1},Y^{0})$ satisfy the unconfoundedness in Assumption 2.1, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nD_{K L}(P_{C}||P_{T})=D_{K L}(P_{X}^{C}||P_{X}^{T});\\quad D_{K L}(P_{T}||P_{C})=D_{K L}(P_{X}^{T}||P_{X}^{C}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The proof is deferred to Appendix B.2. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.6 provides an important insight that the uncomputable term $D_{K L}(P_{C}||P_{T})$ (or $D_{K L}(P_{T}||P_{C}))$ can be replaced by a computable quantity $D_{K L}(P_{X}^{C}||P_{X}^{T})$ (or $D_{K L}(P_{X}^{T}||P_{X}^{C}))$ where $P_{X}^{C}$ and $P_{X}^{T}$ are empirically bservableConsequently, the ideal ambiguity radius can be set as $\\epsilon_{1}^{*}=D_{K L}(P_{X}^{C}||P_{X}^{T})$ and $\\epsilon_{0}^{*}=D_{K L}(P_{X}^{T}||P_{X}^{C})$ While the KL divergence can be approximated using empirical algorithm (e.g, Nearest-Neighbor [73, 57]), we recommend setting the ambiguity radius larger than the empirically approximated KL divergence (see specific explanations in Appendix C.1). This is necessary because it ensures that the ambiguity set is large enough to contain the target distribution. It is also important to note that though the Algorithm 1 involves approximating $\\epsilon_{1}^{*}\\stackrel{=}{=}D_{K L}(P_{X}^{C}||P_{X}^{T})$ and $\\epsilon_{0}^{*}=D_{K L}(P_{X}^{T}||P_{X}^{C})$ , the DRM itself remains free of nuisances, as this approach only determines the ambiguity radius but does not involve learning any nuisance function such as the outcome function, propensity function, and plug-in learner. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1  Experimental Setup. ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Estimators & Selectors. We consider a total of 36 CATE estimators, comprising the combination of 4 base ML models and 9 meta-learners. Specifically, the base ML models are Linear Regression (LR), Support Vector Machine (SVM), Random Forests (RF), and Neural Net (Net). We consider these ML models for CATE estimators because they are representative of both rigid and flexible models, with each encoded distinct inductive biases, as highlighted by [19, 20]. Note that for the LR method, we employ Ridge regression for regression tasks and Logistic regression for classification tasks. As for the remaining methods, we utilize their corresponding regressors and classifiers for regression and classification tasks, respectively. Regarding the meta-learners, we select a set of both traditional basic learners (S-, T-, PS-, and IPW-learners) and recently developed learners (X-, DR-, U-, R-, and RA-learners), as detailed in Appendix A.1. We consider 14 CATE selectors, consisting of 9 plug-in methods that rely on the above 9 learners, 3 pseudo-outcome methods (pseudo-DR, -R, and -IF), the random selection, the factual selection (from the 6-learner pool with S-, T-), the NearestNeighbor Matching [62], and our proposed DRM. The specific details of baseline selectors are stated in Appendix A.2. We employ the eXtreme Gradient Boosting (XGB) [12] as the underlying ML model for both plug-in and pseudo-outcome methods. We choose XGB because: i) it demonstrates superior performance in various scenarios, ensuring a good performance of baseline selectors; i) the need to avoid potential congeniality bias that may arise from using the similar ML models employed in CATE estimators [20]; ii) aligning with [5] where XGB is used for their proposed pseudo-IF metric. The details of hyperparameters for nuisance models are stated in Section C.2 of Appendix. ", "page_idx": 6}, {"type": "text", "text": "Dataset. Since the ground truth of CATE is unavailable in real-world data, previous studies commonly utilize semi-synthetic datasets to compare model performance. In line with [19, 20], we collect the covariates with $n=4802$ data points from ACIC2016 dataset [22]. Then, we generate treatmentwith $T_{i}|X_{i}\\sim B e r n(1/(1+\\exp(-\\xi(\\beta_{T}^{\\prime}X_{i}+3))))$ ),where $B e r n$ indicates theBernoulli ", "page_idx": 6}, {"type": "text", "text": "Table 1: Comparison of Regret for different selectors across Settings A, B, and C (Note that B $(\\xi=1)$ matchesA $(\\rho=0.1)$ ). Reported values (mean $\\pm$ standard deviation) are computed over 100 experiments. Bold denotes the best three results among all selectors. Smaller value is better. ", "page_idx": 7}, {"type": "table", "img_path": "k4EP46Q9X2/tmp/a70a36c4beae3b6ae9e257fdeaff3a31894a8980b729cf443bc1a91d566260a3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "distribution. The potential outcomes are generated by a linear function with interaction terms: ", "page_idx": 7}, {"type": "equation", "text": "$$\nY_{i}=\\sum_{j}^{d}\\beta_{j}^{\\prime}X_{i;j}+\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\beta_{j,k}^{\\prime}X_{i;j}X_{i;k}+\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\sum_{l=k}^{d}\\beta_{j,k,l}^{\\prime}X_{i;j}X_{i;k}X_{i;l}+T_{i}\\sum_{j=1}^{d}\\gamma_{j}X_{i;j}+\\epsilon_{i}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The coeficient values are set as follows: $\\beta_{T},\\beta_{j},\\beta_{j,k},\\beta_{j,k,l}\\,\\sim\\,B e r n(0.2)$ $\\gamma_{j}\\,\\sim\\,B e r n(\\rho)$ , and $\\epsilon_{i}\\sim\\mathcal{N}(0,0.1)$ . The parameter $\\xi$ in treatment assignment represents the level of selection bias, and theparameter $\\rho$ in $\\gamma_{j}$ represents the complexity of the CATE function. We adopt the above data generating process to randomly generate 100 datasets, each with a training/validation/testing ratio of $49\\%/21\\%/30\\%$ ", "page_idx": 7}, {"type": "text", "text": "Settings. In this section, we mainly investigate whether the estimator selected by DRM can demonstrate robustness to the selection bias and unobserved confounders. In addition, as demonstrated in [19, 20], the complexity of CATE function also affects relative performance of estimators and selectors. Given these considerations, we design the following three settings to compare the CATE selectors. Setting A: With the unconfoundedness assumption, let $\\rho$ vary in $\\{0,0.1,0.3\\}$ with fixing $\\xi=1$ . Setting B: With the unconfoundedness assumption, let $\\xi$ vary in $\\{0,1,2\\}$ with fixing $\\rho=0.1$ ", "page_idx": 7}, {"type": "text", "text": "Setting C: Without unconfoundedness assumption, fix $\\rho=0.1$ and $\\xi=1$ . Then randomly remove $\\lfloor m\\cdot d\\rfloor$ covariates such that the dimension of observed covariates is $d-\\lfloor m\\cdot d\\rfloor$ , where $m$ denotes the ratio of missing covariates varying in $\\{0.1,0.5,0.9\\}$ . All the experiments are run on Dell 3640 with Intel Xeon W-1290P 3.60GHz CPU. ", "page_idx": 7}, {"type": "text", "text": "Comparison criteria. The CATE estimator $\\hat{\\tau}$ is believed better if it achieves a smaller difference between $\\mathcal{R}^{o r a c l e}(\\hat{\\tau})$ and $\\mathcal{R}^{o r a c l e}(\\hat{\\tau}_{b e s t})$ ,where $\\hat{\\tau}_{b e s t}$ is the actual best estimator in equation (3). We therefore use the following Regret criteria to compare estimators chosen by different selectors: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Regret}=\\mathcal{R}^{o r a c l e}(\\hat{\\tau}_{s e l e c t})-\\mathcal{R}^{o r a c l e}(\\hat{\\tau}_{b e s t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "To further assess the ranking ability of each selector, we calculate the Spearman rank correlation between the rank order determined by the oracle metric $\\mathcal{R}^{o r a c l e}(\\hat{\\tau})$ and the rank order determined by each selector. All the reported values (Mean $\\pm$ Standard deviation) are computed over 100 runs. ", "page_idx": 7}, {"type": "text", "text": "5.2  Experimental Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Regret comparison. The results presented in Table 1 demonstrate consistently good performance from the DRM selector across various settings. In setting A, the DRM selector outperforms other selectors as the CATE complexity $(\\rho)$ varies. Additionally, Plug-R, Plug-S, and Plug-PS also perform well in terms of the Regret criterion, which aligns with prior findings in [66] that the R-objective is excellent in many cases. Note that the strong performance of Plug-S and Plug-PS may be due to less pronounced heterogeneity in the CATE function compared to the outcome function in the data generating process. We also compare the PEHE performance (i.e., $\\mathcal{R}^{o r a c l e}(\\hat{\\tau}_{s e l e c t}))$ of different selectors in Table 3 of Section C.3. The results indicate that Plug-R, Plug-S, and Plug-PS tend to ", "page_idx": 7}, {"type": "table", "img_path": "k4EP46Q9X2/tmp/a1669ae04570028ef8c6df4aca59adc55c449115245ebf7e1d6ef45a6b93bcdd.jpg", "table_caption": ["Table 2: Comparison of rank correlation for different selectors across Settings A, B, and C (Note that B $(\\xi=1)$ )matchesA $(\\rho=0.1)$ ). Bold denotes the best three results among all selectors. Reported values(mean $\\pm$ standard deviation) are computed over 100 experiments. Larger is better. "], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "k4EP46Q9X2/tmp/c90dbf2b7817e40e67d515dafff39cdc3b84edd346fd64341f973e240f429cf3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 1: The stacked bar chart showing the distribution of the selected estimator's rank for each evaluation metric across rank intervals: [1-3], [4-11], [12-19], [20-27], and [28-36]. The greener (or redder) color indicates that the selected estimator ranks higher (or lower). For example, the dark red (or green) indicates the percentage of cases (out of 100 experiments) where the selected estimator ranks among the worst 9 estimators, specifically as ranks 28, 29, .., or 36 (or among the best 3 estimators, specifically as ranks 1, 2, or 3). ", "page_idx": 8}, {"type": "text", "text": "exhibit better PEHE as the CATE complexity decreases, aligning with the findings in [20]. In setting B, the DRM selector demonstrates robustness against selection bias (controlled by $\\xi$ compared to many baselines. However, for the case $\\xi=2$ , DRM selects a poor estimator 1 or 2 times out of 100 experiments, as shown in Figure 1. Although this weakens its overall performance, DRM still outperforms many baselines in this scenario. In the scenario $\\xi=0$ where no selection bias is present, the factual selection criterion performs better in this specific setting. In this case, DRM does not demonstrate a significant advantage, as there is no distribution shift caused by selection bias. In setting C where the unconfoundedness assumption is violated, most selectors exhibit inferior performance. In contrast, DRM demonstrates consistent outperformance across all three cases, and its superiority becomes particularly significant as $m$ increases to 0.9, showcasing its robustness against the distribution shift arising from unobserved confounders. ", "page_idx": 8}, {"type": "text", "text": "Ranking ability. In Table 2, the DRM method demonstrates favorable performance in ranking estimators, surpassing certain Plug- (e.g., U, T, IPW, DR, RA) and Pseudo- (e.g., DR, IF) selectors. ", "page_idx": 8}, {"type": "text", "text": "In comparison to other nuisance-free baselines (Random, Fact, and Matching), DRM achieves significantly superior ranking ability. However, compared to Plug-S, -PS, -X, and -R, it does not exhibit remarkable performance in ranking CATE estimators, possibly due to the fact that DRM selects estimators based on their distributionally robust (worst-case) performance. Indeed, the definition of ranking inherently involves the concept of expected (average) performance, which is not determined solely by either the best or worst performance. While distributionally robust performance serves as a suitable criterion for selecting players to participate in the Olympics, it may not be a reasonable standard for ranking players? average performance. Therefore, it would be intriguing to explore some ways in future research that can enhance the ranking ability of our DRM selector. ", "page_idx": 9}, {"type": "text", "text": "Variance analysis.  Table 1 indicates that baseline selectors tend to exhibit higher variances in Regret performance. This is primarily due to the wide range of PEHE performances across the 36 CATE estimators. If a selector consistently selects either good or bad estimators, the variance would not be very large. To investigate this further, we sorted all 36 estimators in ascending order based on their $\\mathcal{\\dot{R}}^{o r a c\\breve{l}e}(\\hat{\\tau})$ values, resulting in the sorted list: $[\\mathcal{R}^{o r a c l e}(\\hat{\\tau}_{1}),\\dots,\\mathcal{R}^{o r a c l e}(\\hat{\\tau_{J}})]$ .Wethen determine the actual rank of the selected estimator within this list and visualize the distribution of these 100 ranks using a stacked bar chart. Figure 1 shows that many baseline methods tend to select CATE estimators from various percentile ranges, leading to high variance across the 100 selections. Notably, the DRM selector consistently chooses higher-ranked (i.e., better performing in PEHE) estimators, demonstrating its robustness in CATE estimator selection. ", "page_idx": 9}, {"type": "text", "text": "Potential improvements.  There are several potential improvements based on the current experimental settings. First, the existing results suggest that Plug-S performs better than Plug-T, indicating that the complexity of CATE function is relatively simple. It would help to provide more comprehensive analysis if investigating how DRM compares to baselines when the CATE function is more complex. Second, since the impact of selection bias can vary with sample size [3], it is important to compare different selectors when the sample size is sufficiently large. Third, considering baselines that are specifically designed for addressing hidden confounders could provide valuable insights for testing different selectors under such conditions. We encourage deeper investigation of causal model selection without assuming unconfoundedness. Finally, it would be good if future studies will apply DRM and other selectors in Healthcare, Economics, and Business applications with real-world data, as CATE estimator selection plays an important role in personalized decision makings. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper sheds lights on the potential of robustness in CATE estimator selection. We propose a distributionally robust metric (DRM). The proposed metric is nuisance-free, eliminating the need to fit models for nuisance parameters (outcome function, propensity function, and plug-in learner). Additionally, it is well-targeted for selecting a robust CATE estimator. We provide a finite sample analysis that demonstrates the gap between $\\bar{\\dot{\\gamma}^{t}}(\\hat{\\tau})$ and $\\gamma^{t}(\\hat{\\tau})$ reduces at a rate of $n^{-1/2}$ for $t\\in\\{0,1\\}$ The experimental results showcase that the CATE estimator selected by DRM demonstrate robustness to the distribution shift incurred by covariate shift and hidden confounders. ", "page_idx": 9}, {"type": "text", "text": "Limitations and future work. This paper explores the potential of robustness in CATE estimator selection. However, we must acknowledge that our DRM method is not a silver bullet, as consistent estimation on the CATE are never attainable [14]. Here, we outline some challenges and suggest future research directions. First, while Proposition 4.6 provides useful guidance for setting ambiguity radius in the DRM algorithm, we cannot guarantee that the empirically-computed radius is optimal due to potential bias in the algorithm's approximation of KL-divergence. Second, as discussed in Section 5.2, enhancing the ranking capability of DRM is a promising area for further research. Moreover, our findings are based on KL-divergence. However, using other divergences, such as the Wasserstein distance, to construct the ambiguity set could incorporate more diverse distributions, despite the challenges in solving the dual formulation of the Wasserstein distributionally robust value. Simultaneously, exploring whether alternative divergences can yield a tighter bound for the PEHE error is also interesting [4]. Finally, inspired by [16], understanding how nuisance parameters influence metrics like plug-DR and pseudo-DR might be helpful in CATE estimator selection. We hope our methods and findings will spur interest in model selection for causal inference, as well as in related fields like domain adaptation and out-of-distribution generalization. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Qi WU acknowledges the support from The CityU-JD Digits Joint Laboratory in Financial Technology and Engineering, The Hong Kong Research Grants Council [General Research Fund 11219420/9043008], and The CityU APRC Grant 9610643. The work described in this paper was partially supported by the InnoHK initiative, the Government of the HKSAR, and the Laboratory for AI-Powered Financial Technologies. We finally thank all the anonymous reviewers for their constructivesuggestions. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  Alberto Abadie, Susan Athey, Guido W Imbens, and Jeffrey M Wooldridge. When should you adjust standard errors for clustering? The Quarterly Journal of Economics, 138(1):1-35, 2023. [2]  Arun Advani, Toru Kitagawa, and Tymon Sloczynski. Mostly harmless simulations? using monte carlo studies for estimator selection. Journal of Applied Econometrics, 34(6):893-910, 2019. [3]  Ahmed Alaa and Mihaela Schaar. Limits of estimating heterogeneous treatment effects: Guidelines for practical algorithm design. In International Conference on Machine Learning, pages 129-138. PMLR, 2018. [4]  Ahmed Alaa and Mihaela van der Schaar. Limits of estimating heterogeneous treatment effects: Guidelines for practical algorithm design. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 129-138. PMLR, 10-15 Jul 2018. [5]  Ahmed Alaa and Mihaela Van Der Schaar. Validating causal inference models via influence functions. In International Conference on Machine Learning, pages 191-201. PMLR, 2019. [6] Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo Henao, Fan Li, and Lawrence Carin. Counterfactual representation learning with balancing weights. In International Conference on Artijficial Intelligence and Statistics, pages 1972-1980. PMLR, 2021. [7] Susan Athey, Guido W Imbens, Jonas Metzger, and Evan Munro. Using wasserstein generative adversarial networks for the design of monte carlo simulations. Journal of Econometrics, 2021. [8] SUSAN ATHEY, JULIE TIBSHIRANI, and STEFAN WAGER. Generalized random forests. The Annals of Statistics, 47(2):1148-1178, 2019. [9] Ioana Bica, Ahmed M Alaa, Craig Lambert, and Mihaela Van Der Schaar. From real-world patient data to individualized treatment effects using machine learning: current and future methods to address underlying challenges. Clinical Pharmacology & Therapeutics, 109(1):87- 100, 2021.   \n[10] Ioana Bica and Mihaela van der Schaar. Transfer learning on heterogeneous feature spaces for treatment effects estimation. Advances in Neural Information Processing Systems, 35:37184 37198, 2022.   \n[11] L\u00e9on Bottou, Jonas Peters, Joaquin Quinonero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. Counterfactual reasoning and learning systems: The example of computational advertising. Journal of Machine Learning Research, 14(11), 2013.   \n[12]  Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785-794, 2016.   \n[13] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters, 2018.   \n[14] Victor Chernozhukov, Mert Demirer, Esther Duflo, and Ivan Fernandez-Val. Generic machine learning inference on heterogeneous treatment effects in randomized experiments, with an application to immunization in india. Technical report, National Bureau of Economic Research, 2018.   \n[15] Zhixuan Chu, Stephen L Rathbun, and Sheng Li. Graph infomax adversarial learning for treatment effect estimation with networked observational data. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 176-184, 2021.   \n[16]  Yifan Cui and EJ Tchetgen Tchetgen. Selective machine learning of doubly robust functionals. Biometrika, 111(2):517-535, 2024.   \n[17] Alicia Curth, David Svensson, Jim Weatherall and Mihaela van der Schaar. Really doing great at estimating cate? a critical look at ml benchmarking practices in treatment effect estimation. In Thirty-fth conference on neural information processing systems datasets and benchmarks track (round 2), 2021.   \n[18]  Alicia Curth and Mihaela van der Schaar. Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms. In International Conference on Artificial Intelligence and Statistics, pages 1810-1818. PMLR, 2021.   \n[19] Alicia Curth and Mihaela van der Schar. On inductive biases for heterogeneous treatment effect estimation. Advances in Neural Information Processing Systems, 34:15883-15894, 2021.   \n[20]  Alicia Curth and Mihaela Van Der Schaar. In search of insights, not magic bullets: Towards demystification of the model selection dilemma in heterogeneous treatment effect estimation. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 6623-6642. PMLR, 23-29 Jul 2023.   \n[21] Robert Donnelly, David Blei, Susan Athey, et al. Correction to: Counterfactual inference for consumer choice across many product categories. Quantitative Marketing and Economics, 19(3-4):409-409, 2021.   \n[22] Vincent Dorie, Jennifer Hill, Uri Shalit, Marc Scott, and Dan Cervone. Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition. Statistical Science, 34(1):43-68, 2019.   \n[23]  Max H Farrell. Robust inference on average treatment effects with possibly more covariates than observations. Journal of Econometrics, 189(1):1-23, 2015.   \n[24] Carlos Fernandez-Loria, Foster Provost, Jesse Anderton, Benjamin Carterette, and Praveen Chandar. A comparison of methods for treatment assignment with an application to playlist generation. Information Systems Research, 34(2):786-803, 2023.   \n[25]  Aaron Fisher. Inverse-variance weighting for estimation of heterogeneous treatment effects. In Forty-first International Conference on Machine Learning.   \n[26]  Dylan J Foster and Vasilis Syrgkanis. Orthogonal statistical learning. The Annals of Statistics, 51(3):879-908, 2023.   \n[27] Jared C Foster, Jeremy MG Taylor, and Stephen J Ruberg. Subgroup identification from randomized clinical trial data. Statistics in medicine, 30(24):2867-2880, 2011.   \n[28] Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. A survey of learning causality with data: Problems and methods. ACM Computing Surveys (CSUR), 53(4):1-37, 2020.   \n[29]  Ruocheng Guo, Jundong Li, Yichuan Li, K Selcuk Candan, Adrienne Raglin, and Huan Liu. Ignite: A minimax game toward learning individual treatment effects from networked observational data. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Arificial Intelligence, pages 4534-4540, 2021.   \n[30] P Richard Hahn, Jared S Murray, and Carlos M Carvalho. Bayesian regression tree models for causal inference: Regularization, confounding, and heterogeneous effects (with discussion). Bayesian Analysis, 15(3):965-1056, 2020.   \n[31]  Negar Hassanpour and Russell Greiner. Learning disentangled representations for counterfactual regression. In International Conference on Learning Representations, 2019.   \n[32]  Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics, 20(1):217-240, 2011.   \n[33]  Paul W Holland. Statistics and causal inference. Journal of the American statistical Association, 81(396):945-960, 1986.   \n[34]  Zhaolin Hu and L Jeff Hong. Kullback-leibler divergence constrained distributionally robust optimization. Available at Optimization Online, 1(2):9, 2013.   \n[35]  Yiyan Huang, Cheuk Hang Leung, Shumin Ma, Zhiri Yuan, Qi Wu, Siyi Wang, Dongdong Wang, and Zhixiang Huang. Towards balanced representation learning for credit policy evaluation. In International Conference on Artijficial Intelligence and Statistics, pages 3677-3692. PMLR, 2023.   \n[36] Yiyan Huang, Cheuk Hang Leung, Qi Wu, Xing Yan, Shumin Ma, Zhiri Yuan, Dongdong Wang, and Zhixiang Huang. Robust causal learning for the estimation of average treatment effects. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1-9. IEEE, 2022.   \n[37] Yiyan Huang, Cheuk Hang Leung, Xing Yan, Qi Wu, Nanbo Peng, Dongdong Wang, and Zhixiang Huang. The causal learning of retail delinquency. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 35, pages 204-212, 2021.   \n[38] Yiyan Huang, WANG Siyi, Cheuk Hang Leung, WU Qi, WANG Dongdong, and Zhixiang Huang. Dignet: Learning decomposed patterns in representation balancing for treatment effect estimation. Transactions on Machine Learning Research, 2024.   \n[39]  Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual inference. In International conference on machine learning, pages 3020-3029. PMLR, 2016.   \n[40] Fredrik D Johansson, Uri Shalit, Nathan Kallus, and David Sontag. Generalization bounds and representation learning for estimation of potential outcomes and causal effects. The Journal of Machine Learning Research, 23(1):7489-7538, 2022.   \n[41]  Edward H Kennedy. Towards optimal doubly robust estimation of heterogeneous causal effects. Electronic Journal of Statistics, 17(2):3008-3049, 2023.   \n[42] Newton Mwai Kinyanjui and Fredrik D Johansson. Adcb: An alzheimer's disease simulator for benchmarking observational estimators of causal effects. In Conference on Health, Inference, and Learning, pages 103-118. PMLR, 2022.   \n[43]  Toru Kitagawa and Aleksey Tetenov. Who should be treated? empirical welfare maximization methods for treatment choice. Econometrica, 86(2):591-616, 2018.   \n[44] Kun Kuang, Peng Cui, Bo Li, Meng Jiang, Shiqiang Yang, and Fei Wang. Treatment effect estimation with data-driven variable decomposition. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 31, 2017.   \n[45] Kun Kuang, Peng Cui, Hao Zou, Bo Li, Jianrong Tao, Fei Wu, and Shiqiang Yang. Data-driven variable decomposition for treatment effect estimation. IEEE Transactions on Knowledge and Data Engineering, 34(5):2120-2134, 2020.   \n[46] Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh ShafieezadehAbadeh. Wasserstein distributionally robust optimization: Theory and applications in machine learning. In Operations research & management science in the age of analytics, pages 130-166. Informs, 2019.   \n[47] Soren R Kunzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the national academy of sciences, 116(10):4156-4165, 2019.   \n[48] Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. Large-scale methods for distributionally robust optimization. Advances in Neural Information Processing Systems, 33:8847-8860, 2020.   \n[49]  Shuangning Li and Stefan Wager. Random graph asymptotics for treatment effect estimation under network interference. The Annals of Statistics, 50(4):2334-2358, 2022.   \n[50] Yijun Li, Cheuk Hang Leung, Xiangqian Sun, Chaoqun Wang, Yiyan Huang, Xing Yan, Qi Wu, Dongdong Wang, and Zhixiang Huang. The causal impact of credit lines on spending distributions. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 38, pages 180-187, 2024.   \n[51] Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal effect inference with deep latent-variable models. Advances in neural information processing systems, 30, 2017.   \n[52] Shumin Ma, Cheuk Hang Leung, Qi Wu, Wei Liu, and Nanbo Peng. Understanding distributional ambiguity via non-robust chance constraint. In Proceedings of the First ACM International Conference on AI in Finance, pages 1-8, 2020.   \n[53] Divyat Mahajan, Ioannis Mitliagkas, Brady Neal, and Vasilis Syrgkanis. Empirical analysis of model selection for heterogenous causal effect estimation. International Conference on Learning Representations, 2024.   \n[54]  Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven distributionally robust optimization using the wasserstein metric: performance guarantees and tractable reformulations. Mathematical Programming, 171(1-2):115-166, 2018.   \n[55] Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2):299-319, 2021.   \n[56] Ana Rita Nogueira, Andrea Pugnana, Salvatore Ruggieri, Dino Pedrechi, and Joao Gama. Methods and tools for causal discovery and causal inference. Wiley interdisciplinary reviews: data mining and knowledge discovery, 12(2):e1449, 2022.   \n[57]  Yung-Kyun Noh, Masashi Sugiyama, Song Liu, Marthinus C Plessis, Frank Chongwoo Park, and Daniel D Lee. Bias reduction and metric learning for nearest-neighbor estimation of kullback-leibler divergence. In Artificial Intelligence and Statistics, pages 669-677. PMLR, 2014.   \n[58] Miruna Oprescu, Vasilis Syrgkanis, and Zhiwei Steven Wu. Orthogonal random forest for causal inference. In International Conference on Machine Learning, pages 4932-4941. PMLR, 2019.   \n[59] Harsh Parikh, Carlos Varjao, Louise Xu, and Eric Tchetgen Tchetgen. Validating causal inference methods. In International Conference on Machine Learning, pages 17346-17358. PMLR, 2022.   \n[60]  Georg Ch Pfug. Multistage stochastic decision problems: Approximation by recursive structures and ambiguity modeling. European Journal of Operational Research, 306(3):1027-1039, 2023.   \n[61] Zhaozhi Qian, Yao Zhang, Ioana Bica, Angela Wood, and Mihaela van der Schaar. Synctwin: Treatment effect estimation with longitudinal outcomes. Advances in Neural Information Processing Systems, 34:3178-3190, 2021.   \n[62]  Craig A Rolling and Yuhong Yang. Model selection for estimating treatment effects. Journal of the Royal Statistical Society Series B: Statistical Methodology, 76(4):749-769, 2014.   \n[63]  Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1):41-55, 1983.   \n[64] Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469):322-331, 2005.   \n[65]  Yuta Saito and Shota Yasui. Counterfactual cross-validation: Stable model selection procedure for causal inference models. In International Conference on Machine Learning, pages 8398- 8407.PMLR, 2020.   \n[66] Alejandro Schuler, Michael Baiocchi, Robert Tibshirani, and Nigam Shah. A comparison of methods for model selection when estimating individual treatment effects. arXiv preprint arXiv:1804.05146, 2018.   \n[67] Alejandro Schuler, Ken Jung, Robert Tibshirani, Trevor Hastie, and Nigam Shah. Synthvalidation: Selecting the best causal inference method for a given dataset. arXiv preprint arXiv:1711.00083, 2017.   \n[68]  Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: generalization bounds and algorithms. In International conference on machine learning, pages 3076-3085. PMLR, 2017.   \n[69]  Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment effects. Advances in neural information processing systems, 32, 2019.   \n[70]  Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523):1228-1242, 2018.   \n[71] Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu. Flaml: A fast and lightweight automl library. Proceedings of Machine Learning and Systems, 3:434-447, 2021.   \n[72]  Jie Wang, Rui Gao, and Yao Xie. Sinkhorn distributionally robust optimization. arXiv preprint arXiv:2109.11926, 2021.   \n[73]  Qing Wang, Sanjeev R Kulkarni, and Sergio Verdu. A nearest-neighbor approach to estimating divergence between continuous random vectors. In 2006 IEEE International Symposium on Information Theory, pages 242-246. IEEE, 2006.   \n[74] Anpeng Wu, Junkun Yuan, Kun Kuang, Bo Li, Runze Wu, Qiang Zhu, Yueting Zhuang, and Fei Wu. Learning decomposed representations for treatment effect estimation. IEEE Transactions on Knowledge and Data Engineering, 35(5):4989-5001, 2022.   \n[75] Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, and Aidong Zhang. A survey on causal inference. ACM Transactions on Knowledge Discovery from Data (TKDD), 15(5):1-46, 2021.   \n[76] Liuyi Yao, Sheng Li, Yaliang Li, Mengdi Huai, Jing Gao, and Aidong Zhang. Representation learning for treatment effect estimation from observational data. Advances in neural information processing systems, 31, 2018.   \n[77]  Jinsung Yoon, James Jordon, and Mihaela Van Der Schaar. Ganite: Estimation of individualized treatment effects using generative adversarial nets. In International conference on learning representations, 2018.   \n[78] Linying Zhang, Yixin Wang, Anna Ostropolets, Jami J Mulgrave, David M Blei, and George Hripcsak. The medical deconfounder: assessing treatment effects with electronic health records. In Machine Learning for Healthcare Conference, pages 490-512. PMLR, 2019.   \n[79]  Yao Zhang, Alexis Bellot, and Mihaela Schaar. Learning overlapping representations for the estimation of individualized treatment effects. In International Conference on Artificial Intelligence and Statistics, pages 1005-1014. PMLR, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A   CATE Estimation Strategies ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 CATE Learners ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We now detail how to construct CATE learners using the observed samples $\\{(X_{i},T_{i},Y_{i})\\}_{i=1}^{n}$ Note that CATE learners are learned on the training set, so the sample size $n$ here equals the training sample size. Denote $n_{t}$ by the sample size in the treat group, and $n_{c}$ by the sample size in the control group such that $n=n_{t}+n_{c}$ ", "page_idx": 15}, {"type": "text", "text": "\u00b7 S-learner: Let predictors $=(X,T)$ , response $-Y$ . Train a model $\\hat{\\mu}(X,T)$ . Then we obtain $\\hat{\\tau}_{S}(X)$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{S}(X)=\\hat{\\mu}(X,1)-\\hat{\\mu}(X,0).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 T-learner: Let predictors $\\scriptstyle=X^{T}$ (covariates in the treat), response $\\scriptstyle=Y^{T}$ (outcome in the treat). Train a model $\\hat{\\mu}_{1}(X)$ . Let predictors $\\textstyle=X^{C}$ (covariates in the control), response $\\scriptstyle=Y^{C}$ (outcome in the control). Train a model $\\hat{\\mu}_{0}(X)$ . Then we obtain ${\\hat{\\tau}}_{T}(X)$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{T}(X)=\\hat{\\mu}_{1}(X)-\\hat{\\mu}_{0}(X).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 PS-learner: Fisrt-step: Train ${\\hat{\\tau}}_{S}(X)$ using the above-mentioned step in S-learner. Secondstep: Let predictors $=X$ ,response $\\mathrm{=}\\hat{\\tau}_{S}(X)$ . Train a model $\\hat{\\tau}_{P S}(X)$ from the following objective: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{P S}=\\arg\\operatorname*{min}_{\\tau}\\;\\frac{1}{n}\\sum_{i=1}^{n}(\\tau(X_{i})-\\hat{\\tau}_{S}(X_{i}))^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 IPW-learner: First-step: let predictors $=X$ ,response= $\\mathbf{\\nabla}\\cdot\\mathbf{\\mathcal{T}}$ . Train a propensity score model ${\\hat{\\pi}}(X)$ . Construct surrogate of CATE using pseudo-outcomes with inverse propensity weighting (PW) fomula: $Y_{I P W}^{1,0}=Y_{I P W}^{1}-Y_{I P W}^{0}$ where $\\begin{array}{r}{Y_{I P W}^{1}=\\frac{T Y}{\\hat{\\pi}(X)}}\\end{array}$ andYipw=TXY Train a model ${\\hat{\\tau}}_{I P W}(X)$ from the following objective: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{I P W}=\\arg\\operatorname*{min}_{\\tau}\\mathrm{~}\\frac{1}{n}\\sum_{i=1}^{n}(\\tau(X_{i})-Y_{i,I P W}^{1,0})^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 X-learner [47]: First-step: Train ${\\hat{\\mu}}_{1}(X)$ and $\\hat{\\mu}_{0}(X)$ using the the above-mentioned procedure in T-learner. Train a propensity score model ${\\hat{\\pi}}(X)$ using the the above-mentioned procedure in IPW-learner. Second-step: Let predictors= $:\\!X^{T}$ , response $\\d s=\\hat{\\mu}_{1}(X^{T})-Y^{T}$ , and predictors: $\\mathbf{\\Psi}=\\boldsymbol{X}^{C}$ ,response= $:\\!\\hat{\\mu}_{0}(X^{C})-\\!\\!\\stackrel{\\!\\cdot}{Y}\\!^{C}$ . Obtain a model ${\\hat{\\tau}}_{X}(X)$ by learning two separate functions $\\hat{\\tau}_{X}^{1}(X)$ and ${\\hat{\\tau}}_{X}^{0}(X)$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\tau}_{X}(X)=(1-\\hat{\\pi}(X))\\hat{\\tau}_{X}^{1}(X)+\\hat{\\pi}(X)\\hat{\\tau}_{X}^{0}(X),}\\\\ &{\\hat{\\tau}_{X}^{1}=\\underset{\\tau}{\\arg\\operatorname*{min}}\\ \\frac{1}{n_{t}}\\displaystyle\\sum_{i=1}^{n_{t}}(\\tau(X_{i})-(Y_{i}-\\hat{\\mu}_{0}(X_{i})))^{2},}\\\\ &{\\hat{\\tau}_{X}^{0}=\\underset{\\tau}{\\arg\\operatorname*{min}}\\ \\frac{1}{n_{c}}\\displaystyle\\sum_{i=1}^{n_{c}}(\\tau(X_{i})-(\\hat{\\mu}_{1}(X_{i})-Y_{i}))^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 U-learner [25, 55]: First-step: Let predictors $=X$ , response ${\\it=}Y$ . Train a model ${\\hat{\\mu}}(X)$ to approximate the conditional mean outcome $\\mathbb{E}[Y|X]$ . Train a propensity score model ${\\hat{\\pi}}(X)$ using the the above-mentioned procedure in IPW-learner. Second-step: Compute the outcome residual $\\xi=Y-\\hat{\\mu}(X)$ and treatment residual $\\nu=T-\\hat{\\pi}(X)$ . Train a model ${\\hat{\\tau}}_{U}(X)$ from the following objective: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{U}=\\mathop{\\arg\\operatorname*{min}}_{\\tau}\\;\\frac{1}{n}\\sum_{i=1}^{n}(\\frac{\\xi_{i}}{\\nu_{i}}-\\tau(X_{i}))^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u00b7 DR-learner [41, 26]: First-step: Train $\\hat{\\mu}_{1}(X)$ and $\\hat{\\mu}_{0}(X)$ using the the above-mentioned procedure in T-learner. Train a propensity score model ${\\hat{\\pi}}(X)$ using the the abovementioned procedure in IPW-learner. Second-step: Construct surrogate of CATE using pseudo-outcomes with doubly robust (DR) formula: YD $Y_{D R}^{1,0}\\,=\\,Y_{D R}^{1}\\,-\\,Y_{D R}^{0}$ ,where $\\begin{array}{r}{Y_{D R}^{1}=\\hat{\\mu}_{1}(X)+\\frac{T}{\\hat{\\pi}(X)}(Y-\\hat{\\mu}_{1}(X))}\\end{array}$ and $\\begin{array}{r}{Y_{D R}^{0}=\\hat{\\mu}_{0}(X)+\\frac{1-T}{1-\\hat{\\pi}(X)}(Y-\\hat{\\mu}_{0}(X))}\\end{array}$ Train a model $\\hat{\\tau}_{D R}(X)$ from the following objective: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{D R}=\\arg\\operatorname*{min}_{\\tau}\\;\\frac{1}{n}\\sum_{i=1}^{n}(\\tau(X_{i})-Y_{i,D R}^{1,0})^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "\u00b7 R-learner [55]: First-step: Let predictors= $X$ , response $=Y$ . Train a model ${\\hat{\\mu}}(X)$ to approximate the conditional mean outcome $\\mathbb{E}[Y|X]$ . Train a propensity score model ${\\hat{\\pi}}(X)$ using the the above-mentioned procedure in IPW-learner. Second-step: Compute the outcome residual $\\xi=Y-\\hat{\\mu}(X)$ and treatment residual $\\nu=T-\\hat{\\pi}(X)$ . Train a model $\\hat{\\tau}_{R}(X)$ from the following objective: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\tau}_{R}=\\underset{\\tau}{\\arg\\operatorname*{min}}~\\frac{1}{n}\\sum_{i=1}^{n}(\\xi_{i}-\\nu_{i}\\tau(X_{i}))^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "\u00b7 RA-learner [18]: First-step: Train ${\\hat{\\mu}}_{1}(X)$ and $\\hat{\\mu}_{0}(X)$ using the the above-mentioned procedure in T-learner. Second-step: Construct surrogate of CATE using pseudo-outcomes with regression adjustment (RA) formula: $Y_{R A}=T(Y-{\\hat{\\mu}}_{0}(X))+(1-T)({\\hat{\\mu}}_{1}(X)-Y)$ Train a model $\\hat{\\tau}_{R A}(X)$ from the following objective: ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\hat{\\tau}}_{R A}=\\operatorname{arg\\,min}_{\\tau}\\,{\\frac{1}{n}}\\sum_{i=1}^{n}(\\tau(X_{i})-Y_{i,R A})^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "A.2  CATE Selectors ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We now detail how to construct CATE selectors using the observed samples $\\{(X_{i},T_{i},Y_{i})\\}_{i=1}^{n}$ Note that CATE selectors are constructed on the validation set, so the sample size $n$ here equals the validation sample size. ", "page_idx": 16}, {"type": "text", "text": "\u00b7 Plug-in selector: Obtain any CATE learners $\\tilde{\\tau}$ using the observational validation data. Then plug-in $\\tilde{\\tau}$ into the following metric $\\mathcal{R}_{\\tilde{\\tau}}^{p l u g}(\\hat{\\tau})$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\tilde{\\tau}}^{p l u g}({\\hat{\\tau}})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}({\\hat{\\tau}}(X_{i})-{\\tilde{\\tau}}(X_{i}))^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For each plug-in selector $\\tilde{\\tau}$ , the selected $j^{*}$ -th CATE estimator is $\\hat{\\tau}_{j^{*}}$ ,where $j^{*}\\ =$ $\\arg\\operatorname*{min}_{j\\in\\{1,...,J\\}}\\mathcal{R}_{\\tilde{\\tau}}^{p l u g}(\\hat{\\tau}_{j})$ ", "page_idx": 16}, {"type": "text", "text": "\u00b7 Pseudo-outcome selector: ", "page_idx": 16}, {"type": "text", "text": "1. Pseudo-DR: Utilize validation data to estimate nuisance parameters $(\\tilde{\\mu}_{1},\\tilde{\\mu}_{0},\\tilde{\\pi})$ ,fol$\\tilde{Y}_{D R}~=~\\tilde{Y}_{D R}^{1}\\,-\\,\\tilde{Y}_{D R}^{0}$ $\\begin{array}{r}{\\tilde{Y}_{D R}^{1}\\,=\\,\\tilde{\\mu}_{1}(X)\\,+\\,\\frac{T}{\\tilde{\\pi}(X)}(Y\\,-\\,\\tilde{\\mu}_{1}(X))}\\end{array}$ $\\begin{array}{r}{\\tilde{Y}_{D R}^{0}\\,=\\,\\tilde{\\mu}_{0}(X)+\\frac{1-T}{1-\\tilde{\\pi}(X)}(Y-\\tilde{\\mu}_{0}(X))}\\end{array}$ Then the pseudo-DR metric is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{R}_{D R}^{p s e u d o}(\\hat{\\tau})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{\\tau}(X_{i})-\\tilde{Y}_{i,D R})^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For pseudo-DR selector, the selected $j^{*}$ -th CATE estimator is $\\hat{\\tau}_{j^{*}}$ \uff0cwhere $j^{*}\\;=$ $\\arg\\operatorname*{min}_{j\\in\\{1,...,J\\}}\\mathcal{R}_{D R}^{p s e u d o}(\\hat{\\tau}_{j})$ ", "page_idx": 16}, {"type": "text", "text": "2. Pseudo-R: Utilize validation data to estimate nuisance parameters $(\\widetilde{\\mu},\\widetilde{\\pi})$ ,following the procedure described in Section A.1. Then the pseudo- $\\mathbf{\\nabla}\\cdot\\mathbf{R}$ metric is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{R}_{R}^{p s e u d o}(\\hat{\\tau})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}((Y_{i}-\\tilde{\\mu}(X_{i}))-\\hat{\\tau}(X_{i})(T_{i}-\\tilde{\\pi}(X_{i})))^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For pseudo-R selector, the selected $j^{*}$ -th CATE estimator is $\\hat{\\tau}_{j^{*}}$ \uff0cwhere $\\begin{array}{r l}{\\boldsymbol{j}^{*}}&{{}=}\\end{array}$ $\\arg\\operatorname*{min}_{j\\in\\{1,...,J\\}}\\mathcal{R}_{R}^{p s e u d o}(\\hat{\\tau}_{j})$ ", "page_idx": 17}, {"type": "text", "text": "3. Pseudo-IF [5]: Utilize validation data to estimate nuisance parameters $(\\tilde{\\mu}_{1},\\tilde{\\mu}_{0},\\tilde{\\pi})$ following the procedure described in Section A.1. Let $\\tilde{\\tau}(X)\\ =\\ (\\tilde{\\mu}_{1}(X)\\stackrel{\\cdot\\cdot}{-}\\tilde{\\mu}_{0}(X))$ Then the pseudo-IF metric is ", "page_idx": 17}, {"type": "text", "text": "$\\mathcal{R}_{I F}^{p s e u d o}(\\hat{\\tau})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}((1-B_{i})\\tilde{\\tau}^{2}(X_{i})+B_{i}Y_{i}(\\tilde{\\tau}(X_{i})-\\hat{\\tau}(X_{i}))-A_{i}(\\tilde{\\tau}(X_{i})-\\hat{\\tau}(X_{i}))^{2}+\\hat{\\tau}^{2}(X_{i})^{2})^{2}}$ where $A_{i}=T_{i}-\\tilde{\\pi}(X_{i})$ \uff0c $B_{i}=2T_{i}(T_{i}-\\tilde{\\pi}(X_{i}))C_{i}^{-1}$ \uff0c $C_{i}=\\tilde{\\pi}(X_{i})(1-\\tilde{\\pi}(X_{i}))$   \nFor pseudo-IF selector, the selected $j^{*}$ -th CATE estimator is $\\hat{\\tau}_{j^{*}}$ , where $j^{*}\\ =$   \n$\\arg\\operatorname*{min}_{j\\in\\{1,...,J\\}}\\mathcal{R}_{I F}^{p s e u d o}(\\hat{\\tau}_{j})$   \n4. Other pseudo-outcome selector: By manipulating the formula of $\\tilde{Y}$ , it is possible to   \ncreate additional pseudo-outcome selectors, such as the pseudo-IPW selector. In our   \npaper, we choose pseudo-DR as the baseline because it is representative in the causal   \ninference literature and it often demonstrates superior performance, owing to its doubly   \nrobust property. ", "page_idx": 17}, {"type": "text", "text": "B Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "B.1 Proof of Proposition 4.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. ", "page_idx": 17}, {"type": "text", "text": "$\\begin{array}{r l}&{\\mathbb{E}\\{(\\hat{\\tau}(X)-\\tau_{t r e}(X))^{2}\\}}\\\\ &{=\\mathbb{E}\\{(\\hat{\\tau}(X)-\\beta_{t}(X)-\\mu_{0}(X))\\}^{2}]}\\\\ &{=\\mathbb{E}\\{(\\hat{\\tau}(X)-\\mu_{1}(X)+\\mu_{0}(X))^{2}\\}}\\\\ &{=\\mathbb{E}\\{(\\hat{\\tau}(X)-\\mu_{1}(X))^{2}\\}+\\mathbb{E}\\{\\mu_{0}(X)^{2}\\}^{2}+2\\mathbb{E}\\{(\\hat{\\tau}(X)-\\mu_{1}(X))\\mu_{0}(X)\\}}\\\\ &{=\\mathbb{E}\\{\\hat{\\tau}(X)^{2}\\}+\\mathbb{E}\\mu_{0}(X)^{2}\\|_{\\displaystyle=-2\\mathbb{E}\\{\\hat{\\tau}(X)\\mu_{1}(X)\\}}+\\mathbb{E}\\{\\mu_{0}(X)^{2}\\}+2\\mathbb{E}\\{\\hat{\\tau}(X)\\mu_{0}(X)\\}-2\\mathbb{E}\\{\\mu_{1}(X)\\mu_{0}(X)}\\\\ &{=\\mathbb{E}\\{\\hat{\\tau}(X)^{2}\\}-2\\mathbb{E}\\{(X)(\\mu)(X)-Y^{\\ast}1+Y^{\\ast}\\}+2\\mathbb{E}\\{\\hat{\\tau}(X)(\\mu)(X)-Y^{\\ast}(Y)\\}}\\\\ &{\\quad+\\mathbb{E}\\{\\mu_{1}(X)^{2}\\}+\\mathbb{E}\\{\\mu_{0}(X)^{2}\\}-2\\mathbb{E}\\{(\\mu_{1}(X)\\mu_{0}(X))\\}}\\\\ &{=\\mathbb{E}\\{\\hat{\\tau}(X)^{2}\\}-2\\mathbb{E}\\{\\hat{\\tau}(X)Y^{\\ast}1\\}-2\\mathbb{E}\\{(Y)(\\mu_{1}(X)-Y^{\\ast}1)\\}+2\\mathbb{E}\\{\\hat{\\tau}(X)Y^{\\ast}\\}+2\\mathbb{E}\\{\\hat{\\tau}(X)(\\mu_{0}(X)-Y^{\\ast})}\\\\ &{\\quad+\\mathbb{E}\\{\\mu_{1}(X)^{2}\\}+\\mathbb{E}\\{\\mu_{0}(X)^{2}\\}-2\\mathbb{E}\\{\\mu_{1}(X)\\mu_{0}(X)\\}}\\\\ &{=\\mathbb{E}\\{\\hat{\\tau}(X)^{2}\\}-2\\mathbb{E}\\{(X)Y^{\\ast}1\\}-2\\mathbb{E}\\{\\hat{\\tau $ X)] $+\\,2\\mathbb{E}[\\hat{\\tau}(X)\\mu_{0}(X)-\\hat{\\tau}(X)\\mathbb{E}[Y^{0}|X]]+\\mathbb{E}[\\mu_{1}(X)^{2}]+\\mathbb{E}[\\mu_{0}(X)^{2}]-2\\mathbb{E}[\\mu_{1}(X)\\mu_{0}(X)]$ = E[(Xx)] - 2E[(x)Y1] - 2E[(X)\u03bc1(X) -(X)\u03bc(X)] + 2E[(X)] + 2E[(X)\u03bco(X) - (X)\u03bco(X)] + E[\u03bc(X)] + E[\u03bco(X)\u00b2] - 2E[\u03bc(X)\u03bco(X)] = E[(x)\u00b2] + 2E[(x)Y\u00b0] - 2E[(X)Y1] + E[\u03bc(X)2] + E[\u03bco(X)\u00b2] - 2E[\u03bc(X)\u03bco(X)] = E[(x)\u00b2] + 2E[(x)Y] - 2E[(x)Y1] + C. ", "page_idx": 17}, {"type": "text", "text": "B.2 Proof of Proposition 4.6 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The following Proposition B.1 is useful in proving Proposition 4.6.   \nProposition B.1. Assuming the random variable tuple $(X,T,Y^{1},Y^{0})$ satisfies Assumption 2.1, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p(X,Y^{0},Y^{1}|T=0)=p(Y^{0},Y^{1}|X)p(X|T=0);}\\\\ {p(X,Y^{0},Y^{1}|T=1)=p(Y^{0},Y^{1}|X)p(X|T=1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~~p(X,Y^{0},Y^{1}|T=0)}\\\\ &{{=}p(Y^{0},Y^{1}|X,T=0)p(X|T=0)}\\\\ &{{=}p(Y^{0},Y^{1}|X)p(X|T=0).~~~(\\mathrm{Unconfoundedness})}\\\\ &{~~~p(X,Y^{0},Y^{1}|T=1)}\\\\ &{{=}p(Y^{0},Y^{1}|X,T=1)p(X|T=1)}\\\\ &{{=}p(Y^{0},Y^{1}|X)p(X|T=1).~~~(\\mathrm{Unconfoundedness})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now we can prove Proposition 4.6. ", "page_idx": 18}, {"type": "text", "text": "Proof. ", "page_idx": 18}, {"type": "text", "text": "$\\begin{array}{r l}&{\\quad D_{k\\ell}(P_{\\ell}||P_{r})}\\\\ &{=D_{k\\ell}(P_{\\ell}||P_{r})}\\\\ &{=\\int_{x}\\int_{y}\\int_{y_{0}}p(x,y^{0},y^{1}|T=0)||P(X,Y^{0},Y^{1}|T=1))}\\\\ &{=\\int_{x}\\int_{y_{0}}\\int_{y_{0}}p(x,y^{0},y^{1}|T=0)\\log\\frac{p(x,y^{0},y^{1}|T=0)}{p(x,y^{0},y^{1}|T=1)}\\partial_{y}^{1}\\,\\mathrm{d}y\\,\\mathrm{d}z}\\\\ &{=\\int_{x}\\int_{y_{0}}\\int_{y_{0}}p(y,y^{1}|x)p(x|T=0)\\log\\frac{p(y,y^{0},y^{1}|T)\\rho(x|T=0)}{p(y,y^{0},y^{1}|T)\\rho(x|T=1)}\\partial_{y}^{1}\\,\\mathrm{d}y\\,\\mathrm{d}z}\\\\ &{=\\int_{x}\\int_{y_{0}}\\int_{y_{0}}p(y,y^{1}|x)p(x|T=0)|\\log\\frac{p(x,y^{0}=0)}{p(x|T=1)}\\partial_{y}^{1}\\,\\mathrm{d}y\\,\\mathrm{d}z}\\\\ &{=\\int_{x}\\left(\\int_{y_{0}}\\int_{y_{0}}p(y,y^{1}|x)\\partial_{y}^{1}\\,\\mathrm{d}y\\right)\\eta(x|T=0)\\log\\frac{p(x|T=0)}{p(x|T=1)}\\,\\mathrm{d}x}\\\\ &{=\\int_{x}p(x/T=0)\\log\\frac{p(x|T=0)}{p(x|T=1)}\\,\\mathrm{d}x}\\\\ &{=D_{k\\ell}(P(X|T=0)|P(X|T=1))}\\end{array}$=DkL(P&IIPx).$D_{K L}(P_{T}||P_{C})=D_{K L}(P_{X}^{T}||P_{X}^{C})$", "page_idx": 18}, {"type": "text", "text": "Similarly, it is easy to show ", "page_idx": 18}, {"type": "text", "text": "B.3Proof of Theorem 4.4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Lemma B.2 (Theorem 1 in [34]). Let $f_{\\theta}(X)$ denote the loss functionof $X$ and it isbounded almost surely. $\\theta\\in\\Theta$ represents the model parameters of the function $f_{\\theta}(X)$ . Let $B_{\\epsilon}(P)$ be theuncertainty ball centered at distribution $P$ with ambiguity radius e. Define k as the mass of the distribution $P$ on its essential supremum (Proposition 2 in [34]). Assume $f_{\\theta}(X)$ is bounded and $\\log\\kappa+\\epsilon<0,$ then we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{V}:=\\operatorname*{sup}_{Q\\in\\mathcal{B}_{\\epsilon}(P)}\\mathbb{E}^{Q}[f_{\\theta}(X)]=\\operatorname*{min}_{\\lambda>0}\\lambda\\epsilon+\\lambda\\log\\mathbb{E}^{P}[\\exp(f_{\\theta}(X)/\\lambda)].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Our Theorem 4.4 follows by directly applying the above Lemma B.2. ", "page_idx": 18}, {"type": "text", "text": "B.4Proof of Theorem 4.5 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "For notational simplicity, we denote $W=(X,T,Y)\\in\\mathcal{W}$ and $Z={\\hat{\\tau}}(X)Y$ .Assume $Z$ is bounded within the range $M$ and $\\bar{M}$ . Define the following functions: ", "page_idx": 18}, {"type": "equation", "text": "$$\nG_{0}(\\lambda_{0};W)=\\mathbb{E}[g_{0}(\\lambda_{0};W)],\\;\\;\\;\\hat{G}_{0}(\\lambda_{0};W)=\\frac{1}{n}\\sum_{i=1}^{n}g_{0}(\\lambda_{0};W_{i}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\nG_{1}(\\lambda_{1};W)=\\mathbb{E}[g_{1}(\\lambda_{1};W)],\\;\\;\\;\\hat{G}_{1}(\\lambda_{1};W)=\\frac{1}{n}\\sum_{i=1}^{n}g_{1}(\\lambda_{1};W_{i}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have the following lemma that guarantees the convergence for $\\hat{G}_{0}(\\lambda_{0};W)$ and $\\hat{G}_{1}(\\lambda_{1};W)$ Lemma B.3. Assume $0<\\lambda\\leq\\lambda_{0},\\lambda_{1}\\leq\\bar{\\lambda},$ and $\\hat{\\tau}(X)Y$ is bounded within the range of $M$ to $\\bar{M}$ Then with probability $1-\\delta$ we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\bar{\\lambda}\\right)\\right)^{2}}{n}}\\right);}\\\\ &{\\left.\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-M/\\lambda\\right)\\right)^{2}}{n}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\lambda\\right)\\right)^{2}}{n}}\\right);}\\\\ &{\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-\\underline{{M}}/\\lambda\\right)\\right)^{2}}{n}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\lambda\\right)\\right)^{2}}{n}}\\right);}\\\\ &{\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-\\underline{{M}}/\\bar{\\lambda}\\right)\\right)^{2}}{n}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Denote $\\begin{array}{r}{h_{0}(W_{1},W_{2},\\ldots,W_{n})=\\frac{1}{n}\\sum_{i=1}^{n}g_{0}(\\lambda_{0};W_{i})}\\end{array}$ We notice that $\\boldsymbol{h_{0}}(W_{1},W_{2},\\ldots,W_{n})$ satisfies the bounded difference inequality: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{W_{1},\\ldots,W_{n},W_{i}^{\\prime}\\in\\mathcal{W}}{\\operatorname*{sup}}|h_{0}(W_{1},\\ldots,W_{i},\\cdots,W_{n})-h_{0}(W_{1},\\ldots,W_{i}^{\\prime},\\cdots,W_{n})|}\\\\ &{=\\underset{W_{i},W_{i}^{\\prime}\\in\\mathcal{W}}{\\operatorname*{sup}}\\frac{\\left|g_{0}\\left(\\lambda_{0};W_{i}\\right)-g_{0}\\left(\\lambda_{0};W_{i}^{\\prime}\\right)\\right|}{n}}\\\\ &{\\le2\\underset{W_{i}\\in\\mathcal{W}}{\\operatorname*{sup}}\\frac{\\left|g_{0}\\left(\\lambda_{0};W_{i}\\right)\\right|}{n}\\le\\frac{2\\exp\\left(\\bar{M}/\\lambda_{0}\\right)}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that $|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)|=|h_{0}(W_{1},W_{2},\\ldots,W_{n})-\\mathbb{E}[h_{0}(W_{1},W_{2},\\ldots,W_{n})]|.$ Then using McDiarmid's inequality, for any $\\epsilon>0$ ,we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P\\left(\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|\\geq\\epsilon\\right)}\\\\ &{=P\\left(\\left|h_{0}(W_{1},W_{2},\\ldots,W_{n})-\\mathbb{E}[h_{0}(W_{1},W_{2},\\ldots,W_{n})]\\right|\\geq\\epsilon\\right)}\\\\ &{\\leq2\\exp\\left(-\\frac{2\\epsilon^{2}}{n\\left(\\frac{2\\exp\\left(\\bar{M}/\\lambda_{0}\\right)}{n}\\right)^{2}}\\right)=2\\exp\\left(\\frac{-n\\epsilon^{2}}{2\\left(\\exp\\left(\\bar{M}/\\lambda_{0}\\right)\\right)^{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For some $\\delta>0$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nP\\left(\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|\\geq\\epsilon\\right)\\leq2\\exp\\left(\\frac{-n\\epsilon^{2}}{2\\left(\\exp\\left(\\Bar{M}/\\lambda_{0}\\right)\\right)^{2}}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This solves $\\epsilon$ such that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\epsilon\\geq\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\lambda_{0}\\right)\\right)^{2}}{n}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The above inequality should hold for any $\\lambda_{0}$ such that $0<\\lambda\\le\\lambda_{0}\\le\\bar{\\lambda}$ . Therefore, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{{\\mathrm{If}}\\ \\bar{M}\\ge0:}&{\\ \\epsilon\\ge\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\lambda\\right)\\right)^{2}}{n}};}\\\\ {{\\mathrm{If}}\\ \\bar{M}\\le0:}&{\\ \\epsilon\\ge\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(\\bar{M}/\\bar{\\lambda}\\right)\\right)^{2}}{n}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Similarly,denote $\\begin{array}{r}{h_{1}(W_{1},W_{2},\\ldots,W_{n})=\\frac{1}{n}\\sum_{i=1}^{n}g_{1}(\\lambda_{1};W_{i})}\\end{array}$ We note that $h_{1}(W_{1},W_{2},\\ldots,W_{n})$ satisfies the bounded difference inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{W_{1},\\ldots,W_{n},W_{i}^{\\prime}\\in\\mathcal{W}}{\\operatorname*{sup}}|h_{1}(W_{1},\\ldots,W_{i},\\cdots,W_{n})-h_{1}(W_{1},\\ldots,W_{i}^{\\prime},\\cdots,W_{n})|}\\\\ &{=\\underset{W_{i},W_{i}^{\\prime}\\in\\mathcal{W}}{\\operatorname*{sup}}\\frac{\\left|g_{1}\\left(\\lambda_{1};W_{i}\\right)-g_{1}\\left(\\lambda_{1};W_{i}^{\\prime}\\right)\\right|}{n}}\\\\ &{\\leq2\\underset{W_{i}\\in\\mathcal{W}}{\\operatorname*{sup}}\\frac{\\left|g_{1}\\left(\\lambda_{1};W_{i}\\right)\\right|}{n}\\leq\\frac{2\\exp\\left(-\\underline{{M}}/\\lambda_{1}\\right)}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then using McDiarmid's inequality, for any $\\epsilon>0$ ,wehave ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P\\left(\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|\\geq\\epsilon\\right)}\\\\ &{=P\\left(|h_{1}(W_{1},W_{2},\\ldots,W_{n})-\\mathbb{E}[h_{1}(W_{1},W_{2},\\ldots,W_{n})]|\\geq\\epsilon\\right)}\\\\ &{\\leq2\\exp\\left(-\\frac{2\\epsilon^{2}}{n(\\frac{2\\exp(-M/\\lambda_{1})}{n})^{2}}\\right)=2\\exp\\left(\\frac{-n\\epsilon^{2}}{2\\left(\\exp\\left(-\\underline{{M/\\lambda_{1}}}\\right)\\right)^{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For some $\\delta>0$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nP\\left(\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|\\geq\\epsilon\\right)\\leq2\\exp\\left(\\frac{-n\\epsilon^{2}}{2\\left(\\exp\\left(-M/\\lambda_{1}\\right)\\right)^{2}}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This solves $\\epsilon$ such that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\epsilon\\geq\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-\\underline{{M}}/\\lambda_{1}\\right)\\right)^{2}}{n}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The above inequality should hold for any $\\lambda_{1}$ such that $0<\\lambda\\leq\\lambda_{1}\\leq\\bar{\\lambda}$ . Therefore, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{{\\mathrm{If}}\\ {\\underline{{M}}}\\geq0:}&{\\ \\epsilon\\geq\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-{\\underline{{M}}}/{\\bar{\\lambda}}\\right)\\right)^{2}}{n}};}\\\\ {{\\mathrm{If}}\\ {\\underline{{M}}}\\leq0:}&{\\ \\epsilon\\geq\\sqrt{\\frac{2\\log\\frac{2}{\\delta}\\left(\\exp\\left(-{\\underline{{M}}}/{\\bar{\\lambda}}\\right)\\right)^{2}}{n}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In the following content, we will bound terms $\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\right|$ and $\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\right|.$ Lemma B.4 is useful for bounding these two terms. ", "page_idx": 20}, {"type": "text", "text": "Lemma B.4. Let c be a constant. For any $x_{1},\\,x_{2}$ suchthat $x_{1},x_{2}\\geq c>0$ wehave ", "page_idx": 20}, {"type": "equation", "text": "$$\n|\\log(x_{1})-\\log(x_{2})|\\leq{\\frac{1}{c}}|x_{1}-x_{2}|\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Without loss of generality, assume $0<c\\leq x_{1}\\leq x_{2}$ . We then have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\log(x_{2})-\\log(x_{1})=\\log({\\frac{x_{2}}{x_{1}}})=\\log(1+{\\frac{x_{2}}{x_{1}}}-1)\\leq{\\frac{x_{2}}{x_{1}}}-1={\\frac{x_{2}-x_{1}}{x_{1}}}\\leq{\\frac{x_{2}-x_{1}}{c}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Taking the absolute value of both the left-hand side and the right-hand side, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n|\\log(x_{1})-\\log(x_{2})|\\leq{\\frac{1}{c}}|x_{1}-x_{2}|.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Next, we introduce Lemma B.5 that bounds terms $\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\right|$ and $\\Bigl|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\Bigr|.$ ", "page_idx": 21}, {"type": "text", "text": "Lemma B.5. Let u denote the probability of treat, i.e., $u=P(T=1)$ . Assume that $\\lambda_{0},\\lambda_{1}\\in\\Lambda:=$ $[\\underline{{\\lambda}},\\bar{\\lambda}]$ and $\\hat{\\tau}(X)Y$ is bounded within $M$ and $\\bar{M}$ Then for $\\begin{array}{r}{n\\ge\\operatorname*{max}\\lbrace\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right),\\frac{2}{(1-u)^{2}}\\log\\left(\\frac{2}{\\delta}\\right)\\rbrace,}\\end{array}$ with probability $1-\\delta$ we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log(G_{0}(\\lambda_{0};W))\\right|\\leq\\frac{2}{\\exp(M/\\lambda)(1-u)}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|;}\\\\ &{\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log(G_{1}(\\lambda_{1};W))\\right|\\leq\\frac{2}{\\exp(-M/\\lambda)u}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|;}\\\\ &{f^{\\prime}M\\leq0,\\bar{M}\\geq0;}\\\\ &{\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log(G_{0}(\\lambda_{0};W))\\right|\\leq\\frac{2}{\\exp(M/\\lambda)(1-u)}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|;}\\\\ &{\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log(G_{1}(\\lambda_{1};W))\\right|\\leq\\frac{2}{\\exp(-M/\\lambda)u}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|;}\\\\ &{f^{\\prime}0\\leq M\\leq\\bar{M}:}\\\\ &{\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log(G_{0}(\\lambda_{0};W))\\right|\\leq\\frac{2}{\\exp(M/\\lambda)(1-u)}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|;}\\\\ &{\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log(G_{1}(\\lambda_{1};W))\\right|\\leq\\frac{2}{\\exp(-M/\\lambda)u}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. First, we bound the term $\\Bigl|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\Bigr|.$ ", "page_idx": 21}, {"type": "text", "text": "$G_{0}(\\lambda_{0};W)$ and $\\hat{G}_{0}(\\lambda_{0};W)$ are greater than O and bounded because $Z={\\hat{\\tau}}(X)Y$ is bounded within the range $M$ and $M$ . Therefore, applying Lemma B.4, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\right|\\leq\\frac{1}{c}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|,}\\\\ &{\\mathrm{where~}c=\\operatorname*{min}\\left\\{\\underset{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}{\\operatorname*{inf}}\\hat{G}_{0}(\\lambda_{0};W),\\underset{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}{\\operatorname*{inf}}G_{0}(\\lambda_{0};W)\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Moreover, for any $\\lambda_{0}\\in\\Lambda$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{M}\\geq0\\,:}&{G_{0}(\\lambda_{0};W)=\\mathbb{E}[(1-T)\\exp(Z/\\lambda_{0})]=\\mathbb{E}[\\exp(Z/\\lambda_{0})/T=0]\\,P(T=0)}\\\\ &{\\geq\\mathbb{E}[\\exp(\\lambda/\\lambda_{1})/T=0](1-u)=\\exp(\\lambda/\\lambda)(1-u);}\\\\ &{\\hat{G}_{0}(\\lambda_{0};W)=\\frac{1}{n}\\,\\frac{\\hat{\\mathbf{V}}}{t=1}(1-T)\\exp(Z_{i}/\\lambda_{0})}\\\\ &{\\qquad\\qquad\\geq\\frac{1}{n}\\,\\frac{\\hat{\\mathbf{V}}}{t=1}(1-T)\\exp(M/\\Tilde{\\lambda})=\\exp(M/\\Tilde{\\lambda})(1-\\Tilde{u}).}\\\\ {\\mathcal{M}\\leq0\\,:}&{G_{0}(\\lambda_{0};W)=\\mathbb{E}[(1-T)\\exp(Z/\\lambda_{0})]=\\mathbb{E}[\\exp(Z/\\lambda_{0})/T=0]\\,P(T=0)}\\\\ &{\\geq\\mathbb{E}[\\exp(M/\\Tilde{\\lambda})]/T=0[(1-u)=\\exp(\\beta I/\\lambda)(1-u);}\\\\ &{\\hat{G}_{0}(\\lambda_{0};W)=\\frac{1}{n}\\,\\frac{\\hat{\\mathbf{V}}}{t=1}(1-T)\\exp(Z_{i}/\\lambda_{0})}\\\\ &{\\qquad\\qquad\\geq\\frac{1}{n}\\,\\frac{\\hat{\\mathbf{V}}}{t=1}(1-T_{i})\\exp(M/\\lambda)=\\exp(M/\\lambda)(1-\\Tilde{u}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Given $\\textstyle{\\hat{u}}={\\frac{1}{n}}\\sum_{i=1}^{n}T_{i}$ and $\\begin{array}{r}{u=\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]}\\end{array}$ , using Hoeffding\u2019s inequality, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\nP\\left(\\left|\\frac{1}{n}\\sum_{i=1}^{n}(1-T_{i})-\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}(1-T_{i})]\\right|\\geq\\frac{\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}(1-T_{i})]}{2}\\right)\\leq2\\exp\\left(-\\frac{2(\\frac{1-u}{2})^{2}}{n(\\frac{1}{n})^{2}}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We can solve $n$ by ", "page_idx": 22}, {"type": "equation", "text": "$$\n2\\exp\\left(-\\frac{n(1-u)^{2}}{2}\\right)\\leq\\delta\\Rightarrow n\\geq\\frac{2}{(1-u)^{2}}\\log\\left(\\frac{2}{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This indicates that $(1-\\hat{u})\\geq(1-u)/2$ with probabity $1-\\delta$ when $\\begin{array}{r}{n\\ge\\frac{2}{(1-u)^{2}}\\log\\left(\\frac{2}{\\delta}\\right)}\\end{array}$ . Combining this with equations (21) and (22), with probability $1-\\delta$ , when (1-u) log (3), we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{~H~}\\,\\mathcal{M}\\geq0:}&{\\operatorname*{inf}_{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}G_{0}(\\lambda_{0};W)\\geq\\exp(M/\\bar{\\lambda})(1-u);}\\\\ &{\\qquad\\operatorname*{inf}_{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}\\hat{G}_{0}(\\lambda_{0};W)\\geq\\exp(M/\\bar{\\lambda})(1-\\hat{u})\\geq\\exp(M/\\bar{\\lambda})(1-u)/2.}\\\\ {\\mathrm{~H~}\\,\\mathcal{M}\\leq0:}&{\\operatorname*{inf}_{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}G_{0}(\\lambda_{0};W)\\geq\\exp(M/\\lambda)(1-u);}\\\\ &{\\qquad\\operatorname*{inf}_{\\lambda_{0}\\in\\Lambda,W\\in\\mathcal{W}}\\hat{G}_{0}(\\lambda_{0};W)\\geq\\exp(M/\\lambda)(1-\\hat{u})\\geq\\exp(M/\\lambda)(1-u)/2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, with probability $1-\\delta$ when $\\begin{array}{r}{n\\ge\\frac{2}{(1-u)^{2}}\\log\\left(\\frac{2}{\\delta}\\right)}\\end{array}$ we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\right|\\leq\\frac{2}{\\exp(\\underline{{M}}/\\bar{\\lambda})(1-u)}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|;\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "If $M\\leq0$ \uff1a", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\log(\\hat{G}_{0}(\\lambda_{0};W))-\\log\\left(G_{0}(\\lambda_{0};W)\\right)\\right|\\leq\\frac{2}{\\exp(\\underline{{M}}/\\lambda)(1-u)}\\left|\\hat{G}_{0}(\\lambda_{0};W)-G_{0}(\\lambda_{0};W)\\right|.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next, we bound the term $\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\right|$ $G_{1}(\\lambda_{1};W)$ and $\\hat{G}_{1}(\\lambda_{1};W)$ are greater than O and bounded above. Therefore, applying Lemma B.4, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\right|\\leq\\frac{1}{c}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|,}\\\\ {\\mathrm{where~}c=\\operatorname*{min}\\left\\{\\underset{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}{\\operatorname*{inf}}\\hat{G}_{1}(\\lambda_{1};W),\\underset{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}{\\operatorname*{inf}}G_{1}(\\lambda_{1};W)\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Moreover, for any $\\lambda_{1}\\in\\Lambda$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{~H~}\\,\\bar{M}\\geq0:\\;}&{G_{1}(\\lambda_{1};W)=\\mathbb{E}[T\\exp(-Z/\\lambda_{1})]=\\mathbb{E}[\\exp(-Z/\\lambda_{1})|T=1]P(T=1)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\geq\\mathbb{E}[\\exp(-\\bar{M}/\\lambda)|T=1]u=\\exp(-\\bar{M}/\\lambda)u;}\\\\ &{\\hat{G}_{1}(\\lambda_{1};W)=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(-Z_{i}/\\lambda_{1})}\\\\ &{\\quad\\quad\\quad\\quad\\geq\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(-\\bar{M}/\\lambda)=\\exp(-\\bar{M}/\\lambda)\\hat{u}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{G_{1}(\\lambda_{1};W)=\\mathbb{E}[T\\exp(-{Z}/\\lambda_{1})]=\\mathbb{E}[\\exp(-{Z}/\\lambda_{1})|T=1]P(T=1)}}\\\\ {{\\mathrm{~}\\qquad\\qquad\\ge\\mathbb{E}[\\exp(-\\bar{M}/\\bar{\\lambda})|T=1]u=\\exp(-\\bar{M}/\\bar{\\lambda})u;}}\\\\ {{\\hat{G}_{1}(\\lambda_{1};W)=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(-{Z_{i}}/\\lambda_{1})}}\\\\ {{\\mathrm{~}\\qquad\\qquad\\ge\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(-\\bar{M}/\\bar{\\lambda})=\\exp(-\\bar{M}/\\bar{\\lambda})\\hat{u}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Given $\\textstyle{\\hat{u}}={\\frac{1}{n}}\\sum_{i=1}^{n}T_{i}$ and $\\begin{array}{r}{u=\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]}\\end{array}$ , using Hoeffding's inequality, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\nP\\left(\\left|\\frac{1}{n}\\sum_{i=1}^{n}T_{i}-\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]\\right|\\geq\\frac{\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]}{2}\\right)\\leq2\\exp\\left(-\\frac{2(\\frac{u}{2})^{2}}{n(\\frac{1}{n})^{2}}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We can solve $n$ by ", "page_idx": 23}, {"type": "equation", "text": "$$\n2\\exp\\left(-\\frac{n u^{2}}{2}\\right)\\leq\\delta\\Rightarrow n\\geq\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This indicates that $h a t u\\ge u/2$ with probability $1-\\delta$ when $n\\geq\\textstyle{\\frac{2}{u^{2}}}\\log\\left({\\frac{2}{\\delta}}\\right)$ . Combining this with equations (23) and (24), with probability $1-\\delta$ when $\\begin{array}{r}{n\\geq\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right)}\\end{array}$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{If}~\\,\\bar{M}\\geq0:}&{\\operatorname*{inf}_{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}G_{1}(\\lambda_{1};W)\\geq\\exp(-\\bar{M}/\\lambda)u;}\\\\ &{\\operatorname*{inf}_{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}\\hat{G}_{1}(\\lambda_{1};W)\\geq\\exp(-\\bar{M}/\\lambda)\\hat{u}\\geq\\exp(-\\bar{M}/\\lambda)u/2.}\\\\ {\\mathrm{If}~\\,\\bar{M}\\leq0:}&{\\operatorname*{inf}_{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}G_{1}(\\lambda_{1};W)\\geq\\exp(-\\bar{M}/\\bar{\\lambda})u;}\\\\ &{\\operatorname*{inf}_{\\lambda_{1}\\in\\Lambda,W\\in\\mathcal{W}}\\hat{G}_{1}(\\lambda_{1};W)\\geq\\exp(-\\bar{M}/\\bar{\\lambda})\\hat{u}\\geq\\exp(\\bar{M}/\\bar{\\lambda})u/2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Therefore, with probability $1-\\delta$ , when $\\begin{array}{r}{n\\ge\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right)}\\end{array}$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\right|\\leq\\frac{2}{\\exp(-\\bar{M}/\\lambda)u}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|;\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\bar{M}\\leq0$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left|\\log(\\hat{G}_{1}(\\lambda_{1};W))-\\log\\left(G_{1}(\\lambda_{1};W)\\right)\\right|\\leq\\frac{2}{\\exp(-\\bar{M}/\\bar{\\lambda})u}\\left|\\hat{G}_{1}(\\lambda_{1};W)-G_{1}(\\lambda_{1};W)\\right|.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This completes the proof of Lemma B.5. ", "page_idx": 23}, {"type": "text", "text": "Additionally, the following Lemma B.6 provides the bound of $|\\log(\\hat{u})-\\log(u)|$ ", "page_idx": 23}, {"type": "text", "text": "Lemma B.6. Let $\\begin{array}{r}{\\hat{u}\\,=\\,\\frac{1}{n}\\sum_{i=1}^{n}T_{i}}\\end{array}$ and $\\begin{array}{r}{u=\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]}\\end{array}$ .For $\\begin{array}{r}{n\\,\\geq\\,\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right)}\\end{array}$ ,with probability $1-\\delta$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n|\\log(\\hat{u})-\\log(u)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{2\\log(\\frac{2}{\\delta})}{n u^{2}}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. Using Hoeffding's inequality, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{P(|\\hat{u}-u|\\ge\\epsilon)=P\\left(\\left|\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}T_{i}-\\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{n}T_{i}]\\right|\\ge\\epsilon\\right)\\le2\\exp\\left(-2n\\epsilon^{2}\\right),}}\\\\ {{2\\exp\\left(-2n\\epsilon^{2}\\right)\\le\\delta\\quad\\mathrm{solves}\\quad\\epsilon\\ge\\sqrt{\\frac{\\log(\\frac{2}{\\delta})}{2n}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Notably, using the results in the previous lemma, we know for $\\begin{array}{r}{n\\geq\\frac{2}{u^{2}}\\log\\left(\\frac{2}{\\delta}\\right),\\,\\hat{u}\\geq u/2}\\end{array}$ .Therefore, wehave ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\log(\\hat{u})-\\log(u)|\\leq\\frac{1}{\\operatorname*{min}\\{\\hat{u},u\\}}|\\hat{u}-u|.\\quad(\\mathrm{By~Lemma~B.4})}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2}{u}|\\hat{u}-u|\\leq\\frac{2}{u}\\mathcal{O}\\left(\\sqrt{\\frac{\\log(\\frac{2}{\\delta})}{2n}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{2\\log(\\frac{2}{\\delta})}{n u^{2}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In the following, we will bound the term $|\\hat{\\mathcal{V}}(\\hat{\\tau})-\\mathcal{V}(\\hat{\\tau})|$ using above lemmas. We first define functions $F_{0}(\\lambda_{0}),\\hat{F}_{0}(\\lambda_{0}),F_{1}(\\lambda_{1})$ and $\\hat{F}_{1}(\\lambda_{1})$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F_{\\vartheta_{1}}(\\lambda_{0})=\\lambda_{0}\\varphi+\\lambda_{0}\\log(\\mathbb{E}^{T}\\{\\exp(\\alpha)(Y^{*}/\\lambda_{1})Y^{\\lambda_{2}}\\})}\\\\ &{\\qquad=\\lambda_{0}\\varphi+\\lambda_{0}\\log\\left(\\frac{1}{1-\\pi}\\mathbb{E}\\{(1-T)\\exp(\\tilde{\\ell}(X)Y^{\\lambda_{1}}/\\lambda_{0})\\}\\right);}\\\\ &{\\tilde{F}_{0}(\\lambda_{0})=\\lambda_{0}\\varphi+\\lambda_{0}\\log(\\frac{1}{\\lambda_{0}}\\frac{1}{\\log(1-T)}(1-T)\\exp(\\tilde{\\ell}(X)Y_{\\ast}/\\lambda_{0}))}\\\\ &{\\qquad=\\lambda_{0}\\varphi+\\lambda_{0}\\log(\\frac{1}{\\alpha}(1-\\frac{1}{\\alpha})\\frac{1}{\\log(1-T)}\\exp(\\tilde{\\ell}(X)Y_{\\ast}/\\lambda_{0}));}\\\\ &{F_{1}(\\lambda_{1})=\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log(\\mathbb{E}^{T}\\{\\exp(-\\tilde{\\ell}(X)Y^{\\lambda_{1}}/\\lambda_{1})\\})}\\\\ &{\\qquad=\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log\\left(\\frac{1}{18}\\mathbb{E}\\{\\exp(-\\tilde{\\ell}(X)Y^{\\lambda_{1}}/\\lambda_{1})\\}\\right);}\\\\ &{\\tilde{F}_{1}(\\lambda_{1})=\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log(\\frac{1}{10}\\frac{1}{\\log(1-\\frac{T}{\\lambda_{1}})}T,\\log(-\\ell(X)Y_{\\ast}/\\lambda_{1}))\\}}\\\\ &{\\qquad=\\lambda_{1}\\epsilon_{1}+\\lambda_{1}\\log(\\frac{1}{10}\\frac{1}{\\log(1-\\frac{T}{\\lambda_{1}})}T,\\log(-\\ell(X)Y_{\\ast}/\\lambda_{1})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The following Lemma B.7 bounds the term $|\\hat{F}(\\lambda)-F(\\lambda)|$ ", "page_idx": 24}, {"type": "text", "text": "Lemma B.7. Let $u\\ :=\\ P(T\\ =\\ 1).$ _Assumingthat $0\\ <\\ \\lambda\\ \\le\\ \\lambda\\ \\le\\ {\\bar{\\lambda}}$ and $\\hat{\\tau}(X)Y$ is bounded within the range of $M$ to $\\bar{M}$ Define $C_{e x p}\\ =\\ {\\bf1}_{\\{{\\underline{{M}}\\leq\\bar{M}\\leq0}\\}}\\exp\\left({\\bar{M}/\\bar{\\lambda}-\\underline{{M}}/\\underline{{\\lambda}}}\\right)\\ +$ $\\mathbf{1}_{\\{\\underline{{M}}\\leq0,\\bar{M}\\geq0\\}}\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\lambda\\right)+\\mathbf{1}_{\\{0\\leq\\underline{{M}}\\leq\\bar{M}\\}}\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\bar{\\lambda}\\right)$ For $n\\geq2/u^{2}\\log(2/\\delta),$ with probability $1-\\delta$ wehave ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{F}_{0}(\\lambda_{0})-F_{0}(\\lambda_{0})|\\le\\mathcal{O}\\left(\\sqrt{\\frac{8\\lambda_{0}^{2}\\log\\frac{2}{\\delta}}{n(1-u)^{2}}C_{e x p}^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\lambda_{0}^{2}\\log(\\frac{2}{\\delta})}{n(1-u)^{2}}}\\right);}\\\\ &{|\\hat{F}_{1}(\\lambda_{1})-F_{1}(\\lambda_{1})|\\le\\mathcal{O}\\left(\\sqrt{\\frac{8\\lambda_{1}^{2}\\log\\frac{2}{\\delta}}{n u^{2}}C_{e x p}^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\lambda_{1}^{2}\\log(\\frac{2}{\\delta})}{n u^{2}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\hat{F}_{0}(\\lambda_{0})-F_{0}(\\lambda_{0})\\big|}\\\\ {\\displaystyle=\\left|\\lambda_{0}\\left(\\log\\left(\\frac{1}{1-u}\\mathbb{E}[(1-T)\\exp(\\hat{\\tau}(X)Y/\\lambda_{0})]\\right)-\\log\\left(\\frac{1}{n(1-\\hat{u})}\\sum_{i=1}^{n}(1-T_{i})\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{0})\\right)\\right)\\right|}\\\\ {\\displaystyle=\\lambda_{0}\\left|\\log\\left(\\mathbb{E}[(1-T)\\exp(\\hat{\\tau}(X)Y/\\lambda_{0})]\\right)-\\log\\left(\\frac{1}{n}\\sum_{i=1}^{n}(1-T_{i})\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{0})\\right)+\\log(1-\\hat{u})-\\frac{1}{n}}\\\\ {\\displaystyle\\leq\\lambda_{0}\\left|\\log\\left(\\mathbb{E}[(1-T)\\exp(\\hat{\\tau}(X)Y/\\lambda_{0})]\\right)-\\log\\left(\\frac{1}{n}\\sum_{i=1}^{n}(1-T_{i})\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{0})\\right)\\right|+\\lambda_{0}\\left|\\log(1-\\hat{u})\\right|}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{\\mathbb{R}^{3}(\\Delta)}-\\int_{\\mathbb{R}^{3}(\\Delta)}1}\\\\ &{\\leq\\frac{2\\tilde{\\lambda}}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1,\\cdots,\\delta)}\\left|\\left\\langle\\tilde{\\lambda}_{2}(\\nu_{k},\\mathcal{W})-G_{\\mu}(|\\mathcal{N}|)\\right\\rangle+\\lambda_{3}\\left||\\varphi_{1}(1-\\delta)-\\mathrm{bet}(1-s)\\right|\\,\\,\\mathrm{~d}(1)\\,\\,\\mathrm{~d}s\\right|\\mathrm{~d}s}\\\\ &{\\leq\\sigma\\left(\\sqrt{\\frac{\\lambda_{2}\\tilde{\\lambda}_{3}(1-s)}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1-s)}}\\left(\\operatorname*{sup}\\left(|\\mathcal{N}|\\mathcal{N}-\\mathcal{M}|/s\\right)\\right)^{2}\\right)+\\sigma\\left(\\sqrt{\\frac{\\lambda_{2}\\tilde{\\lambda}_{3}(1-s)}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1-s)^{2}}}\\right)\\quad\\mathrm{(by~Lemm~B~and~Lemms)}}\\\\ &{\\quad\\pi\\left(\\lambda_{2}\\leq0,\\,\\mathcal{B}\\geq0\\right),}\\\\ &{\\int_{\\mathbb{R}^{3}(\\Delta)}-\\int_{\\mathbb{R}^{3}(\\Delta)}1}\\\\ &{\\leq\\frac{\\sigma\\left(\\nu_{1}\\tilde{\\lambda}_{2}(1-s)\\right)}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1-s)}\\left|\\left\\langle d_{\\lambda}(\\nu_{k},\\mathcal{W})-G_{\\mu}(|\\mathcal{N}|)\\right\\rangle+\\lambda_{3}\\left||\\varphi_{1}(1-\\delta)-\\mathrm{bet}(1-s)\\right|\\,\\,\\mathrm{(by~Lemm~)}}\\\\ &{\\leq\\sigma\\left(\\sqrt{\\frac{\\lambda_{2}\\tilde{\\lambda}_{3}(1-s)}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1-s)}}\\left(\\operatorname*{sup}\\left(|\\mathcal{N}|\\mathcal{B}|-\\mathcal{B}|/s\\right)\\right)^{2}\\right)+\\sigma\\left(\\sqrt{\\frac{\\lambda_{2}\\tilde{\\lambda}_{3}(1-s)}{w(|\\mathcal{N}|)\\tilde{\\lambda}_{1}(1-s)^{2}}}\\right)\\quad\\mathrm{(by~Lemm~B~and~Lemms)}}\\\\ &{\\quad\\pi\\left(\\eta\\leq\\tilde{\\lambda}_{1}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{F}_{1}(\\lambda_{1})-F_{1}(\\lambda_{1})|}\\\\ &{=\\Bigg|\\lambda_{1}\\left(\\log\\left(\\frac{1}{u}\\mathbb{E}[T\\exp(-\\hat{\\tau}(X)Y/\\lambda_{1})]\\right)-\\log\\left(\\frac{1}{n\\hat{u}}\\sum_{i=1}^{n}T_{i}\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{0})\\right)\\right)\\Bigg|}\\\\ &{=\\lambda_{1}\\left|\\log\\left(\\mathbb{E}[T\\exp(\\hat{\\tau}(X)Y/\\lambda_{1})]\\right)-\\log\\left(\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{1})\\right)+\\log(\\hat{u})-\\log(u)\\right|}\\\\ &{\\leq\\lambda_{1}\\left|\\log\\left(\\mathbb{E}[T\\exp(\\hat{\\tau}(X)Y/\\lambda_{1})]\\right)-\\log\\left(\\frac{1}{n}\\sum_{i=1}^{n}T_{i}\\exp(\\hat{\\tau}(X_{i})Y_{i}/\\lambda_{1})\\right)\\right|+\\lambda_{1}\\left|\\log(\\hat{u})-\\log(u)\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "If $M\\leq M\\leq0$   \n$\\begin{array}{r l}&{f_{\\left(1\\right),\\left(1\\right),\\left(2\\right),1}}\\\\ &{:\\le\\frac{2\\operatorname{tr}\\big(\\lambda_{1}\\big)}{\\operatorname{tr}\\big(\\lambda_{2}\\big)}\\Bigg\\vert\\frac{1}{\\lambda_{3}}\\Bigg\\vert\\int_{\\r{0}}^{\\lambda_{1}}\\vert\\mathrm{d}\\lambda_{4}\\vert\\mathcal{R}_{\\lambda}\\vert-G_{\\left(\\lambda_{1}\\right),\\left(1\\right)}^{-1}\\lambda_{1}\\vert\\mathrm{d}\\lambda_{2}\\vert(\\lambda_{1})-\\log(\\vert\\alpha_{1}\\vert)\\,\\ \\ (\\log(\\lambda_{2}))}\\\\ &{:\\le\\sigma\\Big(\\sqrt{\\frac{2\\lambda_{1}\\log\\lambda_{2}}{\\operatorname{tr}\\big(\\lambda_{3}\\big)}}\\Big(\\log(\\vert\\lambda_{2}\\vert\\lambda_{1}-\\lambda_{2}/\\lambda_{3}/\\lambda_{3})\\Big)^{2}\\Big)+\\sigma\\bigg(\\sqrt{\\frac{2\\lambda_{1}\\log\\lambda_{1}}{\\operatorname*{tr}\\big(\\lambda_{2}\\big)}}\\bigg)\\quad\\mathrm{d}\\lambda_{3}\\operatorname{sims}\\ B_{3}\\lambda_{4}\\mathrm{Le}}\\\\ &{:=\\ M\\times0,\\ \\delta\\sum_{\\alpha_{1}=0}^{\\lambda}\\ \\mathrm{,}}\\\\ &{f_{\\left(1\\right),\\left(\\lambda_{1}\\right)}^{-1}\\left(\\log\\lambda_{1}\\right)}\\\\ &{:\\le\\frac{\\operatorname{tr}\\big(\\lambda_{2}\\big)}{\\operatorname{tr}\\big(\\lambda_{2}/\\lambda_{1}\\big)}\\Bigg\\vert\\hat{G}_{\\left(\\lambda_{1}\\vert\\lambda_{1}\\vert\\mathrm{R}^{\\alpha}\\right)}-G_{\\left(\\lambda_{1}\\vert\\lambda_{1}\\vert\\mathrm{R}^{\\alpha}\\right)}\\Big\\vert+\\lambda_{1}\\log(\\vert\\lambda_{2}\\vert-\\log(\\vert\\alpha_{1}\\vert))}\\\\ &{:=\\sigma\\bigg(\\sqrt{\\frac{2\\lambda_{1}\\log\\lambda_{2}}{\\operatorname*{tr}\\big(\\lambda_{2}/\\lambda_{1}\\big)}}\\left(\\log(\\vert\\lambda_{2}\\vert\\lambda_{2}\\vert-\\lambda_{2}/\\lambda_{3}/\\lambda_{3}\\vert)\\right)^{2}\\bigg)+\\sigma\\bigg(\\sqrt{\\frac{2\\lambda_{1}\\log\\lambda_{1}}{\\operatorname*{tr}\\big(\\lambda_{2}/\\lambda_{1}\\big)}}\\bigg)\\quad $ ma B.6) nma B.6) nma B.6) nu2 nu2 ", "page_idx": 26}, {"type": "text", "text": "Proof. Let $=\\mathrm{\\arg\\,min}_{\\lambda}\\;\\hat{F}_{0}(\\lambda_{0}),\\;\\lambda_{0}^{*}\\;=\\;\\arg\\operatorname*{min}_{\\lambda_{0}}F_{0}(\\lambda_{0}),\\;\\hat{\\lambda}_{1}\\;=\\;\\arg\\operatorname*{min}_{\\lambda}\\hat{F}_{1}(\\lambda_{1})$ and $\\lambda_{1}^{*}\\,=$ arg $\\mathrm{min}_{\\lambda_{1}}\\,F_{1}(\\lambda_{1})$ . Then we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{V}^{0}(\\hat{\\tau})-\\hat{\\mathcal{V}}^{0}(\\hat{\\tau})=F_{0}(\\lambda_{0}^{*})-\\hat{F}_{0}(\\hat{\\lambda}_{0})}\\\\ &{\\quad\\quad\\quad\\quad\\quad=F_{0}(\\lambda_{0}^{*})-\\hat{F}_{0}(\\hat{\\lambda}_{0})+F_{0}(\\hat{\\lambda}_{0})-F_{0}(\\hat{\\lambda}_{0})}\\\\ &{\\quad\\quad\\quad\\quad\\quad=F_{0}(\\hat{\\lambda}_{0})-\\hat{F}_{0}(\\hat{\\lambda}_{0})+F_{0}(\\lambda_{0}^{*})-F_{0}(\\hat{\\lambda}_{0})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\leq|F_{0}(\\hat{\\lambda}_{0})-\\hat{F}_{0}(\\hat{\\lambda}_{0})|+0}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq\\operatorname*{sup}_{\\lambda_{0}}|F_{0}(\\lambda_{0})-\\hat{F}_{0}(\\lambda_{0})|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{V}^{0}(\\hat{\\tau})-\\hat{V}^{0}(\\hat{\\tau})=\\hat{F}_{0}(\\hat{X}_{0})-F_{0}(\\hat{X}_{0}^{*})}&{}\\\\ {=\\hat{F}_{0}(\\hat{X}_{0})-F_{0}(\\hat{X}_{0}^{*})+\\hat{F}_{0}(\\hat{X}_{0}^{*})-\\hat{F}_{0}(\\hat{X}_{0}^{*})}\\\\ {=\\hat{F}_{0}(\\hat{X}_{0}^{*})-F_{0}(\\hat{X}_{0}^{*})+\\hat{F}_{0}(\\hat{X}_{0})-\\hat{F}_{0}(\\hat{X}_{0}^{*})}\\\\ {\\le[\\hat{V}_{0}(\\hat{X}_{0}^{*})-F_{0}(\\hat{X}_{0}^{*})]+0}\\\\ {\\le\\operatorname*{sup}_{i}[F_{0}(\\hat{X}_{0})-F_{0}(\\hat{X}_{0})].}\\\\ {\\hat{V}^{1}(\\hat{\\tau})-\\hat{V}^{1}(\\hat{\\tau})=F_{1}(\\hat{X}_{1}^{*})-\\hat{F}_{1}(\\hat{X}_{1})}&{}\\\\ {=F_{1}(\\hat{X}_{1}^{*})-\\hat{F}_{1}(\\hat{X}_{1})+F_{1}(\\hat{X}_{1})-F_{1}(\\hat{X}_{1})}\\\\ {=F_{1}(\\hat{X}_{1})-\\hat{F}_{1}(\\hat{X}_{1})+F_{1}(\\hat{X}_{1}^{*})-F_{1}(\\hat{X}_{1})}\\\\ {\\le F_{1}(\\hat{X}_{1})-\\hat{F}_{1}(\\hat{X}_{1})]+0}\\\\ {\\le\\operatorname*{sup}_{i}[F_{1}(\\hat{X}_{1})-\\hat{F}_{1}(\\hat{X}_{1})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{\\mathcal{V}}^{1}(\\hat{\\tau})-\\mathcal{V}^{1}(\\hat{\\tau})=\\hat{F}_{1}(\\hat{\\lambda}_{1})-F_{1}(\\lambda_{1}^{*})}&{}\\\\ {=\\hat{F}_{1}(\\hat{\\lambda}_{1})-F_{1}(\\lambda_{1}^{*})+\\hat{F}_{1}(\\lambda_{1}^{*})-\\hat{F}_{1}(\\lambda_{1}^{*})}&{}\\\\ {=\\hat{F}_{1}(\\lambda_{1}^{*})-F_{1}(\\lambda_{1}^{*})+\\hat{F}_{1}(\\hat{\\lambda}_{1})-\\hat{F}_{1}(\\lambda_{1}^{*})}&{}\\\\ {\\leq|\\hat{F}_{1}(\\lambda_{1}^{*})-F_{1}(\\lambda_{1}^{*})|+0}&{}\\\\ {\\leq\\operatorname*{sup}_{1}|\\hat{F}_{1}(\\lambda_{1})-F_{1}(\\lambda_{1})|.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Therefore, we have ", "page_idx": 27}, {"type": "text", "text": "If ${\\underline{{M}}}\\leq{\\bar{M}}\\leq0$ $\\begin{array}{r l}&{\\hat{\\tau})-\\mathcal{V}^{0}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n(1-u)^{2}}\\left(\\exp\\left(\\bar{M}/\\bar{\\lambda}-\\underline{{M}}/\\lambda\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n(1-u)^{2}}}\\right)}\\\\ &{\\hat{\\tau})-\\mathcal{V}^{1}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n u^{2}}\\left(\\exp\\left(\\bar{M}/\\bar{\\lambda}-\\underline{{M}}/\\lambda\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n u^{2}}}\\right)}\\end{array}$ ()   \nDO )2 20   \nD1(   \nIf $\\underline{{M}}\\leq0,\\bar{M}\\geq0$ $\\begin{array}{r l}&{\\hat{\\tau})-\\mathcal{V}^{0}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n(1-u)^{2}}\\left(\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\lambda\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n(1-u)^{2}}}\\right)}\\\\ &{\\hat{\\tau})-\\mathcal{V}^{1}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n u^{2}}\\left(\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\lambda\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n u^{2}}}\\right)}\\end{array}$ ()   \nD )2 20   \nD1(   \nIf $0\\leq\\underline{{M}}\\leq\\bar{M}$ \uff1a $\\begin{array}{r l}&{\\hat{\\tau})-\\mathcal{V}^{0}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n(1-u)^{2}}\\left(\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\bar{\\lambda}\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n(1-u)^{2}}}\\right)}\\\\ &{\\hat{\\tau})-\\mathcal{V}^{1}(\\hat{\\tau})|\\leq\\operatorname*{sup}_{\\lambda}|\\hat{F}(\\lambda)-F(\\lambda)|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n u^{2}}\\left(\\exp\\left(\\bar{M}/\\lambda-\\underline{{M}}/\\bar{\\lambda}\\right)\\right)^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\sqrt{\\lambda})}{n u^{2}}}\\right)}\\end{array}$ (   \nDO )2 20   \nD1( ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\hat{\\mathcal{V}}_{t}(\\hat{\\tau})-\\mathcal{V}_{t}(\\hat{\\tau})|\\leq\\mathcal{O}\\left(\\sqrt{\\frac{8\\bar{\\lambda}^{2}\\log\\frac{2}{\\delta}}{n u_{t}^{2}}C_{e x p}^{2}}\\right)+\\mathcal{O}\\left(\\sqrt{\\frac{2\\bar{\\lambda}^{2}\\log(\\frac{2}{\\delta})}{n u_{t}^{2}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Note that $u_{1}\\,=\\,P(T\\,=\\,1)$ and $u_{0}\\,=\\,P(T\\,=\\,0)$ $C_{e x p}\\;=\\;{\\bf1}_{\\{\\underline{{M}}\\leq\\bar{M}\\leq0\\}}\\exp\\left(\\bar{M}/\\bar{\\lambda}-{\\underline{{M}}}/{\\underline{{\\lambda}}}\\right)\\;+$ $\\mathbf{1}_{\\{M\\leq0,\\bar{M}\\geq0\\}}\\exp\\left(\\bar{M}/\\underline{{\\lambda}}-\\underline{{M}}/\\underline{{\\lambda}}\\right)+\\mathbf{1}_{\\{0\\leq M\\leq\\bar{M}\\}}\\exp\\left(\\bar{M}/\\underline{{\\lambda}}-\\underline{{M}}/\\bar{\\lambda}\\right)$ ", "page_idx": 27}, {"type": "text", "text": "C  Additional Materials ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "C.1Additional Explanations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Q1. Why DRM can select CATE estimators that are robust to the uncertainty in PEHE caused by selection bias and unobserved confounders?  In Section 3.1 and Section 4.1, we have presented theoretical explanations for the reason why DRM can measure a CATE estimator's robustness against selection bias and unobserved confounding. Below we will explain it more specifically. ", "page_idx": 27}, {"type": "text", "text": "In causal inference, all the CATE estimators are constructed on the observational factual data. But how reliable the CATE estimator that learned on factual data is? This question can be never known unless we have the knowledge of the oracle PEHE. As shown in equation (6), we know that the PEHE is equal to two $\\hat{\\tau}$ -dependentterms, $\\mathbb{E}[\\hat{\\tau}(X)Y^{t}|T=t]$ and $\\mathbb{E}[\\hat{\\tau}(X)Y^{t}|T=1-t]$ ", "page_idx": 27}, {"type": "text", "text": "Unfortunately, $\\mathbb{E}[\\hat{\\tau}(X)Y^{t}|T=1-t]$ is uncomputable empirically because we can only observe the factual distribution $P^{F}\\,=\\,P(X,^{\\prime}\\!Y^{t}|T\\,=\\,t)$ but not the counterfactual distribution $P^{C F}\\,=$ $P(X,Y^{t}|T=1-t)$ . The unobserved counterfactual distribution can be regarded as an uncertain distribution varying around the observed and certain factual distribution $P^{F}$ . If we could assume a \"God's perspective\" and observe $P^{C F}$ directly, the counterfactual distribution will be certain - like a quantum world! Such an uncertainty in $P^{C F}$ results in the uncertainty in PEHE. Now we will analyze the source of such uncertainty by analyzing the relationship between the uncertain distribution $P^{\\dot{C}F}$ and the certain distribution ${\\dot{P}}^{F}$ based on equation (2): ", "page_idx": 28}, {"type": "equation", "text": "$$\nP(X,Y^{t}|T=1-t)=P(X,Y^{t}|T=t){\\frac{P(Y^{t}|T=1-t,X)}{P(Y^{t}|T=t,X)}}{\\frac{P(X|T=1-t)}{P(X|T=t)}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "From above, we find the unobservable distribution $P(X,Y^{t}|T\\,=\\,1-t)$ is equal to the observable distribution $P(X,Y^{t}|T\\,=\\,t)$ multiplied with P(Y(T=1-t,x) P(XIT=1-t). In other words, $\\frac{p(y^{t}|T{=}1{-}t,x)}{p(y^{t}|T{=}t,x)}\\,\\frac{p(x|T{=}1{-}t)}{p(x|T{=}t)}$ controls the discrepancy between $P^{F}$ and $P^{C F}$ . Note that if there is no unmeasured confounders, then we have $p(y^{t}|T=1-t,x)=p(y^{t}|T=t,x)$ ; and if there is no selection bias (covariate shift), then we have $p(x|T=1-t)=p(x|T=t)$ . Now we understand the root cause of the discrepancy between $P^{F}$ and $P^{C F}$ (or between $\\mathbb{E}[\\tau(X)Y^{t}|T=1-t]$ and $\\mathbb{E}[\\tau(X)Y^{t}|T=t])$ lies at the unobserved confounders and selection bias (covariate shift). In the DRM method, the uncertainty caused by potential unobserved confounders and selection bias in PEHE can be further measured as the distributionally robust values $\\hat{\\mathcal{V}}^{1}$ and $\\hat{\\mathcal{V}}^{0}$ . Then the PEHE w.r.t. the CATE estimator $\\hat{\\tau}$ will be at most $\\mathcal{R}^{D R M}(\\dot{\\tau})$ , as shown in equation (15). An estimator $\\hat{\\tau}$ that attains smallest $\\mathcal{R}^{D R M}(\\hat{\\tau})$ by definition reflects the distributional robustness against potential unobserved confounders and selection bias. ", "page_idx": 28}, {"type": "text", "text": "Q2.Howtoset $\\epsilon^{*}$ when there are unobserved confounders?  When unobserved confounders are present, Proposition 3.6 can also provide guidance for setting $\\epsilon^{*}$ .Taking $\\epsilon_{1}^{*}=D_{K L}(P_{C}||P_{T})$ as an example,we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D k L(P_{C}||P_{T})}\\\\ &{=\\displaystyle\\int_{\\mathcal{X}}\\int_{\\mathcal{Y}^{0}}\\int_{\\mathcal{Y}^{1}}p(y^{0},y^{1}|x,T=0)p(x|T=0)\\log\\frac{p(y^{0},y^{1}|x,T=0)p(x|T=0)}{p(y^{0},y^{1}|x,T=1)p(x|T=1)}d y^{1}d y^{0}d x}\\\\ &{=\\displaystyle\\int_{\\mathcal{X}}\\left(\\int_{\\mathcal{Y}^{0}}\\int_{\\mathcal{Y}^{1}}p(y^{0},y^{1}|x,T=0)d y^{1}d y^{0}\\right)p(x|T=0)\\log\\frac{p(x|T=0)}{p(x|T=1)}d x}\\\\ &{\\quad+\\displaystyle\\int_{\\mathcal{X}}\\int_{\\mathcal{Y}^{0}}\\int_{\\mathcal{Y}^{1}}p(y^{0},y^{1}|x,T=0)p(x|T=0)\\log\\frac{p(y^{0},y^{1}|x,T=0)}{p(y^{0},y^{1}|x,T=1)}d y^{1}d y^{0}d x}\\\\ &{=D_{K L}(P(X|T=0)|P(X|T=1))}\\\\ &{\\quad+\\displaystyle\\int_{\\mathcal{X}}\\int_{\\mathcal{Y}^{0}}\\int_{\\mathcal{Y}^{1}}p(y^{0},y^{1}|x,T=0)p(x|T=0)\\log\\frac{p(y^{0},y^{1}|x,T=0)}{p(y^{0},y^{1}|x,T=1)}d y^{1}d y^{0}d x}\\\\ &{>D_{K L}(P_{c}^{\\top}|P_{T}^{X})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Therefore, when unobserved confounders present, we can set $\\epsilon^{*}$ to a larger value than the one guided by Proposition 4.6. Simultaneously, as the empirical approximation of $\\epsilon_{1}^{*}=D_{K L}(P_{X}^{C}||P_{X}^{\\tilde{T}})$ and $\\epsilon_{0}^{*}=D_{K L}(P_{X}^{T}||P_{X}^{C})$ can be biased, we also suggest set $\\epsilon^{*}$ to a large value than the empiricallycomputed ones to ensure the ambiguity set is large enough to contain the target distribution. Therefore, we generally set $\\epsilon_{1}^{*}=D_{K L}(P_{X}^{C}||P_{X}^{\\tilde{T}})+5.2$ and $\\epsilon_{0}^{*}=\\bar{D}_{K L}(P_{X}^{T}||P_{X}^{C})+\\bar{5}.2$ for all settings in our experiment. Theoretically, a larger $\\epsilon^{*}$ should guarantee the DRM-selected estimator to be more robust, as it allows for a broader range of possible counterfactual distributions in the ambiguity set. However, setting $\\epsilon^{*}$ too large can result in overly conservative estimator selection (similar to the well-known accuracy-robustness tradeoff). Therefore, how to determine a proper ambiguity radius still remains an open challenge in both our work and distributionally robust optimization literature. ", "page_idx": 28}, {"type": "text", "text": "C.2  Hyperparameters ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u00b7 For linear model, we use LogisticRegressionCV and RidgeCV (both are with 3-fold crossvalidation) from sklearn package to tune hyperparameters: Logistic regression: $C s\\in\\{0.01$ 0.1, 1, 10); Ridge Regression: $\\alpha\\in\\{0.01,0.1,1,10,100\\}$ ", "page_idx": 28}, {"type": "text", "text": "\u00b7 For Neural Net, we set the hidden layers as [200, 200, 200, 100, 100], each with the ReLU activation function. The model is trained using the Adam optimizer with a learning rate of 0.001, a batch size of 64, and 300 epochs.   \n\u00b7 For RF, XGBoost, and SVM model, we use AutoML [71, 53] (with 3-fold cross-validation) from flaml package to tune hyperparameters. ", "page_idx": 29}, {"type": "text", "text": "C.3  The Complementary Results ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "First, we would like to emphasize that the experimental results in this final version of the paper differ from those in the original version. We made several revisions based on the feedback from anonymous reviewers: 1) We add Neural Net model to the base ML models and add the U-learner to the meta-learners, increasing the number of CATE estimators from 24 to 36; 2) We adopted AutoML for hyperparameter tuning when training SVM, RF, and XGBoost. All code is available at https: //github.com/yiyhuang3/CATE_estimator_selection. ", "page_idx": 29}, {"type": "text", "text": "Below, we prsent the complementary PEHE results for 36 candidate CATE estimators, where the candidate pool contains $4\\,\\mathrm{ML}$ models (LR, SVM, RF, and Neural Net) $\\times\\:9$ learners (U-, S-, T-, PS-, IPW-, X-, DR-, R-, RA-). ", "page_idx": 29}, {"type": "table", "img_path": "k4EP46Q9X2/tmp/60e07e6e57c7bb730bcd1bb76e2d201f430d569673d2d6c65fd40b56b98dd78f.jpg", "table_caption": ["Table 3: Comparison of PEHE for different selectors across Settings A, B, and C (Note that B $(\\xi=1)$ matchesA $(\\rho=0.1)$ ), with base model for CATE estimator being {LR, SVM, RF, Net}. Reported values (mean $\\pm$ standard deviation) are computed over 100 experiments. Smaller is better. "], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] Justification: [Yes] ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] Justification: [Yes] ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] Justification: [Yes] ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 31}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with suficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: [Yes] Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 32}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: [Yes] Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 32}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] Justification: [Yes] ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 33}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] Justification: [Yes] Guidelines: ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 33}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 33}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faitheffort. ", "page_idx": 34}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 35}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 35}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 35}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 35}]