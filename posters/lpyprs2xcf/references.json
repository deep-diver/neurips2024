{"references": [{"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides foundational algorithms for linear stochastic bandits, which are crucial building blocks for the algorithms used in the current paper."}, {"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model", "publication_date": "2013-01-01", "reason": "This paper establishes fundamental theoretical limits on reinforcement learning, providing a context for evaluating the efficiency of the current paper's algorithms."}, {"fullname_first_author": "Alex Ayoub", "paper_title": "Model-based reinforcement learning with value-targeted regression", "publication_date": "2020-01-01", "reason": "This paper introduces the linear mixture MDP framework, which is the specific problem setting addressed by the current research."}, {"fullname_first_author": "Chi Jin", "paper_title": "Is Q-learning provably efficient?", "publication_date": "2018-01-01", "reason": "This paper investigates the theoretical efficiency of Q-learning, a key algorithm in reinforcement learning, providing a basis for understanding algorithm efficiency in the context of the current study."}, {"fullname_first_author": "Sham M. Kakade", "paper_title": "Approximately optimal approximate reinforcement learning", "publication_date": "2002-01-01", "reason": "This paper presents fundamental results on approximate reinforcement learning, which are important for understanding the challenges and opportunities in using function approximation, a core component of the current paper's approach."}]}