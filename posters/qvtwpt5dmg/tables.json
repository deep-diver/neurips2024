[{"figure_path": "QVtwpT5Dmg/tables/tables_4_1.jpg", "caption": "Table 1: A subset of propositions used in our Safety RBR. (See Appendix Table 13 for the full list)", "description": "This table lists a subset of the propositions used in the Rule-Based Reward (RBR) system described in the paper.  Propositions are binary statements about a model's response to a given prompt, such as whether the response contains an apology, is judgmental, or provides a complete answer.  These propositions are used to construct rules that define desirable or undesirable model behaviors for different types of user requests (e.g., safe, unsafe, etc.). The full list of propositions is available in Appendix Table 13.", "section": "4.1 Elements of RBRS"}, {"figure_path": "QVtwpT5Dmg/tables/tables_5_1.jpg", "caption": "Table 3: RBR Training Datasets Summary", "description": "This table summarizes the three datasets used in training the Rule-Based Rewards (RBR) model.  It specifies whether each dataset is human-labeled or automatically generated, the size of the dataset, and a brief description of its contents. The Ps dataset contains safety-relevant prompts, the Gold dataset is a small set of human-labeled data for tuning the classification prompts for the RBR model, and the DRBR dataset is synthetically generated data for fitting the RBR weights.", "section": "3 Setting and Terminology"}, {"figure_path": "QVtwpT5Dmg/tables/tables_8_1.jpg", "caption": "Table 4: Safety evaluation results on an internal safety metric and human evaluation metrics.", "description": "This table presents the results of safety evaluations performed using both internal automated metrics and human evaluations.  It compares three different model training approaches: Helpful-PPO (a baseline using only helpful data), Human-PPO (a baseline incorporating human-labeled safety data), and RBR-PPO (the proposed method using rule-based rewards). The metrics evaluated include Not-Unsafe (percentage of completions without unsafe content), Not-Overrefuse (percentage of safe prompts not refused), and an F1-score combining both safety and usefulness metrics. The results show that RBR-PPO achieves a good balance between safety and usefulness compared to the baselines.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_8_2.jpg", "caption": "Table 5: Safety results on XSTest, WildChat. The Not-Overrefuse and Not-Unsafe metrics are measured using RBR propositions. Additionally, we also give capability evaluation on common capability benchmarks.", "description": "This table presents the results of safety and capability evaluations on three different models: Helpful-only, Human-feedback, and RBR-trained models.  The safety evaluations are conducted on two datasets, XSTest and WildChat, measuring over-refusal and unsafe content respectively, using both automated and manual metrics (Not-Overrefuse and Not-Unsafe). Capability is assessed on four standard benchmarks: MMLU, Lambada, HellaSwag, and GPQA. The results highlight the trade-off between safety and capability, showcasing the RBR model's ability to balance safety and functionality.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_12_1.jpg", "caption": "Table 14: Propositions used for each Completion type and Class.", "description": "This table shows the propositions used in the Rule-Based Reward (RBR) system for each completion type (Hard Refusal, Soft Refusal, Comply) and class (Ideal, Minimum Acceptable Style, Unacceptable Completion, Illogical Completion, Disallowed Completion).  For each proposition, the table indicates whether it's desired (+) or undesired for each class.  It also notes the total number of propositions and features used in the weight fitting process.  The table helps to understand the fine-grained control exerted by the RBR system over different aspects of the model's response. ", "section": "4.1 Elements of RBRS"}, {"figure_path": "QVtwpT5Dmg/tables/tables_14_1.jpg", "caption": "Table 7: PPO Prompts and RBR Gold per Response Type", "description": "This table presents the breakdown of the number of prompts used for training and testing in different response types (Comply, Hard Refuse, and Soft Refuse).  It shows the counts from the human baseline, the RBR training data (which uses automatically generated labels), and the agreement rate between human and automatically generated labels.  Finally, it shows how many prompts in each type were used for creating the Gold set for prompt tuning.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_18_1.jpg", "caption": "Table 8: Example Response Type Based on Content Type (Behavior Policy)", "description": "This table shows example response types that are expected based on the content and behavior policies defined in the paper.  It breaks down several content areas (Erotic, Criminal Advice, Hate Speech, Self-Harm) and shows, for each, different response types (Comply, Hard Refuse, Soft Refuse) with example responses.  The table illustrates how the model's response should vary depending on the type of user request and the predefined safety guidelines.", "section": "3.1 Content and Behavior Policies in Our Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_18_2.jpg", "caption": "Table 9: Raw results with Standard Error for Plots", "description": "This table presents the detailed results for the key metrics (Refusal-Style, Not-Overrefuse, Not-Unsafe, F1-Score) from several model training approaches.  It compares the performance of different methods, including baselines (Helpful-SFT, Human-SFT, Old Data-SFT), standard RLHF (Helpful-PPO, Human-PPO, Old Data-PPO), and the proposed RBR method (RBR-PPO, HumanRM+RBR PPO, Human-matchRBR-PPO, Old Data+RBR-PPO). It also includes ablation study results (RBR-Fixed1-PPO, RBR-Fixed10-PPO, SFTOnly-noRBR-PPO, RBR-noRM-PPO, RBR-noSFT-PPO) to analyze the impact of different design choices.  The results shown are averages across multiple checkpoints with standard errors, offering a comprehensive evaluation of various aspects of model safety and helpfulness.", "section": "Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_19_1.jpg", "caption": "Table 10: Experimental Settings", "description": "This table details the experimental settings used in the paper.  It specifies the model size (Large, Medium, Small, XSmall), the type of SFT data used (Helpful, Helpful, Human, Synthetic, Old Safety, Limited Human), the reward model used (Helpful, Human, RBR, Old Safety), the PPO prompts used (Helpful, Safety), and any additional notes on the experiment (Baseline, Human Data Baseline, RBRs, Outdated safety data, Matches RBR data size, No RBR used, No safety SFT data, No RM score for safety prompts, Safety prompts are fixed, amount may vary). The table is divided into two parts: main experiments and ablation studies. The ablation studies examine the effects of changing various aspects of the training process, such as the type and amount of data used, the reward model, and the inclusion or exclusion of safety RBRs.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_20_1.jpg", "caption": "Table 7: PPO Prompts and RBR Gold per Response Type", "description": "This table breaks down the number of prompts per response type (Comply, Hard Refuse, Soft Refuse) used in the training and testing sets for both the PPO (reinforcement learning) and RBR (rule-based reward) models.  It shows the number of prompts with human-provided labels, automatically generated labels, and the agreement rate between the two labeling methods. The table also indicates the number of prompts from the human-labeled Gold set, used for tuning the classification prompts for RBRs.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_20_2.jpg", "caption": "Table 12: Some example samples from Large sized models for different prompt types", "description": "This table provides examples of model responses to different prompt types (Comply, Hard Refusal, Soft Refusal) from three different model setups: Helpful-PPO Baseline, Human-PPO Baseline, and RBR-PPO.  It illustrates how the models respond to requests that should be complied with, those that require a strong refusal due to safety concerns, and those that should receive an empathetic but firm refusal. The \"Ideal\" column indicates whether the response is considered the ideal response according to the paper's criteria.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_20_3.jpg", "caption": "Table 9: Raw results with Standard Error for Plots", "description": "This table presents the quantitative results of several experiments comparing different model training methods.  It shows the performance metrics (Refusal-Style, Not-Overrefuse, Not-Unsafe, and F1-Score) for each model, highlighting the differences in safety and helpfulness across various approaches (e.g., Helpful-Only, Human, and RBR-based models).  The F1-score is particularly important as it balances safety and usefulness.  The table also includes results for ablation studies investigating the impact of varying training parameters and data sources.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_20_4.jpg", "caption": "Table 9: Raw results with Standard Error for Plots", "description": "This table presents the raw numerical results from several experiments comparing different model configurations.  It includes standard errors for each metric, allowing for a better understanding of the variability in the results. The models being compared include baselines using only helpful data, models trained with human safety data, and models utilizing the Rule-Based Rewards (RBR) method. The metrics evaluated are related to safety (e.g., avoiding unsafe content, not over-refusing), refusal style, and the F1 score which combines safety and usefulness.", "section": "5 Experiments"}, {"figure_path": "QVtwpT5Dmg/tables/tables_21_1.jpg", "caption": "Table 14: Propositions used for each Completion type and Class.", "description": "This table lists the propositions used in the Rule-Based Rewards (RBR) system for classifying different completion types (Hard Refusal, Soft Refusal, Comply) into classes based on the presence or absence of specific features.  Each proposition represents a characteristic of the model's response (e.g., contains an apology, uses threatening language, provides resources). The table shows whether each proposition is considered \"desired\" or \"undesired\" for each class.  This helps define the desired behavior of the model for various situations.", "section": "4.1 Elements of RBRS"}, {"figure_path": "QVtwpT5Dmg/tables/tables_22_1.jpg", "caption": "Table 14: Propositions used for each Completion type and Class.", "description": "This table shows the propositions used in the Rule-Based Reward (RBR) system, categorized by their desirability for each of the three completion types (Hard Refusal, Soft Refusal, Comply).  It indicates whether each proposition is considered acceptable, undesirable, required, or a feature used for weight fitting.  The table also provides the total number of propositions used for each completion type and the total number of features used in the RBR weight fitting process.", "section": "4.1 Elements of RBRS"}, {"figure_path": "QVtwpT5Dmg/tables/tables_22_2.jpg", "caption": "Table 15: Proposition Evaluation Accuracy by Model Size", "description": "This table presents the accuracy of proposition evaluation for different model sizes (XSmall, Small, Medium, Large).  Each row represents a proposition (e.g., \"Apology,\" \"Disallowed Content\"), and the columns show the accuracy of that proposition's classification for each model size.  The accuracy is expressed as a percentage with a standard error. The table illustrates how the accuracy of identifying various aspects of model responses improves as the model size increases.", "section": "A.1.3 RBR Propositions"}]