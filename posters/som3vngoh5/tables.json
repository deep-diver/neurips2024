[{"figure_path": "SoM3vngOH5/tables/tables_7_1.jpg", "caption": "Table 1: Fraction of Jailbreaks Achieved as per the GPT4-Metric. For each method and target LLM, we report (1) the fraction of jailbreaks found on AdvBench Subset according to GPT4-Metric and (2) the number of queries sent to the target LLM in the process. For both TAP and PAIR we use Vicuna-13B-v1.5 as the attacker. The best result for each model is bolded. The success rate of PAIR in our evaluations differs from those in [12]; see Remark A.1. Results for GCG are as in [12].", "description": "This table presents the results of jailbreaking different LLMs using three different methods: TAP (the proposed method), PAIR (a state-of-the-art method), and GCG (another state-of-the-art method).  For each LLM and method, the table shows the percentage of successful jailbreaks and the average number of queries needed to achieve a successful jailbreak.  The results highlight TAP's superior performance in achieving a higher success rate while requiring fewer queries compared to other methods. Note that there is a discrepancy between the success rates of PAIR reported in this paper and in the original paper [12], explained in Remark A.1. GCG results are taken directly from [12] since it requires white-box access, unlike TAP and PAIR.", "section": "Empirical Evaluation of Performance and Query Efficiency"}, {"figure_path": "SoM3vngOH5/tables/tables_7_2.jpg", "caption": "Table 1: Fraction of Jailbreaks Achieved as per the GPT4-Metric. For each method and target LLM, we report (1) the fraction of jailbreaks found on AdvBench Subset according to GPT4-Metric and (2) the number of queries sent to the target LLM in the process. For both TAP and PAIR we use Vicuna-13B-v1.5 as the attacker. The best result for each model is bolded. The success rate of PAIR in our evaluations differs from those in [12]; see Remark A.1. Results for GCG are as in [12].", "description": "This table presents the success rate and query efficiency of three different methods (TAP, PAIR, and GCG) for jailbreaking several LLMs (Vicuna, Llama-7B, GPT-3.5, GPT-4, GPT-4-Turbo, GPT-40, PaLM2, GeminiPro, and Claude3).  The success rate is measured using the GPT4-Metric, which uses GPT-4 to judge the success or failure of a jailbreak attempt.  The table shows that TAP consistently outperforms PAIR in terms of success rate while using fewer queries.  The comparison to GCG, a white-box method, highlights the effectiveness of TAP as a black-box method.", "section": "Empirical Evaluation of Performance and Query Efficiency"}, {"figure_path": "SoM3vngOH5/tables/tables_8_1.jpg", "caption": "Table 4: Effect of Branching and Pruning. Evaluation of TAP and variants that do not perform branching and pruning respectively. The setup is identical to Table 1. The best results are bolded.", "description": "This table presents the results of an ablation study on the TAP model. Three versions of the TAP model were tested: the original TAP model, a version without pruning (TAP-No-Prune), and a version without branching (TAP-No-Branch).  The goal was to determine the impact of branching and pruning on the model's performance. The results show that both branching and pruning are crucial for achieving a high success rate and query efficiency.  Specifically, removing pruning significantly reduces the query efficiency, while removing branching substantially reduces the success rate.", "section": "Empirical Evaluation of the Effects of Branching and Pruning"}, {"figure_path": "SoM3vngOH5/tables/tables_31_1.jpg", "caption": "Table 8: Fraction of Jailbreaks Achieved as per Human-Judgement. For each target LLM and method pair, we report the fraction of jailbreaks achieved on AdvBench Subset according to Human-Judgement (as defined in Section 5). For both TAP and PAIR we use Vicuna-13B-v1.5 as the attacker and GPT4 as the evaluator. In each column, the best results are bolded.", "description": "This table presents the success rates of TAP and PAIR methods in jailbreaking different LLMs according to human evaluation.  Human judges assessed whether the generated responses qualified as successful jailbreaks based on criteria defined in Section 5 of the paper.  Vicuna-13B-v1.5 was used as the attacker LLM, and GPT-4 served as the evaluator LLM for both methods. The table highlights the percentage of successful jailbreaks achieved for each LLM and method, allowing for a direct comparison of their effectiveness.", "section": "Additional Results of Empirical Study"}, {"figure_path": "SoM3vngOH5/tables/tables_31_2.jpg", "caption": "Table 1: Fraction of Jailbreaks Achieved as per the GPT4-Metric. For each method and target LLM, we report (1) the fraction of jailbreaks found on AdvBench Subset according to GPT4-Metric and (2) the number of queries sent to the target LLM in the process. For both TAP and PAIR we use Vicuna-13B-v1.5 as the attacker. The best result for each model is bolded. The success rate of PAIR in our evaluations differs from those in [12]; see Remark A.1. Results for GCG are as in [12].", "description": "This table presents the results of jailbreaking different LLMs using three different methods: TAP (the proposed method), PAIR (a state-of-the-art method), and GCG (another state-of-the-art method). For each LLM and method, the table shows the percentage of successful jailbreaks and the average number of queries required to achieve a successful jailbreak. The results show that TAP significantly outperforms both PAIR and GCG in terms of success rate, especially for more advanced LLMs like GPT4 and GPT4-Turbo.", "section": "Evaluation of Performance and Query Efficiency"}, {"figure_path": "SoM3vngOH5/tables/tables_32_1.jpg", "caption": "Table 1: Fraction of Jailbreaks Achieved as per the GPT4-Metric. For each method and target LLM, we report (1) the fraction of jailbreaks found on AdvBench Subset according to GPT4-Metric and (2) the number of queries sent to the target LLM in the process. For both TAP and PAIR we use Vicuna-13B-v1.5 as the attacker. The best result for each model is bolded. The success rate of PAIR in our evaluations differs from those in [12]; see Remark A.1. Results for GCG are as in [12].", "description": "This table presents the success rate (percentage of prompts successfully jailbroken) and the average number of queries needed to achieve a jailbreak for different LLMs (Vicuna, Llama-7B, GPT3.5, GPT4, GPT4-Turbo, GPT40, PaLM-2, GeminiPro, Claude3-Opus) using three different methods: TAP (Tree of Attacks with Pruning), PAIR (Prompt Automatic Iterative Refinement), and GCG (Gradient-based method).  The best-performing method for each LLM is highlighted in bold.", "section": "Evaluation of Performance and Query Efficiency"}]