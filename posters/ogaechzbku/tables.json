[{"figure_path": "ogaeChzbKu/tables/tables_1_1.jpg", "caption": "Table 1: Summary of features of several representative watermark techniques. The second column denotes the method's suitability for real-time on-the-fly implementation. / denotes cases where the watermark is embedded during the generative process. The third column evaluates whether the watermarking method provides provable guarantees on false-positive rates (FPRs) under adversarial attacks in a distribution-free manner.", "description": "This table compares several watermarking methods based on three key features: whether they are model-agnostic (meaning they work on images generated by any AI model), whether they can be deployed on-the-fly (meaning the watermark can be added to an image immediately after it is generated), and whether they offer provable guarantees on the False Positive Rate (FPR) even if someone tries to remove the watermark.  A checkmark indicates that the method satisfies the feature, an X indicates it does not, and a slash (/) means it is sometimes true, depending on how the method is used.", "section": "1 Introduction"}, {"figure_path": "ogaeChzbKu/tables/tables_7_1.jpg", "caption": "Table 2: Summary of main results. 'N-ROC' denotes the AUROC performance without image manipulations or adversarial attacks. \u2018Ad-ROC' represents the average performance across nine distinct image manipulations and attacks. The 'Encoding Speed' column denotes the efficiency of injecting watermarks into images post-training, measured in seconds (CPU time) per image.", "description": "This table summarizes the main results of the proposed RAW watermarking framework and compares its performance with other state-of-the-art methods.  It shows the AUROC (Area Under the Receiver Operating Characteristic curve) scores for both benign conditions and under various adversarial attacks (Ad-ROC). Encoding speed (in seconds per image) is also compared across methods.  Finally, image quality is assessed using Fr\u00e9chet Inception Distance (FID) and CLIP scores.", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_7_2.jpg", "caption": "Table 3: AUROC performance of state-of-the-art methods under 9 (adversarial) image manipulations: Rotation 90\u00b0, Cropping and resizing 70%, Gaussian Blur with a kernel size of (7,9) and bandwidth of 4, Noise with IID mean Gaussian \u03c3 = 0.05, Jitter with brightness factor 0.6, JPEG compression with quality 50, and 3 attacks (VAE Att1, VAE Att2, Diff Att).", "description": "This table presents the Area Under the Receiver Operating Characteristic (AUROC) scores for various watermarking methods under nine different image manipulations or attacks. These manipulations include common image distortions like rotation, cropping, blurring, and adding noise, as well as three adversarial attacks designed to remove watermarks.  The results show how robust each method is against these manipulations, with higher AUROC scores indicating better robustness.  The table is separated by datasets (MS-COCO and DBDiffusion).", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_8_1.jpg", "caption": "Table 2: Summary of main results. 'N-ROC' denotes the AUROC performance without image manipulations or adversarial attacks. \u2018Ad-ROC' represents the average performance across nine distinct image manipulations and attacks. The 'Encoding Speed' column denotes the efficiency of injecting watermarks into images post-training, measured in seconds (CPU time) per image.", "description": "This table summarizes the main results of the RAW watermarking framework, comparing its performance to other methods. It shows the Area Under the ROC Curve (AUROC) for both normal conditions ('N-ROC') and under nine different adversarial attacks ('Ad-ROC').  The encoding speed is also provided, showcasing the efficiency of RAW in embedding watermarks.  The table also includes the Fr\u00e9chet Inception Distance (FID) and CLIP scores which are used to measure the quality of the watermarked images.  The lower the FID, the better the image quality.  CLIP score indicates how well generated images align with the text prompt used.", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_9_1.jpg", "caption": "Table 2: Summary of main results. 'N-ROC' denotes the AUROC performance without image manipulations or adversarial attacks. \u2018Ad-ROC' represents the average performance across nine distinct image manipulations and attacks. The 'Encoding Speed' column denotes the efficiency of injecting watermarks into images post-training, measured in seconds (CPU time) per image.", "description": "This table summarizes the main results of the RAW watermarking framework, comparing its performance to other state-of-the-art methods across two datasets (MS-COCO and DBdiffusion).  It shows the AUROC (Area Under the ROC Curve) scores for both normal conditions and under nine different adversarial attacks or manipulations.  Encoding speed (in seconds per image) is also compared, demonstrating RAW's efficiency.  Finally, Fr\u00e9chet Inception Distance (FID) and CLIP scores are included to assess image quality.", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_15_1.jpg", "caption": "Table 2: Summary of main results. 'N-ROC' denotes the AUROC performance without image manipulations or adversarial attacks. \u2018Ad-ROC' represents the average performance across nine distinct image manipulations and attacks. The 'Encoding Speed' column denotes the efficiency of injecting watermarks into images post-training, measured in seconds (CPU time) per image.", "description": "This table summarizes the main experimental results, comparing the performance of RAW against other watermarking methods.  It shows the Area Under the Receiver Operating Characteristic (AUROC) scores for both normal conditions ('N-ROC') and under nine different types of image manipulations or attacks ('Ad-ROC').  Additionally, it provides the speed of watermark embedding (in seconds per image) for each method.  Lower encoding speed values are better.", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_17_1.jpg", "caption": "Table 2: Summary of main results. 'N-ROC' denotes the AUROC performance without image manipulations or adversarial attacks. \u2018Ad-ROC' represents the average performance across nine distinct image manipulations and attacks. The 'Encoding Speed' column denotes the efficiency of injecting watermarks into images post-training, measured in seconds (CPU time) per image.", "description": "This table summarizes the main results of the RAW watermarking framework, comparing its performance with other state-of-the-art methods across two datasets (MS-COCO and DBdiffusion).  It shows the Area Under the Receiver Operating Characteristic (AUROC) scores under both normal conditions ('N-ROC') and after applying nine different image manipulations/adversarial attacks ('Ad-ROC').  Additionally, it presents the time taken for watermark injection (encoding speed) per image, demonstrating RAW's efficiency.", "section": "4 Experiments"}, {"figure_path": "ogaeChzbKu/tables/tables_18_1.jpg", "caption": "Table 6: Additional metrics for image quality.", "description": "This table presents Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) values for watermarked images generated using different watermarking methods on the MS-COCO and DBdiffusion datasets.  Higher PSNR and SSIM values indicate better image quality after watermarking.  The results show that RAW achieves comparable PSNR to StegaStamp but lower than DwtDctSvd and RivaGAN, while maintaining good SSIM scores.", "section": "B.3 Additional metrics on image quality"}, {"figure_path": "ogaeChzbKu/tables/tables_19_1.jpg", "caption": "Table 7: Summary of detection results under different model architectures. AUROC (Ben) denotes the AUROC performance without image manipulations or adversarial attacks. AUROC (Adv) represents the average performance across nine distinct image manipulations and attacks.", "description": "This table presents the Area Under the Receiver Operating Characteristic (AUROC) scores for different model architectures used in the watermark detection system.  It shows performance both without any image manipulations (AUROC (Ben)) and with nine different manipulations or adversarial attacks (AUROC (Adv)). The goal is to compare the robustness and accuracy of the detection system using various model architectures.", "section": "D.1 Verification module/model architectures"}, {"figure_path": "ogaeChzbKu/tables/tables_20_1.jpg", "caption": "Table 8: Summary of detection results under numbers of training data. AUROC (Ben) denotes the AUROC performance without image manipulations or adversarial attacks. AUROC (Adv) represents the average performance across nine distinct image manipulations and attacks.", "description": "This table presents the results of an ablation study on the effect of varying the size of the watermarked training dataset used to fine-tune a pre-trained watermarking and verification model. The results are shown for both the MS-COCO and DBDiffusion datasets, separating performance under benign conditions (AUROC (Ben)) from that under nine distinct image manipulations and adversarial attacks (AUROC (Adv)). The table demonstrates that satisfactory performance can be achieved with a reasonably small training dataset.", "section": "D.2 Size of watermarked training data under fine-tuning scenario"}, {"figure_path": "ogaeChzbKu/tables/tables_20_2.jpg", "caption": "Table 9: Summary of detection results under numbers of training data. AUROC (Ben) denotes the AUROC performance without image manipulations or adversarial attacks. AUROC (Adv) represents the average performance across nine distinct image manipulations and attacks.", "description": "This table presents the Area Under the Receiver Operating Characteristic (AUROC) scores for watermark detection.  It compares the performance with benign images (no attacks or manipulations) and with images subjected to nine types of attacks and manipulations.  The results are broken down by the dataset used (MS-COCO and DBdiffusion) and the generative model used (SDXL and BriXL).", "section": "D.3 Different diffusion models for generating images"}]