[{"type": "text", "text": "Fine-Grained Dynamic Framework for Bias- Variance Joint Optimization on Data Missing Not at Random ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mingming Ha Xuewen Tao Wenfang Lin MYbank, Ant Group MYbank, Ant Group MYbank, Ant Group Beijing, China Shanghai, China Hangzhou, China hamingming.hmm@mybank.cn xuewen.txw@mybank.cn moxi.lwf@mybank.cn ", "page_idx": 0}, {"type": "text", "text": "Qiongxu Ma Wujiang Xu Linxun Chen MYbank, Ant Group MYbank, Ant Group MYbank, Ant Group Shanghai, China Shanghai, China Beijing, China qiongxu.mqx@mybank.cn xuwujiang.xwj@mybank.cn linxun.clx@mybank.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In most practical applications such as recommendation systems, display advertising, and so forth, the collected data often contains missing values and those missing values are generally missing-not-at-random, which deteriorates the prediction performance of models. Some existing estimators and regularizers attempt to achieve unbiased estimation to improve the predictive performance. However, variances and generalization bound of these methods are generally unbounded when the propensity scores tend to zero, compromising their stability and robustness. In this paper, we first theoretically reveal that limitations of regularization techniques. Besides, we further illustrate that, for more general estimators, unbiasedness will inevitably lead to unbounded variance. These general laws inspire us that the estimator designs is not merely about eliminating bias, reducing variance, or simply achieve a bias-variance trade-off. Instead, it involves a quantitative joint optimization of bias and variance. Then, we develop a systematic finegrained dynamic learning framework to jointly optimize bias and variance, which adaptively selects an appropriate estimator for each user-item pair according to the predefined objective function. With this operation, the generalization bounds and variances of models are reduced and bounded with theoretical guarantees. Extensive experiments are conducted to verify the theoretical results and the effectiveness of the proposed dynamic learning framework. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In virtually all real-world applications, the pieces of data we collected are partially missing with certain probabilities. A special case with the identical missing probability is known as missing at random (MAR) [1]. However, in online recommendation, search, and display advertising, there are lots of missing-not-at-random (MNAR) click, conversion, and rating records [2, 3, 4], which are missing with different probabilities, i.e., propensities. For example, in recommendation systems, a user usually clicks the items that she/he is likely to purchase and ignores other items with a low willingness to buy. Therefore, the observed click and conversion data is MNAR, which are not representative samples of all the events [5]. When the MNAR data is used to train a model, the prediction performance of this model on the MAR data is generally unacceptable. This is because MNAR data introduces sample selection bias [3, 6] into the prediction model. To eliminate sample selection bias, lots of debiasing estimators [3, 6, 7, 8, 9] have been developed, e.g., Error-Imputation", "page_idx": 0}, {"type": "text", "text": "Based (EIB) approach [10], Inverse Propensity-Scoring (IPS) technique [6], Doubly Robust (DR) method [11], and so forth. ", "page_idx": 1}, {"type": "text", "text": "However, in almost all debiased methods, the existence of propensities results in the high variance and generalization bound. [11, 12]. Therefore, various methods [5, 8, 12] have been developed to reduce estimation variances and improve the model stability. Even so, they still suffer from unbounded variances and generalization bounds when the propensity tends to zero. For the high variance and generalization bound caused by small propensities, some approaches compromise to self-normalized technique [12, 13] at the expense of unbiasedness. In addition, the overwhelming majority of previous works focus on the specific designs of the estimators or regularizers to reduce variance or eliminate bias while neglecting both the bias-variance relationship of estimators and the essence of the estimator designs. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we reveal limitations of general regularization techniques. We find that it is impossible to reduce variance without sacrificing unbiasedness by introducing regularizers, and that regularization cannot guarantee estimators to have bounded variance and generalization bound. Besides, for general estimators, unbiasedness will inevitably result in unbounded variance and generalization bound. To some extent, the generalization bound can reflect the predictive performance of an estimator. Therefore, reducing and bounding the generalization bound can assist in improving the predictive performance of models. Since the generalization bounds of estimators contain the bias and variance terms, the essence of estimator design is not merely about eliminating bias, reducing variance, or simply achieving a bias-variance trade-off but about the quantitative joint optimization of bias and variance. Then, we develop a systematic dynamic learning framework to achieve this objective. To the best of our knowledge, this is the first work to systematically reveal limitations of general regularizers and the design perspective of the quantitative bias-variance joint optimization. Our main contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "1) We theoretically elaborate limitations of regularization techniques, and the relationship of unbiasedness, variance and generalization bound of general estimators.   \n2) Based on the general laws, we elaborate a novel design perspective for the estimator, namely the quantitative bias-variance joint optimization;   \n3) We develop a comprehensive dynamic learning framework with the bounded variances and generalization error to optimize a weighted objective with respect to bias and variance for each user-item pair $(u,i)$ , which dynamically selects different estimators for different user-item pair from a family of estimators according to the given objective function;   \n4)  We conduct extensive experiments to verify the theoretical results and the performance of the dynamic regularizer and estimators. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Data missing not at random. Denote the sets of users and items as $\\mathcal{U}=\\{u_{1},u_{2},\\dotsc,u_{M}\\}$ and $\\bar{\\mathcal{Z}}=\\{i_{1},i_{2},\\bar{...}\\cdot,i_{N}\\}$ , respectively. The set of all user-item pairs is denoted as $\\mathcal{D}=\\mathcal{U}\\times\\mathcal{T}$ Define the true and prediction matrices as $Y\\in\\mathbb{R}^{M\\times N}$ and $\\hat{Y}\\in\\mathbb{R}^{M\\times N}$ , where prediction tasks include rating, CTR and CVR predictions, and so forth. Each element $y_{u,i}$ in $Y$ and each entry $\\hat{y}_{u,i}$ in $\\hat{Y}$ are the true label and predicted output of a user $u$ to an item $i$ In general, it is impossible to observe all entries in the matrix $Y$ . The indicator entry of revealed elements is defined as $o_{u,i}\\in\\{0,1\\}$ . If the true label $y_{u,i}$ is revealed, the indicator entry of $(u,i)$ satisfies $o_{u,i}=1$ . If an entry in $Y$ is missing, then $o_{u,i}=0$ . The corresponding indicator set is denoted as $\\mathcal{O}=\\{o_{u,i}=1\\}$ . Considering the case that no entries are missing, the prediction inaccuracy [11] of $\\hat{Y}$ is defined as ", "page_idx": 1}, {"type": "equation", "text": "$$\nL_{\\mathrm{real}}(\\hat{Y},Y)=\\frac{1}{M N}\\sum_{u=1}^{M}\\sum_{i=1}^{N}e_{u,i}=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $e_{u,i}$ is the prediction error. $e_{u,i}$ can be selected as mean absolute error (MAE), mean square error (MSE) or other measures. The objective of prediction problems is to minimize the prediction inaccuracy $L_{\\mathrm{real}}(\\hat{Y},Y)$ [5, 7, 8, 11, 12, 14]. Actually, only the observed label set $Y^{o}$ can be used to establish the prediction model. The naive approach uses $Y^{o}$ to minimize the following prediction inaccuracy: ", "page_idx": 1}, {"type": "equation", "text": "$$\nL_{\\mathrm{naive}}(\\hat{Y},Y^{o})=\\frac{1}{|\\mathcal{O}|}\\sum_{(u,i)\\in\\mathcal{O}}e_{u,i}=\\frac{1}{|\\mathcal{O}|}\\sum_{(u,i)\\in\\mathcal{D}}o_{u,i}e_{u,i}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "As mentioned in [11], if the probability of every entry $y_{u,i}$ in $Y$ being missing is identical, then the naive estimator is unbiased, that is $\\bar{\\mathbb{E}_{O}}[L_{\\mathrm{naive}}]\\stackrel{\\cdot}{=}L_{\\mathrm{real}}$ where $O$ is taken to represent the random variable of observation. The unbiased estimation property of the naive approach is no longer valid when the data is MNAR, which even results in a large difference between $L_{\\mathrm{real}}$ and $\\mathbb{E}_{O}[L_{\\mathrm{naive}}]$ ", "page_idx": 2}, {"type": "text", "text": "Quantitative Bias-Variance Joint Optimization.  Considering the large difference between $L_{\\mathrm{real}}$ and $\\mathbb{E}_{O}[L_{\\mathrm{naive}}]$ , various unbiased estimation methods have been developed to overcome this problem, such as EIB [i0], IPS estimator [6], DR method [11], and various variations of them [5, 7, 8, 12, 13, 15]. The corresponding estimators are given as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\boldsymbol{L}_{\\mathtt{E I B}}(\\hat{Y},Y^{o})=\\frac{1}{|\\mathcal{D}|}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\big[o_{u,i}e_{u,i}+(1-o_{u,i})\\hat{e}_{u,i}\\big],}&\\\\ &{\\boldsymbol{L}_{\\mathtt{I P S}}(\\hat{Y},Y^{o})=\\!\\frac{1}{|\\mathcal{D}|}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{o_{u,i}}{\\hat{p}_{u,i}}e_{u,i},}&\\\\ &{\\boldsymbol{L}_{\\mathtt{D R}}(\\hat{Y},Y^{o})=\\!\\frac{1}{|\\mathcal{D}|}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\Big[\\hat{e}_{u,i}+\\frac{o_{u,i}}{\\hat{p}_{u,i}}\\big(e_{u,i}-\\hat{e}_{u,i}\\big)\\Big],}&\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\hat{e}_{u,i}\\,=\\,w|\\hat{y}_{u,i}-\\gamma|$ for MAE or $\\hat{e}_{u,i}\\,=\\,w(\\hat{y}_{u,i}-\\gamma)^{2}$ for MSE of missing entries $y_{u,i}$ is the imputed errors, and $\\hat{p}_{u,i}\\,\\in\\,(0,1)$ is the estimation of the observation propensity, i.e., $p_{u,i}\\,=$ $\\mathrm{Pr}(o_{u,i}=1)\\in(0,1)$ . Note that $w$ and $\\gamma$ are hyper-parameters [10]. For the naive, EIB, IPS, and DR estimators, their biases, variances and generalization bounds are summarized in Table 4 (see AppendixAformore dtails)whre $\\begin{array}{r}{\\Delta_{u,i}=\\overline{{1}}-\\frac{p_{u,i}}{\\hat{p}_{u,i}}}\\end{array}$ and $\\delta_{u,i}=e_{u,i}-\\hat{e}_{u,i}$ . In general, the learning of the imputation model also involves the MNAR problem. Some joint learning algorithms [11, 12] employ the propensity model to overcome this problem. Therefore, propensity estimation has a crucial role in unbiasedness and robustness. Besides, it is difficult to accurately estimate imputed errors for all user-item pair $(u,i)$ in the sense that it is difficult to achieve the unbiasedness of the EIB estimator. If the propensity estimation $\\hat{p}_{u,i}$ is accurate, that is $\\hat{p}_{u,i}=p_{u,i}$ , then IPS and DR estimators are unbiased. For a new dataset, we cannot know in advance the range of the propensities in this dataset. Therefore, a new dataset may introduce extremely small propensities to lead to unbounded variances of IPS and DR, which will disrupt the stability of estimators, especially for larger datasets. It is unacceptable for real industrial scenarios. Specifically, the smaller the propensity, the larger the variance. When the propensity tends to zero, the variance tends to infinity (see Appendix B for more details). Similarly, variances of other IPS-based and DR-based unbiased estimation methods [15] are also unbounded. On the other hand, although the variances of naive and EIB methods are bounded when the prediction error $e_{u,i}$ is bounded, it is difficult and even impossible to achieve an unbiased estimation. Other variance reduction estimation methods [5, 7, 8, 12] are generally biased. According to the expressions of estimators and Table 4, the bias and variance of an estimation are determined by the random variable $O$ . We found that slightly relaxing the requirements for unbiasedness will lead to a bounded variance for all propensities. Therefore, the core problem of estimation on MNAR data is the bias-variance joint optimization. ", "page_idx": 2}, {"type": "text", "text": "3  Fine-Grained Dynamic Framework for Quantitative Bias-Variance Joint Optimization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we first discuss limitations of regularization techniques and the relationship between unbiasedness of the generalized estimator and its generalization bound, which illustrate the core of the fine-grained estimator design. Then, the dynamic estimation framework for quantitative bias-variance optimization is present. Its generalization bounds and variances are reduced and bounded with theoretical guarantees. ", "page_idx": 2}, {"type": "text", "text": "3.1  Limitations of Regularization Techniques ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Define the general form of the estimator with regularization as ", "page_idx": 2}, {"type": "equation", "text": "$$\nL_{\\mathrm{Est+Reg}}=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}\\left[f\\big(o_{u,i},\\hat{p}_{u,i}\\big)e_{u,i}+g\\big(o_{u,i},\\hat{p}_{u,i}\\big)\\hat{e}_{u,i}\\right]+\\lambda\\,\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}h\\big(o_{u,i},\\hat{p}_{u,i}\\big),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $f(\\cdot,\\cdot)\\neq0$ with $f(0,\\hat{p}_{u,i})=0$ $g(\\cdot,\\cdot)$ , and $h(\\cdot,\\cdot)$ are functions with respect to $o$ and $\\hat{p}$ $L_{\\mathrm{Est}}$ and $L_{\\mathrm{Reg}}$ are prediction inaccuracies of the estimator and regularizer, respectively. For all $(u,i)$ pairs, they satisfy $\\bar{f}(o_{u,i},\\hat{p}_{u,i})e_{u,i}+g(o_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}\\geq0$ and $h(o_{u,i},\\hat{p}_{u,i})\\stackrel{*}{\\geq}0$ $\\lambda>0$ is a scalar weight. The generalized estimator form $L_{\\mathrm{Est}}$ given in Eq. (1) covers the vast majority of existing estimators involving EIB [10], IPS [6], DR [11], More Robust DR (MRDR) [5], Targeted DR (TDR) [15], MIS [16], IPS/DR-SV [16], and other IPS-based and DR-based methods. On the other hand, almost all existing regularization designs, including the Sample Variance (SV) [16], mean inverse square (MIS) [16], Balancing-Mean-Square Error (BMSE) [8], and so forth, can be transformed into the form $L_{\\mathrm{Reg}}$ given in (1). In previous works, the regularization technique plays a critical role in variance reduction of estimators and improvement of the generalization performance to a certain extent. However, it still have some inevitable limitations described in the following box. ", "page_idx": 3}, {"type": "text", "text": "CoreResults   \n1) For the general estimator with regularization $L_{E s t+R e g}$ , it is impossible to reduce variance without sacrificing unbiasedness.   \n2)Regularization $L_{R e g}$ cannot guarantee a bounded variance and generalization bound. ", "page_idx": 3}, {"type": "text", "text": "In what follows, we provide a detailed theoretical analysis to reveal the aforementioned limitations of the regularization technique. Considering the variance of $L_{\\mathrm{Est+Reg}}$ wehave ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]=\\mathbb{V}_{O}[L_{\\mathrm{Est}}]+2\\lambda\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})+\\lambda^{2}\\mathbb{V}_{O}[L_{\\mathrm{Reg}}].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As mentioned in [8], when the parameter $\\lambda$ is set as the optimal parameter $\\begin{array}{r}{\\lambda_{\\mathrm{opt}}=-\\frac{\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})}{\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]}}\\end{array}$ the variance $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]$ achieves its minimum and satisfies $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]\\le\\mathbb{V}_{O}[L_{\\mathrm{Est}}]$ in the sense that the regularization term $\\lambda L_{\\mathrm{Reg}}$ enables the estimator $L_{\\mathrm{Est+Reg}}$ to reduce its variance. However, the covariance $\\mathrm{Cov}({L}_{\\mathrm{Est}},{L}_{\\mathrm{Reg}})$ needs to fulfill $\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})\\,<\\,0$ as $\\lambda\\:>\\:0$ . Otherwise, an inappropriate parameter will result in an increased variance. The formal theoretical results are provided by Theorems 3.1 and Corollary 3.2, which reveal the limitation 1) (see Appendix $\\mathrm{D}$ for proofs). Corollary 3.2 is the contrapositive of Theorems 3.1. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. Let $L_{E s t+R e g}$ be defined in $(I)$ and the estimator $L_{E s t}$ be unbiased. If $L_{E s t+R e g}$ is unbiased, then the variance of $L_{E s t+R e g}$ is greater than the varianceof the original estimator $L_{E s t}$ ", "page_idx": 3}, {"type": "text", "text": "Corollary 3.2. If the variance of $L_{E s t+R e g}$ is less than the variance of the original estimator $L_{E s t},$ then $L_{E s t+R e g}$ is not unbiased. ", "page_idx": 3}, {"type": "text", "text": "We further find that, if the variance of the original estimator is unbounded, the variances of estimators cannot be bounded by introducing a regularizer even if $\\hat{p}_{u,i}=p_{u,i}$ . The theoretical results are shown in Theorem 3.3(see Appendix D for proofs). ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.3. Let the bias of $L_{E s t+R e g}$ be bounded and the variance of $L_{E s t}$ satisfy $\\begin{array}{r}{\\operatorname*{lim}_{p_{u,i}\\to0}\\mathbb{V}_{O}[L_{E s t}|\\hat{p}_{u,i}\\;=\\;p_{u,i}]\\;=\\;\\infty}\\end{array}$ Then, there exists no regularizer $L_{R e g}$ that enables the varianceandgeneralizationboundoftheestimatorboundedeventhelearnedimputederrorsor propensitiesareaccurate. ", "page_idx": 3}, {"type": "text", "text": "According to the previous works and the present Theorem 3.3, regularizers enable variance reduction to a certain extent while cannot enable estimators to possess bounded variances and generalization bounds. In other words, regularization techniques have limited impact on improving the predictive performance of the model. In the next subsection, a novel perspective of dynamic estimator designs is proposed, which not only achieves quantitative bias-variance joint optimization but also guarantees bounded variances and generalization bounds. ", "page_idx": 3}, {"type": "text", "text": "3.2Dynamic Estimator Designs With Quantitative Optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Most of the existing estimators are based on IPS and DR methods, which are elaborately designed to reduce bias or variance. However, all these estimators are static estimators in the sense that they cannot achieve bias-variance joint optimization for each user-item pair $(u,i)$ .Eventhoughsome methods [5, 8] can effectively reduce the variance of estimators, the estimators are biased and the corresponding variances are unbounded. In this subsection, the core results are provided in the following box. Also, based on theses results, we develop a fine-grained dynamic framework with quantitative optimization to guarantee the reduction and boundedness of variances and generalization bounds ", "page_idx": 3}, {"type": "image", "img_path": "gLoe70Tn8V/tmp/8facb827d19e6d774541a7cc9af40e609196dc9d7fb42542bf14228f7c36f76e.jpg", "img_caption": ["Figure 1: The surfaces of determining factors and the objective function of dynamic estimators, and theoptimal objectivevalues:(a) $h_{B}^{\\mathrm{Est}}$ (6) $h_{V}^{\\mathrm{Est}}$ (C) $w_{1}(h_{B}^{\\mathrm{Est}})^{2}+w_{2}h_{V}^{\\mathrm{Est}}$ (d)Objectiveopt "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Core Results ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "3) For the generalized estimator $L_{\\mathrm{Est}}$ , unbiasedness of the estimator will inevitably lead to the unbounded variance and generalization bound. 4)  The core of the estimator design involves not merely a simple bias-variance trade-off, but rather a quantitative joint optimization of both bias and variance. ", "page_idx": 4}, {"type": "text", "text": "We find that the unbiased estimators with general form generally possess unbounded variances, which is formally derived in Theorem 3.4. Its proofs are provided in Appendix D. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.4 (Limitation of Static Estimator). Given prediction errors $e_{u,i;}$ imputed errors $\\hat{e}_{u,i}$ and learnedpropensities $\\hat{p}_{u,i}$ for all user-itempairs $(u,i)$ , if for any $e_{u,i}-g(0,\\hat{p}_{u,i})\\hat{e}_{u,i}\\neq0,$ $L_{E s t}$ given in $(I)$ is unbiased,then thecorrespondingvariance and generalization bound are unbounded. ", "page_idx": 4}, {"type": "text", "text": "According to Theorem 3.4, the core objective of estimators is not merely about eliminating bias, reducing variance, or simply achieving a bias-variance trade-off but about a quantitative joint optimization between bias and variance. Therefore, as mentioned in Core Results, it is necessary to develop a dynamic estimation framework to achieve the quantitative joint optimization. ", "page_idx": 4}, {"type": "text", "text": "Design Principle of Dynamic Estimators. The IPS-based and DR-based dynamic learning frameworks are designed as ", "page_idx": 4}, {"type": "equation", "text": "$$\nL_{\\mathrm{{D}\\cdot\\mathrm{{IPS}}}}=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}\\frac{o_{u,i}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}e_{u,i},\\ L_{\\mathrm{{D}\\cdot\\mathrm{{D}\\cdot}}}=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}\\left(\\hat{e}_{u,i}+\\frac{o_{u,i}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}\\delta_{u,i}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $f(\\cdot)$ is a designed function and $\\alpha_{u,i}\\in[0,1]$ is optimizable parameters. When $f(\\hat{p}_{u,i})=\\hat{p}_{u,i}$ and $\\forall\\alpha_{u,i}=1$ , D-IPS and D-DR are equivalent to the original IPS and DR estimators, respectively, which possess unbiasedness. When $f(\\hat{p}_{u,i})=\\hat{p}_{u,i}$ and $\\forall\\alpha_{u,i}=0$ , D-IPS and D-DR are equivalent to $\\frac{|\\mathcal{O}|}{|\\mathcal{D}|}L_{\\mathrm{naive}}$ add $f(\\hat{p}_{u,i})$ in (2) is actually a mapping, which balances the bias and variance of estimators. The design principles of $f(\\hat{p}_{u,i})$ are provided as follows: ", "page_idx": 4}, {"type": "text", "text": ". (Isotonic Propensity) $f(\\hat{p}_{u,i})$ with $f(0)=0$ $f(1)=1$ , and $f(\\hat{p}_{u,i})>\\hat{p}_{u,i}$ is a monotonically increasing function. ", "page_idx": 4}, {"type": "text", "text": "\u00b7 (Same Order) $\\operatorname*{lim}_{\\hat{p}_{u,i}\\to0}\\frac{\\hat{p}_{u,i}}{f(\\hat{p}_{u,i})}=C$ ,where $C$ is a positive constant. ", "page_idx": 4}, {"type": "text", "text": "Some specific expressions of $f(\\hat{p}_{u,i})$ fulfilling the above design principles are summarized in Table 1. The corresponding biases, variances and tail bounds of D-IPS and D-DR estimators are formally formulated in Lemmas D.1-D.4 given in Appendix D. From the biases and variances of the D-IPS and D-DR methods given as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{ias}(L_{\\mathrm{D},\\mathrm{IPS}})=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\,\\sum_{(u,i)\\in\\mathcal{D}}h_{B}^{\\mathrm{Eut}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})e_{u,i}\\bigg\\rvert,\\ \\mathrm{Bias}(L_{\\mathrm{D},\\mathrm{IP}})=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\,\\sum_{(u,i)\\in\\mathcal{D}}h_{B}^{\\mathrm{Eut}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})\\delta_{u,i}\\bigg\\rvert,}\\\\ &{^{\\prime}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 4}, {"type": "table", "img_path": "gLoe70Tn8V/tmp/249b9e2b154764fed0113a0c65b201a3b0da5780bc1eb21c298944e5962e3fe5.jpg", "table_caption": ["Table 1: The specific expressions of $f^{\\alpha_{u,i}}(\\hat{p}_{u,i})$ and their determining factors of the bias and variance. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "where $\\begin{array}{r}{h_{B}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})=1-\\frac{p_{u,i}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}}\\end{array}$ and $\\begin{array}{r}{h_{V}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})=\\frac{p_{u,i}(1-p_{u,i})}{f^{2\\alpha_{u,i}}(\\hat{p}_{u,i})}}\\end{array}$ funtions $h_{B}^{\\mathrm{Est}}$ and $h_{V}^{\\mathrm{Est}}$ determine the bases and variance, respectively. $h_{B}^{\\mathrm{Est}}$ and $h_{V}^{\\mathrm{Est}}$ corresponding the specic expressions of $f(\\hat{p}_{u,i})$ are given in Table 1. The monotonicity of bias and variance are provided in Appendix D Proposition D.3. The surfaces of $h_{B}^{\\mathrm{Est}}$ and $h_{V}^{\\mathrm{Est}}$ are plotted in Figs. 1(a) and (b). It is observed that $h_{B}^{\\mathrm{Est}}$ is monotonially dereasing and $h_{V}^{\\mathrm{Est}}$ is monotoniallyinreasing as the numberof $\\alpha_{u,i}$ increases. ", "page_idx": 5}, {"type": "text", "text": "Bias-Variance Quantitative Joint Optimization. According to Proposition D.3 given in Appendix D, the bias-variance trade-off problem can be quantitatively formalized as the following joint optimization problem: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Objective}=\\operatorname*{min}_{\\alpha_{u,i}}\\Big\\{w_{1}\\mathrm{Bias}(L(\\alpha_{u,i}))+w_{2}\\mathbb{V}_{O}[L(\\alpha_{u,i})]\\Big\\},\\ \\mathrm{s.t.}\\ 0\\leq\\alpha_{u,i}\\leq1,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $w_{1}$ and $w_{2}$ are weights of the bias and variance. ", "page_idx": 5}, {"type": "text", "text": "Accordingto determinefctors $h_{B}^{\\mathrm{Est}}$ and $h_{V}^{\\mathrm{Est}}$ of bias and variance,respectively, the bias-variance jint optimization problem can be defined as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Objective}^{\\mathrm{opt}}=\\operatorname*{min}_{\\alpha_{u,i}}\\Big\\{w_{1}E_{B}\\big(h_{B}^{\\mathrm{Est}}(\\alpha_{u,i})\\big)+w_{2}E_{V}\\big(h_{V}^{\\mathrm{Est}}(\\alpha_{u,i})\\big)\\Big\\},\\ \\mathrm{s.t.}\\ 0\\leq\\alpha_{u,i}\\leq1.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For each user-item pair $(u,i)$ , minimizing $E_{B}(h_{B}^{\\mathrm{Est}})$ and $E_{V}(h_{V}^{\\mathrm{Est}})$ given accurate propensity estimations $\\hat{p}_{u,i}$ leads to the bias and variance reduction, respectively. Therefore, the optimal parameter $\\alpha_{u,i}~\\in~[0,1]$ for each user-item pair $(u,i)$ can achieve fine-grained bias-variance joint optimization. The function $h_{B}^{\\mathrm{Est}}$ under $\\alpha_{u,i}~\\in~[0,1]$ \uff0c+ $f(\\hat{p}_{u,i})~\\geq~\\hat{p}_{u,i}$ and $\\hat{p}_{u,i}~=~p_{u,i}$ satisfies $h_{B}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})\\;\\in\\;[0,1)$ . On the other hand, $h_{V}^{\\mathrm{Est}}$ under $\\alpha_{u,i}~\\in~[0,1]$ and $\\hat{p}_{u,i}\\,=\\,p_{u,i}$ satisfies $h_{V}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})\\;\\in\\;[0,\\infty)$ . Therefore, the objective function in (4) can be simplified as $w_{1}h_{B}^{\\mathrm{Est}}(\\alpha_{u,i})+w_{2}h_{V}^{\\mathrm{Est}}(\\alpha_{u,i})$ The curves of objective functions under different designed functions $f(\\cdot)$ are given in Fig. 1(c). It can be observed that for a fixed propensity, there exists an $\\alpha$ such that the objective function attains the minimum value. Besides, different measure metrics are also applicable for dynamic estimators, such as $E(h^{\\mathrm{Est}})=(h^{\\mathrm{Est}}(\\alpha_{u,i}))^{2}$ \uff0c $E(h^{\\mathrm{Est}}(\\alpha_{u,i}))=\\ln(\\cosh(h^{\\mathrm{Est}}(\\alpha_{u,i}^{~\\cdot~\\cdot})))$ , and soonIwat followertbjtiveftn $w_{1}h_{B}^{\\mathrm{Est}}+w_{2}h_{V}^{\\mathrm{Est}}$ the analytical solution of the optimal parameter $\\alpha_{u,i}^{\\mathrm{opt}}$ is given in Theorem 3.5 (see Appendix D for proofs). ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.5 The optimal parameter $\\alpha_{u,i}^{\\mathrm{opt}}$ $\\hat{p}_{u,i}=p_{u,i}$ For weights $w_{1}$ and $w_{2}$ , the objective function $w_{1}h_{B}^{E s t}+w_{2}h_{V}^{E s t}$ under $\\alpha_{u,i}~\\in~[0,1]$ achieves its minimumat ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha_{u,i}^{o p t}=\\operatorname*{min}\\bigg\\{\\operatorname*{max}\\bigg\\{\\frac{\\ln\\bigg(\\frac{2w_{2}}{w_{1}}(1-p_{u,i})\\bigg)}{\\ln\\bigl(f(p_{u,i})\\bigr)},0\\bigg\\},1\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "From the expression of the optimal parameter (5), the optimal solution of (4) under different weights depends on the weight ratio $w_{2}/w_{1}$ . Under different designed function $f(\\cdot)$ , the schematic diagram of optimal objective values corresponding to the optimal parameter $\\alpha_{u,i}^{o p t}$ is shown in Fig. 1(d). Next, the generalization bounds of the developed dynamic estimator framework are further discussed. The formalized results are derived in Theorem 3.6 (see Appendix $\\mathrm{D}$ for more details). ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.6 (Generalization Bounds of D-IPS and D-DR). For any finite hypothesis space $\\mathcal{H}$ of $\\hat{Y}$ and the optimal predictionmatrix ${\\hat{Y}}^{-}$ given $\\hat{e}_{u,i}$ and $\\hat{p}_{u,i}$ for all $(u,i)\\in\\mathcal{D}$ withprobability $1-\\rho_{i}$ thepredictioninaccuracies $L_{D-I P S}(\\hat{Y}^{-},Y)$ and $L_{D-D R}(\\hat{Y}^{-},Y)$ under $D$ -IPSand $D$ DRhave ", "page_idx": 5}, {"type": "text", "text": "the following upper bounds ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{D\\cdot I P S}(\\hat{Y}^{-},Y^{O})+\\underbrace{\\sum_{\\stackrel{\\mathrm{\\scriptsize~|}}{=}}\\frac{\\vert\\boldsymbol{h}_{B}^{E s t}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})e_{u,i}^{-}\\vert}{\\vert\\mathcal{D}\\vert}}_{\\stackrel{\\mathrm{\\scriptsize~|}}{=}\\frac{\\vert\\boldsymbol{h}_{B}^{E s t}(\\hat{p}_{u,i}^{+})\\vert}{\\vert\\mathcal{D}\\vert}}+\\underbrace{h_{G}^{E s t}(e_{u,i}^{+})}_{V_{u r i a n c e}^{-}T e r m},}\\\\ {L_{D\\cdot D R}(\\hat{Y}^{-},Y^{O})+\\underbrace{\\sum_{\\stackrel{\\mathrm{\\scriptsize~|}}{=}}\\frac{\\vert\\boldsymbol{h}_{B}^{E s t}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i})\\delta_{u,i}^{-}\\vert}{\\vert\\mathcal{D}\\vert}}_{\\stackrel{\\mathrm{\\scriptsize~|}}{=}\\frac{\\vert\\boldsymbol{D}\\vert}{\\vert\\mathcal{D}\\vert}}+\\underbrace{h_{G}^{E s t}(\\delta_{u,i}^{+})}_{V_{u r i a n c e}^{-}T e r m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $e_{u,i}^{+}$ and $\\delta_{u,i}^{+}$ are the error and error deviation corresponding to $\\hat{Y}^{+}\\quad=$ $\\begin{array}{r l}{\\arg\\operatorname*{max}_{\\hat{Y}\\in\\mathcal{H}}\\bigg\\{\\sum_{(u,i)\\in\\mathcal{D}}\\left(\\frac{e_{u,i}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}\\right)^{2}\\bigg\\}}\\end{array}$ and $\\begin{array}{r}{\\hat{Y}^{+}~=~\\arg\\operatorname*{max}_{\\hat{Y}\\in\\mathcal{H}}\\bigg\\{\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(\\frac{\\delta_{u,i}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}\\bigg)^{2}\\bigg\\},}\\end{array}$ respectively and the function $h_{G}^{E s t}$ isformulated as $\\begin{array}{r}{h_{G}^{E s t}(z_{u,i}^{+})=\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}}\\sum_{(u,i)\\in\\mathcal{D}}\\left(\\frac{z_{u,i}^{+}}{f^{\\alpha_{u,i}}(\\hat{p}_{u,i})}\\right)^{2}}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "From Theorem 3.6, the bias-variance joint optimization is actually to minimize generalization bounds, which include both the bias term and the variance term. Besides, the dynamic estimators with the optimal parameter $\\alpha_{u,i}^{\\mathrm{opt}}$ make variances and generalization bounds bounded. The formal result is given in Theorem 3.7 (The corresponding proofs and bounds of variances are given in Appendix D). ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.7 (Boundedness of Variance and Generalization Bound). Let $\\alpha_{u,i}^{o p t}\\in[0,1]$ be the optimal $\\alpha_{u,i}^{o p t}$ ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we conduct extensive experiments to compare the performance of the present dynamic learning framework with existing SOTA approaches and to answer the following questions: Q1: Does the developed dynamic learning framework improve the prediction performance compared with the SOTA approaches? Q2: Do the present dynamic estimator designs reduce the variance and make performance more stable compared with the SOTA approaches? Q3: How do the performance and variance of the proposed method change under different optimization weights and estimator functions? ", "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Dataset and Preprocessing.  Three real-world datasets with MNAR and MAR samples are used to conduct the experiments, namely CoAT with 4,640 MAR and 6,960 MNAR ratings of 290 users to 300 coats, YAH00! R3 with 54,000 MAR and 311,704 MNAR ratings of 15,400 users to 1,000 songs, and KUA1REC with 4,676,570 video watching ratio records of 1,411 users to 3,327 video. Similar to literature [8, 7, 5], the rating scores in CoAT and YAHOo! R3 are binarized as 1 when it is greater than three, otherwise as O. For the KUA1REC dataset, the video watching ratios are binarized as O when it is less than two, otherwise as 1. ", "page_idx": 6}, {"type": "text", "text": "Baselines and Experimental Details.  To avoid the uncertainty caused by the prediction and observe the performance of the prediction model, we take the matrix factorization (MF) [17] as the base model and compare the present dynamic learning framework with the following representative IPS-based and DR-based approaches: naive MF [17], IPS [6], SNIPS [13], IPS-AT [18], CVIB [19], IPS-V2 [8], DR [11], DR-JL [11], MRDR-JL [5], Stable DR [12], Stable MRDR [12], TDR-CL [15], TMRDR-CL [15], DR-V2 [8]. Here, we adopt the two common metrics used in recommender system, i.e., area under the ROC curve (AUC), and normalized discounted cumulative gain (NDCG), to evaluate the performance of prediction models. To guarantee the fair comparison, we set the same parameters for all approaches. The learning rates are tuned in $\\left\\lbrace0.001,0.005,0.01,0.05\\right\\rbrace$ and weight decay is tuned in $\\{\\bar{1},1e-1,1e-2,1e-\\bar{3},1e-4,1e-5,\\bar{1}e-6\\}$ . Note that, for $X X$ and $D{\\mathrm{-}}X X$ approaches, their model structures and parameters are identical. Every approach is preformed 10 times to record its mean and standard deviation. ", "page_idx": 6}, {"type": "text", "text": "4.2  Performance Comparison (for Q1 and Q2) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The MNAR records in datasets are used to train the prediction model and the MAR data is employed to evaluate the present dynamic learning approaches and the existing SOTA approaches. The function in proposed $D{\\cdot}X X$ approaches is select as (log(+1). The performance of other functions provided in Table 1 are discussed in subsection 4.3. The performances of the developed dynamic estimators and the SOTA approaches are shown in Table 2, where $\\mathrm{Gain_{AUC}=(A U C_{X X}-A U C_{D-X X})/A U C_{X X}}$ and $\\mathrm{Gain_{N}=(N D C G_{X X}-N D C G_{D-X X})/N D C G_{X X}}$ , e.g. $\\mathrm{Gain_{AUC}=\\big(A U C_{I P S}-A U C_{D\\mathrm{-}I P S}\\big)/A U C_{I P S}},$ $\\mathrm{Gain_{N}=(N D C G_{I P S}-N D C G_{D-I P S})/N D C G_{I P S}}.$ The weights in bias-variance joint optimization are setas $w_{1}=1$ and $w_{2}=0.1$ . For almost all of metrics and datasets, the performances of IPS, IPS-AT, CVIB, IPS-V2, DR, DR-JL, MRDR, DR-V2 outperform the naive method while the naive approach has smaller variance, which implies that unbiased estimators possess high variance. Besides, it can be observed that estimators with the dynamic learning mechanism greatly improve the performances and reduce the variances of various debiased approaches, such as IPS and D-IPS, DR and D-DR, DR-JL and D-DR-JL. Meanwhile, for SNIPS, MRDR-JL, the variance reduction of dynamic estimators do not seem obvious. One possible reason is that these approaches themselves can effectively reduce the variances of estimators by sacrificing unbiasedness. These experiment results further verify Theorem 3.4. ", "page_idx": 7}, {"type": "table", "img_path": "gLoe70Tn8V/tmp/3d4823e2147177a4fe8b786d442892986d8d4ccf60af659d60894aad2770bf2f.jpg", "table_caption": ["Table 2: Performances of the proposed method and baselines (mean $\\pm$ standard deviation across 10 runs). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.3 Ablation Studies (for Q3) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Effects of Different Weights and Functions in Dynamic Estimators. In subsection 3.2, we provide four specific dynamic estimators given in Table 1. We set the weights in bias-variance joint optimization (4) as $w_{1}=1$ and $w_{2}=[0.02,0.04,0.06,0.08,1]$ for these four dynamic estimators to investigate the effects of weights on the performances and variances. From Eq. (5), the optimal parameter $\\alpha_{\\mathrm{opt}}$ is determined by the ratio $\\frac{w_{2}}{w_{1}}$ and $\\alpha_{\\mathrm{opt}}$ determines the objective function. Therefore, we just focus on the effects of the weight ratios on the performance and variances of estimators, which are given in Fig. 2. It can be observed that, for D-IPS, D-IPS-AT, D-DR, D-DR-JL, and D-MRDR-JL approaches, the performances increased at first and then decreased as the number of the weight ratio increases. Meanwhile, the variances seem to achieve their minimums when the performances achieve their highest values. Since the smaller the weight ratio is, the smaller the bias of the dynamic estimator is, the experimental results given in Fig. 2 reveal that the unbiasedness of estimators is not exactly equivalent to the performances of estimators. Actually, from the generalization bounds given in Theorem 3.6, the bias-variance joint optimization enable estimators to minimize the generalization ", "page_idx": 7}, {"type": "image", "img_path": "gLoe70Tn8V/tmp/b50eeffb998c5a331ddf114e097344498766d7945590f53b980e4f2042cd57d6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figurtfitwe $\\frac{w_{2}}{w_{1}}$ nperfadmtmadi functions $f^{\\alpha}(\\hat{p}_{u,i})$ : (a) $\\hat{p}_{u,i}^{\\alpha}$ ; (b) $\\left(\\frac{\\sin(\\hat{p}_{u,i})}{\\sin(1)}\\right)^{\\hat{\\alpha}}$ ; (c) (10g(@(+1)\u00b0; (\u2460) ( $\\left(\\frac{\\operatorname{tanh}(\\hat{p}_{u,i})}{\\operatorname{tanh}(1)}\\right)^{\\alpha}$ ", "page_idx": 7}, {"type": "table", "img_path": "gLoe70Tn8V/tmp/d510a3ff91ec6dc1a9a8668ab750eb65e2abe575fc3440f15aeba5d015083d1d.jpg", "table_caption": ["Table 3: Effects of different functions on performances of dynamic estimators. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "bounds and then further improve the generalization performance. Meanwhile, we find that the variances of dynamic estimators is not decreasing when the weight ratio increases. This because, for different ratios, the global minimum of the objective function (4) cannot be reached within the interval $\\alpha\\in[0,1]$ . For SNIPS, the property of variance reduction might lead to the non-obvious performance and variance trends. ", "page_idx": 8}, {"type": "text", "text": "Under the identical weight ratio $\\textstyle{\\frac{w_{2}}{w_{1}}}\\,=\\,0.1$ , we further discuss the effects of different functions $f^{\\alpha}(\\hat{p}_{u,i})$ on the prediction performance and variance. The experimental results are shown in Fig. 3. Nearly all dynamic estimators with different function expressions outperform the corresponding debiased approaches given in Table 3. It further demonstrates that the proposed dynamic learning mechanism can greatly improve the performance of the original estimator. Besides, the prediction performance of the dynamic estimator with $\\begin{array}{r}{f^{\\alpha}(\\hat{p}_{u,i})=\\left(\\frac{\\log(\\hat{p}_{u,i}+1)}{\\log(2)}\\right)^{\\alpha}}\\end{array}$ outperforms other dynamic estimators. ", "page_idx": 8}, {"type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Aiming at the prediction model bias caused by the MNAR data, EIB [10] and IPS [6] approaches are two classical unbiased estimators. To leverage the advantages of EIB and IPS, the DR method [11] was designed to make the unbiasedness of estimator doubly robust. Focusing on the unbiasedness of estimators, various estimation methods have been proposed to overcome mixed or even unknown biases in the data [9], to solve the sample selection bias problem in the multi-task learning [20, 21, 22, 23], to improve the performance of the propensity model by different approaches [18, 14], and so forth. A multiple robust estimator is developed in [24] by taking the advantage of multiple candidate imputation and propensity models, which is unbiased when any of the imputation or propensity models, or a linear combination of these models is accurate. From a novel function balancing perspective, Li et al. propose to approximate the balancing functions in reproducing kernel Hilbert space [25]. Moreover, aimed at limitations of miscalibrated imputation and propensity models, Kweon and Yu [26] propose a doubly calibrated estimator and a tri-level joint learning framework to simultaneously optimize calibration experts alongside prediction and imputation models. For the variance of estimators, an increasing body of works have emerged to reduce the variance. The most common estimator reducing variance is Self-Normalized IPS (SNIPS) [13]. Based on DR, literature [5] designed a MRDR estimator to reduce the variance of the DR estimator by the present variance expression of DR. In [15], TDR estimator is elaborated to reduce the bias and variance of DR simultaneously by the present semi-parametric collaborative learning. Moreover, stable DR estimator [12] achieves the bounded bias, variance, and generalization error bound simultaneously for arbitrarily small propensities by combining SNIPS and DR methods. Various regularization designs, such as SV [16], MIS [16], BMSE [8], and so forth, are also introduced into the estimator to achieve variancereduction. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "To the best of our knowledge, this is the first work to reveal that the essence of estimator designs is not merely to eliminate bias, to reduce variance, or to achieve a simple bias-variance trade-off but to quantitatively and simultaneously optimize bias and variance. Besides, the limitations of general regularization techniques and general static estimators are presented. Based on the general laws with respect to the relationship between bias and variance, we propose a systematic dynamic learning framework, which guarantees the bounded variances and generalization bounds by the present fine-grained bias-variance joint optimization scheme. Extensive experiment results have verified the theoretical results and the performance of the present dynamic estimators. The search for optimal weights in the objective function and the functions in the dynamic estimation framework remains an open question. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1]  Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In Proceedings of the twenty-first international conference on Machine learning, page 114, 2004. ", "page_idx": 9}, {"type": "text", "text": "[2] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. Modeling task relationships in multi-task learning with multi-gate mixture-of-experts. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, pages 1930-1939, 2018.   \n[3] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pages 1137-1140, 2018.   \n[4] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, and Yu Chen. Modeling the sequential dependence among audience multi-step conversions with multi-task learning in targeted display advertising. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 3745-3755, 2021.   \n[5] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang, Hechang Chen, Dawei Yin, and Yi Chang. Enhanced doubly robust learning for debiasing post-click conversion rate estimation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 275-284, 2021.   \n[6]  Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. Recommendations as treatments: Debiasing learning and evaluation. In international conference on machine learning, pages 1670-1679. PMLR, 2016.   \n[7] Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, Xiao-Hua Zhou, Rui Zhang, Rui Zhang, and Jie Sun. A generalized doubly robust learning framework for debiasing post-click conversion rate prediction. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 252-262, 2022.   \n[8]  Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, and Peng Cui. Propensity matters: Measuring and enhancing balancing for recommendation. In International Conference on Machine Learning, pages 20182-20194. PMLR, 2023.   \n[9] Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin, and Keping Yang. Autodebias: Learning to debias for recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 21-30, 2021.   \n[10]  Harald Steck. Training and testing of recommender systems on data missing not at random. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 713-722, 2010.   \n[11] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. Doubly robust joint learning for recommendation on data missing not at random. In International Conference on Machine Learning, pages 6638-6647. PMLR, 2019.   \n[12]  Haoxuan Li, Chunyuan Zheng, Xiao-Hua Zhou, and Peng Wu. Stabilized doubly robust learning for recommendation on data missing not at random. In Proceedings of the 1lth International Conference on Learning Representations, 2023.   \n[13]  Adith Swaminathan and Thorsten Joachims. The self-normalized estimator for counterfactual learning. advances in neural information processing systems, 28, 2015.   \n[14]  Wei Ma and George H Chen. Missing not at random in matrix completion: The effectiveness of estimating missingness probabilities under a low nuclear norm assumption. Advances in neural information processing systems, 32, 2019.   \n[15] Haoxuan Li, Yan Lyu, Chunyuan Zheng, and Peng Wu. Tdr-cl: Targeted doubly robust collaborative learning for debiased recommendations. In Proceedings of the 1lth International Conference on Learning Representations, 2023.   \n[16] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. Combating selection biases in recommender systems with a few unbiased ratings. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pages 427-435, 2021.   \n[17]  Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30-37, 2009.   \n[18]  Yuta Saito. Asymmetric tri-training for debiasing missing-not-at-random explicit feedback. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 309-318, 2020.   \n[19] Zifeng Wang, Xi Chen, Rui Wen, Shao-Lun Huang, Ercan Kuruoglu, and Yefeng Zheng. Information theoretic counterfactual learning from missing-not-at-random feedback. Advances in Neural Information Processing Systems, 33:1854-1864, 2020.   \n[20] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen, and Ramin Ramezani. Large-scale causal approaches to debiasing post-click conversion rate estimation with multi-task learning. In Proceedings of The Web Conference 2020, pages 2775-2781, 2020.   \n[21] Wujiang Xu, Qitian Wu, Runzhong Wang, Mingming Ha, Qiongxu Ma, Linxun Chen, Bing Han, and Junchi Yan. Rethinking cross-domain sequential recommendation under open-world assumptions. arXiv preprint arXiv:2311.04590, 2023.   \n[22] Wujiang Xu, Shaoshuai Li, Mingming Ha, Xiaobo Guo, Qiongxu Ma, Xiaolei Liu, Linxun Chen, and Zhenfeng Zhu. Neural node matching for multi-target cross domain recommendation. In 2023 IEEE 39th International Conference on Data Engineering (ICDE), pages 2154-2166. IEEE, 2023.   \n[23] Wujiang Xu, Xuying Ning, Wenfang Lin, Mingming Ha, Qiongxu Ma, Linxun Chen, Bing Han, and Minnan Luo. Towards open-world cross-domain sequential recommendation: A model-agnostic contrastive denoising approach. arXiv preprint arXiv:2311.04760, 2023.   \n[24] Haoxuan Li, Quanyu Dai, Yuru Li, Yan Lyu, Zhenhua Dong, Xiao-Hua Zhou, and Peng Wu. Multiple robust learning for recommendation. In In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence, 2023.   \n[25] Haoxuan Li, Chunyuan Zheng, Yanghao Xiao, Peng Wu, Zhi Geng, Xu Chen, and Peng Cui. Debiased collaborative fltering with kernel-based causal balancing. In Proceedings of the 12th International Conference on Learning Representations, 2024.   \n[26]  Wonbin Kweon and Hwanjo Yu.  Doubly calibrated estimator for recommendation on data missing not at random. In In Proceedings of the ACM Web Conference 2024 (WWw '24), page 3810-3820,2024. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "A Derivation of bias and variance for naive, EIB, IPS, and DR estimators. ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "As mentioned in literature [11], the bias of an estimator is defined as ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathrm{Bias}(L)=|L_{\\mathrm{real}}-\\mathbb{E}_{O}[L]|\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "According to the prediction inaccuracy expressions of $L_{\\mathrm{naive}}$ and the definition of bias (6), the bias of naive estimator satisfies ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathrm{Bias}(L_{\\mathrm{naive}})=\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i}-|\\mathcal{D}|\\mathbb{E}_{O}[L_{\\mathrm{naive}}]\\bigg\\rvert=\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(1-\\frac{|\\mathcal{D}|}{|\\mathcal{O}|}p_{u,i}\\bigg)e_{u,i}\\bigg\\rvert.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "According to the definition of variance for an estimation given in [5], the variance of the naive approach can be formulated as ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}\\!\\left[L_{\\mathrm{naive}}\\right]=\\!\\mathbb{E}_{O}\\!\\left[L_{\\mathrm{naive}}^{2}\\right]-\\mathbb{E}_{O}^{2}\\!\\left[L_{\\mathrm{naive}}\\right]}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\frac{1}{|O|^{2}}\\mathbb{E}_{O}\\!\\left[\\left(\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}o_{u,i}e_{u,i}\\right)^{2}\\right]-\\frac{1}{|O|^{2}}\\!\\left(\\sum_{(u,i)\\in\\mathcal{D}}p_{u,i}e_{u,i}\\right)^{2}}\\\\ &{\\quad\\quad\\quad=\\!\\frac{1}{|O|^{2}}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}p_{u,i}(1-p_{u,i})e_{u,i}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "The biases of EIB, IPS and DR methods have been given in Lemma 3.1 of [11]. The variance formulations of IPS and DR estimators have been provided in [5]. For the variance of EIB, we obtain ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{^{\\prime}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Therefore, the bias and variance of naive, EIB, IPS, and DR estimators shown in Table 4 can be obtained. ", "page_idx": 11}, {"type": "text", "text": "B Unbounded Variance ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "According to the definitions of variances of IPS and SR methods, if $\\hat{p}_{u,i}=p_{u,i}$ , when the propensity tends to zero, the variace of IPS and DR satisfy ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{p_{u,i}\\to0}{\\operatorname*{lim}}\\mathbb{V}_{O}[L_{\\mathrm{IPS}}|\\hat{p}_{u,i}=p_{u,i}]=\\underset{p_{u,i}\\to0}{\\operatorname*{lim}}\\frac{1}{|\\mathscr{D}|^{2}}\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\frac{1-p_{u,i}}{p_{u,i}}e_{u,i}^{2}=\\infty,}\\\\ {\\underset{p_{u,i}\\to0}{\\operatorname*{lim}}\\mathbb{V}_{O}[L_{\\mathrm{DR}}|\\hat{p}_{u,i}=p_{u,i}]=\\underset{p_{u,i}\\to0}{\\operatorname*{lim}}\\frac{1}{|\\mathscr{D}|^{2}}\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\frac{1-p_{u,i}}{p_{u,i}}\\delta_{u,i}^{2}=\\infty.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "This demonstrates that the variances of IPS and DR are unbounded even if the propensities are accurate. If there exists one propensity going to zero then the variance tends to infinity ", "page_idx": 11}, {"type": "text", "text": "C Limitations of Regularization Techniques and Static Estimators ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Theorem 3.1. Let $\\scriptstyle L_{\\mathrm{Est+Reg}}$ be defned in (1) and the estimator $L_{\\mathrm{Est}}$ be unbiased. If $\\scriptstyle L_{\\mathrm{Est+Reg}}$ is unbiased, then the variance of $L_{\\mathrm{Est+Reg}}$ is greater than the one of the original estimator $L_{\\mathrm{Est}}$ ", "page_idx": 11}, {"type": "table", "img_path": "gLoe70Tn8V/tmp/7bb700a062110289e565d47bc07af2e4d299eb14eaea4f0ece586544c8585bb8.jpg", "table_caption": ["Table 4: Bias and variance of naive, EIB, IPS, and DR estimators. "], "table_footnote": [], "page_idx": 11}, {"type": "text", "text": "Proof. The variance of $L_{\\mathrm{Est+Reg}}$ satisfies ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]=\\mathbb{V}_{O}[L_{\\mathrm{Est}}]+2\\lambda\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})+\\lambda^{2}\\mathbb{V}_{O}[L_{\\mathrm{Reg}}].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "To reduce the variance of $L_{\\mathrm{Est}},\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]$ satisfies $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]\\le\\mathbb{V}_{O}[L_{\\mathrm{Est}}]$ which implies that ", "page_idx": 12}, {"type": "equation", "text": "$$\n2\\lambda\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})+\\lambda^{2}\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]\\le0.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Therefore, the parameter $\\lambda$ satisies $\\begin{array}{r}{0\\leq\\lambda\\leq-\\frac{2\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})}{\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]}}\\end{array}$ and the optimal parameter is $\\lambda_{\\mathrm{opt}}=$ Co. On theotherhand, since LEst adLEsReg are ubiaed, webtan ELRe = . Then $\\mathrm{Cov}(\\bar{L}_{\\mathrm{Est}},L_{\\mathrm{Reg}})$ satisfies ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathsf{C o v}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})=\\mathbb{E}_{O}(L_{\\mathrm{Est}}L_{\\mathrm{Reg}})-\\mathbb{E}_{O}(L_{\\mathrm{Est}})\\mathbb{E}_{O}(L_{\\mathrm{Reg}})}&{}\\\\ &{=\\mathbb{E}_{O}(L_{\\mathrm{Est}}L_{\\mathrm{Reg}})}\\\\ &{=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{O}\\left(\\bigg[\\sum_{(u,i)\\in\\mathcal{D}}\\Big(f(o_{u,i},\\hat{p}_{u,i})e_{u,i}+g(o_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}\\Big)\\bigg]\\bigg[\\sum_{(u,i)\\in\\mathcal{D}}h(o_{u,i},\\hat{p}_{u,i})\\bigg]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "To facilitate representation, $f(o_{u,i},\\hat{p}_{u,i})e_{u,i}+g(o_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}$ is denoted as $r(o_{u,i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})$ \uff0c which satisfies $r(o_{u,i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})\\ge0$ . Then the equation (9) can be rewritten as ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Cov}(L_{\\mathrm{Eat}},L_{\\mathrm{Reg}})=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{\\boldsymbol\\sigma}\\left(\\sum_{(u_{i},i)\\in\\mathcal{D}}r(\\sigma_{u_{i},i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})\\right)\\Bigg[\\sum_{(u_{i},i)\\in\\mathcal{D}}h(\\sigma_{u_{i},i},\\hat{p}_{u,i})\\Bigg]\\Bigg)}\\\\ &{=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{\\boldsymbol\\sigma}\\left(\\sum_{(u_{i},i)\\in\\mathcal{D}}\\left[h(\\sigma_{u_{i},i},\\hat{p}_{u,i})\\sum_{(u_{i},i)\\in\\mathcal{D}}r(\\sigma_{u_{i},i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})\\right]\\right)}\\\\ &{=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{\\boldsymbol\\sigma}\\left(\\sum_{j=1}^{|\\mathcal{D}|}\\sum_{k=1}^{|D|}h(\\sigma_{j},\\hat{p}_{j})r(\\sigma_{k},\\hat{p}_{k},e_{k},\\hat{e}_{k})\\right)}\\\\ &{=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{j=1}^{|D|}\\sum_{k=1}^{|D|}\\mathbb{E}_{\\boldsymbol\\sigma}[h(\\sigma_{j},\\hat{p}_{j})r(\\sigma_{k},\\hat{p}_{k},e_{k},\\hat{e}_{k})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Let us \u3001consider the term $\\mathbb{E}_{O}[h(o_{j},\\hat{p}_{j})r(o_{k},\\hat{p}_{k},e_{k},\\hat{e}_{k})]$ in (10), _which fulfills $\\mathbb{E}_{O}[h(o_{j},\\hat{p}_{j})r(o_{k},\\hat{p}_{k},e_{k},\\hat{e}_{k})]\\,\\ge\\,0$ Therefore, we obtain $\\mathrm{Cov}(\\dot{L_{E s t}},L_{R e g})\\,=\\,\\mathbb{E}_{O}(L_{\\mathrm{Est}}L_{\\mathrm{Reg}})\\,\\geq$ 0. ", "page_idx": 12}, {"type": "text", "text": "Corollary 3.2. If the variance of $L_{\\mathrm{Est+Reg}}$ is less than the variance of the original estimator $L_{\\mathrm{Est}}$ .then $\\cal L_{\\mathrm{Est+Reg}}$ is not unbiased. ", "page_idx": 12}, {"type": "text", "text": "Proof. We use the method of proof by contradiction. Assume that when $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]\\le\\mathbb{V}_{O}[L_{\\mathrm{Est}}]$ $L_{\\mathrm{Est+Reg}}$ is unbiased. According to the definition of $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]$ and $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]\\le\\mathbb{V}_{O}[L_{\\mathrm{Est}}]$ we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]=\\mathbb{V}_{O}[L_{\\mathrm{Est}}]+2\\lambda\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})+\\lambda^{2}\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{V}_{O}[L_{\\mathrm{Est}}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "which implies that $2\\lambda\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})+\\lambda^{2}\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]\\,\\le\\,0$ .Therefore, the parameter $\\lambda$ needs to satisfy $\\begin{array}{r}{0\\,\\leq\\,\\lambda\\,\\leq\\,-\\frac{2\\mathrm{Cov}(L_{\\mathrm{Est}},L_{\\mathrm{Reg}})}{\\mathbb{V}_{O}[L_{\\mathrm{Reg}}]}}\\end{array}$ 2Cv() Since Vo[LRe and \u5165 \u22650, Cov(LEs,LReg) \u2264 0 needs to b satisfied. On the other hand, as shown in A1, when $L_{\\mathrm{Est+Reg}}$ is unbiased, we have $\\mathrm{Cov}(L_{E s t},L_{R e g})=$ $\\mathbb{E}_{O}(L_{\\mathrm{Est}}L_{\\mathrm{Reg}})\\geq0$ , which contradicts the condition $\\mathrm{Cov}\\bar{(\\cal L_{\\mathrm{Est}},\\cal L_{\\mathrm{Reg}})}\\leq0$ Therefore, Corollary 3.2 holds. \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Theorem 3.3. Let the bias of $L_{\\mathrm{Est+Reg}}$ be bounded and the variance of $L_{\\mathrm{Est}}$ satisfy $\\begin{array}{r}{\\operatorname*{lim}_{p_{u,i}\\to0}\\mathbb{V}_{O}[L_{\\mathrm{Est}}|\\hat{p}_{u,i}\\;=\\;p_{u,i}]\\;=\\;\\infty}\\end{array}$ Then, there exists no regularizer $L_{\\mathrm{Reg}}$ that enables the variance and generalization bound of the estimator bounded even the learned imputed errors or propensities are accurate. ", "page_idx": 12}, {"type": "text", "text": "Proof. According to the definition of variance, $\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]$ satisfies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}]=\\!\\mathbb{E}_{O}[(L_{\\mathrm{Est}}+\\lambda L_{\\mathrm{Reg}})^{2}]-\\mathbb{E}_{O}^{2}[L_{\\mathrm{Est}}+\\lambda L_{\\mathrm{Reg}}]\\quad\\quad}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\!\\mathbb{E}_{O}[L_{\\mathrm{Est}}^{2}+\\lambda^{2}L_{\\mathrm{Reg}}^{2}+2\\lambda L_{\\mathrm{Est}}L_{\\mathrm{Reg}}]-\\mathbb{E}_{O}^{2}[L_{\\mathrm{Est}}+\\lambda L_{\\mathrm{Reg}}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Since the bias of the estimator $L_{\\mathrm{Est+Reg}}$ isbounded and $\\begin{array}{r}{\\operatorname*{lim}_{p_{u,i}\\to0}\\mathbb{V}_{O}[L_{\\mathrm{Est}}|\\hat{p}_{u,i}\\,=\\,p_{u,i}]\\;=\\;\\infty}\\end{array}$ $\\mathbb{E}_{O}^{2}[L_{\\mathrm{Est}}+\\lambda L_{\\mathrm{Reg}}]$ is alsobounded, i.e. $\\mathbb{E}_{O}^{2}[L_{\\mathrm{Est}}+\\lambda L_{\\mathrm{Reg}}]\\leq\\bar{B}$ Eq.(11) satisfies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L_{\\mathtt{E s t+R e g}}]=\\!\\mathbb{E}_{O}[L_{\\mathtt{E s t}}^{2}]+\\lambda^{2}\\mathbb{E}_{O}[L_{\\mathtt{R e g}}^{2}]+2\\lambda\\mathbb{E}_{O}[L_{\\mathtt{E s t}}L_{\\mathtt{R e g}}]-\\mathbb{E}_{O}^{2}[L_{\\mathtt{E s t}}+\\lambda L_{\\mathtt{R e g}}]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\ge\\!\\mathbb{E}_{O}[L_{\\mathtt{E s t}}^{2}]+\\lambda^{2}\\mathbb{E}_{O}[L_{\\mathtt{R e g}}^{2}]+2\\lambda\\mathbb{E}_{O}[L_{\\mathtt{E s t}}L_{\\mathtt{R e g}}]-\\bar{B}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which implies that $\\begin{array}{r}{\\operatorname*{lim}_{p_{u,i}\\to0}\\mathbb{V}_{O}[L_{\\mathrm{Est+Reg}}|\\hat{p}_{u,i}=p_{u,i}]=\\infty}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "Theorem 3.4. (Limitation of Static Estimator). Given prediction errors $e_{u,i}$ , imputed errors $\\hat{e}_{u,i}$ , and learned propensities $\\hat{p}_{u,i}$ for all user-item pair's $(u,i)$ , if for any $e_{u,i}-g(0,\\hat{p}_{u,i})\\hat{e}_{u,i}\\neq0$ \uff0c $L_{\\mathrm{Est}}$ given in (1) is unbiased, then the corresponding variance and generalization bound are unbounded. ", "page_idx": 13}, {"type": "text", "text": "Proof. According to the formulation of the estimator (1) and $f(0,\\hat{p}_{u,i})=0$ , its bias is given as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Bias}(L)=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i}-\\mathbb{E}_{O}[L]\\bigg\\rvert}\\\\ &{\\qquad\\quad=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}\\left[\\big(1-f(1,\\hat{p}_{u,i})p_{u,i}\\big)e_{u,i}-\\big(g(1,\\hat{p}_{u,i})p_{u,i}+g(0,\\hat{p}_{u,i})(1-p_{u,i})\\big)\\hat{e}_{u,i}\\right]\\bigg\\rvert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "From (12), it can be observed that the unbiasedness of the estimator $L$ implies that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big[1-f(1,\\hat{p}_{u,i})p_{u,i}\\big]e_{u,i}-\\big[g(1,\\hat{p}_{u,i})p_{u,i}+g(0,\\hat{p}_{u,i})(1-p_{u,i})\\big]\\hat{e}_{u,i}=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which is equivalent to ", "page_idx": 13}, {"type": "equation", "text": "$$\nf(1,\\hat{p}_{u,i})p_{u,i}e_{u,i}+\\big[g(1,\\hat{p}_{u,i})p_{u,i}+g(0,\\hat{p}_{u,i})(1-p_{u,i})\\big]\\hat{e}_{u,i}=e_{u,i}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and ", "page_idx": 13}, {"type": "equation", "text": "$$\nf(1,\\hat{p}_{u,i})e_{u,i}+g(1,\\hat{p}_{u,i})\\hat{e}_{u,i}=\\frac{e_{u,i}-g(0,\\hat{p}_{u,i})(1-p_{u,i})\\hat{e}_{u,i}}{p_{u,i}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let us consider the variance of the estimator $L$ . It satisfies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Big|=\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{\\sigma}\\Bigg[\\Bigg(\\sum_{(u_{i},i)\\in\\mathcal{D}}\\Big(f(\\alpha_{u_{i},i},\\hat{p}_{u_{i},i})e_{u_{i},i}+g(o_{u_{i},i},\\hat{p}_{u_{i},i})\\hat{e}_{u_{i},i}\\Big)\\Bigg)^{2}\\Bigg]}\\\\ &{\\quad-\\frac{1}{|\\mathcal{D}|^{2}}\\Bigg(\\sum_{(u_{i},i)\\in\\mathcal{D}}\\Big[f\\big(1,\\hat{p}_{u_{i},i}\\big)p_{u_{i},i}e_{u_{i},i}+\\big(g(1,\\hat{p}_{u_{i},i})p_{u_{i},i}+g(0,\\hat{p}_{u_{i},i})\\big(1-p_{u_{i},i}\\big)\\big)\\hat{e}_{u_{i},i}\\Big]\\Bigg)^{2}}\\\\ &{\\quad=\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u_{i},i)\\in\\mathcal{D}}\\Big[\\mathbb{E}_{\\sigma}\\Big[\\Big(f\\big(\\alpha_{u_{i},i},\\hat{p}_{u_{i},i}\\big)e_{u_{i},i}+g(o_{u_{i},i},\\hat{p}_{u_{i},i})\\hat{e}_{u_{i},i}\\Big)^{2}\\Big]}\\\\ &{\\quad\\quad-\\Big[f\\big(1,\\hat{p}_{u_{i},i}\\big)p_{u_{i},i}e_{u_{i},i}+\\big[g\\big(1,\\hat{p}_{u_{i},i}\\big)p_{u_{i},i}+g\\big(0,\\hat{p}_{u_{i},i}\\big)\\big(1-p_{u_{i},i}\\big)\\big]\\hat{e}_{u_{i},i}\\Big]^{2}\\Bigg]}\\\\ &{\\quad=\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u_{i},i)\\in\\mathcal{D}}\\Big[\\mathbb{E}_{\\sigma}\\Big[\\Big(f\\big(\\alpha_{u_{i},i},\\hat{p}_{u_{i},i}\\big)e_{u_{i},i}+g\\big(\\alpha_{u_{i},i},\\hat{p}_{u_{i},i}\\big)\\hat{e}_{u_{i},i}\\Big)^{2}\\Big]-e_{u_{i},i}^{2}\\Big]\\qquad\\mathrm{b e\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let us focus on the fist term in (15).  Denote $f(o_{u,i},\\hat{p}_{u,i})e_{u,i}~+~g(o_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}$ as $r(o_{u,i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})$ . Then, the first term in (15) satisfies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{\\boldsymbol{\\mathcal{O}}}\\bigg[\\bigg(\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}r(\\sigma_{u,i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})\\bigg)^{2}\\bigg]}\\\\ &{\\qquad\\qquad=\\frac{1}{|\\mathcal{D}|^{2}}\\displaystyle\\sum_{j=1}^{|\\mathcal{D}|}\\sum_{k=1}^{|\\mathcal{D}|}\\mathbb{E}_{\\boldsymbol{\\omega}}\\bigg[r(\\sigma_{j},\\hat{p}_{j},e_{j},\\hat{e}_{j})r(\\rho_{k},\\hat{p}_{k},e_{k},\\hat{e}_{k})\\bigg]}\\\\ &{\\qquad\\qquad\\geq\\frac{1}{|\\mathcal{D}|^{2}}\\displaystyle\\sum_{j=1}^{|\\mathcal{D}|}\\mathbb{E}_{\\boldsymbol{\\mathcal{O}}}\\big[r^{2}(\\sigma_{j},\\hat{p}_{j},e_{j},\\hat{e}_{j})\\big]\\qquad\\mathrm{because~of}\\,r(\\rho_{u,i},\\hat{p}_{u,i},e_{u,i},\\hat{e}_{u,i})\\geq0}\\\\ &{\\qquad\\qquad=\\frac{1}{|\\mathcal{D}|^{2}}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\mathbb{E}_{\\boldsymbol{\\mathcal{O}}}\\bigg[\\big(f(\\sigma_{u,i},\\hat{p}_{u,i})e_{u,i}+g(\\sigma_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}\\big)^{2}\\bigg]}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "According to (15) and (16), the variance of the estimator $L$ satisfies ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L]\\geq\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Bigg[\\mathbb{E}_{O}\\Big[\\Big(f(\\alpha_{u,i},\\hat{p}_{u,i})e_{u,i}+g(\\alpha_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}\\Big)^{2}\\Big]}\\\\ &{\\qquad\\quad-\\Big[f(1,\\hat{p}_{u,i})p_{u,i}e_{u,i}+\\big[g(1,\\hat{p}_{u,i})p_{u,i}+g(0,\\hat{p}_{u,i})(1-p_{u,i})\\big]\\hat{e}_{u,i}\\Big]^{2}\\Bigg]}\\\\ &{\\qquad=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Bigg[\\mathbb{E}_{O}\\Big[\\Big(f(\\alpha_{u,i},\\hat{p}_{u,i})e_{u,i}+g(\\alpha_{u,i},\\hat{p}_{u,i})\\hat{e}_{u,i}\\Big)^{2}\\Big]-e_{u,i}^{2}\\Bigg]}\\\\ &{\\qquad=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Bigg[\\Big[f(1,\\hat{p}_{u,i})e_{u,i}+g(1,\\hat{p}_{u,i})\\hat{e}_{u,i}\\Big]^{2}p_{u,i}+g^{2}\\big(0,\\hat{p}_{u,i})\\hat{e}_{u,i}^{2}\\big(1-p_{u,i}\\big)-e_{u,i}^{2}\\Bigg]}\\\\ &{\\qquad=\\displaystyle\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\frac{1-p_{u,i}}{p_{u,i}}\\Big[e_{u,i}-g(0,\\hat{p}_{u,i})\\hat{e}_{u,i}\\Big]^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, when the propensity tends to zero, for any $e_{u,i}-g(0,\\hat{p}_{u,i})\\hat{e}_{u,i}\\neq0$ . the limit of the variance satisfies $\\mathrm{lim}_{p_{u,i}\\to0}^{\\ \\bar{}}\\,\\mathbb{V}_{O}[L]\\,=\\,\\infty$ . Since the generalization bound contains the bias and variance terms, the generalization bound is also unbounded when the propensity tends to zero. The proof is completed. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "D  Proofs of Properties for Fine-Grained Dynamic Estimators ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma D.1 (Bias of D-IPS and D-DR). Given prediction errors $e_{u,i}$ imputed errors $\\hat{e}_{u,i}.$ .and learned propensities $\\hat{p}_{u,i}$ for all user-item pairs $(u,i)$ the biases of the $D$ -IPS and $D$ -DR methods are given as ", "page_idx": 14}, {"type": "equation", "text": "$$\nB i a s(L_{D\\cdot I P s})=\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}h_{B}^{E u t}(\\hat{p}_{u,i},p_{u,i},\\alpha)e_{u,i}\\bigg\\rvert,\\;B i a s(L_{D\\cdot D R})=\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}h_{B}^{E u t}(\\hat{p}_{u,i},p_{u,i},\\alpha)\\delta_{u,i}\\bigg\\rvert,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the function hB satisfies h(pui,Pui \u03b1) =1 - Fp) ", "page_idx": 14}, {"type": "text", "text": "Proof. According to the definition of bias (6), the biases of D-IPS and D-DR are formulated as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Bias}(L_{\\mathrm{D\\cdotIPs}})=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i}-\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotIPs}}]\\bigg\\rvert=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(1-\\frac{p_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\bigg)e_{u,i}\\bigg\\rvert,}\\\\ &{\\mathrm{Bias}(L_{\\mathrm{D\\cdotDR}})=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i}-\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotDR}}]\\bigg\\rvert=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\bigg\\lvert\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(1-\\frac{p_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\bigg)\\delta_{u,i}\\bigg\\rvert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lemma D.2 (Variance of D-IPS and D-DR). Given $e_{u,i},~\\hat{e}_{u,i},$ and $\\hat{p}_{u,i}$ for all $(u,i)\\,\\in\\,\\mathcal{D}$ the variances of the $D$ -IPS and $D$ -DR methods are given as ", "page_idx": 14}, {"type": "text", "text": "$\\mathbb{V}_{O}[L_{D.I P S}]=\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}h_{V}^{E s t}(\\hat{p}_{u,i},p_{u,i},\\alpha)e_{u,i}^{2},\\;\\mathbb{V}_{O}[L_{D.D R}]=\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}h_{V}^{E s t}(\\hat{p}_{u,i},p_{u,i},\\alpha)\\delta_{u,i}^{2},\\;\\mathbb{V}_{O}[L_{D.D R}]$ ", "page_idx": 14}, {"type": "text", "text": "where thefton satisfesh(Pu,Pu \u03b1) P) ", "page_idx": 14}, {"type": "text", "text": "Proof. Considering the definition of the variance, we obtain the variances of D-IPS and D-DR as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L_{\\mathrm{D.IPS}}]=\\!\\mathbb{E}_{O}[L_{\\mathrm{D.IPS}}^{2}]-\\mathbb{E}_{O}^{2}[L_{\\mathrm{D.IPS}}]}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{O}\\bigg[\\bigg(\\sum_{(u,i)\\in\\mathcal{D}}\\frac{O_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}e_{u,i}\\bigg)^{2}\\bigg]-\\frac{1}{|\\mathcal{D}|^{2}}\\bigg(\\sum_{(u,i)\\in\\mathcal{D}}\\frac{p_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}e_{u,i}\\bigg)^{2}}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\frac{1}{|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\frac{p_{u,i}(1-p_{u,i})}{f^{2\\alpha}(\\hat{p}_{u,i})}e_{u,i}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}_{O}[L_{\\mathrm{D-DR}}]=\\!\\mathbb{E}_{O}[L_{\\mathrm{D-DR}}^{2}]-\\mathbb{E}_{O}^{2}[L_{\\mathrm{EIB}}]}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\frac{1}{|\\mathcal{D}|^{2}}\\mathbb{E}_{O}\\bigg[\\bigg(\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{O u,i}{f^{\\alpha}(\\hat{p}_{u,i})}\\delta_{u,i}\\bigg)^{2}\\bigg]-\\frac{1}{|\\mathcal{D}|^{2}}\\bigg(\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{p_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\delta_{u,i}\\bigg)^{2}}\\\\ &{\\quad\\quad\\quad\\quad=\\!\\frac{1}{|\\mathcal{D}|^{2}}\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{p_{u,i}(1-p_{u,i})}{f^{2\\alpha}(\\hat{p}_{u,i})}\\delta_{u,i}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proposition D.3 (Monotonicity of Bias and Variance). For IPS-based and $D R$ -baseddynamic learning frameworks, and given $e_{u,i}$ $\\boldsymbol{u},i,\\,\\hat{e}_{u,i},\\,\\hat{p}_{u,i}$ for all $(u,i)\\in\\mathcal{D}_{i}$ f $f(\\hat{p}_{u,i})\\geq\\hat{p}_{u,i}$ and the parameter $\\alpha\\in[0,1]$ is increasing,thenbiasesof $D$ -IPSand $D{-}D R$ aremonotonicallydecreasingandtheir variances are monotonically increasing when learned propensities are accurate. ", "page_idx": 15}, {"type": "text", "text": "Proof. According to the determining functions $h_{B}(\\hat{p}_{u,i},p_{u,i},\\alpha)$ and $h_{V}(\\hat{p}_{u,i},p_{u,i},\\alpha)$ in the bias and variance, the first derivative of $h_{B}$ and $h_{V}$ versus $\\alpha$ are derived as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\partial h_{B}(\\hat{p}_{u,i},p_{u,i},\\alpha)}{\\partial\\alpha}=\\frac{p_{u,i}\\ln(f(\\hat{p}_{u,i}))}{f^{\\alpha}(\\hat{p}_{u,i})},\\;\\frac{\\partial h_{V}(\\hat{p}_{u,i},p_{u,i},\\alpha)}{\\partial\\alpha}=-\\frac{2p_{u,i}(1-p_{u,i})\\ln(f(\\hat{p}_{u,i}))}{f^{2\\alpha}(\\hat{p}_{u,i})}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For all $\\hat{p}_{u,i}~~\\in~~(0,1)$ ,we have $\\ln(f(\\hat{p}_{u,i}))\\;\\;<\\;\\;0$ Therefore, $\\frac{\\partial h_{B}(\\hat{p}_{u,i},p_{u,i},\\alpha)}{\\partial\\alpha}~~<~~0$ and hv (Pui.Pust.)> 0 result in the monotonically decreasing function hg and the monotonicaly increasing $h_{V}$ for all user-item pairs $(u,i)$ as the number of $\\bar{\\alpha}\\in[0,1]$ increases. Note the function $f(\\hat{p}_{u,i})$ satisfies $f(\\hat{p}_{u,i})\\geq\\hat{p}_{u,i}$ , which implies that $h_{B}\\geq0$ and $h_{V}>0$ when learned propensities are accurate. Therefore, biases of D-IPS and D-DR are monotonically decreasing and their variances are monotonically increasing when learned propensities are accurate. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Lemma D.4 (Tail Bounds of D-IPS and D-DR). Given $\\hat{e}_{u,i}$ and $\\hat{p}_{u,i}$ for all $(u,i)\\in\\mathcal{D}_{i}$ for any prediction results, with probability $1-\\rho$ the deviation of $D$ -IPS and $D$ -DR estimators from their expectations satisfy ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Big|L_{D-I P S}-\\mathbb{E}_{O}[L_{D-I P S}]\\Big|\\le_{\\sqrt{\\frac{\\log(\\frac{2}{\\rho})}{2|{\\mathcal D}|^{2}}}\\sum_{(u,i)\\in{\\mathcal D}}\\left(\\frac{e_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\right)^{2}},}\\\\ {\\Big|L_{D-D R}-\\mathbb{E}_{O}[L_{D-D R}]\\Big|\\le_{\\sqrt{\\frac{\\log(\\frac{2}{\\rho})}{2|{\\mathcal D}|}}\\sum_{(u,i)\\in{\\mathcal D}}\\left(\\frac{\\delta_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\right)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. Let $X_{u,i}^{\\mathrm{D-IPS}}$ and $X_{u,i}^{\\mathrm{D-DR}}$ be new random variables, which are defined as $\\begin{array}{r}{X_{u,i}^{\\mathrm{D-IPS}}=\\frac{o_{u,i}}{f^{\\alpha}\\left(\\hat{p}_{u,i}\\right)}e_{u,i}}\\end{array}$ and xD.DR =eu, + Fo( , respectively. Considering the independent observation indicators $\\{o_{u,i}|(u,i)\\in\\mathcal{D}\\}$ random variables $\\{X_{u,i}^{\\mathrm{D-IPS}}|(u,i)\\in\\mathcal{D}\\}$ and $\\{X_{u,i}^{\\mathrm{D-DR}}|(u,i)\\in\\mathcal{D}\\}$ are independent ofeachother Then,the probabilitydistributin $X_{u,i}^{\\mathrm{D-IPS}}$ and $X_{u,i}^{\\mathrm{D-DR}}$ can be obtained as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Pr}\\bigg(X_{u,i}^{\\mathrm{D-IPS}}=\\frac{e_{u,i}}{f^{\\alpha}\\left(\\hat{p}_{u,i}\\right)}\\bigg)=p_{u,i},\\,\\mathrm{Pr}(X_{u,i}^{\\mathrm{D-IPS}}=0)=1-p_{u,i},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\!\\left(X_{u,i}^{\\mathrm{D.DR}}=\\hat{e}_{u,i}+\\frac{\\delta_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\right)=p_{u,i},\\operatorname*{Pr}(X_{u,i}^{\\mathrm{D.DR}}=\\hat{e}_{u,i})=1-p_{u,i}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "According to the Hoeffding's inequality, for any $\\varepsilon>0$ , we have the following inequality ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\biggl(\\biggl|\\sum_{(u,i)\\in\\mathcal{D}}X_{u,i}-\\mathbb{E}_{O}\\biggl[\\sum_{(u,i)\\in\\mathcal{D}}X_{u,i}\\biggr]\\biggr|\\geq\\varepsilon\\biggr)\\leq2\\exp\\bigg(\\frac{-2\\varepsilon^{2}}{(u,i)\\in\\mathcal{D}}\\bigg),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\begin{array}{r}{g(\\hat{p}_{u,i},e_{u,i})\\:=\\:\\frac{e_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}}\\end{array}$ for D-IPS and $\\begin{array}{r}{g(\\hat{p}_{u,i},\\delta_{u,i})\\;=\\;\\frac{\\delta_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}}\\end{array}$ for D-DR. Let $\\begin{array}{r}{\\gamma\\,=\\,\\frac{\\varepsilon}{|\\mathcal{D}|}}\\end{array}$ Therefore, (22) can be rewritten as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\!\\left(\\left|L_{\\mathrm{D-IPS}}-\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}]\\right|\\geq\\gamma\\right)\\leq2\\exp\\left(\\frac{-2(\\gamma|\\mathcal{D}|)^{2}}{(u,i)\\!\\in\\!\\mathcal{D}}\\right)\\!.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\mathrm{Pr}\\Big(\\Big|L_{\\mathrm{D-IPS}}-\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}]\\Big|\\geq\\gamma\\Big)=\\rho$ . According to the inequality (23), the errors $\\gamma$ for D-IPS and D-DR can be solved as in (21). \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Theorem 3.5. The optimal parameter $\\alpha_{u,i}^{\\mathrm{opt}}$ Lth a prensit acat. $\\hat{p}_{u,i}=p_{u,i}$ For weights $w_{1}$ and $w_{2}$ , the objective function $w_{1}h_{B}^{\\mathrm{Est}}\\!+\\!w_{2}h_{V}^{\\mathrm{Est}}$ under $\\alpha\\in[0,1]$ achieves its minimum at ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\alpha_{\\mathrm{opt}}=\\operatorname*{min}{\\bigg\\{\\operatorname*{max}\\bigg\\{\\frac{\\ln{\\bigg(\\frac{2w_{2}}{w_{1}}(1-p_{u,i})\\bigg)}}{\\ln(f(p_{u,i}))},0\\bigg\\},1\\bigg\\}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. The first derivative of the objective function $w_{1}h_{B}^{\\mathrm{Est}}(\\alpha_{\\mathrm{opt}})+w_{2}h_{V}^{\\mathrm{Est}}(\\alpha_{\\mathrm{opt}})$ versus $\\alpha$ is derived as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\mathrm{Objective}\\left(\\hat{p}_{u,i},p_{u,i},\\alpha\\right)}{\\partial\\alpha}=w_{1}\\frac{\\partial h_{B}^{\\mathrm{Est}}\\left(\\hat{p}_{u,i},p_{u,i},\\alpha\\right)}{\\partial\\alpha}+w_{2}\\frac{\\partial h_{B}^{\\mathrm{Est}}\\left(\\hat{p}_{u,i},p_{u,i},\\alpha\\right)}{\\partial\\alpha}}\\\\ {=w_{1}\\frac{p_{u,i}\\ln\\left(f\\left(\\hat{p}_{u,i}\\right)\\right)}{f^{\\alpha}\\left(\\hat{p}_{u,i}\\right)}-w_{2}\\frac{2p_{u,i}\\left(1-p_{u,i}\\right)\\ln\\left(f\\left(\\hat{p}_{u,i}\\right)\\right)}{f^{2\\alpha}\\left(\\hat{p}_{u,i}\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let objetiv(@lp=Pui) be zero. Then the optimal \u03b1 satisfies ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\alpha_{\\mathrm{opt}}=\\frac{\\ln\\left(\\frac{2w_{2}}{w_{1}}(1-p_{u,i})\\right)}{\\ln(f(p_{u,i}))}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note that $\\alpha$ needs to fulfill $0\\leq\\alpha\\leq1$ . Therefore, the solution of the optimization problem with the constraint can be obtained. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Theorem 3.6. (Generalization Bounds of D-IPS and D-DR). For any finite hypothesis space $\\mathcal{H}$ of $\\hat{Y}$ and the optimal prediction matrix ${\\hat{Y}}^{-}$ , given $\\hat{e}_{u,i}$ and $\\hat{p}_{u,i}$ for all $(u,i)\\in\\mathcal{D}$ , with probability $1-\\rho$ the prediction inaccuracies $L_{\\mathrm{D-IPS}}({\\hat{Y}}^{-},Y)$ and $L_{\\mathrm{D-DR}}({\\hat{Y}}^{-},Y)$ under D-IPS and D-DR have the following upper bounds ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\mathrm{D-IPS}}(\\hat{Y}^{-},Y^{O})+\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{\\vert h_{B}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha)e_{u,i}^{-}\\vert}{|\\mathcal{D}|}+h_{G}^{\\mathrm{Est}}(e_{u,i}^{+}),}\\\\ &{L_{\\mathrm{D-DR}}(\\hat{Y}^{-},Y^{O})+\\displaystyle\\sum_{(u,i)\\in\\mathcal{D}}\\frac{\\vert h_{B}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha)\\delta_{u,i}^{-}\\vert}{|\\mathcal{D}|}+h_{G}^{\\mathrm{Est}}(\\delta_{u,i}^{+}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $e_{u,i}^{+}$ and $\\delta_{u,i}^{+}$ are the error and error deviation corresponding to $\\hat{Y}^{+}\\quad=$ $\\begin{array}{r}{\\operatorname*{max}_{\\hat{Y}\\in\\mathcal{H}}\\bigg\\{\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(\\frac{e_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\bigg)^{2}\\bigg\\}}\\end{array}$ $\\begin{array}{r}{\\hat{Y}^{+}=\\arg\\operatorname*{max}_{\\hat{Y}\\in\\mathcal{H}}\\bigg\\{\\sum_{(u,i)\\in\\mathcal{D}}\\bigg(\\frac{\\delta_{u,i}}{f^{\\alpha}(\\hat{p}_{u,i})}\\bigg)^{2}\\bigg\\}}\\end{array}$ tively, and the function $h_{G}^{\\mathrm{Est}}$ is formulated as ", "page_idx": 16}, {"type": "equation", "text": "$$\nh_{G}^{\\mathrm{Est}}(z_{u,i}^{+})=\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}}\\sum_{(u,i)\\in\\mathcal{D}}\\Big(\\frac{z_{u,i}^{+}}{f^{\\alpha}(\\hat{p}_{u,i})}\\Big)^{2}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. According to the definition of bias, the differences between $L_{\\mathrm{real}}(\\hat{Y},Y)$ and expectations of $L_{\\mathrm{D-IPS}}({\\hat{Y}}^{-},Y^{O})$ and $L_{\\mathrm{D-DR}}({\\hat{Y}}^{-},Y^{O})$ satisfy ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\mathrm{real}}(\\hat{Y}^{-},Y)-L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})=\\!L_{\\mathrm{real}}(\\hat{Y}^{-},Y)-\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})]+\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})]-L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\!\\mathrm{Bias}(L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-}))+\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})]-L_{\\mathrm{D\\cdotIPs}}(\\hat{Y}^{-})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\mathrm{real}}(\\hat{Y}^{-},Y)-L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-})=\\!L_{\\mathrm{real}}(\\hat{Y}^{-},Y)-\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-})]+\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-})]-L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\!\\mathrm{Bias}(L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-}))+\\mathbb{E}_{O}[L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-})]-L_{\\mathrm{D\\cdotDR}}(\\hat{Y}^{-}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "respectively. From the inequalities (28) and (29), the expressions of $\\mathrm{Bias}\\big(L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})\\big)$ and Bias $\\overset{\\prime}{L}_{\\mathrm{D-DR}}(\\hat{Y}^{-}))$ have been given in Lemma 3.6 and, in what follows, terms $\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})]-$ $L_{\\mathrm{D-IPS}}({\\hat{Y}}^{-})$ in (28) and $\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})]-L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})$ in (29) are discussed. Considering the finite ", "page_idx": 16}, {"type": "text", "text": "hypothesis space $\\mathcal{\\hat{H}}\\,=\\,\\{\\hat{Y}^{1},\\hat{Y}^{2},...,\\hat{Y}^{|\\mathcal{H}|}\\}$ and the Hoeffding's inequality, for any $\\varepsilon\\ >\\ 0$ the following inequalities can be obtained ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\Big(\\Big|L_{\\mathrm{{DMS}}}(\\hat{Y}^{-})-\\mathbb{E}_{\\mathcal{O}}[L_{\\mathrm{OIS}}(\\hat{Y}^{-})]\\Big|\\leq\\gamma\\Big)=1-\\operatorname*{Pr}\\Big(\\Big|L_{\\mathrm{OPS}}(\\hat{Y}^{-})-\\mathbb{E}_{\\mathcal{O}}[L_{\\mathrm{OIS}}(\\hat{Y}^{-})]\\Big|\\geq\\gamma\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq1-\\operatorname*{Pr}\\Big(\\frac{\\operatorname*{max}}{\\operatorname*{Pr}^{+}\\in\\mathcal{H}}[L_{\\mathrm{OPS}}(\\hat{Y}^{+})]-\\mathbb{E}_{\\mathcal{O}}[L_{\\mathrm{OPS}}(\\hat{Y}^{+})]\\Big|\\geq\\gamma\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\geq1-\\displaystyle\\sum_{k=1}^{\\mathcal{M}}\\operatorname*{Pr}\\Big(\\Big|L_{\\mathrm{OPS}}(\\hat{Y}^{+})-\\mathbb{E}_{\\mathcal{O}}[L_{\\mathrm{OPS}}(\\hat{Y}^{+})]\\Big|\\geq\\gamma\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ &{\\qquad\\qquad\\qquad=1-\\displaystyle\\sum_{k=1}^{\\mathcal{M}}2\\exp\\Big(\\frac{-2(\\gamma)[\\mathcal{D}]^{2}}{(u_{k})\\log^{2}(\\hat{Y}_{k})\\phi_{k}^{-})_{k}}\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\geq1-2|\\mathcal{M}|\\exp\\Big(\\frac{-2(\\gamma)[\\mathcal{D}]^{2}}{(u_{k})\\log^{2}(\\hat{Y}_{k})\\phi_{k}\\phi_{k}^{-})_{k}}\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\operatorname*{Pr}\\Big(\\Big|L_{\\mathrm{OPS}}(\\hat{Y}^{-})-\\mathbb{E}_{\\mathcal{O}}[L_{\\mathrm{OPS}}(\\hat{Y}^{-})]\\Big|\\leq\\gamma\\Big)\\geq1-2|\\mathcal{M}|\\exp\\Big(\\frac{-2(\\gamma)[\\mathcal{D}]^{2}}{(u_{k})\\log^{2}(\\hat{Y}_{k})\\phi_{k}\\phi_{k}^{-})}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $2|\\mathcal{H}|\\exp\\left(\\frac{-2(\\gamma|\\mathcal{D}|)^{2}}{\\sum_{(u,i)\\in\\mathcal{D}}g^{2}(\\widehat{p}_{u,i},Z_{u,i}^{+})}\\right)$ be $\\rho$ . The errors $\\gamma_{\\mathrm{D-IPS}}$ and $\\gamma_{\\mathrm{D-DR}}$ for D-IPS and D-DR can be solved as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\gamma_{\\mathrm{D-IPS}}=\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Big(\\frac{e_{u,i}^{+}}{f^{\\alpha}(\\hat{p}_{u,i})}\\Big)^{2}},\\ \\gamma_{\\mathrm{D-DR}}=\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Big(\\frac{\\delta_{u,i}^{+}}{f^{\\alpha}(\\hat{p}_{u,i})}\\Big)^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, $\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})]-L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})$ in (28) and $\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})]-L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})$ in (29) fulfill ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{O}[L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})]-L_{\\mathrm{D-IPS}}(\\hat{Y}^{-})\\leq\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Big(\\frac{e_{u,i}^{+}}{f^{\\alpha}(\\hat{p}_{u,i})}\\Big)^{2}},}\\\\ {\\mathbb{E}_{O}[L_{\\mathrm{D-DR}}(\\hat{Y}^{-})]-L_{\\mathrm{D-DR}}(\\hat{Y}^{-})\\leq\\sqrt{\\frac{\\log(\\frac{2|\\mathcal{H}|}{\\rho})}{2|\\mathcal{D}|^{2}}\\sum_{(u,i)\\in\\mathcal{D}}\\Big(\\frac{\\delta_{u,i}^{+}}{f^{\\alpha}(\\hat{p}_{u,i})}\\Big)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combining (28), (29) and (32), we can obtain the generalization bounds of D-IPS and D-DR given in Lemma 3.11. ", "page_idx": 17}, {"type": "text", "text": "Theorem 3.7. (Boundedness of Variance and Generalization Bounds). Let $\\alpha_{u,i}^{\\mathrm{opt}}\\in[0,1]$ be the optimal parameter of (4). If the dynamic estimators adopt $\\alpha_{u,i}^{\\mathrm{opt}}$ as the parameter, then the corresponding variance and generalization bounds are bounded. ", "page_idx": 17}, {"type": "text", "text": "Proof. Considering the optimal parameter $\\alpha_{u,i}^{\\mathrm{opt}}$ for each user-item pair $(u,i)$ and the optimization problem (4), we can obtain the corresponding optimal objective function ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Objective}^{\\mathrm{opt}}=w_{1}E_{B}\\big(h_{B}^{\\mathrm{Est}}(\\alpha_{u,i}^{\\mathrm{opt}})\\big)+w_{2}E_{V}\\big(h_{V}^{\\mathrm{Est}}(\\alpha_{u,i}^{\\mathrm{opt}})\\big)\\leq w_{1}E_{B}\\big(h_{B}^{\\mathrm{Est}}(0)\\big)+w_{2}E_{V}\\big(h_{V}^{\\mathrm{Est}}(0)\\big).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since $h_{B}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha)>0$ and $h_{V}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha)>0$ , considering (33), we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w_{2}E_{V}(h_{V}^{\\mathrm{Est}}(\\alpha_{u,i}^{\\mathrm{opt}}))\\leq w_{1}E_{B}(h_{B}^{\\mathrm{Est}}(0))+w_{2}E_{V}(h_{V}^{\\mathrm{Est}}(0))}\\\\ &{\\qquad\\qquad\\qquad\\qquad=w_{1}E_{B}(1-p_{u,i})+w_{2}E_{V}(p_{u,i}(1-p_{u,i})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{V}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i}^{\\mathrm{pt}})=\\frac{p_{u,i}(1-p_{u,i})}{f^{2\\alpha_{u,i}^{\\mathrm{opt}}}(\\hat{p}_{u,i})}}\\\\ &{\\qquad\\qquad\\qquad\\leq E_{V}^{-1}\\Bigl(\\frac{w_{1}E_{B}(1-p_{u,i})}{w_{2}}+E_{V}\\bigl(p_{u,i}(1-p_{u,i})\\bigr)\\Bigr)}\\\\ &{\\qquad\\qquad=E_{V}^{-1}\\Bigl(\\frac{w_{1}E_{B}(1)}{w_{2}}+E_{V}\\bigl(0.25\\bigr)\\Bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, the variance of dynamic estimators are bounded by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}o[L_{\\mathrm{D-IPS}}|\\alpha=\\alpha_{u,i}^{\\mathrm{opt}}]=\\cfrac{1}{|\\mathcal{D}|^{2}}\\,\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\,h_{V}^{\\mathrm{Eq}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i}^{\\mathrm{opt}})e_{u,i}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\cfrac{1}{|\\mathcal{D}|^{2}}\\,\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\,E_{V}^{-1}\\Big(\\cfrac{w_{1}E_{B}(1)}{w_{2}}+E_{V}\\left(0.25\\right)\\Big)e_{u,i}^{2},}\\\\ &{\\mathbb{V}o[L_{\\mathrm{D-DR}}|\\alpha=\\alpha_{u,i}^{\\mathrm{opt}}]=\\cfrac{1}{|\\mathcal{D}|^{2}}\\,\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\,h_{V}^{\\mathrm{Eq}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i}^{\\mathrm{opt}})\\delta_{u,i}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\cfrac{1}{|\\mathcal{D}|^{2}}\\,\\underset{(u,i)\\in\\mathcal{D}}{\\sum}\\,E_{V}^{-1}\\Big(\\cfrac{w_{1}E_{B}(1)}{w_{2}}+E_{V}\\left(0.25\\right)\\Big)\\delta_{u,i}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Considering the expression of $h_{G}^{\\mathrm{Est}}(z_{u,i}^{+})$ in generalization bounds and the boundedness of $h_{V}^{\\mathrm{Est}}(\\hat{p}_{u,i},p_{u,i},\\alpha_{u,i}^{\\mathrm{opt}})$ , it is easy to obtain that under $\\rho~\\neq~0$ the generalization bounds of $L_{\\mathrm{D-IPS}}$ and $L_{\\mathrm{D-DR}}$ are bounded. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: see Introduction ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: see section 5 Conclusions ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: See Appendix ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: see section 4 Experiments ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to acces this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: see section 4 Experiments Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so ^No\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: see subsection 4.1 Experimental Setup Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: see subsection 4.3 Ablation Studies ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: see section 4 Experiments ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Every approach in Experiments is preformed261 10 times to record its mean and standard deviation. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: see Introduction ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Three real-world public datasets are used in Experiments. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: see Section 4 Experiments ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 23}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: This problem is inapplicable to this paper. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: This problem is inapplicable to this paper. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: The datasets used in this paper are public. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]