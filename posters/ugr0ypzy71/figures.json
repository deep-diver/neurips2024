[{"figure_path": "Ugr0yPzY71/figures/figures_3_1.jpg", "caption": "Figure 1: Bar plots showing that most attributes are not modified by the majority of adversarial examples on the mnist and webspam datasets. The leftmost bar shows the number of attributes that are never changed by any of the 10000 adversarial examples generated by kantchelian's approach. The middle bar shows the number of attributes that are modified at least once but at most by 5% of the adversarial examples. The rightmost bar shows the number of frequently modified features.", "description": "This figure shows the distribution of modified attributes in adversarial examples generated for the mnist and webspam datasets using the kantchelian approach.  The x-axis categorizes attributes based on the frequency of their modification (never, less than 5%, or greater than or equal to 5%). The y-axis represents the number of attributes falling into each category. The results highlight that a relatively small set of attributes are consistently perturbed to generate adversarial examples, suggesting an opportunity for optimization.", "section": "3 Method"}, {"figure_path": "Ugr0yPzY71/figures/figures_4_1.jpg", "caption": "Figure 2: An example tree using two attributes HEIGHT and AGE (left). Suppose FNS = {AGE}. Given an example where AGE = 55, we can prune away the internal node splitting on AGE. In the resulting tree (right), subtree (b) is pruned because it is unreachable given that AGE = 55 and only subtrees (a) and (c) remain.", "description": "This figure illustrates the pruning process in the paper's proposed approach.  The left side shows a tree with two attributes, HEIGHT and AGE, where AGE is a split condition below a HEIGHT split. The right side demonstrates the pruning of the subtree (b) under the condition that the AGE attribute is fixed to a value (55) that is greater than the split threshold (50).  This pruning is based on the fact that the path to subtree (b) is now unreachable given the fixed value of AGE.  The result is a simplified tree that is more computationally efficient for the algorithms that generate adversarial examples.", "section": "3.1 Modifying the Search Procedure"}, {"figure_path": "Ugr0yPzY71/figures/figures_7_1.jpg", "caption": "Figure 3: Average run times for 10000 calls to full, pruned and mixed for kantchelian (top) and veritas (bottom). Results are given for both XGBoost and random forest for four selected datasets.", "description": "This figure compares the run times of three adversarial example generation methods: full, pruned, and mixed.  The methods are applied using two different algorithms (kantchelian and veritas) for both XGBoost and random forest models. The results are shown for four representative datasets (mnist, prostate, roadsafety, sensorless).  The figure visually demonstrates the significant speedup achieved by the pruned and mixed methods, especially compared to the original full search approach.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/figures/figures_8_1.jpg", "caption": "Figure 4: Generated adversarial examples for an mnist digit and an XGBoost ensemble, using both attacks (full vs pruned).", "description": "This figure displays adversarial examples generated for a handwritten digit '2' from the MNIST dataset using two different attack methods: Kantchelian and Veritas.  Each attack method is shown with two variants: the 'full' version where all features can be modified, and a 'pruned' version where only a subset of features determined to be most frequently perturbed are modified.  The goal is to show that using a pruned set of features does not significantly impact the quality of the adversarial examples generated, while drastically reducing the computation time.", "section": "3 Method"}, {"figure_path": "Ugr0yPzY71/figures/figures_8_2.jpg", "caption": "Figure 5: Run time of full, mixed and pruned settings using veritas XGB, veritas RF, kantchelian XGB on mnist, and varying the max depth (top) and number of estimators in the ensemble (bottom).", "description": "This figure shows how the run time to perform 10000 adversarial example generation searches varies as a function of the maximum tree depth (top) and the number of trees in the ensemble (bottom).  The results are shown for three settings: full, pruned, and mixed.  The full setting represents the original approach; the pruned setting only allows modifications to a subset of frequently perturbed features; and the mixed setting combines the pruned and full settings. The figure shows that the pruned and mixed approaches exhibit much better scaling behavior than the full search, particularly as the complexity of the ensemble increases.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/figures/figures_9_1.jpg", "caption": "Figure 6: Speedups achieved by the pruned setting when attempting to generate 10000 adversarial examples using kantchelian (left) and veritas (right) on an XGB ensemble, varying the empirical false negative rate. The dotted horizontal line corresponds to a speedup of 1x, i.e., same run time of the full setting.", "description": "This figure shows the relationship between the empirical false negative rate (FNR) and speedup achieved by using the pruned approach for generating adversarial examples. The empirical FNR is the percentage of times where the pruned approach fails to find an adversarial example while the full approach succeeds.  The x-axis represents the empirical FNR, and the y-axis represents the speedup.  The dotted line indicates the speedup is equal to 1, which means there is no speedup using the pruned method. The figure shows that as the FNR increases, the speedup also increases. This is because a higher FNR corresponds to smaller feature subsets, leading to a faster pruned search, even though there is a trade-off because a smaller feature subset can result in more false negatives.", "section": "3.2 Identifying Relevant Features"}, {"figure_path": "Ugr0yPzY71/figures/figures_16_1.jpg", "caption": "Figure 7: Run times to attempt to generate adversarial examples for 10000 test examples with the three presented settings (full, pruned and mixed), using kantchelian on an XGBoost/random forest/GROOT forest ensemble, averaged over 5 folds.", "description": "This figure shows the run time performance comparison of three adversarial example generation methods: full, pruned, and mixed.  The experiment involves generating 10,000 adversarial examples using the Kantchelian method on three types of tree ensembles: XGBoost, Random Forest, and GROOT. The figure presents results averaged over 5 folds of cross-validation for 10 datasets. Each subplot represents a single dataset and shows how the number of searches (y-axis) increases over time (x-axis) for each of the three methods.  The pruned and mixed methods aim to improve performance by limiting perturbations to a subset of features, which explains their faster convergence in most cases when compared to the full approach which explores the complete feature space.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/figures/figures_17_1.jpg", "caption": "Figure 3: Average run times for 10000 calls to full, pruned and mixed for kantchelian (top) and veritas (bottom). Results are given for both XGBoost and random forest for four selected datasets.", "description": "This figure shows the run time performance of three different approaches (full, pruned, and mixed) for generating adversarial examples using two different attack methods (kantchelian and veritas) on two different types of tree ensembles (XGBoost and random forest). The results are displayed for four selected datasets (mnist, prostate, roadsafety, and sensorless). It demonstrates the efficiency gains achieved by the pruned and mixed approaches in comparison to the standard full approach.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/figures/figures_20_1.jpg", "caption": "Figure 6: Speedups achieved by the pruned setting when attempting to generate 10000 adversarial examples using kantchelian (left) and veritas (right) on an XGB ensemble, varying the empirical false negative rate. The dotted horizontal line corresponds to a speedup of 1x, i.e., same run time of the full setting.", "description": "The figure shows the relationship between empirical false negative rate and speedup for the pruned setting in the context of adversarial example generation.  It displays four separate plots, two for each evasion attack (Kantchelian and Veritas). Each plot shows the relationship for a different dataset (mnist, prostate, roadsafety, sensorless) and uses XGBoost. The speedup is the run time of the full approach relative to that of the pruned approach, with the empirical false negative rate being the fraction of times the pruned search reported UNSAT while the full search reported SAT.  Higher FNR generally indicates greater speedup because it implies the pruning removed many less important attributes that reduced search space without significantly harming the attack's accuracy. The dotted line at 1x speedup represents the baseline (no speedup).", "section": "3.2 Identifying Relevant Features"}, {"figure_path": "Ugr0yPzY71/figures/figures_25_1.jpg", "caption": "Figure 4: Generated adversarial examples for an mnist digit and an XGBoost ensemble, using both attacks (full vs pruned).", "description": "This figure shows adversarial examples generated for MNIST digits using both the Kantchelian and Veritas attacks, comparing the results obtained when using the full method (allowing modifications to all features) against the pruned method (restricting modifications to a subset of frequently perturbed features).  The goal is to visually demonstrate the similarity of adversarial examples generated by both methods, supporting the claim that the pruned approach effectively generates similar adversarial examples more quickly.", "section": "3 Method"}]