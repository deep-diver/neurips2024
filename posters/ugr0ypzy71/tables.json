[{"figure_path": "Ugr0yPzY71/tables/tables_6_1.jpg", "caption": "Table 1: Datasets' characteristics: N and #F are the number of examples and the number of features. higgs and prostate are random subsets of the original, bigger datasets. Multi-class classification datasets were converted to binary classification: for covtype we predict majority-vs-rest, for mnist and fmnist we predict classes 0-4 vs. classes 5-9, and for sensorless classes 0-5 vs. classes 6-10. We also report adopted values of max allowed perturbation \u03b4 and learners' tuned hyperparameters after the grid search described in Appendix B. Each ensemble T has maximum tree depth d and contains M trees. The learning rate for XGBoost is \u03b7. GROOT robustness is defined by \u03b5.", "description": "This table presents the characteristics of the ten datasets used in the experiments.  For each dataset, it shows the number of examples (N), number of features (#F), the maximum perturbation size (\u03b4) used, and hyperparameters for three different ensemble models (XGBoost, Random Forest, GROOT): the number of trees (M), maximum tree depth (d), learning rate (\u03b7 for XGBoost), and robustness parameter (\u03b5 for GROOT).  It also notes that multi-class datasets were converted to binary classification problems, specifying how this conversion was done.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_7_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average runtime and speedup achieved by applying three different approaches (full, pruned, and mixed) to generate 10,000 adversarial examples using two different attack methods (kantchelian and veritas) on two different types of tree ensembles (XGBoost and random forest).  The speedup is calculated relative to the \"full\" approach which does not use any optimization techniques. A '*' indicates that the experiment did not complete within the six-hour time limit.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_13_1.jpg", "caption": "Table 1: Datasets' characteristics: N and #F are the number of examples and the number of features. higgs and prostate are random subsets of the original, bigger datasets. Multi-class classification datasets were converted to binary classification: for covtype we predict majority-vs-rest, for mnist and fmnist we predict classes 0-4 vs. classes 5-9, and for sensorless classes 0-5 vs. classes 6-10. We also report adopted values of max allowed perturbation \u03b4 and learners' tuned hyperparameters after the grid search described in Appendix B. Each ensemble T has maximum tree depth d and contains M trees. The learning rate for XGBoost is \u03b7. GROOT robustness is defined by \u20ac.", "description": "This table presents the characteristics of the ten datasets used in the experiments.  It shows the number of examples (N), the number of features (#F), the type of classification task (binary or multi-class, converted to binary),  the maximum allowed perturbation (\u03b4), and the hyperparameters of the trained models (XGBoost, Random Forest, GROOT).  The hyperparameters include maximum tree depth (d), the number of trees (M), learning rate (\u03b7 for XGBoost), and robustness parameter (\u03b5 for GROOT).", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_13_2.jpg", "caption": "Table 4: Average run times for generating 10000 adversarial examples using LT-attack and veritas in the full search setting.", "description": "This table compares the run times of the LT-attack and veritas methods for generating 10000 adversarial examples using a full search.  The run times are presented for four datasets: mnist, prostate, roadsafety, and sensorless. The table highlights the significant speed improvement achieved by the veritas method compared to the LT-attack method in the full search setting for adversarial example generation.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_14_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average runtime and speedup achieved by using three different approaches (full, pruned, and mixed) for generating 10000 adversarial examples using two different attack methods (kantchelian and veritas) on two different ensemble types (XGBoost and Random Forest). The speedup is calculated by comparing the runtime of the pruned and mixed approaches to the runtime of the full approach.  A star (*) indicates that the dataset exceeded the allocated time limit of six hours. The results are presented for several datasets, allowing for a comprehensive analysis of the methods' performance under different circumstances. ", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_15_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average run time performance of generating 10000 adversarial examples using two different attack methods (kantchelian and veritas) and three different model types (XGBoost, random forest, and a robustified ensemble type GROOT).  The table compares the runtime for three different approaches: the original \"full\" approach, a \"pruned\" approach that restricts modifications to a subset of frequently perturbed features, and a \"mixed\" approach that uses the pruned approach first and falls back to the full approach only when necessary.  The table shows that the pruned and mixed approaches offer significant speedups over the full approach, especially for Random Forest models.  The '*' indicates that the dataset exceeded the time limit of six hours for the full search.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_18_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average runtime and speedup achieved by using three different approaches (full, pruned, and mixed) for generating 10,000 adversarial examples using two different attack methods (kantchelian and veritas) on two different ensemble types (XGBoost and random forest).  The speedup is calculated relative to the \"full\" approach, which doesn't use any of the optimizations proposed in the paper. The table shows the runtime for each approach on several datasets, highlighting the significant speed improvements achieved by the pruned and mixed methods. An asterisk (*) indicates datasets where the full approach exceeded the six-hour time limit.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_19_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average run times for generating 10000 adversarial examples using two different attack methods (kantchelian and veritas) on two different ensemble types (XGBoost and Random Forest). It compares the performance of three approaches: full (original method), pruned (proposed method), and mixed (combination of full and pruned). The table shows that the proposed methods (pruned and mixed) significantly reduce the runtime compared to the full approach, especially for larger datasets. A '*' indicates that the experiment exceeded the six-hour time limit.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_20_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average runtime and speedup achieved by using three different methods (full, pruned, and mixed) to generate 10,000 adversarial examples using two different attack algorithms (kantchelian and veritas) on XGBoost and random forest ensemble models. The speedup is calculated by comparing the runtime of the pruned and mixed methods to the runtime of the full method.  A '*' indicates that the experiment timed out before completion (exceeded a six-hour limit).", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_21_1.jpg", "caption": "Table 10: Fraction of pruned timeouts and speedup of the pruned and mixed settings when attempting to generate 10000 adversarial examples for fmnist using (veritas, random forest), for different values of the pruned setting timeout tprun (in seconds).", "description": "This table shows the impact of varying the timeout value for the pruned setting (tprun) on the performance of the pruned and mixed approaches.  It presents the percentage of timeouts observed in the pruned setting, as well as the speedup factors achieved by the pruned and mixed approaches relative to the full approach for different timeout values. The results demonstrate a trade-off: a smaller timeout leads to fewer timeouts but lower speedups, while a larger timeout results in more timeouts but higher speedups.  The optimal timeout value balances speed improvements with the number of timeouts.", "section": "D.2 Sensitivity to Timeouts"}, {"figure_path": "Ugr0yPzY71/tables/tables_22_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average run time in seconds for generating 10000 adversarial examples using two different attack methods (kantchelian and veritas) and three different ensemble types (XGBoost, random forest).  For each combination of attack method and ensemble type, the table displays the average run time for three different experimental settings: full (original method), pruned (proposed method with feature subset selection), and mixed (combination of the full and pruned methods).  The table also indicates cases where the runtime exceeded the 6 hour time limit with a *. Speedup is calculated by comparing the average runtime for the full setting to the average run times for the pruned and mixed settings. This table helps in evaluating the efficiency gains of the proposed feature subset selection method. ", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_23_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average run time and speedup achieved by using three different approaches (full, pruned, and mixed) to generate 10000 adversarial examples using two different attack methods (kantchelian and veritas) on two different types of ensembles (XGBoost and random forest). The speedup is calculated by comparing the runtime of each approach to the runtime of the full approach. A * indicates that the dataset exceeded the global timeout of 6 hours.  The results demonstrate the significant speedup achieved by the pruned and mixed settings across various datasets and ensemble types.", "section": "4 Experiments"}, {"figure_path": "Ugr0yPzY71/tables/tables_24_1.jpg", "caption": "Table 2: Average run times and speedups when attempting to generate 10000 adversarial examples using kantchelian/veritas on an XGBoost/random forest ensemble for full, pruned and mixed. A * means that the dataset exceeded the global timeout of six hours.", "description": "This table presents the average runtime and speedup achieved by using three different approaches (full, pruned, and mixed) to generate 10000 adversarial examples using two different attack methods (kantchelian and veritas) on two types of ensemble models (XGBoost and random forest).  The speedup is calculated relative to the 'full' approach. A '*' indicates that the experiment exceeded the six-hour time limit.", "section": "4 Experiments"}]