[{"figure_path": "lpFDhC91Oj/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of our black-box forgetting framework. The confidence of each class is computed as the similarity with the image and class (text) embeddings from the black-box pre-trained vision-language model (e.g., CLIP). The obtained confidence is used to compute the respective loss functions for the classes to be forgotten and the classes to be memorized. (a) For the classes to be forgotten, maximize the entropy of the confidence so that the accuracy is reduced. (b) For the classes to be memorized, minimize the cross-entropy loss to retain the accuracy. These two objective are jointly optimized to tune the learnable text prompt. The gradients of the objective are not available when the model is black-box. We therefore use CMA-ES [Hansen et al., 2003], a derivative-free optimizer, to learn the text prompt. Instead of directly optimizing the original high-dimensional context (token) embeddings for the prompt, our method learns lower-dimensional latent contexts for mitigating the difficulty of high-dimensional optimization.", "description": "This figure illustrates the Black-Box Forgetting framework.  It shows how the model uses a learnable text prompt to selectively reduce the accuracy of specified classes while maintaining accuracy for others. The process involves computing class confidence scores based on image and text embeddings, then optimizing two loss functions: entropy maximization for classes to be forgotten and cross-entropy minimization for classes to be memorized. Derivative-free optimization (CMA-ES) is used because model gradients are unavailable in black-box settings.  Latent Context Sharing (LCS) is employed to reduce the complexity of high-dimensional optimization.", "section": "3 Method"}, {"figure_path": "lpFDhC91Oj/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of our black-box forgetting framework. The confidence of each class is computed as the similarity with the image and class (text) embeddings from the black-box pre-trained vision-language model (e.g., CLIP). The obtained confidence is used to compute the respective loss functions for the classes to be forgotten and the classes to be memorized. (a) For the classes to be forgotten, maximize the entropy of the confidence so that the accuracy is reduced. (b) For the classes to be memorized, minimize the cross-entropy loss to retain the accuracy. These two objectives are jointly optimized to tune the learnable text prompt. The gradients of the objective are not available when the model is black-box. We therefore use CMA-ES [Hansen et al., 2003], a derivative-free optimizer, to learn the text prompt. Instead of directly optimizing the original high-dimensional context (token) embeddings for the prompt, our method learns lower-dimensional latent contexts for mitigating the difficulty of high-dimensional optimization.", "description": "This figure illustrates the Black-Box Forgetting framework.  It shows how the system uses a pre-trained vision-language model (like CLIP) to estimate class confidence.  This confidence is then used in two loss functions: one to maximize entropy for classes to be forgotten (reducing accuracy), and one to minimize cross-entropy for classes to be remembered (maintaining accuracy).  Because the model is a black box, derivative-free optimization (CMA-ES) is used to optimize the input prompt.  Latent Context Sharing (LCS) is employed to reduce the dimensionality of the optimization problem.", "section": "3 Method"}, {"figure_path": "lpFDhC91Oj/figures/figures_7_1.jpg", "caption": "Figure 3: Sensitivity to the number of latent contexts. Results of BBT [Sun et al., 2022b] and Ours for varying number of the latent contexts. We can see that our method shows stable performance within a wide range of the number of latent contexts in contrast BBT.", "description": "This figure shows how the performance of the proposed method and the baseline method (BBT) changes with the number of latent contexts.  The x-axis represents the number of latent contexts (m), and the y-axis shows the performance metrics (H, Err_for, Acc_mem). The results indicate that the proposed method maintains relatively stable performance across a wide range of m values, while the BBT method's performance is more sensitive to changes in m.", "section": "4.3 Analysis"}, {"figure_path": "lpFDhC91Oj/figures/figures_8_1.jpg", "caption": "Figure 1: Overview of our black-box forgetting framework. The confidence of each class is computed as the similarity with the image and class (text) embeddings from the black-box pre-trained vision-language model (e.g., CLIP). The obtained confidence is used to compute the respective loss functions for the classes to be forgotten and the classes to be memorized. (a) For the classes to be forgotten, maximize the entropy of the confidence so that the accuracy is reduced. (b) For the classes to be memorized, minimize the cross-entropy loss to retain the accuracy. These two objective are jointly optimized to tune the learnable text prompt. The gradients of the objective are not available when the model is black-box. We therefore use CMA-ES [Hansen et al., 2003], a derivative-free optimizer, to learn the text prompt. Instead of directly optimizing the original high-dimensional context (token) embeddings for the prompt, our method learns lower-dimensional latent contexts for mitigating the difficulty of high-dimensional optimization.", "description": "This figure illustrates the Black-Box Forgetting framework.  It shows how the confidence scores for each class are calculated using a pre-trained vision-language model (like CLIP) and how these scores are used to define loss functions. For classes to be forgotten, entropy maximization is used to reduce accuracy, while for classes to be remembered, cross-entropy minimization maintains accuracy.  The framework uses CMA-ES, a derivative-free optimization method, to optimize the text prompt, and employs Latent Context Sharing (LCS) to reduce the complexity of high-dimensional optimization.", "section": "3 Method"}, {"figure_path": "lpFDhC91Oj/figures/figures_9_1.jpg", "caption": "Figure 3: Sensitivity to the number of latent contexts. Results of BBT [Sun et al., 2022b] and Ours for varying number of the latent contexts. We can see that our method shows stable performance within a wide range of the number of latent contexts in contrast BBT.", "description": "This figure shows the impact of the number of latent contexts (m) on the performance of both BBT and the proposed method.  The x-axis represents the number of latent contexts, while the y-axis shows the three evaluation metrics: H (harmonic mean of forgetting and memorization accuracy), Err_for (error rate for forgotten classes), and Acc_mem (accuracy for memorized classes). The figure demonstrates that the proposed method maintains relatively stable performance across a range of m values, unlike BBT, which shows significant performance fluctuations.", "section": "4.3 Analysis"}]