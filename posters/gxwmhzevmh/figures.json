[{"figure_path": "gXWmhzeVmh/figures/figures_1_1.jpg", "caption": "Figure 1: A representation of the multi-view signature. The continuous-time path is irregularly sampled at points marked with a red x. The local and global signatures of a linear interpolation of these points are computed and concatenated to form the multi-view signature. The multi-view signature transform consists of multi-view signatures.", "description": "This figure illustrates the concept of a multi-view signature, a key component of the Rough Transformer architecture.  It shows how an irregularly sampled continuous-time path (represented by the black curve with red x's marking sample points) is transformed into a multi-view signature. This transformation involves two steps: 1) Linear interpolation of the irregularly sampled path to create a continuous representation, 2) Computation of both local (blue) and global (green) signatures of the interpolated path. These local and global signatures capture both local and global dependencies in the input time-series. Finally, the local and global signatures are concatenated to form the multi-view signature, which is then used as input to the Rough Transformer.", "section": "Contributions"}, {"figure_path": "gXWmhzeVmh/figures/figures_4_1.jpg", "caption": "Figure 2: Seconds per epoch for growing input length and for different model types on the sinusoidal dataset. Left: Log Scale. Middle: Regular Scale. Right: Log-log scale. When a line stops, it indicates an OOM error.", "description": "This figure compares the training time (seconds per epoch) of various models on a sinusoidal dataset as the input sequence length increases.  The x-axis represents input length, and the y-axis shows seconds per epoch. The three subplots show the data using different scales: log scale, regular scale, and log-log scale.  The different colored lines represent different models (Transformer, ContiFormer, Rough Transformer (Online and Offline), Neural CDE, Neural RDE).  When a line stops, it means that the model ran out of memory (OOM).  The figure demonstrates the superior computational efficiency of the Rough Transformer, particularly as the sequence length grows.", "section": "3.1 Advantages of Rough Transformers"}, {"figure_path": "gXWmhzeVmh/figures/figures_5_1.jpg", "caption": "Figure 3: Test accuracy per epoch for the frequency classification task across three random seeds. Left: Sinusoidal dataset. Right: Long Sinusoidal dataset.", "description": "This figure shows the test accuracy per epoch for a frequency classification task. The task is performed on two datasets: a standard sinusoidal dataset and a more challenging \"long sinusoidal\" dataset.  The figure compares the performance of several models: Transformer, RFormer, Neural ODE (NRDE), Neural Controlled Differential Equation (NCDE), ODE-RNN, and GRU.  The plots illustrate the learning curves across three different random seeds, demonstrating the relative performance and convergence speed of each model on both datasets. The results show that the Rough Transformer (RFormer) outperforms other models in accuracy and convergence speed, particularly on the more challenging \"long sinusoidal\" dataset.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/figures/figures_8_1.jpg", "caption": "Figure 4: Average performance of all models on the 15 univariate datasets from the UEA Time Series archive under different degrees of data drop.", "description": "This figure shows the average performance of various models (RFormer, CRU, Neural SDE, Neural LSDE, Neural LNSDE, Neural GSDE, Neural CDE, Neural RDE) on 15 univariate datasets from the UEA Time Series archive under different data drop percentages (30%, 50%, 70%).  The x-axis represents the data drop percentage, and the y-axis represents the accuracy.  The figure demonstrates the robustness of RFormer to irregular sampling, maintaining relatively high accuracy even with significant data loss compared to other models.", "section": "4.3 Irregular Time Series Classification"}, {"figure_path": "gXWmhzeVmh/figures/figures_9_1.jpg", "caption": "Figure 5: Left: Graph connectivity structures for multivariate, univariate and sparse signature. Middle: Example samples for synthetic task. Right: Performance on spatial synthetic experiment.", "description": "This figure demonstrates the spatial processing capabilities of the Rough Transformer.  The left panel shows different graph structures representing the relationships between channels processed by the different signature types: multivariate, univariate, and sparse. The middle panel displays example samples from the synthetic experiment designed to evaluate spatial processing.  The right panel shows the performance comparison between the Rough Transformer and a vanilla Transformer on the synthetic spatial task, highlighting the Rough Transformer's superior sample efficiency and accuracy.", "section": "5 Reasons for improved model performance"}, {"figure_path": "gXWmhzeVmh/figures/figures_9_2.jpg", "caption": "Figure 6: Left: Dirichlet energy as a function of window size for the Eigenworms dataset. Right: Original and hidden representation after signature layer for two examples in the EW dataset.", "description": "This figure shows the impact of different window sizes on the Eigenworms dataset. The left panel shows a plot of the Dirichlet energy against the number of windows used for the global signature. The Dirichlet energy measures the smoothness of the representation. The right panel shows the original and compressed representations of two examples from the dataset after the signature layer. The compressed representations show that the signature transform effectively captures the essential information while reducing the dimensionality of the data.", "section": "5 Reasons for improved model performance"}, {"figure_path": "gXWmhzeVmh/figures/figures_21_1.jpg", "caption": "Figure 7: Ablation of local and local components of the multi-view signature for the sinusoidal datasets. Left: Sinusoidal dataset. Right: Long Sinusoidal dataset.", "description": "This figure shows the ablation study of the multi-view signature on the sinusoidal datasets. It compares the performance of using both global and local components of the signature against using only one of them.  The left panel shows the results for the standard sinusoidal dataset, while the right panel presents the results for the long sinusoidal dataset. The results indicate that using both global and local components generally leads to better performance than using only one type of component. This highlights the importance of considering both local and global dependencies for accurate and efficient time series modeling.", "section": "F.1 Global and Local Signature Components"}, {"figure_path": "gXWmhzeVmh/figures/figures_22_1.jpg", "caption": "Figure 3: Test accuracy per epoch for the frequency classification task across three random seeds. Left: Sinusoidal dataset. Right: Long Sinusoidal dataset.", "description": "This figure shows the test accuracy per epoch for a frequency classification task using different models.  Two datasets were used: a standard sinusoidal dataset and a \"long sinusoidal\" dataset. The \"long sinusoidal\" dataset is more complex, featuring a change in frequency midway through the time series, thus challenging the models' ability to capture long-range dependencies.  The results are averaged over three random seeds to show variability.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/figures/figures_25_1.jpg", "caption": "Figure 2: Seconds per epoch for growing input length and for different model types on the sinusoidal dataset. Left: Log Scale. Middle: Regular Scale. Right: Log-log scale. When a line stops, it indicates an OOM error.", "description": "This figure compares the training time (seconds per epoch) of different models on a sinusoidal dataset as the input sequence length increases.  The x-axis represents the input sequence length, and the y-axis shows the seconds per epoch.  Three subplots are provided: one with a logarithmic scale on both axes, one with a linear scale on the y-axis, and one with a logarithmic scale on the x-axis. The different colored lines represent different models: Transformer, ContiFormer, Rough Transformer (online), and Rough Transformer (offline).  When a line abruptly ends, it indicates that the model ran out of memory (OOM).  This figure highlights the computational efficiency of Rough Transformers, especially compared with the other models.", "section": "3.1 Advantages of Rough Transformers"}]