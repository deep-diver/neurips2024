[{"figure_path": "gXWmhzeVmh/tables/tables_6_1.jpg", "caption": "Table 1: Test RMSE (mean \u00b1 std) computed across five seeds on the Heart Rate (HR) dataset.", "description": "This table presents the test root mean squared error (RMSE) results for different models on the Heart Rate dataset.  The RMSE is a measure of the average difference between predicted and actual heart rates.  Lower RMSE values indicate better performance. The results are averaged across five separate trials (seeds) to provide a more robust estimate of model performance.  The models compared include ODE-RNN, Neural-CDE, Neural-RDE, GRU, a standard Transformer model, ContiFormer, and the proposed Rough Transformer (RFormer).  The plus sign (+) in Neural-RDE+ indicates the authors' own reproduction of a result from another paper.  'OOM' stands for 'out of memory' and indicates that the ContiFormer model was unable to run on the given dataset due to memory limitations. The table highlights that RFormer achieves the lowest RMSE value, signifying superior performance.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_6_2.jpg", "caption": "Table 2: Classification performance on various long context temporal datasets from UCR TS archive.", "description": "This table presents the classification performance of different models on several long temporal datasets from the UCR Time Series Classification Archive.  The datasets vary in characteristics like sequence length, number of classes, and dimensionality.  The models compared include traditional machine learning methods like GRU, Neural CDE, Neural RDE, and LogCDE, as well as the vanilla Transformer and the proposed Rough Transformer (RFormer).  The results show the average accuracy of each model across multiple runs, highlighting RFormer's competitive performance and efficiency.", "section": "4 Experiments"}, {"figure_path": "gXWmhzeVmh/tables/tables_7_1.jpg", "caption": "Table 3: Seconds per epoch for all models considered.", "description": "This table presents the training efficiency (seconds per epoch) for various models considered in the paper.  It compares the Rough Transformer (RFormer) against several baseline models, including GRU, ODE-RNN, Neural-CDE, Neural-RDE, and the standard Transformer.  The results highlight the significant computational advantages of RFormer, especially when dealing with the Heart Rate dataset.", "section": "4.2 Training Efficiency"}, {"figure_path": "gXWmhzeVmh/tables/tables_7_2.jpg", "caption": "Table 4: Dataset processing times for training, validation, and testing phases.", "description": "This table presents the time taken (in seconds) to process each dataset during the training, validation, and testing phases.  The datasets include Eigenworms, HR (Heart Rate), and Sine wave datasets with varying lengths (1k, 5k, 20k, 100k samples). The table shows the computational efficiency of the Rough Transformer on datasets of various sizes. ", "section": "4.2 Training Efficiency"}, {"figure_path": "gXWmhzeVmh/tables/tables_8_1.jpg", "caption": "Table 5: Performance of all models under a random 50% drop in datapoints per epoch.", "description": "This table presents the performance of various models (GRU, ODE-RNN, Neural-RDE, Transformer, and RFormer) on different tasks (EW, HR, Sine, Sine Long) when 50% of the data points are randomly dropped per epoch.  It demonstrates the robustness of the RFormer model to irregular sampling, showing consistent superior performance compared to other models, even with significant data loss.", "section": "4.3 Irregular Time Series Classification"}, {"figure_path": "gXWmhzeVmh/tables/tables_18_1.jpg", "caption": "Table 6: Hyperparameters used for Table 2, where G and L refer to the Global and Local signature components, respectively.", "description": "This table lists the hyperparameters used in the experiments reported in Table 2 of the paper.  It shows the batch size, embedding dimension, multi-view terms (using global [G] or local [L] signatures, or a combination of both), learning rate, number of attention heads, number of layers, number of signature windows, signature level, whether univariate signatures were used, and the number of training epochs for six different datasets: SCP1, SCP2, MI, EW, ETC, and HB.", "section": "C Experimental Details"}, {"figure_path": "gXWmhzeVmh/tables/tables_19_1.jpg", "caption": "Table 7: Hyperparameters validation on remaining datasets.", "description": "This table shows the hyperparameters used for validation on the remaining datasets after hyperparameter tuning on the sinusoidal dataset.  It details the learning rate, number of windows used in the multi-view signature transform, signature depth, type of signature used (Multi-view or Local), and whether univariate or multivariate signatures were employed for each dataset (Sinusoidal, HR).", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_19_2.jpg", "caption": "Table 8: Validation accuracy on the sinusoidal dataset.", "description": "This table presents the validation accuracy results for different hyperparameter settings (Step and Depth) of the Neural-RDE model on the sinusoidal dataset.  It shows the trade-off between model complexity (memory usage) and performance (accuracy) with varying step and depth values, which are crucial for tuning the model.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_19_3.jpg", "caption": "Table 9: Validation accuracy on the long sinusoidal dataset.", "description": "This table presents the validation accuracy results for the long sinusoidal dataset.  It shows the accuracy achieved by the model with different hyperparameter settings (Step and Depth) of the Neural RDE model. Each row represents a different configuration, showing the resulting validation accuracy, memory usage, and elapsed time.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_20_1.jpg", "caption": "Table 10: Validation accuracy on the EW dataset.", "description": "This table presents the validation accuracy achieved by the Rough Transformer model on the EigenWorms (EW) dataset.  It shows the accuracy for different combinations of 'Step' and 'Depth' parameters within the multi-view signature transform. The memory usage (in MB) and elapsed training time (in seconds) are also reported for each configuration.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_20_2.jpg", "caption": "Table 1: Test RMSE (mean \u00b1 std) computed across five seeds on the Heart Rate (HR) dataset.", "description": "This table presents the test root mean squared error (RMSE) results for different models on the Heart Rate dataset.  The RMSE is a measure of the models' prediction accuracy, with lower values indicating better performance. The results are averaged across five random seeds to account for variability.  Models include ODE-RNN, Neural-CDE, Neural-RDE, GRU, a standard Transformer, and the proposed Rough Transformer.  The table shows that the Rough Transformer outperforms all other models except Neural-RDE, highlighting its effectiveness on this task.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_20_3.jpg", "caption": "Table 12: Validation loss on the LOB dataset (1K), included as an additional experiment in Appendix G.4.", "description": "This table shows the validation loss for different hyperparameter settings (Step and Depth) of the Rough Transformer model on the LOB (Level 1) dataset with 1000 data points.  The table details the validation loss, step size, depth, memory usage, and elapsed time for each hyperparameter configuration. It demonstrates the impact of these parameters on the model's performance.", "section": "G Additional Experiments and Comparisons"}, {"figure_path": "gXWmhzeVmh/tables/tables_21_1.jpg", "caption": "Table 13: Summary of datasets used in the long time-series classification task.", "description": "This table presents a summary of the five long temporal datasets used for the long time-series classification experiments in the paper.  For each dataset, the table shows the number of sequences, the length of each sequence, the number of classes, and the number of dimensions.", "section": "E Long Temporal Datasets Details"}, {"figure_path": "gXWmhzeVmh/tables/tables_21_2.jpg", "caption": "Table 14: Comparative performance of different methods on datasets.", "description": "This table compares the performance of Linear Interpolation + Vanilla Transformer against Rough Transformer with different signature levels (n) on two datasets: EigenWorms and HR.  The \"Improvement\" column shows the percentage increase in performance achieved by the Rough Transformer over the baseline method.  The number in parentheses after the signature level indicates the level used for that particular dataset's Rough Transformer result.", "section": "F.2 Signature Level and Naive Downsampling"}, {"figure_path": "gXWmhzeVmh/tables/tables_22_1.jpg", "caption": "Table 15: Performance of models under various data drop scenarios for EW dataset.", "description": "This table shows the performance of different models on the EigenWorms dataset under various data drop scenarios.  The \"Full\" column represents the performance on the complete dataset, while the other columns show performance when 30%, 50%, 70%, and 85% of the data is randomly dropped. The results highlight the robustness of the RFormer model compared to the Transformer model, especially under high data drop rates.  The Transformer model fails to run at higher drop rates due to memory limitations, indicating its sensitivity to reduced data size.", "section": "G.1 Random Drop Experiments"}, {"figure_path": "gXWmhzeVmh/tables/tables_22_2.jpg", "caption": "Table 16: Performance consistency of RFormer under data drop scenarios for HR dataset.", "description": "This table shows the Root Mean Squared Error (RMSE) for the Heart Rate (HR) dataset under different percentages of randomly dropped data points (30%, 50%, 70%).  It demonstrates the robustness of the Rough Transformer (RFormer) model, showing only a small increase in error even when a significant portion of the data is missing.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_22_3.jpg", "caption": "Table 18: Epoch-wise performance under different data drop scenarios for the long sinusoidal dataset", "description": "This table presents the test accuracy of different models on the long sinusoidal dataset with 30% and 70% of data randomly dropped per epoch. The results are shown for epochs 100, 250, 500, and 1000, providing insights into model performance under different data scarcity conditions.", "section": "4.1 Time Series Processing"}, {"figure_path": "gXWmhzeVmh/tables/tables_22_4.jpg", "caption": "Table 18: Epoch-wise performance under different data drop scenarios for the long sinusoidal dataset.", "description": "This table shows the test accuracy of different models at various epochs (100, 250, 500, 1000) under different data drop scenarios (30% and 70%). The results are based on the long sinusoidal dataset.  It highlights the model's performance under data scarcity.", "section": "4.3 Irregular Time Series Classification"}, {"figure_path": "gXWmhzeVmh/tables/tables_23_1.jpg", "caption": "Table 19: Comparison of RFormer and CRU (two best and simplest performing instances [Num.basis/Bandwidth= 20/3]) at different random drop percentages.", "description": "This table compares the performance of RFormer and CRU models on an irregularly sampled synthetic dataset with varying random drop percentages (0%, 30%, 50%, 70%, and 85%).  The results show the accuracy of each model for different sequence lengths (100, 250, and 500) under different data drop scenarios, highlighting the robustness of RFormer to irregular sampling.", "section": "G.2 Additional Efficiency Experiments and Discussion"}, {"figure_path": "gXWmhzeVmh/tables/tables_23_2.jpg", "caption": "Table 20: CRU's hyperparameters (L = 100) (latent state dimension (LSD), number of basis matrices (Num.basis), and their bandwidth).", "description": "This table presents the hyperparameters used for the CRU model in the experiments with L=100.  It shows different combinations of latent state dimension (LSD), number of basis matrices (Num. basis), and bandwidth, and reports the accuracy achieved after 30 epochs of training for each hyperparameter configuration.", "section": "G.2 Additional Efficiency Experiments and Discussion"}, {"figure_path": "gXWmhzeVmh/tables/tables_24_1.jpg", "caption": "Table 21: Seconds per epoch for growing input length and for different model types on the sinusoidal dataset.", "description": "This table presents the training time (seconds per epoch) for various sequence lengths (from 100 to 10,000) using different models: NRDE, NCDE, GRU, CRU, ContiFormer, Transformer, and RFormer (with online and offline signature computation).  It demonstrates the computational efficiency of the Rough Transformer, especially as sequence length increases, where other models experience out-of-memory (OOM) errors or significant slowdowns.", "section": "4.2 Training Efficiency"}, {"figure_path": "gXWmhzeVmh/tables/tables_24_2.jpg", "caption": "Table 21: Seconds per epoch for growing input length and for different model types on the sinusoidal dataset.", "description": "This table presents the computational efficiency of various time series models (NRDE, NCDE, GRU, CRU, Contiformer, Transformer, RFormer(Online), RFormer(Offline)) for different input sequence lengths (L=100, L=250, L=500, L=1000, L=2500, L=5000, L=7.5k, L=10k). It shows the time taken per epoch (seconds) for each model as the input length increases. This is a key result highlighting the computational advantage of the proposed Rough Transformer model (RFormer) over other methods, especially for longer sequences.", "section": "4.2 Training Efficiency"}, {"figure_path": "gXWmhzeVmh/tables/tables_24_3.jpg", "caption": "Table 23: Processing times for different sizes on the sinusoidal dataset.", "description": "This table presents the processing times for different sequence lengths (sizes) on the sinusoidal dataset.  It shows how the time required for processing increases as the length of the sequence increases. The times are given in seconds.", "section": "4.2 Training Efficiency"}, {"figure_path": "gXWmhzeVmh/tables/tables_25_1.jpg", "caption": "Table 24: Model performance for L = 100.", "description": "This table compares the performance of ContiFormer (with 1 and 4 heads), Transformer (1 head), and RFormer (1 head) models on a sinusoidal classification task with input sequence length L=100.  The results are shown for epochs 100, 250, and 500, highlighting the training progress and the relative performance of each model.", "section": "G.3 Additional ContiFormer Comparisons"}, {"figure_path": "gXWmhzeVmh/tables/tables_26_1.jpg", "caption": "Table 25: Test RMSE (mean \u00b1 std) and average seconds per epoch (S/E), computed across five seeds on the LOB dataset, on a scale of 10<sup>-2</sup>.", "description": "This table presents the results of a time-to-cancellation prediction task on limit order book (LOB) data using different models. It shows the Root Mean Squared Error (RMSE) and seconds per epoch (S/E) for each model with two different context window sizes (1k and 20k).  The RMSE is a measure of the prediction accuracy, while S/E reflects the computational efficiency. Lower RMSE values indicate better prediction accuracy, and lower S/E values indicate higher computational efficiency. The table highlights the performance of the Rough Transformer (RFormer) against several baselines, including traditional Recurrent Neural Networks (RNNs), Neural ODEs, and the vanilla Transformer.", "section": "4.3 Irregular Time Series Classification"}, {"figure_path": "gXWmhzeVmh/tables/tables_26_2.jpg", "caption": "Table 26: RMSE comparison between RFormer, Transformer, and NRDE.", "description": "This table presents a comparison of the Root Mean Squared Error (RMSE) achieved by three different models: RFormer, the standard Transformer, and the Neural Rough Differential Equation (NRDE) model.  The RMSE is a common metric used to evaluate the accuracy of regression models, where a lower RMSE indicates better performance. This table likely shows the results on a specific task or dataset to demonstrate the relative performance improvements of the RFormer model.", "section": "4.2 Training Efficiency"}]