[{"figure_path": "nrcFNxF57E/tables/tables_7_1.jpg", "caption": "Table 1a. Mean accuracy of SVM using each distance in kernel.", "description": "This table presents the mean accuracy achieved by an SVM classifier using different distance metrics (GW, MPGW, UGW, and PGW) as kernels for shape retrieval tasks on two datasets (Dataset I and Dataset II).  The accuracy reflects the percentage of correctly classified shapes using each distance metric.", "section": "5.2 Shape Retrieval"}, {"figure_path": "nrcFNxF57E/tables/tables_7_2.jpg", "caption": "Table 1b. Wall-clock time comparison.", "description": "This table shows the wall-clock time comparison of four different methods: GW, MPGW, UGW, and PGW (ours) for computing pairwise distances in two datasets, Dataset I and Dataset II.  The results show that the PGW method proposed in the paper is significantly faster than the UGW method, and has comparable speed to the GW and MPGW methods.", "section": "5.2 Shape Retrieval"}, {"figure_path": "nrcFNxF57E/tables/tables_48_1.jpg", "caption": "Table 2: Accuracy comparison of the MPGW, UGW, and the proposed PGW method on PU learning. Here, 'M' denotes MNIST, and 'EM' denotes EMNIST.", "description": "This table presents the accuracy comparison of three different methods for positive-unlabeled (PU) learning using two different datasets (MNIST and EMNIST).  Three initialization methods (POT, FLB-U, FLB-P) are used for each method. The methods compared are Mass-Constrained Partial Gromov-Wasserstein (MPGW), Unbalanced Gromov-Wasserstein (UGW), and the proposed Partial Gromov-Wasserstein (PGW) method. The table shows that the proposed PGW method achieves similar or better accuracy than the other methods across all initialization methods and datasets.", "section": "P Positive Unlabeled Learning Problem"}, {"figure_path": "nrcFNxF57E/tables/tables_49_1.jpg", "caption": "Table 3: In this table, we present the wall-clock time for the MPGW, UGW, and the proposed PGW method, as well as three different initialization methods (POT, FLB-UOT, FLB-POT). In the \"Source\" (or \"Target\") column, M (or EM) denotes the MNIST (or EMNIST) dataset, the value 1000 (or 5000) denotes the sample size of X (or Y). The units of all reported wall-clock times is seconds.", "description": "This table compares the computation time of three different methods (MPGW, UGW, PGW) with three different initialization methods (POT, FLB-UOT, FLB-P) for MNIST and EMNIST datasets. The source and target datasets are varied.  The table shows that the proposed PGW method is comparable to the other methods in terms of computation time.", "section": "P Positive Unlabeled Learning Problem"}, {"figure_path": "nrcFNxF57E/tables/tables_50_1.jpg", "caption": "Table 2: Accuracy comparison of the MPGW, UGW, and the proposed PGW method on PU learning. Here, 'M' denotes MNIST, and 'EM' denotes EMNIST.", "description": "This table compares the accuracy of three different methods (MPGW, UGW, and PGW) on positive unlabeled (PU) learning tasks using two datasets (MNIST and EMNIST).  Three initialization methods (POT, FLB-U, FLB-P) are also considered, showing accuracy for each combination of dataset, method, and initialization. The results indicate the relative performance of the three methods in the PU learning setting.", "section": "P.5 Numerical details and performance"}, {"figure_path": "nrcFNxF57E/tables/tables_51_1.jpg", "caption": "Table 2: Accuracy comparison of the MPGW, UGW, and the proposed PGW method on PU learning. Here, \u2018M\u2019 denotes MNIST, and \u2018EM\u2019 denotes EMNIST.", "description": "This table compares the accuracy of three methods (MPGW, UGW, and PGW) on positive unlabeled (PU) learning tasks using MNIST and EMNIST datasets. Three initialization methods (POT, FLB-U, and FLB-P) are used to initialize each method.  The table shows that the proposed PGW method generally achieves high accuracy, comparable or better than the other methods.", "section": "P.5 Numerical details and performance"}]