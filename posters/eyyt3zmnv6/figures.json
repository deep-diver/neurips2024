[{"figure_path": "Eyyt3ZmNV6/figures/figures_1_1.jpg", "caption": "Figure 1: The overview of existing dataset ownership verification (DOV) methods and our ZeroMark. In the verification phase, existing DOV approaches directly exploit watermarked samples for verification purposes. In contrast, ZeroMark queries the suspicious model with boundary samples without disclosing dataset-specified watermarks to safeguard the verification process.", "description": "This figure compares existing Dataset Ownership Verification (DOV) methods with the proposed ZeroMark method.  Existing DOV methods use watermarked samples directly for verification, making them vulnerable if the watermark is discovered.  ZeroMark addresses this by using boundary samples instead, which don't reveal the specific watermark, thus protecting the dataset's copyright more effectively.  The figure visually represents the steps in both approaches: watermark embedding, and verification with either watermarked samples or boundary samples.", "section": "1 Introduction"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_4_1.jpg", "caption": "Figure 2: (a) shows the watermark pattern for BadNets [29] used in our empirical study. (b) and (c) are examples of boundary gradients calculated under benign and target labels. (d) shows the distribution for the cosine similarity calculated over boundary gradients for benign and target labels. More empirical studies on other types of watermarks are included in the appendix.", "description": "This figure visualizes the results of an empirical study on the relationship between watermark patterns and boundary gradients in a watermarked DNN.  Panel (a) displays the watermark pattern used. Panels (b) and (c) showcase example boundary gradients calculated for benign and target labels, respectively.  Finally, panel (d) presents the distribution of cosine similarity scores between these boundary gradients and the watermark pattern, highlighting a key finding of the study.", "section": "3.3 The Characteristic of Boundary Gradient of Watermarked DNNS"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_6_1.jpg", "caption": "Figure 4: The example of verification samples across different watermarks (i.e., BadNets, Blended, WaNet, DW) and verification methods (i.e., Vanilla, Minimal, Distortion) on Tiny-ImageNet.", "description": "This figure shows example verification samples generated by different watermarking methods (BadNets, Blended, WaNet, and DW) and verification methods (Vanilla, Minimal, and Distortion).  It visually demonstrates how each method affects the appearance of verification samples on the Tiny-ImageNet dataset.  The figure highlights the differences between original benign samples and the variations introduced by each watermarking and verification technique.", "section": "5.1 The Performance of Verification Samples Generated by ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_8_1.jpg", "caption": "Figure 1: The overview of existing dataset ownership verification (DOV) methods and our ZeroMark. In the verification phase, existing DOV approaches directly exploit watermarked samples for verification purposes. In contrast, ZeroMark queries the suspicious model with boundary samples without disclosing dataset-specified watermarks to safeguard the verification process.", "description": "This figure compares existing Dataset Ownership Verification (DOV) methods with the proposed ZeroMark method. Existing DOV methods use watermarked samples in the verification stage, which makes them vulnerable if the watermark is compromised.  ZeroMark addresses this by using boundary samples instead, which do not contain dataset-specific watermarks and thus increase the security of the verification process.", "section": "1 Introduction"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_16_1.jpg", "caption": "Figure 2: (a) shows the watermark pattern for BadNets [29] used in our empirical study. (b) and (c) are examples of boundary gradients calculated under benign and target labels. (d) shows the distribution for the cosine similarity calculated over boundary gradients for benign and target labels.", "description": "This figure presents an empirical study on the properties of boundary gradients in watermarked DNNs.  It shows (a) a BadNets watermark pattern, (b) boundary gradients calculated for benign labels, (c) boundary gradients calculated for target labels, and (d) a distribution illustrating the cosine similarity between these gradients and the watermark pattern. The distribution shows a significant difference in cosine similarity between the benign and target labels, highlighting that boundary gradients calculated on the target label are more similar to the watermark pattern.", "section": "3.3 The Characteristic of Boundary Gradient of Watermarked DNNS"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_16_2.jpg", "caption": "Figure 2: (a) shows the watermark pattern for BadNets [29] used in our empirical study. (b) and (c) are examples of boundary gradients calculated under benign and target labels. (d) shows the distribution for the cosine similarity calculated over boundary gradients for benign and target labels.", "description": "This figure shows the watermark pattern used in the empirical study and the distribution of cosine similarity between watermark patterns and boundary gradients of the closest boundary samples.  Panels (b) and (c) show example boundary gradients for benign and target labels, illustrating that the distribution of cosine similarity is different (has larger values) for target labels compared to benign labels.", "section": "3.3 The Characteristic of Boundary Gradient of Watermarked DNNS"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_16_3.jpg", "caption": "Figure 2: (a) shows the watermark pattern for BadNets [29] used in our empirical study. (b) and (c) are examples of boundary gradients calculated under benign and target labels. (d) shows the distribution for the cosine similarity calculated over boundary gradients for benign and target labels.", "description": "This figure demonstrates the empirical results supporting Theorem 1, which states that the cosine similarity between watermark patterns and boundary gradients increases as the boundary sample is updated.  Subfigure (a) shows the watermark pattern itself. (b) and (c) illustrate example boundary gradients calculated for benign and target labels, respectively, highlighting their differing patterns. Finally, (d) presents a distribution of the cosine similarity scores, visually showing that higher cosine similarity scores are obtained for target labels.", "section": "3.3 The Characteristic of Boundary Gradient of Watermarked DNNs"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_17_1.jpg", "caption": "Figure 9: The t-SNE results with varied optimization iterations t for the embedding features of benign, watermark, and ZeroMark samples extracted from watermarked DNNs.", "description": "This figure shows the results of t-distributed stochastic neighbor embedding (t-SNE) applied to the embedding features extracted from watermarked deep neural networks (DNNs).  Four different optimization iteration counts (t=10, 20, 30, 40) are shown, each with visualizations of benign samples, watermarked samples, and samples generated by the ZeroMark method.  The t-SNE plots illustrate how the feature representations of ZeroMark-generated samples differ from those of both benign and watermarked samples across different optimization levels, supporting the algorithm's ability to distinguish between them without revealing watermark information.", "section": "5.5 A Closer Look to the Effectiveness of our ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_18_1.jpg", "caption": "Figure 9: The t-SNE results with varied optimization iterations t for the embedding features of benign, watermark, and ZeroMark samples extracted from watermarked DNNs.", "description": "This figure visualizes the embedding features of benign samples, watermarked samples, and samples generated by ZeroMark using t-SNE.  It shows how the features cluster together with varying optimization iteration steps (t=10, 20, 30, 40).  The goal is to demonstrate that ZeroMark generates samples whose features are distinct from the watermarked samples, thus protecting the watermark.", "section": "5.5 A Closer Look to the Effectiveness of our ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_18_2.jpg", "caption": "Figure 9: The t-SNE results with varied optimization iterations t for the embedding features of benign, watermark, and ZeroMark samples extracted from watermarked DNNs.", "description": "This figure visualizes the embedding features of benign samples, watermarked samples, and samples generated by the ZeroMark method using t-SNE.  The visualization shows how the different sample types cluster in the feature space for different numbers of optimization iterations (t).  It demonstrates that ZeroMark samples are distinctly separated from the watermarked samples, indicating that ZeroMark effectively avoids revealing watermark information.", "section": "5.5 A Closer Look to the Effectiveness of our ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_20_1.jpg", "caption": "Figure 2: (a) shows the watermark pattern for BadNets [29] used in our empirical study. (b) and (c) are examples of boundary gradients calculated under benign and target labels. (d) shows the distribution for the cosine similarity calculated over boundary gradients for benign and target labels.", "description": "This figure shows the watermark pattern used and examples of boundary gradients calculated for benign and target labels.  The distribution of cosine similarity between the watermark pattern and the boundary gradients is also shown. This illustrates the key finding that boundary gradients for the target label (watermarked samples) show significantly higher cosine similarity with the watermark pattern than those for benign labels.", "section": "3.3 The Characteristic of Boundary Gradient of Watermarked DNNS"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_21_1.jpg", "caption": "Figure 1: The overview of existing dataset ownership verification (DOV) methods and our ZeroMark. In the verification phase, existing DOV approaches directly exploit watermarked samples for verification purposes. In contrast, ZeroMark queries the suspicious model with boundary samples without disclosing dataset-specified watermarks to safeguard the verification process.", "description": "This figure compares the existing Dataset Ownership Verification (DOV) methods with the proposed ZeroMark method.  Existing methods directly use watermarked samples for verification, potentially revealing the watermark and making the system vulnerable. In contrast, ZeroMark uses boundary samples to verify ownership without exposing the watermarks, enhancing security.", "section": "1 Introduction"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_22_1.jpg", "caption": "Figure 1: The overview of existing dataset ownership verification (DOV) methods and our Zero-Mark. In the verification phase, existing DOV approaches directly exploit watermarked samples for verification purposes. In contrast, ZeroMark queries the suspicious model with boundary samples without disclosing dataset-specified watermarks to safeguard the verification process.", "description": "This figure illustrates the difference between existing Dataset Ownership Verification (DOV) methods and the proposed ZeroMark method.  Existing DOV methods use watermarked samples directly in the verification stage, making them vulnerable if the watermark pattern is leaked.  ZeroMark, on the other hand, uses boundary samples, which do not contain dataset-specific watermarks, to verify ownership of a dataset more securely.", "section": "1 Introduction"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_23_1.jpg", "caption": "Figure 4: The example of verification samples across different watermarks (i.e., BadNets, Blended, WaNet, DW) and verification methods (i.e., Vanilla, Minimal, Distortion) on Tiny-ImageNet.", "description": "This figure shows a comparison of verification samples generated using different watermarking techniques (BadNets, Blended, WaNet, DW) and verification methods (Vanilla, Minimal, Distortion) on the Tiny-ImageNet dataset.  Each watermarking technique embeds a unique pattern into the dataset, making the models trained on the watermarked data exhibit specific behaviors on particular samples. The verification methods then try to identify if a model was trained on the watermarked data by examining its prediction behavior on these samples. The figure visually demonstrates the differences in verification samples generated by different approaches, highlighting the variations introduced by each watermarking technique and verification method.", "section": "5.1 The Performance of Verification Samples Generated by ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_24_1.jpg", "caption": "Figure 4: The example of verification samples across different watermarks (i.e., BadNets, Blended, WaNet, DW) and verification methods (i.e., Vanilla, Minimal, Distortion) on Tiny-ImageNet.", "description": "This figure shows a comparison of verification samples generated by different watermarking methods (BadNets, Blended, WaNet, DW) and verification approaches (Vanilla, Minimal, Distortion).  Each watermarking technique embeds a unique pattern into the dataset, and the verification methods use different strategies to check if the model was trained on the watermarked dataset.  The image displays example samples from each combination, visually illustrating the differences in how the watermarks and verification methods affect the generated images.", "section": "5.1 The Performance of Verification Samples Generated by ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_24_2.jpg", "caption": "Figure 4: The example of verification samples across different watermarks (i.e., BadNets, Blended, WaNet, DW) and verification methods (i.e., Vanilla, Minimal, Distortion) on Tiny-ImageNet.", "description": "This figure visually demonstrates the verification samples generated by different watermarking methods (BadNets, Blended, WaNet, DW) and verification approaches (Vanilla, Minimal, Distortion) on the Tiny-ImageNet dataset. Each watermarking method embeds a unique pattern into the dataset, and each verification method has a unique way of using those samples to check if a model was trained on the watermarked dataset.  The image shows sample images from each combination to illustrate the differences.", "section": "5.1 The Performance of Verification Samples Generated by ZeroMark"}, {"figure_path": "Eyyt3ZmNV6/figures/figures_25_1.jpg", "caption": "Figure 22: The t-SNE clustering results for aggregated boundary samples.", "description": "This figure shows the results of t-distributed stochastic neighbor embedding (t-SNE) applied to aggregated boundary samples.  It visually represents the separation between watermark samples and those generated by ZeroMark.  The goal is to demonstrate that the aggregated boundary samples, even after an attempt to recover the watermark pattern, are distinct from the actual watermark samples, thus supporting the effectiveness of the ZeroMark method. The black points represent the (Aggregated) ZeroMark samples, while the colored points represent the watermark samples from different classes.", "section": "5.4 The Resistance to Potential Adaptive Methods"}]