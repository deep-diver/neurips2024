[{"figure_path": "opaRhDvQRD/figures/figures_2_1.jpg", "caption": "Figure 1: Real-time accuracy of OCL models trained under the standard cross entropy loss Lce both with and without pre-trained models (pre-trained on ImageNet) under our designed single task setting and the impact of some commomly used strategies[16, 49, 49]. Results on additional datasets, influence of different pre-trained models (pre-trained on different datasets, using different backbones and different pre-train tasks) and implementation details are provided in Appendix C.3.", "description": "The figure shows the real-time accuracy of online continual learning (OCL) models trained with and without pre-trained models under different settings and strategies. It aims to demonstrate the impact of single-pass training and the effectiveness of common strategies like experience replay, contrastive learning, and knowledge distillation on mitigating model's ignorance.", "section": "Unsatisfactory model performance"}, {"figure_path": "opaRhDvQRD/figures/figures_2_2.jpg", "caption": "Figure 2: Left: Throughput of the model trained using vanilla cross-entropy, experience replay [16], supervised contrastive replay [49] and distillation chain[1]. Right: Performance(AAUC: Area Under the Curve of Accuracy) and running time of the above strategies on CIFAR10. \"CE++\" denotes that we compute and perform extra gradient descent per time step to match the delay of the compared-against strategies. All experiments are conducted under single task setting.", "description": "This figure demonstrates the trade-off between model throughput and performance in online continual learning (OCL).  The left panel shows that adding techniques like experience replay, supervised contrastive replay, and distillation chains to a vanilla cross-entropy model increases training time, thus reducing throughput. The right panel shows that, while these techniques improve accuracy (measured by Area Under the Curve of Accuracy, AAUC), they still don't outperform a simple cross-entropy model that is trained multiple times (CE++) to account for the time cost of the other techniques, showcasing the limitations of the standard OCL evaluation.", "section": "2 Ignorance: Trade-off between Effective Learning and Model Throughput"}, {"figure_path": "opaRhDvQRD/figures/figures_3_1.jpg", "caption": "Figure 3: Normalized confusion matrix of NCM classifier (green) and softmax classifier (CIFAR10) (blue) with ImageNet supervised pre-trained initialization. Due to space limitations, we present a partial training process in the main text. Comprehensive training process is in AppendixE.", "description": "This figure shows the normalized confusion matrices of a Nearest Class Mean (NCM) classifier and a softmax classifier trained on the CIFAR-10 dataset.  The matrices are visualized at different stages of the training process. The NCM classifier, shown in green, uses a prototype-based approach, while the softmax classifier is in blue. The confusion matrices illustrate the models' performance in terms of correct and incorrect classifications for each class.  The ImageNet pre-trained initialization is used. The figure highlights that the softmax classifier shows early signs of an excessively sparse classifier that creates confusion between classes.", "section": "3 Myopia: Key Factor for Performance Degradation"}, {"figure_path": "opaRhDvQRD/figures/figures_4_1.jpg", "caption": "Figure 4: Left: averaged weights of the final FC layer for class 0 in CIFAR10. Right: s(w) (lower s(w) stands for increasing sparsity) of the final FC layer for w\u00ba corresponds to class 0 in CIFAR10. During the training of task 5, the class confusion occurs as Figure 3 where model classify \"car\" as \"truck\".", "description": "This figure shows two plots. The left plot displays the average weights of the final fully connected (FC) layer for class 0 in the CIFAR-10 dataset across five tasks.  The right plot shows the sparsity (inverse of s(w)) of the weights for the same class and layer.  Vertical dashed lines indicate the task where the model begins confusing 'car' with 'truck'. The plots illustrate how the model's weights and sparsity change as it learns new tasks, highlighting the increased sparsity of the classifier in later tasks, which is linked to the model's myopia.", "section": "3 Myopia: Key Factor for Performance Degradation"}, {"figure_path": "opaRhDvQRD/figures/figures_8_1.jpg", "caption": "Figure 3: Normalized confusion matrix of NCM classifier (green) and softmax classifier (CIFAR10) (blue) with ImageNet supervised pre-trained initialization. Due to space limitations, we present a partial training process in the main text. Comprehensive training process is in AppendixE.", "description": "This figure displays the confusion matrices for both NCM and softmax classifiers during the training process.  The confusion matrices visualize the model's ability to correctly classify images and show how this changes over time. The difference between the two classifier types highlights different ways the model handles learning new classes.", "section": "3 Myopia: Key Factor for Performance Degradation"}, {"figure_path": "opaRhDvQRD/figures/figures_8_2.jpg", "caption": "Figure 6: Left: Sensitivity analysis on \u03c4 and \u03b3. Right: Sparsity (1/s(w)) of the classifier under different algorithms.", "description": "The left panel shows the sensitivity analysis on the threshold \u03c4 in targeted experience replay and the coefficient \u03b3 on the non-sparse maximum separate regularization.  The right panel shows the sparsity of weights in the classifier for different continual learning algorithms, illustrating the effect of the non-sparse regularization on weight sparsity.", "section": "Sensitivity analysis"}, {"figure_path": "opaRhDvQRD/figures/figures_21_1.jpg", "caption": "Figure 7: We evaluate the real-time accuracy of models on currently seen classes (w/) and (w/o) pre-trained models under our designed single task setting, as well as the impact of experience replay frequency on CIFAR, EuroSAT, CLEAR and ImageNet.", "description": "This figure displays the real-time accuracy curves for different continual learning strategies, comparing models trained with and without pre-trained models.  The impact of varying experience replay frequency (1/100, 1/50, 1/10) is also shown.  The results are presented across six datasets (CIFAR-10, CIFAR-100, EuroSAT, CLEAR-10, CLEAR-100, ImageNet) to showcase the effectiveness of the strategies under different data distributions and model throughput limitations.  The single task setting helps isolate the model's performance in processing the continuous arrival of data within a limited time frame without introducing the confounding effect of catastrophic forgetting from multiple tasks.", "section": "Experiments"}, {"figure_path": "opaRhDvQRD/figures/figures_23_1.jpg", "caption": "Figure 8: Common framework of replay-based OCL methods. Possible sampling failure and training delay due to the mismatch between model training speed and the data stream flow rate are two primary concerns.", "description": "This figure illustrates the common framework of replay-based online continual learning (OCL) methods.  It highlights the process of how data streams are sampled, potentially resulting in skipped data due to slow model training speed. The memory buffer is shown, with the process of sampling from it which may not always be successful. This sampling process then leads to the training delay in the OCL model. The figure also indicates that test (any-time inference) happens as a continuous process. The mismatch between training speed and data stream rate introduces two main concerns: possible sampling failure and training delays.", "section": "D. Detailed Discussions on Efficiency and Feasibility of Current OCL Methods"}, {"figure_path": "opaRhDvQRD/figures/figures_23_2.jpg", "caption": "Figure 7: We evaluate the real-time accuracy of models on currently seen classes (w/) and (w/o) pre-trained models under our designed single task setting, as well as the impact of experience replay frequency on CIFAR, EuroSAT, CLEAR and ImageNet.", "description": "This figure displays the real-time accuracy curves for models trained with and without pre-trained models on various datasets (CIFAR-10, CIFAR-100, EuroSAT, CLEAR-10, CLEAR-100, and ImageNet). It also shows the effect of different experience replay frequencies on the model's accuracy over time.  The results highlight the improvement achieved by using pre-trained models and demonstrate a trade-off between model throughput and performance, where using more sophisticated replay strategies generally increases accuracy but also decreases throughput.", "section": "Experiments"}, {"figure_path": "opaRhDvQRD/figures/figures_24_1.jpg", "caption": "Figure 7: We evaluate the real-time accuracy of models on currently seen classes (w/) and (w/o) pre-trained models under our designed single task setting, as well as the impact of experience replay frequency on CIFAR, EuroSAT, CLEAR and ImageNet.", "description": "This figure shows the real-time accuracy of online continual learning (OCL) models on several datasets (CIFAR-10, CIFAR-100, EuroSAT, CLEAR-10, CLEAR-100, and ImageNet).  It compares models trained with and without pre-trained models and also shows the impact of different experience replay frequencies. The single-task setting isolates model's ignorance for better evaluation.", "section": "2 Ignorance: Trade-off between Effective Learning and Model Throughput"}, {"figure_path": "opaRhDvQRD/figures/figures_24_2.jpg", "caption": "Figure 11: Averaged model throughput of 11 OCL methods on 6 datasets (Replay frequency as 1/100).", "description": "This figure presents a bar chart comparing the average model throughput of eleven different online continual learning (OCL) methods across six datasets.  The replay frequency is set to 1/100. The chart visually represents the efficiency of each method in processing data samples per unit of time.  Higher bars indicate a higher throughput, suggesting that those OCL methods can handle a larger volume of data in a given time frame.", "section": "D.2 Model Throughput and Performance"}, {"figure_path": "opaRhDvQRD/figures/figures_24_3.jpg", "caption": "Figure 1: Real-time accuracy of OCL models trained under the standard cross entropy loss Lce both with and without pre-trained models (pre-trained on ImageNet) under our designed single task setting and the impact of some commomly used strategies[16, 49, 49]. Results on additional datasets, influence of different pre-trained models (pre-trained on different datasets, using different backbones and different pre-train tasks) and implementation details are provided in Appendix C.3.", "description": "This figure displays the real-time accuracy of various online continual learning (OCL) models. It compares the performance of models trained with and without pre-trained models (using ImageNet), under both traditional and single-task settings. The impact of different strategies (experience replay, contrastive learning, etc.) is also shown.  The figure provides evidence of the 'model's ignorance' phenomenon described in the paper, where models struggle to learn effectively from a single pass of data in a continuous stream.", "section": "Unsatisfactory model performance"}, {"figure_path": "opaRhDvQRD/figures/figures_26_1.jpg", "caption": "Figure 13: Color, which is the most discriminative feature for task a (banana vs. cucumber) and task b (butter vs. brick), is precisely the reason why the model confuses butter and banana.", "description": "This figure illustrates the concept of \"model's myopia\" using a simple example. In the training phase, the model learns to distinguish between bananas and cucumbers based on their color (yellow vs. green). Similarly, it learns to distinguish between bricks and butter based on color (red vs. yellow).  However, in the testing phase, the model fails to distinguish between butter and bananas because both are yellow. This shows how focusing on short-term discriminative features (color in this case) can lead to poor generalization and confusion when encountering new tasks or similar features in new classes. The model's \"myopia\" prevents it from considering broader features or more robust classification criteria that would have avoided this confusion.", "section": "3 Myopia: Key Factor for Performance Degradation"}, {"figure_path": "opaRhDvQRD/figures/figures_26_2.jpg", "caption": "Figure 1: Real-time accuracy of OCL models trained under the standard cross entropy loss Lce both with and without pre-trained models (pre-trained on ImageNet) under our designed single task setting and the impact of some commomly used strategies[16, 49, 49]. Results on additional datasets, influence of different pre-trained models (pre-trained on different datasets, using different backbones and different pre-train tasks) and implementation details are provided in Appendix C.3.", "description": "This figure compares the real-time accuracy of various online continual learning (OCL) models trained with and without pre-trained models (ImageNet) under two different settings: traditional OCL and the proposed single-task setting.  It illustrates the effect of common OCL strategies (experience replay, contrastive learning, distillation chains) on model accuracy over iterations. The single-task setting isolates the impact of single-pass training from other OCL challenges, revealing that pre-trained initialization is crucial for satisfactory performance.", "section": "Unsatisfactory model performance"}, {"figure_path": "opaRhDvQRD/figures/figures_27_1.jpg", "caption": "Figure 3: Normalized confusion matrix of NCM classifier (green) and softmax classifier (CIFAR10) (blue) with ImageNet supervised pre-trained initialization. Due to space limitations, we present a partial training process in the main text. Comprehensive training process is in AppendixE.", "description": "This figure shows the confusion matrices of a softmax classifier and a nearest class mean (NCM) classifier trained on CIFAR10 with and without ImageNet pre-trained initialization. The matrices visualize the model's classification performance at different stages of training, highlighting the impact of pre-trained initialization and the difference in performance between softmax and NCM classifiers.", "section": "3 Myopia: Key Factor for Performance Degradation"}]