[{"figure_path": "YNx7ai4zTs/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure illustrates the overall process of Single Image Unlearning (SIU) in Multimodal Large Language Models (MLLMs). It starts by showing a user's request to remove the visual recognition of specific concepts.  The MMUBench dataset is used to provide concepts, and SIU, consisting of Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss, is then employed to perform unlearning. After the unlearning process, the resulting MLLM is thoroughly evaluated using different metrics such as generality, specificity, diversity, fluency, and resistance to both membership inference attacks and jailbreak attacks. The illustration visually represents the flow of the process from the initial request to the comprehensive post-unlearning evaluation.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_7_1.jpg", "caption": "Figure 2: Visualization of various metrics across different methods over steps using LLAVA7B.", "description": "This figure visualizes the performance of various machine unlearning methods (PO, GA, GA+KL, and SIU) across different fine-tuning steps using the LLAVA7B model.  The metrics shown include Efficacy (EM), Generality (G-eval and C-Dis), Specificity, Fluency, and Diversity.  It illustrates how each method's performance changes as the number of fine-tuning steps increase.", "section": "6.2 Experiment Results"}, {"figure_path": "YNx7ai4zTs/figures/figures_7_2.jpg", "caption": "Figure 2: Visualization of various metrics across different methods over steps using LLAVA7B.", "description": "This figure visualizes the performance of various metrics (EM, G-eval, Distance, Fluency, Diversity) across different fine-tuning steps using the LLAVA7B model.  It compares four different machine unlearning methods: PO, GA, GA+KL, and SIU.  The graph shows how each method's performance changes as the number of fine-tuning steps increases. This allows for a direct comparison of the effectiveness and efficiency of each unlearning method in terms of maintaining model utility and forgetting the target concept.", "section": "6.2 Experiment Results"}, {"figure_path": "YNx7ai4zTs/figures/figures_8_1.jpg", "caption": "Figure 4: EM performance comparison of methods SIU, GA+KL, PO, and GA across different concepts.", "description": "This figure shows the performance comparison across various methods (SIU, GA+KL, PO, and GA) for the task of unlearning different concepts.  The Exact Match (EM) scores, representing the accuracy of the unlearning process, are displayed for each method on a variety of concepts. The figure provides a visual representation of the effectiveness of SIU compared to baseline approaches in terms of its ability to successfully 'forget' the learned visual representations associated with different concepts. ", "section": "6.2 Experiment Results"}, {"figure_path": "YNx7ai4zTs/figures/figures_13_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure illustrates the overall process of Single Image Unlearning (SIU) in Multimodal Large Language Models (MLLMs).  It begins with a user request to remove a specific concept's visual recognition from the model.  The MMUBench dataset provides the concepts to be unlearned. SIU uses multifaceted fine-tuning data and a Dual Masked KL-divergence loss to perform the unlearning. Finally, it shows how the resulting model is assessed based on generality, specificity, diversity, fluency, and resistance to various attacks.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_14_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure illustrates the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs). It begins with a user's request to remove the model's ability to recognize specific concepts.  The MMUBench benchmark provides a list of concepts for this unlearning.  SIU consists of two key parts: creating multifaceted fine-tuning data and utilizing a Dual Masked KL-divergence loss function.  After the unlearning process, the model is evaluated on several metrics (generality, specificity, diversity, fluency) and tested for robustness against membership inference and jailbreak attacks.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_15_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure provides a visual overview of the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs).  It begins with a user request to remove the model's ability to recognize specific concepts.  The MMUBench dataset provides the concepts to be unlearned. SIU then uses Multifaceted Fine-tuning Data and a Dual Masked KL-divergence Loss to fine-tune the model.  Finally, the figure shows the evaluation metrics used to assess the success of the unlearning process, including the model's performance on unseen data (generality), its ability to avoid incorrectly identifying concepts (specificity), the diversity of its outputs, its fluency, and its resistance to adversarial attacks (membership inference and jailbreak attacks).", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_17_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure provides a visual overview of the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs). It starts with a user's request to unlearn visual recognition of specific concepts.  The MMUBench is used to provide concepts for the unlearning process. SIU is depicted as having two key components: Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. Finally, the unlearned MLLM is comprehensively evaluated using metrics like generality, specificity, diversity, fluency and resistance to attacks such as membership inference and jailbreak attacks.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_19_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure provides a visual overview of the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs). It begins with a user requesting to unlearn the visual recognition of specific concepts, leveraging the MMUBench dataset for concept selection. The core of SIU involves two key aspects: creating multifaceted fine-tuning data and employing a Dual Masked KL-divergence Loss.  After the unlearning process, the modified MLLM is assessed across several metrics including generality, specificity, diversity, fluency, and its resilience against membership inference and jailbreak attacks.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_19_2.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure illustrates the overall process of single image unlearning (SIU) in multimodal large language models (MLLMs).  It starts by showing a user requesting to remove a concept's visual recognition using the MMUBench dataset.  The process then uses SIU, with its two key components: Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. Finally, it depicts the evaluation of the unlearned MLLM by assessing its generality, specificity, diversity, fluency, and resilience against membership inference and jailbreak attacks. ", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_20_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure provides a visual overview of the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs).  It begins with a user's request to remove a concept's visual recognition. The SIU method uses Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss to achieve this. Finally, it evaluates the results based on generality, specificity, diversity, fluency, and resistance to attacks.", "section": "4 Methodology"}, {"figure_path": "YNx7ai4zTs/figures/figures_26_1.jpg", "caption": "Figure 1: Overview of the Unlearning Process in MLLMs Using SIU. The process starts with a user request to unlearn the visual recognition of concepts, utilizing MMUBench (introduced in Section 5) to provide concepts for unlearning. SIU has two elements which are Multifaceted Fine-tuning Data and Dual Masked KL-divergence Loss. After unlearning, the unlearned MLLM is evaluated for generality, specificity, diversity, fluency, and resistance to membership inference and jailbreak attacks.", "description": "This figure provides a visual overview of the Single Image Unlearning (SIU) process for Multimodal Large Language Models (MLLMs). It starts by depicting the user's request to unlearn a concept's visual recognition, making use of the MMUBench dataset for concept selection. The core of SIU involves two key components: Multifaceted Fine-tuning Data and the Dual Masked KL-divergence Loss. After the unlearning process, the resulting MLLM is evaluated for various aspects such as generalization, specificity, diversity, fluency, and its robustness against membership inference and jailbreak attacks. The figure visually guides the reader through the steps and components of SIU, clarifying its operation and evaluation.", "section": "4 Methodology"}]