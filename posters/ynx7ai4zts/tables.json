[{"figure_path": "YNx7ai4zTs/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three existing machine unlearning methods (Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL)) across two different sizes of LLAVA models (7B and 13B). The comparison is done across five key metrics: Efficacy, Generality (measured by Exact Match (EM), GPT-4 Evaluation (G-Eval), and C Probability Distance (C-Dis)), Specificity, Fluency, and Diversity.  Higher scores generally indicate better performance.  Note that Specificity values are detailed separately in Table 7.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_6_2.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three existing machine unlearning methods: Preference Optimization (PO), Gradient Ascent (GA), and GA combined with KL-divergence (GA+KL).  The comparison is done using two different sizes of LLAVA models (7B and 13B). The metrics used for comparison include Efficacy (measured by Exact Match - EM), Generality (measured by G-Eval and C-Dis), Specificity, Fluency, and Diversity.  The table shows that SIU significantly outperforms the other methods in most metrics, particularly Generality and Specificity, demonstrating its effectiveness and robustness in machine unlearning for multimodal large language models.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_8_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method with three existing machine unlearning methods (Preference Optimization, Gradient Ascent, and Gradient Ascent + KL-divergence) on several metrics.  The metrics evaluate the effectiveness of unlearning (Efficacy, Generality), the model's utility after unlearning (Specificity, Fluency, Diversity), and are measured on two different sizes of the LLAVA model (7B and 13B parameters).  The results show that SIU significantly outperforms the existing methods across most metrics.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_8_2.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods: Preference Optimization (PO), Gradient Ascent (GA), and Gradient Ascent with KL-divergence (GA+KL).  The comparison is made across multiple metrics evaluating the efficacy (EM score) and generality (G-Eval and C-Dis) of unlearning,  the specificity of the unlearning (impact on non-target knowledge), fluency (perplexity), and diversity of generated outputs. The results are shown for two different sizes of the LLAVA language model, demonstrating the consistency of SIU's performance across different model sizes and its superiority to existing methods.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_16_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method with three existing machine unlearning methods (Preference Optimization (PO), Gradient Ascent (GA), and GA+KL) on two different sizes of LLAMA models (7B and 13B).  The comparison uses several metrics to evaluate the effectiveness of unlearning: Efficacy (Exact Match), Generality (Exact Match, GPT-4 Evaluation, C Probability Distance), Specificity, Fluency, and Diversity.  Higher scores in Generality, Specificity, Fluency and Diversity indicate better preservation of model utility after unlearning.  The table highlights SIU's superior performance across most metrics, showcasing its ability to effectively unlearn target concepts while preserving model functionality.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_18_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three existing machine unlearning methods (Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL)) on two different sizes of LLAVA models (7B and 13B).  The comparison is done across several metrics: Efficacy (measured by Exact Match - EM), Generality (measured by Exact Match - EM, GPT-4 Evaluation - G-Eval, and C Probability Distance - C-Dis), Specificity, Fluency, and Diversity.  Higher scores are better for all metrics except Fluency, where a lower score is better. The table highlights the superior performance of SIU across most metrics and model sizes.  The Specificity metric is further detailed in a separate table (Table 7).", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_20_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method with three existing machine unlearning methods (Preference Optimization, Gradient Ascent, and Gradient Ascent + KL Divergence) across several evaluation metrics.  The metrics include Efficacy (Exact Match), Generality (Exact Match, GPT-4 Evaluation, C Probability Distance), Specificity, Fluency, and Diversity.  The results are shown for two different sizes of the LLAMA language model (7B and 13B parameters).  The table highlights SIU's superior performance across most metrics, demonstrating its effectiveness and robustness in unlearning visual concepts from multimodal large language models.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_21_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods (Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL)) for machine unlearning in large language models (LLMs).  The comparison is done across multiple metrics including Efficacy (EM), Generality (G-Eval, C-Dis), Specificity, Fluency, and Diversity.  Higher values generally indicate better performance. The table shows results for two different sizes of the LLAVA model (7B and 13B parameters). The Specificity scores are detailed separately in Table 7.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_22_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods for machine unlearning in large language models (LLMs): Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL).  The comparison is done using two different sized LLMs (LLAVA7B and LLAVA13B).  The metrics used for evaluation are efficacy, generality (measured by Exact Match (EM), GPT-4 Evaluation (G-Eval), and C Probability Distance (C-Dis)), specificity, fluency, and diversity.  The results show that SIU significantly outperforms the baselines across all metrics.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_23_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods: Preference Optimization (PO), Gradient Ascent (GA), and GA combined with KL-divergence (GA+KL).  The comparison is based on several evaluation metrics across two different sizes of LLAVA models (7B and 13B parameters).  Metrics include Efficacy (EM score), Generality (G-Eval and C-Dis scores), Specificity, Fluency, and Diversity. Higher scores generally indicate better performance. The table shows SIU significantly outperforms the baselines across most metrics.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_24_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods: Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL).  The comparison is done across several metrics evaluating efficacy, generality, specificity, fluency, and diversity.  The results show that SIU outperforms the baseline methods in most metrics.  Note that the Specificity metric is further detailed in Table 7.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_25_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method with three existing machine unlearning methods: Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL).  The comparison is done across several metrics including efficacy (EM), generality (G-Eval, C-Dis), specificity, fluency, and diversity.  The results are based on three independent trials and show the mean and standard deviation for each metric. Note that the specificity results are summarized in a separate Table 7.", "section": "6.2 Experiment Results"}, {"figure_path": "YNx7ai4zTs/tables/tables_27_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods (Preference Optimization (PO), Gradient Ascent (GA), and GA+KL) for machine unlearning in large language models (LLMs).  The comparison is done across several metrics: Efficacy (Exact Match), Generality (G-Eval, C-Dis), Specificity, Fluency, and Diversity.  The results show SIU's superior performance, especially in maintaining the LLM's utility after unlearning (Generality, Specificity, Fluency, Diversity).", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_28_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against several existing machine unlearning methods.  The comparison is done across multiple metrics, including efficacy, generality, specificity, fluency, and diversity.  Efficacy measures how effectively the model forgets the target concept. Generality assesses the model's ability to generalize the forgetting to unseen examples. Specificity evaluates the impact of unlearning on non-target knowledge. Fluency and diversity measure the utility of the model after unlearning.  The results show that SIU significantly outperforms the baselines across various metrics, achieving high efficacy and generality while maintaining good specificity, fluency, and diversity.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_29_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three existing machine unlearning methods (PO, GA, GA+KL) across various metrics.  The metrics include efficacy (EM), generality (G-Eval, C-Dis), specificity, fluency, and diversity.  The comparison is done for two different sizes of LLAMA model (7B and 13B), showing the effectiveness of SIU, particularly in maintaining utility (specificity, fluency, diversity) while achieving high efficacy and generality.", "section": "6.2 Experiment Results"}, {"figure_path": "YNx7ai4zTs/tables/tables_30_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods (Preference Optimization (PO), Gradient Ascent (GA), and GA+KL) for machine unlearning in large language models.  The comparison is done across multiple metrics: Efficacy (Exact Match), Generality (G-Eval, C-Dis), Specificity, Fluency, and Diversity.  The results show SIU's superior performance across all metrics, particularly in terms of generality and fluency.  Note that Specificity scores are detailed in a separate Table 7. The experiment is conducted on two different sizes of LLAMA (7B and 13B) to examine its robustness against different model scales.", "section": "6 Experiments"}, {"figure_path": "YNx7ai4zTs/tables/tables_31_1.jpg", "caption": "Table 1: Comparison with the existing machine unlearning methods. We report the means and standard deviation of 3 independent trials. It is noted that the Specificity of each benchmark is summarized in Table 7.", "description": "This table compares the performance of the proposed Single Image Unlearning (SIU) method against three baseline methods: Preference Optimization (PO), Gradient Ascent (GA), and GA with KL-divergence (GA+KL).  The comparison is made across several metrics: Efficacy (EM), Generality (G-Eval, C-Dis), Specificity, Fluency, and Diversity.  The results show SIU outperforms the baseline methods across various aspects, demonstrating its effectiveness in unlearning visual information from Multimodal Large Language Models (MLLMs).  The table includes results for two different sizes of LLAVA models (7B and 13B) for comprehensive comparison.", "section": "6.2 Experiment Results"}]