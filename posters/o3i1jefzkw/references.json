{"references": [{"fullname_first_author": "C. Jin", "paper_title": "Sample-efficient reinforcement learning of undercomplete POMDPs", "publication_date": "2020-12-01", "reason": "This paper formalizes the theoretical foundation for sample-efficient reinforcement learning in undercomplete POMDPs, which is crucial for understanding the efficiency of algorithms in this setting."}, {"fullname_first_author": "N. Golowich", "paper_title": "Learning in observable POMDPs, without computationally intractable oracles", "publication_date": "2022-12-01", "reason": "This paper provides efficient algorithms for solving observable POMDPs, without relying on computationally expensive oracles, offering a new direction for provable RL."}, {"fullname_first_author": "N. Golowich", "paper_title": "Planning in observable POMDPs in quasipolynomial time", "publication_date": "2022-01-01", "reason": "This paper presents a quasipolynomial-time algorithm for planning in observable POMDPs, establishing a significant improvement over previous exponential-time algorithms."}, {"fullname_first_author": "X. Liu", "paper_title": "Partially observable multi-agent RL with (quasi-)efficiency: the blessing of information sharing", "publication_date": "2023-07-01", "reason": "This paper explores the efficiency of multi-agent reinforcement learning in partially observable settings, providing valuable insights into the role of information sharing."}, {"fullname_first_author": "J. Lee", "paper_title": "Learning in POMDPs is sample-efficient with hindsight observability", "publication_date": "2023-07-01", "reason": "This paper demonstrates the sample efficiency of reinforcement learning in POMDPs with hindsight observability, which is an important paradigm for addressing partial observability."}]}