[{"figure_path": "h3k2NXu5bJ/figures/figures_2_1.jpg", "caption": "Figure 1: The overview of PNSGD unlearning. (Left) Proof sketch for PNSGD unlearning guarantees. (Right) PNSGD (un)learning processes on adjacent datasets. Given a mini-batch sequence B, the learning process M induces a regular polyhedron where each vertex corresponds to a stationary distribution VDB for each dataset D. VD|B and VD|B' are adjacent if D, D' differ in one data point. We provide an upper bound ZB for the infinite Wasserstein distance W\u221e(VD|B, VD'|B'), which is crucial for non-vacuous unlearning guarantees. Results of [16] allow us to convert the initial W\u221e bound to R\u00e9nyi difference bound db, and apply joint convexity of KL divergence to obtain the final privacy loss \u025b, which also take the randomness of B into account.", "description": "This figure illustrates the proposed PNSGD unlearning framework. The left panel shows a proof sketch outlining the steps involved in establishing unlearning guarantees.  The right panel visually represents the (un)learning processes using adjacent datasets (datasets differing by a single data point). It highlights the concept of using the Wasserstein distance between distributions to bound the privacy loss and how the framework handles both learning and unlearning using the same algorithm (PNSGD).", "section": "3 Certified Unlearning Guarantee for PNSGD"}, {"figure_path": "h3k2NXu5bJ/figures/figures_7_1.jpg", "caption": "Figure 1: The overview of PNSGD unlearning. (Left) Proof sketch for PNSGD unlearning guarantees. (Right) PNSGD (un)learning processes on adjacent datasets. Given a mini-batch sequence B, the learning process M induces a regular polyhedron where each vertex corresponds to a stationary distribution VD|B for each dataset D. VD|B and VD'|B are adjacent if D, D' differ in one data point. We provide an upper bound ZB for the infinite Wasserstein distance W\u221e(VD|B, VD'|B), which is crucial for non-vacuous unlearning guarantees. Results of [16] allow us to convert the initial W\u221e bound to R\u00e9nyi difference bound dB, and apply joint convexity of KL divergence to obtain the final privacy loss \u03b5, which also take the randomness of B into account.", "description": "This figure illustrates the proposed PNSGD unlearning framework. The left panel shows a proof sketch, highlighting key steps: the convergence of the learning process to a stationary distribution, the bounding of the initial Wasserstein distance between adjacent distributions, the conversion of this distance to a R\u00e9nyi divergence bound using results from [16], and finally, the calculation of the overall privacy loss.  The right panel visually depicts the (un)learning processes as movements between adjacent vertices of a polyhedron, each vertex representing a stationary distribution for a specific dataset.  The distance between these vertices, bounded by ZB, is critical to the unlearning guarantee.", "section": "3 Certified Unlearning Guarantee for PNSGD"}, {"figure_path": "h3k2NXu5bJ/figures/figures_8_1.jpg", "caption": "Figure 3: Main experiments, where the top and bottom rows are for MNIST and CIFAR10 respectively. (a) Compare to baseline for unlearning one point using limited K unlearning epoch. For PNSGD, we use only K = 1 unlearning epoch. For D2D, we allow it to use K = 1,5 unlearning epochs. (b) Unlearning 100 points sequentially versus baseline. For LU, since their unlearning complexity only stays in a reasonable range when combined with batch unlearning of size S sufficiently large, we report such a result only. (c,d) Noise-accuracy-complexity trade-off of PNSGD for unlearning 100 points sequentially with various mini-batch sizes b, where all methods achieve (\u03b5, 1/n)-unlearning guarantee with \u03b5 = 0.01. We also report the required accumulated epochs for retraining for each b.", "description": "This figure presents the main experimental results comparing the proposed PNSGD method against existing baselines (D2D and LU) on MNIST and CIFAR10 datasets.  It showcases the performance of each method in several scenarios: unlearning a single data point, unlearning multiple data points sequentially, and exploring the trade-off between noise level, accuracy, and computational complexity. The results highlight the efficiency and efficacy of the PNSGD approach, particularly in the context of multiple sequential unlearning requests.", "section": "4 Experiments"}]