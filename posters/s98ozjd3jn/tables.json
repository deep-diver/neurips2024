[{"figure_path": "S98OzJD3jn/tables/tables_6_1.jpg", "caption": "Table 1: Comparisons on 8 downstream tasks with pre-trained DiT-XL-2-256x256. Methods with \"+\" are reported from the original Table 1 of [54]. Parameter-efficient methods are denoted by \"*\"", "description": "This table presents a comparison of different methods for fine-tuning a pre-trained Diffusion Transformer model (DiT-XL-2-256x256) on eight downstream tasks.  The methods compared include full fine-tuning and several parameter-efficient fine-tuning (PEFT) techniques.  The table shows the Fr\u00e9chet Inception Distance (FID) score for each method on each dataset, a lower FID indicating better performance.  The \"Relative Promotion\" row indicates the percentage improvement of Diff-Tuning over standard fine-tuning for each dataset and on average.", "section": "4.1 Transfer to Class-conditional Generation"}, {"figure_path": "S98OzJD3jn/tables/tables_7_1.jpg", "caption": "Table 2: Sudden convergence steps on controlling Stable Diffusion with 5 conditions.", "description": "This table presents the results of an experiment comparing the number of steps to reach sudden convergence for standard ControlNet fine-tuning and ControlNet fine-tuning with Diff-Tuning applied.  Five different control conditions (Sketch, Normal, Depth, Edge, and Segmentation) were tested using the Stable Diffusion model.  The table shows the average number of steps needed for sudden convergence across all conditions and the percentage improvement achieved by using Diff-Tuning.", "section": "4.2 Transfer to Controllable Generation"}, {"figure_path": "S98OzJD3jn/tables/tables_16_1.jpg", "caption": "Table 1: Comparisons on 8 downstream tasks with pre-trained DiT-XL-2-256x256. Methods with \"+\\\" are reported from the original Table 1 of [54]. Parameter-efficient methods are denoted by \"*\"", "description": "This table presents a comparison of different methods for fine-tuning a pre-trained Diffusion Transformer (DiT) model on eight downstream tasks.  The table shows the Fr\u00e9chet Inception Distance (FID) scores achieved by each method.  The methods compared include full fine-tuning, several parameter-efficient fine-tuning (PEFT) methods, and the proposed Diff-Tuning method.  Lower FID scores indicate better performance. The table highlights the improvement achieved by Diff-Tuning compared to other methods, particularly standard fine-tuning.", "section": "4.1 Transfer to Class-conditional Generation"}, {"figure_path": "S98OzJD3jn/tables/tables_16_2.jpg", "caption": "Table 3: Hyperparameters of experiments.", "description": "This table lists the hyperparameters used in the experiments described in the paper.  It shows hyperparameters used for both class-conditional generation and controlled generation experiments, specifying different settings for the backbone model, image size, batch size, learning rate, optimizer, number of training steps, validation interval, number of sampling steps and the augmented dataset size used in Diff-Tuning.", "section": "B.2 Experiment Details"}, {"figure_path": "S98OzJD3jn/tables/tables_17_1.jpg", "caption": "Table 4: The FID results comparison of the KD varient. KD loss is trade-off by 0.05.", "description": "This table compares the Fr\u00e9chet Inception Distance (FID) scores achieved by three different methods on the CUB-Bird and Standard Cars datasets.  The methods are: Vanilla Fine-tuning (standard fine-tuning), Diff-Tuning with augmented data (using an augmented dataset for knowledge retention), and Diff-Tuning with KD (using knowledge distillation for knowledge retention).  The table shows that Diff-Tuning, in both its augmented data and KD variants, significantly outperforms standard fine-tuning in terms of FID scores, demonstrating its effectiveness in improving the transferability of pre-trained diffusion models.", "section": "4.4 Analysis and Ablation"}, {"figure_path": "S98OzJD3jn/tables/tables_17_2.jpg", "caption": "Table 1: Comparisons on 8 downstream tasks with pre-trained DiT-XL-2-256x256. Methods with \"+\" are reported from the original Table 1 of [54]. Parameter-efficient methods are denoted by \"*\"", "description": "This table presents a comparison of different fine-tuning methods on eight downstream tasks using a pre-trained DiT-XL-2-256x256 model.  It shows the Fr\u00e9chet Inception Distance (FID) scores achieved by various methods, including full fine-tuning and several parameter-efficient fine-tuning (PEFT) techniques. The results highlight the performance of the proposed Diff-Tuning method compared to existing state-of-the-art approaches.", "section": "4.1 Transfer to Class-conditional Generation"}, {"figure_path": "S98OzJD3jn/tables/tables_18_1.jpg", "caption": "Table 6: Results of fine-tuning EDM", "description": "This table presents the results of fine-tuning the Energy-based Diffusion Model (EDM) on the CIFAR-10 dataset after pre-training on the ImageNet dataset.  It compares the Fr\u00e9chet Inception Distance (FID) score achieved using standard fine-tuning ('Vanilla') against the FID score obtained using the proposed Diff-Tuning method. The lower FID score indicates better performance in image generation.", "section": "E Fine-tuning EDM with Diff-Tuning"}, {"figure_path": "S98OzJD3jn/tables/tables_19_1.jpg", "caption": "Table 2: Sudden convergence steps on controlling Stable Diffusion with 5 conditions.", "description": "This table presents the number of steps required to reach \"sudden convergence\" for ControlNet and ControlNet enhanced with Diff-Tuning across five different control conditions (Sketch, Normal, Depth, Edge, and Segmentation on COCO/ADE20k datasets).  Sudden convergence refers to the point where ControlNet abruptly gains the ability to synthesize images according to the specified control conditions, rather than learning gradually.  The table highlights the significant improvement in convergence speed achieved by Diff-Tuning compared to the standard ControlNet.", "section": "4.2 Transfer to Controllable Generation"}]