[{"figure_path": "AQ1umQL7dZ/tables/tables_6_1.jpg", "caption": "Table 1: Genomic Benchmarks. Average performance across three random seeds for Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA and MxDNA with sample standard deviations. We highlight the best values in bold type and underline the second best.", "description": "This table presents the average performance and standard deviation across three random seeds for five different models (Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA, and MxDNA) on eight genomic datasets.  The best performance for each dataset is highlighted in bold, and the second-best is underlined. The table allows for a comparison of the different models' performance on various genomic tasks.", "section": "4.2 Downstream Evaluation"}, {"figure_path": "AQ1umQL7dZ/tables/tables_6_2.jpg", "caption": "Table 2: Nucleotide Transformer Benchmarks. Average performance across three random seeds for Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA and MxDNA with sample standard deviations. We highlight the best values in bold type and underline the second best.", "description": "This table presents the average performance and standard deviation across three random seeds for five different DNA foundation models (Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA, and MxDNA) on the Nucleotide Transformer Benchmarks dataset.  The benchmarks encompass 18 datasets across three task types: histone marker prediction, regulatory annotation prediction, and splice site annotation prediction. The best performance for each dataset is highlighted in bold, and the second-best is underlined.", "section": "4.2 Downstream Evaluation"}, {"figure_path": "AQ1umQL7dZ/tables/tables_7_1.jpg", "caption": "Table 3: Average results on Nucleotide Transformer Benchmarks and Genomic Benchmarks with different tokenization methods. We highlight the best values in bold type, underline the second best.", "description": "This table compares the performance of different DNA tokenization methods on two benchmark datasets: Nucleotide Transformer Benchmarks and Genomic Benchmarks. The methods compared include Single Nucleotide, Overlapping k-mer, Non-overlapping k-mer, Byte-pair Encoding, and the proposed MxDNA method.  The table shows that MxDNA outperforms other methods on both benchmarks. The average performance and standard deviations are presented for each method.", "section": "4.3 Ablation Studies"}, {"figure_path": "AQ1umQL7dZ/tables/tables_7_2.jpg", "caption": "Table 4: Average results on Nucleotide Transformer Benchmarks and Genomic Benchmarks with components added successively. We highlight the best values in bold type, underline the second best.", "description": "This table shows the impact of adding different components to the MxDNA model.  It starts with a baseline of single nucleotide tokenization and then adds the Mixture of Convolution Experts, the deformable convolution and jitter noise sequentially. Each row shows the average performance on both Nucleotide Transformer and Genomic Benchmarks after each component addition.  The results demonstrate that each component contributes to improved performance, culminating in the final MxDNA model.", "section": "4.3 Ablation Studies"}, {"figure_path": "AQ1umQL7dZ/tables/tables_15_1.jpg", "caption": "Table 5: Glossary of terms used in describing the method.", "description": "This table provides a glossary of terms and their descriptions used in the paper's methodology section.  It defines key variables such as the number of nucleotides, dimension of hidden states, number of experts, etc., along with their data types and meanings within the context of MxDNA.", "section": "3.2 Learnt Tokenization Module"}, {"figure_path": "AQ1umQL7dZ/tables/tables_15_2.jpg", "caption": "Table 1: Genomic Benchmarks. Average performance across three random seeds for Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA and MxDNA with sample standard deviations. We highlight the best values in bold type and underline the second best.", "description": "This table compares the average performance of five different DNA foundation models (Nucleotide Transformer v2 100M, DNABERT, DNABERT2, HyenaDNA, and MxDNA) across eight genomic benchmark datasets.  The best performing model for each dataset is highlighted in bold, and the second-best is underlined. The results show MxDNA's superior performance on several benchmarks.", "section": "4.2 Downstream Evaluation"}, {"figure_path": "AQ1umQL7dZ/tables/tables_19_1.jpg", "caption": "Table 6: Genomic Benchmarks. Different tokenization methods.", "description": "This table compares the performance of different DNA tokenization methods (single nucleotide, overlapping 6-mer, non-overlapping 6-mer, Byte Pair Encoding, and MxDNA) on eight genomic tasks.  The performance metric used is average accuracy across three random seeds.  The table showcases how MxDNA outperforms other methods in most tasks.", "section": "4.2 Downstream Evaluation"}, {"figure_path": "AQ1umQL7dZ/tables/tables_19_2.jpg", "caption": "Table 7: Nucleotide Transformer Benchmarks. Different tokenization methods.", "description": "This table presents the average performance across three random seeds for different DNA tokenization methods on the Nucleotide Transformer Benchmarks.  The methods compared include single nucleotide (1-mer), overlapping 6-mer, non-overlapping 6-mer, Byte-Pair Encoding (BPE), and the proposed MxDNA method. The results are shown for various downstream tasks, including histone marker prediction, regulatory annotation, and splice site annotation, demonstrating the performance of MxDNA against other tokenization approaches.", "section": "4.3 Ablation Studies"}, {"figure_path": "AQ1umQL7dZ/tables/tables_19_3.jpg", "caption": "Table 8: Genomic Benchmarks. Different components.", "description": "This table presents the average performance results on Genomic Benchmarks for different model configurations. It compares the performance of a single nucleotide baseline model against models with progressively added components: Mixture of Convolution Experts, Deformable Convolution, and finally, Jitter Noise (resulting in the full MxDNA model).  The results show how each component contributes to the overall improved performance.", "section": "4.2 Downstream Evaluation"}, {"figure_path": "AQ1umQL7dZ/tables/tables_20_1.jpg", "caption": "Table 9: Nucleotide Transformer Benchmarks. Different components.", "description": "This table presents the average results on Nucleotide Transformer Benchmarks with components added successively to the single nucleotide baseline.  It shows the performance improvements with the addition of the Mixture of Convolution Experts, deformable convolution, and jitter noise, culminating in the final MxDNA model.  Each row represents a specific dataset or average across multiple datasets within the benchmarks, and each column shows the performance with a progressively more complete version of the model.", "section": "4.3 Ablation Studies"}, {"figure_path": "AQ1umQL7dZ/tables/tables_21_1.jpg", "caption": "Table 10: Comparison of various models based on their computational complexity.", "description": "This table compares several DNA foundation models (DNABERT2, Nucleotide Transformer v2 100M, DNABERT, HyenaDNA tiny d256, HyenaDNA tiny, MxDNA, Learnt Tokenization Module, Single Nucleotide Baseline) across four key metrics reflecting their computational complexity: floating point operations (FLOPs), multiply-accumulate operations (MACs), number of parameters, and the number of tokens.  The table allows for a quantitative assessment of the relative computational resource requirements of each model.", "section": "4.1 Model Implementation & Pretraining"}, {"figure_path": "AQ1umQL7dZ/tables/tables_21_2.jpg", "caption": "Table 11: Assets used in this work", "description": "This table lists the various assets (datasets, models, libraries, etc.) used in the research, along with their respective licenses.  It provides transparency regarding the source and usage rights of the components that contribute to the overall methodology and results.", "section": "Appendix / supplemental material"}]