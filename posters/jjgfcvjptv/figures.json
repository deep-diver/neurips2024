[{"figure_path": "JJGfCvjpTV/figures/figures_3_1.jpg", "caption": "Figure 1: Results of training HSM on a Gaussian mixture. The score vector field faithfully recovers gradients of the density. The optimal velocity predictor is zero everywhere.", "description": "This figure shows the results of applying the Hamiltonian Score Matching (HSM) method to a Gaussian mixture dataset. Panel (a) displays the true density of the data distribution. Panel (b) shows the learned score function, which is a vector field representing the gradient of the log-density.  As expected, the learned score function accurately captures the gradients of the true density. Panel (c) shows the learned velocity predictor, which ideally should be zero everywhere according to theory.  The near-zero values in this panel demonstrate the effectiveness of the HSM method.", "section": "4 Hamiltonian Score Matching"}, {"figure_path": "JJGfCvjpTV/figures/figures_5_1.jpg", "caption": "Figure 2: Evolution of various HGFs in joint coordinate-velocity space from t = 0 (blue) to t = T (red) with trajectories (black). Data distribution \u03c0(x) = 0.4 * \u039d(\u22122, 1) + 0.6 * \u2116(2, 1). Diffusion models and flow matching have zero force fields, i.e. the velocity does not change. Diffusion models do not converge in finite time (here, T = 3). The coupled distribution in FM allow for a convergence for T = 1. Both distort the joint distribution. Oscillation HGFs only rotate the distribution.", "description": "This figure compares three different types of Hamiltonian Generative Flows (HGFs) in a joint coordinate-velocity space.  It shows how the distribution evolves over time from t=0 (blue) to t=T (red) using trajectories (black). The data distribution is a mixture of two Gaussians.  It demonstrates the differences in how Diffusion models, Flow matching, and Oscillation HGFs change the distribution's shape and location in phase space, highlighting the effect of different force fields on the distribution.", "section": "6 Diffusion Models and Flow Matching as HGFs with zero force field"}, {"figure_path": "JJGfCvjpTV/figures/figures_8_1.jpg", "caption": "Figure 3: Empirical investigation of Hamiltonian score discrepancy (HSD). (a) The Taylor approximation is a good approximation. (b) Hamiltonian score discrepancy is strongly correlated with explicit score matching loss. (c) Signal-to-noise ratio is significantly better for HSM vs DSM for low \u03c3.", "description": "This figure empirically validates the Hamiltonian Score Discrepancy (HSD) proposed in the paper.  Panel (a) shows a strong correlation between the HSD and the explicit score matching loss, confirming HSD's effectiveness as a score matching metric. Panel (b) demonstrates the accuracy of the Taylor approximation used to connect HSD and the explicit score matching loss.  Finally, panel (c) highlights the superior signal-to-noise ratio achieved by the HSM method (Hamiltonian Score Matching) compared to DSM (Denoising Score Matching) at lower noise levels, indicating HSM's ability to generate more accurate score estimates.", "section": "Experiments"}, {"figure_path": "JJGfCvjpTV/figures/figures_8_2.jpg", "caption": "Figure 4: Image generation examples based on Oscillation HGFs for FFHQ.", "description": "This figure shows several example images generated by the Oscillation HGF model trained on the FFHQ dataset.  The images demonstrate the model's ability to generate high-quality, realistic-looking faces.", "section": "9.2 HGF experiments - Image Generation"}, {"figure_path": "JJGfCvjpTV/figures/figures_20_1.jpg", "caption": "Figure 5: Data distribution (left) and velocity distribution (right) used for Reflection HGFs as initial distribution. With the above starting conditions, a reflection (=\"infinite force\") at the boundaries of the domain is used to simulate trajectories forward (this can be computed in closed form in a simulation-free manner).", "description": "This figure shows the initial data and velocity distributions used for training Reflection HGFs. The data distribution is a checkerboard pattern, representing a mixture of data points in different regions. The velocity distribution is a central Gaussian, indicating that the initial velocities of the particles are randomly drawn from a normal distribution centered around zero.  The \"infinite force\" at the boundaries means particles bounce off the borders.  This model can generate a uniform distribution without explicit ODE simulation, highlighting the flexibility of HGFs.", "section": "I Reflection HGFs - A New Example of HGFs"}, {"figure_path": "JJGfCvjpTV/figures/figures_21_1.jpg", "caption": "Figure 2: Evolution of various HGFs in joint coordinate-velocity space from t = 0 (blue) to t = T (red) with trajectories (black). Data distribution \u03c0(x) = 0.4 * \u039d(\u22122, 1) + 0.6 * \u2116(2, 1). Diffusion models and flow matching have zero force fields, i.e. the velocity does not change. Diffusion models do not converge in finite time (here, T = 3). The coupled distribution in FM allow for a convergence for T = 1. Both distort the joint distribution. Oscillation HGFs only rotate the distribution.", "description": "This figure compares the evolution of three different Hamiltonian Generative Flow (HGF) models in a joint coordinate-velocity space. The models are: diffusion models, flow matching, and oscillation HGFs. Each model starts from the same data distribution and is visualized using different colors and trajectories. The figure illustrates how the distribution evolves over time (from t=0 to t=T) in each model, highlighting the difference in their dynamics and convergence properties.", "section": "6 Diffusion Models and Flow Matching as HGFs with zero force field"}]