[{"figure_path": "G89r8Mgi5r/tables/tables_7_1.jpg", "caption": "Table 1: Test accuracy of CRFed and the competing methods on five datasets. We run five trials with different random seeds and report the mean accuracy.", "description": "This table presents the mean test accuracy achieved by CRFed and several other federated learning algorithms across five benchmark datasets (MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD).  The results are averages over five independent trials with different random seeds to account for variability and provide a reliable comparison. It demonstrates CRFed's performance in comparison to existing methods, highlighting its accuracy and robustness across diverse datasets.", "section": "4.2 Performance Comparison"}, {"figure_path": "G89r8Mgi5r/tables/tables_7_2.jpg", "caption": "Table 2: Performance of top 5 models on CIFAR-100 and NIPD datasets under different \u03b2 values.", "description": "This table presents the performance comparison of the top 5 models (FedDPMS, FRAug, G-FML, FedCD, and CRFed) on CIFAR-100 and NIPD datasets under different values of the Dirichlet concentration parameter \u03b2 (0.1, 0.3, and 0.5). The parameter \u03b2 controls the level of data heterogeneity, with smaller values indicating higher heterogeneity.  The table shows the test accuracy for CIFAR-100 and mean Average Precision (mAP) for NIPD.  It demonstrates how the performance of each model varies under different levels of data heterogeneity.", "section": "4.2 Performance Comparison"}, {"figure_path": "G89r8Mgi5r/tables/tables_9_1.jpg", "caption": "Table 3: The performance of different importance sampling methods on CIFAR-100 under various \u03b2 values.", "description": "This table compares the performance of several importance sampling methods (ISFedAvg, ISFL, FedIR, Harmony) and the proposed CRFed method on the CIFAR-100 dataset under different levels of data heterogeneity (\u03b2 = 0.1, 0.3, 0.5).  It demonstrates CRFed's superior performance compared to existing importance sampling techniques in handling non-IID data in federated learning.", "section": "4.4 Comparison with Importance Sampling Methods"}, {"figure_path": "G89r8Mgi5r/tables/tables_16_1.jpg", "caption": "Table 1: Test accuracy of CRFed and the competing methods on five datasets. We run five trials with different random seeds and report the mean accuracy.", "description": "This table presents the mean test accuracy of the proposed CRFed model and several other federated learning algorithms across five benchmark datasets (MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD).  The results are averaged over five independent trials with different random seeds to assess the statistical reliability of the performance comparison.", "section": "4.2 Performance Comparison"}, {"figure_path": "G89r8Mgi5r/tables/tables_17_1.jpg", "caption": "Table 1: Test accuracy of CRFed and the competing methods on five datasets. We run five trials with different random seeds and report the mean accuracy.", "description": "This table presents the test accuracy achieved by CRFed and several other federated learning algorithms on five benchmark datasets (MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD).  The results are averaged over five independent trials, each using different random seeds, to showcase the robustness of the models and reduce the impact of randomness on the results.  The table highlights CRFed's superior performance compared to existing state-of-the-art methods, demonstrating its effectiveness in handling the challenges of non-IID data in federated learning scenarios.", "section": "4.2 Performance Comparison"}]