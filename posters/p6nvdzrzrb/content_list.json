[{"type": "text", "text": "Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage? ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Maohao Shen1,\u2217 J. Jon Ryu1\u2217, Soumya Ghosh2,\u2020 Yuheng $\\mathbf{B}\\mathbf{u}^{3}$ , Prasanna Sattigeri2, Subhro Das2, Gregory W. Wornell1 ", "page_idx": 0}, {"type": "text", "text": "1Department of EECS, MIT, Cambridge, MA 02139 2MIT-IBM Watson AI Lab, IBM Research, Cambridge, MA 02142 3Department of ECE, University of Florida, Gainesville, FL 32611 ", "page_idx": 0}, {"type": "text", "text": "{maohao,jongha,gww}@mit.edu, {ghoshoso,prasanna}@us.ibm.com, subhro.das@ibm.com, buyuheng@ufl.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.1 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Accurate estimation of uncertainty in the prediction becomes more crucial to enhance the reliability of a predictive model, especially for high-stake applications such as medical diagnosis [1, 2]. Among several approaches proposed, a class of uncertainty estimation methods under the category of evidential deep learning (EDL) has recently gained attention [3], due to their claimed advantages over other methods. EDL methods typically learn a single neural network that maps input data to the parameters of a meta distribution, which is a distribution over the predictive distribution. The EDL methods generally claim the following advantages. (1) Computational efficiency: they bypass the expensive sampling costs associated with Bayesian or ensemble-based methods by training a single neural network and estimating uncertainty with a single forward pass. (2) Promising empirical performance: they achieve superior results on downstream uncertainty quantification (UQ) tasks, particularly in detecting out-of-distribution (OOD) data. (3) Ability to quantify different uncertainties: EDL methods can quantify distributional uncertainty versus aleatoric uncertainty, by representing them as the spread and mean of an estimated meta distribution over the prediction, respectively. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Despite the above benefits, a line of recent works has reported theoretical limitations and pitfalls of uncertainties learned by EDL methods, including the issue of non-vanishing distributional uncertainty [4], a possibility of non-existence of proper scoring rules for meta distributions [5], and a gap between learned uncertainty and an ideal meta distribution [6]. While these works call for the attention of the UQ community for the raised issues, a comprehensive theoretical understanding of the learned uncertainties from this type of UQ model is still lacking, as the existing analyses focus on a restricted subset of objective functions in the literature. Moreover, they did not explain the empirical success of the EDL methods at downstream tasks, such as OOD detection, despite such issues. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we provide a simpler and sharper theoretical characterization of what is being learned by representative EDL methods, and re-examine the empirical success of the EDL methods based on the analysis. More concretely, our contributions are threefold: ", "page_idx": 1}, {"type": "text", "text": "1. Theoretical Analysis: In Sec. 4, we provide a unifying perspective on several representative EDL methods proposed in the literature, establishing an exact characterization of the optimal meta distribution defined by existing methods. This reveals that existing methods enforce the meta distribution to fti a sample-size-independent target distribution (Theorem 5.1). This analysis covers a wider class of objective functions and modalities, and is sharper than the prior analyses [4, 6]. ", "page_idx": 1}, {"type": "text", "text": "2. Empirical Investigation: In Sec. 5, we further provide empirical evidence to point out the fundamental limitations of the learned uncertainties by EDL methods, and present several findings showing that existing EDL methods are essentially OOD detectors and hence exhibit their pitfalls. ", "page_idx": 1}, {"type": "text", "text": "3. Insights and Solutions: In Sec. 6, we explain why model uncertainty seems inevitable for faithful UQ and how we can improve the EDL method accordingly. We propose a new model uncertainty based on the idea of bootstrap, and demonstrate that an EDL model can well distill its behavior and achieve superior UQ downstream task performance compared to the existing methods. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We summarize the literature that is closely aligned with the scope of this paper. We refer the reader to Sec. B in Appendix for an overview of classical UQ literature and a recent survey paper [3] for a comprehensive review of EDL methods. ", "page_idx": 1}, {"type": "text", "text": "EDL Methods. EDL methods, mainly applied in classification settings, utilize a single neural network to model Dirichlet distributions over label distributions, which can be divided into three categories. (1) OOD-data-dependent methods: Earlier works such as Forward Prior Network [7], and Reverse Prior Network [8, 9], proposed to train a model to output sharp Dirichlet distribution for in-distribution (ID) data and flat Dirichlet distribution for OOD data. (2) OOD-data-free methods: Subsequently, several methods without OOD data were proposed with various training objectives, including the MSE loss with reverse Kullback\u2013Leibler (KL) regularizer [10, 11], the \u201cVI\u201d loss [12, 13, 14], and the \u201cUCE\u201d loss [15]. (3) Distillation based methods: are motivated by training a single model to mimic the behavior of classical UQ approaches, including END2 [16] that emulates ensemble method, and S2D [17] that emulates (Gaussian) random dropout method. EDL methods have also been explored for regression problems [18, 19, 20]. ", "page_idx": 1}, {"type": "text", "text": "Critiques of EDL Methods. Recently, several works have raised concerns about the quality of uncertainty learned by EDL methods. Bengs et al. [4] pointed out the learned distributional uncertainty does not vanish even in the asymptotic limit of infinite training samples. Bengs et al. [5] provided further theoretical arguments for why a proper scoring rule for learning the meta distribution might not exist. More recently, J\u00fcrgens et al. [6] argues that the learned uncertainty by EDL methods is inconsistent with a reference distribution. In a similar spirit to these critiques, we offer a sharper analysis to characterize the exact behavior of EDL methods. Our analysis can subsume, generalize, and simplify the existing analyses. See Appendix A for a more in-depth review of these works. ", "page_idx": 1}, {"type": "text", "text": "3 Problem Setting and Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the predictive modeling, we aim to learn the label distribution $p(y|x)$ over $\\boldsymbol{\\wp}$ using data ${\\mathcal{D}}=$ $\\{(x_{i},\\dot{y_{i}})\\}_{i=1}^{N}$ drawn from an underlying data distribution $p(x)p(y|x)$ over $\\mathcal X\\times\\mathcal Y$ . Here, $\\boldsymbol{\\wp}$ is a label set; $\\bar{\\mathcal{V}}^{*}=[C]:=\\{1,\\ldots,C\\}$ for classification for some $C\\geq1$ and $y=\\mathbb R$ for regression. $\\Delta^{C-1}$ denotes the probability simplex over $\\left[C\\right]$ . In addition to accurately learning the conditional distribution $\\eta_{y}(x)\\stackrel{*}{:=}p(y|x)$ , we wish to quantify \u201cuncertainty\u201d of the learned prediction. We focus on classification in this paper, but some of our analyses also apply to certain existing EDL methods for regression [19, 20]. For the sake of clarity, we defer all related discussion on regression and beyond to Appendix F. ", "page_idx": 2}, {"type": "text", "text": "Bayesian and Ensemble-based Approaches. Different UQ methods define predictive uncertainties based on different sources of randomness. The Bayesian approach is arguably the most widely studied UQ approach, in which a parametric classifier $p(y|x,\\psi)$ is trained via the Bayesian principle, and inference is performed with the predictive posterior distribution $\\begin{array}{r}{p(y|x,\\mathcal{D}):=\\int\\displaylimits_{\\mathbf{\\mathcal{P}}}^{}(y|x,\\bar{\\psi})p(\\bar{\\psi}|\\mathcal{D})\\;\\mathrm{d}\\psi,}\\end{array}$ , where $p(\\psi|\\mathcal{D})$ is the model posterior distribution, induced by the prior $p(\\psi)$ and likelihood $p(\\mathcal{D}|\\psi)$ . Ensemble-based methods assume a different distribution $p(\\psi|\\mathcal{D})$ to generate random models given data, e.g., training neural networks with different random seeds. As alluded to earlier, both Bayesian and ensemble approaches are computationally demanding due to the intractability of $p(\\psi|\\mathcal{D})$ and the need for computing the integration over $\\psi$ . Moreover, $p(y\\vert x,\\mathcal{D})$ can capture aleatoric uncertainty (or data uncertainty), and the amount of spread over $p(y|x,\\psi)$ induced by the model uncertainty of $p(\\psi|\\mathcal{D})$ is regarded as epistemic uncertainty (or knowledge uncertainty) for its prediction. ", "page_idx": 2}, {"type": "text", "text": "EDL Approach. The EDL approach further decomposes the predictive posterior distribution as $\\begin{array}{r}{p(y|\\bar{x_{\\surd}},\\psi)\\,=\\,\\int p(\\pi|x,\\psi)p(y|\\bar{\\pi})\\,\\mathrm{d}\\pi}\\end{array}$ , where $p(\\pi|x,\\psi)$ is a meta distribution (or called secondorder distribution $[4,\\,5])$ over the prediction at $x$ , and $p(y|\\pi)$ is a fixed likelihood model. For classification, $\\pi\\,\\in\\,\\Delta^{C-1}$ is a probability vector over $C$ classes, $p(y|\\pmb{\\pi})\\,=\\,\\pi_{y}$ is the categorical likelihood model, and $p(\\pi|x,\\psi)$ is a distribution over the simplex $\\Delta^{C-1}$ . Oftentimes, $p(\\pi|x,\\psi)$ is chosen as a conjugate prior of the likelihood model $p(y|\\bar{\\boldsymbol{\\pi}})$ , like the Dirichlet distribution for classification [7, 8, 13, 15, 20], but sometimes not [10, 18, 11]. Given the full decomposition, $\\begin{array}{r}{p(y|x,\\mathcal{D})=\\int\\!\\!\\int p(y|\\pi)p(\\pi|x,\\psi)p(\\psi|\\mathcal{D})\\,\\mathrm{d}\\psi\\,\\mathrm{d}\\pi}\\end{array}$ , the uncertainty captured in $p(y|\\pi)$ is called aleatoric uncertainty, in $p(\\pi|x,\\psi)$ is called distributional uncertainty, a kind of epistemic uncertainty. However, EDL methods often assume the best single model $\\psi^{\\star}$ learned with data $\\mathcal{D}$ , without any randomness in $p(\\psi|\\mathcal{D})$ , or formally setting it to be $\\delta(\\psi-\\psi^{\\star})$ [7, 3]. It then aims to train the meta distribution $p(\\pi|x,\\psi)$ under certain learning criteria so that it encodes less uncertainty for ID points $x$ and more for OOD points. While this simplification allows its computational efficiency over the classical methods, as we will argue later, no randomness assumed in the model $p(\\psi|\\mathcal{D})$ lets all the methods in this framework learn spurious distributional uncertainty. Since a single model $\\psi$ is assumed, we use a frequentist notation $p_{\\psi}(\\pi|x)$ instead of $p(\\pi|x,\\psi)$ in that context. ", "page_idx": 2}, {"type": "text", "text": "4 New Taxonomy for EDL Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we propose a new taxonomy to understand different EDL methods (for classification) in a systematic way. Ignoring the choice of base architectures, we identify that the key distinguishing features in EDL methods are (1) the parametric form of the model and (2) the learning criteria. A wide class of EDL methods can be classified with the taxonomy as in Table 1. Several theoretical implications and empirical consequences of the new taxonomy will be investigated in the next section. ", "page_idx": 2}, {"type": "table", "img_path": "P6nVDZRZRB/tmp/1df11b92b504aced930eec3e60d99c597bd50d6f85975638f5a84e36defdeb95.jpg", "table_caption": ["Table 1: New taxonomy of representative EDL methods. $\\mathcal{L}(\\psi)$ in Eq. (6) subsumes these as special cases. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Criterion 1. Parametric Form of Meta Distribution. For classification, one distinguishing feature is the parametric form of $\\alpha_{\\psi}(x)$ in Dirichlet distribution $p_{\\psi}(\\pmb{\\pi}|x)=\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{\\psi}(x))$ . Earlier works [12, 7, 8, 13, 10] typically parameterize $\\alpha_{\\psi}(x)$ by a direct output of a neural network, e.g., exponentiated logits; we call this direct parameterization. Later, Charpentier et al. [15] brought up a potential issue with the direct parameterization that $\\alpha_{\\psi}(x)$ can take arbitrary values on the unseen (i.e., OOD) data points. They proposed a more sophisticated parameterization of the form to explicitly resemble the posterior distribution update of the Dirichlet distribution ${\\pmb\\alpha}_{\\psi}(x)\\gets{\\pmb\\alpha}_{0}+{\\bf N}_{\\psi}(x)$ , where, for $y\\in[C]$ , $\\begin{array}{r}{\\bar{(}\\mathbf{N}_{\\psi}(x))_{y}:=N\\hat{p}(y)\\bar{p_{\\psi_{2}}}(f_{\\psi_{1}}(x)|y)}\\end{array}$ , with $\\hat{p}(y):=N_{y}/N$ , $N_{y}$ denotes the number of data points with label $y$ , $\\begin{array}{r}{N:=\\sum_{y\\in[C]}{\\bar{N_{y}}}}\\end{array}$ , $x\\mapsto f_{\\psi_{1}}(x)$ a feature extractor, and $p_{\\psi_{2}}(z|y)$ a tractable density model such as normalizing flows [21] for each $y\\in[C]$ . We call this density parameterization. In Sec. 5, we carefully examine the effectiveness of density parameterization. ", "page_idx": 3}, {"type": "text", "text": "Criterion 2. Objective Function. The desired behavior of EDL model is to output sharp $p_{\\psi}(\\pi|x)$ if it is confident, and fall back to output prior distribution $p(\\pi)$ if it is uncertain at an unseen data $x$ . To achieve this, various objectives have been introduced with different jargon and motivations, e.g.: ", "page_idx": 3}, {"type": "text", "text": "1. Prior Networks (PriorNet) [7, 8] aimed to explicitly encourage $p_{\\psi}(\\pi|x)$ to be diffused prior $p(\\pi)$ for OOD data, and a more concentrated Dirichlet distribution $\\mathsf{D i r}(\\pi;\\boldsymbol{\\alpha}_{0}+\\nu\\mathbf{e}_{y})$ for $\\mathrm{ID}$ data, with $\\nu\\gg1$ , $\\mathbf{\\alpha}\\alpha_{0}=\\mathbf{1}_{C}$ and ${\\bf e}_{y}$ as the one-hot true label, by minimizing ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{E}_{p(x,y)}[D\\big(\\mathrm{Dir}(\\pi;\\alpha_{0}+\\nu\\mathbf{e}_{y}),p_{\\psi}(\\pi|x)\\big)+\\gamma_{\\mathrm{ood}}\\mathbb{E}_{p_{\\mathrm{ood}}(x)}[D\\big(\\mathrm{Dir}(\\pi;\\alpha_{0}),p_{\\psi}(\\pi|x)\\big)]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for $D(p,q)=D(p\\parallel q)$ (forward KL) in [7], and $D(p,q)=D(q\\parallel p)$ (reverse KL) later in [8]. It is known that PriorNet with forward KL requires an additional auxiliary loss logp\u03c8(1y|x) to ensure high accuracy, and the reverse-KL version can outperform without such term. ", "page_idx": 3}, {"type": "text", "text": "2. The \u201cEvidential Deep Learning\u201d paper [10] proposed the MSE loss with a reverse $\\mathrm{KL}$ regularizer: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\ell_{\\mathsf{M S E}}(\\psi;x,y):=\\mathbb{E}_{p_{\\psi}(\\pi|x)}[\\|\\pi-\\mathbf{e}_{y}\\|^{2}]+\\lambda D(p_{\\psi}(\\pi|x)\\parallel\\mathsf{D i r}(\\pi;\\alpha_{0})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "3. Belief Matching [12, 13] proposed VI loss justified by variational inference framework: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{\\mathsf{V I}}(\\psi;x,y):=\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\left[\\log\\frac{1}{\\pi_{y}}\\right]+\\lambda D(p_{\\psi}(\\pi|x)\\parallel\\mathsf{D i r}(\\pi;\\alpha_{0})).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "4. Posterior Networks (PostNet [15] and NatPN [20]) proposed the uncertainty-aware cross entropy (UCE) loss, motivating it from a general framework for updating belief distributions [22]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{\\mathsf{U C E}}(\\psi;x,y):=\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\Big[\\log\\frac{1}{\\pi_{y}}\\Big]-\\lambda h\\big(p_{\\psi}(\\pmb{\\pi}|x)\\big).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The hyper-parameter $\\lambda>0$ in objectives 2, 3, and 4 balances the first likelihood term which forces $p_{\\psi}(\\pi|x)$ to learn the label distribution and the second regularizer term promotes $p_{\\psi}(\\pi|x)$ to be close to the prior $p(\\pi)$ . Below, we reveal that the seemingly different objectives 1, 3, 4 are exactly equivalent, while objective Eq. (2) (different likelihood) can also be unified in a single framework. ", "page_idx": 3}, {"type": "text", "text": "A Unifying View. We now provide a unifying view of the fairly wide class of representative objective functions. First, for convenience of analysis, we define the tempered likelihood: for $\\nu>0$ , define ", "text_level": 1, "page_idx": 3}, {"type": "equation", "text": "$$\np^{(\\nu)}(\\pi|y):=\\frac{p^{(\\nu)}(\\pi,y)}{\\int p^{(\\nu)}(\\pi,y)\\,\\mathrm{d}\\pi},\\quad\\mathrm{~where~}p^{(\\nu)}(\\pi,y):=\\frac{p(\\pi)p^{\\nu}(y|\\pi)}{\\int p(\\pi)\\sum_{y}p^{\\nu}(y|\\pi)\\,\\mathrm{d}\\pi}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Objectives 1, 3, 4 assume the likelihood model is categorical, i.e., $p(y|\\pmb{\\pi})=\\pi_{y}$ , by the conjugacy of the Dirichlet distribution for the multinomial distribution, it is easy to check that $p^{(\\nu)}(\\pi|y)=$ $\\mathsf{D i r}(\\pi;\\boldsymbol{\\alpha}_{0}+\\nu\\mathbf{e}_{y})$ , where $\\mathbf{e}_{y}\\in\\mathbb{R}^{C}$ is the one-hot vector activated at $y\\in[C]$ . Objective 2 used Gaussian likelihood model $p(y|\\pi)=\\mathcal{N}(\\mathbf{e}_{y};\\pi,\\sigma^{2}I_{C})$ , which does not admit a closed form expression for $p^{(\\nu)}(\\pi|y)$ . The prior distribution is usually defined as $p(\\pi)=\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0})$ with $\\mathbf{\\alpha}\\alpha_{0}=\\mathbf{1}_{C}$ (all-one vector). Other choices of prior were also proposed to promote some other desired property [9]. ", "page_idx": 3}, {"type": "text", "text": "We now introduce a unified objective function ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\psi):=\\mathbb{E}_{p(x,y)}[D(p^{(\\nu)}(\\pi\\vert y),p_{\\psi}(\\pi\\vert x))]+\\gamma_{\\mathrm{ood}}\\mathbb{E}_{p_{\\mathrm{ood}}(x)}[D(p(\\pi),p_{\\psi}(\\pi\\vert x))]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for some divergence function $D(\\cdot,\\cdot)$ , a tempering parameter $\\nu\\,>\\,0$ , and an OOD regularization parameter $\\gamma_{\\mathsf{o o d}}\\geq0$ with a distribution $p_{\\mathsf{o o d}}$ for OOD samples. The following theorem summarizes how this unified objective subsumes several existing proposals. The proof is deferred to Appendix D. ", "page_idx": 3}, {"type": "text", "text": "1. Let $p(y|\\pmb{\\pi})\\,=\\,\\pi_{y}$ and let $\\gamma_{\\mathsf{o o d}}\\,>\\,0$ . With $D(p,q)\\,=\\,D(p\\parallel q)$ (forward $K L,$ ) and $D(p,q)\\,=$ $D(q\\parallel p)$ (reverse $K L_{.}$ ), $\\mathcal{L}(\\psi)$ is equivalent to the objective (Eq. (1)) of forward PriorNet (FPriorNet) $I7J$ and that of reverse PriorNet (RPriorNet) $l\\mathcal{B}J,$ , respectively.   \n2. Let $p(y|\\pi)=\\mathcal{N}(\\mathbf{e}_{y};\\pi,\\sigma^{2}I_{C})$ , and let $\\gamma_{\\mathsf{o o d}}=0$ , $\\mathcal{L}(\\psi)$ is equivalent to the objective $\\mathcal{L}_{M S E}(\\psi):=$ $\\mathbb{E}_{p(x,y)}[\\ell_{M S E}(\\psi;x,\\bar{y})]$ (Eq. (2)).   \n3. Let $p(y|\\pmb{\\pi})=\\pi_{y},\\,\\nu=\\lambda^{-1}$ , and let $\\gamma_{\\mathsf{o o d}}=0$ . With $D(p,q)=D(q\\parallel p)$ (reverse $K L_{.}$ ), $\\mathcal{L}(\\psi)$ is equivalent to the objective $\\mathcal{L}_{V I}(\\psi):=\\mathbb{E}_{p(x,y)}[\\ell_{V I}(\\psi;x,y)]$ (Eq. (3)).   \n4. Let $p(y|\\pmb{\\pi})=\\pi_{y}.$ , $\\nu=\\lambda^{-1}$ , and let $\\gamma_{\\mathsf{o o d}}=0$ . With $D(p,q)=D(q\\parallel p)$ (reverse $K L,$ ), $\\mathcal{L}(\\psi)$ is equivalent to the objective $\\mathcal{L}_{U C E}(\\psi):=\\mathbb{E}_{p(x,y)}[\\ell_{U C E}(\\psi;x,y)]$ (Eq. (4)). ", "page_idx": 4}, {"type": "text", "text": "We first remark that the reverse KL divergence captures most of the cases, except the forward KL PriorNet, which is known to be outperformed by PriorNet with reverse KL. Hence, it suffices to focus on understanding the reverse KL objective. Second, the VI loss in Eq. (3) and UCE loss Eq. (4) turn out to be equivalent to the RPriorNet objective, where the tempering parameter $\\nu$ and the regularization parameter $\\lambda$ is realted to be reciprocal $\\lambda=\\nu^{-1}$ ; see Lemma D.1. Overall, this theorem reveals that different motivations, such as VI or Bayesian updating mechanism of belief distributions, were not very significant, and those objectives turn out to be equivalent to the simple divergence matching in Eq. (6). Given this, distinguishing features that better classify different EDL methods are the choices of (1) likelihood model, (2) prior, (3) use of OOD data, and (4) model parametric form, as shown in Table 1. The recent survey [3] also offers a unified view of different objective functions with these features. However, the dichotomy between \u201cPriorNet-type methods\u201d [7, 8] and \u201cPostNet-type methods\u201d [12, 13, 15, 20, 14] in [3] may not effectively contrast different EDL methods compared to our taxonomy. ", "page_idx": 4}, {"type": "text", "text": "We acknowledge that there exist other objective functions that might not be covered by this unified view. We defer the discussion on another line of representative work, including the distillationbased methods [16, 17] to Sec. 6. A notable exception that is not subsumed by this unification is FisherEDL [11], which was recently proposed to use a variant of the MSE loss [10] by taking into account the Fisher information of $p_{\\psi}(\\pi|x)$ ; see Appendix F for a discussion. Finally, similar reasoning can be naturally extended to unify different EDL objectives for other tasks such as regression and count data analysis, including [19, 20]. We defer a detailed discussion to Appendix F. ", "page_idx": 4}, {"type": "text", "text": "5 Rethinking the Success of EDL Methods ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we aim to reveal the secrets of EDL methods\u2019 empirical success through a combination of theoretical and empirical findings. As alluded to earlier, our empirical investigation focuses on the reverse-KL type EDL methods, i.e., RPriorNet [8], Belief Matching (BM) [13], PostNet [15], and NatPN [20], which are representative and widely used in the literature. ", "page_idx": 4}, {"type": "text", "text": "5.1 What Is the \u201cOptimal\u201d Meta Distribution Characterized By The EDL Objectives? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Based on the unification in Eq. (6), we can provide a sharp mathematical characterization of the optimally learned meta distribution for a wide class of EDL objectives. A direct and important consequence of the divergence minimization view is that we can now characterize the \u201coptimal\u201d behavior of the learned meta distribution of a wide class of EDL objectives, provided that the global minimizer is achieved in the nonparametric and population limit. The following theorem is proved in Appendix E. ", "page_idx": 4}, {"type": "text", "text": "Theorem 5.1. For any prior $p(\\pi)$ and likelihood $p(y|\\pi)$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\psi}{\\operatorname*{min}}\\,\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pi\\vert x)\\,\\Vert\\,p_{\\nu}(\\pi\\vert y))]\\equiv\\underset{\\psi}{\\operatorname*{min}}\\,\\mathbb{E}_{p(x)}[D(p_{\\psi}(\\pi\\vert x)\\,\\Vert\\,p^{\\star}(\\pi\\vert x))],}\\\\ &{\\qquad\\qquad w h e r e\\,p^{\\star}(\\pi\\vert x):=\\frac{p(\\pi)\\exp(\\nu\\mathbb{E}_{p(y\\vert x)}[\\log p(y\\vert\\pi)])}{\\int p(\\pi)\\exp(\\nu\\mathbb{E}_{p(y\\vert x)}[\\log p(y\\vert\\pi)])\\,\\mathrm{d}\\pi}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In words, Theorem 5.1 states that when the model meta distribution $p_{\\psi}(\\pi|x)$ is trained with the reverse-KL objective, it is forced to fit a fixed target meta distribution $p^{\\star}(\\pi|x)$ . ", "page_idx": 4}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/226f42d023d25e3571403cdb5e12ab814c99439dbf6cf046f98a76ecfb471a71.jpg", "img_caption": ["(b) Aleatoric Uncertainty: CIFAR10 "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: Behavior of Uncertainties Learned by EDL methods on Real Data. (a) EDL methods learn spurious epistemic uncertainty, wherein uncertainty does not vanish with an increasing number of observed samples, contrary to the fundamental definition of epistemic uncertainty. (b) Instead of a constant, EDL methods learn model-dependent aleatoric uncertainty that depends on hyper-parameter $\\lambda$ , contrary to the fundamental definition of aleatoric uncertainty. Similar behavior holds for 2D Gaussian data (see Figure 5 in Appendix H.1). ", "page_idx": 5}, {"type": "text", "text": "Example 5.2 (Categorical likelihood). If we consider $p(\\pi)=\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0})$ and $p(y|\\pmb{\\pi})\\,=\\,\\pi_{y}$ (categorical likelihood), we have $p^{\\star}(\\pi|x)\\;=\\;\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0}\\,\\!+\\!\\nu\\pmb{\\eta}(x))$ , where $\\pmb{\\eta}(x)\\;:=\\;\\mathbb{E}_{p(y|x)}[\\mathring{\\mathbf{e}}_{y}]\\;=$ $[p(1|x),...\\,,p(C|x)]$ denotes the true label distribution, Theorem 5.1 implies that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[D\\big(p_{\\psi}(\\pi|x)\\|p_{\\nu}(\\pi|y)\\big)]\\equiv\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x)}[D\\big(\\mathrm{Dir}(\\pi;\\alpha_{\\psi}(x))\\|\\mathrm{Dir}(\\pi;\\alpha_{0}+\\nu\\eta(x))\\big)].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In particular, with the most common Dirichlet parameterization $p_{\\psi}(\\pmb{\\pi}|x)\\,=\\,\\mathsf{D i r}(\\pmb{\\pi};\\pmb{\\alpha}_{\\psi}(x))$ , this shows that $\\alpha_{\\psi}(x)$ is forced to match the scaled-and-shifted version $\\alpha_{0}+\\nu\\eta(x)$ of the conditional label distribution $\\eta(x)$ as the fixed target, under the categorical likelihood model. A similar argument still applies to the Gaussian likelihood model of [10], but the fixed target distribution $p^{\\star}(\\bar{\\pi}|x)$ in Eq. (7) does not admit a closed-form expression unlike the categorical likelihood. ", "page_idx": 5}, {"type": "text", "text": "An immediate consequence of the Theorem 5.1 is that neither epistemic uncertainty nor aleatoric uncertainty quantified by EDL methods is consistent with their dictionary definition. ", "page_idx": 5}, {"type": "text", "text": "Implication 1: EDL Methods Learn Spurious Epistemic Uncertainty ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "First, epistemic uncertainty for ID data, by definition, should monotonically decrease and eventually vanish as the number of observations increases. However, Theorem 5.1 implies that, even with infinite data, the learned \u201cdistributional uncertainty\u201d would remain constant for ID data. We also empirically confirm such behavior; see Fig. 1(a). Specifically, we sample data of varying sizes to train the EDL models and evaluate their test accuracy and averaged epistemic uncertainty (mutual information) on a held-out test set. As observed in Fig. 1(a), epistemic uncertainties quantified by EDL methods are almost constant with respect to the sample size and never vanish to 0, regardless of the increasing test accuracy. This suggests that practitioners cannot rely on the learned distributional uncertainty to determine if the model is lacking knowledge. We remark that Bengs et al. [4] identified a similar issue in the EDL methods specifically for the UCE loss of PostNet [15, 20], which is the reverse-KL objective for $\\alpha=\\mathbb{1}_{C}$ in our view, is not appropriate in a similar spirit.3 Theorem 5.1 can be understood as a more general and sharper mathematical characterization of the behavior of the reverse-KL objective. ", "page_idx": 5}, {"type": "text", "text": "Implication 2: EDL Methods Learn Spurious Aleatoric Uncertainty ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Second, EDL methods quantify aleatoric (data) uncertainty as $\\mathbb{E}_{p_{\\psi}(\\pmb{\\pi}|x)}[H(p(y|\\pmb{\\pi}))]$ , where $H$ denotes the Shannon entropy [23]. Eq. (8) reveals the optimal meta distribution as $p_{\\psi^{\\star}}(\\pi|x)\\;=\\;$ ", "page_idx": 5}, {"type": "text", "text": "$\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0}+\\nu\\pmb{\\eta}(x))$ , suggesting that the aleatoric uncertainty quantified by EDL methods would also depend on model or algorithm\u2019s hyper-parameter $\\left(\\lambda=\\nu^{-1}\\right.$ ). This is inconsistent with the definition of aleatoric uncertainty, which should be a fixed constant capturing the irreducible uncertainty by underlying label distribution $p(y|x)$ . As shown in Fig. 1(b), we empirically demonstrate that the aleatoric uncertainty quantified by EDL methods vary with $\\lambda$ . In conclusion, our analysis in this section suggests that EDL methods do not behave as a reasonable uncertainty quantifier since they cannot faithfully quantify either epistemic or aleatoric uncertainty. ", "page_idx": 6}, {"type": "text", "text": "5.2 EDL Methods Are EBM-Based OOD Detector Rather Than Uncertainty Quantifier ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "As we have shown so far, the EDL methods with Dirichlet prior and categorical model typically aim to fit the model meta distribution $\\alpha_{\\psi}(x)$ to a fixed target $\\alpha_{0}\\mathrm{~+~}\\nu\\eta(x)$ , which is approximately $\\nu\\eta(x)$ for $\\nu$ sufficiently large. Since the induced model predictive distribution is $p_{\\psi}(y|x)\\,=\\,\\mathbb{E}_{p_{\\psi}(\\pi|x)}[p(y|\\pi)]\\,=\\,\\alpha_{\\psi,y}(x)/(\\mathbb{1}_{C}^{\\top}\\alpha_{\\psi}(x))$ , it can be understood that the reverse-KL enforces $p_{\\psi}(y|x)$ to fit $\\nu\\pmb{\\eta}(x)/\\nu(\\mathbb{1}_{C}^{\\sf T}\\pmb{\\eta}(x))=\\pmb{\\eta}(x)=\\pmb{p}(y|x)$ for accurate prediction, while letting the summation $\\mathbb{1}^{\\top}\\alpha_{\\psi}(x)$ large (i.e., $1^{\\intercal}\\alpha_{\\psi}(x)\\,\\approx\\,\\nu)$ for ID data, and small for OOD data, e.g., $\\mathbb{1}_{C}^{\\mathsf{T}}\\pmb{\\alpha}_{0}=C$ , if there exists an explicit OOD regularization. ", "page_idx": 6}, {"type": "text", "text": "In the OOD detection literature, there exists an energy-based-model (EBM) based algorithm aim to achieve the exactly same goal [24]. They consider a standard classifier with exponentiated logits $\\beta_{\\phi}(x)$ , whose prediction is given as $p_{\\phi}\\dot{(\\boldsymbol y|\\boldsymbol x)}\\,:=\\,\\beta_{\\phi,\\boldsymbol y}(\\boldsymbol x)/\\mathbb{1}_{C}^{\\top}\\beta_{\\phi}(\\boldsymbol x)$ . Liu et al. [24] related the denominator to a free energy $E_{\\phi}(x):=-\\log\\mathbb{1}_{C}^{\\top}\\beta_{\\phi}(x)$ , and proposed to train model so that $p_{\\phi}(y|x)$ accurately captures $p(y|x)$ , while minimizing the energy $E_{\\phi}(x)$ for ID $x$ \u2019s, and maximizing for OOD. They proposed to minimize ", "page_idx": 6}, {"type": "equation", "text": "$$\n-\\mathbb{E}_{p(x,y)}[\\log p_{\\psi}(y|x)]+\\tau\\{\\mathbb{E}_{p(x)}[\\operatorname*{max}(0,E_{\\phi}(x)-m_{\\mathrm{id}})^{2}]+\\mathbb{E}_{p_{\\mathrm{ood}}(x)}[\\operatorname*{max}(0,m_{\\mathrm{ood}}-E_{\\phi}(x))^{2}]\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\tau>0$ and $m_{000}>m_{\\mathrm{id}}>0$ are hyperparameters. This reveals that this EBM-based OOD framework has an almost identical learning mechanism to the EDL methods; setting $E_{\\phi}(x)\\;=\\;$ $-\\log\\mathbb{1}_{C}^{\\mathsf{T}}\\pmb{\\alpha}_{\\phi}(x)$ , $m_{\\mathsf{i d}}=-\\log\\nu$ , and $m_{\\tt o o d}=-\\log C$ makes the correspondence explicit. ", "page_idx": 6}, {"type": "text", "text": "This resemblance suggests that the EDL methods can be better understood as an EBM-based OOD detector with the additional layer of Dirichlet framework for computational convenience rather than a statistically meaningful mechanism that can faithfully distinguish epistemic uncertainty and aleatoric uncertainty. Below, we elaborate on two particular implications based on this connection. ", "page_idx": 6}, {"type": "text", "text": "Implication 3: EDL Methods Always Prefer Smaller Hyper-Parameter \u03bb ", "text_level": 1, "page_idx": 6}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/dddc640a188efd94c2c62894852bf7030fdeccfe36c79985f82d25be312ce734.jpg", "img_caption": ["Figure 2: OOD Detection Performance v.s. Hyper-parameter $\\lambda$ on CIFAR10. The $x$ -axis represents the increasing $\\lambda$ value, and the ${\\mathrm{y}}.$ -axis represents the Average AUROC score of OOD detection tasks. EDL Methods uncertainty quantification performance are sensitive to hyper-parameter $\\lambda$ , while generally benefti from small $\\lambda$ . "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Just as the EBM-based OOD detection algorithm needs to manually define hyper-parameter $m_{000}$ and $m_{\\mathrm{id}}$ , EDL methods also significantly rely on hyper-parameter tuning; recall the target distribution $\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0}\\!+\\!\\nu\\pmb{\\eta}(x))$ with $\\nu=\\lambda^{-1}$ is determined by the regularization parameter $\\lambda$ , we aim to explore the dependency of EDL methods\u2019 OOD detection performance on the choice of $\\lambda$ . Specifically, we directly conduct such an analysis on real data using CIFAR10 as ID data, and use four OOD datasets; see Appendix G for details. By varying $\\lambda$ across $\\{1{\\bf e}-4\\,,1{\\bf e}-3\\,,1{\\bf e}-2\\,,1{\\bf e}-1\\}$ , we train an EDL model and evaluate its OOD detection performance on these OOD datasets. The performance in terms of average AUROC score with respect to the increasing value of $\\lambda$ are shown in Fig. 2. The result shows that using smaller values of $\\lambda$ always improves the OOD detection performance, suggesting that the EDL model is essentially encouraged to fit its output $\\alpha_{\\psi}(x)$ to an extremely large target $\\alpha_{0}+\\lambda^{-1}\\eta(x)$ , so that $\\mathbb{1}_{C}^{\\mathsf{T}}\\alpha_{\\psi}(x)\\approx\\lambda^{-1}\\gg1$ for ID data, and such behavior seems to benefit the downstream task performance. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Implication 4: Impact of Specific Objective on UQ Performance is Less Significant ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Given the close resemblance to the OOD detection algorithm, a notable difference is the reverseKL learning criterion used by the EDL methods. In Appendix H.2, as another ablation study, we investigate if the reverse-KL objective induced by the Dirichlet framework has a significant practical impact, or other Dirichlet-framework-independent objectives which promote the same behavior suffice for the downstream task performance. ", "page_idx": 7}, {"type": "text", "text": "5.3 Are EDL Methods Robust for OOD Detection? ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Lastly, we investigate the robustness of the auxiliary techniques like density parameterization and OOD regularization of EDL methods for the downstream task performance. Note that in the empirical result with real data presented in Fig. 9 in Appendix, neither OOD regularization (RPriorNet vs. BM) nor density parameterization (PostNet/NatPN vs. BM) demonstrates a clear advantage of deploying such techniques. Thus, we further investigate this counterintuitive phenomenon and discover that the performance of these EDL methods on real data is hindered by certain limitations of the auxiliary techniques they use. Namely, we find that OOD-data-dependent methods [8] are sensitive to choice of model architectures, and methods [15, 20] using density models may not perform well even for moderate dimensionality. We defer the detailed discussion to Appendix H.3. ", "page_idx": 7}, {"type": "text", "text": "6 EDL Methods Will Benefit from Incorporating Model Uncertainty ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Through the series of analyses in the prior section, we attempted to provide a comprehensive understanding of EDL methods, revealing their key limitations. A reader then may ask an important question: What is the fundamental issue in these EDL methods that cause all these problems? As we alluded to in Sec. 3, we identify that the issue arises from that all of the EDL methods discussed in Sec. 4 and Sec. 5 assume no model uncertainty $p(\\psi|\\mathcal{D})$ in the decomposition of predictive posterior distribution $\\begin{array}{r}{p(y|x,\\psi)=\\iint p(y|\\pi)p(\\pi|x,\\dot{\\psi})\\dot{p(\\psi|\\mathcal{D})}\\mathrm{{d}}\\psi\\,\\mathrm{{d}}\\pi}\\end{array}$ . A proper definition of distributional uncertainty should be based on the induced posterior distribution $\\bar{p}(\\pmb{\\pi}|\\boldsymbol{x},\\mathcal{D}):=$ $\\begin{array}{r}{\\int p(\\pmb{\\pi}|\\boldsymbol{x},\\psi)p(\\psi|\\mathcal{D})\\,\\mathrm{d}\\psi}\\end{array}$ over the prediction $\\pi$ at $x$ , given the dataset $\\mathcal{D}$ . Without the randomness in the model, however, i.e., setting $\\bar{p}(\\psi|\\mathcal{D})\\leftarrow\\delta(\\psi-\\bar{\\psi}^{\\star})$ , the induced distribution $p(\\pi|x,\\mathcal{D})$ becomes degenerate as $p(\\pi|x,\\psi^{\\star})$ . This simplification is often rationalized for the computational efficiency, but as we reveal, it renders the distributional uncertainty inherently ill-defined in this framework. The existing EDL methods thus have no choice but to train the \u201cUQ\u201d model $p_{\\psi}(\\pi|x)$ to fti to an artificial target $\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{0}+\\nu\\pmb{\\eta}(x))$ . Consequently, the learned distributional uncertainty cannot possesses a statistical meaning, and can be better interpreted as free energy in the EBM-based OOD detector. ", "page_idx": 7}, {"type": "text", "text": "Model Uncertainty Can Induce A Proper Distributional Uncertainty. This strongly suggests that it is inevitable to assume a stochastic procedure $p(\\psi|\\mathcal{D})$ to properly define the distributional uncertainty $p(\\pi|x,\\mathcal{D})$ . We remark that, to expect the distributional uncertainty $p(\\pi|x,\\mathcal{D})$ to exhibit a desirable behavior, i.e., getting concentrated for ID data and remaining dispersed for OOD data as $|\\mathcal{D}|\\to\\infty$ , we implicitly assume that the stochastic algorithm $p(\\psi|\\mathcal{D})$ would behave as follows: as $|\\mathcal{D}|\\to\\infty$ , $p(\\psi|\\mathcal{D})$ will become supported on a subset of models $\\psi$ that agree upon the prediction for ID data while disagreeing on OOD data. Under this assumption, the induced distributional uncertainty will be consistent with the dictionary definition of epistemic uncertainty. ", "page_idx": 7}, {"type": "text", "text": "Revisiting Distillation-Based Methods. The downside of such an approach is that approximating $p(\\pi|x,\\mathcal{D})$ can be computationally intractable due to the high-dimensional integration with respect to the stochastic algorithm $p(\\psi|\\mathcal{D})$ , which means that a practitioner needs to generate (or train) and save multiple models to approximately emulate the randomness. In this context, the EDL framework, which aims to quantify uncertainty by a single neural network, can be used to distill the properly defined distributional uncertainty. Indeed, this is what has been explored by another line of EDL literature called distillation-based methods [16, 17], which were originally proposed to emulate the behavior the ensemble methods. Our analyses strongly advocate that considering a stochastic algorithm $p(\\psi|\\mathcal{D})$ and training a single meta distribution trying to fit the induced distributional uncertainty to expedite the inference time complexity is the best practice for the EDL framework to faithfully capture uncertainties. More precisely, we can fit an UQ model $p_{\\theta}(\\pi|x)$ to $p(\\pi|x,\\mathcal{D})$ through the forward-KL objective and Monte Carlo samples, i.e., by minimizing $\\begin{array}{r}{\\mathbb{E}_{p(x)}[D(p(\\pi|x,\\mathcal{D})\\stackrel{\\cdot}{\\|}p_{\\theta}(\\pi|x))]\\approx-\\sum_{i=1}^{N^{\\top}}\\sum_{j=1}^{M}\\log p_{\\theta}(\\eta_{\\hat{\\psi}_{j}}(\\cdot|x_{i})|x_{i})+\\overline{{(\\mathrm{const.})}}}\\end{array}$ with respect to $\\theta$ , where $x\\mapsto\\eta_{\\hat{\\psi}_{j}}(\\cdot|x)$ is a classifier corresponding to a randomly generated model $\\hat{\\psi}_{j}\\sim p(\\psi|D)$ [16]. ", "page_idx": 7}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/5b7701e10b737e0fbd164f5d2c42c836197b9306b814580d5c49e24345b248f7.jpg", "img_caption": ["Figure 3: Comparison of Different EDL Methods on OOD Detection. Distillation based methods, including new proposed Bootstrap-Distill method, demonstrate clear advantage over other classical EDL methods. Similar behavior holds for selective classification task. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/f8c36dbbc3cbd3d4e3f7d66085a93aee0c7839d994fd803c6a66b32f97122bf4.jpg", "img_caption": ["Figure 4: Comparison of Different EDL Methods on Selective Classification. Distillation based methods, including new proposed Bootstrap-Distill method, demonstrate clear advantage over other classical EDL methods. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Examples of Stochastic Algorithms $p(\\psi|\\mathcal{D})$ : Old and New. There are two popular proposals for $p(\\psi|\\bar{D)}$ in the literature: (1) $\\mathrm{\\breve{EnD}^{2}}$ [16] considers randomness in random initialization and stochastic optimization, which is called ensemble [25], and (2) S2D [17] considers a random dropout [26] applied to a single network. We propose yet another algorithm based on the frequentist approach bootstrap: given the training dataset $\\mathcal{D}$ , the procedure randomly samples $M$ different subsets $\\{\\bar{D}_{j}\\}_{j=1}^{M}$ of size $N$ without replacement, and train a model $\\hat{\\psi}_{j}$ based on $\\mathcal{D}_{j}$ for each $j$ . Unlike the previous proposals of $p(\\psi|\\mathcal{D})$ , the bootstrap method aims to leverage the internal consistency among the ID data, beyond the randomness induced by optimization and architectures. We note that this is inspired by a concurrent work of J\u00fcrgens et al. [6], which recently proposed an ideal meta distribution. The proposed bootstrapping can be understood as a practical method for approximating such behavior with finite samples. In the next section, we demonstrate that the new Bootstrap Distillation method performs almost best on both OOD detection and selective classification tasks. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "7 Comprehensive Empirical Evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we conduct a comprehensive evaluation of the existing EDL methods, including the new proposed Bootstrap Distillation method, on two UQ downstream tasks: (1) OOD data detection: identify the OOD data based on the learned epistemic uncertainty; (2) Selective classification: identify the wrongly predicted test samples based on total uncertainty, as wrong prediction can occur from either high epistemic or high data uncertainty, or both. These results corroborate several key findings and insights presented in this paper. The detailed experiment setup are provided in Appendix G, and additional experiment results are included in Appendix H. ", "page_idx": 8}, {"type": "text", "text": "\u2022 Baselines. We include a wide range of EDL methods as baselines: Classical methods: (1) RPriorNet [8], (2) Belief Matching (BM) [13], (3) PostNet [15], (4) NatPN [20], (5) EDL [10], and (6) Fisher-EDL [11]. Distillation-based method: (1) $\\mathrm{EnD^{2}}$ [16] and (2) S2D [17]. All baseline results are reproduced using their official implementation, if available, and their recommended hyper-parameters.   \n\u2022 Benchmark. We consider two ID datasets: CIFAR10, and CIFAR100. For the OOD detection task, we select four OOD datasets for each ID dataset: we use SVHN, FMNIST, TinyImageNet, and corrupted ID data.   \n\u2022 Evaluation Metric. We elaborate metrics for quantifying different types of uncertainties in Section C. We evaluate the UQ downstream performance through the Area Under the ROC Curve (AUROC) and Area Under the Precision-Recall Curve (AUPR), where we treat ID (correctly classified) test samples as the negative class and outlier (misclassified) samples as the positive class. ", "page_idx": 9}, {"type": "text", "text": "Results and Takeaway. The result is summarized in Fig. 3 and Fig. 4. We present the average AUROC score across four OOD datasets for the OOD detection task, and the AUROC score for the selective classification task. More numerical results can be found in Table 2, 3, and 4 in Appendix H. This set of evaluations corroborates our key findings and insights in the previous sections. ", "page_idx": 9}, {"type": "text", "text": "Firstly, the results show that varying the likelihood model does not significantly impact performance (BM vs. EDL and Fisher-EDL), supporting the discussion in Sec. 4. Secondly, classical EDL methods achieve comparable performance regardless of the auxiliary techniques, such as density parameterization (PostNet, NatPN), or leveraging OOD data (RPriorNet); this validates our finding in Sec. 5.3. Thirdly, distillation-based methods, particularly $\\mathrm{EnD^{2}}$ and the new Bootstrap Distillation, demonstrate superior performance over other baselines, especially on CIFAR100, thereby validating the insights provided in Sec. 6. Moreover, our empirical analysis confirms that the Bootstrap Distillation method can faithfully quantify epistemic uncertainty, as illustrated in Fig. 13 in Appendix H, effectively addressing the limitations identified with other EDL methods in Sec. 5.1. Finally, we note that the performance of Bootstrap Distillation comes at a higher computational cost due to training multiple bootstrap models; see Fig. 14 in Appendix H. ", "page_idx": 9}, {"type": "text", "text": "8 Concluding Remarks ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we revealed that the uncertainty learned by most of the existing EDL methods bear no statistical meaning. The key theoretical insight is based on the unification of representative EDL objectives in Sec. 5.1. Given this, we suggested that EDL methods can be better interpreted as energy-based OOD detection algorithms, which can explain the reported empirical successes of EDL methods from a different perspective. Additionally, we demonstrated that the performance of EDL methods is sensitive to the choice of auxiliary techniques, further raising questions about their robustness. Finally, we identified that the aforementioned issues with EDL arise from ignoring the model uncertainty for computational efficiency, and argued that the distillation-based methods could potentially remedy the issues, at the cost of additional complexity. ", "page_idx": 9}, {"type": "text", "text": "Overall, this work calls researchers\u2019 attention to carefully reexamine the capabilities and limitations of the EDL approach at large. For practitioners, EDL methods can still be utilized as efficient algorithms for specific applications, such as OOD data detection. However, when considering EDL methods to build reliable machine learning agents based on their UQ capabilities, practitioners should be aware of their limitations, which contrast with the common belief that EDL approaches can accurately learn and distinguish between epistemic and aleatoric uncertainty. ", "page_idx": 9}, {"type": "text", "text": "We conclude the paper with a few remarks on the theory of the Bootstrap-Distill method. As we empirically showed, it can resolve the common issues of the EDL methods with improved downstream task performance, and we thus believe that a careful theoretical analysis of its behavior would be a fruitful direction. While it is relatively easy to argue that the epistemic uncertainty would vanish when the sample size grows to infinity with the bootstrap procedure, we believe that a more sophisticated asymptotic analysis for vanishing epistemic uncertainty could be carried out with overparameterized neural networks, adopting a similar setting in [27]. That is, if the trained model\u2019s prediction can be shown to be asymptotically normal in the limit of the sample size, one can argue that the uncertainty captured by bootstrap behaves as Gaussian of vanishing variance in the sample limit. This implies a naturally vanishing epistemic uncertainty. We leave this as a future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The authors appreciate the constructive feedback from anonymous reviewers, which helped improve the manuscript. MS and JJR thank Viktor Bengs for helpful discussions on the literature. This work was supported, in part, by the MIT-IBM Watson AI Lab under Agreement No. W1771646. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] E. Begoli, T. Bhattacharya, and D. Kusnezov, \u201cThe need for uncertainty quantification in machine-assisted medical decision making,\u201d Nat. Mach. Intell., vol. 1, no. 1, pp. 20\u201323, 2019. 1   \n[2] B. Djulbegovic, I. Hozo, and S. Greenland, \u201cUncertainty in clinical medicine,\u201d in Philosophy of medicine. Elsevier, 2011, pp. 299\u2013356. 1   \n[3] D. Ulmer, C. Hardmeier, and J. Frellsen, \u201cPrior and posterior networks: A survey on evidential deep learning methods for uncertainty estimation,\u201d Trans. Mach. Learn. Res., 2023, https://www.jmlr.org/tmlr/papers/. 1, 2, 3, 5   \n[4] V. Bengs, E. H\u00fcllermeier, and W. Waegeman, \u201cPitfalls of epistemic uncertainty quantification through loss minimisation,\u201d in Adv. Neural Inf. Proc. Syst., ser. 35, 2022, pp. 29 205\u201329 216. 2, 3, 6, 14, 15   \n[5] V. Bengs, E. H\u00fcllermeier, and W. Waegeman, \u201cOn second-order scoring rules for epistemic uncertainty quantification,\u201d in Proc. Int. Conf. Mach. Learn., ser. Proceedings of Machine Learning Research, A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202. PMLR, 23\u201329 Jul 2023, pp. 2078\u20132091. [Online]. Available: https://proceedings.mlr.press/v202/bengs23a.html 2, 3, 14, 15   \n[6] M. J\u00fcrgens, N. Meinert, V. Bengs, E. H\u00fcllermeier, and W. Waegeman, \u201cIs epistemic uncertainty faithfully represented by evidential deep learning methods?\u201d arXiv preprint arXiv:2402.09056, 2024. 2, 9, 14, 15, 16   \n[7] A. Malinin and M. Gales, \u201cPredictive uncertainty estimation via prior networks,\u201d in Adv. Neural Inf. Proc. Syst., ser. 31, February 2018. 2, 3, 4, 5, 17, 24   \n[8] \u2014\u2014, \u201cReverse KL-divergence training of prior networks: Improved uncertainty and adversarial robustness,\u201d in Adv. Neural Inf. Proc. Syst., ser. 32, May 2019. 2, 3, 4, 5, 8, 10, 17, 20, 22, 24   \n[9] J. Nandy, W. Hsu, and M. L. Lee, \u201cTowards maximizing the representation gap between indomain & out-of-distribution examples,\u201d in Adv. Neural Inf. Proc. Syst., ser. 33, 2020, pp. 9239\u20139250. 2, 4, 17   \n[10] M. Sensoy, L. Kaplan, and M. Kandemir, \u201cEvidential deep learning to quantify classification uncertainty,\u201d in Adv. Neural Inf. Proc. Syst., vol. 31, 2018. 2, 3, 4, 5, 6, 10   \n[11] D. Deng, G. Chen, Y. Yu, F. Liu, and P.-A. Heng, \u201cUncertainty estimation by Fisher informationbased evidential deep learning,\u201d in Proc. Int. Conf. Mach. Learn. PMLR, 2023, pp. 7596\u20137616. 2, 3, 5, 10, 20, 22, 24   \n[12] W. Chen, Y. Shen, H. Jin, and W. Wang, \u201cA variational Dirichlet framework for out-ofdistribution detection,\u201d arXiv preprint arXiv:1811.07308, November 2018. 2, 3, 4, 5, 17   \n[13] T. Joo, U. Chung, and M.-G. Seo, \u201cBeing Bayesian about categorical probability,\u201d in Proc. Int. Conf. Mach. Learn., ser. 119, February 2020, pp. 4950\u20134961. 2, 3, 4, 5, 10, 17, 18   \n[14] M. Shen, Y. Bu, P. Sattigeri, S. Ghosh, S. Das, and G. Wornell, \u201cPost-hoc uncertainty learning using a Dirichlet meta-model,\u201d in Proc. AAAI Conf. Artif. Intell., vol. 37, 2023, pp. 9772\u20139781. 2, 5   \n[15] B. Charpentier, D. Z\u00fcgner, and S. G\u00fcnnemann, \u201cPosterior network: Uncertainty estimation without OOD samples via density-based pseudo-counts,\u201d in Adv. Neural Inf. Proc. Syst., ser. 33, June 2020, pp. 1356\u20131367. 2, 3, 4, 5, 6, 8, 10, 14, 18, 21, 24, 25   \n[16] A. Malinin, B. Mlodozeniec, and M. Gales, \u201cEnsemble distribution distillation,\u201d in Int. Conf. Learn. Repr., 2020. [Online]. Available: https://openreview.net/forum?id=BygSP6Vtvr 2, 5, 8, 9, 10, 22   \n[17] Y. Fathullah and M. J. Gales, \u201cSelf-distribution distillation: efficient uncertainty estimation,\u201d in Proc. Uncertainty Artif. Intell., ser. 180. PMLR, August 2022, pp. 663\u2013673. [Online]. Available: https://proceedings.mlr.press/v180/fathullah22a.html 2, 5, 8, 9, 10, 23   \n[18] A. Amini, W. Schwarting, A. Soleimany, and D. Rus, \u201cDeep evidential regression,\u201d in Adv. Neural Inf. Proc. Syst., vol. 33, 2020, pp. 14 927\u201314 937. 2, 3, 15, 20   \n[19] A. Malinin, S. Chervontsev, I. Provilkov, and M. Gales, \u201cRegression prior networks,\u201d arXiv preprint arXiv:2006.11590, 2020. 2, 3, 5, 15, 20   \n[20] B. Charpentier, O. Borchert, D. Z\u00fcgner, S. Geisler, and S. G\u00fcnnemann, \u201cNatural posterior network: Deep Bayesian uncertainty for exponential family distributions,\u201d in Int. Conf. Learn. Repr., 2022. 2, 3, 4, 5, 6, 8, 10, 15, 18, 20, 21, 22, 25   \n[21] I. Kobyzev, S. J. Prince, and M. A. Brubaker, \u201cNormalizing flows: An introduction and review of current methods,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 43, no. 11, pp. 3964\u20133979, 2020. 4   \n[22] P. G. Bissiri, C. C. Holmes, and S. G. Walker, \u201cA general framework for updating belief distributions,\u201d J. R. Stat. Soc. B, vol. 78, no. 5, pp. 1103\u20131130, November 2016. 4, 18   \n[23] T. M. Cover and J. A. Thomas, Elements of information theory. John Wiley & Sons, 2006. 6, 17   \n[24] W. Liu, X. Wang, J. D. Owens, and Y. Li, \u201cEnergy-based out-of-distribution detection,\u201d in Adv. Neural Inf. Proc. Syst., vol. 33, October 2020, pp. 21 464\u201321 475. 7   \n[25] B. Lakshminarayanan, A. Pritzel, and C. Blundell, \u201cSimple and scalable predictive uncertainty estimation using deep ensembles,\u201d in Adv. Neural Inf. Proc. Syst., ser. 30, 2017. 9, 16   \n[26] Y. Gal and Z. Ghahramani, \u201cDropout as a Bayesian approximation: Representing model uncertainty in deep learning,\u201d in Proc. Int. Conf. Mach. Learn., ser. 48. PMLR, June 2016, pp. 1050\u20131059. [Online]. Available: https://proceedings.mlr.press/v48/gal16.html 9, 16   \n[27] Z. Huang, H. Lam, and H. Zhang, \u201cEfficient uncertainty quantification and reduction for over-parameterized neural networks,\u201d vol. 36, 2023. 10   \n[28] T. Gneiting and A. E. Raftery, \u201cStrictly proper scoring rules, prediction, and estimation,\u201d J. Am. Statist. Assoc., vol. 102, no. 477, pp. 359\u2013378, 2007. 15   \n[29] H. Ma, Z. Han, C. Zhang, H. Fu, J. T. Zhou, and Q. Hu, \u201cTrustworthy multimodal regression with mixture of normal-inverse gamma distributions,\u201d in Adv. Neural Inf. Proc. Syst., vol. 34, 2021, pp. 6881\u20136893. 15   \n[30] A. Graves, \u201cPractical variational inference for neural networks,\u201d in Adv. Neural Inf. Proc. Syst., vol. 24, 2011. 16   \n[31] D. P. Kingma, T. Salimans, and M. Welling, \u201cVariational dropout and the local reparameterization trick,\u201d in Adv. Neural Inf. Proc. Syst., vol. 28, 2015. 16   \n[32] M. Welling and Y. W. Teh, \u201cBayesian learning via stochastic gradient langevin dynamics,\u201d in Proc. Int. Conf. Mach. Learn. Citeseer, 2011, pp. 681\u2013688. 16   \n[33] K. A. Dubey, S. J Reddi, S. A. Williamson, B. Poczos, A. J. Smola, and E. P. Xing, \u201cVariance reduction in stochastic gradient Langevin dynamics,\u201d in Adv. Neural Inf. Proc. Syst., vol. 29, 2016. 16   \n[34] A. Kristiadi, M. Hein, and P. Hennig, \u201cLearnable uncertainty under Laplace approximations,\u201d in Proc. Uncertainty Artif. Intell. PMLR, 2021, pp. 344\u2013353. 16   \n[35] H. Ritter, A. Botev, and D. Barber, \u201cA scalable laplace approximation for neural networks,\u201d in Int. Conf. Learn. Repr., vol. 6. International Conference on Representation Learning, 2018. 16   \n[36] A. Alaa and M. Van Der Schaar, \u201cDiscriminative jackknife: Quantifying uncertainty in deep learning via higher-order influence functions,\u201d in Proc. Int. Conf. Mach. Learn. PMLR, 2020, pp. 165\u2013174. 16   \n[37] W. Huang, J. Zhang, and K. Huang, \u201cBootstrap estimated uncertainty of the environment model for model-based reinforcement learning,\u201d in Proc. AAAI Conf. Artif. Intell., vol. 33, 2019, pp. 3870\u20133877. 16   \n[38] M. Valdenegro-Toro, \u201cDeep sub-ensembles for fast uncertainty estimation in image classification,\u201d arXiv preprint arXiv:1910.08168, 2019. 16   \n[39] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U. R. Acharya, V. Makarenkov, and S. Nahavandi, \u201cA review of uncertainty quantification in deep learning: Techniques, applications and challenges,\u201d Inf. fusion, vol. 76, pp. 243\u2013297, 2021. 16   \n[40] J. Gawlikowski, C. R. N. Tassi, M. Ali, J. Lee, M. Humt, J. Feng, A. Kruspe, R. Triebel, P. Jung, R. Roscher et al., \u201cA survey of uncertainty in deep neural networks,\u201d arXiv preprint arXiv:2107.03342, 2021. 16   \n[41] M. Sensoy, L. Kaplan, F. Cerutti, and M. Saleki, \u201cUncertainty-aware deep classifiers using generative models,\u201d in Proc. AAAI Conf. Artif. Intell., vol. 34, April 2020, pp. 5620\u20135627. 20   \n[42] N. Meinert, J. Gawlikowski, and A. Lavin, \u201cThe unreasonable effectiveness of deep evidential regression,\u201d in Proc. AAAI Conf. Artif. Intell., vol. 37, 2023, pp. 9134\u20139142. 20   \n[43] K. Simonyan and A. Zisserman, \u201cVery deep convolutional networks for large-scale image recognition,\u201d arXiv preprint arXiv:1409.1556, 2014. 21   \n[44] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit., 2016, pp. 770\u2013778. 21   \n[45] J. Van Amersfoort, L. Smith, A. Jesson, O. Key, and Y. Gal, \u201cOn feature collapse and deep kernel learning for single forward pass uncertainty,\u201d arXiv preprint arXiv:2102.11409, 2021. 25 ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A In-Depth Review of Recent Critiques on EDL Methods 14 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Review of [4] \u201cPitfalls of Epistemic Uncertainty Quantification Through Loss Minimisation\u201d 14   \nA.2 Review of [5] \u201cOn Second-Order Scoring Rules for Epistemic Uncertainty Quantification\u201d 15   \nA.3 Review of [6] \u201cIs Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?\u201d 15 ", "page_idx": 13}, {"type": "text", "text": "B Literature Review for Classical UQ Methods 16 ", "page_idx": 13}, {"type": "text", "text": "C Definition of Uncertainty and Its Measures 16 ", "page_idx": 13}, {"type": "text", "text": "D Proof of Theorem 4.1 17 ", "page_idx": 13}, {"type": "text", "text": "D.1 Prior Network Objective 17   \nD.2 Variational Inference and EDL Objective . . 17   \nD.3 Uncertainty Cross Entropy Objective 18 ", "page_idx": 13}, {"type": "text", "text": "E Proof of Theorem 5.1 18 ", "page_idx": 13}, {"type": "text", "text": "F An Extension For General Observation Models 19   \nF.1 Example: Classification . 20   \nF.2 Example: Regression 20   \nG Experiment Setup 20   \nG.1 Data Processing . 20   \nG.2 Model Architecture 21   \nG.3 Implementation Details 21 ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "H Additional Experiment Results 23 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "H.1 Omitted Results in Sec. 5.1 23   \nH.2 Ablation Study in Sec. 5.2 23   \nH.3 Ablation Study in Sec. 5.3 24   \nH.4 Bootstrap Distillation Method Faithfully quantify Epistemic Uncertainty 25   \nH.5 Bootstrap Distillation Method Benefits from More Samples . 26   \nH.6 Detailed Results on UQ Downstream Tasks 27 ", "page_idx": 13}, {"type": "text", "text": "A In-Depth Review of Recent Critiques on EDL Methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we conduct a compressive review of the recent critiques of EDL methods [4, 5, 6] that are closely relevant to our paper. We begin by acknowledging the contributions of [4], which pioneered the theoretical study of EDL methods. However, there are several limitations in these works to be noted: (1) Some of the main arguments presented in [4] are invalid given errors in the corresponding proofs. (2) The analysis in these works are purely theoretical. They do not sufficiently explain the empirical behaviors of EDL methods in practical application. (3) The analyses do not include some representative EDL approaches in the literature, such as the distillation-based methods discussed in our paper. (4) While these works effectively point out various limitations of EDL methods, none of these works provide insights or concrete solutions to address these issues. ", "page_idx": 13}, {"type": "text", "text": "A.1 Review of [4] \u201cPitfalls of Epistemic Uncertainty Quantification Through Loss Minimisation\u201d ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In [4], the authors studied the property of a meta distribution characterized by minimizing a certain loss such as the UCE loss [15] for classification. The authors proposed a definition of two desirable properties for a faithfully learned meta distribution should satisfy [4, Definition 1]: First, for some distributional uncertainty measure, the expected uncertainty captured in the meta distribution over observations should monotonically decrease as the data size increases. Second, as the data size goes to infinity, the meta distribution needs to converge to a degenerate Dirac delta distribution around a single distribution. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "They provide three arguments based on the value of regularization parameter: (1) if $\\lambda=0$ , which means no regularizer in the UCE loss, then the meta distribution becomes a Dirac function thus the first is violated [4, Theorem 1]; (2) if $\\lambda>0$ in the UCE loss is too large, then the second desideratum is not satisfied [4, Theorem 2]. (3) Also, they claimed that if $\\lambda>0$ is too small, then the first is violated [4, Theorem 3]. ", "page_idx": 14}, {"type": "text", "text": "We respectfully point out, however, that the proofs of both Theorem 2 and Theorem 3 are erroneous due to the steps that identify the differential entropy of a Dirac delta function as 0, instead of $-\\infty$ . After correction, we realize the statements of [4, Theorem 3] is no longer valid. Instead, the arguments in [4, Theorem 1] and [4, Theorem 2] can be more sharply inferred from our Theorem 5.1. First, when $\\lambda=0$ , it is easy to show that the optimal meta distribution $p^{\\star}(\\pi|x)$ in Eq. (7) will be Dirac function. Second, Theorem 5.1 implies a stronger result than the second claim: for any value of $\\lambda$ , the meta distribution converges to a non-Dirac-delta distribution as the sample size grows, thus the second desideratum in [4, Definition 1] is not satisfied. We also note that we do not need an additional regularity assumption. ", "page_idx": 14}, {"type": "text", "text": "A.2 Review of [5] \u201cOn Second-Order Scoring Rules for Epistemic Uncertainty Quantification\u201d ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "As a follow-up work, Bengs et al. [5] studied an existence of a proper scoring rule for second-order distributions (i.e., meta distributions). They extended the standard definition of proper scoring rules [28] to meta distributions, and provided theoretical arguments why there can be virtually no such proper scoring rule, even if we hypothetically assume the existence of the true second-order distribution. ", "page_idx": 14}, {"type": "text", "text": "At a facial value, this seems to contradict the fact that we use the forward $\\mathrm{KL}$ objective in the distillation approach. To resolve the inconsistency, we consider the classification case, and we even omit the dependence on the covariate $x$ for simplicity. On the one hand, Bengs et al. [5] considered a particular form of objective in the form ", "page_idx": 14}, {"type": "equation", "text": "$$\nL_{2}(\\psi;p_{\\mathrm{target}}):=\\mathbb{E}_{p_{\\mathrm{target}}(\\pi)}[\\mathbb{E}_{y\\sim\\pi}[\\ell(\\psi;y)]],\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for some scoring rule $\\ell(\\psi;y)$ . On the other hand, in the distillation-based method, we use the forward KL objective: ", "page_idx": 14}, {"type": "equation", "text": "$$\nL_{\\mathsf{f K L}}(\\psi;p_{\\mathsf{t a r g e t}}):=D(p_{\\mathsf{t a r g e t}}(\\pi)\\parallel p_{\\psi}(\\pi)).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Even in the standard EDL methods, we use the reverse-KL objective, though the target may not be meaningful: ", "page_idx": 14}, {"type": "equation", "text": "$$\nL_{\\mathsf{r K L}}(\\psi;p_{\\mathsf{t a r g e t}}):=D(p_{\\psi}(\\boldsymbol{\\pi})\\parallel p_{\\mathsf{t a r g e t}}(\\boldsymbol{\\pi})).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "As the side-by-side comparison reveals, in practice, most existing EDL methods are using either the forward KL objective (distillation based EDL methods) or the reverse-KL objective (classical EDL methods), but the objective function analyzed in [5] assumes a particular form that involves the expectation $\\mathbb{E}_{y\\sim\\pi}[\\cdot]$ , and this implies that the negative results are of rather limited applicability. As our Sec. 6 suggests, if we can directly construct a reasonable target meta distribution in a way that either KL divergence is computable, then we can use such divergence matching to learn the meta distribution in a faithful manner. ", "page_idx": 14}, {"type": "text", "text": "A.3 Review of [6] \u201cIs Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?\u201d ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In a concurrent work, J\u00fcrgens et al. [6] questions the reliability of distributional uncertainty learned by two types of loss under different settings, including classification, regression and count data: the \u201cinner loss\u201d widely used by evidential regression framework [18, 29], and the \u201couter loss\u201d which is more commonly applied in classification setting and some regression methods [19, 20] (equivalent to general UCE loss in Sec. F in our view). J\u00fcrgens et al. [6] mainly aims to examine whether the leared distributional uncertainty can be consistent to a \u201ctarget\u201d epistemic uncertainty induced by a reference distribution. ", "page_idx": 14}, {"type": "text", "text": "First, [6, Definition 3.1] defines such a reference distribution as $\\begin{array}{r}{q_{N}(\\pmb{\\theta}|x):=\\int_{(\\mathcal{X}\\times\\mathcal{Y})^{N}}\\mathbb{I}[\\pmb{\\theta}_{\\mathcal{D}_{N}}=}\\end{array}$ $\\theta]\\,\\mathrm{d}P^{N}$ , assuming an access to the underlying data generating distribution $\\mathcal{D}_{N}\\sim P^{N}$ is available, with $\\pmb{\\theta}$ representing the true first-order target for input $x$ . The term $\\pmb{\\theta}_{\\mathcal{D}_{N}}$ denotes the first-order prediction obtained by a model optimized the first-order objective (e.g., log likelihood) using a dataset $\\mathcal{D}_{N}$ with size $N$ , randomly sampled from $P$ . ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Given this reference distribution, [6, Theorem 3.2] suggests that the optimal second-order distributions derived from EDL methods using \u201cinner loss\u201d are not uniquely defined, [6, Theorem 3.3] states that when there is no regularizer, i.e., $\\lambda=0$ , the optimal second-order distribution derived from optimizing the \u201couter loss\u201d is a Dirac delta function, and [6, Theorem 3.4] demonstrates that for any data generation distribution, there exists a $\\lambda>0$ for which the optimal second-order distribution learned by \u201couter loss\u201d differs from the reference distribution defined in [6, Definition 3.1]. ", "page_idx": 15}, {"type": "text", "text": "While [6, Theorem 3.2] falls outside the primary scope of our paper, the arguments from both [6, Theorem 3.3] and [6, Theorem 3.4] can be derived from our Theorem 5.1, which provides an exact characterization of the optimal second-order distribution as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\np^{\\star}(\\pmb\\theta|x)=\\frac{p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])\\,\\mathrm d\\pmb\\theta}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For the $\\lambda=0$ scenario described in [6, Theorem 3.3], where $\\nu=\\lambda^{-1}\\to\\infty$ , the sample $\\pmb{\\theta}^{*}$ that maximizes $\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb{\\theta})]$ will exponentially dominate the integral, leading to: ", "page_idx": 15}, {"type": "equation", "text": "$$\np^{\\star}(\\pmb\\theta|x)=\\frac{p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])\\,\\mathrm{d}\\pmb\\theta}\\xrightarrow{\\nu\\rightarrow\\infty}\\delta(\\pmb\\theta-\\pmb\\theta^{\\ast}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\pmb{\\theta}^{*}\\;=\\;\\arg\\operatorname*{max}_{\\pmb{\\theta}}\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb{\\theta})]\\;=\\;\\pmb{\\eta}(x)$ . For the case when $\\lambda\\:>\\:0$ analyzed in [6, Theorem 3.4], our analysis provides the exact optimal second-order distribution in Eq. (9), which clearly demonstrates that it is different from their reference distribution for any specific choice of $\\lambda$ . ", "page_idx": 15}, {"type": "text", "text": "For the classification setting with categorical likelihood $p(y|\\pmb{\\theta})=\\pmb{\\pi}_{y}$ , our analysis in Example 5.2 provides even sharper results. Here, the optimal Dirichlet distribution can be expressed as: ", "page_idx": 15}, {"type": "equation", "text": "$$\np^{\\star}(\\pmb{\\pi}|\\boldsymbol{x})=\\mathsf{D i r}(\\pmb{\\pi};\\pmb{\\alpha}_{0}+\\nu\\pmb{\\eta}(\\boldsymbol{x}))\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "When $\\lambda=0$ , $\\nu=\\lambda^{-1}\\to\\infty$ , the optimal Dirichlet distribution converges to a Dirac function, i.e., $\\begin{array}{r}{\\mathsf{D i r}(\\pi;\\alpha_{0}+\\nu\\eta(x))\\xrightarrow{\\nu\\to\\infty}\\delta(\\pi-\\eta(x))}\\end{array}$ . When $\\lambda>0$ , the behavior of the learned second-order distribution can be exactly characterized by $\\mathsf{D i r}(\\pmb{\\pi};\\pmb{\\alpha}_{0}+\\lambda^{-1}\\pmb{\\eta}(x))$ . ", "page_idx": 15}, {"type": "text", "text": "Hence, both [6, Theorem 3.3] and [6, Theorem 3.4] can be understood as simple corollaries of our Theorem 5.1. ", "page_idx": 15}, {"type": "text", "text": "B Literature Review for Classical UQ Methods ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Classical UQ methods include Bayesian approaches, which model posterior distributions over model parameters and approximate the Bayesian inference in various ways, including variational inference [30, 31], MCMC [32, 33], Monte-Carlo dropout [26], and Laplace approximation [34, 35]. Frequentist methods construct uncertainty sets through techniques such as jackknife [36] and bootstrap [37]. Ensemble methods aggregate decisions of several random models to capture predictive uncertainty [25, 38]. These classical methods suffer from expensive computation cost incurred by either multiple forward passes or training multiple models. More comprehensive review of classical UQ approaches can be found in survey papers [39, 40]. ", "page_idx": 15}, {"type": "text", "text": "C Definition of Uncertainty and Its Measures ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In EDL, the uncertainty captured by $p_{\\psi}(\\pi|x)$ and $p_{\\psi}(y|x)$ are called the distributional uncertainty and aleatoric (data) uncertainty, respectively. distributional uncertainty is also a kind of epistemic (knowledge) uncertainty that captures the model\u2019s lack of knowledge arising from the mismatch in the training distribution and test distribution. That is, the distribution $p_{\\psi}(\\pi|x_{0})$ should be dispersed if the model is uncertain on the particular query point $x_{0}$ , and sharp otherwise. As the adjective epistemic suggests, this uncertainty is supposed to vanish at points in the support of the underlying distribution, when the model has observed infinitely many samples. In contrast, the aleatoric uncertainty captures the inherent uncertainty in $p(y|x)$ , and thus must be invariant to the sample size in principle. ", "page_idx": 15}, {"type": "text", "text": "There are two standard metrics to measure distributional uncertainty: (1) differential entropy (DEnt) $\\begin{array}{r}{h_{\\psi}(\\pmb{\\pi}|x)\\ :=\\ -\\int p_{\\psi}(\\pmb{\\pi}|x)\\log p_{\\psi}(\\pmb{\\pi}|x)d\\pmb{\\pi}}\\end{array}$ ; (2) mutual information (MI) $I_{\\psi}(y;\\pi|x)\\stackrel{*}{:=}$ $\\begin{array}{r}{H(p_{\\psi}(y|x))-\\mathbb{E}_{p_{\\psi}(\\pi|x)}[H(p(y|\\pi))]}\\end{array}$ , where $\\ddot{\\mathbb{E}}_{p_{\\psi}(\\pmb{\\pi}|x)}[H\\left(p(y|\\pmb{\\pi})\\right)]$ is usually defined as the aleatoric (data) uncertainty. The resulting probabilistic classifier $p_{\\psi}(y|x)$ captures both epistemic and aleatoric uncertainties without distinction, and the total uncertainty is often measured via two standard metrics: (1) entropy (Ent) of $p_{\\psi}(y|x)$ , i.e., $H\\left(p_{\\psi}(y|x)\\right)$ ; (2) max probability (MaxP) of $p_{\\psi}(y|x)$ , i.e., $\\operatorname*{max}_{y}p_{\\psi}(y|x)$ . ", "page_idx": 16}, {"type": "text", "text": "D Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We prove the four statements in Theorem 4.1 in the following three subsections: the first (PriorNet objectives) is proved in Appendix D.1, second (EDL/MSE objective) and third (VI/ELBO objective) in Appendix D.2, and fourth (PostNet/UCE objective) in Appendix D.3. ", "page_idx": 16}, {"type": "text", "text": "D.1 Prior Network Objective ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Prior networks [7, 8] proposed to use the following form of objectives: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{p(x,y)}[D(p^{(\\nu)}(\\pi|y),p_{\\psi}(\\pi|x))+\\gamma_{\\mathsf{o o d}}\\mathbb{E}_{p_{\\mathsf{o o d}}(x)}[D(p(\\pi),p_{\\psi}(\\pi|x))].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here, $\\nu(\\in\\{10^{2},10^{3}\\})$ and $\\gamma_{00{\\mathsf{d}}}$ are hyperparameters. ", "page_idx": 16}, {"type": "text", "text": "\u2022 The F-KL objective [7] is when $D(p,q)=D(p\\parallel q)$ . The in-distribution objective can be written as $\\mathbb{E}_{p(x,y)}[D(p^{(\\nu)}(\\pi\\lvert y)\\rvert\\lvert\\,p_{\\psi}(\\pi\\lvert x))]=\\mathbb{E}_{p(x)}[D(\\mathbb{E}_{p(y\\mid x)}[p^{(\\nu)}(\\pi\\lvert y)]\\rvert\\,\\lVert\\,p_{\\psi}(\\pi\\,\\lvert x))]+(\\mathrm{const.}).$ This implies that minimizing the F-KL objective function forces the unimodal UQ model $p_{\\psi}(\\pi|x)$ to fit the mixture of Dirichlet distributions $\\mathbb{E}_{p(y|x)}[p^{(\\nu)}(\\pi|y)]$ . Since the mixture can be multimodal when $p(y|x)$ is not one-hot, or equivalently, if aleatoric uncertainty is nonzero, the F-KL objective will drive the UQ model to spread the probability mass over the simplex, which possibly leads to low accuracy.   \n\u2022 The R-KL objective [8] is when $D(p,q)\\,=\\,D(q\\parallel p)$ . Unlike the F-KL objective, the in-distribution objective can be written as $\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pi|x)\\parallel p^{(\\nu)}(\\pi|y))]=\\mathbb{E}_{p(x)}[D(p_{\\psi}(\\pi|x)\\parallel\\mathsf{D i r}(\\pi;\\alpha_{0}+\\nu\\eta(x)))]+(\\mathsf{c o n s t.}).$ Since $p_{\\psi}(\\pi|x)$ is being fti to another Dirichlet distribution $\\mathsf{D i r}(\\pmb{\\pi};\\pmb{\\alpha}_{0}+\\nu\\pmb{\\eta}(x))$ , it no longer has the issue of the F-KL objective above. We note in passing that Nandy et al. [9] proposed an ad-hoc objective such that $\\alpha_{\\psi}(x)<1$ for OOD $x'_{\\mathrm{s}}$ . ", "page_idx": 16}, {"type": "text", "text": "D.2 Variational Inference and EDL Objective ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The variational inference (VI) loss was proposed by Chen et al. [12], Joo et al. [13] in the following form: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\ell_{\\mathsf{V}1}(\\psi;x,y):=\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\Bigl[\\log\\frac{1}{p(y|\\pi)}\\Bigr]+\\lambda D(p_{\\psi}(\\pi|x)\\parallel p(\\pi)).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Although the original derivation is a bit involved, we can rephrase the key logic in the paper by the following variational relaxation: ", "page_idx": 16}, {"type": "equation", "text": "$$\nD(p(x,y)\\parallel p(x)p_{\\lambda^{-1}}(y))\\le D(p(x,y)p_{\\psi}(\\pi\\vert x)\\parallel p(x)p_{\\lambda^{-1}}(\\pi,y)),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $p^{(\\nu)}(y)$ is induced by the tempered distribution $p^{(\\nu)}(\\pmb{\\pi},y)\\propto p(\\pmb{\\pi})p^{\\nu}(y|\\pmb{\\pi})$ . The inequality is a simple application of a form of data processing inequality [23]. We remark that the original name, \u201cELBO loss,\u201d is a misnomer for this loss function, as the right-hand side simply bounds a constant on the left-hand side, as opposed to the negative ELBO, which bounds the negative log-likelihood. ", "page_idx": 16}, {"type": "text", "text": "Lemma D.1. Let $\\nu:=\\lambda^{-1}$ . Then, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[\\ell_{\\mathsf{V}1}(\\psi;x,y)]\\equiv\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pi|x)\\parallel p^{(\\nu)}(\\pi|y))].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. Note that by the chain rule of $\\mathrm{KL}$ divergence, we have on the one hand ", "page_idx": 17}, {"type": "text", "text": "1 $\\begin{array}{r}{\\operatorname{\\calO}(p(x,y)p_{\\psi}(\\pi|x)\\parallel p(x)p^{(\\nu)}(\\pi,y))=D(p(x,y)\\parallel p(x)p^{(\\nu)}(y))+\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pi|x)\\parallel p^{(\\nu)}(\\pi|y)].}\\end{array}$ Hence, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pi|x)\\parallel p^{(\\nu)}(\\pi|y))]\\equiv\\operatorname*{min}_{\\psi}D(p(x,y)p_{\\psi}(\\pi|x)\\parallel p(x)p^{(\\nu)}(\\pi,y)).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "On the other hand, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D(p(x,y)p_{\\psi}(\\pi|x)\\mid p(x)p^{(\\nu)}(\\pi,y))}\\\\ &{=\\mathbb{E}_{p(x,y)p_{\\psi}(\\pi|x)}\\Big[\\log\\frac{p(x,y)p_{\\psi}(\\pi|x)}{p(x)p^{(\\nu)}(\\pi,y)}\\Big]}\\\\ &{=\\mathbb{E}_{p(x,y)p_{\\psi}(\\pi|x)}\\Big[\\log\\frac{p(x,y)p_{\\psi}(\\pi|x)}{p(x)p(\\pi)p^{\\nu}(y|\\pi)}\\Big]+\\log B}\\\\ &{=\\mathbb{E}_{p(x,y)}\\Big[\\nu\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\Big[\\log\\frac{1}{p(y|\\pi)}\\Big]+D(p_{\\psi}(\\pi|x)\\parallel p(\\pi))\\Big]+D(p(x,y)\\parallel p(x))+\\log B}\\\\ &{=\\mathbb{E}_{p(x,y)}[\\ell_{\\forall}(\\psi;x,y)]+D(p(x,y)\\parallel p(x))+\\log B.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Here, we let $\\begin{array}{r}{B:=\\sum_{y}\\int p(\\pi)p^{\\nu}(y|\\pi)\\,\\mathrm{d}\\pi}\\end{array}$ is the normalization constant, which satisfies $p^{(\\nu)}(\\pi,y)=$ $\\begin{array}{r}{\\frac{1}{B}p(\\pmb{\\pi})p^{\\nu}(\\pmb{y}|\\pmb{\\pi})}\\end{array}$ . This implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\psi}D(p(x,y)p_{\\psi}(\\pi|x)\\parallel p(x)p^{(\\nu)}(\\pi,y))\\equiv\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[\\ell_{\\mathsf{V}1}(\\psi;x,y)].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combining Eq. (12) and Eq. (11), we prove the desired equivalence. ", "page_idx": 17}, {"type": "text", "text": "D.3 Uncertainty Cross Entropy Objective ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Charpentier et al. [15, 20] proposed to use the uncertainty cross-entropy loss, which is defined as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{\\mathsf{U C E}}(\\psi;x,y):=\\nu\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\Bigl[\\log\\frac{1}{p(y|\\pi)}\\Bigr]-h(p_{\\psi}(\\pi|x)).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In [15, 20], this loss function was originally motivated from a general framework for updating belief distributions [22]. ", "page_idx": 17}, {"type": "text", "text": "As alluded to earlier, however, it is a special instance of the VI objective of Joo et al. [13] when $\\mathbf{\\alpha}_{\\alpha_{0}}=\\mathbb{1}$ , since $\\begin{array}{r}{p(\\pi)=\\mathsf{D i r}(\\pi;\\mathbb{1})=\\frac{1}{B(\\mathbb{1})}=(C-1)!}\\end{array}$ and thus ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D(p_{\\psi}(\\pi|x)\\parallel p(\\pi))=\\mathbb{E}_{p_{\\psi}(\\pi|x)}\\Big[\\log\\frac{p_{\\psi}(\\pi|x)}{p(\\pi)}\\Big]}\\\\ &{\\qquad\\qquad\\qquad=-h(p_{\\psi}(\\pi|x))-\\mathbb{E}_{p_{\\psi}(\\pi|x)}[\\log p(\\pi)]}\\\\ &{\\qquad\\qquad\\qquad=-h(p_{\\psi}(\\pi|x))-\\log(C-1)!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since the VI loss Eq. (10) also only uses $\\mathbf{\\alpha}\\alpha_{0}=\\mathbb{1}$ in the original paper [13], this implies that the VI loss and the UCE loss are essentially equivalent. ", "page_idx": 17}, {"type": "text", "text": "E Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We prove a stronger result than Theorem 5.1, allowing any observation model for $y$ beyond the categorical case, i.e., $y\\in[C]$ . ", "page_idx": 17}, {"type": "text", "text": "Theorem E.1. For a choice of prior distribution $p(\\pmb\\theta)$ and $\\lambda>0$ , define ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\psi):=\\mathbb{E}_{p(x,y)p_{\\psi}(\\pmb{\\theta}|x)}\\Big[\\log\\frac{1}{p(y|\\pmb{\\theta})}\\Big]+\\lambda\\mathbb{E}_{p(x)}[D(p_{\\psi}(\\pmb{\\theta}|x)\\parallel p(\\pmb{\\theta}))].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $\\nu:=\\lambda^{-1}$ . Define the tempered likelihood ", "page_idx": 17}, {"type": "equation", "text": "$$\np^{(\\nu)}(\\theta|y):=\\frac{p^{(\\nu)}(\\theta,y)}{\\int p^{(\\nu)}(\\theta,y)\\,\\mathrm{d}\\theta},\\ \\ \\ \\,w h e r e\\,p^{(\\nu)}(\\theta,y):=\\frac{p(\\theta)p^{\\nu}(y|\\theta)}{\\iint p(\\theta)p^{\\nu}(y|\\theta)\\,\\mathrm{d}\\theta\\,\\mathrm{d}y}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\psi}{\\operatorname*{min}}\\,\\mathcal{L}(\\psi)=\\underset{\\psi}{\\operatorname*{min}}\\,\\mathbb{E}_{p(x,y)}[D(p_{\\psi}(\\pmb{\\theta}|x)\\parallel p^{(\\nu)}(\\pmb{\\theta}|y))]}\\\\ &{\\quad\\quad\\quad\\quad\\equiv\\underset{\\psi}{\\operatorname*{min}}\\,\\mathbb{E}_{p(x)}[D(p_{\\psi}(\\pmb{\\theta}|x)\\parallel p^{\\star}(\\pmb{\\theta}|x))],}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where ", "page_idx": 18}, {"type": "equation", "text": "$$\np^{\\star}(\\pmb\\theta|x):=\\frac{p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])\\,\\mathrm d\\pmb\\theta}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Note that we can rewrite the objective function as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\psi)=\\lambda\\mathbb{E}_{p(x,y)}\\Big[D\\Big(p_{\\psi}(\\pmb{\\theta}|x)\\;\\Big\\|\\;\\frac{p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})}{\\int p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})\\,\\mathrm{d}\\pmb{\\theta}}\\Big)\\Big]+C}\\\\ &{\\quad\\quad=\\lambda\\mathbb{E}_{p(x)}\\Big[D\\Big(p_{\\psi}(\\pmb{\\theta}|x)\\;\\Big\\|\\;\\frac{\\exp\\Big(\\mathbb{E}_{p(y|x)}\\Big[\\log\\frac{p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})}{\\int p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})\\,\\mathrm{d}\\pmb{\\theta}}\\Big]\\Big)}{\\int\\exp\\Big(\\mathbb{E}_{p(y|x)}\\Big[\\log\\frac{p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})}{\\int p(\\pmb{\\theta})p^{\\nu}(y|\\pmb{\\theta})\\,\\mathrm{d}\\pmb{\\theta}}\\Big]\\Big)\\,\\mathrm{d}\\pmb{\\theta}}\\Big)\\Big]+C^{\\prime}}\\\\ &{\\quad\\quad=\\lambda\\mathbb{E}_{p(x)}\\Big[D\\Big(p_{\\psi}(\\pmb{\\theta}|x)\\;\\Big\\|\\;\\frac{p(\\pmb{\\theta})\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb{\\theta})])}{\\int p(\\pmb{\\theta})\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb{\\theta})])\\,\\mathrm{d}\\pmb{\\theta}}\\Big)\\Big]+C^{\\prime\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, $\\begin{array}{r}{\\nu:=\\frac{1}{\\lambda}}\\end{array}$ and $C,C^{\\prime}$ , and $C^{\\prime\\prime}$ are some constants with respect to $\\psi$ . In particular, ", "page_idx": 18}, {"type": "equation", "text": "$$\nC^{\\prime\\prime}=\\mathbb{E}_{p(x)}\\left[\\log\\frac{1}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y\\vert x)}[\\log p(y\\vert\\pmb\\theta)])\\,\\mathrm{d}\\pmb\\theta}\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This characterizes the optimal $p_{\\psi}(\\pmb\\theta|\\boldsymbol x)$ under this objective function as ", "page_idx": 18}, {"type": "equation", "text": "$$\np_{\\psi^{*}}(\\pmb\\theta|x)=\\frac{p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])\\,\\mathrm{d}\\pmb\\theta},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 18}, {"type": "text", "text": "F An Extension For General Observation Models ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, following the similar exponential family distribution setup, We consider a likelihood model of exponential family distribution over a target variable $y\\in\\mathbb R$ with natural parameters $\\pmb\\theta\\in\\mathbb{R}^{L}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\np(y|\\pmb\\theta):=h(y)\\exp(\\pmb\\theta^{\\sf T}{\\bf u}(y)-A(\\pmb\\theta)).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, $h\\colon\\ensuremath{\\mathbb{R}}\\to\\ensuremath{\\mathbb{R}}$ is the base measure, $A\\colon\\ensuremath{\\mathbb{R}}^{L}\\to\\ensuremath{\\mathbb{R}}$ is the log-partition function, and $\\mathbf{u}\\in\\mathbb{R}\\rightarrow\\mathbb{R}^{L}$ is sufficient statistics. Note that the entropy of the parametric distribution is given as $h(p(y|\\pmb\\theta))=$ $A(\\pmb\\theta)-\\pmb\\theta^{\\intercal}\\nabla_{\\pmb\\theta}A(\\pmb\\theta)-\\mathbb{E}[\\log h(\\boldsymbol y)]$ . ", "page_idx": 18}, {"type": "text", "text": "In EDL methods, a distribution over the parameter $\\pmb{\\theta}$ is assumed to capture uncertainty. A convenient choice is the conjugate prior $p(\\pmb{\\theta}|\\pmb{\\xi},n)$ of the likelihood $p(y|\\pmb\\theta)$ , which is given as ", "page_idx": 18}, {"type": "equation", "text": "$$\np(\\pmb\\theta|\\pmb\\xi,n)=\\eta(\\pmb\\xi,n)\\exp(n(\\pmb\\theta^{\\top}\\pmb\\xi-A(\\pmb\\theta))).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, $\\pmb{\\xi}~\\in~\\mathbb{R}^{L}$ is the prior parameter, $n\\,\\in\\,\\mathbb{R}_{>0}$ is the evidence parameter, and $\\eta(\\pmb{\\xi},n)$ is the normalization constant. ", "page_idx": 18}, {"type": "text", "text": "The benefit of the conjugate distribution is in the easy posterior update. Given $N$ observations $y^{N}$ and prior $p(\\pmb{\\theta}|\\pmb{\\xi}_{o},n_{o})$ , the posterior is $p(\\pmb{\\theta}|\\pmb{\\xi}_{+},n_{+})$ , where ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\xi}_{+}=\\frac{n_{o}\\pmb{\\xi}_{o}+\\sum_{j=1}^{N}\\mathbf{u}\\left(y_{j}\\right)}{n_{o}+N}}\\\\ {n_{+}=n_{o}+N.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now, we assume that there exists neural networks that, for each point $x$ , can approximate the \u201cassociated parameters\u201d $n_{\\psi}(x)$ and $\\xi_{\\psi}(x)$ . We then define the target posterior distribution as ", "page_idx": 18}, {"type": "equation", "text": "$$\np_{\\psi}(\\pmb\\theta|x):=p\\Big(\\pmb\\theta\\Big|\\,\\frac{n_{o}\\pmb\\xi_{o}+n_{\\psi}(x)\\pmb\\xi_{\\psi}(x)}{n_{o}+n_{\\psi}(x)},n_{o}+n_{\\psi}(x)\\Big).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For a choice of prior distribution $p(\\pmb\\theta)$ and $\\lambda>0$ , define the objective function as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\psi):=\\mathbb{E}_{p(x,y)p_{\\psi}(\\pmb{\\theta}|x)}\\Big[\\log\\frac{1}{p(y|\\pmb{\\theta})}\\Big]+\\lambda\\mathbb{E}_{p(x)}[D(p_{\\psi}(\\pmb{\\theta}|x)\\parallel p(\\pmb{\\theta}))].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This is a generalization of the UCE loss proposed by NatPN [20], as will be detailed below. We note that Theorem 5.1 remains to hold for this general observation model. That is, by minimizing the UCE loss, $p_{\\psi}(\\pmb\\theta|\\boldsymbol x)$ is encouraged to fit to a fixed target ", "page_idx": 19}, {"type": "equation", "text": "$$\np^{\\star}(\\pmb\\theta|x)=\\frac{p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])}{\\int p(\\pmb\\theta)\\exp(\\nu\\mathbb{E}_{p(y|x)}[\\log p(y|\\pmb\\theta)])\\,\\mathrm d\\pmb\\theta}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "F.1 Example: Classification ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For classification, we set $\\pmb{\\theta}(=\\pi)\\in\\Delta^{\\mathcal{V}},p(y|\\pmb{\\theta})=\\theta_{y}$ (categorical model), and we have, for $\\mathbf{\\alpha}_{\\alpha_{o}}=\\mathbb{1}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname{tuon},\\,\\mathrm{we}\\,\\mathrm{set}\\,\\sigma(=\\pi\\,)\\in\\triangle^{\\mathrm{e}}\\,,\\,p(y|\\pmb{\\sigma})=\\sigma_{y}\\,\\operatorname{tcavgontcal}\\operatorname{mouct}_{1}\\operatorname{ant}\\operatorname{we}_{1}\\operatorname{anve}}\\\\ &{\\qquad p(\\theta)=\\operatorname{Dir}(\\theta;\\alpha_{o}),}\\\\ &{p_{\\psi}(\\theta|x)=\\operatorname{Dir}(\\theta;\\alpha_{o}+n_{\\psi}(x)\\alpha_{\\psi}(x)),}\\\\ &{\\quad p^{\\star}(\\theta|x)=\\operatorname{Dir}(\\theta;\\alpha_{0}+\\nu\\eta(x))\\propto\\exp\\bigl(\\mathbb{E}_{p(y|x)}\\bigl[\\log\\operatorname{Dir}(\\theta;\\alpha_{o}+\\nu\\mathbf{e}_{y})\\bigr]\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "While the categorical model is typically assumed, a few exceptions exist. Sensoy et al. [41] used $p(y|\\pmb\\theta)=\\mathcal N(\\mathbf{e}_{y};\\pmb\\theta,\\sigma^{2}I)$ . Deng et al. [11] used $p(y|\\pmb{\\theta},\\pmb{\\alpha}_{\\psi}(x))\\stackrel{*}{=}\\mathcal{N}(\\mathbf{e}_{y};\\pmb{\\theta},\\sigma^{2}\\mathcal{Z}(\\pmb{\\alpha}_{\\psi}(x))^{-1})$ , where $\\mathcal{T}(\\alpha)$ denotes the Fisher information matrix of the probability model $\\mathsf{D i r}(\\pmb{\\alpha})$ , i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{Z}(\\alpha):=\\mathbb{E}_{\\theta\\sim\\mathrm{Dir}(\\alpha)}\\Big[\\frac{\\partial\\log\\mathsf{D i r}(\\theta;\\alpha)}{\\partial\\alpha}\\frac{\\partial\\log\\mathsf{D i r}(\\theta;\\alpha)^{\\mathsf{T}}}{\\partial\\alpha}\\Big].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In this modified case, the equivalence in Eq. (14) in Theorem E.1 does not hold. The analysis breaks down since the constant $C^{\\prime\\bar{\\prime}}$ in Eq. (15) now becomes dependent on $\\psi$ , and cannot be ignored in the optimization: ", "page_idx": 19}, {"type": "equation", "text": "$$\nC^{\\prime\\prime}=\\mathbb{E}_{p(x)}\\left[\\log\\frac{1}{\\mathbb{E}_{p(\\theta)}[\\exp(\\nu\\mathbb{E}_{p(y\\mid x)}[\\log p(y\\vert\\theta,\\alpha_{\\psi}(x))])]}\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Our high-level critique on the EDL methods remains to hold, since the FisherEDL still does not take into account any external uncertainty in the model $\\psi$ . Therefore, the FisherEDL would fit the meta distribution to some arbitrary target, which could be however potentially better than the simple scaled-and-shifted target. We also note that in our empirical demonstration in Sec. 7, FisherEDL did not show outstanding performance on the downstream task performance. ", "page_idx": 19}, {"type": "text", "text": "F.2 Example: Regression ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For regression, we can set $\\pmb{\\theta}=(\\mu,\\sigma)\\in\\mathbb{R}\\times\\mathbb{R}_{>0}$ , $p(y|\\pmb{\\theta})=\\mathcal{N}(y;\\pmb{\\mu},\\pmb{\\sigma}^{2})$ . For a prior, normal-inverseGamma (NIG) distribution $\\sqrt{\\Gamma^{-1}}(\\mu,\\sigma;\\mu_{0},\\bar{\\lambda},\\alpha,\\beta)$ is a convenient choice due to its conjugacy to the Gaussian likelihood. Charpentier et al. [20] proposed to use this choice with the UCE loss Eq. (D.3). Malinin et al. [19] considered a multivariate regression with Gaussian likelihood together with the Normal-Wishart distribution, which is a multi-dimensional generalization of the NIG distribution. They used the reverse-KL type objective extending their prior work [8]. In our unified view (Theorem E.1), both objectives are equivalent, and these two approaches would suffer the same issue in its UQ ability. ", "page_idx": 19}, {"type": "text", "text": "While the \u201cDeep Evidential Regression\u201d objective proposed by Amini et al. [18] cannot be subsumed by our work, Meinert et al. [42] recently investigated the effectiveness of the EDL method of Amini et al. [18], and also showed that the objective function characterizes a degenerate distribution as its optimal meta distribution, suggesting that its empirical success is likely due to an optimization artifact. ", "page_idx": 19}, {"type": "text", "text": "G Experiment Setup ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "G.1 Data Processing ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Details about Synthetic Data. We create a mixture of Gaussian distribution with mean $[-2,3]$ , $[0,0]$ , and [2, 3], and variance 0.25. We randomly sample 1000 training data used to train EDL models and use 2000 test data for the generation of visualization plots in Fig. 6 and Fig. 8. ", "page_idx": 19}, {"type": "text", "text": "Data Split of Real Data. For in-distribution datasets CIFAR10 and CIFAR100, we divide the original training data into two subsets: a training set and a validation set, using an $80\\%/20\\%$ split ratio. The testing set of these datasets is utilized as in-distribution samples for evaluation. For OOD datasets, we utilize their testing sets as OOD data. To maintain consistency in sample size, we ensured that each OOD dataset contains exactly 10,000 samples, matching the number of in-distribution test samples. ", "page_idx": 20}, {"type": "text", "text": "Details about OOD Data. For all the OOD datasets, we standardized the dataset images by resizing them to dimensions of 32x32 pixels. Additionally, all gray-scale images were converted to a three-channel format. The following datasets are selected for the OOD detection task: ", "page_idx": 20}, {"type": "text", "text": "\u2022 Fashion-MNIST: Contains article images of clothes. We use the testing set, which contains 10,000 images.   \n\u2022 SVHN: The Street View House Numbers (SVHN) dataset contains images of house numbers sourced from Google Street View. We use 10,000 images from its testing set as OOD samples.   \n\u2022 TinyImageNet (TIM): As a subset of the larger ImageNet dataset, TIM\u2019s validation set, containing 10,000 images, is used as OOD samples.   \n\u2022 Corrupted: This is an artificially created dataset generated by applying perturbations, including Gaussian blurring, pixel permutation, and contrast re-scaling to the original testing images. ", "page_idx": 20}, {"type": "text", "text": "G.2 Model Architecture ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Base Model Architecture. To ensure a fair comparison, we use the same base model architecture for all EDL methods. We describe the base model architecture for different tasks as follows: ", "page_idx": 20}, {"type": "text", "text": "\u2022 Synthetic 2-D Gaussian Data: We utilize a simple Multi-Layer Perceptron (MLP) model. This model comprises three linear layers, each with a hidden dimension of 64, each followed by the ReLU activation function.   \n\u2022 Real Datasets (CIFAR10 and CIFAR100): We adopt the existing model architecture VGG16 [43] and ResNet18 [44] as the base model. ", "page_idx": 20}, {"type": "text", "text": "The base model serves as the feature extractor for the EDL model, which extracts the feature with latent dimension 6 for 2-D Gaussian Data and CIFAR10, and extracts the feature with latent dimension 12 for CIFAR100. ", "page_idx": 20}, {"type": "text", "text": "UQ Model Head. The UQ model of most EDL methods consists of a base model feature extractor and a UQ head. The feature extractor takes the data as input and extracts the latent features. The UQ head then takes the latent feature to parameterize a Dirichlet distribution $\\mathsf{D i r}(\\pi;\\pmb{\\alpha}_{\\psi}(x))$ . As we discussed in Sec. 4, different EDL method mainly differs from the parametric form of $\\alpha_{\\psi}(x)$ , either direct parameterization or density parameterization, which is achieved by using different types of UQ head. We describe the model architecture of these two different UQ heads as follows: ", "page_idx": 20}, {"type": "text", "text": "\u2022 Direct Parameterization: the UQ head of direct parameterization is similar to a typical classification head, which consists of two linear layers with hidden dimension 64 (128 for CIFAR100), equipped with a ReLU activation between the two layers. \u2022 Density Parameterization: density parameterization adopts a density model. PostNet [15] uses a radial flow model with a flow length of 6 to estimate class-wise density, which results in the creation of multiple flow models corresponding to the number of classes in datasets. NatPN [20] uses a single radial flow model with a flow length of 8 to estimate the density of marginal data distribution $p(x)$ . ", "page_idx": 20}, {"type": "text", "text": "G.3 Implementation Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "For all the EDL methods, we use the same base model architecture discussed previously. We elaborate on their common configurations, method-specific configurations, and hyper-parameter as follows. ", "page_idx": 20}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/dadc5717a046a7319d927130844bd0fa7d2194497578b5a1905659e22b1753ae.jpg", "img_caption": ["(b) Aleatoric Uncertainty: 2D Gaussian "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure 5: Behavior of Uncertainties Learned by EDL methods on Toy Data. (a) EDL methods learn spurious epistemic uncertainty, wherein uncertainty does not vanish with an increasing number of observed samples, contrary to the fundamental definition of epistemic uncertainty. (b) Instead of a constant, EDL methods learn model-dependent aleatoric uncertainty that depends on hyper-parameter $\\lambda$ , contrary to the fundamental definition of aleatoric uncertainty. ", "page_idx": 21}, {"type": "text", "text": "Common configurations. The maximum training epochs are set to 50, 100, and 200 for 2-D Gaussian data, CIFAR10 and CIFAR100, respectively. We train models with the early stopping of patience 10. The model is evaluated on the validation set with frequency 2, and the optimal model with the lowest validation loss or highest accuracy is returned. The training batch size is set to 64, 64, and 256 for Gaussian data, CIFAR10 and CIFAR100, respectively. We use Adam optimizer without weight decay or learning rate schedule during model optimization. The learning rates of the optimizer are $1{\\:\\mathrm{e}}{-3\\,,2\\,.5{\\:\\mathrm{e}}{-4\\,,2\\,.5{\\:\\mathrm{e}}{-4\\,}}}$ for Gaussian data, CIFAR10 and CIFAR100, respectively. The default hyper-parameter $\\lambda$ is set to 1e-4 for those EDL methods with regularizer. All reported numbers are averaged over five runs. All experiments are implemented in PyTorch using a Tesla V100 GPU with 32 GB memory. ", "page_idx": 21}, {"type": "text", "text": "Method-specific Configurations. We describe those EDL methods with additional training configurations and hyper-parameters as follows, ", "page_idx": 21}, {"type": "text", "text": "\u2022 RPriorNet [8]: This method requires additional OOD data during training. In alignment with the original paper, CIFAR100 serves as the OOD data for CIFAR10, and TinyImageNet is utilized as the OOD data for CIFAR100. We set the OOD regularizer weight $\\gamma_{\\mathsf{o o d}}=5$ and $\\gamma_{\\mathsf{o o d}}=1$ for CIFAR10 and CIFAR100, respectively. We realize that both the training loss and validation loss can fluctuate significantly due to the confilct between in-distribution and OOD data optimization. In this case, we use validation accuracy as the criterion to save the optimal model, making sure the model is well optimized.   \n\u2022 NatPN [20]: NatPN uses a single density model with flow length 8 and latent feature dimension 16 to parameterize density. The method also requires \u201cwarm-up training\u201d and \u201cfine-tuning\u201d of the density model, where we set warm-up epochs to be 3 and fine-tuning epochs to 100, as the paper\u2019s official implementation suggests.   \n\u2022 Fisher-EDL [11]: This method requires two regularizers, one is the standard r-KL regularizer, the other their proposed \u201cFisher Information\u201d regularizer in the training objective. As the paper suggest, we set the corresponding hyper-parameter $\\lambda_{2}=5\\mathsf{e}\\!-\\!2$ and $\\lambda_{2}=5\\mathsf{e}\\!-\\!3$ for CIFAR10 and CIFAR100, respectively, and set $\\lambda_{1}=1$ for both datasets.   \n\u2022 END2 [16]: To obtain the ensemble samples, we train 100 ensemble models using standard cross entropy loss. In alignment with the original paper, we also use the temperature annealing technique, which is the key technique to ensure the distillation training works smoothly. The temperature will be initialized as a large value and then gradually decay to 1 after certain epochs. We set the initial temperature to 5 for both datasets and set the decay epochs to 30 and 60 for CIFAR10 and CIFAR100, respectively.   \n\u2022 S2D [17]: We train a single model with random dropout and then run inference of the model to obtain 100 samples. We also use the temperature annealing technique with the same configurations as END2 for the distillation training.   \n\u2022 Bootstrap Distillation (Ours): First, we randomly sample 100 subsets of training data from the original training set with an $80\\%/20\\%$ split ratio. Then, for each dataset, we train a bootstrap model using standard cross entropy loss, resulting 100 bootstrap models. For the distillation stage, we also apply the temperature annealing technique with the same configurations as END2. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "H Additional Experiment Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "H.1 Omitted Results in Sec. 5.1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The behavior of both epistemic uncertainty and aleatoric uncertainty learned by EDL methods on 2D Gaussian data is shown in Fig. 5. We observe similar behavior as real data. EDL methods cannot quantify either epistemic or aleatoric uncertainty in a faithful way. ", "page_idx": 22}, {"type": "text", "text": "H.2 Ablation Study in Sec. 5.2 ", "text_level": 1, "page_idx": 22}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/3e3e7989c70979811ac12a9f51e59b275697747f7b00e8f4910d8b144db8d679.jpg", "img_caption": ["Figure 6: Visualization of Epistemic Uncertainty on 2D Gaussian Data. The first row $(a)\\!-\\!(d)$ corresponds to differential entropy quantified by EDL models trained using their original proposed training objective (reverseKL), and the second row (e)- $(h)$ corresponds to epistemic uncertainty quantified by same EDL methods ablated with MSE objective in Eq. (18). This ablation study implies that the specific training objectives has no actual impact on the methods\u2019 ability to quantify uncertainty. Other techniques, such as using density estimation (PostNet $(c,g)$ , NatPN $(d,h))$ ), and using OOD data during training (RPriorNet $(b,f))$ , play a more significant role in EDL methods\u2019 UQ performance. Without auxiliary techniques, BM $(a,e)$ cannot distinguish in-distribution and OOD regions. Similar behavior holds for total uncertainty quantification (see Fig. 8). "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "There could be many other Dirichlet-framework-independent objectives that can capture similar behavior. For instance, we can consider a simple variant of MSE loss as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\psi}\\mathbb{E}_{p(x,y)}[\\|\\log(\\alpha_{\\psi}(x))-\\log(\\alpha_{0}+\\lambda^{-1}\\mathbf{e}_{y})\\|^{2}].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The global minimum of optimizing this heuristic loss function can be characterized by $\\log(\\alpha_{\\psi^{\\star}}(x))=$ $\\mathbb{E}_{p(y|x)}[\\log(\\pmb{\\alpha}_{0}+\\lambda^{-1}\\mathbf{e}_{y})]$ , which implies $\\pmb{\\alpha}_{\\psi}(x)\\approx\\pmb{\\alpha}_{0}+\\lambda^{-1}\\pmb{\\eta}(x)$ under the assumption of a sharp true label distribution $p(y|x)$ . Independent of the training procedure, we can artificially define $-\\log\\mathbb{1}_{\\mathcal{C}}^{\\mathsf{T}}\\pmb{\\alpha}_{\\psi}(x)$ as an epistemic uncertainty metric, while the entropy of normalized model output $H(\\pmb{\\alpha}_{\\psi}(\\breve{x})/\\mathbb{1}_{C}^{\\dagger}\\pmb{\\alpha}_{\\psi}(x))$ can represent total uncertainty. ", "page_idx": 22}, {"type": "text", "text": "We conduct an ablation study by replacing the reverse-KL objective with the MSE objective in Eq. (18) for model training. First, we provide visualization of epistemic uncertainty, aleatoric uncertainty, and total uncertainty on 2D Gaussian data quantified by different EDL methods in Fig. 6, Fig. 7, and Fig. 8, respectively. Next, we extend the ablation study to OOD detection (using epistemic uncertainty) and ambiguous data detection (using aleatoric uncertainty) tasks using real data in Fig. 9 and Fig. 10, respectively. The results indicate that EDL methods exhibit similar behavior by using reverse KL or MSE objectives. ", "page_idx": 22}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/0ede48131db317b6ce39e68880c2909fc5d65ac4b02cd3907ed4c64dce3f1844.jpg", "img_caption": ["Figure 7: Visualization of Aleatoric Uncertainty on 2D Gaussian Data. The first row $(a-d)$ corresponds to the aleatoric uncertainty quantified by EDL models trained using their original proposed training objective (reverse-KL), and the second row $(e-h)$ corresponds to aleatoric uncertainty quantified by the same EDL methods ablated with MSE objective in the equation Eq. (18). Based on these results, We can draw a similar conclusion as Fig. 6: specific training objective has no actual impact on the methods\u2019 ability to quantify aleatoric uncertainty either. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/960cbd251d797bb58d9d7cade45b21b89ff0e2aeb2e11933d68cf9d71fec1d65.jpg", "img_caption": ["Figure 8: Visualization of Total Uncertainty on 2D Gaussian Data. Total uncertainty is measured using entropy. We can draw a similar conclusion as Fig. 6 and Fig. 7. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "H.3 Ablation Study in Sec. 5.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Empirical Finding 1. OOD-Data-Dependent Methods are Sensitive to Model Architectures ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Firstly, we remark on the confilcting empirical findings regarding the Prior Network [7, 8] as reported in current EDL literature. Baseline results of [8] on the OOD detection task, reproduced by [15, 11], deviate a lot from the original paper\u2019s results. Upon closer investigation, we can attribute these conflicting results to nuances in different model architectures, i.e., the use of BatchNorm has a significant impact when incorporating OOD data during training. Specifically, we conduct an ablation study on the model architectures of RPriorNet, using VGG-16 and ResNet as backbone models, and compare their performance with and without BatchNorm layers removed. As illustrated in Figures 11, the OOD detection performance of RPriorNet shows sensitivity to the model architecture, with the removal of BatchNorm layers leading to performance improvement. This observation further reflects the limitations of utilizing OOD data during training, particularly for large-scale models in which BatchNorm is usually employed. ", "page_idx": 23}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/618e37a058a1894173e64e68760f5ae60216a248824e7b0eda0d5d5fe80a2ca4.jpg", "img_caption": ["Figure 9: Comparison of OOD Detection Performance of EDL methods with Original Objective v.s. MSE Objective. The EDL models trained using MSE objective in Eq. (18) demonstrate comparable performance. These results further justify that the specific training objective has no actual impact on the downstream task performance. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/e633b9cf7d88e22f57deb48f901d3b1fed1246f93eacfb976f523eba4d9443a6.jpg", "img_caption": ["Figure 10: Comparison of Ambiguous Data Detection Performance of EDL methods with Original Objective v.s. MSE Objective. We can draw a similar conclusion as Fig. 9. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "Empirical Finding 2. Density Models May Not Perform Well with Moderate Dimensionality ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Charpentier et al. [15, 20] claim that utilizing density parametrization can effectively address the OOD detection task without the need to observe OOD data during training. This seems to be intuitive, since a perfect density estimator should be capable of identifying OOD data, as OOD data are typically from low-density regions. However, density estimation itself may encounter challenges, particularly in high-dimensional spaces. To validate this conjecture, we train PostNet [15] with a latent feature dimension of 2. As illustrated in Fig. 12, we visualize the epistemic uncertainty (measured by differential entropy) in the latent feature space and plot the features of both in-distribution and OOD data. Despite the density model effectively generating higher uncertainty for OOD regions, the OOD data are mapped to the same region as the in-distribution data. This phenomenon, known as model collapse [45], limits the model\u2019s capability to distinguish between in-distribution and OOD data. ", "page_idx": 24}, {"type": "text", "text": "H.4 Bootstrap Distillation Method Faithfully quantify Epistemic Uncertainty ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The comparison of epistemic uncertainty quantified by existing EDL methods and our proposed Bootstrap Distillation method is shown in Fig. 13. Compared to existing EDL methods, our proposed ", "page_idx": 24}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/022566c142b2452456918833c32da4e9b85768c303925c64402727d2fed2097c.jpg", "img_caption": ["Figure 11: OOD Detection Performance of RPriorNet with Different Model Architecture. RPriorNet is trained using CIFAR10 as in-distribution data and CIFAR100 as OOD data. The OOD detection performance (showing four OOD datasets) is sensitive to the choice of model architecture. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/f28ee1eb6dacba0528debe81eb27bbed5e17b28d8835af778e097311624a3d7d.jpg", "img_caption": ["Figure 12: Visualization of Epistemic Uncertainty in PostNet\u2019s 2D Latent Feature Space. PostNet leverages a flow-based density estimation model, which outputs low (high) uncertainty for in-distribution (OOD) regions as expected. However, given that the input data is high-dimensional, PostNet suffers from the feature collapse issue that mapping OOD data to the same region as ID data in the latent space, making them indistinguishable. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Bootstrap Distillation method demonstrates monotonically decreasing and eventually vanishing uncertainty, consistent with the dictionary definition of epistemic uncertainty. ", "page_idx": 25}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/f878ac73bf6974feeeb3bea7f07a1810214384e2662a5946ed912aae4ad77a44.jpg", "img_caption": ["Figure 13: Epistemic Uncertainty and Test Accuracy v.s. Number of Training Data. Compared to other EDL methods, our proposed Bootstrap Distillation method can faithfully quantify epistemic uncertainty, i.e., the uncertainty is monotonically decreasing with increasing number of data. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "H.5 Bootstrap Distillation Method Benefits from More Samples ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "As discussed in Sec. 6, the Bootstrap Distillation method needs the sampling of multiple bootstrap samples, with each requiring the training of a model using randomly sampled datasets. To understand the impact of varying the number of samples 5, 10, 20, 50, 100, we conduct an empirical investigation on the OOD detection performance of Bootstrap Distillation. The results shown in Fig. 14 reveal that Bootstrap Distillation indeed beneftis from a larger number of samples, particularly in more complex OOD detection tasks using CIFAR100 as the in-distribution data. ", "page_idx": 25}, {"type": "image", "img_path": "P6nVDZRZRB/tmp/91893dce3fe9dd5d0c38f0308b4aca8bab59b3671bbd58f4fbc38b1271b8dc03.jpg", "img_caption": ["Figure 14: Bootstrap Distillation\u2019s OOD Detection Performance v.s. Number of Bootstrap Samples. The $x$ -axis represents the number of bootstrap samples, and the y-axis represents the Average AUROC score of OOD detection tasks. Bootstrap Distillation\u2019s UQ performance will improve by obtaining more bootstrap samples, but more computational cost is the price needs to pay. "], "img_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "P6nVDZRZRB/tmp/c73e740eddeea6ebd6041556526bab438395e358ef86f44f7daf595f23776d93.jpg", "table_caption": ["Table 2: OOD detection AUROC score. MI and Dent stand for Mutual Information and Differential Entropy. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "H.6 Detailed Results on UQ Downstream Tasks ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The complete AUROC and AUPR results of OOD data detection are shown in Table 2 and Table 3, respectively. The complete results of selective classification are shown in Table 4. ", "page_idx": 26}, {"type": "table", "img_path": "P6nVDZRZRB/tmp/24ea284a73d2ac5f1720fbd0f5f4574a3e15a4b7125faefb3045071f2337f44f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "P6nVDZRZRB/tmp/d751e900ddd08a63c25a73eef4ed8fa9bc8049d90076900e6ccdaac6611c3cc2.jpg", "table_caption": ["Table 4: Selective classification Test Accuracy, AUROC, and AUPR score. Ent and MaxP stand for Entropy and Max Probability, respectively. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The abstract and introduction clearly state our conclusion and contribution of this paper, which are supported by both theoretical analysis and empirical evidence presented in the subsequent sections. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper mainly aims to discuss the limitations of existing methods. For the new methods proposed in this paper, i.e., Bootstrap Distillation, we also acknowledge its computational limitation in Section 7. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We clearly state the assumptions of our proposed theorems, and the proofs and derivations are included in Appendix. ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide all experiment settings and implementation details in Appendix G, and we further include the code in the supplementary material. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We include the code in the supplementary material. We also include the scripts and instructions to run the code. We also plan to make the code open-source upon acceptance. All the data used in our experiments are those publicly available datasets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide all experiment settings and implementation details in Appendix G. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: All the results are averaged over five random trials, with mean and standard error reported. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 30}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: This is included in Appendix G. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We have carefully reviewed Code of Ethics and our paper conforms with the Code of Ethics. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA]   \nJustification: The high-level goal of this paper is to better improve the reliability of machine   \nlearning models, we do not expect negative societal impacts of our work.   \nGuidelines: \u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper uses publicly available, standard image classification datasets with no risk for misuse. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The datasets used in this paper are all publicly available datasets, and we have properly cited the relevant papers. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]