{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-10-27", "reason": "This paper introduces the vision transformer (ViT), a foundational model used in DisPA's content-aware encoder for efficient image processing and feature extraction."}, {"fullname_first_author": "Ze Liu", "paper_title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "publication_date": "2021-06-01", "reason": "This paper introduces the Swin Transformer architecture, which is adopted by DisPA's distortion-aware encoder for effectively capturing local and global contextual information in mini-patch maps."}, {"fullname_first_author": "Qi Liu", "paper_title": "PQA-Net: Deep No-Reference Point Cloud Quality Assessment via Multi-View Projection", "publication_date": "2021-12-01", "reason": "This paper proposes PQA-Net, a state-of-the-art NR-PCQA model that serves as a baseline for comparison in DisPA's experiments, showcasing the advancements made in DisPA compared to the existing methods."}, {"fullname_first_author": "Mohamed Ishmael Belghazi", "paper_title": "Mutual Information Neural Estimation", "publication_date": "2018-07-01", "reason": "This paper introduces MINE, a method for estimating mutual information, which is the core of DisPA's disentanglement strategy using MI minimization for learning independent representations of point cloud content and distortion."}, {"fullname_first_author": "Ziyu Shan", "paper_title": "GPA-Net: No-reference Point Cloud Quality Assessment with Multi-task Graph Convolutional Network", "publication_date": "2023-01-01", "reason": "This paper proposes GPA-Net, another state-of-the-art NR-PCQA model and the direct predecessor of the current work, illustrating the progression of research leading to DisPA's improved performance."}]}