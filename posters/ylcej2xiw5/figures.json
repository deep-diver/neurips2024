[{"figure_path": "ylceJ2xIw5/figures/figures_8_1.jpg", "caption": "Figure 1: Top left: FWC runtime when changing the original dataset size n. Others: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes m, with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique [33]. See text and Appendix C.2 for more details.", "description": "This figure demonstrates the runtime performance of the Fair Wasserstein Coresets (FWC) algorithm and its fairness-utility trade-off against other methods on real-world datasets. The top-left plot shows the linear runtime scaling of FWC with increasing dataset size.  The other plots display the fairness-utility trade-off for each dataset across various coreset sizes and fairness hyperparameters.  Each point represents the best performing model found for a particular coreset size, indicating the optimal balance between fairness and utility for different algorithms.  The dashed red line shows the Pareto frontier, illustrating the best possible combination of fairness and utility across all methods and coreset sizes, highlighting FWC's competitive performance.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_20_1.jpg", "caption": "Figure 2: Runtime analysis of FWC when varying the size of the coreset m (left) and the dimensionality of the features p (right). We report averages and one standard deviation computed over 10 runs.", "description": "This figure shows the runtime analysis of the Fair Wasserstein Coresets (FWC) algorithm.  The left panel displays the runtime per iteration and the number of iterations as a function of the coreset sample size (m) while keeping the dimensionality of features (p) and the original dataset size (n) constant. The right panel displays the same metrics but this time as a function of the dimension of features (p) while keeping the coreset sample size (m) and the original dataset size (n) constant.  Error bars represent one standard deviation calculated over 10 runs. The figures demonstrate the algorithm's scalability and performance under different parameter settings.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_24_1.jpg", "caption": "Figure 1: Top left: FWC runtime when changing the original dataset size n. Others: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes m, with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique [33]. See text and Appendix C.2 for more details.", "description": "This figure shows the results of experiments on real-world datasets. The top-left subplot displays the runtime of FWC as the size of the original dataset increases.  The remaining subplots illustrate the fairness-utility tradeoff achieved by FWC and other methods for a downstream MLP classifier. Each subplot represents a different dataset and shows the AUC (utility) against demographic disparity (fairness) for various methods and coreset sizes. The Pareto frontier is plotted to highlight the best possible tradeoffs.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_24_2.jpg", "caption": "Figure 1: Top left: FWC runtime when changing the original dataset size n. Others: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes m, with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique [33]. See text and Appendix C.2 for more details.", "description": "This figure displays the runtime of the Fair Wasserstein Coresets (FWC) algorithm as a function of the dataset size and also shows fairness-utility tradeoffs for several real-world datasets. The Pareto frontier highlights the competitive performance of FWC compared to other methods, even when those other methods use pre-processing techniques to improve fairness.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_25_1.jpg", "caption": "Figure 5: Data augmentation fairness-utility tradeoff of downstream MLP classifier for the Drug dataset when the protected attribute D (gender) is either not included (left) or included (right) as feature in the learning process. As in Figure 3, the best model across various data augmentation degrees is reported, with averages and standard deviations obtained over 10 runs. FWC manages to successfully reduce the demographic disparity when gender is not used as a feature, but fail to do so when gender is used, indicating that gender provides strong predictive power for the outcome in question, which would require enforcing fairness either during model training or by post-processing the outputs.", "description": "This figure shows the fairness-utility tradeoff of a downstream MLP classifier for the Drug dataset when using data augmentation with FWC.  The left panel shows results when the protected attribute 'gender' is not used as a predictor variable, while the right panel includes 'gender'.  The results indicate that FWC effectively reduces disparity when gender is excluded but not when included. This suggests gender's strong predictive power on the outcome might require additional fairness techniques beyond FWC.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_28_1.jpg", "caption": "Figure 1: Top left: FWC runtime when changing the original dataset size n. Others: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes m, with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique [33]. See text and Appendix C.2 for more details.", "description": "This figure shows the runtime of the Fair Wasserstein Coresets (FWC) algorithm when varying the dataset size and the fairness-utility tradeoffs obtained by using FWC and other baselines on several real-world datasets. The Pareto frontier is displayed to highlight the best tradeoff between fairness and utility across all methods and coreset sizes.  The results show that FWC consistently achieves a competitive or better fairness-utility tradeoff compared to existing approaches.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/figures/figures_29_1.jpg", "caption": "Figure 1: Top left: FWC runtime when changing the original dataset size n. Others: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes m, with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique [33]. See text and Appendix C.2 for more details.", "description": "This figure shows the runtime of FWC (top left) and the fairness-utility tradeoff on four real-world datasets (others). The runtime analysis demonstrates that FWC's runtime scales linearly with the dataset size. The fairness-utility analysis compares FWC with several other fair clustering methods, showing that FWC consistently achieves a competitive or better tradeoff in downstream models compared to existing approaches, even when fairness pre-processing is used.", "section": "7 Experiments"}]