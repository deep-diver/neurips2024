[{"figure_path": "ylceJ2xIw5/tables/tables_5_1.jpg", "caption": "Table 3: Wasserstein distance of the weighted coresets with respect to the original dataset, with averages and standard deviations obtained over 10 runs. In bold, coresets with the closest distance to the original dataset (i.e., smallest Wasserstein distance) in each coreset size and dataset combination.", "description": "This table presents the Wasserstein distances between the original datasets and the generated coresets for various coreset sizes and fairness parameters (epsilon).  The Wasserstein distance measures how similar the distribution of the coreset is to the original data distribution. Lower values indicate a better representation of the original data.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_9_1.jpg", "caption": "Table 1: Using the same setup as in [76], we use GPT-3.5 Turbo and GPT-4 LLM's for fairness evaluations, with a test set of 200 samples with 0.5 base parity (bp = 0.5). Few Shot - FWC is used to provide sixteen examples with weights to the model as examples. Accuracy and demographic disparity (DP) are based on the resulting predictions from GPT-3.5 and GPT-4 models.", "description": "This table compares the performance of GPT-3.5 Turbo and GPT-4 language models on a fairness prediction task using three different approaches: zero-shot, few-shot with balanced examples, and few-shot with Fair Wasserstein Coresets (FWC).  The metrics evaluated are accuracy and demographic parity (DP).  The FWC approach uses a weighted set of examples to improve fairness, highlighting its ability to mitigate biases in large language models.", "section": "Using FWC to improve fairness for LLM"}, {"figure_path": "ylceJ2xIw5/tables/tables_20_1.jpg", "caption": "Table 2: Average runtimes for FWC in the same settings as Figures 1 (top left), varying the dataset size n while fixing m = 250 and p = 25, compared with the runtimes for the smallest dataset extrapolated (i) linearly, with a factor of 1, (ii) linearly, with a factor of 10 and (iii) quadratically. FWC enjoys a near linear time complexity, increasing with the largest dataset sizes; this phenomenon is shared with other clustering algorithm such as k-means (see text).", "description": "This table shows the runtime of the Fair Wasserstein Coresets (FWC) algorithm for different dataset sizes (n).  It compares the actual runtime to estimations based on linear and quadratic extrapolations from the smallest dataset size. The results suggest that FWC exhibits near-linear time complexity.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_21_1.jpg", "caption": "Table 3: Wasserstein distance of the weighted coresets with respect to the original dataset, with averages and standard deviations obtained over 10 runs. In bold, coresets with the closest distance to the original dataset (i.e., smallest Wasserstein distance) in each coreset size and dataset combination.", "description": "This table presents the Wasserstein distance between the original dataset and the generated coresets for different coreset sizes (m) and fairness violation hyperparameters (\u03b5).  The Wasserstein distance measures the similarity in distribution between the original and coreset data. Smaller distances indicate a better representation of the original data by the coresets. The table shows that FWC consistently achieves the smallest Wasserstein distances for all datasets and coreset sizes, highlighting its effectiveness in generating representative samples.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_22_1.jpg", "caption": "Table 4: Clustering cost of the coresets with respect to the original dataset, with averages and standard deviations obtained over 10 runs. In bold, coresets with the smallest clustering cost (i.e., smallest sum of square distances of original dataset samples from the closest generated coreset sample) in each coreset size and dataset combination.", "description": "This table shows the clustering cost for different coreset methods across four datasets.  The clustering cost is calculated as the sum of squared distances between each point in the original dataset and its nearest point in the generated coreset. Lower values indicate better coreset quality in terms of representing the original data's structure. The table displays average clustering cost and standard deviations, obtained from 10 independent runs, for each method and dataset, across different coreset sizes (5%, 10%, 20%).", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_23_1.jpg", "caption": "Table 3: Wasserstein distance of the weighted coresets with respect to the original dataset, with averages and standard deviations obtained over 10 runs. In bold, coresets with the closest distance to the original dataset (i.e., smallest Wasserstein distance) in each coreset size and dataset combination.", "description": "This table presents the Wasserstein distances between the weighted coresets generated by different methods and the original datasets.  Lower values indicate a better representation of the original data by the coreset. The results are averaged over 10 runs, and the coresets with the smallest Wasserstein distance for each dataset and coreset size are highlighted in bold.  This helps assess how well the different methods create coresets that maintain the original data distribution.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_23_2.jpg", "caption": "Table 3: Wasserstein distance of the weighted coresets with respect to the original dataset, with averages and standard deviations obtained over 10 runs. In bold, coresets with the closest distance to the original dataset (i.e., smallest Wasserstein distance) in each coreset size and dataset combination.", "description": "This table presents the Wasserstein distance between the weighted coresets generated by different methods and the original datasets for four benchmark datasets.  The Wasserstein distance is a metric that measures the dissimilarity between two probability distributions. Lower values indicate a closer resemblance between the coreset and the original data.  The table shows that FWC consistently achieves the lowest Wasserstein distance compared to other methods across different coreset sizes.", "section": "7 Experiments"}, {"figure_path": "ylceJ2xIw5/tables/tables_25_1.jpg", "caption": "Table 5: Demographic disparity (Equation (25)), AUC and fairness-utility tradeoff (Equation (26)) of downstream MLP classifier trained using all fair coresets/clustering methods across the four real datasets. The best method across the 3 different coreset sizes is shown, and the best performing method for each metric in each dataset is bolded. Averages and standard deviations taken over 10 runs. For the Credit dataset, K-means reaches low disparities due to the classifier being trivial, i.e., returning the same prediction regardless of input features.", "description": "This table shows the Demographic disparity, AUC, and fairness-utility tradeoff for different coreset methods on four real-world datasets.  The best performing method for each metric and coreset size is highlighted. Note that the Credit dataset shows artificially low disparity for K-means due to a trivial classifier.", "section": "Real datasets results"}, {"figure_path": "ylceJ2xIw5/tables/tables_27_1.jpg", "caption": "Table 8: Presence on the Pareto frontier for FWC across different fairness violation hyper-parameter values (\u20ac = {0.01, 0.05, 0.1}), for both demographic parity (left) and equalized odds (right) in the downstream learning settings of Section 7. As equalized odds is not an independence notion of fairness as demographic parity, constraints on demographic parity do not guarantee an improvement in equalized odds, resulting in FWC not performing as well for downstream performance-fairness tradeoff when using equalized odds.", "description": "This table shows whether FWC achieves a competitive fairness-utility tradeoff (Pareto frontier) when considering both demographic parity and equalized odds. It highlights that while FWC performs well for demographic parity across all datasets, its performance is not as consistent for equalized odds, indicating that optimizing for one fairness metric does not guarantee optimization for others.", "section": "Implications for other fairness measures"}]