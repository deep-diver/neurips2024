[{"figure_path": "arHJlYiY2J/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative Results on Geometry Consistency. Following SuperGlue [47], we report the area under the cumulative error curve (AUC) of the predicted camera rotation and translation under certain thresholds (5\u00b0, 10\u00b0, 20\u00b0), and the precision (P) and matching score (MS) of the Super-Glue correspondences. We feed the models with prompts from RealEstate10K [68] (RE10K) and WebVid10M [1] (WV10M) in two experiments separately. For RealEstate10K scenes, we also run SuperGlue on the original RealEstate10K [68] frames as reference. Our model achieves the highest scores on all metrics compared to baselines.", "description": "This table presents a quantitative comparison of different video generation models in terms of geometry consistency.  It uses the SuperGlue metric to assess the accuracy of predicted camera rotations and translations, evaluating performance across various error thresholds.  The models are tested on two datasets: RealEstate10K (static scenes) and WebVid10M (dynamic scenes), with SuperGlue scores calculated for the original RealEstate10K frames as a reference.  The results show that the proposed model outperforms existing methods on all metrics.", "section": "5.2 Quantitative Results"}, {"figure_path": "arHJlYiY2J/tables/tables_6_2.jpg", "caption": "Table 2: Quantitative Results for semantic & fidelity metrics. The semantic metrics are evaluated on WebVid10M [1] and the fidelity metrics are performed on RealEstate10k [68]. As shown in the table, our method is better than or on par with all prior work regarding semantic matching with the prompt, cross-video consistency, and frame fidelity.", "description": "This table presents a quantitative comparison of the proposed CVD model against several baselines across various metrics.  The metrics are grouped into two categories: semantic consistency (CLIP-T and CLIP-F) and fidelity (FID, KID, and FVD). CLIP-T measures the similarity between the generated videos and the input text prompts, assessing the semantic consistency of the generated content.  CLIP-F evaluates the semantic consistency between video pairs, ensuring that the same scene is depicted in multiple views. FID, KID, and FVD are image quality metrics assessing the visual fidelity of the generated videos.  The results show that CVD demonstrates comparable or superior performance to the baselines in terms of both semantic consistency and visual fidelity.", "section": "5.2 Quantitative Results"}, {"figure_path": "arHJlYiY2J/tables/tables_8_1.jpg", "caption": "Table 3: Ablation Study conducted on generic scenes (prompts from WebVid10M [1]), where we deactivate each of our introduced modules. Results indicate that our full pipeline outperforms the ablation settings for both geometric and semantic consistencies.", "description": "This table presents the results of an ablation study conducted to evaluate the contribution of different modules in the proposed Collaborative Video Diffusion (CVD) model.  The study focuses on generic scenes using prompts from the WebVid10M dataset. Several variations of the CVD model were tested, each excluding a specific module, to assess their impact on geometric and semantic consistency. The results demonstrate that the full CVD model, incorporating all modules, achieves superior performance compared to the ablation variants, highlighting the importance of each component for optimal results.", "section": "5.3 Ablation Study"}]