[{"figure_path": "1FikBPewU9/figures/figures_2_1.jpg", "caption": "Figure 1: The robustness testing on the depth range. Under identical training configurations, our method exhibits superior robustness to variations in depth range compared with two state-of-the-art methods [13; 14]. The red markings denote the actual depth range used during training.", "description": "This figure demonstrates the robustness of different multi-view stereo (MVS) methods to variations in depth range.  The authors' method, along with DispMVS and IterMVS, were trained under specific depth ranges (indicated in red).  The images show the resulting 3D point cloud reconstructions for each method under varying input depth ranges, highlighting the superior robustness of the authors' method to deviations from the training depth range.", "section": "2 Related Work"}, {"figure_path": "1FikBPewU9/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our method. We introduce the disparity feature encoding module to encode viewpoint quality differences, and the Multi-view Disparity Attention (MDA) module to facilitate information interaction between multi-view images. The MDA module is depicted in Fig. 3. Starting from an initial depth map Do, the epipolar disparity flows are iteratively updated and fused to the depth of the next stage.", "description": "This figure presents a detailed overview of the proposed multi-view stereo (MVS) method. It illustrates the different modules involved in the process, starting from feature extraction and culminating in depth map generation.  The core components include a disparity feature encoding module that handles variations in image quality across views, a multi-view disparity attention (MDA) module for efficient information fusion, and an iterative update mechanism using GRUs. Pose embedding is integrated to leverage geometric relationships between views and camera poses, improving the accuracy of depth estimation. The pipeline involves iterative refinement of epipolar disparity flows, ultimately yielding a robust and reliable depth map.", "section": "3 Method"}, {"figure_path": "1FikBPewU9/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of MDA module. After concatenating features with 3D pose embedding and 2D normalized positional encoding, we achieve intra-image and inter-image information interaction through self-attention and cross-attention. As shown in the right figure, 3D pose embedding encodes relative pose and pixel geometric information into the features to enhance the learning capability of the attention mechanism.", "description": "This figure illustrates the Multi-view Disparity Attention (MDA) module.  The MDA module takes disparity features, 2D positional encoding, and 3D pose embeddings as input. These inputs are concatenated and fed into a self-attention mechanism followed by a cross-attention mechanism.  The self-attention mechanism captures intra-image relationships, while the cross-attention mechanism captures inter-image relationships. The 3D pose embedding encodes both relative camera poses and geometric relationships between pixels across multiple images to aid feature fusion and improve accuracy. The output is an enhanced disparity feature that is passed to subsequent stages of the network.", "section": "3.4 Multi-view Stereo Transformer"}, {"figure_path": "1FikBPewU9/figures/figures_7_1.jpg", "caption": "Figure 1: The robustness testing on the depth range. Under identical training configurations, our method exhibits superior robustness to variations in depth range compared with two state-of-the-art methods [13; 14]. The red markings denote the actual depth range used during training.", "description": "This figure demonstrates the robustness of the proposed method to variations in depth range.  It compares the performance of the proposed method against two other state-of-the-art methods (IterMVS and DispMVS) across different depth ranges. The results show that the proposed method is significantly less sensitive to errors in the depth range than the compared methods. This superior robustness is highlighted by the visual results and is a key advantage of the depth-range-free approach.", "section": "2 Related Work"}]