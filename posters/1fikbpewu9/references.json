{"references": [{"fullname_first_author": "Yao Yao", "paper_title": "Mvsnet: Depth inference for unstructured multi-view stereo", "publication_date": "2018-09-01", "reason": "This paper introduces MVSNet, a pioneering CNN-based approach that significantly advanced multi-view stereo depth estimation."}, {"fullname_first_author": "Fangjinhua Wang", "paper_title": "IterMVS: Iterative probability estimation for efficient multi-view stereo", "publication_date": "2022-06-01", "reason": "This work proposes IterMVS, an efficient method improving multi-view stereo through iterative probability estimation, addressing limitations of previous approaches."}, {"fullname_first_author": "Qingsong Yan", "paper_title": "Rethinking disparity: a depth range free multi-view stereo based on disparity", "publication_date": "2023-01-01", "reason": "DispMVS is a key scale-agnostic approach that is directly relevant to the current paper's goal of depth-range-free MVS, mitigating the influence of depth priors."}, {"fullname_first_author": "Xiaoyu Shi", "paper_title": "Videoflow: Exploiting temporal cues for multi-frame optical flow estimation", "publication_date": "2023-03-01", "reason": "This method is highly relevant due to its inspiration for using attention modules for multi-frame information interaction, adapting concepts from optical flow to MVS."}, {"fullname_first_author": "Yikang Ding", "paper_title": "TransMVSNet: Global context-aware multi-view stereo network with transformers", "publication_date": "2022-06-01", "reason": "This paper is highly influential as it introduced transformers to MVS, enabling the capture of global context information within and between input images for improved depth map generation."}]}