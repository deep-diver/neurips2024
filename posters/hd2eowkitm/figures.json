[{"figure_path": "Hd2EOwKItm/figures/figures_1_1.jpg", "caption": "Figure 1: (left) CLIP uses two separate Transformer encoders to extract vector representations from image-text pairs. The text encoder operates on a subword-level tokenizer. (right) The proposed bag of subwords classification both only use the single Transformer encoder.", "description": "This figure compares the architectures of CLIP and SuperClass.  CLIP uses two separate transformer encoders: one for images and one for text (processed at a subword level). SuperClass, in contrast, uses a single transformer encoder and directly uses tokenized raw text as classification labels, eliminating the need for a separate text encoder.", "section": "1 Introduction"}, {"figure_path": "Hd2EOwKItm/figures/figures_6_1.jpg", "caption": "Figure 2: Zero-shot classification accuracy and linear probing accuracy on ImageNet-1k dataset (left two columns); Performance of VQAv2 and T-VQA with LLaVA training recipe (right two columns). Top row: We compare the performance of vision backbones\u2014ViT-S/16, B/16, and L/16\u2014pretrained via classification and contrastive methods with the same batch size of 16k and 512 million seen samples, focusing on their size and computational cost. SuperClass demonstrates better scaling on zero-shot classification and VQAv2, T-VQA tasks. Bottom row: Comparing SuperClass and CLIP, performance increases with more training examples, mirroring the effects of model scaling. All methods are trained the same batch size of 16k and ViT-L/16 as backbone.", "description": "This figure compares the performance of SuperClass and CLIP models on various downstream tasks (ImageNet zero-shot classification, ImageNet linear probing, VQAv2, and T-VQA).  The top row shows how performance scales with model size (ViT-S/16, B/16, L/16) for both methods, using a consistent batch size of 16k and 512 million seen samples. The bottom row illustrates how performance changes with the number of training examples seen, demonstrating the scaling behavior of both approaches.  SuperClass generally shows improved scaling and performance across the board.", "section": "4.3 Main results"}]