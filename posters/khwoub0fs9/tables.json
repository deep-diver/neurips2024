[{"figure_path": "KhwOuB0fs9/tables/tables_1_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various LLMs (Large Language Models) on the EffiBench benchmark, both before and after optimization using the proposed EFFI-LEARNER framework.  The metrics used to evaluate efficiency include Execution Time (ET), Normalized Execution Time (NET), Max Memory Usage (MU), Normalized Max Memory Usage (NMU), Total Memory Usage (TMU), and Normalized Total Memory Usage (NTMU). The percentage values in parentheses represent the reduction in each metric achieved after optimization by EFFI-LEARNER.  The table highlights the top-performing LLMs after optimization.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_5_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) using the EFFI-LEARNER framework on the EffiBench benchmark.  For each LLM, it shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) before and after optimization by EFFI-LEARNER. The percentage reduction achieved by EFFI-LEARNER for each metric is indicated in parentheses. The table also highlights the top-performing LLMs after optimization.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_6_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) using the EFFI-LEARNER framework on the EffiBench benchmark.  It shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM both before and after optimization with EFFI-LEARNER.  The percentage reduction in each metric after optimization is shown in parentheses.  Top-performing LLMs in terms of efficiency gains are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_7_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) using the EFFI-LEARNER framework on the EffiBench benchmark.  It shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM before and after optimization with EFFI-LEARNER. The percentage reduction in each metric is shown in parentheses. The top-performing LLMs in terms of efficiency gains are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_8_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the code efficiency results of various LLMs (both open-source and closed-source) evaluated on the EffiBench benchmark, before and after applying the EFFI-LEARNER optimization framework.  It shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU).  The percentages in parentheses indicate the percentage reduction in each metric achieved by EFFI-LEARNER.  Top-performing LLMs, in terms of efficiency improvements after optimization, are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_8_2.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the code efficiency results of various LLMs (large language models) evaluated using the EffiBench benchmark, both before and after applying the EFFI-LEARNER optimization framework.  The table shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM.  The percentages in parentheses indicate the percentage reduction in each metric achieved by EFFI-LEARNER.  Top-performing LLMs after optimization are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_8_3.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) before and after applying the EFFI-LEARNER optimization framework.  It uses the EffiBench benchmark, showing the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM.  The percentages in parentheses indicate the performance improvement achieved by EFFI-LEARNER.  Top-performing LLMs in terms of efficiency gains are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_18_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) using the EffiBench benchmark, both before and after applying the EFFI-LEARNER optimization framework.  The table shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM.  The percentage reduction in each metric after EFFI-LEARNER optimization is shown in parentheses. The LLMs with the highest performance improvements are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_18_2.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of the EFFI-LEARNER's effectiveness on EffiBench benchmark. It shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for various LLMs both before and after applying EFFI-LEARNER.  The percentage reduction in each metric after optimization is shown in parentheses, highlighting the improvements achieved by EFFI-LEARNER. Top-performing LLMs are visually highlighted in the table.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_19_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the efficiency of various Large Language Models (LLMs) in generating code, specifically focusing on the EffiBench benchmark. The table compares the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for LLMs both before and after optimization using the proposed EFFI-LEARNER framework.  The percentage reduction achieved by EFFI-LEARNER is shown in brackets, highlighting the efficiency improvements obtained.  Top-performing LLMs after optimization are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_23_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) before and after applying the EFFI-LEARNER optimization framework on the EffiBench benchmark.  The metrics used include execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU). For each LLM, the table shows the initial values of these metrics and the improved values after optimization, with the percentage reduction indicated in parentheses. Highlighted LLMs represent the top performers after the optimization process.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_23_2.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the efficiency of various Large Language Models (LLMs) when used with the EFFI-LEARNER framework on the EffiBench benchmark.  It compares the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) of LLMs both before and after applying EFFI-LEARNER.  The percentage reduction in each metric after optimization is shown in parentheses.  Top-performing models are highlighted to show which LLMs experienced the greatest efficiency gains.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_24_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the efficiency of various LLMs (large language models) for code generation using the EffiBench benchmark, both before and after applying the EFFI-LEARNER self-optimization framework.  The metrics used to measure efficiency include Execution Time (ET), Normalized Execution Time (NET), Max Memory Usage (MU), Normalized Max Memory Usage (NMU), Total Memory Usage (TMU), and Normalized Total Memory Usage (NTMU).  The table shows the improvement achieved by EFFI-LEARNER in each metric for a variety of LLMs (both open-source and closed-source), with the percentage improvement in parentheses, highlighting the most efficient models.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_28_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the code efficiency results obtained using EFFI-LEARNER on the EffiBench benchmark.  It compares the performance of various LLMs (both open-source and closed-source) before and after applying EFFI-LEARNER. The metrics used include execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU). The percentage improvement in each metric achieved by EFFI-LEARNER is shown in parentheses.  The table highlights the LLMs that showed the most significant efficiency improvements after optimization.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_30_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various LLMs (large language models) on the EffiBench benchmark, both before and after applying the EFFI-LEARNER optimization framework.  The table shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU) for each LLM.  The percentage improvement achieved by EFFI-LEARNER is shown in parentheses for each metric. The LLMs with the best performance after optimization are highlighted.", "section": "4.3 Main Results"}, {"figure_path": "KhwOuB0fs9/tables/tables_31_1.jpg", "caption": "Table 1: Code efficiency of LLMs with EFFI-LEARNER on EffiBench. The percentage in the brackets indicates the extent of the reduction for each respective item. Top performing LLMs are highlighted.", "description": "This table presents the results of evaluating the code efficiency of various Large Language Models (LLMs) on the EffiBench benchmark, both before and after applying the EFFI-LEARNER optimization technique.  For each LLM, it shows the execution time (ET), normalized execution time (NET), maximum memory usage (MU), normalized maximum memory usage (NMU), total memory usage (TMU), and normalized total memory usage (NTMU).  The percentage reduction in each metric after optimization is indicated in parentheses.  Top-performing LLMs are highlighted to emphasize the effectiveness of EFFI-LEARNER.", "section": "4.3 Main Results"}]