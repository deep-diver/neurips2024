[{"figure_path": "UGUkPYSdg4/figures/figures_1_1.jpg", "caption": "Figure 1: A comparison unveils distinctions between conventional data expansion methods and our innovative distribution-aware diffusion framework, benefiting from hierarchical clustering and multi-step energy guidance.", "description": "This figure compares conventional data expansion methods with the proposed DistDiff method. Conventional methods either directly optimize or filter the final generated data points (zT) in the diffusion process, while ignoring intermediate denoising steps (zt). In contrast, DistDiff introduces an innovative distribution-aware diffusion framework that incorporates hierarchical clustering to approximate the real data distribution and utilizes multi-step energy guidance to refine intermediate predicted data points (zt), improving the quality and consistency of generated samples.", "section": "1 Introduction"}, {"figure_path": "UGUkPYSdg4/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of the DistDiff pipeline. DistDiff enhances the generation process in diffusion models with distribution-aware optimization. It approximates the real data distribution using hierarchical prototypes pc and pg, optimizing the sampling process through distribution-aware energy guidance. Subsequently, original generated data point z\u0142 is refined for improved alignment with the real distribution.", "description": "This figure shows the pipeline of DistDiff, a data expansion framework.  It uses hierarchical prototypes (pc and pg) to approximate the data distribution.  These prototypes guide the sampling process within a diffusion model via distribution-aware energy. The generated sample (z') is refined to better match the real distribution.", "section": "3 Method"}, {"figure_path": "UGUkPYSdg4/figures/figures_5_1.jpg", "caption": "Figure 3: Our method outperforms state-of-the-art data expansion methods when trained on expanded datasets, underscoring the importance of a high-quality generator in training a classifier.", "description": "This figure compares the classification accuracy of different data expansion methods on the Caltech-101 and CIFAR100-Subset datasets.  The \"Original\" bars represent the accuracy of models trained only on the original datasets.  The other bars show the improvement in accuracy gained by augmenting the original data with synthetic samples generated using various methods: Stable Diffusion (SD), LECF, GIF-SD, and the authors' proposed DistDiff method.  DistDiff consistently outperforms the other methods, highlighting its ability to generate high-quality, distribution-consistent samples that significantly improve downstream model performance.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/figures/figures_6_1.jpg", "caption": "Figure 4: Performance comparison across different scale data sizes. Our method demonstrates significant improvements in classification model performance in both low-data and large-scale data scenarios, outperforming the transformation method AutoAug and the synthesized method Stable Diffusion 1.4.", "description": "This figure compares the performance of DistDiff against AutoAug and Stable Diffusion 1.4 across various dataset sizes for image classification. The results demonstrate that DistDiff consistently outperforms these other methods across all dataset scales, indicating its effectiveness in improving data augmentation efficiency in various data regimes.", "section": "4 Experiments"}, {"figure_path": "UGUkPYSdg4/figures/figures_7_1.jpg", "caption": "Figure 5: The visualization of synthetic samples generated by our method, showcasing high fidelity, diversity, and alignment with the original data distribution.", "description": "This figure shows a comparison between original images from various categories (helicopter, rooster, seahorse, gramophone, pizza, rhinoceros) and their corresponding synthetic counterparts generated using the proposed DistDiff method. The synthetic images exhibit high fidelity, meaning they closely resemble their real counterparts, and high diversity, showing variations in pose, angle, background, and lighting.  The alignment with the original data distribution implies that the generated images maintain the statistical properties of the real data, reducing distribution shift. This demonstrates that the DistDiff method effectively generates high-quality and distribution-consistent synthetic data.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/figures/figures_8_1.jpg", "caption": "Figure 6: The visualization of group-level prototypes alongside original sample features. Here \u2022 is the sample point and \u2606 is group-level prototype. By selecting an appropriate number K, these prototypes effectively span the feature space, providing an approximation of the real data distribution.", "description": "This figure shows how hierarchical prototypes approximate the real data distribution.  It illustrates the effect of varying the number of group-level prototypes (K) on the representation of the data distribution. For each value of K, the figure shows the original data points as light blue circles and the group prototypes as orange stars.  As K increases, the prototypes better capture the structure and spread of the data, providing a more accurate representation of the underlying distribution.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/figures/figures_19_1.jpg", "caption": "Figure 7: Comparison with FID and accuracy across varying noise strengths.", "description": "This figure shows the trade-off between fidelity and diversity in the data expansion task.  The x-axis represents the FID score (Fr\u00e9chet Inception Distance), a metric that measures the similarity between the generated and real data distributions. A lower FID score indicates higher fidelity. The y-axis shows the accuracy of a classifier trained on the expanded dataset.  The plot shows two lines, one for Caltech-101 and one for PathMNIST datasets.  As the noise strength increases, diversity increases (lower FID score), but accuracy may decrease, indicating that an optimal noise level is needed to balance fidelity and diversity for effective model training. For PathMNIST, a higher noise strength leads to a significant drop in accuracy. For Caltech-101, this drop is less drastic.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/figures/figures_19_2.jpg", "caption": "Figure 8: Comparison of visualizations between original Stable Diffusion 1.4 and our DistDiff.", "description": "This figure provides a visual comparison of images generated using Stable Diffusion 1.4 and the proposed DistDiff method.  It shows that DistDiff produces images that are visually similar to those of Stable Diffusion 1.4, but with subtle differences in details and style variations. These differences demonstrate DistDiff's ability to generate high-fidelity images while also exhibiting the diversity that is needed for good data augmentation.", "section": "More Visualization Results"}, {"figure_path": "UGUkPYSdg4/figures/figures_20_1.jpg", "caption": "Figure 9: Visualization of synthetic images produced by our method.", "description": "This figure shows a grid of images generated by the DistDiff method for six different datasets: Caltech-101, CIFAR100-Subset, StanfordCars, DTD, ImageNette, and PathMNIST. Each dataset is represented by a 6x6 grid of images, showing the diversity and quality of the generated images. The figure visually demonstrates the effectiveness of the DistDiff method in producing high-quality synthetic images that closely resemble the distribution of the original datasets.", "section": "More Visualization Results"}]