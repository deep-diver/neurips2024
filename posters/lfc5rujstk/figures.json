[{"figure_path": "LfC5rujSTk/figures/figures_1_1.jpg", "caption": "Figure 1: Example DS program with constraints", "description": "This figure shows a typical data science (DS) program built using the PyTorch library.  It highlights the constraints that must be satisfied for the program to be valid.  These constraints involve relationships between the input data properties (like its dimensions) and the parameters of the PyTorch Conv2d API (such as kernel size and padding).  The example illustrates that satisfying these constraints is crucial for the correct execution of the DS program. The constraints are shown in a box on the right, illustrating how the numerical values must meet specific conditions.", "section": "1 Introduction"}, {"figure_path": "LfC5rujSTk/figures/figures_2_1.jpg", "caption": "Figure 2: Example problem input and LLM output for each evaluation setting", "description": "This figure shows three different settings used to evaluate the performance of LLMs in handling numeric constraints in data science APIs.  The settings vary in the level of detail provided to the LLM and the complexity of the task: 1) **Full program:** The LLM is asked to generate a complete DS program, including importing the necessary libraries and creating an input tensor. 2) **All parameters:** The LLM is provided with the input data and is only asked to generate the API parameters. 3) **Individual parameter:** The LLM is given the input data and all but one parameter and asked to predict only the missing parameter value. This figure also presents example problem inputs, expected outputs and the actual LLMs' outputs for each of the three settings. ", "section": "2.2 Evaluation settings"}, {"figure_path": "LfC5rujSTk/figures/figures_3_1.jpg", "caption": "Figure 3: Example usage of constraint solvers to generate inputs and validate outputs.", "description": "The figure shows how the authors use SMT solvers (Z3 and CVC5) to generate valid inputs and validate the outputs of LLMs.  Panel (a) illustrates input generation: SMT solvers check if a set of constraints (encoded as a formula) is satisfiable given concrete input values and symbolic variables representing the parameters that the LLM needs to predict. If satisfiable, the input is valid for the LLM. Panel (b) illustrates output validation: SMT solvers verify if the concrete values predicted by the LLM satisfy the constraints given the concrete input values. This process ensures that the input and output data used for evaluating the LLMs' performance are valid and properly constrained.", "section": "2.3 Input creation and output validation"}, {"figure_path": "LfC5rujSTk/figures/figures_5_1.jpg", "caption": "Figure 4: Full program prediction result on all 28 APIs (PyTorch and NumPy).", "description": "This figure shows the results of the full program prediction experiment on 28 APIs from PyTorch and NumPy libraries.  The x-axis represents the temperature used during LLM sampling, and the y-axis shows both the accuracy of the generated programs (left panel) and the unique valid rate (right panel).  Each line in the graph represents a different API.  The results illustrate that LLMs achieve near-perfect accuracy with low temperatures but that performance decreases as temperature increases. The unique valid rate also increases with higher temperature, indicating that higher temperatures lead to more diverse outputs, but that still a significant number of programs are repetitive.", "section": "4.1 Full program prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_5_2.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure displays the results of the full API parameter prediction experiment. The experiment tested the ability of a large language model (LLM) to predict all the parameters for 28 APIs (18 from PyTorch and 10 from NumPy) given input data.  The difficulty of the task was varied by adjusting the rank (number of dimensions) and dimension values of the input data. The figure shows the accuracy of the LLM across different difficulty levels.  The observation that some APIs show near-perfect accuracy highlights the LLM's ability to perform well on common or simpler API calls and that the difficulty increases with more complex inputs.", "section": "Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_6_1.jpg", "caption": "Figure 6: Single API parameter result. Solid lines (except Fig. 6c) show the accuracy of using greedy decoding (temp=0). In Fig. 6b, dashed lines show the pass@1 accuracy in sampling experiments with temp=1. In Fig. 6d, dotted lines show the accuracy after excluding trivial solutions. In Fig. 6h and 6i, we use *-Inst. to distinguish between the generation settings: infilling (GPT4-Turbo) and free-form generation (GPT4-Turbo-Inst.). More details are provided in Appendix H and I.", "description": "This figure displays the results of experiments focusing on a single API parameter prediction.  It presents accuracy metrics for various LLMs across different difficulty levels and constraint types (equality, inequality, arithmetic, set-related).  The use of different line styles and the references to the appendices highlight the nuanced methods and additional results detailed elsewhere in the paper.", "section": "4.3 Single API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_17_1.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure shows the accuracy of LLMs in predicting all the parameters of 28 APIs (18 from PyTorch and 10 from NumPy) when given the input data. The difficulty is varied by changing either the rank or the dimension of the input data.  The results show that while LLMs perform well on simple APIs, their accuracy drops significantly as the difficulty increases.  Some APIs consistently maintain high accuracy regardless of difficulty, which are grouped together in the legend.", "section": "4.2 Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_18_1.jpg", "caption": "Figure 8: Example of GPT-4-Turbo's incorrect response. In this example, instead of operating on the original input tensor x and set in_feature to its last input dimension (10), GPT-4-Turbo multiplies all the dimensions together and performs a flattening operation (x.view(1, -1)) before invoking Linear. This violates the instruction to the model, which prohibits modifying the API invocation code. As such, this model response is evaluated as incorrect.", "description": "This figure shows an example of GPT-4-Turbo's incorrect response in a code generation task.  Instead of correctly using the input tensor's last dimension as the `in_features` parameter for a `torch.nn.Linear` layer, GPT-4-Turbo incorrectly flattens the input tensor before applying the linear layer.  This demonstrates a failure to correctly understand and apply the API's constraints, highlighting a limitation of the model's ability to reason about numerical constraints in code generation.", "section": "4.3 Single API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_19_1.jpg", "caption": "Figure 9: Single API parameter result (cont).", "description": "The figure shows the accuracy of different LLMs across various difficulty levels for four different APIs: PyTorch Reshape, PyTorch MaxPool2d, NumPy squeeze, and NumPy split.  Each subfigure shows how accuracy changes as the difficulty (input dimension or rank) increases.  The results highlight the challenges LLMs face in handling diverse numerical constraints within single API parameters.", "section": "4.3 Single API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_20_1.jpg", "caption": "Figure 7: Result on torch.nn.Linear using 8 different LLMs. We further evaluate this phenomenon across different LLMs. Figure 7b shows the results for both the full API parameter and single API parameter setting for torch.nn.Linear as we increase the difficulty (rank of the input data) across 8 LLMs. Similar to DeepSeek Coder-33b, the performance of other LLMs also drops significantly when rank reaches 4. Afterwards, the performance stabilizes for higher difficulties (i.e., rank > 4) especially for open-source LLMs. This is true for both the full API parameter and single API parameter setting.", "description": "This figure shows the results of using 8 different LLMs on the torch.nn.Linear API in two different settings: full API parameter and single API parameter. The x-axis represents the difficulty (rank of the input tensor). The y-axis represents the accuracy of the models. The figure demonstrates that the performance of all models drop when the rank reaches 4, and then stabilizes for higher ranks, especially for open-source LLMs. The result shows the difference between the performance of different LLMs in handling different difficulty levels.", "section": "4.3 Single API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_21_1.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure shows the accuracy of the DeepSeek Coder-33b model in predicting the full API parameters for 28 different APIs from PyTorch and NumPy libraries.  The difficulty of prediction is systematically varied by adjusting the rank (number of dimensions) and dimension values (size along each dimension) of the input data.  The graph displays how accuracy changes across different difficulty levels. The figure highlights that while some APIs show near-perfect accuracy, others demonstrate a significant drop in performance as the difficulty increases.", "section": "4.2 Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_22_1.jpg", "caption": "Figure 4: Full program prediction result on all 28 APIs (PyTorch and NumPy).", "description": "This figure shows the accuracy and unique valid rate for 28 APIs (18 from PyTorch and 10 from NumPy) when LLMs generate complete DS programs from scratch with varying temperature. The results demonstrate that LLMs achieve near-perfect accuracy at low temperatures but the performance decreases as the temperature increases.  The unique valid rate is also plotted, showing that LLMs tend to memorize common patterns instead of genuinely understanding the underlying constraints. This indicates that the ability of LLMs to generate programs that satisfy complex constraints is limited.", "section": "4.1 Full program prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_23_1.jpg", "caption": "Figure 13: Instruction model results. Figure 13a shows the result where we do not add the additional non-trivial requirement in the prompt (\"Don't set groups=1\"), and we also count groups=1 answers as correct. Figure 13b shows the result on the same setting and model samples as Figure 13a but we count groups=1 answers as incorrect. Figure 13c shows the result where we add the additional non-trivial requirement in the prompt (\"Don't set groups=1\"), but we still count groups=1 answers as correct.", "description": "This figure displays the results of experiments using instruction-tuned LLMs on three different settings for the Conv2d API. The first setting (a) includes all answers, while the second (b) excludes groups=1 as correct. The third (c) is similar to (b) but with an additional instruction in the prompt. It demonstrates how the additional instruction affects the performance and the impact of excluding groups=1.", "section": "Single API parameter results for instruction model with CoT prompting"}, {"figure_path": "LfC5rujSTk/figures/figures_24_1.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure presents the results of the full API parameter prediction experiment on 28 APIs from PyTorch and NumPy.  The x-axis shows the difficulty level, increasing from left to right. The y-axis represents the accuracy of the LLM in predicting the correct API parameters given input data with varying levels of complexity.  Some APIs showed nearly perfect accuracy regardless of difficulty, while many others showed a significant decrease in accuracy as the difficulty increased. The 'others(x)' group indicates APIs that performed well across all difficulty levels.", "section": "4.2 Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_25_1.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure displays the results of the full API parameter prediction experiment on 28 APIs from PyTorch and NumPy.  The x-axis shows the difficulty level, which was varied by changing either the rank or dimension values of the input data. The y-axis represents the accuracy achieved by the LLM in predicting the correct API parameters. The figure reveals near-perfect accuracy on several APIs (grouped as \"others(x)\"), suggesting that these APIs might have simpler or more commonly observed constraint patterns.  However, for other APIs, accuracy noticeably decreases as the difficulty increases, demonstrating the challenge of handling complex constraints for LLMs.", "section": "Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_25_2.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "The figure shows the accuracy of the DeepSeek Coder-33b model in predicting all API parameters given different input data for 28 APIs from PyTorch and NumPy libraries.  The difficulty of the task is varied by changing the rank or the dimension values of the input data. The results show that the model performs well on simple APIs but struggles with more complex or uncommon inputs.", "section": "4.2 Full API parameter prediction"}, {"figure_path": "LfC5rujSTk/figures/figures_26_1.jpg", "caption": "Figure 5: Full API parameter prediction result on all 28 APIs (PyTorch and NumPy). The LLM has near 100% accuracy on some APIs, which are collectively referred to as others(x), where x is the number of grouped APIs.", "description": "This figure shows the results of evaluating LLMs on predicting the parameters of 28 APIs from PyTorch and NumPy when the input data is provided. The difficulty of the task is varied by changing the rank or dimension values of the input data. The LLM achieves near-perfect accuracy on some easier APIs, while the accuracy drops significantly on more complex APIs as the difficulty increases.", "section": "4.2 Full API parameter prediction"}]