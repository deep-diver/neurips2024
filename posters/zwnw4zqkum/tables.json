[{"figure_path": "zWnW4zqkuM/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative evaluation of different methods on ART500K, Amazon, and Goodreads datasets. The CLIP score denotes the image-image score. INSTRUCTG2I significantly outperforms the best baseline with p-value < 0.05 and consistently outperforms all the other common baselines in image synthesis, supporting the benefits of graph conditioning.", "description": "This table presents a quantitative comparison of various image synthesis methods on three different datasets: ART500K, Amazon, and Goodreads.  The methods compared include Stable Diffusion (with and without fine-tuning), InstructPix2Pix, ControlNet, and the proposed INSTRUCTG2I model.  The evaluation metrics used are CLIP score and DINOV2 score, which measure the similarity between generated images and ground truth images.  The results demonstrate that INSTRUCTG2I significantly outperforms the baselines, highlighting the effectiveness of incorporating graph conditioning into the image generation process.", "section": "4.2 Main results"}, {"figure_path": "zWnW4zqkuM/tables/tables_7_1.jpg", "caption": "Table 2: Ablation study on graph condition variants and Graph-QFormer.", "description": "This table presents the results of an ablation study comparing different variants of graph conditions and the Graph-QFormer architecture in the INSTRUCTG2I model.  It shows the performance of INSTRUCTG2I with the full model, and then compares this against versions where the Graph-QFormer is removed or replaced with other graph encoding methods (GraphSAGE and GAT). Additionally, it shows how using only neighbor images or neighbor texts as conditions impacts the performance.", "section": "4.3 Ablation Study"}, {"figure_path": "zWnW4zqkuM/tables/tables_14_1.jpg", "caption": "Table 3: Dataset Statistics", "description": "This table presents the number of nodes and edges in each of the three datasets used in the INSTRUCTG2I experiments: ART500K, Amazon, and Goodreads.  It provides a summary of the size and complexity of the graph structures used in evaluating the model.", "section": "4.1 Experimental Setups"}, {"figure_path": "zWnW4zqkuM/tables/tables_14_2.jpg", "caption": "Table 4: Hyper-parameter configuration for model training.", "description": "This table presents the hyperparameters used during the training process of the INSTRUCTG2I model and baseline models.  It includes details like the optimizer used (AdamW), its specific settings (epsilon, beta1, beta2), weight decay, batch size per GPU, gradient accumulation steps, number of epochs, image resolution, learning rate, and the backbone stable diffusion model version (Stable Diffusion 1.5). These hyperparameters were fine-tuned separately for the three datasets used in the experiments (ART500K, Amazon, Goodreads).", "section": "4.1 Experimental Setups"}]