{"references": [{"fullname_first_author": "Andy Zeng", "paper_title": "Multi-view self-supervised deep learning for 6d pose estimation in the amazon picking challenge", "publication_date": "2017-00-00", "reason": "This paper is foundational for multi-view self-supervised deep learning and 6D pose estimation, which is directly relevant to the current paper's goal of improving robot manipulation."}, {"fullname_first_author": "Alexander Khazatsky", "paper_title": "Scalable deep reinforcement learning for vision-based robotic manipulation", "publication_date": "2018-00-00", "reason": "This paper presents a significant advancement in vision-based robotic manipulation, using scalable deep reinforcement learning, a key area that the current paper aims to improve."}, {"fullname_first_author": "Octo Model Team", "paper_title": "Octo: An open-source generalist robot policy", "publication_date": "2023-00-00", "reason": "This paper introduces Octo, an open-source generalist robot policy, which serves as a strong baseline and comparison point for the current paper's proposed VidMan framework."}, {"fullname_first_author": "Abhishek Padalkar", "paper_title": "Open x-embodiment: Robotic learning datasets and rt-x models", "publication_date": "2023-00-00", "reason": "This paper introduces a large-scale, heterogeneous dataset that the current paper leverages, making it critical for understanding the methodology and context of the VidMan research."}, {"fullname_first_author": "Hongtao Wu", "paper_title": "Unleashing large-scale video generative pre-training for visual robot manipulation", "publication_date": "2023-00-00", "reason": "This paper explores large-scale video generative pre-training for robot manipulation, directly addressing the similar challenge tackled by the current paper's VidMan framework."}]}