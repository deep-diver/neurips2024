{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021", "reason": "This paper introduces the Vision Transformer (ViT), a foundational model used as the backbone for UniDSeg's encoder, demonstrating the effectiveness of transformers in image recognition."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023", "reason": "This paper introduces the Segment Anything Model (SAM), a powerful foundation model leveraged in UniDSeg for enhanced semantic understanding and cross-modal learning."}, {"fullname_first_author": "Benjamin Graham", "paper_title": "3d semantic segmentation with submanifold sparse convolutional networks", "publication_date": "2018", "reason": "This paper introduces SparseConvNet, a crucial 3D backbone architecture adopted in UniDSeg for efficient processing of point cloud data."}, {"fullname_first_author": "Maximilian Jaritz", "paper_title": "Cross-modal learning for domain adaptation in 3d semantic segmentation", "publication_date": "2023", "reason": "This paper is highly relevant due to its focus on cross-modal learning for domain adaptation in 3D semantic segmentation, a key area addressed by UniDSeg."}, {"fullname_first_author": "Holger Caesar", "paper_title": "nuScenes: A multimodal dataset for autonomous driving", "publication_date": "2020", "reason": "This paper introduces the nuScenes dataset, a benchmark dataset for 3D semantic segmentation used for evaluating UniDSeg's performance."}]}