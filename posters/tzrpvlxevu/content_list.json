[{"type": "text", "text": "Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Victor Boutin1,2,3, Rishav Mukherji3, Aditya Agrawal3, Sabine Muzellec2,3, Thomas Fel1,3, Thomas Serre1,3, Rufin VanRullen1,2 ", "page_idx": 0}, {"type": "text", "text": "1Artificial and Natural Intelligence Toulouse Institute, Universit\u00e9 de Toulouse, Toulouse, France. 2Centre de Recherche Cerveau & Cognition CNRS, Universite de Toulouse, France 3Carney Institute for Brain Science, Brown University victor_boutin@brown.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Humans can effortlessly draw new categories from a single exemplar, a feat that has long posed a challenge for generative models. However, this gap has started to close with recent advances in diffusion models. This one-shot drawing task requires powerful inductive biases that have not been systematically investigated. Here, we study how different inductive biases shape the latent space of Latent Diffusion Models (LDMs). Along with standard LDM regularizers (KL and vector quantization), we explore supervised regularizations (including classification and prototype-based representation) and contrastive inductive biases (using SimCLR and redundancy reduction objectives). We demonstrate that LDMs with redundancy reduction and prototype-based regularizations produce near-human-like drawings (regarding both samples\u2019 recognizability and originality) \u2013 better mimicking human perception (as evaluated psychophysically). Overall, our results suggest that the gap between humans and machines in one-shot drawings is almost closed. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "For cognitive scientists, human drawings offer a window into the brain, providing tangible insights into its visual and motor internal processes [1]. For instance, drawings have been used in clinical settings to screen for perceptual impairments following brain trauma or Alzheimer\u2019s disease [2, 3], to assess perceptual disorders in autistic individuals [4\u20136] or to investigate perceptual changes during child development [7, 8] (see [1] for a recent review). Drawing tasks have also proven instrumental for exploring how the brain generalizes to novel visual categories [9\u201311]. Cognitive psychologists routinely use the one-shot drawing task to understand how human observers can reliably form new object categories from just one exemplar [12, 13]. From a computational viewpoint, this task is ill-defined because of the infinite number of possible sets of samples that could be associated with that exemplar. Yet, humans can effortlessly produce drawings that are not only easily recognizable but also original (i.e., sufficiently distinct from the reference exemplar) [12]. This remarkable capability suggests that the brain leverages powerful representational inductive biases \u2013 yet to be discovered \u2013 to form novel categories. ", "page_idx": 0}, {"type": "text", "text": "Computer scientists have started to make progress in identifying some of the inductive biases for machine learning algorithms to learn from limited data. For one-shot classification tasks, a particularly effective representational inductive bias is to design an embedding space where samples of the same category, whether seen during training or not, cluster closely. This approach spans a wide range of models ranging from representations learned via contrastive objective functions [14\u201316], prototypebased representations [17, 18] or metric matching losses [19, 20]. Conversely, for one-shot generation tasks, researchers have preferred architectural over representational inductive biases. For instance, novel architectures based on Generative Adversarial Networks (GANs) or Variational Auto-Encoders (VAEs) have incorporated forms of spatial attention [21] or contextual integration [22\u201324]. Recent advances in diffusion models [25, 26] make them particularly promising for one-shot generation tasks. Indeed, clever conditioning on a context vector [24] or directly using guidance from the exemplar [27] has led to powerful one-shot diffusion models [28]. Such a guidance mechanism has also proven successful in Latent Diffusion Models (LDMs) [29], which use a Regularized AutoEncoder (RAE) to compress input data and a diffusion model to learn the RAE\u2019s latent distribution. These diffusion models have started to close the gap with humans in the one-shot drawing task [30] (see section 2 for related work on one-shot learning). While better conditioning mechanisms have driven improvements in one-shot generative models, the potential of shaping their input space with representational inductive biases inspired by one-shot classification remains largely unexplored. This raises the question: \u201cDo representational inductive biases from one-shot classification help narrow the gap with humans in one-shot drawing tasks ?\u201d ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this article, we use Latent Diffusion Models (LDMs [29]) to address this question. LDMs combine the flexibility of the Regularized AutoEncoder (RAE), in which one can seamlessly include various representational inductive biases in the latent space via regularization, with the high expressivity of the diffusion model. Herein, we study the impact of 6 different regularizers corresponding to distinct representational inductive biases. They are categorized into 3 groups. The first group, which serves as a baseline, includes the $\\mathbf{KL}$ and the vector quantization regularization approaches typically used in LDMs [29]. The second group involves supervised regularizers: a classification loss that promotes discriminative features mapping with categorical training labels and a prototype-based objective function that clusters samples with their respective prototypes in an embedding space. The third group features contrastive learning regularization schemes with the SimCLR and Barlow losses. The SimCLR objective function keeps a sample and its augmented view close in the embedding space but far apart from other samples\u2019 views. In contrast, the Barlow loss ensures that features of similar samples are decorrelated from those of dissimilar ones. ", "page_idx": 1}, {"type": "text", "text": "We compare those regularized LDMs against humans on the one-shot drawing task. Such a task offers a leveled playfield in which humans and machines can create sketches that are directly comparable using established evaluation frameworks [31, 30, 12] (see section 2 for related work). More specifically, our comparison focuses on two metrics to evaluate the quality of sketches produced by humans and machines \u2013 based on how distinct from the exemplar and how recognizable they are [31] \u2013 and on the alignment between humans\u2019 and machines\u2019 perceptual strategies. For the latter, we describe a novel method to generate importance maps highlighting category-diagnostic features in LDMs. These maps are then directly compared against importance maps derived from human observers obtained through psychophysics experiments. Our results show that LDMs using prototypebased and redundancy-reduction (with the Barlow twin objective) regularization techniques are further closing the gap with humans. These results are supported by both the sample\u2019s similarity and the feature importance maps alignment. Overall, our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We introduce novel representational inductive biases in Latent Diffusion Models. In particular, we draw inspiration from losses that have proven effective in one-shot classification tasks (with the prototype-based, Barlow and SimCLR objective functions) to regularize the latent space of LDMs.   \n\u2022 We derive a novel explainability method to generate LDMs\u2019 feature importance maps that highlight category diagnostic features.   \n\u2022 We systematically compare the sketches and feature importance maps derived from humans and machines, and we show that LDMs with prototype-based and Barlow regularization significantly narrow the gap with humans on the one-shot drawing task. ", "page_idx": 1}, {"type": "text", "text": "Our work underscores the critical role of well-designed representational inductive biases in achieving human-like performance in one-shot drawing tasks. It also sets the stage for developing generative models that are better aligned with humans. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Representation learning for one-shot classification tasks: Learning representations that bring unseen samples (from the query set) close to the exemplars (in the support set) has proven effective in one-shot classification. The historical approach, called metric learning, aims at creating a feature space in which the distances between the query and support sets are preserved [20, 19, 32, 33]. However, the limited number of samples in the support set restricts these networks\u2019 ability to recognize novel classes. This limitation becomes more pronounced in the one-shot setting as the support set contains only one sample (the exemplar). To address this, the field has shifted towards prototype-based representations. Rather than trying to preserve the distances between query and support samples, such networks learn an embedding space in which the query samples cluster near the support samples [17, 34, 35]. Contrastive learning, a self-supervised learning approach, offers another effective solution to mitigate sample scarcity by augmenting the training set. This method learns an embedding space where positive pairs (a sample and its augmented version) are close together, and distant from negative pairs (augmented views from different instances) [14, 15, 36\u201339]. Among alternative methods, the SimCLR algorithm [14] uses a cosine similarity between samples whereas the Barlow-twins network [15] leverages the correlation matrix between features to dissociate positive and negative pairs. In this article, we use the prototype-based [17], the SimCLR [14] and the Barlow twins [15] objectives to regularize RAEs latent space. For additional mathematical details, see section 4.1 for the prototype-based loss and section A.2.3 for SimCLR and Barlow. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Generative models for one-shot image generation tasks: Some of the main techniques involve including information from the support set into the generative process, a method known as conditioning. For instance, the Neural Statistician uses a context vector containing summary statistics from the support sets, which is then concatenated with a VAE latent space [22, 24, 40]. Similarly, GANs leverage a compressed representation of the support set as a conditioning mechanism [23]. Such a mechanism has also been used successfully to either condition [41\u201343, 29] or guide the denoising process of diffusion models [27, 28] and latent diffusion models [29]. Here, we leverage LDMs with classifier-free guided diffusion models [27]. Such a diffusion process has been shown to well approximate human drawings in one-shot drawing tasks [30]. ", "page_idx": 2}, {"type": "text", "text": "Human-machine comparison in one-shot drawing tasks: Cognitive scientists have developed various methods to compare the generalization abilities of machines and brains on drawing tasks. Lake et al. [44] introduced the Omniglot challenge in which both humans and machines are tasked with drawing symbols from categories represented by a single exemplar (see [45] for a review on the challenge). The authors evaluated the drawings\u2019 recognizability in a visual Turing test where humans (or classifiers) had to distinguish between human-drawn and machine-generated symbols [11]. Additional metrics, including classification uncertainty and semantic similarity, were also used to compare drawings produced by humans and machines under different time constraints [46, 8]. While these evaluation frameworks provide useful insights into a sample\u2019s recognizability, they do not measure how the diversity of model-generated samples compares to those created by humans. The \u201coriginality vs. recognizability\u201d framework [31] mitigates this issue by adding the originality metric. An originality score quantifies the similarity between the original exemplar and its corresponding variations (see section 5.1 for details on this evaluation framework). This evaluation framework has been used to benchmark the generalization performance of mainstream generative models \u2013 Diffusion models [47], GANs [48] and VAEs [49] \u2013 against humans in the one-shot drawing setting [30]. Although Diffusion models come closest to human performance, a noticeable gap remained in this study. In this article, we use the \u201coriginality vs. recognizablility\u201d framework from Boutin et al. [31] to evaluate representational inductive biases in Latent Diffusion Models. In particular, we demonstrate that effective biases in one-shot classification tasks also prove efficient in the one-shot drawing task. ", "page_idx": 2}, {"type": "text", "text": "3 Datasets ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As done in previous work [31, 30, 11], we use the Omniglot [11] and the QuickDraw-FS [30] datasets to compare humans and machines on the one-shot drawing task. These datasets, made of handwritten symbols or drawings, offer a fair environment for comparing the generation abilities of humans and machines [11, 46, 31, 30]. It is important to note that natural images generation is a task beyond human capability, making it unsuitable for a fair comparison between humans and machines. ", "page_idx": 2}, {"type": "text", "text": "Omniglot contains 1, 623 categories of handwritten characters from 50 different alphabets, with 20 samples per class [11]. This article uses a downsampled version of the dataset (size: $48\\times48$ pixels). We train the models on a training set composed of all available symbols minus 3 symbols per alphabet left aside for the test set (similar to [21]). All the results on the Omniglot dataset are in the Appendix (see A.6). ", "page_idx": 2}, {"type": "text", "text": "QuickDraw-FS is made from drawings of the Quick, Draw ! challenge [50]. In this challenge, human participants are asked to produce drawings in less than 20 seconds when presented with an object name. The categories are, therefore, made with semantically consistent samples that do not necessarily represent the same visual concept (e.g., the \"phone\" object category might contain corded phones, smartphones, phones with rotary dials, etc). The Quickraw-FS dataset mitigates this issue with categories representing the same visual concepts (see A.1 for more details). This dataset is ideally suited for purely visual one-shot generation tasks [30]. It contains 665 categories with 500 samples each. The training set is made of 550 randomly selected categories, and 115 are left aside for the testing set. We downsampled the drawings to $48\\times48$ pixels to keep computational resources manageable. ", "page_idx": 3}, {"type": "text", "text": "For each category in both datasets, we extract a \u2019prototypical\u2019 sample, selected in the center of the category cluster to condition the one-shot generative models (see A.1 for more details on the exemplar selection). ", "page_idx": 3}, {"type": "text", "text": "4 One-shot Latent Diffusion Models ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The one-shot image generation task involves synthesizing variations of a visual concept not seen during training. Let $\\mathbf{x}\\in\\mathbb{R}^{D}$ denote the image variation and $\\mathbf{y}\\in\\mathbb{R}^{D}$ the exemplar. Latent Diffusion Models (LDMs) are composed of 2 distinct stages: a first stage leverages a Regularized AutoEncoder (RAE) that extracts a latent representation $\\textbf{z}\\in\\mathbb{R}^{d}$ $(d\\ll D)$ for each image (see green boxes in Fig. 1), and a second stage consisting of a diffusion model that learns the latent distribution (orange boxes in Fig. 1). In the one-shot setting, the diffusion model is conditioned by $\\mathbf{z_{y}}$ , the latent representation of y. We call c the category label of the training set (a one-hot vector). ", "page_idx": 3}, {"type": "text", "text": "4.1 Regularized Auto-Encoders (RAEs) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To describe the RAE, we use a probabilistic formulation in which $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ is the recognition model (or the encoder), and $p_{\\theta}(\\mathbf{\\dot{x}}|\\mathbf{z})$ is the decoder. We train the RAEs by minimizing $\\mathcal{L}_{R A E}$ (Eq. 1). In this equation, the first term is a reconstruction loss (computed with a $\\ell_{2}$ distance), and the second term $(\\mathcal{L}_{r e g})$ covers a wide range of regularization losses. $\\mathcal{L}_{r e g}$ includes the representational inductive biases we study in this article. Those inductive biases fall into 3 groups: the standard LDM regularizers, the supervised regularizers, and the contrastive regularizers. ", "page_idx": 3}, {"type": "image", "img_path": "tZRpvLXevU/tmp/46c1601881abde6ad043faa0eee46d35f62b99f8e5df00eef9c1703de0941ed7.jpg", "img_caption": ["Figure 1: Latent Diffusion Models stack a diffusion model (orange) on top of an Auto-Encoder (green). "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\;\\;\\mathrm{s.t.}\\;\\;\\;\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(.|\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}|\\mathbf{z})\\right]+\\beta\\mathcal{L}_{r e g}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Standard regularizers $\\mathbf{kL}$ and VQ): The KL divergence in Eq. 2 forces each coordinate of the latent vector to be distributed following a pre-determined distribution (e.g Gaussian distribution, ianst ion  at hdei scVrAetEe  [c4o9d]e). hues ivnegc ttohre  qnueaarnetsitz eendt rloy sisn i na  cEoqd. e3b toroakn ntwiintuh otuhse  lqatueanntt iczoadtieo ${\\bf z}$ $\\mathbf{z_{q}}$ $\\mathcal{Z}=\\{\\mathbf{e_{i}}\\}_{i=1}^{K}$ operator: ${\\bf z_{q}}=n_{\\mathcal{Z}}({\\bf z})$ (s.t. $n_{\\mathcal{Z}}:\\mathbf{z}\\rightarrow\\operatorname{arg\\,min}_{e_{i}}\\|\\mathbf{z}-\\mathbf{e_{i}}\\|_{2}$ as in the VQ-VAE [51]). This quantization operation being non-differentiable, backpropagation is achieved using a stop-gradient operation $s g[\\cdot]$ to provide a gradient estimator. We provide an extensive mathematical description of the VQ-VAE in App. A.2.1. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{K L}=\\mathbb{K L}(q_{\\phi}(\\mathbf{z}|x)||p(\\mathbf{z}))\\ \\ (\\mathrm{with}\\;p(\\mathbf{z})=\\mathcal{N}(0,\\mathbf{I}))}\\\\ &{\\mathcal{L}_{V Q}=(\\|s g[\\mathbf{z}]-\\mathbf{z_{q}}\\|_{2}^{2}-\\|s g[\\mathbf{z_{q}}]-\\mathbf{z}\\|_{2}^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Supervised regularizers (Classif. and Proto.): The classification regularizer forces discriminative features by minimizing the cross-entropy between the true labels (c) and the softmax of the logits. Here the logits are learned by a linear layer $(h_{\\theta}^{C L})$ stacked on the latent space (Eq. 4). While the classification loss is supervised by the true categorical labels, the prototype-based loss is supervised by the exemplars themselves (as in the Prototypical Net [17]). The prototype-based loss learns a metric space in which classification can be performed by computing distances between the variations and their corresponding exemplars (i.e., the prototypes)(see Eq. 5). Here, the metric space is linked to the latent space of the RAE through a linear layer $\\bar{(h_{\\theta}^{P R})}$ . Intuitively, the prototype-based loss finds an embedding space where the variations will be close (in terms of $\\ell_{2}$ distance) from their prototypes. See A.2.2 for more details. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{C L}=\\mathcal{C E}(h_{\\theta}^{C L}(\\mathbf{z}),\\mathbf{c})}\\\\ &{\\mathcal{L}_{P R}=\\mathbb{E}_{\\mathbf{z}_{\\mathbf{y}}\\sim\\mathbf{q}_{\\phi}(.|\\mathbf{y})}\\big[-\\log(\\mathrm{softmax}(\\|h_{\\theta}^{P R}(\\mathbf{z})-h_{\\theta}^{P R}(\\mathbf{z}_{\\mathbf{y}})\\|_{2})\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Contrastive regularizers (SimCLR and Barlow): Contrastive learning algorithms learn representations that are invariant under different distortions (i.e., data augmentations). Here we define two data-augmentation operators, $\\tau^{A}(\\cdot)$ and $\\tau^{B}(\\cdot)$ , that transform the variations $\\mathbf{x}$ into $\\mathbf{x^{A}}=\\tau^{A}(\\mathbf{x})$ and $\\mathbf{x}^{\\mathbf{B}}=\\bar{\\boldsymbol{\\tau}}^{\\mathbf{\\check{B}}}(\\mathbf{x})$ , respectively. We denote $\\mathbf{z}^{\\mathbf{A}}=q_{\\phi}(\\cdot|\\mathbf{x^{A}})$ and $\\mathbf{z}^{\\mathbf{B}}=q_{\\phi}(\\cdot|\\mathbf{x^{B}})$ the projection of $\\mathbf{x}^{\\mathbf{A}}$ and $\\mathbf{x}^{\\mathbf{B}}$ into the RAE latent space, respectively. The SimCLR regularizer is based on the InfoNCE loss: it maximizes the similarity between the representation of a sample and its augmented view while minimizing the similarity with negative pairs (augmented views of different instances) [14]. The Barlow regularizer (as in the Barlow twins [15]) forces the cross-correlation matrix between $\\mathbf{z^{A}}$ and $\\mathbf{z}^{\\mathbf{B}}$ to be as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of samples to be similar while minimizing the redundancy between the components of these vectors. Said differently, the SimCLR loss shapes the space based on the samples\u2019 similarity, while the Barlow operates on the correlation between the features of the samples. For conciseness, we have included the mathematical derivations and details on the data augmentation we used in App. A.2.3. ", "page_idx": 4}, {"type": "text", "text": "We leverage standard convolutional architectures (from [52]) to parametrize both the encoder and the decoder. The resulting autoencoder has a 1D bottleneck $d=128$ for QuickDraw-FS and $d=64$ for Omniglot). We refer the reader to App. A.3.1 for complete architectural and training details of the RAE. In the rest of the article, we evaluate the impact of these regularizations by exploring the effect of $\\beta$ (see Eq. 1) on LDMs. ", "page_idx": 4}, {"type": "text", "text": "4.2 Diffusion Model ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The LDM second stage is a diffusion model that learns the data distribution in the latent space of the RAE. Diffusion models progressively denoise a pure noise $\\mathbf{z_{T}}\\sim\\mathcal{N}(0,\\mathbf{I})$ into a clean latent representation $\\mathbf{z_{0}}:=\\mathbf{z}$ through a sequence of partially denoised variables $\\{{\\bf z_{i}}\\}_{i=1}^{T}$ . The goal is then to learn a transition \u221aprobabilit\u221ay $p_{\\psi}(\\mathbf{\\bar{z}_{t-1}}|\\mathbf{z_{t}})$ that approximates a noise injection operator $\\nu_{t}(.)$ so that $\\mathbf{z_{t}}=\\nu_{t}(\\mathbf{z_{0}})=\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{z_{0}}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon$ ( $\\textstyle{\\bar{\\alpha_{t}}}$ is an hyperparameter of the diffusion schedule, and $\\epsilon$ a Gaussian noise). The Denoising Diffusion Probabilistic Model (DDPM) [47] reduces the learning of $p_{\\psi}(\\mathbf{z_{t-1}}|\\mathbf{z_{t}})$ to the optimization of a simple autoencoder $\\epsilon_{\\psi}$ trained to predict the noise from a degraded latent representation $\\mathbf{z}_{t}$ (see A.4 for mathematical justification): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underset{\\psi}{\\arg\\operatorname*{min}}\\mathbb{E}_{\\mathbf{z}_{0}\\sim q_{\\phi}(\\cdot\\vert\\mathbf{x})}\\bigg[\\left\\|\\epsilon_{\\psi}\\!\\left(\\nu_{t}(\\mathbf{z}_{0}),\\mathbf{z}_{\\mathbf{y}},t\\right)-\\epsilon\\right\\|_{2}^{2}\\bigg]\\ \\mathrm{~s.t.~}\\ \\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})\\ \\mathrm{~and~}\\ t\\sim\\mathcal{U}(1,T)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In Eq. 6, $\\mathbf{z_{y}}$ denotes the latent representation of the exemplar y. Eq. 6 could be interpreted as a denoising score matching objective [53], so the optimal model $\\epsilon_{\\psi^{*}}$ matches the following score function: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{z}_{t}}\\log p_{\\psi^{\\star}}(\\mathbf{z}_{t}|\\mathbf{z_{y}})\\approx-\\frac{1}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{\\psi^{\\star}}(\\mathbf{z}_{t},\\mathbf{z_{y}})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The autoencoder-like model $\\epsilon_{\\psi}(.,\\mathbf{z_{y}},t)$ is a 1D Unet conditioned on the time variable $t$ and $\\mathbf{z_{y}}$ (see A.4.3 for details on the architecture and the training of the Unet). Herein, we use a classifier-free guided version of the DDPM [27] with the following score function: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{z}_{t}}\\log p_{\\psi^{\\star},\\gamma}(\\mathbf{z}_{t}|\\mathbf{z}_{\\mathbf{y}})=(1+\\gamma)\\nabla_{\\mathbf{z}_{t}}\\log p_{\\psi^{\\star}}(\\mathbf{z}_{t}|\\mathbf{z}_{\\mathbf{y}})-\\gamma\\nabla_{\\mathbf{z}_{t}}\\log p_{\\psi^{\\star}}(\\mathbf{z}_{t})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This formulation introduces a guidance scale $\\gamma$ (we use $\\gamma{=}1$ ) to tune how much the conditioning signal influences the final score. Such a formulation has shown effective in one-shot settings [28, 30]. Note that each term on the RHS of Eq. 8 is computed with the same network $\\epsilon_{\\psi}$ using Eq. 7. $\\epsilon_{\\psi}$ is simply conditioned on a non-informative signal to compute $\\log p_{\\psi^{\\star}}(\\mathbf{z}_{t})$ . We remind the reader that the training of the diffusion model begins only after the RAE training is complete, and occurs exactly identically, regardless of the type of regularization used. The quality of images generated by the diffusion model thus directly serves to compare the different regularizations. The code to train all described models is available at http://anonymous.4open.science/r/LatentMatters-526B. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "5 Results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "5.1 Originality vs. Recognizabilty ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To compare humans and machines in the one-shot drawing task, we first use the originality vs. recognizability framework [31, 30]. This framework leverages 2 critic networks to evaluate the samples produced during the testing phase. The recognizability is quantified using the classification accuracy of a one-shot classifier [17], while the originality is measured using the average distance between the variations and their corresponding exemplars. This distance is computed in the feature space of a self-supervised model [14]. Importantly, both human-drawn and machine-generated samples are evaluated using the same 2 critic networks. This ensures that any potential biases in the critic networks are minimized, leading to a more balanced comparative analysis. Note that the originality is normalized across all tested models to range between 0 and 1. Here, we use the same originality vs. recognizability framework setting as that used in Boutin et al. [30]. Importantly, the originality vs. recognizability plots should be interpreted based on how close the models are to the human data point (grey star in Fig. 3), rather than focusing solely on their individual originality or recognizability scores. In simple terms, a model that effectively mimics human drawings should fall near the human data point. Note also that there is an inherent trade-off between originality and recognizability: while recognizability assesses how likely the data point falls within the classifier decision boundary, originality measures how \u2019diffuse\u2019 the sample distribution is. Therefore a very original agent (producing highly diverse samples) will tend to have a low recognizability as the samples are likely to fall outside of the classifier decision boundary. ", "page_idx": 5}, {"type": "text", "text": "In Fig. 3, we first evaluate how increasing the regularization weights (i.e. the $\\beta$ in Eq. 1) for each regularizer (taken separately) affects the similarity of LDM samples to human drawings. To do so, we report the originality and the recognizability values for LDM samples trained with different $\\beta$ values (see data points in Fig. 3). We use a parametric fit (least curve fitting methods [54]) to illustrate how increasing $\\beta$ affects these scores (see A.5 for more details on the parametric fit computations). We observe a similar concave shape for all curves. As $\\beta$ starts increasing, the recognizability improves while the originality decreases (except for VQ regularizer). Beyond a certain $\\beta$ value, the recognizability declines, and the originality increases. In particular, the maximum recognizability values for KL and VQ (obtained with $\\beta_{K L}=10^{\\overline{{-5}}}$ and $\\beta_{V Q}=5)$ ) match those of a diffusion model trained in the pixel space and barely exceed those of a non-regularized LDM (see Fig. 3a). Increasing the weight of the prototype-based regularizer substantially reduces the distance to human compared to the classification regularizer (the minimal distance to human is 0.04 for $\\beta_{P R}=5\\cdot10^{2}$ vs. 0.15 for $\\beta_{C L}=5$ , see Fig. 3b). Among the contrastive regularizers, Barlow regularization significantly reduces the distance to human compared to the SimCLR one (the minimal distance to human is 0.08 with $\\beta_{B A R}=30\\$ vs. 0.12 with $\\beta_{S i m C L R}=10^{-2}$ , see Fig. 3c). A visual inspection of the samples tends to corroborate these results (see Fig. 2 and A.7 for more samples). We observe similar trends for all tested regularizers on the Omniglot dataset (see A.6). ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "image", "img_path": "tZRpvLXevU/tmp/1a995bbc7ac6282cb1f4ea9adb8e73777b260a12cd2d5e83261f9aee446a90d2.jpg", "img_caption": ["Figure 2: Samples from LDMs w/ different regularizers. The LDMs correspond to the larger data points in Fig. 3. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Overall, our findings indicate that not all regularizers are created equal. For supervised regularizers (see Fig. 3b), the prototype-based regularizer generates more recognizable samples compared to the classification regularizer. This is expected since the classifier focuses on separating categories in the training set, which may not be ideal for unseen categories in the one-shot setting [19, 17]. In contrast, the prototype-based regularizer clusters samples near their prototypes, leading to less overfitting and better transferability, which is valuable for few-shot tasks [55]. Our experiments confirm that the prototype-based regularizer generalizes better for one-shot drawing. In Fig. 3c, the Barlow regularization outperforms the SimCLR regularizer in recognizability, likely due to Barlow\u2019s effective feature disentangling [15]. These features transfer well to new datasets, making Barlow more suitable for the one-shot drawing task. Overall, our results demonstrate that effective representational inductive biases in few-shot learning also enhance performance in one-shot drawing. ", "page_idx": 5}, {"type": "image", "img_path": "tZRpvLXevU/tmp/f7a2413299a90ac72b83fa1794b74104c1df69ba5b1c1e025fba8e16e25ab111.jpg", "img_caption": ["Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights $(\\beta)$ . The curves represent the parametric ftis, oriented in the direction of an increase of $\\beta$ . a): For the LDMs with \u201cstandard\u201d regularizers, the $\\beta$ is applied on the KL $(\\mathcal{L}_{K L}$ in Eq. 2) or on the VQ regularizers $\\mathcal{L}_{V Q}$ in Eq. 3). b): For the supervised regularizers, the $\\beta$ is applied on the $\\mathrm{CL}$ ( $\\mathcal{L}_{C L}$ in Eq. 4) or on the prototype-based regularizers $\\mathcal{L}_{P R}$ in Eq. 5). c): For the contrastive regularizers, the $\\beta$ is applied on the SimCLR $\\mathcal{L}_{S i m C L R}$ in Eq. 14) or on the Barlow regularizers ( $\\mathcal{L}_{B a r}$ in Eq. 15). See A.5 for more information on the range of $\\beta$ we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star). "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "We now study the effect of the regularizers when they are used in combination. In particular, we have systematically explored the following combinations of regularizers Barlow $^+$ Prototype (Fig. 4a), SimCLR. $^+$ Prototype (Fig. 4b), $\\mathrm{KL+}$ Prototype (Fig. 4c), $\\mathbf{VQ}+\\mathbf{\\Omega}$ Prototype (Fig. 4d). We observe that the Barlow $^+$ Prototype and the $\\mathrm{KL+}$ Prototype combinations produced the most human-like samples. Those regularizer\u2019s combinations are particularly as in both cases the combined recognizability is significantly higher compared to using each regularizer alone. This suggests that clustering samples around their prototypes (using the Prototype regularizer) within a disentangled space (achieved via the $\\mathrm{KL}$ or Barlow regularizer) enhances generalization. In contrast, the $\\mathbf{VQ}+\\mathbf{\\deltaV}$ Prototype and the SimCLR $^+$ Prototype combinations show little to no improvements. ", "page_idx": 6}, {"type": "text", "text": "5.2 Comparing humans and LDM perceptual strategies ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "While the originality vs. recognizability framework allows us to compare human and machine performances in the one-shot drawing task, it does not reveal the strategies each uses to generalize to new categories. To address this, we aim to compare the visual strategies more directly via feature importance maps. These maps emphasize the most salient features to recognize a drawing. ", "page_idx": 6}, {"type": "image", "img_path": "tZRpvLXevU/tmp/8911f91e304ce86d29a3d7ad04a42d67a7659bab5f55631be46c27dac1358e64.jpg", "img_caption": ["Figure 4: Combined effect of the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with a combination of 2 different regularizers. All combinations include the prototype-based regularizers. The curves represent the parametric fits, oriented in the direction of an increase of $\\beta$ . a): Barlow and prototype-based regularizers applied either separately (plain lines) or in combination (dashed-line). When applied in combinations, only the weight of the prototype-based regularizer is modified (with $\\beta=30$ for Barlow). b): SimCLR and prototype-based regularizers. When applied in combinations, only the weight of the prototype-based regularizer is modified, the SimCLR is set to $\\beta=1$ . c): $\\mathrm{KL}$ and prototype-based regularizers. When applied in combinations, only the weight of the prototype-based regularizer is modified, the KL is set to $\\beta=1e-3.\\,{\\bf d}$ ): VQ and prototype-based regularizers. When applied in combinations, only the weight of the prototype-based regularizer is modified, the VQ is set to $\\beta=20$ . See caption in Fig. 3. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Previous research has demonstrated that by summing the absolute values of the diffusion scores $(\\nabla_{z_{t}}\\log p_{\\psi}(z_{t}|z_{y}))$ throughout all diffusion steps, one can create heatmaps that highlight salient features in a diffusion model\u2019s generation process [30]. Here, we adapt this heuristic to make it compatible with LDMs. This involves projecting each intermediate noisy state $\\bf(z_{t})$ back to pixel space using the RAE\u2019s decoder $(p_{\\theta}(\\cdot|\\mathbf{z_{t}}))$ . To do so, we use the chain rule, and we multiply each diffusion score by the Jacobian of the RAE decoder w.r.t $\\mathbf{x_{t}}$ (denoted $J_{\\log p_{\\theta}(\\mathbf{\\cdot}|\\mathbf{z_{t}})}(\\mathbf{x_{t}}))$ . For each variation $\\mathbf{x}$ and its corresponding exemplar $\\mathbf{y}$ , we can therefore compute a heatmap using Eq. 9 (see A.8.1 for mathematical details). Then, we average 10 of these heatmaps, obtained with the same exemplar but for different variations belonging to the same category. This process allows us to mitigate intra-class variations while focusing on category-specific features. We call this average the feature importance map (see A.8.2 to visualize feature importance maps). ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\phi(\\mathbf{x},\\mathbf{y})=\\sum_{i=0}^{\\cdot}\\left|J_{\\log p_{\\theta}(\\cdot|\\mathbf{z_{t}})}(\\mathbf{x_{t}})\\nabla_{\\mathbf{z_{t}}}\\log p_{\\psi}(\\mathbf{z_{t}}|\\mathbf{z_{y}})\\right|\\;\\mathrm{with}\\;\\;\\mathbf{z_{y}}\\sim q_{\\phi}(\\cdot|\\mathbf{y})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We derived human feature importance maps using psychophysical data from Boutin et al. [30] (data shared by the original authors). The authors collected human saliency maps through an online psychophysics experiment based on a similar protocol to the ClickMe experiment [56]. In this experiment, participants were presented with drawings and were asked to draw on regions important for categorization (see App. S in [30] for more details on the experimental protocol). We averaged the heatmaps across participants and drawings within the same category to obtain the feature importance maps we compared with those of machines (see A.8.3 for visualizing feature importance maps). ", "page_idx": 7}, {"type": "text", "text": "In Fig 5, we compare humans and LDMs feature importance maps. For each regularizer, we select the LDMs that produce the most human-like sketches (highlighted with larger data points in Fig. 3). Note that we exclude the VQ-regularized LDM from this analysis because it produces irrelevant feature importance maps, possibly due to the non-differentiability of the quantization process (see Fig. A.15). In Fig. 5a, we showcase examples of the obtained feature importance maps for all other LDMs\u2019 regularizations (see also A.8.2) and for humans (see also A.8.3). We qualitatively observe that the LDMs regularized with the Barlow and the prototype-based objectives tend to focus on sparse features. This particular aspect seems to be shared with the human feature importance maps. We compute the Spearman rank correlation to quantify the similarity between human and machine feature importance maps (see Fig. 5b). To make sure that the correlation comparison between the different LDMs is significant, we have computed pairwise statistical tests (Wilcoxon signed-rank test, see A.8.4). Our results show that all considered regularizations correlate significantly more with human feature importance maps than non-regularized LDMs. In addition, the prototype-based regularizer produces the feature importance maps with the highest correlation with humans and is significantly above all other tested regularizations $(p<10^{-3})$ ). In the human-alignment ranking, the Barlow-regularized LDM follows the prototype-based LDM, also showing a significantly higher Spearman correlation coefficient than KL, classification, SimCLR regularizers $(p<10^{\\bar{-}3})$ ). All other pair-wise statistical tests (between KL, classification, SimCLR) are not significant enough to draw a meaningful ranking. ", "page_idx": 7}, {"type": "image", "img_path": "tZRpvLXevU/tmp/9976307fed41a1ad797a61f89b6934298b46ef649271847a636b5a37d1fa7991.jpg", "img_caption": ["Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging $\\phi(\\mathbf{x},\\mathbf{y})$ (see Eq. 9) over 10 different image variations $\\bf{\\Psi}(x)$ belonging to the same category. The models\u2019 maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman\u2019s rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the $\\mathbf{p}$ -value $(\\star\\star\\star:\\,p\\,<\\,10^{-3}$ and $\\star:p<5.10^{-2};$ ) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this article, we used Latent Diffusion Models (LDMs) to study the effect of representational inductive biases for one-shot drawing tasks. We explore 6 different regularizers: KL, vector quantization, classification, prototype-based, SimCLR and Barlow regularizers. We analyzed the human/LDMs alignment from two (independent) perspectives: their performance relative to humans on the one-shot drawing task (with the recognizability vs. originality framework in section 5.1) and the similarity of the underlying visual strategies (with the feature importance maps in 5.2). Overall, we observe a clear alignment between the 2 analyses on the following points: ", "page_idx": 8}, {"type": "text", "text": "\u2022 All regularized LDMs have an optimal regularization weight $(\\beta)$ where they are more aligned with humans than their non-regularized counterparts. ", "page_idx": 8}, {"type": "text", "text": "\u2022 The prototype-based regularizer is showing the best matches with human performance and attentional strategy. \u2022 In the one-shot drawing tasks, the samples\u2019 human-likeness could be further improved by combining the prototype-based regularizer with either the $\\mathrm{KL}$ or the Barlow regularizers. ", "page_idx": 9}, {"type": "text", "text": "In conclusion, we observe that all representational inductive biases \u201care not created equal\u201d. However, some of them (prototype-based and Barlow regularizers) do narrow the gap with humans in the one-shot drawing task. ", "page_idx": 9}, {"type": "text", "text": "7 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this article, we tested six representational inductive biases, a small number considering the extensive range available in the representation-learning literature. This field encompasses hundreds of inductive biases that have proven successful in one-shot classification tasks. Therefore, other representational inductive biases might align better with human performance, both in terms of sample similarity and visual strategy. Our goal wasn\u2019t to test all possible biases but to demonstrate that some of them can significantly narrow the gap with humans in one-shot drawing tasks. ", "page_idx": 9}, {"type": "text", "text": "Another limitation of this article lies in the recognizability vs. originality framework we are using to evaluate the drawings. This framework leverages 2 critic networks to evaluate the sample\u2019s originality and recognizability. There\u2019s no guarantee these networks align with human perceptual judgments. Thus, the recognizability and originality scores might not reflect human perception accurately. However, since both human and model outputs are evaluated using the same pre-trained critic networks, the comparison remains fair. ", "page_idx": 9}, {"type": "text", "text": "8 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "It is noteworthy that the $\\mathrm{KL}$ and VQ regularizers, commonly used to train LDMs on natural images (as in StableDiffusion [29]) are not the best-performing regularizers in the one-shot drawing task. Our study indicates that the prototype-based and the Barlow regularizers, not tested yet on LDMs trained on natural images, hold a significant potential for enhancing their one-shot ability. From a single image of a new vehicle prototype or of a new fashion item design, a generative model trained with these regularizers could produce relevant variations \u2013 an ability that current commercial applications still struggle with (see Fig. A.8.5). ", "page_idx": 9}, {"type": "text", "text": "Interestingly, the 2 inductive biases that align most closely with humans are directly related to prominent neuroscience theories. The prototype-based objectives provide an instantiation of the prototype theory of recognition and memory [57\u201361], suggesting that humans use prototype similarity to recognize novel objects. Similarly, the Barlow regularization is inspired by Barlow\u2019s redundancy reduction theory [62, 63], which posits that the brain encodes statistically independent features to eliminate redundancy (and minimize energy consumption). The effectiveness of these regularizations provides hints that the brain may use similar inductive biases to generalize to new categories. In terms of brain inspiration, although we use LDMs to model humans\u2019 one-shot generation abilities, we do not claim that these neural networks constitute a realistic model of brain processes. It is indeed unlikely that humans generate samples by iteratively denoising random noise. More biologically plausible generative models might further help to obtain better models of human behavior (e.g., see [64\u201368]). ", "page_idx": 9}, {"type": "text", "text": "With this paper, we highlight how specific representational inductive biases, included in the input space of generative models, can help bridge the gap with human capabilities. We believe these biases will allow advanced models to generalize and create as effectively as humans do, leading to exciting advancements in technology and creativity. ", "page_idx": 9}, {"type": "text", "text": "Aknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was funded by the European Union (ERC, GLoW, 101096017), ANITI (Artificial and Natural Intelligence Toulouse Institute) and the French National Research Agency (ANR-19-PI3A0004). Additional funding was provided by ONR (N00014-24-1-2026) and NSF (IIS-1912280, IIS-2402875 and EAR-1925481). Computing hardware supported by NIH Office of the Director grant S10OD025181 via the Center for Computation and Visualization (CCV). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "[1] Judith E Fan, Wilma A Bainbridge, Rebecca Chamberlain, and Jeffrey D Wammes. Drawing as a versatile cognitive tool. Nature Reviews Psychology, 2(9):556\u2013568, 2023.   \n[2] Anna Cantagallo and Sergio Della Sala. Preserved insight in an artist with extrapersonal spatial neglect. Cortex, 34(2):163\u2013189, 1998.   \n[3] Berit Agrell and Ove Dehlin. The clock-drawing test. Age and ageing, 27(3):399\u2013404, 1998.   \n[4] Laurent Mottron and Sylvie Belleville. A study of perceptual analysis in a high-level autistic subject with exceptional graphic abilities. Brain and cognition, 23(2):279\u2013309, 1993.   \n[5] Laurent Mottron, Jacob A Burack, Johannes EA Stauder, and Philippe Robaey. Perceptual processing among high-functioning persons with autism. The Journal of Child Psychology and Psychiatry and Allied Disciplines, 40(2):203\u2013211, 1999.   \n[6] Nicholas Humphrey. Cave art, autism, and the evolution of the human mind. Cambridge Archaeological Journal, 8(2):165\u2013191, 1998.   \n[7] Annette Karmiloff-Smith. Constraints on representational change: Evidence from children\u2019s drawing. Cognition, 34(1):57\u201383, 1990.   \n[8] Bria Long, Judith E Fan, Holly Huey, Zixian Chai, and Michael C Frank. Parallel developmental changes in children\u2019s production and recognition of line drawings of visual concepts. Nature Communications, 15(1):1191, 2024.   \n[9] Tomer D Ullman and Joshua B Tenenbaum. Bayesian models of conceptual development: Learning as building models of the world. Annual Review of Developmental Psychology, 2: 533\u2013558, 2020.   \n[10] Joshua Brett Tenenbaum. A Bayesian framework for concept learning. PhD thesis, Massachusetts Institute of Technology, 1999.   \n[11] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 350(6266):1332\u20131338, 2015.   \n[12] Henning Tiedemann, Yaniv Morgenstern, Filipp Schmidt, and Roland W Fleming. One-shot generalization in humans revealed through a drawing task. Elife, 11:e75485, 2022.   \n[13] Henning Tiedemann, Yaniv Morgenstern, Filipp Schmidt, and Roland W Fleming. Probing feature spaces of object categories with a drawing task. Journal of Vision, 23(9):4765\u20134765, 2023.   \n[14] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pages 1597\u20131607. PMLR, 2020.   \n[15] Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St\u00e9phane Deny. Barlow twins: Selfsupervised learning via redundancy reduction. In International conference on machine learning, pages 12310\u201312320. PMLR, 2021.   \n[16] Chen Liu, Yanwei Fu, Chengming Xu, Siqian Yang, Jilin Li, Chengjie Wang, and Li Zhang. Learning a few-shot embedding model with contrastive learning. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 8635\u20138643, 2021.   \n[17] Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. Advances in neural information processing systems, 30, 2017.   \n[18] Junnan Li, Pan Zhou, Caiming Xiong, and Steven CH Hoi. Prototypical contrastive learning of unsupervised representations. arXiv preprint arXiv:2005.04966, 2020.   \n[19] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. Advances in neural information processing systems, 29, 2016.   \n[20] Gregory Koch, Richard Zemel, Ruslan Salakhutdinov, et al. Siamese neural networks for one-shot image recognition. In ICML deep learning workshop, volume 2. Lille, 2015.   \n[21] Danilo Rezende, Ivo Danihelka, Karol Gregor, Daan Wierstra, et al. One-shot generalization in deep generative models. In International conference on machine learning, pages 1521\u20131529. PMLR, 2016.   \n[22] Harrison Edwards and Amos Storkey. Towards a neural statistician. arXiv preprint arXiv:1606.02185, 2016.   \n[23] Antreas Antoniou, Amos Storkey, and Harrison Edwards. Data augmentation generative adversarial networks. arXiv preprint arXiv:1711.04340, 2017.   \n[24] Giorgio Giannone and Ole Winther. Hierarchical few-shot generative models. arXiv preprint arXiv:2110.12279, 2021.   \n[25] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems, 32, 2019.   \n[26] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International Conference on Machine Learning, pages 2256\u20132265. PMLR, 2015.   \n[27] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022.   \n[28] Bin Cheng, Zuhao Liu, Yunbo Peng, and Yue Lin. General image-to-image translation with oneshot image guidance. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 22736\u201322746, 2023.   \n[29] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.   \n[30] Victor Boutin, Thomas Fel, Lakshya Singhal, Rishav Mukherji, Akash Nagaraj, Julien Colin, and Thomas Serre. Diffusion models as artists: Are we closing the gap between humans and machines? Proceedings of the 40th International Conference on Machine Learning, 2023.   \n[31] Victor Boutin, Lakshya Singhal, Xavier Thomas, and Thomas Serre. Diversity vs. recognizability: Human-like generalization in one-shot generative models. Advances in Neural Information Processing Systems, 35:20933\u201320946, 2022.   \n[32] Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1199\u20131208, 2018.   \n[33] Fusheng Hao, Fengxiang He, Jun Cheng, Lei Wang, Jianzhong Cao, and Dacheng Tao. Collect and select: Semantic alignment metric learning for few-shot learning. In Proceedings of the IEEE/CVF international Conference on Computer Vision, pages 8460\u20138469, 2019.   \n[34] Rinu Boney and Alexander Ilin. Semi-supervised few-shot learning with prototypical networks. CoRR abs/1711.10856, 2017.   \n[35] Fangyu Wu, Jeremy S Smith, Wenjin Lu, Chaoyi Pang, and Bailing Zhang. Attentive prototype few-shot learning with capsule network-based embedding. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXVIII 16, pages 237\u2013253. Springer, 2020.   \n[36] Xi Chen, Diederik P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. arXiv preprint arXiv:1611.02731, 2016.   \n[37] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33:21271\u201321284, 2020.   \n[38] Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet, and Andrew Zisserman. With a little help from my friends: Nearest-neighbor contrastive learning of visual representations. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9588\u20139597, 2021.   \n[39] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020.   \n[40] Luke B Hewitt, Maxwell I Nye, Andreea Gane, Tommi Jaakkola, and Joshua B Tenenbaum. The variational homoencoder: Learning to learn high capacity generative models from few examples. arXiv preprint arXiv:1807.08919, 2018.   \n[41] Giorgio Giannone, Didrik Nielsen, and Ole Winther. Few-shot diffusion models. arXiv preprint arXiv:2205.15463, 2022.   \n[42] Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, and Houqiang Li. Sindiffusion: Learning a diffusion model from a single natural image. arXiv preprint arXiv:2211.12445, 2022.   \n[43] Vladimir Kulikov, Shahar Yadin, Matan Kleiner, and Tomer Michaeli. Sinddm: A single image denoising diffusion model. In International Conference on Machine Learning, pages 17920\u201317930. PMLR, 2023.   \n[44] Brenden Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua Tenenbaum. One shot learning of simple visual concepts. In Proceedings of the annual meeting of the cognitive science society, volume 33, 2011.   \n[45] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. The omniglot challenge: a 3-year progress report. Current Opinion in Behavioral Sciences, 29:97\u2013104, 2019.   \n[46] Kushin Mukherjee, Holly Huey, Xuanchen Lu, Yael Vinker, Rio Aguina-Kang, Ariel Shamir, and Judith Fan. Seva: Leveraging sketches to evaluate alignment between human and machine visual abstraction. Advances in Neural Information Processing Systems, 36, 2024.   \n[47] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020.   \n[48] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):139\u2013144, 2020.   \n[49] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.   \n[50] Jonas Jongejan, Henry Rowley, Takashi Kawashima, Jongmin Kim, and Nick Fox-Gieg. The quick, draw!-ai experiment. Mount View, CA, accessed Feb, 17(2018):4, 2016.   \n[51] Aaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in neural information processing systems, 30, 2017.   \n[52] Partha Ghosh, Mehdi SM Sajjadi, Antonio Vergari, Michael Black, and Bernhard Sch\u00f6lkopf. From variational to deterministic autoencoders. arXiv preprint arXiv:1903.12436, 2019.   \n[53] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020.   \n[54] M Grossman. Parametric curve fitting. The Computer Journal, 14(2):169\u2013172, 1971.   \n[55] Xiaoxu Li, Xiaochen Yang, Zhanyu Ma, and Jing-Hao Xue. Deep metric learning for few-shot image classification: A review of recent developments. Pattern Recognition, 138:109381, 2023.   \n[56] Drew Linsley, Dan Shiebler, Sven Eberhardt, and Thomas Serre. Learning what and where to attend. arXiv preprint arXiv:1805.08819, 2018.   \n[57] Michael I Posner and Steven W Keele. On the genesis of abstract ideas. Journal of experimental psychology, 77(3p1):353, 1968.   \n[58] Stephen K Reed. Pattern recognition and categorization. Cognitive psychology, 3(3):382\u2013407, 1972.   \n[59] Donald Homa, Deborah Rhoads, and Daniel Chambliss. Evolution of conceptual structure. Journal of Experimental Psychology: Human Learning and Memory, 5(1):11, 1979.   \n[60] J David Smith and John Paul Minda. Prototypes in the mist: The early epochs of category learning. Journal of Experimental Psychology: Learning, memory, and cognition, 24(6):1411, 1998.   \n[61] John Paul Minda and J David Smith. Prototypes in category learning: the effects of category size, category structure, and stimulus complexity. Journal of Experimental Psychology: Learning, Memory, and Cognition, 27(3):775, 2001.   \n[62] Horace B Barlow et al. Possible principles underlying the transformation of sensory messages. Sensory communication, 1(01):217\u2013233, 1961.   \n[63] Horace Barlow. Redundancy reduction revisited. Network: computation in neural systems, 12 (3):241, 2001.   \n[64] Rajesh PN Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature neuroscience, 2(1):79\u201387, 1999.   \n[65] Bhavin Choksi, Milad Mozafari, Callum Biggs O\u2019May, Benjamin Ador, Andrea Alamia, and Rufin VanRullen. Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics. Advances in Neural Information Processing Systems, 34:14069\u201314083, 2021.   \n[66] Victor Boutin, Aimen Zerroug, Minju Jung, and Thomas Serre. Iterative vae as a predictive brain model for out-of-distribution generalization. SVRHM workshop at Neural and Information Processing Systems 34, 2020.   \n[67] Victor Boutin, Angelo Franciosini, Fr\u00e9d\u00e9ric Chavane, and Laurent U Perrinet. Pooling strategies in v1 can account for the functional and structural diversity across species. PLOS Computational Biology, 18(7):e1010270, 2022.   \n[68] Victor Boutin, Angelo Franciosini, Frederic Chavane, Franck Ruffier, and Laurent Perrinet. Sparse deep predictive coding captures contour integration capabilities of the early visual system. PLoS computational biology, 17(1):e1008629, 2021.   \n[69] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[70] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.   \n[71] Alexander Shmakov, Kevin Greif, Michael Fenton, Aishik Ghosh, Pierre Baldi, and Daniel Whiteson. End-to-end latent variational diffusion models for inverse problems in high energy physics. Advances in Neural Information Processing Systems, 36, 2024. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Appendix/Supplementary Information ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 QuickDraw-FS dataset ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The QuickDraw-FS dataset is built from the samples of the Quick, Draw ! challenge [50]. In this online experiment (https://quickdraw.withgoogle.com), participants have to draw an object when presented with the category name. The resulting dataset is made of 345 object categories, with approximately 150, 000 drawings per category. The experimental protocol of the Quick, Draw ! challenge forces the participants to produce drawings that are semantically related to the category name, but those drawings do not necessarily represent the same visual concepts. For example, the \u201calarm clock\u201d category includes digital and analogic types of alarm clocks, which represent 2 different visual concepts (see Fig.A.1). This property makes the original Quick, Draw ! dataset not optimal for purely visual one-shot generation tasks. ", "page_idx": 15}, {"type": "image", "img_path": "tZRpvLXevU/tmp/384db260c68c40738b805d44cc3e4119de69581e0c393f9cb59d934b6d9bf170.jpg", "img_caption": ["Figure A.1: Examples of distinct visual concepts belonging to the same object category in the Quick, Draw ! dataset. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "To mitigate this issue, previous work has proposed the QuickDraw-FS dataset. In this dataset, new categories are formed based on the visual similarity of the drawings (see Appendix A in [30]). The authors have used clustering techniques in the latent space of the contrastive learning algorithms to compute the infer the new categories. The resulting dataset is made of categories representing one single visual concept. Using this dataset, one can extract a \u201cprototype\u201d exemplar \u2013 at the center of the cluster \u2013 to exemplify the category visual concepts. We include examples of drawing variations and their corresponding exemplars in Fig. A.2. ", "page_idx": 15}, {"type": "image", "img_path": "tZRpvLXevU/tmp/7e75f12e4cf97954eb262cffb2e267a9b366b571aecc92ff2b637c9915e2d8ac.jpg", "img_caption": ["Figure A.2: Illustration of the samples and the corresponding exemplars for 4 categories of the QuickDraw-FS dataset. The small image located on the top represents the exemplars of the different visual concepts. The $5\\times5$ grid of drawings represents the corresponding visual concepts (randomly sampled in the cluster. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "A.2 Regularized AutoEncoders ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A.2.1 VQ-VAE ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Let us define a codebook $\\mathcal{Z}=\\{\\mathbf{e}_{i}\\}_{i=1}^{K}$ made of $K$ elements (also called codewords). Each codeword has a dimension $\\mathbf{s}:\\mathbf{e}_{i}\\in\\mathbb{R}^{s}$ . The Vector-Quantized Variational AutoEncoder (VQ-VAE) [51] can be decomposed into 3 stages: i) an encoder $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ mapping the input data $\\mathbf{x}$ to a continuous latent vector $z\\in\\mathbb{R}^{d}$ , ii) a discretizing operator denoted $n_{\\mathcal{Z}}(z)$ which transforms $\\mathbf{z}$ into a discretized latent vector $\\mathbf{z}_{q}$ , and iii) a decoder $p_{\\boldsymbol{\\theta}}(\\mathbf{x}|\\mathbf{z_{q}})$ mapping $\\mathbf{z}_{q}$ to a reconstructed image $\\mathbf{x}$ . The discrete latent code $\\mathbf{z_{q}}$ is calculated using a nearest-neighbor look-up in the codebook $\\mathcal{Z}$ (see Eq. 10). Said differently, each element of the continuous latent vector $\\mathbf{z_{i}}$ is replaced by the nearest $\\mathbf{e}_{\\mathbf{j}}$ in the codebook (here the $i$ index corresponds to the $i$ -th coordinate of ${\\bf z}$ ): ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{z}_{\\mathbf{q}_{i}}=n_{\\mathcal{Z}}(\\mathbf{z_{i}})=\\underset{\\mathbf{e_{j}}\\in\\mathcal{Z}}{\\arg\\operatorname*{min}}\\|\\mathbf{z}_{i}-\\mathbf{e}_{j}\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\mathbf{z_{q}}$ could then be transformed into a discretized vector by mapping each codeword with its corresponding address in the codebook $(\\mathbf{e}_{\\mathbf{j}}\\rightarrow j)$ . Note that this quantization process is equivalent to defining a posterior distribution following a $K$ -way categorical distribution [51]. ", "page_idx": 16}, {"type": "text", "text": "To learn the resulting networks, one naive way would be to minimize the following loss function : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{arg\\,min}_{\\phi,\\theta,\\mathcal{Z}}\\mathcal{L}_{V Q V A E}\\quad\\mathrm{with}\\quad\\mathcal{L}_{V Q V A E}=-\\mathbb{E}_{\\mathbf{z_{q}}\\sim n_{\\mathcal{Z}}(q_{\\phi}(.|\\mathbf{x}))}\\left[\\log p_{\\theta}(\\mathbf{x}|\\mathbf{z_{q}})\\right]\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Eq. 11 is a reconstruction loss in which the information first flows through the quantized encoder, (i.e.   \n$n\\bar{z}(q_{\\phi}(.|\\mathbf{x}));$ ), to then produce a reconstructed image (i.e. $\\log(p_{\\theta}(\\mathbf{x}|\\mathbf{z}))$ . ", "page_idx": 16}, {"type": "text", "text": "However, Eq. 11 cannot be directly optimized as it has no real gradient (the arg min function is not derivable). To minimize this loss function, the gradient is then approximated using a straight-through estimator [36]. The straight-through estimator involves copying the gradients from the decoder input to the encoder output. We refer the reader to line 5 in Algo. 1 for practical implementation of the straight-through gradient estimator. Intuitively, since ${\\bf z}$ is supposed to be very close to $\\mathbf{z_{q}}$ the gradient contains meaningful information for how the encoder has to change to minimize the reconstruction loss. During inference, the nearest embedding $\\mathbf{z_{q}}$ is computed using Eq. 10 and then fed to the decoder. Due to the straight-through operation, the codebook $\\mathcal{Z}$ does not receive any gradient information from the reconstruction term. Therefore, the codebook is learned with the simplest dictionary learning algorithm that involves minimizing the $\\ell_{2}$ distance between the quantized vector $\\mathbf{z_{q}}$ and the continuous one $\\mathbf{z}$ (i.e. $||\\mathbf{z}-\\mathbf{z_{q}}||_{2}^{2})$ . This quantity cannot be directly minimized because there is no gradient flowing from $\\mathbf{z_{q}}$ to $\\mathbf{z}$ . To mitigate this issue, it is replaced with the estimator term $||s g[\\mathbf{z_{q}}]-\\mathbf{z}||_{2}^{2}+||\\mathbf{z_{q}}-s g[\\mathbf{z}]||_{2}^{\\hat{2}}$ . The full VQ-VAE loss is described in Eq. 12: : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{V Q V A E}=-\\mathbb{E}_{\\mathbf{z_{q}}\\sim n_{\\mathcal{Z}}(q_{\\phi}(\\mathbf{.}|\\mathbf{x}))}\\left[\\log p_{\\theta}(\\mathbf{x}|\\mathbf{z_{q}})\\right]+\\beta_{V Q}(\\|s g[\\mathbf{z_{q}}]-\\mathbf{z}\\|_{2}^{2}+\\|\\mathbf{z_{q}}-s g[\\mathbf{z}]\\|_{2}^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The following pseudo-code illustrates how the VQ-VAE is usually implemented (see Algo. 1). We follow a similar implementation: ", "page_idx": 16}, {"type": "table", "img_path": "tZRpvLXevU/tmp/a0dca995766c5fe4fb34dd7d937f44c05c04f25aae1e5746eeb2594c2c7c6b56.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "A.2.2 Prototype-based regularization ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Prototypical networks focus on learning an embedding space where data points cluster around a single prototype representation for each class. A prototype is originally defined as the mean vector of ", "page_idx": 16}, {"type": "text", "text": "the embedded support points belonging to its class [17]. In the one-shot setting, the support set is reduced to one single sample. Therefore here the prototype and the exemplar are the same. ", "page_idx": 17}, {"type": "text", "text": "To achieve the desired embedding space for the autoencoder we regularize the reconstruction loss with a protoype-based loss. The loss uses the pairwise $\\ell_{2}$ distance between samples and prototype to derive a probability distribution: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{L}_{P R}=\\mathbb{E}_{{\\mathbf{z}_{\\mathbf{y}}}\\sim{\\mathbf{q}_{\\phi}}(.|{\\mathbf{y}})}\\big[-\\log(\\mathrm{softmax}(\\|h_{\\theta}^{P R}(\\mathbf{z})-h_{\\theta}^{P R}(\\mathbf{z_{y}})\\|_{2})\\big]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In Eq. 13, $h_{\\theta}^{P R}(\\mathbf{z_{y}})$ represents the projection of the prototype in the embedding space while $h_{\\theta}^{P R}({\\bf z})$ represents the projections of the sample. See Algo. 2 for more details on the exact implementation of the prototype-based regularized RAE. ", "page_idx": 17}, {"type": "text", "text": "", "text_level": 1, "page_idx": 17}, {"type": "image", "img_path": "tZRpvLXevU/tmp/994c8244d58d0ef33eb4478b2a2ae731e023f9532baf98d343d8dcd03d990ac9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "A.2.3 Constrastive regularizers ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Maths and Algorithms: Contrastive learning algorithms learn representations that are invariant under different distortions (i.e. data augmentations). Here we use two data-augmentation operators, $\\tau^{A}(\\cdot)$ and $\\tau^{B}(\\cdot)$ , that transform the variations $\\mathbf{x}$ into $\\mathbf{x^{A}}=\\tau^{A}(\\mathbf{x})$ and $\\mathbf{x^{B}}=\\boldsymbol{\\tau}^{B}(\\mathbf{x})$ , respectively. We denote $\\mathbf{z}^{\\mathbf{A}}$ and $\\mathbf{z}^{\\mathbf{B}}$ the latent space projection of $\\mathbf{x}^{\\mathbf{A}}$ and $\\mathbf{x}^{\\mathbf{B}}$ , respectively (i.e. $q_{\\phi}^{'}(\\mathbf{z}^{\\mathbf{A}}|\\mathbf{\\hat{x}}^{\\mathbf{A}})$ and $q_{\\phi}(\\mathbf{z}^{\\mathbf{B}}|\\mathbf{x}^{\\mathbf{B}}))$ . Here, we use two different types of contrastive regularizations that are $\\mathcal{L}_{S i m C L R}$ (see Eq. 14) and $\\mathcal{L}_{B a r}$ (see Eq. 15) ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{S i m C L R}(\\mathbf{z}^{\\mathbf{A}},\\mathbf{z}^{\\mathbf{B}})=\\mathbb{E}_{\\mathbf{z}^{\\mathbf{A}},\\mathbf{z}^{\\mathbf{B}}}\\Bigg[-\\displaystyle\\sum_{b}\\sin(h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{k}}^{\\mathbf{A}}),h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{k}}^{\\mathbf{B}}))_{i}+}\\\\ &{\\phantom{A A_{\\theta}^{j}(\\mathbf{z}^{\\mathbf{A}})}\\displaystyle\\sum_{b}\\log\\Big(\\sum_{b^{\\prime}\\neq b}\\mathrm{exp}(\\sin(h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{k}}^{\\mathbf{A}}),h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{k}}^{\\mathbf{B}}))_{i})\\Big)\\Bigg]}\\\\ &{\\mathcal{L}_{B a r}(\\mathbf{z}^{\\mathbf{A}},\\mathbf{z}^{\\mathbf{B}})=\\mathbb{E}_{\\mathbf{z}^{\\mathbf{A}},\\mathbf{z}^{\\mathbf{B}}}\\Bigg[\\displaystyle\\sum_{i}\\Big(1-\\sin(h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{A}}^{\\mathbf{A}}),h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{A}}^{\\mathbf{B}}))_{i}\\Big)^{2}+}\\\\ &{\\phantom{A A_{\\theta}^{j}(\\mathbf{z}^{\\mathbf{A}})}\\displaystyle\\lambda\\sum_{i,j\\neq i}\\Bigg(\\sin(h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{A}}^{\\mathbf{A}}),h_{\\theta}^{j}(\\mathbf{z}_{\\mathbf{j}}^{\\mathbf{B}}))_{i}\\Bigg)^{2}\\Bigg]}\\\\ &{\\phantom{A A_{\\theta}^{j}(\\mathbf{z}^{\\mathbf{A}})}\\displaystyle\\times\\mathrm{idisim}(\\mathbf{x},\\mathbf{y})_{i}=\\frac{\\langle\\mathbf{x},\\mathbf{y}\\rangle_{i}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|\\|_{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In these equations, $b$ indexes the sample in a batch, $i$ indexes the vector component of the embeddings, $h_{\\theta}^{I}(\\mathbf{z})$ and $h_{\\theta}^{B}(\\mathbf{z})$ are linear probe stacked on the RAE latent space. In the Barlow regularizer, we use $\\lambda=5\\times10^{-3}$ . For both networks, the linear probe projects in a space of size 128. ", "page_idx": 17}, {"type": "text", "text": "This is important to observe that the scalar product in Eq. 14 is computed along the vector component dimension whereas this is computed along the batch dimension in Eq. 15. Said differently, in Eq. 14 sim computes a square matrix of size (batch size, batch size) (this is a pair-wise similarity matrix between samples) while it is of dimension (feature space dimension, feature space dimension) in Eq. 15 (this is a correlation matrix between vector\u2019s coordinate). We refer the reader to Algo. 3 and Algo. 4 for the pseudo-code of the SimCLR and the Barlow regularizers, respectively. ", "page_idx": 17}, {"type": "text", "text": "Input: dataset $\\mathcal{D}=\\{\\mathbf{x}\\}$ , model parameters $\\pi=(\\theta,\\phi)$ # x: variations   \n1 for $(\\mathbf{x},\\mathbf{y})$ in $\\mathcal{D}$ do   \n2 $\\mathbf{x_{A}}=\\tau^{A}(\\mathbf{x})$ # augment x in xA   \n3 $\\mathbf{x_{B}}=\\boldsymbol{\\tau}^{B}(\\mathbf{x})$ # augment x in $\\mathbf{x}_{\\mathbf{B}}$   \n4 $\\mathbf{z}_{\\mathbf{A}}=q_{\\phi}(\\mathbf{z}_{\\mathbf{A}}|\\mathbf{x}_{\\mathbf{A}})$ # encode xA   \n5 $\\mathbf{z}_{\\mathbf{B}}=q_{\\phi}(\\mathbf{z}_{\\mathbf{B}}\\vert\\mathbf{x}_{\\mathbf{B}})$ # encode xB   \n6 $\\mathcal{L}_{r e g}=\\mathcal{L}_{S i m C L R}(\\mathbf{z_{A}},\\mathbf{z_{B}})$ # see Eq. 14   \n7 $\\tilde{\\mathbf{x}}=p_{\\theta}(\\mathbf{x}|\\mathbf{z_{A}})$ # decode   \n8 $\\mathcal{L}=\\|\\mathbf{x}-\\tilde{\\mathbf{x}}\\|_{2}^{2}+\\mathcal{L}_{r e g}$ \u2202L   \n9 \u03c0 \u2190 \u03c0 ", "page_idx": 18}, {"type": "text", "text": "Algorithm 4: Barlow regularizer pseudo-code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Input: dataset $\\mathcal{D}=\\{\\mathbf{x}\\}$ , model parameters $\\pi=(\\theta,\\phi)$ # x: variations   \n1 for $(\\mathbf{x},\\mathbf{y})$ in $\\mathcal{D}$ do   \n2 $\\mathbf{x_{A}}=\\tau^{A}(\\mathbf{x})$ # augment x in $\\mathbf{x_{A}}$   \n3 $\\mathbf{x_{B}}=\\boldsymbol{\\tau}^{B}(\\mathbf{x})$ # augment x in xB   \n4 $\\mathbf{z}_{\\mathbf{A}}=q_{\\phi}(\\mathbf{z}_{\\mathbf{A}}|\\mathbf{x}_{\\mathbf{A}})$ # encode xA   \n5 $\\mathbf{z}_{\\mathbf{B}}=q_{\\phi}(\\mathbf{z}_{\\mathbf{B}}\\vert\\mathbf{x}_{\\mathbf{B}})$ # encode xB   \n6 $\\mathcal{L}_{r e g}=\\mathcal{L}_{B a r}(\\mathbf{z_{A}},\\mathbf{z_{B}})$ # see Eq. 15   \n7 $\\tilde{\\mathbf{x}}=p_{\\theta}(\\mathbf{x}|\\mathbf{z_{A}})$ # decode   \n8 $\\mathcal{L}=\\|\\mathbf{x}-\\tilde{\\mathbf{x}}\\|_{2}^{2}+\\mathcal{L}_{r e g}$ \u2202L   \n9 \u03c0 \u2190 \u03c0 ", "page_idx": 18}, {"type": "text", "text": "Augmentations: The augmentations we use are the same for both regularizers (i.e. $\\tau^{A}(\\cdot)$ and $\\tau^{B}\\check{(}\\cdot))$ , they are randomly picked among the following transformations: ", "page_idx": 18}, {"type": "text", "text": "\u2022 Random resized crop: with a scale parameter ranging from (0.1, 0.9) and a ratio parameter ranging from (0.8, 1.2). The scale parameter tunes the upper and lower bound of the cropped area, and the ratio parameter defines the lower and upper bound for the aspect of the ratio of the crop.   \n\u2022 Random affine transformation: with a rotation parameter varying from ( $\\mathrm{-15^{\\circ}}$ to $15^{\\circ}$ ), a translation (from $-5$ pixels to 5 pixels), a zoom (with a ratio from 0.75 to 1.25) and a shearing (from $-10^{\\circ}$ to $10^{\\circ}$ )   \n\u2022 Random perspective transformation: apply a scale distortion with a certain probability to simulate 3D transformations. The scale distortion we have chosen is 0.5, and it is applied to the image with a probability of $50\\%$ ", "page_idx": 18}, {"type": "text", "text": "A.3 RAEs training and architectures ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "A.3.1 RAEs architectures ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For the encoder, $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ , and decoder, $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$ , we leverage similar architectures than those proposed in Ghosh et al. [52]. In Table 1 we detail the exact architecture of the RAE encoder and decoder. ", "page_idx": 19}, {"type": "table", "img_path": "tZRpvLXevU/tmp/1323fc61bab696a2f82ddc80802fed138a31f32d8ce4a524dda384fded684892.jpg", "table_caption": [], "table_footnote": ["Table 1: The base architecture for all the autoencoders. "], "page_idx": 19}, {"type": "text", "text": "Note that for Omniglot and QuickDraw, we have chosen different latent-space sizes (denoted $d$ ). For Omniglot $d=64$ and for QuickDraw, $d=128$ . ", "page_idx": 19}, {"type": "text", "text": "A.3.2 RAEs training details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We train the model using the Mean Squared Error loss with a batch size of 128 for the reconstruction, along with different regularizations to study its effects. For both datasets, we use the Adam optimizer [69] with a weight decay of $10^{-5}$ and a learning rate of $10^{-4}$ . The RAEs on the QuickDraw dataset were trained for 200 epochs and 300 epochs on the Omniglot dataset. Note that when trained on the Omniglot dataset, we use a learning rate scheduler in which the learning rate is divided by 4 every 70 epoch. ", "page_idx": 19}, {"type": "text", "text": "In this section, we describe the mathematics behind the latent diffusion models. The following mathematical derivations are mostly derived from Sohl-Dickstein et al. [26], Song and Ermon [25], Ho et al. [47], Rombach et al. [29] and are adapted to match the one-shot generation task and the notations of this paper. Those mathematical derivations are not necessary to understand this article but we include them to make it self-contained. ", "page_idx": 20}, {"type": "text", "text": "Herein, we consider a pretrained Regularized AutoEncoder, with an encoder $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ and decoder $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$ that map the input $\\textbf{x}\\in\\mathbb{R}^{D}$ to a latent representation $\\textbf{z}\\in\\mathbb{R}^{d}$ $d\\ll D)$ ) and inversely, respectively. In the following, we will call indifferently ${\\bf z}$ or $\\mathbf{z_{0}}$ the latent variable corresponding to the input x. We will also call $\\mathbf{z_{y}}$ the latent variable associated with the exemplar y. The goal of a diffusion model in a one-shot latent diffusion algorithm is to learn the conditional probability of $\\mathbf{z}_{\\mathrm{0}}$ given the latent representation of the exemplar $\\mathbf{z}_{y}$ , we call this probability distribution $p_{\\psi}(\\mathbf{z}_{0}|\\mathbf{z}_{y})$ . ", "page_idx": 20}, {"type": "text", "text": "A.4.1 Diffusion process and noising operator in latent diffusion process ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Diffusion models learn the transformation of a pure noise, called $\\mathbf{z_{T}}\\in\\mathbb{R}^{d}$ , into a fully denoised latent representation $\\mathbf{z_{0}}\\in\\mathbb{R}^{d}$ . This transformation is progressive, through a sequence of partially denoised latent representations $\\{\\mathbf{z_{i}}\\}_{i=1}^{T-1}\\in\\mathbb{R}^{d\\times(T-1)}$ . In this sequence $\\mathbf{z_{t+1}}$ is therefore sligthly more noisy than $\\mathbf{z_{t}}$ . The idea behind the diffusion model is to learn the transition probability $p_{\\psi}(\\mathbf{z_{t-1}}|\\mathbf{z_{t}},\\mathbf{z_{y}})$ . To do so, diffusion models introduce a tractable noising process $r(\\mathbf{z_{t}}|\\mathbf{z_{t-1}})$ that gradually injects noise in the latent representation. An illustration of such a directed graphical model is shown in Fig. A.3. ", "page_idx": 20}, {"type": "image", "img_path": "tZRpvLXevU/tmp/2de7b3807de42a8179cf6e9546a6ef558f7a036c8400c4bad285737c6b742c98.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure A.3: The directed graphical model considered in this work. Dotted and plain arrows represent the forward (i.e. noise injection) and the reverse processes (i.e. noise removal), respectively. $\\mathbf{z_{y}}$ and $\\mathbf{z_{0}}$ are the latent representations of the exemplar image y and the image $\\mathbf{x}$ , respectively (exemplified with skull drawings). $\\mathbf{z_{i}}$ corresponds to the sequence of partially corrupted latent representations. $\\mathbf{z_{y}}$ and $\\mathbf{z_{0}}$ are obtained using the RAE encoder $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ and can be mapped to the input space using the RAE decoder $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$ . The \u2018dummy\u2019 distributions located on top of the $\\mathbf{z_{i}}$ variables, illustrate the noise injection process, starting from an \u2018informative\u2019 multimodal distribution to a fully \u2018uninformative\u2019 Gaussian distribution. ", "page_idx": 20}, {"type": "text", "text": "Here we describe, in mathematical terms, the noise injection process : ", "page_idx": 20}, {"type": "equation", "text": "$$\nr(\\mathbf{z}_{1:T}|\\mathbf{z}_{0})=\\prod_{t=1}^{T}r(\\mathbf{z}_{t}|\\mathbf{z}_{t-1})\\ \\ \\mathrm{with}\\ \\ r(\\mathbf{z}_{t}|\\mathbf{z}_{t-1})={\\cal N}(\\mathbf{z}_{t};\\sqrt{1-\\beta_{t}}\\mathbf{z}_{t-1},\\beta_{t}\\mathbf{I})\\ \\mathrm{~s.t.~}\\left\\{\\beta_{t}\\in(0,1)\\right\\}_{i=1}^{T}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In Eq. 17, $\\beta_{t}$ tunes the step size of the diffusion process. Using the successive product of Gaussian, this process could be reduced to a tractable noising operator $\\nu_{t}(.)$ that injects the right amount of noise at time $t$ to obtain $\\mathbf{z_{t}}$ from $\\bf{z}_{0}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{z}_{t}=\\sqrt{\\alpha_{t}}\\mathbf{z}_{t-1}+\\sqrt{1-\\alpha_{t}}\\epsilon\\quad\\mathrm{with}\\quad\\epsilon\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})}\\\\ &{\\quad=\\sqrt{\\alpha_{t}\\alpha_{t-1}}\\mathbf{z}_{t-2}\\sqrt{1-\\alpha_{t}\\alpha_{t-1}}\\epsilon}\\\\ &{\\quad=\\ldots}\\\\ &{\\quad=\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{z}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon=\\nu_{t}(\\mathbf{z_{0}})\\quad\\mathrm{with}\\quad\\alpha_{t}=1-\\beta_{t}\\quad\\mathrm{and}\\quad\\bar{\\alpha}_{t}=\\prod_{i=1}^{t}\\alpha_{t}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "One could then express the probablity of $\\mathbf{z_{t}}$ given $\\mathbf{z_{0}}$ in a closed form: ", "page_idx": 21}, {"type": "equation", "text": "$$\nr(\\mathbf{z}_{t}|\\mathbf{z}_{0})=\\mathcal{N}(\\mathbf{z}_{t};\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{z}_{0},(1-\\bar{\\alpha}_{t})\\mathbf{I})\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The denoising probabilistic process, recovering the latent representation $\\mathbf{z}_{\\mathrm{0}}$ from noise, could be parametrized as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{p_{\\psi}(\\mathbf{z}_{0:T}|\\mathbf{z}_{\\mathbf{y}})=p_{\\psi}(\\mathbf{z}_{T}|\\mathbf{z}_{\\mathbf{y}})\\displaystyle\\prod_{t=1}^{T}p_{\\psi}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{\\mathbf{y}})}\\\\ &{}&{\\mathrm{with~}\\left\\{\\begin{array}{l l}{p_{\\psi}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{\\mathbf{y}})}&{=\\mathcal{N}(\\mathbf{z}_{t};\\mu_{\\psi}(\\mathbf{z}_{t},t,\\mathbf{z}_{\\mathbf{y}}),\\sigma_{t}^{2}\\mathbf{I})}\\\\ {p_{\\psi}(\\mathbf{z}_{T}|\\mathbf{z}_{\\mathbf{y}})}&{=s(\\mathbf{z}_{T})=\\mathcal{N}(\\mathbf{0},\\mathbf{I})}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "A.4.2 Loss of the Denoising Diffusion Probabilistic Model in the Latent Diffusion case ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "As in VAEs [49], the Evidence Lower Bound of the diffusion model could be recovered using Jensen\u2019s inequality [47]: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathbf{z}_{0}\\sim r(\\mathbf{z}_{0})}\\log{p_{\\psi}(\\mathbf{z}_{0}|\\mathbf{z}_{\\mathbf{y}})}=\\mathbb{E}_{\\mathbf{z}_{0}\\sim r(\\mathbf{z}_{0})}\\log{\\big(\\int p_{\\psi}(\\mathbf{z}_{0:T}|\\mathbf{z}_{\\mathbf{y}})d\\mathbf{z}_{1:T}\\big)}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\mathbb{E}_{\\mathbf{z}_{0}\\sim r(\\mathbf{z}_{0})}\\log{\\big(\\int r(\\mathbf{z}_{1:T}|\\mathbf{z}_{0})\\frac{p_{\\psi}(\\mathbf{z}_{0:T}|\\mathbf{z}_{\\mathbf{y}})}{r(\\mathbf{z}_{1:T}|\\mathbf{z}_{0})}d\\mathbf{z}_{1:T}\\big)}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\mathbb{E}_{\\mathbf{z}_{0}\\sim r(\\mathbf{z}_{0})}\\log{\\Bigg(\\mathbb{E}_{\\mathbf{z}_{1:T}\\sim r(\\mathbf{z}_{1:T}|\\mathbf{z}_{0})}\\Big[\\frac{p_{\\psi}(\\mathbf{z}_{0:T}|\\mathbf{z}_{\\mathbf{y}})}{r\\left(\\mathbf{z}_{1:T}|\\mathbf{z}_{0}\\right)}\\Big]\\Bigg)}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\mathbb{E}_{\\mathbf{z}_{0:T}\\sim r(\\mathbf{z}_{0:T})}\\log{\\Big(\\frac{p_{\\psi}\\big(\\mathbf{z}_{0:T}|\\mathbf{z}_{\\mathbf{y}}\\big)}{r\\left(\\mathbf{z}_{1:T}|\\mathbf{z}_{0}\\right)}\\Big)}=-L_{V L B}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The Variational Lower Bound could be written as a sum of $\\mathbb{K L}$ terms [26]: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{L_{V L,L B}=\\mathbb{E}_{r}\\left[\\log_{p}(\\log_{t}\\gamma_{0})\\right]}\\\\ &{=\\mathbb{E}_{r}\\left[\\log_{p}(\\log_{t}\\gamma_{1})\\prod_{j=1}^{r}\\left(r_{j}(\\alpha_{t-1})\\right)\\right.}\\\\ &{\\qquad\\left.=\\mathbb{E}_{r}\\left[\\log_{p}(\\log_{t}\\gamma_{0})\\prod_{j=1}^{r}p_{\\mathbb{I}_{j}}(\\log_{(\\ell-1)\\left\\Vert\\ell_{0},\\ell_{0}\\right\\Vert})\\right]\\ \\ \\mathrm{sup}\\mathbb{E}_{\\mathbf{I}_{0}}\\left(17\\right)\\mathrm{and}\\ (20)}\\\\ &{=\\mathbb{E}_{r}\\left[-\\log_{p}(\\pi_{r})\\gamma_{0}\\right]+\\frac{\\sum_{1=1}^{r}\\log_{p}(\\pi_{r}|\\alpha_{t-1}|)}{\\sum_{1=1}^{r}\\log_{p}(\\log_{t-1}|\\ell_{0},\\ell_{0}|)}\\right]}\\\\ &{=\\mathbb{E}_{r}\\left[-\\log_{p}(\\pi_{r}|\\gamma_{0})\\Big.+\\frac{\\sum_{1=1}^{r}\\log_{p}(\\pi_{r}|\\alpha_{t-1}|)}{p_{\\mathbb{I}_{j}}\\log_{p}(\\log_{t-1}|\\ell_{0},\\ell_{0}|)}+\\log_{\\frac{r}{\\Theta_{0}(\\alpha_{t}|\\alpha_{t},\\ell_{0})}}\\right]}\\\\ &{\\qquad=\\mathbb{E}_{r}\\left[-\\log_{p}(\\pi_{r}|\\gamma_{0})\\Big.+\\frac{\\sum_{1=1}^{r}\\log_{p}(\\pi_{r}|\\alpha_{t-1}|)}{\\sum_{1=2}^{r}\\Big(\\frac{r_{0}(\\ell-1)(\\ell_{1},\\ell_{0},\\ell_{0})}{p_{\\mathbb{I}_{j}}(\\log_{t-1}|\\ell_{0},\\ell_{0}|)}\\Big.\\ \\right.\\mathrm{r}\\left.\\left.\\frac{r(\\alpha_{t}|\\alpha_{t})}{p_{\\mathbb{I}_{j}}(\\alpha_{t})\\ln_{p}(\\log_{t}|\\ell_{1},\\ell_{0}|)}\\right)}\\\\ &{=\\mathbb{E}_{r}\\left[-\\log_{p}(\\pi_{r}|\\gamma_{0\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad=\\mathbb{E}_{r}\\bigg[\\log\\frac{r(\\mathbf{z}_{T}|\\mathbf{z}_{0})}{p_{\\psi}(\\mathbf{z}_{T}|\\mathbf{z}_{\\mathbf{y}})}+\\sum_{t=2}^{T}\\log\\frac{r(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{0})}{p_{\\psi}(\\mathbf{z}_{T-1}|\\mathbf{z}_{t},\\mathbf{z}_{\\mathbf{y}})}-\\log p_{\\psi}(\\mathbf{z}_{0}|\\mathbf{z}_{1},\\mathbf{z}_{\\mathbf{y}})\\bigg]}\\\\ &{=\\mathbb{E}_{r}\\bigg[\\mathbb{K}\\mathbb{L}(r(\\mathbf{z}_{T}|\\mathbf{z}_{0})||p_{\\psi}(\\mathbf{z}_{T}|\\mathbf{z}_{\\mathbf{y}}))+\\sum_{t=2}^{T}K L\\big[r(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{0})||p_{\\psi}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{\\mathbf{y}})\\big]-}\\\\ &{\\log p_{\\psi}(\\mathbf{z}_{0}|\\mathbf{z}_{1},\\mathbf{z}_{y})\\bigg]}\\\\ &{=\\underset{t=0}{\\overset{T}{\\sum}}L_{t}\\quad\\mathrm{with}\\quad\\left\\{\\begin{array}{l l}{L_{0}}&{=-\\mathbb{E}_{r}\\bigg[\\log p_{\\psi}(\\mathbf{z}_{0}|\\mathbf{z}_{1},\\mathbf{z}_{\\mathbf{y}})\\bigg]}\\\\ {L_{t}}&{=\\mathbb{E}_{r}\\bigg[\\mathbb{K}\\mathbb{L}\\big[r(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{0})||p_{\\psi}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{\\mathbf{y}})\\big]\\bigg]}\\\\ {L_{T}}&{=\\mathbb{E}_{r}\\bigg[\\mathbb{K}\\mathbb{L}\\big[r(\\mathbf{z}_{T}|\\mathbf{z}_{0}|\\big|\\mathbf{z}_{\\vartheta}(\\mathbf{z}_{T}|\\mathbf{z}_{\\mathbf{y}})\\big]\\bigg]}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In the previous equations, $\\mathbb{E}_{r}$ is a shortcut notation for $\\mathbb{E}_{\\mathbf{z}_{0:T}\\sim r\\left(\\mathbf{z}_{0:T}\\right)}.$ Note that in the optimization process, $L_{T}$ could be ignored because it doesn\u2019t depend on the model parameter $\\psi$ , this is a pure non-informative Gaussian distribution (see Eq. 22). $L_{0}$ is modeled by Ho et al. [47] using a separate neural network. $L_{t}$ is a $\\mathbb{K L}$ between 2 Gaussians distributions, so it could be calculated with a closed form: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left\\langle\\mathbf{z}_{t-1}|\\mathbf{z}_{t},\\mathbf{z}_{0}\\right\\rangle=\\mathcal{N}(\\mathbf{z}_{t-1};\\tilde{\\mu}_{t}(\\mathbf{z}_{t},\\mathbf{z}_{0}),\\tilde{\\beta}_{t}\\mathbf{I})\\mathrm{~with~}\\left\\{\\begin{array}{l l}{\\tilde{\\mu}_{t}(\\mathbf{z}_{t},\\mathbf{z}_{0})}&{=\\frac{\\sqrt{\\tilde{\\alpha}_{t-1}}\\beta_{t}}{1-\\tilde{\\alpha}_{t}}\\mathbf{z}_{0}+\\frac{\\sqrt{\\tilde{\\alpha}_{t}}\\left(1-\\tilde{\\alpha}_{t-1}\\right)}{1-\\tilde{\\alpha}_{t}}\\mathbf{z}_{t}}\\\\ {\\tilde{\\beta}_{t}}&{=\\frac{1-\\tilde{\\alpha}_{t-1}}{1-\\tilde{\\alpha}_{t}}\\beta_{t}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "With $\\tilde{\\mu}_{t}\\big(\\mathbf{z}_{t},\\mathbf{z}_{0}\\big)$ and $\\tilde{\\beta}_{t}\\mathbf{I}$ the mean and the variance of $r\\big({\\bf z}_{t-1}\\big|{\\bf z}_{t},{\\bf z}_{0}\\big)$ , respectively. Using Eq. 18 we can express $\\mathbf{z}_{\\mathrm{0}}$ in a convenient way: ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\bf z}_{0}=\\frac{1}{\\sqrt{\\bar{\\alpha}}}\\big({\\bf z}_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon\\big)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore on can simplify $\\tilde{\\mu}_{t}(\\mathbf{z}_{t},\\mathbf{z}_{0})$ in Eq. 23: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tilde{\\mu}_{t}(\\mathbf{z}_{t},\\mathbf{z}_{0})=\\tilde{\\mu}_{t}=\\frac{1}{\\sqrt{\\alpha_{t}}}\\Big(\\mathbf{z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon\\Big)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Similarly, we can re-parameterize $p_{\\psi}\\big(\\mathbf z_{t-1}\\big|\\mathbf z_{t},\\mathbf z_{\\mathbf y}\\big)$ because $\\mathbf{z}_{t}$ is available as input at training time: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mu_{\\psi}({\\bf z}_{t},t)=\\frac{1}{\\sqrt{\\alpha_{t}}}\\Big({\\bf z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{\\psi}({\\bf z}_{t},t)\\Big)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "One can apply the closed form formula of the $\\mathbb{K L}$ between 2 gaussians distributions to compute $L_{t}$ in Eq. 22: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal L}_{t}=\\mathbb{E}_{r}\\Bigg[\\frac{1}{2\\left\\|\\sigma_{t}^{2}\\right\\|_{2}^{2}}\\left\\|\\tilde{\\mu}_{t}\\big({\\bf z}_{t},{\\bf z}_{0}\\big)-\\mu_{\\psi}\\big({\\bf z}_{t},t\\big)\\right\\|_{2}^{2}\\Bigg]}}\\\\ {{\\displaystyle~~~=\\mathbb{E}_{r}\\Bigg[\\frac{1}{2\\left\\|\\sigma_{t}^{2}\\right\\|_{2}^{2}}\\left\\|\\frac{1}{\\sqrt{\\alpha_{t}}}\\Big({\\bf z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon\\Big)-\\frac{1}{\\sqrt{\\alpha_{t}}}\\Big({\\bf z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{\\psi}\\big({\\bf z}_{t},t\\big)\\Big)\\right\\|_{2}^{2}\\Bigg]}}\\\\ {{\\displaystyle~~~=\\mathbb{E}_{r}\\Bigg[\\frac{(1-\\alpha_{t})^{2}}{2\\alpha_{t}(1-\\bar{\\alpha}_{t})\\left\\|\\sigma_{t}^{2}\\right\\|_{2}^{2}}\\left\\|\\epsilon-\\epsilon_{\\psi}\\big(\\sqrt{\\bar{\\alpha}_{t}}{\\bf z}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon,t\\big)\\right\\|_{2}^{2}\\Bigg]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "With further simplification of Eq. 27 [47]: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{t}=\\mathbb{E}_{r}\\Big[\\left\\|\\epsilon-\\epsilon_{\\psi}(\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{z}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon,t)\\right\\|_{2}^{2}\\Big]}\\\\ &{\\quad=\\mathbb{E}_{r}\\Big[\\left\\|\\epsilon-\\epsilon_{\\psi}(\\mathbf{z}_{t},t)\\right\\|_{2}^{2}\\Big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "A.4.3 Architecture and Training ", "text_level": 1, "page_idx": 23}, {"type": "table", "img_path": "tZRpvLXevU/tmp/b2fd396873e3a00ecf9c7362a96bb974ee4f0d83e64b2d8fd4bee419392f7f5f.jpg", "table_caption": ["The DDPM model we leverage is a 1D-UNet to perform the diffusion process over the latent embeddings. The architecture of the UNet is described in Table 2: "], "table_footnote": ["Table 2: The neural architecture of the diffusion model used for all experiments unless stated otherwise (the parameter count is shown for the latent size of Quickdraw-FS experiments, ie $d=128)$ ). "], "page_idx": 23}, {"type": "text", "text": "The architectures of the diffusion models for both the Quickdraw-FS and Omniglot datasets are kept identical. The only difference is that the diffusion model is applied on a latent space of size $d=128$ for QuickDraw and of size $d=64$ for Omniglot. The models are trained on a batch size of 128 using the DDPM scheduler for 1000 time steps. $\\beta_{T}$ linearly spanning between $1.5\\times10^{-3}$ and $1.95\\times10^{-2}$ and trained for 1000 epochs. The model is optimized using the AdamW optimizer [70] with an initial learning rate of $10^{-4}$ . Then we use a scheduler in which the learning rate is divided by 10 every 200 epochs. ", "page_idx": 23}, {"type": "text", "text": "A.5 Impact of the regularization on the QuickDraw-FS dataset ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Herein we systematically vary the $\\beta$ parameter in Eq. 1 for each type of regularization and we evaluate its effect using the originality vs. recognizability framework. To visualize this effect while maintaining the order of the hyper-parameters, we use the parametric fit method described in [54]. This technic involves 2 simultaneous parametric fit: i) a polynomial fit (degree 2) between the hyperparameters and the originality values (shown in Fig. A.4b, Fig. A.5b, Fig. A.6b, Fig. A.8b and Fig. A.9b) and ii) another a polynomial fit (degree 2) between the hyperparameters and the recognizability values (shown in Fig. A.4c, Fig. A.5c, Fig. A.6c, Fig. A.8c and Fig. A.9c). Those 2 fits could then be combined to create an oriented parametric fit between the originality and the recognizability (shown in Fig. A.4a, Fig. A.5a, Fig. A.6a, Fig. A.8a and Fig. A.9a). In these curves, the \u201cchevron\u201d indicates the direction in which the value of the $\\beta$ hyperparameter is increased. We have included the range of $\\beta$ we have explored in the caption of each type of regularized LDM. We use the notation $[a:b::c]$ to express that we explored from $a$ to $b$ with a step of $c$ . ", "page_idx": 24}, {"type": "text", "text": "A.5.1 Impact of the KL regularization ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{K L}$ ) in Eq. 2: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\;\\;\\;\\mathrm{s.t.}\\;\\;\\;\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(\\mathbf{.}\\mid\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}\\mid\\mathbf{z})\\right]+\\beta_{K L}\\mathcal{L}_{K L}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "image", "img_path": "tZRpvLXevU/tmp/adfa026515c09461ace0b1b01393cc16ab8f99c5c589254481378e7af8ca26b8.jpg", "img_caption": ["Figure A.4: Impact of the $\\beta_{K L}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{K L}$ in Eq. 30. Herein we have explored the following $\\beta_{K L}$ range : $[10^{-6}\\!:\\!10^{-2}\\!:\\!:\\!10^{-1}]$ and 0.05 and $[0.1:0.5::0.1]$ . "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "A.5.2 Impact of the VQ regularization ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{V Q}$ ) in Eq. 3: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\;\\;\\;\\mathrm{s.t.}\\;\\;\\;\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(\\mathbf{.}\\mid\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}\\mid\\mathbf{z})\\right]+\\beta_{V Q}\\mathcal{L}_{V Q}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "image", "img_path": "tZRpvLXevU/tmp/5f2ff00e85e107394174c85bb56a44c186374d1081e82fd61a55197c43a94a4b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure A.5: Impact of the $\\beta_{V Q}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{V Q}$ in Eq. 31. Herein we have explored the following $\\beta_{V Q}$ range : [1, 2, 5] and [10:50::10] and 100. ", "page_idx": 25}, {"type": "text", "text": "A.5.3 Impact of the $\\mathrm{CL}$ regularization ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{C L}$ ) in Eq. 4: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta\\ _{\\star}}\\mathcal{L}_{R A E}\\ \\ \\mathrm{s.t.}\\ \\ \\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(\\mathbf{.}\\vert\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}\\vert\\mathbf{z})\\right]+\\beta_{C L}\\mathcal{L}_{C L}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "image", "img_path": "tZRpvLXevU/tmp/9d22eb1fe9be227ea35b1dc7eef282d476e3cf678ec7947405ebab70caedf2ec.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure A.6: Impact of the $\\beta_{C L}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{C L}$ in Eq. 32. Herein we have explored the following $\\beta_{C L}$ range : $[0.7{:}0.9{:};0.1]$ and [1:10::1] and $\\left[10\\!:\\!40\\!:\\!:\\!10\\right]$ . ", "page_idx": 25}, {"type": "text", "text": "A.5.4 Impact of the prototype-based regularization ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{P R}$ ) in Eq. 5: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\;\\;\\;\\mathrm{s.t.}\\;\\;\\;\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(\\mathbf{.}\\mid\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}\\mid\\mathbf{z})\\right]+\\beta_{P R}\\mathcal{L}_{P R}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "image", "img_path": "tZRpvLXevU/tmp/3e7436869c7cf17086e2a021ba472345ec142dd901a8ff350128baf3ec12db29.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure A.7: Impact of the $\\beta_{P R}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{P R}$ in Eq. 33. Herein we have explored the following $\\beta_{P R}$ range : $[10^{-4}\\!:\\!10^{-1}\\!:\\!:\\!10^{-1}]$ and $[0.25\\colon\\!0.75\\!:\\!:\\!0.25]$ and $\\left[1.0\\!:\\!10\\!:\\!:\\!1\\right]$ and [15:30::5] and [100, 200, 500]. ", "page_idx": 26}, {"type": "text", "text": "A.5.5 Impact of the SimCLR regularization ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{S i m C L R})$ in Eq. 14: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\quad\\mathrm{s.t.}\\quad\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(.|\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}|\\mathbf{z})\\right]+\\beta_{S i m C L R}\\mathcal{L}_{S i m C L R}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 26}, {"type": "image", "img_path": "tZRpvLXevU/tmp/a69b9f8de1b30e202f1dce4873d4d42f4f1c4039de9663ec7f6d6f631166c1e6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure A.8: Impact of the $\\beta_{S i m C L R}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{S i m C L R}$ in Eq. 34. Herein we have explored the following $\\beta_{S i m C L R}$ range : $[10^{-4}\\!:\\!10^{-1}\\!:\\!:\\!10^{-1}]$ and [1:10::1]. ", "page_idx": 26}, {"type": "text", "text": "A.5.6 Impact of the Barlow regularization ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Herein we evaluate a LDM leveraging a RAE trained with the following loss (with $\\mathcal{L}_{B A R})$ ) in Eq. 15: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\phi}\\mathcal{L}_{R A E}\\quad\\mathrm{s.t.}\\quad\\mathcal{L}_{R A E}=-\\mathbb{E}_{\\mathbf{z}\\sim q_{\\phi}(.|\\mathbf{x})}\\left[\\log p_{\\theta}(\\mathbf{x}|\\mathbf{z})\\right]+\\beta_{B A R}\\mathcal{L}_{B A R}(\\mathbf{z})\n$$", "text_format": "latex", "page_idx": 26}, {"type": "image", "img_path": "tZRpvLXevU/tmp/3b48d3fc46a9279e8ba335fea9ce1c0852b241744fd8a5514b862e54bc3ffb75.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure A.9: Impact of the $\\beta_{B A R}$ hyperparameter on the originality vs. recognizability. Each data point corresponds to a LDM trained with a different value of $\\beta_{B A R}$ in Eq. 35. Herein we have explored the following $\\beta_{B A R}$ range $:$ $\\left[1:10::1\\right]$ and [15:30::5] and [50, 100, 200]. ", "page_idx": 27}, {"type": "image", "img_path": "tZRpvLXevU/tmp/69bc8f47d83deaed3fc82cfd4ca4da0e51c99188552a76551171be8b05f32ce3.jpg", "img_caption": ["A.6 Impact of the regularization on the Omniglot dataset dataset ", "Figure A.10: Effect of increasing the regularization weights on the originality vs recognizability framework (Omniglot dataset). Each data point represents an LDM trained with different values of regularization weights $(\\beta)$ . The curves represent the parametric fits, oriented in the direction of an increase of $\\beta$ . a): For the LDMs with \u201cstandard\u201d regularizers, the $\\beta$ is applied on the KL $\\mathcal{L}_{K L}$ in Eq. 2). b): For the supervised regularizations, the $\\beta$ is applied on the CL ( $\\mathcal{L}_{C L}$ in Eq. 4) or on the prototype-based regularizations $\\mathcal{L}_{P R}$ in Eq. 5). c): For the contrastive regularizations, the $\\beta$ is applied on the SimCLR $\\mathcal{L}_{S i m C L R}$ in Eq. 14) or on the Barlow regularizations $\\mathcal{L}_{B a r}$ in Eq. 15). See A.5 for more information on the range of $\\beta$ we have explored for each regularization. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include a LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality of human drawings (shown with a grey star) "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Here we present a curve similar to Fig. 3 but for LDMs trained on the Omniglot dataset. We were unable to train a VQ-VAE with reasonable performance on this dataset, so we have excluded the VQ-regularized LDM from Fig. A.10. We believe this issue is due to improper hyperparameter tuning as the same regularizer works reasonably well on the QuickDraw-FQ dataset. We are actively working to resolve this problem. ", "page_idx": 28}, {"type": "text", "text": "Except for the VQ regularizer, we observe that all other regularizers follow a similar trend to those trained on the QuickDraw-FS dataset. In particular, the prototype-based and the Barlow regularizers outperform all others. ", "page_idx": 28}, {"type": "text", "text": "A.7 Samples generated by the one-shot LDMs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Here we showcase the images generated by one-shot LDMs. The exemplars used to condition the LDMs are present in top line in the red frame. We randomly chose 10 exemplars from 115 possible options in the QuickDraw-FS test set. All images below the red frame represent samples of the corresponding visual concept generated by the LDM. We use the same 10 exemplars for all the LDMs for easy comparison. All shown exemplar corresponds to the LDMs, for each regularizer, showing the shortest distance to humans. They correspond to larger data points in Fig. 3. ", "page_idx": 28}, {"type": "image", "img_path": "tZRpvLXevU/tmp/729eb94beefc397857563ba29ec70b5d0d4e0663605e79b7bb36bd796521c5a5.jpg", "img_caption": ["Figure A.11: Samples generated by a LDM without regularzation. For this LDM, $\\beta$ is set to 0. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "tZRpvLXevU/tmp/dc1291b97260fc36f2b58de228ca6a82493e7442476fb53ba322185a5969abf2.jpg", "img_caption": ["Figure A.12: Samples generated by LDMs with standard regularizer. a) $\\mathrm{KL}$ regularizer (obtained with $\\beta_{K L}=10^{-5}$ ). b) VQ regularizer (obtained with $\\beta_{V Q}=5$ ). "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "tZRpvLXevU/tmp/d33af2cedc27b757874fe5691b13fe456abaa7a9463ab810338249e7013b2df7.jpg", "img_caption": ["Figure A.13: Samples generated by LDMs with supervised regularizers. a) classification regularizer (obtained with $\\beta_{C L}=5)$ ). b) prototype-based regularizer (obtained with $\\beta_{P R}=5\\cdot10^{2}$ ). "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "tZRpvLXevU/tmp/7a4326e6bea4dd6ecfa7d2c9e7d4ae69e3aafda615538070a4d96c776747a73c.jpg", "img_caption": ["Figure A.14: Samples generated by LDMs with contrastive regularizer. a) $\\operatorname{Sim}\\mathbf{C}\\mathbf{L}\\mathbf{R}$ regularizer (obtained with $\\bar{\\beta_{S i m C L R}}=10^{-2},$ ). b) Barlow regularizer (obtained with $\\beta_{B A R}=30\\$ ). "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "A.8 LDM feature importance maps ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "A.8.1 Mathematics behind the feature importance maps ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We remind that $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$ is the decoder of the RAE, and that $p_{\\psi}(\\mathbf{z_{t-1}}|\\mathbf{z_{t}},\\mathbf{z_{y}})$ is the transition probability learned by the diffustion model. To make the mathematical derivations more concise, we define the following function : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l r l r}{p_{\\theta}:\\mathbb{R}^{d}\\longrightarrow\\mathbb{R}^{D}}&{}&&{\\qquad\\mathrm{and}}&{}&&{p_{\\psi}:\\mathbb{R}^{d}\\longrightarrow\\mathbb{R}^{d}}\\\\ {\\mathbf{z}\\longmapsto\\mathbf{x}=\\log p_{\\theta}(\\cdot|\\mathbf{z})}&{}&&{}&&{\\mathbf{z_{t}}\\longmapsto\\mathbf{z_{t-1}}=\\log p_{\\psi}(\\cdot|\\mathbf{z_{t}},\\mathbf{z_{y}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "To project each intermediate noisy state $\\mathbf{z_{t}}$ into the pixel, we feed them into the decoder. The resulting projection is $\\mathbf{x_{t}}=p_{\\theta,\\psi}(\\mathbf{z_{t}})=p_{\\theta}\\circ p_{\\psi}(\\mathbf{z_{t}})$ ", "page_idx": 31}, {"type": "text", "text": "For each time step of the diffusion process, the importance feature map quantifies how the absolute value of $p_{\\theta,\\psi}(\\mathbf{z_{t}})$ changes when one varies $\\mathbf{z_{t}}$ . $\\phi(\\mathbf{x},\\mathbf{y})$ describes the accumulation, over all time steps, of these \u201clocal feature map\u201d: ", "page_idx": 31}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{\\phi(\\mathbf{x},\\mathbf{y})=\\displaystyle\\sum_{t=0}^{T}{\\left|{\\frac{\\partial p_{\\theta,\\psi}(\\mathbf{z_{t}})}{\\partial\\mathbf{z_{t}}}}\\right|}}\\\\ &{\\qquad=\\displaystyle\\sum_{t=0}^{T}{\\left|{\\frac{\\partial p_{\\theta}\\circ p_{\\psi}(\\mathbf{z_{t}})}{\\partial\\mathbf{z_{t}}}}\\right|}}\\\\ &{\\qquad=\\displaystyle\\sum_{t=0}^{T}{\\left|{\\frac{\\partial p_{\\theta}}{\\partial\\mathbf{x}_{t}}}(p_{\\psi}(\\mathbf{z_{t}})){\\frac{\\partial p_{\\psi}}{\\partial\\mathbf{z_{t}}}}(\\mathbf{z_{t}})\\right|}}\\\\ &{\\qquad=\\displaystyle\\sum_{t=0}^{T}{\\left|J_{p_{\\theta}}(\\mathbf{x_{t}})\\nabla_{\\mathbf{z_{t}}}p_{\\psi}(\\mathbf{z_{t}})\\right|}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "with $J_{p_{\\theta}}(\\mathbf{x_{t}})$ the Jacobian of the function $p_{\\theta}$ w.r.t $\\mathbf{x_{t}}$ computed in $p_{\\psi}(\\mathbf{z_{t}})$ . If we trade the functional notations for probabilistic ones we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\phi(\\mathbf{x},\\mathbf{y})=\\sum_{t=0}^{T}\\left|J_{\\log p_{\\theta}(\\cdot|\\mathbf{z_{t}})}(\\mathbf{x_{t}})\\nabla_{\\mathbf{z_{t}}}\\log p_{\\psi}(\\cdot|\\mathbf{z_{t}},\\mathbf{z_{y}})\\right|\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "A.8.2 Example of LDM feature importance maps ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The LDMs\u2019 feature importance maps have been computed on 25 different categories, for each of the six different regularization methods discussed in the paper. The feature maps were calculated by taking the average of $n=10$ misalignment maps $\\phi(\\mathbf{x},\\mathbf{y})$ as defined in Eq. 9. All shown feature importance maps correspond to the LDMs, for each regularizer, showing the shortest distance to humans. They correspond to larger data points in Fig. 3. ", "page_idx": 32}, {"type": "image", "img_path": "tZRpvLXevU/tmp/1872cbfd02253c4d7a567e48210634ca228448bdc60fc2652b5f569700a15008.jpg", "img_caption": ["Figure A.15: Feature importance maps for LDMs with standard regularizer. a) $\\mathrm{KL}$ regularizer (obtained with $\\beta_{K L}=10^{\\overline{{-}}5}$ ). b) VQ regularizer (obtained with $\\beta_{V Q}=5)$ ). "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "tZRpvLXevU/tmp/c0292ae00e197ceade88a57fe1d08cefd70478cd11f0562f025f008e2e09eb54.jpg", "img_caption": ["Figure A.16: Feature importance maps for LDMs with supervised regularizer. a) classification regularizer (obtained with $\\beta_{C L}=5)$ ). b) prototype-based regularizer (obtained with $\\beta_{P R}=5\\cdot10^{2}_{\\phantom{.}}$ ). "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "tZRpvLXevU/tmp/4aa7c3ec69e018839d5cc4dfcc4ea7d13900de66dc22062ea76d45c1cdcde908.jpg", "img_caption": ["Figure A.17: Feature importance maps for LDMs with contrastive regularizer. a) SimCLR regularizer (obtained with $\\bar{\\beta}_{S i m C L R}=\\bar{1}0^{-2},$ ). b) Barlow regularizer (obtained with $\\beta_{B A R}=30)$ ). "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "A.8.3 Example of Human feature importance maps ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "For comparison, feature importance maps have also been computed for humans for the same 25 categories. For humans, the feature importance maps are heatmaps representing the likelihood of a pixel being selected by a participant as part of the ClickMe-QuickDraw experiment (further details on the experiment provided in App. S of Boutin et al. [30]). The same image used to calculate the misalignment maps for the LDMs is presented to the participants during the CliCkMe-QuickDraw experiment. ", "page_idx": 33}, {"type": "image", "img_path": "tZRpvLXevU/tmp/4a18a897f369797dea39f4dc39d7f8696d921796269a8163802c641599f6ed40.jpg", "img_caption": ["Figure A.18: Feature Importance maps for humans "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Human consistency: To evaluate how humans agree with each other on the feature importance maps, we computed the human consistency. To do so we use a bootstrapping technique. For each category, we divided the participants into 2 populations (randomly selected), obtaining approximately 25 annotations (heatmaps) coming from different participants for each category. We then average those annotations within the same population (and the same category) to form population-wise feature importance maps. We finally compute the human consistency with the Spearman correlation between those population-wise feature importance maps. We obtain a spearman of 0.8845 $\\%<5.10^{-2}\\$ ). ", "page_idx": 33}, {"type": "text", "text": "A.8.4 Pair-wise statistical test for importance feature maps ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "To verify the statistical significance between the human/machine correlation we have obtained for all types of regularized LDMs we use a pair-wise statistical test. In particular, we compute the Wilcoxon signed-rank test between all pairs of LDMs. This test is non-parametric and does not consider the \u201cGaussianity\u201d of the underlying population. The null hypothesis of this test (that could not be rejected when the $p$ -value is over 0.05) is that the two tested populations are sampled from the same distribution. The alternative hypothesis (validated when the $p$ -value is below 0.05) is that the first population ( columns of the Table A.8.4) is stochastically greater than the second population (rows of the Table A.8.4). All $p$ -values, for all pairwise statistical tests are shown in Table A.8.4. ", "page_idx": 34}, {"type": "table", "img_path": "tZRpvLXevU/tmp/5d0d2eb6f886a3ff51babfbfa73de0f01bd0c89c820c9889d3c3a4d706e10ae8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "Importantly those statistical tests have been computed on the Spearman correlation vector (one Spearman value per category) between the feature importance maps of the best-performing models (those indicated with bigger data points in Fig. 3) and those of humans. ", "page_idx": 34}, {"type": "text", "text": "A.8.5 Illustration of the limited one-shot ability of Dall-e ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Herein we illustrate how current Latent Diffusion Models tend to fail at producing faithful variations when prompted with a single image. We showcase some of the generations made by Dall-e 3 when conditioned on a single image of a self-balancing bike. The self-balancing bike is a particularly interesting use case as it represents an \u2019unusual\u2019 vehicle that is unlikely to belong to the Dall-e 3 training database. You can observe that Dall-e generates images missing some of the key concepts of the self-balancing bike (i.e. one-wheel). ", "page_idx": 34}, {"type": "image", "img_path": "tZRpvLXevU/tmp/0fe957f99934d619da0548db866d8e7f55c79907ad593fabe167c7780d4d86f1.jpg", "img_caption": ["Figure A.19: Examples of variations generated by Dall-e 3 when prompted with a single image of a self-balancing bike "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "A.8.6 Potential limitations ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "In this article, we tested six representational inductive biases, a small number considering the extensive range available in the representation-learning literature. This field encompasses hundreds of inductive biases that have proven successful in one-shot classification tasks. Therefore, other representational inductive biases might align better with human performance, both in terms of sample similarity and visual strategy. Our goal wasn\u2019t to test all possible biases but to demonstrate that some of them can significantly narrow the gap with humans in one-shot drawing tasks. ", "page_idx": 35}, {"type": "text", "text": "Another limitation of this article lies in the recognizability vs. originality framework we are using to evaluate the drawings. This framework leverages 2 critic networks to evaluate the sample\u2019s originality and recognizability. There\u2019s no guarantee these networks align with human perceptual judgments. Thus, the recognizability and originality scores might not reflect human perception accurately. However, since both human and model outputs are evaluated using the same pre-trained critic networks, the comparison remains fair. ", "page_idx": 35}, {"type": "text", "text": "Our approach leveraged two-stage generative models: the first stage compresses information and shapes the latent distribution with representational inductive biases (the RAE), and the second stage learns this latent distribution (the diffusion model). This type of architecture takes longer to train because it requires two separate training procedures. However, this limitation could be overcome by using an end-to-end training procedure for Latent Diffusion Models, which could streamline the process [71]. ", "page_idx": 35}, {"type": "text", "text": "A.8.7 Computational Resources ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "All the experiments of this paper have been performed using Quadro-RTX600 GPUs with 16 GB memory. The training time for the RAE is approximately 24 hours and 72 hours for the Diffusion model (96 hours overall). Note that as we have explored a large range of hyperparameters for all types of regularization, our paper is relatively extensive in terms of computations (600 models have been trained overall, but just a small part of them have been used in this article). ", "page_idx": 35}, {"type": "text", "text": "A.8.8 Broader Impact ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "This work does not present any foreseeable negative societal consequences. We think the societal impact of this work is positive. It might help the neuroscience community to evaluate the different mechanisms that allow human-level generalization and then better understand the brain. ", "page_idx": 35}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our main claim is that representational inductive biases in LDMs help to close the gap with humans on the one-shot drawing task. This claim is experimentally verified in Fig. 3 and Fig. 5. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 36}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We have discussed the limitations in the supplementary information (see section A.8.6). There are 3 main limitations. First, the originality vs. recognizability framework might not be aligned with human perceptual judgment. Second, the long training time of 2-stages latent diffusion models prevents the wide adoption of the representational inductive biases we propose in this paper. Third, we have tested a limited number of regularizers, so other regularization techniques might be even better aligned with humans. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 36}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 37}, {"type": "text", "text": "Justification: We do not have theoretical results. This article is mainly experimental. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 37}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: In the Appendix and the main text, we have extensively described the experiments we have run. In particular, in section A.2 we describe the models we use as well as their hyperparameters. We go even further by releasing the code to reproduce our experiments: http://anonymous.4open.science/r/LatentMatters-526B. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 37}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The databases we use are already in open access. The code we used to train the LDMs is available on an anonymous GitHub link (http://anonymous.4open.science/ r/LatentMatters-526B). We cannot release the human data we have leveraged because we did not collect them. We invite interested people to send mail to the authors of [30] if they are interested in human data (the authors are open to sharing their data). ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in the supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 38}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: We extensively describe the databases we use as well as hyperparameter training details in section A.2 and section A.1. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 38}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We report error bars and pair-wise statistical tests on Fig. 5 (see A.8.4). Note that we did not compute error bars for Fig. 3 as our analysis relies on a fit made on tens of models. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: In the Appendix (see App. A.8.7) we describe the type of hardware we use to train the models, the training time for each model, and the total number of runs we spent to publish this paper. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 39}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: We believe we conform with the NeurIPS code of ethics in every aspect. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 39}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: We have included a broader impact section in App. A.8.8, but we do not foresee any notable societal impact. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 40}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: We don\u2019t think our work poses a significant risk. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 40}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: We use the Quickdraw database (under CC BY 4.0 license). We also used Omniglot, which is under the MIT license. We credit the creator of these assets by citing them when we introduced the databases. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 41}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: Our only new asset is the code that allows us to run all our experiments. This code is available publicly and is under the MIT license. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 41}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: We have not conducted any psychophysics experiments. However, we use human data collected by other researchers. The protocol to collect those data is extensively in their article (appendix S of [30]). ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 41}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: We have not conducted any psychophysical experiments. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]