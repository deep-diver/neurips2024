{"references": [{"fullname_first_author": "Nicolas Carion", "paper_title": "End-to-End Object Detection with Transformers", "publication_date": "2020-00-00", "reason": "This paper introduces DETR, a foundational model for the query-based object detection approach that the current paper builds upon."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper introduces DINOv2, a self-supervised vision transformer model used as a foundation model in the current work, demonstrating strong image understanding capabilities."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, another foundation model leveraged in the current research, showcasing its effectiveness in transferring knowledge from image-text pairings."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces MAE, a self-supervised learning method for training vision transformers that is used for comparison in the current paper."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "DeiT III: Revenge of the ViT", "publication_date": "2022-00-00", "reason": "This paper introduces DeiT-III, a supervised vision transformer model used as a foundation model in the current paper, showing high performance in image classification."}]}