[{"figure_path": "wblxm5zdkE/tables/tables_9_1.jpg", "caption": "Table 1: Average values with candidate dataset and income dataset: FSR(Tm), ES(Tm) (\u00d710\u22123) and stopping time Tm. The target FSR level is \u03b1 = 0.2 for both. For the candidate data, the target ES level K = 1 \u00d7 10\u22123; For the income data, K = 6 \u00d7 10\u22123. The bracket contains the standard error.", "description": "This table presents the results of the II-COS, SAST, and CP methods applied to two real-world datasets: a candidate dataset and an income dataset.  It shows the False Selection Rate (FSR), Expected Similarity (ES), and stopping time (Tm) for each method across 500 replications.  The target FSR level was 0.2 for both datasets. The target ES level was 1 x 10^-3 for the candidate dataset and 6 x 10^-3 for the income dataset.  Standard errors are reported in parentheses.", "section": "4.2 Results on Real Data"}, {"figure_path": "wblxm5zdkE/tables/tables_15_1.jpg", "caption": "Table 2: A comparison of FDP in offline methods v.s. online methods for FDR control.", "description": "This table compares different methods for controlling the False Discovery Rate (FDR), both offline and online.  It shows the formulas used for estimating the False Discovery Proportion (FDP) for each method, highlighting the key differences in how they adjust for multiple testing in offline versus online settings.  The offline methods are Storey-BH and BH, while the online methods are LOND, SAFFRON, and ADDIS. The formulas illustrate how each method dynamically adapts its thresholds for rejecting hypotheses, balancing the trade-off between controlling the FDR and maximizing the number of true discoveries.", "section": "Implementation Details of Algorithms"}, {"figure_path": "wblxm5zdkE/tables/tables_18_1.jpg", "caption": "Table 3: Results of flexible choice of \u03b1 and K for the classification example. Average values among 500 repetitions: FSR(\u03b4Tm), ES(\u03b4Tm) and stopping time Tm.", "description": "This table shows the results of an experiment to illustrate the flexibility of the II-COS procedure in terms of adjusting the individual and interactive constraint levels.  It presents the average false selection rate (FSR), expected similarity (ES), and stopping time (Tm) for different combinations of \u03b1 and K, which represent the individual and interactive constraint levels respectively. By changing these parameters, one can control the trade-off between the two types of constraints and stopping time.", "section": "4 Experiments and Evaluation"}, {"figure_path": "wblxm5zdkE/tables/tables_18_2.jpg", "caption": "Table 4: Average number of selected samples when stopping for II-COS, LOND, SAFFRON and ADDIS.", "description": "This table presents a comparison of the number of samples selected by the II-COS method and three other online FDR control methods (LOND, SAFFRON, ADDIS) under different calibration sizes (ncal) in both classification and regression settings. The stopping rule is to select m=100 samples.  The results show that II-COS consistently selects the target number of 100 samples, unlike the other methods which often select fewer samples, especially when the calibration size is small. The under-selection is more prominent in the regression setting than in the classification setting.", "section": "4 Experiments and Evaluation"}, {"figure_path": "wblxm5zdkE/tables/tables_18_3.jpg", "caption": "Table 5: Average values of FSR(Tm)(%) and ES(Tm)(\u00d710\u22122) (with standard errors in parentheses) for II-COS with different ncal under classification setting (\u03b1 = 10%, K = 4.50 \u00d7 10\u00af\u00b2) and regression setting (\u03b1 = 10%, K = 1.50 \u00d7 10\u00af\u00b2).", "description": "This table presents the average values of the False Selection Rate (FSR) and Expected Similarity (ES) at the stopping time Tm for the II-COS method under different calibration sizes (ncal).  It shows the performance of II-COS in controlling both individual and interactive constraints for both classification and regression settings when the calibration set size varies from 200 to 800. The results demonstrate that II-COS effectively maintains the FSR and ES levels across different calibration sizes.", "section": "D.3 Effects of the Calibration Size"}, {"figure_path": "wblxm5zdkE/tables/tables_21_1.jpg", "caption": "Table 1: Average values with candidate dataset and income dataset: FSR(Tm), ES(Tm) (\u00d710\u22123) and stopping time Tm. The target FSR level is a = 0.2 for both. For the candidate data, the target ES level K = 1 \u00d7 10\u22123; For the income data, K = 6 \u00d7 10\u22123. The bracket contains the standard error.", "description": "This table presents the results of the II-COS, SAST, and CP methods on two real-world datasets: a candidate dataset and an income dataset.  The table shows the average values (across 500 repetitions) for the False Selection Rate (FSR), Expected Similarity (ES), and stopping time (Tm) for each method on each dataset.  The target FSR level (\u03b1) is 0.2 for both datasets, but the target ES level (K) differs: 1 x 10^-3 for the candidate dataset and 6 x 10^-3 for the income dataset. Standard errors are included in parentheses for each value.", "section": "4.2 Results on Real Data"}, {"figure_path": "wblxm5zdkE/tables/tables_21_2.jpg", "caption": "Table 7: FSR(Tm), ES(Tm) (\u00d710\u22122) and Tm of the II-COS and the oracle procedure under classification model.", "description": "This table presents the results of comparing the proposed II-COS method with an oracle method which knows the true state 0t in advance. The experiment is conducted under a classification setting.  The table shows the False Selection Rate (FSR), Expected Similarity (ES), and the stopping time (Tm) for both II-COS and the oracle method.  The oracle method serves as a benchmark for evaluating the efficiency of II-COS.", "section": "Experiments for the comparison with oracle procedure"}]