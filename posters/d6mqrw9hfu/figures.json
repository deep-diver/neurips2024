[{"figure_path": "D6MQrw9HFu/figures/figures_1_1.jpg", "caption": "Figure 1: Motivation of FOOGD. The distributions of two clients are non-IID, and we seek to estimate the global distribution among decentralized data.", "description": "This figure illustrates the core idea behind the FOOGD method.  It shows three plots representing the data distributions of two individual clients (Client 1 and Client 2) and the combined global distribution. Each plot displays data points categorized as IN (in-distribution), IN-C (in-distribution covariate shift), and OUT (out-of-distribution). The non-IID nature of the client distributions is evident, as each client has a different distribution of data points. The global distribution, in the center, aims to consolidate the information from both clients to provide a reliable and combined view of the overall data distribution for guiding the subsequent federated learning process.", "section": "1 Introduction"}, {"figure_path": "D6MQrw9HFu/figures/figures_3_1.jpg", "caption": "Figure 2: Framework of FOOGD. For each client, we have main task feature extractor, a SM3D module estimates score model (Eq. (8)) for detection, and a SAG module regularizes feature extractor for enhancing generalization. The server aggregates models and obtains global distribution.", "description": "The figure illustrates the FOOGD framework. Each client has a feature extractor for the main task, a SM3D module for OOD detection (estimating the score model using score matching and MMD), and a SAG module for OOD generalization (regularizing the feature extractor using Stein's identity). The server aggregates the models from all clients to obtain a global distribution.  The SM3D module generates samples to estimate the score function, which helps in identifying OOD data points in low-density areas. SAG aligns features from original and augmented data, helping to generalize better to covariate shift.", "section": "3. Methodology"}, {"figure_path": "D6MQrw9HFu/figures/figures_4_1.jpg", "caption": "Figure 3: Motivation of SM\u00b3D. Red points are sampled from target data distribution, and the blue points are generated by LDS in Eq. (6).", "description": "This figure illustrates the motivation behind the SM\u00b3D method. It shows how SM\u00b3D generates samples from a wider feature space to improve density estimation by leveraging Langevin dynamic sampling (LDS). The red points represent samples from the true data distribution, and the blue points represent samples generated by the LDS process. The different subfigures (a) to (d) show the results obtained with different values of \u03bbm, a trade-off coefficient that balances between score matching and maximum mean discrepancy (MMD). The results show how varying \u03bbm affects the density estimation, with \u03bbm = 0.1 providing the best balance between accuracy and coverage of the data distribution.", "section": "3.2 SM\u00b3D: Estimating Score Model for Detection"}, {"figure_path": "D6MQrw9HFu/figures/figures_7_1.jpg", "caption": "Figure 4: T-SNE visualizations of FedAvg and FedRod with FOOGD.", "description": "This figure uses t-distributed stochastic neighbor embedding (t-SNE) to visualize the data representations learned by four different federated learning methods: FedATOL, FedAvg+FOOGD, FedTHE, and FedRod+FOOGD.  Each point represents a data sample, colored according to its class (IN, IN-C, or OUT). The visualizations illustrate how the different methods separate the three classes in the feature space.  FOOGD is shown to improve the separation between the classes compared to baselines, indicating enhanced generalization and OOD detection capabilities.", "section": "5.2 Experimental Results"}, {"figure_path": "D6MQrw9HFu/figures/figures_8_1.jpg", "caption": "Figure 5: Detection score distribution of FL methods on Cifar10 (\u03b1 = 5.0).", "description": "This figure visualizes the distribution of detection scores produced by four different federated learning methods on the CIFAR-10 dataset, where \u03b1=5.0 represents a relatively high degree of heterogeneity among client data distributions.  The methods compared are FedATOL, FedAvg+FOOGD, FedTHE, and FedRod+FOOGD.  The x-axis shows the detection scores and the y-axis represents the probability density. Each curve represents the distribution for in-distribution (IN), in-distribution covariate-shift (IN-C), and out-of-distribution (OUT) data. The figure helps illustrate how well each method separates IN, IN-C, and OUT data,  indicating the effectiveness of the FOOGD framework in enhancing both generalization and detection capabilities for federated learning in the presence of wild data.", "section": "5.2 Experimental Results"}, {"figure_path": "D6MQrw9HFu/figures/figures_23_1.jpg", "caption": "Figure 3: Motivation of SM\u00b3D. Red points are sampled from target data distribution, and the blue points are generated by LDS in Eq. (6).", "description": "This figure shows the motivation behind using Langevin dynamic sampling (LDS) in the SM\u00b3D module of FOOGD.  The red points represent samples from the true data distribution, while the blue points are generated using LDS, starting from random noise and iteratively updating based on the score model.  The goal is to ensure that the generated samples broadly explore the feature space to mitigate issues associated with sparse or multimodal data when directly applying score matching, thereby improving the reliability of the density estimation.", "section": "3.2 SM\u00b3D: Estimating Score Model for Detection"}, {"figure_path": "D6MQrw9HFu/figures/figures_23_2.jpg", "caption": "Figure 8: T-SNE visualizations of FedAvg and FedRod with FOOGD.", "description": "This figure shows the t-distributed stochastic neighbor embedding (t-SNE) visualizations of the feature representations from FedAvg, FedRod, and their corresponding versions combined with FOOGD.  The visualizations illustrate the clustering of in-distribution (IN), in-distribution covariate-shift (IN-C), and out-of-distribution (OUT) data points in the feature space.  The goal is to demonstrate how FOOGD improves the separation and clustering of these data types compared to the baseline methods.", "section": "3. Methodology"}, {"figure_path": "D6MQrw9HFu/figures/figures_24_1.jpg", "caption": "Figure 5: Detection score distribution of FL methods on Cifar10 (\u03b1 = 5.0).", "description": "This figure visualizes the distribution of detection scores for different data types (IN, IN-C, OUT) using four different federated learning methods: FedATOL, FedAvg+FOOGD, FedTHE, and FedRod+FOOGD.  The x-axis represents the detection score, and the y-axis represents the density.  The distributions show how well each method separates in-distribution (IN) and in-distribution covariate shift (IN-C) data from out-of-distribution (OUT) data.  FOOGD methods clearly show better separation of OUT data from IN and IN-C data compared to the baseline methods. The figure illustrates the effectiveness of the FOOGD framework in improving the detection of out-of-distribution data.", "section": "3.3 SAG: Enhancing Feature Extractor for Generalization"}, {"figure_path": "D6MQrw9HFu/figures/figures_25_1.jpg", "caption": "Figure 10: Effect of participating clients numbers K.", "description": "This figure shows the impact of the number of participating clients (K) on the performance of Fed-ATOL and FedAvg+FOOGD.  Subfigures (a) and (b) illustrate the accuracy on in-distribution (IN) and covariate-shift (IN-C) data, respectively.  (c) and (d) display the false positive rate at 95% true positive rate (FPR95) and the area under the receiver operating characteristic curve (AUROC) for out-of-distribution (OUT) data detection.  The results suggest that increasing the number of clients generally improves performance, but the effect is more pronounced for FedAvg+FOOGD, particularly in terms of OUT data detection.", "section": "5.2 Experimental Results"}, {"figure_path": "D6MQrw9HFu/figures/figures_25_2.jpg", "caption": "Figure 11: Effect of \u03bbm and \u03bb\u03b1.", "description": "This figure shows the impact of hyperparameters \u03bbm and \u03bb\u03b1 on the performance of the FOOGD model.  \u03bbm is the trade-off coefficient between score matching and maximum mean discrepancy (MMD) loss in the SM\u00b3D module, balancing the exploration of the feature space with the accuracy of density estimation.  \u03bb\u03b1 is the regularization strength in the SAG module, controlling the alignment between original and augmented features for generalization.  The plots illustrate how varying these parameters affects the AUROC score (a), FPR95 (b), and both IN and IN-C accuracies (c) on a Cifar-10 dataset, demonstrating the optimal parameter settings for balancing detection and generalization.", "section": "5 Experiments"}, {"figure_path": "D6MQrw9HFu/figures/figures_26_1.jpg", "caption": "Figure 10: Effect of participating clients numbers K.", "description": "This figure shows the impact of the number of participating clients (K) on the performance of different federated learning methods for in-distribution (IN) and out-of-distribution (OOD) data.  The plots illustrate the accuracy for IN and IN-C data (measuring generalization), and the false positive rate at 95% true positive rate (FPR95) and area under the ROC curve (AUROC) for OOD detection.  It demonstrates how the performance of various algorithms, including FOOGD, changes as the number of clients increases.", "section": "5 Experiments"}]