[{"figure_path": "Gcks157FI3/figures/figures_0_1.jpg", "caption": "Figure 2: Mesh Representation. We present the Neural Coordinate Field (NeurCF) to encode the discretized coordinates in the Euclidean space. Benefiting from NeurCF and a pre-defined ordering strategy, our proposed MeshXL can directly generate the unstructured 3D mesh auto-regressively.", "description": "This figure illustrates the MeshXL's mesh representation method using Neural Coordinate Fields (NeurCF).  NeurCF encodes 3D coordinates implicitly using neural embeddings, allowing for efficient representation of mesh data. A pre-defined ordering strategy enables autoregressive generation of unstructured 3D meshes directly, eliminating the need for intermediate representations.", "section": "4 Neural Coordinate Field"}, {"figure_path": "Gcks157FI3/figures/figures_3_1.jpg", "caption": "Figure 2: Mesh Representation. We present the Neural Coordinate Field (NeurCF) to encode the discretized coordinates in the Euclidean space. Benefiting from NeurCF and a pre-defined ordering strategy, our proposed MeshXL can directly generate the unstructured 3D mesh auto-regressively.", "description": "This figure illustrates the Neural Coordinate Field (NeurCF) and how it is used in MeshXL for autoregressive 3D mesh generation.  (a) shows NeurCF encoding the 3D mesh by embedding each discretized coordinate (x, y, z) using an embedding layer E, forming a face embedding Eface and finally a mesh embedding Emesh.  (b) depicts the autoregressive generation process; MeshXL predicts the next coordinate based on the previously generated coordinates to produce the complete 3D mesh sequentially.", "section": "4 Neural Coordinate Field"}, {"figure_path": "Gcks157FI3/figures/figures_4_1.jpg", "caption": "Figure 3: Training and Validation Perplexity (PPL) for MeshXL Models. We train all the models from scratch on 150 billion tokens. We observe that the performance grows with model sizes.", "description": "This figure shows the training and validation perplexity (PPL) for MeshXL models of different sizes (125M, 350M, and 1.3B parameters).  The models were trained from scratch using 150 billion tokens.  The plots demonstrate that as model size increases, both training and validation PPL decrease, indicating improved performance and generalization ability.", "section": "Experiments"}, {"figure_path": "Gcks157FI3/figures/figures_7_1.jpg", "caption": "Figure 4: Evaluation of Partial Mesh Completion. Given some partial observation of the 3D mesh (white), MeshXL is able to produce diverse object completion results (blue).", "description": "This figure showcases the MeshXL model's ability to complete partially observed 3D meshes.  The left column shows the incomplete input meshes (in white). The central columns display several different completed meshes generated by MeshXL (in blue).  The right column shows the corresponding ground truth complete meshes (in green). This demonstrates MeshXL's capacity to generate plausible and varied completions based on incomplete input data.", "section": "6 Experiments"}, {"figure_path": "Gcks157FI3/figures/figures_8_1.jpg", "caption": "Figure 5: Evaluation of X-to-mesh generation. We show that MeshXL can generate high-quality 3D meshes given the corresponding image or text as the additional inputs.", "description": "This figure demonstrates the capability of the MeshXL model to generate 3D meshes conditioned on either image or text inputs.  It shows three examples: a laptop, a computer monitor, and a vase. For each example, the input image or text prompt is shown alongside the generated 3D mesh and a ground truth 3D mesh for comparison. The results highlight MeshXL's ability to produce high-quality 3D models that align well with the given input.", "section": "X-to-Mesh Generation"}, {"figure_path": "Gcks157FI3/figures/figures_8_2.jpg", "caption": "Figure 6: Texture Generation for the Generated 3D Meshes. We adopt Paint3D [91] to generate textures for 3D meshes produced by MeshXL.", "description": "This figure shows the results of applying a texture generation pipeline (Paint3D) to 3D meshes generated by the MeshXL model.  It demonstrates that the generated meshes are compatible with existing texturing methods, resulting in high-quality textured 3D assets. Each row displays a generated mesh, the same mesh after texturing is applied, and the UV map used in the texturing process.", "section": "6.4 Visualizations"}, {"figure_path": "Gcks157FI3/figures/figures_9_1.jpg", "caption": "Figure 7: Qualitative comparisons. We visualize the generated meshes and normal vectors. MeshXL is able to produce high-quality 3D meshes with both sharp edges and smooth surfaces.", "description": "This figure presents a qualitative comparison of 3D mesh generation results from four different methods: PolyGen, GET3D, MeshGPT, and MeshXL.  For each method, sample outputs of chair and table models are shown, with a visualization of their normal vectors. The comparison highlights MeshXL's ability to generate high-quality meshes with both sharp edges and smooth surfaces, contrasting it with the other methods which sometimes produce meshes with less refined details or smoother surfaces.", "section": "6 Experiments"}, {"figure_path": "Gcks157FI3/figures/figures_16_1.jpg", "caption": "Figure 8: Gallery results. Additional generation results for chair, table, lamp, and bench.", "description": "This figure shows a gallery of additional 3D mesh generation results produced by the MeshXL model. The results demonstrate the model's ability to generate diverse and high-quality 3D meshes for various object categories, including chairs, tables, lamps, and benches.", "section": "A.1 More Visualization Results"}, {"figure_path": "Gcks157FI3/figures/figures_17_1.jpg", "caption": "Figure 9: Gallery results. MeshXL is able to produce diverse 3D meshes with high quality.", "description": "This figure shows a gallery of 3D meshes generated by the MeshXL model.  The variety of shapes and styles demonstrates the model's ability to produce diverse and high-quality outputs, ranging from simple objects to more complex structures. This visual representation highlights the model's capability in generating realistic and detailed 3D models.", "section": "A.1 More Visualization Results"}]