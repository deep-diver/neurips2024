[{"type": "text", "text": "Credal Learning Theory ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Michele Caprio Department of Computer Science   \nUniversity of Manchester, Manchester, UK   \nmichele.caprio@manchester.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Maryam Sultana Eleni G. Elia Fabio Cuzzolin School of Engineering Computing & Mathematics Oxford Brookes University, Oxford, UK {msultana,eelia,fabio.cuzzolin}@brookes.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learned from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a \u2018credal\u2019 theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not), as well as infinite model spaces, which directly generalize classical results. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Statistical Learning Theory (SLT) considers the problem of predicting an output $y\\,\\in\\,\\mathcal{V}$ given an input $x\\,\\in\\,{\\mathcal{X}}$ using a mapping $h:\\mathcal{X}\\rightarrow\\mathcal{Y}$ , $h\\in\\mathcal H$ , called model or hypothesis, belonging to a model (or hypotheses) space $\\mathcal{H}$ . The loss function $l:\\,(\\mathcal{X}\\times\\mathcal{Y})\\times\\mathcal{H}\\to\\mathbb{R}$ measures the error committed by a model $h\\in\\mathcal H$ . For instance, the zero-one loss is defined as $l((x,y),h)\\doteq$ $\\mathbb{I}[y\\neq h(x)]$ , where $\\mathbb{I}$ denotes the indicator function, and assigns a zero value to correct predictions and one to incorrect ones. Input-output pairs are usually assumed to be generated i.i.d. by a probability distribution $P^{\\star}$ , which is unknown. The expected risk \u2013 or expected loss \u2013 of the model $h$ , $\\begin{array}{r}{L(h)\\equiv\\dot{L}_{P^{\\star}}(h)\\doteq\\mathbb{E}_{P^{\\star}}[l((x,y),h)]=\\int_{\\mathcal{X}\\times\\mathcal{Y}}l((x,y),h)P^{\\star}(\\mathrm{d}(x,y))}\\end{array}$ , measures the expected value \u2013 taken with respect to $P^{\\star}$ \u2013 of loss $l$ . The expected risk minimizer $h^{\\star}\\in\\arg\\operatorname*{min}_{h\\in\\mathcal{H}}L(h)$ is any hypothesis in the given model space $\\mathcal{H}$ that minimizes the expected risk. Given a training dataset $\\bar{D}=\\{(x_{1},y_{1}),\\dots,(x_{n},y_{n})\\}$ whose elements are drawn independently and identically distributed (i.i.d.) from probability distribution $P^{\\star}$ , the empirical risk of a hypothesis $h$ is the average loss over $D$ . The empirical risk minimizer (ERM), i.e., the model $\\hat{h}$ one actually learns from the training set $D$ , is the one minimizing the empirical risk [44]. Statistical Learning Theory seeks upper bounds for the expected risk $L(\\hat{h})$ of the ERM $\\hat{h}$ , and in turn, for the excess risk, that is, the difference between $L(\\hat{h})$ and the lowest expected risk $L(h^{\\star})$ . This endeavor is pursued under increasingly more relaxed assumptions about the nature of the hypotheses space $\\mathcal{H}$ . Two common such assumptions are that either the model space is finite, or that there exists a model with zero expected risk (realizability). ", "page_idx": 0}, {"type": "text", "text": "In real-world situations, however, the data distribution may (and often does) vary, causing issues of domain adaptation (DA) [11] or generalization (DG) [59]. Domain adaptation and generalization are interrelated yet distinctive concepts in machine learning, as they both deal with the challenges of transferring knowledge across different domains. The main goal of DA is to adapt a machine learning model trained on source domains to perform well on target domains. In opposition, DG aims to train a model that can generalize well to unseen data/domains not available during training. In simple terms, DA works on the assumption that our source and target domains are related to each other, meaning that they somehow follow a similar data-generating probability distribution. DG, instead, assumes that the trained model should be able to handle unseen target data. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Attempts to derive generalization bounds under more realistic conditions within classical SLT have been made (see Section 2). Those approaches, however, are characterized by a lack of generalizability, and the use of strong assumptions. A more detailed account of the state of the art and their limitations is discussed in Section 2. In opposition to all such proposals, our learning framework leverages Imprecise Probabilities (IPs) to provide a radically different solution to the construction of bounds in learning theory. ", "page_idx": 1}, {"type": "text", "text": "A hierarchy of formalisms aimed at mathematically modeling the \u2018epistemic\u2019 uncertainty induced by sources such as lack of data, missing data or data which is imprecise in nature [24, 62, 63], IPs have been successfully employed in the design of neural networks providing both better accuracy and uncertainty quantification to predictions [17, 47\u201349, 64, 73]. To date, however, they have never been considered as a tool to address the foundational issues of statistical learning theory associated with data drifting. ", "page_idx": 1}, {"type": "text", "text": "Contributions. This paper provides two innovative contributions: (1) the formal definition of a new learning setting in which models are inferred from a (finite) sample of training sets (via either objectivist or subjectivist modeling techniques, as explained in Section 3), rather than a single training set, each assumed to have been generated by a single data distribution (as in classical SLT); (2) the derivation of generalization bounds to the expected risk of a model learned in this new learning setting, under the assumption that the epistemic uncertainty induced by the available training sets can be described by a credal set [41], i.e., a convex set of (data generating) probability distributions. ", "page_idx": 1}, {"type": "text", "text": "The overall framework is illustrated in Figure 1. Generalized upper bounds under credal uncertainty are derived under three increasingly realistic sets of assumptions, mirroring classical statistical learning theory treatment: (i) finite hypotheses spaces with realizability, (ii) finite hypotheses spaces without realizability, and (iii) infinite hypotheses spaces. We show that the corresponding classical results in SLT are special cases of the ones derived in the present paper. ", "page_idx": 1}, {"type": "image", "img_path": "AH5KwUSsln/tmp/a8a28ebbbb987b1182f43302afc009f573c785ddff2f0054088fc1ce698faa94.jpg", "img_caption": [], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: Graphical representation of the proposed learning framework. Given an available finite sample of training sets, each assumed to be generated by a single data distribution, one can learn a credal set $\\mathcal{P}$ of data distributions in either a frequentist or subjectivist fashion (Section 3). This allows us to derive generalization bounds under credal uncertainty (Section 4). ", "page_idx": 1}, {"type": "text", "text": "Paper outline. The paper is structured as follows. First (Section 2) we present the existing work addressing data distribution shifts in learning theory. We then introduce our new learning framework (Section 3). In Section 4 we illustrate the bounds derived under credal uncertainty and show how classical results can be recovered as special cases. Section 5 concludes and outlines future undertakings. We prove our results in Appendix A, and we provide synthetic experiments on our first two main results (Theorems 4.1 and 4.5) in Appendix B. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The standard statistical approach to generalization is based on the assumption that test and training data are i.i.d. according to an unknown distribution. This assumption can fall short in real-world applications: as a result, many recent papers have been focusing on the \u201cOut of Distribution\" (OOD) generalization problem, also known as domain generalization (DG), to address the discrepancy between test and training distribution(s) [31, 40, 68]. Extensive surveys of existing methods and approaches to DG can be found in Wang et al. [71], Zhou et al. [79]. Although several proposals for learning bounds with theoretical guarantees have been made within DA, only a few attempts have been made in the field of DG [28, 60]. Most theoretical attempts have focused on kernel methods, starting from the seminal work of Blanchard et al. [12], spanning to a body of later work (see for example Deshmukh et al. [28], Hu et al. [33], Muandet et al. [57]). In this line of work, assumptions related to boundedness of kernels and continuity of feature maps and loss function render the approaches not directly applicable to broader scenarios. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Other work has focused on providing theoretical grounds using domain-adversarial learning method; in this approach, the authors use a convex combination of source domains in order to approximate the target distribution leveraging H-divergence [2]. Ye et al. [75] have attempted to relax assumptions to provide more general bounds, focusing on feature distribution characteristics; the authors have introduced terms related to stability and discriminative power to calculate the error bound on unseen domains, through the use of an expansion function. Nonetheless, as the authors acknowledge, practical challenges arise concerning the estimation of the expansion function and the choice of a constraint on the top model to improve convergence. ", "page_idx": 2}, {"type": "text", "text": "Researchers have also focused on adaptation to new domains over time, treating DG as an online game and the model as a player minimizing the risk associated with introducing new distributions by an adversary at each step [61]. However, in scenarios where the training distribution is significantly outside the convex hull of training distributions [2], or because of unmet strong convexity loss function assumption [61], they fall short from achieving robust generalization. Causality principles have been leveraged in this sense, for example by Bellot and Bareinboim [10], Sheth et al. [67], to provide distributional robustness guarantees using causal diagrams and source domain data. However, causal approaches for improving model robustness across varying domains pose important challenges including reliance on domain knowledge. Researchers have also explored generalization bounds for DG based on the Rademacher complexity, allowing for the approach to be applicable to a broader range of models [42]. Though this simplification has a number of practical benefits, models trained under covariate shift assumptions might suffer in terms of robustness to other distribution shift types. On the empirical analysis side, Gulrajani and Lopez-Paz [31] have provided a comprehensive review of the state of the art. Though a simple ERM was found to outperform other more sophisticated methods in benchmark experiments [21], this approach has been criticized for its non-generalizability. In this direction, Izmailov et al. [35] have highlighted the importance of searching for flat minima in the training process for improved generalization. ", "page_idx": 2}, {"type": "text", "text": "All the aforementioned approaches take a point estimate-like, stance (i.e., assuming a single training set) to the derivation of generalization bounds. In this paper, in opposition, we explicitly acknowledge the uncertainty inherent to domain variation in the form of a sample of training sets, each assumed to be generated by a different distribution, and propose a robust and flexible approach representing the resulting epistemic uncertainty via credal sets. Related works on the computational complexity specific to the use of credal sets are discussed in Appendix E. ", "page_idx": 2}, {"type": "text", "text": "3 Credal Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let us formalize the notion of learning a model from a collection of (training) sets of data, each issued from a different \u2018domain\u2019 characterized by a single, albeit unknown, data-generating probability distribution. Assume that we wish to learn a mapping $h:\\mathcal{X}\\to\\mathcal{Y}$ between an input space $\\mathcal{X}$ and an output space $\\boldsymbol{\\wp}$ (where, once again, the mapping $h$ belongs to a hypotheses space $\\mathcal{H}$ ), having as evidence a finite sample of training sets, $D_{1},\\dots,D_{N}$ , $\\bar{D_{i}}\\,=\\,\\{(\\bar{x_{i,1}},y_{i,1}),\\bar{\\dots}\\,,(x_{i,n_{i}},y_{i,n_{i}})\\}$ . Assume also that the data in each set $D_{i}$ has been generated by a distinct probability distribution $P_{i}^{\\star}$ . The question we want to answer is: What sort of guarantees can be derived on the expected risk of a model learned from such a sample of training sets? How do they relate to classical Probably Approximately Correct (PAC) bounds from statistical learning theory? ", "page_idx": 2}, {"type": "text", "text": "3.1 Objectivist Modeling ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "While in classical statistical learning theory results are derived assuming no knowledge about the data-generating process, the theorems and corollaries in this paper do require some knowledge, although incomplete, of the true distribution. To be more specific, we will posit that, by leveraging the available evidence $D_{1},\\ldots,D_{N}$ , the agent is able to elicit a credal set \u2013 i.e., a closed and convex set of probabilities \u2013 that contains the true data generating process $P^{\\mathrm{true}}\\equiv P_{N+1}^{\\star}$ for a new set of data $D_{N+1}$ (that we call the test set), possibly different from $D_{1},\\dots,D_{N}$ . As we shall see in Section 4, though, this extra modeling effort allows us to derive stronger results. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "There are at least two ways in which such a credal set can be derived, that is, via either an objectivist or a subjectivist modeling stance. In this section, we present the former. We start by inspecting the frequentist approach to objectivist modeling, considering in particular epsilon-contamination models (Section 3.1.1) and belief functions models (Sections 3.1.2, 3.1.3). A further objectivist model based on fiducial inference [3, 32] is outlined in Appendix D. ", "page_idx": 3}, {"type": "text", "text": "3.1.1 Epsilon-contamination models ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In classical frequentist statistics, given the available dataset, the agent assumes the analytical form of a likelihood $\\mathcal{L}$ (not to be confused with the expected loss function, which we denote by a Roman letter $L$ ), e.g., a Normal or a Gamma distribution. As shown by Huber and Ronchetti [34], though, small perturbations of the specified likelihood can induce substantial differences in the conclusions drawn from the data. A robust frequentist agent is thus interested in statistical methods that may not be fully optimal under the ideal \u2018true\u2019 likelihood model, but still lead to reasonable conclusions if the ideal model is only approximately true [8]. ", "page_idx": 3}, {"type": "text", "text": "To account for this, the agent specifies the class of $\\epsilon$ -contaminated distributions ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{P}=\\{P:P=(1-\\epsilon)\\mathcal{L}+\\epsilon Q,\\forall Q\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\epsilon$ is some positive quantity in $(0,1)$ , and $Q$ is any distribution on $\\mathcal X\\times\\mathcal X$ . Wasserman and Kadane [74] show that $\\mathcal{P}$ is indeed a (nonempty) credal set. In view of this robust frequentist goal, then, requiring that the true data generating process belongs to $\\mathcal{P}$ is a natural assumption. ", "page_idx": 3}, {"type": "text", "text": "In our framework, in which a finite sample of $N$ training sets $\\{D_{i}\\}_{i=1}^{N}$ is available, one approach to building the desired credal set is to specify $N$ many likelihoods $\\{\\mathcal{L}_{i}\\}_{i=1}^{N}$ and $\\epsilon_{i}$ -contaminate each of them to obtain $\\mathcal{L}_{i}=\\{P:P=(1-\\epsilon_{i})\\bar{\\mathcal{L}}_{i}+\\epsilon_{i}Q\\}\\forall Q\\}$ , $i\\in\\{1,\\ldots,N\\}$ . The credal set $\\mathcal{P}$ can then be derived by setting ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{P}=\\operatorname{Conv}(\\cup_{i=1}^{N}\\mathcal{L}_{i}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathrm{Conv}(\\cdot)$ denotes the convex hull operator.1 An immediate consequence of Wasserman and Kadane [74] and references therein is that $\\mathcal{P}=\\operatorname{Conv}(\\cup_{i=1}^{N}\\mathcal{L}_{i})\\,=\\,\\{\\dot{P^{\\prime}}:P(A)\\,\\geq\\,\\underline{{\\mathcal{L}}}(A),\\forall A\\,\\subseteq$ $\\mathcal{X}\\times\\mathcal{Y}\\}$ , where $\\underline{{\\mathcal{L}}}(A)=\\operatorname*{min}_{i\\in\\{1,...,N\\}}(1-\\epsilon_{i})\\mathcal{L}_{i}(A)$ , for all $A\\subset\\mathcal{X}\\times\\mathcal{Y}$ . A simple numerical example for such a procedure is given in Appendix $\\mathbf{C}$ . ", "page_idx": 3}, {"type": "text", "text": "3.1.2 Belief functions as lower probabilities ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "An alternative way to derive a credal set from the sample training evidence can be formulated within the framework of the Dempster-Shafer theory of evidence [27, 66]. ", "page_idx": 3}, {"type": "text", "text": "A random set [39, 52, 55, 58] is a set-valued random variable, modeling random experiments in which observations come in the form of sets. In the case of finite sample spaces, they are called belief functions [66]. While classical discrete mass functions assign normalized, non-negative values to the elements $\\omega\\in\\Omega$ of their sample space, a belief function independently assigns normalized, nonnegative mass values to subsets of the sample space: $m(A)\\geq0$ , for all $\\begin{array}{r}{\\dot{A}\\subseteq{\\bar{\\Omega}},\\sum_{A\\subseteq\\Omega}m(A)=1}\\end{array}$ The belief function associated with a mass function $m$ then measures the total mass of the subsets of each event $A$ , $\\textstyle\\operatorname{Bel}(A)=\\sum_{B\\subseteq A}m(B)$ . ", "page_idx": 3}, {"type": "text", "text": "Crucially, a belief function can be seen as the lower probability (or lower envelope) of the credal set ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{M}(\\mathrm{Bel})=\\{P:\\Omega\\rightarrow[0,1]:\\mathrm{Bel}(A)\\leq P(A),\\forall A\\subseteq\\Omega\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $P$ is a data distribution. The dual upper probability to Bel is $\\operatorname{Pl}(A)\\doteq1-\\operatorname{Bel}(A^{c})$ , for all $A\\subseteq\\Omega$ . When restricted to singleton elements, it is called the contour function, $\\mathsf{p l}(\\omega)=\\mathsf{P l}(\\{\\omega\\})$ . ", "page_idx": 3}, {"type": "text", "text": "3.1.3 Inferring belief functions from data ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "There are various ways one can infer a belief (or, equivalently, a plausibility) function from (partial) data, such as a sample of training sets. If a classical likelihood $\\mathcal{L}$ having probability density or mass function (pdf/pmf) $\\ell$ is available (as assumed in the frequentist paradigm),2 one can build a belief function by using the normalized likelihood as its contour function. That is, $\\begin{array}{r}{\\ p l(\\omega)\\doteq\\frac{\\ell(\\omega)}{s u p_{\\omega^{\\prime}\\in\\Omega}\\ell(\\omega^{\\prime})}}\\end{array}$ , for all $\\omega\\in{\\Omega}$ , where $\\Omega=\\mathcal{X}\\times\\mathcal{Y}$ is the space where the training pairs live. ", "page_idx": 4}, {"type": "text", "text": "As before, in our framework in which a finite sample of $N$ training sets $\\{D_{i}\\}_{i=1}^{N}$ is available, we can specify $N$ many likelihoods $\\{\\mathcal{L}_{i}\\}_{i=1}^{N}$ , and their corresponding pdf/pmf\u2019s $\\{\\ell_{i}\\}_{i=1}^{N}$ . Then, we can compute $\\overline{{\\ell}}(\\omega)=\\operatorname*{max}_{i\\in\\{1,...,N\\}}\\ell_{i}(\\omega)$ , for all $\\omega\\in{\\Omega}$ , and in turn ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{pl}(\\omega)=\\bar{\\ell}(\\omega)/s u p_{\\omega^{\\prime}\\in\\Omega}\\bar{\\ell}(\\omega^{\\prime}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "for all $\\omega\\in\\Omega$ .3 In turn, our credal set is derived as ${\\mathcal{P}}=\\{P:\\mathrm{d}P/\\mathrm{d}\\nu=p\\le\\mathrm{pl}\\}$ , where $\\mathrm{d}P/\\mathrm{d}\\nu=p$ is the pdf/pmf associated with distribution $P$ via its Radon-Nikodym derivative with respect to a sigma-finite dominating measure $\\nu$ . Such construction means that $\\mathcal{P}$ includes all distributions whose pdf/pmf\u2019s are element-wise dominated by plausibility contour pl. ", "page_idx": 4}, {"type": "text", "text": "Numerical example. Let $\\Omega\\,=\\,\\{\\omega_{1},\\omega_{2},\\omega_{3}\\}$ , where $\\omega_{j}\\,=\\,(x_{j},y_{j})$ , $j\\,\\in\\,\\{1,2,3\\}$ . Suppose also that we observed four sample training sets $D_{1},\\ldots,D_{4}$ and that we specified the likelihood pmf\u2019s $\\ell_{1},\\ldots,\\ell_{4}$ as in Table 1.4 There, we see e.g. how pmf $\\ell_{1}$ assigns a probability of 0.3 to the element $\\omega_{1}$ of the state space $\\omega$ , and similarly for the other pmf\u2019s and the other elements of the state space. It is immediate to see that $\\bar{\\ell}=(0.4,0.8,0.6)^{\\top}$ .5 Then, by Equation (1), we have that $\\mathsf{p l}=(0.5,1,0.75)^{\\top}$ . ", "page_idx": 4}, {"type": "text", "text": "We can then derive the lower $\\underline{{P}}$ and upper $\\overline{P}$ probabilities of ${\\mathcal{P}}\\;=\\;\\{{\\boldsymbol{P}}\\,:\\,\\mathrm{d}P/\\mathrm{d}{\\boldsymbol{\\nu}}\\;=\\;p\\,\\le\\,\\mathrm{pl}\\}$ on $2^{\\Omega}$ as in Table 2, using the results in Augustin et al. [8, Section 4.4]. That is, ${\\underline{{P}}}(A)\\;=\\;$ max $\\begin{array}{r}{\\{\\sum_{\\omega\\in A}\\underline{{P}}(\\omega),1-\\sum_{\\omega\\in A^{c}}\\overline{{P}}(\\omega)\\}}\\end{array}$ and $\\begin{array}{r}{\\overline{{P}}(A)=\\operatorname*{min}\\left\\{\\sum_{\\omega\\in A}\\overline{{P}}(\\omega),1-\\sum_{\\omega\\in A^{c}}\\underline{{P}}(\\omega)\\right\\}}\\end{array}$ . As we can see from the visual representation of $\\mathcal{P}$ (the yellow convex region in Figure 2), the probability bounds imposed by the credal set are not too stringent, and in line with the evidence encapsulated in $\\ell_{1},\\ldots,\\ell_{4}$ . Hence, the assumption that $P^{\\mathrm{true}}\\equiv P_{5}^{\\star}\\in\\mathcal{P}$ is quite plausible. ", "page_idx": 4}, {"type": "image", "img_path": "AH5KwUSsln/tmp/c3166c3070347228456c6b2f3942bd4e05018e5b05ed2436b973670e170f50d8.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.2 Subjectivist Modeling ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Another way of specifying a credal set is by taking a personalistic (or subjectivist) route [14, 70]. In this approach, let $\\{A_{S}\\}$ be a finite collection of subsets of $\\Omega=\\mathcal{X}\\times\\mathcal{Y}$ . The agent first specifies the lower probability $\\underline{{P}}_{\\mathcal{S}}$ on the power set $2^{S}$ , where $S=\\cup A_{S}-\\mathrm{i.e}$ ., the smallest value that the probability of any subset of $\\boldsymbol{S}$ can take on. This can be done, for example, as a result of the empirical distribution, as described below. ", "page_idx": 4}, {"type": "text", "text": "In our framework in which a finite sample of $N$ training sets $\\{D_{i}\\}_{i=1}^{N}$ is available, we have that $\\{A_{\\mathcal{S}}\\}\\,=\\,\\{D_{i}\\}_{i=1}^{N}$ , and so $\\textstyle S\\,=\\,\\cup_{i=1}^{N}D_{i}$ . Recall that we originally denoted by $P_{i}^{\\star}$ etmhpe true data generating process for training set $D_{i}$ , $i\\in\\{1,\\ldots,N\\}$ : the empirical distribution $\\bar{P}_{i}^{\\mathrm{emp}}$ is a (nonparametric) estimation of $P_{i}^{\\star}$ . On the other hand, recall that we denoted by $P^{\\mathrm{true}}\\equiv\\dot{P}_{N+1}^{\\star}$ the true data generating process for the test set of data $D_{N+1}$ . ", "page_idx": 5}, {"type": "text", "text": "The lower probabil.ity $\\underline{{P}}_{S}$ is defined as follows. For every element $(x,y)$ in $\\textstyle S\\,=\\,\\cup_{i=1}^{N}D_{i}$ , we let $\\underline{{P}}_{S}(\\{(x,y)\\})\\;\\doteq\\;\\mathrm{min}\\bigl\\{P_{i}^{\\mathrm{emp}}(\\{(x,y)\\})\\;:\\;P_{i}^{\\mathrm{emp}}(\\{(x,y)\\})\\;>\\;0\\bigr\\}$ . Requiring $\\underline{{{P}}}_{S}(\\{(x,y)\\})\\;=$ $\\operatorname*{min}_{i}P_{i}^{\\mathrm{emp}}(\\{(x,y)\\})$ is not enough because, if the training data sets do not overlap, we would end up having lower probability 0 for some singleton that we observed at training time, and hence we would be neglecting some collected evidence. The lower probability $\\underline{{P}}_{S}$ of all the other non-singleton elements $B$ of $\\boldsymbol{S}$ is computed according to [8, Equation (4.6a)], that is, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\underline{{P}}_{S}(B)=\\operatorname*{max}\\left\\{\\sum_{(x,y)\\in B}\\underline{{P}}_{S}(\\{(x,y)\\}),1-\\sum_{(x,y)\\in B^{c}}\\operatorname*{max}_{i}P_{i}^{\\mathrm{emp}}(\\{(x,y)\\})\\right\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Numerical example. Suppose for simplicity that $\\mathcal{X}\\,=\\,\\{{x}\\}$ , so that $\\Omega\\,=\\,\\{x\\}\\times\\mathcal{y}\\,\\simeq\\,\\mathcal{y}$ , and let $\\mathcal{V}\\,=\\,\\{1,\\dots,10\\}$ . Suppose $N\\,=\\,2$ , and let $D_{1}$ be a collection of three 4\u2019s, three 5\u2019s, and three 6\u2019s. Let also $D_{2}$ be a collection of six 5\u2019s and two $6\\,\\mathrm{{\\dot{s}}}$ . Then, $\\ensuremath{\\cal S}\\ensuremath{\\mathrm{~=~}}\\{4,5,6\\}$ and $2^{S}\\ =$ $\\{\\varnothing,\\{4\\},\\{5\\},\\{6\\},\\{4,5\\},\\{5,6\\},\\{4,6\\},\\{4,5,6\\}\\}$ . In turn, $\\underline{{{P}}}_{S}(\\{4\\})=1/3$ , $\\underline{{{P\\dot{\\mathbf{\\delta}}}}}(\\{5\\})=1/3$ , and $\\underline{{P}}_{S}(\\{6\\})=1/4$ . By (2), this implies that $\\underline{{P}}_{S}(\\{4,5\\})=2/3$ , $\\underline{{P}}_{S}(\\{5,6\\})=2/3$ , and ${\\underline{{P}}}_{S}(\\{4,6\\})=$ $\\operatorname*{max}\\{1/3+1/4,1-\\operatorname*{max}_{i\\in\\{1,2\\}}P_{i}^{\\mathrm{emp}}(\\{5\\})\\}=\\operatorname*{max}\\{7/12,1-\\operatorname*{max}\\{1/3,3/4\\}=\\operatorname*{max}\\{7/12,1-\\operatorname*{max}\\{1/3,2\\}=0,\\forall\\dag,\\dag,\\dag\\},$ $3/4\\}=7/12$ . Of course, $\\underline{{P}}_{S}(\\varnothing)=0$ and $\\underline{{P}}_{S}(S)=1$ . ", "page_idx": 5}, {"type": "text", "text": "3.2.1 Walley\u2019s Natural Extension ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Once a lower probability $\\underline{{P}}_{S}$ on $2^{S}$ is inferred, it can be (coherently uniquely) extended to a lower probability $\\underline{{P}}$ on the whole sigma-algebra endowed to $\\mathcal X\\times\\mathcal X$ through an operator called natural extension [69], [70, Sections 3.1.7-3.1.9]. The resulting extended lower probability is such that $\\underline{{P}}(B)=\\underline{{P}}_{S}(B)$ , for all $B\\in{2^{S}}$ , and a lower probability value ${\\underline{{P}}}(A)$ is assigned to all the other subsets $A$ of $\\mathcal X\\times\\mathcal X$ that are not in $\\boldsymbol{S}$ . It is also coherent \u2013 in Walley\u2019s terminology \u2013 because, in the behavioral interpretation of probability derived from de Finetti [25, 26], its values cannot be used to construct a bet that would make the agent lose for sure, no matter the outcome of the bet itself. ", "page_idx": 5}, {"type": "text", "text": "Once $P$ is obtained, the agent can consider the core of $\\underline{{P}}$ , ${\\mathcal{M}}({\\underline{{P}}})\\doteq\\{P:{\\underline{{P}}}(A)\\leq P(A),\\forall A\\subseteq$ $\\mathcal{X}\\times\\mathcal{Y}\\}$ , i.e., the collection of all the (countably additive) probabilities that set-wise dominate $\\underline{{P}}$ . Scholars [20, 50] have shown that $\\mathscr{P}=\\mathcal{M}(\\underline{{{P}}})$ is indeed a (nonempty) credal set. ", "page_idx": 5}, {"type": "text", "text": "3.2.2 Properties of the Core ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As shown in Amarante and Maccheroni [5, Example 1] and Amarante et al. [6, Examples 6, 7, 8], given a generic credal set $\\mathcal{Q}$ whose lower envelope is $\\underline{{\\theta}}-\\mathrm{i.e.}$ , a credal set $\\mathcal{Q}$ for which $\\underline{{Q}}(\\cdot)=\\operatorname*{inf}_{Q\\in\\mathcal{Q}}Q(\\cdot)$ \u2013 we have that $\\mathcal{M}(\\underline{{Q}})\\supseteq\\mathcal{Q}$ . From an information-theoretic perspective, this means that the uncertainty encapsulated in the core of a lower probability $Q$ is larger than that in any credal set whose lower envelope is $Q$ [13, 15, 16, 18, 30]. In turn, $\\mathbf{\\mathcal{M}}(\\underline{{Q}})$ is the largest credal set the agent can build which represents their partial knowledge. In our learning framework, given the available evidence $D_{1},\\ldots,D_{N}$ that the agent uses to derive $\\underline{{P}}_{S}$ , if the agent is confident that $P^{\\mathrm{true}}(B)\\ge\\underline{{P}}_{S}(B)$ , for all $B\\in{2^{S}}$ , then it is natural to assume $P^{\\mathrm{true}^{*}}\\equiv P_{N+1}^{\\star}\\in\\mathcal{M}(\\underline{{P}})$ . ", "page_idx": 5}, {"type": "text", "text": "4 Generalization Bounds under Credal Uncertainty ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Consider a credal set $\\mathcal{P}$ on $\\mathcal X\\times\\mathcal Y$ derived as in Section 3, and assume that we collect new evidence in the form of a test set of data $D_{N+1}=\\{(x_{N+1,1},y_{N+1,1}),\\ldots,(x_{N+1,n_{N+1}},y_{N+1,n_{N+1}})\\}$ . To ease notation, in the following we refer to the newly acquired evidence as $(x_{1},y_{1}),\\ldots,(x_{n},y_{n})$ . ", "page_idx": 5}, {"type": "text", "text": "An assumption that is common to all the results we present in this section is that $(x_{1},y_{1}),\\Bar{\\dots,}(x_{n},y_{n})\\sim P\\equiv P^{\\mathrm{true}}\\equiv P_{N+1}^{\\star}$ i.i.d., and $P\\,\\in\\,\\mathcal P$ . This means that either the new evidence comes from one of the distributions that generated $D_{1},\\ldots,D_{N}$ , or that it is at least compatible with the credal set we built from past evidence [30]. That is, either $P$ set-wise dominates the lower probability $\\underline{{P}}$ of $\\mathcal{P}$ (as in Sections 3.1, 3.1.2, and 3.2), or it is set-wise dominated by the upper probability $\\overline{P}$ of $\\mathcal{P}$ (induced, e.g., by a contour function as in Section 3.1.3). This is a rather natural assumption, especially when the stream of training sets we collect pertains to similar experiments or tasks. For example, this is the case in Continual Learning (CL), where it is customary to assume task similarity [47], that is, to posit that the oracle distributions pertaining to all the tasks of interest are all contained in a TV-ball of radius chosen by the user. A more complete discussion on the relation between our credal approach and CL can be found in Appendix F. It is also the case in the healthcare setting, where experts\u2019 opinions can be incorporated alongside empirical data (plausible probability distributions) to represent the probability uncertainty, for example, for the prognosis of a disease given a set of patient characteristics/biomarkers [65]. To make sure that the credal set constructed encapsulates most of the \u201cpotential distributions needed\u201d, a number of approaches can be taken including incremental learning; in this approach the AI model learns and updates knowledge incrementally. As a result, the credal set can be continuously updated (via incremental learning) as new data become available. In this direction, learning health systems are being implemented in practice. These are health systems \u201cin which internal data and experience are systematically integrated with external evidence, and that knowledge is put into practice\u201d. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "We note, in passing, that assuming $P\\in\\mathcal P$ is less stringent than what is typically done in frequentist statistics, where the data-generating process is assumed to be perfectly captured by the likelihood. We instead posit that the true data generating process for the new evidence available belongs to a credal set $\\mathcal{P}$ , that was derived by the sample of training sets $D_{1},\\ldots,D_{N}$ . ", "page_idx": 6}, {"type": "text", "text": "Formal ways of checking whether the assumption $P\\in\\mathcal P$ holds exist, e.g., by following what Cella and Martin [19, Section 7] and Javanmardi et al. [36] do for credal-set-based conformal prediction methods, or more general approaches [1, 22, 29, 46, 56].6 That being said, deriving PAC-like guarantees on the correct distribution $P$ being an element of the credal set $\\mathcal{P}$ is a desirable objective - a task that we defer to future work. Here, we focus on formally deriving what the consequences are in terms of generalization bounds. ", "page_idx": 6}, {"type": "text", "text": "4.1 Realizability and Finite Hypotheses Space ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Theorem 4.1. Let $(x_{1},y_{1}),\\dotsc,(x_{n},y_{n})\\sim P$ i.i.d., where $P$ is any element of the credal set $\\mathcal{P}$ . Let the empirical risk minimizer be ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\hat{h}\\in\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\frac{1}{n}\\sum_{i=1}^{n}l((x_{i},y_{i}),h).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Assume that there exists a realizable hypothesis, that is, $h^{\\star}\\ \\in\\ {\\mathcal{H}}$ such that $L_{P}(h^{\\star})\\;=\\;0,$ , and that the model space $\\mathcal{H}$ is finite. Let $l$ denote the zero-one loss, and fix any $\\delta\\,\\in\\,(0,1)$ . Then, $\\mathbb{P}[L_{P}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)]\\geq1-\\delta$ , where $\\epsilon^{\\star}(\\delta)$ is a well-defined quantity that depends only on $\\delta$ and on extreme elements $e x\\mathcal{P}$ of $\\mathcal{P}$ , i.e., those that cannot be written as a convex combination of one another. ", "page_idx": 6}, {"type": "text", "text": "Under the assumptions of finiteness and realizability, Theorem 4.1 gives us a tight probabilistic bound for the expected risk $L_{P}(\\hat{h})$ of the empirical risk minimizer $\\hat{h}$ . The bound holds for any possible distribution $P$ in the credal set $\\mathcal{P}$ that generated the stream of training data. A slightly looser bound depending on the diameter of credal set $\\mathcal{P}$ holds if we calculate $L_{Q}(\\bar{\\hat{h}})$ in place of $\\bar{L_{P}}(\\hat{h})$ . ", "page_idx": 6}, {"type": "text", "text": "Corollary 4.2. Retain the assumptions of Theorem 4.1. Denote by $Q\\,\\in\\,\\mathcal P$ , $Q\\neq P$ , a generic distribution in $\\mathcal{P}$ different from $P$ . Let $\\Delta_{\\mathcal{X}\\times\\mathcal{X}}$ denote the space of all distributions over $\\mathcal X\\times\\mathcal X$ , and endow it with the total variation metric $d_{T V}$ . Then, pick any $\\eta\\in\\mathbb{R}_{>0}$ . If the diameter of $\\mathcal{P}$ , denoted b $\\prime\\,d i a m_{T V}(\\mathcal{P})_{.}$ , is equal to $\\eta,$ we have that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}[L_{Q}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)+\\eta]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\epsilon^{\\star}(\\delta)$ is the same quantity as in Theorem 4.1. ", "page_idx": 6}, {"type": "text", "text": "Corollary 4.2 gives us a probabilistic bound for the expected risk $L_{Q}(\\hat{h})$ of the empirical risk minimizer $\\hat{h}$ , calculated with respect to a \u201cwrong\u201d distribution $Q$ \u2013 that is, any distribution in $\\mathcal{P}$ ", "page_idx": 6}, {"type": "text", "text": "different from the one generating the new test set of data $D_{N+1}$ . We can also give a looser \u2013 but easier to compute \u2013 bound for $L_{P}(\\hat{h})$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 4.3. Under the assumptions of Theorem 4.1, $\\begin{array}{r}{\\epsilon^{\\star}(\\delta)\\leq\\epsilon_{U B}(\\delta)\\doteq1/n[\\log|\\mathcal{H}|+\\log(\\frac{1}{\\delta})]}\\end{array}$ and ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}[L_{P}(\\hat{h})\\leq\\epsilon_{U B}(\\delta)]\\geq1-\\delta,\\quad\\forall P\\in\\Delta_{x\\times y}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Notice how $\\epsilon_{\\mathrm{UB}}(\\delta)$ is a uniform bound, that is, a bound that holds for all possible distributions on $\\mathcal X\\times\\mathcal Y$ , not just those in $\\mathcal{P}$ . Strictly speaking, this means that we do not need to come up with a credal set $\\mathcal{P}$ to find such a bound. Observe, though, that the bound $\\epsilon^{\\star}(\\delta)$ in Theorem 4.1 is tighter, as it leverages the training evidence encoded in the credal set $\\mathcal{P}$ . A synthetic experiment confirming this, and studying other interesting properties of $\\epsilon^{\\star}(\\delta)$ and $\\epsilon_{\\mathrm{UB}}(\\delta)$ , can be found in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "By the proof of Theorem 4.1, we have that $L_{P}(\\hat{h})$ behaves as ${\\mathcal{O}}(\\log|\\cup_{P^{\\mathrm{ex}}\\in{\\mathrm{ex}}{\\mathcal{P}}}B_{P^{\\mathrm{ex}}}|/n)$ , which is faster than the rate ${\\mathcal{O}}(\\log|{\\mathcal{H}}|/n)$ that we find in Corollary 4.3, since $\\bigcup P^{\\mathrm{ex}}{\\in}\\mathbf{ex}\\mathbf{\\mathcal{P}}^{\\bigstar}P^{\\mathrm{ex}}\\subseteq\\mathbf{\\mathcal{H}}$ .7 Roughly, $B_{P^{\\mathrm{cx}}}$ is the set of \u201cbad hypotheses\u201d according to $P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}$ . That is, those $h$ \u2019s for which $L_{P^{\\mathrm{ex}}}(h)$ is larger than 0. A formal definition is given in the proof of Theorem 4.1. The modeling effort required by producing credal set $\\mathcal{P}$ is therefore rewarded with a tighter bound and a faster rate. ", "page_idx": 7}, {"type": "text", "text": "Notice that Corollary 4.3 corresponds to Liang [44, Theorem 4]: we obtain a classical result as a special case of our more general theorem. ", "page_idx": 7}, {"type": "text", "text": "Let us now allow for distribution drift in the new test set of data $D_{N+1}$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 4.4. Consider a natural number $k\\,<\\,n$ . Let $(x_{1},y_{1}),\\ldots,(x_{k},y_{k})\\,\\sim\\,P_{1}$ i.i.d., and $(x_{k+1},y_{k+1}),\\ldots,(x_{n},y_{n})\\,\\sim\\,P_{2}$ i.i.d., where $P_{1},P_{2}$ are two generic elements of credal set $\\mathcal{P}$ . Retain the other assumptions of Theorem 4.1. Then, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{1}}(\\hat{h}_{1})+L_{P_{2}}(\\hat{h}_{2})\\leq\\epsilon^{\\star}(\\delta)\\frac{n^{2}}{k(n-k)}\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\epsilon^{\\star}(\\delta)$ is the same quantity as in Theorem 4.1, and ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widehat{h}_{1}\\in\\mathop{\\mathrm{arg\\,min}}_{h\\in\\mathcal{H}}\\left\\{\\frac{1}{k}\\sum_{i=1}^{k}l((x_{i},y_{i}),h)\\right\\},\\quad\\widehat{h}_{2}\\in\\mathop{\\mathrm{arg\\,min}}_{h\\in\\mathcal{H}}\\left\\{\\frac{1}{n-k}\\sum_{i=k+1}^{n}l((x_{i},y_{i}),h)\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Corollary 4.4 gives us a bound similar to the one in Theorem 4.1 when distribution drift is allowed. The price we pay for it is that it is looser. As a result of Corollary 4.3, for a looser but easier to compute bound, we can substitute $\\epsilon^{\\star}(\\delta)$ with $\\epsilon_{\\mathrm{UB}}(\\delta)$ . ", "page_idx": 7}, {"type": "text", "text": "4.2 No Realizability and Finite Hypotheses Space ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Let us now relax the realizability assumption in Theorem 4.1. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.5. Let $(x_{1},y_{1}),\\dotsc,(x_{n},y_{n})\\sim P$ i.i.d., where $P$ is any element of the credal set $\\mathcal{P}$ . Assume that the model space $\\mathcal{H}$ is finite. Let l be the zero-one loss, $\\hat{h}$ the empirical risk minimizer, and $h^{\\star}$ the best theoretical model. Fix any $\\delta\\in(0,1)$ . Then, $\\mathbb{P}[L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)]\\geq1-\\delta,$ , where $\\epsilon^{\\star\\star}(\\delta)$ is a well-defined quantity that depends only on $\\delta$ and on the elements of $e x\\mathcal{P}$ . ", "page_idx": 7}, {"type": "text", "text": "As we did in Section 4.1, we can also show that the \u201cwrong\u201d expected risk $L_{Q}(\\hat{h})$ \u2013 that is, the expected risk computed according to $Q\\in\\mathcal{P}$ different from the one generating the new evidence $D_{N+1}$ \u2013 concentrates around the expected risk $L_{P}(h^{\\star})$ evaluated at the best theoretical model $h^{\\star}$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 4.6. Retain the assumptions of Theorem 4.5. Denote by $Q\\,\\in\\,\\mathcal P$ , $Q\\neq P$ , a generic distribution in $\\mathcal{P}$ different from $P$ . Pick any $\\eta\\in\\mathbb{R}_{>0};\\,i f\\,d i a m_{T V}(\\mathcal{P})=\\eta,$ , we have that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}[L_{Q}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)+\\eta]\\geq1-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\epsilon^{\\star\\star}(\\delta)$ is the same quantity as in Theorem 4.5. ", "page_idx": 7}, {"type": "text", "text": "Similarly to Corollary 4.3, we can give a looser \u2013 but easier to compute \u2013 bound for $L_{P}(\\hat{h})-L_{P}(h^{\\star})$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 4.7. Retain the assumptions of Theorem 4.5. Then, $\\begin{array}{r l r}{\\epsilon^{\\star\\star}(\\delta)}&{{}\\leq}&{\\epsilon_{U B}^{\\prime}(\\delta)\\quad\\dot{=}}\\end{array}$ 2(log|H|n+log( \u03b42)). In turn, P[LP (\u02c6h) \u2212LP (h\u22c6) \u2264\u03f5\u2032UB(\u03b4)] \u22651 \u2212\u03b4, for all P \u2208\u2206X\u00d7Y. ", "page_idx": 8}, {"type": "text", "text": "The main difference with respect to Theorem 4.1 is that in Theorem 4.5, $L_{P}(\\hat{h})-L_{P}(h^{\\star})$ behaves as $\\mathcal{O}(\\sqrt{\\log{|B_{\\mathrm{ex}}^{\\prime}\\mathcal{P}|}/n})$ , which is slower than what we had in Theorem 4.1. This is due to the relaxation of the realizability hypothesis. Just like before, though, we have that $\\mathcal{O}(\\sqrt{\\log{|B_{\\mathrm{ex}}^{\\prime}\\r|}/n})$ is faster than the rate $O({\\sqrt{\\log|{\\mathcal{H}}|/n}})$ that we find in Corollary 4.7. This is because $B_{\\mathrm{ex}\\mathcal{P}}^{\\prime}\\subseteq\\mathcal{H}$ . ", "page_idx": 8}, {"type": "text", "text": "Roughly, $B_{\\mathrm{ex}\\mathcal{P}}^{\\prime}$ is the set of \u201cbad hypotheses\u201d according to at least one $P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal P$ . That is, those $h$ \u2019s for which $|\\hat{L}(h)-L_{P^{\\mathrm{ex}}}(h)|$ is larger than 0, for at least one $P^{\\mathrm{ex}}$ . A formal definition is given in the proof of Theorem 4.5. Notice that Corollary 4.7 corresponds to Liang [44, Theorem 7]: we obtain a classical result as a special case of our more general theorem. ", "page_idx": 8}, {"type": "text", "text": "Let us now allow for distribution drift. To improve notation clarity, in the following we let $h_{P}^{\\star}$ denote an element of ${\\mathrm{arg\\,min}}_{h\\in{\\mathcal{H}}}\\,L_{P}(h)$ , for a distribution $P\\in\\mathcal P$ . ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.8. Consider a natural number $k\\,<\\,n$ . Let $(x_{1},y_{1}),\\ldots,(x_{k},y_{k})\\,\\sim\\,P_{1}$ i.i.d., and $(x_{k+1},y_{k+1}),\\ldots,(x_{n},y_{n})\\,\\sim\\,P_{2}$ i.i.d., where $P_{1},P_{2}$ are two generic elements of credal set $\\mathcal{P}$ . Retain the other assumptions of Theorem 4.5. Then, ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\big[}\\big(L_{P_{1}}(\\widehat{h}_{1})-L_{P_{1}}(h_{P_{1}}^{\\star})\\big)+\\big(L_{P_{2}}(\\widehat{h}_{2})-L_{P_{2}}(h_{P_{2}}^{\\star})\\big)\\le\\epsilon^{\\star\\star}(\\delta)\\sqrt{\\frac{n}{k(n-k)}}\\big(\\sqrt{k}+\\sqrt{n-k}\\big)\\big]\\ge1-\\delta,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\epsilon^{\\star\\star}(\\delta)$ is the same quantity as in Theorem 4.5, and $\\hat{h}_{1}$ and $\\hat{h}_{2}$ are defined as in Corollary 4.4. ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.8 tells us that the excess risk is also bounded in the presence of distribution drift. The price we pay for allowing distribution shift is a looser bound. As a result of Corollary 4.7, for a looser but easier to compute bound, we can substitute $\\epsilon^{\\star\\star}(\\delta)$ with $\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)$ . ", "page_idx": 8}, {"type": "text", "text": "4.3 No Realizability and Infinite Hypotheses Space ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now relax also the finite hypotheses space assumption in Theorem 4.1. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.9. Let $(x_{1},y_{1}),\\dotsc,(x_{n},y_{n})\\sim P$ i.i.d., where $P$ is any element of credal set $\\mathcal{P}$ . Let $l$ denote the zero-one loss, $\\hat{h}$ the empirical risk minimizer and $h^{\\star}$ the best theoretical model. Fix any $\\delta\\in(0,1)$ . Then, ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left[L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star\\star}(\\delta)\\right]\\geq1-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for all $\\textbf{\\textit{P}}\\in\\textbf{\\textit{P}}$ . Here, $\\begin{array}{r l r}{\\epsilon^{\\star\\star\\star}(\\delta)}&{{}\\doteq}&{4\\overline{{R}}_{n,P^{e x}}(A)\\ +\\ \\sqrt{\\frac{2\\log(2/\\delta)}{n}}}\\end{array}$ , where $\\begin{array}{r l}{\\overline{{R}}_{n,P^{e x}}(A)}&{{}\\doteq}\\end{array}$ $\\operatorname*{sup}_{P^{e x}\\in e x\\mathcal{P}}R_{n,P^{e x}}(A)$ and ", "page_idx": 8}, {"type": "equation", "text": "$$\nR_{n,P^{e x}}(A)\\doteq\\mathbb{E}_{P^{e x}}\\left[\\operatorname*{sup}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^{n}\\sigma_{i}l((x_{i},y_{i}),h)\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "In (6), $\\sigma_{1},\\ldots,\\sigma_{n}\\sim U n i f(\\{-1,1\\})$ , and $A\\doteq\\{(x,y)\\mapsto l((x,y),h):h\\in\\mathcal{H}\\}.$ ", "page_idx": 8}, {"type": "text", "text": "$R_{n,P^{\\mathrm{ex}}}(A)$ is a slight modification of the classical Rademacher complexity of class $\\boldsymbol{\\mathcal{A}}$ ,8 given by ", "page_idx": 8}, {"type": "equation", "text": "$$\nR_{n}(\\boldsymbol{A})\\equiv R_{n,P}(\\boldsymbol{A})\\doteq\\mathbb{E}_{P}\\left[\\operatorname*{sup}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^{n}\\sigma_{i}l((x_{i},y_{i}),h)\\right],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where the expectation is taken with respect to the same distribution $P$ from which the data points $(x_{1},y_{1}),\\dotsc,{\\bar{(x_{n},y_{n})}}$ are drawn. We consider $R_{n,P^{\\mathrm{ex}}}(A)$ instead of $R_{n,P}({\\mathcal{A}})$ because, since $\\mathcal{P}$ is a credal set, $P$ can be written as a convex combination of the extreme elements of $\\mathcal{P}$ , and $\\operatorname*{sup}_{P\\in{\\mathcal{P}}}R_{n,P}(A)=\\operatorname*{sup}_{P^{\\mathrm{ex}}\\in\\exp{\\mathcal{P}}}R_{n,P^{\\mathrm{ex}}}(A)$ . If the credal set is finitely generated, that is, if it has finitely many extreme elements (see footnote 7), then it is easier to compute $\\epsilon^{\\star\\star\\star}(\\delta)$ : we only need to compute a maximum in place of a supremum. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "As we show in Corollary 4.10, Theorem 4.9 generalizes Liang [44, Theorem 9]. This latter focuses only on the \u201ctrue\u201d probability $P_{N+1}^{\\star}\\equiv P^{\\mathrm{true}}$ on $\\mathcal X\\times\\mathcal X$ , while our result holds for all the plausible distributions in credal set $\\mathcal{P}$ . This grants us to hedge against distribution misspecification. ", "page_idx": 9}, {"type": "text", "text": "Let us pause here to add a clarification. In real-world applications, we effectively cannot compute $R_{n,P^{\\mathrm{true}}}(A)$ , since the distribution $P^{\\mathrm{true}}$ is unknown. While $R_{n,P^{\\mathrm{true}}}(A)$ can be approximated via the empirical Rademacher complexity $\\hat{R}_{n}(A)$ [44, Equation (219)], whose expected value is indeed $R_{n,P^{\\mathrm{tne}}}(A)$ , doing so has at least two drawbacks: (1) When the number of data points $n\\equiv n_{D_{N+1}}$ is not \u201clarge enough\u201d, this may lead to a poor approximation of the classical bound (Equation (10) in Appendix A); (2) The test set of data $D_{N+1}=\\{(x_{i},y_{i})\\}_{i=1}^{n}$ may well be a realization from the tail of distribution $P^{\\mathrm{true}}\\equiv P_{N+1}^{\\star}$ . The empirical Rademacher complexity $\\hat{R}_{n}(A)$ , then, would be a poor approximation of $R_{n,P^{\\mathrm{true}}}(A)$ . In opposition, while $\\overline{{R}}_{n,P^{\\mathrm{ex}}}(A)$ is more conservative, it can be computed explicitly \u2013 since we know the credal set $\\mathcal{P}$ and its extreme elements $\\mathrm{ex}\\mathcal{P}$ \u2013 and it leads to a bound that, although looser, holds for all $P\\in\\mathcal P$ . ", "page_idx": 9}, {"type": "text", "text": "Corollary 4.10. Retain the assumptions of Theorem 4.9. If $\\mathcal{P}$ is the singleton $\\{P^{t r u e}\\}$ (i.e., all the training datasets $D_{1},\\ldots,D_{N}$ are generated by the same distribution as the new test set $D_{N+1.}$ ), we retrieve Liang [44, Theorem $^{g}J$ . ", "page_idx": 9}, {"type": "text", "text": "We then derive a more general version of Corollary 4.6. ", "page_idx": 9}, {"type": "text", "text": "Corollary 4.11. Retain the assumptions of Theorem 4.9. Denote by $Q\\in\\mathcal{P}$ , $Q\\neq P$ , a generic distribution in $\\mathcal{P}$ different from $P$ . Pick any $\\eta\\in\\mathbb{R}_{>0};\\,i f\\,d i a m_{T V}(\\mathcal{P})=\\eta,$ , we have that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}[L_{Q}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star\\star}(\\delta)+\\eta]\\geq1-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $\\epsilon^{\\star\\star\\star}(\\delta)$ is the same quantity as in Theorem 4.9. ", "page_idx": 9}, {"type": "text", "text": "Finally, we once again allow for distribution drift. ", "page_idx": 9}, {"type": "text", "text": "Corollary 4.12. Consider a natural number $k\\,<\\,n$ . Let $(x_{1},y_{1}),\\ldots,(x_{k},y_{k})\\,\\sim\\,P_{1}$ i.i.d., and $(x_{k+1},y_{k+1}),\\ldots,(x_{n},y_{n})\\,\\sim\\,P_{2}$ i.i.d., where $P_{1},P_{2}$ are two generic elements of credal set $\\mathcal{P}$ . Retain the other assumptions of Theorem 4.9, and let $\\epsilon_{s h i f t}^{\\star\\star\\star}\\:\\doteq\\:4[\\overline{{{R}}}_{k,P e x}({\\cal A})+\\overline{{{R}}}_{n-k,P e x}({\\cal A})]\\:+$ 2 nlo(gn(\u22122/k\u03b4)) ( n \u2212k +  n). Then, ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathbb{P}[(L_{P_{1}}(\\hat{h}_{1})-L_{P_{1}}(h_{P_{1}}^{\\star}))+(L_{P_{2}}(\\hat{h}_{2})-L_{P_{2}}(h_{P_{2}}^{\\star}))\\leq\\epsilon_{s h i f t}^{\\star\\star\\star}]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $\\hat{h}_{1}$ and $\\hat{h}_{2}$ are defined as in Corollary 4.4. ", "page_idx": 9}, {"type": "text", "text": "Similar considerations as the ones after Corollaries 4.4 and 4.8 hold in this more general case as well. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we laid the foundations of a more general Statistical Learning Theory (SLT), that we called Credal Learning Theory (CLT). We generalized some of the most important results of classical SLT to allow for drift and misspecification of the data-generating process. We did so by considering sets of probabilities (credal sets), instead of single distributions. The modeling effort needed to elicit credal sets is paid off in terms of the tightness of the resulting bounds. ", "page_idx": 9}, {"type": "text", "text": "Limitations. (i) We only consider the zero-one loss in our results (we did so to be able to directly build on the classical results in Liang [44, Chapter 3]). (ii) We assume that the true distribution which the elements of the new test set $D_{N+1}$ are sampled from, belongs to the credal set that we derive at training time. ", "page_idx": 9}, {"type": "text", "text": "Future work. In the future, we plan to further our undertaking, for instance by (i) modeling the epistemic uncertainty induced by domain variation through random sets rather than credal sets, (ii) comparing our method with robust learning [23], (iii) extending our results to different losses, and (iv) deriving PAC-like guarantees on the correct distribution $P$ being an element of the credal set $\\mathcal{P}$ . We also intend to validate our findings on real datasets. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Jayadev Acharya, Constantinos Daskalakis, and Gautam Kamath. Optimal Testing for Properties of Distributions. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015. URL https://proceedings.neurips.cc/paper_files/paper/2015/file/ 1f36c15d6a3d18d52e8d493bc8187cb9-Paper.pdf.   \n[2] Isabela Albuquerque, Jo\u00e3o Monteiro, Mohammad Darvishi, Tiago H Falk, and Ioannis Mitliagkas. Generalizing to unseen domains via distribution matching. arXiv preprint arXiv:1911.00804, 2019.   \n[3] Russell Almond. Fiducial inference and belief functions. Technical report, University of Washington, 1992.   \n[4] Lama Alssum, Juan Leon Alcazar, Merey Ramazanova, Chen Zhao, and Bernard Ghanem. Just a glimpse: Rethinking temporal information for video continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2474\u20132483, 2023.   \n[5] Massimiliano Amarante and Fabio Maccheroni. When an event makes a difference. Theory and Decision, 60:119\u2013126, 2006.   \n[6] Massimiliano Amarante, Fabio Maccheroni, Massimo Marinacci, and Luigi Montrucchio. Cores of non-atomic market games. International Journal of Game Theory, 34:399\u2013424, 2006.   \n[7] Ron Amit, Baruch Epstein, Shay Moran, and Ron Meir. Integral probability metrics pac-bayes bounds. Advances in Neural Information Processing Systems, 35:3123\u20133136, 2022.   \n[8] Thomas Augustin, Frank P. A. Coolen, Gert de Cooman, and Matthias C. M. Troffaes. Introduction to imprecise probabilities. John Wiley & Sons\u201e West Sussex, England, 2014.   \n[9] Maria-Florina Balcan and Chris Berlind. Rademacher complexity. Lecture notes for the course CS8803 of the Georgia Institute of Technology, 2011.   \n[10] Alexis Bellot and Elias Bareinboim. Partial transportability for domain generalization. Available at https://openreview.net/pdf?id=mVn2JGzlET, 2022.   \n[11] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 79: 151\u2013175, 2010.   \n[12] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generalizing from several related classification tasks to a new unlabeled sample. Advances in neural information processing systems, 24, 2011.   \n[13] Michele Caprio and Ruobin Gong. Dynamic precise and imprecise probability kinematics. In Enrique Miranda, Ignacio Montes, Erik Quaeghebeur, and Barbara Vantaggi, editors, Proceedings of the Thirteenth International Symposium on Imprecise Probability: Theories and Applications, volume 215 of Proceedings of Machine Learning Research, pages 72\u201383. PMLR, 11\u201314 Jul 2023.   \n[14] Michele Caprio and Sayan Mukherjee. Extended probabilities in statistics. Available at arXiv:2111.01050, 2021.   \n[15] Michele Caprio and Sayan Mukherjee. Ergodic theorems for dynamic imprecise probability kinematics. International Journal of Approximate Reasoning, 152:325\u2013343, 2023.   \n[16] Michele Caprio and Teddy Seidenfeld. Constriction for sets of probabilities. In Enrique Miranda, Ignacio Montes, Erik Quaeghebeur, and Barbara Vantaggi, editors, Proceedings of the Thirteenth International Symposium on Imprecise Probability: Theories and Applications, volume 215 of Proceedings of Machine Learning Research, pages 84\u201395. PMLR, 11\u201314 Jul 2023. URL https://proceedings.mlr.press/v215/caprio23b.html.   \n[17] Michele Caprio, Souradeep Dutta, Kuk Jang, Vivian Lin, Radoslav Ivanov, Oleg Sokolsky, and Insup Lee. Credal Bayesian Deep Learning. arXiv preprint arXiv:2302.09656, 2023.   \n[18] Michele Caprio, Yusuf Sale, Eyke H\u00fcllermeier, and Insup Lee. A Novel Bayes\u2019 Theorem for Upper Probabilities. In Fabio Cuzzolin and Maryam Sultana, editors, Epistemic Uncertainty in Artificial Intelligence, pages 1\u201312, Cham, 2024. Springer Nature Switzerland.   \n[19] Leonardo Cella and Ryan Martin. Valid inferential models for prediction in supervised learning problems. International Journal of Approximate Reasoning, 150:1\u201318, 2022.   \n[20] Simone Cerreia-Vioglio, Fabio Maccheroni, and Massimo Marinacci. Ergodic theorems for lower probabilities. Proceedings of the American Mathematical Society, 144:3381\u20133396, 2015.   \n[21] Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and Sungrae Park. Swad: Domain generalization by seeking flat minima. Advances in Neural Information Processing Systems, 34:22405\u201322418, 2021.   \n[22] Siu Lun Chau, Anurag Singh, and Krikamol Muandet. Comparing the uncertain with credal two-sample tests, 2024.   \n[23] Christian Cianfarani, Arjun Nitin Bhagoji, Vikash Sehwag, Ben Zhao, Heather Zheng, and Prateek Mittal. Understanding robust learning through the lens of representation similarities. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 34912\u201334925. Curran Associates, Inc., 2022.   \n[24] Fabio Cuzzolin. The Geometry of Uncertainty. Artificial Intelligence: Foundations, Theory, and Algorithms. Cham : Springer, 2020.   \n[25] Bruno de Finetti. Theory of Probability, volume 1. New York $:$ Wiley, 1974.   \n[26] Bruno de Finetti. Theory of Probability, volume 2. New York $:$ Wiley, 1975.   \n[27] Arthur Pentland Dempster. Upper and lower probabilities induced by a multivalued mapping. The Annals of Mathematical Statistics, 38(2):325\u2013339, 1967.   \n[28] Aniket Anand Deshmukh, Yunwen Lei, Srinagesh Sharma, Urun Dogan, James W Cutler, and Clayton Scott. A generalization error bound for multi-class domain generalization. arXiv preprint arXiv:1905.10392, 2019.   \n[29] Rui Gao, Liyan Xie, Yao Xie, and Huan Xu. Robust hypothesis testing using wasserstein uncertainty sets. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper_files/paper/ 2018/file/a08e32d2f9a8b78894d964ec7fd4172e-Paper.pdf.   \n[30] Ruobin Gong and Xiao-Li Meng. Judicious judgment meets unsettling updating: dilation, sure loss, and Simpson\u2019s paradox. Statistical Science, 36(2):169\u2013190, 2021.   \n[31] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020.   \n[32] Jan Hannig. On generalized fiducial inference. Statistica Sinica, pages 491\u2013544, 2009.   \n[33] Shoubo Hu, Kun Zhang, Zhitang Chen, and Laiwan Chan. Domain generalization via multidomain discriminant analysis. In Uncertainty in Artificial Intelligence, pages 292\u2013302. PMLR, 2020.   \n[34] Peter J. Huber and Elvezio M. Ronchetti. Robust statistics. Wiley Series in Probability and Statistics. Hoboken, New Jersey $:$ Wiley, 2nd edition, 2009.   \n[35] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407, 2018.   \n[36] Alireza Javanmardi, David Stutz, and Eyke H\u00fcllermeier. Conformalized credal set predictors. arXiv preprint arXiv:2402.10723, 2024.   \n[37] Kishaan Jeeveswaran, Elahe Arani, and Bahram Zonooz. Gradual divergence for seamless adaptation: A novel domain incremental learning method. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 21486\u201321501. PMLR, 21\u201327 Jul 2024. URL https://proceedings.mlr.press/v235/jeeveswaran24a.html.   \n[38] Praneeth Kacham and David Woodruff. Sketching algorithms and lower bounds for ridge regression. In International Conference on Machine Learning, pages 10539\u201310556. PMLR, 2022.   \n[39] David G. Kendall. Foundations of a theory of random sets. In E. F. Harding and D. G. Kendall, editors, Stochastic Geometry, pages 322\u2013376. Wiley, London, 1974.   \n[40] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637\u20135664. PMLR, 2021.   \n[41] Isaac Levi. The Enterprise of Knowledge. London, UK $:$ MIT Press, 1980.   \n[42] Da Li, Henry Gouk, and Timothy Hospedales. Finding lost dg: Explaining domain generalization via model complexity. arXiv preprint arXiv:2202.00563, 2022.   \n[43] Shaojie Li and Yong Liu. High probability generalization bounds with fast rates for minimax problems. In International Conference on Learning Representations, 2021.   \n[44] Percy Liang. Statistical learning theory. Lecture notes for the course CS229T/STAT231 of Stanford University, 2016.   \n[45] Julian Lienen and Eyke H\u00fcllermeier. Credal self-supervised learning. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 14370\u201314382. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/ 7866c91c59f8bffc92a79a7cd09f9af9-Paper.pdf.   \n[46] Xing Liu and Fran\u00e7ois-Xavier Briol. On the Robustness of Kernel Goodness-of-Fit Tests. Available at arXiv:2408.05854, 2024.   \n[47] Pengyuan Lu, Michele Caprio, Eric Eaton, and Insup Lee. IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning. arXiv preprint arXiv:2305.14782, 2024.   \n[48] Shireen Kudukkil Manchingal and Fabio Cuzzolin. Epistemic deep learning. Available at arxiv:2206.07609, 2022.   \n[49] Shireen Kudukkil Manchingal, Muhammad Mubashar, Kaizheng Wang, Keivan Shariatmadar, and Fabio Cuzzolin. Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning. Available at arxiv:2307.05772, 2023.   \n[50] Massimo Marinacci and Luigi Montrucchio. Introduction to the mathematics of ambiguity. In Itzhak Gilboa, editor, Uncertainty in economic theory: a collection of essays in honor of David Schmeidler\u2019s 65th birthday. London : Routledge, 2004.   \n[51] Radu Marinescu, Debarun Bhattacharjya, Junkyu Lee, Fabio Cozman, and Alexander Gray. Credal marginal map. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36, pages 47804\u201347815. Curran Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper_files/ paper/2023/file/953390c834451505703c9da45de634d8-Paper-Conference.pdf.   \n[52] Georges Matheron. Random sets and integral geometry. Wiley Series in Probability and Mathematical Statistics, New York, 1975.   \n[53] Denis D. Maua, Cassio Polpo de Campos, Alessio Benavoli, and Alessandro Antonucci. On the complexity of strong and epistemic credal networks, 2013. URL https://arxiv.org/abs/ 1309.6845. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "[54] Denis Deratani Mau\u00e1 and Fabio Gagliardi Cozman. Thirty years of credal networks: Specification, algorithms and complexity. International Journal of Approximate Reasoning, 126: 133\u2013157, 2020. ISSN 0888-613X. doi: https://doi.org/10.1016/j.ijar.2020.08.009. URL https://www.sciencedirect.com/science/article/pii/S0888613X20302152. ", "page_idx": 13}, {"type": "text", "text": "[55] Ilya S Molchanov. Theory of random sets, volume 19. Springer, 2005.   \n[56] Thomas Mortier, Viktor Bengs, Eyke H\u00fcllermeier, Stijn Luca, and Willem Waegeman. On the calibration of probabilistic classifier sets. In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent, editors, Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 8857\u20138870. PMLR, 25\u201327 Apr 2023. URL https://proceedings.mlr.press/v206/mortier23a.html.   \n[57] Krikamol Muandet, David Balduzzi, and Bernhard Sch\u00f6lkopf. Domain generalization via invariant feature representation. In International conference on machine learning, pages 10\u201318. PMLR, 2013.   \n[58] Hung T. Nguyen. On random sets and belief functions. Journal of Mathematical Analysis and Applications, 65:531\u2013542, 1978.   \n[59] Fabrizio J. Piva, Daan de Geus, and Gijs Dubbelman. Empirical generalization study: Unsupervised domain adaptation vs. domain generalization methods for semantic segmentation in the wild. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), pages 499\u2013508, January 2023.   \n[60] Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Youn\u00e8s Bennani. A survey on domain adaptation theory: learning bounds and theoretical guarantees. arXiv preprint arXiv:2004.11829, 2020.   \n[61] Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. An online learning approach to interpolation and extrapolation in domain generalization. In International Conference on Artificial Intelligence and Statistics, pages 2641\u20132657. PMLR, 2022.   \n[62] Yusuf Sale, Viktor Bengs, Michele Caprio, and Eyke H\u00fcllermeier. Second-Order Uncertainty Quantification: A Distance-Based Approach. Available at arxiv:2312.00995, 2023.   \n[63] Yusuf Sale, Michele Caprio, and Eyke H\u00fcllermeier. Is the volume of a credal set a good measure for epistemic uncertainty? In Robin J. Evans and Ilya Shpitser, editors, Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence, volume 216 of Proceedings of Machine Learning Research, pages 1795\u20131804. PMLR, 31 Jul\u201304 Aug 2023.   \n[64] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. CesaBianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[65] Silvia Seoni, Vicnesh Jahmunah, Massimo Salvi, Prabal Datta Barua, Filippo Molinari, and U. Rajendra Acharya. Application of uncertainty quantification to artificial intelligence in healthcare: A review of last decade (2013\u20132023). Computers in Biology and Medicine, 165: 107441, 2023. ISSN 0010-4825. doi: https://doi.org/10.1016/j.compbiomed.2023.107441. URL https://www.sciencedirect.com/science/article/pii/S001048252300906X.   \n[66] Glenn Shafer. A mathematical theory of evidence, volume 42. Princeton university press, 1976.   \n[67] Paras Sheth, Raha Moraffah, K Sel\u00e7uk Candan, Adrienne Raglin, and Huan Liu. Domain generalization\u2013a causal perspective. arXiv preprint arXiv:2209.15177, 2022.   \n[68] Anurag Singh, Siu Lun Chau, Shahine Bouabid, and Krikamol Muandet. Domain generalisation via imprecise learning. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 45544\u201345570. PMLR, 21\u201327 Jul 2024. URL https://proceedings.mlr.press/v235/singh24a.html. ", "page_idx": 13}, {"type": "text", "text": "[69] Matthias C.M. Troffaes and Gert de Cooman. Lower Previsions. Chichester, United Kingdom : John Wiley and Sons, 2014. ", "page_idx": 14}, {"type": "text", "text": "[70] Peter Walley. Statistical Reasoning with Imprecise Probabilities, volume 42 of Monographs on Statistics and Applied Probability. London : Chapman and Hall, 1991.   \n[71] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip Yu. Generalizing to unseen domains: A survey on domain generalization. IEEE Transactions on Knowledge and Data Engineering, 2022.   \n[72] Kaizheng Wang, Fabio Cuzzolin, Keivan Shariatmadar, David Moens, and Hans Hallez. Credal wrapper of model averaging for uncertainty estimation on out-of-distribution detection, 2024. URL https://arxiv.org/abs/2405.15047.   \n[73] Kaizheng Wang, Keivan Shariatmadar, Shireen Kudukkil Manchingal, Fabio Cuzzolin, David Moens, and Hans Hallez. CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks. Available at arxiv:2401.05043, 2024.   \n[74] Larry A. Wasserman and Joseph B. Kadane. Bayes\u2019 theorem for Choquet capacities. The Annals of Statistics, 18(3):1328\u20131339, 1990.   \n[75] Haotian Ye, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, and Liwei Wang. Towards a theoretical framework of out-of-distribution generalization. Advances in Neural Information Processing Systems, 34:23519\u201323531, 2021.   \n[76] Yiwen Ye, Yutong Xie, Jianpeng Zhang, Ziyang Chen, Qi Wu, and Yong Xia. Continual self-supervised learning: Towards universal multi-modal medical data representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11114\u201311124, 2024.   \n[77] Jiazuo Yu, Yunzhi Zhuge, Lu Zhang, Ping Hu, Dong Wang, Huchuan Lu, and You He. Boosting continual learning of vision-language models via mixture-of-experts adapters. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23219\u201323230, 2024.   \n[78] Jianchun Zhang and Chuanhai Liu. Dempster\u2013Shafer inference with weak beliefs. Statistica Sinica, 21:475\u2013494, 2011.   \n[79] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022. ", "page_idx": 14}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof of Theorem 4.1. The proof builds on that of Liang [44, Theorem 4]. Fix any $\\epsilon>0$ , and any $P\\in\\mathcal P$ . Assume that the training dataset is given by $n$ i.i.d. draws from $P$ . We want to bound the probability that $L_{P}(\\hat{h})>\\epsilon$ . Define $B_{P}\\doteq\\{h\\in\\mathcal{H}:L_{P}(h)>\\epsilon\\}$ . It is the set of \u201cbad hypotheses\u201d according to distribution $P$ . As a consequence, we can write $\\mathbb{P}[{L}_{P}(\\hat{h})>\\epsilon]=\\mathbb{P}[\\hat{h}\\in\\dot{B_{P}}]$ . Recall that the empirical risk of the empirical risk minimizer is 0, that is, $\\hat{L}(\\hat{h})=0$ .9 So if the empirical risk minimizer is a bad hypothesis according to $P$ , that is, if ${\\hat{h}}\\in B_{P}$ , then some bad hypothesis (according to $P$ ) must have zero empirical risk. In turn, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\hat{h}\\in B_{P}]\\leq\\mathbb{P}[\\exists h\\in B_{P}:\\hat{L}(h)=0].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let us bound $\\mathbb{P}[\\hat{L}(h)=0]$ for a fixed $h\\in B_{P}$ . Given our choice of zero-one loss, on each example, hypothesis $h$ does not err with probability $1-L_{P}(h)$ . Since the training examples are i.i.d. and $\\bar{L_{P}}(h)>\\epsilon$ for all $h\\in B_{P}$ , then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\hat{L}(h)=0]=(1-L_{P}(h))^{n}\\leq(1-\\epsilon)^{n}\\leq\\exp(-\\epsilon n).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "9Indeed, at least $\\hat{L}(h^{\\star})=L_{P}(h^{\\star})=0$ . ", "page_idx": 14}, {"type": "text", "text": "Applying the union bound, we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}[\\exists h\\in B_{P}:\\hat{L}(h)=0]\\leq\\displaystyle\\sum_{h\\in B_{P}}\\mathbb{P}[\\hat{L}(h)=0]}\\\\ &{\\qquad\\qquad\\qquad\\le|B_{P}|\\exp(-\\epsilon n)}\\\\ &{\\qquad\\qquad\\le|\\cup_{P\\in\\mathcal{P}}B_{P}|\\exp(-\\epsilon n)}\\\\ &{\\qquad\\qquad\\qquad=|\\cup_{P^{\\mathrm{ex}}\\in\\exp}B_{P^{\\mathrm{ex}}}|\\exp(-\\epsilon n)}\\\\ &{\\qquad\\qquad\\qquad\\doteq\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The penultimate equality comes from $\\mathcal{P}$ being a credal set, by the Bauer Maximum Principle and the linearity of the expectation operator. Rearranging the terms we get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\epsilon^{\\star}(\\delta)\\equiv\\epsilon=\\frac{\\log|\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}}\\mathcal{P}\\;B_{P^{\\mathrm{ex}}}|+\\log(1/\\delta)}{n}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In turn, this implies that $\\mathbb{P}[L_{P}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)]\\geq1-\\delta.$ . ", "page_idx": 15}, {"type": "text", "text": "Proof of Corollary 4.2. Let $A_{\\hat{h}}\\doteq\\{(x,y)\\in\\mathcal{X}\\times\\mathcal{Y}:y\\ne\\hat{h}(x)\\}\\in\\mathcal{A}_{\\mathcal{X}\\times\\mathcal{Y}}.$ . Notice that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{P}(\\hat{h})=\\mathbb{E}_{P}[\\mathbb{I}(y\\neq\\hat{h}(x))]=P(A_{\\hat{h}}),}\\\\ {L_{Q}(\\hat{h})=\\mathbb{E}_{Q}[\\mathbb{I}(y\\neq\\hat{h}(x))]=Q(A_{\\hat{h}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Recall that $\\mathrm{diam}_{T V}(\\mathcal{P})\\doteq\\operatorname*{sup}_{P,Q\\in\\mathcal{P}}\\operatorname*{sup}_{A\\in\\mathcal{A}_{x\\times y}}|P(A)-Q(A)|$ . As a consequence, we have that $L_{Q}(\\hat{h})=L_{P}(\\hat{h})+\\zeta_{Q}$ , where $\\zeta_{Q}$ is a quantity in $[-\\eta,\\eta]$ depending on $Q$ . Given our assumption on the diameter, then, $L_{P}(\\hat{h})+\\zeta_{Q}\\leq L_{P}(\\hat{h})+\\eta$ , so $L_{Q}(\\hat{h})-\\eta\\leq L_{P}(\\hat{h})$ . In turn this implies that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left[L_{Q}(\\hat{h})-\\eta\\leq\\epsilon^{\\star}(\\delta)\\right]\\geq\\mathbb{P}\\left[L_{P}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The proof is concluded by noting that $\\mathbb{P}[L_{Q}(\\hat{h})-\\eta\\leq\\epsilon^{\\star}(\\delta)]=\\mathbb{P}[L_{Q}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)+\\eta],$ , and that $\\mathbb{P}[L_{P}(\\hat{h})\\leq\\epsilon^{\\star}(\\delta)]\\geq1-\\delta$ by Theorem 4.1. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proof of Corollary 4.3. Since $\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}}B_{P^{\\mathrm{ex}}}\\subseteq\\mathcal{H}$ , it is immediate to see that $\\epsilon^{\\star}(\\delta)\\,\\leq\\,\\epsilon_{\\mathrm{UB}}(\\delta)$ . In turn, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{sup}_{P\\in\\mathcal{P}}L_{P}(\\hat{h})\\leq\\epsilon_{\\mathsf{U B}}(\\delta)\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "or equivalently, $\\mathbb{P}[L_{P}(\\hat{h})\\leq\\epsilon_{\\mathrm{UB}}(\\delta)]\\geq1-\\delta$ , for all $P\\in\\mathcal P$ . ", "page_idx": 15}, {"type": "text", "text": "Proof of Corollary 4.4. From Theorem 4.1, we have that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{1}}(\\hat{h}_{1})\\leq\\frac{\\log\\left|\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}}B_{P^{\\mathrm{ex}}}\\right|+\\log(1/\\delta)}{k}\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{2}}(\\hat{h}_{2})\\leq\\frac{\\log\\left|\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}}B_{P^{\\mathrm{ex}}}\\right|+\\log(1/\\delta)}{n-k}\\right]\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The result, then, is an immediate consequence of the additivity of the expectation operator and of probability $\\mathbb{P}$ . \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem 4.5. The proof builds on that of Liang [44, Theorem 7]. Fix any $\\epsilon>0$ , and any $P\\in\\mathcal P$ . Assume that the training dataset is given by $n$ i.i.d. draws from $P$ . By Liang [44, Equations (158) and (186)], we have that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\big[L_{P}(\\boldsymbol{\\hat{h}})-L_{P}(\\boldsymbol{h}^{\\star})>\\epsilon\\big]\\leq\\mathbb{P}\\displaystyle\\left[\\operatorname*{sup}_{h\\in\\mathcal{H}}\\Big|\\hat{L}(h)-L_{P}(h)\\Big|>\\frac{\\epsilon}{2}\\right]}\\\\ &{\\phantom{\\leq\\quad}<|\\mathcal{H}|\\cdot2\\exp\\left(-2n\\left(\\frac{\\epsilon}{2}\\right)^{2}\\right)}\\\\ &{\\doteq\\delta(\\epsilon).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Notice though, that we can improve on this bound, since we know that $P\\in\\mathcal P$ , a credal set. Let $B_{P}^{\\prime}\\doteq\\{h\\in\\mathcal{H}:|\\hat{L}(h)-L_{P}(h)|>\\epsilon/2\\}$ be the set of \u201cbad hypotheses\u201d according to $P$ . Then, it is immediate to see that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{h\\in\\mathcal{H}}\\Big|\\hat{L}(h)-L_{P}(h)\\Big|=\\operatorname*{sup}_{h\\in B_{P}^{\\prime}}\\Big|\\hat{L}(h)-L_{P}(h)\\Big|\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Notice though that we do not know $P$ ; we only know it belongs to $\\mathcal{P}$ . Hence, we need to consider the set $B_{\\mathcal{P}}^{\\prime}$ of bad hypotheses according to all the elements of $\\mathcal{P}$ , that is, $B_{\\mathcal{P}}^{\\prime}\\doteq\\{h\\in\\mathcal{H}:\\exists P\\in$ $\\mathcal{P}$ $;|\\hat{L}(h)-L_{P}(h)|>\\epsilon/2\\}=\\cup_{P\\in\\mathcal{P}}B_{P}^{\\prime}$ . Since $\\mathcal{P}$ is a credal set, by the Bauer Maximum Principle and the linearity of the expectation operator we have that $B_{\\mathcal P}^{\\prime}\\;\\stackrel{}{=}\\;B_{\\mathrm{ex}\\mathcal P}^{\\prime}\\;\\doteq\\;\\{h\\;\\in\\;\\mathcal H\\;:\\;\\exists P^{\\mathrm{ex}^{\\cdot}}\\in$ $\\mathrm{ex}\\mathcal{P}$ , $|\\hat{L}(h)-L_{P}(h)|>\\epsilon/2\\}=\\cup_{P^{\\mathrm{ex}}\\in\\mathfrak{e x}\\mathcal{P}}B_{P^{\\mathrm{ex}}}^{\\prime}$ . Hence, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{h\\in\\mathcal{H}}\\Big|\\hat{L}(h)-L_{P}(h)\\Big|=\\operatorname*{sup}_{h\\in B_{\\mathrm{ex}}^{\\prime}\\mathcal{P}}\\Big|\\hat{L}(h)-L_{P}(h)\\Big|\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In turn, (8) implies that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\big[L_{P}(\\boldsymbol{\\hat{h}})-L_{P}(\\boldsymbol{h}^{\\star})>\\epsilon\\big]\\leq\\mathbb{P}\\left[\\underset{h\\in B_{\\mathrm{exp}}^{\\prime}}{\\operatorname*{sup}}\\;\\Big|\\boldsymbol{\\hat{L}}(h)-L_{P}(h)\\Big|>\\frac{\\epsilon}{2}\\right]}\\\\ &{\\qquad\\qquad\\qquad<|B_{\\mathrm{ex}}^{\\prime}\\mathscr{P}|\\cdot2\\exp\\left(-2n\\left(\\frac{\\epsilon}{2}\\right)^{2}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\doteq\\delta_{\\mathrm{ex}}\\mathscr{P}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Rearranging, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\epsilon=\\sqrt{\\frac{2\\left(\\log|B_{\\mathrm{ex}}^{\\prime}\\mathcal{P}|+\\log\\left(\\frac{2}{\\delta_{\\mathrm{ex}}\\mathcal{P}}\\right)\\right)}{n}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "so if $\\delta$ is fixed, we can write $\\epsilon\\equiv\\epsilon^{\\star\\star}(\\delta)$ . In turn, this implies that $\\mathbb{P}[L_{P}(\\hat{h})-L_{P}(h^{\\star})>\\epsilon^{\\star\\star}(\\delta)]<\\delta$ , or equivalently, $\\mathbb{P}[L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)]\\geq1-\\delta$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Proof of Corollary 4.6. The first part of the proof is very similar to that of Corollary 4.2. Given our assumption on the diameter, we have that $L_{Q}\\dot{(h)}-L_{P}(\\dot{h^{\\star}})=L_{P}(\\hat{h})+\\zeta_{Q}-L_{P}(h^{\\star}),$ , where $\\zeta_{Q}$ is a quantity in $[-\\eta,\\eta]$ depending on $Q$ . Then, $L_{P}(\\hat{h}){+}\\zeta_{Q}{-}L_{P}(h^{\\star})\\leq L_{P}(\\hat{h}){+}\\eta{-}L_{P}(h^{\\star})$ , so $L_{Q}(\\hat{h})-$ $\\eta-L_{P}(h^{\\star})\\leq L_{P}(\\hat{h})-L_{P}(h^{\\star})$ . In turn this implies that $\\begin{array}{r}{\\mathbb{P}\\left[L_{Q}(\\hat{h})-\\eta-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)\\right]\\geq}\\end{array}$ $\\mathbb{P}\\left[L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)\\right]$ . The proof is concluded by noting that $\\mathbb{P}[L_{Q}(\\hat{h})-\\eta-L_{P}(h^{\\star})\\leq$ $\\epsilon^{\\star\\star}(\\delta)]=\\mathbb{P}[L_{Q}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)+\\eta]$ , and that $\\mathbb{P}[L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)]\\geq1-\\delta$ by Theorem 4.5. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Proof of Corollary 4.7. Since $\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}}B_{P^{\\mathrm{ex}}}^{\\prime}\\subseteq\\mathcal{H}$ , it is immediate to see that $\\epsilon^{\\star\\star}(\\delta)\\leq\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)$ . In turn, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{sup}_{P\\in\\mathcal{P}}\\left(L_{P}(\\boldsymbol{\\hat{h}})-L_{P}(h^{\\star})\\right)\\leq\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "or equivalently, $\\mathbb{P}[L_{P}(\\boldsymbol{\\hat{h}})-L_{P}(h^{\\star})\\leq\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)]\\geq1-\\delta$ , for all $P\\in\\mathcal P$ . ", "page_idx": 16}, {"type": "text", "text": "Proof of Corollary 4.8. From Theorem 4.5, we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{1}}(\\hat{h}_{1})-L_{P_{1}}\\left(h_{P_{1}}^{\\star}\\right)\\leq\\sqrt{\\frac{2\\left(\\log|B_{\\mathrm{ex}}^{\\prime}\\mathscr{P}|+\\log\\left(\\frac{2}{\\delta}\\right)\\right)}{k}}\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{2}}(\\hat{h}_{2})-L_{P_{2}}\\left(h_{P_{2}}^{\\star}\\right)\\leq\\sqrt{\\frac{2\\left(\\log|B_{\\mathrm{ex}}^{\\prime}\\mathscr{P}|+\\log\\left(\\frac{2}{\\delta}\\right)\\right)}{n-k}}\\right]\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The result, then, is an immediate consequence of the additivity of the expectation operator and of probability $\\mathbb{P}$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 4.9. Fix any $\\delta\\,\\in\\,(0,1)$ . In Liang [44, Theorem 9], the author shows that for a fixed probability measure $P$ on $\\mathcal X\\times\\mathcal X$ , we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\nL_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq4R_{n,P}(\\mathcal{A})+\\sqrt{\\frac{2\\log(2/\\delta)}{n}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "holds with probability at least $1-\\delta$ , where $R_{n,P}$ is defined analogously as in (6). The result in (5), then, follows from $\\mathcal{P}$ being a credal set, and the expectation being a linear operator. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Proof of Corollary 4.10. Immediate from Theorem 4.9. ", "page_idx": 17}, {"type": "text", "text": "Proof of Corollary 4.11. The proof is very similar to that of Corollary 4.6. ", "page_idx": 17}, {"type": "text", "text": "Proof of Corollary 4.12. From Theorem 4.9, we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{1}}(\\hat{h}_{1})-L_{P_{1}}(h_{1}^{\\star})\\leq4\\overline{{R}}_{k,P^{\\mathrm{ex}}}(\\mathcal{A})+\\sqrt{\\frac{2\\log(2/\\delta)}{k}}\\right]\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[L_{P_{2}}(\\hat{h}_{2})-L_{P_{2}}(h_{2}^{\\star})\\leq4\\overline{{R}}_{n-k,P^{\\mathrm{ex}}}(\\cal{A})+\\sqrt{\\frac{2\\log(2/\\delta)}{n-k}}\\right]\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The result, then, is an immediate consequence of the additivity of the expectation operator and of probability $\\mathbb{P}$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "B Synthetic Experiments on Theorems 4.1 and 4.5 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we perform synthetic experiments to show that the bounds we find in Theorems 4.1 and 4.5 are indeed tighter than the classical SLT ones reported in Corollaries 4.3 and 4.7, respectively. In recent literature, studies by Amit et al. [7], Kacham and Woodruff [38], Li and Liu [43] have conducted synthetic experiments in a similar manner. These works are mainly theoretical in nature, but they also acknowledge the importance of experimental validation with preliminary analysis. ", "page_idx": 17}, {"type": "text", "text": "Experiment 1: Let the available training sets be $D_{1},D_{2},D_{3}$ . Assume, for simplicity, that $\\Omega=$ $\\ X\\times\\mathcal{Y}=\\{x\\}\\times\\mathbb{R}\\simeq\\mathbb{R}$ . Suppose that we specified the likelihood pdfs $\\ell_{1}=\\mathcal{N}(-5,1)$ , $\\ell_{2}=\\mathcal{N}(0,1)$ , and $\\ell_{3}=\\mathcal{N}(5,1)$ . Call $\\mathcal{L}_{1},\\mathcal{L}_{2},\\mathcal{L}_{3}$ their respective probability measures, and derive the credal set $\\mathcal{P}$ as we did in footnote 7. That is, let $\\mathcal{P}\\doteq\\operatorname{Conv}(\\{\\mathcal{L}_{i}\\}_{i=1}^{3})$ . We determine the credal set in this way because it is then easy to find its extreme elements $\\mathrm{ex}\\mathcal{P}$ . Indeed, it is immediate to notice that $\\mathrm{ex}\\dot{\\mathcal{P}}=\\{\\mathcal{L}_{i}\\}_{i=1}^{3}$ . Let now $D_{N+1}\\equiv D_{4}$ be a collection of $n$ samples from $P^{\\mathrm{true}}\\equiv\\mathcal{L}_{2}\\in\\mathcal{P}$ . The hypotheses space $\\mathcal{H}$ is defined as a finite set of simple binary classifiers containing at least one realizable hypothesis, and we consider the zero-one loss $l$ as we did in the main portion of the paper. ", "page_idx": 17}, {"type": "text", "text": "We need to find $\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}\\mathcal{P}}B_{P^{\\mathrm{ex}}}=\\cup_{i=1}^{3}\\{h\\in\\mathcal{H}:L_{\\mathcal{L}_{i}}(h)>\\epsilon\\}$ , where $\\epsilon$ depends on $\\delta$ as in the proof of Theorem 4.1. That is, we want those $h$ \u2019s for which the expected loss according to ${\\mathcal{L}}_{1}$ or ${\\mathcal{L}}_{2}$ or $\\mathcal{L}_{3}$ is larger than $\\epsilon$ . They are the collection of \u201cbad hypotheses\u201d according to at least one of the extreme elements of our credal set. Recall that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\epsilon^{\\star}(\\delta)=\\frac{\\log|\\cup_{P^{\\mathrm{ex}}\\in\\mathrm{ex}}\\mathcal{P}\\;B_{P^{\\mathrm{ex}}}|+\\log(1/\\delta)}{n}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "is the bound we found in Theorem 4.1, and that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\epsilon_{\\mathrm{UB}}(\\delta)=\\frac{\\log|\\mathcal{H}|+\\log(1/\\delta)}{n}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "is the classical SLT bound, that we reported in Corollary 4.3. ", "page_idx": 17}, {"type": "text", "text": "As we can see from Table B.1, our bound $\\epsilon^{\\star}(\\delta)$ improves on the classical SLT one $\\epsilon_{\\mathrm{UB}}(\\delta)$ . Table B.1 also tells us that bound $\\epsilon^{\\star}(\\delta)$ is tighter than $\\epsilon_{\\mathrm{UB}}(\\delta)$ when the sample size $n=|D_{4}|$ is small, and then $\\epsilon^{\\star}(\\delta)$ becomes progressively closer to $\\epsilon_{\\mathrm{UB}}(\\delta)$ as $n=|D_{4}|$ increases. This same pattern is observed when the extrema of the credal set are closer to each other. Indeed, in Table B.2 we repeat the experiment and choose as extrema of $\\mathcal{P}$ three measures whose pdf\u2019s are three Normals $\\mathcal{N}(-0.1,1)$ , $\\mathcal{N}(0,1)$ , and $\\mathcal{N}(0.1,1)$ .10 The reason for this behavior is the following. With few available samples, that is, when $n=|D_{4}|$ is low, Credal Learning Theory is able to leverage the evidence encoded in the credal set, and hence to derive a tighter bound than classical Statistical Learning Theory. When the sample size is large, that is, when $n=|D_{4}|$ is high, the classical bound $\\epsilon_{\\mathrm{UB}}(\\delta)$ itself is very small. This is because the amount of evidence available is large, and so $1/n\\textstyle\\sum_{i=1}^{n}l((x_{i},y_{i}),h)$ well approximates $\\begin{array}{r}{\\int_{\\mathcal{X}\\times\\mathcal{Y}}l((x,y),h)P^{\\mathrm{true}}(\\mathbf{d}(x,y))}\\end{array}$ . In turn, since $\\epsilon_{\\mathrm{UB}}(\\delta)$ is already very small, then the CLT bound $\\epsilon^{\\star}(\\delta)$ we derive cannot improve greatly on it. Hence, their values are close together, despite $\\epsilon^{\\star}(\\delta)$ being slightly tighter. The code for this experiment is available upon request. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "table", "img_path": "AH5KwUSsln/tmp/2e452a1e45ecf0737581dd6b456bda92cf55072e5c261b5877856884a8a76b79.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "AH5KwUSsln/tmp/35834719e009951bab6ae3aa55cbf504d5b4b907dca0d104fd99ea5d0f3849b8.jpg", "table_caption": ["Table B.1: Results of experimental evaluation of our bound tightness. Here the hypotheses space is such that $|\\mathcal{H}|\\,=\\,100$ , and $\\delta\\,=\\,0.05$ . The likelihood pdfs $\\ell_{1}=\\mathcal{N}(-5,1)$ , $\\ell_{2}=\\mathcal{N}(0,1)$ , and $\\ell_{3}=\\mathcal{N}(5,1)$ . "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Experiment 2: We conducted another synthetic experiment to show that the empirical risk for a given distribution is upper bounded by the traditional SLT bound of Corollary 4.3. This is a sanity check to see whether the environment we used in Experiment 1 is a valid one to check our results. ", "page_idx": 18}, {"type": "text", "text": "For the experiment, we selected a standard Gaussian distribution ${\\mathcal{N}}(0,1)$ (mean 0, standard deviation 1) to generate data. Similarly to Experiment 1, (i) the hypotheses space $\\mathcal{H}$ is defined as a finite set of simple binary classifiers containing at least one realizable hypothesis, and (ii) we assume a zero-one loss function. The latter is used to evaluate the performance of the classifiers. For each run, we generated a training set and a test set from the standard Gaussian distribution. At training time, for each hypothesis $h$ in $\\mathcal{H}$ , we calculate the empirical risk on the training set using the zero-one loss and identify the hypothesis $\\hat{h}$ that minimizes such risk (the empirical risk minimizer). At test time, we compute the empirical risk $L_{P}(\\hat{h})$ of $\\hat{h}$ on the test set as shown in Table B.3.11 ", "page_idx": 18}, {"type": "table", "img_path": "AH5KwUSsln/tmp/27e92c84b55a77dc3241b11dd8f5c96edd5148f84ca2b5aeac7d54341d8a4c8f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Table B.3: Results of experimental evaluation. The hypotheses space is such that $\\begin{array}{r}{\\overline{{\\vert\\mathcal{H}\\vert=100}}}\\end{array}$ , and $\\delta=0.05$ . ", "page_idx": 18}, {"type": "text", "text": "We calculate the upper bound $\\epsilon_{\\mathrm{UB}}(\\delta)$ on the empirical risk based on Corollary 4.3, which is a function of the number of hypotheses in $\\mathcal{H}$ , the value of $\\delta$ , and the number $n$ of training samples. This is the classic SLT bound. The experiment is run 1000 times with specified numbers of training and test samples, and a $\\delta$ value of 0.05 to check whether the condition (empirical risk on the test set is upper bounded by the theoretical bound) is satisfied in any of the 1000 trials. The experimental results in Table B.3 validate the classical SLT bound by repeatedly testing it on randomly generated data. The code for this experiment is also available upon request. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Experiment 3: In this, we aim to empirically validate Theorem 4.5, which addresses the behavior of the empirical risk minimizer in the presence of a finite hypothesis space and no realizability. We generate synthetic data from Gaussian distributions (with the same parameters as in Experiment 1), with added uniform noise to ensure no realizability, meaning that no hypothesis can perfectly predict the labels. The hypotheses space $\\mathcal{H}$ is defined as a set of threshold-based classifiers parameterized by $\\theta$ . For the experiment, we generate training samples $D_{1},D_{2},D_{3}$ and test sample $D_{4}$ from Gaussian distributions with added noise. Labels are created based on the samples, with noise introduced to filp labels randomly, ensuring that no hypothesis in $\\mathcal{H}$ can achieve zero loss. We identify the empirical risk minimizer $\\hat{h}$ using the combined training samples $D_{1},D_{2},D_{3}$ . We calculate the empirical risk $L_{P}(\\hat{h})$ using the test data $D_{4}$ . The theoretical risk $L_{P}(h^{\\star})$ is assumed to be the risk of a perfect classifier. We compute the theoretical bound $\\epsilon^{\\star\\star}(\\delta)$ and verify whether the difference $L_{P}(\\hat{h})-L_{P}(h^{\\star})$ is within this bound. The results show that the empirical risk of the empirical risk minimizer $\\hat{h}$ is within the bound $\\epsilon^{\\star\\star}(\\delta)$ of the best theoretical model $h^{\\star}$ . The difference $L_{P}(\\hat{h})-L_{P}(h^{\\star})$ also satisfies the condition ", "page_idx": 19}, {"type": "equation", "text": "$$\nL_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This validates empirically (in a synthetic environment) Theorem 4.5, showing that even under no realizability, the empirical risk minimizer\u2019s performance is close to the theoretical best within a computable bound. The experimental results are presented in Table B.4, where we also show (i) that $\\begin{array}{r}{\\epsilon^{\\star\\star}(\\delta)\\leq\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)\\doteq\\sqrt{\\frac{2\\left(\\log|\\mathcal{H}|+\\log\\left(\\frac{2}{\\delta}\\right)\\right)}{n}}}\\end{array}$ from Corollary 4.7 always holds; and (ii) that by foregoing realizability, we obtain a slightly looser bound. Indeed, as we can see, $\\epsilon^{\\star\\star}(\\delta)$ is slightly larger than $\\epsilon^{\\star}(\\delta)$ from Table B.1 for all the sample size values $n$ that we consider. The code for this experiment is also available upon request. ", "page_idx": 19}, {"type": "table", "img_path": "AH5KwUSsln/tmp/b633f360d8d8011d9461dc4f2c37d8dd06e523208bb8bae0361f40474b8f6c9a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Table B.4: Results of experimental evaluation of Theorem 4.5. Here the hypotheses space is such that $|\\mathcal{H}|=100$ , $\\delta=0.05$ and noise level 0.1. The likelihood pdfs $\\ell_{1}=\\mathcal{N}(-5,1)$ , $\\bar{\\ell}_{2}=\\mathcal{N}(0,1)$ , and $\\ell_{3}=\\mathcal{N}(5,1)$ . Let us remark that in this experiment we forego the assumption of realizability, that $L_{P}(\\hat{h})-L_{P}(h^{\\star})\\leq\\epsilon^{\\star\\star}(\\delta)$ for every sample size we tested on, and that $\\epsilon^{\\star\\star}(\\delta)\\leq\\epsilon_{\\mathrm{UB}}^{\\prime}(\\delta)$ for every sample size we tested on. ", "page_idx": 19}, {"type": "text", "text": "C A Simple Numerical Example for the $\\epsilon$ -Contamination Model of Section 3.1.1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Just like in Section 3.1.3, let $\\Omega=\\{\\omega_{1},\\omega_{2},\\omega_{3}\\}$ , where $\\omega_{j}=(x_{j},y_{j})$ , $j\\in\\{1,2,3\\}$ . Suppose also that we observed four training samples $D_{1},\\ldots,D_{4}$ and that we specified the likelihoods $\\mathcal{L}_{1},\\ldots,\\mathcal{L}_{4}$ as in the following Table. ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\frac{1}{\\begin{array}{c}{{\\left(\\omega_{1}\\right)}}\\end{array}}}\\,{\\begin{array}{c}{{\\left\\{\\omega_{2}\\right\\}}}\\end{array}}\\,{\\begin{array}{c}{{\\left\\{\\omega_{3}\\right\\}}}\\\\ {{\\begin{array}{c}{{0.3}}\\end{array}}}\\end{array}}}\\\\ {{\\begin{array}{c}{{\\mathcal{L}_{2}}}\\\\ {{\\mathcal{L}_{3}}}\\\\ {{\\mathcal{L}_{4}}}\\end{array}}\\,{\\begin{array}{c c c}{{0.2}}&{{0.4}}\\\\ {{0.1}}&{{0.8}}&{{0.1}}\\end{array}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, suppose that $\\epsilon_{1}~=~0.2$ , $\\epsilon_{2}~=~0.3$ , $\\epsilon_{3}~=~0.1$ , and $\\epsilon_{4}~=~0.25$ , so that ${\\mathcal{L}}_{1}\\,=\\,\\{P\\,:\\,P\\,=$ $0.8\\mathcal{L}_{1}\\,+\\,\\stackrel{..}{0.2}\\!Q,\\forall Q\\,\\in\\,\\Delta_{\\Omega}\\}$ , ${\\mathcal{L}}_{2}\\,=\\,\\{P\\,:\\,P\\,=\\,0.7{\\mathcal{L}}_{2}+0.3Q,\\forall Q\\,\\in\\,\\Delta_{\\Omega}\\},$ ${\\mathcal{L}}_{3}\\,=\\,\\{P\\,:\\,P\\,=$ $0.9\\mathcal{L}_{3}+0.1Q$ , $\\forall Q\\in\\Delta_{\\Omega}\\}$ , and $\\mathcal{L}_{4}=\\{P:P=0.75\\mathcal{L}_{4}+0.25Q,\\forall Q\\in\\Delta_{\\Omega}\\}$ . By Wasserman and Kadane [74, Example 3], we know that, if we put $\\mathcal{P}=\\mathrm{Conv}(\\cup_{i=1}^{4}\\mathcal{L}_{i})$ , the following holds ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\underline{{P}}(A)=\\left\\{\\!\\!\\begin{array}{l l}{\\operatorname*{min}_{i\\in\\{1,\\dots,4\\}}(1-\\epsilon_{i})\\mathcal{L}_{i}(A),}&{\\forall A\\neq\\Omega}\\\\ {1,}&{\\mathrm{if~}A=\\Omega}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\overline{{P}}(A)=\\left\\{\\!\\!\\!\\begin{array}{l l}{\\operatorname*{max}_{i\\in\\{1,...,4\\}}(1-\\epsilon_{i})\\mathcal{L}_{i}(A)+\\epsilon_{i},}&{\\forall A\\neq\\varnothing}\\\\ {0}&{\\mathrm{if~}A=\\varnothing}\\end{array}\\!\\!\\right..\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Simple calculations, then, give us the following values ", "page_idx": 20}, {"type": "table", "img_path": "AH5KwUSsln/tmp/336ad46eaedf8b379d1a0d3b11a89996cf75e25fc747cc728729f1fc0bc85438.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "As we can see, in this example too, the probability bounds imposed by the credal set are not too stringent, and in line with the evidence encapsulated in $\\mathcal{L}_{1},\\ldots,\\mathcal{L}_{4}$ . Hence, the assumption that $P^{\\mathrm{true}}\\equiv P_{5}^{\\star}\\in\\mathcal{P}$ is very plausible. For a visual representation of the credal set $\\mathcal{P}=\\mathbf{Conv}\\bar{(}\\cup_{i=1}^{4}\\mathcal{L}_{i})$ , see the yellow convex region in the next figure; it is very similar to the convex region in Figure 2. This is unsurprising since the evidence used to derive the credal set in Section 3.1.3 is the same that we use to elicit $\\mathcal{P}$ here. ", "page_idx": 20}, {"type": "image", "img_path": "AH5KwUSsln/tmp/6f768bb3fe0e998401ce74378bc3605e9dee8b6ced55f81a6b1e1417e56b54d7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "D A Fiducial Approach to Objectivist Modeling ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "An alternative objectivist approach to the ones presented in Section 3.1, proposed by Dempster and Almond [3], is based on fiducial inference [32]. Consider a parametric model, i.e., a family of conditional probability distributions of the data $\\{f(\\omega|\\theta):\\omega\\in\\Omega,\\theta\\in\\Theta\\}$ , where $\\Omega$ is, again, the observation space and $\\Theta$ is a parameter space. If the parametric (sampling) model is supplemented by a suitably designed auxiliary equation $\\omega=a(\\theta,u)$ , where $u$ is a \u201cpivot\" variable of known a-priori distribution $\\mu$ , one obtains a random set $\\Gamma$ mapping pivot values $u$ to subsets ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Gamma(u)=\\{(\\omega,\\theta)\\in\\Omega\\times\\Theta:\\omega=a(\\theta,u)\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "of $\\Omega\\times\\Theta$ . This, in turn, induces a belief function on the product space $\\Omega\\times\\Theta$ defined as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname{Bel}(A)=\\sum_{u\\in U:\\Gamma(u)\\subset A}\\mu(u),\\quad A\\subset\\Omega\\times\\Theta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This can be finally be marginalized to the data space $\\Omega=\\mathcal{X}\\times\\mathcal{Y}$ to generate a belief function there. This approach was further extended by Martin, Zhang, and Liu, who used a \u201cpredictive\" random set to express uncertainty on the pivot variable itself, leading to a weak belief inference technique [78]. ", "page_idx": 20}, {"type": "text", "text": "In our framework, in which a finite sample of $N$ training sets $\\{D_{i}\\}_{i=1}^{N}$ is available, we can derive $N$ many random sets $\\Gamma_{i}$ as before, $i\\in\\{1,\\overline{{\\ldots}},N\\}$ , and consider the $N$ belief functions $\\mathrm{Bel}_{i}$ on $\\Omega\\times\\Theta$ they induce. Then, we can compute their marginalization $\\mathrm{\\mathbf{B}e l}_{i}|_{\\Omega}$ on the data space $\\Omega=\\mathcal{X}\\times\\mathcal{Y}$ , and compute the minimum $\\underline{{\\mathbf{B}\\mathbf{e}}}\\vert_{\\Omega}\\,\\doteq\\,\\operatorname*{min}_{i\\in\\{1,...,N\\}}\\mathbf{B}\\mathbf{e}\\ensuremath{\\mathrm{l}_{i}}\\vert_{\\Omega}$ . It is easy to see that ${\\underline{{\\mathbf{B}}}}\\mathbf{el}|_{\\Omega}$ is itself a well-defined belief function. Finally, our credal set is given by $\\mathscr{P}=\\mathscr{M}(\\underline{{\\mathbf{B}}}\\mathbf{e}\\mathbf{l}|_{\\Omega})$ as in Section 3.1.2. ", "page_idx": 21}, {"type": "text", "text": "E Related Work on the Computational Complexity of Credal Sets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we discuss some of the analyses existing in the literature of the computational complexity specific to the use of credal sets, particularly in the context of graphical models and probabilistic inference. Such approaches can be implemented for large datasets, but they often require approximation techniques to be computationally feasible [45, 53, 54]. Despite this, credal set approaches can be implemented for large datasets using techniques like parallel processing, distributed computing, and efficient data structures. Similar to Deep Learning-based approaches, utilization of high-performance computing resources, algorithm optimization, and domain-specific adaptations, the computational challenges can be effectively managed. Recent advancements demonstrate the practicality of these approaches. For instance, Credal-Set Interval Neural Networks (CreINNs) have shown significant improvements in inference time over variational Bayesian neural networks [73]. Thus, while the computational demands are comparable to those of deep learning-based methods, the robustness and flexibility of credal sets, as demonstrated in recent research, make them a practical and valuable approach [51, 72]. ", "page_idx": 21}, {"type": "text", "text": "F On the Relation Between Credal Sets and Continual Learning ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The credal approach in this paper is closely linked to Continual Learning applications, which emphasize the need to handle diverse and sequential datasets to achieve robust and generalizable models. Recent works in continual learning have demonstrated the practical applications and beneftis of using a multi-dataset setup. For instance, Jeeveswaran et al. [37] introduce a novel method for domain incremental learning, leveraging multiple datasets to adapt seamlessly across different tasks. Another example is Yu et al. [77], who propose a parameter-efficient continual learning framework that dynamically expands a pre-trained CLIP model through Mixture-of-Experts (MoE) adapters in response to new tasks. Ye et al. [76] address the challenges of multi-modal medical data representation learning through a continual self-supervised learning approach. These examples from recent studies demonstrate the practical applications and benefits of using a multi-dataset setup in a continual learning framework. Furthermore, some techniques use a multi-dataset setup in continual learning without relying on a specific temporal order. For example, Alssum et al. [4] present a replay mechanism based on single frames, arguing that video diversity is more crucial than temporal information under extreme memory constraints. By storing individual frames rather than contiguous sequences, they can maintain higher diversity in the replay memory, which leads to better performance in continual learning scenarios. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 22}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 22}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] . ", "page_idx": 22}, {"type": "text", "text": "\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available. \u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 22}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 22}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 22}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 22}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: The main claims presented in both the abstract and introduction align well with the contributions and scope of the paper. The abstract succinctly outlines the theoretical framework and the bounds introduced in the paper, laying the foundations for a \u2018credal\u2019 learning theory to model variability in data-generating distributions. Similarly, the introduction provides a comprehensive account of the relevant background, the motivation behind the research, and the significance of the proposed learning framework. Throughout the manuscript, there is consistent support for the claims made in the abstract and introduction. The results from synthetic experiments conducted, and the theoretical results in the paper, provide detailed insights into the novel learning framework and reinforce the claims by demonstrating the effectiveness and relevance of the proposed framework. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper. \u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The main limitations of this paper are two. The first is that we only consider the zero-one loss in our results. The other is that we assume that the true distribution which the elements of the new test set $D_{N+1}$ are sampled from, belongs to the credal set we derive at training time. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The assumptions are thoroughly discussed in the main body of the paper. Proofs are provided in the Appendix section. We have taken great care to provide complete and correct proofs, structured in a logical and transparent manner, for each theoretical result. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. ", "page_idx": 23}, {"type": "text", "text": "\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] We conducted three synthetic experiments. One serves as a sanity check, while the other demonstrates that the bound established in Theorem 4.1 is tighter than the classical bound found in Statistical Learning Theory (SLT). The third one validates empirically Theorem 4.5, showing that even under no realizability, the empirical risk minimizer\u2019s performance is close to the theoretical best within a computable bound. ", "page_idx": 24}, {"type": "text", "text": "Justification: Drawing inspiration from recent literature, including studies by Kacham and Woodruff [38], Amit et al. [7], Li and Liu [43], we have conducted synthetic experiments in a similar manner. While these works are primarily theoretical, they recognize the importance of experimental validation through preliminary analysis. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: The experiments are synthetic and extremely easy to reproduce. Also, the experiments do not require any special libraries or large-scale real-world datasets. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We have clearly mentioned all the details of our synthetic experiments. In the Supplementary Section B, we provide comprehensive details of our training data and hyperparameter values. Tables B.1 and B.2 present the results of our bound tightness experiments alongside the hyperparameter values used. Additionally, Table B.3 displays the outcomes of our sanity check experiment. Table B.4 presented the results of the experimental evaluation of Theorem 4.5. Together, the details of these experiments enhance the support for our theoretical results. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "page_idx": 25}, {"type": "text", "text": "Justification: In our experiments, we primarily rely on sampling from known distributions and calculating the theoretical bounds as detailed in the main text of the paper. Given the theoretical nature of our analysis and the use of these known distributions, traditional error bars or measures of statistical significance are not necessary for conveying the reliability of our results. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 25}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [No] ", "page_idx": 26}, {"type": "text", "text": "Justification: There is no need to discuss the allocation of computer resources, as the synthetic experiments we conducted can be performed on any standard computer. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The experiments in our work are entirely synthetic. This means that they do not involve real individuals or sensitive data that could raise ethical concerns. The synthetic nature of our experiments ensures that they inherently avoid issues such as privacy breaches or misuse of personal data. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper presents work whose goal is to advance the theoretical foundations of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for the responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our study does not utilize or produce pretrained models, image generators, or datasets that are derived from scraping, which are typically associated with high risks for misuse. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The above is not applicable to our research, as our study exclusively employs synthetic data and self-generated models without relying on external assets, special libraries, or models. Therefore, there are no third-party assets involved that would require attribution or adherence to licensing terms. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The concern regarding the documentation of new assets is not applicable to our work. This is because our research does not introduce any new assets such as datasets, models, or software tools that would require documentation or accompanying flies. We have focused solely on synthetic experiments, which do not involve creating or releasing new assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This is not applicable in our case as our study exclusively involves synthetic experiments and does not engage with crowdsourcing methods or human subjects. Therefore, there are no participant instructions or compensation issues to report. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our research strictly involves synthetic experiments and does not include human participants. Consequently, the need for IRB review or any equivalent ethical oversight does not arise in the context of our research methodology. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]