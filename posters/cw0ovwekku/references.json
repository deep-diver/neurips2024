{"references": [{"fullname_first_author": "Laurent Dinh", "paper_title": "Sharp minima can generalize for deep nets", "publication_date": "2017-00-00", "reason": "This paper introduces the concept of sharp minima in deep learning, which is central to the paper's investigation of valley shapes."}, {"fullname_first_author": "Ian J. Goodfellow", "paper_title": "Qualitatively characterizing neural network optimization problems", "publication_date": "2015-00-00", "reason": "This foundational paper explores the loss landscape of neural networks, providing a basis for the current research on valley symmetry."}, {"fullname_first_author": "Hao Li", "paper_title": "Visualizing the loss landscape of neural nets", "publication_date": "2018-00-00", "reason": "This paper presents visualization techniques for understanding the loss landscape, which are crucial for the current paper's analysis of valley shapes."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Flat minima", "publication_date": "1997-00-00", "reason": "This early work introduces the concept of flat minima, which is a key aspect of the paper's discussion on valley types and their properties."}, {"fullname_first_author": "Haowei He", "paper_title": "Asymmetric valleys: Beyond sharp and flat local minima", "publication_date": "2019-00-00", "reason": "This paper directly addresses the concept of asymmetric valleys in deep neural networks, a key focus of the current study."}]}