[{"figure_path": "V2MBWYXp63/figures/figures_0_1.jpg", "caption": "Figure 1: An example of NKG construction.", "description": "This figure illustrates the process of constructing an N-ary Relational Knowledge Graph (NKG) from a natural language text.  The text describes several facts about Albert Einstein's life, including his education, professional positions, and the Nobel Prize he received. The figure shows how these facts are represented as interconnected n-ary relational facts within an NKG. Each n-ary fact involves multiple entities (Einstein, University of Zurich, Physics, Doctorate, Nobel Prize, etc.) and their relationships, capturing richer knowledge than simple binary relations.  The different colored circles represent different n-ary facts, and their overlaps highlight the shared entities and relationships, demonstrating the interconnectedness of information within the NKG.", "section": "1 Introduction"}, {"figure_path": "V2MBWYXp63/figures/figures_1_1.jpg", "caption": "Figure 2: Taking a real-world textual fact as an example, we can extract a four-arity structured span-tuple for entities (Einstein, University of Zurich, Doctorate, Physics) with an answer label-list for relations accordingly as a 4-ary relational fact from the sentence through n-ary relation extraction.", "description": "This figure illustrates the process of extracting a four-arity relational fact from a sentence.  It shows how a sentence, \"Einstein received his Doctorate degree in Physics from the University of Zurich.\" is processed. First, a span-tuple of entities is identified: (Einstein, University of Zurich, Doctorate, Physics).  Then, based on the identified entities and the sentence's meaning,  a list of relations is generated: [educated_at, academic_major, academic_degree]. Finally, these entities and relations are combined to form a four-arity relational fact in different NKG schemas (hyper-relational, event-based, role-based, hypergraph-based), demonstrating how the system handles varied schema representations of the same underlying information.", "section": "4 Methodology"}, {"figure_path": "V2MBWYXp63/figures/figures_3_1.jpg", "caption": "Figure 3: An overview of Text2NKG extracting n-ary relation facts from a natural language sentence in hyper-relational NKG schema for an example.", "description": "This figure illustrates the Text2NKG framework's process of extracting n-ary relation facts from a sample sentence.  It begins by inputting a sentence, then performs entity recognition, and creates span-tuples representing various entity combinations. A BERT-based encoder processes these tuples, feeding the information into a multi-label classification step to predict relations between entities.  Hetero-ordered merging refines these predictions, and output merging combines 3-ary relations into higher-arity ones. The example shown focuses on the hyper-relational schema of NKGs.", "section": "4.1 Overview of Text2NKG"}, {"figure_path": "V2MBWYXp63/figures/figures_7_1.jpg", "caption": "Figure 4: (a) Precision, Recall, and F\u2081 changes in the dev set during the training of Text2NKG. (b) The changes of the number of true facts, the number of predicted facts, and the number of predicted accurate facts during the training of Text2NKG. (c) Precision, Recall, and F\u2081 results on different null-label hyperparameter (\u03b1) settings.", "description": "This figure shows three plots illustrating different aspects of the Text2NKG model's performance during training and how it is affected by hyperparameter \u03b1. Plot (a) displays the precision, recall, and F1-score on the development set over training epochs. Plot (b) shows the number of true facts, predicted facts, and correctly predicted facts over epochs. Plot (c) demonstrates how precision, recall, and F1-score vary with different \u03b1 values.", "section": "5.2 Main Results (RQ1)"}, {"figure_path": "V2MBWYXp63/figures/figures_8_1.jpg", "caption": "Figure 5: (a) The changes of the number of extracted n-ary RE in different arity, where \"pred_n\" represents the number of extracted n-ary facts with different arities by Text2NKG, and \"ans_n\" represents the ground truth. (b) Case study of Text2NKG's n-ary relation extraction in four schemas on HyperRED.", "description": "Figure 5(a) is a graph showing the number of n-ary relations extracted by Text2NKG during training, broken down by arity (number of entities involved). It compares the number of predicted relations (\"pred_n\") against the actual number of relations (\"ans_n\") in the ground truth dataset, across different epochs of training.  Figure 5(b) provides a concrete example of how Text2NKG extracts n-ary relational facts from a sample sentence. It shows how a single sentence is processed to generate n-ary relational facts according to four different knowledge graph schemas (hyper-relational, event-based, role-based, and hypergraph-based).", "section": "5. Experiments"}]