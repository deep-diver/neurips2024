{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a model that bridges image and text understanding, which is foundational to the TADPoLe approach by providing a way to evaluate how well the generated images align with the text prompts."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper establishes the effectiveness of diffusion models for image generation, which is the core technology used in TADPoLe to generate reward signals for the agent."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces Stable Diffusion, a high-resolution image generation model based on diffusion, demonstrating the practical effectiveness of the method on high-resolution images."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper lays the theoretical foundation for diffusion models, providing a framework for understanding and developing the core technology behind the reward signals used in the TADPoLe method."}, {"fullname_first_author": "Yilun Du", "paper_title": "Learning universal policies via text-guided video generation", "publication_date": "2023-12-01", "reason": "This paper explores the use of text-guided video generation for learning universal policies, which is closely related to the TADPoLe approach in using generative models for policy learning, particularly addressing the temporal aspects of behavior generation."}]}