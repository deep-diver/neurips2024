[{"type": "text", "text": "A Swiss Army Knife for Heterogeneous Federated Learning: Flexible Coupling via Trace Norm ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tianchi Liao, Lele Fu, Jialong Chen, Zhen Wang, Zibin Zheng, Chuan Chen ", "page_idx": 0}, {"type": "text", "text": "Sun Yat-sen University, Guangzhou, China {liaotch, fulle, chenjlong}@mail2.sysu.edu.cn {wangzh665, zhzibin, chenchuan}@mail.sysu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The heterogeneity issue in federated learning (FL) has attracted increasing attention, which is attempted to be addressed by most existing methods. Currently, due to systems and objectives heterogeneity, enabling clients to hold models of different architectures and tasks of different demands has become an important direction in FL. Most existing FL methods are based on the homogeneity assumption, namely, different clients have the same architectural models with the same tasks, which are unable to handle complex and multivariate data and tasks. To flexibly address these heterogeneity limitations, we propose a novel federated multi-task learning framework with the help of tensor trace norm, FedSAK. Specifically, it treats each client as a task and splits the local model into a feature extractor and a prediction head. Clients can flexibly choose shared structures based on heterogeneous situations and upload them to the server, which learns correlations among client models by mining model low-rank structures through tensor trace norm. Furthermore, we derive convergence and generalization bounds under non-convex settings. Evaluated on 6 real-world datasets compared to 13 advanced FL models, FedSAK demonstrates superior performance. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated learning (FL) is an effective machine learning approach that enables decentralized computations and data resources [1]. It is regarded as a promising distributed and privacy-preserving method. A common challenge in FL is the data heterogeneity problem, in particular when the diversity of client data distribution increases, the generalization error of the global model increases significantly as well [2]. Therefore, to address data heterogeneity, common personalized federated learning (pFL) methods learn a personalized model for each client in addition to the global model [3, 4, 5]. ", "page_idx": 0}, {"type": "text", "text": "However, current research indicates that the fundamental bottleneck in executing pFL across heterogeneous clients is the misassumption of one global model can fit all clients [6]. Instead, we should focus on exploring intrinsic collaborations across clients to obtain better local models. Unlike pFL, the goal of federated multi-task learning (FMTL) is to simultaneously learn separate models, where each model caters to the heterogeneous needs of each client [7]. Thus, FMTL directly addresses the issues stemming from client heterogeneity without constructing a global model [8]. ", "page_idx": 0}, {"type": "text", "text": "Moreover, most of the existing FL methods require all clients to train models with the same architecture (i.e., model homogeneity) [9, 10, 11]. In practical heterogeneous FL scenarios, besides data heterogeneity, model heterogeneity and task heterogeneity are also present due to varying hardware, computational capabilities, and requirements across clients [12, 13]. Although some FL methods to handle model heterogeneity have emerged [14, 15, 16], many of them resort to knowledge distillation techniques that necessitate public datasets closely aligned with the learning objectives [17, 18]. This incurs high communications and computational costs, limiting model performance. Alternatively, some strategies utilize prototype models linked to labels [15, 16], rendering them futile when client tasks are related but inconsistent. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Currently, task heterogeneity is rarely mentioned in federated settings, however, it is widespread in real-world scenarios [19]. For example, given the same batch of portrait samples for different clients, some clients may want to predict person\u2019s age (Task 1: Multi-Class Classification or Regression), while others may need to recognize gender (Task 2: Binary Classification). In such scenario, existing methods are ill-equipped to handle task heterogeneity. Effective algorithms that can overcome data, model, and task heterogeneity in federated settings remain largely underdeveloped. ", "page_idx": 1}, {"type": "text", "text": "In light of the heterogeneity in FL and limitations of existing techniques, we adopt FMTL to address complex heterogeneous FL. A key issue in FMTL is how to design priors such that knowledge obtained from each client can be shared by others. Corinzia et al. [20] built connections among client tasks using approximate variational inference, while Dinh et al. [8] proposed a Laplace regularizationbased FMTL that only considers grouping similarities among different client tasks. To effectively utilize correlations across clients, Kumar et al. [21] proposed a method leveraging low-dimensional subspaces shared by multiple tasks, which was shown effective but limited to linear models. ", "page_idx": 1}, {"type": "text", "text": "Imposing low-rank constraints on model parameters is effective when learning objectives are correlated among clients [22]. Trace norm has been proposed as a solution to uncover potential connections among model parameters of different objectives. Thus, we propose a novel and flexible FMTL framework based on tensor trace norm, FedSAK, which like a Swiss Army Knife provides flexible aggregation choices for heterogeneous FL. Specifically, we split each client model into a feature extractor and a prediction head, allowing our model can adaptively define certain parts as global shared layers for different heterogeneity settings and upload them to the server. The server aggregates the global shared layers into a tensor and applies trace norm regularization to induce a low-rank structure. In this way, inter-dependencies are created among different client models to reflect across clients\u2019 intrinsic connections about their model parameters. In summary, our main contributions are: ", "page_idx": 1}, {"type": "text", "text": "\u2022 FedSAK is an FMTL algorithm that simultaneously considers data heterogeneity, model heterogeneity and task heterogeneity. It is more flexible than most existing FL methods.   \n\u2022 We employ tensor trace norm to exploit low-rank structure for identifying relationships among client models.   \n\u2022 We theoretically derive convergence guarantees for FedSAK under non-convex settings, and establish generalization bounds for the proposed tensor trace norm minimizer.   \n\u2022 We conduct extensive experiments on 13 advanced methods over 6 datasets to demonstrate the flexibility and efficacy of FedSAK. Results show that FedSAK outperforms baselines in handling heterogeneous federated scenarios. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Heterogeneous Federated Learning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Data Heterogeneity, is one of the most significant challenges in FL [23]. Initial methods like FedProx [2] added a proximal term to the local training objective to keep updated parameters close to the original downloaded model. MOON [9] employed contrastive loss to improve representation learning. Additionally, various personalized models have been proposed to train specialized components using globally shared information, including fine-tuning methods like FedRep [24], FedPer [25]; regularization-based methods such as FedMTL [7], pFedMe [4], and Ditto [5]; meta-learning methods like Per-FedAvg [3]; and methods decoupling feature extractors and classifiers like GPFL [10], FedCP [26]. Moreover, the clustered FL has also been explored by partitioning clients into multiple groups or clusters for clustered local models to provide multiple global models [27]. However, the development of existing data heterogeneity methods is constrained by homogenous model assumptions. ", "page_idx": 1}, {"type": "text", "text": "Model Heterogeneity presents another major challenge in FL. Researchers often employ FL based on knowledge distillation as an alternative solution. FedMD [17] have clients compute logits on a public dataset using locally trained heterogeneous models, which are then uploaded to the server. FedDF [28] and FedKT [29] train each client\u2019s heterogeneous model on a shared public dataset at the server via distillation. However, obtaining shared datasets with similar data distributions required by these methods may not always be feasible in a practical setting. Especially when the public dataset is large-scale, the computational costs of such methods can increase substantially, limiting their applicability. Additionally, there are FL methods of model heterogeneous that employ aggregated logit or representation matching losses by class to train local models e.g., FedProto [15] and FedGH [16]. However, these methods impose higher computational costs on clients. In addition, each client can only acquire knowledge of known categories from the server, restricting generalization to unseen categories as well as possibilities for task heterogeneity. ", "page_idx": 1}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/2ec07c533c90ca3c21976a73667304bffb7fa8ce761cc02ad82a1ac7a90e494f.jpg", "img_caption": ["Figure 1: The main framework of FedSAK model. DH denotes \u201cData Heterogeneity\u201d, MH denotes \u201cModel Heterogeneity\u201d, and TH denotes \u201cTask Heterogeneity\u201d. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Task Heterogeneity is an often overlooked issue in federated settings where tasks may have varying numbers of outputs in practice. Huang et al. [30] proposed a model for multi-lingual speech processing with each task corresponding to an individual language. Zhang et al. [31] employed DNNs for facial landmark localization and face attribute recognition. However, these task-heterogeneous methods have not been considered for FL. Yao et al. [32] first generalized traditional FL to federated heterogeneous task learning, but they did not propose a new algorithm and merely considered data and task heterogeneity. ", "page_idx": 2}, {"type": "text", "text": "2.2 Federated Multi-Task Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Multi-task learning (MTL) aims to process all task data with identical distributions centrally in a single computing environment [33]. In contrast, FMTL places greater emphasis on data privacy and heterogeneity. FMTL aims to learn separate models tailored to local heterogeneous conditions for each client. FMTL was first introduced in [7], where a system-aware optimization method was proposed that first considered theoretical issues like high communication costs, stragglers, and fault tolerance in FMTL. Yasmin et al. [34] formulated FMTL network using generalized total variation minimization as a regularizer. Li et al. [35] adopted FMTL algorithms to handle accuracy, fairness and robustness issues in FL. Corinzia et al. [20] modeled the FL network as a star-shaped Bayesian network and used approximate variational inference for FMTL. Dinh et al. [8] utilized Laplace regularization to construct relationships among clients. However, these methods operate under model homogeneity assumptions, and there is scarce analysis of the convergence and error bounds for non-convex FMTL objectives. To effectively utilize correlations across tasks, some MTL methods such as Maurer et al. [33] established excess risk bounds for MTL based on data distributions. Kumar et al. [21] proposed a new framework where in-group tasks lie in a low-dimensional subspace. Zhang et al. [22] employed transformed tensor nuclear norm constraints to capture intrinsic relationships among tasks. However, these methods did not explore federated settings and heterogeneity. ", "page_idx": 2}, {"type": "text", "text": "3 Notations and Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 General Federated Multi-Task Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Suppose we have $M$ clients, where client $i$ has $n_{i}$ private data points $\\mathbf{x}_{i}\\;\\in\\;\\mathbb{R}^{d_{\\mathbf{x}}\\times n_{i}}$ with labels $y_{i}$ , and $N$ denotes the total number of data, i.e., $\\bar{N_{\\mathrm{~=~}}}\\sum_{i=1}^{M}n_{i}$ . The datasets among the clients are heterogeneous. With the help of a central server, the goal of FMTL is to collaboratively learn ", "page_idx": 2}, {"type": "text", "text": "individual local models $\\theta_{i}\\in\\mathbb{R}^{d_{\\mathbf{x}}\\times d_{\\theta}}$ for each client\u2019s data without exchanging private data. Note that when the model is a shallow network, $d_{\\theta}=1$ . Many FMTL problems can be captured by the following general formulation [7]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\Theta,\\Omega}\\left\\{\\sum_{i=1}^{M}\\sum_{j=1}^{n_{i}}\\mathcal{L}_{i}\\left(\\mathcal{F}_{i}(\\boldsymbol{\\theta}_{i};\\mathbf{x}_{i}^{j}),y_{i}^{j}\\right)+R(\\Theta,\\Omega)\\right\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\Theta:=[\\theta_{1},\\cdot\\cdot\\cdot\\,,\\theta_{m}]\\in\\mathbb{R}^{d_{\\mathbf{x}}\\times d_{\\theta}\\times M}$ is a collective model stacked by individual clients. $R(\\cdot)$ is a regularizer, and $\\Omega$ is expressed as modeling the relationship among client tasks. FMTL issues vary according to their presuppositions about $R$ , which receives $\\Omega$ as input and promotes some suitable structure amongst the tasks. ", "page_idx": 3}, {"type": "text", "text": "3.2 Tensor Trace Norm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the field of MTL, the trace norm is utilized as a regularization method to learn the low-rank structure among model parameters across all tasks [22]. Typically, when dealing with vectorized data, shallow networks are used, i.e., $d_{\\theta}=1$ , where $\\Theta$ is a matrix. Thus, matrix trace norm is employed to enhance dependencies among models, defined as $\\begin{array}{r}{\\|\\Theta\\|_{*}=\\sum_{i}\\sigma_{i}(\\Theta)}\\end{array}$ , where $\\sigma_{i}(\\Theta)$ denotes the $i$ -th largest singular value of a matrix. However, with the collection of complex data, the data can be a tensor (e.g., images) and the model can become more complex (e.g., deep neural networks). In such scenarios, the parameters for all tasks can be structured into a multi-dimensional tensor, such as a $p$ -way tensor $\\left(p\\geq3\\right)$ , e.g., $\\Theta\\in\\mathbb{R}^{d_{1}\\times\\cdots\\times d_{p}}$ . For example, in a classification model with a fully connected layer (i.e., $p=3$ ), where $d_{1}$ represents the dimension of the input, $d_{2}$ indicating the number of classes, and $d_{3}=M$ denotes the number of clients. In this context, the traditional matrix trace norm becomes inapplicable, necessitating the use of a tensor trace norm instead. ", "page_idx": 3}, {"type": "text", "text": "Currently, the Tucker trace norm, a representative overlapping tensor trace norm, is extensively utilized in deep learning [36]. It unfolds the tensor into a matrix using Tucker decomposition and computes the convex sum for the matrix trace norms of the various flattened tensors [37]. The \u201cunfold\u201d operation along the $k$ -th mode on a tensor $\\Theta$ is defined as $\\mathrm{~unfold}_{k}(\\Theta):=\\Theta_{(k)}\\in\\mathbb{R}^{d_{k}\\times(d_{1}\\cdots d_{k-1}d_{k+1}\\cdots d_{p})}$ . $\\alpha_{k}$ denotes the weight of the matrix unfolded along $k$ -th mode. Thus, we formulate the Tucker-based trace norm in the following form: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left\\|\\Theta\\right\\|_{*}:=\\sum_{k=1}^{p}\\alpha_{k}\\left\\|\\Theta_{(k)}\\right\\|_{*},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\alpha_{k}$ is the weight on the $k$ -th mode, here we default to the same weight on each mode. Thus, the computational complexity of the tensor trace norm is $\\begin{array}{r}{O(\\operatorname*{min}_{k}d_{k}^{2}\\prod_{i\\neq k}^{p}\\overline{{d_{i}}})}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "4 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce the multi-task learning framework in a federated environment in more detail and propose a novel method, FedSAK, to address the challenges of FMTL. The framework of FedSAK is displayed in Figure 1. ", "page_idx": 3}, {"type": "text", "text": "4.1 Optimization Objective ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Without loss of generality, the client model can be decoupled into representation layers, also known as a feature extractor, and final decision layers like a prediction head for classification tasks. Under this design, much research has actively studied collaboration among different layers. However, these methods typically require model homogeneity as a means for server parameter aggregation, which inherently restricts the development of heterogeneous FL. Therefore, our objective in FMTL is to facilitate heterogeneous FL in supervised classification scenarios, encompassing both data heterogeneity (DH), model heterogeneity (MH), and task heterogeneity (TH). ", "page_idx": 3}, {"type": "text", "text": "Following previous conventions, we denote the feature extractor as $f_{i}(\\varphi_{i};\\mathbf{x}_{i})\\,:\\,\\mathbb{R}^{d_{\\mathbf{x}}}\\,\\to\\,\\mathbb{R}^{d_{H}}$ and the prediction head as $h_{i}(v_{i};c_{i}):\\mathbb{R}^{d_{H}}\\rightarrow\\mathbb{R}^{d_{y}}$ . Thus, the model for client $i$ can be expressed as ${\\mathcal F}_{i}(\\theta_{i})\\,=\\,f_{i}(\\varphi_{i})\\circ h_{i}(v_{i})$ , $\\circ$ denotes concatenation among model components, where $\\theta_{i}$ are the model parameters. We assume $f_{i}$ and $h_{i}$ can be heterogeneous across clients, meaning clients can customize the size and architecture of their local feature extractor and prediction head based on available resources. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "To flexibly apply our method to different federated heterogeneity settings, we define $w_{i}$ to represent the global shared layers for client $i$ , which is a subset of $\\theta_{i}$ , i.e. $w_{i}\\subseteq\\theta_{i}$ . The choice of $w_{i}$ can be flexibly adapted to the heterogeneity setting. For example, with data heterogeneity, $w_{i}=\\theta_{i}=\\varphi_{i}\\circ v_{i}$ ; with model heterogeneity, $w_{i}=v_{i}$ ; and with task heterogeneity, $w_{i}=\\varphi_{i}$ . ", "page_idx": 4}, {"type": "text", "text": "Since the global shared layers are aggregated at the server, where a low-rank structure among clients is learned by computing the trace norm to reinforce dependencies among models. Thus the objective for heterogeneous FMTL in Eq. (1) can be reformulated as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\Theta}\\frac{1}{M}{\\sum_{i=1}^{M}\\frac{1}{n_{i}}\\sum_{j=1}^{n_{i}}{\\mathcal{L}}({\\mathcal{F}}_{i}(\\Theta;\\mathbf{x}_{i}^{j}),y_{i}^{j})}+\\lambda\\left\\|{\\mathcal{W}}\\right\\|_{*},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathscr{F}_{i}(\\theta_{i})\\,=\\,f(\\varphi_{i})\\circ h(v_{i})$ , we use $\\theta_{i}$ to represent $(\\varphi_{i},v_{i})$ for short, and $\\Theta\\,=\\,[\\theta_{1},\\cdot\\cdot\\cdot,\\theta_{M}]$ . $\\mathcal{W}\\in\\mathbb{R}^{d_{1}\\times\\cdots\\times d_{p}}$ $(d_{p}=M)$ is denoted as the tensor stacked by each client\u2019s shared layers $w_{i}$ and $\\lambda$ is the hyperparameter. ", "page_idx": 4}, {"type": "text", "text": "4.2 Global Shared Layer Representation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Considering the heterogeneity of participating clients, the optimal model parameters are not identical across clients. This implies that simple weighted aggregation is insufficient to provide the required information to each client. Therefore, to uncover the underlying connections among model parameters of different clients, we utilize the trace norm as a regularizer to induce a low-rank structure among the parameters, which can better exploit intrinsic task relationships among the clients in the FMTL fashion. Since deep learning has evolved, the global shared layers $w$ may be an $L$ -layer deep network structure, we use the superscript $l$ to denote the $l$ -th layer of the global shared layers. Specifically, we first stack the global shared layers into a tensor on the server, which can handle the inherent correlation among multiple local models more efficiently: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{W}^{l}=\\mathrm{stack}(w_{1}^{l};w_{2}^{l};\\cdot\\cdot\\cdot\\;;w_{M}^{l})\\in\\mathbb{R}^{d_{1}\\times\\cdots\\times d_{p}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $p$ denotes that $\\mathcal{W}^{l}$ is a $p$ -way tensor, $d_{1}$ to $d_{p-1}$ are denoted as the dimensions of the model parameters and $d_{p}$ is the number of clients, i.e., $d_{p}=M$ . Then, we regularize the tensor $\\mathcal{W}^{l}$ formed by stacking the global shared layers $w_{i}^{l}$ from all $M$ clients using a trace norm penalty $||\\cdot||_{*}$ . That is: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{r}=\\sum_{l=1}^{L}\\left\\|\\mathcal{W}^{l}\\right\\|_{*}=\\sum_{l=1}^{L}\\sum_{k=1}^{p}\\left\\|\\mathcal{W}_{(k)}^{l}\\right\\|_{*},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{W}_{(k)}^{l}$ is the matrix unfolded according to the $k$ -th dimension, see Eq. (2). Minimizing the trace norm of ${\\mathcal{L}}_{r}$ yields a low-rank structure that reveals commonalities among the clients. This allows clients to transfer knowledge through coupled shared low dimensional subspaces, while still allowing clients to customize local models $f_{i}$ and $h_{i}$ . ", "page_idx": 4}, {"type": "text", "text": "For the server\u2019s $t$ -th round of global shared layers training, after stacking the received global shared layers form clients to compute the trace norm loss, we update the global shared parameters $\\widetilde{\\boldsymbol{w}}_{i}^{t}$ by gradient descent. Since the trace norm of a matrix is not differentiable, according to Watson et al. [38], we can compute a subgradient, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\partial||\\mathcal{W}_{(k)}^{l}||_{*}}{\\partial\\mathcal{W}_{(k)}^{l}}=U V^{T},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where for $\\mathcal{W}_{(k)}^{l}=U\\Sigma V^{T}$ , the singular value decomposition of $\\mathcal{W}_{(k)}^{l}$ . Since $w_{i}$ is the $i$ -th slice of $\\mathcal{W}$ , for each client we can update the global shared layers in a slice-wise manner as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widetilde{w}_{i}^{t}\\gets w_{i}^{t}-\\eta_{w}\\nabla\\mathcal{L}_{r},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta_{w}$ is the learning rate. Intuitively, this subtracts the aggregated trace norm subgradient from each client\u2019s current shared layers, reducing redundancy and coupling the parameters to learn a jointly low-dimensional subspace. The updated $\\widetilde{\\boldsymbol{w}}_{i}^{t}$ are then sent back to the respective client at the end of each communication round to update thei r  local models for the next round of training. ", "page_idx": 4}, {"type": "text", "text": "4.3 Local Model Update ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The server broadcasts the updated global shared layers $\\widetilde{\\boldsymbol{w}}_{i}^{t}$ to the client. In the $(t+1)$ -th round, client $i$ replaces the shared layers of its local model with the received global shared layers. Thus, the replaced local model is represented as $\\widetilde{\\theta}_{i}^{\\,\\,t+1}$ ", "page_idx": 5}, {"type": "text", "text": "Each client\u2019s local model obtains local knowledge from the local update and further obtains global knowledge among clients from the global update, allowing it to better handle heterogeneity. The assembled full local model $\\theta_{i}$ is then trained on the local data $\\mathbf{X}_{i}$ to obtain the updated local model parameters: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\theta_{i}^{t+1}\\leftarrow\\widetilde{\\theta}_{i}^{t+1}-\\eta_{\\theta}\\nabla{\\mathcal L}_{c}\\left(\\widetilde{\\theta}_{i}^{t+1};\\mathbf x_{i}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\eta_{\\theta}$ is the learning rate, and $\\mathcal{L}_{c}$ is the loss of cross entropy. We summarize the steps of FedSAK in Algorithm 1, see Appendix. ", "page_idx": 5}, {"type": "text", "text": "5 THEORETICAL ANALYSIS ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "5.1 Convergence Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To analyze the convergence of FedSAK, we define $t$ as the current communication round, $e\\in$ $\\{0,1,\\cdot\\cdot\\cdot,E\\}$ as the number of local iterations, where $E$ denotes the maximum number of local iterations. Thus, $(t E+e)$ represents the $e$ -th iteration in the $(t+1)$ -th communication round. The $(t+0)$ denotes that at the beginning of the $(t+1)$ -th round, the client uses the global shared layers gradients from round $t$ to update the local shared layer parameters. Note that $(t E+E)$ corresponds to the last iteration in round $(t+1)$ . We make some assumptions see Appendix C.1, which is similar to the existing general framework [15, 16]. Based on the above assumptions, due to our same local training, Tan et al. [15] and $\\mathrm{Yi}$ et al. [16] deduce that Lemma 1 and 2 still holds. For notational simplicity, we set \u03b7 = \u03b7\u03b8 = \u03b7w. ", "page_idx": 5}, {"type": "text", "text": "Lemma 1 Based on Assumption $^{\\,l}$ and 2, in the local iteration $e\\in\\{0,1,...,E\\}$ of the $(t+1)$ -th training round, the local model loss of any client is bounded by. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E}\\right]\\leqslant\\mathcal{L}_{t E+0}-\\left(\\eta-\\frac{K\\eta^{2}}{2}\\right)\\sum_{e=0}^{E}\\|\\mathcal{L}_{t E+e}\\|_{2}^{2}+\\frac{K E\\eta^{2}}{2}\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Lemma 2 Based on Assumption $^3$ , the loss of an arbitrary client\u2019s local model $(t+1)$ -this bounded by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]\\leqslant\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E}\\right]+\\frac{\\eta K\\lambda\\omega^{2}}{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The detailed proof can be found in Appendix C.2-C.3 [15, 16]. ", "page_idx": 5}, {"type": "text", "text": "Based on Lemma 1 and Lemma 2, we can derive the model nonconvex convergence rate. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1 The above assumptions, for an arbitrary client and any $\\epsilon>0$ , if $\\begin{array}{r}{\\eta<\\frac{2E\\epsilon-K\\lambda\\omega^{2}}{K E(\\epsilon+\\sigma^{2})}}\\end{array}$ , the following inequality holds: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\frac{1}{T E}\\sum_{t=0}^{T-1}\\sum_{e=0}^{E}\\mathbb{E}\\left[\\left\\|\\mathcal{L}_{t E+e}\\right\\|_{2}^{2}\\right]\\leqslant\\frac{2\\left(\\mathcal{L}_{t=0}-\\mathcal{L}^{*}\\right)}{T E\\eta\\left(2-K\\eta\\right)}+\\frac{K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}{E\\left(2-K\\eta\\right)}\\leqslant\\epsilon,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "With this, it is evident that the local model of any client of FedSAK converges at a non-convex convergence rate $\\textstyle{\\mathcal{O}}\\left({\\frac{1}{T}}\\right)$ . See Appendix C.4 for a detailed proof. ", "page_idx": 5}, {"type": "text", "text": "5.2 Excess Risk Bound ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Without loss of generality [37, 39], to simplify the analysis we take the case where $\\Theta=\\mathcal{W}$ , i.e., sharing all model structures. Consequently, we define the problem (3) empirical loss for all the tasks as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{W}\\;\\hat{\\mathcal{R}}(\\mathcal{W})=\\sum_{i=1}^{M}\\frac{1}{n_{i}}\\sum_{j=1}^{n_{i}}\\mathcal{L}\\big(\\mathcal{F}_{i}(\\mathcal{W};\\mathbf{x}_{i}^{j}),y_{i}^{j}\\big)\\quad\\mathrm{s.t.}\\;\\|\\mathcal{W}\\|_{*}\\leq\\gamma.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\gamma$ is a regularization parameter that controls the complexity of the model. Follow [37], the true risk is defined by the generalized loss of the task as $\\begin{array}{r}{\\mathcal{R}(\\bar{\\mathcal{W}})=\\sum_{i=1}^{M}\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{i}}\\mathcal{L}(\\mathcal{F}_{i}(\\mathcal{W};\\mathbf{x}),y)}\\end{array}$ , where $\\mathcal{P}_{i}$ denotes the underlying data distribution for the $i$ -th client and $\\mathbb{E}[\\cdot]$ denotes the expectation. Each training data $\\boldsymbol{x}_{j}^{i}$ is assumed to satisfy $\\langle x_{j}^{i},x_{j}^{i}\\rangle\\le1$ . To characterize correlations among features, we assume that $\\begin{array}{r}{\\mathbf{C}_{k}=\\mathbb{E}[\\mathbf{x}_{(k)}^{i,j}(\\mathbf{x}_{(k)}^{i,j})^{T}]\\preceq\\frac{k}{d}\\mathbf{I}}\\end{array}$ for any $k\\neq\\emptyset$ and $k\\subseteq[p-1]$ , where $\\mathbf{A}\\preceq\\mathbf{B}$ means that is a positive semidefinite matrix, $\\begin{array}{r}{d=\\prod_{i\\in[p-1]}d_{i}}\\end{array}$ , and I denotes an identity matrix with an appropriate size. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3 From Tomioka et al. [40], the dual norm of the tensor trace norm in Eq. (2) is defined as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\mathcal{W}\\right\\rVert_{*^{\\star}}=\\operatorname*{inf}_{\\substack{\\sum_{k\\neq\\emptyset,k\\subset[p]}\\mathcal{W}^{(k)}=\\mathcal{W}^{\\underline{{\\operatorname*{max}}}}}}\\operatorname*{max}_{k}\\left\\lVert\\mathcal{W}_{(k)}^{(k)}\\right\\rVert_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the infimum is over tensors $\\mathcal{W}^{(k)}$ that sum to the original tensor $\\mathcal{W}$ , and $\\|\\cdot\\|_{\\infty}$ is the operator norm (maximal singular value). ", "page_idx": 6}, {"type": "text", "text": "For simplicity, different tasks are assumed to have the same number of data points, i.e., $n_{i}$ equals $n$ for $i=1,\\cdots,M$ . It is simple to extend our analysis to the general case. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2 Let $\\sigma_{i}^{j}$ be a Rademacher variable, which is a random variable taking values in $\\{\\pm1\\}$ with equal probability. Consider W to be a tensor of order d1 \u00d7\u00b7 \u00b7 \u00b7\u00d7dp\u22121 \u00d7dp with Wi =  jn=1n1\u03c3ij xij, where $d_{p}$ is set equal to $M$ . Then the following inequality holds: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\|\\mathcal{W}\\|_{*^{\\star}}]\\leq C\\operatorname*{min}_{k}\\left(\\sqrt{\\frac{\\kappa M}{n d}l n\\;D_{k}}+\\frac{l n\\;D_{k}}{n}\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $D_{k}=d_{k}+(d_{1}\\cdot\\cdot\\cdot d_{k-1}d_{k+1}\\cdot\\cdot\\cdot d_{p})$ , and $C,\\kappa$ are an absolute constant. ", "page_idx": 6}, {"type": "text", "text": "Under Assumption 1 and Theorem 2 we derive the excess risk bound of the estimator in Eq. (12). ", "page_idx": 6}, {"type": "text", "text": "Theorem 3 Suppose that $n_{i}\\;\\geq\\;n\\;>\\;0,$ , $|y_{i}^{j}|\\,\\leq\\,b,$ , then for any $\\left\\|\\mathcal{W}\\right\\|_{*}\\leq\\gamma$ and $\\delta\\,\\in\\,(0,1)$ , the following inequality holds ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{R}(\\hat{\\mathcal{W}})-\\mathcal{R}(\\mathcal{W})\\leq\\frac{4\\gamma K}{M}\\mathbb{E}[\\|\\mathcal{W}\\|_{*^{\\star}}]+\\frac{2b K\\sqrt{N}}{M n}+a\\sqrt{\\frac{2l o g(2/\\delta)}{M n}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with probability at least $1-\\delta$ , where $\\hat{\\mathcal{W}}$ is the optimal solution of Eq. $(I2)$ and $\\left\\|\\mathcal{W}\\right\\|_{*^{\\star}}$ is defined as Theorem 2. ", "page_idx": 6}, {"type": "table", "img_path": "3YkeHuT1o6/tmp/5c675003db50f244e56d821453c3a1395d68f63cd030ca668acf2c05e7c3a17c.jpg", "table_caption": ["Table 1: Test accuracy $(\\%)$ on image classification tasks under data heterogeneity. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "6.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets and local models. We evaluate FedSAK on diverse image classification tasks. For image classification, six well-known datasets are utilized, including Human Activity (HumA) [41], MNIST [42], CIFAR-10 [43], CIFAR-100 [43], PACS [44], and Adience Faces [45]. Due to space constraints, detailed introductions of the datasets and the experimental setup are provided in Appendix B, while their splits will be elaborated in Section 6.2 for each heterogeneous task. Each client test set follows a similar distribution to the training set. Two fully connected layers are provided for Human Activity and MNIST datasets. CIFAR-10, CIFAR-100, PACS, and Adience Faces datasets are downsampled to $32\\times32$ size and consider a CNN model comprising 2 convolutional layers followed by 2 fully connected layers. Note that we only consider the last fully-connected layer of the model as the predictor head, and the other layers form the feature extractor. We ran each model 5 times and recorded its average value recorded as the result. ", "page_idx": 6}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/ccc225cc88ad813548d024978c085a4101e52b4f7a0ef4765dca9e7f9864db62.jpg", "img_caption": ["Figure 2: The test accuracy and convergence process of each method. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Baselines. We study the performance of FedSAK in heterogeneous settings and compare against baselines including: (1) Conventional federated learning: FedAvg [1], FedProx [2]; (2) Personalized federated learning: Per-FedAvg [3], pFedMe [4], MOON [9], Ditto [5], GPFL [10], FedAvgDBE [46]; (3) Federated multi-task learning: FedMTL [7], FedU [8] and (4) Heterogeneous federated learning: FedMD [17], FedProto [15], FedGH [16]. ", "page_idx": 7}, {"type": "text", "text": "6.2 Results and Discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Data Heterogeneity. Following the FMTL work [7, 8], we adopt a commonly used setup called pathology Non-IID to simulate DH in the form of label distribution shift in FL. We partition the dataset into $M$ clients, with each client sampling data from $S$ classes, where the number of samples per class varies significantly. The distribution of client data for each dataset is shown in Appendix B.2. For extensive comparisons of the advanced baselines, we design the individual client models to be homogeneous in DH scenarios. Thus, the global shared layer for each client is the client\u2019s entire model, i.e., $w_{i}=\\varphi_{i}\\circ v_{i}$ . Table 1 reports the average test accuracy across all clients, and Figure 2 summarizes the convergence behavior and performance of all methods. It can be observed that FedSAK achieves the highest accuracy in most cases, indicating that constraining through tensor trace norm facilitates transferring useful information across multiple clients, thereby improving model performance on each client. Notably, in this scenario, the lower the number of clients, the fewer the samples involved in training, and hence the accuracy is higher when the number of clients is higher, which is consistent with the results derived from our Theorem 3. ", "page_idx": 7}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/25855c2e0225dda3f192317e418d8285b84875af05a91400a957951739da141c.jpg", "img_caption": ["Figure 3: The test accuracy of all methods on MH.Figure 4: Confusion matrix of classification results obtained from two clients TH on the Adience Face. ", "Model Heterogeneity is an important challenge in FL due to the differences in client computational resources and the fact that heterogeneous client requires different models. For example, the dataset PACS contains 4 different domains, and we set up each client to contain data from one domain. In this setup, we vary the number of fliters in the convolutional layers and dimensions of the fully connected layers to obtain 4 heterogeneous models. The detailed model architectures are shown in Table 4 in the Appendix. Thus, in the MH scenario, our shared layers consist of the prediction head, which is "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "$w_{i}=v_{i}$ . For CIFAR10, we set up 20 clients and alter data distribution using a Dirichlet distribution and label distribution skew. PACS itself has heterogeneity, so we set 4, 8, 10 clients respectively. The results in Table 2 show that FedSAK consistently achieves the highest model accuracy, while FedMD has lower accuracy. On CIFAR-10, since the distribution of our test set is similar to that of the training set, the model\u2019s performance will decrease due to the increase in the number of predicted label categories. Therefore, the results on the Dirichlet distribution are inferior to those with skewed label distribution. On PACS, it outperforms the best baseline FedGH by $5.98\\%$ , $4.08\\%$ , and $3.94\\%$ respectively. Figure 3 shows the test set accuracy with 4 clients on this dataset. Additionally, FedSAK requires less communication, thereby converging faster. ", "page_idx": 8}, {"type": "table", "img_path": "3YkeHuT1o6/tmp/4fccfe95cfd7130846429cf36334a8f63d92bc5e35e245855b800f6ebc3c4df0.jpg", "table_caption": ["Table 2: Test accuracy $(\\%)$ for the image classification task under model heterogeneity, $\\beta$ is the Dirichlet distribution, $S$ is the number of labels, and $M$ is the number of clients. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "3YkeHuT1o6/tmp/8ec34ed5f8715f685de76185bf3ddd4a18ee321bc1a1867ff022d8372f3b4913.jpg", "table_caption": ["Table 3: Accuracy $(\\%)$ of the Adience Faces, with (brackets) inside indicating the improvement rate relative to the Local, where the Gender (2) and Age (8) rows show the average test accuracy. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Task Heterogeneity in FL is commonly overlooked but objectively exists in reality, where clients typically train different tasks on a similar dataset. We adopt a large-scale face image dataset, AdienceFaces, which contains gender and age group labels for each person. Specifically, we set up 2, 10, and 15 clients to achieve gender classification and age classification, in which the ratio of heterogeneous tasks are 1:1, 1:2, and 2:1. Under the TH scenario, our shared layers consists of the feature extractor, i.e. $w_{i}=\\varphi_{i}$ . Since there are currently no FL methods that can handle task heterogeneity, we use FedAvg-c to denote clients only uploading the feature extractor and aggregating with FedAvg. Table 3 reports our results. It can be seen that training only with local data is less effective than FL, indicating task heterogeneity is meaningful in the FL setting. We can see that FedSAK achieves the best results under all settings when the task distribution is balanced. When the heterogeneous task distribution is skewed amongst clients, FedAvg-c will be biased towards clients with a larger task proportion. For example, with 15 clients, 5 doing 2-class and 10 doing 8-class, although FedAvg-c performs slightly better on 8-class than FedSAK, its performance on 2-class clients is worse than Local. The confusion matrix in Figure 4 visualizes the results of our classification of the $2\\;\\mathrm{TH}$ clients, and we can see that our method can achieve significant results. ", "page_idx": 8}, {"type": "text", "text": "6.3 Parameter Experiment ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We first evaluated the impact of the trade-off parameters on different heterogeneous setups, Figure 5 depicts the performance of FedSAK on 3 heterogeneous tasks across datasets as $\\lambda$ varies. The $\\lambda$ controls the extent of coupling among client models, with larger $\\lambda$ indicating more emphasis on sharing information among parameters, while smaller $\\lambda$ focuses models on utilizing their own data. It can be observed that the optimal $\\lambda$ value differs across the heterogeneous tasks. In the data heterogeneity scenario, since models are homogeneous, larger $\\lambda$ values yield better performance. In contrast, in the task heterogeneity setting where client differences are greater, smaller $\\lambda$ produces improved results. Furthermore, when $\\lambda$ is too large, performance decreases in all heterogeneous scenarios. In summary, appropriately tuning $\\lambda$ allows balancing between customized local learning and collaborative multi-task training for each heterogeneous scenario. ", "page_idx": 8}, {"type": "text", "text": "Additionally, we tested the sensitivity of FedSAK\u2019s trade-off parameter $\\lambda$ , learning rate $\\eta$ $\\left[\\eta\\right.=$ $\\eta_{\\theta}\\,=\\,\\eta_{w}^{\\phantom{\\dagger}}\\,,$ ), and local iteration number $E$ on CIFAR-10 ( $M{=}10$ , $S{=}3$ ). As Figure 6 shows, our model converges under all settings. The convergence curve fluctuates as $\\lambda$ changes, but is smoother for learning rate and local iterations, indicating FedSAK is not sensitive to the learning rate and local iterations. We also find increasing local iterations speeds up convergence, aligning with our theoretical derivations. ", "page_idx": 8}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/cc86034626cfaea0b86273a472dcfe0006a07ebe2cac1ba4208588cd73a21097.jpg", "img_caption": ["Figure 5: Test accuracy of parameter $\\lambda$ in different scenarios. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/d01dbb98f695f98e13d2a541b0c9e16e2668247d7c90fd27f9eb66efab1db332.jpg", "img_caption": ["Figure 6: Sensitivity of model parameters. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6.4 Computing and Communication Overhead ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We plotted the per-epoch time for each method under the data heterogeneity setting with 100 clients on the MNIST dataset, as shown in Figure 7. The figure shows that personalized methods Ditto and pFedMe spend more time per epoch than most methods, due to the need to train additional personalized models. FedMD, which uses knowledge distillation, also has high time costs because the student and teacher models need to collaborate. Compared to most baselines, FedSAK reduces communication overhead on smaller models by track ", "page_idx": 9}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/96abae2133c47d39bd66df4a8ce879a9217a5a79b65b29f95409cde3af77e310.jpg", "img_caption": ["Figure 7: Running time per epoch for each method on the MNIST. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "norm regularization updates for local model gradients. It is worth noting that since FedSAK performs tensor track norm, the computational complexity is $\\begin{array}{r}{O(\\operatorname*{min}_{k}d_{k}^{2}\\prod_{i\\neq k}^{p}d_{i})}\\end{array}$ , which seems to significantly increase with the model\u2019s dimensionality, representing a limitation of FedSAK. Nevertheless, FedSAK can balance communication overhead through a flexible upload of shared layer structures. To further demonstrate the communication overhead of FedSAK, we tested it using ResNet18 in the Appendix, as shown in Table 5. It can be seen that FedSAK can also effectively cope with large-scale modeling scenarios. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we propose a novel FMTL framework based on tensor trace norm to address challenging federated scenarios with data, model, and task heterogeneity. The method facilitates modeling associations and dependencies among client tasks by flexibly selecting model shared layer structures and uploading them to the server for tensor trace norm regularization. This enables useful knowledge transfer across clients to improve model performance on each task. We conduct comprehensive analyses on the efficacy of the method from both theoretical and experimental perspectives. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The research is supported by the National Key R&D Program of China (2023YFB2703700), the National Natural Science Foundation of China (62176269), the Guangzhou Science and Technology Program (2023A04J0314), the National Natural Science Foundation of China under Grant (62302537). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017.   \n[2] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2:429\u2013450, 2020.   \n[3] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach. Advances in Neural Information Processing Systems, 33:3557\u20133568, 2020.   \n[4] Canh T Dinh, Nguyen Tran, and Josh Nguyen. Personalized federated learning with moreau envelopes. Advances in Neural Information Processing Systems, 33:21394\u201321405, 2020.   \n[5] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated learning through personalization. In International Conference on Machine Learning, pages 6357\u20136368. PMLR, 2021.   \n[6] Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei, and Yong Zhang. Personalized cross-silo federated learning on non-iid data. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 7865\u20137873, 2021.   \n[7] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task learning. Advances in neural information processing systems, 30, 2017.   \n[8] Canh T Dinh, Tung T Vu, Nguyen H Tran, Minh N Dao, and Hongyu Zhang. A new look and convergence rate of federated multitask learning with laplacian regularization. IEEE Transactions on Neural Networks and Learning Systems, 2022.   \n[9] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10713\u201310722, 2021.   \n[10] Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao, and Haibing Guan. Gpfl: Simultaneously learning global and personalized feature information for personalized federated learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 5041\u20135051, 2023.   \n[11] Chuan Chen, Tianchi Liao, Xiaojun Deng, Zihou Wu, Sheng Huang, and Zibin Zheng. Advances in robust federated learning: Heterogeneity considerations. arXiv preprint arXiv:2405.09839, 2024.   \n[12] La\u00e9rcio Lima Pilla. Optimal task assignment for heterogeneous federated learning devices. In 2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS), pages 661\u2013670. IEEE, 2021.   \n[13] Wenke Huang, Mang Ye, and Bo Du. Learn from others and be yourself in heterogeneous federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10143\u201310153, 2022.   \n[14] Samiul Alam, Luyang Liu, Ming Yan, and Mi Zhang. Fedrolex: Model-heterogeneous federated learning with rolling sub-model extraction. Advances in Neural Information Processing Systems, 35:29677\u201329690, 2022.   \n[15] Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang, and Chengqi Zhang. Fedproto: Federated prototype learning across heterogeneous clients. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8432\u20138440, 2022.   \n[16] Liping Yi, Gang Wang, Xiaoguang Liu, Zhuan Shi, and Han Yu. Fedgh: Heterogeneous federated learning with generalized global header. pages 8686\u20138696, 2023.   \n[17] Daliang Li and Junpu Wang. Fedmd: Heterogenous federated learning via model distillation. arXiv preprint arXiv:1910.03581, 2019.   \n[18] Chuhan Wu, Fangzhao Wu, Lingjuan Lyu, Yongfeng Huang, and Xing Xie. Communicationefficient federated learning via knowledge distillation. Nature communications, 13(1):2032, 2022.   \n[19] Yongxin Yang and Timothy Hospedales. Deep multi-task representation learning: A tensor factorisation approach. arXiv preprint arXiv:1605.06391, 2016.   \n[20] Luca Corinzia, Ami Beuret, and Joachim M Buhmann. Variational federated multi-task learning. arXiv preprint arXiv:1906.06268, 2019.   \n[21] Abhishek Kumar and Hal Daume III. Learning task grouping and overlap in multi-task learning. arXiv preprint arXiv:1206.6417, 2012.   \n[22] Xiongjun Zhang, Jin Wu, and Michael K Ng. Multilinear multitask learning by transformed tensor singular value decomposition. Machine Learning with Applications, page 100479, 2023.   \n[23] Siran Zhao, Tianchi Liao, Lele Fu, Chuan Chen, Jing Bian, and Zibin Zheng. Data-free knowledge distillation via generator-free data generation for non-iid federated learning. Neural Networks, 179:106627, 2024.   \n[24] Liam Collins, Hamed Hassani, Aryan Mokhtari, and Sanjay Shakkottai. Exploiting shared representations for personalized federated learning. In International conference on machine learning, pages 2089\u20132099. PMLR, 2021.   \n[25] Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Federated learning with personalization layers. arXiv preprint arXiv:1912.00818, 2019.   \n[26] Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, and Haibing Guan. Fedcp: Separating feature information for personalized federated learning via conditional policy. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 3249\u20133261, 2023.   \n[27] Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. An efficient framework for clustered federated learning. Advances in Neural Information Processing Systems, 33:19586\u2013 19597, 2020.   \n[28] Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model fusion in federated learning. Advances in Neural Information Processing Systems, 33:2351\u20132363, 2020.   \n[29] Qinbin Li, Bingsheng He, and Dawn Song. Practical one-shot federated learning for cross-silo setting. In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, pages 1484\u20131490. ijcai.org, 2021.   \n[30] Jui-Ting Huang, Jinyu Li, Dong Yu, Li Deng, and Yifan Gong. Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers. In 2013 IEEE international conference on acoustics, speech and signal processing, pages 7304\u20137308. IEEE, 2013.   \n[31] Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. Facial landmark detection by deep multi-task learning. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VI 13, pages 94\u2013108. Springer, 2014.   \n[32] Liuyi Yao, Dawei Gao, Zhen Wang, Yuexiang Xie, Weirui Kuang, Daoyuan Chen, Haohui Wang, Chenhe Dong, Bolin Ding, and Yaliang Li. A benchmark for federated hetero-task learning. arXiv preprint arXiv, 2206, 2022.   \n[33] Massimiliano Pontil and Andreas Maurer. Excess risk bounds for multitask learning with trace norm regularization. In Conference on Learning Theory, pages 55\u201376. PMLR, 2013.   \n[34] Yasmin Sarcheshmehpour, Yu Tian, Linli Zhang, and Alexander Jung. Networked federated multi-task learning. CoRR, 2021.   \n[35] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Federated multi-task learning for competing constraints. CoRR, 2020.   \n[36] Ji Liu, Przemyslaw Musialski, Peter Wonka, and Jieping Ye. Tensor completion for estimating missing values in visual data. IEEE transactions on pattern analysis and machine intelligence, 35(1):208\u2013220, 2012.   \n[37] Yi Zhang, Yu Zhang, and Wei Wang. Multi-task learning via generalized tensor trace norm. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 2254\u20132262, 2021.   \n[38] G Alistair Watson. Characterization of the subdifferential of some matrix norms. Linear Algebra Appl, 170(1):33\u201345, 1992.   \n[39] Kishan Wimalawarne, Masashi Sugiyama, and Ryota Tomioka. Multitask learning meets tensor factorization: task imputation via convex optimization. Advances in neural information processing systems, 27, 2014.   \n[40] Ryota Tomioka, Taiji Suzuki, Kohei Hayashi, and Hisashi Kashima. Statistical performance of convex tensor decomposition. Advances in neural information processing systems, 24, 2011.   \n[41] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Luis Reyes-Ortiz, et al. A public domain dataset for human activity recognition using smartphones. In Esann, volume 3, page 3, 2013.   \n[42] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.   \n[43] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[44] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542\u20135550, 2017.   \n[45] Eran Eidinger, Roee Enbar, and Tal Hassner. Age and gender estimation of unfiltered faces. IEEE Transactions on information forensics and security, 9(12):2170\u20132179, 2014.   \n[46] Jianqing Zhang, Yang Hua, Jian Cao, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, and Haibing Guan. Eliminating domain bias for federated learning in representation space. arXiv preprint arXiv:2311.14975, 2023.   \n[47] Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational mathematics, 12:389\u2013434, 2012.   \n[48] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. The collected works of Wassily Hoeffding, pages 409\u2013426, 1994.   \n[49] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research, 3(Nov):463\u2013482, 2002.   \nInput: total number of clients $M$ , number of rounds $T$ ; learning rate of local models $\\eta_{w}$ ;   \nlearning rate $\\eta_{\\theta},\\eta_{w}$ , hyper-parameter for loss $\\lambda$ .   \nRandomly initialize the heterogeneous local models $\\left[\\theta_{1}^{0},\\dots,\\theta_{M}^{0}\\right]$ and share layer $\\widetilde{w}^{0}$ .   \nfor $t=1$ to $T$ do // Clients Side: for each batch in $B_{i}$ do 1: Receive the share layer $\\widetilde{\\boldsymbol{w}}_{i}^{t-1}$ broadcast by the server; 2: Update the local model: $\\widetilde{\\theta_{i}}^{t}$ ; 3: Perform local training: $\\theta_{i}^{t}\\leftarrow\\widetilde{\\theta}_{i}^{t}-\\eta_{\\theta}\\nabla\\mathcal{L}_{c}\\left(\\widetilde{\\theta}_{i}^{t};\\mathcal{B}_{i}\\right)$ ; end 4: Upload the global shared layers $w_{i}^{t}$ to the server. // Server Side: 1: Receive the global shared layers $w_{i}^{t}$ from $M$ clients and stack the parameters into $L$ tensors via Eq.(4); 2: Calculated loss : $\\begin{array}{r}{\\langle\\mathcal{L}_{r}=\\lambda\\sum_{l=1}^{L}\\sum_{k=1}^{p}\\left\\|\\mathcal{W}_{(k)}^{l,t}\\right\\|_{*}}\\end{array}$ ; 3: Calculate gradient to update client parameters: for $i\\in M$ do $\\begin{array}{r l}{|}&{{}\\widetilde{w}_{i}^{t}\\gets w_{i}^{t}-\\eta_{w}\\nabla{\\mathcal{L}}_{r}}\\end{array}$ ; end 4: Broadcast the updated global shared layers $w_{i}$ to the $i$ -th client.   \nend ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Return Personalized heterogeneous private models for all clients: $\\left[\\theta_{1}^{T},\\theta_{2}^{T},\\dots,\\theta_{M}^{T}\\right]$ . ", "page_idx": 13}, {"type": "text", "text": "A Supplementary Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Training Setup ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "See Algorithm 1 for details of our algorithm. ", "page_idx": 13}, {"type": "text", "text": "For local optimization, all methods utilize mini-batch SGD, with the number of local epochs set to $E{=}5$ and the batch size selection range is $\\{16,20,32\\}$ per client. The number of global communication rounds is uniformly set to $t{=}100$ across all datasets, which is sufficient for the convergence of the FL methods. We report the average test accuracy across all clients as the evaluation metric after convergence. We also tune special hyperparameters for baselines and report the optimal results. We ran these experiments using 4 NVIDIA GeForce RTX 4090 GPUs for all methods. ", "page_idx": 13}, {"type": "text", "text": "A.2 Model Setup", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Data heterogeneity. In the data heterogeneity scenario, to explore only the impact of data heterogeneity, we set up each client to have the same model structure. On the HumA and MNIST datasets, we used 2 fully connected layers, i.e., $i n p u t\\times100\\times c l a s s n u m b e r.$ . On the CIFAR dataset, we used a CNN model with 2 convolutional layers and 2 fully connected layers. Where the convolutional layer kernel is $5*5$ and the fliter distribution is 32 or 64, i.e. $(5\\times5,32)$ and $(5\\times5,64)$ . Connecting 2 fully connected layers, i.e. $i n p u t\\times512\\times c l a_{:}$ ss number. While communicating with the server, these model structures are uploaded to the server for tensor trace norm constraints. ", "page_idx": 13}, {"type": "text", "text": "Model heterogeneity. In the model heterogeneity setup, we vary the number of filters in the convolutional layer and the dimensionality of the fully connected layer in the CNN model to obtain four heterogeneous models The detailed design of each model is shown in Table 4. In the model heterogeneity experiments, we select different heterogeneous models for each client in turn. In this case, we only uploaded the prediction head to the server communication. ", "page_idx": 13}, {"type": "text", "text": "Task heterogeneity. We adopt the same network structure as the CIFAR dataset in the data heterogeneity scenario. And consider the last fully connected layer as the prediction head, i.e., 512 \u00d7 class number. Therefore, in the task heterogeneity scenario, we uploaded a feature extractor ", "page_idx": 13}, {"type": "text", "text": "Table 4: The structure of the four heterogeneous CNN models in model heterogeneity, with the client model selected in order by id $\\boldsymbol{p}$ for padding, $s$ for stride). ", "page_idx": 14}, {"type": "table", "img_path": "3YkeHuT1o6/tmp/3bdf28d0bd91cc3cf1bea99ee96cdefb5446f8e057924e77d1767f43c96c9bec.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "consisting of 2 convolutional layers i.e. $(5\\times5,32)$ and $(5\\times5,64)$ and 1 fully connected layer i.e.   \n$i n p u t\\times512$ to interact with other clients. ", "page_idx": 14}, {"type": "text", "text": "A.3 Ablation Experiment ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To emphasize the effectiveness of FedSAK\u2019s knowledge transfer using the tensor trace norm, we conducted ablation experiments. Due to model-specific design choices, when the model does not communicate, the model degrades to the Local state. When the shared layer uploads are weighted and aggregated only on the server side, our approach will degrade to the standard FedAvg algorithm. It is worth noting that FedAvg cannot do weighted averaging on the whole model in model heterogeneous and task heterogeneous scenarios. Therefore we only performed FedAvg computation on the uploaded shared layer. The experimental results are shown in Figure 8, where it can be seen that FedSAK for client knowledge transfer learning using tensor trace paradigms yields better results. ", "page_idx": 14}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/541c6ec0c63f8db74ca08744ebd7b77f6726d29b7bffcc08756546df33bbad93.jpg", "img_caption": ["Figure 8: Sensitivity of model parameters. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "A.4 Computing Overhead ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Section 6.4, we report a FedSAK computational complexity of $\\begin{array}{r}{O(\\operatorname*{min}_{k}d_{k}^{2}\\prod_{i\\neq k}^{p}d_{i})}\\end{array}$ and compare the communication overhead of FedSAK with the baseline method on the MNIST dataset. The computational complexity of our method does increase with network size. Due to its flexibility in uploading shared structures, FedSAK can easily handle larger networks compared to methods that upload the entire model (e.g., FedAvg). To further emphasize the effectiveness of FedSAK on complex networks, we tested it using ResNet18 on the CIFAR-10 dataset. We set up a total of 20 clients, each containing 5 labels. In the FedSAK model, we shared the fully connected layer behind. ", "page_idx": 14}, {"type": "table", "img_path": "3YkeHuT1o6/tmp/95b08f83a147aebe3a41ce8ba95a85810656af466ce640c1b5a5f2913ffb52f2.jpg", "table_caption": ["Table 5: The accuracy, time consumption, and memory usage of each method running ResNet18 on the CIFAR-10 dataset. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Table 5 reports the accuracy, time consumption, and memory usage of each method running ResNet18 on the CIFAR10 dataset. It can be seen that when only fully connected layer is uploaded, our model is still advantageous compared to most methods. In addition, its time consumption and memory occupation are much smaller than other methods, which greatly demonstrates the flexibility of our method. ", "page_idx": 15}, {"type": "text", "text": "B Datasets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Dataset Description ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "\u2022 Human Activity [41]: Mobile phone accelerometer and gyroscope data collected from 30 individuals, performing one of six activities: walking, walking-upstairs, walking-downstairs, sitting, standing, lying-down. We use the provided 561-length feature vectors of time and frequency domain variables generated for each instance. We model each individual as a separate task and predict between sitting and the other activities. ", "page_idx": 15}, {"type": "text", "text": "\u2022 MNIST [42]: A handwritten digit dataset includes 10 labels and 70,000 instances. The whole dataset is distributed to $\\Nu=100$ clients. Each client has a different local data size and consists of 2 labels.   \n\u2022 CIFAR-10 & CIFAR-100 [43]: CIFAR-10 consists of 60000, $32\\!\\times\\!32$ color images in 10 classes, with 6,000 images per class. Similar to CIFAR-10, CIFAR-100 has 100 classes, with 600 images per class. We partition the dataset into $M$ clients, with each client assigned $S$ labels. Datasets are split randomly with $75\\%$ and $25\\%$ for training and testing, respectively.   \n\u2022 PACS [44]: PACS is a challenging heterogeneous dataset with large domain discrepancies. The PACS dataset has a total of 9,991 images, each of size $3\\!\\times\\!227\\!\\times\\!227$ . The dataset consists of 4 distinct domains: art painting, cartoon, photo, and sketch. Each domain contains 7 classes: Dog, Elephant, Giraffe, Guitar, Horse, House, Person. The picture of this dataset is shown in Figure 9.   \n\u2022 Adience Faces [45]: Adience Faces is a large-scale face image dataset with labels for gender and age group of each individual. This enables the dataset to be used for two tasks: (i) gender classification into two classes (male and female), and (ii) age group classification into eight groups (0-2, 4-6, 8-12, 15-20, 25-32, 38-48, 48-53, 60-100 years old). We use this dataset to evaluate heterogeneous task federated learning, where each client is assigned one of the tasks for training. ", "page_idx": 15}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/8915f8d3e7e56fe1aaaf1655a0f3f7cc227129bf04e49091f0ca9fb88dc9044d.jpg", "img_caption": ["Figure 9: The PACS datasets. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "B.2 Data Distribution Visualization ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We visualized the data in order to clearly show the client\u2019s training data. The red circle represents the percentage of data, the larger the circle, the more data the client has of that type. ", "page_idx": 16}, {"type": "text", "text": "In the experiments with data heterogeneity, we follow the setup of the FMTL reference [7, 8], where each client contains a different number of partially labeled classes. Thus in our data heterogeneity setup, the data distribution of clients on Human Activity, MNIST, CIFAR-10, and CIFAR-100 are shown in Figure 10 - 13 . ", "page_idx": 16}, {"type": "text", "text": "The CIFAR-10 and PACS datasets were the main ones we used in the experiments on model heterogeneity. In CIFAR-10 we employed the Dillikerley distribution to divide the heterogeneous data see Figure 14 and the labeled division data see Figure 12, respectively. PACS contains data from 4 different domains, which is more suitable for model heterogeneity in real scenarios. Since this data itself has a high degree of heterogeneity, we did not have a heterogeneous division of the client data label distribution, the data distribution is shown in Figure 15. ", "page_idx": 16}, {"type": "text", "text": "In the experiments of task heterogeneity, we use Adience Facs dataset and each client samples similar data for different training tasks, and its data distribution is shown in Figure 16. ", "page_idx": 16}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/ff84de46cda055a3366ff666f8028ff497ce6009dd818faa685800dcc53bc3f4.jpg", "img_caption": ["Figure 10: The data distribution on Human Activity. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/763bbf2478089bbb879278a709aeba20023b3bc6a25f0d5b20c430ba1796588c.jpg", "img_caption": ["Figure 11: The data distribution on MNIST. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/6f19fbeccec948cd582f98d38a967e2ad73bf5f16e2de885bd46d6ccb85f20ef.jpg", "img_caption": ["Figure 12: The data distribution of all clients on CIFAR-10. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "C Convergence Analysis ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "To analyze the convergence of FedSAK, we follow [15, 16] and make the following assumptions C.1: Define $t$ as the current communication round, $e\\in\\{0,1,\\cdots\\,,E\\}$ as the number of local iterations, where $E$ denotes the maximum number of local iterations. Thus, $(t E+e)$ represents the e-th iteration ", "page_idx": 16}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/a4622439bb205f697492d82ea412ab8efeff863d3c54575202bc0f321948ef2f.jpg", "img_caption": ["Figure 13: The data distribution of all clients on CIFAR-100. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/f5c831dfd6ad8e52c411201919dbc89165ece64ec5bb539238cdf662c2660357.jpg", "img_caption": ["Figure 14: The data distribution of all clients on CIFAR-10. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "in the $(t+1)$ -th communication round. The $(t+0)$ denotes that at the beginning of the $(t+1)$ -th round, the client uses the global shared layers gradients from round $t$ to update the local shared layer parameters. Note that $(t E+E)$ corresponds to the last iteration in round $(t+1)$ . ", "page_idx": 17}, {"type": "text", "text": "C.1 Assumption ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Assumption 1 (Lipschitz Smoothness) The i-th client\u2019s local model loss function $\\mathcal{L}$ is Lipschitz continuous with Lipschitz constant $K$ , and $0\\leq\\mathcal{L}\\leq a$ with $\\mathcal{L}(0)=0$ , i.e., ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla\\mathcal{L}_{t_{1}}-\\nabla\\mathcal{L}_{t_{2}}\\|_{2}\\leq K\\|\\theta_{i}^{t_{1}}-\\theta_{i}^{t_{2}}\\|_{2},\\quad}\\\\ {\\forall t_{1},t_{2}>0,i\\in\\{1,2,...\\,,M\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Assumption 2 (Unbiased Gradient and Bounded Variance) The random gradient $\\begin{array}{r l}{g_{i}^{t}}&{{}=}\\end{array}$ $\\nabla{\\mathcal{L}}_{t}\\left(\\theta_{i}^{t};B_{i}^{t}\\right)$ of each client\u2019s local model is unbiased, where $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is a batch of local data, i.e., ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{B}_{i}^{t}\\subseteq n_{i}}\\left[g_{i}^{t}\\right]=\\nabla\\mathcal{L}(\\theta_{i}^{t})=\\nabla\\mathcal{L}_{t},\\forall i\\in\\{1,2,\\ldots,M\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and the variance of random gradient $g_{k}^{t}$ is bounded by: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{B}_{i}^{t}\\subseteq n_{i}}\\left[\\left\\|\\nabla\\mathcal{L}_{t}\\left({\\boldsymbol{\\theta}}_{i}^{t};\\mathcal{B}_{i}^{t}\\right)-\\nabla\\mathcal{L}_{t}\\left({\\boldsymbol{\\theta}}_{i}^{t}\\right)\\right\\|_{2}^{2}\\right]\\leqslant\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Assumption 3 (Bounded Variance of the Shared Layers) The variance of the shared layers $w_{i}$ of the model $\\theta_{i}$ trained by client $i$ with local data $n_{i}$ , and the server tensor low-rank constrained update to the shared layers $\\widetilde{w}_{i}$ are bounded, i.e., ", "page_idx": 17}, {"type": "text", "text": "parameter bounded: $\\mathbb{E}\\left[\\left\\lVert w_{i}-\\widetilde{w}_{i}\\right\\rVert_{2}^{2}\\right]\\leqslant\\varepsilon^{2},$ gradient bounded: $\\mathbb{E}\\left[\\|\\nabla{\\mathcal{L}}_{r}\\left(w_{i}\\right)-\\nabla{\\mathcal{L}}_{r}(\\widetilde{w}_{i})\\|_{2}^{2}\\right]\\leqslant\\omega^{2}.$ ", "page_idx": 17}, {"type": "text", "text": "Based on the above assumptions, due to our same local training, Tan et al. [15] and Yi et al. [16] deduce that Lemma 1 and 2 still holds. For notational simplicity, we set \u03b7 = \u03b7\u03b8 = \u03b7w. ", "page_idx": 17}, {"type": "image", "img_path": "3YkeHuT1o6/tmp/a3b00f5d16c2ef0fc40d437c84cc9577fbcb3aaa877598ac81495e07e430fd82.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 15: The data distribution of all clients on PACS Figure 16: The data distribution of all clients on Adience Faces.   \nin practical settings with 4 and 20 clients, respectively. ", "page_idx": 18}, {"type": "text", "text": "C.2 Proof for Lemma 1 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. For arbitrary clients, we have $\\theta^{t+1}=\\theta^{t}-\\eta g^{t}$ , then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{t E+1}\\leq\\mathcal{L}_{t E+0}+\\langle\\nabla\\mathcal{L}_{t E+0},(\\theta^{t E+1}-\\theta^{t E+0})\\rangle}\\\\ &{\\quad\\quad\\quad+\\displaystyle\\frac{K}{2}\\|\\theta^{t E+1}-\\theta^{t E+0}\\|_{2}^{2}}\\\\ &{\\quad\\quad\\quad=\\mathcal{L}_{t E+0}-\\eta\\langle\\nabla\\mathcal{L}_{t E+0},g^{t E+0}\\rangle+\\displaystyle\\frac{K}{2}\\|\\eta g^{t E+0}\\|_{2}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Taking expectation of both sides of the above equation on the random variable $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[C_{t E+1}]\\leq C_{t E+0}-\\eta\\mathbb{E}[\\langle\\nabla{C}_{t E+0},g^{t E+0}\\rangle]+\\displaystyle{\\frac{K\\eta^{2}}{2}}\\mathbb{E}[\\|g^{t E+0}\\|_{2}^{2}]}\\\\ &{\\quad=C_{t E+0}-\\eta\\|\\nabla{C}_{t E+0}\\|_{2}^{2}+\\displaystyle{\\frac{K\\eta^{2}}{2}}\\mathbb{E}[\\|g_{t,t E+0}\\|_{2}^{2}]}\\\\ &{\\quad\\le\\!C_{t E+0}-\\eta\\|\\nabla{C}_{t E+0}\\|_{2}^{2}+\\displaystyle{\\frac{K\\eta^{2}}{2}}(\\|\\nabla{C}_{t E+0}\\|_{2}^{2}+\\mathrm{Var}(g^{i,t E+0}))}\\\\ &{\\quad=C_{t E+0}-(\\eta-\\displaystyle{\\frac{K\\eta^{2}}{2}})\\|\\nabla{C}_{t E+0}\\|_{2}^{2}+\\displaystyle{\\frac{K\\eta^{2}}{2}}\\mathrm{Var}(g^{i,t E+0})}\\\\ &{\\quad\\le\\!C_{t E+0}-(\\eta-\\displaystyle{\\frac{K\\eta^{2}}{2}})\\|\\nabla{C}_{t E+0}\\|_{2}^{2}+\\displaystyle{\\frac{K\\eta^{2}}{2}}\\sigma^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\mathrm{Var}(x)=\\mathbb{E}[x^{2}]-(\\mathbb{E}[x])^{2}$ . Take expectation of $\\theta$ on both sides. Then, by telescoping of $E$ steps, we have, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathcal{L}_{(t+1)E}]\\leq\\mathcal{L}_{t E+0}-(\\eta-\\frac{K\\eta^{2}}{2})\\sum_{e=0}^{E}\\|\\nabla\\mathcal{L}_{t E+e}\\|_{2}^{2}+\\frac{K E\\eta^{2}}{2}\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.3 Proof for Lemma 2 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Until the proof, we denote $q$ to indicate that the local model has not been used as a parameter for uploading the server side as a shared layer,i.e., $q=\\theta-w$ . Note that the client symbol $i$ is omitted since it is used for arbitrary clients. ", "page_idx": 18}, {"type": "text", "text": "Proof. ", "text_level": 1, "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}_{(t+1):k}=-C_{(t+1)k}+C_{(t+1)k}+\\alpha-C_{(t+1)k}}&{}\\\\ &{=\\mathcal{L}_{(t+1)k}+Z\\left((\\psi^{t+1},\\psi^{t+1});\\,x,y\\right)-Z\\left((\\psi^{t+1},\\psi^{t+1});x,y\\right)}\\\\ &{\\leqslant Z(t+1)E+\\sqrt{\\mathbb{C}\\left((\\psi^{t+1},\\psi^{t+1})\\right)\\left((\\psi^{t+1},\\psi^{t+1})-(\\psi^{t+1},\\psi^{t+1})\\right)}}\\\\ &{\\quad+\\frac{E}{2}\\left[\\|(\\psi^{t+1},\\psi^{t+1})-(\\psi^{t+1},\\psi^{t+1})\\|_{2}^{2}\\right]}\\\\ &{\\leqslant\\mathcal{L}_{(t+1)E}+\\frac{K\\lambda}{2}\\left\\|(\\psi^{t+1},\\widetilde{w}^{t+1})-(\\psi^{t+1},w^{t+1})\\|_{2}^{2}}\\\\ &{\\leqslant\\mathcal{L}_{(t+1)E}+\\frac{K\\lambda}{2}\\left\\|\\widetilde{w}^{t+1}-w^{t+1}\\right\\|_{2}^{2}}\\\\ &{=\\mathcal{L}_{(t+1)E}+\\frac{K\\lambda}{2}\\left\\|\\widetilde{w}^{t}-\\eta\\nabla Z\\left(\\psi^{t}-w^{t}+\\eta\\nabla Z\\left(w^{t}\\right)\\right\\|_{2}^{2}}\\\\ &{=C_{t+1}\\kappa+\\frac{K\\lambda}{2}\\left\\|\\widetilde{w}^{t}-w^{t}+\\eta\\nabla Z\\left(w^{t}-\\nabla Z\\left(\\psi^{t}\\right)\\right\\|_{2}^{2}\\right.}\\\\ &{\\left.\\leqslant Z(t+1)E+\\frac{K\\lambda}{2}\\left\\|\\widetilde{w}^{t}\\mathbb{C}\\left(w^{t}\\right)-\\nabla Z\\left(\\psi^{t}\\right)\\right\\|_{2}^{2}}\\\\ &{=C_{(t+1)E}+\\frac{\\eta\\sqrt{\\lambda}}{2}\\left\\|\\nabla^{t}\\mathbb{C}\\left(w^{t}\\right)-\\nabla Z\\left(\\psi^{t}\\right)\\right\\|_{2}^{2}}\\\\ &{=C_{(t+1)E}+\\frac{\\eta\\sqrt{\\lambda}}{2}\\left\\|(\\nabla Z\\left(w^{t}\\right)-\\nabla Z\\left(\\psi^{t}\\right)\\right\\|_{2}^{2}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The lemma is proved. ", "page_idx": 19}, {"type": "text", "text": "Taking expectation of both sides of the above equation on the random variable $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathcal{L}_{\\left(t+1\\right)E+0}\\right]\\leqslant\\mathbb{E}\\left[\\mathcal{L}_{\\left(t+1\\right)E}\\right]+\\frac{\\eta K\\lambda}{2}\\mathbb{E}\\left[\\left\\|\\left(\\nabla\\mathcal{L}\\left(w^{t}\\right)-\\nabla\\mathcal{L}\\left(\\widetilde{w}^{t}\\right)\\right)\\right\\|_{2}^{2}\\right]}\\\\ &{\\qquad\\qquad\\leqslant\\mathbb{E}\\left[\\mathcal{L}_{\\left(t+1\\right)E}\\right]+\\frac{\\eta K\\lambda\\omega^{2}}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "C.4 Proof for Theorem 1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Before presenting the proof for Theorem 1, then prove the following theorem. ", "page_idx": 19}, {"type": "text", "text": "Theorem 4 Based on the above assumptions, the expectation of the loss of an arbitrary client\u2019s local model before the start of a round of local iteration satisfies ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]{\\leqslant}\\mathcal{L}_{t E+0}-\\left(\\eta-\\displaystyle\\frac{K\\eta^{2}}{2}\\right)\\displaystyle\\sum_{e=0}^{E}\\|\\mathcal{L}_{t E+e}\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\displaystyle\\frac{\\eta K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Substituting Lemma 1 into the second term on the right-hand side of Lemma 2 proves it. ", "page_idx": 19}, {"type": "text", "text": "Then we can prove Theorem 1 as follows: Proof. Transform the form of Theorem 4 into ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{e=0}^{E}\\|\\mathcal{L}_{t E+e}\\|_{2}^{2}\\leqslant\\frac{\\mathcal{L}_{t E+0}-\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]+\\frac{\\eta K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}{2}}{\\eta-\\frac{K\\eta^{2}}{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Take expectations of model $\\theta$ on both sides, we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{e=0}^{E}\\mathbb{E}\\left[\\left\\|\\mathcal{L}_{t E+e}\\right\\|_{2}^{2}\\right]\\leqslant\\frac{\\mathbb{E}\\left[\\mathcal{L}_{t E+0}\\right]-\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]+\\frac{\\eta K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}{2}}{\\eta-\\frac{K\\eta^{2}}{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $\\begin{array}{r}{\\sum_{t=1}^{T}\\left(\\mathbb{E}\\left[\\mathcal{L}_{t E+0}\\right]-\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]\\right)\\leqslant\\mathcal{L}_{t=1}-\\mathcal{L}^{*}}\\end{array}$ , for each round: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{T E}\\displaystyle\\sum_{t=0}^{T-1}\\frac{\\mathbb{E}}{\\sum_{t=0}^{T-1}}\\mathbb{E}\\left[\\left\\|\\mathcal{L}_{t}E_{+}e\\right\\|_{2}^{2}\\right]}\\\\ &{\\quad\\leqslant\\frac{\\frac{1}{T E}\\sum_{t=0}^{T-1}\\left(\\mathbb{E}\\left[\\mathcal{L}_{t}E_{+}0\\right]-\\mathbb{E}\\left[\\mathcal{L}_{(t+1)E+0}\\right]\\right)+\\frac{\\eta K\\left(E\\eta^{2}+\\lambda\\omega^{2}\\right)}{2}}{\\eta-\\frac{K\\eta^{2}}{2}}}\\\\ &{\\quad\\leqslant\\frac{\\frac{1}{T E}\\left(\\mathcal{L}_{t-1}-\\mathcal{L}^{*}\\right)+\\frac{\\eta K\\left(E\\eta^{2}+\\lambda\\omega^{2}\\right)}{2}}{\\eta-\\frac{K\\eta^{2}}{2}}}\\\\ &{\\quad=\\frac{2\\left(\\mathcal{L}_{t-1}-\\mathcal{L}^{*}\\right)+\\eta K T E\\left(E\\eta^{2}+\\lambda\\omega^{2}\\right)}{T E\\left(2\\eta-K\\eta^{2}\\right)}}\\\\ &{\\quad=\\frac{2\\left(\\mathcal{L}_{t-1}-\\mathcal{L}^{*}\\right)}{T E\\eta\\left(2-K\\eta\\right)}+\\frac{K\\left(E\\eta^{2}+\\lambda\\omega^{2}\\right)}{E\\left(2-K\\eta\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Given any $\\epsilon>0$ the above equation satisfies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{2\\left(\\mathcal{L}_{t=1}-\\mathcal{L}^{*}\\right)}{T E\\eta\\left(2-K\\eta\\right)}+\\frac{K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}{E(2-K\\eta)}\\leqslant\\epsilon.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then, we can obtain: ", "page_idx": 20}, {"type": "equation", "text": "$$\nT\\geqslant\\frac{2\\left(\\mathcal{L}_{t=1}-\\mathcal{L}^{*}\\right)}{E\\eta\\epsilon\\left(2-K\\eta\\right)-\\eta K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $T>0,\\mathcal{L}_{t=1}-\\mathcal{L}^{*}>0$ , we can further derive: ", "page_idx": 20}, {"type": "equation", "text": "$$\nE\\eta\\epsilon\\left(2-K\\eta\\right)-\\eta K\\left(E\\eta\\sigma^{2}+\\lambda\\omega^{2}\\right)>0,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "i.e., ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\eta<\\frac{2E\\epsilon-K\\lambda\\omega^{2}}{K E\\left(\\epsilon+\\sigma^{2}\\right)}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "D Excess risk bound ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "D.1 Proof for Lemma 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. By following [40], we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathcal{W}\\|_{*^{\\star}}=\\underset{\\sum_{k\\neq\\emptyset,k\\subset[p]}}{\\operatorname*{inf}}\\underset{\\mathcal{W}^{(k)}=\\mathcal{W}}{\\operatorname*{max}}\\left\\|\\mathcal{W}_{(k)}^{(k)}\\right\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $[p]$ denotes a set of positive integers no larger than $p$ . Since we can take any $\\mathcal{W}^{(k)}$ to equal $\\mathcal{W}$ , the norm can be upper bounded as follows: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\mathcal{W}\\|_{*^{\\star}}\\leq\\operatorname*{min}_{k}\\left\\|\\mathcal{W}_{(k)}\\right\\|_{\\infty}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "D.2 Proof for Theorem 2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. Based on Lemma 3, given that the minimum expectation across $k$ can be confined to an upper limit by the minimum of the expected values, it follows that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|\\mathcal{W}\\right\\|_{*^{\\star}}\\leq\\mathbb{E}\\operatorname*{min}_{k}\\left\\|\\mathcal{W}_{(k)}\\right\\|_{\\infty}\\leq\\operatorname*{min}_{k}\\mathbb{E}\\left\\|\\mathcal{W}_{(k)}\\right\\|_{\\infty}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Referring to Theorem 6.1 in Reference [47], we upper bound for each expectation that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{Pr}\\{\\left\\|\\mathcal{W}_{(k)}\\right\\|_{\\infty}\\geq t\\}\\leq\\left\\{\\!\\!\\!D_{k}e x p(-3t^{2}/8\\sigma_{k}^{2}),\\quad\\mathrm{for}\\,\\,t\\leq\\sigma_{k}^{2}/R_{k},}\\\\ {D_{k}e x p(-3t/8R_{k}),\\quad\\mathrm{for}\\,\\,t\\geq\\sigma_{k}^{2}/R_{k},}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|\\mathcal{W}_{(k)}\\right\\|_{\\infty}\\leq C(\\sigma_{k}\\sqrt{l n D_{k}}+R_{k}l n D_{k}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $C$ is an absolute constant, and $\\mathcal{Z}^{i,j}$ is a $d_{1}\\times\\cdots\\times d_{p-1}\\times d_{p}$ zero tensor with only the ith slice along the last axis equal to $\\begin{array}{r}{\\frac{1}{n}\\sigma_{i}^{j}\\mathbf{x}_{i}^{j}}\\end{array}$ , and in addition, $R_{k}$ satisfies $\\begin{array}{r}{R_{k}\\geq||\\mathcal{Z}_{(k)}^{i,j}||_{\\infty}}\\end{array}$ , therefore: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sigma_{k}^{2}=\\operatorname*{max}\\left(\\left\\lVert\\sum_{i=1}^{M}\\sum_{j=1}^{n}\\mathbb{E}[\\mathcal{Z}_{(k)}^{i,j}(\\mathcal{Z}_{(k)}^{i,j})^{T}]\\right\\rVert_{\\infty},\\left\\lVert\\sum_{i=1}^{M}\\sum_{j=1}^{n}\\mathbb{E}[(\\mathcal{Z}_{(k)}^{i,j})^{T}\\mathcal{Z}_{(k)}^{i,j}]\\right\\rVert_{\\infty}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since the Frobenius norm of a matrix is larger than its spectral norm, $\\begin{array}{r}{||\\mathcal{Z}_{(k)}^{i,j}||_{\\infty}\\leq\\frac{1}{n}}\\end{array}$ and we simply set $\\begin{array}{r}{R_{k}=\\frac{1}{n}}\\end{array}$ . For $\\sigma_{k}$ , we obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\sum_{j=1}^{N}\\mathcal{Z}_{(k)}^{i,j}(\\mathcal{Z}_{(k)}^{i,j})^{T}]=\\frac{1}{n}\\mathbf{C}_{k-\\{p\\}}\\preceq\\frac{\\kappa}{n d}\\mathbf{I},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\kappa>0$ is given constant. This means: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i=1}^{M}\\sum_{j=1}^{n}\\mathbb{E}[\\mathcal{Z}_{(k)}^{i,j}(\\mathcal{Z}_{(k)}^{i,j})^{T}]\\right\\|_{\\infty}\\leq\\frac{\\kappa M}{n d}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Similarly, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\sum_{j=1}^{n}(\\mathcal{Z}_{(k)}^{i,j})^{T}\\mathcal{Z}_{(k)}^{i,j}]=\\operatorname{diag}\\left(\\frac{\\operatorname{tr}\\left(\\mathbf{C}_{k-\\{p\\}}\\right)}{n}\\right)\\preceq\\frac{\\kappa}{n d}\\mathbf{I},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\operatorname{tr}(\\cdot)$ denotes the trace on a matrix and diag(\u00b7) converts a vector or scalar to a diagonal matrix. This inequality implies ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i=1}^{M}\\sum_{j=1}^{n}\\mathbb{E}[(\\mathcal{Z}_{(k)}^{i,j})^{T}\\mathcal{Z}_{(k)}^{i,j}]\\right\\|_{\\infty}\\leq\\frac{\\kappa M}{n d}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting inequalities Eq. (39) and Eq. (41) into Eq. (36), we obtain inequality Eq.(14). ", "page_idx": 21}, {"type": "text", "text": "D.3 Proof for Theorem 3 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Proof. Note that ", "text_level": 1, "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{R}(\\hat{\\mathcal{W}})-\\mathcal{R}(\\mathcal{W})=\\underbrace{\\mathcal{R}(\\hat{\\mathcal{W}})-\\hat{\\mathcal{R}}(\\hat{\\mathcal{W}})}_{r1}+\\underbrace{\\hat{\\mathcal{R}}(\\hat{\\mathcal{W}})-\\hat{\\mathcal{R}}(\\mathcal{W})}_{r2}+\\underbrace{\\hat{\\mathcal{R}}(\\mathcal{W})-\\mathcal{R}(\\mathcal{W})}_{r3}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We first establish the upper bound for part $r3$ in Eq. (42). Under Assumption 1, it follows from Hoeffding\u2019s inequality [48] that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{R}}(\\mathcal{W})-\\mathcal{R}(\\mathcal{W})\\leq a\\sqrt{\\frac{l o g(2/\\delta)}{2\\sum_{i}n_{i}}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "with probability at least $\\textstyle1-{\\frac{\\delta}{2}}$ . Since $\\hat{\\mathcal{W}}$ is the optimal solution of Eq. (12), for the part $r2$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{R}}(\\hat{\\mathcal{W}})-\\hat{\\mathcal{R}}(\\mathcal{W})\\leq0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $\\mathcal{L}$ is bounded such that the perturbation of Eq. (12) to $\\mathbf{x}_{i}^{j}$ is less than $\\frac{a}{M n_{i}}$ . By McDiarmid\u2019s inequality [49], the part we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}(\\hat{\\mathcal{W}})-\\hat{\\mathcal{R}}(\\hat{\\mathcal{W}})\\leq\\underset{\\Vert\\mathcal{W}\\Vert_{*}\\leq\\gamma}{\\operatorname*{sup}}\\{\\mathcal{R}(\\mathcal{W})-\\hat{\\mathcal{R}}(\\mathcal{W})\\}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{E}\\left[\\underset{\\Vert\\mathcal{W}\\Vert_{*}\\leq\\gamma}{\\operatorname*{sup}}\\{\\mathcal{R}(\\mathcal{W})-\\hat{\\mathcal{R}}(\\mathcal{W})\\}\\right]+a\\sqrt{\\frac{\\log\\left(2/\\delta\\right)}{2M n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "with probability at least $\\textstyle1-{\\frac{\\delta}{2}}$ . Therefore, plugging Eq. (43-45), into Eq. (42), we deduce ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}(\\hat{\\mathcal{W}})-\\mathcal{R}(\\mathcal{W})\\leq\\mathbb{E}\\left[\\underset{\\|\\mathcal{W}\\|_{*}\\leq\\gamma}{\\operatorname*{sup}}\\left\\lbrace\\mathcal{R}(\\mathcal{W})-\\hat{\\mathcal{R}}(\\mathcal{W})\\right\\rbrace\\right]}\\\\ &{\\qquad\\qquad\\qquad+\\left.a\\sqrt{\\frac{\\log(2/\\delta)}{2M n}}+a\\sqrt{\\frac{l o g(2/\\delta)}{2\\sum_{i}n_{i}}}\\right.}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{E}\\left[\\underset{\\|\\mathcal{W}\\|_{*}\\leq\\gamma}{\\operatorname*{sup}}\\left\\lbrace\\mathcal{R}(\\mathcal{W})-\\hat{\\mathcal{R}}(\\mathcal{W})\\right\\rbrace\\right]+a\\sqrt{\\frac{2\\log(2/\\delta)}{M n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second inequality follows from $n_{i}\\geq n$ . Now we estimate an upper bound of the expectation in Eq. (46) as: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\underset{||V||\\leq\\gamma}{\\operatorname*{sup}}\\;\\lbrace\\mathcal{R}(\\mathcal{W})-\\hat{\\mathcal{R}}(\\mathcal{W})\\rbrace\\right]}\\\\ &{\\quad\\leq\\mathbb{E}\\underset{||V||\\leq\\gamma}{\\operatorname*{sup}}\\left|\\frac{1}{M}\\sum_{n_{i}}\\mathbb{E}_{(\\mathbb{x},y)\\sim\\mathcal{P}_{i}}\\mathcal{L}(\\mathcal{F}_{i}(\\mathcal{W};\\mathbf{x}),y)\\right.}\\\\ &{\\qquad\\left.-\\frac{1}{M}\\frac{M}{\\int_{i=1}}\\frac{1}{n_{i}}\\sum_{j=1}^{n_{i}}\\mathcal{L}(\\mathcal{F}_{i}(\\mathcal{W};\\mathbf{x}_{i}^{j}),y_{i}^{j})\\right|}\\\\ &{\\quad\\leq\\mathbb{E}\\underset{||\\mathcal{W}||\\leq\\gamma}{\\operatorname*{sup}}\\left|\\frac{2}{M}\\underset{i=1}{\\overset{M}{\\sum}}\\frac{1}{n_{i}}\\sum_{j=1}^{n_{i}}\\sigma_{i}^{j}\\mathcal{L}(\\mathcal{F}_{i}(\\mathcal{W};\\mathbf{x}_{i}^{j}),y_{i}^{j})\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the expectation is taken over the Rademacher random variables and the training samples. Then, we obtain that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}\\left[\\frac{2\\nu}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\sum_{j=1}^{\\infty}e^{j\\cdot\\left(Z_{i}(X)\\left(X\\right)\\right)}x_{i}\\right]}\\\\ &{\\phantom{=}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\frac{1}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\frac{1}{\\gamma}e^{-j\\cdot\\left(Z_{i}(X)\\left(X_{i}^{\\nu}\\right)\\right)}\\Bigg]}\\\\ &{\\phantom{=}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\frac{1}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\frac{1}{\\gamma}e^{-j\\cdot\\left(Z_{i}(X)\\left(X_{i}^{\\nu}\\right)\\right)}\\Bigg]}\\\\ &{\\phantom{=}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\frac{1}{\\gamma}\\sum_{j=1}^{\\infty}e^{j\\cdot\\left(Z_{i}(X)\\right)}x_{i}\\Bigg]}\\\\ &{\\phantom{=}+\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\frac{1}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\frac{1}{\\gamma}e^{-j\\cdot\\left(Z_{i}(X)\\right)}}\\\\ &{\\phantom{=}-\\frac{4\\nu}{\\hbar\\alpha}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\left[(\\mathbf{S}\\right)\\right]+\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\frac{1}{\\hbar\\alpha}\\sum_{i=1}^{\\nu}\\frac{1}{\\gamma}e^{-j\\cdot\\left(N_{i}(X)\\right)}}\\\\ &{\\phantom{=}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\left[(\\mathbf{S}\\right)\\right]\\Bigg]+\\frac{2\\nu}{\\hbar\\alpha}\\mathbb{E}_{\\left[\\nu\\left(\\mathbf{S}\\right)\\right]<\\nu}^{\\infty}\\Bigg[\\frac{2\\nu}{\\hbar\\alpha}\\sum_{i=1}^ \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Notice that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left\\lvert\\sum_{i=1}^{M}\\sum_{j=1}^{n_{i}}\\sigma_{i}^{j}\\lvert y_{i}^{j}\\rvert\\right\\rvert\\leq b\\mathbb{E}\\left\\lvert\\sum_{i=1}^{M}\\sum_{j=1}^{n_{i}}\\sigma_{i}^{j}\\right\\rvert=b\\mathbb{E}\\left[\\sqrt{\\left(\\displaystyle\\sum_{i=1}^{M}\\sum_{j=1}^{n_{i}}\\sigma_{i}^{j}\\right)^{2}}\\right]}\\\\ {\\displaystyle\\leq b\\left[\\mathbb{E}\\sqrt{\\left(\\displaystyle\\sum_{i=1}^{M}\\sum_{j=1}^{n_{i}}\\sigma_{i}^{j}\\right)^{2}}\\right]=b\\sqrt{\\displaystyle\\sum_{i=1}^{M}n_{i}}=b\\sqrt{N}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining Eq.(46-49), we deduce that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{R}(\\hat{\\mathcal{W}})-\\mathcal{R}(\\mathcal{W})\\leq\\frac{4\\gamma K}{M}\\mathbb{E}[\\|\\mathcal{W}\\|_{*^{\\star}}]+\\frac{2b K\\sqrt{N}}{M n}+a\\sqrt{\\frac{2l o g(2/\\delta)}{M n}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "with probability at least $\\textstyle1-{\\frac{\\delta}{2}}$ . The proof of this theorem is completed. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our paper aims to provide a flexible framework for dealing with heterogeneous federated learning, accurately reflecting the contributions and scope of the paper in the abstract and introduction. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: In this paper, we present the limitations of the model used in this approach in terms of computational complexity. At the same time, we also provide a solution to this limitation in the appendix. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provide detailed proof in the appendix. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provide detailed proof in the appendix. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our datasets are all public datasets and we provide the source address of the data and details of the experimental setups. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We explain in detail the choice of model hyperparameters and the optimizers used in the appendix. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our experiments do not include significance experiments and therefore do not take into account statistical error information. ", "page_idx": 24}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We report in the Appendix that we experimented with all methods using four NVIDIA GeForce RTX 4090 GPUs. ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research is consistent in all respects with the NeurIPS Code of Ethics. ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We discuss the significance of algorithms for the real world in the introduction section ", "page_idx": 25}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: Inapplicable ", "page_idx": 25}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We cite all creators or original owners in our papers. ", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: New assets are well documented. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] Justification: Inapplicable ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] Justification: Inapplicable ", "page_idx": 25}]