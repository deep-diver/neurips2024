[{"figure_path": "3YkeHuT1o6/figures/figures_2_1.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "This figure illustrates the architecture of the FedSAK model, which is designed to handle heterogeneous federated learning scenarios. The model consists of multiple local clients and a central server. Each local client has its own dataset and a model composed of a feature extractor and a prediction head. Clients can flexibly choose shared structures based on their specific heterogeneous situations. The clients upload the global shared layers to the server, which learns correlations among client models by mining model low-rank structures through the tensor trace norm.  Different heterogeneity types are represented: DH (Data Heterogeneity), MH (Model Heterogeneity), and TH (Task Heterogeneity). The figure shows how the model handles these different types of heterogeneity by adapting its structure.", "section": "4 Methodology"}, {"figure_path": "3YkeHuT1o6/figures/figures_7_1.jpg", "caption": "Figure 2: The test accuracy and convergence process of each method.", "description": "This figure presents the test accuracy and convergence performance of various federated learning (FL) methods across four different datasets: Human Activity, MNIST, CIFAR-10, and CIFAR-100.  Each dataset represents a different level of complexity and data heterogeneity. The x-axis represents the number of epochs, and the y-axis represents the test accuracy. The figure showcases the relative performance and convergence speed of each method, highlighting the superior performance of FedSAK (in red) in most cases.", "section": "6.2 Results and Discussion"}, {"figure_path": "3YkeHuT1o6/figures/figures_7_2.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "This figure illustrates the architecture of the FedSAK model, highlighting its ability to handle data, model, and task heterogeneity in federated learning.  The model is split into a feature extractor and a prediction head at each client, allowing for flexibility in model structure. Clients upload their models (or parts thereof) to a central server, which utilizes tensor trace norm to learn correlations among the client models.  The figure uses DH, MH, and TH to represent Data, Model, and Task Heterogeneity respectively.", "section": "4 Methodology"}, {"figure_path": "3YkeHuT1o6/figures/figures_9_1.jpg", "caption": "Figure 5: Test accuracy of parameter \u03bb in different scenarios.", "description": "This figure shows the test accuracy of the parameter \u03bb (lambda) in different heterogeneous settings: data heterogeneity (CIFAR-10 dataset with varying numbers of clients and classes), model heterogeneity (PACS dataset with different numbers of clients), and task heterogeneity (Adience Faces dataset with different numbers of clients and tasks).  The x-axis represents the value of \u03bb, while the y-axis represents the test accuracy.  Each line represents a different experimental setup, illustrating how the optimal \u03bb value varies depending on the type of heterogeneity.", "section": "6.3 Parameter Experiment"}, {"figure_path": "3YkeHuT1o6/figures/figures_9_2.jpg", "caption": "Figure 2: The test accuracy and convergence process of each method.", "description": "This figure presents the test accuracy and convergence behavior of different federated learning methods across various datasets and heterogeneity scenarios.  The x-axis represents the number of epochs (training iterations), and the y-axis shows the test accuracy achieved by each algorithm.  Different colored lines represent different algorithms, allowing for a comparison of their performance and convergence speed under the specific settings of each dataset (Human Activity, MNIST, CIFAR-10, CIFAR-100).  This visualization helps to understand the relative effectiveness of each method in handling data heterogeneity and achieving high accuracy in federated learning.", "section": "6.2 Results and Discussion"}, {"figure_path": "3YkeHuT1o6/figures/figures_9_3.jpg", "caption": "Figure 2: The test accuracy and convergence process of each method.", "description": "This figure shows the test accuracy and convergence process of different federated learning methods across various datasets (Human Activity, MNIST, CIFAR-10, CIFAR-100).  It compares FedSAK's performance against 13 baseline methods, demonstrating its superior performance and faster convergence in handling data heterogeneity.  Each subfigure represents a different dataset, illustrating the training progress over epochs.", "section": "6.2 Results and Discussion"}, {"figure_path": "3YkeHuT1o6/figures/figures_14_1.jpg", "caption": "Figure 3: The test accuracy of all methods on MH. Figure 4: Confusion matrix of classification results obtained from two clients TH on the Adience Face.", "description": "This figure actually contains two figures combined.  The first (Figure 3) shows the test accuracy of various federated learning methods under Model Heterogeneity (MH) conditions across several datasets.  The second (Figure 4) displays confusion matrices for a task heterogeneity scenario, illustrating the performance of a classifier for two clients on the Adience Face dataset. These matrices showcase the model's ability to correctly classify different aspects of faces, such as gender and age, across different domains or clients.", "section": "6.2 Results and Discussion"}, {"figure_path": "3YkeHuT1o6/figures/figures_16_1.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "The figure illustrates the architecture of the FedSAK model, a federated multi-task learning framework designed to handle data, model, and task heterogeneity.  The model is composed of local clients and a central server. Each client has a local dataset and a local model split into a feature extractor and a prediction head. Clients upload their global shared layers (a subset of their model parameters) to the server. The server aggregates these layers, applies a tensor trace norm to mine correlations and low-rank structures, updates the shared layers, and broadcasts them back to the clients.  DH, MH, and TH represent the types of heterogeneity addressed by the model.", "section": "4 Methodology"}, {"figure_path": "3YkeHuT1o6/figures/figures_16_2.jpg", "caption": "Figure 10: The data distribution on Human Activity.", "description": "This figure visualizes the data distribution across different clients in the Human Activity dataset. Each client is represented by a column, and each row represents a class ID. The size of the red circle indicates the proportion of data points for that class in the client's dataset.  The visualization helps illustrate the heterogeneity of data distribution among clients, where some clients have more data for specific classes than others.", "section": "B.2 Data Distribution Visualization"}, {"figure_path": "3YkeHuT1o6/figures/figures_16_3.jpg", "caption": "Figure 10: The data distribution on Human Activity.", "description": "This figure visualizes the data distribution among 30 clients in the Human Activity dataset. Each client is assigned a subset of the data, and the size of the red circles represents the proportion of data each client has for a given class.  It highlights the non-i.i.d. nature of the data distribution, showing that clients do not have the same classes nor the same number of samples per class.", "section": "B.2 Data Distribution Visualization"}, {"figure_path": "3YkeHuT1o6/figures/figures_16_4.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "This figure illustrates the architecture of the FedSAK model, a federated multi-task learning framework designed to handle data, model, and task heterogeneity.  The model consists of multiple local clients and a central server. Each client has a local dataset and a model divided into two parts: a feature extractor and a prediction head. Clients can customize these components based on their resources and task demands. The clients upload their extracted features to the central server, which aggregates these features and learns correlations between client models using the tensor trace norm. The central server then updates the global shared layers and sends them back to the clients.  The figure highlights how the framework addresses different types of heterogeneity: DH (Data Heterogeneity) representing differences in data distribution across clients; MH (Model Heterogeneity) representing differences in model architecture and capacity; and TH (Task Heterogeneity) representing differences in the task objectives of the clients.", "section": "4 Methodology"}, {"figure_path": "3YkeHuT1o6/figures/figures_17_1.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "This figure illustrates the architecture of the FedSAK model, highlighting its flexibility in handling various types of heterogeneity in federated learning.  The model is composed of local clients and a central server. Each client has a local dataset and a model divided into a feature extractor and a prediction head.  Clients can upload different parts of their model (feature extractor, prediction head, or both) depending on their resources and the type of heterogeneity present. The server aggregates the uploaded components and learns correlations among client models using the tensor trace norm.  The figure also uses abbreviations to represent the different types of heterogeneity addressed by the model: DH (Data Heterogeneity), MH (Model Heterogeneity), and TH (Task Heterogeneity).", "section": "4 Methodology"}, {"figure_path": "3YkeHuT1o6/figures/figures_17_2.jpg", "caption": "Figure 12: The data distribution of all clients on CIFAR-10.", "description": "This figure visualizes the data distribution across different clients in the CIFAR-10 dataset. Each small dot represents a data sample, and the size of the dot reflects the number of samples for each class label. The x-axis represents the client ID, and the y-axis represents the class ID. The different subfigures (a, b, c, and d) show the data distribution under varying settings.  The distribution is non-IID (non-independent and identically distributed), meaning that the data across clients is not uniform.", "section": "B.2 Data Distribution Visualization"}, {"figure_path": "3YkeHuT1o6/figures/figures_18_1.jpg", "caption": "Figure 1: The main framework of FedSAK model. DH denotes \"Data Heterogeneity\", MH denotes \"Model Heterogeneity\", and TH denotes \u201cTask Heterogeneity\".", "description": "The figure illustrates the FedSAK model's architecture.  It shows multiple clients (local clients 1 to m), each with its dataset (X1 to Xm) and labels (Y1 to Ym). Each client model is split into a feature extractor and a prediction head, allowing for flexible model structures depending on the specific client and its data characteristics. The clients upload their model parameters (w) to a central server, which aggregates and processes the information using a tensor trace norm to identify relationships between client models and create a low-rank structure, representing intrinsic correlations among clients. The server then sends back updated global shared layers to each client to facilitate model training and knowledge transfer.  The figure highlights the model's ability to handle Data, Model, and Task Heterogeneity (DH, MH, TH).", "section": "4 Methodology"}]