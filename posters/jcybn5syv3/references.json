{"references": [{"fullname_first_author": "Holger Caesar", "paper_title": "nuScenes: A multimodal dataset for autonomous driving", "publication_date": "2020-00-00", "reason": "This paper introduces a large-scale, multimodal dataset crucial for training and evaluating autonomous driving models, which is heavily used and cited in the target paper's methodology."}, {"fullname_first_author": "Quanyi Li", "paper_title": "MetaDrive: Composing diverse driving scenarios for generalizable reinforcement learning", "publication_date": "2022-00-00", "reason": "This paper introduces the MetaDrive simulator, a key component of the target paper's method that enables controllable and diverse driving scene generation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces a state-of-the-art diffusion model for high-resolution image synthesis, which is adapted and utilized as a core component in the target paper's SimGen framework."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-00-00", "reason": "This paper presents ControlNet, a method for adding conditional control to diffusion models, which is used and adapted in the target paper's ImgDiff module for controlled image generation."}, {"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2021-00-00", "reason": "This paper introduces a text-guided diffusion model that achieves photorealistic image generation, which is improved upon by the target paper for generating diverse driving scenes."}]}