[{"figure_path": "32g9BWTndc/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results on citation and e-commerce datasets for various models.  It compares the performance of TEA-GLM against several baseline methods, including traditional GNNs, self-supervised methods, and LLMs. The results are shown for different datasets (Arxiv, Pubmed, Cora, Children, History, Computer, Photo, Sports) and highlight TEA-GLM's superior zero-shot learning capabilities across diverse datasets and tasks.", "section": "3 Experimental results"}, {"figure_path": "32g9BWTndc/tables/tables_7_1.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results of various models on citation and e-commerce datasets.  The models are categorized by type (MLP, GNN, LLM, and TEA-GLM).  For each dataset, the accuracy is shown, with the best result in bold and the second-best underlined. This illustrates the cross-dataset generalization capabilities of the different approaches, highlighting the superior performance of TEA-GLM.", "section": "3.1 Experimental setup"}, {"figure_path": "32g9BWTndc/tables/tables_13_1.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results on eight datasets (three citation and five e-commerce datasets) using various methods.  It compares the performance of TEA-GLM against several baselines, including MLP, GCN, GraphSAGE, GAT, DGI, GKD, GLNN, NodeFormer, DIFFormer, OFA, Vicuna-7B-v1.5, Vicuna-7B-SPT, GraphGPT, and LLaGA.  The results show TEA-GLM's superior performance in zero-shot settings across diverse datasets and tasks. Bold highlights the best result across all models for each dataset; underline highlights the second best.", "section": "3.1 Experimental setup"}, {"figure_path": "32g9BWTndc/tables/tables_13_2.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results on eight datasets across three different domains: citation and e-commerce. It compares the performance of TEA-GLM against various baselines, including non-GNN methods, supervised GNN methods, self-supervised GNN methods, graph knowledge distillation methods, graph transformer networks, and LLMs.  The results are shown for each dataset separately, with bold highlighting the best performance and underlined values indicating the second-best performance for each dataset.  The table highlights TEA-GLM's superiority across diverse datasets and tasks.", "section": "3.1 Experimental setup"}, {"figure_path": "32g9BWTndc/tables/tables_14_1.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results on citation and e-commerce datasets for various models, including MLP, GCN, GraphSAGE, GAT, DGI, GKD, GLNN, NodeFormer, DIFFormer, OFA, Vicuna-7B-v1.5, Vicuna-7B-SPT, GraphGPT-std, GraphGPT-cot, LLaGA, and TEA-GLM. The best result for each dataset is shown in bold, while the second-best is underlined.  It compares the performance of TEA-GLM against multiple baselines across different model types (GNNs, LLMs) and learning strategies (supervised, self-supervised, zero-shot). This allows for a comprehensive evaluation of TEA-GLM's performance in zero-shot cross-dataset settings.", "section": "3 Experimental results"}, {"figure_path": "32g9BWTndc/tables/tables_14_2.jpg", "caption": "Table 1: Zero-shot accuracy on citation and e-commerce datasets (bold highlights the best result across all methods, while underline highlights the second-best results)", "description": "This table presents the zero-shot accuracy results of various models on citation and e-commerce datasets.  The models are categorized into GNNs as predictors, LLMs as predictors, and a combined approach using both.  The best result for each dataset is shown in bold, and the second-best is underlined.  This allows for a direct comparison of different model types and their performance in zero-shot settings across diverse datasets. The datasets represent various citation networks (Arxiv, Pubmed, Cora) and e-commerce product co-purchasing/co-viewing networks.", "section": "3.1 Experimental setup"}, {"figure_path": "32g9BWTndc/tables/tables_16_1.jpg", "caption": "Table 2: AUC of link prediction (Cross-task)", "description": "This table presents the Area Under the Curve (AUC) scores for link prediction task in a cross-task zero-shot learning setting.  The results are shown for different models on various citation and e-commerce datasets. The models include OFA, Vicuna-7B-v1.5, Vicuna-7B-SPT, GraphGPT-std, LLaGA and TEA-GLM (using max, sum, and mean pooling methods). The table allows for a comparison of the performance of various models in a cross-task setting, highlighting the effectiveness of TEA-GLM in this challenging scenario.", "section": "3.3 Cross-task zero-shot ability (RQ2)"}]