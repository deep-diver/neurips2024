[{"figure_path": "mYEjc7qGRA/figures/figures_3_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H, H<sup>v</sup>, H<sup>a</sup>, H<sup>cc</sup>, and H<sup>D</sup> are randomly initialized learnable vectors.", "description": "This figure presents a comprehensive overview of the Language-dominated Noise-resistant Learning Network (LNLN) architecture for robust multimodal sentiment analysis.  It details the entire process, from multimodal input with randomly missing data to final sentiment prediction. The diagram visually depicts the individual components: Multimodal Input, Feature Extraction, Dominant Modality Correction (DMC) module with Completeness Check and Proxy Dominant Feature Generation, Dominant Modality based Multimodal Learning (DMML) module containing Language, Visual, and Audio Embedding, Adaptive Hyper-modality Learning, Cross-modality Fusion Transformer, and a Reconstructor. Each component's function and interconnections are clearly illustrated, along with the learnable vectors used in the process.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_7_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00b2, H\u00b3, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a detailed overview of the Language-Dominated Noise-resistant Learning Network (LNLN) pipeline, highlighting the key components such as the embedding layer, Dominant Modality Correction (DMC) module, Dominant Modality based Multimodal Learning (DMML) module, and Reconstructor.  The pipeline starts with a multimodal input that includes language, visual, and audio data, which may have random missing data. The DMC module corrects for noise in the dominant modality (language). The DMML module then integrates the corrected dominant modality with the other modalities, leading to more robust feature representation.  A reconstructor is used to reconstruct missing data to further improve robustness.  Finally, a classifier outputs the sentiment prediction. The figure illustrates the flow of data through each module, highlighting the interactions and dependencies between them.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_13_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00ba, H\u00ba, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a comprehensive overview of the Language-dominated Noise-resistant Learning Network (LNLN) pipeline. It illustrates the process of how the model handles multimodal input with random data missing. The input is first standardized using an embedding layer, then processed by the Dominant Modality Correction (DMC) module to improve the quality of dominant modality (language). The Dominant Modality based Multimodal Learning (DMML) module then fuses the corrected dominant modality with auxiliary modalities (audio and visual). Finally, a reconstruction layer reconstructs the missing data, boosting the system's robustness. The entire process highlights the model's ability to maintain high-quality representation and achieve robust sentiment analysis despite noise.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_14_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00b2, H\u00b3, Hcc, and HD are randomly initialized learnable vectors.", "description": "This figure presents a detailed illustration of the Language-dominated Noise-resistant Learning Network (LNLN) pipeline for robust multimodal sentiment analysis. The pipeline consists of several key modules: 1) Input Construction and Multimodal Input, which generates a multimodal input with random data missing; 2) Embedding, which standardizes the dimensions of each modality; 3) Dominant Modality Correction (DMC), which mitigates noise impacts using adversarial learning and a dynamic weighted enhancement strategy; 4) Dominant Modality based Multimodal Learning (DMML), which performs multimodal fusion and classification; 5) Reconstructor, which reconstructs missing data. These modules work together to enhance the robustness of LNLN across various noise scenarios. The figure visually demonstrates the flow of data through these modules, highlighting the key processes and learnable parameters within the network architecture.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_14_2.jpg", "caption": "Figure 1: Overall pipeline. Note: H<sup>l</sup>, H<sup>v</sup>, H<sup>a</sup>, H<sup>cc</sup>, and H<sup>D</sup> are randomly initialized learnable vectors.", "description": "This figure presents a schematic overview of the Language-dominated Noise-resistant Learning Network (LNLN).  It illustrates the overall processing pipeline, starting with multimodal input (language, visual, audio) which may contain random missing data. The input is then processed sequentially through embedding, dominant modality correction (DMC), dominant modality based multimodal learning (DMML), and a reconstruction layer.  The DMC module aims to improve the quality of the dominant language modality despite noise, while DMML integrates the refined language features with other modalities.  The reconstruction layer handles missing data. Finally, a classifier produces the sentiment prediction.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_14_3.jpg", "caption": "Figure 1: Overall pipeline. Note: H, H<sup>v</sup>, H<sup>a</sup>, H<sup>cc</sup>, and H<sup>d</sup> are randomly initialized learnable vectors.", "description": "This figure presents a comprehensive overview of the proposed Language-Dominated Noise-resistant Learning Network (LNLN) for robust multimodal sentiment analysis.  The pipeline starts with a multimodal input that has undergone random data missing. An embedding layer standardizes the input dimensions. A Dominant Modality Correction (DMC) module is responsible for refining the language modality (considered dominant due to its richer sentiment information), mitigating noise effects via adversarial learning. A Dominant Modality based Multimodal Learning (DMML) module fuses the enhanced dominant modality with auxiliary modalities. Finally, a reconstructor addresses missing data, enhancing robustness. The entire process is designed to achieve robust multimodal sentiment analysis, even with incomplete data.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_17_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00ba, H\u00ba, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a detailed overview of the Language-dominated Noise-resistant Learning Network (LNLN) pipeline. It illustrates the process of handling multimodal input with missing data through several modules: embedding, dominant modality correction (DMC), dominant modality-based multimodal learning (DMML), and a reconstructor.  Each module's role in mitigating noise and improving sentiment analysis robustness is visualized. The figure highlights the flow of information and the interactions between different components of the LNLN architecture.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_18_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00b2, H\u00b3, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a detailed illustration of the Language-dominated Noise-resistant Learning Network (LNLN) architecture. The pipeline begins with a multimodal input that incorporates data from three modalities: language, audio, and visual data. After an embedding layer, the Dominant Modality Correction (DMC) module uses an adversarial learning approach to reduce the negative impact of noise on the dominant modality (language). The Dominant Modality based Multimodal Learning (DMML) module then incorporates these features for effective multimodal fusion and classification. Finally, a reconstructor aims to refine the network's robustness by reconstructing missing data. This comprehensive pipeline enhances the model's robustness in handling incomplete and noisy data.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_19_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H, H0, H0, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a schematic overview of the proposed Language-dominated Noise-resistant Learning Network (LNLN) architecture.  The pipeline begins with a multimodal input, which is then processed through embedding, Dominant Modality Correction (DMC), and Dominant Modality based Multimodal Learning (DMML) modules. The DMC module addresses noise in the dominant modality (language). The DMML module integrates modalities for effective multimodal fusion and classification.  A reconstructor addresses missing data. The final output is the sentiment prediction.  The figure also visually illustrates the flow of information and the components of the LNLN.", "section": "3 Method"}, {"figure_path": "mYEjc7qGRA/figures/figures_20_1.jpg", "caption": "Figure 1: Overall pipeline. Note: H\u00b9, H\u00ba, H\u00ba, Hcc, and H are randomly initialized learnable vectors.", "description": "This figure presents a comprehensive overview of the proposed Language-dominated Noise-resistant Learning Network (LNLN) architecture and its training pipeline. It illustrates the process, starting from the multimodal input with random data missing, through various modules such as embedding, dominant modality correction (DMC), dominant modality based multimodal learning (DMML), and reconstructor, ultimately leading to sentiment prediction.  The figure highlights the key components of LNLN and their interactions, providing a visual representation of the model's workflow.  The learnable vectors (H\u00b9, H\u00ba, H\u00ba, Hcc, and H) are also indicated, emphasizing the model's trainable parameters.", "section": "3 Method"}]