[{"figure_path": "hCOuip5Ona/figures/figures_4_1.jpg", "caption": "Figure 1: Effect of perturbing L by S on minimizers of (10) on the simplex. Shade of level-curves denotes descent direction. Blue dots denote unique minimizers in the simplex. As the magnitude of the perturbation increases, the minimizers gravitate towards the extreme points of the simplex.", "description": "This figure shows how adding a perturbation matrix S to the graph Laplacian L affects the minimizers of the objective function in equation (10).  As the value of s (scaling factor for S) increases, the initially convex objective function becomes non-convex, and the minimum shifts from the interior of the simplex (representing a non-integer solution) towards its vertices (representing integer solutions). This illustrates the core idea of the CutSSL method, where a controlled perturbation drives the optimization towards integer solutions representing smooth discrete label assignments.", "section": "2.3 Graph cuts and continuous quadratic programming"}, {"figure_path": "hCOuip5Ona/figures/figures_9_1.jpg", "caption": "Figure 2: Prediction accuracy on citation networks.", "description": "This figure shows the prediction accuracy of different semi-supervised learning methods on Cora and Citeseer citation networks, with varying label rates.  It demonstrates the performance of Laplace learning, mean-shifted Laplace learning, Poisson learning, Poisson-MBO, and CutSSL across different label ratios. The graph visually represents how each method's accuracy changes as more labels are added to the training data.  It highlights the superior performance of CutSSL, especially at low label rates.", "section": "Experiments"}, {"figure_path": "hCOuip5Ona/figures/figures_14_1.jpg", "caption": "Figure 3: (top) Reciprocal of the small eigenvalue of Lu (bottom) Label disagreements", "description": "This figure shows two plots. The top plot displays the reciprocal of the smallest eigenvalue of the matrix Lu against the label rate. The bottom plot shows the number of label disagreements against the label rate.  The plots illustrate how the smallest eigenvalue of Lu and the number of label disagreements change as the label rate varies. This is relevant to understanding the performance of the Laplace learning algorithm under different label rates. The figure supports the discussion on how the Laplace learning algorithm suffers from degeneracy at low label rates.", "section": "Additional Details and Experiments"}, {"figure_path": "hCOuip5Ona/figures/figures_15_1.jpg", "caption": "Figure 4: Predicted label distribution on MNIST at 1 label per class. Vanilla Laplace learning (orange) is degenerate. The mean-shift heuristic (green) imposes a constraint on the predictions corresponding to a balanced prior on the class distribution. Shifting the labels (blue) is insufficient to enforce the prior.", "description": "The figure shows the predicted label distributions of three different methods on the MNIST dataset with one label per class. Vanilla Laplace learning shows a highly unbalanced distribution, concentrated on one class. The mean-shift heuristic shows a much more balanced distribution across all classes.  Shifting the labels alone does not produce a balanced distribution.", "section": "C.1 MNIST and Fashion-MNIST"}, {"figure_path": "hCOuip5Ona/figures/figures_17_1.jpg", "caption": "Figure 5: (a) Random sample of misclassified images on the cut-boundary on MNIST. (b) misclassified images on the cut-boundary of FashionMnist.", "description": "This figure shows examples of misclassified images from the MNIST and Fashion-MNIST datasets.  These examples are specifically chosen from images located on the boundary between different partitions created by the CutSSL algorithm. The images in (a) are handwritten digits, and the images in (b) are images of clothing items.  The misclassifications likely occur because these images are ambiguous or lie on the decision boundary between classes, making them difficult for the algorithm to classify accurately.", "section": "Additional Details and Experiments"}, {"figure_path": "hCOuip5Ona/figures/figures_19_1.jpg", "caption": "Figure 1: Effect of perturbing L by S on minimizers of (10) on the simplex. Shade of level-curves denotes descent direction. Blue dots denote unique minimizers in the simplex. As the magnitude of the perturbation increases, the minimizers gravitate towards the extreme points of the simplex.", "description": "This figure visualizes how adding a perturbation matrix S to the Laplacian matrix L affects the minimizers of the objective function (10) over the probability simplex.  As the magnitude of S (controlled by the scalar parameter 's') increases, the initially unique minimizer moves towards the vertices (corners) of the simplex, representing the binary solutions that are desirable for the graph partitioning problem. The level curves illustrate the change in the objective function's value, and the color shading indicates the direction of descent.", "section": "Graph Partitioning for SSL"}, {"figure_path": "hCOuip5Ona/figures/figures_19_2.jpg", "caption": "Figure 1: Effect of perturbing L by S on minimizers of (10) on the simplex. Shade of level-curves denotes descent direction. Blue dots denote unique minimizers in the simplex. As the magnitude of the perturbation increases, the minimizers gravitate towards the extreme points of the simplex.", "description": "This figure shows how adding a perturbation matrix S to the Laplacian L affects the minimizers of the objective function (10) defined on the simplex. As the magnitude of S increases (controlled by parameter s), the minimizers move from the interior of the simplex to its vertices (extreme points). This illustrates the effect of the perturbation in guiding solutions towards binary values.", "section": "Graph Partitioning for SSL"}]