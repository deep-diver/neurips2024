[{"figure_path": "UGlDVc0GTU/tables/tables_3_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents a comparison of the zero-shot performance of the proposed LDuS framework against several baselines across different manipulation tasks in two environments: MetaWorld and Multi-stage MetaWorld.  The performance is evaluated under three conditions: without context, with language context, and with multi-modal context.  The table shows the success rate (SR) and context reward (CR) for each method, with the best performance highlighted in bold. The results demonstrate LDuS's superior zero-shot adaptability to various contexts.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_4_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents a comparison of the proposed LDuS method against several baseline methods for zero-shot policy adaptation in robotic manipulation tasks.  The results are shown for two different environments (MetaWorld and Multi-stage MetaWorld) and three different context types (no context, language context, multi-modal context).  The performance is evaluated using two metrics: Success Rate (SR) and Context Reward (CR), with the best performance for each setting highlighted in bold. The table also indicates the number of random seeds used for each experiment.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison between the proposed LDuS method and several baselines across different experimental settings. The baselines include LangDT, LISA, LCD, and Diffuser, each with and without guidance. The experiments are conducted on two different MetaWorld environments: the standard MetaWorld with 10 manipulation tasks and the multi-stage MetaWorld with 3 long-horizon tasks.  The results are shown for three context conditions: without context, language context, and multi-modal context.  The success rate (SR) and context reward (CR) are reported with 95% confidence intervals, based on multiple random seeds for each condition. The highest performance in each setting is highlighted in bold.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_7_1.jpg", "caption": "Table 2: Performance w.r.t various context types", "description": "This table presents the results of the experiments conducted to evaluate the performance of LDuS and the baselines across various context types. The context types include precise context, abstract context, and temporal context. For each context type, the table shows the average context reward (CR) and success rate (SR) for each method.  The results demonstrate the effectiveness of LDuS in adapting to diverse contexts, outperforming the baselines in terms of both CR and SR across all context types.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_7_2.jpg", "caption": "Table 3: Comparison with waypoint generation method", "description": "This table compares the performance of LDuS with Kinematic-LLM, a waypoint generation method, on MetaWorld and Multi-stage MetaWorld.  It shows that LDuS significantly outperforms Kinematic-LLM in terms of Context Reward (CR) and maintains a comparable success rate (SR) in MetaWorld, while demonstrating superior performance in both metrics on the more complex Multi-stage MetaWorld.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_8_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison between LDuS and several baselines across different manipulation tasks (MetaWorld and multi-stage MetaWorld). The performance is evaluated under three conditions: without context, with language context, and with multi-modal context. The metrics used are success rate (SR) and context reward (CR), both measured with 95% confidence intervals.  The table highlights the superior performance of LDuS in zero-shot adaptation.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_8_2.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2~5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison of the proposed LDuS framework against several baselines across different contexts (without context, language context, multi-modal context) and for two different benchmark environments (MetaWorld and multi-stage MetaWorld).  The performance metrics are Success Rate (SR) and Context Reward (CR), both reported with 95% confidence intervals and averaged across multiple random seeds for each condition.  The table highlights the superior performance of LDuS in most zero-shot settings.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_13_1.jpg", "caption": "Table 6: Hyperparameter settings for LangDT", "description": "This table shows the hyperparameter settings used for training the LangDT model.  It includes the total number of training timesteps, batch size, learning rate, embedding size, hidden size, number of attention heads, number of layers, and the planning horizon for both short (MetaWorld) and long (multi-stage MetaWorld) horizon tasks.", "section": "5.1 Experiment Settings"}, {"figure_path": "UGlDVc0GTU/tables/tables_14_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents a comparison of the zero-shot performance of the proposed LDuS framework against several baselines on two MetaWorld environments: the standard MetaWorld with 10 manipulation tasks and a multi-stage version with 3 long-horizon tasks. The performance is evaluated under three conditions: without context, language context, and multi-modal context.  The metrics used are Success Rate (SR) and Context Reward (CR), both calculated with 95% confidence intervals.  The best-performing method for each condition is highlighted in bold. The table showcases LDuS's superior performance across various contexts compared to the baseline models.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_14_2.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance results of the proposed LDuS method and several baselines across different contexts (without context, language context, multi-modal context) on two MetaWorld environments (MetaWorld and multi-stage MetaWorld).  The performance is evaluated using Success Rate (SR) and Context Rewards (CR), with confidence intervals provided.  The table highlights the superior performance of LDuS in zero-shot adaptation across various contexts.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_15_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison of LDuS against several baselines across different manipulation tasks (MetaWorld and Multi-stage MetaWorld).  It shows the success rate (SR) and context reward (CR) for each method under three conditions: without context, with language context, and with multi-modal context. The results highlight LDuS's superior performance in zero-shot adaptation to various contexts.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_16_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison of the proposed LDuS method against several baselines across different contexts (without context, language context, multi-modal context) on two MetaWorld environments (standard MetaWorld and multi-stage MetaWorld).  The performance is measured using success rate (SR) and context reward (CR), with confidence intervals reported.  The table highlights the superior performance of LDuS in zero-shot adaptation to various contexts.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_19_1.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the zero-shot performance comparison of the proposed LDuS method against several baselines across different manipulation tasks in two environments (MetaWorld and Multi-stage MetaWorld).  The performance is evaluated under three conditions: without context, with language context, and with multi-modal context.  The metrics used are Success Rate (SR) and Context Reward (CR), both reported with 95% confidence intervals. The best-performing method is highlighted in bold for each scenario.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_19_2.jpg", "caption": "Table 12: Performance without context in multi-stage MetaWorld: We abbreviate each goal by using initials of its words (e.g. \u201cClose Drawer\u201d is CD, and \u201cPush Button\u201d is PB)", "description": "This table presents the results of a zero-shot experiment conducted on a multi-stage MetaWorld environment.  The experiment evaluates the performance of several methods (LangDT, LISA, LCD, Diffuser, and LDuS) on three different long-horizon manipulation tasks without providing any contextual information.  Each method's success rate (SR) and context rewards (CR) are shown for each task. The goal names are abbreviated using their initials (e.g., CD for Close Drawer, PB for Push Button).", "section": "5.2 Main results"}, {"figure_path": "UGlDVc0GTU/tables/tables_19_3.jpg", "caption": "Table 1: Zero-shot performance: The baselines and LDuS are trained on 10 different manipulation goals for MetaWorld and 3 different long-horizon goals for multi-stage MetaWorld. For each manipulation goal, we use 2 ~ 5 different contexts. The success rate (SR) and context rewards (CR) are measured in 95% confidence interval. Each is evaluated with 5 random seeds for language contexts and 3 random seeds for multi-modal contexts. The highest performance is highlighted in bold.", "description": "This table presents the results of a zero-shot policy adaptation experiment comparing the performance of the proposed LDuS method against several baselines.  The experiment evaluates performance across different manipulation tasks in two MetaWorld environments: a standard version and a multi-stage version with longer horizon goals. Results are presented for three context conditions: without context, with language context, and with multimodal context.  Success rate (SR) and context reward (CR) are reported with 95% confidence intervals and the best performing method is highlighted in bold for each condition.", "section": "5 Experiments"}, {"figure_path": "UGlDVc0GTU/tables/tables_19_4.jpg", "caption": "Table 14: Zero-shot performance with language context in multi-stage MetaWorld", "description": "This table presents the results of a zero-shot policy adaptation experiment on multi-stage MetaWorld tasks.  It compares the performance of LDuS against several baselines (LCD + Guidance, Diffuser + Guidance) across two different language contexts (Context1 and Context2). The performance is measured using two metrics: Contextual Reward (CR) and Success Rate (SR). The table highlights the superior performance of LDuS in adapting to unseen contexts specified in language, demonstrating the effectiveness of the proposed LLM-based framework.", "section": "5.2 Main results"}, {"figure_path": "UGlDVc0GTU/tables/tables_20_1.jpg", "caption": "Table 15: Zero-shot performance with energy and spatial context in MetaWorld", "description": "This table presents the results of additional experiments evaluating LDuS and baseline methods under two different context types: energy constraints and spatial constraints.  The experiments were conducted on a single task within the MetaWorld environment. For the energy constraint, the agent aimed to minimize energy consumption by reducing acceleration and deceleration.  The spatial constraint involved maintaining the agent's position within specified boundaries. The table displays the Context Rewards (CR) and Success Rates (SR) for each method under both context types.", "section": "C.2 Performance on different context types"}]