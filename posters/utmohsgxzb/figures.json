[{"figure_path": "utMOhsgXzB/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of our two-step BEND-VLM method. In this example, the initial query embedding of doctor is more strongly associated with males, and the CCF distance is 0.10. After performing debiasing step 1, Orthogonalizing the Embedding, the embedding is modified to remove bias along the gender direction defined by \"male doctor\" and \"female doctor\". This still results in a CCF distance of 0.05. We then perform the second debiasing step, where the query embedding is again modified to be equidistant to the relevant male and female images. The final representation achieves the optimal distance of 0.00.", "description": "This figure illustrates the two-step BEND-VLM debiasing process.  It starts with an initial embedding that shows bias towards males for the term \"doctor\". Step 1 (Textual Debiasing) uses gender-augmented queries (\"male doctor\", \"female doctor\") to identify and remove bias along the gender dimension, reducing but not eliminating the bias. Step 2 (Distance Debiasing) further refines the embedding by ensuring it is equidistant to images of male and female doctors, effectively removing the remaining bias. The CCF distance metric quantifies the remaining bias at each step, demonstrating the effectiveness of the two-step approach in achieving fairness.", "section": "Methodology"}, {"figure_path": "utMOhsgXzB/figures/figures_5_1.jpg", "caption": "Figure 1: Overview of our two-step BEND-VLM method. In this example, the initial query embedding of doctor is more strongly associated with males, and the CCF distance is 0.10. After performing debiasing step 1, Orthogonalizing the Embedding, the embedding is modified to remove bias along the gender direction defined by \"male doctor\" and \"female doctor\". This still results in a CCF distance of 0.05. We then perform the second debiasing step, where the query embedding is again modified to be equidistant to the relevant male and female images. The final representation achieves the optimal distance of 0.00.", "description": "This figure illustrates the two-step BEND-VLM debiasing process.  It starts with an initial query embedding (e.g., for the word \"doctor\") that shows a bias towards males (higher CCF distance). The first step uses textual debiasing to orthogonalize the embedding, reducing the bias but not eliminating it. The second step employs distance debiasing using a reference dataset to ensure the final embedding is equidistant from relevant male and female examples, thus achieving an optimal, unbiased representation.", "section": "3 Methodology"}, {"figure_path": "utMOhsgXzB/figures/figures_6_1.jpg", "caption": "Figure 2: Our approach increases accuracy while decreasing bias.", "description": "This figure shows the performance of BEND-VLM compared to other debiasing methods on two different versions of the CLIP model (CLIP-ViT-Base-Patch16 and CLIP-ViT-Large-Patch14).  The x-axis represents the average MaxSkew, a metric indicating the level of bias, with lower values signifying less bias. The y-axis shows the Worst Group Zero-Shot AUC ROC, a measure of classification accuracy for the group most disadvantaged by bias.  The plot demonstrates that BEND-VLM achieves higher accuracy while exhibiting lower bias than other methods.  Each point represents a different debiasing method, with BEND-VLM positioned in the top-left quadrant indicating superior performance (high accuracy, low bias).", "section": "4 Experiments"}]