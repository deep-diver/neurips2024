[{"type": "text", "text": "On Weak Regret Analysis for Dueling Bandits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "El Mehdi Saad\u2217 KAUST mehdi.saad@kaust.edu.sa ", "page_idx": 0}, {"type": "text", "text": "Alexandra Carpentier Institut f\u00fcr Mathematik Universit\u00e4t Potsdam carpentier@uni-potsdam.de ", "page_idx": 0}, {"type": "text", "text": "Tom\u00e1\u0161 Koc\u00e1k   \nInstitut f\u00fcr Mathematik   \nUniversit\u00e4t Potsdam   \nkocak@uni-potsdam.de ", "page_idx": 0}, {"type": "text", "text": "Nicolas Verzelen INRAE, MISTEA, Univ. Montpellier nicolas.verzelen@inrae.fr ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the problem of $K$ -armed dueling bandits in the stochastic setting, under the sole assumption of the existence of a Condorcet winner. We study the objective of weak regret minimization, where the learner doesn\u2019t incur any loss if one of the selected arms is a Condorcet winner\u2014unlike strong regret minimization, where the learner has to select the Condorcet winner twice to incur no loss. This study is particularly motivated by practical scenarios such as content recommendation and online advertising, where frequently only one optimal choice out of the two presented options is necessary to achieve user satisfaction or engagement. This necessitates the development of strategies with more exploration. While existing literature introduces strategies for weak regret with constant bounds (that do not depend on the time horizon), the optimality of these strategies remains an unresolved question. This problem turns out to be really challenging as the optimal regret should heavily depend on the full structure of the dueling problem at hand, and in particular on whether the Condorcet winner has a large minimal optimality gap with the other arms. Our contribution is threefold: first, when said optimality gap is not negligible compared to other properties of the gap matrix, we characterize the optimal budget as a function of $K$ and the optimality gap. Second, we propose a new strategy called WR-TINF that achieves this optimal regret and improves over the state-of-the-art both in $K$ and the optimality gap. When the optimality gap is negligible, we propose another algorithm that outperforms our first algorithm, highlighting the subtlety of this dueling bandit problem. Finally, we provide numerical simulations to assess our theoretical findings. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider an instance of the problem of sequential and active learning from comparisons - namely dueling bandits. It can be modeled as a sequential game where, at each time, a learner presents to a user a pair of two items and collects feedback, which is a noisy indication of the user\u2019s preference between the two items. If neither of the presented items aligns with the user\u2019s top choice, the learner incurs a loss. Preference-based learning has gained importance recently as it reflects human decisionmaking processes, which often rely on relative rather than absolute evaluations. This approach is notably effective in systems that involve human interaction, where feedback is provided in a qualitative form [7]. In the dueling bandit setting, initially presented by [19], the compared items are called \u201carms\u201d and there are $K$ of them. This setting is structured as an ongoing sequential game with time horizon $T$ , where in each round $t\\leq T$ , the learner selects two arms (items) indexed by $i,j\\in[K]$ , and receives the result of a duel between these arms as feedback. The result of each duel is encoded by 1 if the first arm - in our case arm $i$ - beats the second one - in our case arm $j$ - and 0 otherwise. This result follows a Bernoulli distribution with unknown parameter $q_{i,j}$ . Specifically, this paper focuses on the stochastic scenario where the parameters governing the duels are assumed to be constant throughout the game, albeit unknown to the learner. The literature on the stochastic dueling bandits is very rich and contains various settings that differ from our paper either in optimal arm characterization or the definition of rewards. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In contrast to the classic multi-armed bandit problem, defining the optimal arm in dueling bandits is not straightforward. This led to the introduction of various definitions of winners within the literature as detailed in the surveys [2, 16, 17]. Our study focuses on situations where there is an arm $k^{*}\\in[K]$ that, on average, defeats all other arms: formally, $q_{k^{*},j}>1/2$ for any $j\\in[K]\\setminus\\{k^{*}\\}$ . This arm is termed the Condorcet winner while we refer to it as optimal in the rest of the paper. In the context of dueling bandits, particularly the cumulative regret minimization problem, most of prior works either made the assumption of the existence of a Condorcet winner [24, 23, 10, 8, 4, 14, 15] or the stronger assumption of the exitence of a total order between arms [18, 20, 4]. ", "page_idx": 1}, {"type": "text", "text": "Once the concept of the optimal arm is established, the next step is to define the objective. Rather than identifying the best arm, our goal is to minimize the cumulative loss. To this end, we must determine the loss incurred each round based on the two arms selected by the learner. The dueling bandit literature distinguishes between two primary types of losses: strong loss and weak loss, as described by [18]. With strong loss, the learner must select the Condorcet winner twice to avoid any loss (noting that the feedback in this case is equivalent to a fair coin flip). In contrast, weak loss requires only one of the selected arms to be the Condorcet winner. Formal definitions of weak and strong regrets are provided in Section 2. In many practical scenarios, such as recommendation systems and online advertising [6, 3], minimizing weak regret aligns more closely with the learner\u2019s objectives than strong regret minimization. For example, consider a situation where the learner operates as a service provider, presenting two options to a client who then chooses their preferred option. In this framework, the learner should incur a loss only if neither option matches the client\u2019s preference, encouraging exploration and maximizing information gain. While previous research in dueling bandits has primarily focused on minimizing strong regret, developing optimal strategies for minimizing weak regret remains an unresolved issue despite prior works [4, 12], as highlighted in the survey [2]. Further details on the technical distinctions between these two objectives will be discussed in the next sections. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we focus on minimising the weak regret. We provide a lower bound for this problem in a specific regime where the Condorcet winner beats largely the other arms. We provide an algorithm that matches it. Nevertheless, it is not optimal in all regimes, and we highlight this by providing another algorithm that performs better in some interesting regimes. ", "page_idx": 1}, {"type": "text", "text": "2 Problem setting ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We consider $K$ arms. Let $Q=(q_{i,j})_{1\\leq i,j\\leq K}\\in[0,1]^{K\\times K}$ be the matrix of preference probabilities where the probability of arm $i$ beating arm $j$ in a duel corresponds to $q_{i,j}$ . We assume that $q_{j,i}=$ $1-q_{i,j}$ and $q_{i,i}=1/2$ for all $i,j\\in[K]$ . Define $\\Delta_{i,j}:=q_{i,j}-\\frac{1}{2}$ . Notably, the sign of $\\Delta_{i,j}$ indicates the relative preference between arms $i$ and $j$ (specifically, $i$ is preferred over $j$ if $\\Delta_{i,j}\\,>\\,0_{,}^{)}$ ). The quantity $\\Delta_{i,j}$ characterizes the hardness of distinguishing which of the arms $(i,j)$ is preferred to the other. We denote $\\pmb{\\Delta}:=(\\Delta_{i,j})$ the gap matrix. The only assumption made in this paper is regarding the existence of a Condorcet winner, which we denote $k^{*}$ for the remainder of this paper: ", "page_idx": 1}, {"type": "text", "text": "Assumption 2.1. Existence of a Condorcet winner: There exists an arm $k^{*}\\in[K]$ such that: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\forall i\\in[K]\\setminus\\{k^{*}\\}:q_{k^{*},i}>1/2.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "We consider that at each time $t\\,=\\,1,2,\\dots$ , the learner chooses two arms $\\left(I_{t},J_{t}\\right)$ based on past information and receives the output of a duel between the chosen arms. More formally, the output is a sample from a Bernoulli distribution with parameter $q_{I_{t},J_{t}}$ , independent of everything else after conditioning on $(I_{t},J_{t})$ . We consider that after each round $t$ the learner incurs a loss given by: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\ell_{t}^{(w)}:=\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}},\\Delta_{k^{*},J_{t}}\\},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "which we term the weak instantaneous loss, following [18]. Another concept of instantaneous loss that is often considered in the literature is the strong instantaneous loss [18, 1, 24], where at round $t$ the learner incurs the loss $\\ell_{t}^{(s)}\\,:=\\,(\\Delta_{k^{\\ast},I_{t}}+\\Delta_{k^{\\ast},J_{t}})/2$ . Note that when it comes to the weak instantaneous loss, in contrast to the strong instantaneous loss, the learner does not incur any loss if at least one of the two chosen arms is the Condorcet winner, $I_{t}=k^{*}$ or $J_{t}=k^{*}$ , while for the strong instantaneous loss, both arms need to be the Condorcet winner in order for the learner to not incur a loss. We finally define the weak expected cumulative regret up to time $T$ by for the weak instantaneous loss by R(Tw):= $\\begin{array}{r}{R_{T}^{(w)}:=\\sum_{t=1}^{T}\\mathbb{E}[\\ell_{t}^{(w)}]}\\end{array}$ , which we term weak regret. Similarly, we define the strong regret as $\\begin{array}{r}{R_{T}^{(s)}:=\\sum_{t=1}^{T}\\mathbb{E}[\\ell_{t}^{(s)}]}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "3 Literature review and our contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "When it comes to the stochastic dueling bandit literature, much of the prior work has been devoted to the goal of minimizing the strong regret, under the assumption of a total order between the arms [19, 18] or only under the assumption of the existence of a Condorcet winner [24, 23, 10, 8, 12]. We detail nevertheless those results here as, since the strong regret upper bounds the weak regret, all algorithms and upper bounds that are available for the strong regret also hold for the weak regret. In [8], an instance-dependent lower bound for strong regret was established: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\to\\infty}\\operatorname*{inf}_{\\log(T)}\\frac{\\mathbb{E}\\left[R_{T}^{(s)}\\right]}{\\log(T)}\\ge\\sum_{k\\ne k^{*}}\\operatorname*{min}_{i\\in\\mathcal{O}_{k}}\\frac{\\Delta_{k^{*},k}+\\Delta_{k^{*},i}}{2\\Delta_{i,k}^{2}},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{O}_{k}=\\{i\\in[K]\\mid q_{i,k}>1/2\\}$ . This work also introduces an algorithm that asymptotically matches this lower bound as $T\\,\\rightarrow\\,+\\infty$ . However, in finite-horizon, their regret bound has a quadratic dependence on the number of arms $K$ . Deriving bounds that scale linearly with $K$ has been the subject of several works [23, 10], In particular, [14] devised a reduction to a standard (but adversarial) multi-armed bandits problem. They obtained guarantees on the strong regret which are of the order $\\begin{array}{r}{\\sum_{k\\neq k^{*}}\\log(T)/\\Delta_{k^{*},k}.}\\end{array}$ . This regret bound turns out to match (1) in scenarios where the Condorcet winner is also the arm that is best for eliminating all other sub-optimal arms, namely where $\\Delta_{k^{*},k}=\\operatorname*{max}_{i}\\Delta_{i,k}$ . In more general cases, the last upper bound of [14] does not match the lower bound given in (1). ", "page_idx": 2}, {"type": "text", "text": "Weak regret itself was introduced in [18] to model in a more refined way some recommender systems applications. As mentioned, it is upper bounded by the strong regret so that all described algorithms and associated regret upper bounds would also hold for the weak regret. However, a distinction was made in [4] regarding the fundamental nature of these two problems. While the problem-dependent optimal order of the strong regret scales as $\\log T$ (see above) - which is aligned with classical results in stochastic bandits - there exist some algorithms whose problem-dependent weak regret is upper bounded by a quantity that does not depend on $T$ - which is in sharp contrast with classical results on stochastic bandits. Specifically, [4] introduced an algorithm called WS-W, which, under the sole assumption of the existence of a Condorcet winner, achieves an upper bound on weak regret of the order $K^{2}/\\operatorname*{min}_{i\\neq j}\\Delta_{i,j}^{2}$ . More recently, in [12], the Beat The Winner (BTW) algorithm was introduced. BTW adopts a round-based approach where the best arm so far keeps being challenged through batches of duels by candidate arms. Assuming only the presence of a Condorcet winner, this algorithm achieves an upper bound on weak regret of the order $K^{2}+K/\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i}^{4}$ . Finally, under the additional and arguably the strong assumption of the existence of a total order between arms, the upper bound can be proven to be of order $\\begin{array}{r}{(K\\log K)/\\operatorname*{min}_{i\\neq j}|\\Delta_{i,j}|^{5}}\\end{array}$ . In summary, the dependency on the optimal regret on both $K$ and on the matrix $\\Delta$ still remains largely unknown. ", "page_idx": 2}, {"type": "text", "text": "From a technical standpoint, developing optimal strategies in the weak regret framework underlies different challenges than the ones for the strong regret. This complexity arises because losses in the strong regret framework are linear in the problem parameters (the gaps matrix entries $(\\Delta_{i,j})_{1\\leq i,j\\leq K})$ : $\\ell_{t}^{(s)}=(\\Delta_{k^{*},I_{t}}+\\Delta_{k^{*},J_{t}})/2$ , whereas in weak regret, the loss is determined as the minimum gap with the client\u2019s preference: \u2113t(w) $\\ell_{t}^{(w)}=\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}},\\Delta_{k^{*},J_{t}}\\}$ , which breaks linearity. As a result, classical reduction methods as the one used in [1, 14, 15] are not directly applicable for weak losses. ", "page_idx": 2}, {"type": "text", "text": "3.2 Main contributions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this paper, we address the following fundamental question: ", "page_idx": 3}, {"type": "text", "text": "(i) What is the best possible weak regret one can achieve in terms of $K$ and the gaps $(\\Delta_{k^{*},i})_{i\\neq k^{*}}$ to the Condorcet winner?   \n(ii) Beyond that, is it possible to improve the regret by leveraging over the unknown entries of the matrix $\\Delta?$ As a simple toy example, assume that the gaps $\\Delta_{k^{*},k}$ are small and that, some gaps $(\\Delta_{i,j})$ for $i,j\\neq k^{*}$ are much higher. In that regime, it is perhaps more beneficial to explore the $\\mathcal{O}(K^{2})$ duels between all arms to better discard sub-optimal arms than simply to directly look for the Condorcet winner. This informal argument suggests the optimal guarantees depend in an intricate way on the number of arms $K$ and the gaps $(\\Delta_{i,j})$ and that there is a complex trade-off between directly aiming for the Condorcet winner and further exploration for better elimination. ", "page_idx": 3}, {"type": "text", "text": "To address the first question, we provide a lower bound on the weak regret, which, to the best of our knowledge, is the first of its kind for this problem. We demonstrate that in certain cases, where in particular the gaps between the Condorcet winner and the sub-optimal arms are larger than the gaps between sub-optimal arms, the bound $K/\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i}$ is not improvable (see Section 5). ", "page_idx": 3}, {"type": "text", "text": "We introduce and analyze two new procedures. First, we provide in Section 4.1 an algorithm WR-TINF (Weak Regret-Tsallis INF) whose weak regret is bounded by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\sqrt{\\frac{K}{\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i}}}\\sqrt{\\sum_{i\\neq k^{*}}\\frac{1}{\\Delta_{k^{*},i}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This can be upper-bounded by $K/(\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i})$ . This improves over the state-of-the art [4, 12] (where bounds are respectively of the order of $K^{2}/\\operatorname*{min}_{i\\neq j}\\Delta_{i,j}^{2}$ and $K^{2}+K/\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i}^{4})$ both in the dependency with respect to $K$ and the gaps. Also, we do not require the strong stochastic transitivity assumption, required in $[12]^{2}$ . Conversely, the bound $K/\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*},i}$ turns out to be impossible to improve in general \u2013see Section 5. ", "page_idx": 3}, {"type": "text", "text": "Second, we introduce in Section 4.2 the algorithm WR-EXP3-IX (Weak Regret EXP3-IX), which, from an heuristic viewpoint aims at eliminating sub-optimal arms by looking at duels between sub-optimal arms. For any $\\Delta$ , its weak regret is at most of the order of ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\sum_{i\\neq k^{*}}\\frac{K\\log(K/\\Delta_{*})\\Delta_{k^{*},i}}{\\Delta_{j^{*}(i),i}^{2}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $j^{*}(i)\\in\\arg\\operatorname*{max}_{j}\\Delta_{j,i}$ and $\\Delta_{*}=\\mathrm{min}_{k\\neq k^{*}}\\,\\Delta_{k^{*},k}$ . In the case, where the gaps $\\Delta_{j^{*}(i),i}$ are larger (up to log-terms) than $\\Delta_{k^{*},i}\\sqrt{K}$ , the regret guarantee (3) for WR-EXP3-IX becomes smaller than (2) for WR-TINF. Up to our knowledge, WR-EXP3-IX is the first algorithm in weak regret minimization that builds upon the complete structure of the gaps matrix $\\Delta$ to lower the regret. ", "page_idx": 3}, {"type": "text", "text": "To further discuss the difference between the performances of both procedures, let us consider a toy model where, for some positive constants, $\\Delta_{\\mathrm{cw}}$ and $\\Delta_{\\mathrm{sub}}$ , we have, for any $i\\neq k^{*}$ , $\\Delta_{k^{*},i}=\\Delta_{\\mathrm{cw}}$ , that is the gap between the Condorcet winner and the sub-optimal arms. Besides, for any $i\\neq k^{*}$ , the\u221are exists $j^{*}(i)$ such that $\\Delta_{j^{*}(i),i}=\\Delta_{\\mathrm{sub}}$ . We distinguish two main regimes: (a) If $\\Delta_{\\mathrm{cw}}/\\Delta_{\\mathrm{sub}}\\ge$ $1/\\sqrt{K}$ , then the \u221aweak regret of WR-TINF is the better one and is of the order of $K/\\Delta_{c w}$ . (b) If $\\Delta_{\\mathrm{cw}}/\\Delta_{\\mathrm{sub}}\\leq1/\\sqrt{K}$ , then a transition occurs. To show that an arm $k$ is not the Condorcet winner, then it now becomes beneficial to identify arms that provide the most evidence for the suboptimality of $k$ . Here, WR-EXP3-IX achieves the better guarantee which is (up to log terms) of the order of $K^{2}(\\Delta_{c w}/\\Delta_{\\mathrm{sub}}^{2})$ . ", "page_idx": 3}, {"type": "text", "text": "The presented algorithms use different techniques: we develop WR-TINF using an adaptation of the standard reduction technique (discussed in Section 4.1). We extend the idea of using a best-of-both worlds procedure as a base algorithm to sample each of the two arms $I_{t}$ and $J_{t}$ . However, since only one of the sampled arms should be optimal, we modify the sampling distribution prescribed by the base algorithm to induce more exploration. The second procedure, WR-EXP3-IX, uses a different approach. Given the value of the left arm $I_{t}$ (selected in a round-robin manner), we use the EXP3-IX algorithm [11] to select the right arm $J_{t}$ . Then after a fixed number of rounds, the choice of $J_{t}$ (given the value of $I_{t}$ ) concentrates around the arm with highest probability of defeating it. We leverage the fact that when $I_{t}$ is the Condorcet winner, the gaps are positive, while for sub-optimal arms the minimal gap is negative. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "4 Upper Bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "This section presents two algorithms with guarantees on weak regret. Recall that we present two strategies since we identified two regimes as discussed in Section 3.2. Each of the algorithms we present is optimal in one of the regimes and none of them require prior knowledge on the problem parameters. ", "page_idx": 4}, {"type": "text", "text": "The first algorithm, WR-TINF, is built upon an adaptation of the reduction technique to a standard multi-armed bandit problem. Its upper bounds depend on the gaps between sub-optimal arms and the Condorcet winner $(\\Delta_{k^{*},k})_{k\\in[K]}$ . As demonstrated in the results of Section 5, this algorithm is optimal for some regimes.The second procedure, WR-EXP3-IX, aims for the task of identifying, for each arm, the arm that can eliminate it most rapidly (i.e., the arm with the largest gap). While this strategy results in a quadratic dependence on $K$ , we argue that it outperforms WR-TINF for some instances. ", "page_idx": 4}, {"type": "text", "text": "4.1 Algorithm 1: Weak Regret Tsallis-INF ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We adopt a previously explored approach [1, 15, 14], where the dueling bandit problem is converted into two separate multi-armed bandit problems - one for each arm pulled. This reduction was originally applied in the context of strong regret. However, adapting this approach to weak regret requires a more nuanced approach. ", "page_idx": 4}, {"type": "text", "text": "The idea of reducing a dueling bandit problem to a standard one was first introduced in [1] where it was termed Sparring in the context of minimizing strong regret. The high-level idea of this technique is to view the problem of selecting the the arm pair $\\left(I_{t},J_{t}\\right)$ as two individual multi-armed bandit (MAB) problems. The choice of $I_{t}$ (resp. $J_{t}$ ) can be performed by the first (resp. second) player, following which they incur a loss denoted $\\ell_{-1,t}(I_{t}):=X_{t}(I_{t},J_{t})$ (resp. $\\ell_{+1,t}(J_{t}):=1\\!-X_{t}(I_{t},J_{t}))$ , where $\\bar{X_{t}}(I_{t},J_{t})\\sim\\mathrm{Ber}(q_{I_{t},J_{t}})$ . Here the subscript $-1$ (resp. $+1$ ) refers to the first (resp. second) player. It is easy to show that the regret of each player $R_{\\pm1,T}$ satisfies the following identity, where $R_{T}^{(s)}$ is the strong regret of the dueling bandits problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}^{(s)}]=\\frac{1}{2}\\mathbb{E}[R_{-1,T}+R_{+1,T}].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The last identity reveals that the dueling bandits problem can be addressed using a \u2018black-box\u2019 strategy, where each player is allowed to use a standard Multi-Armed Bandit (MAB) algorithm. In [1], the authors selected the EXP3 algorithm, which provides guarantees suitable for worst-case scenarios. It\u2019s important to note that achieving problem-dependent bounds is not possible when the players use stochastic MAB procedures such as Upper Confidence Bounds algorithms, as the losses experienced by the first player, for example, are not stationary. In a later work, [14] implemented a best-of-both-worlds MAB algorithm, specifically the online mirror descent with the Tsallis-INF regularizer [22]. This approach is effective because, from the perspective of the first player, the loss distribution, although variable, is not entirely arbitrary. This is due to the second player\u2019s strategy of minimizing their own regret, which involves concentrating on sampling distributions that approximate those associated with the optimal choice, corresponding to the Condorcet winner. ", "page_idx": 4}, {"type": "text", "text": "Adopting the reduction above to solve the weak regret dueling bandit problem seems however insufficient due to several reasons. First, Equation (4) shows that minimizing the strong regret, and minimizing the regrets of individual players is equivalent. Second, the weak regret can be significantly smaller than the strong regret. This is because selecting the Condorcet winner just once is sufficient to suffer zero instantaneous weak regret while leaving the second arm free to explore and gain information about the problem. This is not the case in the strong regret minimization where both selected arms have to be Condorcet winners to incur zero instantaneous strong regret. This suggests that the algorithms that are optimal for strong regret cannot be expected to be optimal for weak regret. ", "page_idx": 4}, {"type": "text", "text": "For the task of minimizing weak regret, we follow the intuition presented in [14], which involves using a best-of-both-worlds procedure consisting of online mirror descent with the Tsallis-INF regularizer. However, as previously argued, minimizing weak regret necessitates increased exploration, requiring an adjustment to the sampling scheme, denoted as $p_{t}=(p_{t,i})_{1\\leq i\\leq K}$ , suggested by these strategies. Our algorithm first performs an internal step where two arms, $I_{t}^{\\overline{{\\prime}}}$ and $J_{t}^{\\prime}$ , are sampled independently from the distribution $\\scriptstyle\\mathbf{\\delta}p_{t}$ over $[K]$ , without playing them. We consider two cases: If $I_{t}^{\\prime}=J_{t}^{\\prime}$ , we infer that $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ lacks sufficient exploration. In this case, we use the left arm $I_{t}$ for exploitation by sampling it from $\\scriptstyle\\mathbf{\\delta}p_{t}$ , and the right arm $J_{t}$ for exploration. This approach reduces to a decoupled exploration-exploitation problem in standard multi-armed bandits, as studied in [13]. The authors in [13] developed a strategy where exploitation is carried out using $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ , while exploration follows a distribution $\\pmb{r}_{t}$ with $r_{t,i}\\propto p_{t,i}^{2/3}$ . They further demonstrated that this strategy, using Tsallis entropy regularizers with a power of $2/3$ , provides instance-specific bounds independent of the time horizon $T$ . In the second case, if the internal step results in $I_{t}^{\\prime}\\bar{\\neq}\\;J_{t}^{\\prime}$ , we consider that $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ adequately encourages exploration, and both $I_{t}$ and $J_{t}$ are sampled from $\\scriptstyle{p_{t}}$ . In summary, given that $I_{t}^{\\prime}$ and $J_{t}^{\\prime}$ are sampled from $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ , we employ the following strategy: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left\\{\\mathrm{If}~I_{t}^{\\prime}\\neq J_{t}^{\\prime}:~~I_{t}\\sim p_{t}\\;\\;\\mathrm{and}\\;\\;J_{t}\\sim p_{t}\\,\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\pmb{r}_{t}=(r_{t,k})_{k}$ is a distribution over the set $[K]$ defined as follows: for each $k\\in[K]$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nr_{t,k}:=\\frac{p_{t,k}^{2/3}}{\\sum_{i=1}^{K}p_{t,i}^{2/3}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Observe that arms with small probability $p_{t,k}$ , have a higher chance of being sampled under $\\pmb{r}_{t}$ Hence, the distribution $\\pmb{r}_{t}$ encourages more exploration, which will be beneficial for the weak regret. Finally the losses fed to the online mirror descent procedure are estimated using the importance weight estimators: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\ell}_{t}(k):=\\frac{\\mathbb{1}\\left(J_{t}=k\\right)X_{t}(k,I_{t})}{q_{t,k}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where, $q_{t,k}=p_{t,k}$ if $I_{t}^{\\prime}\\neq J_{t}^{\\prime}$ and $q_{t,k}=r_{t,k}$ if $I_{t}^{\\prime}=J_{t}^{\\prime}$ . We dedicate Section B in the appendix to develop guarantees on the resulting modified online mirror descent with Tsallis regularizer using the sampling scheme described above. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 WR-TINF ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Input: $\\alpha$ , Learning rates $(\\eta_{t})$   \ninit: $\\hat{L}_{0}=0$ .   \nfor $t=1,\\ldots$ do compute: $p_{t}=\\underset{p\\in S^{K-1}}{\\arg\\operatorname*{min}}\\left\\{\\langle p,\\hat{L}_{t-1}\\rangle-\\frac{1}{\\eta_{t}}\\sum_{i=1}^{K}\\frac{p_{i}^{\\alpha}-\\alpha p_{i}}{\\alpha(1-\\alpha)}\\right\\}$ (8) where $S^{K-1}$ is the $K$ -dimensional simplex Sample $I_{t}^{\\prime}$ and $J_{t}^{\\prime}$ independently following $\\scriptstyle{p_{t}}$ if $I_{t}^{\\prime}=J_{t}^{\\prime}$ then Sample $I_{t}$ following $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ and $J_{t}$ following $\\pmb{r}_{t}$ in (6). else Sample $I_{t}$ and $J_{t}$ independently following $\\textstyle p_{t}$ end if Play $\\left(I_{t},J_{t}\\right)$ , for each $k\\in[K]$ compute $\\hat{\\ell}_{t}(k)$ using (7) and update: $\\hat{L}_{t}(k)=\\hat{L}_{t-1}(k)+\\hat{\\ell}_{t}(k)$   \nend for ", "page_idx": 5}, {"type": "text", "text": "Remark 4.1. The sampling method used in WR-TINF may occasionally result in selecting the same arm twice $(I_{t}=J_{t},$ ), which is not ideal for weak regret minimization. However, WR-TINF\u2019s design ensures that the probability of this event is small enough to maintain the presented guarantees, which are optimal in scenarios that we describe. While we could modify the algorithm to prevent entirely that $I_{t}=J_{t}$ , such a modification would not enhance our theoretical guarantees significantly. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.2. Consider Algorithm $^{\\,l}$ with $\\alpha=2/3$ and $\\eta_{t}=2K^{-1/6}/\\sqrt{t}$ . For any $T\\geq1$ , the weak regret satisfies: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T}^{(w)}\\right]\\leq c\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\sum_{k\\neq k^{*}}\\frac{1}{\\Delta_{k^{*},k}}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where c is a numerical constant and $\\Delta_{*}=\\mathrm{min}_{k\\neq k^{*}}\\,\\Delta_{k^{*},k}$ . ", "page_idx": 6}, {"type": "text", "text": "We obtain an upper-bound on weak regret of the order of $\\begin{array}{r}{\\tilde{O}(\\sqrt{K/\\Delta_{*}}\\sqrt{\\sum_{k\\neq k^{*}}{1/\\Delta_{k^{*},k}}})}\\end{array}$ . In the setting where all the gaps for the Condorcet winner are constant, the upper bound above translates to $\\mathcal{O}(K\\bar{/}\\Delta_{\\mathrm{cw}})$ . The last optimality result is shown in Theorem 5.1. ", "page_idx": 6}, {"type": "text", "text": "4.2 Algorithm 2: Weak Regret-EXP3-IX ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This algorithm uses the Implicit Exploration strategy (EXP3-IX) [11], which is adapted specifically for the dueling bandits problem. At its core, the algorithm selects one arm (left arm $I_{t}$ ) for exploitation and another (right arm $J_{t}$ ) for exploration. Given $I_{t}$ , $J_{t}$ is selected following the EXP3-IX procedure. We chose the EXP3-IX algorithm (restated in Section D.2 of the Appendix), particularly the version without a fixed horizon for technical reasons, namely its bounds on cumulative loss that hold with high probability. To clarify the notation used: in each round, we observe the result of the duel between $I_{t}$ and $J_{t}$ , denoted by $X_{t}\\dot{(I_{t},J_{t})}$ . The variable $X_{t}(i,j)$ represents the duel outcome between arm $i$ and arm $j$ in round $t$ . ", "page_idx": 6}, {"type": "text", "text": "The algorithm operates across multiple stages, where each stage $n\\geq1$ is defined by a threshold value ${\\bar{B}}=2^{n-1}$ , updated through a doubling technique. At every stage, given $B$ , we consistently select the left arm as $I_{t}\\;=\\;i$ , and consider a standard Multi-Armed Bandit problem where the choices are the duels between arm $i$ and the other arms in $[K]\\setminus i$ . Specifically, these choices relate to the variables $\\begin{array}{r}{X_{t}(i,j)-\\frac{1}{2}:j\\in[K]\\setminus i}\\end{array}$ . Recall that $\\begin{array}{r}{\\mathbb{E}\\left[X_{t}(i,j)-\\frac{1}{2}\\right]\\,=\\,\\Delta_{i,j}}\\end{array}$ , and the optimal arm, which minimizes cumulative loss, is $j^{*}(i)=\\arg\\operatorname*{min}_{j\\in[K]\\backslash i}\\Delta_{i,j}$ . The cumulative loss after executing EXP3-IX for this specified problem over $u$ rounds is denoted by $S(i,n,u)$ . ", "page_idx": 6}, {"type": "equation", "text": "$$\nS(i,n,u):=\\sum_{s=\\tau+1}^{u+\\tau}\\left(X_{s}(i,J_{s})-\\frac{1}{2}\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\tau$ represents the round at which th\u221ae procedure starts. We continue the procedure until the value of $S(i,n,u)$ reaches the threshold $-B\\sqrt{u}$ . When this threshold is met, we transition to the next arm, $i+1$ , and address the duels involving this new arm. A stage is completed once all arms have met this stopping criterion, allowing the algorithm to advance to the next stage, $n+1$ . ", "page_idx": 6}, {"type": "text", "text": "The underlying rationale of the algorithm is as follows: consider stage $n$ , by design of the algorithm, if $i$ is a sub-optimal arm, then after a constant number of rounds, the process $S(i,n,u)$ mimics a random walk characterized by a \u221anegative drift of $\\Delta_{i,j^{*}(i)}\\,<\\,0$ . We demonstrate that $S(i,n,u)$ typically reaches the threshold $-B\\sqrt{u}$ when $u$ is approximately of the order $\\operatorname*{max}\\{K,B\\}/\\Delta_{j^{*}(i),i}^{2}$ In contrast, the process $S(k^{*},n,u)$ , which is linked to the Condorcet winner, has\u221a a positive drift. We show that the probability of the last process never meeting the threshold $-B\\sqrt{u}$ for some $u\\geq1$ is less than $\\operatorname*{min}\\{1,\\exp(-B^{2})\\log(1/\\Delta_{*})\\}$ , where $\\Delta_{*}=\\mathrm{min}_{k\\neq k^{*}}\\,\\Delta_{k^{*},k}$ . Consequently, there is a high probability that, at some stage, the algorithm will be trapped in a loop where the left arm is the Condorcet winner leading to zero regret when considering weak regret. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.3. Under the assumption of the existence of a Condorcet winner, the weak regret of Algorithm 2 satisfies: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T}^{(w)}\\right]\\leq c\\log(K/\\Delta_{*})\\sum_{k\\neq k^{*}}\\frac{K\\Delta_{k^{*},k}}{\\Delta_{j^{*}(k),k}^{2}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where for each $k\\;\\;\\neq\\;\\;k^{*}\\colon\\;\\;j^{*}(k)\\;\\;\\in\\;\\;\\arg\\operatorname*{max}_{j}\\Delta_{j,k},$ , $\\begin{array}{r c l}{{\\Delta_{*}}}&{{=}}&{{\\displaystyle\\operatorname*{min}_{k\\neq k^{*}}\\Delta_{k^{*},k}}}\\end{array}$ and $\\begin{array}{r l}{c}&{{}=}\\end{array}$ $c^{\\prime}\\operatorname*{max}\\{1,\\log\\log\\log(K\\vee16)\\}$ with $c^{\\prime}$ being an absolute constant. ", "page_idx": 6}, {"type": "text", "text": "The complete proof is presented in Section D of the supplementary material. ", "page_idx": 6}, {"type": "text", "text": "Comparison with WR-TINF: Intuitively, WR-EXP3-IX is designed to outperform WR-TINF when the gaps between sub-optimal arms are more important than the gaps with the Condorcet winner. In ", "page_idx": 6}, {"type": "text", "text": "Initialization: $B\\gets1$ and for all $i$ : $n_{i}\\leftarrow0$ , $S(i)\\gets0$ .   \nfor $t=1,,...$ . do for $i=1,\\ldots,K$ do while $S(i)>-B{\\sqrt{n_{i}}}$ do Run EXP3-IX algorithm on the problem with variables $\\{X(i,k)-\\frac{1}{2}:k\\in[K]\\setminus\\{i\\}\\}$ , after each round, update the cumulative loss $S(i)$ and the number of rounds $n_{i}$ . end while Re-initialize: $S(i)\\gets0$ , $n_{i}\\leftarrow0$ . end for $B\\leftarrow2B$ .   \nend for ", "page_idx": 7}, {"type": "text", "text": "this case, as argued in Section 3.2, the algorithm should explore the $K^{2}$ duels to detect sub-optimal arms. More rigorously, consider an example where the gaps satisfy: For all $i\\neq k^{*}\\colon\\Delta_{k^{*},i}=\\Delta_{\\mathrm{cw}}$ and $\\mathrm{max}_{j\\neq k^{*}}\\,\\Delta_{j,i}=\\Delta_{\\mathrm{sub}}$ , where $\\Delta_{\\mathrm{cw}}$ and $\\Delta_{\\mathrm{sub}}$ are positive constants. Then the upper bound in Theorem 4.3 is of order $K^{2}\\Delta_{\\mathrm{cw}}/\\Delta_{\\mathrm{sub}}^{2}$ . The last bound\u221a is sharper than the bound for WR-TINF (which is of order $K/\\Delta_{\\mathrm{cw}})$ , when we have $\\Delta_{\\mathrm{sub}}/\\Delta_{\\mathrm{cw}}>1/\\sqrt{K}$ . ", "page_idx": 7}, {"type": "text", "text": "5 Lower Bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we provide a lower bound on the largest weak regret of any algorithm, when confronted with a given set of dueling bandit problems, which we will discuss below. ", "page_idx": 7}, {"type": "text", "text": "Let $\\Delta_{\\mathrm{cw}}\\,\\in\\,(0,1/4)$ denote a positive number. For a dueling bandits problem, define the class of problems $\\mathbb{D}(\\Delta_{\\mathrm{cw}})$ by the set of matrices $M$ representing the gaps $(\\bar{\\Delta}_{i,j})_{i j}$ such that $M$ is skewsymmetric and there exists some $k^{*}\\in[K]$ (representing the Condorcet winner) such that: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\forall i\\neq k^{*}:M_{k^{*},i}=\\Delta_{\\mathrm{cw}}\\,\\mathrm{~and~}\\,\\forall i,j\\neq k^{*}:|M_{i,j}|\\leq\\Delta_{\\mathrm{cw}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The introduced class of matrices $\\mathbb{D}(\\Delta_{\\mathrm{cw}})$ includes many natural instances, such as when the gaps satisfy the general identifiability assumption. This assumption states that for each sub-optimal arm $j$ , the arm with the highest probability to beat $j$ is the Condorcet winner $k^{*}$ : i.e., $k^{*}\\in\\arg\\operatorname*{min}_{i\\in[K]}\\Delta_{j,i}$ . It has been considered in prior works such as [21] and more specifically it is implied by strong stochastic transitivity assumption (Section 3.1 of [2]). ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.1. Fix $K\\geq6,$ , $\\Delta_{c w}\\in(0,1/4)$ . The weak regret of an algorithm $\\boldsymbol{\\mathcal{A}}$ satisfies: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{M\\in\\mathbb{D}(\\Delta_{c w})}\\mathbb{E}_{M,A}\\left[R_{T}\\right]\\geq c\\frac{K}{\\Delta_{c w}},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "when $T\\geq c^{\\prime}K/\\Delta_{c w}^{2}$ . Here $c$ and $c^{\\prime}$ are numerical constants. ", "page_idx": 7}, {"type": "text", "text": "The result in Theorem 5.1 proves that Algorithm 1 is optimal for the considered instance, particularly highlighting that linear scaling with $K$ is optimal in this case. In the lower bound, we assumed uniform gaps between the Condorcet winner and the sub-optimal arms (equal to $\\Delta_{\\mathrm{cw}.}$ ). A potential improvement would be to develop a lower bound that depends on all the gaps with the Condorcet winner $(\\Delta_{k^{*},i})_{i\\in[K]}$ . Additionally, a more general lower bound should discard the general identifiability assumption. As previously argued, if the gaps between sub-optimal arms are large compared to the gaps with the Condorcet winner, it becomes easier to explore the $K^{2}$ duels to detect the sub-optimality of the arms and focus decision-making on the Condorcet winner. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we perform a numerical evaluation of WR-EXP3-IX and WR-TINF algorithms in three different scenarios that favor different algorithms according to the prior theoretical results. As a benchmark for our experiments, we utilize the state-of-the-art algorithm for weak regret, WS-W [4]. Additionally, we include one of the best-performing algorithms for strong regret, Versatile-DB [14], to demonstrate that optimizing for strong regret does not necessarily translate into optimal weak regret performance. For each of the experiments, we plot the mean regret over 20 iterations together with 0.2 and 0.8 quantiles. All the experiments in this section use theoretical values of parameters for the algorithms. The runtime of each algorithm and iteration is in terms of minutes on a personal computer. ", "page_idx": 7}, {"type": "image", "img_path": "dY4YGqvfgW/tmp/d46741e2ccf5775eb3b587728711ffd134c537f42ec7593a6bcf01b54c5f80d4.jpg", "img_caption": ["(a) Weak regret for small problem (Scenario 1) "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "dY4YGqvfgW/tmp/f40a29c3585d71a7af9b13fef301ae32b11291263f7c3df33a8bef8025aa515c.jpg", "img_caption": ["(b) Weak regret for moderate problem (Scenario 2) "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "dY4YGqvfgW/tmp/9dfe671aa07c70c5add369cfecab78508ef3a2f31ab9da0c75ea949e811db1f0.jpg", "img_caption": ["(c) Strong regret for moderate problem (Scenario 2) "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "dY4YGqvfgW/tmp/df47a8225ff13bdf788ab6969b09d6423ede24bc135ffa9888e5ba7b7048fab5.jpg", "img_caption": ["Figure 1: Performance of algorithms in different scenarios ", "(d) Weak regret for large problem (Scenario 3) "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Scenario 1: weak regret under SST (Figure 1a). We consider here: $K\\,=\\,30$ , $T\\,=\\,10000$ , $q_{i,j}=1-q_{j,k^{*}}=0.8$ for $i,j\\in[K]$ such that $i<j$ . In this scenario, we have a small number of arms and the SST holds - the arm with the lower index always wins with probability 0.8. This favors WS-W and WR-EXP3-IX algorithms. On the other hand, WR-TINF is a explores less, this results in larger regret for small $K$ while the algorithm shines as $K$ grows. ", "page_idx": 8}, {"type": "text", "text": "Scenario 2: Strong and weak regret comparison without SST (Figures 1b and 1c). We consider here: $K=150$ , $T=100000$ , $q_{k^{*},i}=0.9$ for every $i\\in[K]\\setminus\\{k^{*}\\}$ , $q_{i,j}\\,=\\,0.9$ (resp. $q_{i,j}=0.1)$ for $i,j\\in[K]\\setminus\\{k^{*}\\}$ such that $i<j$ and $(i+j)\\equiv0$ mod 2 (resp. $(i+j)\\equiv1$ mod 2). In this scenario, we have a moderately large number of arms and SST does not hold - each arm, except for the Condorcet winner, wins against approximately $K/2$ (every other index) other arms with probability 0.9 and loses to the other arms with probability 0.1. This should still favor WR-EXP3-IX algorithm but lack of ordering makes WS-W algorithm perform slightly worse. Algorithm WR-TINF slightly closes the gap in weak regret thanks to the increased number of arms. This can be seen in Figure 1b. For completeness of comparison, we also plot strong regret of the algorithms, see Figure 1c. Naturally, algorithms WS-W and WR-EXP3-IX suffer linear strong regret since they never play the same arm twice. However, WR-TINF performs well even with extra exploration, needed for weak regret, compared to Versatile-DB. ", "page_idx": 8}, {"type": "text", "text": "Scenario 3: large number of arms, no SST (Figure 1d). We consider: $K=400$ , $T=50000$ , $q_{k^{*},i}\\,=\\,0.9$ for every $i\\,\\in\\,[K]\\setminus\\{k^{*}\\}$ , $q_{i,j}\\,=\\,0.9$ (resp. $q_{i,j}\\,=\\,0.1)$ for $i,j\\,\\in\\,[K]\\setminus\\{k^{*}\\}$ such that $i<j$ and $(i+j)\\equiv0$ mod 2 (resp. $(i+j)\\equiv1$ mod 2). The same setup without SST as in Scenario 2 but with a larger $K$ . Better scaling with $K$ gives algorithm WR-TINF an edge over algorithms WS-W and WR-EXP3-IX while WS-W still suffers from the lack of SST. ", "page_idx": 8}, {"type": "text", "text": "Remark 6.1. On the variance of the WS-W algorithm: WS-W is a round-based procedure where the selected arms, \"winner and challenger,\" duel in batches of iterations. The length of each batch increases with the number of duels won by the selected arms so far. When an arm loses, it is replaced by a contender chosen from the remaining arms. Once the set of candidate arms is exhausted, the process is repeated. In numerical experiments, particularly with a large number of arms (Scenario 3 in the simulations section), we observe that in some unfortunate cases, especially in the early stages, the CW may lose its duels. This results in a large number of iterations before it is picked again as a contender, leading to very high weak regret for the procedure. Although such outcomes are infrequent, they significantly impact the empirical variance of the weak regret of WS-W. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion and limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we addressed the problem of weak regret analysis under the assumption of a Condorcet winner. We showed that, it is impossible in general to achieve a weak regret smaller than $K/(\\operatorname*{min}_{i\\neq k^{*}}\\Delta_{k^{*}i})$ and we introduced the procedure WR-TINF which achieves this bound. The second algorithm, WR-EXP3-IX, employs a more aggressive exploration strategy by querying the $K^{2}$ duels. We show that in some cases, this approach, despite inducing a quadratic dependence on $K$ can outperform WR-TINF, because it better adapts to the gaps between suboptimal arms. This is the first work in duelling bandit with weak regret that establishes how that the full matrix $\\Delta$ can be leveraged in the regret. ", "page_idx": 9}, {"type": "text", "text": "This work gives rise to several open questions. While WR-TINF is optimal in certain instances, developing algorithms that fully adapt to the underlying problem parameters remains a significant challenge. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The work of E.M. Saad and N. Verzelen has been partially supported by grant ANR-21-CE23-0035 (ASCAI,ANR). The work of A. Carpentier is partially supported by the Deutsche Forschungsgemeinschaft (DFG)- Project-ID 318763901 - SFB1294 \"Data Assimilation\", Project A03, by the DFG on the Forschungsgruppe FOR5381 \"Mathematical Statistics in the Information Age - Statistical Efficiency and Computational Tractability\", Project TP 02 (Project-ID 460867398), by the Agence Nationale de la Recherche (ANR) and the DFG on the French-German PRCI ANR-DFG ASCAI CA1488/4-1 \"Aktive und Batch-Segmentierung, Clustering und Seriation: Grundlagen der KI\" (Project-ID 490860858). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Nir Ailon, Zohar Karnin, and Thorsten Joachims. Reducing dueling bandits to cardinal bandits. In International Conference on Machine Learning, pages 856\u2013864. PMLR, 2014.   \n[2] Viktor Bengs, R\u00f3bert Busa-Fekete, Adil El Mesaoudi-Paul, and Eyke H\u00fcllermeier. Preferencebased online learning with dueling bandits: A survey. The Journal of Machine Learning Research, 22(1):278\u2013385, 2021.   \n[3] Olivier Chapelle, Thorsten Joachims, Filip Radlinski, and Yisong Yue. Large-scale validation and analysis of interleaved search evaluation. ACM Transactions on Information Systems (TOIS), 30(1):1\u201341, 2012.   \n[4] Bangrui Chen and Peter I Frazier. Dueling bandits with weak regret. In International Conference on Machine Learning, pages 731\u2013739. PMLR, 2017.   \n[5] Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999.   \n[6] Marco De Gemmis, Leo Iaquinta, Pasquale Lops, Cataldo Musto, Fedelucio Narducci, Giovanni Semeraro, et al. Preference learning in recommender systems. Preference Learning, 41(41- 55):48, 2009.   \n[7] Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, and Geri Gay. Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search. ACM Transactions on Information Systems (TOIS), 25(2):7\u2013es, 2007. [8] Junpei Komiyama, Junya Honda, Hisashi Kashima, and Hiroshi Nakagawa. Regret lower bound and optimal algorithm in dueling bandit problem. In Conference on learning theory, pages 1141\u20131154. PMLR, 2015. [9] Gregory F Lawler. Introduction to stochastic processes. Chapman and Hall/CRC, 2018.   \n[10] Chang Li, Ilya Markov, Maarten De Rijke, and Masrour Zoghi. Mergedts: A method for effective large-scale online ranker evaluation. ACM Transactions on Information Systems (TOIS), 38(4):1\u201328, 2020.   \n[11] Gergely Neu. Explore no more: Improved high-probability regret bounds for non-stochastic bandits. Advances in Neural Information Processing Systems, 28, 2015.   \n[12] Erol Pek\u00f6z, Sheldon M Ross, and Zhengyu Zhang. Dueling bandit problems. Probability in the Engineering and Informational Sciences, 36(2):264\u2013275, 2022.   \n[13] Chlo\u00e9 Rouyer and Yevgeny Seldin. Tsallis-inf for decoupled exploration and exploitation in multi-armed bandits. In Conference on Learning Theory, pages 3227\u20133249. PMLR, 2020.   \n[14] Aadirupa Saha and Pierre Gaillard. Versatile dueling bandits: Best-of-both world analyses for learning from relative preferences. In International Conference on Machine Learning, pages 19011\u201319026. PMLR, 2022.   \n[15] Aadirupa Saha and Shubham Gupta. Optimal and efficient dynamic regret algorithms for non-stationary dueling bandits. In International Conference on Machine Learning, pages 19027\u201319049. PMLR, 2022.   \n[16] Yanan Sui, Masrour Zoghi, Katja Hofmann, and Yisong Yue. Advancements in dueling bandits. In IJCAI, pages 5502\u20135510, 2018.   \n[17] Xinyi Yan, Chengxi Luo, Charles LA Clarke, Nick Craswell, Ellen M Voorhees, and Pablo Castells. Human preferences as dueling bandits. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 567\u2013577, 2022.   \n[18] Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims. The $\\mathbf{k}$ -armed dueling bandits problem. Journal of Computer and System Sciences, 78(5):1538\u20131556, 2012.   \n[19] Yisong Yue and Thorsten Joachims. Interactively optimizing information retrieval systems as a dueling bandits problem. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 1201\u20131208, 2009.   \n[20] Yisong Yue and Thorsten Joachims. Beat the mean bandit. In Proceedings of the 28th international conference on machine learning (ICML-11), pages 241\u2013248. Citeseer, 2011.   \n[21] Julian Zimmert and Yevgeny Seldin. Factored bandits. Advances in Neural Information Processing Systems, 31, 2018.   \n[22] Julian Zimmert and Yevgeny Seldin. Tsallis-inf: An optimal algorithm for stochastic and adversarial bandits. The Journal of Machine Learning Research, 22(1):1310\u20131358, 2021.   \n[23] Masrour Zoghi, Shimon Whiteson, and Maarten de Rijke. Mergerucb: A method for large-scale online ranker evaluation. In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, pages 17\u201326, 2015.   \n[24] Masrour Zoghi, Shimon A Whiteson, Maarten De Rijke, and Remi Munos. Relative confidence sampling for efficient on-line ranker evaluation. In Proceedings of the 7th ACM international conference on Web search and data mining, pages 73\u201382, 2014. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "8 Appendix / supplemental material ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "A Preliminary results for Algorithm 1 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "A.1 Preliminary Lemma: ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Lemma below upper-bounds the weak regret of Algorithm 2. ", "page_idx": 11}, {"type": "text", "text": "Lemma A.1. Let an algorithm $\\mathcal{A^{\\prime}}$ playing in each round the pair of arms $(I_{t}^{\\prime},J_{t}^{\\prime})$ observing only the feedback of the duel between arms $(I_{t},J_{t})$ sampled following the scheme in (5). Let $\\boldsymbol{\\mathcal{A}}$ be an algorithm playing in each round the pair $(I_{t},J_{t})$ and observing the feedback $X_{t}(I_{t},J_{t})$ . let $R_{T,A^{\\prime}}^{(s)}$ denote the strong regret of $\\mathcal{A^{\\prime}}$ and $R_{T,A}^{(w)}$ the weak regret of $\\boldsymbol{\\mathcal{A}}$ . We have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T,A}^{(w)}\\right]\\leq\\mathbb{E}\\left[R_{T,A^{\\prime}}^{(s)}\\right].\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. For $t\\in[T]$ observe that following Algorithm 1, we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}};\\Delta_{k^{*},I_{t}}\\}\\right]=\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}};\\Delta_{k^{*},I_{t}}\\}\\,I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right]}\\\\ &{\\qquad\\qquad\\qquad+\\,\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}};\\Delta_{k^{*},I_{t}}\\}\\,I_{t}^{\\prime}=J_{t}^{\\prime}\\right]}\\\\ &{\\leq\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\operatorname*{min}\\{\\Delta_{k^{*},I_{t}^{\\prime}};\\Delta_{k^{*},I_{t}^{\\prime}}\\}\\right]+\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\Delta_{k^{*},I_{t}^{\\prime}}\\right]}\\\\ &{\\leq\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\frac{\\Delta_{k^{*},I_{t}^{\\prime}}+\\,\\Delta_{k^{*},J_{t}^{\\prime}}}{2}\\right]+\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}\\left[\\Delta_{k^{*},I_{t}^{\\prime}}\\right]}\\\\ &{=\\mathbb{E}\\left[\\frac{\\Delta_{k^{*},I_{t}^{\\prime}}+\\,\\Delta_{k^{*},J_{t}^{\\prime}}}{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "We used in the second line the fact that conditionally to the event $\\{I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\}$ , $(I_{t},J_{t})$ are sampled independently from $\\scriptstyle{p_{t}}$ (same distribution as $(I_{t}^{\\prime},J_{t}^{\\prime}))$ , and conditionally to the event $\\{I_{t}^{\\prime}=J_{t}^{\\prime}\\}$ , $I_{t}$ is sampled from $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ . The result follows by summing over $t\\in[T]$ . \u53e3 ", "page_idx": 11}, {"type": "text", "text": "A.2 Additional Lemmas: ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Lemma below states that the reduction proved in Theorem 2 of [14] is still valid in our setting. Recall the notation: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R_{-1,T}^{\\prime}=\\sum_{t=1}^{T}\\ell_{-1,t}^{\\prime}(I_{t}^{\\prime})-\\ell_{-1,t}^{\\prime}(k^{*})}}\\\\ {{\\displaystyle R_{+1,T}^{\\prime}=\\sum_{t=1}^{T}\\ell_{+1,t}^{\\prime}(J_{t}^{\\prime})-\\ell_{+1,t}^{\\prime}(k^{*})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "where $\\ell_{-1,t}^{\\prime}(k)=X_{t}(J_{t}^{\\prime},k)$ and $\\ell_{+1,t}^{\\prime}(k)=X_{t}(I_{t}^{\\prime},k)$ . ", "page_idx": 11}, {"type": "text", "text": "Lemma A.2. Theorem 2 of [14] The expected strong regret of algorithm $\\mathcal{A^{\\prime}}$ satisfies: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[R_{T,A^{\\prime}}^{(s)}]=\\frac{1}{2}\\mathbb{E}\\left[R_{-1,T}^{\\prime}+R_{+1,T}^{\\prime}\\right]}\\\\ &{~~~~~~~~~~~~~~~~~~~~~~~~~=\\mathbb{E}\\left[R_{-1,T}^{\\prime}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Moreover, we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{-1,T}^{\\prime}\\right]=\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sum_{k\\neq k^{*}}p_{t,k}\\Delta_{k^{*},k}\\right].\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. We have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{-1,T}^{\\prime}+R_{+1,T}^{\\prime}\\right]=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\ell_{-1,t}^{\\prime}(I_{t}^{\\prime})-\\ell_{-1,t}^{\\prime}(k^{*})+\\ell_{+1,t}^{\\prime}(J_{t}^{\\prime})-\\ell_{+1,t}^{\\prime}(k^{*})\\right]}\\\\ &{\\phantom{\\mathbb{E}\\left[R_{-1,T}^{\\prime}+R_{+1,T}^{\\prime}\\right]}=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[1-\\left(\\ell_{-1,t}^{\\prime}(k^{*})+\\ell_{+1,t}^{\\prime}(k^{*})\\right)\\right]}\\\\ &{\\phantom{\\mathbb{E}\\left[R_{-1,T}^{\\prime}+R_{+1,T}^{\\prime}\\right]}=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\Delta_{k^{*},I_{t}^{\\prime}}+\\Delta_{k^{*},I_{t}^{\\prime}}\\right]}\\\\ &{\\phantom{\\mathbb{E}\\left[R_{-1,t}^{\\prime}+R_{+1,t}^{\\prime}\\right]}=2\\mathbb{E}\\left[R_{T,A^{\\prime}}^{(s)}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We used in the second line the fact that: $\\ell_{-1,t}^{\\prime}+\\ell_{+1,t}^{\\prime}=X_{t}(I_{t}^{\\prime},J_{t}^{\\prime})+X_{t}(J_{t}^{\\prime},I_{t}^{\\prime})=1.$ ", "page_idx": 12}, {"type": "text", "text": "Furthermore, observe that for any $t\\in[T]$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\ell_{-1,t}^{\\prime}(I_{t}^{\\prime})-\\ell_{-1,t}^{\\prime}(k^{*})\\right]=\\mathbb{E}\\left[X_{t}(I_{t}^{\\prime},J_{t}^{\\prime})-X_{t}(k^{*},J_{t}^{\\prime})\\right]}\\\\ {=\\mathbb{E}\\left[X_{t}(J_{t}^{\\prime},I_{t}^{\\prime})-X_{t}(k^{*},I_{t}^{\\prime})\\right]}\\\\ {=\\mathbb{E}\\left[\\ell_{+1,t}^{\\prime}(J_{t}^{\\prime})-\\ell_{+1,t}^{\\prime}(k^{*})\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where we used the fact that $I_{t}^{\\prime}$ and $J_{t}^{\\prime}$ are sampled independently from the same distribution. Therefore we have summing over $t$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{-1,T}^{\\prime}\\right]=\\mathbb{E}\\left[R_{+1,T}^{\\prime}\\right]\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Now let us prove the last identity of the lemma. We have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[R_{-1,T}^{\\prime}\\right]=\\frac{1}{2}\\mathbb{E}\\left[R_{-1,T}^{\\prime}+R_{+1,T}^{\\prime}\\right]}}\\\\ &{=\\frac{1}{2}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\Delta_{k^{*},I_{t}^{\\prime}}+\\Delta_{k^{*},J_{t}^{\\prime}}\\right]}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\Delta_{k^{*},I_{t}^{\\prime}}\\right]}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\sum_{k\\neq k^{*}}\\mathbb{E}\\left[p_{k,t}\\Delta_{k^{*},k}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We used in the last equality (9), and the fact that $I_{t}^{\\prime}\\sim J_{t}^{\\prime}$ in the fourth. ", "page_idx": 12}, {"type": "text", "text": "Recall the notation: $\\ell_{t}^{\\prime}(k):=X_{t}(k,J_{t}^{\\prime})$ , which corresponds to the loss of the learner playing $k$ when the environment chooses $J_{t}^{\\prime}$ . Recall the expression of the importance weights estimator introduced in (7) in the main body: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\hat{\\ell}_{t}(k):=\\frac{\\mathbb{1}\\left(J_{t}=k\\right)X_{t}(k,I_{t})}{q_{t,k}},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where, ", "page_idx": 12}, {"type": "equation", "text": "$$\nq_{t,k}=\\left(\\frac{\\mathbb{1}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)}+\\frac{\\mathbb{1}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}\\right)^{-1}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We provide the following expressions of the probabilities used in the definition above. we have that $I_{t}^{\\prime}$ and $J_{t}^{\\prime}$ are sampled independently following $p_{t}=(p_{t,k})_{k\\in[K]}$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)=p_{t,k}}\\\\ {\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)=\\displaystyle\\frac{p_{t,k}^{2/3}}{\\sum_{i=1}^{K}p_{t,i}^{2/3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Lemma A.3. We have for any $k\\in[K]$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t-1}[\\hat{\\ell}_{t}(k)]=\\mathbb{E}_{t-1}\\left[\\ell_{t}^{\\prime}(k)\\right],\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathbb{E}_{t-1}[.]$ corresponds to the expectation at round $t$ given the past information. ", "page_idx": 13}, {"type": "text", "text": "Proof. We have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathfrak{L}_{t-1}[\\hat{\\ell}_{t}(k)]=\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{1}\\left(J_{t}=k\\right)\\mathbb{1}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)X_{t}(k,I_{t})}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)}\\right]+\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{1}\\left(J_{t}=k\\right)\\mathbb{1}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)X_{t}(k,I_{t})}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}\\right]\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Calculating Term 1: We have ", "text_level": 1, "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Term~}1=\\mathbb{E}_{t-1}\\left[\\frac{1}{\\mathbb{P}}\\left(J_{t}=k\\right)\\mathbb{1}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)X_{t}(k,I_{t})\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(J_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}\\left[\\frac{1}{\\mathbb{P}}\\left(J_{t}=k\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\right.}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{1}}{\\mathbb{P}}\\left(J_{t}=k\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{1}}{\\mathbb{P}}\\left(J_{t}=k\\right)X_{t}(k,J_{t}^{\\prime})\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}\\neq J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}[\\hat{\\ell}_{t}(k)\\mid I_{t}^{\\prime}\\neq J_{t}^{\\prime}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where we used in the third line the fact that conditionally to $I_{t}^{\\prime}\\neq J_{t}^{\\prime}$ , we have $I_{t}\\sim J_{t}^{\\prime}$ . ", "page_idx": 13}, {"type": "text", "text": "Calculating Term 2: We have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Term~}2=\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{I}\\left(J_{t}=k\\right)\\mathbb{1}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)X_{t}\\left(k,I_{t}\\right)}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}\\right]}\\\\ &{\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{I}\\left(J_{t}=k\\right)X_{t}\\left(k,I_{t}\\right)}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right]}\\\\ &{\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}\\left[\\frac{\\mathbb{I}\\left(J_{t}=k\\right)X_{t}\\left(k,J_{t}^{\\prime}\\right)}{\\mathbb{P}\\left(J_{t}=k\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right)}\\mid I_{t}^{\\prime}=J_{t}^{\\prime}\\right]}\\\\ &{\\qquad=\\mathbb{P}\\left(I_{t}^{\\prime}=J_{t}^{\\prime}\\right)\\mathbb{E}_{t-1}[\\widehat{\\ell}_{t}(k)\\mid I_{t}^{\\prime}=J_{t}^{\\prime}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The conclusion follows by summing the obtained expressions. ", "page_idx": 13}, {"type": "text", "text": "B Analysis for the modified OMD with Tsallis regularizer ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "B.1 The Setting: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The online mirror descent with Tsallis regularizer in the standard coupled exploration and exploitation case was analyzed in [22] and in the decoupled exploration and exploitation setting in [13]. In this section, we develop guarantees in the case where exploration and exploitation are partially coupled via the sampling scheme that we employ, which is restated in Algorithm 4. Note that to be compatible with our setting for dueling bandits, we need to make some modifications to the game protocol for the problem of regret minimization. More precisely, we assume that in each round $t$ instead of choosing a sequence of numbers, the environment chooses a sequence of distributions for losses. The incurred and observed losses are sampled independently from the sequence chosen by the environment. Note that this change doesn\u2019t affect the definition of the pseudo-regret, which is the quantity of interest here, since the definitions involve expectations. We present in Algorithm 3 the game protocol of this game. ", "page_idx": 13}, {"type": "text", "text": "Algorithm 3 Game Protocol ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "for $t=1,\\ldots.$ . do ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The player chooses two distributions $p_{t}=(p_{t,k})_{k\\in[K]}$ and $\\pmb{q}_{t}=(q_{t,k})_{k\\in[K]}$ over $[K]$ . Concurrently, the environment chooses $K$ random distributions with support in $[0,1]$ denoted $(\\mathcal{L}_{t,k})_{k\\in[K]}$   \nThe player plays an arm $A_{t}$ sampled following $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ and incurs an unseen loss $\\ell_{t,A_{t}}$ sampled from Lt,At.   \nThe player samples an arm $B_{t}$ following $\\mathbf{\\deltaq}_{t}$ and observes an independent fresh sample $\\bar{\\ell}_{t,B_{t}}$ from the distribution Lt,Bt. ", "page_idx": 14}, {"type": "text", "text": "end for ", "page_idx": 14}, {"type": "text", "text": "Remark B.1. The only difference between the game protocol above and the one used in [13] is that in our setting we assume that the observed losses and the incurred losses are independently sampled from some distribution, while in $[I3]$ the losses that are observed and incurred are the same. ", "page_idx": 14}, {"type": "text", "text": "We define the pseudo-regret with respect to $k$ as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}:=\\sum_{t=1}^{T}\\mathbb{E}\\left[\\ell_{t,A_{t}}\\right]-\\operatorname*{min}_{k}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell_{t,k}\\right].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We denote by $\\begin{array}{r}{k^{\\ast}:=\\arg\\operatorname*{min}_{k}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell_{t,k}\\right]\\!.}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "We consider the stochastically constrained adversarial setting where we have for some positive numbers $(\\Delta_{k})$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}=\\sum_{t=1}^{T}\\sum_{k\\neq k^{*}}\\mathbb{E}\\left[p_{t,k}\\right]\\Delta_{k}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "B.2 The Algorithm: ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Following [22], we consider a follow-the-regularized leader (FTRL) approach using ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Psi_{t}(w)=-\\frac{1}{\\eta_{t}}\\sum_{k=1}^{K}\\frac{w_{k}^{\\alpha}-\\alpha w_{k}}{\\alpha(1-\\alpha)},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "as regularizers where $(\\eta_{t})$ is a sequence of positive numbers and $\\alpha\\in(0,1)$ . ", "page_idx": 14}, {"type": "text", "text": "More specifically, following the analysis of decoupled exploration and exploitation in [13], we focus on the case where $\\alpha=2/3$ . We introduce the following loss estimators: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall t\\in[T],k\\in[K],\\ \\hat{\\ell}_{t,k}=\\frac{\\mathbb{1}\\left(B_{t}=k\\right)}{q_{t,k}}\\ \\bar{\\ell}_{t,k},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Recall that following Game Protocol 3: $\\bar{\\ell}_{t,k}$ and $\\ell_{t,k}$ are independent and follow the same distribution $\\mathcal{L}_{t,k}$ . ", "page_idx": 14}, {"type": "text", "text": "We define our exploration distribution $\\pmb q_{t}$ by: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{1}\\left(B_{t}=k\\right)}{q_{t,k}}:=\\frac{\\mathbb{1}\\left(\\left\\{B_{t}=k\\right\\}\\mathrm{~and~}E_{t}\\right)}{q_{t,k}^{\\left(1\\right)}}+\\frac{\\mathbb{1}\\left(\\left\\{B_{t}=k\\right\\}\\mathrm{~and~}E_{t}^{c}\\right)}{q_{t,k}^{\\left(2\\right)}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $E_{t}$ is some internal event specified by the learner based on past information and some internal randomization. In Algorithm 4 below, $E_{t}$ corresponds to the event $\\{A_{t}=B_{t}^{\\prime}\\}$ where $A_{t}$ and $B_{t}^{\\prime}$ are independent and sampled from $[K]$ following $p_{t}.\\;E_{t}^{c}$ denotes the complementary to $E_{t}$ . $(q_{t,k}^{(1)})_{k\\in[K]}$ and $(q_{t,k}^{(2)})_{k\\in[K]}$ are probability distributions defined by: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{q_{t,k}^{(1)}=\\mathbb{P}\\left(B_{t}=k\\mid E_{t}\\right)}\\\\ &{q_{t,k}^{(2)}=\\mathbb{P}\\left(B_{t}=k\\mid E_{t}^{c}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We define the probability $(q_{t,k}^{(1)})_{k\\in[K]}$ by: $q_{t,k}^{(1)}:=p_{t,k}$ . Define the probability $q_{t,k}^{(2)}$ as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nq_{t,k}^{(2)}:=\\frac{p_{t,k}^{2/3}}{\\sum_{i=1}^{K}p_{t,i}^{2/3}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Algorithm 4 Partially coupled Tsallis-INF ", "page_idx": 15}, {"type": "text", "text": "Input: $(\\Psi_{t})_{t=1,2,..}$ .   \ninit: $\\hat{L}_{0}=0$ .   \nfor $t=1,\\ldots$ do choose $p_{t}=\\arg\\operatorname*{max}_{p}\\left\\{\\langle p,-\\hat{L}_{t-1}\\rangle-\\Psi_{t}(p)\\right\\}$ Sample $A_{t}$ from $[K]$ using $\\textstyle p_{t}$ . Play $A_{t}$ and suffer $\\ell_{t,A_{t}}$ . Sample $B_{t}^{\\prime}$ independently from $[K]$ using $\\textstyle p_{t}$ . if $B_{t}^{\\prime}\\neq\\bar{A_{t}}$ then Sample $B_{t}$ according to $\\textstyle p_{t}$ . else Sample $B_{t}$ according to $(q_{t,k}^{(2)})$ defined in (13). end if Observe $\\bar{\\ell}_{t,B_{t}}$ (loss having the same distribution as $\\ell_{t,B_{t}}$ ) Compute $\\hat{\\ell}_{t,k}$ using (11) and update $\\hat{L}_{t}$ .   \nend for ", "page_idx": 15}, {"type": "text", "text": "Theorem B.2. Suppose the regret satisfies the self-constraining condition (10). The pseudo-regret of Algorithm 4 with \u03b1 = 2/3, \u03b7t = 2K\u221a\u2212t1/6, $\\begin{array}{r}{\\Psi_{t}(w)=-\\frac{1}{\\eta_{t}}\\sum_{i}\\frac{w_{i}^{\\alpha}-\\alpha w_{i}}{\\alpha(1-\\alpha)}}\\end{array}$ , satisfies: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}\\leq c\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\sum_{k\\neq k^{*}}\\frac{1}{\\Delta_{k}}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\begin{array}{r}{\\Delta_{*}=\\operatorname*{min}_{k\\neq k^{*}}\\Delta_{k}}\\end{array}$ and $c$ is a numerical constant. ", "page_idx": 15}, {"type": "text", "text": "Proof. Following previous works, we decompose the expected regret into the stability and penalty terms using the potential $\\Phi_{t}$ defined by: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Phi_{t}(-L)=\\operatorname*{max}_{w\\in{\\cal S}^{K-1}}\\left\\{\\langle w,-L\\rangle+\\frac{1}{\\eta_{t}}\\sum_{k=1}^{K}\\frac{w_{k}^{\\alpha}-\\alpha w_{k}}{\\alpha(1-\\alpha)}\\right\\},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $S^{K-1}$ is the set of probability weights on $[K]$ . Let $\\begin{array}{r}{\\hat{L}_{t}=\\sum_{t=1}^{T}\\hat{\\ell}_{t}}\\end{array}$ , where $\\hat{\\ell}_{t}$ is defined by (11). We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}=\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell_{t,A_{t}}+\\Phi_{t}(-\\hat{L}_{t})-\\Phi_{t}(-\\hat{L}_{t-1})\\right]+\\mathbb{E}\\left[\\sum_{t=1}^{T}\\Phi_{t}(-\\hat{L}_{t-1})-\\Phi_{t}(-\\hat{L}_{t})-\\ell_{k^{*},t}\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Recall that we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}=\\sum_{t=1}^{T}\\sum_{k\\neq k^{*}}\\mathbb{E}[p_{t,k}]\\Delta_{k}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathcal R}_{T}=2{\\mathcal R}_{T}-\\displaystyle\\sum_{t=1}^{T}\\sum_{k\\neq k^{\\star}}\\mathbb{E}[p_{t,k}]\\Delta_{k}}\\\\ &{\\quad=\\underbrace{2\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\ell_{t,A_{t}}+\\Phi_{t}(-\\hat{L}_{t})-\\Phi_{t}(-\\hat{L}_{t-1})\\right]}_{\\mathrm{Term~I}}-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\sum_{k\\neq k^{\\star}}\\mathbb{E}[p_{t,k}]\\Delta_{k}}\\\\ &{\\quad\\quad\\quad\\quad+\\underbrace{2\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\Phi_{t}(-\\hat{L}_{t-1})-\\Phi_{t}(-\\hat{L}_{t})-\\ell_{t,k^{\\star}}\\right]}_{\\mathrm{Term~I}}-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\sum_{k\\neq k^{\\star}}\\mathbb{E}[p_{t,k}]\\Delta_{k}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let us bound each term separately. ", "page_idx": 16}, {"type": "text", "text": "Bounding the term corresponding to the penalty: Term 2 Let $T_{0}\\geq1$ . We have using Lemma B.4 ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tan2\\le\\displaystyle\\frac{9\\sqrt{K}}{2}+\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\left(\\frac{9}{4}K^{1/6}\\frac{\\mathbb{E}\\left[p_{t,i}\\right]^{2/3}}{\\sqrt{t}}-\\frac{1}{2}\\mathbb{E}\\left[p_{t,i}\\right]\\Delta_{i}\\right)}&{\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(14)}\\\\ &{\\qquad\\le\\displaystyle\\frac{9\\sqrt{K}}{2}+\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\left(\\frac{9}{4}K^{1/6}\\frac{\\mathbb{E}\\left[p_{t,i}\\right]^{2/3}}{\\sqrt{t}}\\right)+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{\\star}}\\left(\\frac{9}{4}K^{1/6}\\frac{\\mathbb{E}\\left[p_{t,i}\\right]^{2/3}}{\\sqrt{t}}-\\frac{1}{2}\\mathbb{E}\\left[p_{t,i}\\right]Z^{1}\\right.}\\\\ &{\\qquad\\left.\\le\\displaystyle\\frac{9\\sqrt{K}}{2}+\\frac{9}{2}\\sqrt{K T_{0}}+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{\\star}}\\left(\\frac{9}{4}K^{1/6}\\frac{\\mathbb{E}\\left[p_{t,i}\\right]^{2/3}}{\\sqrt{t}}-\\frac{1}{2}\\mathbb{E}\\left[p_{t,i}\\right]\\Delta_{i}\\right)}&\\\\ &{\\qquad\\le9\\sqrt{K T_{0}}+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{\\star}}\\frac{\\operatorname*{max}}{z^{3}}\\left\\{\\frac{9K^{1/6}\\underline{{{z}}}^{2/3}}{4\\sqrt{t}}-\\frac{\\Delta_{i}}{2}z\\right\\},}&{\\displaystyle\\qquad\\qquad\\qquad\\quad(15)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we used in the third line Jensen\u2019s inequality on the concave function $x\\ \\to\\ x^{2/3}$ , giving: $\\begin{array}{r}{\\sum_{i\\neq k^{*}}\\mathbb{E}[p_{t,i}^{2/3}]\\leq K^{1/3}}\\end{array}$ and the fact that $\\begin{array}{r}{\\sum_{t=1}^{T_{0}}\\frac{1}{\\sqrt{t}}\\leq2\\sqrt{T_{0}}}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "Bounding the term corresponding to the stability: Term 1 We have using Lemma B.3 ", "text_level": 1, "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\boldmath~\\hat{vem}~}1\\leq2\\displaystyle\\sum_{t=1}^{T}\\eta_{t}\\mathbb{E}\\left[(1-p_{t,k})\\sum_{i\\neq k^{\\star}}p_{t,i}^{1/3}+K^{1/3}\\sum_{i\\neq k^{\\star}}p_{t,i}^{2/3}\\right]-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[p_{t,i}\\right]\\Delta_{i}}\\\\ &{\\qquad=\\displaystyle\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,i\\cdot})p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]+\\displaystyle\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[4\\frac{K^{1/6}}{\\sqrt{t}}p_{t,i}^{2/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]}\\\\ &{\\qquad=\\displaystyle\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,i\\cdot})p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]+\\displaystyle\\sum_{t=1}^{T}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[4\\frac{K^{1/6}}{\\sqrt{t}}p_{t,i}^{2/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]}\\\\ &{\\qquad\\qquad+\\displaystyle\\sum_{t=T_{+1}+1\\neq k^{\\star}}\\mathbb{E}\\left[4\\frac{K^{1/6}}{\\sqrt{t}}p_{t,i}^{2/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we used the definition of $\\eta_{t}$ from line 1 to line 2. ", "page_idx": 16}, {"type": "text", "text": "The Terms 1.2 and 1.3 can be upper bounded using the same derivation as in the previous calculations for Term 1, where we obtained (15) from (14): ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Term~}12+\\mathrm{Term~}13\\leq8\\sqrt{K T_{0}}+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{*}}\\operatorname*{max}_{z\\geq0}\\Big[\\frac{4K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{\\Delta_{i}}{4}z\\Big].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let us bound Term 1.1. Let $\\begin{array}{r}{\\bar{T}:=\\lceil\\frac{256K}{\\Delta_{*}^{2}}\\rceil}\\end{array}$ . We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{crm~11}=\\sum_{t=1}^{\\bar{T}}\\sum_{i\\neq k^{*}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,k^{*}})p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]+\\sum_{t=\\bar{T}+1}^{T}\\sum_{i\\neq k^{*}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,k^{*}})p_{t,i}^{1/3}\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let t \u2265T\u00af, recall that  iK=1 pt,i = 1, therefore using Jensen\u2019s inequality for the concave function $x\\to x^{1/3}$ , we have: $\\begin{array}{r}{\\sum_{i\\neq k^{*}}p_{t,i}^{1/3}\\le K^{2/3}(\\sum_{i\\neq k^{*}}p_{t,i})^{1/3}=K^{2/3}(1-p_{t,k^{*}})^{1/3}}\\end{array}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{\\neq k^{\\star}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,k^{\\star}})p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]\\leq4\\frac{K^{-1/6}}{\\sqrt{t}}(1-p_{t,k^{\\star}})K^{2/3}(1-p_{t,k^{\\star}})^{1/3}-\\frac{1}{4}\\Delta_{*}(1-p_{t,k^{\\star}})^{1/3}}&{{}\\leqq2\\frac{|\\Delta_{*}(1-p_{t,k^{\\star}})|}{\\sqrt{t}},}\\\\ {\\displaystyle\\leq\\frac{\\Delta_{*}}{4}(1-p_{t,k^{\\star}})^{4/3}-\\frac{1}{4}\\Delta_{*}(1-p_{t,k^{\\star}})}&{{}}\\\\ {\\displaystyle}&{{}\\leq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the the second line follows from the fact that $t\\geq\\bar{T}$ , and the last line from the fact that $p_{t,k^{*}}\\in[0,1]$ . We conclude that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Term~1.1}\\leq\\displaystyle\\sum_{t=1}^{\\hat{T}}\\displaystyle\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}(1-p_{t,k^{\\star}})p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{\\hat{T}}\\sum_{i\\neq k^{\\star}}\\mathbb{E}\\left[\\frac{4K^{-1/6}}{\\sqrt{t}}p_{t,i}^{1/3}-\\frac{1}{4}p_{t,i}\\Delta_{i}\\right]}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{\\hat{T}}\\displaystyle\\sum_{i\\neq k^{\\star}}\\operatorname*{max}_{\\varepsilon\\leq0}\\left\\{4\\frac{K^{-1/6}}{\\sqrt{t}}z^{1/3}-\\frac{\\Delta_{i}}{4}z\\right\\}}\\\\ &{\\leq25\\displaystyle\\sum_{t=1}^{\\hat{T}}\\sum_{i\\neq k^{\\star}}\\frac{K^{-1/4}}{t^{3/4}}\\displaystyle\\frac{1}{\\sqrt{\\Delta_{i}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where we used Lemma F.4 to obtain the last line. Using $\\sum_{t=1}^{\\bar{T}}t^{-3/4}\\leq4\\bar{T}^{1/4}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Term}\\;1.1\\leq100\\left(\\frac{\\bar{T}}{K}\\right)^{1/4}\\sum_{i\\neq k^{*}}\\frac{1}{\\sqrt{\\Delta_{i}}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Next we use the definition of $\\bar{T}$ , then Jensen\u2019s inequality for the concave function $x\\rightarrow{\\sqrt{x}}$ to have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Term~1.1}\\leq400\\frac{1}{\\sqrt{\\Delta_{*}}}\\displaystyle\\sum_{i\\neq k^{*}}\\frac{1}{\\sqrt{\\Delta_{i}}}}\\\\ {\\leq400\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\displaystyle\\sum_{i\\neq k^{*}}\\frac{1}{\\Delta_{i}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We conclude combining (16) and (17) that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Term~1}\\le400\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\sum_{i\\ne k^{*}}\\frac{1}{\\Delta_{i}}}+8\\sqrt{K T_{0}}+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\ne k^{*}}\\operatorname*{max}_{z\\ge0}\\frac{4K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{\\Delta_{i}}{4}z.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Conclusion: Combining the bounds in (18) and (15) we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}\\leq400\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\sum_{i\\neq k^{*}}\\frac{1}{\\Delta_{i}}}+17\\sqrt{K T_{0}}+\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{*}}\\operatorname*{max}_{z\\geq0}\\left\\{\\frac{7K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{3\\Delta_{i}}{4}z\\right\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Using Lemma F.4, we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=T_{0}+1}^{T}\\operatorname*{max}_{z\\geq0}\\left\\{\\frac{7K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{3\\Delta_{i}}{4}z\\right\\}\\leq\\displaystyle\\sum_{t=T_{0}+1}^{T}\\left(\\frac{7K^{1/6}}{\\sqrt{t}}\\right)^{3}\\left(\\frac{3\\Delta_{i}}{4}\\right)^{-2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq610\\displaystyle\\sum_{t=T_{0}+1}^{T}\\frac{\\sqrt{K}}{t^{3/2}}\\frac{1}{\\Delta_{i}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We conclude that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{t=T_{0}+1}^{T}\\sum_{i\\neq k^{*}}\\operatorname*{max}_{z\\geq0}\\left\\{\\frac{7K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{3\\Delta_{i}}{4}z\\right\\}\\leq610\\sqrt{K}\\sum_{i\\neq k^{*}}S_{i}(T),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{S_{i}(T):=\\sum_{t=T_{0}+1}^{T}{\\frac{1}{\\Delta_{i}^{2}t^{3/2}}}}\\end{array}$ . Let us bound the quantities $S_{i}(T)$ . We have for any $i\\neq k^{*}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{S_{i}(T)\\le\\sum_{t=T_{0}+1}^{+\\infty}\\frac{1}{\\Delta_{i}^{2}t^{3/2}}}}\\\\ &{}&{\\le\\frac{1}{\\Delta_{i}^{2}}\\int_{T_{0}}^{+\\infty}\\frac{1}{t^{3/2}}d t}\\\\ &{}&{=\\frac{1}{\\Delta_{i}^{2}}\\operatorname*{lim}_{T\\to\\infty}\\frac{T^{-1/2}-T_{0}^{-1/2}}{-\\frac{1}{2}}}\\\\ &{}&{=\\frac{2}{\\Delta_{i}^{2}\\sqrt{T_{0}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Next, we re-inject the bound above on inequality (20) and obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=T_{0}+1}^{T}\\sum_{i\\not=k^{*}}\\operatorname*{max}_{z\\geq0}\\left\\{\\frac{7K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{3\\Delta_{i}}{4}z\\right\\}\\le610\\sqrt{K}\\sum_{i\\not=k^{*}}S_{i}(T)}}\\\\ &{}&{\\le1220\\sqrt{K}\\sum_{i\\not=k^{*}}\\frac{1}{\\Delta_{i}^{2}\\sqrt{T_{0}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We take ", "page_idx": 18}, {"type": "equation", "text": "$$\nT_{0}:=\\lceil*\\rceil\\frac{1}{\\Delta_{*}}\\sum_{i\\neq k^{*}}\\frac{1}{\\Delta_{i}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=T_{0}+1}^{T}\\sum_{i\\not=k^{*}}\\operatorname*{max}_{z\\geq0}\\left\\{\\frac{7K^{1/6}}{\\sqrt{t}}z^{2/3}-\\frac{3\\Delta_{i}}{4}z\\right\\}\\leq1220\\sqrt{K}\\sum_{i\\not=k^{*}}\\frac{1}{\\Delta_{i}^{2}\\sqrt{T_{0}}}}}\\\\ &{}&{\\leq1220\\frac{\\sqrt{K}}{\\sqrt{T_{0}}}T_{0}}\\\\ &{}&{\\leq1220\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\underset{i\\not=k^{*}}{\\sum_{i\\not=k^{*}}}\\frac{1}{\\Delta_{i}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Finally, we use the bounds (21) and (22) in (19) and conclude that for some numerical constant $c$ we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{R}_{T}\\leq c\\sqrt{\\frac{K}{\\Delta_{*}}}\\sqrt{\\sum_{i\\neq k^{*}}\\frac{1}{\\Delta_{i}}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "B.3 Some Lemmas: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The following lemma is an adaptation of part 2 of Lemma 6 in 13 that bounds the stability term. Lemma B.3. We have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\ell_{t,A_{t}}+\\Phi_{t}(-\\hat{L}_{t})-\\Phi_{t}(-\\hat{L}_{t-1})\\right]\\le2\\eta_{t}\\mathbb{E}\\left[(1-p_{t,k^{*}})\\sum_{i\\neq k^{*}}p_{t,i}^{1/3}+K^{1/3}\\sum_{i\\neq k^{*}}p_{t,i}^{2/3}\\right]\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. We adapt the arguments presented in the proof of Lemma 6 in [13]. We use Lemma B.5, where we choose $x=\\mathbf{\\bar{1}}\\{B_{t}=\\mathbf{\\dot{k}}^{*}\\}\\bar{\\ell}_{t,k^{*}}$ . When $B_{t}\\neq k^{*}$ , we have $x\\,=\\,0$ and the expression is maximized for $\\tilde{p}_{i}=p_{t,i}$ , since the losses are non-negative, and $\\nabla\\Psi_{t}^{*}$ is monotonically increasing. When $B_{t}=k^{*}$ , we have $\\hat{\\ell}_{t,k^{*}}-x=0-x\\ge-1$ and we can apply Lemma B.6 and bound $\\tilde{p_{i}}^{4/3}$ by $(3/2)p_{t,i}^{4/3}$ . We conclude that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{i=1}^{K}\\tilde{p}_{i}\\!\\in\\![p_{t,i},\\!\\nabla\\Psi^{*}\\!\\left(\\nabla\\Psi_{t}(p_{t})\\!-\\!\\tilde{\\ell}_{t}\\!+\\!x1_{K}\\right)_{i}]^{\\frac{\\eta_{t}}{2}}\\left(\\hat{\\ell}_{t,i}-x\\right)^{2}\\left(\\tilde{p}_{t,i}\\right)^{4/3}\\right]}\\\\ &{\\leq\\displaystyle\\sum_{i\\neq k^{*}}\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[\\hat{\\ell}_{t,i}^{2}p_{t,i}^{4/3}\\right]+\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[\\left(\\hat{\\ell}_{t,k^{*}}-x\\right)^{2}(3/2)^{4/3}p_{t,i}^{4/3}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let us bound each term in the expression above. For the first term we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{\\neq k^{*}}\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[\\widehat{\\ell}_{t,i}^{2}p_{t,i}^{4/3}\\right]\\leq\\sum_{i\\neq k^{*}}\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[\\left(\\frac{\\mathbb{1}(B_{t}=i\\mathrm{~and~}A_{t}\\neq B_{t}^{\\prime})}{p_{t,i}^{2}}+\\frac{\\mathbb{1}\\left(B_{t}=i\\mathrm{~and~}A_{t}=B_{t}^{\\prime}\\right)}{r_{t,i}^{2}}\\right)\\bar{\\ell}_{t,i}^{2}p_{t,i}^{4/3}\\right]\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{t-1}\\left[\\mathbb{1}\\big(B_{t}=i\\mathrm{~and~}A_{t}\\neq B_{t}^{\\prime}\\big)\\right]=\\mathbb{P}_{t-1}\\left(A_{t}\\neq B_{t}^{\\prime}\\right)\\mathbb{P}\\left(B_{t}=i\\mid A_{t}\\neq B_{t}^{\\prime}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\left(1-\\|p_{t}\\|^{2}\\right)p_{t,i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Similarly, we show that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t-1}\\left[\\mathbb{1}\\left(B_{t}=i\\;\\mathrm{and}\\;A_{t}=B_{t}^{\\prime}\\right)\\right]=\\left\\|\\pmb{{p}}_{t}\\right\\|^{2}\\;r_{t,i}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{i\\neq k^{*}}\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[\\hat{\\ell}_{t,i}^{2}p_{t,i}^{4/3}\\right]\\leq\\sum_{i\\neq k^{*}}\\frac{\\eta_{t}}{2}\\mathbb{E}\\left[(1-\\|p_{t}\\|^{2})p_{t,i}^{1/3}+\\frac{\\left\\Vert p_{t}\\right\\Vert^{2}}{r_{t,i}}p_{t,i}^{4/3}\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For the second term in (23)we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\hbar}{2}\\mathbb{E}\\left[\\left(\\widehat{\\ell}_{t,k^{*}}-x\\right)^{2}(3/2)^{4/3}p_{t,i}^{4/3}\\right]\\leq\\eta_{t}\\mathbb{E}\\left[\\mathbb{1}\\big(B_{t}=k^{*}\\big)\\left(\\displaystyle\\frac{\\mathbb{1}\\left(A_{t}\\neq B_{t}^{\\prime}\\right)}{p_{t,k^{*}}}+\\displaystyle\\frac{\\mathbb{1}\\left(A_{t}=B_{t}^{\\prime}\\right)}{r_{t,k^{*}}}-1\\right)^{2}\\bar{\\ell}_{t,k^{*}}^{2}p_{t,k^{*}}\\right]}\\\\ {=\\eta_{t}\\mathbb{E}\\left[\\left\\{(1-\\|p_{t}\\|^{2})p_{t,k^{*}}\\left(\\displaystyle\\frac{1}{p_{t,k^{*}}}-1\\right)^{2}+\\|p_{t}\\|^{2}\\,r_{t,k^{*}}\\left(\\displaystyle\\frac{1}{r_{t,k^{*}}}-\\frac{1}{r_{t,k^{*}}}\\right)p_{t,k^{*}}\\right\\}\\right]}\\\\ {\\leq\\eta_{t}\\mathbb{E}\\left[(1-\\|p_{t}\\|^{2})(1-p_{t,k^{*}})^{2}p_{t,k^{*}}^{1/3}+\\|p_{t}\\|^{2}\\,\\frac{\\left(1-r_{t,k^{*}}\\right)^{2}}{r_{t,k^{*}}}p_{t,k^{*}}^{4/3}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Finally, we inject the bounds (24) and (25) into (23), rearranging the terms we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{i=1}^{K}\\hat{p}_{i}\\{\\boldsymbol{p}_{i,\\},\\nabla\\psi_{i}^{\\mathrm{max}},\\hat{\\boldsymbol{\\tau}}_{t+1,\\epsilon}\\}_{i}\\frac{\\eta_{t}}{2}\\left(\\hat{\\ell}_{t,i}-\\boldsymbol{x}\\right)^{2}\\left(\\hat{p}_{t,i}\\right)^{4/3}\\right]}\\\\ &{\\le\\underbrace{\\eta_{t}\\mathbb{E}\\left[(1-\\|\\boldsymbol{p}_{t}\\|^{2})\\left((1-p_{t,k})^{2}p_{t,k}^{1/3}+\\displaystyle\\sum_{i\\neq k^{*}}p_{t,i}^{1/3}\\right)\\right]}_{\\mathbb{T}\\mathrm{em}}}\\\\ &{\\qquad+\\underbrace{\\eta_{t}\\mathbb{E}\\left[\\|\\boldsymbol{p}_{t}\\|^{2}\\left(\\frac{\\left(1-r_{t,k^{*}}\\right)^{2}}{r_{t,k}}p_{t,k^{*}}^{4/3}+\\displaystyle\\sum_{i\\neq k^{*}}\\frac{p_{t,i}^{4/3}}{r_{t,i}}\\right)\\right]}_{\\hat{\\eta}_{t,k^{*}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Upper bounding Term 1: We have: ", "text_level": 1, "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left((1-\\|p_{t}\\|^{2})\\left((1-p_{t,k})^{2}p_{t,k}^{1/3}+\\displaystyle\\sum_{i\\neq j\\neq k}p_{t,i}^{1/3}\\right)\\right)\\leq\\eta_{t}\\mathbb{E}\\left[(1-\\|p_{t}\\|^{2})\\left((1-p_{t,k})+\\displaystyle\\sum_{i\\neq j\\neq k^{\\star}}p_{t,i}^{1/3}\\right)\\right]}&{}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\eta_{t}\\mathbb{E}\\left[(1-\\|p_{t}\\|^{2})\\left(\\displaystyle\\sum_{i\\neq j\\neq k^{\\star}}p_{t,i}^{1/3}+\\displaystyle\\sum_{i\\neq k^{\\star}}p_{t,i}^{1/3}\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2\\eta_{t}\\mathbb{E}\\left[(1-\\|p_{t}\\|^{2})\\displaystyle\\sum_{i\\neq j\\neq k^{\\star}}p_{t,i}^{1/3}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2\\eta_{t}\\mathbb{E}\\left[(1-p_{t,k^{\\star}})\\displaystyle\\sum_{i\\neq j\\neq k^{\\star}}p_{t,i}^{1/3}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Upper bounding Term 2: We have: ", "text_level": 1, "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{(1-r_{s,k})^{2}}{r_{s,k}-r_{s}+\\gamma_{s,k}}\\rho_{k,k}^{(3)}}&{\\leq\\eta_{k}\\mathbb{E}\\left[\\frac{(1-r_{s,k})^{2}}{r_{s,k}}\\rho_{k,k}^{(3)}+\\sum_{i=1}^{p}\\frac{R_{i}^{(4)}}{r_{s,i}}\\right]}\\\\ &{\\leq\\eta_{k}\\mathbb{E}\\left[\\frac{(1-r_{s,k})}{r_{s,k}}\\rho_{k,k}^{(4)}+\\sum_{i=1}^{p}\\frac{R_{i}^{(4)}}{r_{s,i}^{(4)}}\\left(\\sum_{j=1}^{p}\\rho_{k,j}^{(2)}\\right)\\right]}\\\\ &{=\\eta_{k}\\mathbb{E}\\left[\\frac{\\sum_{i,j\\leq k}r_{s,i}}{\\rho_{k,k}^{(2)}}\\left(\\sum_{j=1}^{p}\\rho_{k,j}^{(2)}\\right)\\rho_{k,k}^{(4)}+\\left(\\sum_{i\\geq k}\\rho_{k,i}^{(2)}\\right)\\left(\\sum_{j=1}^{K}\\rho_{j,j}^{(2)}\\right)\\right.}\\\\ &{\\leq\\eta_{k}\\mathbb{E}\\left[\\left(\\sum_{j=k}p_{k,j}^{(2)}\\right)\\rho_{k,k}^{(2)}+\\left(\\sum_{i\\neq k}\\rho_{k,i}^{(2)}\\right)\\left(\\sum_{j=1}^{K}\\rho_{j,j}^{(3)}\\right)\\right]}\\\\ &{\\leq2\\eta_{k}K^{1/2}\\mathbb{E}\\left[\\sum_{j\\neq k}p_{k,i}^{(2)}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where we used in the last line Jensen\u2019s inequality for the concave function $x\\to x^{2/3}$ . ", "page_idx": 20}, {"type": "text", "text": "The following lemma is a direct consequence of the second part of Lemma 7 in 13 where we take $\\alpha=2/3$ and $\\bar{\\beta}=K^{-1/6}$ . It provides a bound on the penalty term: ", "page_idx": 21}, {"type": "text", "text": "Lemma B.4 (Part 2 of Lemma 7 in 13). For \u03b7t = 2K\u221a\u2212t1/6, the penalty term satisfies: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\Phi_{t}(-\\hat{L}_{t-1})-\\Phi_{t}(-\\hat{L}_{t})-\\ell_{t,k^{*}}\\right]\\leq\\frac{9}{8}K^{1/6}\\sum_{k\\neq k^{*}}\\sum_{t=1}^{T}\\frac{\\mathbb{E}\\left[p_{t,k}\\right]^{2/3}}{\\sqrt{t}}+\\frac{9}{4}\\sqrt{K}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Our algorithm uses the Tsallis-inf framework introduced by [22] and [13]. We use a learning rate \u03b7t = $\\begin{array}{r}{\\eta_{t}=\\frac{2\\beta}{\\sqrt{t}}}\\end{array}$ , with $\\beta=K^{-1/6}$ . Moreover, the loss estimator we use defined by (11) is unbiased. Therefore the statement of Lemma 7 from [13] applies. The expression in the lemma follows by taking $\\alpha=2/3$ and $\\beta=K^{-1/6}$ . \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Lemma B.5. Lemma $\\iota\\,I0\\,i n\\,[I3J\\,L e t\\,p_{t}=\\nabla\\Phi_{t}\\left(-\\tilde{L}_{t-1}\\right)f o r\\,\\tilde{L}_{t}=\\tilde{L}_{t-1}+\\tilde{\\ell}_{t},$ , where $\\tilde{\\ell}_{t}$ is an unbiased estimate of $\\ell_{t}$ . For any $x\\geq0$ , the instantaneous stability of the pseudo-regret of Algorithm $^{4}$ satisfies: $\\upxi\\left[\\ell_{t,A_{t}}+\\Phi_{t}\\left(-\\tilde{L}_{t}\\right)-\\Phi_{t}(-\\tilde{L}_{t-1})\\right]\\leq\\mathbb{E}\\left[\\sum_{i=1}^{K}\\operatorname*{max}_{\\tilde{p}_{i}\\in[p_{t,i},\\nabla\\Psi^{*}\\left(\\nabla\\Psi_{t}(p_{t})-\\tilde{\\ell}_{t}+x\\mathbf{1}_{K}\\right)_{i}]}\\frac{\\eta_{t}}{2}\\left(\\tilde{\\ell}_{t,i}-x\\right)^{2}\\left(\\tilde{p}_{t,i}\\right)^{2}\\right]$ ", "page_idx": 21}, {"type": "text", "text": "Proof. Recall that our loss estimators (11) are unbiased and the played arm $A_{t}$ is selected following the same rule as in [13]. Therefore the statement of Lemma 10 in [13] applies. ", "page_idx": 21}, {"type": "text", "text": "Lemma B.6. Lemma 11 in [13] Let $p\\in S^{K-1}$ and $\\tilde{p}=\\nabla\\Psi_{t}^{*}\\left(\\nabla\\Psi_{t}(p)-\\ell\\right)$ . If $\\eta_{t}\\leq1/4$ then for all \u2113i \u2265\u22121 it holds that p\u02dci4/3\u226432pi4 ", "page_idx": 21}, {"type": "text", "text": "C Proof of Theorem 4.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Proving Theorem 4.2 amounts to combining the previous results. We have using Lemma A.1: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T,A}^{(w)}\\right]\\leq\\mathbb{E}\\left[R_{T,A^{\\prime}}^{(s)}\\right].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Furthermore, using Lemma A.2, we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T,A^{\\prime}}^{\\left(s\\right)}\\right]\\leq\\mathbb{E}\\left[R_{-1,T}^{\\prime}\\right].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now let us show how the problem of upper-bounding the regret above related to the analysis of the modified OMD with Tsallis-INF regularizer in Algorithm 4 developed in Section B. ", "page_idx": 21}, {"type": "text", "text": "The regret $R_{-1,T}^{\\prime}$ is with respect to a learner playing with the following strategy: In each round $t\\in[T]$ ", "page_idx": 21}, {"type": "text", "text": "\u2022 The learner samples $I_{t}^{\\prime}$ from $\\scriptstyle{p_{t}}$ .   \n\u2022 The learner plays $I_{t}^{\\prime}$ and incurs $\\ell_{t,I_{t}^{\\prime}}=X_{t}(I_{t}^{\\prime},J_{t}^{\\prime})$ where $J_{t}^{\\prime}$ is independently sampled from $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ .   \n\u2022 The learner samples $J_{t}$ using: \u2013 from $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ if an event with probability $1-\\left\\|p_{t}\\right\\|^{2}$ holds. \u2013 from $\\mathbf{\\boldsymbol{r}}_{t}$ if an event with probability $\\|\\boldsymbol{p}_{t}\\|^{2}$ holds.   \n\u2022 The learner observes the feedback $X_{t}(J_{t},I_{t})$ where $I_{t}$ is independently sampled using $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ . ", "page_idx": 21}, {"type": "text", "text": "Comparing the strategy above with the game protocol 3 and Algorithm 4 of Section B, we conclude that: $A_{t}$ plays the same role as $I_{t}^{\\prime}$ , and $J_{t}$ plays the same role as $B_{t}$ . Moreover, the losses observed $X_{t}(k,I_{t})$ corresponding to $\\bar{\\ell}_{t,k}$ are independent but follow the same distribution as the actual losses $X_{t}(k,J_{t}^{\\prime})$ corresponding to $\\ell_{t,k}$ . ", "page_idx": 21}, {"type": "text", "text": "Finally in order to apply Theorem B.2, we need to check whether the regret $R_{-1,T}^{\\prime}$ satisfies the necessary self-bounding condition (condition considered in Section B). The last requirement is a direct consequence of Lemma A.2. ", "page_idx": 21}, {"type": "text", "text": "Therefore, the bound in Theorem B.2 applies and gives the result. ", "page_idx": 21}, {"type": "text", "text": "D Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We restate here the theorem: ", "page_idx": 22}, {"type": "text", "text": "Theorem D.1. Under the assumption of the existence of a Condorcet winner, the weak regret of Algorithm 2 satisfies: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T}^{(w)}\\right]\\leq c\\log(K/\\Delta_{*})\\sum_{k\\neq k^{*}}\\frac{K\\Delta_{k^{*},k}}{\\Delta_{j^{*}(k),k}^{2}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where for each $k\\ \\ \\neq\\ \\ k^{*}\\colon\\ \\ j^{*}(k)\\ \\ \\in\\ \\ \\arg\\operatorname*{max}_{j}\\Delta_{j,k}$ , $\\begin{array}{r c l}{{\\Delta_{*}}}&{{=}}&{{\\displaystyle\\operatorname*{min}_{k\\neq k^{*}}\\Delta_{k^{*},k}}}\\end{array}$ and $\\begin{array}{r l}{c}&{{}=}\\end{array}$ $c^{\\prime}\\operatorname*{max}\\{1,\\log\\log\\log(K\\vee16)\\}$ with $c^{\\prime}$ an absolute constant. ", "page_idx": 22}, {"type": "text", "text": "Proof. Notation: Let ${\\mathcal F}_{t}\\ =\\ \\sigma\\left((I_{1},J_{1}),X_{1}(I_{1},J_{1}),\\ldots,(I_{t},J_{t}),X_{t}(I_{t},J_{t})\\right)$ . Following Algorithm 2, we run EXP3-IX Algorithm for each arm $k$ in each phase (a phase corresponds to a fixed value of the parameter $B$ ), during the $n^{t h}$ increment of the value $B$ (phase number $n$ ) we have $B=-2^{n-1}$ . When we fix arm $k$ as a left arm and run EXP3-IX to choose the right arm for $t$ rounds, we denote by $S(k,n,t)$ the obtained cumulative loss: ", "page_idx": 22}, {"type": "equation", "text": "$$\nS(k,n,t):=\\sum_{s=1}^{t}\\bigg(X_{s}(k,J_{s})-\\frac{1}{2}\\bigg)\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "More rigorously, the sum above is over rounds between $\\tau+1$ and $\\tau+t$ , where $\\tau$ is a variable independent of the considered cumulative loss. We consider the notation above to simplify the proof. ", "page_idx": 22}, {"type": "text", "text": "We define, for each $\\textit{k}\\in\\ [K]$ and $n~\\ge~1$ , by $\\tau_{k}^{(n)}$ as the stoppin\u221ag time, with respect to $\\left(\\mathcal{F}_{t}\\right)$ , corresponding to the round where $(S(k,n,t))_{t}$ hits the level $-2^{n-1}{\\sqrt{t}}$ for the first time: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tau_{k}^{(n)}:=\\operatorname*{min}\\left\\{t\\geq1:S(k,n,t)<-2^{n-1}\\sqrt{t}\\right\\}\\;\\;.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We call phase, the time interval in Algorithm 2 between two increments of the variable $B$ . More formally, phase number $n$ corresponds to the number of rounds $t$ such that $\\tau_{K}^{(n)}<t\\leq\\tau_{K}^{(n+1)}$ ", "page_idx": 22}, {"type": "text", "text": "For $k\\leq K$ and a positive $n$ , let $E_{k}^{(n)}$ denote the following event ", "page_idx": 22}, {"type": "equation", "text": "$$\nE_{k}^{(n)}=\\{\\tau_{k-1}^{(n)}<+\\infty\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We use the following \u03c4 (K0) $\\tau_{K}^{(0)}=0$ , $\\tau_{0}^{(n)}:=\\tau_{K}^{(n-1)}$ for each $n\\geq1$ . The expected regret incurred at phase $n$ satisfies: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{T}^{(n)}\\ |\\ E_{1}^{(n)}\\right]\\leq\\displaystyle\\sum_{k=1}^{K}\\mathbb{P}\\left(E_{k}^{(n)}\\ |\\ E_{1}^{(n)}\\right)\\mathbb{E}\\left[\\sum_{t=1}^{\\tau_{k}^{(n)}}\\operatorname*{min}\\left\\{\\Delta_{k^{*},k},\\Delta_{k^{*},J_{t}}\\right\\}\\mid E_{k}^{(n)}\\right]}\\\\ &{\\leq\\displaystyle\\sum_{k=1}^{K}\\mathbb{P}\\left(E_{k}^{(n)}\\ |\\ E_{1}^{(n)}\\right)\\mathbb{E}\\left[\\sum_{t=1}^{\\tau_{k}^{(n)}}\\Delta_{k^{*},k}\\mid E_{k}^{(n)}\\right]}\\\\ &{=\\displaystyle\\sum_{k=1}^{K}\\Delta_{k^{*},k}\\,\\mathbb{P}\\left(E_{k}^{(n)}\\mid E_{1}^{(n)}\\right)\\mathbb{E}\\left[\\tau_{k}^{(n)}\\mid E_{k}^{(n)}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore the weak regret of Algorithm 2 satisfies: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{T}\\right]\\leq\\displaystyle\\sum_{n=1}^{+\\infty}\\mathbb{P}(E_{1}^{(n)})\\mathbb{E}\\left[R_{T}^{(n)}\\mid E_{1}^{(n)}\\right]}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{n=1}^{+\\infty}\\sum_{k=1}^{K}\\mathbb{P}(E_{k}^{(n)})\\Delta_{k^{*},k}\\,\\mathbb{E}\\left[\\tau_{k}^{(n)}\\mid E_{k}^{(n)}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Define by $U_{k}$ the quantity: ", "page_idx": 22}, {"type": "equation", "text": "$$\nU_{k}:=\\frac{K\\log(K)}{\\Delta_{j^{*}(k),k}^{2}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Using Lemma D.2. We have for some numerical constant $c>0$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{T}\\right]\\leq c\\sum_{n=1}^{+\\infty}\\sum_{k=1}^{K}\\mathbb{P}(E_{k}^{(n)})\\Delta_{k^{*},k}\\;\\left(U_{k}+\\frac{4^{n}}{\\Delta_{j^{*}(k),k}^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{T}\\right]\\leq c\\displaystyle\\sum_{n=1}^{+\\infty}\\displaystyle\\sum_{k=1}^{K}\\mathbb{P}(E_{k}^{(n)})\\Delta_{k^{*},k}\\ \\left(U_{k}+\\frac{4^{n}}{\\Delta_{j^{*}(k),k}^{2}}\\right)}\\\\ &{\\qquad\\qquad=c\\displaystyle\\sum_{n=1}^{+\\infty}\\sum_{k=1}^{K}\\mathbb{P}(E_{k}^{(n)})\\Delta_{k^{*},k}U_{k}+\\displaystyle\\sum_{n=1}^{+\\infty}\\sum_{k=1}^{K}\\mathbb{P}(E_{k}^{(n)})\\Delta_{k^{*},k}\\frac{4^{n}}{\\Delta_{j^{*}(k),k}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let $N=\\log_{4}(1\\vee\\log(1\\vee\\log_{2}(1/\\Delta_{*})))$ , therefore we have $\\exp(2^{2N})\\geq\\log_{2}(1/\\Delta_{*})$ . Therefore, using Lemma D.3, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n=1}^{+\\infty}\\mathbb{P}\\left(E_{k}^{(n)}\\right)\\leq1+\\sum_{n=2}^{+\\infty}\\operatorname*{min}\\left\\{1,\\frac{\\exp(-2^{2n-2})}{4\\log(2)}\\left(1-8\\log\\left(\\operatorname*{min}\\{1,2^{n-2}\\Delta_{*}\\}\\right)\\right)\\right\\}}\\\\ &{\\leq1+\\displaystyle\\sum_{n=2}^{+\\infty}\\operatorname*{min}\\left\\{1,\\frac{\\exp(-2^{2n-2})}{4\\log(2)}9\\log\\left(1/\\Delta_{*}\\right)\\right\\}}\\\\ &{\\leq1+\\displaystyle\\sum_{n=2}^{+\\infty}\\operatorname*{min}\\left\\{1,5\\exp(2^{2N}-2^{2n-2})\\right\\}}\\\\ &{\\leq1+N+\\displaystyle\\sum_{n=(N+2)\\vee2}^{\\infty}\\quad5\\exp(-2^{2(n-N)-2})\\leq N+4.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Moreover, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n=1}^{+\\infty}4^{n}\\mathbb{P}\\left(E_{k}^{(n)}\\right)\\leq4+\\sum_{n=2}^{+\\infty}4^{n}\\frac{\\exp(-2^{2n-2})}{4\\log(2)}\\left(1-8\\log\\left(\\operatorname*{min}\\{1,2^{n-2}\\Delta_{*}\\}\\right)\\right)}\\\\ &{\\displaystyle\\leq4+\\frac{9\\log(1/\\Delta_{*})}{4\\log(2)}\\sum_{n=2}^{+\\infty}4^{n}\\exp(-2^{n-2})}\\\\ &{\\displaystyle<4+150\\log(1/\\Delta_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "2FiKn allolgy( Kwe/ \u2206plu) gm (a2x7{)1 , alnodg  l(o2g8 l)o gin(tKo  (\u22282166) )}a,n tdo  ucsoen ctlhued ef.act that K log(K)N + log(1/\u2206\u2217) \u2264 ", "page_idx": 23}, {"type": "text", "text": "D.1 Auxiliary Lemmas ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We recall the notation: for each $k\\,\\in\\,[K]$ , let $j^{*}(k)\\,\\in\\,\\arg\\operatorname*{min}_{j\\in[K]\\backslash\\{k\\}}\\Delta_{k,j}$ . Therefore, $j^{*}(k)$ represents the arm with the largest chance to beat arm $k$ . Moreover, let $S(k,n,t)$ denote the cumulative loss obtained when running EXP3-IX algorithm in phase $n$ for arm $k$ . For $n\\geq1$ , let $\\tau_{k}^{(n)}$ den\u221aote the stopping time corresponding to the round where the process $S(k,n,t)$ hits the level $-2^{n-1}{\\sqrt{t}}$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\tau_{k}^{(n)}:=\\operatorname*{min}\\left\\{t\\geq1:S(k,n,t)\\leq-2^{n-1}\\sqrt{t}\\right\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Lemma D.2. Let $k\\in[K]\\setminus\\{k^{*}\\}$ , then we have for any $n>0$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\tau_{k}^{(n)}\\mid\\tau_{k-1}^{(n)}<+\\infty\\right]\\le c\\frac{K\\log(K)}{\\Delta_{j^{*}(k),k}^{2}}+c\\frac{4^{n}}{\\Delta_{j^{*}(k),k}^{2}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where c is an absolute constant. ", "page_idx": 23}, {"type": "text", "text": "Proof. Fix $k\\in[K]\\setminus\\{k^{*}\\}$ and $n\\geq1$ . Suppose that $\\{\\tau_{k-1}^{(n)}<+\\infty\\}$ holds. Recall the definition of $S(k,n,t)$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\nS(k,n,t):=\\sum_{s=1}^{t}\\bigg(X_{s}(k,J_{s})-\\frac{1}{2}\\bigg)\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "To ease notation we will focus only on the rounds where the fixed arm $k$ was chosen as a left arm in phase $n$ . Recall that at each phase when we consider a new arm, we run EXP3-IX from scratch, therefore the obtained cumulative loss process is independent from the past. Denote by $Y_{j,s}$ the sample received when choosing $j$ as a right arm at round $s$ , $Y_{j,s}$ has the same distribution as the variable $X(k,j)-1/2$ , hence $\\mathbb{E}[Y_{j,u}]\\,=\\,\\Delta_{k,j}$ . In each round $u$ , the chosen arm is denoted $A_{u}$ . Therefore we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\nS(k,n,t)=\\sum_{s=1}^{t}Y_{A_{s},s}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let $j^{*}\\in\\arg\\operatorname*{min}_{j}\\{\\Delta_{k,j}\\}\\;(j^{*}=j^{*}(k)$ , we just dropped the dependence on $k$ ). Let ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\Delta:=\\Delta_{k,j^{*}}<0,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "$\\Delta$ is negative because $k$ is not the Condorcet winner (remember we fixed $k\\in[K]\\setminus\\{k^{*}\\})$ . Define the (random) regret for this problem after $t$ rounds as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\nR_{t}=\\sum_{s=1}^{t}Y_{A_{s},s}-\\sum_{s=1}^{t}Y_{j^{*},s}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Our objective is to upper-bound the expectation of the stopping time $\\tau_{k}^{(n)}$ . To develop such a bound we use the identity: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\tau_{k}^{(n)}\\mid\\tau_{k-1}^{(n)}<+\\infty\\right]=\\sum_{N=0}^{+\\infty}\\mathbb{P}\\left(\\tau_{k}^{(n)}>N\\mid\\tau_{k-1}^{(n)}<+\\infty\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In the remainder of this proof all events are assumed to hold conditionally to $\\{\\tau_{k-1}^{(n)}<+\\infty\\}$ . Let us bound the probabilities in the rhs: Fix $m\\geq n$ and let ", "page_idx": 24}, {"type": "equation", "text": "$$\nN_{m}:=\\lceil\\frac{K}{\\Delta^{2}}+\\frac{2^{m}}{\\Delta^{2}}\\rceil,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\Delta$ is defined by (29). Recall that con\u221aditional to $\\{\\tau_{k-1}^{(n)}<+\\infty\\}$ the event $\\{\\tau_{k}^{(n)}>N_{m}\\}$ implies in particular that $\\begin{array}{r}{\\{\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}\\sqrt{N_{m}}\\}}\\end{array}$ . Therefore: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\tau_{k}^{(n)}>N_{m}\\right)\\le\\mathbb{P}\\left(\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}\\sqrt{N_{m}}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let us upper bound the probability of the last event. We have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\phantom{\\frac{1}{b}}_{i},t>-2^{n-1}\\sqrt{N_{m}}\\alpha\\Bigg)=\\mathbb{P}\\left(\\underset{t=1}{\\overset{N_{m}}{\\sum}}Y_{A_{t},t}-\\underset{t=1}{\\overset{N_{m}}{\\sum}}Y_{j^{*},t}+\\underset{t=1}{\\overset{N_{m}}{\\sum}}Y_{j^{*},t}-N_{m}\\Delta>-2^{n-1}\\sqrt{N_{m}}-N_{m}\\Delta\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbb{P}\\left(R_{N_{m}}+\\underset{t=1}{\\overset{N_{m}}{\\sum}}Y_{j^{*},t}-N_{m}\\Delta>-2^{n-1}\\sqrt{N_{m}}-N_{m}\\Delta\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathbb{P}\\left(R_{N_{m}}>7x\\sqrt{K N_{m}\\log(K)}\\right)}\\\\ &{\\qquad\\qquad+\\mathbb{P}\\left(\\underset{t=1}{\\overset{N_{m}}{\\sum}}Y_{j^{*},t}-N_{m}\\Delta>-2^{n-1}\\sqrt{N_{m}}-N_{m}\\Delta-7x\\sqrt{K N_{m}\\log(K)}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $x$ is any constant larger than 1. Using the definition of $N_{m}$ (recall that $\\Delta<0$ ), we have $-N_{m}\\Delta\\geq-2^{m}/\\Delta$ . Therefore ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}\\sqrt{N_{m}}\\,\\Bigg)\\leq\\mathbb{P}\\left(R_{N_{m}}>7x\\sqrt{K N_{m}\\log(K)}\\right)}}\\\\ &{}&{\\quad+\\,\\mathbb{P}\\left(\\sum_{t=1}^{N_{m}}Y_{j^{*},t}-N_{m}\\Delta>-2^{n-1}\\sqrt{N_{m}}-\\frac{2^{m}}{\\Delta}-7x\\sqrt{K N_{m}\\log(\\Delta)}\\right)}\\\\ &{}&{\\quad\\leq\\mathbb{P}\\left(R_{N_{m}}>7x\\sqrt{K N_{m}\\log(K)}\\right)}\\\\ &{}&{\\quad+\\,\\mathbb{P}\\left(\\sum_{t=1}^{N_{m}}Y_{j^{*},t}-N_{m}\\Delta>-2^{n-1}\\sqrt{N_{m}}-\\frac{2^{m}}{\\Delta}-7x\\sqrt{K N_{m}\\log(\\Delta)}\\right)}\\\\ &{}&{\\quad\\quad.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Now let us take: ", "page_idx": 25}, {"type": "equation", "text": "$$\nx={\\frac{-2^{m}}{28|\\Delta|{\\sqrt{K N_{m}\\log(K)}}}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Define $\\bar{n}$ as the smallest integer in $[2n+3,+\\infty)$ such that ", "page_idx": 25}, {"type": "equation", "text": "$$\n2^{\\bar{n}}\\geq28\\Delta\\sqrt{K N_{\\bar{n}}\\log(K)}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hence $2^{\\bar{n}}\\geq K$ . Moreover, for $m\\geq\\bar{n}$ , we have: $x\\geq1$ . Furthermore: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2^{n-1}\\sqrt{N_{m}}<2^{n-1}\\sqrt{4\\operatorname*{max}\\left\\{\\cfrac{K}{\\Delta^{2}},\\frac{2^{m}}{\\Delta^{2}}\\right\\}}}\\\\ &{\\phantom{2p c}\\leq2^{n-1}\\sqrt{4\\frac{2^{m}}{\\Delta^{2}}}=-\\frac{2^{\\frac{m}{2}+n}}{\\Delta}}\\\\ &{\\phantom{2p c}\\leq-\\frac{2^{m-3/2}}{\\Delta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we used $m\\geq\\bar{n}\\geq2n+3$ . ", "page_idx": 25}, {"type": "text", "text": "Using (31): ", "page_idx": 25}, {"type": "equation", "text": "$$\n>\\left(\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}\\sqrt{N_{m}}\\right)\\leq\\mathbb{P}\\left(R_{N_{m}}>7x\\sqrt{K N_{m}\\log(K)}\\right)+\\mathbb{P}\\left(\\sum_{t=1}^{N_{m}}Y_{j^{*},t}-N_{m}\\Delta>-\\frac{2^{m-1}\\sqrt{K N_{m}\\log(K)}}{\\Delta}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using Theorem D.5 to bound the first term (recall that by definition of $\\bar{n}$ , for $m\\geq\\bar{n};\\,x\\geq1)$ ), and Hoeffding\u2019s inequality to bound the second term we obtain: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}\\sqrt{N_{m}}\\right)\\leq2\\exp\\left(-x\\sqrt{\\log(K)}\\right)+\\exp\\left(-\\frac{2^{2m-4}}{\\Delta^{2}N_{m}}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Let us upper-bound the r.h.s of the inequality above. We have for $m\\geq\\bar{n}$ : ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\exp\\left(-x\\sqrt{\\log(K)}\\right)=\\exp\\left(-\\frac{2^{m}\\sqrt{\\log(K)}}{28|\\Delta|\\,\\sqrt{K N_{m}\\log(K)}}\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using (30) we have that $\\begin{array}{r}{N_{m}\\le\\frac{2^{m}}{\\Delta^{2}}}\\end{array}$ , therefore $\\begin{array}{r}{\\frac{1}{\\sqrt{N_{m}}}\\geq\\frac{|\\Delta|}{2^{m/2}}}\\end{array}$ we get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\exp\\left(-x\\sqrt{\\log(K)}\\right)\\le\\exp\\left(-\\frac{2^{m}\\sqrt{\\log(K)}}{28\\Delta\\sqrt{K\\log(K)}}\\cdot\\frac{|\\Delta|}{2^{m/2}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\le\\exp\\left(-\\frac{2^{m/2}}{28}\\sqrt{\\frac{1}{K}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we used the definition of $N_{m}$ . The second term in (34) can be bounded for $m\\geq\\bar{n}$ following: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\exp\\left(-\\frac{2^{2m-4}}{\\Delta^{2}N_{m}}\\right)\\leq\\exp\\left(-2^{m-4}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining (34), (35) and (36) we conclude that: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\displaystyle\\sum_{t=1}^{N_{m}}Y_{A_{t},t}>-2^{n-1}-\\sqrt{N_{m}}\\right)\\leq2\\exp\\left(-\\displaystyle\\frac{2^{m/2}}{28}\\sqrt{\\frac{1}{K}}\\right)+\\exp\\left(-2^{m-4}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq3\\exp\\left(-\\displaystyle\\frac{2^{m/2}}{28}\\sqrt{\\frac{1}{K}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We conclude that for $m\\geq\\bar{n}$ : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\tau_{k}^{(n)}>N_{m}\\mid\\tau_{k-1}^{(n)}<+\\infty\\right)\\leq3\\exp\\left(-\\frac{2^{m/2}}{28}\\sqrt{\\frac{1}{K}}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\tau_{k}^{(n)}\\ |\\tau_{k-1}^{(n)}<\\infty\\right]=}&{\\displaystyle\\sum_{N=0}^{+\\infty}\\mathbb{P}\\left(\\tau_{k}^{(n)}>N\\ |\\tau_{k-1}^{(n)}<+\\infty\\right)}\\\\ &{\\le N_{+}+\\displaystyle\\sum_{N=1}^{+\\infty}\\mathbb{P}\\left(\\tau_{k}^{(n)}>N\\ |\\tau_{k-1}^{(n)}<+\\infty\\right)}\\\\ &{\\le N_{+}+\\displaystyle\\sum_{n=1}^{+\\infty}\\sum_{N=0}^{+\\infty}\\mathbb{P}\\left(\\tau_{k}^{(n)}>N\\ |\\tau_{k-1}^{(n)}<+\\infty\\right)}\\\\ &{\\le N_{+}+\\displaystyle\\sum_{n=1}^{+\\infty}N_{-n}^{-n-1}\\ \\mathbb{P}\\left(\\tau_{k}^{(n)}>N\\ |\\ \\tau_{k-1}^{(n)}<+\\infty\\right)}\\\\ &{\\le N_{+}+\\displaystyle\\sum_{n=1}^{+\\infty}\\left(N_{+n+1}-N_{m}\\right)\\mathbb{P}\\left(\\tau_{k}^{(n)}>N_{m}\\ |\\ \\tau_{k-1}^{(n)}<+\\infty\\right)}\\\\ &{\\le N_{+}+\\displaystyle\\sum_{n=1}^{+\\infty}\\left(\\frac{2n^{-1}}{\\Delta^{2}}+1\\right)\\exp\\left(-\\frac{2n^{-2}}{2\\Delta}\\sqrt{\\frac{1}{K}}\\right)}\\\\ &{=N_{+}+\\displaystyle\\sum_{n=1}^{\\infty^{2(n)}+\\infty}\\sum_{n=1}^{+\\infty}\\mathbb{P}\\left(-\\frac{2n^{-n-1}}{2\\Delta}\\big)^{2}\\frac{\\sqrt{2^{n}}}{K}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Recall that by definition of $\\bar{n}$ in (32), we have: $2^{\\bar{n}}\\geq K$ . Therefore: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\tau_{k}^{(n)}\\ |\\ \\tau_{k-1}^{(n)}<+\\infty\\right]\\leq N_{\\bar{n}}+6\\frac{2^{\\bar{n}}}{\\Delta^{2}}\\ \\displaystyle\\sum_{m=\\bar{n}}^{+\\infty}2^{m-\\bar{n}}\\exp\\left(-\\frac{2^{(m-\\bar{n})/2}}{28}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq N_{\\bar{n}}+6\\frac{2^{\\bar{n}}}{\\Delta^{2}}\\ \\displaystyle\\sum_{p=0}^{+\\infty}2^{p}\\exp\\left(-\\frac{2^{p/2}}{28}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Next we use the bound ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{p=0}^{+\\infty}2^{p}\\exp\\left(-\\frac{2^{p/2}}{28}\\right)\\le888.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We conclude using the definition of $N_{m}$ and $\\bar{n}$ that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\tau_{k}^{(n)}\\ \\vert\\ \\tau_{k-1}^{(n)}<+\\infty\\right]\\leq\\displaystyle\\frac{K}{\\Delta^{2}}+\\frac{2^{\\bar{n}}}{\\Delta^{2}}+6000\\ \\frac{2^{\\bar{n}}}{\\Delta^{2}}}\\\\ &{\\phantom{\\displaystyle\\mathbb{E}\\left[\\tau_{k}^{(n)}\\ \\vert\\ \\tau_{k-1}^{(n)}<+\\infty\\right]}\\leq\\displaystyle\\frac{K}{\\Delta^{2}}+c\\operatorname*{max}\\left\\{\\frac{2^{2n}}{\\Delta^{2}},\\ \\frac{K\\log(K)}{\\Delta^{2}}\\right\\}}\\\\ &{\\phantom{\\displaystyle\\mathbb{E}\\left[\\tau_{k}^{(n)}\\ \\vert\\ \\tau_{k-1}^{(n)}<+\\infty\\right]}\\displaystyle\\frac{K\\log(K)}{\\Delta^{2}}+c\\frac{4^{n}}{\\Delta^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma D.3. We have for any $n\\geq2$ , $k\\in[K]$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(E_{k}^{(n)}\\right)\\leq\\frac{\\exp(-2^{2n-2})}{4\\log(2)}\\left(1-8\\log(\\operatorname*{min}\\{1,2^{n-2}\\Delta_{*}\\})\\right),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\Delta_{*}=\\mathrm{min}_{k\\neq k^{*}}\\,\\Delta_{k^{*},k}$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. Let $n\\geq2$ and $k\\in[K]$ . We have that $E_{k}^{(n)}$ implies the event: $E_{k^{*}+1}^{(n-1)}$ . Therefore: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(E_{k}^{(n)}\\right)\\leq\\mathbb{P}\\left(E_{k^{*}+1}^{(n-1)}\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(\\tau_{k^{*}}^{(n-1)}<+\\infty\\right)}\\\\ &{\\qquad\\qquad\\leq\\frac{\\exp\\left(-2^{2n-2}\\right)}{4\\log(2)}\\left(1-8\\log(\\operatorname*{min}\\{1,2^{n-2}\\Delta_{*}\\})\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where we used in the last line Lemma F.3. ", "page_idx": 27}, {"type": "text", "text": "D.2 Deviation guarantees for the regret of EXP3-IX ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We recall below the algorithm EXP3-IX from [11] ", "page_idx": 27}, {"type": "table", "img_path": "dY4YGqvfgW/tmp/2a5366226b74a6c21a9c54ecaae5bfd6d8d6c3100bd7da6b8b2eba2088f44f04.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Define the random regret $R_{T}$ by: $\\begin{array}{r}{R_{T}:=\\sum_{t=1}^{T}\\ell_{I_{t},t}-\\operatorname*{min}_{i\\in[K]}\\sum_{t=1}^{T}\\ell_{i,t}}\\end{array}$ . We restate below the main result from [11]. ", "page_idx": 27}, {"type": "text", "text": "Theorem D.4. Theorem $^{\\,l}$ in [11]. Fix an arbitrary $\\delta\\in(0,1)$ , set $\\begin{array}{r}{\\eta_{t}=2\\gamma_{t}=\\sqrt{\\frac{\\log(K)}{K t}}}\\end{array}$ for all $t,$ , then EXP3-IX guarantees with probability at least $1-\\delta$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\nR_{T}\\leq4\\sqrt{K T\\log(K)}+\\left(2\\sqrt{\\frac{K T}{\\log(K)}}+1\\right)\\log(2/\\delta).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We have the following corollary ", "page_idx": 27}, {"type": "text", "text": "Corollary D.5. Fix $x\\geq1$ , and consider EXP3-IX algorithm with $\\begin{array}{r}{\\eta_{t}=2\\gamma_{t}=\\sqrt{\\frac{\\log(K)}{K t}}}\\end{array}$ , then: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(R_{T}\\leq7x\\sqrt{K T\\log(K)}\\right)\\leq2\\exp\\left(-x\\sqrt{\\log(K)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. Let $x\\geq1$ , take: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\delta=\\operatorname*{min}\\left\\{1,2\\exp\\left(-x{\\sqrt{\\log(K)}}\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Therefore: ", "page_idx": 27}, {"type": "equation", "text": "$$\nx\\geq\\frac{\\log(2/\\delta)}{\\sqrt{\\log(K)}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We have with probability at least $1-\\delta\\geq1-2\\exp(-x{\\sqrt{\\log(K)}})$ : ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T}\\leq4\\sqrt{K T\\log(K)}+\\left(2\\sqrt{\\frac{K T}{\\log(K)}}+1\\right)\\log(2/\\delta)}\\\\ &{\\quad\\leq7\\sqrt{K T}\\operatorname*{max}\\Big\\{\\sqrt{\\log(K)},\\log(2/\\delta)\\Big\\}}\\\\ &{\\quad=7\\sqrt{K T\\log(K)}\\operatorname*{max}\\bigg\\{1,\\frac{\\log(2/\\delta)}{\\sqrt{\\log(K)}}\\bigg\\}}\\\\ &{\\quad\\leq7x\\sqrt{K T\\log(K)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "E Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We restate the theorem for the lower bound, then we proceed with the proof. Let $\\Delta_{\\mathrm{cw}}$ denote a positive number. For a dueling bandits problem, we denote by $M=(M_{i,j})_{1\\geq i,j\\leq K}$ the matrix such that $M_{i,j}=\\Delta_{i,j}$ . Define the class of problems $\\mathbb{D}(\\Delta_{\\mathrm{cw}})$ by the set of matrices $M$ representing the gaps $(\\Delta_{i,j})_{i j}$ such as $M$ is skew-symmetric and there exists some $k^{*}\\in[K]$ such that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\mathrm{~}\\forall i\\neq k^{*}:M_{k^{*},i}=\\Delta_{\\mathrm{cw}}}\\\\ {\\mathrm{~}\\mathrm{and~}}\\\\ {\\mathrm{~}\\forall i,j\\neq k^{*}:|M_{i,j}|\\leq\\Delta_{\\mathrm{cw}}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $k^{*}\\in[K]$ denotes the Condorcet winner. ", "page_idx": 28}, {"type": "text", "text": "Theorem E.1. Fix $K\\geq6$ , $\\Delta_{c w}\\in(0,1/4)$ . The weak regret of an algorithm $\\boldsymbol{\\mathcal{A}}$ satisfies: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{M\\in\\mathbb{D}(\\Delta_{c w})}\\mathbb{E}_{M,A}\\left[R_{T}\\right]\\geq c\\frac{K}{\\Delta_{c w}},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "when $T\\geq c^{\\prime}K/\\Delta_{c w}^{2}$ . Here $c$ and $c^{\\prime}$ are numerical constants. ", "page_idx": 28}, {"type": "text", "text": "Proof. Let $M^{(0)}$ denote a matrix such that $M_{1,i}^{(0)}=\\Delta_{c w}$ for any $i>1$ and $M_{i,j}^{(0)}=0$ for $i,j\\neq1$ Let $\\mathbb{P}_{0}$ denote the probability distribution associated with the dueling bandits\u2019 problem with matrix $M^{(0)}$ (where arm 1 is the Condorcet winner). ", "page_idx": 28}, {"type": "text", "text": "Let $k\\neq1$ , let $M^{(k)}$ denote the matrix defined by: for all $u\\ne k\\ M_{k,u}^{(k)}=\\Delta_{c w}=-M_{u,k}^{(k)}$ , for all $i\\neq k\\ M_{1,i}^{(k)}=\\Delta_{\\mathrm{cw}}=-M_{i,1}^{(k)}$ , otherwise for $i\\neq k,1$ and $j\\neq k,1\\colon M_{i,j}^{(k)}=0$ . Let $\\mathbb{P}_{k}$ denote the probability distribution associated with the dueling bandits\u2019 problem with matrix $M^{(k)}$ (where arm $k$ is the Condorcet winner). ", "page_idx": 28}, {"type": "text", "text": "For any $u\\in[K]$ , let $N_{u}$ denote the total number of rounds where arm $u$ was queried. For $u,v\\in[K]$ , let $N_{u,v}$ denote the total number of rounds where arms $u$ and $v$ were dueled. ", "page_idx": 28}, {"type": "text", "text": "Information theoretic tool: Without loss of generality, we assume that the player follows a deterministic strategy $\\boldsymbol{\\mathcal{A}}$ . Let us introduce the following notation: let $Z_{t}=\\left((I_{t},\\dot{J_{t}_{}}\\dot{)}\\,,X_{t}(I_{t},J_{t})\\right)$ denote the information disclosed to the player at time $t$ . Let $\\boldsymbol{Z}_{t}=(Z_{1},\\ldots,\\dot{Z}_{t})$ denote the entire information available to the player after $t$ rounds. ", "page_idx": 28}, {"type": "text", "text": "Lemma E.2. Assume that $\\Delta_{c w}\\leq1/4$ . Let $F(Z_{T})$ denote a fixed function of the player observations, taking values in $[0,B]$ . Then for any $k\\in[K]\\setminus\\{1\\}$ and any player strategy $\\boldsymbol{\\mathcal{A}}$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}_{k}\\left[F(Z_{T})\\right]\\le\\mathbb{E}_{0}\\left[F(Z_{T})\\right]+4B\\sqrt{\\frac{2}{3}\\Delta_{c w}^{2}\\mathbb{E}_{0}[N_{k}]},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\begin{array}{r}{N_{u}=\\sum_{v=1}^{K}N_{u,v}}\\end{array}$ and $N_{u,v}$ denotes the number of rounds where arms u and v were duelled. ", "page_idx": 28}, {"type": "text", "text": "Proof. Recall that for any function $G$ bounded by $R$ , we have: $|\\mathbb{E}_{X\\sim\\mathbb{P}}[G(X)]-\\mathbb{E}_{X\\sim\\mathbb{Q}}[G(X)]|\\leq$ $2R\\,\\dot{\\mathrm{TV}}(\\mathbb{P},\\mathbb{Q})$ , where $\\mathrm{TV}(.,.)$ denotes the total variation distance. Therefore, by shifting $F$ by $-B/2$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}_{k}F(\\pmb{Z}_{T})-\\mathbb{E}_{0}F(\\pmb{Z}_{T})\\leq B\\operatorname{TV}(\\mathbb{P}_{k},\\mathbb{P}_{0})\\leq B\\sqrt{\\frac{1}{2}\\mathbf{K}\\mathbf{L}\\left(\\mathbb{P}_{0},\\mathbb{P}_{k}\\right)},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "by Pinsker\u2019s inequality, where KL(.) denotes the Kullback-Leibler divergence and $\\operatorname{KL}(\\mathbf{x},\\mathbf{y})$ for $\\dot{x_{},y}\\,\\in\\,(0,1)$ denotes the Kullback-Leibler divergence between two Bernoulli distributions with means $x$ and $y$ . ", "page_idx": 29}, {"type": "text", "text": "Next we use the chain rule for relative entropy (Theorem 2.5.3 in 5): ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathrm{KL}\\left(\\mathbb{P}_{0},\\mathbb{P}_{k}\\right)=\\sum_{t=1}^{T}\\mathbb{E}\\left[\\mathrm{KL}\\left(\\mathbb{P}_{0}\\left(Z_{t}|Z_{t-1}\\right),\\mathbb{P}_{k}\\left(Z_{t}|Z_{t-1}\\right)\\right)\\right]\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Observe that we have for each $t\\in[T]$ : ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[\\mathrm{KL}\\left(\\mathbb{P}_{0}\\left(Z_{t}|Z_{t-1}\\right),\\mathbb{P}_{k}\\left(Z_{t}|Z_{t-1}\\right)\\right)\\right]}\\quad}&{}\\\\ {\\leq}&{\\displaystyle\\sum_{u\\neq k}\\mathbb{P}_{0}\\left(k,u\\in\\{I_{t},J_{t}\\}\\right)\\mathrm{KL}(M_{k,u}^{(0)}+1/2;M_{k,u}^{(k)}+1/2)}\\\\ {\\leq}&{\\displaystyle\\frac{64}{3}\\mathbb{P}_{0}\\left(k\\in\\{I_{t},J_{t}\\}\\right)\\Delta_{c w}^{2}\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where in the last line we used that $K L(x,y)\\leq(x-y)^{2}/[y(1-y)]$ . Summing over $t\\in[T]$ leads to the desired result. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "Recall that the weak regret for the problem $\\mathbb{P}_{k}$ is given by: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}_{k}\\left[R_{T}\\right]=\\sum_{u,v=1}^{K}\\operatorname*{min}\\{\\Delta_{k,u},\\Delta_{k,v}\\}\\mathbb{E}_{k}[N_{u,v}]}}\\\\ &{=\\Delta_{c w}(T-\\mathbb{E}_{k}[N_{k}]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Applying Lemma E.2 with $F(Z_{T})=\\Delta_{c w}N_{k}$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Delta_{c w}\\mathbb{E}_{0}\\left[T-N_{k}\\right]\\leq\\Delta_{c w}\\mathbb{E}_{k}[T-N_{k}]+2\\Delta_{c w}T\\sqrt{\\frac{8}{3}\\Delta_{c w}^{2}\\mathbb{E}_{0}[N_{k}]}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Averaging over $k\\in[K]\\setminus\\{1\\}$ and using Jensen\u2019s inequality: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Delta_{\\mathrm{cw}}\\mathbb{E}_{0}\\left[T-\\frac{1}{K-1}\\sum_{k}N_{k}\\right]\\leq\\frac{1}{K-1}\\sum_{k}\\mathbb{E}_{k}\\left[R_{T}\\right]+2\\Delta_{c w}T\\sqrt{\\Delta_{c w}^{2}\\frac{8}{2(K-1)}\\mathbb{E}_{0}[\\sum_{k}N_{k}]},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Observe that $\\textstyle\\sum_{u=1}^{K}N_{u}\\leq2T$ , therefore the inequality above gives: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Delta_{\\mathrm{cw}}\\left(T-\\frac{2T}{K-1}\\right)\\leq\\frac{1}{K-1}\\sum_{k}\\mathbb{E}_{k}\\left[R_{T}\\right]+2\\Delta_{c w}T\\sqrt{\\Delta_{c w}^{2}\\frac{16T}{3(K-1)}}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Let $\\mathbb{P}_{*}$ denote the problem where we choose $k$ uniformly at random from $[K]\\setminus\\{1\\}$ , then we proceed to the game where gaps are given by $M^{(k)}$ . Hence we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}_{*}\\left[R_{T}\\right]=\\frac{\\sum_{k}\\mathbb{E}_{k}\\left[R_{T}\\right]}{K-1}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We conclude that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}_{*}[R_{T}]\\ge\\Delta_{\\mathrm{cw}}\\left(T-\\frac{2T}{K-1}\\right)-2\\Delta_{c w}T\\sqrt{\\frac{16T\\Delta_{c w}^{2}}{3K-3}}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{*}[R_{T}]\\geq\\underset{T^{\\prime}\\leq T}{\\operatorname*{sup}}\\ \\mathbb{E}_{*}\\left[R_{T^{\\prime}}\\right]}\\\\ &{\\qquad\\ge\\underset{T^{\\prime}\\leq T}{\\operatorname*{sup}}\\left\\{\\Delta_{\\mathrm{cw}}\\left(T^{\\prime}-\\frac{2T^{\\prime}}{K-1}\\right)-2\\Delta_{c w}T^{\\prime}\\sqrt{\\frac{16T^{\\prime}\\Delta_{c w}^{2}}{3(K-1)}}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Recall that we assume that $K\\geq6$ . In the above inequality, the supremum is achieved for $T^{\\prime}$ of the order of $K/\\Delta_{c w}^{2}$ , which is achievable as long as $T$ is at least of this order. This leads to the desired result when $K/\\Delta_{c w}^{2}$ is higher than some numerical constant $c^{\\prime\\prime}$ . In the extreme situation, where $K/\\Delta_{c w}^{2}$ is smaller or equal to $c^{\\prime\\prime}$ , the lower bound (38) could be negative for any $T^{\\prime}\\geq1$ . In that case, we can use the trivial bound $\\mathbb{E}_{*}[R_{T}]\\ge\\mathbb{E}_{*}[R_{1}]\\ge c^{\\prime}\\Delta_{c w}$ as, with probability bounded away from zero, the first duel does not contain the Condorcet winner. ", "page_idx": 30}, {"type": "text", "text": "F Technical Results: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Lemma F.1. Let $q\\in(0,1)$ , we have: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\sum_{n=0}^{+\\infty}2^{n}q^{2^{n}}\\leq2\\sum_{n=1}^{+\\infty}q^{n}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. We have: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n=1}^{+\\infty}2^{n-1}q^{2^{n}}\\leq\\displaystyle\\sum_{n=1}^{+\\infty}\\ \\sum_{i=0}^{2^{n-1}}q^{2^{n-1}+i}}\\\\ &{\\qquad\\qquad\\qquad\\le\\displaystyle\\sum_{n=1}^{\\infty}q^{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Lemma F.2 (Doob\u2019s maximal inequality: Section 5.6 from Lawler). Let $\\left(X_{i}\\right)$ be a sequence of independent Bernoulli variables such that for any $i\\geq1\\colon\\mathbb{E}[X_{i}]=p_{i}$ . Let $\\begin{array}{r}{S_{t}=\\sum_{i=1}^{t}(X_{i}-p_{i})}\\end{array}$ . We have for any $t\\geq1,\\,a>0$ : ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{max}_{1\\leq t\\leq n}\\{S_{t}\\}>a\\right)\\leq\\exp\\left(-\\frac{2a^{2}}{n}\\right).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. We have $S_{t}$ is a martingale with respect to the filtration associated to the process $\\left(X_{i}\\right)$ . Therefore using Doob\u2019s maximal inequality: Section 5.6 [9], for any $b>0$ : ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\underset{1\\leq t\\leq n}{\\operatorname*{max}}\\left\\{S_{t}\\right\\}>a\\right)\\leq\\frac{\\mathbb{E}\\left[\\exp\\left(b S_{n}\\right)\\right]}{\\exp\\left(b a\\right)}}\\\\ &{\\qquad\\qquad\\qquad=\\frac{\\mathbb{E}\\left[\\exp\\left(b\\sum_{i=1}^{n}(X_{i}-p_{i})\\right)\\right]}{\\exp\\left(b a\\right)}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\exp(-b a)\\exp(n b^{2}/8),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we used the fact that for each $i\\in[n]:\\mathbb{E}[\\exp(b(X_{i}-\\mathbb{E}[X_{i}]))]\\leq\\exp(b^{2}/8)$ . The conclusion follows by minimizing the upper bound for $b>0$ . ", "page_idx": 30}, {"type": "text", "text": "Lemma F.3. Let $\\left(X_{t}\\right)$ be a sequence of independent Bernoulli variables such that for some $\\Delta\\in$ $(0,1/2)$ , for each $t$ we have: E $\\begin{array}{r}{\\left[X_{t}\\right]\\geq\\frac{1}{2}+\\Delta}\\end{array}$ . Let $B\\geq1$ and define the stopping time: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\tau:=\\operatorname*{inf}\\left\\{t\\geq1:\\sum_{s=1}^{t}\\left(X_{s}-{\\frac{1}{2}}\\right)<-B{\\sqrt{t}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\tau<+\\infty\\right)\\le\\frac{\\exp(-B^{2})}{4\\log(2)}\\left(1-8\\log(\\operatorname*{min}\\{1,B\\Delta/2\\})\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{S_{t}=\\sum_{i=1}^{t}(\\mathbb{E}[X_{i}]-X_{i})}\\end{array}$ . We have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(\\tau<+\\infty)=\\mathbb{P}\\left(\\exists t\\in\\mathbb{N}:\\displaystyle\\sum_{s=1}^{t}\\left(X_{s}-\\frac{1}{2}\\right)<-B\\sqrt{t}\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(\\exists t\\in\\mathbb{N}:\\displaystyle\\sum_{s=1}^{t}\\left(\\frac{1}{2}+\\Delta-X_{s}\\right)>\\Delta t+B\\sqrt{t}\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathbb{P}\\left(\\exists t\\in\\mathbb{N}:\\displaystyle\\sum_{s=1}^{t}\\left(\\mathbb{E}[X_{s}]-X_{s}\\right)>\\Delta t+B\\sqrt{t}\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{P}\\left(\\exists t\\in\\mathbb{N}:S_{t}>\\Delta t+B\\sqrt{t}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Since we have for each $t\\geq1;\\,S_{t}\\leq t$ , and $\\Delta>0$ . We have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\tau<+\\infty\\right)=\\mathbb{P}\\left(\\exists t\\ge1:\\:S_{t}>\\Delta t+B\\sqrt{t}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\quad=\\mathbb{P}\\left(\\exists t\\ge B^{2}:\\:S_{t}>\\Delta t+B\\sqrt{t}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Let $N_{0}=\\lfloor\\log_{2}(B^{2})\\rfloor$ . We have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\tau<+\\infty\\right)\\le\\displaystyle\\sum_{n=N_{0}}^{+\\infty}\\mathbb{P}\\left(\\exists t\\in[2^{n},2^{n+1}]:\\;S_{t}>\\Delta t+B\\sqrt{t}\\right)}\\\\ &{\\qquad\\qquad\\le\\displaystyle\\sum_{n=N_{0}}^{+\\infty}\\mathbb{P}\\left(\\exists t\\in[2^{n},2^{n+1}]:\\;S_{t}>\\Delta2^{n}+B2^{n/2}\\right)}\\\\ &{\\qquad\\qquad\\le\\displaystyle\\sum_{n=N_{0}}^{+\\infty}\\mathbb{P}\\left(\\exists t\\le2^{n+1}:\\;S_{t}>\\Delta2^{n}+B2^{n/2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Using Lemma F.2, we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\exists t\\leq2^{n+1}:\\ S_{t}>\\Delta2^{n}+2B2^{n/2}\\right)=\\mathbb{P}\\left(\\underset{1\\leq t\\leq2^{n+1}}{\\operatorname*{max}}S_{t}>\\Delta2^{n}+B2^{n/2}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\left(-\\frac{\\left(\\Delta2^{n}+B2^{n/2}\\right)^{2}}{2^{n}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\left(-{\\Delta^{2}2^{n}-B^{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Pluging the last bound in the previous display gives: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\tau<+\\infty\\right)\\le\\displaystyle\\sum_{n=N_{0}}^{+\\infty}\\exp\\left(-\\Delta^{2}2^{n}-B^{2}\\right)}\\\\ &{\\qquad\\qquad\\le\\exp(-B^{2})\\displaystyle\\sum_{n=1}^{+\\infty}\\exp\\left(-\\displaystyle\\frac{\\Delta^{2}}{2}2^{n+N_{0}}\\right)}\\\\ &{\\qquad\\qquad\\le\\exp(-B^{2})\\displaystyle\\sum_{n=1}^{+\\infty}\\exp\\left(-\\displaystyle\\frac14(B\\Delta)^{2}2^{n}\\right)}\\\\ &{\\qquad\\qquad\\le\\exp(-B^{2})\\left(\\displaystyle\\frac1{4\\log(2)}-\\frac{2\\log(\\operatorname*{min}\\{1,B\\Delta/2\\})}{\\log(2)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "To get the last bound, we bounded the sum by an integral and use the change of variable $u=$ $(B\\bar{\\Delta})^{2}2^{t}/4$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{n=1}^{+\\infty}\\exp\\left(-\\frac{1}{4}(B\\Delta)^{2}2^{n}\\right)\\leq\\int_{0}^{+\\infty}\\exp\\left(-\\frac{1}{4}(B\\Delta)^{2}2^{t}\\right)d t}\\\\ &{=\\displaystyle\\int_{(B\\Delta)^{2}2^{\\prime}4}^{+\\infty}\\frac{\\exp\\left(-u\\right)}{\\log(2)u}d u}\\\\ &{=\\displaystyle\\int_{(B\\Delta)^{2}2^{\\prime}4}^{1}\\frac{\\exp\\left(-u\\right)}{\\log(2)u}d u+\\int_{1}^{+\\infty}\\frac{\\exp\\left(-u\\right)}{\\log(2)u}d u}\\\\ &{\\leq\\displaystyle\\int_{\\operatorname*{min}\\{1,(B\\Delta)^{2}/4\\}}^{1}\\frac{1}{\\log(2)u}d u+\\int_{1}^{+\\infty}\\frac{\\exp\\left(-u\\right)}{\\log(2)u}d u}\\\\ &{\\leq-\\frac{2\\log(\\operatorname*{min}\\{1,B\\Delta/2\\})}{\\log(2)}+\\frac{1}{4\\log(2)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Lemma F.4. Lemma 8 in [13] Let $\\alpha\\in(0,1)$ , $c>0$ and $d\\in(0,1]$ , we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\geq0}\\left\\{c x^{\\alpha}-d x\\right\\}=c^{\\frac{1}{1-\\alpha}}d^{\\frac{\\alpha}{\\alpha-1}}\\left(\\alpha^{\\frac{\\alpha}{1-\\alpha}}-\\alpha^{\\frac{1}{1-\\alpha}}\\right).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: In the abstract and introduction, we introduce in a non-technical way the main setting of the paper (duelling bandits and minimisation of weak regret), and expose our main contributions also in a non-technical way. We detail this after we introduce the setting. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: This work primarily concentrates on theoretical aspects. We explored the optimality and limitations of the guarantees in Section 3.2. Additionally, discussions on the guarantees for WR-TINF and WR-EXP3-IX are provided in Sections 4.1 and 4.2, respectively. Limitations and directions for potential improvements are presented in Section 7. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: The assumption made is the existence of a Condorcet winner Assumption 2.1. All the proofs are provided in the appendix: The proof of the upper bound for WR-TINF (Theorems 4.2) is provided in Section C, the proof of the upper bound for WR-EXP3-IX (Theorem 4.3) is provided in Section D. The proof of the lower bound (Theorem 5.1) is provided in Section E. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Algorithms introduced in this paper, together with the theoretical values of parameters, are fully described in sections 4.1 and 4.2. Section 6 provides all the details needed to reproduce the simulations presented in our paper. The code is provided as well. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 34}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 35}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: In our experiments, we used data generated synthetically. The description of the distributions of the duels considered is provided in Section 6. The code is provided as well. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: Section 6 describes all the necessary details to understand the experimental results and their connection to the theoretical guarantees of the presented algorithms. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The experimental results in Figure 1 compare algorithms and their average performance over multiple iterations together with 0.2 and 0.8 quantiles. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The algorithms for dueling bandits use a small amount of resources and can be run on personal computers. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The NeurIPS Code of Ethics was respected. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: This paper presents work whose goal is to advance the field of theoretical Machine Learning. There are no potential relevant societal consequences of our work, we feel must be specifically highlighted here. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The original owners of assets are authors. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not use existing assets. ", "page_idx": 37}, {"type": "text", "text": "\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 39}]