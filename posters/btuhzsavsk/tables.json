[{"figure_path": "btuHzsAVsK/tables/tables_8_1.jpg", "caption": "Table 1: Our model outperforms all existing models on Joint videos (J-6P) from two standard computer vision datasets. See Sec. 3.2 for dataset descriptions. Best is in bold.", "description": "This table presents a comparison of the performance of various action recognition models, including the proposed Motion Perceiver (MP), on two standard computer vision datasets (NTU RGB+D 60 and NW-UCLA) using Joint videos. The results show that MP significantly outperforms all existing models, achieving the highest top-1 accuracy on both datasets.", "section": "3.2 Video Action Recognition Datasets and Baselines in Computer Vision"}, {"figure_path": "btuHzsAVsK/tables/tables_9_1.jpg", "caption": "Table 2: Ablation reveals critical components in our model. Top-1 accuracy is reported on RGB videos, Joint videos with 6 points (J-6P), and SP videos with 8 points and a lifetime of 1 (SP-8P-1LT). From left to right, the ablated components are: the pathway with Motion Invariance Neurons (MIN), the pathway with Flow Snapshot Neurons (FSN), the single-scale branch with FSN M1, Slots 2, threshold \u03b3 (Sec. 2.1), and data augmentation by randomly shuffling and reversing training frames within the same video. Best is in bold.", "description": "This table presents the results of ablation studies performed on the Motion Perceiver model.  It systematically removes components of the model (MIN, FSN, single-scale FSN, number of slots, threshold \u03b3, and temporal augmentation) to evaluate their individual contributions to the model's performance on three types of video data: RGB, Joint videos with 6 points, and SP videos with 8 points and a lifetime of 1 frame. The 'Best' results are highlighted in bold, showcasing the importance of each component for optimal performance.", "section": "4.3 Ablation studies reveal key components in our model"}, {"figure_path": "btuHzsAVsK/tables/tables_19_1.jpg", "caption": "Table S1: Results of more baselines and our motion perceiver (MP) in BMP tasks. Our MP demonstrates superior performance than baselines on RGB videos, Joint videos with 6 points (J-6P), and SP videos with 8 points and a lifetime of 1 (SP-8P-1LT). Top-1 accuracy (%) is reported. Best is in bold.", "description": "This table presents a comparison of the performance of several AI models, including the proposed Motion Perceiver (MP), on three different types of video data: natural RGB videos, Joint videos (with 6 points), and Sequential Position actor videos (with 8 points and a lifetime of 1 frame).  The results show the top-1 accuracy for each model, highlighting MP's superior performance, particularly in the more challenging Joint and SP video tasks.", "section": "More Baselines Comparisons"}, {"figure_path": "btuHzsAVsK/tables/tables_19_2.jpg", "caption": "Table 1: Our model outperforms all existing models on Joint videos (J-6P) from two standard computer vision datasets. See Sec. 3.2 for dataset descriptions. Best is in bold.", "description": "This table compares the performance of the proposed Motion Perceiver (MP) model against six other state-of-the-art action recognition models on two standard benchmark datasets (NTU RGB+D 60 and NW-UCLA).  The models are evaluated on \"Joint videos (J-6P)\", a specific type of video data used in the paper's biological motion perception experiments, where only the skeletal joints of actors are visible.  The table highlights that the MP model significantly outperforms all other models, achieving the highest top-1 accuracy on both datasets.", "section": "3.2 Video Action Recognition Datasets and Baselines in Computer Vision"}, {"figure_path": "btuHzsAVsK/tables/tables_21_1.jpg", "caption": "Table 1: Our model outperforms all existing models on Joint videos (J-6P) from two standard computer vision datasets. See Sec. 3.2 for dataset descriptions. Best is in bold.", "description": "This table presents a comparison of the performance of the proposed Motion Perceiver (MP) model against several existing baseline models on two standard video action recognition datasets (NTU RGB+D 60 and NW-UCLA).  The results show that the MP model significantly outperforms the baselines on the Joint videos (J-6P) from both datasets, indicating its superior performance in recognizing actions from point-light displays.", "section": "3.2 Video Action Recognition Datasets and Baselines in Computer Vision"}, {"figure_path": "btuHzsAVsK/tables/tables_22_1.jpg", "caption": "Table S4: Ablation of key hyper-parameters in our model. Top-1 accuracy is reported on RGB videos, Joint videos with 6 points (J-6P), and SP videos with 8 points and a lifetime of 1 (SP-8P-1LT). From left to right, the ablated hyper-parameters are: the number of slots K (Sec. 2.2), the weight \u03b1 of Lslot (Sec. 2.2), temperature \u03c4 in the patch-level optical flow (Sec. 2.1), and temperature \u03bc in Lslot (Appendix, Sec. B.2). Best is in bold.", "description": "This table presents the results of ablation studies performed on the Motion Perceiver (MP) model to assess the impact of key hyperparameters.  The ablation study systematically varies four hyperparameters: the number of slots (K), the weight (\u03b1) of the contrastive loss (Lslot), the temperature (\u03c4) in patch-level optical flow calculations, and the temperature (\u03bc) in the contrastive walk loss (Lslot).  The table shows the top-1 accuracy achieved on three different video types: RGB, Joint videos with 6 points (J-6P), and Sequential Position actor videos with 8 points and a lifetime of 1 (SP-8P-1LT). The results help understand the impact of each hyperparameter on the model's overall performance.", "section": "K More Ablation Studies"}, {"figure_path": "btuHzsAVsK/tables/tables_23_1.jpg", "caption": "Table S5: Ablation of the time embedding (Sec. 2.4), the loss term Lslot (Sec. 2.2) and the referenced frame for calculating path-level optical flow (Sec. 2.1) in our model. Top-1 accuracy is reported on RGB videos, Joint videos with 6 points (J-6P), and SP videos with 8 points and a lifetime of 1 (SP-8P-1LT). Best is in bold.", "description": "This table presents the ablation study results for three key components of the Motion Perceiver model: time embedding, contrastive loss (Lslot), and the reference frame for optical flow calculation.  It shows the top-1 accuracy achieved on RGB videos, Joint videos with 6 points, and SP videos (8 points, 1 lifetime) when each component is removed individually or in combination.  The results help to understand the contribution of each component to the overall model performance.", "section": "K More Ablation Studies"}, {"figure_path": "btuHzsAVsK/tables/tables_24_1.jpg", "caption": "Table S6: Detailed results of baselines, motion perceiver (MP) and human in all BMP conditions. Top-1 accuracy (%) is reported. There are 24 conditions in total. Best is in bold. The second best is underlined.", "description": "This table presents a comprehensive comparison of the performance of various models (including the proposed Motion Perceiver, MP, and several baselines) against human performance across 24 different conditions.  These conditions systematically vary five key properties of biological motion perception, allowing for a detailed analysis of the models' generalization capabilities under diverse scenarios.  The results show the top-1 action recognition accuracy (percentage) for each model under each condition, highlighting the superior performance of the MP model, especially when compared to human performance and other state-of-the-art models.", "section": "L Detailed Results of All BMP Conditions"}]