[{"figure_path": "c7m1HahBNf/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of DUSA. Our method adapts a discriminative task model f\u03b8 with a generative diffusion model \u03b5\u03c6. Given image x0 at test-time, the task model outputs logits. To improve efficiency, we devise a CSM to select classes to adapt and return their probabilities (probs). The embeddings of the classes are then queried as diffusion model conditions, yielding conditional noise predictions from noisy image xt. The aggregated noise  \u1f14\u03b8,\u03c6 is then constructed from ensembling conditional noises with probs, which is aligned with the added noise e following Eq. (10). Both models are updated.", "description": "This figure illustrates the DUSA framework.  It shows how a discriminative task model and a generative diffusion model are used together for test-time adaptation. The task model provides logits, which are used by a Candidate Selection Module (CSM) to select relevant classes. The embeddings of these classes are used as conditions for the diffusion model, generating conditional noise predictions. These predictions are aggregated using the probabilities from the CSM, resulting in an aggregated noise which is used to update both models.", "section": "3 Structured Semantic Priors in Diffusion Score for Test-Time Adaptation"}, {"figure_path": "c7m1HahBNf/figures/figures_7_1.jpg", "caption": "Figure 1: Overview of DUSA. Our method adapts a discriminative task model f\u03b8 with a generative diffusion model \u03c6. Given image x0 at test-time, the task model outputs logits. To improve efficiency, we devise a CSM to select classes to adapt and return their probabilities (probs). The embeddings of the classes are then queried as diffusion model conditions, yielding conditional noise predictions from noisy image xt. The aggregated noise \u03b8t,\u03c6 is then constructed from ensembling conditional noises with probs, which is aligned with the added noise e following Eq. (10). Both models are updated.", "description": "This figure illustrates the DUSA framework, showing how a discriminative task model and a generative diffusion model work together for test-time adaptation.  The task model produces logits which are then used by the Candidate Selection Module (CSM) to select a subset of classes for adaptation.  These classes are used to condition the diffusion model and to generate a noise prediction. The predictions are aggregated and used to update both the task model and diffusion model.", "section": "3 Structured Semantic Priors in Diffusion Score for Test-Time Adaptation"}, {"figure_path": "c7m1HahBNf/figures/figures_7_2.jpg", "caption": "Figure 1: Overview of DUSA. Our method adapts a discriminative task model f\u03b8 with a generative diffusion model \u03c6. Given image x0 at test-time, the task model outputs logits. To improve efficiency, we devise a CSM to select classes to adapt and return their probabilities (probs). The embeddings of the classes are then queried as diffusion model conditions, yielding conditional noise predictions from noisy image xt. The aggregated noise \u03be\u03b8,\u03c6 is then constructed from ensembling conditional noises with probs, which is aligned with the added noise e following Eq. (10). Both models are updated.", "description": "This figure illustrates the DUSA framework. It starts with an input image, which is processed by a task model to produce logits. A Candidate Selection Module (CSM) selects a subset of classes based on the logits. These selected classes are used to condition a diffusion model, which produces noise predictions. The noise predictions are aggregated with the probabilities from the CSM to produce a final aggregated noise.  This noise is then combined with the actual noise to update both the task model and the diffusion model.  The process iteratively refines the task model's predictions.", "section": "3 Structured Semantic Priors in Diffusion Score for Test-Time Adaptation"}, {"figure_path": "c7m1HahBNf/figures/figures_23_1.jpg", "caption": "Figure 1: Overview of DUSA. Our method adapts a discriminative task model f\u03b8 with a generative diffusion model \u03c6. Given image x0 at test-time, the task model outputs logits. To improve efficiency, we devise a CSM to select classes to adapt and return their probabilities (probs). The embeddings of the classes are then queried as diffusion model conditions, yielding conditional noise predictions from noisy image xt. The aggregated noise \u03be\u03b8,\u03c6 is then constructed from ensembling conditional noises with probs, which is aligned with the added noise e following Eq. (10). Both models are updated.", "description": "This figure illustrates the overall framework of the proposed DUSA method. It shows how a discriminative task model and a generative diffusion model work together to adapt to new, unseen data at test time.  A Candidate Selection Module (CSM) is used to efficiently select a subset of classes for adaptation. The process leverages conditional noise predictions from the diffusion model to update both models, leading to improved performance in test-time adaptation.", "section": "3 Structured Semantic Priors in Diffusion Score for Test-Time Adaptation"}]