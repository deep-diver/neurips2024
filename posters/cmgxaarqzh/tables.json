[{"figure_path": "CMgxAaRqZh/tables/tables_5_1.jpg", "caption": "Table 1: Comparing the ASR and processing time of Probe sampling with and without simulated annealing to GCG with and without simulated annealing, while measuring time and FLOPs by averaging each iteration.", "description": "This table compares the attack success rate (ASR) and processing time of four different methods: GCG, GCG with simulated annealing, Probe Sampling, and Probe Sampling with simulated annealing.  The comparison is made for two different models, Vicuna (7b-v1.3) and Llama2 (7b-Chat), and two different datasets within AdvBench (Harmful Strings and Harmful Behaviors). The table shows ASR results for both individual and multiple attacks as well as processing time and floating point operations (FLOPs) per iteration.  Speedup factors compared to GCG are also provided.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_5_2.jpg", "caption": "Table 2: Transferability of Probe sampling with different draft models.", "description": "This table demonstrates the robustness of the probe sampling method across various draft models. It shows the attack success rate (ASR) achieved when using different smaller models (draft models) to estimate the loss before using the larger target model. The results highlight that probe sampling maintains effectiveness even when different draft models are used, showcasing its generalizability.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_6_1.jpg", "caption": "Table 4: Performance of Probe sampling on accelerating AutoDAN.", "description": "This table presents the results of applying Probe Sampling to accelerate the AutoDAN algorithm. It compares the Attack Success Rate (ASR) and processing time of AutoDAN-GA and AutoDAN-HGA with and without Probe Sampling.  The results show that Probe Sampling significantly reduces the processing time of both AutoDAN variants while maintaining or slightly improving the ASR. Specifically, Probe Sampling accelerates AutoDAN-GA by 2.3 times and AutoDAN-HGA by 2.5 times.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_6_2.jpg", "caption": "Table 5: Performance of Probe sampling on accelerating prompt learning method AutoPrompt.", "description": "This table presents the performance of AutoPrompt with and without Probe Sampling (PS).  It shows the accuracy (Acc) and processing time (in seconds) for both methods on two benchmark datasets: SST-2 and SICK-E.  The speedup achieved by incorporating PS is highlighted in parentheses.  The results demonstrate that PS significantly accelerates AutoPrompt without substantially affecting its accuracy.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_7_1.jpg", "caption": "Table 7: Ablation on the filtered set size reduction R. The filter set size is (1 \u2013 a) * B/R.", "description": "This table shows the results of an ablation study on the hyperparameter R, which controls the size of the filtered set in the Probe Sampling algorithm. The filtered set size is calculated as (1 - \u03b1) * B/R, where \u03b1 is the probe agreement score, and B is the batch size. The table shows how different values of R affect both the Attack Success Rate (ASR) and the processing time. The study demonstrates a tradeoff between speedup and performance, with smaller values of R resulting in faster processing time but potentially lower ASR. R=8 appears to provide a good balance between speed and performance.", "section": "3.4 Further analysis"}, {"figure_path": "CMgxAaRqZh/tables/tables_7_2.jpg", "caption": "Table 8: Ablation on fixed probe agreement score a vs adaptive score.", "description": "This table presents an ablation study comparing the performance of using a fixed probe agreement score versus an adaptive score in the Probe Sampling algorithm.  The probe agreement score, denoted as 'a', reflects the similarity between the draft model's and target model's predictions.  The table shows the Attack Success Rate (ASR) and processing time (in seconds) for different fixed values of 'a' (0.9, 0.6, 0.3, 0.0) and for the adaptive approach where 'a' is dynamically calculated. The results demonstrate the superior performance of the adaptive method in terms of both ASR and speed.", "section": "3.4 Further analysis"}, {"figure_path": "CMgxAaRqZh/tables/tables_8_1.jpg", "caption": "Table 9: Ablation on probe agreement measurements. All methods achieve similar speedup while Spearman's rank correlation coefficient achieves the best ASR.", "description": "This table presents ablation study results on different methods for measuring probe agreement score in the Probe Sampling algorithm.  The goal is to determine which method yields the best attack success rate (ASR) while maintaining similar speedup. The table compares Spearman's rank correlation, Pearson correlation, Kendall's Tau correlation, and Goodman and Kruskal's gamma, showing that Spearman's rank correlation achieves the highest ASR (85.0) with a time of 2.60 seconds, while other methods show slightly lower ASR and similar computation time. This highlights the importance of choosing an appropriate correlation method for optimal performance in the algorithm.", "section": "3.4 Further analysis"}, {"figure_path": "CMgxAaRqZh/tables/tables_8_2.jpg", "caption": "Table 10: Ablation on the probe set size k. Using B/16 leads to accurate probe agreement measurement while achieving significant acceleration.", "description": "This table presents an ablation study on the impact of different probe set sizes on the performance of the proposed Probe Sampling algorithm.  The probe set size is varied from B/64 to B, where B is the batch size of suffix candidates. The table shows the attack success rate (ASR) and the processing time for each probe set size. The results indicate that using a probe set size of B/16 achieves the best balance between ASR and speedup.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_8_3.jpg", "caption": "Table 11: Experiments with different draft models. Models with over 1B parameters, like TinyLlama, Phi, and ShearedLlMa, need two GPUs for parallel computation. ShearedLlMa achieves the highest ASR probably because it is a pruned version of Llama2. Both GPT-2 and GPT-Neo achieve a good balance of ASR and speedup.", "description": "This table shows the results of experiments using different draft models with varying sizes, from smaller models like GPT-2 and GPT-Neo to larger models like TinyLlama, Phi, and ShearedLlaMa.  The table compares the probe agreement score (\u03b1), attack success rate (ASR), and processing time (in seconds) for each model. The results highlight the trade-off between model size, performance (ASR), and computational cost (time).  Larger models generally yield better ASR but require more computational resources (multiple GPUs).  ShearedLlaMa, a pruned version of Llama2, stands out with the highest ASR, suggesting that model architecture plays a role in the effectiveness of the probe sampling method, in addition to model size.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_15_1.jpg", "caption": "Table 1: Comparing the ASR and processing time of Probe sampling with and without simulated annealing to GCG with and without simulated annealing, while measuring time and FLOPs by averaging each iteration.", "description": "This table compares the attack success rate (ASR) and processing time of the Greedy Coordinate Gradient (GCG) algorithm with and without simulated annealing against the proposed Probe Sampling method, also with and without simulated annealing.  It shows the performance on two datasets: Harmful Strings and Harmful Behaviors, using two different LLMs (Vicuna and Llama2). The table provides detailed results, including ASR, individual and multiple processing time, and FLOPs for each combination of method and LLM, highlighting the speedup achieved by Probe Sampling.", "section": "3.2 Main Results"}, {"figure_path": "CMgxAaRqZh/tables/tables_15_2.jpg", "caption": "Table 1: Comparing the ASR and processing time of Probe sampling with and without simulated annealing to GCG with and without simulated annealing, while measuring time and FLOPs by averaging each iteration.", "description": "This table compares the attack success rate (ASR) and processing time of the Greedy Coordinate Gradient (GCG) algorithm with and without simulated annealing against the Probe Sampling method (with and without simulated annealing).  It shows the performance improvements achieved by Probe Sampling in terms of both speed and accuracy.  The table provides results for two different large language models (LLMs): Vicuna and Llama2.", "section": "3.2 Main Results"}]