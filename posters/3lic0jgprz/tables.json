[{"figure_path": "3lic0JgPRZ/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison on single images from Voxceleb2. Source and Target denote differences evaluation on reconstructed source images and synthetic target images. LPIPS is multiplied with 10<sup>2</sup>. Underline and bold mark the suboptimal and optimal results, respectively.", "description": "This table presents a quantitative comparison of different face reconstruction methods on single images from the VoxCeleb2 dataset.  It compares the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) metrics for both the reconstructed source images (Source) and the synthesized target images (Target).  The best results for each metric are bolded, and the second-best are underlined. The LPIPS scores are multiplied by 100 for easier interpretation.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_7_2.jpg", "caption": "Table 1: Quantitative comparison on single images from Voxceleb2. Source and Target denote differences evaluation on reconstructed source images and synthetic target images. LPIPS is multiplied with 102. Underline and bold mark the suboptimal and optimal results, respectively.", "description": "This table presents a quantitative comparison of different methods on single images from the Voxceleb2 dataset.  It compares the performance of CPEM, D3DFR, NextFace, NextFace*, FFHQ-UV, and the proposed method ('Ours') in terms of PSNR, SSIM, and LPIPS metrics.  The comparison is done for both the reconstructed source images and the synthesized target images.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative ablation study for proposed Losses GP, LP, and HP.", "description": "This table presents the quantitative results of an ablation study conducted on the proposed loss functions: Global Prior Constraint (GP), Local Prior Constraint (LP), and Human Prior Constraint (HP).  The study evaluates the impact of each loss function on the overall performance of the face texture modeling framework, specifically looking at PSNR, SSIM, and LPIPS.  By incrementally adding each loss function, the table shows how each one contributes to improved performance.  The \"NA\" row indicates the performance without any of the proposed losses applied.", "section": "4.5 Ablation Study"}, {"figure_path": "3lic0JgPRZ/tables/tables_8_2.jpg", "caption": "Table 4: Quantitative ablation study for f(\u00b7), g(\u00b7).", "description": "This table presents the results of an ablation study investigating the impact of the neural representations f(\u00b7) and g(\u00b7) on the performance of the proposed method.  The study measures the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) metrics.  The \"NA\" row shows the performance when both neural networks are omitted. The \"+ Light (f(\u00b7))\" row shows the performance when only the f(\u00b7) network is used. The \"+ Occlusion (g(\u00b7))\" row shows the performance when both f(\u00b7) and g(\u00b7) networks are included. The results demonstrate the individual and combined contributions of these networks in achieving higher-quality facial texture reconstruction.", "section": "4.5 Ablation Study"}, {"figure_path": "3lic0JgPRZ/tables/tables_8_3.jpg", "caption": "Table 5: Quantitative comparisons on images with diverse shadows.", "description": "This table presents a quantitative comparison of different methods for face image reconstruction on a dataset of images with diverse shadows. The metrics used for comparison are PSNR (higher is better), SSIM (higher is better), and LPIPS (lower is better). The methods being compared are CPEM, D3DFR, NextFace, NextFace*, FFHQ-UV, and the proposed method (Ours). The table shows the performance of each method on both source and target images. The \"Source\" metrics evaluate the reconstruction quality on the source images, while the \"Target\" metrics evaluate the ability of the method to generate realistic images (by comparing the generated images to the ground truth images).", "section": "4.4 Evaluation on Images with Diverse Shadows"}, {"figure_path": "3lic0JgPRZ/tables/tables_13_1.jpg", "caption": "Table 1: Quantitative comparison on single images from Voxceleb2. Source and Target denote differences evaluation on reconstructed source images and synthetic target images. LPIPS is multiplied with 10<sup>2</sup>. Underline and bold mark the suboptimal and optimal results, respectively.", "description": "This table presents a quantitative comparison of different methods for face texture reconstruction on single images from the Voxceleb2 dataset.  The metrics used are PSNR, SSIM, and LPIPS (multiplied by 100), assessing the quality of both reconstructed source images and synthetic target images generated by each method.  The best and second-best performing methods for each metric are highlighted.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_13_2.jpg", "caption": "Table 7: Comparisons against baselines with 2D shadow-removal pre-processing on [41].", "description": "This table presents a quantitative comparison of different methods for 3D face texture reconstruction, specifically focusing on images pre-processed using a 2D shadow removal technique. The methods compared include CPEM, D3DFR, NextFace, NextFace*, FFHQ-UV, and the authors' proposed method. The metrics used for comparison are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity). Higher PSNR and SSIM values, and lower LPIPS values indicate better performance.", "section": "A.3 Comparisons against the combination of 2D Shadow Removal and 3D Texture Modeling"}, {"figure_path": "3lic0JgPRZ/tables/tables_15_1.jpg", "caption": "Table 2: Quantitative comparison on video sequences from Voxceleb2. Source and Target denote differences evaluation on reconstructed source sequences and synthetic target sequences.", "description": "This table presents a quantitative comparison of the proposed method's performance on video sequences from the Voxceleb2 dataset.  It compares the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) metrics for both the source (reconstructed) and target (synthesized) video sequences.  Higher PSNR and SSIM values and lower LPIPS values indicate better performance. The comparison includes several state-of-the-art methods for context.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_16_1.jpg", "caption": "Table 9: Comparisons against baselines with Deocclusion methods on Voxceleb2.", "description": "This table compares the performance of the proposed method against baselines using the deocclusion method on the Voxceleb2 dataset.  The metrics used are PSNR (higher is better), SSIM (higher is better), and LPIPS (lower is better). The comparison is done for both single images and video sequences, showing that the proposed method achieves better results in most cases, particularly in terms of LPIPS which measures perceptual similarity.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative comparison on single images from Voxceleb2. Source and Target denote differences evaluation on reconstructed source images and synthetic target images. LPIPS is multiplied with 10<sup>2</sup>. Underline and bold mark the suboptimal and optimal results, respectively.", "description": "This table presents a quantitative comparison of different methods' performance on single images from the Voxceleb2 dataset.  It evaluates the quality of reconstructed source images and synthetic target images (generated by replacing the texture of a target image with the texture from a source image and re-rendering).  The metrics used are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity).  The best and worst-performing methods are highlighted.", "section": "4.2 Evaluation on Voxceleb2"}, {"figure_path": "3lic0JgPRZ/tables/tables_17_2.jpg", "caption": "Table 11: Ablation study for the number of lighting conditions n.", "description": "This table presents the results of an ablation study conducted to determine the optimal number of lighting conditions (n) used in the proposed face texture modeling framework.  The study varied the number of initial light conditions (n = 3, 5, 7, and 9), and evaluated the performance using three metrics: Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS). The results show that using 5 initial lighting conditions produced the best performance, indicating that increasing the number beyond that point does not yield a significant improvement.", "section": "4.5 Ablation Study"}, {"figure_path": "3lic0JgPRZ/tables/tables_18_1.jpg", "caption": "Table 3: Quantitative ablation study for proposed Losses GP, LP, and HP.", "description": "This table presents a quantitative comparison of the proposed losses (GP, LP, and HP) on the performance of the model. It demonstrates the individual contribution of each loss to the overall performance, showing improvements in PSNR, SSIM, and LPIPS metrics when more losses are included.", "section": "4.5 Ablation Study"}]