[{"figure_path": "eHzIwAhj06/tables/tables_6_1.jpg", "caption": "Table 1: Mixture balancing is robust to model selection without group annotations. We compare the best class-balancing method during validation with and without group annotations. Both worst-class accuracy [69] and the bias-unsupervised validation score of [60] are effective for model selection without group annotations, often choosing the same method or mixture ratio as worst-group accuracy (WGA) validation. We list the method maximizing each metric and its average WGA over 3 seeds.", "description": "This table compares the performance of different class balancing methods (upsampling, subsetting, mixture balancing) for model selection in the absence of group annotations.  Three different metrics are used for model selection: bias-unsupervised score, worst-class accuracy, and worst-group accuracy. The table shows the best performing method according to each metric and its average worst-group accuracy across three independent seeds for Waterbirds, CelebA, and CivilComments datasets.", "section": "3.2 Mixture balancing: interpolating between subsetting and upsampling"}, {"figure_path": "eHzIwAhj06/tables/tables_15_1.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table presents the details of four datasets used in the paper to evaluate group robustness in machine learning models.  For each dataset, it lists the class labels, spurious features, and the proportions of each group in the training, validation, and test sets.  The table also indicates which groups are considered minority groups within each class. This information is crucial for understanding the experimental setup and the challenges involved in evaluating group robustness.", "section": "A.1 Dataset Composition"}, {"figure_path": "eHzIwAhj06/tables/tables_16_1.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table presents the details of four datasets used in the paper to evaluate the group robustness of machine learning models.  Each dataset is described by its name, the number of groups, the class and spurious features used to define those groups, the size of the training, validation, and test sets, and the proportion of each group in the training set. The table helps to understand the characteristics of each dataset, particularly the class and group imbalances which present challenges for finetuning models.", "section": "A.1 Dataset Composition"}, {"figure_path": "eHzIwAhj06/tables/tables_16_2.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table details the composition of the four datasets used in the paper's experiments. For each dataset, it provides information on the number of training, validation, and testing samples, as well as the class and spurious feature distributions within those samples. This information is crucial for understanding the experimental setup and the challenges faced in addressing group robustness.", "section": "A.1 Dataset Composition"}, {"figure_path": "eHzIwAhj06/tables/tables_16_3.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table details the four datasets used in the paper's experiments: Waterbirds, CelebA, CivilComments, and MultiNLI.  For each dataset, it lists the number of classes, the spurious features, and the number of training, validation, and test examples for each class and spurious feature combination.  It also provides the proportion of each group within the training data.  Note that the Waterbirds dataset has a distribution shift between the training and test sets, and the MultiNLI dataset is class-balanced.", "section": "A.1 Dataset Composition"}, {"figure_path": "eHzIwAhj06/tables/tables_16_4.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table details the composition of the four datasets used in the paper's experiments.  It shows the number of training, validation, and test examples for each group within each dataset. Groups are defined by the combination of class and spurious feature. The table also highlights which datasets are class-imbalanced and which dataset has a distribution shift (Waterbirds). Minority groups within each class are marked with an asterisk.", "section": "A.1 Dataset Composition"}, {"figure_path": "eHzIwAhj06/tables/tables_16_5.jpg", "caption": "Table 2: Dataset composition. We study four well-established benchmarks for group robustness across vision and language tasks. The class probabilities change dramatically when conditioned on the spurious feature. Note that Waterbirds is the only dataset that has a distribution shift and MultiNLI is the only dataset which is class-balanced a priori. The minority groups within each class are denoted by an asterisk in the \u201cNum", "description": "This table presents the details of the four datasets used in the paper's experiments. For each dataset, it shows the class labels, spurious features, group IDs, and the number of training, validation, and test samples in each group.  It also indicates the class-imbalance ratio and highlights the minority groups within each class.  The table clarifies the composition and characteristics of the datasets, which are crucial for understanding the experimental results.", "section": "2 Preliminaries"}, {"figure_path": "eHzIwAhj06/tables/tables_22_1.jpg", "caption": "Table 5: Correspondence between p(y) and intra-class group accuracy disparity. We compare p(y), the intra-class spectral norm ratio, to the difference in intra-class group accuracy. Each row represents a different experimental seed. Each cell contains a tuple with the class label for the class with largest value of p(y) paired with the class label for the class with the largest intra-class group test accuracy disparity, i.e., Acc(gmaj(y)) \u2013 Acc(gmin(y)). We see that in most cases these classes correspond, suggesting an explanatory power of the spectral norm ratio. In particular, this correspondence is consistent throughout all trials of CelebA and CivilComments, the most class-imbalanced datasets we study.", "description": "This table shows the correspondence between the intra-class spectral norm ratio (p(y)) and the difference in intra-class group accuracy for each seed across four datasets.  The intra-class spectral norm ratio is a metric showing spectral imbalance, while the accuracy difference reflects the group disparity.  The correspondence between these two metrics suggests that spectral imbalance may be a factor contributing to group disparities in accuracy.", "section": "Additional Experiments for Section 5"}]