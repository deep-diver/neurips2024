[{"figure_path": "jCMYIUwprx/figures/figures_1_1.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure illustrates the INDICT framework, showing how two critics (safety and helpfulness) interact with an actor (LLM) to generate code.  The example demonstrates how INDICT addresses a security vulnerability (CWE-78) by iteratively improving the code through the critics' interactions and knowledge retrieval, ultimately resulting in safer and more helpful code.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_3_1.jpg", "caption": "Figure 2: INDICT (Internal Dialogues of Critiques) is a framework to generate code by both safety and helpfulness. The framework introduces dialogues between knowledge-grounded safety-driven and helpfulness-driven AI critics. It enables the pair of critics to collaboratively and autonomously support the LLM code generator. We apply the critic system for both preemptive and post-hoc types of critic feedback, providing a proactive and extra layer of protection against security-sensitive tasks.", "description": "This figure illustrates the INDICT framework's architecture.  It shows the interaction between a task, an actor (LLM code generator), two critics (safety and helpfulness-driven), an executor (code execution environment), and the final response.  The actor generates a solution, which is then reviewed by both critics.  The critics provide feedback (preemptive and post-hoc) to the actor, leading to a revised solution. The executor then executes the solution and provides post-hoc feedback.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_6_1.jpg", "caption": "Figure 4: we evaluated INDICT against insecure coding practice tasks with CyberSecEval-1 (Auto-complete and Instruction splits) and CVS benchmarks. Safety measure is computed as the percentage of outputs that are safe (determined by a rule-based detector). Helpfulness measure is the winning rate against prior SoTA model or available ground-truth outputs (determined by a GPT evaluator). Notations: JV: Java, JS: Javascript, Py: Python; CR: CommandR, GT: ground-truth (\"GT Safe\" and \"GT Unsafe\" are the secure and insecure code samples provided by the CVS benchmark).", "description": "This figure presents the results of evaluating the INDICT framework on three benchmarks related to insecure coding practices: CyberSecEval-1 (Autocomplete), CyberSecEval-1 (Instruction), and CVS.  The graphs show the safety and helpfulness of code generated by different LLMs, both with and without INDICT. Safety is measured as the percentage of secure code outputs, and helpfulness is the winning rate against state-of-the-art models or ground truth. The results demonstrate that INDICT consistently improves both safety and helpfulness across various LLMs and programming languages.", "section": "4.1 Insecure coding practice tasks"}, {"figure_path": "jCMYIUwprx/figures/figures_7_1.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure illustrates the INDICT framework, showing how a safety-driven critic and a helpfulness-driven critic interact with each other and with an actor (the LLM code generator) to improve the quality of the generated code. The example demonstrates how INDICT addresses a specific security vulnerability (CWE-78) and enhances code functionality.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_7_2.jpg", "caption": "Figure 4: we evaluated INDICT against insecure coding practice tasks with CyberSecEval-1 (Auto-complete and Instruction splits) and CVS benchmarks. Safety measure is computed as the percentage of outputs that are safe (determined by a rule-based detector). Helpfulness measure is the winning rate against prior SoTA model or available ground-truth outputs (determined by a GPT evaluator). Notations: JV: Java, JS: Javascript, Py: Python; CR: CommandR, GT: ground-truth (\u201cGT Safe\u201d and \u201cGT Unsafe\u201d are the secure and insecure code samples provided by the CVS benchmark).", "description": "This figure shows the results of evaluating INDICT on insecure coding tasks using three benchmarks: CyberSecEval-1 (Autocomplete and Instruction), and CVS.  The evaluation metrics are safety (percentage of secure outputs) and helpfulness (winning rate against existing state-of-the-art models or ground truth).  The results are presented for different programming languages and models, comparing performance with and without INDICT.  The figure demonstrates INDICT's improvements in both safety and helpfulness across various tasks and languages.", "section": "4.1 Insecure coding practice tasks"}, {"figure_path": "jCMYIUwprx/figures/figures_9_1.jpg", "caption": "Figure 8: We conducted ablation experiments over multiple rounds of INDICT applications, using CommandR (left) and Codellama-13b-instruct (right) as the base models.", "description": "This figure shows the ablation study of applying INDICT for multiple rounds.  The left chart shows the results using CommandR as the base model, and the right chart uses Codellama-13b-instruct.  Each bar represents a metric (Security, Helpfulness, and their average (S+H)) at each round, comparing the performance of INDICT with and without external tools and against a baseline with no INDICT applied.", "section": "4.5 Ablation analysis"}, {"figure_path": "jCMYIUwprx/figures/figures_24_1.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure shows an example of how INDICT works.  INDICT uses two critics: a safety critic and a helpfulness critic. These critics work together to improve the code generated by an LLM. In the example, the safety critic identifies a security vulnerability (CWE-78). The helpfulness critic then suggests ways to improve the code's functionality. The LLM then uses the feedback from both critics to generate an improved version of the code.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_26_1.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure illustrates the INDICT framework, showing how two critics (safety and helpfulness) interact with each other and an actor LLM to generate code.  The example demonstrates how INDICT addresses a specific security vulnerability (CWE-78) and enhances the code's functionality through iterative refinement and the use of external knowledge.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_26_2.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "The figure shows an example of how INDICT works.  INDICT uses two critics: a safety critic and a helpfulness critic. These critics work together to analyze code and provide feedback to an actor (the LLM). The example shows how INDICT identifies a security vulnerability (CWE-78) in code generated by the actor and then uses external knowledge to suggest improvements, leading to a safer and more helpful code.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_28_1.jpg", "caption": "Figure 2: INDICT (Internal Dialogues of Critiques) is a framework to generate code by both safety and helpfulness. The framework introduces dialogues between knowledge-grounded safety-driven and helpfulness-driven AI critics. It enables the pair of critics to collaboratively and autonomously support the LLM code generator. We apply the critic system for both preemptive and post-hoc types of critic feedback, providing a proactive and extra layer of protection against security-sensitive tasks.", "description": "This figure illustrates the INDICT framework.  It shows how a task is given to an Actor (LLM code generator), which produces a solution. This solution then undergoes evaluation by two critics: a safety-driven critic and a helpfulness-driven critic.  These critics leverage external knowledge and interact with each other, providing both preemptive (before execution) and post-hoc (after execution) feedback to the Actor. The final, revised solution is then the output of the system.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_29_1.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure shows an example of how INDICT works.  It uses a dual cooperative system with a safety-driven critic and a helpfulness-driven critic. These critics work together autonomously to improve the code generation process, addressing both security vulnerabilities (in this case, CWE-78) and helpfulness issues. The critics interact iteratively, each providing analysis and feedback that guides the code generation process towards a safer and more helpful result.  External knowledge sources are also used.", "section": "3 INDICT Framework"}, {"figure_path": "jCMYIUwprx/figures/figures_29_2.jpg", "caption": "Figure 1: INDICT (Internal Dialogues of Critiques) enables two different critics to interact with each other autonomously and collaboratively, improving code generation by both security and helpfulness. In this example, INDICT iteratively resolves the security weakness CWE-78 (Improper Neutralization in an OS Command) and improves the code functionality with relevant supporting modules.", "description": "This figure shows how INDICT, a framework for improving code generation using LLMs, works by incorporating two critics: a safety-driven critic and a helpfulness-driven critic. These critics interact autonomously and collaboratively to analyze the code generated by an LLM, providing feedback to improve both its security and helpfulness. The example shows an iterative process where INDICT addresses a security vulnerability (CWE-78) and enhances the code functionality.", "section": "INDICT Framework"}]