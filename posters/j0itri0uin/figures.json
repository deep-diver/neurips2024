[{"figure_path": "J0Itri0UiN/figures/figures_2_1.jpg", "caption": "Figure 1: Causal graph. A represents sensitive attribute, Y represents the target variable, U represents latent confounders, X represents observed features. Note that the validity of our theoretical analysis holds for all causal models that satisfy the condition given by Assumption 3.1. It is not restricted to this specific graph.", "description": "This figure shows a causal graph illustrating the relationships between variables in a causal model. A represents the sensitive attribute (e.g., gender or race), Y is the target variable (the outcome of interest, e.g., loan approval or hiring decision), U signifies unobserved confounders (factors affecting both A and Y that are not directly measured), and X includes the remaining observed features. The arrows show the direction of causal influence.  The assumption is that the theoretical analysis applies to a range of causal models beyond this specific graph, so long as a specific set of conditions hold.", "section": "3 Counterfactual Fairness via Output Combination"}, {"figure_path": "J0Itri0UiN/figures/figures_7_1.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure shows the results of different fairness methods on synthetic datasets when ground truth counterfactuals are available.  It compares four methods (CFR, CFU, ERM, and PCF) across four different tasks (Linear-Reg, Cubic-Reg, Linear-Cls, and Cubic-Cls).  Each point represents a different setting. The x-axis represents the total effect (TE), a measure of counterfactual fairness violation. The y-axis represents the root mean squared error (RMSE) for regression tasks and the classification error for classification tasks. The figure demonstrates that PCF achieves the lowest error while maintaining perfect counterfactual fairness (TE=0), supporting the paper's claim about its optimality.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_7_2.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure presents the results of experiments conducted on synthetic datasets where ground truth counterfactuals were available.  The figure compares different fairness methods (ERM, CFU, CFR, PCF) across four scenarios (Linear Regression, Cubic Regression, Linear Classification, Cubic Classification).  Each subplot shows the tradeoff between Total Effect (TE) as a measure of counterfactual fairness and the model's prediction error (RMSE for regression and Error for classification).  The results visually demonstrate that the proposed method PCF achieves optimal predictive performance under the constraint of perfect counterfactual fairness. ", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_8_1.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure displays the results of four different machine learning models (ERM, CFU, CFR, and PCF) on four different synthetic datasets (Linear-Reg, Cubic-Reg, Linear-Cls, Cubic-Cls).  Each model's performance is evaluated using Root Mean Squared Error (RMSE) and Total Effect (TE) metrics.  The results show that PCF achieves perfect counterfactual fairness with the lowest error across all datasets, supporting the paper's claim of PCF's optimality under perfect CF constraints.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_8_2.jpg", "caption": "Figure 9: Results on Sim-Law with estimated counterfatuals. The predictor is a MLP regressor. We also test the convex combination of each algorithm and ERM. For example, PCFAug with \u03bb means \u0177 = \u03bb\u0177PCFAug + (1 \u2212 \u03bb)\u0177ERM. This suggests that PCFAug can achieve lower Error given the same TE and lower TE given the same Error.", "description": "This figure shows the results of experiments conducted on the Sim-Law dataset using a Multilayer Perceptron (MLP) regressor.  It compares several methods for achieving counterfactual fairness (CF), including Empirical Risk Minimization (ERM), CFU, CFR, ECO-CF, and PCF-CRM. The x-axis represents the Total Effect (TE), a measure of CF violation, and the y-axis shows the root mean squared error (RMSE), a measure of prediction accuracy. The different colored lines show different convex combinations of PCF-CRM and ERM, demonstrating that PCF-CRM generally achieves better performance (lower RMSE) for a given level of CF (TE) or better CF for a given prediction accuracy.  This supports the paper's claim about the effectiveness of the PCF-CRM method.", "section": "5 Experiments"}, {"figure_path": "J0Itri0UiN/figures/figures_22_1.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure shows the results of different fairness methods on synthetic datasets when ground truth counterfactuals are available.  It compares four methods: Empirical Risk Minimization (ERM), Counterfactual Fairness with U (CFU), Counterfactual Fairness with fair representation (CFR), and Plug-in Counterfactual Fairness (PCF). The x-axis represents the Total Effect (TE), a measure of counterfactual fairness, and the y-axis represents the RMSE (root mean squared error) or error for regression and classification tasks respectively. The plot demonstrates that PCF achieves the lowest error while maintaining perfect counterfactual fairness (TE = 0), validating Theorem 3.3 in the paper.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_22_2.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure presents the results of experiments conducted on synthetic datasets, where ground truth counterfactuals were available. It showcases the performance of four different methods (ERM, CFU, CFR, and PCF) in terms of Root Mean Squared Error (RMSE) and Total Effect (TE). The results demonstrate that PCF achieves the lowest prediction error while maintaining perfect counterfactual fairness.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_22_3.jpg", "caption": "Figure 2: Results on synthetic datasets given ground truth counterfactuals.", "description": "This figure displays the results of experiments conducted on synthetic datasets, where ground truth counterfactuals were available.  The results are visualized in four subplots, one for each of the following tasks: Linear Regression, Cubic Regression, Linear Classification, and Cubic Classification. Each subplot shows the relationship between the total effect (TE, a measure of counterfactual fairness) and the root mean squared error (RMSE) or error rate, depending on the task, for several different fairness methods.  The goal is to show the trade-off between fairness and accuracy. The points represent results for different values of the sensitive attribute's distribution, and the shapes represent different algorithms.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_23_1.jpg", "caption": "Figure 3: Results on synthetic datasets under counterfactual estimation error. Different color represents different a indicating the standard deviation of the error (\u2208 ~ N(0, a)) while shape represents different algorithms.", "description": "This figure shows the results of experiments on synthetic datasets, investigating the impact of counterfactual estimation errors on different fairness algorithms. The x-axis represents the total effect (TE), a metric for counterfactual fairness, and the y-axis represents the root mean squared error (RMSE), a measure of predictive performance. Different colors represent different levels of added noise (standard deviation of the error) during counterfactual estimation, while different shapes represent different fairness algorithms. This figure helps visualize the trade-off between fairness and accuracy under various levels of uncertainty in counterfactual estimation.", "section": "5.1 Synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_23_2.jpg", "caption": "Figure 11: Results on Sim-Adult with estimated counterfatuals. The predictor is a MLP classifier.", "description": "This figure shows the results of the experiment conducted on the Sim-Adult dataset using a Multilayer Perceptron (MLP) classifier as the predictor. The experiment evaluated the performance of different methods under counterfactual estimation error. The x-axis represents the total effect (TE), a measure of counterfactual fairness, and the y-axis represents the error of the predictor. Different colors represent different levels of added gaussian noise used to simulate the counterfactual estimation error. The plot shows how the error and fairness trade-off changes with different algorithms and levels of noise.", "section": "5.2 Semi-synthetic Dataset"}, {"figure_path": "J0Itri0UiN/figures/figures_24_1.jpg", "caption": "Figure 5: Results on Sim-Law with estimated counterfactuals. The predictor is a MLP regressor. We also test the convex combination of each algorithm and ERM. For example, PCF-CRM with \u03bb means \u0177 = \u03bb\u0177PCF-CRM + (1 \u2212 \u03bb)\u0177ERM. This suggests that PCF-CRM can achieve lower Error given the same TE and lower TE given the same Error.", "description": "This figure shows the results of experiments on the Sim-Law dataset using a Multilayer Perceptron (MLP) regressor.  The main comparison is between different fairness-aware algorithms (CFR, CFU, ERM, PCF-CRM) and their performance in terms of prediction error and Total Effect (TE).  A key aspect is exploring the trade-off between fairness and accuracy by varying a mixing parameter (\u03bb) that blends the predictions of PCF-CRM with ERM. The results indicate that PCF-CRM consistently outperforms other methods in achieving a balance between low error and low TE.", "section": "5 Experiments"}]