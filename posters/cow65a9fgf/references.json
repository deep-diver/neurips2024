{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is central to the research presented and the basis of the experimental setup."}, {"fullname_first_author": "Chengzhi Mao", "paper_title": "Understanding zero-shot adversarial robustness for large-scale models", "publication_date": "2023-01-01", "reason": "This paper is highly relevant as it is the first to investigate zero-shot adversarial robustness in large-scale vision-language models, directly inspiring the current work."}, {"fullname_first_author": "Sibo Wang", "paper_title": "Pre-trained model guided fine-tuning for zero-shot adversarial robustness", "publication_date": "2024-01-01", "reason": "This paper is a key comparative study that builds upon the previous research on zero-shot adversarial robustness, providing a direct benchmark for the current study's proposed approach."}, {"fullname_first_author": "Christian Schlarmann", "paper_title": "Robust CLIP: Unsupervised adversarial fine-tuning of vision embeddings for robust large vision-language models", "publication_date": "2024-01-01", "reason": "This paper provides another critical comparative study, focusing on enhancing robustness while maintaining clean accuracy in vision-language models."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-01-01", "reason": "This paper introduces BERT, a highly influential language representation model that is leveraged in many vision-language models and is relevant to the contextual understanding aspect of the current work."}]}