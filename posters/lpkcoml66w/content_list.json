[{"type": "text", "text": "Visual Pinwheel Center Act as Geometric Saliency Detector ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Haixin Zhong1,2 Mingyi Huang1,3 Wei P. Dai1,5 hxzhong@fudan.edu.cn myhuang20@fudan.edu.cn weidai@fudan.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Haoyu Wang3 Anna Wang Roe4 Yuguo Yu1,2,3,5,\u2217 haoyuwang18@fudan.edu.cn annawang@zju.edu.cn yuyuguo@fudan.edu.cn ", "page_idx": 0}, {"type": "text", "text": "1. Research Institute of Intelligent Complex Systems, Fudan University. 2. State Key Laboratory of Medical Neurobiology and MOE Frontiers Center for Brain Science, Institutes of Brain Science, Fudan University. ", "page_idx": 0}, {"type": "text", "text": "3. Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University.   \n4. MOE Frontier Science Center for Brain Science and Brain-machine Integration, School of Brain   \nScience and Brain Medicine, Key Laboratory of Biomedical Engineering of Ministry of Education, College of Biomedical Engineering and Instrument Science, Zhejiang University. 5. Shanghai Artificial Intelligence Laboratory. $^*$ Corresponding author. ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "During natural evolution, the primary visual cortex (V1) of lower mammals typically forms salt-and-pepper organizations, while higher mammals and primates develop pinwheel structures with distinct topological properties. Despite the general belief that V1 neurons primarily serve as edge detectors, the functional advantages of pinwheel structures over salt-and-peppers are not well recognized. To this end, we propose a two-dimensional self-evolving spiking neural network that integrates Hebbian-like plasticity and empirical morphological data. Through extensive exposure to image data, our network evolves from salt-and-peppers to pinwheel structures, with neurons becoming localized bandpass filters responsive to various orientations. This transformation is accompanied by an increase in visual field overlap. Our findings indicate that neurons in pinwheel centers (PCs) respond more effectively to complex spatial textures in natural images, exhibiting stronger and quicker responses than those in salt-and-pepper organizations. PCs act as first-order stage processors with heightened sensitivity and reduced latency to intricate contours, while adjacent iso-orientation domains serve as second-order stage processors that refine edge representations for clearer perception. This study presents the first theoretical evidence that pinwheel structures function as crucial detectors of spatial contour saliency in the visual cortex. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The seminal work of Hubel and Wiesel revealed orientation-selective columns in the visual cortex of higher mammals [1, 2]. In higher mammals\u2019 primary visual cortex (V1), neurons cluster into \"pinwheel\" structures around singularities [3], unlike in some mammals like rodents, which display \"salt-and-pepper\" organizations [4] or mini-columns [5]. While there are established theories and experiments for studying the formation of topological organization maps in the visual cortex [6, 7, 8, 9, 10, 11], the functional significance of pinwheel-like columnar organization remains an unresolved question and is even debated [12, 13]. ", "page_idx": 0}, {"type": "text", "text": "Sophisticated visual analyses, such as image pattern extraction [14], pattern symmetry [15], material properties [16], and textures [17], are crucial for understanding complex visual inputs. Imaging and electrophysiological studies have shown that iso-orientation domains (IODs) undergo crossorientation suppression [18], reducing a neuron\u2019s response to its preferred orientation when another orientation is also present in the stimulus [13, 19, 20]. This indicates IODs encoding the linear oriented stimuli, which is crucial for detecting edges and contours [21, 22]. Cross-orientation suppression is believed to facilitate the detection of local discontinuities, such as orientation discontinuities [23, 24, 25], leading to perceptual \"pop-out\" effects and the perception of illusory contours [24, 26, 27]. In contrast, neurons at pinwheel centers (PCs) exhibit greater selectivity for cross-orientation stimuli [12, 13]. This indicates that PCs respond more effectively to multi-orientation patterns, such as pattern symmetry than IODs [12]. This indicates PCs may contribute to encode more complex contour features. However, PCs are less selective but have longer response latency than IODs for stimulus orientation in the hierarchy process within OPMs when it comes to a single stimulus orientation [13, 19, 28]. Some studies indicate that colors [29], textures [30], darks and lights [31], luminance [32], and mirror symmetry [15] play a role in salient to visual processing. Despite these insights, the functional implications of how neurons within IODs and PCs of pinwheels process complex contour stimuli\u2014potentially affecting stimulus salience for both IODs and PCs\u2014from bottom-up visual inputs remain poorly understood, particularly from a temporal-spatial neural dynamics standpoint. ", "page_idx": 1}, {"type": "text", "text": "In response to these challenges, our research contributes the following: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a novel 2D self-evolving spiking neural network (SESNN) model that investigates the spiking mechanisms behind orientation preference maps (OPMs), spanning from salt-and-pepper organizations in mice to pinwheel structures in cats and macaques. The SESNN uniquely produces sparse codes through local synaptic plasticity during natural scene learning, establishing a new benchmark for neural coding strategies.   \n\u2022 PCs act as first-stage processors, detecting natural images and initiating spiking waves to neighboring IODs, which then process as second-stage neurons. This indicates that early processing involves complex contours, not just edge detection.   \n\u2022 PCs react faster to a variety of orientation features than IODs, indicating their function in detecting complex orientations and serving as geometric saliency detectors. This suggests PCs have an evolutionary advantage due to self-organized pinwheel structures, which improves their ability to process complex contours. ", "page_idx": 1}, {"type": "text", "text": "2 Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Visual overlap underlying pinwheels emergence ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Our SESNN model generates diverse OPMs, from salt-and-peppers to pinwheel structures, by adjusting the visual overlap metric $\\varepsilon$ . This metric, crucial for the variety of visual topologies across species, is shown in Fig. 1a to produce pinwheel structures at high overlap, akin to those in cats and macaques, while low overlap results in salt-and-pepper organizations, typical of mice or rats. High overlap also enables cortical neurons to sample natural scenes more frequently, aiding in generating high-resolution images during decoding. ", "page_idx": 1}, {"type": "text", "text": "Fig. 1a shows how visual input overlap levels from 10 to 15 pixels affect pinwheel structure representation in the model. The top panel illustrates a higher overlap (15 pixels), and the middle, a lower overlap (12 pixels). This comparison reveals the impact of stimulus overlap on pinwheel density and layout in the visual cortex. Below the threshold (10 pixels in our case), salt-and-pepper patterns form, as the bottom panel indicates. Thus, 9 pixels of overlap are excluded from pinwheel analysis, as shown in Fig. 1b-d. ", "page_idx": 1}, {"type": "text", "text": "We quantitatively analyze the OPMs shown in Fig. 1a with several metrics [7, 33]: ", "page_idx": 1}, {"type": "text", "text": "Pinwheel counts, defined as the number of PCs, can be measured by 2D FFT [34] which are located at the intersection of the real and imaginary components that equal 0 [33]. It exhibits a decreasing trend as the visual input overlap increases (illustrated in Fig. 1b), suggesting that a greater overlap in the visual field may lead to a reduction in the number of discrete pinwheel structures. ", "page_idx": 1}, {"type": "image", "img_path": "LPkcoml66W/tmp/5c7b5f1fe9daeb53efd5b6f442f31562b634035ad432b0a85f930efe7db2070b.jpg", "img_caption": ["Figure 1: RF visual overlaps underlying the emergence of OPM and the salt-and-peppers are revealed via our SESNN model. a. Modifying the overlap parameter $(\\varepsilon)$ among neighboring neurons receiving $16\\times16$ pixels) visual inputs from natural images influences the dimensions (e.g., b. Pinwheel counts, c. Nearest-neighbor pinwheel distance, d. Hypercolumn size) of pinwheel structures and saltand-pepper organizations. (Lines: mean. Shaded area: SD.) e. Comparing the SESNN model overlap with actual anatomical data overlap percentages in different species (mice, cats, and macaques). f. Relationship between the IOD size and the extent of the visual field in anatomical data (mice, cats, and macaques). "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "The nearest-neighbor pinwheel distance (NNPD) in millimeter (mm) unit is defined as the distance between the two nearest PCs. The increasing trend of visual input overlap expands the distance between neighboring pinwheels (Fig. 1c). ", "page_idx": 2}, {"type": "text", "text": "The size of hypercolumns $(\\mathbf{mm})$ is defined with periodicity measured by 2D FFT and also increases with the visual input overlap (shown in Fig. 1d). This paper does not account for left- and right-eye dominance columns, so the hypercolumn size is defined as the full $180^{\\circ}$ cycle of repeating column spacing $(\\Lambda)$ (mm). ", "page_idx": 2}, {"type": "text", "text": "It\u2019s noteworthy that pinwheel density is not included as a metric in our analysis. This omission is because the observed pinwheel density, irrespective of the hypercolumn size, approaches $\\pi$ pinwheels $\\Lambda^{2}$ , conforming to topological constraints [33, 34]. ", "page_idx": 2}, {"type": "text", "text": "Our findings emphasize the importance of overlap degrees. Greater overlap (e.g., $\\varepsilon_{1}=15$ pixels) fosters stronger local clustering, leading to larger hypercolumn sizes, fewer pinwheels, and longer NNPDs, versus lower overlap (e.g., $\\varepsilon_{2}=12$ pixels). Minimal overlap (e.g., $\\varepsilon_{3}=9$ pixels), yields weak clustering, resembling salt-and-pepper organizations (Fig. 1a). This suggests that shared input among V1 neurons significantly influences OPM and salt-and-pepper formation. A strong positive correlation $/R^{2}=0.{\\overset{\\circ}{9}}9\\$ ) between the SESNN model and species\u2019 visual RF overlaps (mouse, cat, macaque) is observed in Fig. 1e. This relationship highlights the overlap index\u2019s key role in spatial organization within orientation maps. The model\u2019s predictions on IOD sizes and visual field extent (Fig. 1f) align with empirical data [7], confirming the SESNN model\u2019s robustness in simulating neuroanatomical organization and the biological development of orientation maps. ", "page_idx": 2}, {"type": "text", "text": "2.2 Spatial-temporal distributed spiking waves propagate within pinwheels ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "V1 neurons stimulated by natural images primarily fire within pinwheel structures, particularly within and around PCs (Fig. 2a-b). This pattern is especially pronounced in higher mammals with large IODs, such as macaques and cats. ", "page_idx": 2}, {"type": "image", "img_path": "LPkcoml66W/tmp/ec91e8fcfbfdf2b417397ea5a2abf7d33d1fa3811a39f2ecbb28b9a1293322c5.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 2: Spatial-temporal response pattern within pinwheels. a. This figure displays the neuronal responses on OPM with a large IOD in a pinwheel structure. The neurons that fire at time $t_{0}$ are shown as large black dots at PC, and they expand towards the periphery at time $t_{0}{+}1$ , also denoted as large black dots. The other small dots represent resting neurons. b. Distance between firing neurons and the PC at time $t_{0}$ and $t_{0}{+}1$ . c. This panel shows the response onset latency of neurons and the mean distance $(\\pm\\,S\\mathbf{D})$ between these neurons within a pinwheel. The distance is measured as the Euclidean distance within a 2D grid, simulating the structure of a 2D V1 area. (Significance: \\*\\*\\*p $-0.001$ , Mann-Whitney U test.) ", "page_idx": 3}, {"type": "text", "text": "We define the response onset latency as $1~\\mathrm{ms}$ for the initial discharge from pinwheel structures, with subsequent firings occurring at $2\\:\\mathrm{ms}$ , based on a $1~\\mathrm{ms}$ time unit. Stimulated by natural images, the discharges start at the PCs and exhibit pronounced diffusion within the IODs sequentially, depending on their distance from the center, as suggested in Fig. 2c. ", "page_idx": 3}, {"type": "text", "text": "2.3 Visual bottom-up saliency detection: functional role of pinwheel in geometric encoding ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we investigate whether pinwheel structures respond distinctly to salient features in input images. The ground truth boundary from the BSDS 500 dataset [35] used as binary input represents geometric complexity (edges and curves) (Fig. 3a). The complexity is measured by calculating the local pixel entropy using sliding windows, with a $15\\!\\times\\!15$ pixel neighborhood to assess pixel value dispersion in the binary images. The computation adheres to the following equation: ", "page_idx": 3}, {"type": "equation", "text": "$$\nH(i,j)=-\\sum_{k=0}^{L-1}p(m_{k})\\log_{2}p(m_{k}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $H(i,j)$ denotes the entropy at pixel position $(i,j)$ in the entropy map, $L$ the count of distinct gray levels within the local neighborhood around pixel $(i,j)$ , and $m_{k}$ the $k\\mathrm{th}$ gray level within this specified neighborhood. A large entropy value reflects great unpredictability or complexity in the pixel values, signifying a highly variable pixel value distribution. Conversely, a low entropy value indicates a high degree of predictability, less variation, and reduced complexity in the contours of pixel values. In addition, the saliency map of images is generated based on the classical methodology [36]. ", "page_idx": 3}, {"type": "text", "text": "Furthermore, we propose a bimodal ratio analysis to compute the orientation bimodal ratio (OBR) to indicate a neuron\u2019s orientation tuning curve as either unimodal (single peak) or perfectly bimodal (two peaks of equal strength). This analysis focuses on identifying the peaks in the orientation tuning curve and quantifying their relative strengths. ", "page_idx": 3}, {"type": "equation", "text": "$$\nO B R=\\frac{2\\cdot\\operatorname*{min}(R_{1},R_{2})}{R_{1}+R_{2}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "LPkcoml66W/tmp/c0f122bae065f487d289d39ecdec8b72bb1102ab82343b17558f01a952c125dd.jpg", "img_caption": ["Figure 3: Pinwheel structures in V1 exhibit geometric properties. a. A BSDS 500 grayscale image displays boundaries, saliency, and entropy maps. b. Natural images show a positive link between saliency and entropy. c. Neuronal response onset latency from pinwheels and salt-and-peppers relates to structural complexity, measured by local pixel entropy. (Data: mean $\\pm\\ S\\mathbf{D}$ , significance: \\*\\*\\*\\* ${\\times}{0.0001}$ , Welch\u2019s t-test.) "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "where $R_{1}$ and $R_{2}$ represent the normalized firing rates corresponding to the strengths of the two most pronounced peaks in the orientation tuning curve. The OBR ranges from 0, denoting unimodality, to 1, indicating perfect bimodality in the neuron\u2019s orientation tuning. ", "page_idx": 4}, {"type": "text", "text": "A positive correlation is observed between the saliency map and the geometrical complexity of the BSDS500 dataset (Fig. 3b), demonstrating that higher geometrical complexity correlates with increased saliency. Significantly, in response to the stimulus shown in the BSDS500 image (Fig. 3a), pinwheel structures primarily activate in areas of high contour complexity (regions with the highest saliency in this binary image), which is a response pattern have not been observed in salt-and-peppers (Fig. 3c). ", "page_idx": 4}, {"type": "text", "text": "To confirm the disparity in contour complexity responses between pinwheel and salt-and-pepper organizations, we design a star-like binary input (depicted in Fig. 4a), including four identical entities to negate the impact of neuronal positioning within the SESNN model. This approach reaffirms the saliency-complexity correlation (Fig. 4b) and the priority of pinwheel activation over salt-and-peppers in response to heightened complexity (Fig. 4c). ", "page_idx": 4}, {"type": "text", "text": "Findings show that PCs exhibit enhanced saliency detection and significantly faster response times than IODs, indicating that PCs respond more quickly and sensitively to geometrically complex stimuli, while IODs are slower and react to simpler geometrical stimuli (see Fig. 4d). Both saliency and latency measurements are normalized to a 0-1 scale for comparison. ", "page_idx": 4}, {"type": "text", "text": "The enhanced saliency detection of PCs is due to the complex orientation preference in RFs. As addressed in Fig. 4e, the ordinate represents the OBR, reflecting that neurons near PC generally exhibit bimodal orientation tuning curves with near-equal peak strengths while there is a primary peak and a secondary peak at a relatively far position from PC $\\ x=2$ ). And the secondary peak is nearly absent at the IODs level $\\left[x=3\\right]$ ), leading to an OBR close to 0. Salt-and-peppers, however, show less variation, maintaining a consistent OBR. ", "page_idx": 4}, {"type": "text", "text": "In conclusion, PCs demonstrate selectivity for more intricate orientations. This is experimentally supported by [13, 37], who suggest that PCs are particularly sensitive to specific geometric configurations, such as T junctions. Characterized by multiple orientations and an OBR nearing 1 (Fig. 4e), these neurons tend to initiate action potentials in response to complex orientations. Consequently, this leads to pinwheels being the first to respond. In contrast, neurons in salt-and-peppers do not exhibit a similar responsiveness to complex orientations as observed in pinwheels. ", "page_idx": 4}, {"type": "image", "img_path": "LPkcoml66W/tmp/ba00288f730f0a883e7aa943eace8b5d4505f238d87a968d5bb80f5146775a09.jpg", "img_caption": ["Figure 4: Geometric properties emergence in PCs of V1 on star-like patterns. a. We introduce artificial star-like patterns to assess neural response to complexity. b. Star-like images show a link between saliency and entropy. c. Neuron response times in PCs and salt-and-peppers reduce with lower entropy. d. The analysis compares PCs and IODs for saliency and response to star-like patterns; the inset details saliency and latency. e. OBR varies across cortical distance; the red line marks PCs, and the black line, salt-and-peppers (an arbitrary point for salt-and-peppers). (Data: mean $\\pm\\ S\\mathbf{D}$ , significance: $^{**}\\mathrm{p}{<}0.01$ , $\\mathrm{\\ddot{\\Sigma}^{\\ast}\\mathrm{^{*}\\mathrm{*}\\mathrm{^{*}p\\mathrm{<}0.001}}}$ , $\\mathrm{\\ddot{\\Sigma}^{\\vdots}\\hat{\\Sigma}^{\\ast}\\hat{k}^{\\ast}\\Phi^{<}0.0001}$ , Welch\u2019s t-test.) "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "3 Methods ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "3.1 The architecture of SESNN model ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our SESNN model is a two-dimensional network of excitatory (E-) and inhibitory (I-) leaky integrateand-fire neurons (LIF) (5), stimulated by whitened natural images to mimic the LGN\u2019s functions of contrast normalization and edge enhancement without complex modeling [42, 43, 44]. We use 160 whitened natural images as the training dataset, normalized to zero mean and uniform variance, derived from 20 base images ( $\\scriptstyle512\\times512$ pixels) [44, 45]. To capture orientation details, each of the base images undergoes a 90-degree clockwise rotation and flip, creating 8 variations per original. ", "page_idx": 5}, {"type": "text", "text": "The configuration features $\\scriptstyle\\mathrm{E}-$ and I- neurons in recurrent networks with periodic boundary conditions (PBC), simulating a continuous 2D cortical surface. Under natural image stimuli, the SESNN forms single neuron receptive fields and population-level pinwheel structures in the OPM (Fig. 5e-f). To validate the model, we compare its evolution from randomness to organized states against biological data from macaque pinwheel structures and a baseline model [41], using metrics such as pinwheel density (pinwheels/ $\\bar{\\Lambda}^{2}$ ), NNPD (mm), and hypercolumn size (mm) [7, 33, 34] (Fig. 5f and Table 1). ", "page_idx": 5}, {"type": "table", "img_path": "LPkcoml66W/tmp/c7e1a2e56385f3951ec640b4fabdf946ece97d35ce33c9b715fa19bb4df69866.jpg", "table_caption": ["Table 1: SESNN pinwheels (mean $\\pm\\ S\\mathrm{D}\\quad$ ) vs. macaque pinwheels. "], "table_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "LPkcoml66W/tmp/f88453d768896d839d6cb753b5cee83360c94662e3fcd33c32bd264798d3521d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 5: Architecture of proposed SESNN model. a. The SESNN model comprises $4{,}900\\,\\mathrm{E}_{-}$ and $^{1,225\\;\\mathrm{I}_{\\mathrm{-}}}$ neurons [38, 39, 40]. It processes 160 natural images (100 patches each), presenting each $512\\!\\times\\!512$ pixel patch to E-neurons for $100~\\mathrm{ms}$ with input overlap. The FF and E-E connections adhere to the Hebbian-Oja (HO) rule; others follow the Correlation Measuring (CM) rule. b. Eand I-neurons are spatially arranged with periodic boundaries, sharing coordinates with connected boundaries as per diagram arrows. Identical connections are marked by same-color arrows. c. Initial weights are Gaussian distributed. d. Post-training connection strengths are depicted, with medians in red. e. Receptive fields (RF) emerge after training. f. Post-training spatial organization is compared among the SESNN model\u2019s OPM, macaque V1, and an SNN-based model [41], with color bars for orientation and a $1\\;\\mathrm{mm}$ scale bar on the cortical surface. ", "page_idx": 6}, {"type": "text", "text": "3.2 Experiment-data-justified overlapping visual fields among nearby neurons ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In each trial, E-neuron processes 100 different $16\\!\\times\\!16$ patches for 100 milliseconds each, randomly selected from the training dataset to serve as the receptive fields (RFs) (see Fig. 5a middle and right panels). It is assumed that these visual inputs overlap on the retina (Fig. 5a, middle panel and its inset). To reflect biological conditions, we perform a statistical analysis based on data from cats, macaques, and mice (Table 2), calculating average overlaps of $99.84\\%$ for cats, $99.70\\%$ for macaques, and $96.08\\%$ for mice using (Eq. 3). These results closely align with our SESNN model\u2019s configurations (refer to Fig. 1e). Receptive field (RF) size in V1 is more related to resolution than orientation map formation. In macaque V1, RF size increases more than tenfold from fovea to periphery, while orientation map properties show little variation [46, 47]. Our study does not focus on RF size variations across the retina, as we expect minimal effects from these shifts across species, provided the overlap remains constant. Since the fovea is key for detailed visual information, we use V1 RFs in the area centralis to modeling. ", "page_idx": 6}, {"type": "text", "text": "We propose the visual input overlap metric \u03b5percentage, which is defined as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\varepsilon_{\\mathrm{percentage}}=\\frac{\\sqrt[2]{\\rho_{\\mathrm{V1}}S_{\\mathrm{unit}}}-\\frac{L_{\\mathrm{unit}}M}{R F_{\\mathrm{size}}}}{\\sqrt[2]{\\rho_{\\mathrm{V1}}S_{\\mathrm{unit}}}-1}\\times100\\%\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $S_{\\mathrm{unit}}$ represents the unit cortical area, $R F_{\\mathrm{size}}$ denotes the size of the RF in $_{\\mathrm{V}1}$ , $\\rho_{\\mathrm{V}1}$ represents the density of neurons in V1, $L_{\\mathrm{unit}}$ denotes the unit length of the RF and $M$ refers to the cortical magnification factor (CMF). We consider only an effective cortical layer composed of output neurons. This is because the apparent overlap within a vertical cortical column primarily contributes to intermediary processing stages for the same input. Therefore, such overlaps should not be conflated with overlaps in the input space. ", "page_idx": 6}, {"type": "text", "text": "3.3 Neural dynamics ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "E-neurons receive stimuli from natural images as well as noise $\\mathcal{N}(0,0.04)$ from other brain areas (noise term). I-neurons indirectly receive natural image stimuli by adjusting E-neurons. The neural ", "page_idx": 6}, {"type": "text", "text": "Table 2: Comparative anatomical data of the retina and V1 across three species. a. This table includes three diverse species, encompassing both primates (e.g., macaques) and non-primates (e.g., mice and cats). b. V1 neuron density (neurons/ $\\mathrm{\\dot{\\mm}^{2}}$ ) within 2D surface. c. Size of V1 RF in area centralis (deg). d. Cortical magnification factor (CMF) $\\mathrm{(mm/deg)}$ of V1. ", "page_idx": 7}, {"type": "table", "img_path": "LPkcoml66W/tmp/787520403c7439bbbf178d28bb044830f9e59a2ed4062a940570825921d092b3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "spiking dynamics are modeled using biologically inspired LIF neurons, incorporating refractory periods and adaptive firing thresholds [54]. The neural dynamics are iteratively formulated as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u_{i}^{\\mathrm{(K)}}(t+1)=u_{i}^{\\mathrm{(K)}}(t)e^{-\\frac{\\eta}{\\tau^{\\mathrm{(K)}}}}+h_{\\mathrm{K}}(i)\\sum_{j}\\mathrm{FF}_{i j}^{\\mathrm{(image\\toE)}}X_{j}}\\\\ {+\\displaystyle\\sum_{\\mathrm{K}^{*}}\\sum_{j}\\beta_{i j}^{\\mathrm{(K^{*}\\to K)}}\\cdot W_{i j}^{\\mathrm{(K^{*}\\to K)}}\\cdot z_{j}^{\\mathrm{(K^{*})}}(t)+\\mathrm{noise},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\nh_{\\mathrm{K}}(i)={\\binom{1,}{0,}}\\quad\\mathrm{if}\\ i\\ \\mathrm{is\\an\\,E{\\mathrm{-neuron\\,ID}},}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Delta\\theta_{i}^{(\\mathrm{K})}\\propto p_{i}(z_{i}^{(\\mathrm{K}^{*})}=1)-p_{i}^{(\\mathrm{K})},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $i=1,2,\\ldots,N\\mathrm{th}$ (the neuron IDs of E-neurons and I-neurons). ", "page_idx": 7}, {"type": "text", "text": "In neural dynamics equation, $u_{i}^{(\\mathrm{K})}\\left(t\\right)$ denotes the membrane potential of neuron $i$ at time $t_{\\mathrm{:}}$ , applicable to neurons of class $\\mathrm{K}$ , which includes $\\mathrm{E}-$ and $\\scriptstyle\\mathrm{I-}$ neuron groups. The membrane time constant, symbolized by $\\tau$ in the resistor-capacitor circuit, governs the decay rate of the membrane potential in individual neurons. Notably, inhibitory neurons are configured to fire more rapidly than excitatory neurons [43, 55]. This setup reduces reconstruction error and hastens system convergence, leading to a more efficient and accurate representation of input stimuli. ", "page_idx": 7}, {"type": "text", "text": "3.4 Hebbian Learning in SESNN ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The learning rules consist of the Hebbian Oja\u2019s variant (HO) [42] for input weight adjustments and the Correlation Measuring (CM) rules [43, 44] for intra-network weight changes (Fig. 5a-c). These facilitate adaptive synaptic weight adjustment based on firing pattern correlations, emulating a key learning mechanism in biological neural networks. ", "page_idx": 7}, {"type": "text", "text": "The formula for these adjustments is given by: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathrm{HO}:\\ \\Delta W_{i j}^{(\\mathrm{K}^{*}\\rightarrow\\mathrm{K})}\\propto y_{i}x_{j}-y_{i}^{2}W_{i j}^{(\\mathrm{K}^{*}\\rightarrow\\mathrm{K})},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbf{CM}:\\;\\Delta W_{i j}^{(\\mathrm{K}^{*}\\rightarrow\\mathrm{K})}\\propto y_{i}x_{j}-\\left\\langle y_{i}\\right\\rangle\\left\\langle x_{j}\\right\\rangle\\left(1+W_{i j}^{(\\mathrm{K}^{*}\\rightarrow\\mathrm{K})}\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $x,\\,y$ denote the spike rates of presynaptic and postsynaptic neurons, respectively, with $\\langle\\cdot\\rangle$ denotes the lifetime average. After each stimulus presentation of $100\\;\\mathrm{ms}$ , we calculate the network\u2019s neuronal instantaneous spike rates using exponential moving averages (EMAs), which aggregate spikes over time to reflect recent activity (see section A.1). Lifetime averages, also computed as EMAs, are crucial for homeostatic stability, helping to modulate neuronal properties or synaptic strengths for consistent activity. See the appendix for the hyperparameters. ", "page_idx": 7}, {"type": "text", "text": "Our SESNN model reflects experimental findings [56, 57] by representing V1 pyramidal neurons with weaker synaptic strengths, essential for preventing over-excitation and maintaining neural balance. We apply the HO rule [42] to E-E connections with a normalization factor to keep synaptic weights between 0 and 1, while stronger lateral E-I connections under the CM rule lack this normalization [44, 43]. Post-training synaptic strengths are depicted in Fig. 5d. Stabilizing neural network training requires careful learning rate adjustment. A slower rate for E-E connections compared to others is crucial to prevent E-neuron over-excitation, aligning with empirical data [56, 57, 58]. ", "page_idx": 7}, {"type": "text", "text": "The HO and CM rules facilitate LTP and LTD mechanisms, common in rate learning rules that do not require precise spike timing. We selected these rules for their ease of tuning and ability to stabilize recurrent excitation. ", "page_idx": 8}, {"type": "text", "text": "4 Related works ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Functional roles of pinwheel structure can be revealed by SESNN model The classical selforganizing map model [8] and other computational approaches like on-off models [6, 7, 9, 59] and related ANNs [10, 60, 61] lack the dynamic and temporal fidelity needed to realistically simulate the emergence of pinwheel structures in the visual cortex. To address these shortcomings, we propose the novel SESNN model, integrating retinotopy data [48, 49, 51, 52], detailed morphological data [62, 63, 64], and CMF [50, 51, 53] to enhance biological fidelity. The SESNN model effectively simulates macaque cortical organization and pinwheel development within OPMs (Fig. 5f). Furthermore, our investigations reveal that the degree of overlap\u2014reflecting similar feedforward inputs from identical RGCs to neighboring neurons\u2014positively correlates with the retino-cortical mapping ratio [6], aiding in distinguishing between different V1 organizational patterns. ", "page_idx": 8}, {"type": "text", "text": "PCs and IODs in neural processing hierarchies Our findings show that PCs and IODs exhibit distinct neural activity waves, leading to varied responses to contour complexity from spatial-temporal dynamics: PCs react first to complex contours, having more multi-orientation selective neurons (Fig. 4e, $x=1$ ) before activity spreads to IODs, which process simpler edges (Fig. 4d and e). PCs display a stronger correlation with contour saliency, indicating a heightened role in processing visual stimuli over IODs (Figs. 3b and 4b). In rodents with salt-and-pepper organizations, contour saliency is less pronounced (Figs. 3c and 4c). While PCs are thought to indicate higher-order processing due to delayed response [13, 28], this is likely due to the nature of the stimuli. Studies reveal IODs show cross-orientation suppression under complex stimuli [12], unlike PCs with broader tuning. The SESNN model illustrates a preference for complex stimuli in PCs and simple stimuli in IODs, with activity cascading from PCs to IODs upon encountering complex contours (Fig. 4d and e). ", "page_idx": 8}, {"type": "text", "text": "PCs as geometric saliency detector The SESNN model reveals PCs have broader orientation tuning and less selectivity for complex contours, unlike IODs, which show sharper tuning and crossorientation suppression, preferring simpler edges $x=1$ in Fig. 4e) [12, 13, 19, 58, 65, 66, 67]. PCs\u2019 excitation leads to reduced cross-orientation suppression. With binary input, PCs correlate more positively with contour complexity than IODs (Figs. 3b and 4b), making them more salient in processing visual stimuli. This differs from rodents with salt-and-pepper organizations that lack distinct contour complexity saliency (Figs. 3c and 4c). Prior studies [12, 13, 28] suggest PCs have delayed response latency, indicative of higher-order processing. This arises from using drifting grating stimuli that activate IODs more readily. Koch et al. [12] note that IODs show cross-orientation suppression under complex stimuli, narrowing their tuning, unlike PCs. However, these studies omit temporal neural data within pinwheel structures. The SESNN model supports physiological findings that IODs and PCs favor single and complex orientation stimuli, respectively. ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion and limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The advantages of pinwheel structures in visual representation and encoding are not fully understood. To address this, we develop a two-dimensional self-evolving spiking neural network (SESNN) that incorporates Hebbian-like plasticity and empirical morphological data. This model evolves to function as localized, bandpass filters, enhancing its responsiveness to a range of orientations and complex spatial textures in natural images. Our findings reveal that neurons within pinwheel structures respond more effectively to these textures, with stronger and quicker reactions than those in salt-and-pepper configurations. Specifically, PCs act as first-order stage processors with heightened sensitivity and reduced response latency to intricate contours, while IODs function as second-stage processors, refining edge representation for greater clarity. This advanced processing capability of pinwheel structures, particularly in detecting spatial contour saliency, not only deepens our understanding of visual processing in higher mammals but may also inform new strategies for visual saliency algorithms in computational models. ", "page_idx": 8}, {"type": "text", "text": "Using sliding windows, local entropy assesses variation and complexity in spatial distributions by capturing local intensity changes, indirectly reflecting geometric complexity through edges, corners, and patterns. Since this method cannot directly measure geometric shapes, we verify the use of the Ramer-Douglas-Peucker algorithm to approximate and directly measure geometric structures (refer to section A.5) [68]. This algorithm simplifies shape contours by reducing vertices while preserving the overall form. The resulting polygon will allow us to calculate the distribution of edge lengths and angles, with geometric entropy defined as the sum of these entropy values. In future studies, we will utilize the Ramer-Douglas-Peucker algorithm to enhance our geometric analysis by identifying and measuring the complexity of specific structural features, such as junctions, sharp corners, and textures, which are essential in complex visual scenes. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We gratefully acknowledge the support from the Science and Technology Innovation 2030 - Brain Science and Brain-Inspired Intelligence Project (2021ZD0201301), the National Natural Science Foundation of China (U20A20221, 12201125), the Shanghai Municipal Science and Technology Committee of Shanghai outstanding academic leaders plan (21XD1400400), the Yang Fan plan (22YF1403300), and the China Postdoctoral Science Foundation (2023M740724). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] D. H. Hubel and T. N. Wiesel. Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex. The Journal of Physiology, 160(1):106\u2013154, 1962. ISSN 1469-7793. doi: 10.1113/jphysiol.1962.sp006837. URL https://onlinelibrary.wiley.com/doi/abs/10.1113/ jphysiol.1962.sp006837.   \n[2] David H. Hubel and Torsten N. Wiesel. Sequence regularity and geometry of orientation columns in the monkey striate cortex. Journal of Comparative Neurology, 158(3):267\u2013293, 1974. ISSN 1096-9861. doi: 10.1002/cne.901580304. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cne. 901580304.   \n[3] Tobias Bonhoeffer and Amiram Grinvald. Iso-orientation domains in cat visual cortex are arranged in pinwheel-like patterns. Nature, 353(6343):429\u2013431, October 1991. ISSN 1476-4687. doi: 10.1038/ 353429a0. URL https://www.nature.com/articles/353429a0.   \n[4] Sergej V. Girman, Yves Sauv\u00e9, and Raymond D. Lund. Receptive Field Properties of Single Neurons in Rat Primary Visual Cortex. Journal of Neurophysiology, 82(1):301\u2013311, July 1999. ISSN 0022-3077. doi: 10.1152/jn.1999.82.1.301. URL https://journals.physiology.org/doi/full/10.1152/jn. 1999.82.1.301.   \n[5] Dario L. Ringach, Patrick J. Mineault, Elaine Tring, Nicholas D. Olivas, Pablo Garcia-Junco-Clemente, and Joshua T. Trachtenberg. Spatial clustering of tuning in mouse primary visual cortex. Nature Communications, 7(1):12270, August 2016. ISSN 2041-1723. doi: 10.1038/ncomms12270. URL https://www.nature.com/articles/ncomms12270.   \n[6] Jaeson Jang, Min Song, and Se-Bum Paik. Retino-Cortical Mapping Ratio Predicts Columnar and Saltand-Pepper Organization in Mammalian Visual Cortex. Cell Reports, 30(10):3270\u20133279.e3, March 2020. ISSN 2211-1247. doi: 10.1016/j.celrep.2020.02.038. URL https://www.cell.com/cell-reports/ abstract/S2211-1247(20)30199-6.   \n[7] Sohrab Najafian, Erin Koch, Kai Lun Teh, Jianzhong Jin, Hamed Rahimi-Nasrabadi, Qasim Zaidi, Jens Kremkow, and Jose-Manuel Alonso. A theory of cortical map formation in the visual brain. Nature Communications, 13(1):2303, April 2022. ISSN 2041-1723. doi: 10.1038/s41467-022-29433-y. URL https://www.nature.com/articles/s41467-022-29433-y.   \n[8] Teuvo Kohonen. Self-organized formation of topologically correct feature maps. Biological Cybernetics, 43(1):59\u201369, January 1982. ISSN 1432-0770. doi: 10.1007/BF00337288. URL https://doi.org/10. 1007/BF00337288.   \n[9] K. D. Miller. A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between ON- and OFF-center inputs. Journal of Neuroscience, 14(1):409\u2013441, January 1994. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI. 14-01-00409.1994. URL https://www.jneurosci.org/content/14/1/409.   \n[10] Anton V. Chizhov and Lyle J. Graham. A strategy for mapping biophysical to abstract neuronal network models applied to primary visual cortex. PLOS Computational Biology, 17(8):e1009007, August 2021. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1009007. URL https://journals.plos.org/ ploscompbiol/article?id=10.1371/journal.pcbi.1009007.   \n[11] Eshed Margalit, Hyodong Lee, Dawn Finzi, James J. DiCarlo, Kalanit Grill-Spector, and Daniel L. K. Yamins. A unifying framework for functional organization in early and higher ventral visual cortex. Neuron, 112(14):2435\u20132451.e7, July 2024. ISSN 0896-6273. doi: 10.1016/j.neuron.2024.04.018. URL https://www.cell.com/neuron/abstract/S0896-6273(24)00279-4.   \n[12] Erin Koch, Jianzhong Jin, Jose M. Alonso, and Qasim Zaidi. Functional implications of orientation maps in primary visual cortex. Nature Communications, 7(1):13529, November 2016. ISSN 2041-1723. doi: 10.1038/ncomms13529. URL https://www.nature.com/articles/ncomms13529.   \n[13] Ming Li, Xue Mei Song, Tao Xu, Dewen Hu, Anna Wang Roe, and Chao-Yi Li. Subdomains within orientation columns of primary visual cortex. Science Advances, 5(6):eaaw0807, June 2019. doi: 10.1126/ sciadv.aaw0807. URL https://www.science.org/doi/full/10.1126/sciadv.aaw0807.   \n[14] Jeremy Freeman, Corey M. Ziemba, David J. Heeger, Eero P. Simoncelli, and J. Anthony Movshon. A functional and perceptual signature of the second visual area in primates. Nature Neuroscience, 16 (7):974\u2013981, July 2013. ISSN 1546-1726. doi: 10.1038/nn.3402. URL https://www.nature.com/ articles/nn.3402.   \n[15] Elias H. Cohen and Qasim Zaidi. Symmetry in context: Salience of mirror symmetry in natural patterns. Journal of Vision, 13(6):22, May 2013. ISSN 1534-7362. doi: 10.1167/13.6.22. URL https://doi. org/10.1167/13.6.22.   \n[16] Gouki Okazawa, Satohiro Tajima, and Hidehiko Komatsu. Image statistics underlying natural texture selectivity of neurons in macaque V4. Proceedings of the National Academy of Sciences, 112(4):E351\u2013 E360, January 2015. doi: 10.1073/pnas.1415146112. URL https://www.pnas.org/doi/full/10. 1073/pnas.1415146112.   \n[17] Andrea Li and Qasim Zaidi. Three-dimensional shape from non-homogeneous textures: Carved and stretched surfaces. Journal of Vision, 4(10):3, October 2004. ISSN 1534-7362. doi: 10.1167/4.10.3. URL https://doi.org/10.1167/4.10.3.   \n[18] Xu Tao, Yan Hong-Mei, Song Xue-Mei, Ming Li, and Yong-Jie Li. Silent suppressive surrounds and optimal spatial frequencies of single neurons in cat V1. Neuroscience Letters, 597:104\u2013110, June 2015. ISSN 0304-3940. doi: 10.1016/j.neulet.2015.04.039. URL https://www.sciencedirect.com/science/ article/pii/S0304394015003389.   \n[19] Ian Nauhaus, Andrea Benucci, Matteo Carandini, and Dario L. Ringach. Neuronal Selectivity and Local Map Structure in Visual Cortex. Neuron, 57(5):673\u2013679, March 2008. ISSN 0896-6273. doi: 10.1016/j. neuron.2008.01.020. URL https://www.cell.com/neuron/abstract/S0896-6273(08)00105-0.   \n[20] Nicholas J. Priebe and David Ferster. Mechanisms underlying cross-orientation suppression in cat visual cortex. Nature Neuroscience, 9(4):552\u2013561, April 2006. ISSN 1546-1726. doi: 10.1038/nn1660. URL https://www.nature.com/articles/nn1660. Publisher: Nature Publishing Group.   \n[21] David J. Field, Anthony Hayes, and Robert F. Hess. Contour integration by the human visual system: Evidence for a local \u201cassociation field\u201d. Vision Research, 33(2):173\u2013193, January 1993. ISSN 0042-6989. doi: 10.1016/0042-6989(93)90156-Q. URL https://www.sciencedirect.com/science/article/ pii/004269899390156Q.   \n[22] Robbe L. T. Goris, Eero P. Simoncelli, and J. Anthony Movshon. Origin and Function of Tuning Diversity in Macaque Visual Cortex. Neuron, 88(4):819\u2013831, November 2015. ISSN 1097-4199. doi: 10.1016/j.neuron.2015.10.009.   \n[23] Zhi-Ming Shen, Wei-Feng Xu, and Chao-Yi Li. Cue-invariant detection of centre\u2013surround discontinuity by V1 neurons in awake macaque monkey. The Journal of Physiology, 583(Pt 2):581\u2013592, September 2007. ISSN 0022-3751. doi: 10.1113/jphysiol.2007.130294. URL https://www.ncbi.nlm.nih.gov/ pmc/articles/PMC2277020/.   \n[24] Adam M. Slllito, Kenneth L. Grieve, Helen E. Jones, Javier Cudeiro, and Justin Davls. Visual cortical mechanisms detecting focal orientation discontinuities. Nature, 378(6556):492\u2013496, November 1995. ISSN 1476-4687. doi: 10.1038/378492a0. URL https://www.nature.com/articles/378492a0.   \n[25] Tao Xu, Ling Wang, Xue-Mei Song, and Chao-Yi Li. The Detection of Orientation Continuity and Discontinuity by Cat V1 Neurons. PLoS ONE, 8(11):e79723, November 2013. ISSN 1932-6203. doi: 10. 1371/journal.pone.0079723. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3836789/.   \n[26] H. C. Nothdurft, J. L. Gallant, and D. C. Van Essen. Response modulation by texture surround in primate area V1: correlates of \"popout\" under anesthesia. Visual Neuroscience, 16(1):15\u201334, 1999. ISSN 0952-5238. doi: 10.1017/s0952523899156189.   \n[27] R. von der Heydt and E. Peterhans. Mechanisms of contour perception in monkey visual cortex. I. Lines of pattern discontinuity. The Journal of Neuroscience: The Official Journal of the Society for Neuroscience, 9 (5):1731\u20131748, May 1989. ISSN 0270-6474. doi: 10.1523/JNEUROSCI.09-05-01731.1989.   \n[28] Xue Mei Song, Ming Li, Tao Xu, Dewen Hu, and Anna Wang Roe. Precise Targeting of Single Microelectrodes to Orientation Pinwheel Centers. Bio-protocol, 10(11):e3643, June 2020. ISSN 2331-8325. doi: 10.21769/BioProtoc.3643. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7842334/.   \n[29] Lauren E. Wool, Stanley J. Komban, Jens Kremkow, Michael Jansen, Xiaobing Li, Jose-Manuel Alonso, and Qasim Zaidi. Salience of unique hues and implications for color theory. Journal of Vision, 15(2):10, February 2015. ISSN 1534-7362. doi: 10.1167/15.2.10.   \n[30] J. J. Knierim and D. C. van Essen. Neuronal responses to static texture patterns in area V1 of the alert macaque monkey. Journal of Neurophysiology, 67(4):961\u2013980, April 1992. ISSN 0022-3077. doi: 10.1152/jn.1992.67.4.961.   \n[31] Stanley Jose Komban, Jose-Manuel Alonso, and Qasim Zaidi. Darks Are Processed Faster Than Lights. Journal of Neuroscience, 31(23):8654\u20138658, June 2011. ISSN 0270-6474, 1529-2401. doi: 10.1523/ JNEUROSCI.0504-11.2011. URL https://www.jneurosci.org/content/31/23/8654.   \n[32] Hamed Rahimi-Nasrabadi, Jianzhong Jin, Reece Mazade, Carmen Pons, Sohrab Najafian, and Jose-Manuel Alonso. Image luminance changes contrast sensitivity in visual cortex. Cell Reports, 34(5), February 2021. ISSN 2211-1247. doi: 10.1016/j.celrep.2021.108692. URL https://www.cell.com/cell-reports/ abstract/S2211-1247(21)00005-X.   \n[33] Jean-Luc R. Stevens, Judith S. Law, J\u00e1n Antol\u00edk, and James A. Bednar. Mechanisms for Stable, Robust, and Adaptive Development of Orientation Maps in the Primary Visual Cortex. Journal of Neuroscience, 33 (40):15747\u201315766, October 2013. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.1037-13.2013. URL https://www.jneurosci.org/content/33/40/15747.   \n[34] Matthias Kaschube, Michael Schnabel, Siegrid L\u00f6wel, David M. Coppola, Leonard E. White, and Fred Wolf. Universality in the Evolution of Orientation Columns in the Visual Cortex. Science, 330(6007): 1113\u20131116, November 2010. doi: 10.1126/science.1194869. URL https://www.science.org/doi/ 10.1126/science.1194869.   \n[35] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, volume 2, pages 416\u2013423 vol.2, July 2001. doi: 10.1109/ICCV.2001.937655. URL https://ieeexplore.ieee.org/document/ 937655.   \n[36] Christopher Kanan and Garrison Cottrell. Robust classification of objects, faces, and flowers using natural image statistics. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 2472\u20132479, June 2010. doi: 10.1109/CVPR.2010.5539947. URL https://ieeexplore.ieee. org/document/5539947.   \n[37] Shiming Tang, Tai Sing Lee, Ming Li, Yimeng Zhang, Yue Xu, Fang Liu, Benjamin Teo, and Hongfei Jiang. Complex Pattern Selectivity in Macaque Primary Visual Cortex Revealed by Large-Scale Two-Photon Imaging. Current Biology, 28(1):38\u201348.e3, January 2018. ISSN 0960-9822. doi: 10.1016/j.cub.2017.11. 039. URL https://www.cell.com/current-biology/abstract/S0960-9822(17)31521-X.   \n[38] Arish Alreja, Ilya Nemenman, and Christopher J. Rozell. Constrained brain volume in an efficient coding model explains the fraction of excitatory and inhibitory neurons in sensory cortices. PLOS Computational Biology, 18(1):e1009642, January 2022. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1009642. URL https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009642.   \n[39] Henry Markram, Maria Toledo-Rodriguez, Yun Wang, Anirudh Gupta, Gilad Silberberg, and Caizhi Wu. Interneurons of the neocortical inhibitory system. Nature Reviews Neuroscience, 5(10):793\u2013807, October 2004. ISSN 1471-0048. doi: 10.1038/nrn1519. URL https://www.nature.com/articles/nrn1519.   \n[40] Carsten K. Pfeffer, Mingshan Xue, Miao He, Z. Josh Huang, and Massimo Scanziani. Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons. Nature Neuroscience, 16(8):1068\u20131076, August 2013. ISSN 1546-1726. doi: 10.1038/nn.3446. URL https: //www.nature.com/articles/nn.3446.   \n[41] Narayan Srinivasa and Qin Jiang. Stable learning of functional maps in self-organizing spiking neural networks with continuous synaptic plasticity. Frontiers in Computational Neuroscience, 7, 2013. ISSN 1662-5188. URL https://www.frontiersin.org/articles/10.3389/fncom.2013.00010.   \n[42] Erkki Oja. Simplified neuron model as a principal component analyzer. Journal of Mathematical Biology, 15(3):267\u2013273, November 1982. ISSN 1432-1416. doi: 10.1007/BF00275687. URL https: //doi.org/10.1007/BF00275687.   \n[43] Paul D. King, Joel Zylberberg, and Michael R. DeWeese. Inhibitory Interneurons Decorrelate Excitatory Cells to Drive Sparse Code Formation in a Spiking Model of V1. The Journal of Neuroscience, 33(13): 5475, March 2013. doi: 10.1523/JNEUROSCI.4188-12.2013. URL http://www.jneurosci.org/ content/33/13/5475.abstract.   \n[44] Joel Zylberberg, Jason Timothy Murphy, and Michael Robert DeWeese. A Sparse Coding Model with Synaptically Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of V1 Simple Cell Receptive Fields. PLOS Computational Biology, 7(10):1\u201312, October 2011. doi: 10.1371/journal.pcbi. 1002250. URL https://doi.org/10.1371/journal.pcbi.1002250.   \n[45] Bruno A. Olshausen and David J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381(6583):607\u2013609, June 1996. ISSN 1476-4687. doi: 10.1038/381607a0. URL https://www.nature.com/articles/381607a0.   \n[46] William H. Bosking, Ying Zhang, Brett Schofield, and David Fitzpatrick. Orientation Selectivity and the Arrangement of Horizontal Connections in Tree Shrew Striate Cortex. Journal of Neuroscience, 17(6): 2112\u20132127, March 1997. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.17-06-02112.1997. URL https://www.jneurosci.org/content/17/6/2112.   \n[47] Jonathan C. Horton and Davina R. Hocking. Intrinsic Variability of Ocular Dominance Column Periodicity in Normal Macaque Monkeys. Journal of Neuroscience, 16(22):7228\u20137339, November 1996. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.16-22-07228.1996. URL https://www.jneurosci. org/content/16/22/7228. Publisher: Society for Neuroscience Section: Articles.   \n[48] Shyam Srinivasan, C. Nikoosh Carlo, and Charles F. Stevens. Predicting visual acuity from the structure of visual cortex. Proceedings of the National Academy of Sciences, 112(25):7815\u20137820, June 2015. doi: 10.1073/pnas.1509282112. URL https://www.pnas.org/doi/10.1073/pnas.1509282112.   \n[49] Benjamin Scholl, Johannes Burge, and Nicholas J. Priebe. Binocular integration and disparity selectivity in mouse primary visual cortex. Journal of Neurophysiology, 109(12):3013\u20133024, June 2013. ISSN 0022-3077. doi: 10.1152/jn.01021.2012. URL https://journals.physiology.org/doi/full/10. 1152/jn.01021.2012.   \n[50] Julia Veit, Anwesha Bhattacharyya, Robert Kretz, and Gregor Rainer. On the Relation Between Receptive Field Structure and Stimulus Selectivity in the Tree Shrew Primary Visual Cortex. Cerebral Cortex, 24 (10):2761\u20132771, October 2014. ISSN 1047-3211. doi: 10.1093/cercor/bht133. URL https://doi.org/ 10.1093/cercor/bht133.   \n[51] Edward J. Tehovnik and Warren M. Slocum. Phosphene induction by microstimulation of macaque V1. Brain Research Reviews, 53(2):337\u2013343, February 2007. ISSN 0165-0173. doi: 10.1016/j.brainresrev.2006. 11.001. URL https://www.sciencedirect.com/science/article/pii/S0165017306001160.   \n[52] Cristopher M. Niell and Michael P. Stryker. Highly Selective Receptive Fields in Mouse Visual Cortex. Journal of Neuroscience, 28(30):7520\u20137536, July 2008. ISSN 0270-6474, 1529-2401. doi: 10.1523/ JNEUROSCI.0623-08.2008. URL https://www.jneurosci.org/content/28/30/7520.   \n[53] Enny H. van Beest, Sreedeep Mukherjee, Lisa Kirchberger, Ulf H. Schnabel, Chris van der Togt, Rob R. M. Teeuwen, Areg Barsegyan, Arne F. Meyer, Jasper Poort, Pieter R. Roelfsema, and Matthew W. Self. Mouse visual cortex contains a region of enhanced spatial resolution. Nature Communications, 12(1):4029, June 2021. ISSN 2041-1723. doi: 10.1038/s41467-021-24311-5. URL https://www.nature.com/ articles/s41467-021-24311-5.   \n[54] P. F\u00f6ldi\u00e1k. Forming sparse representations by local anti-Hebbian learning. Biological Cybernetics, 64(2): 165\u2013170, December 1990. ISSN 1432-0770. doi: 10.1007/BF02331346. URL https://link.springer. com/article/10.1007/BF02331346.   \n[55] Alex Thomson and Christophe Lamy. Functional maps of neocortical local circuitry. Frontiers in Neuroscience, 1, 2007. ISSN 1662-453X. URL https://www.frontiersin.org/articles/10.3389/ neuro.01.1.1.002.2007.   \n[56] Carl Holmgren, Tibor Harkany, Bj\u00f6rn Svennenfors, and Yuri Zilberter. Pyramidal cell communication within local networks in layer 2/3 of rat neocortex. The Journal of Physiology, 551(Pt 1):139\u2013153, August 2003. ISSN 0022-3751. doi: 10.1113/jphysiol.2003.044784. URL https://www.ncbi.nlm.nih.gov/ pmc/articles/PMC2343144/.   \n[57] Sonja B. Hofer, Ho Ko, Bruno Pichler, Joshua Vogelstein, Hana Ros, Hongkui Zeng, Ed Lein, Nicholas A. Lesica, and Thomas D. Mrsic-Flogel. Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex. Nature Neuroscience, 14(8):1045\u20131052, August 2011. ISSN 1546-1726. doi: 10.1038/nn.2876. URL https://www.nature.com/articles/nn.2876.   \n[58] Tatsuo K. Sato, Bilal Haider, Michael H\u00e4usser, and Matteo Carandini. An excitatory basis for divisive normalization in visual cortex. Nature Neuroscience, 19(4):568\u2013570, April 2016. ISSN 1546-1726. doi: 10.1038/nn.4249. URL https://www.nature.com/articles/nn.4249.   \n[59] Min Song, Jaeson Jang, Gwangsu Kim, and Se-Bum Paik. Projection of Orthogonal Tiling from the Retina to the Visual Cortex. Cell Reports, 34(1), January 2021. ISSN 2211-1247. doi: 10.1016/j.celrep.2020. 108581. URL https://www.cell.com/cell-reports/abstract/S2211-1247(20)31570-9.   \n[60] Eshed Margalit, Hyodong Lee, Dawn Finzi, James J. DiCarlo, Kalanit Grill-Spector, and Daniel L. K. Yamins. A Unifying Principle for the Functional Organization of Visual Cortex, May 2023. URL https://www.biorxiv.org/content/10.1101/2023.05.18.541361v1.   \n[61] Leon Lufkin, Ashish Puri, Ganlin Song, Xinyi Zhong, and John Lafferty. Emergent organization of receptive fields in networks of excitatory and inhibitory neurons. May 2022. doi: 10.48550/arXiv.2205.13614.   \n[62] Louis Tao, Michael Shelley, David McLaughlin, and Robert Shapley. An egalitarian network model for the emergence of simple and complex cells in visual cortex. Proceedings of the National Academy of Sciences, 101(1):366\u2013371, January 2004. doi: 10.1073/pnas.2036460100. URL https://www.pnas.org/doi/ full/10.1073/pnas.2036460100.   \n[63] Armen Stepanyants, Luis M. Martinez, Alex S. Ferecsk\u00f3, and Zolt\u00e1n F. Kisv\u00e1rday. The fractions of shortand long-range connections in the visual cortex. Proceedings of the National Academy of Sciences, 106(9): 3555\u20133560, March 2009. doi: 10.1073/pnas.0810390106. URL https://www.pnas.org/doi/abs/10. 1073/pnas.0810390106.   \n[64] Joseph M. Amatrudo, Christina M. Weaver, Johanna L. Crimins, Patrick R. Hof, Douglas L. Rosene, and Jennifer I. Luebke. Influence of Highly Distinctive Structural Properties on the Excitability of Pyramidal Neurons in Monkey Visual and Prefrontal Cortices. Journal of Neuroscience, 32(40):13644\u2013 13660, October 2012. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.2581-12.2012. URL https://www.jneurosci.org/content/32/40/13644.   \n[65] David Ferster, Sooyoung Chung, and Heidi Wheat. Orientation selectivity of thalamic input to simple cells of cat visual cortex. Nature, 380(6571):249\u2013252, March 1996. ISSN 1476-4687. doi: 10.1038/380249a0. URL https://www.nature.com/articles/380249a0.   \n[66] Colin Blakemore and Elisabeth A. Tobin. Lateral inhibition between orientation detectors in the cat\u2019s visual cortex. Experimental Brain Research, 15(4):439\u2013440, September 1972. ISSN 1432-1106. doi: 10.1007/BF00234129. URL https://doi.org/10.1007/BF00234129.   \n[67] A. B. Bonds. Role of inhibition in the specification of orientation selectivity of cells in the cat striate cortex. Visual Neuroscience, 2(1):41\u201355, 1989. ISSN 0952-5238. doi: 10.1017/s0952523800004314.   \n[68] David H. Douglas and Thomas K. Peucker. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Cartographica: The International Journal for Geographic Information and Geovisualization, 10(2):112\u2013122, 1973. Publisher: University of Toronto Press.   \n[69] Edward J. Tehovnik and Kyoungmin Lee. The dorsomedial frontal cortex of the rhesus monkey: topographic representation of saccades evoked by electrical stimulation. Experimental Brain Research, 96(3):430\u2013442, November 1993. ISSN 1432-1106. doi: 10.1007/BF00234111. URL https://doi.org/10.1007/ BF00234111.   \n[70] Andrew D. Huberman, Colenso M. Speer, and Barbara Chapman. Spontaneous Retinal Activity Mediates Development of Ocular Dominance Columns and Binocular Receptive Fields in V1. Neuron, 52(2): 247\u2013254, October 2006. ISSN 0896-6273. doi: 10.1016/j.neuron.2006.07.028. URL https://www.cell. com/neuron/abstract/S0896-6273(06)00625-8.   \n[71] Andrzej T. Foik, Leo R. Scholl, Georgina A. Lean, and David C. Lyon. Visual Response Characteristics in Lateral and Medial Subdivisions of the Rat Pulvinar. Neuroscience, 441:117\u2013130, August 2020. ISSN 0306-4522. doi: 10.1016/j.neuroscience.2020.06.030. URL https://www.sciencedirect.com/ science/article/pii/S0306452220304073.   \n[72] W C Hall, J H Kaas, H Killackey, and I T Diamond. Cortical visual areas in the grey squirrel (Sciurus carolinesis): a correlation between cortical evoked potential maps and architectonic subdivisions. Journal of Neurophysiology, 34(3):437\u2013452, May 1971. ISSN 0022-3077. doi: 10.1152/jn.1971.34.3.437. URL https://journals.physiology.org/doi/abs/10.1152/jn.1971.34.3.437.   \n[73] Marvin Weigand, Fabio Sartori, and Hermann Cuntz. Universal transition from unstructured to structured neural maps. Proceedings of the National Academy of Sciences, 114(20):E4057\u2013E4064, May 2017. doi: 10.1073/pnas.1616163114. URL https://www.pnas.org/doi/full/10.1073/pnas.1616163114.   \n[74] Margaret I. Law, Kathleen R. Zahs, and Michael P. Stryker. Organization of primary visual cortex (area 17) in the ferret. Journal of Comparative Neurology, 278(2):157\u2013180, 1988. ISSN 1096-9861. doi: 10.1002/ cne.902780202. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.902780202.   \n[75] Jason Keller, Hans Strasburger, Daniel T Cerutti, and Bernhard A Sabel. Assessing spatial vision automated measurement of the contrast-sensitivity function in the hooded rat. Journal of Neuroscience Methods, 97(2):103\u2013110, April 2000. ISSN 0165-0270. doi: 10.1016/S0165-0270(00)00173-4. URL https://www.sciencedirect.com/science/article/pii/S0165027000001734.   \n[76] Ralf Engelmann and Leo Peichl. Unique Distribution of Somatostatin-immunoreactive Cells in the Retina of the Tree Shrew (Tupaia belangeri). European Journal of Neuroscience, 8(1):220\u2013228, 1996. ISSN 1460-9568. doi: 10.1111/j.1460-9568.1996.tb01183.x. URL https://onlinelibrary.wiley.com/ doi/abs/10.1111/j.1460-9568.1996.tb01183.x.   \n[77] A. Hughes. A schematic eye for the rat. Vision Research, 19(5):569\u2013588, January 1979. ISSN 0042-6989. doi: 10.1016/0042-6989(79)90143-3. URL https://www.sciencedirect.com/science/article/ pii/0042698979901433.   \n[78] Haoyu Wang, Haixin Zhong, Wei P. Dai, and Yuguo Yu. The Functional Role of Pinwheel Topology in the Primary Visual Cortex of High-Order Animals for Complex Natural Image Representation, March 2024. URL https://www.biorxiv.org/content/10.1101/2024.03.07.583885v1. Pages: 2024.03.07.583885 Section: New Results.   \n[79] Anna W. Roe, Leonardo Chelazzi, Charles E. Connor, Bevil R. Conway, Ichiro Fujita, Jack L. Gallant, Haidong Lu, and Wim Vanduffel. Toward a Unified Theory of Visual Area V4. Neuron, 74(1):12\u201329, April 2012. ISSN 0896-6273. doi: 10.1016/j.neuron.2012.03.011. URL https://www.cell.com/neuron/ abstract/S0896-6273(12)00274-7. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Appendices ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Exponential moving average ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We compute the network\u2019s neuronal instantaneous spike rates as exponential moving averages (EMAs), which accumulate spikes over time (see Eq. 9). EMAs are utilized to track recent neuronal activity levels. Concurrently, lifetime average values are also calculated using EMAs, which are crucial for maintaining homeostatic stability. This method helps stabilize the neural network by adjusting neuronal properties or synaptic strengths to sustain consistent activity levels over time. ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{j}(t)=(1-\\zeta)x_{j}(t-1)+\\zeta\\cdot z_{j}(t),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\zeta=1-e^{-\\frac{1}{10}}$ , indicating that the $10\\,\\mathrm{ms}$ is a temporal window of the moving average weighted with exponential decay. The initialization of $x_{j}$ is 0. The exponential moving average is calculated dynamically and updated along with synaptic weights. ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle x_{j}\\rangle:=(1-\\xi)\\cdot\\langle x_{j}\\rangle+\\xi\\cdot\\overline{{x}}_{j},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\xi=1-e^{-1}$ . It is dynamically updated to ensure the sum of the weights remains constant over time. ", "page_idx": 15}, {"type": "text", "text": "A.2 Detailed parameters and connectivity settings for SESNN ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Detailed neural dynamics: The FF connection, labeled Fi(jimage\u2192E), links pixel Xj of the whitened image patch to E-neuron i. W i(jK\u2192K) signifies the synaptic weight from neuron $j$ of neuron class $\\mathrm{K}^{\\ast}$ to neuron $i$ of neuron class $\\mathrm{K}$ , with its sign determined by the connection type, described as \u03b2i(jK\u2192K)(the neuron receives excitatory connections, set as +1; conversely, the neuron receives inhibitory connections, the sign is set as -1). $z_{j}^{(\\mathrm{K}^{*})}\\left(t\\right)$ indicates the spike output of neuron $j$ at time $t$ Upon reaching the spike threshold $\\theta$ (initialized as 2), a spike is emitted, zj(K\u2217)(t) is set to 1, then the membrane potential is reset to $0\\;\\mathrm{mV}_{\\mathrm{s}}$ , remaining so until the refractory period $\\mathrm{3\\ms},$ concludes. Within V1, homeostatic plasticity [33, 54] ensures neural activity stability by dynamically adjusting the firing threshold $\\theta$ . This adjustment is based on the deviation of the current firing rate $p_{i}\\left(t\\right)$ from the target rates $p_{i}^{(\\mathrm{K)}}$ $(p^{(\\mathrm{E})}=2$ , $p^{(\\mathrm{I})}=4,$ , as outlined in Eq. 6 [54]. We assign $\\tau^{\\mathrm{(E)}}=10$ ms for E-neurons and $\\tau^{(\\mathrm{I})}=5$ ms for I-neurons. To enhance computational efficiency, we set the time step to $1~\\mathrm{ms}$ . ", "page_idx": 15}, {"type": "text", "text": "Hyperparameters: For the synaptic plasticity,learning rates are $\\eta_{\\mathrm{FF}}=0.2$ (image to E-neuron), $\\eta_{\\mathrm{EE}}=0.01$ (E- to E-neuron), $\\eta_{\\mathrm{EI}}=0.7$ (I- to E-neuron), $\\eta_{\\mathrm{II}}=1.5$ (I- to I-neuron), and $\\eta_{\\mathrm{IE}}=0.7$ (Eto I-neuron), while the neural connectivity parameters are $\\alpha_{\\mathrm{max,E}}=1.0$ (E- max weight), $\\alpha_{\\mathrm{max,I}}=0.5$ (I- max weight), $\\sigma_{\\mathrm{EE}}=3.5$ (E-E coupling range), $\\sigma_{\\mathrm{EI}}=2.9$ (E-I coupling range), $\\sigma_{\\mathrm{IE}}=2.6$ (I-E coupling range), and $\\sigma_{\\mathrm{II}}=2.1$ (I-I coupling range). ", "page_idx": 15}, {"type": "text", "text": "Neural connectivity within 2D cortical area: $\\mathrm{E}-$ and $\\scriptstyle\\mathrm{I}-$ neurons are arranged symmetrically on a two-dimensional lattice, as illustrated in Fig. 5b. PBCs are employed to mimic the large number of neurons in the actual V1 cortical surface. Specifically, neurons at the boundary are connected to neurons at corresponding symmetric positions on the opposite boundary. The initial connection weights between neurons are modeled by a Gaussian function of their distance (see Fig. 5c), which can be expressed as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nW_{0}^{\\mathrm{K^{*}\\rightarrow K}}\\left(i,j\\right)=\\alpha_{\\mathrm{K^{*}}}\\times\\exp\\left(\\frac{-d\\left(i,j\\right)^{2}}{2{\\sigma_{\\mathrm{K^{*}}}}^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In this equation, $d(i,j)$ represents the Euclidean distance from neuron $i$ to neuron $j$ in a grid, $\\alpha$ determines the maximum connection weight, which is set to $\\alpha_{\\mathrm{EE}}=1$ , $\\alpha_{\\mathrm{EI}}=1$ , $\\alpha_{\\mathrm{IE}}=0.5$ , $\\alpha_{\\mathrm{II}}=0.5$ , and $\\sigma$ governs the rate at which the weight decays with distance. The synaptic types predominantly determine the parameters for this connection weight distribution function. To accurately replicate the neuronal architecture of V1 in macaques. The connectivity radiuses, denoted by $\\sigma$ , are set to $\\sigma_{\\mathrm{EE}}=3.5$ , $\\sigma_{\\mathrm{EI}}=2.9$ , $\\sigma_{\\mathrm{IE}}=2.6$ , $\\sigma_{\\mathrm{II}}=2.1$ . These values are based on anatomical data indicating that the axon length scales of $\\mathrm{E}-$ and I-neurons are approximately $200\\,\\mu\\mathrm m$ and $100\\;\\mu\\mathrm{m}$ , respectively, while the dendrite length scales are around $150\\;\\mu\\mathrm{m}$ for $\\boldsymbol{\\mathrm E}$ -neurons and $75\\:\\mu\\mathrm{m}$ for I-neurons in the V1 [62, 63, 64]. We prune any connection strengths below a threshold of 0.01 to maintain computational efficiency and biological plausibility. ", "page_idx": 15}, {"type": "text", "text": "A.3 Anatomical data integration ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Neural connection data ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The experimental subjects include six adult cats with unknown genders, with data sourced from research by Armen Stepanyants et al.[63]; and eight macaques, aged 5-11 years, including six males and two females, with data sourced from research by Joseph Amatrudo et al.[64]. ", "page_idx": 16}, {"type": "text", "text": "Neuronal synaptic plasticity ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The subjects are rats aged 14-16 days, with unknown gender and quantity, with data sourced from research by Holmgren et al.[56]; transgenic mice, with unknown quantity and gender, with data sourced from research by Hofer et al. [57]. ", "page_idx": 16}, {"type": "text", "text": "Retinal-V1 topological projection data ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Receptive field data: V1 neuron counts for macaques, cats, tree shrews, ferrets, mice, rats, and gray squirrels respectively come from Tehovnik et al. [69] (subjects: 3 macaques, unknown gender and age), Scholl et al. [49] (subjects: cats, unknown gender and age), Veit et al.[50] (subjects: 9 male and 7 female tree shrews, aged 3-8 years), Huberman et al.[70] (subjects: 8 ferrets, unknown gender and age), Niell et al.[52] (subjects: mice, aged 2\u20136 months, unknown gender), Foik et al.[71](subjects: 21 rats, unknown gender and age), and Hall et al.[72] (subjects: 17 gray squirrels, unknown gender and age). V1 neuron density: Neuron density data for macaques, cats, mice, rats, and gray squirrels come from Srinivasana et al.[51] (subjects: unknown gender and age); tree shrew, ferret, and gray squirrel density data respectively come from Weigand et al.[73]. ", "page_idx": 16}, {"type": "text", "text": "Cortical magnification factor ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Cortical magnification factor data for macaques, cats, tree shrews, ferrets, mice, rats, and gray squirrels are sourced from Tehovnik et al.[69] (subjects: 3 macaques, unknown gender and age), Veit et al.[50](subjects: cats, unknown gender and age), Bosking et al.[46] (subjects: tree shrews, unknown gender and age), Rockland et al. [74] (subjects: 9 ferrets, female, unknown age), Beest et al.[53] (subjects: 28 mice, 11 males and 17 females, ages 2-14 months), Keller et al.[75] (subjects: male rats, age 3 months), and Hall et al.[72] (subjects: 17 gray squirrels, unknown gender and age). ", "page_idx": 16}, {"type": "text", "text": "Additionally, the anatomical data concerning inter-ocular distances are obtained from Najafian et al.   \n[7]. ", "page_idx": 16}, {"type": "text", "text": "A.4 Unveiling species-specific factors distinguishing pinwheels and salt-and-peppers ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A.4.1 Anatomical data suggests RFs density underlying V1 organizations ", "text_level": 1, "page_idx": 16}, {"type": "table", "img_path": "LPkcoml66W/tmp/d1ae4dc47e06939ce20a9b2cecd56fbd3f8b9ab5e31943f713f8acd8beb20c00.jpg", "table_caption": ["Table 3: Comparative anatomical data of the retina and V1 across species. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "We analyzed anatomical data from seven species, including primates (e.g., macaques) and nonprimates (e.g., mice, rats, cats, tree shrews, gray squirrels, and ferrets), as detailed in Table 3. We first find that V1 RFD $(\\rho_{\\mathrm{RF}})$ acts as a linear classifier $\\stackrel{.}{(y=4.42\\times10^{4}x)}$ , effectively distinguishing species with pinwheel structures from those with salt-and-pepper organizations. In this classifier, species like macaques, cats, tree shrews, and ferrets, which have higher RFD, are associated with pinwheel structures (light red area in Fig. 6) and exceed the classification threshold. In contrast, species with lower RFD, such as mice, rats, and gray squirrels, are linked to salt-and-pepper organizations (light blue area in Fig. 6). Thus, V1 RFD serves as a predictive metric for V1 organizational patterns across species. The $\\rho_{\\mathrm{RF}}$ is calculated as follows: ", "page_idx": 16}, {"type": "image", "img_path": "LPkcoml66W/tmp/dcc2c7c39f24355a33d48a66291c39108b48e62fa05bc286730cc239e5021df7.jpg", "img_caption": ["Figure 6: A linear classifier based on RFD $(y\\,=\\,4.42\\,\\times\\,10^{4}x)$ effectively differentiates species with salt-and-pepper organizations (rats, mice, gray squirrels) from those with pinwheel structures (macaques, ferrets, cats, tree shrews). a. This classifier reflects variations in V1 organizations across species. b. A plot categorizing species by the ratio of V1 neuron number to retina size acts as a divider, implying a critical ratio for the formation of pinwheel structures. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "equation", "text": "$$\n\\rho_{\\mathrm{RF}}=\\frac{n}{s_{\\mathrm{r}}}=\\frac{n}{\\left[\\left(s_{\\mathrm{RF}}-\\varepsilon\\right)\\left(\\sqrt{n}-1\\right)+s_{\\mathrm{RF}}\\right]^{2}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $n$ denotes the total number of neurons in V1, $s_{\\mathrm{r}}$ indicates the retinal surface area, $s_{\\mathrm{V}1}$ corresponds to the V1 2D surface area, and $\\rho_{\\mathrm{V}1}$ signifies the neuronal density within V1. The variable $\\varepsilon$ quantifies the degree of visual input overlap among adjacent neurons, and $s_{\\mathrm{RF}}$ represents the RF size. Concerning the Eq. 12 and anatomical data (Table 3), the two main factors influencing RFD $\\rho_{\\mathrm{RF}}$ are the overlap $\\varepsilon$ of visual inputs between adjacent RFs and V1 neuronal density $\\rho_{V1}$ . We discuss the overlap in the main text. Neuronal density is discussed in the following sections. ", "page_idx": 17}, {"type": "image", "img_path": "LPkcoml66W/tmp/a5821bef9bfde2d0b8080c88720a23a03d04d9ca8e2bb0b5974a6bf1ed9907e9.jpg", "img_caption": ["A.4.2 SESNN reveals neuronal connection range influencing V1 clusters "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 7: Neuronal connection range within V1 contributes to the formation of pinwheel structures. a. Modifying the synaptic connection range reshapes the dimensions of pinwheel structures. b-d. The relationship between the synaptic connection range $(\\sigma)$ and the number of pinwheels, NNPD (mm), and hypercolumn size (mm). The scale bar: $1\\;\\mathrm{mm}$ in V1 cortical surface. Color scheme: orientation preference. Lines: mean. Shaded area: SD. ", "page_idx": 17}, {"type": "text", "text": "The anatomical data in Table 3d for seven species show variability in V1 neuronal density $(\\rho_{\\mathrm{V}1})$ , which influences inter-neuronal spacing and connection strength. We explore how V1 cortical orientation patterns form by adjusting the lateral connection range, impacting axon reach among Eand I-neurons, as depicted in Fig. 7. We modulate axonal arborization through parameter $\\sigma$ to adjust the connection range, allowing us to simulate neuronal connections in areas with varying densities. This setup enables the SESNN model to predict changes in cortical patterns (Fig. 7). Our observations indicate that increasing axon lengths, thereby extending the connection range, enlarges hypercolumn sizes within pinwheel structures (Fig. 7d), reduces the overall number of pinwheels (Fig. 7b), and increases NNPD (Fig. 7c). These findings underscore the critical role of neural synaptic connection range in organizing orientation maps. ", "page_idx": 18}, {"type": "text", "text": "A.5 Relationship between maximum values of local pixel entropy and local geometrical entropy for various shapes ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To address the limitations of using local pixel entropy (LPE) with sliding windows alone to capture complex geometric properties, we conduct a new analysis comparing the maximum values of LPE with local geometrical entropy (LGE) across various shapes. These shapes include lines, angles, and junctions (L-, T-, X-junctions), as well as jagged edges. Both LPE and LGE values were normalized to the range [0,1] for consistency. ", "page_idx": 18}, {"type": "text", "text": "Let $P=\\{v_{1},v_{2},\\ldots,v_{n}\\}$ be a polygon with vertices $v_{i}=(x_{i},y_{i})$ , where $i=1,2,\\dots,n$ . The edges of the polygon are the line segments between consecutive vertices, denoted as $e_{i}=\\|v_{i+1}-v_{i}\\|$ , where $\\Vert\\cdot\\Vert$ represents the Euclidean distance. The angle $\\theta_{i}$ between two consecutive edges $e_{i}$ and $e_{i+1}$ can be computed using the dot product: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\theta_{i}=\\cos^{-1}\\left(\\frac{e_{i}\\cdot e_{i+1}}{\\|e_{i}\\|\\|e_{i+1}\\|}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "With the set of edge lengths $\\{e_{1},e_{2},\\ldots,e_{n}\\}$ and angles $\\{\\theta_{1},\\theta_{2},\\ldots,\\theta_{n}\\}$ , we calculate the entropy for both distributions. The entropy $H$ of a discrete distribution $X$ with probability mass function $p(x)$ is given by: ", "page_idx": 18}, {"type": "equation", "text": "$$\nH(X)=-\\sum_{x\\in X}p(x)\\log p(x).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For the edge lengths and angles, the probability mass function is estimated by normalizing the frequency of occurrence of each unique edge length and angle in the polygon: ", "page_idx": 18}, {"type": "equation", "text": "$$\nH(\\mathrm{Lengths})=-\\sum_{i=1}^{n}p(e_{i})\\log p(e_{i}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\nH(\\mathbf{A}\\mathbf{ngles})=-\\sum_{i=1}^{n}p(\\theta_{i})\\log p(\\theta_{i}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "To enhance the sensitivity of geometrical entropy to structural complexity, particularly in differentiating shapes that have similar edge lengths and angles but different structural arrangements, we introduce a scaling factor based on the logarithm of the number of vertices $n$ . The defined geometrical entropy (GE) with the scaling factor is thus defined as: ", "page_idx": 18}, {"type": "equation", "text": "$$\nG E=(H(\\mathrm{Lengths})+H(\\mathrm{Angles}))\\times\\log(n).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This modification allows GE to capture additional complexity arising from intersections and the global arrangement of vertices, providing a more comprehensive assessment of the shape\u2019s structural intricacies. ", "page_idx": 18}, {"type": "text", "text": "Our results, summarized in Table 4, show that while LPE can reflect the complexity of certain patterns, it does not fully capture the geometric variations seen in more intricate shapes. For instance, the LPE values for line structures remain relatively low compared to those for jagged edges, which have the highest LPE and LGE values due to their high structural complexity. This comparison highlights the added value of incorporating LGE to better characterize local geometric structures, providing a more nuanced measure of complexity that includes both intensity distribution and spatial organization. ", "page_idx": 19}, {"type": "table", "img_path": "LPkcoml66W/tmp/1d46db822e59eeef3ae9b7f083a4800a6e467ae2febe25d1865af094a98ca04f.jpg", "table_caption": ["Table 4: Relationship between maximum values of LPE and LGE for various shapes. Both metrics are normalized to the range [0,1]. ", "A.6 Pinwheel centers response to different orientation bandwidths "], "table_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "LPkcoml66W/tmp/0f411bbd34631a9b3663a4c9c09335e299cefad887a8bb3db0d8f057c387d97b.jpg", "img_caption": ["Figure 8: PCs in V1 prefer orientations and ablation study. a. Probability distribution of preferred acute angles in PCs. b. Ablation study on normalized complexity across response onset latencies. Data: mean $\\pm\\,S\\mathbf{D}$ . "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Understanding the tuning of PCs in V1 to edges, corners, and junctions is essential. In Fig. 4e, we show that PCs exhibit broader orientation tuning curves than IODs when using star-like patterns as stimuli, potentially enabling the detection of T-junctions and corners, as demonstrated by Ming Li et al. [13] and Erin Koch et al. [12]. We further examine the distribution of PCs\u2019 tuning curves using gratings as inputs, specifically analyzing acute angles formed by the primary and secondary peaks (Fig. 8a). This analysis reveals that PCs are more frequently associated with larger acute angles, closer to orthogonal $(90^{\\circ})$ , suggesting a preference for orthogonal junctions. However, this result does not differentiate between L- and $\\mathrm{T}-$ junctions based solely on angle. We propose that such high-order feature extraction be deferred to higher visual cortices, like V2 and V4, which are involved in texture detection, as noted by Tianye Wang et al. [78] and Anna W. Roe et al. [79]. ", "page_idx": 19}, {"type": "text", "text": "A.7 Ablation study ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We present a mechanism of multiple orientation tuning that is essential for processing complexity. Our analysis of PCs\u2019 preferred acute angles (Fig. 8a) suggests that their broad tuning enables the detection of complex junctions, such as T- and L-junctions, likely due to variations in local connectivity within and between IODs. ", "page_idx": 19}, {"type": "text", "text": "To test this, we conduct an ablation study by disrupting local connectivity and shuffling the spatial arrangement of orientation-tuned RFs in the pinwheel orientation map, while keeping other properties constant (Fig. 8b). The control group (red) maintains higher complexity over time, whereas shuffilng connections\u2014especially both feedforward and lateral\u2014resulted in a decline in complexity. This highlights the importance of structured connectivity in preserving complex neural responses in V1 and supports the conclusion that structured connectivity underlies enhanced saliency detection by pinwheels. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "A.8 Computing infrastructure ", "text_level": 1, "page_idx": 20}, {"type": "table", "img_path": "LPkcoml66W/tmp/fb8497913a1feb73b5d3bd6f9da97d68a002d55caa9a89b6ba22e021bc2e867f.jpg", "table_caption": ["Table 5: Computing infrastructure "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "The simulations and analyses in this study are performed on a high-performance computing infrastructure to ensure efficient processing of large datasets and complex models. The system is powered by an Intel $\\textsuperscript{\\textregistered}$ Xeon $^\\mathrm{\\textregistered}$ Gold 6348 CPU running at $2.60\\:\\mathrm{GHz}$ and an NVIDIA A100 GPU, providing robust computational power for intensive tasks. The system includes $512\\;\\mathrm{GB}$ of memory, which supports handling memory-intensive applications and large-scale simulations. The operating system used is Ubuntu 20.04.6 LTS, known for its stability and compatibility with scientific software. The simulations are conducted using MATLAB R2023a and Python 3.9, both of which are widely used in scientific computing and neural modeling, enabling effective implementation and analysis of the models presented in this study. ", "page_idx": 20}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The abstract and introduction section state the claims made. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 21}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We discussed over the potential limitations in the last paragraph of the discussion. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 21}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper does not include theoretical results. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 22}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: The information for reproducing the experiments are provided in the methods section and the appendix. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The data and codes are available on request from the authors. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 23}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The training and test details are provided in Methods section 2.1. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 23}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: he errorbars and statistical significance are provided for each data analysis. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The computer resources used are described in the appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 24}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The research conform with the NeurIPS Code of Ethics. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 24}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our work mainly focus on explaning the biological mechanisms underline pinwheel structure in the visual system, thus has no societal impact. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 25}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: The used open-access data and code are explained and cited in Methods section and Appendix accordingly. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 25}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The details of the code and model are part of the submissions including details about training in Methods section and limitations in discussion. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 26}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 26}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 26}]