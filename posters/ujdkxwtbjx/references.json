{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper is foundational to the field of large language models, establishing the effectiveness of few-shot learning."}, {"fullname_first_author": "OpenAI", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-00", "reason": "As a leading model in mathematical reasoning, GPT-4 is used extensively in this paper for data synthesis and comparison."}, {"fullname_first_author": "Zhihong Shao", "paper_title": "DeepSeekMath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-00", "reason": "This paper introduces a strong baseline model, DeepSeekMath, for mathematical reasoning, against which JiuZhang3.0 is compared."}, {"fullname_first_author": "Yiming Huang", "paper_title": "Key-point-driven data synthesis with its enhancement on mathematical reasoning", "publication_date": "2024-03-00", "reason": "This paper presents a competing method that also uses data synthesis for improving mathematical reasoning, allowing for direct comparison."}, {"fullname_first_author": "Long Long Yu", "paper_title": "MetaMath: Bootstrap your own mathematical questions for large language models", "publication_date": "2023-09-00", "reason": "This paper explores a similar technique of using strong LLMs to generate mathematical problems, providing another point of comparison and analysis."}]}