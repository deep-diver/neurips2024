[{"figure_path": "q5CkneUn6K/figures/figures_1_1.jpg", "caption": "Figure 1: Structured cognition on sequential contexts. Humans may easily identify a given passage's topic/scope, break down the text sentences into several aspect points with detailed descriptions, and form a tree-like knowledge structure.", "description": "This figure illustrates the human process of understanding a text.  It shows how humans don't just read sequentially, but rather organize information into a hierarchical structure. Starting with the overall topic (Scope), they then break it down into key aspects, each supported by detailed descriptions. This structured understanding allows for efficient information retrieval and comparison.", "section": "1 Introduction"}, {"figure_path": "q5CkneUn6K/figures/figures_2_1.jpg", "caption": "Figure 2: Framework overview. When instructed to generate responses based on vanilla long-form and sophisticated contexts, LLMs often lose their focus and give unreliable answers due to their limited cognition capability. In contrast, we structurize the vanilla context by using our StruXGPT to identify its main scope and aspect points, facilitating the original LLMs to comprehend the context and generate accurate responses.", "description": "This figure illustrates the core idea of the paper: context structurization.  It shows how Large Language Models (LLMs) struggle to answer questions accurately when presented with long and complex (vanilla) contexts.  The proposed solution is to pre-process the context using the StruXGPT model, organizing it into a structured format (structurized context) that highlights the main points and aspects. This allows the LLMs to better understand the context and provide more accurate responses. The diagram visually represents the improvement in the LLM's ability to generate accurate answers using the structurized version of the context.", "section": "1 Introduction"}, {"figure_path": "q5CkneUn6K/figures/figures_3_1.jpg", "caption": "Figure 1: Structured cognition on sequential contexts. Humans may easily identify a given passage's topic/scope, break down the text sentences into several aspect points with detailed descriptions, and form a tree-like knowledge structure.", "description": "This figure illustrates the human cognitive process of understanding sequential contexts.  It shows how humans naturally organize information hierarchically, starting with identifying the main topic or scope. Then, they break down the text into key aspects and further elaborate on each aspect with detailed descriptions.  This creates a structured representation of the information, which is more easily processed and remembered than a linear sequence of sentences.  This figure motivates the paper's core concept of context structurization, which aims to replicate this human cognitive process in LLMs.", "section": "1 Introduction"}, {"figure_path": "q5CkneUn6K/figures/figures_4_1.jpg", "caption": "Figure 4: Left: templates to transform structurization results into natural languages, with special linguistic markers to preserve and highlight the extracted knowledge structure. Right: transformed context examples with clear information structure for long-form reading comprehension (upper) and hallucination detection (lower) tasks.", "description": "This figure demonstrates two different methods of transforming structured data back into natural language for LLMs to process. The left side shows general templates to maintain the structured knowledge hierarchy using specific linguistic markers.  The right side provides examples of these templates applied to reading comprehension and hallucination detection tasks. This transformation helps LLMs better understand the information in long-form text by presenting it in a clear and structured format.", "section": "3.2 Effective Utilization of Structurization"}, {"figure_path": "q5CkneUn6K/figures/figures_5_1.jpg", "caption": "Figure 2: Framework overview. When instructed to generate responses based on vanilla long-form and sophisticated contexts, LLMs often lose their focus and give unreliable answers due to their limited cognition capability. In contrast, we structurize the vanilla context by using our StruXGPT to identify its main scope and aspect points, facilitating the original LLMs to comprehend the context and generate accurate responses.", "description": "This figure illustrates the core idea of the paper: context structurization.  It shows how LLMs, when given unstructured long-form text, struggle to generate accurate responses because of their limited ability to grasp complex, multifaceted information.  The framework proposes using StruXGPT to transform the unstructured context into a structured representation (highlighting scope and aspects). This structured input helps LLMs to focus, understand the context, and consequently generate more accurate and reliable answers.", "section": "1 Introduction"}, {"figure_path": "q5CkneUn6K/figures/figures_15_1.jpg", "caption": "Figure 1: Structured cognition on sequential contexts. Humans may easily identify a given passage's topic/scope, break down the text sentences into several aspect points with detailed descriptions, and form a tree-like knowledge structure.", "description": "This figure illustrates the concept of structured cognition in humans when processing sequential contexts.  It shows how humans don't just read text linearly but instead identify the main topic (scope), break it down into key aspects, and then elaborate on each aspect with detailed descriptions.  This creates a hierarchical understanding of the text, similar to a tree structure. This is in contrast to how LLMs typically process text sequentially, which the paper argues limits their understanding of complex information.", "section": "1 Introduction"}, {"figure_path": "q5CkneUn6K/figures/figures_16_1.jpg", "caption": "Figure 2: Framework overview. When instructed to generate responses based on vanilla long-form and sophisticated contexts, LLMs often lose their focus and give unreliable answers due to their limited cognition capability. In contrast, we structurize the vanilla context by using our StruXGPT to identify its main scope and aspect points, facilitating the original LLMs to comprehend the context and generate accurate responses.", "description": "This figure illustrates the core concept of the paper, which is to enhance LLMs' ability to understand complex text by first structuring it using StruXGPT. The left side shows the process of transforming a vanilla context into a structured format, and the right side shows the subsequent processing by the LLM, which results in accurate responses compared to processing the vanilla text.", "section": "1 Introduction"}]