[{"figure_path": "oZy4a11SUg/tables/tables_6_1.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance comparison of different methods (including baselines and the proposed ASSISTRAG) across three question answering datasets: HotpotQA, 2Wiki, and Bamboogle.  The performance is measured using Exact Match (EM), F1 score, and Precision (Prec.).  It shows the results for different main LLMs (LLaMA2-chat 7B, ChatGLM 6B, and ChatGPT3.5) used in conjunction with each method.  The best and second best results are highlighted for easy comparison.", "section": "5 Results and Analysis"}, {"figure_path": "oZy4a11SUg/tables/tables_7_1.jpg", "caption": "Table 2: Ablation Studies of ASSISTRAG.", "description": "This table presents the results of ablation studies conducted on the ASSISTRAG model. It shows the impact of removing or freezing different components of the model, including memory management (FNT), and knowledge management (FQD, FKE). It also shows the effect of removing the planning, curriculum, and DPO training phases.  The results are presented as F1 scores for three different datasets: HotpotQA, 2Wiki, and Bamboogle.", "section": "5.2 Analysis"}, {"figure_path": "oZy4a11SUg/tables/tables_7_2.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance comparison of different methods on three question answering datasets: HotpotQA, 2Wiki, and Bamboogle.  The methods include baselines (without and with retrieval), state-of-the-art RAG methods, and the proposed ASSISTRAG.  For each dataset and method, the Exact Match (EM), F1-score, and precision (Prec.) are reported, allowing for a comprehensive evaluation of accuracy.  The \"Main LLM\" column specifies the large language model used for final answer generation in each method.", "section": "4 Experimental Setup"}, {"figure_path": "oZy4a11SUg/tables/tables_9_1.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance of different methods across three question answering datasets: HotpotQA, 2WikiMultiHopQA, and Bamboogle.  The methods compared include various baselines (without and with retrieval), advanced prompt-based methods, and the proposed ASSISTRAG.  The evaluation metrics used are Exact Match (EM), F1 score, and Precision (Prec.).  The results highlight the performance gains achieved by ASSISTRAG, particularly when compared to simpler retrieval-augmented generation (RAG) methods and when using less-advanced LLMs as the main language model.", "section": "4 Experimental Setup"}, {"figure_path": "oZy4a11SUg/tables/tables_9_2.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance of various methods across three question answering datasets (HotpotQA, 2Wiki, Bamboogle).  It compares baselines (without and with retrieval), several state-of-the-art RAG methods, and the proposed ASSISTRAG method.  The performance is evaluated using Exact Match (EM), F1-score, and Precision (Prec.) for each method and dataset, showing the effectiveness of ASSISTRAG, especially when using less powerful LLMs.", "section": "4 Experimental Setup"}, {"figure_path": "oZy4a11SUg/tables/tables_9_3.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance comparison of different methods (including baselines and the proposed ASSISTRAG) on three question answering datasets (HotpotQA, 2Wiki, and Bamboogle).  The metrics used for comparison are Exact Match (EM), F1-score, and Precision (Prec.).  The \"Main LLM\" column specifies the large language model used for answering the questions. The table highlights the best-performing method for each dataset and metric.", "section": "4 Experimental Setup"}, {"figure_path": "oZy4a11SUg/tables/tables_14_1.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance of different methods (baselines and ASSISTRAG) on three question answering datasets (HotpotQA, 2Wiki, Bamboogle).  It compares exact match (EM) accuracy, F1 score, and precision across various LLMs (LLaMA2-chat 7B, ChatGLM 6B, ChatGPT 3.5) and different retrieval-augmented generation (RAG) approaches.  The best and second-best results are highlighted for easier comparison.", "section": "4 Experimental Setup"}, {"figure_path": "oZy4a11SUg/tables/tables_15_1.jpg", "caption": "Table 1: The evaluation results for three datasets. The \"Main LLM\" indicates the LLM employed for question answering. The best results are shown in bold, while the second-best results are underlined.", "description": "This table presents the performance comparison of different methods on three question answering datasets (HotpotQA, 2Wiki, Bamboogle).  It shows the Exact Match (EM), F1 score, and Precision (Prec.) achieved by various methods, including baselines (without and with retrieval) and several state-of-the-art Retrieval Augmented Generation (RAG) approaches. The \"Main LLM\" column specifies the large language model used for generating the final answers.  The table helps to illustrate the effectiveness of the proposed Assistant-based Retrieval-Augmented Generation (ASSISTRAG) method compared to other approaches.", "section": "4 Experimental Setup"}]