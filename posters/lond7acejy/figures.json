[{"figure_path": "LONd7ACEjy/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between traditional and proposed methods: Fig.(a) illustrates traditional attack methods (e.g., FGSM [13], PGD [14]), which are primarily designed for single-modal tasks and lack mechanisms to associate multiple modalities, making them ineffective in simultaneously misleading retrieval results across different modalities. Fig.(b) illustrates the proposed method, which employs an intrinsic mechanism to effectively associate different modalities, thereby misleading retrieval results across multiple modalities simultaneously.", "description": "This figure compares traditional single-modality attack methods with the proposed Cross-Modality Perturbation Synergy (CMPS) attack.  Traditional methods, shown in (a), are ineffective in cross-modality scenarios because they fail to account for the differences between modalities and cannot mislead retrieval results across all modalities simultaneously. In contrast, CMPS (b) leverages an intrinsic mechanism that accounts for these differences, effectively associating multiple modalities and achieving simultaneous misleading results in both modalities.", "section": "Introduction"}, {"figure_path": "LONd7ACEjy/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of the CMPS attack framework. We generate homogeneous grayscale images through random grayscale transformations to reduce the differences between modalities, aiding in the learning of a universal perturbation. The process is as follows: first, the gradient from one modality is used to optimize the universal perturbation, which is then applied to another modality's images to generate adversarial samples for attacks. The new modality's gradient is then used to further optimize the perturbation and attack the next modality. By aggregating feature gradients from different modalities, we iteratively learn a universal perturbation, pushing samples toward a common region in the manifold. The manifold is represented as a sphere, with identical shapes but different colors representing the same person's features across modalities. This method captures shared knowledge between modalities, enabling more effective learning of cross-modal universal perturbations.", "description": "This figure illustrates the CMPS attack framework.  It uses grayscale image transformations to reduce differences between modalities and iteratively learns a universal perturbation by aggregating feature gradients from different modalities. This shared knowledge between modalities enables more effective learning of cross-modal universal perturbations, pushing samples toward a common region and deceiving the model.", "section": "3 Methodology"}, {"figure_path": "LONd7ACEjy/figures/figures_5_1.jpg", "caption": "Figure 2: Illustration of the CMPS attack framework. We generate homogeneous grayscale images through random grayscale transformations to reduce the differences between modalities, aiding in the learning of a universal perturbation. The process is as follows: first, the gradient from one modality is used to optimize the universal perturbation, which is then applied to another modality's images to generate adversarial samples for attacks. The new modality's gradient is then used to further optimize the perturbation and attack the next modality. By aggregating feature gradients from different modalities, we iteratively learn a universal perturbation, pushing samples toward a common region in the manifold. The manifold is represented as a sphere, with identical shapes but different colors representing the same person's features across modalities. This method captures shared knowledge between modalities, enabling more effective learning of cross-modal universal perturbations.", "description": "This figure illustrates the CMPS attack framework which uses a synergistic optimization method combined with triplet loss to learn universal perturbations.  It leverages gradient information from multiple modalities to jointly optimize the perturbations.  The process begins by generating homogeneous grayscale images to reduce differences between modalities, aiding the learning of a universal perturbation which is then iteratively optimized across different modalities. The goal is to push feature vectors of different samples towards a common region, deceiving the model.", "section": "3 Methodology"}, {"figure_path": "LONd7ACEjy/figures/figures_14_1.jpg", "caption": "Figure 5: The impact of different grayscale transformation probabilities on attack performance. Lower evaluation metrics indicate higher attack success rates. The experimental results are derived from experiments on the RegDB dataset using AGW as the baseline model for testing.", "description": "This figure shows the results of an ablation study evaluating the impact of different grayscale transformation probabilities on the attack performance. The lower the evaluation metrics (r=1, r=10, r=20, mAP), the higher the attack success rate.  The experiment was conducted on the RegDB dataset using the AGW model as a baseline.", "section": "Supplemental Experiments"}, {"figure_path": "LONd7ACEjy/figures/figures_14_2.jpg", "caption": "Figure 6: Transferability experiments of the proposed method across different models on the RegDB dataset (visible to thermal). Transferability experiments of the proposed method across different models on the SYSU dataset (visible to Infrared).", "description": "This figure demonstrates the transferability of the CMPS attack across different models and datasets.  The left panel shows results for the RegDB dataset (visible to thermal), while the right panel presents results for the SYSU dataset (visible to infrared).  Each bar represents the average accuracy across different metrics (rank-1, rank-10, rank-20, and mAP) for each model (AGW, DDAG, Col.+Del. attack, and the authors' proposed method). The error bars show the standard deviation, illustrating the variability in performance. The results indicate the effectiveness of the universal perturbation learned by CMPS, which maintains high attack success rates even when transferred to different models.", "section": "Experiments"}, {"figure_path": "LONd7ACEjy/figures/figures_15_1.jpg", "caption": "Figure 7: Comparison of Transferability Between Different Methods on Two Cross-Modal Datasets SYSU and RegDB.", "description": "This figure compares the transferability of the proposed CMPS attack method and the Col.+Del. attack method across two cross-modal datasets, SYSU and RegDB.  Transferability refers to the ability of an adversarial attack trained on one dataset to successfully attack models trained on a different dataset.  The graph shows the rank-1, rank-10, rank-20 accuracies and mean average precision (mAP) for both methods when transferring attacks from SYSU to RegDB and vice-versa.  Lower accuracy values indicate more successful attacks, hence better transferability. The results suggest that the CMPS method demonstrates superior transferability compared to Col.+Del.", "section": "4.2 Transferability of CMPS"}]