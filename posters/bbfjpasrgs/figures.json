[{"figure_path": "bbFjpasRgs/figures/figures_3_1.jpg", "caption": "Figure 1: Accuracy and Brier score [13] across exits for different EENNS for image classification on ImageNet (\u00a7 5.1). Marginally monotone performance trends (Eq. 2) are generally observed across models, with last-layer exits performing best.", "description": "This figure shows the accuracy and Brier score for four different early-exit neural networks (EENNs) on the ImageNet image classification task.  Each EENN allows for predictions at different intermediate layers ('exits'). The x-axis represents the exit layer (1 to 5, with 5 being the final layer), the top graph plots the accuracy at each exit layer and the bottom graph plots the Brier score, a measure of uncertainty. The results show that accuracy generally improves as the network progresses to deeper layers, while uncertainty (Brier score) decreases. This confirms the hypothesis of marginal monotonicity (Eq. 2) of early exiting, meaning that performance generally improves across exits.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/figures/figures_5_1.jpg", "caption": "Figure 2: Empirical test risk (top) and efficiency gains (bottom) for the CALM model [65] for text summarization on CNN/DM. Our adaptation of UCB [8] (Prop. 2) outperforms the LTT [1] approach in CALM by yielding larger efficiency gains under the same risk control assurances (see \u00a7 5.3 for details). Shading denotes the standard deviation across S = 100 calibration/test splits.", "description": "This figure compares the performance of three different risk control methods (LTT, UCB, and CRC) for early-exiting in a text summarization task.  The top panel shows the test risk, a measure of how well the model performs relative to a fully computed model, while the bottom panel shows the efficiency gains,  measured by the average number of layers processed before exiting. The results indicate that the UCB method offers better efficiency gains than the LTT method while maintaining the same level of risk control.", "section": "5.3 Language Modeling"}, {"figure_path": "bbFjpasRgs/figures/figures_6_1.jpg", "caption": "Figure 3: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks (\u00a7 3.2) and risk levels \u03b5 on ImageNet (for calibration set size n = 100). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial.", "description": "This figure displays the empirical test risk and efficiency gains for four different early-exit models (MSDNet, DVIT, L2W-DEN, Dyn-Perc) across four different risk types and various risk levels (\u03b5) on the ImageNet dataset.  The top row shows the test risk, demonstrating that risk control is achieved across all models, risk types and levels.  The bottom row illustrates the efficiency gains (in terms of reduced computation), highlighting that substantial computational savings are achieved while maintaining the specified risk levels, whether controlled in expectation or with high probability.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/figures/figures_7_1.jpg", "caption": "Figure 4: Right: Example of our method's early-exiting on Cityscapes [17]. For two samples that exit early (l = 1) and exit late (l = 4), we display ground truth segmentation masks and confidence maps at the first and last model layer. Left: For every sample, we compute the Brier loss difference \u2206lB = |lB(P1(y|x), y) \u2013 lB(P4(y|x), y)| between first and last model layer (Eq. 7), and stratify values across respective exit layers; the red dot denotes the mean. For both figures, we consider the simplest combination of Top-1 confidence score and mean image-level aggregation (for \u03b5 = 0.08).", "description": "This figure demonstrates the early-exiting mechanism of the proposed method on the Cityscapes dataset. It shows two example images, one with an early exit and one with a late exit. For each example, it displays the ground truth segmentation mask, the confidence map at the first and last model layers, and the Brier loss difference between the first and last layers stratified across the different exit layers.  The left panel provides boxplots summarizing the Brier loss difference across all samples for each exit layer.  The right panel visually shows the confidence maps for the early and late exits, compared to the ground truth.", "section": "5.2 Semantic Segmentation"}, {"figure_path": "bbFjpasRgs/figures/figures_8_1.jpg", "caption": "Figure 13: Results for early-exit diffusion with DeeDiff [69] on CIFAR [42]. Right: Empirical test risks are controlled for both CRC (Prop. 1) and UCB (Prop. 2) (for calibration set size n = 500). Left: The quality of generated images is directly related to the targeted risk control level \u03f5.", "description": "This figure shows the results of applying early-exit diffusion with the DeeDiff model on the CIFAR dataset.  The left side displays generated images at various risk levels (\u03f5), demonstrating how image quality degrades as the risk tolerance increases. The right side presents graphs illustrating that the empirical test risk is successfully controlled across different risk levels using both CRC and UCB risk control methods.  The top graph shows that the risk increases with less stringent thresholds.  The bottom graph shows that the average exit point decreases with higher risk levels, indicating more computational savings but a possible trade-off in image quality.", "section": "5.4 Image Generation with Early-Exit Diffusion"}, {"figure_path": "bbFjpasRgs/figures/figures_9_1.jpg", "caption": "Figure 6: Empirical test risk (top) and efficiency gains (bottom) for the BiLD model [41] for a machine translation task (De-En) on IWSLT [14] (with n = 500). We fix the fallback threshold to 0.5, and apply risk control to the rollback threshold. Our adaptation of UCB again outperforms LTT by yielding larger efficiency gains under the same guarantees. Shading denotes the standard deviation across S = 100 calibration/test splits.", "description": "This figure shows the empirical test risk and efficiency gains for the BiLD model, a soft speculative decoding method for large language models, when applying risk control to the rollback threshold. The upper plot shows how the test risk increases with the risk level (epsilon) for different risk control methods (CRC, UCB, and LTT). The lower plot demonstrates the speedup in samples per second achieved by each method. The results indicate that UCB outperforms LTT in terms of efficiency gains while maintaining the same level of risk control.", "section": "5.5 Speculative Decoding for Large Language Models"}, {"figure_path": "bbFjpasRgs/figures/figures_18_1.jpg", "caption": "Figure 7: We display risk curves based on relative early-exit losses l(\u03bb, L) for the CALM model [65] on CNN/DM (left). The risk based on the zero-bounded losses (\u2013; Eq. 16) naturally upper-bounds the one without (\u2013; Eq. 15). Since LTT requires l(\u03bb, L) \u2208 [0, 1], threshold tuning is performed based on the larger risk (\u2013), despite aiming to control the actual risk (\u2013). This results in overly conservative early-exiting, as indicated by the LTT test risk (\u2013 \u2013) deviating furthest from the optimal (diagonal) risk line (middle), and its lowest empirical gains (right). Since CRC and UCB permit negative losses, we display their results for both zero-bounded (\u2013 \u2013; Eq. 16) and unrestricted (\u2013; Eq. 15) settings. Also here, the unrestricted setting results in controlled risks with larger efficiency gains, highlighting its relevance for the early-exit setting with relative losses of the form l(\u03bb, L).", "description": "The figure compares three different risk control approaches (CRC, UCB, and LTT) for early-exit neural networks on the CNN/DM dataset.  It shows how the choice of loss function and the method for risk control affect the relationship between the risk level and the model's performance.  Specifically, the figure demonstrates that using the zero-bounded loss (max{l(\u03bb) - l(1), 0}) results in more conservative early-exiting compared to using the unrestricted loss (l(\u03bb) - l(1)), which is particularly noticeable for the LTT method.  The figure's three panels visualize the empirical risk, test risk, and average exit layer across different risk levels. The results highlight that methods capable of handling negative losses (CRC and UCB) achieve better efficiency gains while maintaining a controlled risk.", "section": "3.2 Early-Exiting Risks"}, {"figure_path": "bbFjpasRgs/figures/figures_21_1.jpg", "caption": "Figure 3: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks (\u00a7 3.2) and risk levels e on ImageNet (for calibration set size n = 100). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial.", "description": "This figure shows the results of applying different risk control methods (CRC and UCB) to various early-exit neural networks for image classification on the ImageNet dataset. The top row displays the test risk for different risk levels (epsilon) and risk types (performance gap and consistency). The bottom row shows the efficiency gains (in terms of reduced number of layers evaluated) for the same settings. The results demonstrate that the proposed risk control approaches successfully control the test risk while achieving significant computational savings.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/figures/figures_23_1.jpg", "caption": "Figure 3: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks (\u00a7 3.2) and risk levels e on ImageNet (for calibration set size n = 100). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial.", "description": "This figure shows the empirical test risk and efficiency gains for various early-exit models on the ImageNet dataset using different risk control methods.  The top row displays the test risk for four different risk measures (Performance Gap for predictions and distributions, Consistency Risk for predictions and distributions) at various risk levels (epsilon). The bottom row presents the corresponding efficiency gains (reduction in the number of layers needed for inference). The results demonstrate that the proposed risk control methods effectively maintain the desired risk level across models and risk types while achieving substantial computational savings.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/figures/figures_23_2.jpg", "caption": "Figure 3: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks (\u00a7 3.2) and risk levels e on ImageNet (for calibration set size n = 100). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial.", "description": "This figure displays the empirical test risk and efficiency gains for four different early-exit models on the ImageNet dataset.  The top row shows the test risk for four different risk measures (performance gap risk for predictions, performance gap risk for distributions, consistency risk for predictions, and consistency risk for distributions) and varying risk levels (epsilon). The bottom row shows the corresponding efficiency gains, represented by the average exit layer. The results demonstrate that the test risk is controlled across all models, risk types, and risk levels, and that substantial efficiency gains are achieved despite the strong risk control guarantees.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/figures/figures_25_1.jpg", "caption": "Figure 11: Empirical test risk (top) and efficiency gains (bottom) for the CALM model [65] for text summarization on CNN/DM and question answering on SQUAD. Our adaptation of UCB [8] (Prop. 2) outperforms the LTT [1] approach in CALM by yielding larger efficiency gains under the same risk control assurances. Shading denotes the standard deviation across S = 100 calibration/test splits.", "description": "This figure displays the results of applying different risk control methods (CRC, UCB, LTT) to early-exit language models for text summarization and question answering tasks. The top row shows the test risk, while the bottom row displays the efficiency gains. The results show that UCB outperforms LTT, offering greater efficiency gains while maintaining similar levels of risk control.", "section": "D.3 Language Modeling"}, {"figure_path": "bbFjpasRgs/figures/figures_25_2.jpg", "caption": "Figure 12: Empirical test risk (top) and efficiency gains (bottom) for the CALM model [65] for text summarization on CNN/DM across different confidence measures (see Schuster et al. [65], \u00a73.5). From left to right: Hidden state saturation, meta-classifiers, and top-2 softmax difference. Our employed risk control frameworks based on CRC and UCB continue to outperform LTT across all measures of confidence. Shading denotes the standard deviation across S = 100 splits.", "description": "This figure compares the performance of three different confidence measures (state saturation, meta-classifier, and softmax) for the CALM model in text summarization tasks.  It evaluates the risk control and efficiency gains using different risk control frameworks (CRC, UCB, and LTT) across various risk levels. The results demonstrate that the proposed CRC and UCB methods consistently achieve better efficiency gains compared to LTT, while maintaining the desired level of risk control, across all the confidence measures.", "section": "D.3 Language Modeling"}, {"figure_path": "bbFjpasRgs/figures/figures_26_1.jpg", "caption": "Figure 13: Results for early-exit diffusion with DeeDiff [69] on CIFAR [42]. Right: Empirical test risks are controlled for both CRC (Prop. 1) and UCB (Prop. 2) (for calibration set size n = 500). Left: The quality of generated images is directly related to the targeted risk control level \n\u03b5.", "description": "This figure shows the results of early-exit diffusion using the DeeDiff model on the CIFAR dataset.  The left side displays generated images for different risk control levels (\u03b5). As \u03b5 increases, the quality of the generated images decreases, demonstrating the trade-off between computational efficiency and image quality. The right side shows that the empirical test risk is controlled for both CRC and UCB methods, indicating that the proposed risk control framework successfully maintains the desired level of risk, even with early exits.", "section": "5.4 Image Generation with Early-Exit Diffusion"}]