[{"type": "text", "text": "Fast yet Safe: Early-Exiting with Risk Control ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Metod Jazbec1,\u2217 Alexander Timans1,\u2217 Tin Had\u017ei Veljkovic\u00b41 Kaspar Sakmann2 Dan Zhang2 Christian A. Naesseth1 Eric Nalisnick1,3 1UvA-Bosch Delta Lab, University of Amsterdam 2Bosch Center for AI, Robert Bosch GmbH 3Johns Hopkins University ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Scaling machine learning models significantly improves their performance. However, such gains come at the cost of inference being slow and resource-intensive. Early-exit neural networks (EENNs) offer a promising solution: they accelerate inference by allowing intermediate layers to \u2018exit\u2019 and produce a prediction early. Yet a fundamental issue with EENNs is how to determine when to exit without severely degrading performance. In other words, when is it \u2018safe\u2019 for an EENN to go \u2018fast\u2019? To address this issue, we investigate how to adapt frameworks of risk control to EENNs. Risk control offers a distribution-free, post-hoc solution that tunes the EENN\u2019s exiting mechanism so that exits only occur when the output is of sufficient quality. We empirically validate our insights on a range of vision and language tasks, demonstrating that risk control can produce substantial computational savings, all the while preserving user-specified performance goals. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As predictive models continue to grow in size, so do the costs of running them at inference time [12, 80]. This presents a challenge to domains ranging from mobile computing to smart appliances to autonomous vehicles \u2013 all of which require models that operate on resource-constrained hardware [62, 50, 47]. Even if computation is not limited by hardware, concerns over the energy usage and carbon footprint of large models motivates their efficient implementation [55, 44]. Additionally, since computational constraints can be dynamic, e.g., due to variable loads in web traffic or energy demand, it is desirable for models to be able to adjust their computational needs to changing conditions [63]. ", "page_idx": 0}, {"type": "text", "text": "Early-exit neural networks (EENNs) present a simple yet effective approach to such dynamic computation [70, 36]. Leveraging the neural network\u2019s compositional nature, EENNs can generate predictions at intermediate layers, thereby \u2018exiting\u2019 the computation \u2018early\u2019 when a stop condition is met. This early-exit ability has proven useful in settings ranging from vision and language to recommendations ([29], see $\\S\\ 4$ ). Yet the flexibility of EENNs does not come for free: predictions generated at early exits are usually inferior to those produced by the full model. In turn, a dilemma arises in which the exit condition must balance computational savings with predictive performance. ", "page_idx": 0}, {"type": "text", "text": "In this work, we address the EENN\u2019s efficiency vs. performance trade-off via statistical frameworks of risk control (RC) [4, 8]. By tuning the EENN\u2019s exiting mechanism based on a user-specified notion of risk, RC aims to enhance the safety of early-exit outputs. We consider several risks that quantify the difference between the early-exit and full model\u2019s outputs, both in terms of prediction quality and uncertainty estimation. Moreover, we study RC frameworks that control the risk with varying degrees of stringency (i.e., in expectation vs. with high probability). We demonstrate the effectiveness of this light-weight, post-hoc solution across a range of tasks, including image classification, semantic segmentation, language modeling, image generation with diffusion, and speculative decoding in large language models. In particular, we make the following contributions: ", "page_idx": 0}, {"type": "text", "text": "\u2022 We formalize EENNs as risk-controlling predictors, ensuring risk control is amenable to the early-exit setting by explicitly linking risk control and early-exit requirements (Prop. 1 & Prop. 2).   \n\u2022 We propose risk functions to control early-exit performance both in terms of model predictions and their underlying predictive distributions (Eq. 6 & Eq. 8). Previous work has considered only prediction quality [65], not uncertainty quality (as we do).   \n\u2022 We improve upon prior work for language modeling [65], demonstrating that our adaptions of risk control allow for less conservative early-exiting and result in larger efficiency gains $\\left(\\S\\ 3.3,\\S\\ 5.3\\right)$ .   \n\u2022 We apply, for the first time, risk control to early-exiting in image classification, semantic segmentation, and image generation, as well as speculative decoding in large language models $(\\S\\ S)$ . ", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Data. Let $\\mathcal X\\times\\mathcal X$ denote the sample space and assume a data-generating distribution $\\mathcal{P}$ over it. We consider $\\mathcal{V}:=\\{1,\\ldots,K\\}$ for classification and $\\mathcal{V}\\subseteq\\mathbb{R}^{d}$ for regression. Observed samples from $\\mathcal{P}$ are split into disjoint train, calibration and test sets, denoted $\\mathcal{D}_{t r a i n}$ , $\\mathcal{D}_{c a l}$ , and $\\mathcal{D}_{t e s t}$ . We assume samples $\\left(x,y\\right)$ in $\\mathcal{D}_{c a l}$ and $\\mathcal{D}_{t e s t}$ to be drawn i.i.d. from $\\mathcal{P}$ , whereas $\\mathcal{D}_{t r a i n}$ is permitted to be drawn randomly from a different distribution (of same support). ", "page_idx": 1}, {"type": "text", "text": "Early-Exit Neural Networks. EENNs extend traditional static network models by dynamically adjusting computations during the model\u2019s forward pass (e.g., the number of evaluated network layers) on the basis of an input sample\u2019s complexity or \u2018difficulty\u2019. More formally, we define an EENN as a sequence of probabilistic classifiers $\\hat{p}(\\mathbf{y}\\,|\\,\\mathbf{x}=\\mathbf{x};\\boldsymbol{\\phi}_{l},\\pmb{\\theta}_{l})$ , where $l=1,\\dots,L$ enumerates the model\u2019s exit layers, and $\\phi_{l}$ and $\\theta_{l}$ define the model\u2019s classification head and backbone parameters at the $l$ -th exit, respectively. The final index $L$ denotes the full model, i.e., all layers are evaluated for a given input sample $\\textbf{\\em x}$ . The obtained predictive distribution $\\hat{p}(\\mathbf{y}\\,|\\,\\mathbf{x}=\\mathbf{x};\\boldsymbol{\\phi}_{l},\\pmb{\\theta}_{l})$ at the $l$ -th exit layer, denoted in short as $\\hat{p}_{l}(\\mathbf{y}|\\pmb{x})$ , permits to retrieve both a predicted class label $\\hat{\\pmb{y}}_{l}=\\arg\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\hat{p}_{l}(\\pmb{y}\\mid\\pmb{x})$ and an associated confidence score $\\hat{c}_{l}\\in[0,1]$ , which aims to capture model\u2019s certainty about the exit\u2019s current prediction. One common choice for classification tasks is the maximum class probability $\\hat{\\pmb{c}}_{l}=\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\hat{p}_{l}(\\pmb{y}\\,|\\,\\pmb{x})$ . However, different notions of confidence are possible, as we explore in $\\S\\,5.2$ At test-time, these confidence scores can be leveraged to determine the early-exit model\u2019s required computations for new samples via thresholding. For a given test input $\\textbf{\\em x}$ , the EENN exits2 at the first layer for which its confidence exceeds a pre-specified threshold value $\\lambda_{l}\\in[0,1]$ . For simplicity, a single threshold value $\\lambda_{l}=\\lambda$ , $\\forall\\,l\\in\\{1,\\ldots,L-1\\}$ is often fixed across exit layers, a setup we also consider here. The predictive distribution obtained from the model\u2019s early-exit mechanism is then given by ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\hat{p}_{\\lambda}(\\mathbf{y}|\\mathbf{x}):=\\hat{p}_{e}(\\mathbf{y}|\\mathbf{x}),\\mathrm{~where~}e=\\left\\{\\!\\!\\begin{array}{l l}{\\!\\operatorname*{min}E}&{\\mathrm{if}\\;E\\neq\\varnothing}\\\\ {\\!L}&{\\mathrm{if}\\;E=\\varnothing}\\end{array},\\!\\;E:=\\{l\\in\\{1,...,L-1\\}:\\hat{c}_{l}\\geq\\lambda\\}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The threshold parameter $\\lambda$ regulates the trade-off between the EENN\u2019s accuracy and efficiency gains. Lower values equate larger speed-ups by increasing the likelihood of an early exit (and vice versa), at the cost of generally inferior predictions. Such marginally monotone behavior, where model performance improves on average across exits, is a core assumption for the practical use of EENNs (see also Fig. 1). We formalize it as ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(\\mathbf{\\theta},\\mathbf{\\theta},\\mathbf{y})\\sim\\mathcal{P}}[\\ell(\\hat{p}_{l}(\\mathbf{y}|\\mathbf{x}),\\pmb{y})]\\ge\\mathbb{E}_{(\\mathbf{\\theta},\\mathbf{y})\\sim\\mathcal{P}}[(\\ell(\\hat{p}_{l+1}(\\mathbf{y}|\\mathbf{x}),\\pmb{y})]\\quad\\forall l=1,\\dots,L-1}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "for some arbitrary loss function $\\ell$ , and elaborate on its connection to risk control in $\\S\\ 3.3$ . It is common to determine early-exiting criteria by investigating these trade-offs between performance and efficiency on hold-out data, selecting thresholds that ensure the EENN meets a user\u2019s computational budget [36, 70] or performance goals [16, 21, 48]. A standard practice is to treat the EENN\u2019s predictive confidence (e.g., its softmax scores) as a heuristic for prediction quality. However, this is fallible, as EENNs can exhibit fluctuating or poorly-calibrated confidences [40, 37, 51], motivating more principled threshold selection. ", "page_idx": 1}, {"type": "text", "text": "Risk Control. Statistical frameworks for risk control (RC) [1, 4, 8] aim to improve prediction reliability by equipping threshold-based models with safety assurances. Specifically, consider a pre-trained prediction model $\\hat{f}\\lambda$ whose outputs depend on a threshold $\\lambda$ . For example, given a classification task, the set predictor $\\hat{f}\\lambda:\\mathcal{X}\\to2^{\\mathcal{V}}$ described by Bates et al. [8] includes a class label in the set if its probability exceeds the threshold, i.e., ${\\hat{f}}_{\\lambda}(\\pmb{x}):=\\{\\pmb{y}\\in{\\mathcal{Y}}:{\\hat{p}}(\\pmb{y}|\\pmb{x})\\geq\\lambda\\}$ . Next, a notion of error for $\\hat{f}_{\\lambda}$ is captured by defining a problem-specific loss function $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbb{R}$ . For instance, a meaningful choice for the set predictor could be the miscoverage loss $\\ell(\\hat{f}_{\\lambda}(\\pmb{x}),\\pmb{y})=\\mathbb{1}[\\pmb{y}\\notin\\hat{f}_{\\lambda}(\\pmb{x})]$ , where $\\mathbb{I}[\\cdot]$ is the indicator function. The risk associated with a particular threshold $\\lambda\\in\\Lambda$ is then defined as the expected loss ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}(\\lambda):=\\mathbb{E}_{(\\pmb{x},\\pmb{y})\\sim\\mathcal{P}}\\big[\\ell(\\hat{f}_{\\lambda}(\\pmb{x}),\\pmb{y})\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with $\\Lambda$ the set of potential threshold candidates. RC frameworks leverage different probabilistic tools \u2013 which we detail further in $\\S\\ 3.3$ \u2013 to determine a subset $\\hat{\\boldsymbol{\\Lambda}}\\subseteq\\boldsymbol{\\Lambda}$ for which the risk in Eq. 3 is guaranteed to be small. Note that $\\hat{\\Lambda}$ is retrieved in a post-hoc manner by leveraging the calibration set $\\mathcal{D}_{c a l}$ sampled i.i.d. from $\\mathcal{P}$ . Thus, $\\mathcal{R}(\\hat{\\lambda})$ is a random quantity dependent on $\\mathcal{D}_{c a l}$ for any $\\hat{\\lambda}\\in\\hat{\\Lambda}$ . ", "page_idx": 2}, {"type": "text", "text": "Given such a risk, desired safety assurances may vary in strength. For a tolerated risk level $\\epsilon\\in(0,1)$ , risk control in expectation seeks to guarantee that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}\\big[\\mathcal{R}(\\hat{\\lambda})\\big]\\le\\epsilon\\quad\\forall\\hat{\\lambda}\\in\\hat{\\Lambda},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the outer expectation is taken over randomly drawn calibration data of finite size $|\\mathcal{D}_{c a l}|=n$ . A stronger statement on risk control with high probability requires additionally specifying a probability level ${\\bar{\\boldsymbol{\\delta}}}\\in(0,1)$ , and aims to ensure that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\overline{{\\cal D}}_{c a l}\\sim\\mathcal{P}^{n}}(\\mathcal{R}(\\hat{\\lambda})\\leq\\epsilon)\\geq1-\\delta\\quad\\forall\\hat{\\lambda}\\in\\hat{\\Lambda}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "That is, rather than the average control over calibration data in Eq. 4, risk control according to Eq. 5 holds with high probability for any particular sampled set $\\mathcal{D}_{c a l}$ . In both cases, we may refer to $\\hat{f}_{\\hat{\\lambda}}$ for any $\\hat{\\lambda}\\in\\hat{\\Lambda}$ as a risk-controlling predictor. The risk level $\\epsilon$ and probability level $\\delta$ are user-specified parameters dictating how tightly the risk is controlled, and a particular choice has to consider the problem-specific setting and loss $\\ell$ . For example, a reasonable choice for the stated miscoverage loss may be $(\\epsilon,\\delta)=(0.05,0.1)$ . Observing $\\hat{\\Lambda}=\\emptyset$ implies that there is no risk-controlling predictor for the selected $(\\epsilon,\\delta)$ , indicating overly stringent risk control conditions which $\\hat{f}_{\\lambda}$ cannot satisfy. ", "page_idx": 2}, {"type": "text", "text": "The prediction guarantees obtained via RC are highly practical, since they are $(i)$ distribution-free, i.e., they do not impose any particular assumptions on the generating distribution $\\mathcal{P},(i i)$ are post-hoc applicable to any arbitrary choice of underlying predictor $\\bar{\\hat{f}}_{\\lambda}$ , and $(i i i)$ hold in finite samples, thus not relying on asymptotic limit statements. Indeed, we experimentally find that the provided assurances hold even for remarkably small calibration sets $n\\approx100$ , see $\\S\\ S$ ). ", "page_idx": 2}, {"type": "text", "text": "3 Safe Early-Exiting via Risk Control ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We now detail our approach for early-exiting with safety guarantees based on risk control. We begin by outlining EENNs as risk-controlling predictors (\u00a7 3.1). Next, we describe two general types of risk to measure performance drops resulting from early-exiting. Importantly, these risks can be employed to assess the quality of both predictions and predictive distributions $(\\S\\ 3.2)$ . Finally, we motivate and formalise how different risk control frameworks can be adapted to the early-exit setting $(\\S\\ 3.3)$ . ", "page_idx": 2}, {"type": "text", "text": "3.1 EENNs as Risk-Controlling Predictors ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As mentioned in $\\S~2$ , risk control requires a predictor $\\hat{f}_{\\lambda}$ whose outputs depend on a threshold $\\lambda\\in\\Lambda$ . The EENN\u2019s confidence-based thresholding behaviour (following Eq. 1) lends itself naturally to such a formulation. For a particular exit threshold $\\lambda\\in[0,1]$ , the EENN $\\hat{p}_{\\lambda}(\\mathbf{y}|x)$ will act as such a threshold predictor. To ensure that the EENN satisfies the user\u2019s control requirements, the risk-controlling threshold set $\\hat{\\Lambda}$ needs to be identified. Importantly, this can be done post-hoc using a pre-trained EENN with fixed weights, since only the exit threshold $\\lambda$ is modified. In order to maximize computational savings while ensuring that the user-defined risk is managed, we select $\\hat{\\lambda}:=\\operatorname*{min}\\hat{\\Lambda}$ , since a low threshold encourages earlier exiting. If $\\hat{\\Lambda}=\\emptyset$ is empty, we default to $\\hat{\\lambda}=1$ , the equivalent of relying strictly on the full model output $\\hat{p}_{L}(\\mathbf{y}|x)$ . ", "page_idx": 2}, {"type": "text", "text": "3.2 Early-Exiting Risks ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We next detail two types of risk which can be employed to guard against performance drops due to early-exiting. Similarly to Schuster et al. [65], our risks are defined in terms of relative exit performance, permitting their calculation for both labelled and unlabelled calibration data. Moving beyond their setting, we suggest these risks for controlling the quality of both model predictions and predictive distributions, from which confidence scores can be derived. ", "page_idx": 3}, {"type": "text", "text": "Performance Gap Risk. When calibration labels are present, these can be used to measure the early-exit performance through supervised losses. Let $\\hat{o}_{l}(x)$ denote a general EENN output for some input $\\textbf{\\em x}$ . It takes the form $\\hat{\\pmb y}_{l}$ for predictions and $\\hat{p}_{l}(\\mathbf{y}|\\pmb{x})$ for the underlying predictive distribution. The supervised performance gap risk is then defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}^{G}(\\lambda):=\\mathbb{E}_{(\\mathbf{x},\\mathbf{y})\\sim\\mathcal{P}}\\big[\\ell\\big(\\hat{o}_{\\lambda}(\\pmb{x}),\\pmb{y}\\big)-\\ell\\big(\\hat{o}_{L}(\\pmb{x}),\\pmb{y}\\big)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\hat{o}_{\\lambda}(x)$ and $\\hat{o}_{L}(x)$ refer to early-exit and full model outputs, respectively. The choice of loss function $\\ell$ is task-specific, and we outline relevant choices in $\\S~5$ , such as the 0-1 loss for image classification. For predictive distribution control, we suggest leveraging a squared distributional loss which, when averaged across samples, recovers the Brier score [13]. Specifically, we define such a \u2018Brier loss\u2019 for classification tasks as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{B}(\\hat{p}_{l}(\\mathbf{y}|\\mathbf{x}),\\pmb{y}):=\\sum_{k=1}^{K}\\big(\\hat{p}_{l}(k|\\pmb{x})-\\mathbb{1}[\\pmb{y}=k]\\big)^{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\hat{p}_{l}(k|x)$ denotes the predicted probability of a particular class $k$ , and $\\mathbb{I}[\\pmb{y}=k]$ its one-hot encoded label. The Brier score is a strictly proper scoring rule [26, 27], ensuring its suitability to assess probabilistic forecasts. Moreover, its mathematical formulation lends itself favorably to risk control when compared to other widely used probabilistic metrics. We defer further details to $\\S\\mathrm{~A.}3$ . Addressing risk control of the underlying predictive distribution $\\hat{p}_{l}(\\mathbf{y}|x)$ is a compelling extension, as confidence or uncertainty estimates are typically derived from it. Particularly in safety-critical scenarios where reliable uncertainties are essential [32, 9], such control can thus prove very useful. ", "page_idx": 3}, {"type": "text", "text": "Consistency Risk. In the case of unlabelled calibration data, an unsupervised version of Eq. 6 can be obtained by replacing the ground truth labels $\\textit{\\textbf{y}}$ with labels $\\hat{\\pmb y}_{L}$ obtained from the full model. We define the unsupervised consistency risk as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}^{C}(\\lambda):=\\mathbb{E}_{(\\mathbf{x},\\cdot)\\sim\\mathcal{P}}\\big[\\ell\\big(\\hat{\\pmb{\\sigma}}_{\\lambda}(\\pmb{x}),\\hat{\\pmb{y}}_{L}\\big)-\\ell\\big(\\hat{\\pmb{\\sigma}}_{L}(\\pmb{x}),\\hat{\\pmb{y}}_{L}\\big)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where only input samples $x\\sim\\mathcal{P}$ are required for its evaluation. ", "page_idx": 3}, {"type": "text", "text": "For regular prediction losses, Eq. 8 collapses to evaluating the per-sample loss $\\ell(\\hat{\\pmb y}_{\\lambda},\\hat{\\pmb y}_{L})$ , since $\\ell(\\hat{\\pmb y}_{L},\\bar{\\hat{\\pmb y}}_{L})\\,=\\,\\bar{\\mathbf0}$ . For predictive distribution control, the loss difference remains, and we substitute $\\textit{\\textbf{y}}$ in Eq. 7 by sampling a label $\\hat{\\pmb y}_{L}\\;\\sim\\;\\hat{p}_{L}(\\mathbf{y}|\\pmb x)$ from the EENN\u2019s final layer. Our reliance on the last layer\u2019s output is motivated by the EENN\u2019s marginal monotonicity (Eq. 2 and Fig. 1). Finally, we note that both the performance gap risk $\\bar{\\mathcal{R}}^{G}(\\lambda)$ and consistency risk $\\mathcal{R}^{C}(\\lambda)$ are quite agnostic to the EENN\u2019s actual predictive performance. In both cases, the risk formulation aims to ensure prediction consistency via the relative performance gap between exits, as opposed to absolute performance with respect to observed ground truth labels. ", "page_idx": 3}, {"type": "text", "text": "3.3 Risk Control Frameworks ", "text_level": 1, "page_idx": 3}, {"type": "image", "img_path": "bbFjpasRgs/tmp/234970721999c3cd8f539b620cd3a06d4b5a5f7e43e0d375f0bb22c6dc4c4caa.jpg", "img_caption": ["Figure 1: Accuracy and Brier score [13] across exits for different EENNs for image classification on ImageNet (\u00a7 5.1). Marginally monotone performance trends (Eq. 2) are generally observed across models, with last-layer exits performing best. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "After having defined our early-exit risks, we next outline how a desired risk-controlling exit threshold $\\hat{\\lambda}$ can be computed based on calibration data. We begin by considering a \u2018naive\u2019 empirical approach, followed by risk control in expectation (Prop. 1) and with high probability (Prop. 2). ", "page_idx": 3}, {"type": "text", "text": "Empirical Approach. For a tolerated risk level $\\epsilon\\in(0,1)$ , a \u2018naive\u2019 empirical threshold can be selected by picking the smallest threshold $\\lambda\\in[0,1]$ from the candidate set $\\Lambda$ for which the risk on the calibration set $\\mathcal{D}_{c a l}$ is controlled, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\lambda}_{\\mathrm{emp}}:=\\operatorname*{min}\\{\\lambda\\in\\Lambda:\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})\\leq\\epsilon\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})=\\frac{1}{n}\\sum_{i=1}^{n}\\ell(\\hat{\\pmb{o}}_{\\lambda}(\\pmb{x}_{i}),\\pmb{y}_{i})}\\end{array}$ is the empirical calibration risk, an approximation of the true risk in Eq. 3 computed on $\\mathcal{D}_{c a l}$ (and likewise $\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{t e s t})$ denotes the empirical test risk). For the risks introduced in $\\S\\ 3.2$ the threshold $\\hat{\\lambda}_{\\mathrm{emp}}$ is always well-defined, since $\\hat{\\mathcal{R}}(\\lambda=1)$ is zero. ", "page_idx": 4}, {"type": "text", "text": "Risk Control in Expectation. The threshold $\\hat{\\lambda}_{\\mathrm{emp}}$ is a straight-forward choice, but can fail to control the risk on test data if the approximation quality of $\\mathcal{R}(\\lambda)$ by $\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})$ is poor, e.g., due to badly drawn calibration data. Perhaps surprisingly, only a slight modification of Eq. 9 is required to ensure risk control in expectation. Specifically, for a bounded loss function $\\ell\\leq B$ where $B>0$ , and assuming a monotone risk $\\mathcal{R}(\\lambda)$ , the threshold3 ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\lambda}_{\\mathrm{CRC}}:=\\operatorname*{min}\\left\\{\\lambda\\in\\Lambda:\\frac{n}{n+1}\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})+\\frac{B}{n+1}\\leq\\epsilon\\right\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "guarantees Eq. 4, thus shielding against bad sample draws on average. It is easy to show that $\\begin{array}{r}{\\bar{\\lambda}_{\\mathrm{emp}}=\\operatorname*{lim}_{n\\rightarrow\\infty}\\hat{\\lambda}_{\\mathrm{CRC}}}\\end{array}$ , and since our losses are designed to be upper-bounded by $B\\in\\{1,2\\}$ , the two thresholds already coincide for small calibration sets $\\langle n\\approx100\\rangle$ . We formalize risk control in expectation in the following proposition for our early-exit setting: ", "page_idx": 4}, {"type": "text", "text": "Proposition 1. Let $\\ell:\\Lambda\\to(-\\infty,B]$ be a right-continuous bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold $\\hat{\\lambda}_{C R C}$ ensures risk control in expectation, i.e., it holds that $\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}\\left[\\mathcal{R}(\\hat{\\lambda}_{C R C})\\right]\\leq\\epsilon$ for any $\\epsilon\\in(0,1)$ . ", "page_idx": 4}, {"type": "text", "text": "Our proposition is an extension of Conformal Risk Control [4] (CRC) to the early-exit setting, and a proof can be found in $\\S\\mathrm{~A.1~}$ . Our main technical insight is that risk control can be relaxed to assume monotone risks, rather than monotone losses as in the original formulation [4]. This relaxation is crucial for the early-exit setting, since we can relate monotone risks to assumptions of marginal monotonicity on the EENN (see Lemma 1). In contrast, monotone losses translate to assuming conditional monotonicity, a much stronger requirement suggesting the EENN\u2019s performance improves across exits per sample, and which has been shown to be violated in practice [40, 76, 37]. ", "page_idx": 4}, {"type": "text", "text": "Risk control with High Probability. A stronger guarantee can be obtained by ensuring risk control with high probability for any drawn calibration set. We employ the Upper Confidence Bound (UCB) from Bates et al. [8] for this purpose. First, an empirical upper bound $\\hat{\\mathcal{R}}^{+}(\\lambda;\\mathcal{D}_{c a l})$ is derived to bound the risk $\\mathcal{R}(\\lambda)$ with high probability. That is, for a probability level $\\delta\\in(0,1)$ it holds that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}\\big(\\mathcal{R}(\\lambda)\\leq\\hat{\\mathcal{R}}^{+}(\\lambda;\\mathcal{D}_{c a l})\\big)\\geq1-\\delta\\quad\\forall\\lambda\\in\\Lambda.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "An exit threshold ensuring risk control according to Eq. 5 is then selected as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\lambda}_{\\mathrm{UCB}}:=\\operatorname*{min}\\{\\lambda\\in\\Lambda:\\hat{\\mathcal{R}}^{+}(\\lambda^{\\prime};\\mathcal{D}_{c a l})<\\epsilon,\\forall\\lambda^{\\prime}\\geq\\lambda\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Similarly to Prop. 1, we can now formalize risk control with high probability for the early-exit setting: Proposition 2. Let $\\ell:\\Lambda\\rightarrow[-B,B]$ be a bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold $\\hat{\\lambda}_{U C B}$ ensures risk control with high probability, i.e., it holds that $\\mathbb{P}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}(\\mathcal{R}(\\hat{\\lambda}_{U C B})\\leq\\epsilon)\\geq1-\\delta$ for any $(\\epsilon,\\delta)\\in(0,1)^{2}$ . ", "page_idx": 4}, {"type": "text", "text": "This reformulation of the main theorem from Bates et al. [8] (Thm. A.1) is proven in $\\S$ A.1, and an algorithmic description is given in Appendix B. We employ their suggested Waudby-Smith-Ramdas bound [75] (WSR) to compute $\\hat{\\mathcal{R}}^{+}(\\lambda;\\mathcal{D}_{c a l})$ , but relax the bounding requirements on the loss from $\\ell\\in[0,1]$ to $\\ell\\in[-B,B]$ for $B>0$ . This change has important implications for the early-exit setting, since it admits \u2018rewarding\u2019 the EENN when an earlier exit performs better than the final exit for some samples, a phenomenon known as overthinking [40, 37]. In practice, this results in a better risk estimate and less conservative early-exiting. See $\\S\\mathrm{~A.}2$ for more details on the effect of loss bounds. ", "page_idx": 4}, {"type": "text", "text": "Learn-then-Test and CALM [65]. Learnthen-Test [1] (LTT) is another framework for high-probability risk control, where threshold selection is framed as a multiple hypothesis testing problem. In contrast to UCB (Prop. 2), LTT does not require risk monotonicity, and can thus also be employed when the EENN is suspected to violate marginally monotone behaviour. LTT in the early-exit setting has been employed by Schuster et al. [65] (CALM), presumably motivated by the avoidance of this assumption. However, expecting an EENN to marginally improve across exits is a core requirement which implicitly underlies any practical implementation. Since this assumption is usually also empirically satisfied (Fig. 1), there is no obvious reason to explicitly avoid it. Furthermore, correcting for multiple testing in LTT via fixed sequence testing \u2013 as is done for CALM \u2013 will only yield practical savings if monotonicity is satisfied. We stress these observations since we find that UCB provides greater computational savings than LTT under the same guarantees (Fig. 2 and $\\S\\,5.3\\rangle$ , including ", "page_idx": 5}, {"type": "image", "img_path": "bbFjpasRgs/tmp/4665fd2a576f4ec079a87021be2cab8aead5804046d139460af2c453597dc0b9.jpg", "img_caption": ["Figure 2: Empirical test risk $(t o p)$ and efficiency gains (bottom) for the CALM model [65] for text summarization on CNN/DM. Our adaptation of UCB [8] (Prop. 2) outperforms the LTT [1] approach in CALM by yielding larger efficiency gains under the same risk control assurances (see $\\S\\ 5.3$ for details). Shading denotes the standard deviation across $S=100$ calibration/test splits. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "for small-sample regimes $n\\approx100)$ ), which are of high practical interest and were not explored by Schuster et al. [65]. Moreover, due to LTT\u2019s reliance on the Hoeffding-Bentkus bound [11], it cannot account for instances of model overthinking (see $\\S\\ A.2_{.}$ ). Thus, unless Eq. 2 is known to be violated, we recommend UCB over LTT in the early-exit setting. ", "page_idx": 5}, {"type": "text", "text": "4 Related Work ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Early-Exiting [70, 29] as a dynamic approach to accelerate model inference is both orthogonal and complementary to static model compression techniques such as pruning, quantization, and knowledge-distillation [6, 79, 68, 84, 25]. Its wide-ranging applicability has been demonstrated across numerous vision [36, 48, 15, 69, 22] and language tasks [21, 83, 65, 78, 5, 53]. While most prior work has focused on the trade-off between performance quality and computational savings, the safety of early-exit models has received less attention to date [64, 65, 51, 38]. Risk Control has gained traction due to an interest in efficient, post-hoc approaches with safety assurances for large models. Most related, conformal prediction [66] has been popularized as an effective method for uncertainty quantification with guarantees on the miscoverage risk [24, 3]. Recently, multiple proposals address the control of more general risk notions [4, 8, 1, 67, 54, 45], with explored applications ranging from imaging [71, 2, 81, 23, 43, 61, 10, 72] to language [86, 20, 45, 56] and beyond [39, 46]. Most closely related to our work is research by Schuster et al. [65], who first employ risk control for safe early-exiting in language modeling. We move beyond their setting by (i) controlling the quality of both model predictions and uncertainty estimates (\u00a7 3.2), (ii) obtaining better efficiency gains through careful selection of our risk control framework $(\\S\\ 3.3)$ , and (iii) extending early-exit risk control to novel tasks $(\\S\\ S)$ . Ringel et al. [60]\u2019s work is also related: they apply risk control to exit early for a time series prediction task. Yet their emphasis is on exiting from a stream of input features, whereas we exit from the model itself (i.e., a stream of model layers). ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We empirically validate early-exiting via risk control on a suite of different tasks: image classification $(\\S\\ S.1)$ , semantic segmentation $(\\S\\ S.2)$ , language modelling $(\\S\\ S.3)$ , image generation with diffusion $(\\S\\ S.4)$ , and speculative decoding $(\\S\\ S.5)$ . Our code is publicly available at https://github.com/ metodj/RC-EENN. We begin by outlining our general risk control design and evaluation metrics. ", "page_idx": 5}, {"type": "text", "text": "Risk control design. We target control of the performance gap and consistency risks defined in $\\S\\ 3.2$ . For predictions $\\hat{\\pmb y}_{l}$ we employ target-specific losses, and, when applicable, for predictive distributions $\\hat{p}_{l}(\\mathbf{y}|x)$ our Brier score formulation. We denote these four risks in short as $\\mathcal{R}^{G}(\\hat{\\pmb{y}})$ , $\\mathcal{R}^{G}(\\hat{p}),\\mathcal{R}^{C}(\\dot{\\pmb{y}})$ and $\\mathcal{R}^{C}(\\hat{p})$ . Risk control requirements of different strength are assessed by varying the risk level $\\epsilon$ . Note that our approach is entirely post-hoc, and our experiments leverage existing pretrained EENNs when possible. Thus the underlying models are typically not modified, and we omit the commonly seen performance vs. FLOP curves to instead appropriately benchmark against different risk levels. For risk control with high probability, we set $\\delta=0.1$ (i.e., $90\\;\\%$ probability). Reported numbers are averaged across multiple trials of calibration and test splitting $S=100)$ to account for sampling effects. Additional results across experiments can be found in Appendix D. ", "page_idx": 5}, {"type": "image", "img_path": "bbFjpasRgs/tmp/d3ac438d94bb64e4b0bc3139d61664e8d6ef87db14853d01edaec8fb22a44c05.jpg", "img_caption": ["Figure 3: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks $\\left(\\S\\ 3.2\\right)$ and risk levels $\\epsilon$ on ImageNet (for calibration set size $n=100)$ . In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Evaluation metrics. We evaluate our results based on obtained test risks and efficiency gains. We assess whether the guarantees stated in $\\S\\ 3.3$ are satisfied by checking if the empirical test risk for a given risk-controlling threshold is controlled, i.e., $\\hat{\\mathcal{R}}(\\hat{\\lambda};\\mathcal{D}_{t e s t})\\leq\\epsilon$ holds. Ideally, the measured test risk should also approach $\\epsilon$ from below, as to prevent overly conservative early-exiting. We measure efficiency gains by reporting the average exit layer across test samples, or its relative improvement over last-layer exiting (in $\\%$ ). Similar gains in terms of arithmetic operations (FLOPS) are reported in Appendix D. We favour approaches which, while controlling the test risk, exit as early as possible. ", "page_idx": 6}, {"type": "text", "text": "5.1 Image Classification ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For image classification, we focus on the ImageNet dataset [19]. We employ four state-of-theart EENNs to demonstrate that our findings generalize across different models and architectures: MSDNet [36], DViT [74], L2W-DEN [30], and Dyn-Perc [31] (see $\\S\\,\\mathrm{C}.1$ for details). We employ the standard 0-1 loss for predictions, and the Brier loss formulation from Eq. 7 for predictive distributions. Fig. 3 displays results for the small-sample calibration regime $\\mathit{n}=100)$ ). In line with our theoretical guarantees, the test risk remains controlled across all models, risk types, and risk levels $\\epsilon$ (top row). The steeply decreasing efficiency curves affirm that even under strict control requirements, substantial efficiency gains can be obtained (bottom row). For example, controlling the prediction gap risk at a strict $5\\%$ $\\bar{\\mathcal{R}}^{G}(\\hat{\\pmb{y}})$ for $\\epsilon=0.05$ ) results in a model average of $\\sim61\\%$ less layers evaluated for control in expectation (CRC, Prop. 1), and $\\sim46\\%$ for control with high probability (UCB, Prop. 2), see Table 2. Naturally, UCB produces more cautious early-exiting due to its stronger safety assurance, but these differences decrease for larger calibration sets (see $\\S\\,\\mathrm{D}.1$ for $n=1000]$ ). This highlights the practical benefit of allocating more calibration samples: a larger sample size can aid to mitigate the price paid by a high-probability guarantee in terms of obtained inference speed-ups. ", "page_idx": 6}, {"type": "text", "text": "5.2 Semantic Segmentation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For this task, we explore the effect of different confidence measures used in Eq. 1 on realizable speed-ups. We use the EENN with four exits proposed by Liu et al. [48] (ADP-C, see $\\S\\ C.2$ ). ADP-C permits pixel-level early-exiting with per-pixel confidence scores. Since we desire to early-exit the entire image instead, we explore image-level aggregations alongside different confidence scores, which are briefly outlined below. As task-specific prediction losses, we consider the commonly used mean intersection-over-union (mIoU) and miscoverage for the labelled and unlabelled cases, respectively. For predictive distribution control, we employ pixel-averaged versions of the Brier loss in Eq. 7 (see $\\S\\mathrm{~A.}3\\mathrm{~}$ ). We evaluate our approaches on Cityscapes validation data ( $80\\%$ $\\mathcal{D}_{c a l}$ , $20\\%$ $\\mathcal{D}_{t e s t})$ ; in addition, we finetune and evaluate ADP-C on a subset of the GTA5 dataset [59] in $\\S\\,\\mathrm{D}.2$ . ", "page_idx": 6}, {"type": "table", "img_path": "bbFjpasRgs/tmp/dc0acbe0a2d10b4add0466a6e69f24f0fadfafbf97bfc38e3dd69a55e28c14dd.jpg", "table_caption": ["Table 1: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks $(\\S\\ 3.2)$ , confidence measures $(\\S\\ S.2)$ and risk levels $\\epsilon$ . Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in $\\%$ ). "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "bbFjpasRgs/tmp/67a7671962cfe717fb61d0374d22696e7375449e2b67e51d5884b7fbbf57cf2b.jpg", "img_caption": ["Figure 4: Right: Example of our method\u2019s early-exiting on Cityscapes [17]. For two samples that exit early $(l=1)$ ) and exit late $(l=4)$ ), we display ground truth segmentation masks and confidence maps at the first and last model layer. Left: For every sample, we compute the Brier loss difference $\\Delta\\bar{\\ell}_{B}=|\\ell_{B}(\\hat{p}_{1}(\\mathbf{y}|\\mathbf{x}),\\pmb{y})-\\ell_{B}(\\hat{p}_{4}(\\mathbf{y}|\\pmb{x}),\\pmb{y})|$ between first and last model layer (Eq. 7), and stratify values across respective exit layers; the red dot denotes the mean. For both figures, we consider the simplest combination of Top-1 confidence score and mean image-level aggregation (for $\\epsilon=0.08)$ ). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "We consider three pixel-level confidence scores: the top class softmax probability (Top-1), the difference between top two class probabilities (Top-Diff), and the normalized entropy over a pixel\u2019s predictive distribution (Entropy). In addition, we consider three image-level aggregation strategies: the image\u2019s average pixel confidence (Mean), its 0.25-th quantile (Quantile), and a patch-based approach (Patch), wherein a sliding window of fixed size (e.g., $50\\times50$ pixels) computes the mean confidence over pixels per patch, and the min over such patch scores is retrieved. These aggregations consider both varying levels of prudence (Mean vs. Quantile) and granularity (Mean vs. Patch). ", "page_idx": 7}, {"type": "text", "text": "Table 1 displays obtained efficiency gains for risk control via UCB (Prop. 2) across different risk levels $\\epsilon\\in\\lbrace0.01,0.05,0.1\\rbrace$ . In line with Fig. 3, increased speed-ups are observed as the risk requirements are relaxed (i.e., \u03f5 increases). Notably, for a given $\\epsilon$ the gains for Brier-based risks tend to be smaller than for prediction risks, affirming more challenging risk control. The differences between combinations of per-pixel confidence and image-level aggregation are most pronounced for small $\\epsilon$ , where Patch records highest gains while Quantile is more conservative (see $\\S\\,\\mathrm{D}.2$ for full results). In Fig. 4, we display a qualitative example of the model\u2019s exiting behaviour. For a sample which exits at the first layer (top row), the EENN\u2019s confidence map remains fairly stable across subsequent layers, suggesting an accurate model assessment has been reached early on. In contrast, a sample which exits at the final layer (bottom row) will see a substantial improvement in model certainty, justifying additional computations. Such behaviour is also visible when stratifying all samples across their respective model exits (Fig. 4, left). For samples which exit later, the difference between distributional losses at the first and final layer increases, affirming that compute is spent meaningfully. ", "page_idx": 7}, {"type": "image", "img_path": "bbFjpasRgs/tmp/de6bbf76355c35b3726062005befce5353b057b6a4c13be5fdb0c9d1c4a76730.jpg", "img_caption": ["Figure 5: Results for early-exit diffusion with DeeDiff [69] on CelebA [49]. Left: The quality of generated images is directly related to the target risk control level $\\epsilon$ . Right: Empirical test risks are controlled for both CRC (Prop. 1) and UCB (Prop. 2) (for calibration set size $n=500$ ). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.3 Language Modeling ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "For this task, we replicate the main experiments from Schuster et al. [65] (CALM), using their earlyexit version of the T5 model [57] for text summarization on CNN/DM [33] and question answering on SQuAD [58]. Recall that CALM makes use of the Learn-then-Test [1] (LTT) framework for early-exit prediction control, whereas we suggest the Upper Confidence Bound [8] (UCB). In contrast to their experiments which involve excessively large calibration sets $n\\approx8000)$ , we explore more practical settings of low calibration sample counts with $n\\in\\{100,1000\\}$ . Our results for the performance gap risk (Eq. 6) based on task-specific losses (ROUGE- $.L$ for CNN/DM and Token-F1 for SQuAD) are displayed in Fig. 2 and $\\S\\,\\mathrm{D}.3$ . In all cases, UCB exit thresholds provide larger computational savings over LTT, while ensuring the same risk control with high probability (Eq. 5). Since particularly pronounced for $n=100$ , these results highlight the need for careful framework selection in order to minimize the cost of providing guarantees. Once more, risk control in expectation (CRC, Prop. 1) permits faster exiting due to its weaker safety assurance. Encouragingly, even with as few as $n=100$ calibration samples, CRC exit thresholds reach near-optimal exiting, as indicated by their proximity to the ideal (diagonal) risk line. This suggests that even for modern language tasks, equipping an EENN with notions of safety does not necessitate a strong compromise on inference efficiency. ", "page_idx": 8}, {"type": "text", "text": "5.4 Image Generation with Early-Exit Diffusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To demonstrate the wide-ranging applicability of our proposal, we lastly consider early-exiting for image generation with diffusion. We employ the DeeDiff model [69], which performs early-exiting on the denoising network at each sampling step during the reverse diffusion process4. We target control of the perceptual difference between images generated by the accelerated and full diffusion processes, which we measure with the LPIPS score [82], and where lower values indicate perceptually closer images. Our results on the CelebA dataset [49] are shown in Fig. 5 for both risk control via CRC (Prop. 1) and UCB (Prop. 2), asserting that the risk is controlled at all levels $\\epsilon$ . The impact of the risk level on image generation is additionally visualized for two examples. For strict control requirements the early-exit generations perceptually resemble the full model, whereas generated image quality visibly deteriorates for larger $\\epsilon$ (but remains controlled). For smaller $\\epsilon$ , the speed-ups within each sampling step are relatively modest (e.g., $\\mathord{\\sim}15\\%$ for $\\epsilon=0.05$ ). However, such gains accrue over the large number of sampling steps in the image generation process $(\\sim\\!500)$ , resulting in overall meaningful savings. Similar observations for CIFAR [42] are reported in $\\S\\,\\mathrm{D}.4$ . ", "page_idx": 8}, {"type": "text", "text": "5.5 Speculative Decoding for Large Language Models ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "While we primarily focus on early-exiting, our final experiment highlights how risk control can also be applied to other techniques for efficient inference. Here we consider accelerating the inference of large language models (LLMs) using the (soft) speculative decoding approach BiLD [41]. BiLD uses a small draft model to generate multiple tokens autoregressively while the original LLM is only employed for verification. ", "page_idx": 8}, {"type": "text", "text": "This step can be performed in a single forward pass for all proposed tokens, necessitating less computations from the larger, more expensive model. During verification the difference in token distributions between the models is computed, and the tokens generated by the draft model are rejected if the difference exceeds a tolerated threshold, triggering a \u201crollback\u201d (see Eq. 3 in [41]). We apply our risk control frameworks to this rollback threshold, which dictates (i) the similarity of generated text to the output produced solely by the original LLM, and $(i i)$ the associated inference speed-ups in terms of sentences (or samples) per second. Our results in Fig. 6 for the performance gap risk (Eq. 6), as defined via the difference in sentence-level BLEU scores, corroborate our previous findings for language modeling (Fig. 2 and $\\S\\ 5.3\\rangle$ ). That is, our approaches via CRC (Prop. 1) and UCB (Prop. 2) provide meaningful speed-ups and improve upon the LTT method [1] used by CALM [65], while maintaining the desired risk control across test samples. ", "page_idx": 9}, {"type": "image", "img_path": "bbFjpasRgs/tmp/3d6033f92b8f43d0385a17a39d7d1c82c83ab294f7dcf0aad3829764eb581850.jpg", "img_caption": ["Figure 6: Empirical test risk (top) and efficiency gains (bottom) for the BiLD model [41] for a machine translation task $\\scriptstyle({\\mathrm{De-En}})$ on IWSLT [14] (with $n\\,=\\,500)$ ). We fix the fallback threshold to 0.5, and apply risk control to the rollback threshold. Our adaptation of UCB again outperforms LTT by yielding larger efficiency gains under the same guarantees. Shading denotes the standard deviation across $S=100$ calibration/test splits. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work addresses how to select a \u2018safe\u2019 exiting mechanism for early-exit neural networks (EENNs). We propose balancing the EENN\u2019s efficiency vs. performance trade-off via risk control, ensuring that accelerated inference does not compromise the quality of the early-exit outputs. We validate our light-weight, post-hoc solution on a variety of tasks and improve upon prior work [65] (see $\\S\\ 4$ ). ", "page_idx": 9}, {"type": "text", "text": "Limitations and Future Work. A key limitation of our work is the reliance on a single shared exit threshold among layers (Eq. 1). While using a shared exit threshold is common [69, 48, 40, 76, 83, 77], relaxing this condition could lead to further efficiency gains. This, however, introduces new challenges both in terms of theory (e.g., defining monotonicity requirements) and practice (e.g., substantially larger search spaces). Overcoming them by adopting recently proposed risk control techniques for high-dimensional thresholds [60, 71] could prove promising for future extensions. Another (simple) workaround is to reduce the multi-dimensional problem back to a single threshold by use of a threshold function, as partially explored in [65]. Instead of working directly with multiple thresholds, our risk control framework can then be applied to this scalar parameter. Additionally, multiple risk control extensions provide natural avenues for future work. Firstly, risk control as used in our work is achieved only marginally across observations (Eq. 3), and one could aspire for more granular exit-conditional control [60]. Secondly, the employed risk control frameworks define risk in terms of the expected loss. One could instead aim to control the tails of the loss, e.g., via specific quantiles of interest [67]. Lastly, relaxing the i.i.d assumption on calibration and test data could help extend risk-controlling EENNs to scenarios with test-time distribution shifts [86] or to online updating strategies [23]. ", "page_idx": 9}, {"type": "text", "text": "Broader Impacts. EENNs provide a simple and effective approach to dynamic computation [29]. Their computational savings can reduce energy costs and the carbon footprint, as well as allow the model to be deployed on resource-constrained hardware. By incorporating a \u2019safe\u2019 exit mechanism into these models, we improve their trustworthiness and strengthen the reliability of their intermediate outputs, along with any decisions based on them. This facilitates safer model deployment in realworld applications and contributes to more responsible decision-making. While we do not foresee any direct negative consequences from our work, improper use of our risk control framework can lead to violations or misinterpretations of its provided guarantees. This, in turn, can risk instilling a false sense of security. Overall, we believe that our work outlines an effective approach to improve the reliability of EENNs and to safely balance their inherent efficiency vs. performance trade-off. In doing so, it contributes to the goal of developing models that are ultimately fast yet safe. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank Mona Schirmer, Rajeev Verma, Christoph-Nikolas Straehle, Patrick Forr\u00e9 and Stephen Bates for helpful discussions and clarifications. We are also grateful to the anonymous reviewers who helped improve the work with their constructive feedback. This project was generously supported by the Bosch Center for Artificial Intelligence. Eric Nalisnick did not utilize resources from Johns Hopkins University for this project. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Anastasios N. Angelopoulos, Stephen Bates, Emmanuel J. Cand\u00e8s, Michael I. Jordan, and Lihua Lei. Learn then Test: Calibrating Predictive Algorithms to Achieve Risk Control. arXiv Preprint (arXiv:2110.01052), 2021. 3, 6, 9, 10, 11   \n[2] Anastasios N. Angelopoulos, Amit Pal Kohli, Stephen Bates, Michael Jordan, Jitendra Malik, Thayer Alshaabi, Srigokul Upadhyayula, and Yaniv Romano. Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging. International Conference on Machine Learning, 2022. 6   \n[3] Anastasios N Angelopoulos, Stephen Bates, et al. Conformal prediction: A gentle introduction. Foundations and Trends in Machine Learning, 2023. 6   \n[4] Anastasios N Angelopoulos, Stephen Bates, Adam Fisch, Lihua Lei, and Tal Schuster. Conformal risk control. International Conference on Learning Representations, 2024. 1, 3, 5, 6, 2   \n[5] Sangmin Bae, Jongwoo Ko, Hwanjun Song, and Se-Young Yun. Fast and robust early-exiting framework for autoregressive language models with synchronized parallel decoding. Conference on Empirical Methods in Natural Language Processing, 2023. 6, 7   \n[6] Guangji Bai, Zheng Chai, Chen Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu, Yifei Zhang, et al. Beyond efficiency: A systematic survey of resource-efficient large language models. arXiv Preprint (arXiv:2401.00625), 2024. 6 [7] Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu. All are worth words: A vit backbone for diffusion models. Conference on Computer Vision and Pattern Recognition, 2023. 7   \n[8] Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael Jordan. Distribution-free, risk-controlling prediction sets. Journal of the ACM, 2021. 1, 3, 5, 6, 9, 2, 11   \n[9] Edmon Begoli, Tanmoy Bhattacharya, and Dimitri Kusnezov. The need for uncertainty quantification in machine-assisted medical decision making. Nature Machine Intelligence, 2019. 4   \n[10] Omer Belhasin, Yaniv Romano, Daniel Freedman, Ehud Rivlin, and Michael Elad. Principal uncertainty quantification with spatial correlation for image restoration problems. Transactions on Pattern Analysis and Machine Intelligence, 2023. 6   \n[11] Vidmantas Bentkus. On hoeffding\u2019s inequalities. Annals of Probability, 2004. 6, 3   \n[12] Tolga Bolukbasi, Joseph Wang, Ofer Dekel, and Venkatesh Saligrama. Adaptive neural networks for efficient inference. International Conference on Machine Learning, 2017. 1   \n[13] Glenn W Brier. Verification of forecasts expressed in terms of probability. Monthly Weather Review, 1950. 4, 3   \n[14] Mauro Cettolo, Marcello Federico, Luisa Bentivogli, Jan Niehues, Sebastian St\u00fcker, Katsuitho Sudoh, Koichiro Yoshino, and Christian Federmann. Overview of the iwslt 2017 evaluation campaign. International Workshop on Spoken Language Translation, 2017. 10   \n[15] Joud Chataoui, Mark Coates, et al. Jointly-learned exit and inference for a dynamic neural network. International Conference on Learning Representations, 2023. 6 ", "page_idx": 10}, {"type": "text", "text": "[16] Xinshi Chen, Hanjun Dai, Yu Li, Xin Gao, and Le Song. Learning to stop while learning to predict. International Conference on Machine Learning, 2020. 2 ", "page_idx": 11}, {"type": "text", "text": "[17] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. Conference on Computer Vision and Pattern Recognition, 2016. 8, 6   \n[18] A Philip Dawid. Probability forecasting. Encyclopedia of Statistical Sciences, 2004. 3   \n[19] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Conference on Computer Vision and Pattern Recognition, 2009. 7   \n[20] Zhun Deng, Thomas Zollo, Jake Snell, Toniann Pitassi, and Richard Zemel. Distributionfree statistical dispersion control for societal applications. Advances in Neural Information Processing Systems, 2024. 6   \n[21] Maha Elbayad, Jiatao Gu, Edouard Grave, and Michael Auli. Depth-adaptive transformer. International Conference on Learning Representations, 2020. 2, 6   \n[22] Zhengcong Fei, Xu Yan, Shuhui Wang, and Qi Tian. Deecap: Dynamic early exiting for efficient image captioning. Conference on Computer Vision and Pattern Recognition, 2022. 6   \n[23] Shai Feldman, Liran Ringel, Stephen Bates, and Yaniv Romano. Achieving risk control in online learning settings. Transactions on Machine Learning Research, 2023. 6, 10   \n[24] Matteo Fontana, Gianluca Zeni, and Simone Vantini. Conformal prediction: a unified review of theory and new challenges. Bernoulli, 2023. 6   \n[25] Amir Gholami, Sehoon Kim, Zhen Dong, Zhewei Yao, Michael W Mahoney, and Kurt Keutzer. A survey of quantization methods for efficient neural network inference. Low-Power Computer Vision, 2022. 6   \n[26] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 2007. 4, 3   \n[27] Tilmann Gneiting, Fadoua Balabdaoui, and Adrian E Raftery. Probabilistic forecasts, calibration and sharpness. Journal of the Royal Statistical Society Series B: Statistical Methodology, 2007. 4, 3   \n[28] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Weinberger. On calibration of modern neural networks. International Conference on Machine Learning, 2017. 3   \n[29] Yizeng Han, Gao Huang, Shiji Song, Le Yang, Honghui Wang, and Yulin Wang. Dynamic neural networks: A survey. Transactions on Pattern Analysis and Machine Intelligence, 2021. 1, 6, 10   \n[30] Yizeng Han, Yifan Pu, Zihang Lai, Chaofei Wang, Shiji Song, Junfeng Cao, Wenhui Huang, Chao Deng, and Gao Huang. Learning to weight samples for dynamic early-exiting networks. European Conference on Computer Vision, 2022. 7, 6   \n[31] Yizeng Han, Dongchen Han, Zeyu Liu, Yulin Wang, Xuran Pan, Yifan Pu, Chao Deng, Junlan Feng, Shiji Song, and Gao Huang. Dynamic perceiver for efficient visual recognition. International Conference on Computer Vision, 2023. 7, 6   \n[32] Geoffrey Heal and Antony Millner. Reflections: Uncertainty and decision making in climate change economics. Review of Environmental Economics and Policy, 2014. 4   \n[33] Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. Advances in Neural Information Processing Systems, 2015. 9   \n[34] Hans Hersbach. Decomposition of the continuous ranked probability score for ensemble prediction systems. Weather and Forecasting, 2000. 3   \n[35] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 2020. 7   \n[36] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Weinberger. Multi-scale dense networks for resource efficient image classification. International Conference on Learning Representations, 2018. 1, 2, 6, 7   \n[37] Metod Jazbec, James Allingham, Dan Zhang, and Eric Nalisnick. Towards anytime classification in early-exit architectures by enforcing conditional monotonicity. Advances in Neural Information Processing Systems, 2024. 2, 5, 3   \n[38] Metod Jazbec, Patrick Forr\u00e9, Stephan Mandt, Dan Zhang, and Eric Nalisnick. Early-exit neural networks with nested prediction sets. Conference on Uncertainty in Artificial Intelligence, 2024. 6   \n[39] Ying Jin, Zhimei Ren, and Emmanuel J Cand\u00e8s. Sensitivity analysis of individual treatment effects: A robust conformal inference approach. Proceedings of the National Academy of Sciences, 2023. 6   \n[40] Yigitcan Kaya, Sanghyun Hong, and Tudor Dumitras. Shallow-deep networks: Understanding and mitigating network overthinking. International Conference on Machine Learning, 2019. 2, 5, 10, 3   \n[41] Sehoon Kim, Karttikeya Mangalam, Suhong Moon, Jitendra Malik, Michael W Mahoney, Amir Gholami, and Kurt Keutzer. Speculative decoding with big little decoder. Advances in Neural Information Processing Systems, 2024. 9, 10   \n[42] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Toronto, ON, Canada, 2009. 9, 12   \n[43] Gilad Kutiel, Regev Cohen, Michael Elad, and Daniel Freedman. What\u2019s behind the mask: Estimating uncertainty in image-to-image problems. arXiv Preprint (arXiv:2211.15211), 2022. 6   \n[44] Lo\u00efc Lannelongue, Jason Grealey, and Michael Inouye. Green algorithms: quantifying the carbon footprint of computation. Advanced Science, 2021. 1   \n[45] Bracha Laufer-Goldshtein, Adam Fisch, Regina Barzilay, and Tommi S Jaakkola. Efficiently controlling multiple risks with pareto testing. International Conference on Learning Representations, 2022. 6   \n[46] Bracha Laufer-Goldshtein, Adam Fisch, Regina Barzilay, and Tommi Jaakkola. Risk-controlling model selection via guided bayesian optimization. arXiv Preprint (arXiv:2312.01692), 2023. 6   \n[47] Shiya Liu, Dong Sam Ha, Fangyang Shen, and Yang Yi. Efficient neural networks for edge devices. Computers & Electrical Engineering, 2021. 1   \n[48] Zhuang Liu, Zhiqiu Xu, Hung-Ju Wang, Trevor Darrell, and Evan Shelhamer. Anytime dense prediction with confidence adaptivity. International Conference on Learning Representations, 2021. 2, 6, 7, 10   \n[49] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. International Conference on Computer Vision, 2015. 9   \n[50] Arnab Neelim Mazumder, Jian Meng, Hasib-Al Rashid, Utteja Kallakuri, Xin Zhang, Jae-Sun Seo, and Tinoosh Mohsenin. A survey on the optimization of neural network accelerators for micro-ai on-device inference. IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 2021. 1   \n[51] Lassi Meronen, Martin Trapp, Andrea Pilzer, Le Yang, and Arno Solin. Fixing overconfidence in dynamic neural networks. Winter Conference on Applications of Computer Vision, 2024. 2, 6   \n[52] Allan H Murphy. A new vector partition of the probability score. Journal of Applied Meteorology and Climatology, 1973. 3   \n[53] Xuchen Pan, Yanxi Chen, Yaliang Li, Bolin Ding, and Jingren Zhou. Ee-tuning: An economical yet scalable solution for tuning early-exit large language models. arXiv Preprint (arXiv:2402.00518), 2024. 6   \n[54] Sangdon Park, Osbert Bastani, Nikolai Matni, and Insup Lee. Pac confidence sets for deep neural networks via calibrated prediction. International Conference on Learning Representations, 2020. 6   \n[55] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training. arXiv Preprint (arXiv:2104.10350), 2021. 1   \n[56] Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae Ho Sohn, Tommi S Jaakkola, and Regina Barzilay. Conformal language modeling. International Conference on Learning Representations, 2023. 6   \n[57] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 2020. 9   \n[58] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: $100{,}000{+}$ questions for machine comprehension of text. Conference on Empirical Methods in Natural Language Processing, 2016. 9   \n[59] Stephan R Richter, Vibhav Vineet, Stefan Roth, and Vladlen Koltun. Playing for data: Ground truth from computer games. European Conference on Computer Vision, 2016. 8, 6   \n[60] Liran Ringel, Regev Cohen, Daniel Freedman, Michael Elad, and Yaniv Romano. Early time classification with accumulated accuracy gap control. International Conference on Machine Learning, 2024. 6, 10   \n[61] Swami Sankaranarayanan, Anastasios Nikolas Angelopoulos, Stephen Bates, Yaniv Romano, and Phillip Isola. Semantic uncertainty intervals for disentangled latent spaces. Advances in Neural Information Processing Systems, 2022. 6   \n[62] Kavya Saravanan and Abbas Z Kouzani. Advancements in on-device deep neural networks. Information, 2023. 1   \n[63] Simone Scardapane, Michele Scarpiniti, Enzo Baccarelli, and Aurelio Uncini. Why should we add early exits to neural networks? Cognitive Computation, 2020. 1   \n[64] Tal Schuster, Adam Fisch, Tommi Jaakkola, and Regina Barzilay. Consistent accelerated inference via confident adaptive transformers. Conference on Empirical Methods in Natural Language Processing, 2021. 6   \n[65] Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Tran, Yi Tay, and Donald Metzler. Confident adaptive language modeling. Advances in Neural Information Processing Systems, 2022. 2, 4, 6, 9, 10, 3, 7, 11   \n[66] Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal of Machine Learning Research, 2008. 6   \n[67] Jake Snell, Thomas P Zollo, Zhun Deng, Toniann Pitassi, and Richard Zemel. Quantile risk control: A flexible framework for bounding the probability of high-loss predictions. International Conference on Learning Representations, 2022. 6, 10   \n[68] Max Sponner, Bernd Waschneck, and Akash Kumar. Adapting neural networks at runtime: Current trends in at-runtime optimizations for deep learning. ACM Computing Surveys, 2024. 6   \n[69] Shengkun Tang, Yaqing Wang, Caiwen Ding, Yi Liang, Yao Li, and Dongkuan Xu. Deediff: Dynamic uncertainty-aware early exiting for accelerating diffusion model generation. arXiv Preprint (arXiv:2309.17074), 2023. 6, 9, 10, 7, 12 [70] Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung. Branchynet: Fast inference via early exiting from deep neural networks. International Conference on Pattern Recognition,   \n2016. 1, 2, 6 [71] Jacopo Teneggi, Matthew Tivnan, Web Stayman, and Jeremias Sulam. How to trust your diffusion model: A convex optimization approach to conformal risk control. International Conference on Machine Learning, 2023. 6, 10 [72] Alexander Timans, Christoph-Nikolas Straehle, Kaspar Sakmann, and Eric Nalisnick. Adaptive bounding box uncertainties via two-step conformal prediction. European Conference on Computer Vision, 2024. 6 [73] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution representation learning for visual recognition. Transactions on Pattern Analysis and Machine Intelligence, 2020. 6 [74] Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, and Gao Huang. Not all images are worth   \n16x16 words: Dynamic transformers for efficient image recognition. Advances in Neural Information Processing Systems, 2021. 7, 6 [75] Ian Waudby-Smith and Aaditya Ramdas. Estimating means of bounded random variables by betting. Journal of the Royal Statistical Society Series B: Statistical Methodology, 2024. 5, 1, 2 [76] Maciej Wo\u0142czyk, Bartosz W\u00f3jcik, Klaudia Ba\u0142azy, Igor T Podolak, Jacek Tabor, Marek S\u00b4mieja, and Tomasz Trzcinski. Zero time waste: Recycling predictions in early exit neural networks. Advances in Neural Information Processing Systems, 2021. 5, 10 [77] Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin. Deebert: Dynamic early exiting for accelerating bert inference. Proceedings of the Association for Computational Linguistics,   \n2020. 10 [78] Canwen Xu and Julian McAuley. A survey on dynamic neural networks for natural language processing. Findings of the Association for Computational Linguistics, 2023. 6 [79] Mengwei Xu, Wangsong Yin, Dongqi Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang, Shihe Wang, et al. A survey of resource-efficient llm and multimodal foundation models. arXiv Preprint (arXiv:2401.08092), 2024. 6 [80] Xiaowei Xu, Yukun Ding, Sharon Xiaobo Hu, Michael Niemier, Jason Cong, Yu Hu, and Yiyu Shi. Scaling for edge inference of deep neural networks. Nature Electronics, 2018. 1 [81] Yunpeng Xu, Wenge Guo, and Zhi Wei. Conformal risk control for ordinal classification. Conference on Uncertainty in Artificial Intelligence, 2023. 6 [82] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. Conference on Computer Vision and Pattern Recognition, 2018. 9, 7 [83] Wangchunshu Zhou, Canwen Xu, Tao Ge, Julian McAuley, Ke Xu, and Furu Wei. Bert loses patience: Fast and robust inference with early exit. Advances in Neural Information Processing Systems, 2020. 6, 10 [84] Zixuan Zhou, Xuefei Ning, Ke Hong, Tianyu Fu, Jiaming Xu, Shiyao Li, Yuming Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, et al. A survey on efficient inference for large language models. arXiv Preprint (arXiv:2404.14294), 2024. 6 [85] Shlomo Zilberstein. Using anytime algorithms in intelligent systems. AI Magazine, 1996. 2 [86] Thomas P Zollo, Todd Morrill, Zhun Deng, Jake Snell, Toniann Pitassi, and Richard Zemel. Prompt risk control: A rigorous framework for responsible deployment of large language models. International Conference on Learning Representations, 2023. 6, 10 ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "APPENDIX ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The appendix is organized as follows: ", "page_idx": 15}, {"type": "text", "text": "\u2022 Appendix A contains mathematical details, namely proofs for our propositions (\u00a7 A.1), elaboration on bounding conditions of the loss function ( $\\S$ A.2), and further details on our Brier score formulation $\\S$ A.3).   \n\u2022 Appendix B contains algorithmic descriptions of risk control via the Upper Confidence Bound [8] (UCB, Prop. 2) with the Waudby-Smith-Ramdas bound [75] (WSR, Prop. 3) in Algorithm 1 and Algorithm 2.   \n\u2022 Appendix C contains various implementation details of our four experiments: image classification (\u00a7 C.1), semantic segmentation $\\left(\\S\\,\\mathrm{C}.2\\right)$ , language modeling $\\left(\\S\\subset.3\\right)$ , and image generation $\\left(\\S\\subset.4\\right)$ .   \n\u2022 Appendix D contains additional results across our suite of experiments (in the same order as above), including risk control and efficiency curves for varying risk levels $\\epsilon$ ( $\\S$ D.1, $\\S\\,\\mathrm{D}.2$ , $\\S$ D.3, $\\S\\,\\mathrm{D}.4\\rangle$ , as well as additional efficiency gain tables (\u00a7 D.1, $\\S$ D.2). ", "page_idx": 15}, {"type": "text", "text": "A Mathematical Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Proofs for Risk Control ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We begin by formalizing the connection between marginal monotonicity requirements on the EENN (Eq. 2) and the monotonicity of risks (Eq. 3) in Lemma 1 below. ", "page_idx": 15}, {"type": "text", "text": "Lemma 1. A marginally monotone EENN satisfying Eq. 2 for some arbitrary loss function $\\ell$ implies monotone decreasing risks of the form in $\\S\\ 3.2$ , i.e., we have that $\\mathcal{R}(\\lambda_{1})\\geq\\mathcal{R}(\\lambda_{2})$ for $\\lambda_{1}\\leq\\lambda_{2}$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. For a given test sample $\\textbf{\\em x}$ , denote the exit layers corresponding to exit thresholds $\\lambda_{1}$ and $\\lambda_{2}$ as $l_{1}$ and $l_{2}$ . From the EENN\u2019s confidence-based exiting mechanism in Eq. 1 it follows that $l_{1}\\leq l_{2}$ , i.e., a smaller exit threshold $\\lambda_{1}$ will result in exits that are earlier or equal to the larger threshold $\\lambda_{2}$ . From our risk formulation in terms of relative exit performances in $\\S\\ 3.2$ and marginal monotonicity according to Eq. 2 it then follows that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}(\\lambda_{1})=\\mathbb{E}_{(\\pmb{x},\\pmb{y})\\sim\\mathcal{P}}[\\ell(\\hat{o}_{l_{1}}(\\pmb{x}),\\pmb{y})-\\ell(\\hat{o}_{L}(\\pmb{x}),\\pmb{y})]}\\\\ &{\\qquad\\qquad\\overset{\\mathrm{(Eq.~2)}}{\\geq}\\mathbb{E}_{(\\pmb{x},\\pmb{y})\\sim\\mathcal{P}}[\\ell(\\hat{o}_{l_{2}}(\\pmb{x}),\\pmb{y})-\\ell(\\hat{o}_{L}(\\pmb{x}),\\pmb{y})]=\\mathcal{R}(\\lambda_{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Next, we prove Prop. 1, our adaptation of the Conformal Risk Control [4] (CRC) guarantee on risk control in expectation for the early-exit setting. Our proof closely follows the proof for Thm. 1 in Angelopoulos et al. [4], but we relax the condition on monotone losses to that on monotone risks, which implies assuming marginal monotonicity on the EENN according to Lemma 1. We restate our proposition from the main paper for completeness first. ", "page_idx": 15}, {"type": "text", "text": "Proposition 1. Let $\\ell:\\Lambda\\to(-\\infty,B]$ be a right-continuous bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold $\\hat{\\lambda}_{C R C}$ ensures risk control in expectation, i.e., it holds that $\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}\\left[\\mathcal{R}(\\hat{\\lambda}_{C R C})\\right]\\leq\\epsilon$ for any $\\epsilon\\in(0,1)$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. Consider the calibration set $\\mathcal{D}_{c a l}=\\{(\\pmb{x}_{i},\\pmb{y}_{i})\\}_{i=1}^{n}\\sim\\mathcal{P}^{n}$ and some test sample $(\\boldsymbol{x},\\boldsymbol{y})\\sim\\mathcal{P}$ drawn i.i.d from $\\mathcal{P}$ , and denote their union set as $\\tilde{D}\\,:=\\,\\mathcal{D}_{c a l}\\cup\\,\\mathbf{\\omega}(x,\\pmb{y})$ . Additionally, define $\\ell_{i}(\\lambda):=\\ell(\\hat{\\pmb{o}}_{\\lambda}(\\pmb{x}_{i}),\\pmb{y}_{i})$ as the loss of the EENN\u2019s early-exit output for the $i$ -th sample. In particular, $\\ell_{n+1}(\\lambda)$ now denotes the test sample\u2019s loss. Let us first recall the definition of $\\hat{\\lambda}_{\\mathrm{CRC}}$ (Eq. 10): ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\hat{\\lambda}_{\\mathrm{CRC}}:=\\operatorname*{min}\\{\\lambda\\in\\Lambda:\\frac{n}{n+1}\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})+\\frac{B}{n+1}\\leq\\epsilon\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Note that $\\Lambda$ is a discrete grid of values over $[0,1]$ , e.g., equidistant values $\\{0.01,0.02,\\ldots,1\\}$ , and ff $\\hat{\\Lambda}=\\emptyset$ and the risk control condition is never met, we default to $\\hat{\\lambda}=1$ for all threshold selection ", "page_idx": 15}, {"type": "text", "text": "procedures. Thus, the min is well-defined. Next, consider the empirical risk $\\hat{\\mathcal{R}}_{n+1}(\\lambda;\\tilde{\\mathcal{D}})$ computed over $\\tilde{\\mathcal{D}}$ using the $n+1$ available samples, and define the following threshold choice: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\lambda}_{n+1}:=\\operatorname*{min}\\{\\lambda\\in\\Lambda:\\hat{\\mathcal{R}}_{n+1}(\\lambda;\\tilde{\\mathcal{D}})\\leq\\epsilon\\}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\hat{\\lambda}_{n+1}$ is always well-defined, since $\\hat{\\mathcal{R}}_{n+1}(\\lambda=1)$ is zero for the risks introduced in $\\S\\ 3.2$ . As we assume a bounded loss function $\\ell\\leq B$ , we observe that for any $\\lambda\\in\\Lambda$ we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{R}}_{n+1}(\\lambda;\\tilde{\\mathcal{D}})=\\frac{n}{n+1}\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})+\\frac{\\ell_{n+1}(\\lambda)}{n+1}\\leq\\frac{n}{n+1}\\hat{\\mathcal{R}}(\\lambda;\\mathcal{D}_{c a l})+\\frac{B}{n+1},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which implies that $\\hat{\\lambda}_{n+1}\\leq\\hat{\\lambda}_{\\mathrm{CRC}}$ . Since we assume a marginally monotone EENN, by Lemma 1 it follows that the risk is monotone decreasing and by $\\begin{array}{r}{\\mathcal{R}(\\hat{\\lambda}_{n+1})\\stackrel{{}}{\\geq}\\mathcal{R}(\\hat{\\lambda}_{\\mathrm{CRC}})}\\end{array}$ we also have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}[\\mathcal{R}(\\hat{\\lambda}_{n+1})]\\ge\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}[\\mathcal{R}(\\hat{\\lambda}_{\\mathrm{CRC}})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Eq. 3 and our loss definition above, we can rewrite for a general $\\lambda$ the expression ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}[\\mathcal{R}(\\lambda)]=\\mathbb{E}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}[\\mathbb{E}_{(\\pmb{x},\\pmb{y})\\sim\\mathcal{P}}[\\ell_{n+1}(\\lambda)]]\\overset{i.i.d}{=}\\mathbb{E}_{\\tilde{\\mathcal{D}}\\sim\\mathcal{P}^{n+1}}[\\ell_{n+1}(\\lambda)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "in short $\\mathbb{E}[\\ell_{n+1}(\\lambda)]$ . The remainder of the proof follows Thm. 1 in Angelopoulos et al. [4]. Assume a particular set $\\tilde{\\mathcal{D}}$ is given. Then the threshold $\\hat{\\lambda}_{n+1}$ is void of randomness and a constant, and by the $i.i.d$ condition we also have that $\\ell_{n+1}(\\lambda)|\\tilde{\\mathcal{D}}\\sim\\mathrm{Unif}\\big(\\{\\ell_{1},\\dots,\\ell_{n+1}\\}\\big)$ is uniformly distributed. Combining these observations with the law of total expectation (l.o.t.e.) and right-continuity (r.c.) of the loss, the final result follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\ell_{n+1}(\\hat{\\lambda}_{\\mathrm{CRC}})]\\stackrel{(\\mathrm{Eq.\\,}14)}{\\leq}\\mathbb{E}[\\ell_{n+1}(\\hat{\\lambda}_{n+1})]\\stackrel{\\mathrm{l.o.t.e.}}{=}\\mathbb{E}\\big[\\mathbb{E}[\\ell_{n+1}(\\hat{\\lambda}_{n+1})\\,|\\,\\tilde{\\mathcal{D}}]\\big]}\\\\ {\\stackrel{\\mathrm{Unif}}{=}\\mathbb{E}\\bigg[\\frac{1}{n+1}\\sum_{i=1}^{n+1}\\ell_{i}(\\hat{\\lambda}_{n+1})\\bigg]\\stackrel{\\mathrm{(Eq.\\,}13)\\,\\&\\,\\mathrm{r.c.}}{\\leq}\\mathbb{E}[\\epsilon]=\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, we sketch a proof for Prop. 2, our adaptation of the Upper Confidence Bound [8] (UCB) guarantee on risk control with high probability for the early-exit setting. Our main change includes modifying the Waudby-Smith-Ramdas bound [75] (WSR) to relax the bounding condition on the loss from $\\bar{\\ell}\\in[0,1]$ to $\\ell\\in[-B,B]$ (Prop. 3). We first restate our proposition from the main paper. ", "page_idx": 16}, {"type": "text", "text": "Proposition 2. Let $\\ell:\\Lambda\\rightarrow[-B,B]$ be a bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold $\\hat{\\lambda}_{U C B}$ ensures risk control with high probability, i.e., it holds that $\\mathbb{P}_{\\mathcal{D}_{c a l}\\sim\\mathcal{P}^{n}}(\\mathcal{R}(\\hat{\\lambda}_{U C B})\\leq\\epsilon)\\geq1-\\delta$ for any $(\\epsilon,\\delta)\\in(0,1)^{2}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Our result follows almost directly from the proofs in Bates et al. [8] (for their Thm. A.1), where we leverage the required risk monotonicity by Lemma 1. We omit the technical requirement on risk continuity from the original proof, since a relaxation to non-continuous risks is permitted ([8], Remark 3). A proof that the WSR bound can be used to construct a valid upper confidence bound can be found in Bates et al. [8], Sec. 3.1.3. However, an assumption on losses bounded to $\\ell\\in[0,1]$ is made, which is overly restrictive for the early-exit setting. We relax this assumption to $\\ell\\in[-B,B]$ in Prop. 3 below, concluding the result. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Since our risk definitions in $\\S\\ 3.2$ can naturally assume negative values, and we thus want to account for the occurrence of earlier exits performing better, we relax the bounding condition on the loss function for the Waudby-Smith-Ramdas bound [75] (WSR) in the following proposition. ", "page_idx": 16}, {"type": "text", "text": "Proposition 3. A valid upper confidence bound (Eq. 11) based on the Waudby-Smith-Ramdas bound can be constructed for losses $\\ell\\in[-B,B]$ with $B>0$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Observe the definitions of individual components $(\\mu_{i},\\sigma_{i}^{2},\\nu_{i},\\kappa_{i})$ for the WSR bound in Algorithm 2. In particular, define $\\begin{array}{r}{\\nu_{i}=\\operatorname*{min}\\{1/2B,\\sqrt{\\frac{2\\log(1/\\delta)}{n\\sigma_{i-1}^{2}}}\\}}\\end{array}$ 2 lno\u03c3gi(21\u2212/1\u03b4 )}. Since the second term is always non-negative, it follows that $\\nu_{i}\\,\\in\\,[0,1/2B]$ . For the loss $\\ell_{i}\\,\\in\\,[-B,B]$ , we then have that $(\\ell_{i}-$ $\\mathbb{E}[\\ell_{i}])\\,\\stackrel{.}{\\in}\\,[-2B,2B]$ . Hence, it follows that $1\\,-\\,\\nu_{i}(\\ell_{i}\\,-\\,\\mathbb{E}[\\ell_{i}])\\;\\geq\\,0$ , which implies that $\\kappa_{i}~=$ $\\begin{array}{r}{\\prod_{j=1}^{i}\\{1-\\nu_{j}(\\ell_{j}-\\mathbb{E}[\\ell_{j}])\\}}\\end{array}$ is a non-negative martingale. The rest of the proof follows Prop. 5 from Bates et al. [8], concluding the result. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Observe that the proof for Prop. 3 utilizes the fraction $1/2B$ in its definition of $\\nu_{i}$ which can make the WSR bound less tight. However, in the case of a marginally monotone EENN (Lemma 1) we can relax this fraction to $1/B$ instead, a comment we formalize in the following remark. ", "page_idx": 17}, {"type": "text", "text": "Remark 1. Note that in the case of a marginally monotone EENN, the bound from Prop. 3 can be further optimized. For a bounded loss $\\ell\\in[0,B]$ , the relative early-exit loss $\\ell(\\lambda,\\bar{L}):=\\ell\\big(\\hat{\\partial}_{\\lambda}(\\pmb x),\\pmb y\\big)-$ $\\ell\\big(\\hat{\\pmb{o}}_{L}(\\pmb{x}),\\pmb{y}\\big)$ will fall in the $[-B,B]$ range (see also $\\S\\ 3.2$ and $\\S\\ A.2)$ . Additionally, due to the marginal monotonicity assumption (Eq. 2) the risk based on the relative loss will be non-negative, i.e., $\\bar{\\mathcal{R}}(\\lambda,L)=\\mathbb{E}[\\ell(\\lambda,L)]\\in[0,B]$ . This implies that $(\\ell(\\lambda,L)-\\mathcal{R}(\\lambda,L))\\in[-2B,B]$ . Hence, $\\kappa_{i}$ will be a non-negative martingale even when the upper bound $1/B$ is used for $\\nu_{i}$ instead of $1/2B$ . ", "page_idx": 17}, {"type": "text", "text": "A.2 On Bounding of the Loss Function ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The risks outlined in $\\S\\ 3.2$ rely on an early-exit loss definition in terms of relative exit performance. That is, our risks take the general form ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}(\\lambda)=\\mathbb{E}_{(\\pmb{x},\\pmb{y})\\sim\\mathcal{P}}\\big[\\ell(\\lambda,L)\\big],\\quad\\ell(\\lambda,L):=\\ell\\big(\\hat{o}_{\\lambda}(\\pmb{x}),\\pmb{y}\\big)-\\ell\\big(\\hat{o}_{L}(\\pmb{x}),\\pmb{y}\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "with $\\ell(\\lambda,L)$ denoting the relative early-exit loss. Recall that $\\hat{o}_{\\lambda}$ and $\\hat{O}_{L}$ are based on $\\hat{p}_{\\lambda}$ and $\\hat{p}_{L}$ , respectively. For a bounded loss $\\ell\\in[0,B]$ , we then have that $\\ell(\\lambda,L)\\in[-B,B]$ . In our early-exit setting, negative losses have an intuitive interpretation. The associated test samples are cases where the EENN overthinks [40, 37], i.e., the early-exit $\\hat{p}_{\\lambda}$ performs better than the final exit $\\hat{p}_{L}$ . ", "page_idx": 17}, {"type": "text", "text": "Risk control via CRC (Prop. 1) or UCB (Prop. 2) with the relaxed WSR bound (Prop. 3) conveniently account for such occurrences. In contrast, this presents a challenge for the Learn-then-Test [1] (LTT) framework employed by Schuster et al. [65], since the underlying Hoeffding-Bentkus [11] (HB) bound requires $\\ell(\\lambda,L)\\in[0,1]$ . As a workaround, Schuster et al. [65] instead impose a lower loss limit of zero, i.e., they use ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell(\\lambda,L):=\\operatorname*{max}\\{0,\\;\\ell\\big(\\hat{o}_{\\lambda}(\\pmb{x}),\\pmb{y}\\big)-\\ell\\big(\\hat{o}_{L}(\\pmb{x}),\\pmb{y}\\big)\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "While solving their technical requirement, it introduces a key drawback in that the risk control procedure cannot account for samples where the risk requirement is satisfied \u2018for free\u2019. This introduces substantially more conservative early-exiting (see Fig. 7), since an upper bound on the empirical calibration risk is used for threshold tuning. ", "page_idx": 17}, {"type": "text", "text": "In addition, observe that the Brier score is naturally bounded by [0, 2] for the multi-class setting [13]. Thus, our relative early-exit Brier losses assume values in the range of $[-2,2]$ . While acceptable for risk control via CRC and UCB (by setting $B=2$ ), it once again does not align with the LTT requirement on $\\ell(\\lambda,L)\\in[0,1]$ . Thus, applying LTT requires additional restrictions such as scaling (e.g., with a $1/2$ term) and Eq. 16 to satisfy the bounds. This highlights another drawback where the intuitive risk interpretation as a Brier score difference is partially lost (see $\\S\\mathrm{~A.}3$ below). ", "page_idx": 17}, {"type": "text", "text": "Note that while CRC and UCB are amenable to $\\ell(\\lambda,L)\\in[-B,B]$ , it can still be beneficial to ensure non-negative losses (e.g., by Eq. 16) in order to improve the marginal monotonicity of the EENN (Eq. 2). Namely, it can happen that an EENN is not marginally monotone for an unrestricted loss (Eq. 15), but is for its zero-bounded counterpart (Eq. 16). Hence, such approaches might be useful when there is reason to believe that EENN violates its marginal monotonicity assumption, though in such cases a practitioner might better opt for the pruning of unnecessary model layers instead. ", "page_idx": 17}, {"type": "text", "text": "A.3 Brier score formulation ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Brier score motivation. The Brier score is a strictly proper scoring rule [26, 27], ensuring its suitability to assess probabilistic forecasts. This can be demonstrated by its decomposition structure, which highlights that both calibration and sharpness properties of the forecaster are taken into account [52, 18]. Moreover, its mathematical formulation lends itself favorably to risk control when compared to other widely used probabilistic metrics. These include the expected calibration error (ECE [28]), which requires binning and thus cannot be defined at a per-sample level; the negative log-likelihood, which is less interpretable and unbounded; the ranked probability score (RPS), which does not treat class distances equally; and the continuous ranked probability score (CRPS [34]) or $f-$ divergences like the Hellinger distance, which can be overly conservative by aiming to control the (potentially long) tail of the distribution, and require access to the full (ground truth) distribution. While amenable to our overall risk control framework, such probabilistic metrics, or any derived top- $.k$ uncertainty measures, seem either less practical or less principled. ", "page_idx": 17}, {"type": "image", "img_path": "bbFjpasRgs/tmp/2e43ad351a08438b766bed28fefa4367c4d937800ccf6889fb636095f1db83c3.jpg", "img_caption": ["Figure 7: We display risk curves based on relative early-exit losses $\\ell(\\lambda,L)$ for the CALM model [65] on CNN/DM (left). The risk based on the zero-bounded losses ( ; Eq. 16) naturally upper-bounds the one without ( ; Eq. 15). Since LTT requires $\\ell(\\lambda,L)\\in[0,1]$ , threshold tuning is performed based on the larger risk $(-)$ , despite aiming to control the actual risk $(-)$ . This results in overly conservative early-exiting, as indicated by the LTT test risk $\\left(-\\right)$ deviating furthest from the optimal (diagonal) risk line (middle), and its lowest empirical gains $(r i g h t)$ . Since CRC and UCB permit negative losses, we display their results for both zero-bounded ( ; Eq. 16) and unrestricted $(-$ ; Eq. 15) settings. Also here, the unrestricted setting results in controlled risks with larger efficiency gains, highlighting its relevance for the early-exit setting with relative losses of the form $\\ell(\\lambda,L)$ . "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Brier loss and Brier score. For convenience (but easily transferable), consider the supervised setting where we target risk control of the performance gap risk (Eq. 6) for predictive distributions, which we denote in short as $\\mathcal{R}^{G}(\\hat{p})$ . This requires computing the Brier loss $\\ell_{B}(\\hat{p}_{l}(\\mathbf{y}|\\pmb{x}),\\pmb{y})$ , which we define for the multi-class setting in Eq. 7. Now consider a dataset $\\mathcal{D}\\sim\\mathcal{P}$ of size $N$ (e.g., the calibration set $\\mathcal{D}_{c a l}$ ). The associated Brier score [13] denoted Brier $\\left(\\hat{p}_{l}\\right)$ for the $l$ -th exit layer is then defined as the mean Brier loss across samples, i.e., we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbf{\\mathop{trier}}(\\hat{p}_{l})=\\frac{1}{N}\\sum_{n=1}^{N}\\ell_{B,n}(\\hat{p}_{l})=\\frac{1}{N}\\sum_{n=1}^{N}\\ell_{B}(\\hat{p}_{l}(\\mathbf{y}|\\mathbf{x}_{n}),y_{n})\\overset{\\mathrm{(Eq.}7)}{=}\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{k=1}^{K}\\left(\\hat{p}_{l}(k|\\mathbf{x}_{n})\\!-\\!\\mathbb{1}[y_{n}=k]\\right)^{2},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\ell_{B,n}(\\hat{p}_{l})$ is an abbreviation for the $n$ -th sample\u2019s Brier loss. The risk $\\mathcal{R}^{G}(\\hat{p})$ that we aim to control is approximated by its empirical equivalent $\\hat{\\mathcal{R}}^{G}(\\hat{p})$ on $\\mathcal{D}$ , and can then be interpreted as the difference in Brier scores between our EENN with threshold $\\lambda$ and the full (last-layer exit) model: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\hat{\\mathcal{R}}^{G}(\\hat{p})=\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\left[\\ell_{B}(\\hat{p}_{\\lambda}(\\mathbf{y}|x_{n}),y_{n})-\\ell_{B}(\\hat{p}_{L}(\\mathbf{y}|x_{n}),y_{n})\\right]}\\\\ &{}&\\\\ &{}&{=\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\ell_{B,n}(\\hat{p}_{\\lambda})-\\frac{1}{N}\\sum_{n=1}^{N}\\ell_{B,n}(\\hat{p}_{L})=8\\mathbf{rier}(\\hat{p}_{\\lambda})-8\\mathbf{rier}(\\hat{p}_{L}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Mean-pixel Brier score. Since our semantic segmentation experiment $(\\S\\ 5.2)$ is a pixel-level classification task, we obtain pixel-level predictive distributions, and thus compute per-pixel Brier losses. For an image of height $H$ and width $W$ , we can denote by $\\ell_{B,n}(\\hat{p}_{l,i,j})$ the $n$ -th sample\u2019s Brier loss at the pixel location $(i,j)\\in H\\times W$ . Since we target image-level early-exiting, these per-pixel Brier losses are averaged across pixels to compute a per-image Brier loss, which in turn is averaged across samples to obtain the $l$ -th exit layer\u2019s Brier score. That is, the layer\u2019s associated Brier score Brier $\\left(\\hat{p}_{l}\\right)$ is defined as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbf{\\cdot}\\mathbf{rier}(\\hat{p}_{l})=\\frac{1}{N H W}\\sum_{n=1}^{N}\\sum_{(i,j)\\in H\\times W}\\ell_{B,n}(\\hat{p}_{l,i,j})=\\frac{1}{N H W}\\sum_{n=1}^{N}\\sum_{(i,j)\\in H\\times W}\\ell_{B}(\\hat{p}_{l}(\\mathbf{y}|\\mathbf{x}_{n,i,j}),y_{n,i,j}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and can be interpreted as the mean-pixel Brier score of the particular exit layer. Note that if we interpret every image pixel as an individual sample (i.e., define $\\tilde{N}\\,:=\\,N H W)$ , the Brier score formulation as a sample-averaged Brier loss continues to hold. Similar to above, the targeted risk is then interpreted as the mean-pixel Brier score difference. ", "page_idx": 18}, {"type": "text", "text": "B Algorithmic Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Here, we sketch the algorithm for computing the risk-controlling threshold $\\hat{\\lambda}_{\\mathrm{UCB}}$ (Eq. 12) via the Upper Confidence Bound [8] (UCB, Prop. 2) with the Waudby-Smith-Ramdas bound [75] (WSR, Prop. 3). The algorithm is an adaptation of the approach presented in Bates et al. [8] to the early-exit setting. Note that our practical code implementation differs slightly from the pseudo-code presented here, as we omit here some code optimization steps such as vectorization to improve readability. ", "page_idx": 19}, {"type": "table", "img_path": "bbFjpasRgs/tmp/0a7fc383d50d9f0bd176a84d0645ddd11b3047ba382e53fbb00a21ecadc85fd0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "input : losses L, \u03b4, grid step $\\Delta$ , $\\nu$ bound B (default $\\textsf{B}=\\textsf{1}$ ) output : UCB $\\hat{\\mathcal{R}}^{+}(\\lambda)$ ", "page_idx": 19}, {"type": "text", "text": "$\\textbf{n}=\\mathtt{l e n}(\\mathtt{L})$   \n# init arrays   \n$\\mu,\\sigma^{2},\\nu,\\kappa\\;=\\;\\mathrm{\\bar{np}}$ .ones(n), ..   \nfor $\\dot{\\boldsymbol{z}}$ in range $\\left(n\\right)$ do $\\begin{array}{r l}&{\\mu[i]=(1/2+\\textstyle\\sum_{j=0}^{i}\\operatorname{L}[j])/(i+1)}\\\\ &{\\sigma^{2}[i]=(1/4+\\textstyle\\sum_{j=0}^{i}(\\operatorname{L}[j]-\\mu[j])^{2})/(i+1)}\\\\ &{\\nu[i]=\\operatorname*{min}\\{1/\\operatorname{B},\\sqrt{\\frac{2\\log(1/\\delta)}{n\\sigma^{2}[i-1]}}\\}}\\end{array}$ # define $\\kappa$ function \u03ba[i] = lambda $\\begin{array}{r}{\\epsilon:\\prod_{i=0}^{j}\\bigl\\{1-\\nu[j]\\bigl(\\mathtt{L}[j]-\\epsilon\\bigr)\\bigr\\}}\\end{array}$   \ngrid $=$ np.arange(0,1,\u2206)   \nfor $\\epsilon$ in grid do if $\\mathrm{max}_{i}\\,\\kappa[i](\\epsilon)>1/\\delta$ then return \u03f5 ", "page_idx": 19}, {"type": "text", "text": "C Implementation Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Since our approach is post-hoc, the required compute resources needed are minimal. The primary requirement is sufficient memory to process the required calibration and test data, which can be quite large (e.g., images of size $2048\\times1024$ pixels for Cityscapes). All our experiments can be performed and replicated on a single A100 GPU with experiment runtimes of $<\\!1$ day. We detail further case-specific implementations below for each experiment. ", "page_idx": 20}, {"type": "text", "text": "C.1 Image Classification ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Model details. The models we consider are: the multi-scale dense network (MSDNet; [36]), an adaptation of traditional convolutional NNs for the early-exit setting; the dynamic vision transformer (DViT; [74]), which comprises multiple transformers with an increasing number of input patches; an enhanced MSDNet model that weights easy and hard examples differently during training (L2WDEN; [30]); and a recently proposed dynamic perceiver (Dyn-Perc; [31]), which decouples feature extraction and early prediction tasks via a novel dual-branch architecture. For all models, we either work with the publicly available pretrained checkpoints or train the models ourselves, closely following the original implementation details. ", "page_idx": 20}, {"type": "text", "text": "C.2 Semantic Segmentation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Model details. We consider the EENN proposed by Liu et al. [48] (ADP-C), which adds three intermediate exit heads to the HRNet segmentation model [73] (for a total of four exits) and is trained end-to-end on Cityscapes [17]. The model comes in two sizes, small (W18) and large (W48). We focus on the larger model (ADP-C-W48), but find results hold equivalently for the smaller one (in fact, larger gains can be obtained). Across experiments we employ the publicly available model checkpoints from the original implementation. ", "page_idx": 20}, {"type": "text", "text": "Model finetuning. Since the model is trained on Cityscapes, we consider additional finetuning to evaluate ADP-C on GTA5 [59]. We take the available pre-trained model checkpoint (APD-CW48) and finetune the model for 50 epochs on the GTA5 training set $\\sim12000$ images). For this purpose, we employ the original training script and training parameters (e.g., learning rate, batch size, etc.). However, we find that our finetuned model does not perform on par with the original, i.e., performance on GTA5 is substantially inferior to that on Cityscapes. In particular, the performance improvement across subsequent exits on GTA5 is marginal, resulting in an EENN that is less suitable for early-exiting (see also $\\S\\ D.2_{.}$ ). Yet, we find that risk control frameworks still apply, highlighting their robust model-agnostic properties even in light of an inferior underlying predictor. ", "page_idx": 20}, {"type": "text", "text": "Image-level aggregation. ADP-C provides an exiting mechanism following Eq. 1 on pixel-level, which is less useful for down-stream applications and decision making. For details on the exact mechanism, we refer to Liu et al. [48]. Rather than exiting only for selected image pixels, we instead want to early-exit the entire image whilst ensuring risk control. Thus, alongside different per-pixel confidence scores $\\hat{\\mathbf{c}}_{l,i,j}$ , $(i,j)\\,\\in\\,H\\times W$ , we also consider confidence aggregations $\\phi(\\cdot)$ which produce a single image-level confidence measure $\\hat{c}_{l}$ to perform image-level risk control. Note that our prediction losses mean intersection-over-union and miscoverage already aggregate from pixel- to image-level, whereas our distributional loss (Eq. 7) is adapted to additionally average over pixels, resulting in a mean-pixel Brier score interpretation (see $\\S\\mathrm{~A.}3\\mathrm{.}$ ). ", "page_idx": 20}, {"type": "text", "text": "Risk control evaluation. We evaluate the original ADP-C-W48 on Cityscapes validation data, with a split of $80\\%$ $\\mathcal{D}_{c a l}$ (i.e., 400 images) and $20\\%$ $\\mathcal{D}_{t e s t}$ (i.e., 100 images). Similarly, we randomly select a subset of 1000 images from the GTA5 validation set and evaluate our finetuned model using $80\\%$ $\\mathcal{D}_{c a l}$ (i.e., 800 images) and $20\\%$ $\\mathcal{D}_{t e s t}$ (i.e., 200 images). In both cases, we average risk control results over 100 trials of random calibration and test splits. ", "page_idx": 20}, {"type": "text", "text": "C.3 Language Modeling ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Model details. For our language modeling experiments, we employ the early-exit pretrained model based on T5-large (770M parameters) from Bae et al. $[5]^{6}$ . While this model closely follows the implementations in Schuster et al. [65], we found it easier to work with than the original code7. Note that Schuster et al. [65] report results for T5-small (60M parameters) and T5-base (220M parameters), whereas we use the larger T5-large. For risk control evaluation, we follow their exact exiting mechanism. Specifically, we compute softmax-based confidences at every exit and deploy their threshold decay mechanism, where early-exiting is more conservative for initial tokens and becomes progressively more permissive ([65], Eq. 5). ", "page_idx": 21}, {"type": "text", "text": "C.4 Image Generation with Early-Exit Diffusion ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Model details. For our image generation experiment, we re-implement the early-exit diffusion model proposed by Tang et al. [69] (DeeDiff), since the original code is not publicly available. We model our training procedure as closely as possible to the original. As suggested in the paper, we use the U-ViT transformer [7] as a backbone denoising network. Early-exiting in DeeDiff is performed on the denoising network at each sampling step. Specifically, for every sampling step $t$ and exit layer $e=1,\\ldots,L$ , a per-pixel confidence map $\\boldsymbol{c}_{e,t}$ is obtained. Then, $\\boldsymbol{c}_{e,t}$ is used to compute the global (scalar) confidence score $c_{e,t}$ by averaging the confidence across all pixels. If the scalar confidence score satisfies the exit condition $c_{e,t}\\geq\\lambda$ , we proceed to the next denoising step $t+1$ , employing the output (i.e., the predicted noise) of the $e$ -th exit layer at the $t$ -th sampling step. The model is trained using a standard diffusion denoising loss [35] and two uncertainty-aware losses, closely following the approach described in Tang et al. [69]. ", "page_idx": 21}, {"type": "text", "text": "LPIPS metric. Our task-specific prediction loss measures the perceptual difference between earlyexit and full model image generations. For this, we employ the LPIPS metric [82], which computes the similarity between activations of image patches for a selected pre-trained network. LPIPS values are in the range of $[0,1]$ , with smaller values indicating perceptually more similar images. ", "page_idx": 21}, {"type": "text", "text": "D Further Experimental Results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "D.1 Image Classification ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Additional test risk and efficiency curves for calibration set size $n=1000$ on ImageNet are displayed in Fig. 8, while tables with efficiency gain values on ImageNet are given in Table 2. ", "page_idx": 21}, {"type": "image", "img_path": "bbFjpasRgs/tmp/df0f24fb04ec8664091ef0e8969c80dd71020163728986c61a4b368efa00f844.jpg", "img_caption": ["Figure 8: Empirical test risk (top) and efficiency gains (bottom) for different early-exit models, risks $(\\S\\ 3.2)$ and risk levels $\\epsilon$ on ImageNet (for calibration set size $n=1000)$ ). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are substantial. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size $n\\in\\{100,1000\\}$ . Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer $(\\sin\\%$ ). The test risk is successfully controlled in all cases. Results focus on small risk levels $\\epsilon\\in\\{0.01,0.05\\}$ , which are of higher practical interest. ", "page_idx": 22}, {"type": "table", "img_path": "bbFjpasRgs/tmp/610224e2c78d8b099eb7a0af5e122b9965e49707cae5150e328ef240934e2a4d.jpg", "table_caption": ["(a) UCB and $n=100$ "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "bbFjpasRgs/tmp/1fdc031754f7f11509b1f6f068a1c813569589e88803b9fa07be1d1567de308c.jpg", "table_caption": ["(b) CRC and $n=100$ "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "bbFjpasRgs/tmp/02ee4d4b8aafca09a5164dcade894baca2c794d6b5b9c51a4357cbc767545358.jpg", "table_caption": ["(c) UCB and $n=1000$ "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "bbFjpasRgs/tmp/22ab3ef1c9206279464d054d6a7da5ce3442d00b39943cdf18356ae54ab5ac41.jpg", "table_caption": ["(d) CRC and $n=1000$ "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "D.2 Semantic Segmentation ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We report full tables with efficiency gains across risks and confidence measure combinations for Cityscapes (Table 3) and GTA5 (Table 4) in terms of mean exit layer and GFLOPS. In addition, we display test risk and efficiency curves on both Cityscapes (Fig. 9) and GTA5 (Fig. 10) for risk control via CRC (Prop. 1) and UCB (Prop. 2). The figures are for the simplest combination of Top-1 pixel-level confidence and mean image-level aggregation. Note that the figures for other confidence combinations are similar and thus omitted, with the test risk being controlled in all cases. ", "page_idx": 23}, {"type": "text", "text": "GTA5 results. We observe that for GTA5 the performance gap risk for prediction control $\\mathcal{R}^{G}(\\hat{\\pmb{y}})$ (mIoU) seems particularly easy to control, with high gains reached even for very strict $\\epsilon=0.01$ . This relates to the underlying predictor\u2019s generally inferior performance due to finetuning (see $\\S\\,\\mathrm{C}.2\\$ ). The obtained model records lower performance and marginal improvements across exit layers, resulting in a small risk that is easy to control. Intuitively, the price paid by exiting early is marginal, since the early-exit layer performs almost on par with the final layer. Thus, the scale of the risk deviates from that of other risks, and more meaningful risk control should consider both improving the underlying predictor, and selecting a different scale of risk levels $\\epsilon$ . ", "page_idx": 23}, {"type": "image", "img_path": "bbFjpasRgs/tmp/17b51542a23878f6b1cd9d7d78cb38d60166248be725dd34225032c094d618bf.jpg", "img_caption": ["Figure 9: Empirical test risk $(t o p)$ and efficiency gains (bottom) for different risks $(\\S\\ 3.2)$ and risk levels $\\epsilon$ on Cityscapes. In line with theoretical results, the test risk is controlled across risk types and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are meaningful. For both figures, we consider the simplest combination of Top-1 confidence score and mean image-level aggregation. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "bbFjpasRgs/tmp/b9dd0fbfda0b4f6b613316560477af3433ebf8c0c479e690a520df2d937ff23d.jpg", "img_caption": ["Figure 10: Empirical test risk (top) and efficiency gains (bottom) for different risks (\u00a7 3.2) and risk levels $\\epsilon$ on GTA5. In line with theoretical results, the test risk is controlled across risk types and levels. Despite guaranteeing control in expectation (CRC, Prop. 1) or with high probability (UCB, Prop. 2), obtained gains are meaningful. For both figures, we consider the simplest combination of Top-1 confidence score and mean image-level aggregation. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 3: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (\u00a7 3.2), confidence measures (\u00a7 5.2) and risk levels \u03f5. Displayed values denote relative improvement over last-layer exiting (in $\\%$ ) in terms of mean exit layer or floating point operations (GFLOPS). The test risk is successfully controlled in all cases. ", "page_idx": 24}, {"type": "table", "img_path": "bbFjpasRgs/tmp/2cf0a65f68ad358e77a67b7ad45aee3629c9a32de5ff04dcaa2f0f85671ecca3.jpg", "table_caption": ["(a) Efficiency gains in terms of mean exit layer improvement. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "bbFjpasRgs/tmp/3805d454047e090937bdf7828a43956a1c8577debc69c0845aee44f399a1a1c5.jpg", "table_caption": ["(b) Efficiency gains in terms of GFLOPS improvement. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 4: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on GTA5. We evaluate for different risks $(\\S\\ 3.2)$ , confidence measures $(\\S\\ S.2)$ and risk levels $\\epsilon$ . Displayed values denote relative improvement over last-layer exiting (in $\\%$ ) in terms of mean exit layer or floating point operations (GFLOPS). The test risk is successfully controlled in all cases. ", "page_idx": 24}, {"type": "table", "img_path": "bbFjpasRgs/tmp/51940b4238751f1cfc4465f440575bd32208378defa3e8223cde3d5784b536a9.jpg", "table_caption": ["(a) Efficiency gains in terms of mean exit layer improvement. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "bbFjpasRgs/tmp/c1a0fae7aab7fc0c58feef7c1da9ed662b352b911308467e16579829b080de59.jpg", "table_caption": ["(b) Efficiency gains in terms of GFLOPS improvement. "], "table_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "bbFjpasRgs/tmp/4aa0884f43af0fb00fe5a2ee848104e7ba255f09d9ee151ef5606f8de1378abb.jpg", "img_caption": ["D.3 Language Modeling ", "Figure 11: Empirical test risk (top) and efficiency gains (bottom) for the CALM model [65] for text summarization on CNN/DM and question answering on SQuAD. Our adaptation of UCB [8] (Prop. 2) outperforms the LTT [1] approach in CALM by yielding larger efficiency gains under the same risk control assurances. Shading denotes the standard deviation across $S=100$ calibration/test splits. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "bbFjpasRgs/tmp/5249766c04654b76f9b1a5d13a5352d4cc42f5a09827123d6b2c55c1d1128a29.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure 12: Empirical test risk $(t o p)$ and efficiency gains (bottom) for the CALM model for text summarization on CNN/DM across different confidence measures (see Schuster et al. [65], $\\S3.5)$ . From left to right: Hidden state saturation, meta-classifiers, and top-2 softmax difference. Our employed risk control frameworks based on CRC and UCB continue to outperform LTT across all measures of confidence. Shading denotes the standard deviation across $S=100$ splits. ", "page_idx": 25}, {"type": "text", "text": "D.4 Image Generation with Early-Exit Diffusion ", "page_idx": 25}, {"type": "image", "img_path": "bbFjpasRgs/tmp/18d559eb09eed660c9e8ebcd30e606d11873079e0afd9da681fd9655bf3a8c6b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure 13: Results for early-exit diffusion with DeeDiff [69] on CIFAR [42]. Right: Empirical test risks are controlled for both CRC (Prop. 1) and UCB (Prop. 2) (for calibration set size $n=500]$ ). Left: The quality of generated images is directly related to the targeted risk control level $\\epsilon$ . ", "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We provide all theoretical (see $\\S\\ 3$ ) and experimental (see $\\S\\ S$ ) results backing up our claims. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We clearly list out our key limitations in $\\S\\ 6$ . ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We state our theoretical results in $\\S\\ 3.3$ and provide the proofs in $\\S$ A.1. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We describe our experiments in $\\S\\ S$ and provide further implementation details in Appendix C. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our code is publicly available at https://github.com/metodj/RC-EENN. In $\\S\\ S$ and Appendix C, we describe our experimental setup in detail. All employed datasets are publicly available. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We describe our experiments in $\\S\\ S$ and provide further implementation details in Appendix C. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We display 1-sigma standard deviations across multiple trials of random calibration and test data splitting in all figures with empirical test risk and efficiency curves. The exceptions are Fig. 3 and Fig. 8 where we omit them to improve readability, without affecting any interpretation of results. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Since our approach is post-hoc, the required compute resources needed are minimal. The primary requirement is sufficient memory to jointly load the required calibration and test data, which can be quite large (e.g., for $2048\\times1024$ images on Cityscapes). All our experiments can be performed/replicated on a single A100 GPU with runtimes of $<\\!1\\mathrm{d}$ . We mention this in Appendix C. ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We checked the Code of Ethics carefully and our work complies with all the points listed there. ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: We clearly mention what we believe to be the impacts of our work in $\\S\\ 6$ . ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Our work doesn\u2019t introduce any new foundation or generation models, hence additional safeguards are not needed. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We made sure to properly cite all the related work and datasets used. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We describe our theory in $\\S\\ 3.3$ . We also additionally provide pseudo-code for our main algorithm in Appendix B, and reference all underlying papers. Our code is publicly available at https://github.com/metodj/RC-EENN. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: No experiments involving crowd-sourcing or human experiments were conducted in our research. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No experiments involving crowd-sourcing or human experiments were conducted in our research. ", "page_idx": 29}]