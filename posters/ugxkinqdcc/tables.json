[{"figure_path": "ugXKInqDCC/tables/tables_6_1.jpg", "caption": "Table 1: Comparison between BC, Diffusion Policy, Rectified Flow and AdaFlow.", "description": "This table compares four different imitation learning methods: Behavior Cloning (BC), Diffusion Policy, Rectified Flow, and AdaFlow.  It highlights their capabilities in generating diverse behaviors, achieving fast action generation, and avoiding the need for distillation or reflow techniques.  Each method is marked with a checkmark (\u2713) or cross (\u2717) to indicate the presence or absence of each capability.  BC is shown to be fast but not diverse, while the others offer diversity but at the cost of slower inference, except for AdaFlow, which aims to combine both speed and diversity.", "section": "4. Experiments"}, {"figure_path": "ugXKInqDCC/tables/tables_6_2.jpg", "caption": "Table 2: Performance on maze navigation tasks. The table showcases the success rate for each model across different maze complexities. The highest success rate for each task are highlighted in bold. NFE denotes Number of Function Evaluations.", "description": "This table presents the performance of different models on four maze navigation tasks with varying complexities.  The success rate (percentage of times the task was successfully completed) is shown for each model, along with the average number of function evaluations (NFEs) required for each task completion. The best performance for each maze is highlighted in bold.  This helps compare the efficiency and effectiveness of different methods in navigating mazes.", "section": "4.2 Navigating a 2D Maze"}, {"figure_path": "ugXKInqDCC/tables/tables_7_1.jpg", "caption": "Table 3: Success rate on RoboMimic Benchmark. The highest success rate for each task are highlighted in bold.", "description": "This table presents a comparison of the success rates achieved by different methods on the RoboMimic benchmark.  The benchmark consists of several robot manipulation tasks.  Each row represents a different method (Rectified Flow, LSTM-GMM, IBC, BET, Diffusion Policy at different numbers of function evaluations (NFEs), and AdaFlow).  The columns represent the success rate for each task (Lift, Can, Square, Transport, ToolHang, Push-T) and the average number of function evaluations (NFE) required.  The highest success rate for each task is highlighted in bold.", "section": "4.3 Robot Manipulation Tasks"}, {"figure_path": "ugXKInqDCC/tables/tables_7_2.jpg", "caption": "Table 4: Success Rate on LIBERO Benchmark. The highest success rate for each task are highlighted in bold.", "description": "This table presents the success rates of different methods on the LIBERO benchmark, a set of robot manipulation tasks.  The methods compared include Rectified Flow (requiring a reflow step), Diffusion Policy (tested with different numbers of function evaluations (NFE)), and AdaFlow.  The table highlights AdaFlow's consistently high success rates, particularly notable given its low average NFE of 1.27, demonstrating high efficiency.", "section": "4.3 Robot Manipulation Tasks"}, {"figure_path": "ugXKInqDCC/tables/tables_8_1.jpg", "caption": "Table 5: Ablation study on the use of estimated variance to determine inference steps. Euler sampler is used for AdaFlow without variance estimation.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of the variance estimation network on the performance of AdaFlow.  It compares the success rates of AdaFlow with and without the variance estimation network across four different maze navigation tasks (Maze1, Maze2, Maze3, Maze4). The results demonstrate that incorporating the variance estimation network significantly improves AdaFlow's performance.", "section": "4.4 Ablation Study"}, {"figure_path": "ugXKInqDCC/tables/tables_14_1.jpg", "caption": "Table 6: Performance comparison of separate training and joint training of AdaFlow in Maze tasks.", "description": "This table compares the performance of AdaFlow trained using two different methods: separate training and joint training.  The results show success rates across four different maze tasks (Maze1-Maze4).  Separate training is faster but the performance difference between the two methods is minimal.", "section": "A.6 Comparative Analysis of Separate and Joint Training"}, {"figure_path": "ugXKInqDCC/tables/tables_15_1.jpg", "caption": "Table 7: Hyperparameters used for AdaFlow and baseline models.", "description": "This table lists the hyperparameters used for training AdaFlow and three baseline models (BC, Diffusion Policy, and Rectified Flow) across three different task types: 1D toy regression, 2D maze navigation, and robot manipulation tasks (RoboMimic & LIBERO).  For each model and task, the table specifies the learning rate, optimizer, beta1 and beta2 values for the optimizer, weight decay, batch size, number of epochs trained, learning rate scheduler, exponential moving average (EMA) decay rate, the number of training and inference steps, the error threshold (\u03b7), the minimum step size (\u03f5min), action prediction horizon, number of observation inputs, action execution horizon, and the size of the observation input.", "section": "4.3 Robot Manipulation Tasks"}, {"figure_path": "ugXKInqDCC/tables/tables_16_1.jpg", "caption": "Table 8: Performance on maze navigation tasks. The table showcases the success rate (SR) for each model across different maze complexities. The highest success rate for each task are highlighted in bold. Note that 2-RF needs an expensive distillation training stage.", "description": "This table compares the performance of several models, including AdaFlow, on four different maze navigation tasks.  The success rate (SR) is shown for each model and each maze, highlighting the best performance for each task.  It demonstrates that AdaFlow achieves competitive performance with low computational cost. The table also points out that the 2-Rectified Flow model requires an expensive distillation training stage, which contrasts with AdaFlow's efficiency.", "section": "4.2 Navigating a 2D Maze"}]