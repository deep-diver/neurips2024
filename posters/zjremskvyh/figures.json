[{"figure_path": "zJremsKVyh/figures/figures_2_1.jpg", "caption": "Figure 1: A visual abstract outlining the different components of a frugal model, and how each specific component is parameterised. Univariate CDFs are denoted by F, and copula distribution functions are denoted by C. The marginal causal effect, \u03b8y|do(T), is modelled with a univariate normalising flow, which we denote by F (see Section 2.4). The intervened dependency measure, \u03b8ZY|do(T), is modelled with a copula flow which we denote by C (see Section 2.5). The past, \u03b8ZT, is modelled by the combination of univariate normalising flows (for the univariate pretreatment covariate distributions) and a copula flow (for the propensity of treatment).", "description": "This figure illustrates the components of a frugal model and how each is parameterized.  It shows how univariate and copula flows are used to model the marginal causal effect, the intervened dependency measure, and the past (pretreatment covariates and treatment).", "section": "2.2 Frugal Parameterisations"}, {"figure_path": "zJremsKVyh/figures/figures_8_1.jpg", "caption": "Figure 3: Boxplot of ATE estimates from 10 inference methods, estimated across 50 different samples from a FF trained on the Lalonde dataset. The dotted red line represents the customized ATE of samples generated from the trained Frugal Flow.", "description": "Boxplots showing the distribution of Average Treatment Effect (ATE) estimates from ten different causal inference methods applied to 50 datasets generated from a Frugal Flow model trained on the Lalonde dataset.  Each boxplot represents a method, showing the median, quartiles, and range of ATE estimates.  The red dotted line indicates the true ATE programmed into the Frugal Flow model during data generation. This figure demonstrates the performance of various causal inference methods on data that mimics real-world complexity and confounding.", "section": "4.2 Benchmarking and Validation"}, {"figure_path": "zJremsKVyh/figures/figures_9_1.jpg", "caption": "Figure 4: Boxplot of ATE estimates from 10 inference methods, estimated across 50 different samples from a FF trained on the e401(k) dataset. The dotted red line represents the customized ATE of samples generated from the trained Frugal Flow.", "description": "Boxplots showing the distribution of ATE estimates from 10 different causal inference methods applied to 50 synthetic datasets generated by a Frugal Flow trained on the e401(k) dataset.  Three scenarios are shown: no confounding, real-world confounding, and hidden confounding with a correlation of 0.2. The red dotted line indicates the true ATE used to generate the synthetic data.", "section": "4.2 Benchmarking and Validation"}, {"figure_path": "zJremsKVyh/figures/figures_13_1.jpg", "caption": "Figure 5: A generalised example of a static causal treatment model. The past P(T, Z) (black) can be freely specified separately from the causal effect (blue). However, the dependency measure between Z and Y (red), \u03d5, should be parameterised in such a way that the margins P(Z) and P(Y|do(T)) are invariant to changes in \u03d5.", "description": "This figure shows a causal diagram representing a static causal treatment model. The variables are: T (treatment), Z (pre-treatment covariates), and Y (outcome).  The black arrows depict the relationship between Z and T, where Z affects T, representing the data generation process prior to treatment assignment. The red arrow shows the direct effect of Z on Y, while the blue arrow represents the direct causal effect of T on Y. The model aims to estimate the marginal causal effect of T on Y, independent of Z. The crucial element is the dependency measure (\u03d5) which relates Z and Y given the treatment T.  This measure needs to be designed such that it does not change the marginal distributions of Z and Y, ensuring that any change only affects the dependence between them.  This is vital for accurately representing the causal effect of T on Y.", "section": "A The Frugal Parameterisation"}, {"figure_path": "zJremsKVyh/figures/figures_21_1.jpg", "caption": "Figure 7: Lalonde: Correlation matrices across covariates and the outcome (re78), comparing the second moments of distributions for the Lalonde observed real data, as well as synthetic data generated by a trained Frugal Flow (2nd column) and Credence (3rd column) models. The comparison is further extended to models with default settings and those with modified bias rigidity (4th column).", "description": "This figure compares the correlation matrices of the Lalonde dataset's observed data with those generated by Frugal Flows and Credence models.  It demonstrates how closely Frugal Flows reproduce the original data's correlation structure, even when compared to models (Credence) which aim to exactly match specific causal constraints. The different columns illustrate how the correlations change when different causal effects are targeted.", "section": "4.2 Benchmarking and Validation"}, {"figure_path": "zJremsKVyh/figures/figures_22_1.jpg", "caption": "Figure 8: e401(k): Correlation matrices across covariates and the outcome (net_tfa), comparing the second moments of distributions for the e401(k) observed real data, as well as synthetic data generated by a trained Frugal Flow (2nd column) and Credence (3rd column) models. The comparison is further extended to models with default settings and those with modified bias rigidity (4th column).", "description": "This figure compares the correlation matrices of the observed e401(k) dataset with those generated by Frugal Flows and Credence models.  It highlights the ability of Frugal Flows to generate synthetic data that closely resembles the original data, even when adjusting causal constraints. In contrast, Credence shows a greater deviation in covariate dependencies when modifying causal constraints.", "section": "D.3.6 Realism of Datasets"}, {"figure_path": "zJremsKVyh/figures/figures_22_2.jpg", "caption": "Figure 9: Training and validation losses when fitting a Frugal Flow to the Lalonde dataset using optimal hyperparameters and a \\\"patience\\\" setting of 200 iterations for illustrative purposes.", "description": "This figure shows the training and validation loss curves during the training of a Frugal Flow model on the Lalonde dataset.  The x-axis represents the iteration number, and the y-axis represents the loss.  The blue line shows the training loss, and the red line shows the validation loss. The plot illustrates how the model's performance on both the training and validation sets improves over time, ultimately converging towards a low loss value. The use of a 'patience' parameter of 200 indicates that training stopped when the validation loss did not improve for 200 iterations, a common technique to avoid overfitting.", "section": "D.3.7 Loss Optimisation"}, {"figure_path": "zJremsKVyh/figures/figures_22_3.jpg", "caption": "Figure 10: Training and validation losses when fitting a Frugal Flow to the e401(k) dataset using optimal hyperparameters and a \\\"patience\\\" setting of 200 iterations for illustrative purposes.", "description": "The figure shows the training and validation loss curves during the training process of a Frugal Flow model on the e401(k) dataset. The hyperparameters were optimized, and training stopped early using a patience criterion to prevent overfitting.  The x-axis represents the training iteration, and the y-axis shows the loss value.  The plot helps assess the model's convergence and potential overfitting.", "section": "D.3.7 Loss Optimisation"}]