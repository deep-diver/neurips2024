[{"figure_path": "NMwPKjNTEP/tables/tables_5_1.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance of different backdoor attack methods on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection). For each dataset and target class, it shows the clean accuracy (the accuracy on clean data without any backdoor attacks) and attack success rate (the success rate of the backdoor attacks). The best results for each metric are highlighted in bold, and the second-best results are underlined. The poisoning rate (the percentage of poisoned samples in the training data) is fixed at 40%.  The table demonstrates the effectiveness of the proposed ManiBCI attack in comparison with several baseline methods.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_6_1.jpg", "caption": "Table 2: Clean and attack performance with with different trigger search optimization algorithms, the poisoning rate is set to 10%. The target model is EEGNet.", "description": "This table shows the clean accuracy and attack success rate for different trigger search optimization algorithms (Random, Genetic Algorithm, Policy Gradient) on three EEG datasets (Emotion Recognition, Motor Imagery, Epilepsy Detection). The poisoning rate is fixed at 10%, and the target model used is EEGNet.  The table compares the performance of these algorithms in terms of both clean accuracy (how well the model performs on clean data) and attack success rate (how well the backdoor attack works).  The \"Time\" column indicates the time taken for each algorithm to find the optimal trigger injection strategy.", "section": "4.2.3 Performance of Learned Mask Strategies on Other Target Models"}, {"figure_path": "NMwPKjNTEP/tables/tables_6_2.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance of different backdoor attack methods on three different EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) using three different EEG deep learning models (EEGNet, DeepCNN, and LSTM).  For each dataset and model, it shows the clean accuracy (the accuracy on clean data without backdoor attacks) and the attack success rate (ASR) for each of the three or four classes of the task (i.e., target classes). The ASR indicates how well a backdoor attack manipulates the model to misclassify the samples with a specific trigger into a target class. The best and second best results are highlighted in bold and underlined, respectively, to facilitate comparison.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_7_1.jpg", "caption": "Table 4: Clean and attack performance on three datasets after different EEG preprocessing methods. The target model is EEGNet. M w.o. DIS means removing the DIS loss in ManiBCI.", "description": "This table presents the clean accuracy and attack success rate for three different EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) after applying various preprocessing methods (20Hz low-pass filter, 30Hz high-pass filter, and 25% downsampling). The results are compared for the ManiBCI attack with and without the discrete loss (DIS). The average attack success rate (ASR) is also provided.", "section": "4.3.1 Robustness against EEG Preprocessing Methods"}, {"figure_path": "NMwPKjNTEP/tables/tables_12_1.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance of different backdoor attack methods on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) with three different EEG models (EEGNet, DeepCNN, and LSTM).  The table shows the clean accuracy (Clean) and attack success rate (ASR) for each target class and each attack method.  A 40% poisoning rate was used, meaning 40% of the training data was poisoned.  The best results for each class and method are highlighted in bold, while the second best are underlined.  This allows for comparison of the effectiveness of each attack method under controlled conditions.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_15_1.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance comparison of different backdoor attack methods on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) with 40% poisoning rate.  The results are shown for three different EEG models (DeepCNN, EEGNet, and LSTM) and are broken down by target class.  'Clean' represents the accuracy of the model on clean data, while 'ASR' (Attack Success Rate) indicates the success rate of the attack on poisoned data.  The best results for each model and class are shown in bold, while the second-best results are underlined.  This allows for a detailed analysis of each method's efficacy and robustness under a range of circumstances.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_15_2.jpg", "caption": "Table 10: Clean (/C) and attack (/B) performance with ASR's hyperparameter \u03bb, \u03bc = 0.3, \u03bd = 0.005", "description": "This table presents the clean accuracy and attack success rate for each class of all attack methods on three EEG datasets with three different EEG DL models by varying the hyperparameter \u03bb in the reward function of reinforcement learning while keeping \u03bc and \u03bd constant.  It shows the impact of \u03bb on the trade-off between clean accuracy and attack success rate.  Higher values of \u03bb generally lead to higher attack success rates but lower clean accuracies.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_16_1.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance of different backdoor attack methods on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) using three different EEG deep learning models (EEGNet, DeepCNN, and LSTM).  For each dataset and model, the table shows the clean accuracy (the accuracy of the model on clean data without any backdoor attack) and the attack success rate (the accuracy of the model in misclassifying poisoned data into a target class). The poisoning rate is fixed at 40%.  The best and second-best results for each target class are highlighted in bold and underlined, respectively.  This allows for comparison of the effectiveness of various backdoor attack methods under the same conditions.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_17_1.jpg", "caption": "Table 7: Clean (/C) and attack (/B) performance with different poisoning rates for ManiBCI and other baseline methods. The target model is EEGNet for all cases.", "description": "This table presents the clean accuracy and attack success rate for different poisoning rates (5%, 10%, 15%, 20%, 25%, 30%, 35%, 40%, 45%, 50%). The results are shown for three different EEG datasets (Emotion Recognition, Motor Imagery, Epilepsy Detection) and for multiple methods (PatchMT, PulseMT, CompressMT, ManiBCI). The target model used is EEGNet.  The table helps to understand the effectiveness of ManiBCI across different poisoning ratios and in comparison to other baseline methods.", "section": "4.2 Effectiveness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/tables/tables_18_1.jpg", "caption": "Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate. The best results are in bold and the second best are underlined.", "description": "This table presents the performance of different backdoor attack methods on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) with a poisoning rate of 40%.  The table shows the clean accuracy (how well the model performs on clean data without backdoor attacks) and the attack success rate (how successfully the backdoor manipulates the model's prediction on poisoned data) for each target class (0, 1, 2, or 3 depending on the dataset).  Different EEG models (DeepCNN, EEGNet, and LSTM) are used for classification. The best results for each metric are bolded, while the second best are underlined.  The table allows for comparison of the effectiveness of different attack strategies.", "section": "4.2 Effectiveness of ManiBCI"}]