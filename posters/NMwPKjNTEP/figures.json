[{"figure_path": "NMwPKjNTEP/figures/figures_1_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the ManiBCI framework, comparing it to existing EEG backdoor attacks.  Panel (a) shows trigger selection and data distribution on a manifold. Panel (b) depicts the reinforcement learning process for optimizing electrode and frequency injection strategies.  Panel (c) details the ManiBCI data poisoning process. Panel (d) contrasts the payloads of existing attacks, highlighting their limitations. Finally, panel (e) showcases ManiBCI's ability to arbitrarily manipulate the BCI's output.", "section": "3 Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_2_1.jpg", "caption": "Figure 2: t-SNE visualization.", "description": "This figure shows the t-SNE visualization of the real data and poisoned data generated by two different backdoor attacks: NPP-based attack and ManiBCI attack.  The left subplot (a) shows that NPP-added poisoned data forms a distinct cluster separated from the real data, indicating a lack of stealthiness.  The right subplot (b) illustrates that ManiBCI poisoned data is more interspersed with the real data, suggesting improved stealthiness compared to the NPP-based approach. This visualization helps to demonstrate ManiBCI's ability to generate more imperceptible poisoned data.", "section": "2 Related Work"}, {"figure_path": "NMwPKjNTEP/figures/figures_6_1.jpg", "caption": "Figure 3: Clean (/C) and attack (/B) performance with different poisoning or injection rates.", "description": "This figure displays the performance of ManiBCI and other baseline methods across three different datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection) under varying conditions.  The left panel shows the impact of different poisoning rates (the percentage of poisoned samples in the training data) on the clean accuracy and attack success rate. The middle panel demonstrates the effect of varying the frequency/time injection rate (the proportion of the EEG signal modified). The right panel illustrates the effect of altering the electrodes injection rate (the number of electrodes involved in the attack). Each line represents a different method, indicating their respective performance under each parameter variation.  The plots demonstrate ManiBCI's superior performance and robustness compared to other backdoor attack methods.", "section": "4.2.4 Attack Performance with Different Hyperparameters"}, {"figure_path": "NMwPKjNTEP/figures/figures_7_1.jpg", "caption": "Figure 2: t-SNE visualization.", "description": "This figure shows the t-SNE visualization of the real data, NPP-added poisoned data and ManiBCI poisoned data. The visualization shows that the NPP-added poisoned data significantly deviates from the real data distribution, while the ManiBCI poisoned data stays in the real data boundary. This demonstrates that ManiBCI is more stealthy than NPP-based backdoor attack.", "section": "2.1 Backdoor Attacks"}, {"figure_path": "NMwPKjNTEP/figures/figures_7_2.jpg", "caption": "Figure 5: Performance against STRIP on three datasets, the target model is EEGNet.", "description": "This figure shows the performance of ManiBCI and other baseline methods against STRIP on three datasets: Emotion Recognition, Motor Imagery, and Epilepsy Detection.  The target model used is EEGNet. STRIP (Sample-wise Trigger Reconstruction based Input Perturbation) is a backdoor defense method that attempts to identify and mitigate backdoors by analyzing the entropy of predictions made on perturbed input EEG data.  The figure displays the entropy distributions for both clean samples and backdoor samples (generated by ManiBCI). The similar entropy distributions between clean and backdoor samples demonstrate the robustness of ManiBCI against the STRIP defense.", "section": "4.3 Robustness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/figures/figures_8_1.jpg", "caption": "Figure 6: Performance against Spectral Signature on three datasets, the target model is EEGNet.", "description": "This figure shows the results of evaluating the robustness of the ManiBCI backdoor attack against the Spectral Signature defense.  The defense attempts to detect backdoors by analyzing the statistical correlations between clean and backdoor data in a latent space.  The histograms in the figure show the distribution of correlation scores for 5,000 clean samples and 500 ManiBCI backdoor samples, across three different EEG datasets (Emotion Recognition, Motor Imagery, Epilepsy Detection). The lack of a clear separation between the distributions indicates that the ManiBCI backdoor samples are stealthy and difficult to detect using the Spectral Signature method.", "section": "4.3 Robustness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/figures/figures_8_2.jpg", "caption": "Figure 5: Performance against STRIP on three datasets, the target model is EEGNet.", "description": "This figure shows the performance of ManiBCI and other baseline methods against STRIP (a backdoor defense method) on three EEG datasets (Emotion Recognition, Motor Imagery, and Epilepsy Detection).  The x-axis represents the entropy of the EEG data after perturbation by STRIP.  The y-axis is the probability density of the entropy values.  The figure demonstrates that the entropy distributions of backdoor and clean samples are similar for ManiBCI, indicating its robustness against STRIP.", "section": "4.3 Robustness of ManiBCI"}, {"figure_path": "NMwPKjNTEP/figures/figures_8_3.jpg", "caption": "Figure 8: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the ED dataset. The x-axis is the timepoints, the y-axis is the normalized amplitude. Top row: w.o. HF loss; Bottom row: with HF loss. Each column indicates each possible class.", "description": "This figure visualizes the effect of ManiBCI, a backdoor attack on EEG data, by comparing clean EEG signals to those with injected triggers, both with and without a high-frequency (HF) loss component.  The top row shows the results without HF loss, while the bottom row incorporates it. Each column represents a different class, showing how the injected trigger affects the signal, and how the HF loss component reduces the residual difference between the clean and injected signals, resulting in a more stealthy attack.", "section": "4.4 Visualization of Backdoor Attack Samples"}, {"figure_path": "NMwPKjNTEP/figures/figures_19_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the ManiBCI framework, comparing it to existing EEG backdoor attacks.  It breaks down ManiBCI into three stages: trigger selection and data distribution visualization (manifold learning), learning optimal electrode and frequency injection strategies using reinforcement learning, and the generation of poisoned data via frequency transformation.  Panels (d) and (e) show a comparison of the payloads (the injected triggers) used in ManiBCI versus those of existing attacks. ManiBCI's key advantage is its ability to arbitrarily manipulate the EEG BCI's output, unlike the single target class attacks of existing methods.", "section": "Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_20_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the framework of ManiBCI, a novel backdoor attack for EEG-based brain-computer interfaces. It shows the three stages of the attack: trigger selection, learning optimal injection strategies, and generating poisoned data.  It also contrasts ManiBCI with existing backdoor attacks, highlighting ManiBCI's ability to arbitrarily manipulate the output of EEG BCI models.", "section": "3 Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_21_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the ManiBCI framework, comparing it to existing EEG backdoor attacks.  Panel (a) shows trigger selection and data distribution using manifold learning. Panel (b) details the reinforcement learning process for optimizing electrode and frequency injection strategies. Panel (c) depicts the ManiBCI attack's generation process. Panels (d) and (e) contrast the payloads of existing attacks with ManiBCI's ability to arbitrarily manipulate the EEG BCI output.", "section": "3 Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_22_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the ManiBCI framework, comparing it to existing EEG backdoor attacks.  It shows the three stages of ManiBCI: trigger selection, optimal strategy learning (electrode and frequency selection), and poisoned data generation.  The figure highlights how ManiBCI injects triggers in the frequency domain, unlike existing attacks which primarily operate in the time domain, and enables arbitrary target class manipulation.", "section": "Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_22_2.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the ManiBCI framework, comparing it to existing EEG backdoor attacks.  Panel (a) shows trigger selection and data distribution using manifold learning.  Panel (b) depicts the reinforcement learning process to find optimal electrode and frequency injection strategies. Panel (c) details the ManiBCI generation process. Panels (d) and (e) contrast the payloads of existing attacks versus ManiBCI, highlighting the latter's ability to arbitrarily manipulate the EEG BCI's output.", "section": "Methodology"}, {"figure_path": "NMwPKjNTEP/figures/figures_23_1.jpg", "caption": "Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models.", "description": "This figure illustrates the framework of ManiBCI, a novel backdoor attack for EEG-based brain-computer interfaces (BCIs). It is composed of three stages: (a) selecting triggers and visualizing EEG data distribution using manifold learning; (b) learning optimal electrode and frequency injection strategies using reinforcement learning; and (c) generating poisoned data by injecting the learned trigger frequencies into clean EEG data using frequency transform.  The figure also contrasts ManiBCI's payload with existing backdoor attacks, highlighting ManiBCI's ability to arbitrarily manipulate the BCI's output.", "section": "Methodology"}]