[{"figure_path": "HRnSVflpgt/tables/tables_6_1.jpg", "caption": "Table 1: Comparison between Schur Layer and Linmaps with different message passing schemes.", "description": "This table compares the performance of the Schur Layer and Linmaps methods with different message passing schemes on the ZINC-12K dataset. The message passing scheme determines when two subgraph representations communicate (i.e., overlap of 1 or more vertices, or overlap of 2 or more vertices).  The results show that the Schur Layer consistently outperforms Linmaps across various message passing schemes, indicating its improved efficiency and accuracy.", "section": "5.1 Schur layer improves over Linmaps"}, {"figure_path": "HRnSVflpgt/tables/tables_7_1.jpg", "caption": "Table 2: An experiment demonstrating different ways of using Schur layer. \"Complete Schur Layer\" means that we apply Schur Layer on the incoming messages together with the original cycle representation. \"Linmap SchuLayer\" means that we just apply the Schur Layer on the aggregated subgraph representation feature. \"Simple Schur Layer\" means we directly apply Schur Layer on the subgraph features without any preprocessing. We can observe that as the subgraph information diversifies, Schur layer tends to decouple the dense information better and results in better performance. The test MAE of Linmaps in this table is taken from [22].", "description": "This table shows an ablation study on different ways of using the Schur layer in a neural network model.  The results demonstrate that applying the Schur layer at different stages of processing subgraph information leads to varying improvements in predictive accuracy (measured by Test MAE).  Specifically, using the Schur Layer in conjunction with the original cycle representation shows the largest performance gains.", "section": "5.2 Flexibility"}, {"figure_path": "HRnSVflpgt/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of different models on the ZINC-12K and OGBG-MOLHIV datasets.", "description": "This table compares the performance of various graph neural network (GNN) models on two benchmark datasets: ZINC-12K (for predicting molecular properties) and OGB-HIV (for predicting the activity of HIV inhibitors).  The table shows the mean absolute error (MAE) for ZINC-12K and the area under the receiver operating characteristic curve (ROC-AUC) for OGB-HIV.  The models include classical GNNs (GCN, GIN, GINE, PNA, HIMP), higher-order GNNs (N2-GNN, CIN, P-tensors), subgraph-based GNNs (DS-GNN, DSS-GNN, GNN-AK+, SUN), and the Autobahn architecture.  The results demonstrate that the proposed Schur-Net model outperforms many existing methods, particularly on the OGB-HIV dataset.", "section": "Benchmark results"}, {"figure_path": "HRnSVflpgt/tables/tables_15_1.jpg", "caption": "Table 4: Examples on EVD approach vs group theoretical approach towards # of equivariant maps w.r.t. Auts. To calculate the decomposition of Rm into irreps, one can calculate ki = (\u03a6|xi) where and Xi is the character of the first-order action and ith irrep respectively, and (|) is inner product. Another quick approach is to use \u03c6(\u03c3) = \u03a3kKkXk(\u03c3) and look at some examples of o to determine what the Kk should be.", "description": "This table compares the number of equivariant maps obtained by the spectral approach (Schur layer) with the number obtained by the group theoretical approach for several small graphs.  It demonstrates that the spectral method, which is computationally more efficient, achieves comparable results to the theoretically complete, yet computationally intensive group-theoretic approach.  The table shows the automorphism group (Auts), the number of distinct eigenvalues (used in the Schur layer), and the number of irreps obtained via the group-theoretic method, comparing them to show the closeness of the approximation.", "section": "D Analysis of Schur layer"}, {"figure_path": "HRnSVflpgt/tables/tables_16_1.jpg", "caption": "Table 4: Examples on EVD approach vs group theoretical approach towards # of equivariant maps w.r.t. Auts. To calculate the decomposition of R into irreps, one can calculate ki = (\u03a6|\u03c7i) where \u03a6 and \u03c7i is the character of the first-order action and ith irrep respectively, and (|) is inner product. Another quick approach is to use \u03c6(\u03c3) = \u03a3kKkXk(\u03c3) and look at some examples of \u03c3 to determine what the Kk should be.", "description": "This table compares the number of equivariant maps obtained using two different approaches: the eigenvalue decomposition (EVD) approach and the group theoretical approach.  It illustrates the potential gap between these approaches for different types of graphs, highlighting the number of distinct eigenvalues found by the EVD approach versus the number of irreps (irreducible representations) obtained from the group theoretical approach. The table includes calculations for various graphs, such as cycles and stars, and shows how the number of distinct eigenvalues and irreps may differ.  The methods of calculating these values are also described.", "section": "D Analysis of Schur layer"}, {"figure_path": "HRnSVflpgt/tables/tables_20_1.jpg", "caption": "Table 6: Comparison about two use cases of Schur layer. Experiment on ZINC-12K.", "description": "This table compares the performance of three different methods on the ZINC-12K dataset. The methods are: Linmaps (baseline), Schur layer (in place of MLP), and Schur layer (as learning new feature). The validation MAE is used as the evaluation metric. The results show that Schur layer (as learning new feature) achieves the best performance, followed by Schur layer (in place of MLP), and then Linmaps.", "section": "5.2 Flexibility"}, {"figure_path": "HRnSVflpgt/tables/tables_20_2.jpg", "caption": "Table 7: Flexibility of Schur layer. Experiments on ZINC-12k dataset. All other settings are the same. A smaller network than previous experiments was used.", "description": "This table shows the results of experiments on the ZINC-12K dataset comparing the performance of two models: a baseline Schur-Net using only 5 and 6 cycles and an augmented Schur-Net that also includes cycles with up to three branches.  The results demonstrate the impact of incorporating more diverse subgraph structures on model performance, with the augmented model achieving a lower validation MAE.", "section": "5.2 Flexibility"}, {"figure_path": "HRnSVflpgt/tables/tables_20_3.jpg", "caption": "Table 8: Comparison of Linmaps and Schur Layer performance on TUdatasets. Numbers are binary classification accuracy.", "description": "This table presents a comparison of the performance of Linmaps and Schur Layer on various datasets from the TUDataset benchmark.  The performance metric is binary classification accuracy, reported as the mean \u00b1 standard deviation. The results demonstrate that Schur Layer generally improves upon Linmaps across different datasets.", "section": "H More experiment results"}, {"figure_path": "HRnSVflpgt/tables/tables_20_4.jpg", "caption": "Table 9: Runtime per epoch with hyper-params num_layers = 4, rep_dim = 128, dropout = 0.0, batch_size = 256, num of channels = 4, cycle_sizes = 3,4,5,6,7,8. This shows Schur Layer didn't add much computational costs to Linmaps while being more expressive.", "description": "This table compares the runtime per epoch of Linmaps and Schur Layer on the ZINC-12k and NCI1 datasets.  The hyperparameters used are specified in the caption. The results show that Schur Layer's increased expressiveness does not come at a significant computational cost.", "section": "5.3 Benchmark results"}, {"figure_path": "HRnSVflpgt/tables/tables_21_1.jpg", "caption": "Table 10: Comparison between Schur Layer and Linmaps with different set of cycles chosen. Experiments on ZINC-12k dataset and all scores are test MAE.", "description": "This table compares the performance of the Schur layer and Linmaps methods on the ZINC-12k dataset using different sets of cycle sizes for higher-order message passing. The test MAE (Mean Absolute Error) is reported for both methods, showing that the Schur layer consistently outperforms the baseline Linmaps method.", "section": "5 Experiments"}]