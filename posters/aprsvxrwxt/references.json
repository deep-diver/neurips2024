{"references": [{"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2022-09-14", "reason": "This paper introduces a pioneering text-to-3D generation method using 2D diffusion models, significantly impacting the field and inspiring many subsequent works including this one."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces the 3D Gaussian splatting technique, a key component of the proposed method in this paper, enabling high-quality and efficient 3D content generation."}, {"fullname_first_author": "Jiaxiang Tang", "paper_title": "LGM: Large multi-view gaussian model for high-resolution 3d content creation", "publication_date": "2024-02-00", "reason": "This paper presents a strong baseline method for 3D content creation using multi-view Gaussian models, against which the proposed method is compared and improved upon."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-12-00", "reason": "This paper introduces the Mamba model, a core component of the proposed method, which is a novel RNN-like state space model designed for efficient and high-quality long sequence modeling."}, {"fullname_first_author": "Peng Wang", "paper_title": "Imagedream: Image-prompt multi-view diffusion for 3d generation", "publication_date": "2023-12-00", "reason": "This paper provides a crucial multi-view image generation model used as a pre-processing step in the proposed method, which converts single images or text into multi-view images for subsequent 3D reconstruction."}]}