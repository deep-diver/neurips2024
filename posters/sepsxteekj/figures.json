[{"figure_path": "sEpSxteEKJ/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the AL-RNN architecture.", "description": "The figure illustrates the architecture of the Almost-Linear Recurrent Neural Network (AL-RNN). It shows three types of neurons: N linear readout neurons that directly receive input from the time series data, L linear non-readout neurons that are fully connected to the other neurons, and P piecewise linear (PWL) neurons that introduce nonlinearities into the network.  The figure also shows how the activation of the PWL neurons is represented symbolically, using a binary code that represents the activation pattern in each of the 2^P subregions.", "section": "3.1 AL-RNN Model"}, {"figure_path": "sEpSxteEKJ/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of symbolic approach (3 panels on the left) and geometrical graphs (right).", "description": "This figure illustrates the symbolic dynamics approach and its geometrical representation.  The left side demonstrates the process of symbolic coding, starting with a partitioning of the state space into linear subregions (2P possible subregions, given P piecewise linear neurons). A trajectory is represented as a sequence of symbols (000, 100, 110, 011, etc.), where each symbol corresponds to a subregion.  The permitted transitions between symbols are shown using a symbolic graph (a topological graph representation), and the relative frequency of transitions between subregions are shown in a weighted transition graph (a geometrical graph representation). The geometrical graph uses a weighted adjacency matrix to reflect transition frequencies in the dynamics.", "section": "3.2 Theoretical Background: Symbolic Dynamics and Symbolic Coding of AL-RNN"}, {"figure_path": "sEpSxteEKJ/figures/figures_6_1.jpg", "caption": "Figure 3: Quantification of DSR quality in terms of attractor geometry disagreement (Dstsp, top row) and disagreement in temporal structure (DH, bottom row) as a function of the number of ReLUs (P) in the AL-RNN (R\u00f6ssler: M = 20, Lorenz-63: M = 20, ECG: M = 100, fMRI: M = 50). The little humps at P = 3 for the Lorenz-63 indicate that performance may sometimes first degrade again when passing the number of minimally necessary PWL units (see also Fig. 9). Error bars = SEM.", "description": "This figure displays the DSR quality (geometry and temporal structure disagreement) for the AL-RNN model across four datasets (R\u00f6ssler, Lorenz-63, ECG, fMRI) as the number of ReLU (PWL) units increases.  It shows that performance generally improves with more ReLU units, but the optimal number of units varies between datasets, with some datasets showing initial performance degradation before improvement.", "section": "5 Experimental Results"}, {"figure_path": "sEpSxteEKJ/figures/figures_6_2.jpg", "caption": "Figure 4: Left: Number of linear subregions traversed by trained AL-RNNs as a function of the number P of ReLUs. Theoretical limit (2P) in red. Right: Cumulative number of data (trajectory) points covered by linear subregions in trained AL-RNNs (R\u00f6ssler: M = 20, P = 10, Lorenz-63: M = 20, P = 10, ECG: M = 100, P = 10), illustrating that trajectories on an attractor live in a relatively small subset of subregions.", "description": "The left panel of the figure shows the number of linear subregions traversed by the AL-RNN model as a function of the number of piecewise linear (PWL) units (P) used in the model.  The theoretical upper limit of 2P is shown in red. The right panel shows the cumulative percentage of data points covered by the linear subregions as the number of PWL units increases.  The figure demonstrates that, even for complex systems, a majority of the data points tend to reside within a relatively small number of linear subregions.", "section": "5 Experimental Results"}, {"figure_path": "sEpSxteEKJ/figures/figures_7_1.jpg", "caption": "Figure 5: a: Color-coded linear subregions of minimal AL-RNNs representing the R\u00f6ssler (top) and Lorenz-63 (bottom) chaotic attractor. b: Illustration of how the AL-RNN creates the chaotic dynamics. For the R\u00f6ssler, trajectories diverge from an unstable spiral point (true position in gray, learned position in black) into the second subregion, where after about half a cycle they are propelled back into the first. For the Lorenz-63, two unstable spiral points (true: gray; learned: black) create the diverging spiraling dynamics in the two lobes, separated by the saddle node in the center. c: Topological graphs of the symbolic coding. While for the R\u00f6ssler it is fully connected, for the Lorenz-63 the crucial role of the center saddle region in distributing trajectories onto the two lobes is apparent. d: Geometrical divergence (Dstsp) among repeated trainings of AL-RNNs (n = 20), separately evaluated within each subregion, shows close agreement among different training runs. Likewise, low e: normalized distances between fixed point locations and f: relative differences in maximum absolute eigenvalues omax across 20 trained models indicate that these topologically minimal representations are robustly identified.", "description": "This figure shows the topologically minimal piecewise linear (PWL) representations discovered by the AL-RNN for the R\u00f6ssler and Lorenz systems. Panel (a) displays the color-coded linear subregions of the minimal AL-RNNs. Panel (b) illustrates how the AL-RNN generates chaotic dynamics in these systems. Panel (c) presents the topological graphs of the symbolic coding for both systems. Panels (d)-(f) show the robustness of these minimal representations across multiple training runs, demonstrating their topological consistency.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_8_1.jpg", "caption": "Figure 6: Geometrically minimal reconstruction and graph representation of the R\u00f6ssler attractor (M = 30, P = 10, Dstsp = 0.08, DH = 0.06). a: Provided a sufficient number of linear subregions, the geometry of the attractor is almost perfectly captured. b: Reconstruction with linear subregions color-coded by frequency of visits (dark: most frequently visited regions, yellow: least frequent regions). c: Corresponding geometrical graph, which contains information about transition frequencies via node distances, visualized using the spectral layout in networkx. Note that self-connections were omitted in this representation. d: Connectome of relative transition frequencies between subregions.", "description": "This figure shows the geometrically minimal reconstruction of the R\u00f6ssler attractor using an AL-RNN with 10 piecewise linear units.  Panel (a) displays the attractor, color-coded by the frequency of visits to each subregion. Panel (b) shows a graph representation of the attractor, where nodes represent subregions and edges represent transitions between them. The thickness of the edges reflects the frequency of transitions. Panel (c) is a connectome, visualizing the relative transition frequencies between subregions.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_8_2.jpg", "caption": "Figure 7: a: Freely generated ECG activity using an AL-RNN with 3 linear subregions (color-coded according to subregion) and ground truth time series in black. b: After activation of the Q wave in the third subregion, the second PWL unit is driven far below 0, whose activity, consistent with the known physiology [89], mimics the latent de- and re-polarization process of the interventricular septum. c: Symbolic graph representation of the trained AL-RNN.", "description": "This figure shows the results of applying an AL-RNN model to generate ECG data. Panel (a) compares the generated ECG signal (colored lines) with the real ECG data (black line). The model accurately captures the main characteristics of the ECG signal, such as the QRS complex and T wave. Panel (b) illustrates the model's ability to capture the underlying physiological processes. The strong dip in the second PWL unit after the Q wave is consistent with the known physiological mechanism of depolarization and repolarization of the interventricular septum. Panel (c) provides a visual representation of the model as a graph where each node represents a linear subregion and edges represent transitions between subregions.", "section": "5.4 Topologically minimal reconstructions of real-world systems"}, {"figure_path": "sEpSxteEKJ/figures/figures_9_1.jpg", "caption": "Figure 8: Reconstructions from human fMRI data using an AL-RNN with M = 100 total units and P = 2 PWL units. a: Mean generated BOLD activity color-coded according to the linear subregion. Background color shadings indicate the task stage. b: Generated activity (trajectory points) in the latent space of PWL units with color-coding indicating task stage as in a.", "description": "This figure shows the results of applying an AL-RNN to fMRI data.  Panel (a) displays the mean generated BOLD activity, with colors representing different linear subregions discovered by the AL-RNN. The background shading indicates the task stage (Rest and Instruction, CRT, CDRT, CMT). Panel (b) shows the generated activity in the latent space of the piecewise linear (PWL) units, again with colors representing the task stage. This visualization demonstrates the AL-RNN's ability to capture the relationship between task phase and the underlying dynamics of the fMRI data.", "section": "5.4 Topologically minimal reconstructions of real-world systems"}, {"figure_path": "sEpSxteEKJ/figures/figures_22_1.jpg", "caption": "Figure 9: Top: DSR quality (assessed by Dstsp) as a function of strength of regularization on the number of nonlinearities for the AL-RNN trained on Lorenz-63. Bottom: Number of selected piecewise-linear units P as a function of regularization strength. As in Fig. 3, a first optimum consistently occurs for P = 2. To select the number of nonlinear units through regularization, we replaced the standard ReLU by a leaky ReLU max(aizi, zi), ai \u2208 (0, 1), for each of the i = 1 . . . M units. The slope ai = \u03c3(i) is determined through a steep sigmoid, \u03c3(\u03b3i) = 1/(1 + exp(-500(i - 0.5))), via trainable parameter \u03b3i, ensuring that it is either close to 0 or close to 1. To encourage linearity, we include a loss term Llin = \u03bblin \u03a3i=1 |ai \u2013 1|, pushing slopes towards 1. After training, units with ai \u2248 1 are classified as linear, while all remaining units were considered nonlinear to provide an estimate for P.", "description": "This figure shows the effect of regularization on the number of piecewise linear units used in the AL-RNN model.  The top panel shows the DSR quality (Dstsp) as a function of the regularization strength (\u03bblin), demonstrating that an optimal performance is achieved with a small number (around 2) of piecewise linear units.  The bottom panel shows the number of selected piecewise linear units (P) as a function of the regularization strength, indicating that regularization effectively selects a minimal number of piecewise linear units for optimal performance. A leaky ReLU activation function was used in this experiment to control the linearity of units.", "section": "5.2 Reconstructed Systems Occupy a Small Number of Subregions"}, {"figure_path": "sEpSxteEKJ/figures/figures_23_1.jpg", "caption": "Figure 10: Reconstruction performance on Lorenz-63 system for an AL-RNN (M = 20) as a function of the number of linear units, once for the case where the number of PWL units was insufficient for a topologically accurate reconstruction (P = 1, top), and once for the case where it was sufficient (P = 2, bottom). Results indicate performance cannot be improved by adding more linear units if P is too small, but can be \u2013 up to some saturation level \u2013 when P is sufficiently large. Error bars = SEM.", "description": "This figure examines the effect of varying the number of linear units in an AL-RNN model on its ability to reconstruct the Lorenz-63 system.  It shows that the performance (measured by Dstsp and DH) plateaus or slightly decreases beyond a certain number of linear units when the number of piecewise-linear units (PWL) is insufficient to capture the system's topology (P=1).  However, when a sufficient number of PWL units is used (P=2), increasing linear units improves reconstruction up to a saturation point, demonstrating the importance of both linear and PWL units in the model's architecture and their interplay in achieving good reconstruction performance.", "section": "5.2 Reconstructed Systems Occupy a Small Number of Subregions"}, {"figure_path": "sEpSxteEKJ/figures/figures_23_2.jpg", "caption": "Figure 6: Geometrically minimal reconstruction and graph representation of the R\u00f6ssler attractor (M = 30, P = 10, Dstsp = 0.08, DH = 0.06). a: Provided a sufficient number of linear subregions, the geometry of the attractor is almost perfectly captured. b: Reconstruction with linear subregions color-coded by frequency of visits (dark: most frequently visited regions, yellow: least frequent regions). c: Corresponding geometrical graph, which contains information about transition frequencies via node distances, visualized using the spectral layout in networkx. Note that self-connections were omitted in this representation. d: Connectome of relative transition frequencies between subregions.", "description": "This figure shows that with enough linear subregions, the AL-RNN can accurately reconstruct the geometry of the R\u00f6ssler attractor.  Panel (a) displays the attractor with subregions color-coded by visitation frequency. Panel (b) shows the geometrical graph representation of this reconstruction.  Finally, panel (c) and (d) provide a connectome representation and matrix showing the relative transition frequencies between subregions.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_23_3.jpg", "caption": "Figure 12: \"Linearized\" dynamics (i.e., considering the linear map from each subregion) within the three linear subregions of the AL-RNN trained on the ECG data from Fig. 7. The first two subregions host weakly unstable spirals with shifted phase, corresponding to the excitatory/ inhibitory phases of the ECG. The strongly divergent activity in the third subregion induces the Q wave.", "description": "This figure shows the \"linearized\" dynamics within the three linear subregions of the AL-RNN trained on ECG data.  The first two subregions show weakly unstable spirals with phase shifts representing the excitatory and inhibitory phases of the ECG. The third subregion displays strongly divergent activity that triggers the Q wave.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_24_1.jpg", "caption": "Figure 13: Freely generated ECG activity using an AL-RNN with 3 linear subregions (color-coded) shows consistent assignment of the Q wave to a distinct subregion across multiple successful reconstructions.", "description": "This figure shows four examples of freely generated ECG activity using an AL-RNN with three linear subregions. Each subregion is color-coded differently, and the Q wave is consistently assigned to the same subregion across the different reconstructions. This demonstrates the robustness of the AL-RNN model in capturing the critical transition initiated by the Q wave.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_24_2.jpg", "caption": "Figure 13: Freely generated ECG activity using an AL-RNN with 3 linear subregions (color-coded) shows consistent assignment of the Q wave to a distinct subregion across multiple successful reconstructions.", "description": "This figure shows the results of using an Almost-Linear Recurrent Neural Network (AL-RNN) to generate ECG activity. The AL-RNN uses three linear subregions, each represented by a different color.  The Q wave, a significant feature of ECG signals, is consistently assigned to a specific subregion across multiple successful model runs.  This consistency demonstrates the robustness and reliability of the AL-RNN in capturing essential features of the ECG signal.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_25_1.jpg", "caption": "Figure 15: Freely generated fMRI activity using an AL-RNN with M = 100 total units and P = 3 PWL units. a: Mean generated activity color-coded according to linear subregions, with background shading highlighting the most frequently visited subregion. b: Geometrical graph representation of connections between linear subregions, with edge weights representing relative transition frequencies (self-connections omitted). c: Time series of the symbolic coding of dynamics according to linear subregions. d: Dynamics in the two most frequently visited linear subregions in the subspace of the three PWL units, with the boundary between subregions in gray. The dark blue trajectory bit in the first subregion moves towards a virtual stable fixed point located near the center of the saddle spiral in the second subregion. The yellow trajectory illustrates an orbit cycling away from this spiral point and eventually crossing into the first subregion. From there, trajectories are pulled back into the second subregion through the virtual stable fixed point located close to the saddle spiral (see also activity with background shading in a). This dynamical behavior is similar to the one observed in the chaotic benchmark systems, where locally divergent activity of the AL-RNN is propelled back into the center of an unstable manifold within another subregion.", "description": "This figure shows the results of applying the AL-RNN model to fMRI data.  Panel (a) displays the generated fMRI activity, color-coded by the linear subregions identified by the model.  Panel (b) provides a graphical representation of the transitions between these subregions. Panel (c) shows the symbolic representation of the dynamics. Panel (d) illustrates the dynamics within the two most frequently visited subregions, highlighting the presence of a virtual stable fixed point and a saddle spiral, characteristic of chaotic systems.  The overall figure demonstrates how the AL-RNN captures the complex dynamics of the fMRI data and represents them using a low-dimensional symbolic encoding.", "section": "5.4 Topologically minimal reconstructions of real-world systems"}, {"figure_path": "sEpSxteEKJ/figures/figures_25_2.jpg", "caption": "Figure 16: Topological entropy computed from symbolic sequences (Figs. 14 & 15) versus \u03bbmax, calculated from corresponding topologically minimal AL-RNNs (Figs. 5 & 7).", "description": "This figure shows a comparison between the topological entropy (calculated from symbolic sequences representing the dynamics of the AL-RNNs) and the maximum Lyapunov exponent (\u03bbmax). The topological entropy quantifies the complexity of the system's dynamics, while the maximum Lyapunov exponent measures the rate of separation of nearby trajectories. The data points correspond to different systems: R\u00f6ssler, Lorenz-63, ECG, and fMRI. The figure suggests that there might be a correlation between the topological entropy and the maximum Lyapunov exponent; systems with higher topological entropy tend to have higher maximum Lyapunov exponents.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_26_1.jpg", "caption": "Figure 17: Generated fMRI activity using an AL-RNN with M = 100 total units and P = 2 PWL units, with the readout unit states replaced by observations every 7 time steps.", "description": "This figure shows a comparison between the ground truth fMRI BOLD signal and the BOLD signal generated by an AL-RNN model.  The AL-RNN used 100 total units with 2 piecewise linear (PWL) units.  To help the AL-RNN learn, the readout unit states were replaced with observations every 7 time steps.  The figure demonstrates the AL-RNN's ability to generate fMRI activity that closely resembles the ground truth data, suggesting its effectiveness in modeling complex brain dynamics.", "section": "5.4 Topologically minimal reconstructions of real-world systems"}, {"figure_path": "sEpSxteEKJ/figures/figures_26_2.jpg", "caption": "Figure 18: a: Weights of the reconstructed AL-RNN. b: Histogram of the absolute weight distributions for the different types of AL-RNN units. On average, weight magnitudes of the PWL units are much higher than those of the other unit types. c: The correlation structure among the weights of the N = 20 readout units (rows in a, top) reflects the correlation structure within the observed time series variables (correlation between both matrices r \u2248 0.76).", "description": "This figure shows the weights of a trained AL-RNN, broken down by unit type (readout, piecewise linear, and linear).  Panel (a) visualizes the weight matrices for each unit type as heatmaps. Panel (b) provides a histogram of the absolute weight magnitudes for all units, highlighting the generally larger magnitude of the piecewise linear units.  Finally, panel (c) demonstrates a high correlation (r \u2248 0.76) between the correlation matrix of the readout unit weights and the correlation matrix of the data itself.", "section": "5.4 Topologically Minimal Reconstructions of Real-World Systems"}, {"figure_path": "sEpSxteEKJ/figures/figures_27_1.jpg", "caption": "Figure 19: Top row: Activity of the PWL units for the topologically minimal representations of the R\u00f6ssler (a) and Lorenz-63 attractor (b) from Fig. 5. Center row: Time histogram of discrete symbols of the symbolic trajectory. Bottom row: Time series of the symbolic trajectory.", "description": "This figure shows the activity of the piecewise linear (PWL) units for the topologically minimal representations of the R\u00f6ssler and Lorenz-63 attractors.  The top row displays the time series of the PWL units' activity. The center row shows the time histogram of the discrete symbols, representing the symbolic trajectory. The bottom row shows the time series of the symbolic trajectory itself.  This visualization helps to understand how the minimal PWL representations capture the dynamics of these chaotic systems and how they relate to the symbolic representations.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_27_2.jpg", "caption": "Figure 10: Reconstruction performance on Lorenz-63 system for an AL-RNN (M = 20) as a function of the number of linear units, once for the case where the number of PWL units was insufficient for a topologically accurate reconstruction (P = 1, top), and once for the case where it was sufficient (P = 2, bottom). Results indicate performance cannot be improved by adding more linear units if P is too small, but can be \u2013 up to some saturation level \u2013 when P is sufficiently large. Error bars = SEM.", "description": "This figure shows the effect of the number of linear units on the performance of the AL-RNN in reconstructing the Lorenz-63 system. The top panels show the results when the number of piecewise-linear (PWL) units is insufficient (P=1), while the bottom panels show the results when the number of PWL units is sufficient (P=2). The results indicate that adding more linear units does not improve performance when the number of PWL units is too small, but it can improve performance up to a certain saturation level when the number of PWL units is sufficient. Error bars represent the standard error of the mean.", "section": "5.2 Reconstructed Systems Occupy a Small Number of Subregions"}, {"figure_path": "sEpSxteEKJ/figures/figures_28_1.jpg", "caption": "Figure 11: Optimal geometric reconstruction of a Lorenz-63 using the AL-RNN with P = 8 PWL units. Left: reconstruction with subregions color-coded by frequency of trajectory visits (dark: most frequently visited regions, yellow: least frequent regions). Center: Resulting geometrical graph structure (using transition probabilities for placing the nodes) visualized using the spectral layout in networkx. Note that self-connections and directedness of edges were omitted in this representation. The resulting graph shadows the layout of the reconstructed system. Right: Connectome of transitions between subregions.", "description": "This figure shows the results of reconstructing the Lorenz-63 attractor using an AL-RNN with 8 piecewise linear (PWL) units. The left panel displays a color-coded representation of the attractor, where color intensity corresponds to the frequency of visits to each subregion. The center panel shows a geometrical graph representation, where nodes represent subregions and edges represent transitions between them, with edge thickness representing transition frequency. The right panel shows a connectome representing the relative transition frequencies between subregions. The figure demonstrates that AL-RNNs capture the topological structure of the attractor with only a small number of PWL units.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_28_2.jpg", "caption": "Figure 3: Quantification of DSR quality in terms of attractor geometry disagreement (Dstsp, top row) and disagreement in temporal structure (DH, bottom row) as a function of the number of ReLUs (P) in the AL-RNN (R\u00f6ssler: M = 20, Lorenz-63: M = 20, ECG: M = 100, fMRI: M = 50). The little humps at P = 3 for the Lorenz-63 indicate that performance may sometimes first degrade again when passing the number of minimally necessary PWL units (see also Fig. 9). Error bars = SEM.", "description": "This figure displays the performance of the AL-RNN model on four datasets (R\u00f6ssler, Lorenz-63, ECG, fMRI) as the number of piecewise linear (PWL) units increases.  The performance metrics used are the Kullback-Leibler divergence (Dstsp) for geometric agreement between the reconstructed and true attractors and the Hellinger distance (DH) for temporal agreement (comparing power spectra).  The graphs show that performance generally improves with more PWL units, particularly for the Lorenz-63, suggesting the importance of a sufficient number of PWL units for accurate representation.  Error bars represent the standard error of the mean.", "section": "5 Experimental Results"}, {"figure_path": "sEpSxteEKJ/figures/figures_28_3.jpg", "caption": "Figure 23: Pairwise differences in sorted (from lowest to highest probability) cumulative trajectory point distributions across linear subregions across all valid pairs from 20 training runs (quantified by the Kolmogorov-Smirnov distance, DKS) for the AL-RNN vs. PLRNN, revealing much higher consistency for AL-RNN. Note the log-scale on the y-axis.", "description": "This figure compares the consistency of the AL-RNN and PLRNN models across multiple training runs. The Kolmogorov-Smirnov (KS) statistic was used to quantify the differences between cumulative trajectory point distributions in different linear subregions. The results demonstrate that AL-RNN exhibits substantially higher consistency across training runs compared to PLRNN.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_29_1.jpg", "caption": "Figure 5: a: Color-coded linear subregions of minimal AL-RNNs representing the R\u00f6ssler (top) and Lorenz-63 (bottom) chaotic attractor. b: Illustration of how the AL-RNN creates the chaotic dynamics. For the R\u00f6ssler, trajectories diverge from an unstable spiral point (true position in gray, learned position in black) into the second subregion, where after about half a cycle they are propelled back into the first. For the Lorenz-63, two unstable spiral points (true: gray; learned: black) create the diverging spiraling dynamics in the two lobes, separated by the saddle node in the center. c: Topological graphs of the symbolic coding. While for the R\u00f6ssler it is fully connected, for the Lorenz-63 it is apparent the crucial role of the center saddle region in distributing trajectories onto the two lobes. d: Geometrical divergence (Dstsp) among repeated trainings of AL-RNNs (n = 20), separately evaluated within each subregion, shows close agreement among different training runs. Likewise, low e: normalized distances between fixed point locations and f: relative differences in maximum absolute eigenvalues \u03c3max across 20 trained models indicate that these topologically minimal representations are robustly identified.", "description": "This figure shows the minimal piecewise linear (PWL) representation of the R\u00f6ssler and Lorenz attractors discovered by AL-RNNs. It illustrates how the AL-RNN captures chaotic dynamics using only a few linear subregions, and the topological and geometrical agreement of this representation with known minimal PWL designs.  The figure also displays the symbolic coding of these dynamics and shows the robustness of this minimal representation across multiple training runs.", "section": "5.3 Minimal PWL Reconstructions of Chaotic attractors"}, {"figure_path": "sEpSxteEKJ/figures/figures_29_2.jpg", "caption": "Figure 25: Top row: Robust placing of linear subregions (color-coded) mapped to observation space across training runs using the AL-RNN. Model recovery experiments further confirmed the robustness of the model solutions, with very similar overall performance measures across different experiments (original: Dstsp = 3.14, DH = 0.28; recovered: Dstsp = 3.38\u00b10.18, DH = 0.28 \u00b1 0.03; 3 linear subregions in all cases). Bottom row: In contrast, for the PLRNN linear subregions are differently assigned (with varying boundaries) on each run.", "description": "The figure shows the robustness of the AL-RNN in assigning linear subregions to the observation space across multiple training runs.  The top row displays AL-RNN results, demonstrating consistent subregion placement. The bottom row contrasts this with PLRNN results, showing inconsistent subregion assignments across runs.", "section": "5.2 Reconstructed Systems Occupy a Small Number of Subregions"}]