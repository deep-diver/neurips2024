[{"figure_path": "QbPHYPZKJI/tables/tables_1_1.jpg", "caption": "Table 1: Feature comparison of generative models on manifolds. We give a \"\" if any method in a category meets this requirement.", "description": "This table compares different generative models on manifolds based on three features: whether they respect the topology of the manifold, whether they allow for single-step sampling, and whether they are applicable to arbitrary manifolds.  The table highlights the advantages of Manifold Free-Form Flows (M-FFF) by showing that it is the only method that satisfies all three criteria.", "section": "Related work"}, {"figure_path": "QbPHYPZKJI/tables/tables_4_1.jpg", "caption": "Table 2: Manifolds, a global embedding and corresponding projections considered in this paper.", "description": "This table lists manifolds used in the paper, their dimensions, their embedding in Euclidean space, and the projection function used to project points from the embedding space onto the manifold.  The embedding and projection are crucial for the method because the model operates in the embedding space and the gradient calculations are performed in the tangent space of the manifold.  The table shows the specific mathematical forms for several common manifolds, providing concrete examples for the general framework.", "section": "3.2 Riemannian manifolds"}, {"figure_path": "QbPHYPZKJI/tables/tables_7_1.jpg", "caption": "Table 3: Test negative log-likelihood (NLL, \u2193) on SO(3) for multi-step and single-step methods. M-FFF consistently outperforms the specialized normalizing flow by Liu et al. [2023] on synthetic distributions of SO(3) matrices, and outperforms multi-step methods in the cases with more mixture components. Multi-step baseline values are due to De Bortoli et al. [2022].", "description": "This table compares the performance of Manifold Free-Form Flows (M-FFF) against other methods (both single-step and multi-step) for learning distributions on the special orthogonal group SO(3).  The comparison is done using the test negative log-likelihood (NLL), a lower NLL indicating better performance. The results show that M-FFF consistently outperforms a specialized normalizing flow method and often outperforms multi-step methods, particularly when dealing with a higher number of mixture components in the synthetic data.", "section": "Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_7_2.jpg", "caption": "Table 4: M-FFF significantly outperforms the previous single-step density estimator [Peel et al., 2001] on the sphere on real-world earth datasets in terms of negative log-likelihood (lower is better). Baseline values are collected from De Bortoli et al. [2022], Huang et al. [2022], Chen and Lipman [2024].", "description": "This table compares the performance of Manifold Free-Form Flows (M-FFF) against several other generative models on real-world datasets representing data points on a sphere (S2).  The datasets are related to Earth science phenomena, such as volcanic eruptions, earthquakes, floods, and wildfires. The table shows the negative log-likelihood (NLL) achieved by each method. Lower NLL indicates better performance.  The \"Fast inference?\" column indicates whether the method is computationally efficient at inference time. The results indicate that M-FFF either matches or outperforms other single-step methods and often outperforms multi-step methods in terms of NLL, while also being significantly faster.", "section": "Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_8_1.jpg", "caption": "Table 5: M-FFF consistently outperforms normalizing flows specialized to tori [Rezende et al., 2020] on torus datasets, without requiring the development of a specialized architecture. In addition, our method comes close to the performance of the multi-step methods and even outperforms them on the Glycine dataset. Baseline values are due to Huang et al. [2022], Chen and Lipman [2024].", "description": "This table compares the performance of Manifold Free-Form Flows (M-FFF) against other methods for learning distributions on tori.  It shows negative log-likelihood (NLL) scores for several datasets, demonstrating that M-FFF either matches or outperforms the previous state-of-the-art single-step and multi-step methods, especially on the Glycine dataset.", "section": "Torsion angles of molecules on tori"}, {"figure_path": "QbPHYPZKJI/tables/tables_8_2.jpg", "caption": "Table 6: Test NLL on Stanford bunny data proposed by [Chen and Lipman, 2024], living on a manifold with nontrivial curvature (see Fig. 1). M-FFF outperforms the multi-step model for datasets with more modes.", "description": "This table compares the performance of M-FFF against Riemannian Flow Matching models (with diffusion and biharmonic) on a Stanford bunny dataset.  The dataset represents a manifold with non-trivial curvature. The results show negative log-likelihood (NLL) values for different numbers of modes (k) in the dataset.  M-FFF achieves comparable or better performance than the multi-step methods, particularly for datasets with more modes.", "section": "5 Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_22_1.jpg", "caption": "Table 7: Wasserstein-2 distances for all 2-dimensional manifolds.", "description": "This table presents the Wasserstein-2 distances, a metric measuring the distance between two probability distributions, for various 2-dimensional manifolds.  The manifolds include real-world geographical data (Volcano, Earthquakes, Flood, Fire) and data from structural biology (General, Glycine, Proline, Pre-Pro). Results are also given for the Stanford Bunny dataset, at different numbers of modes (k=10, k=50, k=100).  The values represent the average Wasserstein-2 distance and its standard deviation, calculated from multiple experimental runs.", "section": "5 Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_22_2.jpg", "caption": "Table 3: Test negative log-likelihood (NLL, \u2193) on SO(3) for multi-step and single-step methods. M-FFF consistently outperforms the specialized normalizing flow by Liu et al. [2023] on synthetic distributions of SO(3) matrices, and outperforms multi-step methods in the cases with more mixture components. Multi-step baseline values are due to De Bortoli et al. [2022].", "description": "This table compares the performance of Manifold Free-Form Flows (M-FFF) against other methods (both single-step and multi-step) for learning distributions on the special orthogonal group SO(3).  The comparison focuses on negative log-likelihood (NLL), a measure of how well the model fits the data.  The results show that M-FFF consistently outperforms a specialized normalizing flow method and often outperforms multi-step approaches, especially as the number of mixture components in the data increases. The table also highlights the computational efficiency of M-FFF compared to multi-step methods which require many function evaluations.", "section": "5 Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_23_1.jpg", "caption": "Table 4: M-FFF significantly outperforms the previous single-step density estimator [Peel et al., 2001] on the sphere on real-world earth datasets in terms of negative log-likelihood (lower is better). Baseline values are collected from De Bortoli et al. [2022], Huang et al. [2022], Chen and Lipman [2024].", "description": "This table compares the performance of M-FFF against other generative models on four real-world datasets representing earth science data on a sphere. The models are evaluated based on their negative log-likelihood (NLL), a metric where lower values indicate better performance.  M-FFF is shown to outperform a previous single-step method, and shows mixed results compared to multi-step methods, potentially because the multi-step methods are better suited to data with large empty regions between data clusters.", "section": "Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_23_2.jpg", "caption": "Table 11: Hyperparameter choices for the earth data experiments.  \u03b2u and \u03b2p are the same for both the sample and latent space.", "description": "This table lists the hyperparameter values used for the earth data experiments in the paper.  It includes choices for network architecture (layer type, residual blocks, inner depth, inner width, activation function), regularization parameters (\u03b2R, \u03b2U, \u03b2P), latent distribution, optimizer, learning rate, scheduler, gradient clipping, weight decay, batch size, step count, and number of repetitions.  Note that \u03b2u and \u03b2p (regularization parameters) had the same values for both sample and latent spaces.", "section": "5 Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_24_1.jpg", "caption": "Table 12: Details on the torus datasets. Each dataset is randomly split into a train dataset (80%), validation dataset (10%) and test dataset (10%). During training, we add Gaussian noise with mean zero and standard deviation given by 'noise strength' to the data, to counteract overfitting.", "description": "This table presents details about the datasets used in the experiments on the torus manifolds.  It shows the number of instances (data points) in each dataset, and the amount of Gaussian noise added to the data during training to prevent overfitting. The datasets are split into training, validation, and test sets (80%, 10%, 10%, respectively).", "section": "5 Experiments"}, {"figure_path": "QbPHYPZKJI/tables/tables_24_2.jpg", "caption": "Table 1: Feature comparison of generative models on manifolds. We give a \"\" if any method in a category meets this requirement.", "description": "This table compares different generative models on manifolds based on three key features: whether they respect the topology of the manifold, if they perform single-step sampling, and if they can handle arbitrary manifolds.  The table shows that the proposed method (M-FFF) is unique in satisfying all three criteria, unlike existing approaches which may only meet one or two.", "section": "Related work"}, {"figure_path": "QbPHYPZKJI/tables/tables_26_1.jpg", "caption": "Table 1: Feature comparison of generative models on manifolds. We give a \"\\\" if any method in a category meets this requirement.", "description": "This table compares different generative models based on their ability to respect the topology of the manifold, whether they perform single-step sampling, and their applicability to arbitrary manifolds.  It highlights the advantages of the proposed Manifold Free-Form Flows (M-FFF) method by showing that it satisfies all three criteria, unlike other existing methods.", "section": "2 Related work"}, {"figure_path": "QbPHYPZKJI/tables/tables_27_1.jpg", "caption": "Table 8: The reconstruction losses LR show that the reconstructed points lie close to the original data. This justifies evaluating M-FFF via negative log-likelihoods.", "description": "This table displays the reconstruction loss for each experiment performed in the paper.  The reconstruction loss measures how close the model's generated points are to the original data points. Low reconstruction loss indicates that the model accurately reconstructs the data and thus, supports the use of negative log-likelihoods (NLL) for model evaluation.", "section": "5 Experiments"}]