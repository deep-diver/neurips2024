[{"figure_path": "f63DKIpx0I/tables/tables_2_1.jpg", "caption": "Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper.", "description": "This table summarizes the four components of self-healing machine learning: Monitoring, Diagnosis, Adaptation, and Testing.  For each component, it provides the equation number (if applicable), the methodological and experimental contributions, the main practical implications, and links to relevant sections of the paper.  It serves as a quick reference guide to navigate the paper's content.", "section": "3 Self-healing Machine Learning"}, {"figure_path": "f63DKIpx0I/tables/tables_7_1.jpg", "caption": "Table 3: A comparison of the theoretical components, their implementation, and their approximations.", "description": "This table compares the theoretical components of the Self-Healing Machine Learning (SHML) framework with their implementations in the H-LLM algorithm. It shows how each theoretical component (Monitoring, Diagnosis, Adaptation, and Testing) is approximated in practice using specific techniques. The table highlights the use of drift detection algorithms, Large Language Models (LLMs) for diagnosis and adaptation via Monte Carlo sampling, and empirical datasets for testing.", "section": "Experimental viability studies"}, {"figure_path": "f63DKIpx0I/tables/tables_7_2.jpg", "caption": "Table 4: Accuracy of a deployed model f upon an intervention which changes the DGP and corrupts \u03c4 percentage of k columns. Error represents standard deviation. \u2191 is better.", "description": "This table presents the accuracy of a deployed model (f) after an intervention that changes the data generating process (DGP) and corrupts a certain percentage (\u03c4) of columns (k).  The results compare the performance of several methods: no retraining, partially updating, new model training, ensemble method, and H-LLM. The table helps showcase that H-LLM, the proposed self-healing approach, significantly outperforms the other methods, particularly when the corruption level is high.", "section": "Viability study I: Adaptation in the presence of model degradation"}, {"figure_path": "f63DKIpx0I/tables/tables_8_1.jpg", "caption": "Table 5: Accuracy of various methods on different datasets with corrupted columns and varying corruption values. Error represents standard deviations of five runs. \u2191 is better. We simulate concept drift by corrupting the test set as follows: we randomly selected k features and multiplied their values by a corruption factor \u03c4. H-LLM identifies that the test data has been corrupted and perform a relevant transformation to decorrupt the value to its original feature space at test time.", "description": "This table presents the accuracy of different methods (no retraining, partially updating, new model training, ensemble method, and H-LLM) across five datasets (airlines, poker, weather, electricity, and covtype) under two conditions: (1) corrupting 5 columns (k=5) and (2) corrupting 5% of the values (\u03c4=5).  It demonstrates H-LLM's robustness and ability to handle data corruption, consistently outperforming other methods.", "section": "Viability study II: Adaptation across datasets"}, {"figure_path": "f63DKIpx0I/tables/tables_17_1.jpg", "caption": "Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper.", "description": "This table summarizes the four stages of self-healing machine learning: Monitoring, Diagnosis, Adaptation, and Testing.  For each stage, it provides the equation number (if applicable), the methodological and experimental contributions, and the main practical implications,  along with links to relevant sections of the paper, serving as a guide for the reader.", "section": "3 Self-healing Machine Learning"}, {"figure_path": "f63DKIpx0I/tables/tables_17_2.jpg", "caption": "Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper.", "description": "This table summarizes the four key components of self-healing machine learning (SHML): Monitoring, Diagnosis, Adaptation, and Testing.  For each component, it provides the equation number from the paper where the component is defined, the methodological and experimental contributions related to that component, the main practical implications of that component, and links to relevant sections within the paper. It acts as a guide for navigating through the various sections of the paper that deal with each component.", "section": "3 Self-healing Machine Learning"}, {"figure_path": "f63DKIpx0I/tables/tables_20_1.jpg", "caption": "Table 3: A comparison of the theoretical components, their implementation, and their approximations.", "description": "This table compares the theoretical components of the Self-healing Machine Learning (SHML) framework with their practical implementations in the H-LLM algorithm.  It shows how each component (monitoring, diagnosis, adaptation, testing) is conceptually defined and then approximated in the H-LLM system using large language models (LLMs). The table highlights the trade-offs and approximations made in translating the theoretical framework into a practical algorithm.", "section": "Experimental viability studies"}, {"figure_path": "f63DKIpx0I/tables/tables_33_1.jpg", "caption": "Table 4: Accuracy of a deployed model f upon an intervention which changes the DGP and corrupts \u03c4 percentage of k columns. Error represents standard deviation. \u2191 is better.", "description": "This table presents the accuracy of a deployed model (f) after an intervention that changes the data generating process (DGP) and introduces corruption in a percentage (\u03c4) of k columns.  The results compare the performance of H-LLM against four other methods (No retraining, Partially Updating, New model training, Ensemble Method) across different levels of corruption (both the number of corrupted columns and the percentage of corrupted values within those columns).  Higher accuracy is indicated by the upward-pointing arrow (\u2191). The table demonstrates H-LLM's superior performance in handling model degradation caused by DGP changes and data corruption.", "section": "Viability study I: Adaptation in the presence of model degradation"}, {"figure_path": "f63DKIpx0I/tables/tables_33_2.jpg", "caption": "Table 4: Accuracy of a deployed model f upon an intervention which changes the DGP and corrupts \u03c4 percentage of k columns. Error represents standard deviation. \u2191 is better.", "description": "This table presents the accuracy results of different model adaptation methods under varying levels of data corruption.  The methods compared include:  No retraining, Partially Updating, New model training, Ensemble Method and the proposed H-LLM.  The accuracy is measured under different numbers of corrupted columns (k) and different corruption percentages (\u03c4).  Higher accuracy is better, indicating superior model adaptation in the face of corruption and distribution shifts.  The results demonstrate H-LLM's superior performance compared to existing methods across various levels of data corruption.", "section": "Viability study I: Adaptation in the presence of model degradation"}, {"figure_path": "f63DKIpx0I/tables/tables_34_1.jpg", "caption": "Table 9: Accuracies of various adaptations on the original diabetes dataset setup in the paper.", "description": "This table compares the accuracies achieved by different model adaptation methods on the diabetes prediction task.  It includes standard adaptation techniques like no retraining, partial updating, new model training, and ensemble methods, along with streaming-specific algorithms (ADWIN Bagging, Hoeffding Tree, Adaptive Voting), and the authors' proposed Self-Healing ML approach.  The results show that while specialized streaming algorithms outperform basic adaptations, they still underperform the Self-Healing ML approach.", "section": "D.5 Extended benchmarks"}, {"figure_path": "f63DKIpx0I/tables/tables_34_2.jpg", "caption": "Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper.", "description": "This table summarizes the four components of self-healing machine learning: monitoring, diagnosis, adaptation, and testing.  For each component, it provides a brief definition, links to the relevant sections of the paper where the component is discussed in detail, and notes on the methodological and experimental contributions associated with that component. It is designed as a navigation guide for readers to locate specific information within the paper.", "section": "3 Self-healing Machine Learning"}, {"figure_path": "f63DKIpx0I/tables/tables_34_3.jpg", "caption": "Table 11: Comparison of various methods across different ML models on the weather dataset (setup above), where features are corrupted at test time. Results show mean accuracy \u00b1 standard deviation.", "description": "This table compares the performance of different model adaptation methods across various machine learning models on a weather dataset. The features were corrupted during the test phase to simulate real-world scenarios. The table shows that the self-healing machine learning (SHML) approach consistently outperforms other methods, demonstrating its robustness and adaptability across different models and corruption levels.", "section": "D.7 Model agnosticism"}]