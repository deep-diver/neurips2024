[{"type": "text", "text": "Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Paulius Rauba University of Cambridge pr501@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Nabeel Seedat University of Cambridge ns741@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Krzysztof Kacprzyk University of Cambridge kk751@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Mihaela van der Schaar University of Cambridge mv472@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Real-world machine learning systems often encounter model performance degradation due to distributional shifts in the underlying data generating process (DGP). Existing approaches to addressing shifts, such as concept drift adaptation, are limited by their reason-agnostic nature. By choosing from a pre-defined set of actions, such methods implicitly assume that the causes of model degradation are irrelevant to what actions should be taken, limiting their ability to select appropriate adaptations. In this paper, we propose an alternative paradigm to overcome these limitations, called self-healing machine learning (SHML). Contrary to previous approaches, SHML autonomously diagnoses the reason for degradation and proposes diagnosis-based corrective actions. We formalize SHML as an optimization problem over a space of adaptation actions to minimize the expected risk under the shifted DGP. We introduce a theoretical framework for self-healing systems and build an agentic self-healing solution $\\mathcal{H}$ -LLM which uses large language models to perform self-diagnosis by reasoning about the structure underlying the DGP, and self-adaptation by proposing and evaluating corrective actions. Empirically, we analyze different components of $\\mathcal{H}$ -LLM to understand why and when it works, demonstrating the potential of self-healing ML. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Consider the following scenario: You are tasked with monitoring the performance of a black-box model $f$ deployed in production. After some time, you notice that the predictive performance of $f$ has started to degrade. What would be the appropriate action $a$ you should take to ensure that the model\u2019s performance returns to its prior performance levels: $a_{1}$ : re-train the model on a subset of the data; $a_{2}$ : change the type of the model used; $a_{3}$ : remove discovered corrupted values; $a_{4}$ : add new covariates? ", "page_idx": 0}, {"type": "text", "text": "Clearly, the answer to this question is \u201cit depends\u201d. Different actions might result in different behavior of the model over time, as illustrated in Fig. 1. If we could pinpoint degraded, it could help us understand what actions are m action which would directly address the root cause of the ", "page_idx": 0}, {"type": "image", "img_path": "f63DKIpx0I/tmp/880b198ba8266b688094115d7c20afc8f03d30a647fdec4034b3896bac2167dc.jpg", "img_caption": ["Figure 1: Different adaptation strategies $a_{1},\\dots,a_{4}$ might result in different performance after an environment change. ", "why the performance of the model has ost promising, since we could select an problem. "], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "While we take this intuition for granted, state-of-the-art techniques for handling model degradation do not reflect this line of reasoning and rely on pre-determined actions, such as model retraining [1\u20135], re-using old models [1, 6\u20138], or other specialized methods [6, 7, 9\u201312]. Such approaches share a common, implicit assumption \u2014the reason for the degradation in model performance is irrelevant. We refer to this as reason-agnostic methods. ", "page_idx": 1}, {"type": "text", "text": "The practical implications of methods being reason-agnostic are quite concerning. By not considering the causes for drop in performance, the corrective actions are, essentially, shots in the dark. In high-stakes applications like healthcare, finance, or policing, misguided adaptations can lead to real-world harms, such as inaccurate diagnoses, financial losses, or system failures. In some industries\u2014such as healthcare\u2014 this has resulted ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "image", "img_path": "f63DKIpx0I/tmp/e274a42c332bc87a625249a2b4cfa8a66e7d7c3c3e28fd6810a8d68af65c9ce7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 2: Our work introduces self-healing machine learning. A healing mechanism $\\mathcal{H}$ interacts with a deployed model $f$ . $\\mathcal{H}$ contains four components: monitoring, diagnosis, adaptation, and testing. The overall goal of SHML is to find optimal adaptation actions to maximize the predictive performance of a model $f$ . ", "page_idx": 1}, {"type": "text", "text": "in avoiding automated model retraining altogether [13]. ", "page_idx": 1}, {"type": "text", "text": "We propose self-healing machine learning (SHML) to overcome the limitations of reason-agnostic approaches. SHML equips ML models with the ability to diagnose the reasons for performance degradation and take targeted corrective actions. We define a self-healing system as a tuple $\\langle\\mathcal{H},f\\rangle$ , where $f$ is a black-box model and $\\mathcal{H}$ is a healing mechanism that can modulate the behavior of $f$ . An example of $\\mathcal{H}$ modulating $f$ is by deciding what data to use to re-train $f$ , as illustrated in our introductory example. $\\mathcal{H}$ contains four components: monitoring, diagnosis, adaptation, and testing (Fig. 2). The goal of $\\mathcal{H}$ is to decide what actions to take in response to model degradation which are chosen based on an adaptation policy that provides a mapping from diagnoses to actions. We therefore formalize the goal of $\\mathcal{H}$ as finding optimal actions under the shifted data generating process (DGP) which are sampled from an adaptation policy conditioned on a diagnosis (Sec. 3.3). In our introductory example, the optimal action is taking action $a_{1}$ (Fig. 1). Building upon these insights, we propose the first self-healing ML algorithm, $\\mathcal{H}$ -LLM (Sec. 5) which generates diagnoses behind model degradation and suggests diagnosis-based adaptation strategies. ", "page_idx": 1}, {"type": "text", "text": "Significance beyond technical contributions. By enabling systems to autonomously diagnose and adapt to model degradation, we lay the groundwork for a new class of self-healing algorithms. We envision self-healing systems as crucial for high-stakes applications where optimal model performance is essential. We also believe this work has immediate practical relevance in high-stakes areas where model degradation is common, such as medicine [13\u201318], fraud detection [19] or finance [20]. ", "page_idx": 1}, {"type": "text", "text": "Contributions. $\\Phi$ We identify fundamental limitations in existing reason-agnostic adaptation approaches that do not consider the reason for model degradation (Sec. 3.2). $\\circledast$ We introduce the paradigm of self-healing machine learning and establish a theoretical foundation for finding adaptation actions with diagnosis-guided action sampling (Sec. 3.3 - 4). $\\textcircled{3}$ We propose the first self-healing ML algorithm $\\mathcal{H}$ -LLM which reasons about the causes of degradation and modulates the behavior of ML models (Sec. 5). $\\textsuperscript{\\textregistered}$ We demonstrate the viability of SHML by studying why and when it works (Sec. 6). ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "SHML is most closely related to concept drift adaptation or specialized drift handling methods. We provide an extended discussion on related work within each component in Appendix A. ", "page_idx": 1}, {"type": "text", "text": "Concept drift adaptation. The field of concept drift adaptation focuses on developing algorithms to maintain the performance of machine learning models in changing environments. Such algorithms are predominantly proposed within the setting of tabular data. Most common adaptation techniques are re-training models on new data [1\u20135, 21\u201324], re-using stored models [1, 6\u20139] or obtaining new data altogether [25, 26]. These approaches can be implicit, like continuous retraining, or explicit, based on drift detection in data or model error [5, 23, 27]. Because these approaches do not explicitly incorporate the reason for model degradation, we refer to them as reason agnostic. SHML diverges from common approaches by introducing the core idea of diagnosing the root cause to search for optimal adaptation actions. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Specialized drift handling. Techniques have also been developed to adapt in the presence of various drift scenarios, such as sliding windows [10] or adaptive classifiers [11, 28\u201332] which \u201crepair\u201d concept drift [27]. However, these methods lack an explicit diagnosis mechanism and operate under fixed decision rules, which do not incorporate the root causes of degradation into the adaptation strategy. Similarly, works that aim to understand distribution shifts [33\u201335] or attribute shifts to specific variables through causal mechanisms [36, 37] provide valuable insights but do not offer a comprehensive framework for adaptation. We note that some work could be in principle a part of some SHML system components (discussed in Appendix A). ", "page_idx": 2}, {"type": "text", "text": "3 Self-healing Machine Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "This section introduces self-healing machine learning and its four components. We present the problem setting (Sec. 3.1), explain current limitations (Sec. 3.2), and outline the four stages of SHML (Sec. 3.3). NOTE: Table 1 serves as a guide for navigating the paper. ", "page_idx": 2}, {"type": "table", "img_path": "f63DKIpx0I/tmp/60b104d369da83a1cad9ee9fc497c4e0fde8c2033322de019df1109a83f2255f.jpg", "table_caption": [], "table_footnote": ["Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper. "], "page_idx": 2}, {"type": "text", "text": "3.1 Model degradation over time ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Preliminaries. Let $\\mathcal{X}$ and $\\boldsymbol{\\mathscr{y}}$ denote the input and output spaces, respectively, and let $\\mathcal{P}_{t}$ denote the data distribution over $\\mathcal X\\times\\mathcal Y$ at time step $t\\,\\in\\,[T]$ . At each $t$ , we observe a batch of data $\\mathcal{D}_{t}=\\{(\\mathbf{x}_{t}^{(i)},y_{t}^{(i)})\\}_{i=1}^{n_{t}}\\sim\\mathcal{P}_{t}^{n_{t}}$ , where $n_{t}=1$ in the streaming setting and $n_{t}>1$ in the batch setting. We will drop the superscripts where clear from context. ", "page_idx": 2}, {"type": "text", "text": "The goal is to learn a sequence of functions $\\{f_{t}\\in\\mathcal{F}\\}_{t=1}^{T}$ that minimize the cumulative risk: ", "page_idx": 2}, {"type": "equation", "text": "$$\nR(f_{1},\\ldots,f_{T}):=\\sum_{t=1}^{T}\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t}}[\\ell(f_{t}(\\mathbf{x}),y)]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{F}$ is a function class and $\\ell:\\mathcal{V}\\times\\mathcal{V}\\to\\mathbb{R}_{\\ge0}$ is a loss function. ", "page_idx": 2}, {"type": "text", "text": "In the time-invariant setting where $\\mathcal{P}_{t}=\\mathcal{P}\\;\\forall t\\in[T].$ , the goal reduces to learning a single function $f^{\\ast}\\in\\mathfrak{s}$ $\\mathcal{F}$ that minimizes the risk $R(f)=\\mathbb{E}_{\\mathcal{P}}[\\ell(f(\\mathbf{x}),\\bar{y})]$ . When $\\mathcal{P}$ is unknown, $f^{*}$ is often approximated by minimizing the empirical risk on a training set $\\{(\\mathbf{x}^{(i)},y^{(i)})\\}_{i=1}^{n}\\,\\sim\\,\\mathcal{P}^{n}$ . However, when $\\mathcal{P}_{t}$ evolves over time, the optimal predictor $f_{t}^{*}\\;\\in\\;\\arg\\operatorname*{min}_{f\\in\\mathcal{F}}\\mathbb{E}_{\\mathcal{P}_{t}}[\\ell(f(\\mathbf{x}),y)]$ changes across time steps1. Failing to adapt $f_{t}$ in this time-varying setting leads to model degradation, as the learned function becomes increasingly suboptimal w.r.t. the current data distribution. ", "page_idx": 2}, {"type": "text", "text": "3.2 Limitations of existing approaches in adapting to changing environments ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Maintaining stable model performance in the presence of a changing environment poses unique challenges. As the optimal predictor $f_{t}^{*}$ evolves over time, the estimated predictor should also adapt. Iridseka lolyv,e rw teh icso duladt aosebtt.a iHn oa wlaervgeer , btahtics hi so fo fdtaetna $\\mathbf{\\mathcal{D}}_{t+1}=\\big\\{\\big(\\mathbf{x}_{t+1}^{(i)},y_{t+1}^{(i)}\\big)\\big\\}_{i=1}^{n_{t+1}}$ inatnsd  sumcinh iamsi (zie)  tghreo eunmdp-itrriuctahl labels not being immediately available [38]; (ii) the streaming setting, where each new batch contains only one data point [39]; (iii) gradual shifts, where past data remains relevant [40]; or (iv) the presence of corrupted data in new batches [41]. ", "page_idx": 2}, {"type": "text", "text": "To address this, the research community has developed specialized methods determining the appropriate corrective actions in such drifts. As discussed in Sec. 2, these methods primarily execute pre-defined actions upon detecting a change, such as model retraining [1\u20135], re-using old models [1, 6\u20138], or other more specialized methods [6, 7, 9\u201312]. However, such methods are reason-agnostic, disregarding valuable information that inform better adaptation actions. Consider an illustrative example: suppose a batch of new data arrives, but due to a sensor malfunction [42], $80\\%$ of the labels become corrupted and are independent of the input for that batch only. Naively retraining the model on this noisy batch would degrade its performance. This is because this strategy implicitly assumes: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t+1}}\\big[\\ell\\big(f_{t+1}(\\mathbf{x}),y\\big)\\big]<\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t+1}}\\big[\\ell\\big(f_{t}(\\mathbf{x}),y\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $f_{t+1}$ is a model trained on $\\mathcal{D}_{t+1}$ . Relying on this assumption results in worse performance than doing nothing. Similarly, re-using old models assumes that the past data distribution is still relevant: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t+1}}\\big[\\ell\\big(f_{t-k}(\\mathbf{x}),y\\big)\\big]<\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t+1}}\\big[\\ell\\big(f_{t}(\\mathbf{x}),y\\big)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for some $k>0$ . Similarly, this might result in suboptimal performance due to the nature of the shift.   \nEach adaptation method discussed in Sec. 2 has such implicit assumptions about the model or DGP. ", "page_idx": 3}, {"type": "text", "text": "By not taking into account the reason for the model degradation (such as corrupted data), the adaptation strategy is defaulting to suboptimal corrective actions. While any adaptation strategy inherently involves some assumptions about the relationship between the predictor and the data, we would like to prioritize making informed assumptions. As we discuss in Sec. 3.3, a key source of such information is diagnosing why the model\u2019s performance has dropped. ", "page_idx": 3}, {"type": "text", "text": "To address the reason-agnostic nature of such adaptation methods, we propose a paradigm shift called self-healing machine learning (SHML), where deployed models autonomously diagnose the reason for degradation and take diagnosis-guided corrective actions. ", "page_idx": 3}, {"type": "text", "text": "Takeaway. Existing adaptation methods make implicit, pre-defined assumptions about the nature of model degradation. Neglecting its reason can lead to poorly chosen actions. ", "page_idx": 3}, {"type": "text", "text": "3.3 The four stages of self-healing machine learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Self-healing machine learning is a framework for autonomously detecting, diagnosing, and correcting performance degradation in deployed ML models. It aims to maintain model performance in changing environments without constant human intervention. The motto of self-healing ML is \u201cunderstanding your problem is half the solution\u201d (and the most important half). A SHML system is defined by a tuple $\\left\\langle\\mathcal{H},f\\right\\rangle$ , where $f:\\mathcal X\\to\\mathcal Y$ is the deployed machine learning model we aim to heal (i.e., the function that makes predictions on input data), and $\\mathcal{H}$ is a healing mechanism that interacts with the environment and acts upon the model $f$ by proposing and implementing actions, such as selecting when to retrain a model, what data to use or how to change the input data before making predictions. Thus, $\\mathcal{H}$ can modulate the behavior of the deployed model $f$ . ", "page_idx": 3}, {"type": "text", "text": "Self-Healing Machine Learning in a nutshell. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Self-healing ML contains four components: monitoring, diagnosis, adaptation, and testing. After these steps, the best action is implemented on the ML model, illustrated in Fig. 2. ", "page_idx": 3}, {"type": "text", "text": "I. Monitoring. The first step is the detection of degradation, potentially due to a shift in the data distribution. We formalize this as a monitoring component $\\mathcal{H}_{M}$ that takes as input the sequence of data batches $\\{\\mathcal{D}_{i}\\}_{i=1}^{t}$ , up to time $t$ , and outputs $s_{t}\\in[0,1]$ , indicating the likelihood of model degradation. Formally, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{H}_{M}:(\\mathcal{X}\\times\\mathcal{Y})^{*}\\to[0,1],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where higher values of $s_{t}$ indicate a greater likelihood of a shift. ", "page_idx": 3}, {"type": "text", "text": "$\\mathbf{II}$ . Diagnosis. The diagnosis component $\\mathcal{H}_{D}$ detects the reason of degradation. It takes data batches $\\{\\mathcal{D}_{i}\\}_{i=1}^{t}$ , up to time $t$ , along with any available contextual information $c\\in{\\mathcal{C}}$ (e.g. background knowledge), and outputs a distribution $\\zeta\\in\\Delta(\\mathcal{Z})$ over a space of possible reasons $\\mathcal{Z}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{H}_{D}:\\left(\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{C}\\right)^{*}\\to\\Delta(\\mathcal{Z}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "$\\mathcal{Z}$ represents the finite space of possible reasons of the shift and $\\zeta$ is a stochastic vector. ", "page_idx": 3}, {"type": "text", "text": "III. Adaptation. The adaptation component is a policy $\\pi$ that outputs a distribution over actions. Given a diagnosis vector $\\zeta$ , actions $a\\in\\mathcal{A}$ are selected from a finite space $\\mathcal{A}$ by: ", "page_idx": 3}, {"type": "text", "text": "Each action $a$ modifies $f$ . We denote the model used at time $t$ , selected by action $^{a}$ , as $f_{a}^{t}$ . ", "page_idx": 4}, {"type": "text", "text": "IV. Testing. The testing component $\\mathcal{H}_{T}$ evaluates each action $a\\in\\mathcal A$ on a relevant distribution and outputs a performance measure: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{H}_{T}:\\mathcal{A}\\times\\mathcal{P}\\rightarrow\\mathbb{R}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Objective. The goal of self-healing ML is to select the optimal action $a^{*}$ that minimizes the expected loss $\\mathbb{E}[\\ell(f_{t}^{a}(\\mathbf{x}),y)]$ on the data distribution $\\mathcal{P}_{t}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\na^{*}=\\underset{a\\in\\mathcal{A}}{\\arg\\operatorname*{min}}\\,\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{P}_{t}}\\big[\\ell\\big(f_{t}^{a}(\\mathbf{x}),y\\big)\\big],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\ell:\\mathcal{V}\\times\\mathcal{V}\\to\\mathbb{R}_{\\ge0}$ is a loss function, and $f_{t}^{a}$ denotes the model selected by action $a$ to be used at time $t$ . The action $\\footnote{T w o t y p i c a l a p p l i c a t i o n s c e n a r i o s f o r t h e p r o p o s e d s y s t e m a r e h e a l t h c a r e,a n d l o g i s t i c s a n d w a r e h o u s i n g,i n w h i c h m u l t i p l e I o T d e v i c e s a r e d e p l o y e d c l o s e t o t h e r e c e i v e r a n d t h e t i m e d e l a y b e t w e e n t h e d i r e c t l i n k a n d b a c k s c a t t e r l i n k i s t h u s n e g l i g i b l e.}$ is selected according to the adaptation policy $\\pi(\\cdot|\\zeta)$ , which maps the diagnosis vector $\\zeta$ (a distribution over possible reasons for degradation) to a distribution over actions. ", "page_idx": 4}, {"type": "text", "text": "Suppose the following motivating example to guide the notation above. ", "page_idx": 4}, {"type": "text", "text": "Illustrative example. Consider a deployed ML model $f_{t}$ for predicting diabetes. The monitoring component $\\mathcal{H}_{M}$ detects a significant drop in performance, with $s_{t}\\,=\\,0.95$ (Eq. 4). The diagnosis component $\\mathcal{H}_{D}$ outputs three most likely reasons $z_{1},z_{2},z_{3}\\;\\in\\;\\mathcal{Z}$ , with $\\zeta(z_{1})=0.95$ for data quality issues, $\\zeta(z_{2})=0.03$ for concept drift, and $\\zeta(z_{3})\\,=\\,0.02$ for model overfitting (Eq. 5). Based on, $\\zeta$ , the adaptation policy $\\pi$ samples two actions $a_{1},a_{2}\\sim\\pi(\\cdot|\\zeta)$ (Eq. 6): $a_{1}$ : remove detected biologically implausible values (e.g. $\\mathrm{Age}\\,>\\,200\\mathrm{\\Omega},$ ) and retrain $f_{t};\\ a_{2}$ : include interaction terms between features to capture non-linearities. The testing component $\\mathcal{H}_{T}$ evaluates the adapted models $f_{t}^{a_{1}}$ and $f_{t}^{a_{2}}$ on new incoming data (Eq. 7) and selects $a_{1}$ due to lower estimated loss. ", "page_idx": 4}, {"type": "text", "text": "The primary insight of SHML is that the action $a\\sim\\pi(\\cdot|\\zeta)$ should be based on the diagnosis $\\zeta$ , which is a distribution over possible reasons $z\\in{\\mathcal{Z}}$ for model degradation. In contrast, standard approaches (Sec. 3.2) assume that $\\pi\\,\\perp\\!\\!\\!\\perp\\,\\zeta$ . SHML formalizes this as an optimization problem over a space of adaptation actions\u2014we aim to find the optimal actions to take each time the model $f$ degrades, with these actions chosen by the policy $\\pi$ of the self-healing system $\\mathcal{H}$ (Fig. 3). Different policies $\\pi_{1}$ and $\\pi_{2}$ might propose different actions in response to the same performance drop. While the diagnosis $\\zeta$ informs the policy, we do not assume it is necessarily useful. Since $\\zeta\\in\\Delta(\\mathcal{Z})$ is a probability distribution, it can encode no knowledge by being uniform over the diagnosis space: $\\begin{array}{r}{\\zeta(\\bar{z})=\\frac{1}{|\\mathcal{Z}|},\\breve{\\forall z}\\in\\mathcal{Z}}\\end{array}$ . These components and their interactions between two time points $t$ and $t+1$ are shown in Fig. 3. ", "page_idx": 4}, {"type": "image", "img_path": "f63DKIpx0I/tmp/79adcb6ee8e0ecb5b786c559548b4f9e6b5a57832d024354326bd07398156045.jpg", "img_caption": ["Figure 3: The self-healing mechanism $\\mathcal{H}$ modulates the function $f$ via four stages. The chosen adaptation action $a$ is implemented onto the function $f$ at the next time step. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "The effectiveness of the adaptation actions depends on the diagnosis, i.e. how well can we identify the root cause. Therefore, we turn to the diagnosis component next. ", "page_idx": 4}, {"type": "text", "text": "Takeaway. SHML is a framework which selects actions based on the reason for model degradation. It contains four stages: monitoring, diagnosis, adaptation, and testing. ", "page_idx": 4}, {"type": "text", "text": "4 An analysis of the properties of self-healing diagnosis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Self-healing systems have the unique property of having a diagnosis stage. But what constitutes a good diagnosis? In this section, we analyze the properties of self-healing diagnosis and establish its connection to the performance of adaptation actions. ", "page_idx": 4}, {"type": "text", "text": "To effectively use diagnosis information to guide the search for adaptation actions, we require a way to quantify the usefulness of a diagnosis. We propose three desirable properties for such a measure: (i) concentration: it should favor diagnoses that provide more information, i.e. assign higher probabilities to fewer possible reasons; (ii) sensitivity: it should be sensitive to changes in the diagnosis distribution, such that small changes in probabilities would result in small changes in the measure; (iii) maximum uncertainty: it should reach its maximum value when the diagnosis distribution is uniform, indicating no knowledge about the reason for degradation. Therefore, we propose using the entropy of the diagnosis vector as a useful proxy for quality which satisfies all three properties. Because entropy measures uncertainty, we refer to this as the certainty of the diagnosis. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Definition 1 (Certainty of the Diagnosis). Let $\\mathcal{Z}$ be the finite space of possible reasons for degradation and $\\Delta(\\mathcal{Z})$ be the diagnosis space. The certainty of a diagnosis $\\zeta\\in\\Delta(\\mathcal{Z})$ in a self-healing machine learning system is measured by its entropy $\\mathbb{H}(\\zeta)$ , defined as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{H}(\\zeta)=-\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\log\\zeta(z),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\zeta(z)$ is the probability of reason $z$ under the distribution $\\zeta$ . ", "page_idx": 5}, {"type": "text", "text": "The link between diagnosis quality and adaptation performance highlights the importance of obtaining informative diagnoses in SHML. Building upon these concepts, we define the optimal diagnosis: ", "page_idx": 5}, {"type": "text", "text": "Definition 2 (Optimal Diagnosis). The optimal diagnosis $\\zeta^{*}$ is defined as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\zeta^{*}=\\arg\\operatorname*{min}_{\\zeta\\in\\Delta(\\mathcal{Z})}\\mathbb{E}_{a\\sim\\pi(\\cdot|\\zeta)}[R(a)]\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\Delta(\\mathcal{Z})$ is the diagnosis space, $\\pi(\\cdot|\\zeta)$ is the conditional distribution over actions induced by diagnosis vector $\\zeta$ , and $R(a)$ denotes the risk of $f_{t}^{a}$ associated with action $a\\in\\mathcal{A}$ . ", "page_idx": 5}, {"type": "text", "text": "This formalizes the intuition that the best diagnosis is the one that leads to the best adaptation actions, on average. To characterize the properties of this optimal diagnosis, we introduce an assumption about the structure of the adaptation policy: ", "page_idx": 5}, {"type": "text", "text": "Assumption 1 (Independent actions). We assume that $\\pi(\\cdot|\\zeta)$ has a hierarchical structure. First, a reason $z\\in\\mathcal{Z}$ is sampled according to the diagnosis $\\zeta\\colon z\\sim\\zeta$ . Then, an action is sampled conditioned on this reason, $a\\sim\\bar{\\pi}(\\cdot|z^{\\dagger})$ , where $z^{\\dag}\\in\\Delta(\\mathcal{Z})$ such that $z^{\\dag}(z)=1$ . $\\pi(\\cdot|\\zeta)$ can then be described as the following mixture. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pi(a|\\zeta)=\\sum_{z\\in\\mathcal{Z}}\\pi(a|z^{\\dag})\\zeta(z)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\zeta$ are the mixture weights and $\\{\\pi(\\cdot|z^{\\dagger})\\mid z\\in\\mathcal{Z}\\}$ are the mixture components. ", "page_idx": 5}, {"type": "text", "text": "Under this hierarchical structure, we can prove a useful property of the optimal diagnosis: ", "page_idx": 5}, {"type": "text", "text": "Proposition 1. Under Assumption $^{\\,l}$ , the optimal diagnosis $\\zeta^{*}$ has a zero entropy, i.e., $\\mathbb{H}(\\zeta^{*})=0$ . ", "page_idx": 5}, {"type": "text", "text": "Proof in Appendix E. To ensure that the optimal diagnosis is well-defined, we also prove its existence under mild assumptions: ", "page_idx": 5}, {"type": "text", "text": "Proposition 2 (Existence of Optimal Diagnosis). Suppose that the action space $\\boldsymbol{\\mathcal{A}}$ is a compact subspace of $\\mathbb{R}^{n}$ and $R$ is continuous. Then there exists at least one optimal diagnosis $\\zeta^{*}$ . ", "page_idx": 5}, {"type": "text", "text": "Proof. The expected risk $\\mathbb{E}_{a\\sim\\pi(\\cdot|\\zeta)}[R(a)]$ is a continuous function of $\\zeta$ by the continuity of $R$ and the compactness of $\\boldsymbol{\\mathcal{A}}$ . Since the diagnosis space $\\Delta(\\mathcal{Z})$ is also compact (being a probability simplex), the extreme value theorem guarantees the existence of a minimizer $\\zeta^{*}$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Takeaway. The existence of an optimal diagnosis establishes a foundation for designing algorithms that can accurately approximate it in practice. By identifying the underlying reasons for performance degradation, a high-quality diagnosis enables a self-healing system to take the most effective adaptation actions. ", "page_idx": 5}, {"type": "text", "text": "5 Building self-healing systems: $\\mathcal{H}$ -LLM ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "This section outlines the challenges of building SHML systems (Sec. 5.1), describes how LLMs can address these challenges (Sec. 5.2), and introduces the first self-healing system, $\\mathcal{H}$ -LLM (Sec. 5.3). ", "page_idx": 5}, {"type": "text", "text": "5.1 Unique challenges of building self-healing systems ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Implementing SHML systems (Sec. 3.3) poses unique challenges in diagnosis and adaptation. ", "page_idx": 5}, {"type": "text", "text": "Challenges in diagnosis. Discovering the reasons for model degradation poses significant practical challenges because: (i) the space of possible reasons $\\mathcal{Z}$ is often poorly defined or intractable to ", "page_idx": 5}, {"type": "text", "text": "Table 2: Example diagnoses suggested by $\\mathcal{H}$ -LLM. The system proposes diagnoses and suggests evidence for the diagnosis. A post-hoc relative confidence score, constructed using the \u201cevidence\u201d column, helps to guide which diagnoses to pay most attention to while designing adaptation policies. ", "page_idx": 6}, {"type": "text", "text": "specify exhaustively in real-world scenarios; and (ii) assigning well-calibrated probabilities to reasons for model degradation is difficult due to both the epistemic and aleatoric uncertainty that exists in real-world environments. This makes it difficult to approximate the optimal diagnosis (Def. 2). ", "page_idx": 6}, {"type": "text", "text": "Challenges in adaptation. The adaptation policy $\\pi$ (Eq. 6) requires selecting optimal adaptation actions $a$ based on the diagnosis $\\zeta$ . This is challenging because (i) it requires reasoning about how actions interact with diagnoses; and (ii) the space of adaptation actions may be extremely large in practice, making it difficult to find the optimal action (Eq. 8). ", "page_idx": 6}, {"type": "text", "text": "5.2 Language models to empower self-healing ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We posit that LLMs have the potential to satisfy many of the required properties of self-healing components because of the following capabilities: (i) Hypothesis proposers. LLMs are known to be \u201cphenomenal hypotheses proposers\u201d [43] which are required to hypothesizing diagnoses of ML model performance degradation; (ii) Contextual understanding. LLMs have been pretrained with a vast corpus of information and hence have extensive prior knowledge around different contexts and settings [44, 45]; (iii) Language model agents. Language models can work as agents within a larger system [46, 47] which is required to actively interact with a deployed model, trigger and implement changes. We therefore see LLMs as capable proxies for different self-healing components. ", "page_idx": 6}, {"type": "text", "text": "5.3 Design of $\\mathcal{H}$ -LLM ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We instantiate the healing mechanism $\\mathcal{H}$ with an LLM l, using its useful properties (Sec. 5.2) to address the practical challenges of designing SHML systems (Sec. 5.1). ", "page_idx": 6}, {"type": "text", "text": "$\\mathcal{H}$ -LLM in a nutshell. ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "$\\mathcal{H}$ -LLM is the first SHML algorithm that modulates the behavior of $f$ following Fig. 3. ", "page_idx": 6}, {"type": "text", "text": "I. Monitoring. We use statistical drift detection algorithms to monitor model degradation from $k$ previous time points [29, 39, 48]. Diagnosis is triggered if a shift is detected. ", "page_idx": 6}, {"type": "text", "text": "II. Diagnosis. Upon detection, we use a pre-defined prompt template to obtain information about the dataset before and after the diagnosis. The prompt template gives us numerical insights into how the dataset has changed and includes covariate information before and after the shift, together with other numerical details. We denote this prompt as an extractor function $\\mathcal{E}:\\mathcal{D}^{*}\\to\\mathcal{D}_{c}$ to obtain an information vector $\\mathbf{v}$ . Using $\\mathbf{v}$ and a chain-of-thought (CoT) module with self-reflection, $\\mathcal{H}$ -LLM generates $k$ candidate reasons for degradation $\\{\\mathbf{z}_{i}\\}_{i=1}^{k}\\sim{\\cal l}(\\cdot|\\mathbf{v})$ via Monte Carlo (MC) sampling with associated confidence scores. As before, this is obtained by following pre-defined prompt templates conditioned on the obtained information (e.g. \u201cSuggest {self.n} possible reasons why the model might have failed on the basis of the issues presented\u201d). These candidates form an empirical diagnosis vector $\\hat{\\zeta}$ , approximating the optimal diagnosis $\\zeta^{*}$ . Table 2 illustrates diagnoses generated by $\\mathcal{H}$ -LLM. ", "page_idx": 6}, {"type": "text", "text": "III. Adaptation. Conditioned on the empirical diagnosis distribution $\\hat{\\zeta}$ , $\\mathcal{H}$ -LLM generates $^m$ candidate adaptatio\u2217n actions $\\{a_{j}\\}_{j=1}^{m}\\sim l(\\cdot|\\hat{\\zeta})$ via CoT-based MC sampling. This approximates sampling from $\\pi(\\cdot|\\zeta^{*})$ (Def. 6). The actions sampled from $l$ are textual representations, so we use an interpreter function to execute each $^{a}$ on $f$ . ", "page_idx": 6}, {"type": "text", "text": "IV. Testing. The sampled actions are evaluated on an empirical dataset (Def. 7), and the empirically optimal action $\\begin{array}{r}{\\hat{\\boldsymbol{a}}^{*}=\\arg\\operatorname*{min}_{j\\in[m]}R(\\boldsymbol{a})\\quad}\\end{array}$ is implemented. Limited access to the shifted DGP complicates evaluating $R(a)$ , but it can be approximated with empirical data $\\hat{\\mathcal{D}}_{\\mathrm{test}}$ by using a backtesting window, continuously incoming data, or historical data (Appendix B.4). ", "page_idx": 6}, {"type": "text", "text": "Goal. This procedure aims to approximate the optimal action (Def. 8). These actions are orchestrated by an orchestrator component in $\\mathcal{H}$ -LLM which can navigate between these steps. ", "page_idx": 6}, {"type": "table", "img_path": "f63DKIpx0I/tmp/a3a63efaa5edecea6644a9c098a2e1b3a5ed438a4ce2dcf5ecc3a5951f298529.jpg", "table_caption": ["Table 3: A comparison of the theoretical components, their implementation, and their approximations. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "6 Experimental viability studies ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The previous sections constituted the primary contribution of our paper\u2014establishing SHML as a framework. The goal of this section is to provide a viability study by analyzing different components of SHML. We conduct six viability studies.2 ", "page_idx": 7}, {"type": "text", "text": "Experimental setup. We desire to meet two properties: (i) have full control of the DGP to vary experimental parameters; and (ii) we need to benchmark against existing adaptation methods (Sec. 2) which are predominantly tabular-based. Therefore, we simulate a diabetes prediction task [49\u2013 51] based on the setup in Sec. 3.1. We predict diabetes $Y_{t}~\\in~\\{0,1\\}$ at each time point $t$ for a set of n observations, generated according to a (changing) pre-specified DGP log ( PP  ((YYtt==10\u2223\u2223XXtt))) $\\begin{array}{r}{\\alpha_{t}+\\sum_{k\\in K}\\beta_{t,k}X_{t,k}+\\epsilon_{t}}\\end{array}$ , where $K$ includes relevant parameters such as Age or BMI, $\\beta_{t,k}$ are timevarying covariates and $\\epsilon_{t}\\sim\\mathcal{N}(0,\\sigma^{2})$ is a noise component. For evaluating $\\mathcal{H}$ -LLM actions, we use a backtesting window\u2014a representative sample of the shifted distribution obtained after detecting the change but before deploying the adapted model (Sec. B.4). Details provided in Appendix C. ", "page_idx": 7}, {"type": "text", "text": "6.1 Viability study I: Adaptation in the presence of model degradation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Setup. We aim to empirically demonstrate the limitations of existing approaches in adapting to changing environments (Sec. 3.2). We benchmark $\\mathcal{H}$ -LLM against four common drift adaptation methods: (i) new model retraining on post-drift data, (ii) partially updating models with new data; (iii) Ensemble methods by re-using old models, and (iv) No retraining of the models [1]. At time $t$ , we introduce a sudden, single intervention by changing the DGP parameters and corrupting a percentage $\\tau$ of $k$ columns. Table 4 shows the performance of different methods across $\\tau$ and $k$ . ", "page_idx": 7}, {"type": "table", "img_path": "f63DKIpx0I/tmp/2702a47d4543f73bc0de42e1d6f6cd15b99b697cb77ff2d334a89702c057ed82.jpg", "table_caption": [], "table_footnote": ["Table 4: Accuracy of a deployed model $\\overline{{f}}$ upon an intervention which changes the DGP and corrupts $\\tau$ percentage of $k$ columns. Error represents standard deviation. $\\uparrow$ is better. "], "page_idx": 7}, {"type": "text", "text": "Discussion. The performance of $f$ degrades if the corrupted columns are not handled appropriately, such as removing or inputting the corrupted data. Defaulting to standard techniques of adapting to a changed environment results in poor performance. $\\mathcal{H}$ -LLM diagnoses issues by observing that some values have drifted too much from their original values and the DGP has changed. One of the proposed adaptation strategies is to remove samples which were estimated to be corrupted, and re-training the model on the remainder of the data. This results in superior performance. ", "page_idx": 7}, {"type": "text", "text": "Takeaway 1. Diagnosing the root cause of degradation can guide better adaptation actions. ", "page_idx": 7}, {"type": "text", "text": "6.2 Viability study II: Adaptation across datasets ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Setup. We aim to empirically analyze whether SHML can provide beneftis across different datasets. We cover five different datasets: Airlines [52], Poker [53], Weather [54], Electricity [55], Forest Type [56]. We simulate real-world unexpected degradations by assuming lagged labels and corrupting features at test time and evaluating models for different datasets (Table 5). ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Discussion. Ground-truth labels are often not immediately available [38], a core feature of many streaming settings. We evaluate how $\\mathcal{H}$ -LLM compares to existing approaches in such scenarios. Across five datasets with different characteristics, $\\mathcal{H}$ -LLM consistently outperforms traditional adaptation methods by adapting $f_{t}^{a}$ at each time point $t$ . Therefore, SHML\u2019s ability to identify and decorrupt features provides a robust adaptation strategy across varied data distributions and schemas. ", "page_idx": 8}, {"type": "table", "img_path": "f63DKIpx0I/tmp/ff6657d5a1814a73f32eb1ef3f58a022621778f9011c433a821172feecd4ff25.jpg", "table_caption": ["Takeaway 2. Identifying the root cause and restoring features dacn provide consistent beneftis across datasets. "], "table_footnote": ["Table 5: Accuracy of various methods on different datasets with corrupted columns and varying corruption values. Error represents standard deviations of five runs. $\\uparrow$ is better. We simulate concept drift by corrupting the test set as follows: we randomly selected $k$ features and multiplied their values by a corruption factor $\\tau$ . $\\mathcal{H}$ -LLM identifies that the test data has been corrupted and perform a relevant transformation to decorrupt the value to its original feature space at test time. "], "page_idx": 8}, {"type": "text", "text": "6.3 Viability study III: Monitoring ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Setup. We use the same setup as experiment I and vary the drift detection threshold which influences the sensitivity of a detection system to changes in the DGP. Low values mean high sensitivity, and high values mean low sensitivity [57]. We measure average recovery time for $\\mathcal{H}$ -LLM to return recover from degradation and post-intervention accuracy, $\\mathcal{H}$ -LLMs average performance after intervention. Fig. 4 shows this relationship. ", "page_idx": 8}, {"type": "text", "text": "Discussion. Intuitively, one might expect earlier drift detection (lower threshold) to consistently yield faster recovery and higher accuracy. In reality, concept drift algorithms often struggle with false positives which can result in worse model performance because of unnecessary re-training [5, 58]. Self-healing ML exhibits greater robustness to these false positives, as any action will be implemented only if it outperforms doing nothing. This contrasts with traditional systems which would automatically trigger the selected action. In Fig. 4, this represents the higher post-intervention accuracy with smaller thresholds. ", "page_idx": 8}, {"type": "image", "img_path": "f63DKIpx0I/tmp/465b887c16ad4f80def6b89af89d54b009a2fcf2ddede19eaa0b658102291e1d.jpg", "img_caption": ["Figure 4: Lower drift detection thresholds can benefit SHML. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Takeaway 3. SHML has greater robustness to implementing poor adaptation actions. ", "page_idx": 8}, {"type": "text", "text": "6.4 Viability study IV: Diagnosis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Setup. We evaluate how well self-healing systems identify the root causes of problems. We corrupt a proportion of observations (corruption coefficient) by multiplying their values by a factor (outlier factor) and see if the $\\mathcal{H}_{\\mathrm{~\\,~}}$ - LLM detects issues related to these factors. We output a probability distribution over diagnoses of which variable is corrupted. Knowing the true corrupted variable, we measure the difference between the distributions using KLDivergence, with lower values indicating closer matches to true corruption. A uniform diagnosis baseline represents random guessing. Fig. 5 shows these differences. ", "page_idx": 8}, {"type": "image", "img_path": "f63DKIpx0I/tmp/f51a58f71c2fab58a48872b5523288198b94360cf87a10860f508748e17eac0f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 5: KL-Divergence between estimated probabilities of which variables are corrupted, and true probabilities, based on outlier factors and corruption coefficients. \u2193is better. ", "page_idx": 8}, {"type": "text", "text": "Discussion. As the outlier factor and corruption coefficient increase, making data issues more apparent, $\\mathcal{H}$ -LLM assigns higher probabilities to the corrupted variables. Thus, the diagnosis accuracy improves as the problem becomes more evident. ", "page_idx": 8}, {"type": "text", "text": "Takeaway 4. The quality of the diagnosis improves when the issues become more apparent. ", "page_idx": 8}, {"type": "text", "text": "6.5 Viability study V: Adaptation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Setup. We study the sensitivity of SHML adaptation actions by examining how well actions perform based on (i) the number of corrupted values and (ii) the size of the backtesting dataset. Fig. 6 shows this relationship. ", "page_idx": 9}, {"type": "image", "img_path": "f63DKIpx0I/tmp/1aa594427e06abab09420349c9d602cf6f5cdfc65d709ba133fd2d7810720bf0.jpg", "img_caption": ["Figure 6: Model $f$ accuracy for actions with varying corruption range and backtesting window size. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Discussion. As more values are corrupted, adaptation actions become more concentrated and less effective. With a larger backtesting dataset, ", "page_idx": 9}, {"type": "text", "text": "actions are more spread out. This suggests (i) action evaluation is more reliable with non-corrupted data and (ii) larger backtesting windows help in selecting better adaptations. ", "page_idx": 9}, {"type": "text", "text": "Takeaway 5. A large test dataset and high-quality data can improve adaptation action selection. ", "page_idx": 9}, {"type": "text", "text": "6.6 Viability study VI: Testing ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Setup. We study the importance of the testing component (Eq. 7) by evaluating $\\mathcal{H}$ -LLM suggested actions with and without the testing phase (backtesting window) and comparing their accuracies. Fig. 7 shows this relationship. ", "page_idx": 9}, {"type": "text", "text": "Discussion. Having a dataset to evaluate actions significantly improves the self-healing process. We see that better data quality results in more reliable adaptation policies. ", "page_idx": 9}, {"type": "image", "img_path": "f63DKIpx0I/tmp/1daff2ce0a48a0f9fa54d9d08f58a9542ac77caa2aa7a8d2b3cb10ff80c0f7d7.jpg", "img_caption": ["Figure 7: Accuracies of optimal actions with and without testing components "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Takeaway 6. The testing component is important to effectively evaluate the proposed actions. ", "page_idx": 9}, {"type": "text", "text": "6.7 Other studies ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We provide further experiments in Appendix D. Our framework shows strong performance with lower warm-start parameters and increasing benefit as data degradation becomes more severe (Sec. D.4). A component-wise ablation analysis (Sec. D.6) reveals each stage of SHML is essential. Extended benchmarks (Sec. D.5) and model agnostic evaluations (Sec. D.7) demonstrate consistent improvements across different adaptation approaches and ML architectures. ", "page_idx": 9}, {"type": "text", "text": "7 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Algorithms hold significant decision-making power in high-stakes applications, yet little has been done to ensure their optimal performance. This work presents a major leap towards that goal. By enabling systems to autonomously diagnose and adapt to new environments, we aim to create a wave of self-healing systems beneficial to both the ML community and society. Our theoretical framework (Sec. 3.3, 4) builds the foundation for the development of self-healing theory, such as optimal adaptation or diagnosis methods, and our viability study shows the potential beneftis of SHML. Our largest contribution is formalizing this field\u2014we hope to spur new theoretical developments and encourage the adoption of such systems in critical domains like medicine [13\u201318] and finance [20]. ", "page_idx": 9}, {"type": "text", "text": "Limitations. SHML\u2019s success relies on accurate root cause identification and finding effective adaptation policies which could pose challenges in some complex, real-world settings (Sec. 5.1). Furthermore, the prioritization of adaptation strategies is also not trivial. Currently, $\\mathcal{H}$ -LLM primarily looks for subgroup-level issues. We see future work tackling all areas of self-healing ML: finding better diagnosis strategies, improving adaptation selection, and enabling better testing of actions in the presence of changing environments. ", "page_idx": 9}, {"type": "text", "text": "Broader impact. Because SHML could empower many positive technologies, it could also be misused to amplify the impact of more problematic systems, such as surveillance technologies. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We would like to thank the anonymous reviewers, Julianna Piskorz, Katarzyna Kobalczyk, Haris Mackevicius, and Andrew Rashbass for their helpful feedback. PR is supported by GSK, KK is supported by Roche, NS by the Cystic Fibrosis Trust. This work was supported by Microsoft\u2019s Accelerate Foundation Models Academic Research initiative. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, and Guangquan Zhang. Learning under concept drift: A review. IEEE transactions on knowledge and data engineering, 31(12): 2346\u20132363, 2018.   \n[2] Haider Raza, Girijesh Prasad, and Yuhua Li. Adaptive learning with covariate shift-detection for non-stationary environments. In 2014 14th UK Workshop on Computational Intelligence (UKCI), pages 1\u20138. IEEE, 2014.   \n[3] Stephan Rabanser, Stephan G\u00fcnnemann, and Zachary Lipton. Failing loudly: An empirical study of methods for detecting dataset shift. Advances in Neural Information Processing Systems, 32, 2019.   \n[4] Firas Bayram, Bestoun S Ahmed, and Andreas Kassler. From concept drift to model degradation: An overview on performance-aware drift detectors. Knowledge-Based Systems, 245:108632, 2022.   \n[5] Supriya Agrahari and Anil Kumar Singh. Concept drift detection in data stream mining: A literature review. Journal of King Saud University-Computer and Information Sciences, 34(10): 9523\u20139540, 2022.   \n[6] Paulo Mauricio Gon\u00e7alves Jr and Roberto Souto Maior De Barros. Rcd: A recurring concept drift framework. Pattern Recognition Letters, 34(9):1018\u20131025, 2013.   \n[7] Cesare Alippi, Giacomo Boracchi, and Manuel Roveri. Just-in-time classifiers for recurrent concepts. IEEE transactions on neural networks and learning systems, 24(4):620\u2013634, 2013.   \n[8] Stephen H Bach and Marcus A Maloof. Paired learners for concept drift. In 2008 Eighth IEEE International Conference on Data Mining, pages 23\u201332. IEEE, 2008.   \n[9] Joao Gama and Petr Kosina. Recurrent concepts in data streams classification. Knowledge and Information Systems, 40:489\u2013507, 2014.   \n[10] Gerhard Widmer and Miroslav Kubat. Learning in the presence of concept drift and hidden contexts. Machine learning, 23:69\u2013101, 1996.   \n[11] Geoff Hulten, Laurie Spencer, and Pedro Domingos. Mining time-changing data streams. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 97\u2013106, 2001.   \n[12] Pingfan Wang, Nanlin Jin, Wai Lok Woo, John R Woodward, and Duncan Davies. Noise tolerant drift detection method for data stream mining. Information Sciences, 609:1318\u20131333, 2022.   \n[13] Daniel Vela, Andrew Sharp, Richard Zhang, Trang Nguyen, An Hoang, and Oleg S Pianykh. Temporal quality degradation in ai models. Scientific reports, 12(1):11654, 2022.   \n[14] Zachary Young and Robert Steele. Empirical evaluation of performance degradation of machine learning-based predictive models\u2013a case study in healthcare information systems. International Journal of Information Management Data Insights, 2(1):100070, 2022.   \n[15] George Alexandru Adam, Chun-Hao Kingsley Chang, Benjamin Haibe-Kains, and Anna Goldenberg. Hidden risks of machine learning applied to healthcare: unintended feedback loops between models and future data causing model degradation. In Machine Learning for Healthcare Conference, pages 710\u2013731. PMLR, 2020.   \n[16] Berkman Sahiner, Weijie Chen, Ravi K Samala, and Nicholas Petrick. Data drift in medical machine learning: implications and potential remedies. The British Journal of Radiology, 96 (1150):20220878, 2023.   \n[17] Ayne A Beyene, Tewelle Welemariam, Marie Persson, and Niklas Lavesson. Improved concept drift handling in surgery prediction and other applications. Knowledge and Information Systems, 44:177\u2013196, 2015.   \n[18] Hamish Huggard, Yun Sing Koh, Gillian Dobbie, and Edmond Zhang. Detecting concept drift in medical triage. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1733\u20131736, 2020.   \n[19] Tung-Duong Mai, Kien Hoang, Aitolkyn Baigutanova, Gaukhartas Alina, and Sundong Kim. Customs fraud detection in the presence of concept drift. In 2021 International Conference on Data Mining Workshops (ICDMW), pages 370\u2013379. IEEE, 2021.   \n[20] Indre\u02d9 \u017dliobaite\u02d9, Mykola Pechenizkiy, and Joao Gama. An overview of concept drift applications. Big data analysis: new algorithms for a new society, pages 91\u2013114, 2016.   \n[21] Jo\u00e3o Gama, Indre\u02d9 \u017dliobaite\u02d9, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia. A survey on concept drift adaptation. ACM computing surveys (CSUR), 46(4):1\u201337, 2014.   \n[22] Ralf Klinkenberg and Ingrid Renz. Adaptive information flitering: Learning in the presence of concept drifts. Learning for text categorization, pages 33\u201340, 1998.   \n[23] Joao Gama, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. Learning with drift detection. In Advances in Artificial Intelligence\u2013SBIA 2004: 17th Brazilian Symposium on Artificial Intelligence, Sao Luis, Maranhao, Brazil, September 29-Ocotber 1, 2004. Proceedings 17, pages 286\u2013295. Springer, 2004.   \n[24] Manuel Baena-Garc\u0131a, Jos\u00e9 del Campo-\u00c1vila, Raul Fidalgo, Albert Bifet, Ricard Gavalda, and Rafael Morales-Bueno. Early drift detection method. In Fourth international workshop on knowledge discovery from data streams, volume 6, pages 77\u201386. Citeseer, 2006.   \n[25] Bartosz Krawczyk, Bernhard Pfahringer, and Micha\u0142 Woz\u00b4niak. Combining active learning with concept drift detection for data stream mining. In 2018 IEEE international conference on big data (big data), pages 2239\u20132244. IEEE, 2018.   \n[26] Nicol\u00e1s Astorga, Tennison Liu, Nabeel Seedat, and Mihaela van der Schaar. Partially observable cost-aware active-learning with large language models. In The Thirty-Eighth Annual Conference on Neural Information Processing Systems, 2024.   \n[27] Ben Halstead, Yun Sing Koh, Patricia Riddle, Russel Pears, Mykola Pechenizkiy, Albert Bifet, Gustavo Olivares, and Guy Coulson. Analyzing and repairing concept drift adaptation in data stream classification. Machine Learning, 111(10):3489\u20133523, 2022.   \n[28] Dewan Md Farid, Li Zhang, Alamgir Hossain, Chowdhury Mofizur Rahman, Rebecca Strachan, Graham Sexton, and Keshav Dahal. An adaptive ensemble classifier for mining concept drifting data streams. Expert Systems with Applications, 40(15):5895\u20135906, 2013.   \n[29] Anton Dries and Ulrich R\u00fcckert. Adaptive concept drift detection. Statistical Analysis and Data Mining: The ASA Data Science Journal, 2(5-6):311\u2013327, 2009.   \n[30] Tinofirei Museba, Fulufhelo Nelwamondo, Khmaies Ouahada, and Ayokunle Akinola. Recurrent adaptive classifier ensemble for handling recurring concept drifts. Applied Computational Intelligence and Soft Computing, 2021:1\u201313, 2021.   \n[31] En Yu, Jie Lu, Bin Zhang, and Guangquan Zhang. Online boosting adaptive learning under concept drift for multistream classification. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 16522\u201316530, 2024.   \n[32] En Yu, Yiliao Song, Guangquan Zhang, and Jie Lu. Learn-to-adapt: Concept drift adaptation for hybrid multiple streams. Neurocomputing, 496:121\u2013130, 2022.   \n[33] Jiashuo Liu, Tianyu Wang, Peng Cui, and Hongseok Namkoong. On the need for a language describing distribution shifts: Illustrations on tabular datasets. Advances in Neural Information Processing Systems, 36, 2024.   \n[34] Andr\u00e9s R Masegosa, Ana M Mart\u00ednez, Dar\u00edo Ramos-L\u00f3pez, Helge Langseth, Thomas D Nielsen, and Antonio Salmer\u00f3n. Analyzing concept drift: A case study in the financial sector. Intelligent Data Analysis, 24(3):665\u2013688, 2020.   \n[35] Sean Kulinski and David I Inouye. Towards explaining distribution shifts. In International Conference on Machine Learning, pages 17931\u201317952. PMLR, 2023.   \n[36] Kailash Budhathoki, Dominik Janzing, Patrick Bloebaum, and Hoiyi Ng. Why did the distribution change? In International Conference on Artificial Intelligence and Statistics, pages 1666\u20131674. PMLR, 2021.   \n[37] Haoran Zhang, Harvineet Singh, Marzyeh Ghassemi, and Shalmali Joshi. \" why did the model fail?\": Attributing model performance changes to distribution shifts. arXiv preprint arXiv:2210.10769, 2022.   \n[38] Yiming Xu and Diego Klabjan. Concept drift and covariate shift detection ensemble with lagged labels. In 2021 IEEE International Conference on Big Data (Big Data), pages 1504\u20131513. IEEE, 2021.   \n[39] Heng Wang and Zubin Abraham. Concept drift detection for streaming data. In 2015 international joint conference on neural networks (IJCNN), pages 1\u20139. IEEE, 2015.   \n[40] Geoffrey I Webb, Roy Hyde, Hong Cao, Hai Long Nguyen, and Francois Petitjean. Characterizing concept drift. Data Mining and Knowledge Discovery, 30(4):964\u2013994, 2016.   \n[41] Mauricio A Hern\u00e1ndez and Salvatore J Stolfo. Real-world data is dirty: Data cleansing and the merge/purge problem. Data mining and knowledge discovery, 2:9\u201337, 1998.   \n[42] Tuomo W Pirinen, Jari Yli-Hietanen, P Pertila, and Ari Visa. Detection and compensation of sensor malfunction in time delay based direction of arrival estimation. In 2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 04CH37512), volume 4, pages IV\u2013872. IEEE, 2004.   \n[43] Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, et al. Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement. arXiv preprint arXiv:2310.08559, 2023.   \n[44] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. Nature, pages 1\u20139, 2023.   \n[45] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.   \n[46] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):1\u201326, 2024.   \n[47] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.   \n[48] Paulo M Gon\u00e7alves Jr, Silas GT de Carvalho Santos, Roberto SM Barros, and Davi CL Vieira. A comparative study on concept drift detectors. Expert Systems with Applications, 41(18): 8144\u20138156, 2014.   \n[49] Jack W Smith, James E Everhart, WC Dickson, William C Knowler, and Robert Scott Johannes. Using the adap learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the annual symposium on computer application in medical care, page 261. American Medical Informatics Association, 1988.   \n[50] Aishwarya Mujumdar and Vb Vaidehi. Diabetes prediction using machine learning algorithms. Procedia Computer Science, 165:292\u2013299, 2019.   \n[51] Muhammad Azeem Sarwar, Nasir Kamal, Wajeeha Hamid, and Munam Ali Shah. Prediction of diabetes using machine learning algorithms in healthcare. In 2018 24th international conference on automation and computing (ICAC), pages 1\u20136. IEEE, 2018.   \n[52] Albert Bifet, Geoff Holmes, Bernhard Pfahringer, Philipp Kranen, Hardy Kremer, Timm Jansen, and Thomas Seidl. Moa: Massive online analysis, a framework for stream classification and clustering. In Proceedings of the first workshop on applications of pattern analysis, pages 44\u201350. PMLR, 2010.   \n[53] Robert Cattral and Franz Oppacher. Poker Hand. UCI Machine Learning Repository, 2007. DOI: https://doi.org/10.24432/C5KW38.   \n[54] Ryan Elwell and Robi Polikar. Incremental learning of concept drift in nonstationary environments. IEEE transactions on neural networks, 22(10):1517\u20131531, 2011.   \n[55] Indre Zliobaite. How good is the electricity benchmark for evaluating concept drift adaptation. arXiv preprint arXiv:1301.3524, 2013.   \n[56] Jock Blackard. Covertype. UCI Machine Learning Repository, 1998. DOI: https://doi.org/10.24432/C50K5N.   \n[57] Anjin Liu, Jie Lu, Yiliao Song, Junyu Xuan, and Guangquan Zhang. Concept drift detection delay index. IEEE Transactions on Knowledge and Data Engineering, 35(5):4585\u20134597, 2022.   \n[58] Fabian Hinder, Valerie Vaquet, Johannes Brinkrolf, and Barbara Hammer. On the hardness and necessity of supervised concept drift detection. In ICPRAM, pages 164\u2013175, 2023.   \n[59] Vinicius MA Souza, Denis M dos Reis, Andre G Maletzke, and Gustavo EAPA Batista. Challenges in benchmarking stream learning algorithms with real-world data. Data Mining and Knowledge Discovery, 34(6):1805\u20131858, 2020.   \n[60] Rafael MO Cruz, Robert Sabourin, and George DC Cavalcanti. Dynamic classifier selection: Recent advances and perspectives. Information Fusion, 41:195\u2013216, 2018.   \n[61] Jinpeng Li, Hang Yu, Zhenyu Zhang, Xiangfeng Luo, and Shaorong Xie. Concept drift adaptation by exploiting drift type. ACM Transactions on Knowledge Discovery from Data, 18 (4):1\u201322, 2024.   \n[62] Guang-Bin Huang, Qin-Yu Zhu, and Chee-Kheong Siew. Extreme learning machine: theory and applications. Neurocomputing, 70(1-3):489\u2013501, 2006.   \n[63] Shuliang Xu and Junhong Wang. Dynamic extreme learning machine for data stream classification. Neurocomputing, 238:433\u2013449, 2017.   \n[64] Raia Hadsell, Dushyant Rao, Andrei A Rusu, and Razvan Pascanu. Embracing change: Continual learning in deep neural networks. Trends in cognitive sciences, 24(12):1028\u20131040, 2020.   \n[65] Sebastian Raschka. Model evaluation, model selection, and algorithm selection in machine learning. arXiv preprint arXiv:1811.12808, 2018.   \n[66] Tania Cerquitelli, Stefano Proto, Francesco Ventura, Daniele Apiletti, and Elena Baralis. Automating concept-drift detection by self-evaluating predictive model degradation. arXiv preprint arXiv:1907.08120, 2019.   \n[67] Markus Hittmeir, Andreas Ekelhart, and Rudolf Mayer. On the utility of synthetic data: An empirical evaluation on machine learning tasks. In Proceedings of the 14th International Conference on Availability, Reliability and Security, pages 1\u20136, 2019.   \n[68] Angelos D Keromytis. Characterizing self-healing software systems. 2007.   \n[69] Debanjan Ghosh, Raj Sharman, H Raghav Rao, and Shambhu Upadhyaya. Self-healing systems\u2014survey and synthesis. Decision support systems, 42(4):2164\u20132185, 2007.   \n[70] Harald Psaier and Schahram Dustdar. A survey on self-healing systems: approaches and systems. Computing, 91:43\u201373, 2011.   \n[71] David Garlan and Bradley Schmerl. Model-based adaptation for self-healing systems. In Proceedings of the first workshop on Self-healing systems, pages 27\u201332, 2002.   \n[72] Omid Gheibi, Danny Weyns, and Federico Quin. Applying machine learning in self-adaptive systems: A systematic literature review. ACM Transactions on Autonomous and Adaptive Systems (TAAS), 15(3):1\u201337, 2021.   \n[73] Antonio Torralba and Alexei A Efros. Unbiased look at dataset bias. In CVPR 2011, pages 1521\u20131528. IEEE, 2011.   \n[74] James Jordon, Lukasz Szpruch, Florimond Houssiau, Mirko Bottarelli, Giovanni Cherubin, Carsten Maple, Samuel N Cohen, and Adrian Weller. Synthetic data\u2013what, why and how? arXiv preprint arXiv:2205.03257, 2022.   \n[75] Gianluca Detommaso, Martin Bertran, Riccardo Fogliato, and Aaron Roth. Multicalibration for confidence scoring in llms. arXiv preprint arXiv:2404.04689, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendix: Self-Healing Machine Learning: A framework for autonomous adaptation in real-world environments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A Extended related work 17 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Comparison to other fields . 17   \nA.2 Comparison on a component level . . 18   \nA.3 Unique properties of self-healing machine learning 19 ", "page_idx": 15}, {"type": "text", "text": "B $\\mathcal{H}$ -LLM 20 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Algorithm and details H-LLM . 20   \nB.2 Prompt templates used . . . 21   \nB.2.1 Prompts related to diagnosis . . . 21   \nB.2.2 Prompt templates related to adaptation . . . . . 23   \nB.3 Example outputs of H-LLM . . . . . . . \u00b7\u00b7\u00b7 24   \nB.4 Evaluation strategies of self-healing algorithms . . 27   \nB.5 Computational notes . . 27 ", "page_idx": 15}, {"type": "text", "text": "C Case study design 28 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "C.1 Details on the experimental setup . . . 28   \nC.2 Details on viability studies . . . 28   \nC.2.1 Viability Study I . . . . 28   \nC.2.2 Viability Studies III - VI . . . 30   \nC.3 Other experimental details . . 32 ", "page_idx": 15}, {"type": "text", "text": "D Extended experiments 33 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Monitoring 33   \nD.2 Diagnosis 33   \nD.3 Adaptation experiment . . 34   \nD.4 Effects of Self-Healing across corruption levels . . 34   \nD.5 Extended benchmarks . . . 34   \nD.6 Component-wise Ablation Analysis . . . . . . . . 35   \nD.7 Model agnosticism . . . 35 ", "page_idx": 15}, {"type": "text", "text": "E Optimal diagnosis 36 ", "page_idx": 15}, {"type": "text", "text": "A Extended related work", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we describe and contrast our work with other related areas. ", "page_idx": 16}, {"type": "text", "text": "A.1 Comparison to other fields ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Concept drift adaptation. Concept drift adaptation algorithms, a key component of self- healing ML systems, primarily handle drifts by re-training models on new data [1\u20135] or older, pre-trained stored models [1, 6\u20138]. These approaches can be implicit, like continuous retraining, or explicit, based on drift detection in data or model error [5, 23, 27]. Drift detection methods compare distributions, analyze data sequentially, or use statistical process control [59]. For instance, the DDM algorithm [23] has in-control, warning, and out-of-control states. ", "page_idx": 16}, {"type": "text", "text": "Specialized drift handling. Techniques have been developed for various drift scenarios. For recurring drifts, methods store and reuse historical models [6, 7, 9]. Streaming data is handled by blind approaches, like sliding windows [10] or adaptive decision trees [11], and informed approaches with explicit drift detection [21\u201324]. Resampling can repair adaptation errors [27], while dynamic classifier selection finds the best model for each input [60]. Methods have been proposed for robustness to noise [12], specific drift types [61], and other issues [62, 63]. Recent work explores understanding distribution shifts through latent variable models [34] and other techniques [35]. Some adaptive methods of re-training the model also include adding more hidden layer to a learner upon detection of a drift [62, 63]. Another area of research closely linked within the field is dynamic selection which attempts to find the most suitable classifier conditional on the covariates [60]. ", "page_idx": 16}, {"type": "text", "text": "On \u201crepairing concept drift\u201d. There have been other methods propose that implicitly try to adapt by detecting changes [27]. However, these adaptations are still based on the observed empirical distributions as opposed to observing the reason for degradation. By periodically sampling the accuracy of inactive classifers, the authors identify cases where change was missed or misclassifed. However, this falls under the broader umbrella of trying out many pre-determined actions without directly reasoning about the reason for model degradation. ", "page_idx": 16}, {"type": "text", "text": "Continual learning. One might get the impression that self-healing machine learning might bear close resemblance to continual learning. Continual learning focuses on developing models that learn continuously from a stream of data, acquiring, retaining, and transferring knowledge across tasks over time [64]. This contrasts strongly with self-healing machine learning. Below, we outline seven criteria by which self-healing machine learning and continual learning differ. ", "page_idx": 16}, {"type": "text", "text": "Differences between continual learning and self-healing machine learning. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. Objective. The objectives of the two fields are different. Continual learning aims to learn sequentially from a stream of tasks while mitigating catastrophic forgetting. SHML focuses on autonomously diagnosing and recovering from performance degradation within a single task due to distribution shifts.   \n2. Knowledge retention. A core goal of continual learning is to preserve previously acquired knowledge while learning new tasks. SHML does not explicitly aim to retain prior knowledge or acquire new knowledge, but rather to maintain stable performance on the current task by adapting to the reason for degradation.   \n3. Stability-Plasticity Dilemma. Continual learning grapples with the trade-off between being plastic enough to learn new tasks and stable enough to remember old ones. In contrast, there is no such dilemma within SHML.   \n4. Task expansion. Continual learning seeks to expand the model\u2019s capabilities by increasing the number of tasks it can perform. In contrast, SHML operates on a single well-defined task\u2014ensuring the optimal performance of a model, typically by minimizing empirical risk\u2014 and does not aim to increase the number of tasks. Instead, the focus is on ensuring optimal performance under a single task.   \n5. Adaptation mechanism. The underlying logic or mechanism of adaptation is different. Continual learning typically adapts by modifying model architecture, updating parameters via constrained optimization, using memory replay. In contrast, SHML explicitly adapts by diagnosing the root cause of performance drops and conditioning an adaptation action on the basis of that diagnosis. This explicit mechanism which is conditioned on is not a part of a continual learning system. ", "page_idx": 16}, {"type": "table", "img_path": "f63DKIpx0I/tmp/768cb6cf2302e99017dcc6c0a3b976abc9042393ec45ff70c912aac350983dbe.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "A.2 Comparison on a component level ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Here, we focus on some related work within each sub-component. Table 6 provides key related work within each column. We do not focus separately on adaptation and testing because adaptation is covered above, whereas testing is simply a stage which helps to evaluate proposed actions. ", "page_idx": 17}, {"type": "table", "img_path": "f63DKIpx0I/tmp/0e6b35ff56a66165235397291470134d4d02ba73b804dc11e36c59daf1345656.jpg", "table_caption": [], "table_footnote": ["Table 6: Summary table of self-healing ML. Use this as a guiding source to navigate the paper. Related work defines the most similar available work within each component "], "page_idx": 17}, {"type": "text", "text": "Monitoring. Related work within monitoring largely relates to different statistical techniques for discovering the presence of shifts/drifts or model degradation. We see them as an integral part of SHML. However, they are also actively used by other adaptation methods to trigger adaptation systems. ", "page_idx": 17}, {"type": "text", "text": "Diagnosis. The diagnosis component is a core component of SHML. Two primary works are closely related. The first work, \u201cwhy did the distribution change?\u201d [36], attempts to factorize the change of the joint distribution into conditional distributions of each variable and attribute some changes to one of the marginals. This is achieved by modeling the change and relationship between variables as a causal mechanism. The second work, \u201cwhy did the model fail?\u201d [37] attributes model performance degradation via a causal mechanism. They assume that distribution shifts are induced due to an intervention in the causal mechanism which results in model performance changes, and uses Shapley values to attribute changes to specific distributions. These two methods are fundamentally different from SHML in multiple respects. First and most important, these works do not propose any actions on the basis of these failures or shifts. The primary goal of both works is to understand why a distribution has changed or a model has failed, attributing it to a causal mechanism, instead of adapting the model to perform optimally. Second, the theoretical formalism introduced is substantially different and comes with different properties. Both works operate within the directed acyclic graph (DAG) framework, whereas we operate under a diagnosis component which is defined as a vector over a space of possible reasons. Other key differences relate to the adaptation mechanism, shift assumptions, adaptation assumptions, level of granularity of the diagnosis, level of granularity of the adaptation, or testing. ", "page_idx": 17}, {"type": "text", "text": "Recent work has already started coming out on understanding distribution shifts [35]. It is known that understanding why a distribution shift happens is important for mitigating that shift [35]. Some other people have looked at modeling shifts via latent variable models without relying on access to labels at test time [34]. However, as before, these methods do not share the objective of finding optimal actions for adaptation. ", "page_idx": 17}, {"type": "text", "text": "Self-healing systems outside ML. Self-healing systems have been proposed outside of machine learning [68\u201372]. We view these as inspirations for our work but consider them disparate and separate because none of them touch upon the core problem of machine learning model degradation, and have not been applied in practice. ", "page_idx": 17}, {"type": "text", "text": "A.3 Unique properties of self-healing machine learning ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The core of self-healing machine learning revolves around two primary components: the deployed ML model $f$ and the healing system $\\mathcal{H}$ . Here, we provide additional clarity on these components and their interactions: ", "page_idx": 18}, {"type": "text", "text": "Definition of the Deployed Model $f$ The model $f$ represents the deployed machine learning model that we aim to heal. It is the function that makes predictions on input data and whose performance we\u2019re trying to maintain and improve. In our viability studies, we demonstrate this framework using logistic regression models as $f$ , though the approach generalizes to any predictive model. ", "page_idx": 18}, {"type": "text", "text": "Relationship Between $f$ and $\\pi$ While $f$ is the model making predictions, $\\pi$ is the adaptation policy\u2014a function that determines what actions to take to modify $f$ based on the diagnosed reasons for its performance degradation. The healing system $\\mathcal{H}$ follows policy $\\pi$ to output actions $a$ (such as $a_{1}$ : retrain a model or $a_{2}$ : remove corrupted features) which are then implemented onto $f$ . Therefore, $\\mathcal{H}$ follows policy $\\pi$ which helps to determine optimal actions $a$ that change/modulate the deployed ML model $f$ . ", "page_idx": 18}, {"type": "text", "text": "Practical Implementation In our viability studies with H-LLM, the policy $\\pi$ is instantiated with an LLM (GPT-4) which uses the diagnosed reasons for model failures (also achieved with an LLM) to propose concrete actions. For instance, if $f$ is a diabetes prediction model and $\\pi$ diagnoses that $f$ \u2019s performance has degraded due to concept drift, $\\pi$ might suggest an action to retrain $f$ with more recent data or to adjust feature weights. ", "page_idx": 18}, {"type": "text", "text": "B $\\mathcal{H}$ -LLM ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "This section provides more details on $\\mathcal{H}$ -LLM. ", "page_idx": 19}, {"type": "text", "text": "B.1 Algorithm and details H-LLM ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The algorithm of $\\mathcal{H}$ -LLM is presented in Algorithm 1. ", "page_idx": 19}, {"type": "text", "text": "Extended discussion. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "I. Monitoring. We use statistical drift detection algorithms to monitor model degradation from $k$ previous time points [29, 39, 48]. Diagnosis is triggered if a shift is detected. For our practical implementation, we use the Drift Detection Method, a popular method for binary drift detection classification. ", "page_idx": 19}, {"type": "text", "text": "II. Diagnosis. Upon detection, $\\mathcal{H}$ -LLM uses an extractor function $\\mathcal{E}:\\mathcal{D}^{*}\\to\\mathcal{D}_{c}$ to transform the dataset information into an information vector v. This extractor function is a mapping from the dataset to information about the dataset. It takes information before the shift happened and calculates summary statistics, such as the mean, average, standard deviation, percentiles, etc., within each column, as well as the performance of a deployed model $f$ under various data slices. For instance, this would also involve looping over all variables, binning them into 10 discrete values and calculating the average model performance across each bin. This is done to ensure that the information contained within the information vector are both summary statistics, i.e. how the ", "page_idx": 19}, {"type": "text", "text": "Algorithm 1: H-LLM   \nRequire :f,HM,HD,HA,HT ,\u03c4,m,k   \n$t\\gets1$   \n$t^{*}\\gets\\mathrm{null}$   \nwhile $t\\leq T$ do $s_{t}\\gets\\mathcal{H}_{M}(\\{\\left(\\mathbf{x}_{i},y_{i}\\right)\\}_{i=1}^{t})$ if $s_{t}>\\tau$ and $t^{*}=$ null then $t^{*}\\gets t$ if $t^{*}\\neq$ null and $t-t^{*}>$ Detection Window then $\\begin{array}{l}{t^{\\prime}\\leftarrow t}\\\\ {\\mathbf{v}\\leftarrow\\mathcal{E}((\\mathbf{x},y)\\sim\\mathcal{P}_{t^{*}},c\\in\\mathcal{C})}\\end{array}$ for $i=1$ to $k$ do zi \u223cl(\u22c5\u2223v) \u03b6\u02c6 \u2190{zi}ik=1 for j = 1 to m do aj \u223cl(\u22c5\u2223\u03b6\u02c6) \u02c6a\u2217\u2190arg minj\u2208[m] HT (f aj, D\u02c6[t\u2217,t\u2032]) f \u2190f a\u02c6 t\u2217\u2190null t \u2190t + 1 ", "page_idx": 19}, {"type": "text", "text": "data has changed, as well as specific performance metrics within data slices. The information is used to generate specific diagnoses as to what has happened. We observe, for instance, that summary statistics are extremely helpful if there are any larger deviations from average, as the diagnosis module within $\\mathcal{H}$ -LLM picks up on these clues. This information is provided as textual information to the next step which is the diagnosis phase. ", "page_idx": 19}, {"type": "text", "text": "The information vector is used as a textual representation within the next LLM call to generate concrete hypotheses / diagnoses about the reason for the $f$ failure. This is where additional context $c$ could be added, if available, such as the presence of any particular exogeneous events that could have affected model performance and could guide the diagnosis search. In the future, we envision that the additional context could be acquired by the system itself. This is used in a chain-of-thought module with self-reflection, where $k$ candidates for degradation are generated along with associated scores. We employ different \u201cdiagnosis\u201d modules within $\\mathcal{H}$ -LLM. For instance, there is a specific diagnosis module that only attempts to find which covariates are responsible for degradation. The system level instruction could be as follows: \u201cFind covariates that are responsible for the model degrading\u201d. However, we also supplement this with more broader reasons for degradation, such as \u201cFind and hypothesize reasons that could have resulted in model degradation , given the information provided\u201d. We provide three prompt templates used to hypothesize issues in Section B.2.1. We sample such prompts $m$ times using MC sampling. The chain-of-thought and self-reflection is implemented by calling $\\mathcal{H}$ -LLM multiple times to re-consider the evidence and hypotheses. Table 2 illustrates diagnoses generated by $\\mathcal{H}$ -LLM. ", "page_idx": 19}, {"type": "text", "text": "III. Adaptation. Conditioned on the empirical diagnosis distribution $\\hat{\\zeta}$ , $\\mathcal{H}$ -LLM generates $m$ candidate adaptation actions $\\{a_{j}\\}_{j=1}^{m}\\sim l(\\cdot|\\hat{\\zeta})$ via CoT-based MC sampling. Specifically, we focus on three kinds of adaptation actions. ", "page_idx": 19}, {"type": "text", "text": "\u2022 Generic adaptation actions ", "page_idx": 19}, {"type": "text", "text": "\u2022 Adaptation actions by removing corrupted data \u2022 Adaptation actions by training multiple models for subsets of the data ", "page_idx": 20}, {"type": "text", "text": "This is reflected in three different prompt templates in Appendix B.2.2. ", "page_idx": 20}, {"type": "text", "text": "Generic adaptation actions. The first attempt is to find generic adaptation actions that the diagnosis module suggests on the basis of the identified evidence. These are often quite generic, for instance, \u201cadd new covariates that could control for the seasonality\u201d. In many such cases, within the confines of our experiments, we do not have the ability to resolve the issues on the basis of the proposed solutions. Therefore, we add two more directly actionable adaptation actions that are also attempted by $\\mathcal{H}$ -LLM after the generic adaptation actions have been attempted. ", "page_idx": 20}, {"type": "text", "text": "Adaptation actions by removing corrupted data. Another concrete adaptation action is that we instruct $\\mathcal{H}$ -LLM to hypothesize specific data slices that might have been corrupted. This could be, for instance, biologically implausible values (negative insulin, $\\mathrm{age}>200$ , implausible hba1c levels), mismatches (e.g. height, weight do not match BMI), sudden shifts in the data (ages change from averages of 30 to 60), and other. The adaptation module then proposes which data slices to remove to achieve superior performance. These suggested data slices are then removed and re-trained in the next batch. ", "page_idx": 20}, {"type": "text", "text": "Adaptation actions by training multiple models. The final concrete adaptation action is to propose specific data slices where the model might have drifted within that slice. This is done because instead of global drifts, models sometimes drift locally and require complete re-training of the new dataset. ", "page_idx": 20}, {"type": "text", "text": "Example outputs of such strategies are presented in Appendix B.3. We note, however, that, in reality, there might be many possible adaptation actions, such as re-training the model on combinations of old and historical data, re-using old models, re-using parts of old models, creating custom ensembles, changing models altogether, changing hyperparameters or adding regularization terms, building different models for different samples based on their difficulty, switching between symbolic and predictive ML models in the face of high uncertainty, and many more. Our approach is to introduce only the primary few ways with the hope of extending this in the future. ", "page_idx": 20}, {"type": "text", "text": "As before, because the actions sampled from $l$ are textual representations, we use an interpreter function to execute each $a$ on $f$ . ", "page_idx": 20}, {"type": "text", "text": "IV. Testing. The sampled actions are evaluated on an empirical dataset (Def. 7), and the empirically optimal action $\\begin{array}{r}{\\hat{\\boldsymbol{a}}^{*}=\\arg\\operatorname*{min}_{j\\in[m]}R(\\boldsymbol{a})\\quad}\\end{array}$ is implemented. Limited access to the shifted DGP complicates evaluating $R(a)$ , but it can be approximated with empirical data $\\hat{\\mathcal{D}}_{\\mathrm{test}}$ by using a backtesting window, continuously incoming data, or historical data. In all of our experiments, we use a backtesting window. However, other strategies could be attempted. The different strategies are explained in greater detail in Appendix B.4. ", "page_idx": 20}, {"type": "text", "text": "Goal. This procedure aims to approximate the optimal action (Def. 8). We remark that there might be better adaptation policies that could be suggested on the basis of evidence. Likewise, there might be better diagnosis modules available. We see $\\mathcal{H}$ -LLM as a first attempt to integrate self-healing into ML. ", "page_idx": 20}, {"type": "text", "text": "B.2 Prompt templates used ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The following are some of the primary prompt templates used within $\\mathcal{H}$ -LLM. ", "page_idx": 20}, {"type": "text", "text": "B.2.1 Prompts related to diagnosis ", "text_level": 1, "page_idx": 20}, {"type": "table", "img_path": "f63DKIpx0I/tmp/826b0a95225418b92897c5313c57a3337310af46ad5b834496f4eaf06f6c8c91.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "You know for a fact that the model has degraded. Analyze the covariates and think why. ", "page_idx": 21}, {"type": "text", "text": "Review each existing covariate and provide a hypothesis on whether it might have changed and resulted in the model underperforming . Provide evidence for each hypothesis and the strength of belief for each covariate. ", "page_idx": 21}, {"type": "text", "text": "Format your output as follows: ", "page_idx": 21}, {"type": "text", "text": "Covariate: <covariate >; Hypothesis: ...; Evidence: Strength of belief: ", "page_idx": 21}, {"type": "text", "text": "After reviewing all the covariates , assign a confidence score for each covariate indicating your confidence level that the covariate has issues. Use the following confidence levels: extremely confident , confident , somewhat confident , unsure , completely unsure. Only use \u2019extremely confident \u2019 if you have overwhelming evidence for your decision. Prioritize making more confident beliefs. Avoid being uncertain. Use the available inputs as well as the data to make the best possible decision. Your goal is to be correct while reducing entropy of the probabilities (be confidently correct). ", "page_idx": 21}, {"type": "text", "text": "111111 ", "page_idx": 21}, {"type": "text", "text": "Code Listing 1: Generic diagnosis prompt ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "1111 11 ", "page_idx": 21}, {"type": "text", "text": "Given the following information: Data before the shift: {x_before.describe ()} Data after the shift: {x_after.describe ()} Context: {context}   \n- Model performance across each covariate before the shift: { ", "page_idx": 21}, {"type": "text", "text": "covariate_performance_before } ", "page_idx": 21}, {"type": "text", "text": "- Model performance across each covariate after the shift: { covariate_performance_after } ", "page_idx": 21}, {"type": "text", "text": "You know for a fact that the model has degraded. Analyze the covariates and think why. ", "page_idx": 21}, {"type": "text", "text": "Then , hypothesize {n} possible covariates or combinations of covariates that might have changed and resulted in the model underperforming . Each possibility should be mutually exclusive. For example , [X1] is one possibility , [X2] is another , and [X1 , X2 ] is a third. ", "page_idx": 21}, {"type": "text", "text": "Code Listing 2: Generic diagnosis prompt for searching combinations of covariates responsible for degradation ", "page_idx": 21}, {"type": "text", "text": "Given the following information: ", "page_idx": 21}, {"type": "text", "text": "Data before the shift: {x_before.describe ()} Data after the shift: {x_after.describe ()} Context: {context} ", "page_idx": 21}, {"type": "text", "text": "Initial hypotheses on covariates or combinations of covariates that might have changed and resulted in model underperformance : { covariate_guesses } ", "page_idx": 21}, {"type": "text", "text": "Summarize the provided hypotheses and assign probabilities to each hypothesis such that the total probability sums to $1\\,0\\,0\\,\\%$ . ", "page_idx": 21}, {"type": "text", "text": "Your probabilities should be reflective of the evidence and data. Uniform probabilities (10% each) implies no knowledge. $10\\,0\\,\\%$ probability on one covariate implies certain belief. Prioritize ", "page_idx": 21}, {"type": "text", "text": "making more confident beliefs. Avoid being uncertain. Use the available inputs as well as the data to make the best possible decision. Your goal is to be correct while reducing entropy of the probabilities (be confidently correct). ", "page_idx": 22}, {"type": "text", "text": "Format each hypothesis and its probability as follows: Hypothesis: [<covariate1 >, <covariate2 >, ...]; Probability: probability > ", "page_idx": 22}, {"type": "text", "text": "Code Listing 3: Diagnosis probability prompt ", "page_idx": 22}, {"type": "text", "text": "B.2.2 Prompt templates related to adaptation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Suppose the following hypothesized issues in the dataset: issues} ", "page_idx": 22}, {"type": "text", "text": "Data before the shift: {x_before.describe ()} Data after the shift: {x_after.describe ()} ", "page_idx": 22}, {"type": "text", "text": "Suggest {self.n} possible reasons why the model might have failed on the basis of the issues presented. These reasons should be hypotheses that might have resulted in the degradation of the model if such hypotheses turn out to be true. These hypotheses also have to be likely on the basis of the issues provided. These hypotheses should be specific to the data itself. The goal is to track down specific changes within the data that could have resulted in the model degradation. ", "page_idx": 22}, {"type": "text", "text": "Format your output as follows: ", "page_idx": 22}, {"type": "text", "text": "Hypothesis: <>; Evidence: <> ", "page_idx": 22}, {"type": "text", "text": "Code Listing 4: Generic adaptation prompt ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "f\"\"\" Suppose the following issues in the dataset: {issues} Data before the shift: {x_before.describe ()} Data after the shift: {x_after.describe ()} ", "page_idx": 22}, {"type": "text", "text": "Suggest {self.n} possible subgroups that if removed could result in better performance for the model. The subgroups can be single (e.g. $\\texttt{X}>\\texttt{x}$ ) but could also be multiple combinations (e.g. $\\texttt{X}>\\texttt{x}$ and $\\texttt{Y}<\\texttt{y l}$ ) ", "page_idx": 22}, {"type": "text", "text": "Code Listing 5: Subgroup adaptation prompt ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\"\"\" Suggest solutions based on removing data \"\"\" tas k = f\"\"\" Suppose the following issues in the dataset: {issues} Data before the shift: {x_before.describe ()} Data after the shift: {x_after.describe ()} ", "page_idx": 22}, {"type": "text", "text": "Suggest {self.n} possible subgroups that might need re - training. That is , fitting a separate model on these subgroups might result in superior performance. ", "page_idx": 22}, {"type": "text", "text": "The subgroups can be single (e.g. $\\texttt{X}>\\texttt{x}$ ) but could also be multiple combinations (e.g. $\\texttt{X}>\\texttt{x}$ and $\\texttt{Y}<\\texttt{y l}$ ) ", "page_idx": 22}, {"type": "text", "text": "Code Listing 6: Subgroup retrain prompt ", "page_idx": 22}, {"type": "text", "text": "B.3 Example outputs of H-LLM ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1111 11 ", "page_idx": 23}, {"type": "text", "text": "Covariate: HbA1c; Hypothesis: The distribution of HbA1c has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of HbA1c has slightly increased from 5.699 to 5.730 , and the standard deviation has also increased from 0.492 to 0.505. The model performance across different ranges of HbA1c has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "Covariate: FastingGlucose ; Hypothesis: The distribution of FastingGlucose has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of FastingGlucose has slightly increased from 99.639 to 100.519 , and the standard deviation has slightly decreased from 15.341 to 15.280. The model performance across different ranges of FastingGlucose has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "Covariate: Age; Hypothesis: The distribution of Age has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of Age has slightly increased from 49.721 to 49.900 , and the standard deviation has slightly increased from 12.066 to 12.310. The model performance across different ranges of Age has significantly dropped after the shift; Strength of belief : Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "Covariate: BMI; Hypothesis: The distribution of BMI has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of BMI has slightly decreased from 25.075 to 24.985 , and the standard deviation has slightly decreased from 4.015 to 3.903. The model performance across different ranges of BMI has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "0 Covariate: BloodPressure; Hypothesis: The distribution of BloodPressure has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of BloodPressure has slightly increased from 119.417 to 120.106 , and the standard deviation has increased from 14.177 to 15.205. The model performance across different ranges of BloodPressure has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "12 Covariate: Cholesterol; Hypothesis: The distribution of Cholesterol has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of Cholesterol has slightly decreased from 201.108 to 198.927 , and the standard deviation has slightly increased from 39.557 to 40.269. The model performance across different ranges of Cholesterol has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "14 Covariate: Insulin; Hypothesis: The distribution of Insulin has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of Insulin has slightly increased from 84.667 to 84.925 , and the standard deviation has slightly decreased from 45.090 to 45.057. The model performance across different ranges of Insulin has significantly dropped after the shift; Strength of belief: Extremely Confident ", "page_idx": 23}, {"type": "text", "text": "16 Covariate: PhysicalActivity ; Hypothesis: The distribution of PhysicalActivity has shifted after the shift , which might have resulted in the model underperforming ; Evidence: The mean of ", "page_idx": 23}, {"type": "text", "text": "PhysicalActivity has slightly decreased from 3.080 to 3.020 , and the standard deviation has slightly increased from 0.994 to 1.014. The model performance across different ranges of PhysicalActivity has significantly dropped after the shift; Strength of belief: Extremely Confident. 17 11 11 11 18 19 #### Generated probability outputs based on the above 20 21 # Prompt for getting these hypothesses: 22 23 \"\"\" 24 Your goal is to provide a summary of probabilities on likelihood of each of the covariates resulting in the model failing 25 \"\"\" 26 27 Outputs: 28 29 Hypothesis: [HbA1c ]; Probability: 12.5% 30 Hypothesis: [ FastingGlucose ]; Probability: 12.5% 31 Hypothesis: [Age]; Probability: 12.5% 32 Hypothesis: [BMI]; Probability: 12.5% 33 Hypothesis: [BloodPressure ]; Probability: 12.5% 34 Hypothesis: [Cholesterol ]; Probability: 12.5% 35 Hypothesis: [Insulin ]; Probability: 12.5% 36 Hypothesis: [ PhysicalActivity ]; Probability: 12.5% ", "page_idx": 24}, {"type": "text", "text": "Code Listing 7: Output for guesses which covariates have shifted. This example showcases that when there is little evidence that any specific covariate has shifted more than the others ", "page_idx": 24}, {"type": "text", "text": "Issue: Increase in standard deviation; Evidence: The standard deviation for most of the variables has increased in the new dataset , indicating increased variability in the data; Confidence: 8   \n3 2. Issue: Change in mean values; Evidence: The mean values for most of the variables have changed , which could indicate a shift in the population being studied; Confidence: 7 3. Issue: Change in minimum and maximum values; Evidence: The minimum and maximum values for most of the variables have changed , which could indicate outliers or a change in the range of data; Confidence: 7 Issue: Change in quartile values; Evidence: The $25\\%$ , $50\\,\\%$ , and $75\\%$ quartile values for most of the variables have changed , indicating a change in the distribution of the data; Confidence: 7   \n5. Issue: Negative values for Insulin and PhysicalActivity ; Evidence: The minimum values for Insulin and PhysicalActivity are negative , which is not possible in a real -world scenario and indicates data errors; Confidence: 10 6. Issue: Change in distribution of data; Evidence: The changes in mean , standard deviation , and quartile values suggest a change in the distribution of the data , which could affect the model \u2019s performance; Confidence: 8 Issue: Increase in age range; Evidence: The minimum and maximum age has increased , indicating a broader age range in the new dataset; Confidence: 6   \n9 8. Issue: Decrease in BMI; Evidence: The mean BMI has decreased in the new dataset , which could indicate a change in the health status of the population being studied; Confidence: 6   \n10 9. Issue: Increase in Blood Pressure; Evidence: The mean Blood Pressure has increased in the new dataset , which could indicate change in the health status of the population being studied; Confidence: 6 ", "page_idx": 24}, {"type": "text", "text": "1 10. Issue: Decrease in Cholesterol; Evidence: The mean Cholesterol has decreased in the new dataset , which could indicate a change in the health status of the population being studied; Confidence: 6 1111 11 ", "page_idx": 25}, {"type": "text", "text": "Code Listing 8: Generic issue response which identifies overall issues within the dataset. ", "page_idx": 25}, {"type": "text", "text": "1. Subgroup: Individuals with age $>$ 85; Reason: The maximum age has increased in the new dataset , which could be due to outliers or errors in the data.   \n2. Subgroup: Individuals with age $<$ 12; Reason: The minimum age has decreased in the new dataset , which could be due to outliers or errors in the data.   \n3. Subgroup: Individuals with Insulin $<$ 0; Reason: Negative values for Insulin are not possible in a real -world scenario and indicate data errors.   \n4 Subgroup: Individuals with PhysicalActivity < 0; Reason: Negative values for PhysicalActivity are not possible in a real -world scenario and indicate data errors.   \n5. Subgroup: Individuals with BMI $<$ 12.8; Reason: The minimum BMI has decreased in the new dataset , which could be due to outliers or errors in the data.   \n6. Subgroup: Individuals with BloodPressure < 70.5; Reason: The minimum Blood Pressure has decreased in the new dataset , which could be due to outliers or errors in the data. Subgroup: Individuals with Cholesterol < 66.3; Reason: The minimum Cholesterol has decreased in the new dataset , which could be due to outliers or errors in the data.   \n8. Subgroup: Individuals with FastingGlucose > 154; Reason: The maximum FastingGlucose has increased in the new dataset , which could be due to outliers or errors in the data. Subgroup: Individuals with HbA1c < 4; Reason: The minimum HbA1c has decreased in the new dataset , which could be due to outliers or errors in the data.   \n10. Subgroup: Individuals with BMI $>$ 39.6; Reason: The maximum BMI has increased in the new dataset , which could be due to outliers or errors in the data. ", "page_idx": 25}, {"type": "text", "text": "Code Listing 9: Example response about which subgroups to remove ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "11 11 11 Subgroup: Individuals with age $>$ 85; Reason: The maximum age has increased in the new dataset , indicating a broader age range.   \n2. Subgroup: Individuals with age $<$ 12; Reason: The minimum age has decreased in the new dataset , indicating a broader age range.   \n3. Subgroup: Individuals with BMI $<$ 12.83; Reason: The minimum BMI has decreased in the new dataset , indicating a change in the health status of the population.   \n4 Subgroup: Individuals with BMI > 37.07; Reason: The maximum BMI has increased in the new dataset , indicating a change in the health status of the population.   \n5. Subgroup: Individuals with Blood Pressure $>$ 166.85; Reason: The maximum Blood Pressure has increased in the new dataset , indicating a change in the health status of the population.   \n6 Subgroup: Individuals with Blood Pressure < 70.49; Reason: The minimum Blood Pressure has decreased in the new dataset , indicating a change in the health status of the population. Subgroup: Individuals with Cholesterol < 44.64; Reason: The minimum Cholesterol has decreased in the new dataset , indicating a change in the health status of the population.   \n8. Subgroup: Individuals with Cholesterol > 347.08; Reason: The maximum Cholesterol has increased in the new dataset , indicating a change in the health status of the population. ", "page_idx": 25}, {"type": "text", "text": "B.4 Evaluation strategies of self-healing algorithms ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Self-healing relies on a testing phase, i.e. the ability to test whether the proposed actions perform well on a test dataset. However, given that the distribution has shifted and the historical data no longer represents the new distribution, one might ask: how can we test models on this new distribution? The primary alternative used in our experiments is a backtesting window which we define formally below. ", "page_idx": 26}, {"type": "text", "text": "Definition 3 (Backtesting Window). Let $\\{\\mathcal{P}_{t}\\}_{t\\in\\mathbb{T}}$ be a sequence of probability measures on $\\mathcal X\\times\\mathcal Y$ , and suppose a distributional shift occurs at time $t^{*}\\in\\mathbb{T}$ , i.e., $\\mathcal{P}_{t^{*}}\\neq\\mathcal{P}_{t^{*}-1}$ . Let $t^{\\prime}>t^{*}$ be the time at which the self-healing system detects the shift. The backtesting window is the time interval $[t^{*},t^{\\prime}]$ satisfying the following properties: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\forall t\\in\\left[t^{*},t^{\\prime}\\right]:\\left(\\mathbf{x}_{t},y_{t}\\right)\\sim\\mathcal{P}_{t^{*}},}\\\\ &{\\forall t\\in\\left[t^{*},t^{\\prime}\\right]:\\left(\\mathbf{x}_{t},y_{t}\\right)\\,\\rlap/\\,\\mathcal{P}_{t^{*}-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We notice that the backtesting window is a unique property that arises uppon sudden shifts in the data generating process. Specifically, because we assume only two data generating processes and a transition between them at time point $t$ , then all points $k$ where $k>t$ will be from the new DGP and all points $k<t$ will be from the old DGP. Since a drift detection algorithm requries some time to detect the drift, by the time a drift has been detected, we have some collected data from the new distribution which we call the backtesting window. We can therefore optimize our actions on this specific window of the dataset. ", "page_idx": 26}, {"type": "text", "text": "Clearly, this does not hold when the assumptions about the nature of the shift change. In such a case, we could always use continuously incoming streaming data. Upon the arrival of each new batch, we can test each proposed action and validate it, consistently upgrading and using the actions that perform well on the most recent batch of data. This strategy assumes that the labels are almost immediately available at prediction time. If not, another strategy employed could be to test such actions on the mot recent available data with labels. ", "page_idx": 26}, {"type": "text", "text": "Other approaches could include generating synthetic data to imitate the new shift with labels or using historical data by de-biasing it. However, these are experimental approaches which need further validation. ", "page_idx": 26}, {"type": "text", "text": "B.5 Computational notes ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Computational overhead. SHML methods have larger overhead than reason-agnostic approaches due to the self-healing system (LLM pipeline) identifying model failure reasons. Practically, it takes 20-40 seconds to implement a full pipeline and correct a model upon drift detection. This overhead is negligible for real-world systems given the benefits. Overhead may vary across systems. ", "page_idx": 26}, {"type": "text", "text": "Sample efficiency. No differences exist as failure detection doesn\u2019t depend on sample size, but on self-healing pipeline complexity. ", "page_idx": 26}, {"type": "text", "text": "C Case study design ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Code can be found at: https://github.com/pauliusrauba/Self_Healing_ML or https:// github.com/vanderschaarlab/Self_Healing_ML ", "page_idx": 27}, {"type": "text", "text": "C.1 Details on the experimental setup ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Experimental setup. To evaluate the performance of self-healing systems, we require to manipulate the data generating process (DGP) and ask \u201cwhat-if\u201d questions. Real-world datasets, while valuable, do not offer control over the DGP and come with pre-embedded biases that can implicitly affect detection systems [73]. In contrast, by using synthetic data to control the DGP, we can run controlled in silico experiments and perform viability studies [74]. Furthermore, the overwhelming majority of model adaptation methods are designed for tabular data (refer to Sec. 2 and Sec. A) which includes our benchmarks (see Sec. 6.1). Therefore, we simulate a diabetes prediction task [49\u201351]. We perfectly mimic the introduced setup in Sec. 3.1. Our goal is to predict the presence of diabetes $Y_{t}\\,\\in\\,\\{0,1\\}$ at each time point $t$ for a set of $n$ observations, generated according to a (changing) pre-specified DGP log ( PP  ((YYtt==10\u2223\u2223XXtt))) $\\begin{array}{r}{\\log\\left(\\frac{P\\left(Y_{t}=1\\vert X_{t}\\right)}{P\\left(Y_{t}=0\\vert X_{t}\\right)}\\right)=\\alpha_{t}+\\sum_{k\\in K}\\beta_{t,k}X_{t,k}+\\epsilon_{t}}\\end{array}$ , where $K$ includes relevant covariates such as Age or BMI, $\\beta_{t,k}$ are time-varying covariates and $\\epsilon_{t}\\sim\\mathcal{N}(0,\\sigma^{2})$ is a noise component. ", "page_idx": 27}, {"type": "text", "text": "We generated synthetic data for the diabetes prediction task. Each feature is sampled from a normal distribution with specified parameters: ", "page_idx": 27}, {"type": "text", "text": "\u2022 Hemoglobin A1c (HbA1c) levels are sampled from a normal distribution: HbA1c \u223c $\\mathcal{N}(5.7,0.5^{2})$ .   \n\u2022 Fasting Glucose levels are sampled from a normal distribution: Fasting Glucose \u223c $\\mathcal{N}(10\\bar{0},15^{2})$ .   \n\u2022 Age is sampled from a normal distribution: Age $\\sim\\mathcal{N}(50,12^{2})$ .   \n\u2022 Body Mass Index (BMI) is sampled from a normal distribution: $\\mathrm{BMI}\\sim\\mathcal{N}(25,4^{2})$ .   \n\u2022 Blood Pressure is sampled from a normal distribution: Blood Pressure $\\sim\\mathcal{N}(120,15^{2})$ .   \n\u2022 Cholesterol levels are sampled from a normal distribution: Cholesterol $\\sim\\mathcal{N}(200,40^{2})$ .   \n\u2022 Insulin levels are sampled from a normal distribution: Insulin $\\sim\\mathcal{N}(85,45^{2})$ .   \n\u2022 Physical Activity is sampled from a normal distribution: Physical Activity $\\sim\\mathcal{N}(3,1^{2})$ . ", "page_idx": 27}, {"type": "text", "text": "The observations $X$ are constructed as a matrix where each row is an instance of the generated features. The outcomes are then determined by running the model through a logistic regression and obtaining a binary outcome value. ", "page_idx": 27}, {"type": "text", "text": "C.2 Details on viability studies ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "C.2.1 Viability Study I ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Viability Study I. To simulate covariate shift and introduce data corruption, we follow these steps: ", "page_idx": 27}, {"type": "text", "text": "1. Generate two datasets with different coefficients and noise parameters: \u2022 The first dataset with $\\begin{array}{r l r}{n_{1}}&{{}=}&{100,000}\\end{array}$ samples, coefficients $\\beta_{1}$ = $\\left[0.3,0.0075,-0.01,0.05,0.04,-0.03,-0.02,-0.1\\right]$ , and noise $\\epsilon_{1}\\sim\\mathcal{N}(0,0.2^{2})$ . \u2022 The second dataset with $\\begin{array}{r l r}{n_{2}}&{{}=}&{100,000}\\end{array}$ samples, coefficients $\\beta_{2}\\quad=$ $\\left[-0.3,-0.0075,0.2,-0.05,-0.015,-0.001,0.02,-2\\right]$ , and noise $\\epsilon_{2}\\sim\\mathcal{N}(0,0.2^{2})$ .   \n2. Split the first dataset into training and testing sets, using a 70/30 split.   \n3. Combine the testing set of the first dataset with the entire second dataset to form the complete testing set. The second testing set therefore contains a shift where the transitions between the DGPs happen.   \n4. In addition to the shift in the DGP, we introduce outliers in the second dataset by multiplying selected features by an outlier factor that control. By default, it is set to   \n5. This outlier factor corrupts the number of columns corrupted by $k$ , and corrupts a percentage of values within the column, denoted as $\\tau$ .   \n6. The shift index is determined as the starting point of the second dataset in the combined testing set.   \n7. We measure and report the performance of the model during the second data generating process. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "Summary of parameters: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 $n_{1}=100,000$ : Number of samples in the first dataset.   \n\u2022 $n_{2}=100,000$ : Number of samples in the second dataset.   \n\u2022 $\\beta_{1}=\\left[0.3,0.0075,-0.01,0.05,0.04,-0.03,-0.02,-0.1\\right]$ : Coefficients for the first dataset.   \n\u2022 $\\beta_{2}~=~\\left[-0.3,-0.0075,0.2,-0.05,-0.015,-0.001,\\right.$ 0.02,\u22122]: Coefficients for the second dataset.   \n\u2022 $\\epsilon_{1}\\sim\\mathcal{N}(0,0.2^{2})$ : Noise for the first dataset.   \n\u2022 $\\epsilon_{2}\\sim\\mathcal{N}(0,0.2^{2})$ : Noise for the second dataset.   \n\u2022 Seed for reproducibility: 42.   \n\u2022 Proportion of outliers introduced: $20\\%$ .   \n\u2022 Features corrupted varies. ", "page_idx": 28}, {"type": "text", "text": "Viability Study I. Summary of the benchmarks. Below we describe the key benchmarks. ", "page_idx": 28}, {"type": "text", "text": "Benchmark 1. New model retraining. We use the Drift Detection Method (DDM) to monitor changes in the data distribution and retrain the model when a drift is detected. The procedure includes: ", "page_idx": 28}, {"type": "text", "text": "1. Split the test data into multiple batches.   \n2. Train the model on the initial training dataset.   \n3. For each batch in the test set: \u2022 Predict the outcomes and calculate the accuracy. \u2022 Update the drift detector with the prediction error (1 - accuracy). \u2022 If drift is detected: \u2013 Retrain the model on the most recent batch. ", "page_idx": 28}, {"type": "text", "text": "Benchmark 2. Ensemble method. This algorithm uses an ensemble of models to improve robustness against data shifts. It combines the predictions of multiple models, each trained on different segments of the data. The procedure involves: ", "page_idx": 28}, {"type": "text", "text": "1. Initialize an ensemble with a single model trained on the initial training dataset.   \n2. Split the test data into multiple batches.   \n3. For each batch in the test set: \u2022 Aggregate predictions from all models in the ensemble, weighted by their current accuracies. \u2022 Make final predictions based on the weighted aggregation. \u2022 Calculate the accuracy and update the drift detector with the prediction error. \u2022 If drift is detected: \u2013 Train a new model on the current batch and add it to the ensemble. \u2013 Update the weights of all models based on their accuracies. ", "page_idx": 28}, {"type": "text", "text": "This method maintains a diverse set of models that can adapt to different aspects of the data distribution, enhancing overall performance and stability. ", "page_idx": 28}, {"type": "text", "text": "Benchmark 3. Partial updating. The model is retrained using a sliding window of the most recent data batches. This allows continuous adaptation to recent changes in the data distribution. The steps are: ", "page_idx": 28}, {"type": "text", "text": "1. Split the test data into multiple batches.   \n2. Train the model on the initial training dataset.   \n3. Maintain a buffer to store the most recent batches.   \n4. For each batch in the test set: \u2022 Predict the outcomes and calculate the accuracy. \u2022 Update the buffer with the current batch. \u2022 If the buffer exceeds a predefined size (window size), remove the oldest batch. \u2022 Retrain the model using the data in the buffer. ", "page_idx": 29}, {"type": "text", "text": "Our method. $\\mathcal{H}$ -LLM. In this example, we use $\\mathcal{H}$ -LLM to identify corrupted columns and values and identify whether they need removal. The overall setup is as follows: ", "page_idx": 29}, {"type": "text", "text": "1. Split the test data into multiple batches.   \n2. Train the model on the initial training dataset.   \n3. Maintain buffers to store the most recent batches and a backtesting window.   \n4. For each batch in the test set: \u2022 Predict the outcomes and calculate the accuracy. \u2022 Update the buffers with the current batch. \u2022 Update the drift detector with the prediction error. \u2022 If drift is detected: \u2013 Use the self-healing mechanism to inspect the most recent and previous batches. \u2013 Propose multiple adaptation strategies \u2013 Select the best adaptation strategy on a backtesting window. \u2013 Retrain the model on the inspected and backtesting data to recover from the detected drift. ", "page_idx": 29}, {"type": "text", "text": "In all cases, the optimal strategy was removing a corrupted batch of data, where the amount of corrupted values or their extent varied. ", "page_idx": 29}, {"type": "text", "text": "Comments on the experimental setup of viability study I. The goal of this setup is to showcase that blindly retraining the model or using pre-determined actions is not necessarily optimal. In this case, the strategy required is to understand that the model requires full re-training and some values have been corrupted which require careful dealing, such as adjustments or removal. ", "page_idx": 29}, {"type": "text", "text": "C.2.2 Viability Studies III - VI ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Viability Study III. We employ the Drift Detection Method (DDM) and vary the sensitivity parameter indicated on the $\\mathbf{X}$ -axis. We then calculate the recovery time \u2014 how much time it takes to detect the shift\u2014, as well as the post-intervention accuracy. As discussed in the main paper, this is purely determined by the DDM. For each detected drift, we fully run $\\mathcal{H}$ -LLM to detect issues and propose adaptation strategies that are tested on a backtesting window. If none of them beat the performance of the current model, the existing model $f$ is deployed. ", "page_idx": 29}, {"type": "text", "text": "Viability Study IV. We evaluate how well self-healing systems identify the root causes of problems. We corrupt a proportion of observations (corruption coefficient) by multiplying their values by a factor (outlier factor) and see if the $\\mathcal{H}$ -LLM detects issues related to these factors. We output a probability distribution over diagnoses of which variable is corrupted. Knowing the true corrupted variable, we measure the difference between the distributions using KL-Divergence, with lower values indicating better matches between true and estimated corruption. A uniform diagnosis baseline represents random guessing. Here is an example of what it means for the \u201ctrue probabilities\u201d to be corrupted when the corrupted column is \u201cAge\u201d. ", "page_idx": 29}, {"type": "text", "text": "true_probabilities $\\mathbf{\\Psi}=\\mathbf{\\Psi}\\{\\mathbf{\\Psi}^{\\prime}\\mathop{\\mathrm{Age}}^{\\mathbf{\\Psi}^{\\prime}}:\\mathbf{\\Psi}\\ 1$ ,   \n\u2019HbA1c \u2019: 0,   \n\u2019FastingGlucose \u2019: 0,   \n\u2019BMI \u2019: 0, \u2019BloodPressure \u2019: 0,   \n6 \u2019Cholesterol \u2019: 0,   \n7 \u2019Insulin \u2019: 0, \u2019PhysicalActivity \u2019: 0} ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "Code Listing 11: An example of true corrupted probabilities ", "page_idx": 30}, {"type": "text", "text": "Recall that $\\mathcal{H}$ -LLM produces normalized probability guesses, as shown in Sec. B.3. Therefore, the obtained predicted guesses of which variable is corrupted in this setup looks as follows: ", "page_idx": 30}, {"type": "text", "text": "predicted_probabilities $=$ {\u2019Age \u2019: 0.125 ,   \n\u2019HbA1c \u2019: 0.125 ,   \n\u2019FastingGlucose \u2019: 0.125 ,   \n\u2019BMI \u2019: 0.125 ,   \n\u2019BloodPressure \u2019: 0.125 ,   \n\u2019Cholesterol \u2019: 0.125 ,   \n\u2019Insulin \u2019: 0.125 ,   \n\u2019PhysicalActivity \u2019: 0.125} ", "page_idx": 30}, {"type": "text", "text": "Code Listing 12: An example of predicted corrupted probabilities ", "page_idx": 30}, {"type": "text", "text": "When the corruption coefficient is higher, the output looks as follows: ", "page_idx": 30}, {"type": "text", "text": "predicted_probabilities $=$ {\u2019Age \u2019: 0.4,   \n\u2019HbA1c \u2019: 0.2,   \n\u2019FastingGlucose \u2019: 0.15,   \n\u2019BMI \u2019: 0.05,   \n\u2019BloodPressure \u2019: 0.05,   \n\u2019Cholesterol \u2019: 0.05,   \n\u2019Insulin \u2019: 0.05,   \n\u2019PhysicalActivity \u2019: 0.05} ", "page_idx": 30}, {"type": "text", "text": "Code Listing 13: An example of true corrupted probabilities ", "page_idx": 30}, {"type": "text", "text": "Therefore, the KL divergence is computed between these two probability distributions. The KL is the highest when the outputted probability distribution is uniform (first example) and the lowest when it perfectly matches the reference/true probability distribution. It has been shown that with certain techniques, LLMs can generally output calibrated confidence scores or probabilities [75]. ", "page_idx": 30}, {"type": "text", "text": "The reason why the KL-divergence decreases is because the predicted probabilties put greater relative value on the true corrupted value (i.e. the \u201cAge\u201d column in this example) as (i) the outlier factor increases and as (ii) the percent of values corrupted increase. ", "page_idx": 30}, {"type": "text", "text": "Viability Study V. We study the sensitivity of SHML adaptation policies by examining how well actions perform based on (i) the number of corrupted values and (ii) the size of the backtesting dataset. Fig. 6 shows this relationship. The corruption coefficient is described in the overall experimental setup. The size of the backtesting window is the size of the dataset used to evaluat the proposed actions. Recall that $\\mathcal{H}$ -LLM has three adaptation actions in place: (i) generic; (ii) flitering corrupted data slices; and (iii) training slice-specific models (Appendix B). For this experiment, we focus on actions proposed by the second adaptation strategy: filtering corrupted data slices. Each adaptation action is an identified data slice by $\\mathcal{H}$ -LLM that might be corrupted, the removal of which might improve performance. The following is an example of proposed adaptation actions by the removal of the following queries (each query is a separate candidate adaptation action): ", "page_idx": 30}, {"type": "text", "text": "[\u2019 FastingGlucose > 376.145108 \u2019 ,   \n\u2019Insulin $>$ 320.642677 \u2019 ,   \n\u2019HbA1c > 21.553946 \u2019 ,   \n\u2019Age > 187.805319 \u2019 ,   \n\u2019BMI > 93.998780 \u2019 ,   \n\u2019BloodPressure > 452.899287 \u2019 ,   \n\u2019Cholesterol > 757.675355 \u2019 ,   \n\u2019PhysicalActivity > 11.314583 \u2019 ,   \n\u2019(HbA1c > 21.553946) & (FastingGlucose > 376.145108) \u2019,   \n\u2019(Age > 187.805319) & (BMI > 93.998780) \u2019,   \n\u2019( BloodPressure > 452.899287) & (Cholesterol > 757.675355) \u2019,   \n\u2019(Insulin > 320.642677) & ( PhysicalActivity > 11.314583) \u2019,   \n13 \u2019(HbA1c > 21.553946) & (FastingGlucose > 376.145108) & (Age > 187.805319) \u2019,   \n14 \u2019(BMI > 93.998780) & (BloodPressure > 452.899287) & (Cholesterol > 757.675355) \u2019,   \n15 \u2019(Insulin > 320.642677) & ( PhysicalActivity > 11.314583) & (HbA1c > 21.553946) \u2019,   \n16 \u2019( FastingGlucose > 376.145108) & (Age > 187.805319) & (BMI > 93.998780) \u2019,   \n17 \u2019( BloodPressure > 452.899287) & (Cholesterol > 757.675355) & (Insulin > 320.642677) \u2019,   \n18 \u2019( PhysicalActivity > 11.314583) & (HbA1c > 21.553946) & ( FastingGlucose > 376.145108) \u2019,   \n19 \u2019(Age > 187.805319) & (BMI > 93.998780) & ( BloodPressure > 452.899287) \u2019] Code Listing 14: Proposed adaptation actions by removing candidate corrupted slices ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "Such actions are proposed for each range of values corrupted and evaluated accordingly. ", "page_idx": 31}, {"type": "text", "text": "Viability study VI. We study the importance of the testing component (Eq. 7) by evaluating $\\mathcal{H}$ -LLM suggested actions with and without the testing phase (backtesting window) and comparing their accuracies. Fig. 7 shows this relationship. The action with the backtesting window is the action which has received the highest empirical performance on the backtesting window. In contrast, the action proposed by \u201cno backtesting window\u201d is the action that is selected as the most likely one by $\\mathcal{H}$ -LLM without any empirical validation. \u201cMost likely\u201d implies that after a few iteration loops, this was the action that was listed as the first action to perform. This showcases the usefulness of having a way to filter out actions with some specific actions. We mimic the setup from study IV where each action is a specific subgroup to fliter out to achieve better performance due to the corrupted nature of the data. ", "page_idx": 31}, {"type": "text", "text": "C.3 Other experimental details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We note that all experiments were performed using two compute resources: a server with NVIDIA RTX A4000 GPU and 18-Core Intel Core i9-10980XE, as well as an Apple M1 Pro 32GB RAM. We exemplify $\\mathcal{H}$ -LLM with GPT-4 via an API. ", "page_idx": 31}, {"type": "text", "text": "D Extended experiments ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "This section provides a few additional experiments or more detail regarding the experiments presented in the main paper. ", "page_idx": 32}, {"type": "text", "text": "D.1 Monitoring ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Setup. We vary the warm-star criterion within drift detection methods to evaluate the recovery time and post-intervention accuracy of $\\mathcal{H}$ -LLM. The warm start parameter is the minimum number of samples required to conclude that a drift has been detected and trigger re-training or selfhealing. ", "page_idx": 32}, {"type": "text", "text": "Discussion. Fig. 8 showcases the relationship between the warm-start parameter and the average recovery tiem and post-intervention accuracy. You see the massive increase in average covery time that jumps when the warm-start is set at a relatively high threshold. This results from a drift detection algoritihm detecting a false positive drift just before the actual drift. However, given the wwarm-star parameter, there was a significant delay in re-triggering the self-healing system. This suggests self-healing systems benefti from lower warm-start parameters in case the drift detection algorithms are sensitive to false positives. This corresponds with a relative drop in the post-intervention accuracy because of the longer time it took to trigger self-healing. ", "page_idx": 32}, {"type": "image", "img_path": "f63DKIpx0I/tmp/922f46cc159fa93c9eccca48f0576ba08197ce5da359727da4a4e0e93d526490.jpg", "img_caption": ["Figure 8: Adaptation strategies of different methods in response to three shifts. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "Takeaway. Self-healing systems benefit from lower warm-start parameters in case drift detection systems are sensitive to false positive drifts.-intervention accuracy with smaller thresholds. ", "page_idx": 32}, {"type": "text", "text": "D.2 Diagnosis ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Setup. In this experiment, instead of corrupting a single variable which is responsible for model degradation, we corrupt $n$ variables to evaluate how well $\\mathcal{H}$ -LLM can diagnose multiple corrupted values at once. With each corrupted columns, the true corrupted probability changes. For instance, if there are four columns and there is a single corrupted column, the true corruption vector is [1, 0, 0, 0]. If there are four corrupted columns, then it is [0.25, 0.25, 0.25, 0.25]. We use these probabilities and compare them to the corruption probabilities outputted by $\\mathcal{H}$ -LLM. This is shown in Fig. 9. ", "page_idx": 32}, {"type": "image", "img_path": "f63DKIpx0I/tmp/f51be64b54f1b53d91811d5c58a39bfc717637897e8ad7430a77e1dd704a79c1.jpg", "img_caption": ["Figure 9: The qualtiy of diagnosis based on n columns. Lower is better "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "Discussion. This showcases that the more columns are corrupted, the better the predictive diagnosis becomes. For instance, once all columns are corrupted, $\\mathcal{H}$ -LLM outputs a uniform diagnosis because it has no information given the evidence observed. This exactly corresponds to the true corruption probability, outputting a KL of 0. We notice that the KL generally decreases with the number of corrupted columns for this reason. ", "page_idx": 32}, {"type": "text", "text": "Takeaway. Greater uncertainty results in more uniform diagnosis. However, less uncertainty can make it difficult to directly pinpoint the exact cause, causing more uncertainty. ", "page_idx": 32}, {"type": "text", "text": "D.3 Adaptation experiment ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "This section expands on the adaptation experiments by providing more variables and values by corruption coefficient and the number of columns corrupted. ", "page_idx": 33}, {"type": "table", "img_path": "f63DKIpx0I/tmp/68496219fca0e204068af1e6ffbbecf8aeb4ae4b2da48a8e1ed9a51665c99428.jpg", "table_caption": ["Table 7: Accuracy based on the number of corrupted columns, where $5\\%$ of values given a selected column are corrupted on a shifted dataset with a number of corrupted values. Higher is better. (with a corruption coefficient of 0.05) "], "table_footnote": [], "page_idx": 33}, {"type": "table", "img_path": "f63DKIpx0I/tmp/ffbd28a3b5c414ba22a4c64b8583cc8bbc2b8246122c3a91c9544c43e02d9b1c.jpg", "table_caption": ["Table 8: Accuracy based on the number of percent of corrupted value within a given column (with three corrupted columns with three corrupted columns) "], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "D.4 Effects of Self-Healing across corruption levels ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We systematically analyze how self-healing effectiveness varies with corruption levels across our five datasets (Airlines, Poker, Weather, Electricity, and Forest Type). For each dataset, we vary both the corruption value $\\tau$ and the number of corrupted columns $k$ , measuring accuracy with and without the self-healing mechanism. Figure 10 shows that self-healing\u2019s impact grows with corruption severity. Specifically, as either $\\tau$ or $k$ increases, the gap between baseline and self-healed performance widens. This pattern holds consistently across all datasets, though with varying magnitudes. These results demonstrate that self-healing becomes more crucial as data degradation becomes more severe, providing a safety mechanism for maintaining model performance under challenging conditions. ", "page_idx": 33}, {"type": "image", "img_path": "f63DKIpx0I/tmp/ab100a9fba3d569463a398c73b3c6e50ffbfb2b542ffd5cb560413e5f951912f.jpg", "img_caption": ["Figure 10: Effects of self-healing for five datasets as we vary the number of corrupted columns and the corruption value. Self-healing consistently identifies corrupted columns at test time. This typically becomes more important as the corruption level increases (either by corruption value or number of corrupted columns). Baseline is not implementing a self-healing mechanism upon drift detection. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "D.5 Extended benchmarks ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We extend our comparison on the diabetes prediction task to include additional adaptation methods and adaptive algorithms. Table 9 presents results from ten different approaches, including standard adaptations (no retraining, partial updates, new model training, ensemble methods), streaming-specific algorithms (ADWIN Bagging, Hoeffding Tree), and our SHML approach. ", "page_idx": 33}, {"type": "table", "img_path": "f63DKIpx0I/tmp/7faad054d1cd3e1c5d5d2e31e27267050b9f29bc8492befe81674d7368bd1850.jpg", "table_caption": [], "table_footnote": ["Table 9: Accuracies of various adaptations on the original diabetes dataset setup in the paper. "], "page_idx": 34}, {"type": "text", "text": "The results show that while specialized streaming algorithms (e.g., Hoeffding Tree at 0.70 accuracy) outperform basic adaptations, they still fall short of SHML\u2019s performance (0.76 accuracy). ", "page_idx": 34}, {"type": "text", "text": "D.6 Component-wise Ablation Analysis ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "To understand the importance of each SHML component, we conduct an ablation study by systematically removing each component and observing the impact. Table 10 shows the results of this analysis. ", "page_idx": 34}, {"type": "table", "img_path": "f63DKIpx0I/tmp/bc16440bbc32525ad9d5eac70b33cd7b03cbaaadb9472d29d393d67f504fd5ea.jpg", "table_caption": ["Table 10: Ablation study results for $\\overline{{\\mathcal{H}}}$ -LLM. We systematically remove one component of the system and inspect its outputs. The takeaway represents our qualitative evaluation. "], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "The ablation reveals that each component is crucial for effective self-healing. Removing monitoring $52\\%$ accuracy) prevents the system from triggering adaptation. Without diagnosis, the system proposes non-sensical actions, leading to baseline performance. Removing action generation or testing similarly degrades performance to baseline levels, though testing removal shows slightly better performance $(62\\%)$ as some reasonable actions are still attempted, albeit without proper validation. ", "page_idx": 34}, {"type": "text", "text": "This analysis empirically validates our framework\u2019s design, showing that effective self-healing requires all four components working in concert. ", "page_idx": 34}, {"type": "text", "text": "D.7 Model agnosticism ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We evaluate SHML\u2019s effectiveness across ten different ML models to demonstrate its model-agnostic nature. Table 11 shows results for models ranging from simple (e.g., Decision Trees) to complex (e.g., XGBoost), comparing various adaptation strategies. SHML consistently outperforms baseline approaches across all model types, with improvements ranging from 11 percentage points (Naive Bayes) to 31 percentage points (LDA). This consistent improvement demonstrates that SHML\u2019s benefits are not tied to any particular model architecture but rather stem from its ability to reason about and address degradation causes. ", "page_idx": 34}, {"type": "table", "img_path": "f63DKIpx0I/tmp/24ecbc8af018b453111b023a1224348bf43a94ed595e52dd6b5175de1a59b2f6.jpg", "table_caption": [], "table_footnote": ["Table 11: Comparison of various methods across different ML models on the weather dataset (setup above), where features are corrupted at test time. Results show mean accuracy $\\pm$ standard deviation. "], "page_idx": 34}, {"type": "text", "text": "E Optimal diagnosis ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Here, we prove that under the stated assumptions, the optimal diagnosis has zero entropy. ", "page_idx": 35}, {"type": "text", "text": "Proposition 3. Under Assumption $^{\\,l}$ , the optimal diagnosis $\\zeta^{*}$ has a zero entropy, i.e., $\\mathbb{H}(\\zeta^{*})=0$ . ", "page_idx": 35}, {"type": "text", "text": "Proof. By Definition 2, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\zeta^{*}=\\arg\\operatorname*{min}_{\\zeta\\in\\Delta(\\mathcal{Z})}\\mathbb{E}_{a\\sim\\pi(\\cdot|\\zeta)}[R(a)]\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "As $\\boldsymbol{\\mathcal{A}}$ is finite, we write the expected value as follows. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}_{a\\sim\\pi(\\cdot|\\zeta)}[R(a)]=\\sum_{a\\in\\mathcal{A}}R(a)\\pi(a|\\zeta)\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "By Assumption 1, this can be rewritten as: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{a\\in\\mathcal{A}}R(a)\\left(\\sum_{z\\in\\mathcal{Z}}\\pi(a|z^{\\dagger})\\zeta(z)\\right)\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We change the order of summation to arrive at the following. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\sum_{a\\in\\mathcal{A}}R(a)\\pi(a|z^{\\dagger})\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The inner sum can now be rewritten as an expectation. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\mathbb{E}_{a\\sim\\pi(\\cdot|z^{\\dagger})}[R(a)]\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Thus we can rewrite the minimization problem as follows. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\zeta^{*}=\\underset{\\zeta\\in\\Delta(\\mathcal{Z})}{\\arg\\operatorname*{min}}\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\mathbb{E}_{a\\sim\\pi(\\cdot|z^{\\dagger})}[R(a)]\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Let $z^{\\ast}\\in\\mathcal{Z}$ such that ", "page_idx": 35}, {"type": "equation", "text": "$$\nz^{*}\\in\\underset{z\\in\\mathcal{Z}}{\\arg\\operatorname*{min}}\\,\\mathbb{E}_{a\\sim\\pi(\\cdot|z^{\\dagger})}[R(a)]\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Then ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\mathbb{E}_{a\\sim\\pi(\\cdot|z^{\\dagger})}[R(a)]\\ge\\sum_{z\\in\\mathcal{Z}}\\zeta(z)\\mathbb{E}_{a\\sim\\pi(\\cdot|(z^{*})^{\\dagger})}[R(a)]}}\\\\ &{=\\mathbb{E}_{a\\sim\\pi(\\cdot|(z^{*})^{\\dagger})}[R(a)]}\\\\ &{=\\displaystyle\\sum_{z\\in\\mathcal{Z}}(z^{*})^{\\dagger}(z)\\mathbb{E}_{a\\sim\\pi(\\cdot|z^{\\dagger})}[R(a)]}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Therefore ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\zeta^{*}=\\left(z^{*}\\right)^{\\dagger}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "and by the definition of entropy and $(z^{*})^{\\dag}$ we get ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{H}(\\zeta^{*})=0\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper presents a novel paradigm called self-healing machine learning. This is established in Section 3.3 and Sec. 4, where we develop the theoretical underpinnings of this field. We also make significant practical contributions by proposing the first-ever selfhealing algorithm presented in Sec. 5. We discuss the positive impacts of this technology in the introduction and the discussion section, where we argue it can have transformative effects in a variety of real-world situations. We clearly show the viability of self-healing machine learning in Sec. 6. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 36}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: Self-healing machine learning inherently assumes that diagnoses can be performed well and that actions can be proposed on the basis of these diagnoses. This poses challenges we discuss in Sec. 5.1. We attempt to overcome these limitations by using language models and incorporating their unique properties into $\\mathcal{H}$ -LLM. We discuss further challenges of self-healing systems in the discussion section (Sec. 7) ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. ", "page_idx": 36}, {"type": "text", "text": "\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 37}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: In order to establish the relationship between diagnosis and the actions, we define the certainty diagnosis (Def. 1) and the optimal diagnosis (Def. 2). Furthermore, we assume independent actions (Assumption 1). Under this, we establish two propositions about the entropy of an optimal diagnosis (Proposition 1) and its existence (Proposition 2). One of the proofs is in the main paper and the other one can be found in Appendix E. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 37}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: We provide all the required information to reproduce our algorithm $\\mathcal{H}$ -LLM (Appendix. B) as well as the full detail on experiments, including dataset generation, parameters, etc. (Appendix. C). We provide an additional appendix section with supplementary experiments that can aid the reviewers where we discuss the setups within each experiment (Appendix. D). The code can be found at: https://github.com/pauliusrauba/Self_ Healing_ML or https://github.com/vanderschaarlab/Self_Healing_ML ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \nWhile NeurIPS does not require releasing code, the conference does require all submis  \nsions to provide some reasonable avenue for reproducibility, which may depend on the   \nnature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We provide full experimental details, where all access to data and code is fully available. Code can be found at: https://github.com/pauliusrauba/Self_ Healing_ML or https://github.com/vanderschaarlab/Self_Healing_ML. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 38}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: All details are provided in Appendix. C. The experimental setting is presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. Full details provided in the appendix. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 39}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: All appropriate experiments report error bars. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: Yes, all relevant information is provided. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 39}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] Justification: Yes. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 40}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: Yes. We discuss this in Sec. 7. To reiterate, we believe our work can have significant positive effects on multiple areas within AI and have substantial practical implications, as discussed in the Discussion section. This includes having immediate practical benefits in industries where model degradation is common, such as medicine, finance, predictive policing, IoT data streams, and more. We further hope our work spurs substantial developments in self-healing theory. We also discuss that the unique improvements in systems that can employ self-healing could also be misused by agents for other purposes, such as using self-healing for surveillance systems or other ethically ambiguous technologies. The broader impact also subsumes future work in this area. We hope that a potential direction for future work is building theory around optimal diagnoses, optimal adaptation strategies, as well as scaling larger algorithms. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 40}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: We do not release any data or models with a high risk for misuse. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks. ", "page_idx": 40}, {"type": "text", "text": "\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 41}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 41}, {"type": "text", "text": "Answer: ", "page_idx": 41}, {"type": "text", "text": "Justification: We cite and refer to all appropriate codebases that are employed as benchmarks. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 41}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Justification: The core assets, including the framework and the algorithm, are clearly described. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 41}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 42}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]