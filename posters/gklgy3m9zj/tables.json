[{"figure_path": "gKLgY3m9zj/tables/tables_7_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) results for various conformal training methods on five datasets: MNIST, Fashion-MNIST, EMNIST, CIFAR-10, and CIFAR-100.  The methods compared include cross-entropy (CE) loss, ConfTr, ConfTrclass, Fano, Model-Based Fano, and DPI bounds.  Two different conformal prediction methods, THR and APS, are used to calculate the inefficiency.  Lower values indicate better performance, meaning smaller prediction sets which correspond to more efficient use of the model.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_7_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency results for different conformal training methods in a centralized setting.  Inefficiency is measured as the average prediction set size.  The results are averaged over 10 different calibration and test data splits, using a target error rate (\u03b1) of 0.01.  The table shows results for two different conformal prediction methods (THR and APS), each with different model hyperparameters, and several different training objectives (CE, ConfTr, ConfTrclass, Fano, MB Fano, DPI). Lower values indicate better performance.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_8_1.jpg", "caption": "Table 3: Inefficiency results with side information. We report the mean prediction set size (\u00b1 std.) across 10 different calib./test splits for a = 0.01. The side information is the superclass assignment for CIFAR100 and whether the class is a digit / uppercase letter / lowercase letter for EMNIST.", "description": "This table presents the results of experiments evaluating the impact of side information on the efficiency of conformal prediction.  Two different scenarios are tested: standard split conformal prediction (SCP) and group-balanced CP (Mondrian CP). The results show how adding side information, whether 10%, 30%, or 100% of the data, affects the inefficiency (measured by the average prediction set size) of both THR and APS methods for both CIFAR100 and EMNIST datasets.", "section": "7.2 Side Information"}, {"figure_path": "gKLgY3m9zj/tables/tables_9_1.jpg", "caption": "Table 4: Inefficiency results for conformal training in the federated setting with THR. We report the mean prediction set size (\u00b1 standard deviation) of the global federated model across 10 different calib./test splits for a = 0.01 and using THR. We use +si to indicate the inclusion of side information. We show in bold all values within one standard deviation of the best result. Lower is better.", "description": "This table presents the inefficiency (average prediction set size) results for conformal training in a federated learning setting, using the THR method. The results are shown for different conformal training objectives (CE, ConfTr, ConfTrclass, Fano, MB Fano, DPI) with and without side information (+si).  The table shows the mean and standard deviation across 10 different calibration/test splits for a target error rate (alpha) of 0.01. Lower values indicate better performance.", "section": "7.3 Federated Learning (FL)"}, {"figure_path": "gKLgY3m9zj/tables/tables_9_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) of different conformal prediction methods for training classifiers in a centralized setting.  Results are shown for multiple datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100), using two different conformal prediction methods (THR and APS). Lower values indicate better performance (smaller prediction sets). Bold values indicate results within one standard deviation of the best result for each dataset and method.  Hyperparameter settings are explained in Appendix G.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_29_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency results for different conformal training methods in a centralized setting.  Inefficiency is measured as the average prediction set size, with lower values indicating better performance. The results are averaged over 10 different train/test splits with a target error rate of 1%.  The table compares various methods including the cross-entropy loss (CE) and the proposed methods (DPI, Fano, MB Fano).  Different models (THR and APS) with various hyperparameters are used for comparison, with details found in Appendix G.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_30_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the results of conformal training experiments conducted in a centralized setting.  It compares the average prediction set size, a measure of inefficiency, across various methods (CE, ConfTr, ConfTr-class, Fano, MB Fano, DPI). The experiment used a significance level of \u03b1 = 0.01, and the results are averaged across 10 different train-test splits.  The table shows that different methods result in different efficiency levels, with lower values indicating better performance.  The THR and APS results reflect the use of different model hyperparameters.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_30_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (mean prediction set size) of different conformal prediction training methods on five datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100).  It compares the performance of using cross-entropy loss (CE), ConfTr, ConfTr-class, and the proposed methods (Fano, MB Fano, DPI) for training classifiers.  The results are averaged across 10 different train/test splits, and values within one standard deviation of the best result are highlighted.  THR and APS denote different model architectures with varied hyperparameters.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_30_3.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (mean prediction set size) of different conformal prediction training methods on five datasets: MNIST, Fashion-MNIST, EMNIST, CIFAR-10, and CIFAR-100.  The inefficiency is calculated across ten different calibration/test splits with a target coverage rate of 99% (\u03b1=0.01).  Results are shown for two different conformal prediction methods, THR (threshold with probabilities) and APS (adaptive prediction sets), with different hyperparameters indicated by THR and APS. Lower values indicate better performance (more efficient prediction sets).", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_31_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) of different conformal prediction training methods on five datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100).  The results are shown for two different conformal prediction methods (THR and APS) and various training objectives, including cross-entropy and the information-theoretic bounds introduced in the paper.  Lower values indicate better efficiency.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_31_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) of different conformal prediction methods on five datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100).  Inefficiency is calculated across 10 different train-test splits for a target error rate of \u03b1 = 0.01. The methods compared include using cross-entropy loss, ConfTr, ConfTr-class, and three new upper bounds proposed in the paper (DPI, Fano, MB Fano). THR and APS represent results from different models trained with different hyperparameters, and bold values indicate results within one standard deviation of the best performance. Lower numbers are better indicating higher efficiency.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_32_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) results for different conformal prediction training methods on five datasets: MNIST, Fashion-MNIST, EMNIST, CIFAR-10, and CIFAR-100.  The methods compared include cross-entropy (CE) loss, ConfTr, ConfTrclass, and the three information-theoretic bounds proposed in the paper (Fano, MB Fano, DPI).  Results are shown for two conformal prediction methods, THR and APS. Lower inefficiency values indicate better performance.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_32_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the results of conformal training experiments conducted in a centralized setting.  The mean prediction set size, a measure of inefficiency, is reported for ten different train/test splits, using a target error rate (\u03b1) of 0.01.  The results are shown for different conformal training methods, including two versions of ConfTr and three new information-theoretic bounds introduced in the paper.  For the THR and APS methods, results from different models trained with varying hyperparameters are included (details in Appendix G). Lower values indicate higher efficiency (smaller prediction sets).", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_32_3.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the results of conformal training experiments conducted in a centralized setting.  The table shows the average prediction set size (a measure of inefficiency, with lower values indicating better performance) for various methods across 10 different calibration/test dataset splits.  The methods are compared for different datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100). Results for THR and APS (different models) highlight the impact of hyperparameter tuning.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_33_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) results for different conformal training methods on five datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, and CIFAR-100).  The methods compared include cross-entropy loss (CE), ConfTr, ConfTrclass, Fano, Model-Based Fano, and DPI bounds, each using two different conformal prediction methods (THR and APS).  Lower values indicate better performance.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_33_2.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (average prediction set size) of different conformal prediction training methods on several datasets.  Inefficiency is a measure of how concise the prediction sets are. The results are averages across 10 separate train/test splits and the standard deviations are reported for each experiment to show the variability. Lower values of inefficiency are better, indicating more concise and informative prediction sets.  Different model types (THR, APS) and hyperparameter settings are used for more comprehensive evaluation.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_33_3.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (mean prediction set size and standard deviation) of different conformal prediction training methods across various datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, CIFAR-100).  The methods compared include cross-entropy (CE) loss, ConfTr, ConfTrclass, Fano, model-based Fano, and DPI bounds.  The results are obtained from 10 different calibration/test splits, with bold values indicating results within one standard deviation of the best result.  THR and APS represent different models trained with different hyperparameters, detailed in Appendix G.", "section": "7.1 Conformal Training"}, {"figure_path": "gKLgY3m9zj/tables/tables_34_1.jpg", "caption": "Table 1: Inefficiency results for conformal training in the centralized setting. We report the mean prediction set size (\u00b1 standard deviation) across 10 different calib./test splits for \u03b1 = 0.01, showing in bold all values within one std. of the best result. Results for THR and APS correspond to different models trained with different hyperparameters (see Appendix G). Lower is better.", "description": "This table presents the inefficiency (mean prediction set size) results for different conformal training methods on five datasets (MNIST, Fashion-MNIST, EMNIST, CIFAR-10, and CIFAR-100).  It compares the performance of using cross-entropy loss, ConfTr, ConfTrclass, and three information-theoretic upper bounds (DPI, Fano, MB Fano) as training objectives.  The results are averaged over 10 different train/test splits, and statistically significant results are highlighted.", "section": "7.1 Conformal Training"}]