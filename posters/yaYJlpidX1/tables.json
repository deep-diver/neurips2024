[{"figure_path": "yaYJlpidX1/tables/tables_4_1.jpg", "caption": "Table 1: 5-way classification accuracies using 15 (meta-test training) examples for each class in the context. Each row is a single model. Bold numbers highlight cases where in-context catastrophic forgetting is avoided through ACL.", "description": "This table presents the 5-way classification accuracies achieved by different models on two tasks (A and B).  The models are evaluated under different continual learning scenarios: Task A only, Task B only, Task A followed by Task B, and Task B followed by Task A. The table compares the performance of models trained with and without the proposed Automated Continual Learning (ACL) method. Bold numbers indicate instances where ACL successfully prevents catastrophic forgetting, demonstrating its effectiveness in continual learning.", "section": "4.1 Two-Task Setting: Comprehensible Study"}, {"figure_path": "yaYJlpidX1/tables/tables_4_2.jpg", "caption": "Table 2: Similar to Table 1 above but using MNIST and CIFAR-10 (unseen domains) for meta-testing.", "description": "This table shows the results of a continual learning experiment.  It compares the performance of a model trained using the Automated Continual Learning (ACL) method with a model trained without ACL. The experiment uses MNIST and CIFAR-10 datasets for testing, which are different from the datasets used for training (meta-training tasks).  The table shows classification accuracies for two tasks (Task A and Task B), with and without ACL, and in different contextual learning scenarios (A\u2192B and B\u2192A).  The results illustrate the ability of ACL to mitigate catastrophic forgetting, allowing the model to perform well on both old and new tasks.", "section": "4 Experiments"}, {"figure_path": "yaYJlpidX1/tables/tables_6_1.jpg", "caption": "Table 3: Classification accuracies (%) on the Split-MNIST domain-incremental (DIL) and class-incremental learning (CIL) settings [6]. Both tasks are 5-task CL problems. For the CIL case, we also report the 2-task case for which we can directly evaluate our out-of-the-box ACL meta-learner of Sec. 4.1 (trained with a 5-way output and the 2-task ACL loss) which, however, is not applicable (N.A.) to the 5-task CIL requiring a 10-way output. Mean/std over 10 training/meta-testing runs. No method here requires replay memory. See Appendix A.7 & B for further details and discussions.", "description": "This table presents the classification accuracies achieved by various continual learning methods on the Split-MNIST benchmark.  The results are broken down by domain-incremental (DIL) and class-incremental (CIL) learning settings, with both 2-task and 5-task variations shown.  The table highlights the performance of the proposed Automated Continual Learning (ACL) method against several existing state-of-the-art methods in a replay-free setting.", "section": "4.3 General Evaluation"}, {"figure_path": "yaYJlpidX1/tables/tables_7_1.jpg", "caption": "Table 4: Experiments with \u201cmini\u201d Split-CIFAR100 and 5-datasets tasks. Meta-training is done using Mini-ImageNet and Omniglot. All meta-evaluation images are therefore from unseen domains. Numbers marked with * are reference numbers (evaluated in the more challenging, original version of these tasks) which can not be directly compared to ours.", "description": "This table compares the performance of the proposed ACL method against state-of-the-art continual learning methods (L2P and DualPrompt) on two challenging continual learning benchmarks: a reduced version of the 5-datasets benchmark and a reduced version of Split-CIFAR100.  The results show that while ACL performs well on individual tasks within these benchmarks, it lags behind the state-of-the-art methods in overall continual learning performance.  The use of pre-trained models (as in L2P and DualPrompt) is highlighted as a potential reason for the performance gap.", "section": "4.3 General Evaluation"}, {"figure_path": "yaYJlpidX1/tables/tables_17_1.jpg", "caption": "Table 5: Hyper-parameters.", "description": "This table lists the hyperparameters used in the experiments described in the paper, including the number of SRWM layers, total hidden size, feedforward block multiplier, number of heads, and batch size.", "section": "A.3 Training Details & Hyper-Parameters"}, {"figure_path": "yaYJlpidX1/tables/tables_18_1.jpg", "caption": "Table 6: Impact of the choice of meta-validation datasets. Classification accuracies (%) on three datasets: Split-CIFAR-10, Split-Fashion MNIST (Split-FMNIST), and Split-MNIST in the domain-incremental setting (we omit \"Split-\" in the second column). \u201cOOB\u201d denotes \"out-of-the-box\". \"mImageNet\" here refers to mini-ImageNet.", "description": "This table presents the classification accuracies achieved by different models on three datasets (Split-CIFAR-10, Split-Fashion MNIST, and Split-MNIST) using a domain-incremental learning setting. The models were trained using different meta-validation datasets (Omniglot, MNIST, FMNIST, CIFAR10) to evaluate the impact of the choice of meta-validation dataset on model performance.  The \"OOB\" model represents the out-of-the-box 2-task ACL model from section 4.1 of the paper, which serves as a baseline for comparison.  Mini-ImageNet is abbreviated as mImageNet.", "section": "4.1 Two-Task Setting: Comprehensible Study"}, {"figure_path": "yaYJlpidX1/tables/tables_19_1.jpg", "caption": "Table 7: Impact of the number of in-context examples. Classification accuracies (%) on Split-MNIST in the 2-task and 5-task class-incremental learning (CIL) settings and the 5-task domain-incremental learning (DIL) setting. For ACL models, we use the same number of examples for meta-validation as for meta-training. According to Banayeeanzade et al. [31], GeMCL is meta-trained with the 5-shot setting but meta-validated in the 15-shot setting.", "description": "This table presents the classification accuracies achieved on the Split-MNIST benchmark using different numbers of in-context examples. It compares the performance of the proposed Automated Continual Learning (ACL) method against the Generative Meta-Continual Learning (GeMCL) method for both 2-task and 5-task class-incremental learning, as well as domain-incremental learning.  The impact of varying the number of training and testing examples is shown.", "section": "4.3 General Evaluation"}, {"figure_path": "yaYJlpidX1/tables/tables_20_1.jpg", "caption": "Table 8: Meta-testing on sequences that are longer than those from meta-training. Classification accuracies (%) on 5-task Split-FMNIST and 5-task Split-MNIST in the domain-incremental settings. The model is the one finetuned with 5-task ACL loss using Omniglot as the meta-finetuning set and FMNIST as the meta-validation set (i.e., the numbers in the top part of the table are taken from Table 6). In the first column, \u201cSplit-FMNIST, Split-MNIST\u201d indicates continual learning of 5 Split-FMNIST tasks followed by 5 tasks of Split-MNIST (and \u201cSplit-MNIST, Split-FMNIST", "description": "This table presents the results of meta-testing on sequences longer than those used in meta-training.  It evaluates a model fine-tuned with a 5-task ACL loss, using Omniglot for meta-finetuning and FMNIST for meta-validation. The experiment involves continual learning of 5-task Split-FMNIST followed by 5-task Split-MNIST, and vice-versa.  The table shows the classification accuracies (%) at the end of each sequence for both Split-FMNIST and Split-MNIST.", "section": "4.3 General Evaluation"}, {"figure_path": "yaYJlpidX1/tables/tables_20_2.jpg", "caption": "Table 9: Classification accuracies (%) on 5-task 2-way Split-Omniglot. Mean/std is computed over 10 meta-test runs.", "description": "This table presents the classification accuracies achieved by GeMCL and ACL on the 5-task 2-way Split-Omniglot dataset. The results are averaged over 10 meta-test runs, showing the performance of each method under domain-incremental and class-incremental learning scenarios.", "section": "4.3 General Evaluation"}, {"figure_path": "yaYJlpidX1/tables/tables_21_1.jpg", "caption": "Table 10: 5-way classification accuracies using 15 examples for each class for each task in the context. 2-task models are meta-trained on Omniglot and Mini-ImageNet, while 3-task models are in addition meta-trained on FC100. \u2018A, B\u2019 in \u2018Context/Train\u2019 column indicates that models sequentially observe meta-test training examples of Task A then B; evaluation is only done at the end of the sequence. \"no ACL\" is the baseline 2-task models trained without the ACL loss.", "description": "This table shows the 5-way classification accuracies achieved by 2-task and 3-task models on various continual learning settings.  The models were meta-trained using Omniglot and Mini-ImageNet (2-task) and with the addition of FC100 (3-task). The \"Context/Train\" column shows the order in which tasks were presented. The results demonstrate the performance differences when using the proposed Automated Continual Learning (ACL) method versus a baseline without ACL.", "section": "4.1 Two-Task Setting: Comprehensible Study"}]