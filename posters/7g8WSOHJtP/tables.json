[{"figure_path": "7g8WSOHJtP/tables/tables_2_1.jpg", "caption": "Table 1: Revisiting the message passing in representative heterophilous GNNs under the perspective of HTMP mechanism.", "description": "This table revisits the message passing mechanisms in several representative heterophilous graph neural networks (HTGNNs) and categorizes them according to the unified heterophilous message-passing (HTMP) mechanism proposed in the paper.  It breaks down each method's message passing into three main components: the type of neighborhood indicators used, the type of aggregation guidance applied, how the messages from multiple neighborhoods are combined (COMBINE), and how the final node representations are fused across layers (FUSE). The table provides a structured overview to highlight the similarities and differences in how these HTGNNs process information during message passing, facilitating a comparative analysis and unified understanding of the methods.", "section": "3 Revisiting Message Passing in Heterophilous GNNs"}, {"figure_path": "7g8WSOHJtP/tables/tables_6_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across ten different datasets using thirteen graph neural network methods, including the proposed CMGNN.  The results are averaged over ten trials, with error bars representing the standard deviation. The best and second-best performing methods for each dataset are highlighted.  \"OOM\" indicates that the model ran out of memory during training.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study results (%) between CMGNN and three ablation variants, where SM denotes supplementary messages of the desired neighborhoods and DL denotes the discrimination loss.", "description": "This table presents the ablation study results comparing the performance of CMGNN against three variants: one without supplementary messages (SM), one without discrimination loss (DL), and one without both SM and DL. The results are shown in terms of node classification accuracy percentages (%) with standard deviations for various datasets, demonstrating the impact of the supplementary messages and the discrimination loss on the overall performance of CMGNN.", "section": "6.3 Ablation Study"}, {"figure_path": "7g8WSOHJtP/tables/tables_8_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy for 13 different graph neural network (GNN) methods across 10 benchmark datasets.  The accuracy is shown as a percentage, with error bars indicating standard deviations across 10 runs.  The best and second-best results for each dataset are highlighted.  The table also notes any instances where a model ran out of memory (OOM).  The datasets are characterized by different levels of homophily and various properties. The table provides a comprehensive performance overview to compare CMGNN against other GNN models.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_20_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across ten different datasets using thirteen different graph neural network models, including the proposed CMGNN.  The accuracy is expressed as a percentage, with error bars representing the standard deviation across ten runs. The best and second-best performing models for each dataset are highlighted.  OOM indicates that the model ran out of memory during training.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_22_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across ten different datasets using thirteen different graph neural network models, including the proposed CMGNN model.  The accuracy is represented as a percentage, and error bars indicate the standard deviation of the results obtained from ten independent trial runs. The best and second-best performing models for each dataset are highlighted.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_24_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across 10 different datasets for 14 different graph neural network models.  The accuracy is presented as a percentage, along with the standard deviation across 10 trials.  The best and second-best performing models for each dataset are highlighted.  OOM indicates that a model ran out of memory and could not complete the training process on that dataset.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_25_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across ten different datasets using thirteen different graph neural network models.  The accuracy is reported as a percentage, with error bars representing the standard deviation across ten trials. The best and second-best performing models for each dataset are highlighted.  OOM indicates that a model ran out of memory during training and could not complete the experiment.", "section": "6 Benchmarks and Experiments"}, {"figure_path": "7g8WSOHJtP/tables/tables_26_1.jpg", "caption": "Table 2: Node classification accuracy comparison (%). The error bar (\u00b1) denotes the standard deviation of results over 10 trial runs. The best and second-best results in each column are highlighted in bold font and underlined. OOM denotes out-of-memory error during the model training.", "description": "This table presents a comparison of node classification accuracy across 10 datasets and 13 different graph neural network methods.  The accuracy is presented as a percentage, averaged over 10 trials, with standard deviations indicated. The best and second-best performing methods for each dataset are highlighted.  OOM indicates that the model ran out of memory during training.", "section": "6 Benchmarks and Experiments"}]