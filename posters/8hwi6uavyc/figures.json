[{"figure_path": "8HwI6UavYc/figures/figures_1_1.jpg", "caption": "Figure 1: Our method enables prompt-driven object replacement for a variety of realistic 3D scenes.", "description": "This figure shows several examples of how the ReplaceAnything3D model can replace objects within a 3D scene using only text prompts.  The top row shows replacements in an outdoor setting, while the bottom row features replacements in a more contained, indoor-like setting.  Each example demonstrates the model's ability to seamlessly integrate a newly generated object into the existing scene, respecting lighting and shadows, and maintaining visual consistency.", "section": "1 Introduction"}, {"figure_path": "8HwI6UavYc/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of RAM3D Erase and Replace stages.", "description": "This figure shows the two main stages of the ReplaceAnything3D model (RAM3D): the Erase stage and the Replace stage.  The Erase stage uses a text-to-mask model (SAM) to identify and segment the object to be removed from the scene. Then, a text-guided 3D inpainting technique (HiFA) fills the empty space created by the removal, maintaining consistency across multiple views.  The Replace stage involves using a similar text-guided 3D inpainting technique to generate a new object based on user input text, and it composites the new object seamlessly into the inpainted background to create a coherent 3D scene.  The process utilizes a latent diffusion model (LDM) for image inpainting.", "section": "3 Method"}, {"figure_path": "8HwI6UavYc/figures/figures_5_1.jpg", "caption": "Figure 3: Left: Erase stage. The masked region (blue) serves as a conditioning signal for the LDM, indicating the area to be inpainted. The surrounding nearby pixels form the halo region h (green), which is also rendered by RAM3D during the Erase stage. The union of these 2 regions is the Bubble-NeRF region, whilst the remaining pixels are sampled from the input image (red). Right: Replace stage. RAM3D volumetrically renders the masked pixels (shown in blue) to give xfg. The result is composited with xbg to form the combined image x.", "description": "This figure illustrates the two-stage pipeline of the RAM3D model: the Erase stage and the Replace stage.  In the Erase stage, the model identifies the object to be removed using a mask (blue region). It then inpaints the background (pink region) using a combination of the masked region and the surrounding halo region (green). The Replace stage generates a new object (yellow stack of pancakes) based on the user's text prompt and composes it seamlessly into the inpainted background. The figure shows how the model renders the masked pixels and combines them with the inpainted background to create the final image.  The multiview consistency is maintained across all viewpoints of the 3D scene.", "section": "3 Method"}, {"figure_path": "8HwI6UavYc/figures/figures_5_2.jpg", "caption": "Figure 4: Left: Qualitative comparison with Reference-Guided Inpainting [28] (images adapted from the original paper) for object replacement. Right: Qualitative comparison with Blended-NeRF [12] for object replacement. Our method generates results with higher quality and capture more realistic lighting and details.", "description": "This figure compares the results of the proposed method, ReplaceAnything3D (RAM3D), against two other methods for object replacement in 3D scenes: Reference-Guided Inpainting and Blended-NeRF. The comparison highlights the superior quality and realism of RAM3D's results, especially in terms of lighting and detail.", "section": "Results"}, {"figure_path": "8HwI6UavYc/figures/figures_6_1.jpg", "caption": "Figure 5: Qualitative comparison with Gaussian Editor [35]. We show results for 3 challenging edit prompts on the GARDEN scene (top 2 rows) and FACE scene (bottom 2 rows). In the GARDEN scene, our method generates more realistic objects which are better integrated with the surrounding scene. In the FACE scene, our method generates more detailed texture patterns and geometry which are better aligned with the edit prompts.", "description": "This figure compares the results of the proposed ReplaceAnything3D (RAM3D) model with the Gaussian Editor model for three challenging image editing tasks.  The top two rows show results on the GARDEN scene, while the bottom two rows show results on the FACE scene.  The results demonstrate RAM3D's ability to generate more realistic and contextually appropriate objects compared to the Gaussian Editor, particularly with regard to texture detail and integration with the scene.", "section": "4 Results"}, {"figure_path": "8HwI6UavYc/figures/figures_7_1.jpg", "caption": "Figure 6: Given user-defined masks, ReplaceAnything3D can add completely new objects that blend in with the rest of the scene. Furthermore, due to its compositional structure, RAM3D can add multiple objects to 3D scenes while maintaining realistic appearance, lighting, and multi-view consistency (bottom right).", "description": "This figure demonstrates the ability of ReplaceAnything3D (RAM3D) to seamlessly integrate multiple, completely new objects into an existing 3D scene.  The objects are added using user-defined masks, ensuring that the added objects are realistically integrated with the existing scene's lighting, shadows, and overall coherence across multiple viewpoints.  The bottom right image showcases a particularly impressive example of this capability, with multiple objects added without disrupting the scene's integrity.", "section": "Results"}, {"figure_path": "8HwI6UavYc/figures/figures_8_1.jpg", "caption": "Figure 3: Left: Erase stage. The masked region (blue) serves as a conditioning signal for the LDM, indicating the area to be inpainted. The surrounding nearby pixels form the halo region h (green), which is also rendered by RAM3D during the Erase stage. The union of these 2 regions is the Bubble-NeRF region, whilst the remaining pixels are sampled from the input image (red). Right: Replace stage. RAM3D volumetrically renders the masked pixels (shown in blue) to give xfg. The result is composited with xbg to form the combined image x.", "description": "This figure illustrates the two-stage process of RAM3D: Erase and Replace.  The left side shows the Erase stage where the object to be removed is masked (blue), and the surrounding area (green) is also processed to ensure seamless integration. The new object is generated in the Replace stage (right). The blue region shows the new object being rendered, which is then composed with the inpainted background.", "section": "3 Method"}, {"figure_path": "8HwI6UavYc/figures/figures_15_1.jpg", "caption": "Figure 1: Our method enables prompt-driven object replacement for a variety of realistic 3D scenes.", "description": "This figure shows various examples of object replacement in realistic 3D scenes using text prompts.  The top row displays the original scene with the object to be replaced. The bottom row shows the same scene but with the original object replaced by a new object specified by a text prompt. This demonstrates the model's ability to seamlessly integrate new objects into existing scenes while maintaining 3D consistency. The variety of scenes and objects showcase the versatility of the proposed method.", "section": "1 Introduction"}, {"figure_path": "8HwI6UavYc/figures/figures_15_2.jpg", "caption": "Figure 9: STATUE Erase stage ablation: (SAM segmentation shown in purple). From Left to Right: No Halo supervision, No Depth Loss, Full model - which successfully removed the original statue.", "description": "This figure shows an ablation study on the Erase stage of the RAM3D model.  Three variations of the model are compared: one without halo supervision, one without depth loss, and the full model. The results, visualized using SAM segmentation (purple regions), demonstrate that the full model successfully removes the original statue and realistically fills in the background, while the other models fail to completely remove the statue.", "section": "3.3 Erase stage"}, {"figure_path": "8HwI6UavYc/figures/figures_16_1.jpg", "caption": "Figure 10: Users can personalize a 3D scene by replacing or adding their own assets using a fine-tuned RAM3D. We achieve this by first fine-tuning an inpainting diffusion model with five images of the target object (left), and then combining it with RAM3D to perform object replacement and addition with custom content.", "description": "This figure demonstrates the ability of the ReplaceAnything3D model (RAM3D) to be personalized using custom assets. By fine-tuning an inpainting diffusion model with five images of a target object, the model is then integrated into RAM3D for object replacement and addition, enabling users to seamlessly integrate their own assets into 3D scenes.", "section": "E Personalized ReplaceAnything3D"}, {"figure_path": "8HwI6UavYc/figures/figures_17_1.jpg", "caption": "Figure 11: Comparison with Instruct-NeRF2NeRF, a general scene-editing framework [3]. Note that unlike our method, Instruct-NeRF2NeRF modifies the entire scene, cannot synthesise complex texture patterns in the FACE scene and completely fails to generate a pineapple or chess piece object in the 360\u00b0 GARDEN scene.", "description": "This figure compares the results of the proposed method, ReplaceAnything3D (RAM3D), with the Instruct-NeRF2NeRF method for 3D scene editing.  It shows that RAM3D produces significantly better results, particularly in terms of maintaining scene consistency and generating complex textures.  Instruct-NeRF2NeRF struggles to produce high-quality results when dealing with objects that significantly differ from the original object in the scene, and it tends to change the entire scene instead of just the target object.", "section": "Additional qualitative comparisons"}, {"figure_path": "8HwI6UavYc/figures/figures_18_1.jpg", "caption": "Figure 12: Qualitative comparison with Collaborative Score Distillation (CSD) [32], ViCA-NeRF [31] and EfficientNeRF2NeRF [30]. All approaches apart from our RAM3D were unsuccessful in producing results with intricate texture details for both the checkered and tartan jackets. Results were obtained using official publicly available implementations. Note that in the case of CSD, there is no officially released 3D editing implementation at the time of writing. We therefore followed the official instructions to incorporate CSD image edits into the Instruct-NeRF2NeRF framework.", "description": "This figure compares the results of the proposed RAM3D method with three other methods (CSD, ViCA-NeRF, and EfficientNeRF2NeRF) for editing 3D scenes.  The comparison focuses on the ability of each method to realistically reproduce intricate textures, such as those found in tartan and checkered jackets.  The results demonstrate that RAM3D outperforms the other methods in accurately rendering these complex textures, showcasing its superior performance in 3D scene editing tasks.", "section": "4 Results"}, {"figure_path": "8HwI6UavYc/figures/figures_19_1.jpg", "caption": "Figure 13: Left: Qualitative comparison with RepaintNeRF [34] for object replacement. Figure adapted from the original RepaintNeRF paper. Right: Qualitative comparison with DreamEditor [10] for object addition (\"Add a red top hat\"). Figure adapted from the original DreamEditor paper.", "description": "This figure shows a comparison of the proposed method (ReplaceAnything3D) with two other methods for 3D object manipulation: RePaint-NeRF and DreamEditor.  The left side demonstrates object replacement using RePaint-NeRF and the proposed method, showing that the proposed method produces more realistic results. The right side compares the methods on object addition, where the proposed method again produces superior results in terms of realism and integration with the scene.", "section": "4 Results"}, {"figure_path": "8HwI6UavYc/figures/figures_20_1.jpg", "caption": "Figure 14: Qualitative comparisons between our method RAM3D (last column) with a naive 2D baseline method, which produces view-inconsistent results (third column). This is because each input image is processed independently and thus vary widely from each other (second column).", "description": "This figure compares the results of the proposed method, RAM3D, with a naive 2D baseline approach for object replacement. The 2D baseline processes each image individually using a pre-trained text-to-image inpainting model, leading to inconsistent results across different viewpoints.  RAM3D, in contrast, generates multi-view consistent results by considering all views during training, resulting in a more realistic and seamless object replacement.", "section": "Additional qualitative comparisons"}, {"figure_path": "8HwI6UavYc/figures/figures_20_2.jpg", "caption": "Figure 15: Results obtained using GaussianEditor to remove the vase object from the GARDEN scene. Note that GaussianEditor\u2019s proposed mask dilation and hole-fixing refinement stage causes a cloudy artifact to appear above the table, where the vase was originally placed. We therefore use the result on the left, prior to refinement, when adding new objects to replace the vase.", "description": "This figure shows the results of using GaussianEditor to remove a vase from a scene. The left image shows the result before a refinement step, while the right image shows the result after. The refinement step causes a cloudy artifact, so the result before refinement is used for comparison.", "section": "H Gaussian Editor Framework Limitations"}, {"figure_path": "8HwI6UavYc/figures/figures_21_1.jpg", "caption": "Figure 16: We observe that the Object Adding functionality of GaussianEditor does not place new objects into the scene in the correct position. The images on the left show the initial pineapple object placement (far from the table), output by GaussianEditor. The images on the right show the results after manually refining the position of the pineapple, by adjusting its depth along a ray passing through the centre of the reference image.", "description": "This figure shows the results of using GaussianEditor to add a pineapple to a scene.  The left side demonstrates that the tool initially places the pineapple incorrectly far from the table. The right side illustrates that manual intervention is needed to correct the placement using the software's interface for depth adjustment. This highlights a limitation of GaussianEditor where manual correction is needed to properly place newly added objects.", "section": "H Gaussian Editor Framework Limitations"}, {"figure_path": "8HwI6UavYc/figures/figures_21_2.jpg", "caption": "Figure 3: Left: Erase stage. The masked region (blue) serves as a conditioning signal for the LDM, indicating the area to be inpainted. The surrounding nearby pixels form the halo region h (green), which is also rendered by RAM3D during the Erase stage. The union of these 2 regions is the Bubble-NeRF region, whilst the remaining pixels are sampled from the input image (red). Right: Replace stage. RAM3D volumetrically renders the masked pixels (shown in blue) to give xfg. The result is composited with xbg to form the combined image x.", "description": "This figure illustrates the two-stage process of RAM3D: Erase and Replace.  The left panel shows the erase stage, where a mask (blue) defines the area to be removed.  The surrounding pixels (green) form a halo region used for consistent background reconstruction. The model inpaints the masked region using information from this halo and unmasked pixels (red). The right panel shows the replace stage, where a new object (xfg) is generated based on a text prompt and composited with the inpainted background (xbg) using alpha blending to create a seamless whole (x).", "section": "3 Method"}, {"figure_path": "8HwI6UavYc/figures/figures_23_1.jpg", "caption": "Figure 18: We show 2 failure cases for RAM3D. a) a challenging multi-object prompt results in an incoherent combination of both objects. b) we observe a multi-face problem which results in unrealistic geometry for the watermelon slice.", "description": "This figure demonstrates two failure cases of the ReplaceAnything3D model. The first case (a) shows that a prompt requesting multiple objects can lead to an incoherent combination of those objects.  The second case (b) shows that the model struggles with generating realistic geometry when the replaced object has multiple faces, as seen in the unrealistic watermelon slice.", "section": "J Limitations"}, {"figure_path": "8HwI6UavYc/figures/figures_23_2.jpg", "caption": "Figure 19: We show 2 additional failure cases for RAM3D. a): Editing object properties changes object identity. b): replacing the statue with much larger objects leads to degraded synthesis quality.", "description": "This figure shows two failure cases of the proposed RAM3D model. The first case (a) demonstrates that editing object properties, such as changing the color, can lead to a change in object identity, resulting in an incorrect object being generated. The second case (b) illustrates that replacing a smaller object with a much larger object can significantly reduce the quality of the generated result, producing unrealistic results and degrading the overall synthesis quality.", "section": "J Limitations"}]