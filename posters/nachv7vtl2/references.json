{"references": [{"fullname_first_author": "Bradley Efron", "paper_title": "Stein's paradox in statistics", "publication_date": "1977-05-01", "reason": "This paper introduces Stein's paradox, a key concept used to explain the surprising effectiveness of incorporating even unrelated surrogate data into model training."}, {"fullname_first_author": "Lawrence D Brown", "paper_title": "Asymptotic equivalence of nonparametric regression and white noise", "publication_date": "1996-06-01", "reason": "This paper establishes the asymptotic equivalence of nonparametric regression and the simpler white noise model, which simplifies the mathematical analysis of the proposed method."}, {"fullname_first_author": "Charles M Stein", "paper_title": "Estimation of the mean of a multivariate normal distribution", "publication_date": "1981-01-01", "reason": "This seminal paper provides foundational theoretical results for the Stein's paradox, which underpins the core insights of the present work on integrating real and surrogate data."}, {"fullname_first_author": "Alexandre B. Tsybakov", "paper_title": "Introduction to nonparametric estimation", "publication_date": "2009-01-01", "reason": "This book offers a comprehensive overview of nonparametric estimation methods, providing a theoretical foundation for the analysis of the weighted ERM approach used in this paper."}, {"fullname_first_author": "Joel Hestness", "paper_title": "Deep learning scaling is predictable, empirically", "publication_date": "2017-12-01", "reason": "This paper introduces scaling laws for deep learning, providing a framework that is adapted in the current study to incorporate surrogate data and predict optimal weighting schemes."}]}