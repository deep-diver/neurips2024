[{"figure_path": "QbqLcwMXfF/tables/tables_6_1.jpg", "caption": "Table 1: Temperature for each depth. Nodes with the same # of neighbors share the same temperature.", "description": "This table shows the temperature assigned to each node in a graph based on the number of neighbors it has.  Nodes with the same number of neighbors receive the same temperature. This is part of the Selective Self-Attention (SSA) layer's mechanism and its effect on the sparsity of the attention map.", "section": "4.1 The benefits of incorporating query embedding"}, {"figure_path": "QbqLcwMXfF/tables/tables_7_1.jpg", "caption": "Table 2: We apply normalization to attention output and compute the MSE risk.", "description": "This table presents the Mean Squared Error (MSE) risk for different methods in a denoising task. The task involves predicting a target vector using attention mechanisms. The table compares the MSE risk achieved by four different methods: Vanilla attention, Value-selective attention (the proposed method), Naive averaging, and Bayes optimal estimator.  The results highlight the superior performance of Value-selective attention in achieving a significantly lower MSE compared to the other methods, demonstrating its effectiveness in denoising.", "section": "4.3 The benefits of incorporating value embedding"}, {"figure_path": "QbqLcwMXfF/tables/tables_8_1.jpg", "caption": "Table 3: Experiment results for model pretraining and finetuning. For perplexity (ppl), lower is better, and for accuracy (acc), higher is better.", "description": "This table presents the results of experiments evaluating the performance of models with and without Selective Self-Attention (SSA) on various NLP benchmarks. The experiments involve both pre-training (training models from scratch) and fine-tuning (fine-tuning pre-trained models on downstream tasks).  The table shows the perplexity (ppl) and accuracy (acc) scores for several models (GPT-2, Pythia-160m, Pythia-410m, Llama, Llama3-8b) across multiple datasets (Wikitext, Lambada, Piqa, Hella, Winogrande, Arc-E, Arc-C).  Results are shown for the baseline models and models with SSA (both with and without weight sharing). Lower perplexity indicates better performance on language modeling, while higher accuracy indicates better performance on downstream classification tasks. The results demonstrate that SSA consistently improves model performance, even when using a weight-sharing strategy for parameter efficiency.", "section": "5.1 Standard Benchmarks"}, {"figure_path": "QbqLcwMXfF/tables/tables_9_1.jpg", "caption": "Table 4: Passkey retrieval performance of various models.", "description": "This table presents the results of passkey retrieval experiments using different models.  It shows the original performance of two models (Pythia-160m and Llama) on a passkey retrieval task, then compares those results to the performance of the same models after incorporating the proposed Selective Self-Attention (SSA) layer, both with and without a weight-sharing strategy. The passkey retrieval task measures a model's ability to locate a specific five-digit number within a larger body of text.  The results demonstrate a significant improvement in performance after incorporating SSA.", "section": "5.2 Passkey Retrieval"}, {"figure_path": "QbqLcwMXfF/tables/tables_14_1.jpg", "caption": "Table 5: Fine-tuning experiment results for language models on the Wikitext dataset, showcasing baseline and variations with different components (Q, K, V).", "description": "This table presents the results of fine-tuning various language models (Pythia and GPT2) on the Wikitext dataset.  The \"Baseline\" row shows the performance of the standard model. Subsequent rows show the impact of selectively applying temperature scaling to different components of the attention mechanism: the queries (Q), keys (K), and values (V). Each row indicates the model's performance after modifying the specified components. The table helps to demonstrate the individual and combined effects of applying temperature scaling to these components on the models\u2019 performance.", "section": "5.1 Standard Benchmarks"}, {"figure_path": "QbqLcwMXfF/tables/tables_15_1.jpg", "caption": "Table 6: Investigate the benefits of Token-aware Temperature Scaling, Position-aware Temperature Scaling.", "description": "This table presents the results of an ablation study investigating the impact of token-aware and position-aware temperature scaling on the Pythia and GPT-2 language models.  The \"vanilla\" column shows the baseline performance without temperature scaling.  Subsequent columns show the performance when applying only position-aware scaling (\u03c4pos), only token-aware scaling (\u03c4tok), both position-aware and token-aware scaling (\u03c4pos + \u03c4tok), and various combinations thereof, applied separately to the query (q) and value (v) components of the self-attention mechanism. The perplexity (ppl) scores are reported for the Wikitext dataset.", "section": "5.1 Standard Benchmarks"}, {"figure_path": "QbqLcwMXfF/tables/tables_15_2.jpg", "caption": "Table 3: Experiment results for model pretraining and finetuning. For perplexity (ppl), lower is better, and for accuracy (acc), higher is better.", "description": "This table presents the results of experiments conducted on various language models (GPT-2, Pythia-160m, Pythia-410m, Llama, Llama3-8b) for both fine-tuning and pre-training tasks.  The models were evaluated on several benchmarks (Wikitext, Lambada, Piqa, Hella, Winogrande, Arc-E, Arc-C), and the performance is measured using perplexity (ppl) and accuracy (acc).  Lower perplexity values indicate better performance in language modeling, while higher accuracy indicates better performance in downstream tasks. The table also includes results for variants of the models incorporating the Selective Self-Attention (SSA) mechanism and those employing a weight-sharing strategy to reduce computational overhead.", "section": "5.1 Standard Benchmarks"}, {"figure_path": "QbqLcwMXfF/tables/tables_16_1.jpg", "caption": "Table 8: Conducting different functions.", "description": "This table compares the performance of different temperature scaling strategies on the Pythia model, including the vanilla self-attention mechanism, Yarn's method, Constant, Frequency, and SSA.  The results are perplexity scores on the Wikitext dataset, showing that SSA achieves the lowest perplexity.", "section": "B Additional experiments"}]