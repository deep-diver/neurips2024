{"importance": "This paper is crucial for researchers working with LLMs in uncertain environments.  It introduces a novel approach for enhancing information seeking abilities, improving LLM performance on various tasks.  The proposed method, UoT, offers a principled framework with broad applicability and opens exciting avenues for future research in improving LLM efficiency and performance in complex, real-world applications.", "summary": "Uncertainty of Thoughts (UoT) algorithm significantly boosts LLMs' information-seeking abilities, leading to substantial performance gains across diverse tasks.", "takeaways": ["UoT algorithm significantly improves LLMs' ability to actively seek information by asking effective questions.", "UoT achieves an average performance improvement of 38.1% in successful task completion across various LLMs.", "The introduced benchmark and code are publicly available, facilitating further research and development."], "tldr": "Large Language Models (LLMs) often struggle in real-world scenarios with inherent ambiguity and incomplete information. Existing methods focus on improving reasoning within the given context, neglecting the crucial ability to actively seek missing information via effective questioning. This limitation hinders LLM performance in applications like medical diagnosis and troubleshooting, where acquiring necessary information is paramount. \nThe paper introduces \"Uncertainty of Thoughts\" (UoT), a novel algorithm that empowers LLMs to actively seek information by strategically asking questions. UoT combines an uncertainty-aware simulation, uncertainty-based rewards, and a reward propagation scheme.  Experimental results across multiple LLMs and diverse tasks show a substantial 38.1% average improvement in task success rate compared to direct prompting.  UoT demonstrates enhanced efficiency by reducing the number of questions needed for successful task completion.  The researchers also make their benchmark and code publicly available, fostering future research and development in this crucial area.", "affiliation": "National University of Singapore", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "CVpuVe1N22/podcast.wav"}