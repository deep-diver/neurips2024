[{"type": "text", "text": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in LLMs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhiyuan $\\mathbf{H}\\mathbf{u}^{1*}$ Chumin Liu2 Xidong Feng3 Yilun Zhao4 See-Kiong $\\mathbf{N}\\mathbf{g}^{1}$ Anh Tuan Luu2 Junxian He5 Pang Wei Koh6 Bryan Hooi1 ", "page_idx": 0}, {"type": "text", "text": "1 National University of Singapore 2 Nanyang Technological University 3 University College London 4 Yale University 5 The Hong Kong University of Science and Technology 6 University of Washington ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertaintybased rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the \u201820 Questions\u2019 game, UoT achieves an average performance improvement of $38.1\\%$ in the rate of successful task completion across multiple LLMs compared with direct prompting, and also improves efficiency (i.e., the number of questions needed to complete the task). Our code are released2. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As the capabilities of large language models (LLMs) grow, they are being increasingly deployed in challenging real-world settings involving uncertainty and ambiguity. In particular, recent work aims to develop LLM agents or assistants [36, 26] that effectively complete tasks in interactive environments, leading to a growing need for LLMs that can actively seek the information they need to solve a task by asking questions in conversational settings. For example, in medical diagnosis, patients often do not initially report their symptoms in full detail. In such situations, a doctor\u2019s ability to ask effective questions is crucial, as a successful diagnosis often depends on revealing important details that the patient did not initially provide (Figure 1). ", "page_idx": 0}, {"type": "image", "img_path": "CVpuVe1N22/tmp/51329b37a6e8b5334682bfb6fb90c07c1f28ce7242acbdd5290651526e26778e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Figure 1: The importance of information seeking in medical diagnosis. The patient initially only complains of a headache, but by asking the right questions, the doctor uncovers the critical information needed for a correct diagnosis. ", "page_idx": 0}, {"type": "text", "text": "Recent techniques aim to improve LLMs\u2019 reasoning or planning abilities based on the given information rather than enabling LLMs to seek information efficiently. For example, Chain-of-Thought (CoT) [35] and Tree-of-Thoughts (ToT) [38] allow LLMs to express intermediate \u2018thoughts\u2019 and reason over them. Unlike these methods, our focus is on enabling the LLM to ask questions effectively by explicitly guiding the model toward reducing uncertainty, which these do not consider. Thus, they lack effective signals for questions that better reduce uncertainty by revealing critical information. ", "page_idx": 1}, {"type": "text", "text": "To enhance LLMs in actively seeking information, we introduce Uncertainty of Thoughts (UoT), a plug-and-play approach that improves LLMs\u2019 abilities to ask useful questions by modeling their own uncertainty. UoT is a principled approach relying on uncertainty-based rewards motivated by information gain, which incentivizes a model to seek information in a way that maximally reduces the amount of information it does not know. To utilize these rewards, we develop an uncertainty-aware simulation framework, enabling the model to simulate possible future scenarios along with how likely they are to occur. Given these scenarios, we utilize a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. ", "page_idx": 1}, {"type": "text", "text": "Additionally, most standard benchmarks for LLMs, particularly in question answering, assume that all necessary information to solve a task is provided at the outset, and thus do not evaluate the model\u2019s active information-seeking capabilities. To close this gap, we first introduce a benchmark comprising 5 datasets3 on 3 tasks: 20 Questions, a simplified medical diagnosis task, and a basic troubleshooting task. These tasks are designed to measure the model\u2019s ability to ask questions effectively to gather the information they need. For example, the 20 Questions game, also studied by Noever et al.[22], requires the model to ask \u2018yes\u2019 or \u2018no\u2019 questions to determine an unknown object or entity. This scenario serves as a clear and easily analyzed test case, isolating the model\u2019s ability to recognize its own uncertainty, and to ask questions that guide it to the correct answer. ", "page_idx": 1}, {"type": "text", "text": "Our work is a step toward LLMs that can effectively operate in settings with high uncertainty and ambiguity, beyond conventional QA settings where all the information needed to solve the task is provided to the model at the outset. To the best of our knowledge, UoT is the first approach for enabling LLMs to ask effective questions by explicitly modeling and seeking to reduce their uncertainty. Our key contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "1. We introduce Uncertainty of Thoughts (UoT), a plug-and-play approach enabling LLMs to explicitly model and seek to reduce their uncertainty. UoT utilizes a principled approach based on an uncertainty-aware framework for simulating possible futures, rewards motivated by information gain, and a reward propagation scheme to select the optimal question to ask.   \n2. We introduce a benchmark of 3 tasks and 5 datasets, designed to evaluate the ability of LLMs to seek the information they need by asking questions.   \n3. Experiments show that UoT improves the success rate of multiple LLMs by $38.1\\%$ on average compared with direct prompting, achieving top performance on both task success and efficiency. Our benchmark and code are publicly available. ", "page_idx": 1}, {"type": "text", "text": "2 Methodology ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Problem Formulation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The problem setting involves two roles: the Questioner and the Answerer, performed by the LLM and a human, respectively. The goal of the Questioner is to deduce an unknown piece of information. We formulate this using a possibility space $\\Omega$ , which is the set of all possible options, of which a single element $\\omega\\ \\in\\ \\Omega$ , is the true option in each given scenario4. For example, in a medical diagnosis setting, $\\Omega$ is the set of all possible diseases relevant in the context, e.g., \u2126= {Bronchitis, Flu, . . . , Hypertension}, and for each patient, $\\omega$ is the actual disease of the patient. ", "page_idx": 1}, {"type": "image", "img_path": "CVpuVe1N22/tmp/13a8e4bca98c4d217842d4635f10d1df0ffacbfe0e03850a017d850433043785.jpg", "img_caption": ["Figure 2: UoT Overview: UoT includes three components: (a) Question Generation and Simulation, where an LLM proposes candidate questions and simulates future scenarios; (b) Uncertainty-based Rewards, measuring the uncertainty reduction from answers to a question, and (c) Reward Propagation computing accumulated rewards $R_{a}$ over past questions, and expected rewards $R_{e}$ capturing expected future gains. The process ends by choosing questions with the highest expected reward. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "The interaction between the Questioner and the Answerer occurs over multiple turns. For instance, the Questioner may ask, \u201cDo you have a fever?\", to which the Answerer responds, \u201cYes, I\u2019ve had a high fever for the past two days.\" The Questioner then asks another question such as \u201cHave you vomited?\" This exchange continues either until the Questioner correctly determines the final answer, or the conversation reaches a maximum number of turns. At this point, the interaction ends, and the Questioner is successful if it has correctly determined the true option $\\omega$ . ", "page_idx": 2}, {"type": "text", "text": "Most of the description of our approach focuses on the closed set scenario, in which we assume that the Questioner starts with knowledge of the possibility space $\\Omega$ , e.g., the set of all possible diseases in medical diagnosis. In our extension section 2.7, we adapt our approach to the open set scenario, in which this knowledge is absent. Moreover, as the questioning progresses, we use an LLM to gradually refine this set of possibilities to those that are consistent with the current answers given so far by the Answerer. Define the current possibility set $\\Omega_{i}$ as the subset of $\\Omega$ that is consistent with all answers given by the Answerer before the start of the ith interaction step. ", "page_idx": 2}, {"type": "text", "text": "As we discuss more later, we focus on applications where answers can be grouped into a small number of semantically distinct categories (in our case, affirmative and negative responses), as this allows us to compute meaningful uncertainty metrics in a simpler way. Conceptually, our framework can straightforwardly be extended to allow for a wider selection of answers. ", "page_idx": 2}, {"type": "text", "text": "2.2 Uncertainty of Thoughts: Overview ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As Figure 2 shows, to effectively reduce uncertainty, our UoT method first generates multiple questions as candidates to ask, and simulates possible futures for each one in the form of a tree structure. Next, uncertainty-based rewards, motivated by information gain, are used to assess the questions within the simulation. Finally, a reward propagation scheme is used to compute the expected reward from asking each candidate question, allowing us to select the one with highest expected reward, to ask the Answerer. ", "page_idx": 2}, {"type": "text", "text": "2.3 Question Generation and Simulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "UoT starts by using an LLM to generate several candidate questions, then simulates future scenarios for each one. This simulation process allows us to measure how much information we can expect to gain in the next few steps from each question, and thus to choose the most suitable question. ", "page_idx": 2}, {"type": "text", "text": "Question Generation Recall that our setting involves sequential interactions between a Questioner (e.g., a chatbot) and an Answerer (e.g., a human patient). During the ith interaction step, the Questioner generates candidate questions, then selects one of these to ask, denoted as $q_{i}$ . ", "page_idx": 2}, {"type": "text", "text": "To generate candidate questions to ask, UoT uses two inputs: (1) the history of past interactions $h_{i}=\\left\\{q_{1},a_{1},q_{2},a_{2},\\ldots,q_{i-1},a_{i-1}\\right\\}$ , comprising the sequence of past questions and answers; and (2) the current possibility set $\\Omega_{i}$ . These two inputs are combined to form a prompt that includes instructions explaining the nature of the task (e.g., how the 20 Questions game works), provides the current history $h_{i}$ and the current possibility set $\\Omega_{i}$ , and asks an LLM to generate $m$ candidate next questions, conditioned on the previous context. This prompt, denoted as Prompt $_\\mathrm{gen}(h_{i},\\Omega_{i})$ , is fed to our generator $\\mathsf{L L M}_{\\mathtt{g e n}}$ , which then generates $m$ candidate questions, denoted $q_{i}^{1},q_{i}^{2},\\ldots,q_{i}^{m}$ : ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nq_{i}^{1},q_{i}^{2},\\dotsc,q_{i}^{m}=\\mathsf{L L M}_{\\mathsf{g e n}}(\\mathsf{P r o m p t}_{\\mathsf{g e n}}(h_{i},\\Omega_{i}))\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Multistep Simulation As shown in Figure 2 (a), the Question Generation stage generates candidate questions such as $q_{i}^{1}=$ \u201cDid you vomit?\" Next, during Simulation stage, for each such generated candidate question, we simulate possible futures for a few steps, forming a tree of possibilities. This process enables us to compute rewards for each question, helping us to decide which question to ask. ", "page_idx": 3}, {"type": "text", "text": "Each node of the tree can be one of two types: Answerer Nodes where it is the Answerer\u2019s turn to answer a question, and Questioner Nodes where it is the Questioner\u2019s turn to ask a question. At the root, a question has just been asked (e.g., $q_{i}^{1}$ ), so the root is an Answerer Node. Next, we explain how to construct tree by recursively expanding (or \u2018branching\u2019) each node to construct its children, i.e., starting from the root, then proceeding to its children, and so on. ", "page_idx": 3}, {"type": "text", "text": "\u2022 At each Answerer Node, a question has just been asked. Next, we need to further \u2018branch\u2019 the tree based on the possible answers to the current question. Rather than allowing completely open-ended answers, we instead focus on affirmative and negative responses5, as this allows us to compute meaningful uncertainty metrics, as we discuss later. Hence, we branch the node into two children, corresponding to affirmative and negative answers. ", "page_idx": 3}, {"type": "text", "text": "\u2022 At each Questioner Node, we prompt an LLM to generate $m$ questions using the current history and possibility set, in the same way as in the Question Generation step. Note that while the generation procedure is similar, the purpose is different: the Question Generation step generates candidate questions to select from, while here we are generating simulated questions to form a tree for the purpose of evaluating the current question. The resulting $m$ generated questions are added to the tree as children of the current node. ", "page_idx": 3}, {"type": "text", "text": "In this way, we recursively generate tree nodes, stopping at a fixed number of levels (i.e., depth). ", "page_idx": 3}, {"type": "text", "text": "While generating this tree, we also recursively compute the current possibility set $\\Omega_{v}$ at each node $v$ . Specifically, let $h_{v}$ be the current conversation history up to node $v$ , combining both the actual conversation history $h_{i}$ and the simulated conversation up to node $v$ . Then the current possibility set at this node, denoted $\\Omega_{v}$ , is the subset of the possibility space consistent with $h_{v}$ . At the root, the current possibility set is only limited by the actual conversation history, i.e., $\\Omega_{i}$ . Then, as we proceed over the simulated tree, note that the current possibility set only changes at Answerer nodes, when an answer is added to the current history. Hence, at each Answerer node $v$ , we prompt a new LLM (an \u2018Answerer Simulator\u2019 $\\mathsf{L L M}_{\\mathsf{a n s}})$ ), to determine the further subset $\\Omega_{v}^{A}\\subseteq\\Omega_{v}$ for which the answer to the current question is affirmative, and the corresponding $\\Omega_{v}^{N}=\\bar{\\Omega}_{v}\\setminus\\Omega_{v}^{A}$ for which the answer is negative.6 This allows us to recursively compute the possibility sets of the children of $v$ (which themselves correspond to the affirmative and negative answers). ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Omega_{v}^{A},\\Omega_{v}^{N}=\\mathsf{L L M}_{\\mathsf{a n s}}(\\mathsf{P r o m p t}_{\\mathsf{a n s}}(h_{v},\\Omega_{v}))\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In this way, we can recursively compute the possibility set on each node of the tree. ", "page_idx": 3}, {"type": "text", "text": "2.4 Uncertainty-Based Reward Calculation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To develop suitable information-seeking approaches, a critical question is how to evaluate the effectiveness of a question, i.e., its contribution to reducing uncertainty. To address this, we turn to information theory, specifically the concept of information gain, which measures the amount by which uncertainty decreases after a particular observation. To reward information-seeking behavior, we assign rewards to questions based on how much they reduce the model\u2019s uncertainty about the unknown random variable. These reward signals are used by our UoT framework to determine which question to select, to maximize the reduction of uncertainty. ", "page_idx": 3}, {"type": "text", "text": "Entropy. Entropy and information gain are well-known concepts in information theory [29]. In our work, we use these concepts to measure how much information is gained (or equivalently, how much uncertainty is reduced) by asking a question, to formulate our rewards. Entropy measures the level of uncertainty in a random variable: higher entropy indicates greater uncertainty. The entropy of a discrete random variable $X$ taking values $x_{1},...,x_{n}$ is: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nH(X)=-\\sum_{i=1}^{n}p(x_{i})\\log p(x_{i})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Since our goal is to reduce the uncertainty in the unknown $\\omega\\,\\in\\,\\Omega$ , we use entropy to measure this uncertainty. Formally, let $\\Omega=\\{\\omega_{1},\\cdot\\cdot\\cdot,\\omega_{n}\\}$ , and we define an additional set of arbitrary real numbers $\\mathcal{X}=\\left\\{x_{1},\\cdot\\cdot\\cdot\\,,\\dot{x}_{n}\\right\\}\\subseteq\\mathbb{R}$ which we will associate with each of these possibilities. Define a random variable $X:\\Omega\\to\\chi$ such that $X(\\omega_{i})=x_{i}$ . Intuitively, $X$ is a discrete random variable that takes the value $x_{i}$ if the $i$ th possibility is true, i.e., if $\\omega=\\omega_{i}$ . $X$ serves to capture our uncertainty about $\\omega$ , since observing $X$ is equivalent to observing the true option $\\omega$ . As a simple example, suppose our possibility space is $\\Omega=\\{\\omega_{1},\\omega_{2},\\omega_{3}\\}$ ; we accompany these with real numbers $x_{1},x_{2},x_{3}$ , and have a distribution for our random variable $X$ reflecting prior beliefs over these possibilities: e.g., $p(x_{1})=0.2$ , $p(x_{2})=0.3$ , $p(x_{3})=0.5$ . Conceptually, our framework allows for any prior probability distribution over the possibilities (i.e., $p(x_{i}))$ , but in our experiments, we assume a uniform distribution over them due to the lack of an informative prior. ", "page_idx": 4}, {"type": "text", "text": "Before asking any questions, our uncertainty about the unknown $\\omega$ is given by $H(X)$ , as in Eq. (3). At any node $v$ of the trees described in the previous section, recall that we have a conversation history $h_{v}$ which contains some answers given by the Answerer. This history limits the current possibility set to those in $\\Omega_{v}\\subseteq\\Omega$ , thereby reducing our uncertainty. We model this using the standard notion of conditional probability on an event: since $\\Omega_{v}\\subseteq\\Omega$ , thus $\\Omega_{v}$ is an event which we can condition on: ", "page_idx": 4}, {"type": "equation", "text": "$$\np(x_{i}|\\Omega_{v})=p(x_{i})/p(\\Omega_{v})\\;\\;\\;\\forall\\;i\\;\\mathrm{such}\\;\\mathrm{that}\\;\\omega_{i}\\in\\Omega_{v}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $p(\\Omega_{v})$ is the sum of probabilities of the elements in $\\Omega_{v}$ . To illustrate, we continue from the earlier example, where $p(x_{1})=0.2$ , $p(x_{2})=0.3$ , $p(x_{3})=0.5$ . If the conversation history $h_{v}$ at node $v$ is only consistent with $x_{1}$ and $x_{2}$ , i.e., $\\boldsymbol{\\Omega}_{v}=\\{\\omega_{1},\\omega_{2}\\}$ , we can adjust probability distribution by conditioning: e.g., the adjusted probability of $x_{1}$ is $p(x_{1})/p(\\Omega_{v})=0.2/(0.2+0.3)=0.4$ . ", "page_idx": 4}, {"type": "text", "text": "Next, to quantify the uncertainty at node $v$ , note that since $X$ is conditionally distributed based on $p(\\cdot|\\Omega_{v})$ , the entropy of this distribution is: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{v}(X):=\\sum_{i:\\omega_{i}\\in\\Omega_{v}}p(x_{i}|\\Omega_{v})\\log p(x_{i}|\\Omega_{v})}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Intuitively, $H_{v}(X)$ is the remaining uncertainty in $X$ at node $v$ (i.e., after observing the history $h_{v}$ ). ", "page_idx": 4}, {"type": "text", "text": "Information Gain at a Node We now quantify the uncertainty reduction when receiving answers at an Answerer node $v$ . Recall that the answer given at $v$ partitions $\\Omega_{v}$ into two disjoint subsets: $\\Omega_{v}\\,=\\,\\Omega_{v}^{A}\\cup\\Omega_{v}^{N}$ , where $\\Omega_{v}^{A}$ and $\\Omega_{v}^{N}$ are the subsets of possibilities resulting in affirmative and negative answers to last asked question. Given an affirmative answer, the remaining entropy becomes: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{v}^{A}(X):=\\sum_{i:\\omega_{i}\\in\\Omega_{v}^{A}}p(x_{i}|\\Omega_{v}^{A})\\log p(x_{i}|\\Omega_{v}^{A})}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We define $H_{v}^{N}(X)$ analogously for negative answers. Let $p_{v}^{A}\\ =\\ p(\\Omega_{v}^{A})/p(\\Omega_{v})$ and $p_{v}^{N}~=$ $p(\\Omega_{v}^{N})/p(\\Omega_{v})$ be the conditional probabilities of affirmative and negative answers at node $v$ . To compute the expected entropy after receiving the answer at node $v$ , since we have a $p_{v}^{A}$ probability of receiving an affirmative answer and $p_{v}^{N}$ of a negative answer, the expected entropy is: ", "page_idx": 4}, {"type": "equation", "text": "$$\np_{v}^{A}\\cdot H_{v}^{A}(X)+p_{v}^{N}\\cdot H_{v}^{N}(X)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As such, the expected information gain at node $v$ is the difference in entropies before and after receiving the answer: ", "page_idx": 4}, {"type": "equation", "text": "$$\nI G_{v}(X):=H_{v}(X)-p_{v}^{A}\\cdot H_{v}^{A}(X)-p_{v}^{N}\\cdot H_{v}^{N}(X)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We can simplify this: as proven in Appendix A, the above equation reduces to: ", "page_idx": 4}, {"type": "equation", "text": "$$\nI G_{v}(X)=-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This represents the expected reduction of uncertainty in $X$ when receiving an answer at node $v$ . Note that it has an entropy-like expression, and is therefore nonnegative. ", "page_idx": 4}, {"type": "text", "text": "Reward Formulation A natural approach would be to define the reward function $R_{u}(v)$ at node $v$ as the information gain $I G_{v}(X)$ : that is, the reward from the question at node $v$ is the expected information gain $I G_{v}(X)$ from receiving its answer. In practice, we find that a slightly modified function $\\widetilde{I G}_{v}(X)$ is preferable. In particular, we find that $I G_{v}(X)$ does not result in sufficiently sharp differences in reward over the typical ranges we encounter. Hence, we introduce an additional hyperparameter $\\lambda\\geq0$ which helps to sharpen the rewards using a scaling approach. We compare other scaling methods and determine the current design is optimal in performance and their corresponding benefits. Details are in the Appendix B. ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{u}(v)=\\widetilde{I G}_{v}(X):=(-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N})/(1+\\lambda^{-1}|p_{v}^{A}-p_{v}^{N}|)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This definition ensures that $R_{u}(v)$ falls within the range $[0,1]$ , providing a normalized and consistent reward to measure uncertainty reduction. The reward function reaches its maximum when the subsets $\\Omega_{v}^{A}$ and $\\Omega_{v}^{N}$ have equal probability, reflecting the maximum reduction in uncertainty. It reaches its minimum when one of the subsets has zero probability, indicating no reduction in uncertainty. Appendix $\\mathrm{G}$ plots the reward function curve across values of $p_{v}^{A}$ and $\\bar{p_{v}^{N}}$ . ", "page_idx": 5}, {"type": "text", "text": "2.5 Question Selection Via Reward Propagation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Single-step rewards often fall short in dynamic settings as they only consider immediate impact, overlooking long-term effects. To overcome this, our method uses a reward propagation scheme across simulation trees by defining \u2018accumulated rewards\u2019 that gather rewards over multiple simulation steps to reflect the effectiveness of past decisions. These accumulated rewards help compute \u2018expected rewards\u2019, indicating the likely beneftis of the questions and guide the selection of candidate questions. ", "page_idx": 5}, {"type": "text", "text": "Accumulated Reward We first define the accumulated reward at each node $v$ , which accumulates the rewards at $v$ and all its ancestors on the tree, defined recursively as: ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{a}(v):=R_{u}(v)+{\\left\\{\\begin{array}{l l}{0}&{v{\\mathrm{~is~root}}}\\\\ {R_{a}({\\mathsf{P a r e n t}}(v))}&{{\\mathrm{otherwise}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here $R_{u}(v)$ is the uncertainty-based reward at node $v$ defined in Eq. (10), and $R_{a}(\\mathsf{P a r e n t}(v))$ is the accumulated reward of the parent of $v$ . We compute these accumulated rewards by starting at the root and propagating down to the leaves. Intuitively, the accumulated reward at each leaf node represents the total reward we end up with at the end of the conversation at that node. ", "page_idx": 5}, {"type": "text", "text": "Expected Reward Next, we compute the expected reward for each node $R_{e}(v)$ , which represents the expected total value of rewards received on expectation on a node and all its descendants on tree. ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{e}(v):=\\left\\{\\begin{array}{l l}{R_{a}(v)}&{\\mathrm{if~}v\\mathrm{~is~a~leaf;otherwise:~}}\\\\ {p_{v}^{A}R_{e}(v^{A})+p_{v}^{N}R_{e}(v^{N})}&{\\mathrm{if~}v\\mathrm{~is~an~Answerer~Node}}\\\\ {\\frac{1}{m}\\sum_{w\\in\\mathsf{C h i l d r e n}(v)}^{m}R_{e}(w)}&{\\mathrm{if~}v\\mathrm{~is~a~Questioner~Node}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For the case where $v$ is an Answerer Node, recall that $p_{v}^{A}$ and $p_{v}^{N}$ are the conditional probabilities of affirmative and negative answers at node $v$ , defined in section 2.4. $v^{A}$ and $v^{N}$ are its children, corresponding to the affirmative and negative answers. For the case where $v$ is a Questioner Node, we assign equal probability to the $m$ questions asked from this node. In this way, we propagate the expected rewards from the leaves up to the root, allowing us to compute the expected gain at the root. We compare different reward propagation schemes and find that using cumulative rewards from all paths enhances long-term decision-making benefits. See Appendix $\\mathbf{C}$ for details. ", "page_idx": 5}, {"type": "text", "text": "Determining the Optimal Question Finally, to decide the question to ask, we select the question with highest expected reward (and therefore, the highest expected information gain, considering both immediate and future information gains): ", "page_idx": 5}, {"type": "equation", "text": "$$\nq_{i}=\\arg\\operatorname*{max}_{n=1}R_{e}(q_{i}^{n})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "2.6 UoT Summary ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "UoT first generates candidate questions $q_{i}^{1},q_{i}^{2},\\ldots,q_{i}^{m}$ based on the history $h_{i}$ and current possibility set $\\Omega_{i}$ . Then, we conduct multistep simulation to generate a tree for each candidate question $q_{i}^{n}$ . Next, we compute the uncertainty-based rewards $R_{u}(v)$ , and propagate over the trees to compute accumulated reward $R_{a}(v)$ and expected reward $R_{e}(v)$ . Lastly, the optimal question $q_{i}^{n}$ with highest expected reward will be selected as $q_{i}$ to interact with the Answerer. UoT generates candidate questions $q_{i}^{1},q_{i}^{2},\\ldots,q_{i}^{m}$ based on history and the current possibility set $\\Omega_{i}$ . It simulates a tree for each question, calculates uncertainty-based rewards $R_{u}(v)$ , and computes expected rewards $R_{e}(v)$ . The question $q_{i}^{n}$ with the highest expected reward is chosen for interaction. ", "page_idx": 6}, {"type": "text", "text": "2.7 Extensions and Discussion ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Open Set UoT. Recall that in the closed set scenario, the Questioner starts with knowledge of the possibility space $\\Omega$ . In practice, the possibility space is often unknown, resulting in the open set setting. To adapt UoT to this case, we prompt Questioner to initialize the possibility space $\\Omega$ and then reinitialize the possibility set $\\Omega_{i}$ according to current history $h_{i}$ . Then, the rest of UoT is unchanged. The generalization in open-end answers. The UoT framework enables LLMs to update possibilities after each interaction, including affirmative/negative or open-ended responses. Thus, it can be applied to open-ended answers scenarios. Pruned UoT. To enhance efficiency during simulation, pruning akin to Beam Search can be employed when constructing the simulation trees, which limits the number of paths to explore over the tree to a predetermined size. ", "page_idx": 6}, {"type": "text", "text": "3 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "3.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Models We test various LLMs to evaluate the generality of our method, including Llama-3-70BInstruct [1], Mistral-Large [21], Gemini-1.5-Pro [28], Claude-3-Opus [4] and GPT-4 [24]. We also validate the performance of earlier released LLMs (Refer to Appendix D) including Llama 2-70B-Chat [32], Cohere [9], PaLM 2 [2], Claude 2 [3] and GPT-3.5-turbo [23]. ", "page_idx": 6}, {"type": "text", "text": "Baselines Direct Prompting (DP) prompts an LLM directly to generate the next response. Planning Prompting (PP) is motivated by Wang et al.[33]. We leverage another LLM to plan the future and, consequently, determine the question to ask. Chain-of-Thought (CoT) [35] improves reasoning in LLMs by detailing reasoning steps. CoT-SC (Self-Consistency) [34] an is an ensemble method, explores multiple reasoning paths. We standardize sampling counts for fair computational cost comparison with other methods. Reflexion [30] lets agents propose actions and self-assess to foster new ideas. Tree-of-Thoughts (ToT) [38] enables LLMs to make decisions by exploring and evaluating multiple reasoning paths over a tree structure. We examine ToT under two setups: Original-ToT, which uses the standard approach of generating and evaluating questions, and Adapted-ToT (Ad.- ToT), where we integrate heuristic experience into prompt for question generation and evaluation, focusing on questions that halve the search space. We matched the tree depth to the simulation steps in our UoT method for a fair comparison. We evaluate methods and LLMs in both open set (OS) and closed set (CS) settings. In open set, models are tested without prior knowledge of outcomes; in closed set, they are given complete information about all possible outcomes. For details, see Appendix I.1 for experimental settings and Appendix L for prompts. ", "page_idx": 6}, {"type": "text", "text": "Scenarios and Datasets 20 Questions is a game where the answerer thinks of an item and the questioner asks up to 20 yes-or-no questions to guess it. We use two datasets, Common (collected by us, refer to Appendix I.2 for more details) and Things [14], including 111 and 1854 items separately. In this scenario, the maximal turns is set to 20. In Medical Diagnosis, the doctor needs to ask questions to patients about their symptoms, to determine an accurate diagnosis. We use two datasets: DX [37], with 104 doctor-patient dialogues and 5 diseases in test set, and MedDG [19] with over 17K conversations across 15 disease types. We manually selected 500 high-quality samples for evaluation (see Appendix I.3 for selection process). Importantly, Open-ended responses from patient are allowed in MedDG to validate UoT\u2019s generalization in open-ended scenarios. Both datasets are limited to 5 turns. Troubleshooting is a scenario where a customer support technician interacts with customers to identify and resolve faults or issues within computer systems, electronic devices, machinery, or other complex systems. Raghu et al.[27] introduce FloDial with 894 dialogues, containing 153 faults and we also conduct the data preprocessing of FloDial (See Appendix I.4 for details). We evaluate using a maximum of 20 turns. The answerer, simulated by GPT-4, is prompted with the patient\u2019s actual disease and conversation details for each case. For more details, refer to Appendix I.2 and see examples of these scenarios in Appendix K. ", "page_idx": 6}, {"type": "table", "img_path": "CVpuVe1N22/tmp/d10a77fb3081fc8cd59b304c0254325630e3d7720f245ef49a8aa63762188f66.jpg", "table_caption": ["Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "UoT (Open Set) Setup We iteratively update LLMs\u2019 perceived possibilities based on conversational history, rather than defining them all upfront. In medical diagnosis and troubleshooting, initial descriptions from symptoms or issues help set up initial possibilities. In the 20-question game, we start with broad inquiries using the Direct Prompting method for the first three rounds to gather more information. The ToT tree structure method employs a similar strategy. Setup details in Appendix I.5. ", "page_idx": 7}, {"type": "text", "text": "Evaluation Metrics To measure efficacy and efficiency, we use: Success Rate $(\\%)$ : $\\mathbf{S}\\mathbf{R}=S/T$ , where $S$ is the number of successful cases, and $T$ is the total number of cases; Mean Conversation Length in Successful Cases: $\\mathbf{MSC}=R_{s}/S$ , where $R_{s}$ is the total rounds in successful cases; Mean Conversation Length: $\\mathbf{MCL}=R/T$ , where $R$ is the total rounds in all cases. MCL measures efficiency based on the resources used in both successes and failures. ", "page_idx": 7}, {"type": "text", "text": "3.2 Performance ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "20 Questions As illustrated in Table 5, for all types of LLMs, those equipped with UoT outperform the baselines in both open set and close settings. Among the methods used on GPT-4 to enhance planning and reasoning, CoT (CS) and PP (CS) show inferior performance even compared to GPT-4 alone. UoT (OS) demonstrates superior performance, with with an average $8.7\\%$ improvement than Adapted-ToT (OS) in success rate. Moreover, UoT (CS) achieves the highest success rate, surpassing the second-best Reflexion by an average of $4.3\\%$ . ", "page_idx": 7}, {"type": "text", "text": "Medical Diagnosis UoT (CS) outperforms baselines in simplified medical diagnostics, achieving a $97.0\\%$ success rate on the DX dataset with GPT-4. On the MedDG dataset, UoT (CS) on Gemini1.5-Pro and GPT-4 achieve success rates of $81.4\\%$ and $88.0\\%$ . It also reduces conversation lengths to an average MSC of 2.0 on GPT-4 for DX, lower than 3.5 and 3.0 for DP methods. These results demonstrate the versatility of our UoT in handling both binary and open-ended interactions effectively. ", "page_idx": 7}, {"type": "text", "text": "Troubleshooting UoT (CS) with GPT-4 similarly achieves the highest SR of $67.3\\%$ , and the lowest MSC of 7.8. It also shows a remarkable improvement from $43.7\\%$ to $67.3\\%$ in Success Rate. ", "page_idx": 8}, {"type": "text", "text": "Overall Performance On average, UoT enhances the success rate by $38.1\\%$ compared to DP across 5 datasets and 5 different LLMs, including open source and commercial models. Notably, Success Rate increases $46.6\\%$ for Llama3-70B. Furthermore, UoT outperforms CoT-SC by $33.8\\%$ and Reflexion by $29.9\\%$ . Even compared to tree structure methods like Original-ToT and Adapted-ToT, UoT still shows superior performance with gains of $28.3\\%$ and $12.4\\%$ respectively. Additionally, Pruned UoT, our pruning method to improve efficiency, outperforms Adapted-ToT by $7.36\\%$ . Additionally, our study shows that UoT\u2019s one-step planning is effective due to effective reward design and question selection. We limit simulations to three steps for budgetary reasons, balancing efficiency and effectiveness (see Appendix E for further details on simulation depth). To determine whether the differences in success rates between the two methods were statistically significant, we performed a t-test. The results and details are in Appendix H. ", "page_idx": 8}, {"type": "text", "text": "Case Studies and Reliability of GPT-4 as answerer Figure 3 shows UoT, compared to direct prompting, more effectively reduce uncertainty and narrow down candidates, avoiding overly specific queries. After gaining initial information (e.g., stomach pain), it generates targeted questions about related issues rather than general inquiries. Additionally, GPT-4\u2019s accuracy as answerer is evaluated by analyzing $10\\%$ of interactions from each dataset, consistently showing reliable responses. For quantitative details, see Appendix F. ", "page_idx": 8}, {"type": "text", "text": "3.3 Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "3.3.1 Comparing Model Performance at Equal Computational Efficiency ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We compare the performance of approaches with similar computational costs in a closed set setting, in terms of token consumption. To do so, we first prune our UoT as described in section 2.7. Secondly, we expand exploration depth of Adapted-ToT method to bring its token cost in line with that of UoT. ", "page_idx": 8}, {"type": "text", "text": "As shown in the top half of Table 2, the Pruned UoT method, despite its reduced efficacy compared to UoT, still outperforms ToT and other methods. Also, the bottom part of Table 2 shows that even when increasing the depth of Adapted ToT (Adapted-ToT $D=4)$ ) to match the token cost of UoT $\\mathcal{D}=3$ ), it still underperforms compared to UoT. ", "page_idx": 8}, {"type": "text", "text": "3.3.2 Effectiveness of Uncertainty Rewards ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To further demonstrate the effectiveness of our uncertainty-based reward, we compare it with the self-evaluation reward used in the original ToT based on GPT-4 model. We implement the uncertaintybased reward in place of the self-evaluation reward in ToT, creating a variant we call ToT $\\mathbf{\\mu+UR})$ . The results, as shown in left side of Figure 4, indicate that our reward significantly enhances planning efficacy by an average of $5.9\\%$ . Additionally, we use the heuristic self-evaluation reward in AdaptedToT to replace our current uncertainty-based reward in UoT, a variant we refer to as UoT (-UR). This change results in a performance decrease shown in the right part of Figure 4, further validating the effectiveness of our uncertainty-based reward. Moreover, the performance of UoT (-UR) still surpasses that of Adapted-ToT illustrated in Table 5, ", "page_idx": 8}, {"type": "image", "img_path": "CVpuVe1N22/tmp/e0e6479cde94c581655482e44de4a409ea0990e375bcddf98224b9899562ab7b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "CVpuVe1N22/tmp/cc04b762fa1903a4b5be39c2e9be5d72aa5ae261a121117fadbead03cef59345.jpg", "table_caption": ["Table 2: Average success rates for 20Q, MD, and TB at comparable efficiency, measured by GPT-4 token use. $k$ is sampling count, $D$ is tree depth. "], "table_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "CVpuVe1N22/tmp/7fbbfe848555c91371b6d439b5ee8249e057be92ed5de4753ca52ed5e9b6a61f.jpg", "img_caption": ["Figure 4: Success rate comparison between Adapted-ToT and Adapted-ToT using uncertainty reward, and between UoT and UoT without uncertainty reward. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "4 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Planning and Reasoning of LLMs LLMs show prowess in planning and reasoning. Wei et al.[35] introduced CoT prompting for intermediate reasoning; Yao et al.[38] proposed ToT prompting using DFS/BFS. Besta et al.[6] present GoT to solve elaborate problems. Feng et al.[12] illustrated TSLLM\u2019s tree-search guided decoding. ReAct [39] offers acting-based prompting, while Reflexion [30] enhances this with feedback reflection. Zhou et al.[41] unify reasoning and planning. ", "page_idx": 9}, {"type": "text", "text": "Decision-making and Information-seeking by LLMs LLMs have evolved as decision-making tools, with models like LLM $+\\mathrm{P}$ [18] and LLM-DP [10] combining external planners and LLMs for natural language-based programming. RAP [13] goes beyond structured language, using LLMs with Monte Carlo Tree Search (MCTS) [7] for dynamic decision-making. This approach is also seen in the work of Zhao et al.[40], applying MCTS and LLM knowledge for complex tasks like robot control. However, MCTS struggles in uncertain scenarios due to its reliance on terminal states and specific modules for rewards and action selection. Additionally, to enhance LLMs\u2019 questioning abilities, Deng et al.[11] introduce the Rephrase and Respond method. AVIS [15] represents an autonomous visual question answering system that uses external tools. Pan et al.[25] introduce KwaiAgents for processing queries, following guidelines, and accessing external documents. Frameworks such as MEDIQ [17] and MDAgents [16] improve the reliability of LLMs in clinical settings by strengthening information-seeking capabilities and agent systems, thereby supporting more realistic diagnostic processes. [5] also explore Chatgpt\u2019s information seeking strategy in 20-questions game. ", "page_idx": 9}, {"type": "text", "text": "5 Limitation and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In practice, $\\Omega_{v}^{A}$ and $\\Omega_{v}^{N}$ might overlap, as different answers (such as \u201cyes\" or \u201cno\") may lead to the exclusion of different sets of possibilities. Another similar limitation is that some questions or answers may not fully eliminate certain possibilities (e.g.,\u201cI don\u2019t have a fever\" does not $100\\%$ eliminate the possibility of having COVID-19). Furthermore, compared to completely open-ended interaction in medical diagnosis or troubleshooting, our current benchmark represents a simplified scenario. In theory, such cases could be handled using the method of converting interactions into probability estimations and applying some kind of Bayesian update to the probabilities of each possibility, rather than just eliminating some subset. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper presents the Uncertainty of Thoughts (UoT) algorithm, significantly improving LLMs in tasks requiring active information seeking through tree-based simulation, uncertainty-based rewards and a reward propagation scheme. On five datasets UoT increases success rate by $38.1\\%$ on average, establishing a new benchmark for evaluating LLMs in active information-seeking tasks. We evaluate UoT on simplified scenarios; more realistic scenarios raise challenges like allowing incomplete elimination of possibilities by answers, and others which we leave for future work. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgment ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Pang Wei Koh is supported by the Singapore National Research Foundation and the National AI Group in the Singapore Ministry of Digital Development and Innovation under the AI Visiting Professorship Programme (award number AIVP-2024-001). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] AI@Meta. Llama 3 model card. 2024. ", "page_idx": 10}, {"type": "text", "text": "[2] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Cl\u00e9ment Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D\u00edaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023. ", "page_idx": 10}, {"type": "text", "text": "[3] Anthropic. Claude 2, 2023. ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[4] Anthropic. Introducing the next generation of claude. 2024. ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[5] Leonardo Bertolazzi, Davide Mazzaccara, Filippo Merlo, and Raffaella Bernardi. Chatgpt\u2019s information seeking strategy: Insights from the 20-questions game. In Proceedings of the 16th International Natural Language Generation Conference, pages 153\u2013162, 2023.   \n[6] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. arXiv preprint arXiv:2308.09687, 2023.   \n[7] Guillaume Chaslot, Sander Bakkes, Istvan Szita, and Pieter Spronck. Monte-carlo tree search: A new framework for game ai. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, volume 4, pages 216\u2013217, 2008.   \n[8] Cheng-Han Chiang and Hung-yi Lee. Can large language models be an alternative to human evaluations? arXiv preprint arXiv:2305.01937, 2023.   \n[9] Cohere. Cohere for ai, 2023.   \n[10] Gautier Dagan, Frank Keller, and Alex Lascarides. Dynamic planning with a llm. arXiv preprint arXiv:2308.06391, 2023. ", "page_idx": 10}, {"type": "text", "text": "[11] Yihe Deng, Weitong Zhang, Zixiang Chen, and Quanquan Gu. Rephrase and respond: Let large language models ask better questions for themselves. arXiv preprint arXiv:2311.04205, 2023. ", "page_idx": 10}, {"type": "text", "text": "[12] Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, Weinan Zhang, and Jun Wang. Alphazerolike tree-search can guide large language model decoding and training. arXiv preprint arXiv:2309.17179, 2023.   \n[13] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992, 2023.   \n[14] Martin N Hebart, Adam H Dickter, Alexis Kidder, Wan Y Kwok, Anna Corriveau, Caitlin Van Wicklin, and Chris I Baker. Things: A database of 1,854 object concepts and more than 26,000 naturalistic object images. PloS one, 14(10):e0223792, 2019.   \n[15] Ziniu Hu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A Ross, Cordelia Schmid, and Alireza Fathi. Avis: Autonomous visual information seeking with large language model agent. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[16] Yubin Kim, Chanwoo Park, Hyewon Jeong, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park. Adaptive collaboration strategy for llms in medical decision making. arXiv preprint arXiv:2404.15155, 2024.   \n[17] Shuyue Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei Koh, and Yulia Tsvetkov. Mediq: Question-asking llms for adaptive and reliable medical reasoning. arXiv preprint arXiv:2406.00922, 2024.   \n[18] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477, 2023.   \n[19] Wenge Liu, Jianheng Tang, Yi Cheng, Wenjie Li, Yefeng Zheng, and Xiaodan Liang. Meddg: an entity-centric medical consultation dataset for entity-aware medical dialogue generation. In CCF International Conference on Natural Language Processing and Chinese Computing, pages 447\u2013459. Springer, 2022.   \n[20] Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. Geval: Nlg evaluation using gpt-4 with better human alignment, may 2023. arXiv preprint arXiv:2303.16634.   \n[21] Mistral.AI. Mistral large, our new flagship model. 2024.   \n[22] David Noever and Forrest McKee. Chatbots as problem solvers: Playing twenty questions with role reversals. arXiv preprint arXiv:2301.01743, 2023.   \n[23] OpenAI. Gpt-3.5 turbo: A high-performance language model, 2023. Whitepaper.   \n[24] OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.   \n[25] Haojie Pan, Zepeng Zhai, Hao Yuan, Yaojia Lv, Ruiji Fu, Ming Liu, Zhongyuan Wang, and Bing Qin. Kwaiagents: Generalized information-seeking agent system with large language models. arXiv preprint arXiv:2312.04889, 2023.   \n[26] Joon Sung Park, Joseph O\u2019Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, pages 1\u201322, 2023.   \n[27] Dinesh Raghu, Shantanu Agarwal, Sachindra Joshi, and Mausam. End-to-end learning of flowchart grounded task-oriented dialogs. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 4348\u20134366, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.   \n[28] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jeanbaptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024.   \n[29] Claude Elwood Shannon. A mathematical theory of communication. The Bell system technical journal, 27(3):379\u2013423, 1948.   \n[30] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023.   \n[31] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.   \n[32] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.   \n[33] Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:2305.04091, 2023.   \n[34] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022.   \n[35] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.   \n[36] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.   \n[37] Lin Xu, Qixian Zhou, Ke Gong, Xiaodan Liang, Jianheng Tang, and Liang Lin. End-to-end knowledge-routed relational dialogue system for automatic diagnosis. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 7346\u20137353, 2019.   \n[38] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Grifftihs, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601, 2023.   \n[39] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.   \n[40] Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge for large-scale task planning. arXiv preprint arXiv:2305.14078, 2023.   \n[41] Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. Language agent tree search unifies reasoning acting and planning in language models. arXiv preprint arXiv:2310.04406, 2023. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Derivation of Information Gain Formula ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Recall that the information gain at node $v$ is defined as the expected change in uncertainty (or entropy) when receiving an answer at this node, which we defined as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nI G_{v}(X):=H_{v}(X)-p_{v}^{A}\\cdot H_{v}^{Y}(X)-p_{v}^{N}\\cdot H_{v}^{N}(X)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We now show that: ", "page_idx": 13}, {"type": "text", "text": "Proposition 1. The information gain at node $v$ is equal to: ", "page_idx": 13}, {"type": "equation", "text": "$$\nI G_{v}(X)=-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Note that for any outcome $x_{i}$ , we have by the rules of conditional probability: ", "page_idx": 13}, {"type": "equation", "text": "$$\np(x_{i}|\\Omega_{v}^{A})=\\frac{p(x_{i}|\\Omega_{v})}{p(\\Omega_{v}^{A}|\\Omega_{v})}=\\frac{p(x_{i}|\\Omega_{v})}{p_{v}^{A}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Now the information gain is: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I G_{\\mathrm{ev}}(X)}\\\\ &{=I_{\\mathrm{ev}}(X)-p_{\\mathrm{e}}^{A}\\cdot H_{\\mathrm{el}}^{A}(X)-p_{\\mathrm{e}}^{N}\\cdot H_{\\mathrm{el}}^{N}(X)}\\\\ &{=-\\displaystyle\\sum_{i:\\mathrm{el}\\in\\mathrm{Z}(\\mathbb{Z})_{s}}p_{\\mathrm{e}}(x_{i}|\\Omega_{v})\\log p(x_{i}|\\Omega_{v})}\\\\ &{+\\displaystyle p_{\\mathrm{e}}^{A}\\sum_{i:\\mathrm{el}\\in\\mathrm{Z}(\\mathbb{Z})_{s}}p(x_{i}|\\Omega_{v}^{A})\\log p(x_{i}|\\Omega_{v}^{A})}\\\\ &{+\\displaystyle p_{\\mathrm{e}}^{N}\\sum_{i:\\mathrm{el}\\in\\mathrm{Z}(\\mathbb{Z})_{s}}p(x_{i}|\\Omega_{v}^{N})\\log p(x_{i}|\\Omega_{v}^{N})}\\\\ &{=\\displaystyle\\sum_{i:\\mathrm{el}\\in\\mathrm{Z}(\\mathbb{Z})_{s}}p(x_{i}|\\Omega_{v}^{A})(\\log p(x_{i}|\\Omega_{v}^{A})-\\log p(x_{i}|\\Omega_{v}))}\\\\ &{+\\displaystyle\\sum_{i:\\mathrm{el}\\in\\mathrm{Z}(\\mathbb{Z})}p(x_{i}|\\Omega_{v}^{N})(\\log p(x_{i}|\\Omega_{v}^{N})-\\log p(x_{i}|\\Omega_{v})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the last equality holds by $p_{v}^{A}\\cdot p(x_{i}|\\Omega_{v}^{A})=p(x_{i}|\\Omega_{v})$ , and similarly for $p_{v}^{N}$ . We further compute that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i:\\omega_{i}\\in\\Omega_{v}^{A}}p(x_{i}|\\Omega_{v}^{A})(\\log p(x_{i}|\\Omega_{v}^{A})-\\log p(x_{i}|\\Omega_{v}))}\\\\ &{=\\displaystyle\\sum_{i:\\omega_{i}\\in\\Omega_{v}^{A}}p(x_{i}|\\Omega_{v}^{A})\\log\\frac{p(x_{i}|\\Omega_{v}^{A})}{p(x_{i}|\\Omega_{v})}}\\\\ &{=\\displaystyle-\\sum_{i:\\omega_{i}\\in\\Omega_{v}^{A}}p(x_{i}|\\Omega_{v}^{A})\\log p_{v}^{A}}\\\\ &{=\\displaystyle-p_{v}^{A}\\log p_{v}^{A}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Analogously the remaining term is $-p_{v}^{N}\\log{p_{v}^{N}}$ . Finally we conclude that ", "page_idx": 13}, {"type": "equation", "text": "$$\nI G_{v}(X)=-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In fact, this proposition can also be proven using some properties of information theory, particularly the definitions of conditional entropy and mutual information. As the more computational proof shown here is still relatively short and does not require defining certain additional probability distributions, we provide the computational proof here instead. ", "page_idx": 13}, {"type": "text", "text": "B Comparison of Various Scaling Methods in Reward Function Design ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We also consider multiple scaling schemes, including Logarithmic Transformation Scaling, Sigmoid Transformation Scaling and Piecewise Function Scaling. The results demonstrate that our current setting is the optimal one. Additionally, our current design, particularly setting lambda $>0$ , is intended as a straightforward method to incorporate our preference for a sharper reward, as it accelerates the decay of rewards as we move away from 0.5. Furthermore, it is also intended to penalize questions that are too specific when the set of possibilities remains relatively large as $|p_{v}^{A}-p_{v}^{N}|$ will be large. We elaborate all the scaling methods and their corresponding results below. ", "page_idx": 14}, {"type": "text", "text": "Vanilla Expected Information Gain (IG) ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\nI G_{v}(X)=-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Logarithmic Transformation Scaling (LTS), where $k=1$ ", "page_idx": 14}, {"type": "equation", "text": "$$\nL(I G_{v}(X))={\\frac{\\log(1+k\\cdot I G_{v}(X))}{\\log(1+k)}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Sigmoid Transformation Scaling (STS), where $\\tau=10$ and $\\theta=0.5$ ", "page_idx": 14}, {"type": "equation", "text": "$$\nS(I G_{v}(X))=\\frac{1}{1+e^{-\\tau(I G_{v}(X)-\\theta)}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Piecewise Function Scaling (PFS), where $\\lambda=0.5$ ", "page_idx": 14}, {"type": "equation", "text": "$$\nP(I G_{v}(X),p_{v}^{A})={\\left\\{\\begin{array}{l l}{{\\frac{I G_{v}(X)}{\\lambda}}\\cdot p_{v}^{A}}&{{\\mathrm{if~}}p_{v}^{A}\\leq\\lambda}\\\\ {{\\frac{I G_{v}(X)}{1-\\lambda}}\\cdot(1-p_{v}^{A})}&{{\\mathrm{if~}}p_{v}^{A}>\\lambda}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Uncertainty-based Reward (UR) ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\nR_{u}(v)=\\widetilde{I G}_{v}(X):=\\frac{-p_{v}^{A}\\log p_{v}^{A}-p_{v}^{N}\\log p_{v}^{N}}{1+\\lambda^{-1}|p_{v}^{A}-p_{v}^{N}|}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In particular, in this experiment, we use 20Q-BIG-bench (introduced in $\\S\\mathrm{I}.2\\rangle$ and Common dataset instead of Thing dataset in 20 Question scenario. Datasets are the same as the main chapters in other scenarios. ", "page_idx": 14}, {"type": "table", "img_path": "CVpuVe1N22/tmp/338cff4d1f6e5a7e24abd3d02bead04fe802b4822013bee108a933870bbf9f72.jpg", "table_caption": ["Table 3: Performance(Successful Rate) comparison of different reward methods based on GPT-3.5 "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "C Comparison of Different Reward propagation Schemes ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We also consider different reward propagation schemes and introduce their benefits as well as drawbacks. ", "page_idx": 14}, {"type": "text", "text": "Cumulative Reward Path Selection (CRPS): We used the strategy of calculating and comparing the cumulative reward for each path (from the root node to the leaf node), which involves multiplying the rewards of all nodes along the path and then selecting the path with the highest cumulative reward for the first question to interact with the user. This method focuses on identifying the single path that is most likely to yield a high reward. Its main limitation is that it may rely too heavily on the performance of a single path, neglecting the exploration of the overall problem space. ", "page_idx": 14}, {"type": "text", "text": "UoT-Max: Similar to the reward propagation scheme we are currently using, we considered adopting the approach of selecting the maximum reward among the children nodes (when the node is a questioner node) in the calculation of the expected reward. Opting for the maximum child node reward tends to pursue high rewards more aggressively, which may be more effective in some situations but could also overlook the need for exploration, potentially not always being optimal in the long run. ", "page_idx": 15}, {"type": "equation", "text": "$$\nR_{e}(v):=\\left\\{\\!\\!\\!\\begin{array}{l l}{R_{a}(v)}&{\\mathrm{if~}v\\mathrm{~is~a~leaf;otherwise:~}}\\\\ {p_{v}^{A}R_{e}(v^{A})+p_{v}^{N}R_{e}(v^{N})}&{\\mathrm{if~}v\\mathrm{~is~an~Answerer~Node}}\\\\ {\\operatorname*{max}_{w\\in\\mathsf{C h i l d r e n}(v)}R_{e}(w)}&{\\mathrm{if~}v\\mathrm{~is~a~Questioner~Node}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In particular, in this experiment, we use 20Q-BIG-bench (introduced in $\\S\\mathrm{I}.2\\rangle$ and Common dataset instead of Thing dataset in 20 Question scenario. Datasets are the same as the main chapters in other scenarios. ", "page_idx": 15}, {"type": "table", "img_path": "CVpuVe1N22/tmp/8960de8d32a0034f6241c05e974fd31282889bc28146eca315a438a062f74f78.jpg", "table_caption": ["Table 4: Performance (Success Rate) comparison of different reward propagation schemes. The results also demonstrate the superiority of our current reward propagation scheme. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Compared to the other two reward propagation schemes, the existing approach takes into account the cumulative rewards of all paths, providing a more holistic and balanced decision-making mechanism. Instead of merely relying on the maximum short-term rewards or the performance of a single path, it is designed to capture long-term benefits, focusing on sustainable outcomes rather than immediate short-term gains. ", "page_idx": 15}, {"type": "text", "text": "D Experimental Performance for Earlier Released LLMs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In these experiments, we use 20Q-BIG-bench (introduced in $\\S\\mathrm{I}.2\\rangle$ ) and Common dataset instead of Thing dataset in 20 Question scenario. Datasets are the same as the main chapters in other scenarios. ", "page_idx": 15}, {"type": "text", "text": "Table 5: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL). ", "page_idx": 15}, {"type": "table", "img_path": "CVpuVe1N22/tmp/23c2037a23d70ae4b97a913bedced64dd96f773cda4a0ec3886231a590f86b78.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "E Effect of Simulation Depth ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this experiment, we use 20Q-BIG-bench (introduced in $\\S\\mathrm{I}.2)$ and Common dataset instead of Thing dataset in 20 Question scenario. Datasets are the same as the main chapters in other scenarios. ", "page_idx": 16}, {"type": "text", "text": "As the below figure illustrates, we analyze the impact of simulation steps. Even with one-step reasoning and planning, our method can still have a strong performance, further indicating the effectiveness of our reward design and question selection mechanism. With the increase of the step, the performance can gradually rise. However, due to the constraints of computation resources and OpenAI API budgets, we only explore the simulation to the third step and argue that it can be the practical tradeoff between performance and efficiency. ", "page_idx": 16}, {"type": "image", "img_path": "CVpuVe1N22/tmp/c36551192725e97505b518300ec4faaf1cfc1d6891d84876896f1b90c01a9173.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "F Reliability of GPT-4 as the Environment ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "As the impressive understanding ability of LLMs, previous research has validated the effectiveness of evaluators served by ChatGPT or GPT-4 [8, 20]. Consequently, we also adopt GPT-4 as the environment to provide feedback on our work. Prompts can be found in Appendix L.4. To assess the accuracy and reliability of employing GPT-4 as the environment simulator, we randomly sample $10\\%$ interaction records (including the final judgment and intermediate feedback from the environment) from each dataset. As Figure 6 shows, GPT-4 can provide completely accurate judgment and also keep a high level of accurate feedback during the interaction. These experimental results can further support the effectiveness of our method. ", "page_idx": 16}, {"type": "text", "text": "Table 6: Human evaluation results for the accuracy of environment feedback served by GPT-4. IF represent the Accuracy of Intermediate Feedback. ", "page_idx": 16}, {"type": "table", "img_path": "CVpuVe1N22/tmp/587d5b58fe8536d090a0b95015f71910f09ec561ae298d8409d35b0654f4f65e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "CVpuVe1N22/tmp/60418196e232ab769efbcf9446265419390cd148224a9e809d978b1fba485099.jpg", "img_caption": ["Figure 5: Curve of uncertainty based reward on $\\mathrm{Eq\\10}$ , where $p_{v}^{N}$ can be replaced by $(1-p_{v}^{A})$ . The horizontal axis $p_{v}^{A}$ is conditional probabilities of affirmative at node $\\mathbf{V}_{\\cdot}$ , which are introduced in Section $\\S2.4$ . "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "G Reward Function Details and Its Curve ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Refer to Figure 5 for the curve of uncertainty-based reward function. ", "page_idx": 17}, {"type": "text", "text": "H Experimental Statistical Significance ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We conduct three experiments on five datasets using Llama 3 and GPT-4 to compare the performance of Direct Prompting (DP) and UoT methods in a closed-set setting for significance testing. Due to LLM API quota limitations, the number of experiments are restricted. To determine whether the differences in success rates (SR) between the two methods were statistically significant, we performed a t-test. The results are presented below. ", "page_idx": 17}, {"type": "text", "text": "GPT-4 Results ", "text_level": 1, "page_idx": 17}, {"type": "table", "img_path": "CVpuVe1N22/tmp/4fe4aaf0582ff40380fec964791181517e75d78cd75c1eb08a0b6546d8e40e43.jpg", "table_caption": ["Table 7: GPT-4 Comparison of DP and UoT on Success Rates (SR) "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Llama 3 Results ", "text_level": 1, "page_idx": 17}, {"type": "table", "img_path": "CVpuVe1N22/tmp/481518994297f38db7bcbd9eba0adfb04266ef622afda02cf088402bce236cf5.jpg", "table_caption": ["Table 8: Llama 3 Comparison of DP and UoT on Success Rates (SR) "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "The t-test results indicate that UoT significantly outperform DP five datasets $(\\mathsf{p}<0.05)$ , as evidenced by their higher mean scores. ", "page_idx": 18}, {"type": "text", "text": "I Experimental Setups ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "I.1 Baselines Setup ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Chain-of-Thought (CoT) We adapt the typical CoT prompt which instruct LLM to generate the explanation or motivation for the proposed question first, then give the question to ask. ", "page_idx": 18}, {"type": "text", "text": "Chain of Thought with Self-Consistency (CoT-SC) To make the method spend comparable compute to our approach for a fair comparison, we sampled 33 times before deciding on each action with the LLM\u2019s temperature of 0.7. The final selected question is the one repeated most times among 33 samples. ", "page_idx": 18}, {"type": "text", "text": "Planning Prompting To measure whether LLMs\u2019 planning ability can be enhanced through some crafted prompts like CoT, ToT or Reflexion. We design the prompt to enable LLM to simulate multiple different sets of future interactions between questioner and answerer, then let LLM choose one most promising interaction (question) to ask. ", "page_idx": 18}, {"type": "text", "text": "Tree of Thoughts In the case of Original-ToT, a sampling method is employed to generate 3 questions from each answer node, and the self-evaluation method is utilized for reward calculation. Subsequently, breadth-first search will be used and 10 nodes from each step will be selected for later simulation. Additionally, the temperature of the LLM is configured to 0.7, consistent with the settings in original ToT paper. In the case of Adapted-ToT, we provide more heuristical hints in prompt to generate the questions, e.g. \u2018you should try to propose the question to halve the probability set\u2019. Likewise, each answer node generates 3 questions, and the LLM selects 10 nodes with higher self-evaluation rewards to further simulation. The simulation steps are also 3. ", "page_idx": 18}, {"type": "text", "text": "Reflextion This approach involves the LLM agent suggesting questions iteratively until the question reward exceeds the threshold of 0.7 or reaches the maximum limit of 3 questions. The reward score $s$ is calculated using the formula $s=\\operatorname*{min}(p^{A},p^{N})/\\operatorname*{max}(p^{A},p^{N})$ . This heuristic is based on the principle of whether the question can effectively halve the probability set. If a candidate question achieves a score above the threshold, the process of proposing questions is concluded, and that question is selected. In cases where no question meets the threshold, the one with the highest score is chosen. ", "page_idx": 18}, {"type": "text", "text": "Uncertainty of Thoughts Pruned After generating the candidate question based on the possibility set $\\Omega_{i}$ , we sorted these question nodes by uncertainty based reward and reserved half of them, serving the purpose of pruning. In subsequent steps of the simulation, this pruning operation will be continued. Other settings were the same as UoT, described in Section $\\S\\mathrm{I}.6$ . ", "page_idx": 18}, {"type": "text", "text": "I.2 Scenarios Settings and Datasets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "20 Questions game is a classic guessing game where the answerer thinks of an object, person, place, or other, and the questioner, possessing no prior knowledge about the chosen entity, proceeds to pose a series of up to 20 yes-or-no questions to determine what the secret item is. The questions are designed to narrow the possibilities and ultimately guess the secret item within the 20 questions. ", "page_idx": 18}, {"type": "text", "text": "20 Questions in BIG-bench: It is the sub-task of BIG-bench and can be found on the GitHub website7, consist of 29 items. Common Dataset Construction: We came across an official website8 that introduces a 20 Questions game, which mentions that common target categories in this game include animals, places, food, and objects. Therefore, we extracted and manually screened the targets mentioned on this website, resulting in a dataset named \"Common\" comprising 111 targets, each belonging to one of the four aforementioned categories. Thing Dataset: It is a collection of 1,854 varied object concepts, carefully selected from tangible and easily identifiable nouns in American English by Martin at al.[14], which is publicly available on their official website9. ", "page_idx": 18}, {"type": "text", "text": "Medical Diagnosis In this scenario, the patient will simply describe their symptom first which we call a \u2018Self-report\u2019, then doctor acted by LLM will start to ask questions to interact with patient to determine the disease. ", "page_idx": 19}, {"type": "text", "text": "Troubleshooting In FloDial dataset, trouble includes faults of car and laptop. Similar to Medical Diagnosis, the customer first describes some simple fault symptoms, then the customer support technician will chat with customer to further check the specific issues of device. ", "page_idx": 19}, {"type": "text", "text": "LLMs Serve as Questioner (Patient or Customer) In simulated interactions involving questioner and answerer scenarios, particularly for medical diagnosis and troubleshooting, the response given by an LLM acting answerer is guided by scenario instructions and real-world dialogue examples. This approach makes the responses of answerer more human-like and enhances its accuracy in diagnosing diseases or identifying faults. While, in the game of 20-question, where the objective is to guess common items, the LLM acting as the answerer only needs to provide simple \u2018yes\u2019 or \u2018no\u2019 answers. Therefore, incorporating real-world dialogue into the LLM\u2019s prompts for this game is not necessary. ", "page_idx": 19}, {"type": "text", "text": "I.3 Dataset selection criteria and process for MedDG ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In the original MedDG dataset, numerous conversations lacked a clear diagnosis, often concluding with advice for the patient to rest or seek further tests. This ambiguity arose from patients not detailing their symptoms sufficiently or doctors lacking the information or confidence to diagnose. Consequently, these conversations hinder LLMs from accurately understanding disease and symptom information for effective patient role simulation. To address this, we curated our final evaluation set to include only conversations with explicit disease diagnoses. ", "page_idx": 19}, {"type": "text", "text": "Furthermore, to ensure a balanced representation across the 8 disease categories, we selected roughly 40 dialogues for each disease. We also excluded conversations that were too brief (1-2 turns) or excessively lengthy (over 10 turns). The curation process involved two annotators: one for initial selection and another for verification. ", "page_idx": 19}, {"type": "text", "text": "Given these criteria, we finally pick 500 conversations for our evaluation set, aiming to maintain the evaluation\u2019s reliability and quality. We will also clarify this and add the details into the following version. ", "page_idx": 19}, {"type": "text", "text": "I.4 Data Preprocessing of FloDial ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We process the dataset, FloDial, to convert troubleshooting flowcharts into a set of troubleshooting faults. The dialogue is grounded in specific faults, which correspond to the leaf nodes (descriptions and solutions of faults) in the flowcharts. After reviewing all the leaf nodes, we identify 153 faults that had corresponding dialogues. We then use GPT-4 to generate a clear name for each fault based on the descriptions and solutions of faults, and randomly selected one corresponding dialogue history to construct the current dataset. ", "page_idx": 19}, {"type": "text", "text": "I.5 UoT (Open Set) Setup ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "To initialize the possibility set as the start of the algorithm, in medical diagnosis and troubleshooting, initial descriptions from patients or customers about symptoms or issues enable UoT to establish a possibility set right from the start. For the game of 20 Questions, where initial information is scant, prematurely establishing this set could misdirect the inquiry. Therefore, for the first three rounds, we employ Direct Prompting in Open-Set (DPOS) approach to gather information and feedback. After these initial rounds, UoT takes over, refreshing the possibility set each round to refine the questioning strategy. ", "page_idx": 19}, {"type": "text", "text": "For datasets Common, Things, DX, MedDG and FloDial, we configure the size of the possibility set for each update round, setting them at 10, 10, 5, 5, and 5, respectively. This parameter should prevent the increase in cognitive load and decrease in efficiency that comes with larger sizes, while also avoiding the limitations of focusing on a few specific items that come with smaller sizes. We experiments with values(size) between 5 and 50 based on this rationale, and the final selection of these hyperparameters is guided by empirical performance evaluations. ", "page_idx": 19}, {"type": "text", "text": "I.6 Implementation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Empirically, we set the plan (simulation) steps as 3 and the number of questions during the simulation is 3. The hyperparameter $\\lambda$ in uncertainty-based reward is 0.4. ", "page_idx": 20}, {"type": "text", "text": "J Impact Statement ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This paper aims to enhance LLMs\u2019 information seeking abilities, allowing them to make better decisions in challenging real-world settings involving uncertainty and ambiguity, and to interact more effectively with humans in human-AI settings. On the whole, we expect that information seeking capabilities should allow models to behave in a manner that is more reliable and well-aligned with human expectations, as it allows them to better resolve their uncertainty. There may be some potential societal consequences related to LLMs in general, such as privacy and trustworthiness issues. However, we do not believe that any of these must be specifically highlighted here. ", "page_idx": 20}, {"type": "text", "text": "K Examples in Scenarios ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Some examples of conversation in different scenarios are provided in Table 9-12. ", "page_idx": 20}, {"type": "table", "img_path": "CVpuVe1N22/tmp/056a3722da8a1ec31f8f5c3d2f432c777f725253c0157aed1beacf5385ebb7eb.jpg", "table_caption": ["Table 9: Example for 20 Question. Q stands for Questioner and A stands for Answerer. "], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "CVpuVe1N22/tmp/d00fd09c0d37d83b22768a4bb55e52f99bb62db23b63b8d135dff5217d122506.jpg", "table_caption": ["Table 10: Example for Medical Diagnosis. D stands for Doctor (Questioner) and P stands for Patient (P). "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 11: Example for MedDG. D stands for Doctor (Questioner) and P stands for Patient (Answerer). ", "page_idx": 20}, {"type": "table", "img_path": "CVpuVe1N22/tmp/4256a84618f7fb29df93459f33bd941d5122983038f5082675f40f61d5d70ce2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 12: Example for Troubleshooting. T stands for customer support technician and C stands for customer. ", "page_idx": 21}, {"type": "table", "img_path": "CVpuVe1N22/tmp/97c7c98d5cb9768d7d542ef4f682922d72217e8f1b4642bda9c93fc80631ba41.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "L Prompts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "L.1 DP(OS) and DP(CS) Prompt ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The specific prompts for the DP(OS) and DP(CS) baselines in each scenario are provided in Table 13-15. ", "page_idx": 21}, {"type": "text", "text": "Table 13: DPOS and DPCS Prompt for 20 Question game. The two settings are the same except for the content noted in red, which is only for DPCS Prompt. The first time the content marked in red is mentioned at the beginning of interaction is to inform the questioner of the entire probability set. The second mention serves as a reminder for the questioner to determine the target as soon as possible when the conversation is nearing its end. We establish two phases with the aim of encouraging the questioner to guess the target as soon as possible when the second phase of interaction is nearing its conclusion, in order to avoid failure at the end of interaction. ", "page_idx": 21}, {"type": "table", "img_path": "CVpuVe1N22/tmp/e59a57d4e2e178b12d6a36018211f5842c425ca9ca6381d0522a84cf744d9add.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "L.2 Planning Prompt ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The specific prompts for Planning Prompt baselines in each scenario are provided in Table 28-27. As planning prompt method is close set setting, hence the probability set will also be informed in the prompt as DPCS prompt. We do not repeat it in the tables. ", "page_idx": 21}, {"type": "text", "text": "L.3 UoT Prompt ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The detailed prompts for our UoT method in each scenario are attached in Table 19-21. ", "page_idx": 21}, {"type": "text", "text": "L.4 Questioner Prompt ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The specific prompt to guide the examiner in all scenarios is provided in Table 22-24. ", "page_idx": 21}, {"type": "text", "text": "Table 14: DPOS and DPCS are medical diagnostic prompts with similar structures. The key difference is the inclusion of probability set information in red text for DPCS. This red text appears twice: initially to inform the questioner about all potential diagnoses and again towards the end of the interaction as a reminder to quickly confirm the disease. We establish two phases with the aim of encouraging the questioner to confirm the disease as soon as possible when the second phase of interaction is nearing its conclusion, avoiding failure at the end of interaction. ", "page_idx": 22}, {"type": "table", "img_path": "CVpuVe1N22/tmp/a55f8ce46fca5c2827b67d29a03509c4e35c72f0d02637efe6b90a28c34436a0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Table 15: DPOS and DPCS are troubleshooting prompts with similar structures, but DPCS includes unique content highlighted in red. This red content appears first at the beginning, outlining all potential faults, and again towards the end as a reminder to swiftly identify the fault. The two-phase structure of these prompts aims to ensure quick fault confirmation, especially in the final stages of the interaction, to prevent failure. ", "page_idx": 22}, {"type": "table", "img_path": "CVpuVe1N22/tmp/a01287a276002ebab4305f7aa40563aa1bbce9c75c0b1554792ef7fa02b0f30d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "CVpuVe1N22/tmp/7bd0c1bd6471565f7da517bd63f85df61fe620e93651890dc31afb005ca098b6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Table 16: Planning Prompt for 20 Question game. [C1] is the count of questions asked and [C2] is the count of questions remaining. The \u2018information gained\u2019 marked blue represents the previous interaction history. We divide it into three phases to discuss the probability set as quickly as possible, conduct simulation for planning, and remind the questioner to guess the answer. ", "page_idx": 23}, {"type": "table", "img_path": "CVpuVe1N22/tmp/64ffcda5e5af2a790134faa020152b10f952030bc89479800f1a0a3664acf76f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "CVpuVe1N22/tmp/ed0f5b53dcb2c53a6acd842dd3caae1ecde24b9d4cf0475f4535677474c7b86e.jpg", "table_caption": ["Table 17: Planning Prompt for Medical Diagnosis. [C1] is the count of questions asked and [C2] is the count of questions remaining. The \u2018information gained\u2019 marked blue represents the previous interaction history. We divide it into three phases to discuss the probability set as quickly as possible, conduct simulation for planning, and remind the questioner to confirm the disease. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 18: Planning Prompt for Troubleshooting. [C1] is the count of questions asked and [C2] is the count of questions remaining. The \u2018information gained\u2019 marked blue represents the previous interaction history. We divide it into three phases to discuss the probability set as quickly as possible, conduct simulation for planning, and remind the questioner to confirm the fault. ", "page_idx": 24}, {"type": "table", "img_path": "CVpuVe1N22/tmp/6bcc6a0d29b338df8ae2bc14291780e24a1f9b86833b97cc7c600c7cf1cc4970.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 19: UoT Prompt for the 20 Questions Game: As it is based on a closed-set setting, information about probabilities will be given at the beginning of the interaction and will be reminded after Q14. Since it is similar to previous prompts, we will not repeat it here. In the \u2019Prompt for Question Generation and Simulation\u2019, the count of YES/NO indicates the number of items that are consistent with the affirmative/negative response. ", "page_idx": 24}, {"type": "table", "img_path": "CVpuVe1N22/tmp/fb616f6c65c58eebd8ca6063b04e0c59972970c63449dfd2c6b6c64afe696b85.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Please design a question about $\\overline{{\\mathbf{X}}}$ and can only be answered by YES or NO. asked Then classify the possible X above based on this question. If the answer is \u2019YES\u2019, put this X into \u2019YES: ...\u2019, otherwise to \u2019NO: ...\u2019. Finally calculate how many X in YES and NO. ", "page_idx": 24}, {"type": "text", "text": "Notably, this question should fulflil that the count of YES and NO are almost the same with a permissible discrepancy of no more than one! ", "page_idx": 24}, {"type": "text", "text": "You should think about best n questions to respond to. And your answer should be: Question 1: Is X ...?   \nYES: item1, item2, ...   \nCount of YES: ...   \nNO: item1, item2, ...   \nCount of NO: ", "page_idx": 24}, {"type": "table", "img_path": "CVpuVe1N22/tmp/6f4f6333ed46991dbe2f2971d33dd5fcf021777739ffd0de05bab642d0db9ea5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 20: UoT Prompt for medical diagnosis: As it is based on a closed-set setting, information about probabilities will be given at the beginning of the interaction and will be reminded after Q3. Since it is similar to previous prompts, we will not repeat it here. In the \u2019Prompt for Question Generation and Simulation\u2019, the count of YES/NO indicates the number of diseases that are consistent with the affirmative/negative response. ", "page_idx": 25}, {"type": "text", "text": "Prologue ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "You are a doctor and your patient reports that: [self-report]   \nYou should ask your patient questions in English with symptoms which can only be answered by yes or no, to find what disease this patient suffers.   \nLet us begin. Ask me the first question. ", "page_idx": 25}, {"type": "text", "text": "Prompt for Question Generation and Simulation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Please design a question to ask your patient with symptoms about disease and can only be answered by YES or NO. Then classify the possible disease above based on each question. If the answer is \u2019YES\u2019, put this disease into \u2019YES: ...\u2019, otherwise to \u2019NO: ...\u2019. Finally calculate how many X in YES and NO. ", "page_idx": 25}, {"type": "text", "text": "Notably, this question should fulflil that the count of YES and NO are almost the same with a permissible discrepancy of no more than one! ", "page_idx": 25}, {"type": "text", "text": "You should think about best n questions to respond to. And your answer should be:   \nQuestion 1: ...?   \nYES: disease1, disease2, ... (disease names only) Count of YES: ...   \nNO: disease1, disease2, ... (disease names only)   \nCount of NO: ... ", "page_idx": 25}, {"type": "text", "text": "Additional Reminder in Q3 - Q5 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Note that you should point out and ask what disease the patient suffers from now. The patient may suffer from one of diseases below: [list of disease], or other. The question must be \u2019You may have a [disease name]?\u2019 ", "page_idx": 25}, {"type": "text", "text": "Table 21: UoT Prompt for troubleshooting: As it is based on a closed-set setting, information about probabilities will be given at the beginning of the interaction and will be reminded after Q14. Since it is similar to previous prompts, we will not repeat it here. In the \u2019Prompt for Question Generation and Simulation\u2019, the count of YES/NO indicates the number of faults which are consistent with the affirmative/negative response. ", "page_idx": 26}, {"type": "table", "img_path": "CVpuVe1N22/tmp/555fcfde50fa4676d28a71a74f3b2e5e53cba9a5efa16b35bc9cedc347a6480a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "CVpuVe1N22/tmp/3d8e2d23d4d329118d083709fe178b2785033ab21148ddd0225d497aa3e14f9f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 22: Prompt for Answerer in 20 questions game. [target] is the name of the final target for each dialogue. ", "page_idx": 26}, {"type": "text", "text": "Prologue ", "text_level": 1, "page_idx": 26}, {"type": "table", "img_path": "CVpuVe1N22/tmp/6c006fd10e1dc7d52c097095bed4b211c3cb802ace881685534ed3fabe0b68f1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 23: Prompt for Answerer in medical diagnosis. [disease] is the name of the final disease for each dialogue. ", "page_idx": 26}, {"type": "text", "text": "Prologue ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "You are the patient suffering \u2019[target]\u2019 and I am the doctor. I will ask you up to 5 questions and you should answer each one truthfully based on your disease. If I point out correctly what disease you experience, answer me \"You are right. I am experiencing \u2019[target]\u2019.\" Note that never directly tell me what disease is all the time.   \nLet us begin. Here is my first question. ", "page_idx": 26}, {"type": "text", "text": "Table 24: Answerer Prompt in troubleshooting. [fault] is the name of the final fault for each dialogue. ", "page_idx": 26}, {"type": "text", "text": "Prologue ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "You are the client with a device that has \u2019[target]\u2019 and I am the technician. I will ask you up to 20 questions and you should answer each one truthfully based on the issue of your device. If I point out correctly what your issue is, answer me \"You are right. My device has \u2019[target]\u2019.\" Note that never directly tell me what the issue is all the time. Let us begin. Here is my first question. ", "page_idx": 26}, {"type": "text", "text": "Table 25: ToT Prompt for 20 Question game. [C1] is the count of questions asked. The \u2018information gained\u2019 marked blue represents the previous interaction history. ", "page_idx": 27}, {"type": "table", "img_path": "CVpuVe1N22/tmp/277cab43a633a425ff12e93973acc7e577de442db6aef356790af4281c99a441.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 26: ToT Prompt for Medical Diagnosis. [C1] is the count of questions asked. The \u2018information gained\u2019 marked blue represents the previous interaction history. ", "page_idx": 27}, {"type": "table", "img_path": "CVpuVe1N22/tmp/07eb453cc2e973648d62842021d51c25e950d120ab9f72ed8522dcb1c7ed6cce.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 27: ToT prompt for Troubleshooting. [C1] is the count of questions asked. The \u2018information gained\u2019 marked blue represents the previous interaction history. ", "page_idx": 27}, {"type": "table", "img_path": "CVpuVe1N22/tmp/4c637db4aa59a3bf331033eb6ed8d346e5f2d98e6d64bf87018cdfe54725e704.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 27}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 27}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] . ", "page_idx": 27}, {"type": "text", "text": "\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available. ", "page_idx": 27}, {"type": "text", "text": "\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 27}, {"type": "table", "img_path": "CVpuVe1N22/tmp/dcdf1c1203a01c5c5c0d9b048a831e3e8db8e10381e53454bc90b1dc73990ae5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 28}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 28}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 28}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: As shown in the abstract and introduction. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: As shown in the appendix ??.   \nGuidelines: \u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: As shown in the appendix A. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: As shown in the experiment and appendix Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The code and data for this paper can be accessed through https://github .com/zhiyuanhubj/UoT/. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/pu blic/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: As shown in the experiments and appendix. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: As shown in the experimental results and analysis part. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: As shown in the Analysis section. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: As shown in the appendix J. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] https://anonymous.4open.science/r/UoT-B536/ ", "page_idx": 33}, {"type": "text", "text": "Justification: The code and data for this paper can be accessed through ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]