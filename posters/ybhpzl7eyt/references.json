{"references": [{"fullname_first_author": "Johannes L Sch\u00f6nberger", "paper_title": "Structure-from-motion revisited", "publication_date": "2016-00-00", "reason": "This paper is a foundational work in structure-from-motion, a crucial preprocessing step for many traditional 3D reconstruction methods, and the paper is frequently cited in the LSM paper"}, {"fullname_first_author": "Yao Yao", "paper_title": "Mvsnet: Depth inference for unstructured multi-view stereo", "publication_date": "2018-00-00", "reason": "MVSNet is a highly influential work in multi-view stereo, which is a core technique for generating dense 3D models from multiple images, and is frequently cited in the LSM paper"}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "NeRF introduced a novel neural representation for 3D scenes that enables high-quality novel view synthesis, and is a major influence on many recent 3D reconstruction methods, including LSM"}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduced 3D Gaussian splatting, a highly efficient and effective method for rendering neural radiance fields which is directly relevant to the LSM method"}, {"fullname_first_author": "Mehdi SM Sajjadi", "paper_title": "Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations", "publication_date": "2022-00-00", "reason": "This paper introduced a transformer-based approach to novel view synthesis without explicit geometry or camera parameters, which is a key advance that the LSM paper builds upon"}]}