[{"figure_path": "RJG8ar4wHA/figures/figures_2_1.jpg", "caption": "Figure 1: The architecture of EpoD. Left panel: the prediction of future evolution based on historical observations. Right panel: the extraction process of node-centered dynamic subgraph.", "description": "This figure illustrates the architecture of the proposed Environment-prompted Dynamic Graph Learning (EpoD) model. The left panel shows the prediction process, where historical observations are input to a spatio-temporal graph neural network (STGNN) backbone to obtain node embeddings. These embeddings are then processed by a cross-attention mechanism with prompts to generate prompt answers which help infer unseen environment variables. These variables are incorporated into the STGNN backbone along with the original input to predict future evolution. The right panel shows how node-centered dynamic subgraphs are extracted.  The asymmetry between node correlations is quantified using Kullback-Leibler divergence and then used to create dynamic subgraphs. These subgraphs effectively capture distribution shifts due to changes in the environment.", "section": "Methodology"}, {"figure_path": "RJG8ar4wHA/figures/figures_4_1.jpg", "caption": "Figure 2: SCMs of dynamic graph. (a) Traditional generation understanding of dynamic graph; (b) Indirect effect of environment factors; (c) Dynamic subgraph as mediating variable.", "description": "This figure illustrates three structural causal models (SCMs) depicting the influence of environment factors and spatial contexts on the evolution of dynamic graphs.  (a) shows a traditional SCM where environment (E) and context (C) directly influence both historical observations (X) and future evolution (Y). (b) shows an indirect effect, where environment factors indirectly influence Y through C and X. (c) introduces a novel SCM using dynamic subgraphs (Xs) as a mediating variable. This model acknowledges the impact of environment variables on the correlations between nodes within the dynamic graphs and introduces dynamic subgraphs to capture the evolving structural associations.", "section": "3.2 Spatial-temporal Learning with Dynamic Subgraph"}, {"figure_path": "RJG8ar4wHA/figures/figures_8_1.jpg", "caption": "Figure 3: Analysis on the toy dataset.", "description": "This figure shows the distribution difference between masked feature XB and prompted environment feature ZE in two scenarios: sharp temporal distribution shift and temporal distribution shift with slight signals.  The left panel (a) shows that the prompted environment variables can cover more than half of the shifted features even in the case of a sharp shift. The right panel (b) demonstrates that the prompted environment variables effectively capture even slight early signals, indicating their ability to handle OOD issues. The light blue shading represents the standard deviation.", "section": "4.3 Toy Dataset"}, {"figure_path": "RJG8ar4wHA/figures/figures_8_2.jpg", "caption": "Figure 4: A comparison of learnable prompts design approaches.", "description": "This figure compares three different approaches for designing learnable prompts: SingleP (a single globally shared prompt), EpoD (the proposed method with node-wise learnable prompts), and PrivateP (node-private learnable prompts).  It shows the time consumption (in seconds per epoch) and the performance (MAE) for each approach across three different datasets (PEMS08, PEMS07, PEMS04).  The results demonstrate that EpoD achieves a balance between computational efficiency and prediction accuracy, outperforming SingleP while maintaining comparable efficiency to PrivateP.", "section": "4.4 Ablation Study"}, {"figure_path": "RJG8ar4wHA/figures/figures_15_1.jpg", "caption": "Figure 2: SCMs of dynamic graph. (a) Traditional generation understanding of dynamic graph; (b) Indirect effect of environment factors; (c) Dynamic subgraph as mediating variable.", "description": "This figure shows three structural causal models (SCMs) illustrating different understandings of dynamic graphs. (a) shows a traditional SCM where the environment (E) and context (C) directly influence both historical observations (X) and future outcomes (Y). (b) illustrates an indirect effect, where E influences Y through C. (c) introduces a mediating variable, the dynamic subgraph (Xs), which captures the influence of E and C on Y, thereby improving adaptability to environmental changes.", "section": "3.2 Spatial-temporal Learning with Dynamic Subgraph"}, {"figure_path": "RJG8ar4wHA/figures/figures_18_1.jpg", "caption": "Figure 6: Feature description of the toy dataset.", "description": "The figure shows the composition of features in the toy dataset EnvST.  It consists of three components: XA (available evolution-causal feature), XB (unseen evolution-causal feature, masked after data generation), and XC (available evolution-spurious feature).  The figure illustrates how these features are combined and their impact on the evolution label (y).", "section": "E.4 Toy dataset"}, {"figure_path": "RJG8ar4wHA/figures/figures_19_1.jpg", "caption": "Figure 7: Performance is influenced by spurious information.", "description": "This figure shows the results of an experiment on a toy dataset (EnvST) designed to test the model's ability to handle spurious correlations. The x-axis represents the mean (\u03bc) of the spurious information, and the y-axis represents the model's performance (MAE). The shaded area represents the acceptable error bounds.  The plot demonstrates that the model's performance remains consistently within these bounds despite varying levels of spurious information, suggesting its robustness to such noise.", "section": "4.4 Ablation Study"}, {"figure_path": "RJG8ar4wHA/figures/figures_20_1.jpg", "caption": "Figure 8: Sensitivity analysis of the hyperparameter \u03b2 on four real-world datasets.", "description": "The figure shows the sensitivity analysis of the hyperparameter \u03b2 on four real-world datasets: PEMS08, PEMS04, SD, and Yelp. The x-axis represents the value of \u03b2, and the y-axis represents the performance (MAE) of the model. The shaded area represents the standard deviation of the performance. The results show that the performance of the model is not very sensitive to the value of \u03b2, but the best performance is achieved when \u03b2 is around 0.2.", "section": "G.1 Hyperparameter Sensitivity Analysis"}, {"figure_path": "RJG8ar4wHA/figures/figures_21_1.jpg", "caption": "Figure 9: The interpretability of dynamic subgraphs within real-world scenarios.", "description": "This figure shows the interpretability of dynamic subgraphs in real-world scenarios, specifically focusing on the impact of the COVID-19 pandemic on traffic flow. The top panel visualizes the dynamic subgraphs extracted by the proposed EpoD model at different time steps, illustrating how the communication among nodes (representing sensors in a traffic network) changes over time, particularly around three key nodes (shown in blue). The bottom panel displays the ground-truth of traffic flow, showing a similar pattern in suppressed communication during the pandemic's distribution shift.  This demonstrates the model's ability to capture the changes in spatial dependencies that reflect real-world events.", "section": "G.3 Interpretable Dynamic Subgraphs"}]