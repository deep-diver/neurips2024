[{"figure_path": "ztwl4ubnXV/figures/figures_1_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates the advantages of OxonFair over existing fairness toolkits. The left panel shows the trade-off between accuracy and demographic parity when enforcing fairness, highlighting the importance of jointly optimizing both metrics. The top-right panel illustrates the robustness of OxonFair to overfitting by using validation data for fairness enforcement. The bottom-right panel provides a comparison of OxonFair, Fairlearn, and AIF360 in terms of the number of methods, adjustable fairness criteria, support for multiple groups, fairness definitions, and data types.", "section": "2 Related Work"}, {"figure_path": "ztwl4ubnXV/figures/figures_3_1.jpg", "caption": "Figure 2: Left: Summary of the fast path algorithm for inferred attributes (Section 4.1). Groups are noisily estimated using a classifier. Within each estimated group, we cumulatively sum positive and negative samples that truly belong to each group. For each pair of thresholds, we select relevant sums from the inferred group and combine them. See Appendix A.1. Center: Combining two heads (original classifier and group predictor) to create a fair classifier. See Section 4.2. Right: The output of a second head predicting the protected attribute in CelebA. The pronounced bimodal distribution makes the weighted sum of the two heads a close replacement for per-group thresholds.", "description": "This figure illustrates three key aspects of the OxonFair toolkit.  The left panel details the fast path algorithm used for handling situations where group membership is inferred (noisy) rather than directly observed. It explains the efficient cumulative summation technique used for optimizing thresholds across different groups. The center panel shows how the toolkit combines two neural network heads (original classifier and a group predictor) to produce a fair classifier, thereby extending its applicability to deep learning models. Finally, the right panel showcases the output distribution of a group prediction head in the CelebA dataset, demonstrating the bimodal distribution resulting from the noisy estimation of group membership. The bimodal distribution, in turn, supports the approach where thresholds are learned for each estimated group to mitigate bias.", "section": "Inference"}, {"figure_path": "ztwl4ubnXV/figures/figures_5_1.jpg", "caption": "Figure 3: Left: Results on Compas without using group annotations at test time. Right: Runtime Comparison for Fairlearn Reductions and OxonFair on Adult using a Macbook M2. To alter the groups, we iteratively merge the smallest racial group with 'Other', reducing the search space. For both methods, we enforced demographic parity over a train set consisting of 70% of the data. Despite the exponential complexity of our approach, we remain significantly faster until we reach 5 groups. The 0.6+ indicates the seconds to train XGBoost. OxonFair(S) indicates the runtime of the naive slow pathway described in Appendix A.2 rather than our accelerated approach.", "description": "The figure compares the performance of OxonFair and Fairlearn on the COMPAS dataset (left) and the Adult dataset (right).  The left panel shows the accuracy and equal opportunity violation for various fairness methods on the COMPAS dataset without using group annotations at test time, highlighting OxonFair's performance. The right panel compares the runtime of Fairlearn Reductions and OxonFair on the Adult dataset with varying numbers of groups, demonstrating OxonFair's efficiency despite its exponential complexity for a larger number of groups.", "section": "Experimental Analysis"}, {"figure_path": "ztwl4ubnXV/figures/figures_7_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates three key aspects of OxonFair. The left panel shows the trade-off between accuracy and demographic parity when enforcing fairness using various methods.  OxonFair, unlike others, jointly optimizes both, avoiding the deterioration of fairness with improved accuracy. The top-right panel highlights OxonFair's robustness against overfitting by using validation data for fairness enforcement, unlike Fairlearn. The bottom-right panel compares OxonFair with AIF360 and Fairlearn, showcasing OxonFair's broader applicability (NLP, Computer Vision, tabular) and expressiveness in supporting diverse fairness measures and objectives.", "section": "1 Introduction"}, {"figure_path": "ztwl4ubnXV/figures/figures_7_2.jpg", "caption": "Figure 4: Left: The Pareto frontier of min. group recall vs. accuracy on Blond Hair demonstrates OxonFair's superior performance. Right: Comparing accuracy of fairness methods on 26 CelebA attributes while varying global decision thresholds to increase the minimum group recall level to \u03b4.", "description": "The left plot shows the Pareto frontier for minimum group recall versus accuracy for the 'Blond Hair' attribute in the CelebA dataset, highlighting OxonFair's superior performance. The right plot compares the accuracy of various fairness methods across 26 CelebA attributes by adjusting global decision thresholds to achieve a minimum group recall level (\u03b4).", "section": "Computer Vision and CelebA"}, {"figure_path": "ztwl4ubnXV/figures/figures_17_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates the necessity of jointly optimizing fairness and accuracy.  The left panel shows how simply adjusting classification thresholds to improve accuracy can negatively impact fairness.  The top-right panel illustrates OxonFair's robustness against overfitting by utilizing validation data, unlike Fairlearn.  Finally, the bottom-right panel offers a comparison of OxonFair's flexibility and capabilities against other popular fairness toolkits like AIF360 and Fairlearn, highlighting OxonFair's broader support for data types and fairness metrics.", "section": "Introduction"}, {"figure_path": "ztwl4ubnXV/figures/figures_21_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates the advantages of OxonFair over existing fairness toolkits. The left panel shows that optimizing for accuracy alone can lead to a deterioration in fairness. OxonFair jointly optimizes for accuracy and fairness. The top-right panel highlights the importance of using validation data to prevent overfitting and maintain fairness on unseen data. The bottom-right panel summarizes the features and capabilities of OxonFair compared to existing toolkits, such as Fairlearn and AIF360. OxonFair supports a wider range of data types and fairness criteria.", "section": "1 Introduction"}, {"figure_path": "ztwl4ubnXV/figures/figures_22_1.jpg", "caption": "Figure 8: Levelling-up with OxonFair by imposing a minimum group recall of 0.7 on the Fitzpatrick-17k [96] validation set - fpredictor.fit(gm.accuracy, gm.recall.min, 0.7).", "description": "This figure demonstrates the Pareto frontier obtained by using OxonFair to maximize accuracy while ensuring that the minimum recall across all groups is at least 0.7. The plot shows the trade-off between accuracy and minimal group recall. The points on the frontier represent different solutions, each with a different balance between accuracy and the minimum recall achieved across all groups. The selected solution (marked with a star) represents the highest accuracy achieved while meeting the minimum recall constraint.", "section": "C.3 Levelling up"}, {"figure_path": "ztwl4ubnXV/figures/figures_23_1.jpg", "caption": "Figure 9: Solutions found when enforcing demographic parity with varying rate constraints. See Appendix C.4. Left: the change in precision as we enforce demographic parity. Note that we report precision as it is more informative than accuracy for low selection rates. Right: The ratio between selection rates (i.e. disparate impact) for different groups. We report the ratio rather than the difference, as the difference tends to zero as the selection rate also tends to zero. However, as the right figure shows, this ratio becomes unstable as the rate tends to zero.", "description": "This figure demonstrates the effect of enforcing demographic parity with different rate constraints. The left panel shows the change in precision as demographic parity is enforced, highlighting that precision is a more informative metric than accuracy for low selection rates.  The right panel illustrates the ratio of selection rates between different groups, emphasizing that this ratio is more informative than the difference in selection rates, especially when selection rates are low. The instability of the ratio as selection rates approach zero is also pointed out.", "section": "C Additional Metrics"}, {"figure_path": "ztwl4ubnXV/figures/figures_25_1.jpg", "caption": "Figure 10: Comparing OxonFair and Fairret [56] on adult using sex as the protected attribute. A simple neural network classifier with two hidden layers is used as the base classifier. Fairness strengths are varied for different Fairret implementations. Difference in Equal Opportunity and Demographic Parity are considered. An OxonFair-based frontier using XGBoost is also displayed.", "description": "This figure compares the performance of OxonFair and Fairret in enforcing fairness on the adult dataset using sex as the protected attribute.  Two different base classifiers are used: a simple neural network and XGBoost.  The plots show the accuracy versus the difference in equal opportunity (DEO) and demographic parity for different settings of the Fairret algorithm, as well as the performance of OxonFair, highlighting its flexibility to achieve a range of accuracy-fairness trade-offs via its Pareto frontier.", "section": "D Comparisons with specialist methods"}, {"figure_path": "ztwl4ubnXV/figures/figures_26_1.jpg", "caption": "Figure 11: Left: A close-up of possible per-group trade-offs when enforcing Equalized odds. This figure shows possible behaviour when enforcing Equalized odds with respect to sex on the adult dataset. Compared to the original predictor, we see a substantial decrease in recall for the worst performing group accompanied by a small increase in specificity. For the better performing group, both recall and specificity are decreased in order to enforce fairness. Right: The accuracy/fairness trade-offs of OxonFair using single threshold, deterministic multi-thresholds, and randomized multi-thresholds. Single threshold performs substantially worse for strong fairness constraints, but the other two strategies are interchangeable. All results shown are on validation data.", "description": "This figure demonstrates the trade-offs involved when enforcing equalized odds fairness.  The left panel shows per-group recall and specificity changes compared to an unfair baseline classifier. The right panel compares different OxonFair thresholding strategies (single threshold, deterministic multi-thresholds, and randomized multi-thresholds) in terms of accuracy and equalized odds violation on validation data.", "section": "D.2 Specialist Equalized Odds Solvers"}, {"figure_path": "ztwl4ubnXV/figures/figures_27_1.jpg", "caption": "Figure 12: A comparison between single-threshold OxonFair and deterministic multi-threshold OxonFair with [57]. As expected, Multi-threshold is directly comparable to [57], with single threshold performing worse.", "description": "This figure compares the performance of single-threshold OxonFair, multi-threshold OxonFair, and the method from [57] in terms of equalized odds violation and accuracy.  It shows that the multi-threshold approaches (both OxonFair and the method from [57]) perform similarly, achieving lower equalized odds violations at comparable accuracy than the single-threshold OxonFair approach. This highlights the benefit of using multiple thresholds for better fairness-accuracy trade-offs.", "section": "D Comparisons with specialist methods"}, {"figure_path": "ztwl4ubnXV/figures/figures_28_1.jpg", "caption": "Figure 13: Enforcing Equalized odds using inferred characteristics. While the multi-threshold approach shows clear advantages on the validation set, this does not generalize to unseen test data. For unseen data, single threshold approaches show stronger degradation in accuracy, but their fairness constraints generalize better. This can be attributed to single threshold approaches selecting near constant classifiers when the constraints are strong, while the classifiers found by multi-threshold approaches are more vulnerable to sampling differences between validation and test.", "description": "This figure compares the performance of different methods for enforcing equalized odds fairness, specifically focusing on the impact of using inferred group characteristics (where group membership is predicted rather than directly observed) and different thresholding strategies (single threshold vs. multi-threshold). The results reveal that while multi-threshold methods are superior on the validation set, single-threshold methods generalize better to unseen test data.  This difference is attributed to the tendency of multi-threshold methods to produce classifiers that are more susceptible to differences in data distribution between validation and test sets.", "section": "Computer Vision Experiments"}, {"figure_path": "ztwl4ubnXV/figures/figures_30_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates the advantages of OxonFair over existing fairness toolkits.  The left panel shows the trade-off between accuracy and demographic parity when enforcing fairness, highlighting OxonFair's ability to jointly optimize both. The top-right panel illustrates OxonFair's robustness to overfitting by using validation data, unlike Fairlearn which overfits. The bottom-right panel compares the features and capabilities of OxonFair, Fairlearn, and AIF360, showcasing OxonFair's flexibility and broader support.", "section": "1 Introduction"}, {"figure_path": "ztwl4ubnXV/figures/figures_32_1.jpg", "caption": "Figure 1: Left: The need for an objective when enforcing fairness. We evaluate a range of methods with respect to balanced accuracy and demographic parity (OxonFair generates a frontier of solutions). Only OxonFair and RejectOptimization optimize balanced accuracy. As we improve the balanced accuracy of fair methods by adjusting classification thresholds (gray lines) fairness deteriorates. To avoid this, we jointly optimize a fairness measure and an objective. For more examples, see Figure 6. Right Top: Using validation data in fairness. We compare against Fairlearn using standard algorithms with default parameters. These methods perfectly overfit and show no unfairness with respect to equal opportunity on the trainset, but substantial unfairness on test. OxonFair enforces fairness on held-out validation data and is less prone to overfitting. Right Bottom: A comparison of toolkits. AIF360 offers a large range of tabular methods, most of which do not allow fairness metric selection, Fairlearn offers fewer but more customizable tabular methods. OxonFair offers one method that can be applied to text, image, and tabular data, while supporting more notions of fairness and objectives.", "description": "This figure demonstrates the advantages of OxonFair over other fairness toolkits.  The left panel shows the trade-off between accuracy and fairness when adjusting thresholds; OxonFair jointly optimizes both. The top-right panel illustrates OxonFair's robustness to overfitting by using validation data, unlike Fairlearn which perfectly overfits. The bottom-right panel provides a comparison of the features and capabilities of AIF360, Fairlearn, and OxonFair, highlighting OxonFair's flexibility and broader support for various data types and fairness metrics.", "section": "1 Introduction"}]