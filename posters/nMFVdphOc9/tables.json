[{"figure_path": "nMFVdphOc9/tables/tables_7_1.jpg", "caption": "Table 1: Test set performance of several state-of-the-art graph classification algorithms averaged over three different runs and 10 folds. The \u00b1 values report the standard deviation over the 10 folds. The overall best results are colored red and the best ones obtained for the fair comparison from [7] are in bold. The (features) variant of the algorithms uses the same information as the RuleGNN as input features additionally to node labels. The (paper) results are taken from the respective papers and might be obtained with different splits of the datasets.", "description": "This table compares the performance of RuleGNNs against other state-of-the-art graph neural networks on several real-world graph datasets.  It shows test set accuracy (averaged over 3 runs and 10-fold cross-validation) for various methods.  The table also indicates whether additional features (beyond node labels) were used by some algorithms, and where results are taken directly from other papers (as opposed to a consistent, unified experimental setup).", "section": "5 Experiments"}, {"figure_path": "nMFVdphOc9/tables/tables_8_1.jpg", "caption": "Table 2: Test set performance of several state-of-the-art graph classification algorithms averaged over three different runs and 10 folds. The \u00b1 values report the standard deviation over the 10 folds. The best results and our algorithm are highlighted in bold.", "description": "This table compares the performance of RuleGNNs against several other state-of-the-art graph classification algorithms on five synthetic graph datasets: LongRings, EvenOddRings, EvenOddRingsCount, CSL, and Snowflakes.  The results show the average test set accuracy and standard deviation over 10 folds and 3 different runs for each algorithm on each dataset. RuleGNN shows significantly better performance than other methods on four of the five datasets. The table helps to demonstrate the effectiveness of RuleGNNs, particularly on datasets where the graph structure plays a critical role and where expert knowledge can be easily incorporated.", "section": "5 Experiments"}, {"figure_path": "nMFVdphOc9/tables/tables_13_1.jpg", "caption": "Table 3: Details on the real-world datasets used in the experiments. The datasets are from the TU Dortmund Graph Database [13].", "description": "This table provides a detailed overview of the real-world graph datasets used in the experiments reported in the paper.  It lists the number of graphs in each dataset, along with statistics on the number of nodes and edges (maximum, average, and minimum values). It also includes the diameter (maximum, average, and minimum), the maximum number of node labels, and the number of classes in each dataset.  All datasets are sourced from the TU Dortmund Graph Database.", "section": "5 Experiments"}, {"figure_path": "nMFVdphOc9/tables/tables_14_1.jpg", "caption": "Table 3: Details on the real-world datasets used in the experiments. The datasets are from the TU Dortmund Graph Database [13].", "description": "This table presents the characteristics of six real-world graph datasets used in the paper's experiments.  For each dataset, it shows the number of graphs, the range and average number of nodes and edges, the range and average diameter of the graphs, the maximum number of node labels, and the number of classes. The datasets are sourced from the TU Dortmund Graph Database.", "section": "5 Experiments"}, {"figure_path": "nMFVdphOc9/tables/tables_15_1.jpg", "caption": "Table 1: Test set performance of several state-of-the-art graph classification algorithms averaged over three different runs and 10 folds. The \u00b1 values report the standard deviation over the 10 folds. The overall best results are colored red and the best ones obtained for the fair comparison from [7] are in bold. The (features) variant of the algorithms uses the same information as the RuleGNN as input features additionally to node labels. The (paper) results are taken from the respective papers and might be obtained with different splits of the datasets.", "description": "This table compares the performance of RuleGNNs against several state-of-the-art graph classification algorithms on several benchmark datasets.  For each algorithm and dataset, it shows the average test set accuracy over 10 folds and 3 runs, with standard deviations reported.  It also shows the results when using additional features beyond node labels, allowing for a more comprehensive comparison.", "section": "5 Experiments"}, {"figure_path": "nMFVdphOc9/tables/tables_16_1.jpg", "caption": "Table 6: Overview over the hyperparameters of the best models.", "description": "This table presents the hyperparameters used for the best performing models on various datasets.  It shows the rules used (Weisfeiler-Lehman or pattern-based), the number of Weisfeiler-Lehman iterations (k), the maximum distance considered (d), the maximum number of labels (L), and the number of learnable parameters per layer for each dataset.  The hyperparameter settings demonstrate the flexibility and adaptability of the RuleGNN model.", "section": "4.2 Rule Graph Neural Networks (RuleGNNs)"}]