[{"type": "text", "text": "Adaptive Proximal Gradient Method for Convex Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yura Malitsky ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Konstantin Mishchenko ", "page_idx": 0}, {"type": "text", "text": "Faculty of Mathematics University of Vienna, Austria yurii.malitskyi@univie.ac.at ", "page_idx": 0}, {"type": "text", "text": "Samsung AI Center, UK konsta.mish@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20]. ", "page_idx": 0}, {"type": "text", "text": "1 Intro ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we address a convex minimization problem ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x\\in\\mathbb{R}^{d}}F(x).\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "We are interested in the cases when either $F$ is differentiable and then we will use notation $F=f$ , or it has a composite additive structure as $\\boldsymbol{F}=\\boldsymbol{f}+\\boldsymbol{g}$ . Here, $f$ represents a convex and differentiable function, while $g$ is convex, lower semi-continuous (lsc), and prox-friendly. Throughout the paper, we will interchangeably refer to the smoothness of $f$ and the Lipschitzness of $\\nabla f$ , occasionally with the adjective \"locally,\" indicating that it is restricted to a bounded set. We will refer to this property as smoothness, without mentioning the Lipschitzness of $f$ , so we hope there will be no confusion in this regard. ", "page_idx": 0}, {"type": "text", "text": "For simplicity, in most of the introduction, we consider only the simpler problem $\\operatorname*{min}_{x}f(x)$ . We study one of the most classical optimization algorithms \u2014 gradient descent \u2014 ", "page_idx": 0}, {"type": "equation", "text": "$$\nx^{k+1}=x^{k}-\\alpha_{k}\\nabla f(x^{k}).\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "Its simplicity and the sole prerequisite of knowing the gradient of $f$ make it appealing for diverse applications. This method is central in modern continuous optimization, forming the bedrock for numerous extensions. ", "page_idx": 0}, {"type": "text", "text": "Given the initial point $x^{0}$ , the only thing we need to implement (1) is to choose a stepsize $\\alpha_{k}$ (also known as a learning rate in machine learning literature). This seemingly tiny detail is crucial for the method convergence and performance. When a user invokes GD as a solver, the standard approach would be to pick an arbitrary value for $\\alpha_{k}$ , run the algorithm, and observe its behavior. If it diverges at some point, the user would try a smaller stepsize and repeat the same procedure. If, on the other hand, the method takes too much time to converge, the user might try to increase the stepsize. In practice, this approach is not very efficient, as we have no theoretical guarantees for a randomly guessed stepsize, and the divergence may occur after a long time. Both underestimating and overestimating the stepsize can, thus, lead to a large overhead. ", "page_idx": 0}, {"type": "text", "text": "Below we briefly list possible approaches to choosing or estimating the stepsize and we provide a more detailed literature overview in Section 5. ", "page_idx": 1}, {"type": "text", "text": "Fixed stepsize. When $f$ is $L$ -smooth, GD can utilize a fixed stepsize $\\begin{array}{r}{\\alpha_{k}=\\alpha<\\frac{2}{L}}\\end{array}$ and values larger than $\\frac{2}{L}$ will provably lead to divergence. Consequently, in such scenarios, the rate of convergence is given by $\\begin{array}{r}{f(x^{k})-f_{*}=\\mathcal{O}\\left(\\frac{1}{\\alpha k}\\right)}\\end{array}$ , clearly indicating a direct dependence on the stepsize. Nevertheless, several drawbacks emerge from this approach: ", "page_idx": 1}, {"type": "text", "text": "(a) $L$ is not available in many practical scenarios; ", "page_idx": 1}, {"type": "text", "text": "(b) if the curvature of $f$ changes a lot, GD with the global value of $L$ may be too conservative; ", "page_idx": 1}, {"type": "text", "text": "(c) $f$ may be not globally $L$ -smooth. ", "page_idx": 1}, {"type": "text", "text": "For illustration, consider the following functions. Firstly, when dealing with $\\begin{array}{r}{f(x)=\\frac{1}{2}\\|A x-b\\|^{2}}\\end{array}$ , where $A\\in\\mathbb{R}^{n\\times d}$ and $b\\in\\mathbb{R}^{n}$ , estimating $L$ involves evaluating the largest eigenvalue of $A^{\\top}A$ . Second, the logistic loss $f(x)=\\log(1+\\exp(-b a^{\\top}x))$ , with $a\\in\\check{\\mathbb{R}}^{d},b\\in\\check{\\{}\\!-1,1\\check{\\}\\!}$ , is almost flat for large $x$ , yet for values of $x$ closer to $0$ , it has $\\begin{array}{r}{L=\\frac{1}{4}\\|a\\|^{2}}\\end{array}$ . Thus, if the solution is far from 0, gradient descent with a constant stepsize would be too conservative. Finally, consider $f(x)=x^{4}$ . While this simple objective is not globally $L$ -smooth for any value of $L$ , on any bounded set it is smooth, and we would hope we can still minimize objectives like that. ", "page_idx": 1}, {"type": "text", "text": "Linesearch. Also known as backtracking in the literature. In the $k$ -th iteration we compute $x^{k+1}$ with a certain stepsize $\\alpha_{k}$ and check a specific condition. If the condition holds, we accept $x^{k+1}$ and proceed to the next iteration; otherwise we halve $\\alpha_{k}$ and recompute $x^{k+1}$ using this reduced stepsize. This approach, while the most robust and theoretically sound, incurs substantially higher computational costs compared to regular GD due to the linesearch procedure. ", "page_idx": 1}, {"type": "text", "text": "Adagrad-type algorithms. These are the methods of the type ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v_{k}=v_{k-1}+\\|\\nabla f(\\boldsymbol{x}^{k})\\|^{2}}\\\\ {x^{k+1}=x^{k}-\\frac{d_{k}}{\\sqrt{v_{k}}}\\nabla f(\\boldsymbol{x}^{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $v_{-1}\\geq0$ is some constants, and $d_{k}$ is an estimate of $\\lVert x^{0}-x^{*}\\rVert$ for some solution $x^{*}$ . While such methods indeed have certain nice properties, $d_{k}$ is usually either constant or quickly converges to a constant value, so a quick glance at (2) will reveal that its stepsizes are decreasing. Therefore, despite the name, we cannot expect true adaptivity of this method to the local curvature of $f$ . ", "page_idx": 1}, {"type": "text", "text": "Heuristics. Numerous heuristics exist for selecting $\\alpha_{k}$ based on local properties of $f$ and $\\nabla f$ , with the Barzilai-Borwein method [BB88] being among the most widely popular. However, it is crucial to note that we are not particularly interested in such approaches, as they lack consistency and may even lead to divergence, even for simple convex problems. ", "page_idx": 1}, {"type": "text", "text": "We have already mentioned adaptivity a few times, without properly introducing it. Now let us try to properly understand its meaning in the context of gradient descent. Besides the initial point $x^{\\check{0}}$ , GD has only one degree of freedom \u2014 its stepsize. From the analysis we know that it has to be approximately an inverse of the local smoothness. We call a method adaptive, if it automatically adapts a stepsize to this local smoothness without additional expensive computation and the method does not deteriorate the rate of the original method in the worst case. In our case, the original method is GD with a fixed stepsize. ", "page_idx": 1}, {"type": "text", "text": "By this definition, GD with linesearch is not adaptive, because it finds the right stepsize with some extra evaluations of $f$ or $\\nabla f$ . GD with diminishing steps (as in subgradient or Adagrad methods) is also not adaptive, because decreasing steps cannot in general represent well the function\u2019s curvature; also the rate of the subgradient method is definitely worse. It goes without saying, that for a good method its rate must experience improvement when we confine the class of smooth convex functions to the strongly convex ones. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "In a previous work [MM20], which serves as the cornerstone for the current paper, the authors proposed an adaptive gradient method named \u201cAdaptive Gradient Descent without Descent\u201d (AdGD). In the current paper, we ", "page_idx": 2}, {"type": "text", "text": "\u2022 deepen our understanding of AdGD and identify its limitations;   \n\u2022 refine its theory to accommodate even larger steps;   \n\u2022 extend the revised algorithm from unconstrained to the proximal case. ", "page_idx": 2}, {"type": "text", "text": "The analysis in the last two cases is not a trivial extension, and we were rather pleasantly surprised that this was possible at all. After all, the theory of GD is well-established and we thought it to be too well-explored for us to discover something new. ", "page_idx": 2}, {"type": "text", "text": "Continuous point of view. It is instructive for some time to switch from the discrete setting to the continuous and to compare gradient descent (GD) with its parent \u2014 gradient flow (GF) ", "page_idx": 2}, {"type": "equation", "text": "$$\nx^{\\prime}(t)=-\\nabla f(x(t)),\\qquad x(0)=x_{0},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $t$ is the time variable and $x^{\\prime}(t)$ denotes the derivative of $x(t)$ with respect to $t$ . To guarantee the existence and uniqueness of a trajectory $x(t)$ of GF, it is sufficient to assume that $\\nabla f$ is locally Lipschitz-continuous. Then one can prove convergence of $x(t)$ to a minimizer of $f$ in just a few lines. For GD, on the other hand, the central assumption is global Lipschitzness of $\\nabla f$ . Our analysis of gradient descent makes it level: local Lipschitzness suffices for both. Or to put it differently, we provide an adaptive discretization of GF that converges under the same assumptions as the original continuous problem (3). ", "page_idx": 2}, {"type": "text", "text": "Proximal case. We emphasize that there is already an excellent extension by Latafat et al. $[\\mathrm{Lat}+23]$ of the work [MM20] to the additive composite case. Our proposed result, however, is based on an improved unconstrained analysis and uses a different (and simpler) proof. We believe that both these facts will be of interest. We don\u2019t have a good understanding why, but for us finding the proof for the proximal case was quite challenging. It does not follow the standard lines of arguments and uses a novel Lyapunov energy in the analysis. ", "page_idx": 2}, {"type": "text", "text": "Nonconvex problems. We believe that our algorithm will be no less important in the nonconvex case, where gradients are rarely globally Lipschitz continuous and where the curvature may change more drastically. It is true that our analysis applies only to the convex case, but, as far as we know, limited theory has never yet prevented practitioners from using methods in a broader setting. And based on our (speculative) experience, we found it challenging to identify nonconvex functions where the method did not converge to a local solution. ", "page_idx": 2}, {"type": "text", "text": "Outline. In Section 2, we begin by revisiting AdGD from [MM20], examining its limitations, and demonstrating a simple way to enhance it. This section maintains an informal tone, making it easily accessible for quick reading and classroom presentation. In Section 3, we further improve the method and provide all formal proofs, most of which we move to the Appendix. Section 4 extends the improved method to the proximal case. In Section 5 we put our finding in the perspective and compare it to some existing works. Lastly, in Section 6 (see also Appendix D), we conduct experiments to evaluate the proposed method against different linesearch variants. ", "page_idx": 2}, {"type": "text", "text": "1.1 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We say that a mapping is locally Lipschitz if it is Lipschitz over any compact set of its domain. A function $f:\\mathbb{R}^{d}\\stackrel{\\cdot}{\\rightarrow}\\mathbb{R}$ is (locally) smooth if its gradient $\\nabla f$ is (locally) Lipschitz. ", "page_idx": 2}, {"type": "text", "text": "A convex $L$ -smooth function $f$ is characterized by the following inequality ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(y)-f(x)-\\langle\\nabla f(x),y-x\\rangle\\geqslant\\frac{1}{2L}\\|\\nabla f(y)-\\nabla f(x)\\|^{2}\\quad\\forall x,y.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This is equivalently of saying that $\\nabla f$ is a $\\scriptstyle{\\frac{1}{L}}$ -cocoercive operator, that is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\langle\\nabla f(y)-\\nabla f(x),y-x\\rangle\\geqslant\\frac{1}{L}\\|\\nabla f(y)-\\nabla f(x)\\|^{2}\\quad\\forall x,y.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "For a convex differentiable $f$ that is not $L$ -smooth one can only say that $\\nabla f$ is monotone, that is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\langle\\nabla f(y)-\\nabla f(x),y-x\\rangle\\geqslant0\\quad\\forall x,y.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We use notation $[t]_{+}=\\operatorname*{max}\\{t,0\\}$ and for any $a>0$ we suppose that $\\begin{array}{r}{\\frac{a}{0}=+\\infty}\\end{array}$ . With a slight abuse of notation, we write $[n]$ to denote the set $\\{1,\\ldots,n\\}$ . A solution and the value of the optimization problem min $f(x)$ are denoted by $x^{*}$ and $f_{*}$ , respectively. ", "page_idx": 3}, {"type": "text", "text": "2 Adaptive gradient descent: better analysis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Let us start with the simpler problem of $\\operatorname*{min}_{x}f(x)$ with a convex, locally smooth $f\\colon\\ensuremath{\\mathbb{R}}^{d}\\to\\ensuremath{\\mathbb{R}}$ . To solve it, in [MM20], the authors proposed a method called adaptive gradient descent without descent (AdGD), whose update is given below: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\alpha_{k}=\\operatorname*{min}\\Bigl\\{\\sqrt{1+\\theta_{k-1}}\\alpha_{k-1},\\frac{\\|x^{k}-x^{k-1}\\|}{2\\left\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\right\\|}\\Bigr\\},}&{\\quad\\mathrm{where~}\\theta_{k}=\\frac{\\alpha_{k}}{\\alpha_{k-1}}\\operatorname*{max}_{i=1}^{k}\\frac{\\|x^{k}-x^{k-1}\\|}{2\\left\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\right\\|}\\Bigr\\},}\\\\ {x^{k+1}=x^{k}-\\alpha_{k}\\nabla f(x^{k}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Similarly to the standard GD, this method leads to $\\mathcal{O}(1/k)$ convergence rate. However, unlike the former, it doesn\u2019t require any knowledge about Lipschitz constant of $\\nabla f$ and doesn\u2019t even require a global Lipschitz continuity of $\\nabla f$ . ", "page_idx": 3}, {"type": "text", "text": "The update for $\\alpha_{k}$ has two ingredients. The first bound $\\alpha_{k}\\leqslant\\sqrt{1+\\theta_{k-1}}\\alpha_{k-1}$ sets how fast steps may increase from iteration to iteration. The second estimate of local Lipschitzness of . $\\begin{array}{r}{\\alpha_{k}\\leqslant\\frac{\\|x^{k}-x^{k-1}\\|}{2\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\|}}\\end{array}$ corresponds to the ", "page_idx": 3}, {"type": "text", "text": "It is important to understand how essential these bounds are. Do we really need to control the growth rate of $\\alpha_{k}$ or is it an artifact of our analysis? For the second bound, it is not clear whether 2 in the denominator is necessary. For example, given $L$ -smooth $f$ , our scheme (7) does not encompass a standard GD with $\\begin{array}{r}{\\alpha_{k}=\\frac{1}{L}}\\end{array}$ for all $k$ . ", "page_idx": 3}, {"type": "text", "text": "First bound. Answering the first question is relatively easy. Consider the following function ", "page_idx": 3}, {"type": "equation", "text": "$$\nf(x)={\\binom{\\frac{1}{2}x^{2},}{a(|x|-\\log(1+|x|))+b,}}\\quad x\\in[-1,1]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/579540dc13b89ddb223facf7a1d7e63ba9b3bbff028d400b0a3fb446300cce4b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "where parameters $a,b>0$ are chosen to ensure that $f(\\pm1)$ and $f^{\\prime}(\\pm1)$ are well-defined, namely $a=2$ and $b=2\\log2-{\\frac{3}{2}}$ , see Lemma 3 in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "From an optimization point of view, $f$ is a nice function. In particular, it is convex (even locally strongly convex) and its gradient is 1-Lipschitz, see Lemma 3. This means that both GD and AdGD linearly converge on it. However, if we remove the first condition for $\\alpha_{k}$ in AdGD, this new modified algorithm will fail to converge. We can prove an even stronger statement. Specifically, let $c\\geqslant1$ , $\\alpha_{0}=1$ and consider the following method ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\alpha_{k}=\\frac{\\|x^{k}-x^{k-1}\\|}{c\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\|},\\quad\\forall k\\geqslant1}\\\\ {\\displaystyle x^{k+1}=x^{k}-\\alpha_{k}\\nabla f(x^{k}),\\quad\\forall k\\geqslant0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In other words, the update in (9) is the same as in (7) except we removed the first constraint for $\\alpha_{k}$ in (7) and introduced a constant factor $c$ to make the second one more general. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1. For any $c\\geqslant1$ there exists $x^{0}$ such that the method (9) applied to $f$ defined in (8) diverges. ", "page_idx": 3}, {"type": "text", "text": "The formal proof of this statement is in Appendix A, but its main idea should be intuitively clear. First, observe that for $x$ with a large absolute value, $f(x)$ behaves mostly like a linear function. However, $f^{\\prime}(x)$ approaches $-1$ when $x\\to-\\infty$ and $+1$ when $x\\to+\\infty$ . Therefore, if $x^{k}$ and $x^{k-1}$ have the same sign, the local smoothness estimate will be too optimistic and $x^{k+1}$ will \u201cleapfrog\u201d the optimum. In contrast, if the signs of $x^{k}$ and $x^{k-1}$ are different, then $x^{k+1}$ will fail to get sufficiently close to the optimum. It is interesting to remark that on this function both versions of the Barzilai-Borwein method will diverge as well. ", "page_idx": 4}, {"type": "text", "text": "Consequently, the answer to the first question is affirmative: we do need some extra condition for the stepsize $\\alpha_{k}$ . ", "page_idx": 4}, {"type": "text", "text": "Second bound. The answer to the second question is the opposite: it is indeed an artifact of our previous analysis. In the next section, we propose an improvement over the previous version [MM20]. We give a concise presentation in an informal way. We keep a more formal style for section 3 where an even better version (also slightly more complicated) will be presented. ", "page_idx": 4}, {"type": "text", "text": "2.1 Improving AdGD ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The analysis of GD usually starts from the standard identity, followed by convexity inequality ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|x^{k+1}-x^{*}\\|^{2}=\\|x^{k}-\\alpha_{k}\\nabla f(x^{k})-x^{*}\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\|x^{k}-x^{*}\\|^{2}-2\\alpha_{k}\\langle\\nabla f(x^{k}),x^{k}-x^{*}\\rangle+\\alpha_{k}^{2}\\|\\nabla f(x^{k})\\|^{2}}\\\\ &{\\qquad\\qquad\\leqslant\\|x^{k}-x^{*}\\|^{2}-2\\alpha_{k}\\big(f(x^{k})-f(x^{*})\\big)+\\alpha_{k}^{2}\\|\\nabla f(x^{k})\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In [MM20] the only \u201cnontrivial\u201d step in the proof was upper bounding $\\alpha_{k}^{2}\\lvert|\\nabla f(x^{k})\\rvert|^{2}$ , that is $\\|{\\boldsymbol{x}}^{k+1}-{\\boldsymbol{x}}^{k}\\|^{2}$ . Now we do it in a slightly different way. First, we need the following fact. ", "page_idx": 4}, {"type": "text", "text": "Lemma 1. For GD iterates $(x^{k})$ with arbitrary positive stepsizes, it holds ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle\\leqslant\\|\\nabla f(x^{k-1})\\|^{2}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proof. This is just monotonicity of $\\nabla f$ in disguise: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla f(x^{k-1})\\|^{2}-\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle=\\langle\\nabla f(x^{k-1})-\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\cfrac{1}{\\alpha_{k-1}}\\langle\\nabla f(x^{k-1})-\\nabla f(x^{k}),x^{k-1}-x^{k}\\rangle\\geqslant0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Now we are going to bound $\\|{\\boldsymbol{x}}^{k+1}-{\\boldsymbol{x}}^{k}\\|^{2}$ . For convenience, denote the approximate local Lipschitz constant as ", "page_idx": 4}, {"type": "equation", "text": "$$\nL_{k}={\\frac{\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\|}{\\|x^{k}-x^{k-1}\\|}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Let $\\alpha_{k}$ satisfy $\\alpha_{k}\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\|\\,\\leqslant\\,\\gamma\\|x^{k}-x^{k-1}\\|$ for some $\\gamma\\,>\\,0$ , that is $\\alpha_{k}L_{k}\\leqslant\\gamma$ . Using $\\|u\\|^{2}=\\|u-v\\|^{2}-\\|v\\|^{2}+2\\langle u,v\\rangle$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\|x^{k+1}-x^{k}\\|^{2}=\\alpha_{k}^{2}\\|\\nabla f(x^{k})\\|^{2}}&{}&\\\\ &{\\qquad\\qquad=\\alpha_{k}^{2}\\|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\|^{2}-\\alpha_{k}^{2}\\|\\nabla f(x^{k-1})\\|^{2}+2\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&\\\\ &{\\qquad\\quad=\\alpha_{k}^{2}L_{k}^{2}\\|x^{k}-x^{k-1}\\|^{2}-\\alpha_{k}^{2}\\|\\nabla f(x^{k-1})\\|^{2}+2\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&\\\\ &{\\qquad\\quad\\overset{(1)}{\\leqslant}\\gamma^{2}\\|x^{k}-x^{k-1}\\|^{2}+\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&\\\\ &{\\qquad\\quad=\\gamma^{2}\\|x^{k}-x^{k-1}\\|^{2}+\\alpha_{k}\\theta_{k}\\langle\\nabla f(x^{k}),x^{k-1}-x^{k}\\rangle}&\\\\ &{\\qquad\\quad\\leqslant\\gamma^{2}\\|x^{k}-x^{k-1}\\|^{2}+\\alpha_{k}\\theta_{k}(f(x^{k-1})-f(x^{k})),}&{\\quad\\mathrm{(1)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the last inequality follows from convexity of $f$ . For $\\gamma<1$ we can rewrite (12) as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|x^{k+1}-x^{k}\\|^{2}\\leqslant\\frac{\\gamma^{2}}{1-\\gamma^{2}}\\|x^{k}-x^{k-1}\\|^{2}-\\frac{\\gamma^{2}}{1-\\gamma^{2}}\\|x^{k+1}-x^{k}\\|^{2}+\\frac{\\alpha_{k}\\theta_{k}}{1-\\gamma^{2}}(f(x^{k-1})-f(x^{k})).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Substituting this inequality into (10) gives us ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\displaystyle\\frac{\\gamma^{2}}{1-\\gamma^{2}}\\|x^{k+1}-x^{k}\\|^{2}+\\alpha_{k}\\left(2+\\displaystyle\\frac{\\theta_{k}}{1-\\gamma^{2}}\\right)(f(x^{k})-f_{*})}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\displaystyle\\frac{\\gamma^{2}}{1-\\gamma^{2}}\\|x^{k}-x^{k-1}\\|^{2}+\\displaystyle\\frac{\\alpha_{k}\\theta_{k}}{1-\\gamma^{2}}(f(x^{k-1})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "As we want to telescope the above inequality, we require ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\frac{\\alpha_{k}\\theta_{k}}{1-\\gamma^{2}}\\leqslant\\alpha_{k-1}\\left(2+\\frac{\\theta_{k-1}}{1-\\gamma^{2}}\\right)\\iff\\alpha_{k}^{2}\\leqslant\\left(2(1-\\gamma^{2})+\\theta_{k-1}\\right)\\alpha_{k-1}^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "On the other hand, we have already used that $\\alpha_{k}L_{k}\\leqslant\\gamma$ . These two conditions lead to the bound ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha_{k}=\\operatorname*{min}\\left\\{\\sqrt{2(1-\\gamma^{2})+\\theta_{k-1}}\\alpha_{k-1},\\frac{\\gamma}{L_{k}}\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\gamma\\in(0,1)$ can be arbitrary. Now by playing with different values of $\\gamma$ , we obtain different instances of adaptive gradient descent method. For instance, by setting $\\begin{array}{r}{\\gamma=\\frac{1}{\\sqrt{2}}}\\end{array}$ , we get ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha_{k}=\\operatorname*{min}\\left\\{\\sqrt{1+\\theta_{k-1}}\\alpha_{k-1},\\frac{1}{\\sqrt{2}L_{k}}\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which is a strict improvement upon the original version in [MM20]. A simple reason why this is possible is that, unlike in [MM20], we did not resort to the Cauchy-Schwarz inequality and instead relied on transformation (12) and Lemma 1. ", "page_idx": 5}, {"type": "table", "img_path": "qlH21Ig1IC/tmp/1e51bebbc646234cdb8010b9a894e4aaff9b18e9424c9fd9e64af694d9ae5e87.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "We summarize the new scheme in Algorithm 1. We do not provide a formal proof for this scheme and hope that inequality (13) should be sufficient for the curious reader to complete the proof. In any case, the next section will contain a further improvement with all the missing proofs. ", "page_idx": 5}, {"type": "text", "text": "Remark 1. One might notice that we have used several times monotonicity of $\\nabla f$ , where we actually could use a stronger property of cocoercivity (5). That is true, but we just prefer simplicity. We recommend work $[\\mathrm{Lat}+23]$ that exploits cocoercivity in this framework. ", "page_idx": 5}, {"type": "text", "text": "3 Adaptive gradient descent: larger stepsize ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we modify Algorithm 1 to use even larger steps resulting in Algorithm 2. This, however, will require a slightly more complex analysis. ", "page_idx": 5}, {"type": "text", "text": "Recall the notation $[t]_{+}=\\operatorname*{max}\\{t,0\\}$ and note that the second bound $\\begin{array}{r}{\\alpha_{k}\\leqslant\\frac{\\alpha_{k-1}}{\\sqrt{[2\\alpha_{k-1}^{2}L_{k}^{2}-1]_{+}}}}\\end{array}$ in step 5 of Algorithm 2 is equivalent to ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha_{k}^{2}L_{k}^{2}-\\frac{\\alpha_{k}^{2}}{2\\alpha_{k-1}^{2}}\\leqslant\\frac{1}{2},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which obviously allows for a larger range of $\\alpha_{k}$ than $\\alpha_{k}^{2}L_{k}^{2}\\,\\leqslant\\,\\frac{1}{2}$ in Algorithm 1. On the other hand, the first bound $\\begin{array}{r}{\\alpha_{k}\\leqslant\\sqrt{\\frac{2}{3}+\\theta_{k-1}}\\alpha_{k-1}}\\end{array}$ is definitely worse. At the moment, it is not even clear whether it allows $\\alpha_{k}$ to increase. ", "page_idx": 5}, {"type": "text", "text": "Remark 2. A notable distinction between Algorithm 2 and Algorithm $1$ is that the former allows to use a standard fixed step $\\begin{array}{r}{\\alpha_{k}=\\frac{1}{L}}\\end{array}$ , provided that $f$ is $L$ -smooth. For instance, if we start from $\\begin{array}{r}{\\alpha_{0}=\\frac{1}{L}}\\end{array}$ and use $L\\geqslant L_{k}$ in every iteration (we can always use a larger value), then it follows from (15) and $\\begin{array}{r}{\\theta_{k-1}\\geqslant\\frac{1}{3}}\\end{array}$ that $\\begin{array}{r}{\\alpha_{k}=\\frac{1}{L}}\\end{array}$ for all $k\\geqslant1$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 requires an initial stepsize $\\alpha_{0}$ . While the algorithm converges for any value $\\alpha_{0}>0$ , it is important to choose initial step $\\alpha_{0}$ wisely. We suggest to do the following ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{choose~}\\,\\alpha_{0}\\,\\mathrm{~such~that~}\\,\\,\\alpha_{0}L_{1}\\in\\,\\left[\\frac{1}{\\sqrt{2}},2\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The upper bound ensures that $\\alpha_{0}$ is not too large, while the lower ensures that it is not too small either. In most scenarios, this requires to run a linesearch, but we emphasize that it is only needed for the first iteration. Further discussion on this topic is in Appendix B.1. ", "page_idx": 6}, {"type": "text", "text": "We first prove that the sequence $(x^{k})$ is bounded and then derive the convergence result. Both statements are proved in Appendix B.2. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2. The sequence $(x^{k})$ is bounded. In particular, for any solution $x^{*}$ we have $x^{k}\\in B(x^{*},R)$ where ", "page_idx": 6}, {"type": "equation", "text": "$$\nR^{2}=\\|x^{0}-x^{*}\\|^{2}+2\\alpha_{0}^{2}\\|\\nabla f(x^{0})\\|^{2}+\\alpha_{0}\\big(f(x^{0})-f_{*}\\big).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 2. Let $f$ be convex with a locally Lipschitz gradient $\\nabla f$ , $\\boldsymbol{x}^{0}\\in\\mathbb{R}^{d}$ , and $\\alpha_{0}>0$ . Then the sequence $(x^{k})$ generated by Algorithm 2 converges to a solution of $\\textstyle\\operatorname*{min}_{x}f(x)$ and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}\\bigl(f(x^{i})-f_{*}\\bigr)\\leqslant\\frac{R^{2}}{2\\sum_{i=1}^{k}\\alpha_{i}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $R$ is defined as in (17). In particular, if $\\alpha_{0}$ satisfies (16), then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}\\left(f(x^{i})-f_{*}\\right)\\leqslant\\frac{L R^{2}}{\\sqrt{2}k},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $L$ is the Lipschitz constant of $\\nabla f$ over $B(x^{*},R)$ . ", "page_idx": 6}, {"type": "text", "text": "Of course, the important bound here is (18). The second bound only shows that our choice of stepsizes \u03b1k cannot be too bad. The bound in (19) is stronger than the bound 32LkR2, which could be obtained as a direct consequence of Lemma 7 with simple analysis. The derivation of the sharper bound as in (19) is presented in Appendix B.3 with, unfortunately, much more involved analysis. ", "page_idx": 6}, {"type": "text", "text": "4 Adaptive proximal gradient method ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we turn to a more general problem of composite optimization, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x}F(x):=f(x)+g(x),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $g\\colon\\mathbb{R}^{d}\\to(-\\infty,+\\infty]$ is a proper convex lsc function and $f\\colon\\ensuremath{\\mathbb{R}}^{d}\\to\\ensuremath{\\mathbb{R}}$ is a convex differentiable function with locally Lipschitz $\\nabla f$ . Additionally, we assume that $g$ is prox-friendly, that is we can efficiently compute its proximal mapping $\\mathrm{prox}_{g}\\doteq(\\mathrm{Id}+\\partial g)^{-1}$ . ", "page_idx": 6}, {"type": "text", "text": "We present Algorithm 3 that is a verbatim adaptation of Algorithm 2 with the proximal operator applied on top of the main update (similarly, it could be applied to Algorithm 1). However, its analysis is not a straightforward generalization. We encountered two issues in the proof: ", "page_idx": 6}, {"type": "text", "text": "\u2022 combining previous analysis of AdGD and the prox-mapping. As shown even in (13), we operate with the vectors $\\boldsymbol{x}^{\\tilde{k}}$ and $x^{k-1}$ in terms of $f$ . However, using the prox-inequality gives us the value $g(x^{k+1})$ , which is not straightforward to combine with $f(x^{k})$ and $\\overleftarrow{f(x^{k-1})}$ . \u2022 proving convergence of $(x^{k})$ . The challenge arises from having a non-linear update due to the prox-mapping and allowing $\\alpha_{k}$ to go to $\\infty$ , making the proof quite different from the traditional approach. ", "page_idx": 6}, {"type": "text", "text": "We define $R$ in the same way as in (17) ", "page_idx": 6}, {"type": "equation", "text": "$$\nR^{2}=\\|x^{0}-x^{*}\\|^{2}+2\\alpha_{0}^{2}\\|\\widetilde{\\nabla}F(x^{0})\\|^{2}+\\alpha_{0}(F(x^{0})-F_{*}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\widetilde\\nabla F(x^{0})$ denotes a subgradient of $F$ at $x^{0}$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm 3 Adaptive proximal gradient method ", "page_idx": 7}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/a3f084510b63819f54c5a7d7eb81bd4f86198245983b84b5f0d3767de7d67d6a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Theorem 3. Let $f$ be convex with a locally Lipschitz gradient $\\nabla f$ , g be convex lsc, $\\boldsymbol{x}^{0}\\in\\mathbb{R}^{d}$ , and $\\alpha_{0}>0$ . Then the sequence $(x^{k})$ generated by Algorithm $\\beta$ converges to a solution of (20) and ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}\\bigl(F(x^{i})-F_{*}\\bigr)\\leqslant\\frac{R^{2}}{2\\sum_{i=1}^{k}\\alpha_{i}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "In particular, $i f\\alpha_{0}$ satisfies (16), then ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}\\left(F(x^{i})-F_{*}\\right)\\leqslant\\frac{L R^{2}}{\\sqrt{2}k},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $L$ is the Lipschitz constant of $\\nabla f$ over $B(x^{*},R)$ . ", "page_idx": 7}, {"type": "text", "text": "5 Literature and discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Linesearch. There are many variants of linesearch procedures that go back to celebrated works of Goldstein [Gol62] and Armijo [Arm66]. We discuss an efficient implementation of the latter in detail in the next section. For other variants of linesearch, we refer to [BN16; Sal17]. ", "page_idx": 7}, {"type": "text", "text": "Adagrad-type methods. Original Adagrad algorithm was proposed simultaneously in [DHS11] and [MS10]. The method has had a stunning impact on machine learning applications. It has also spawned a stream of various extensions that retain the same idea of using eventually decreasing steps. Because of this, its adaptivity is more prominent in the non-smooth regime, where stepsizes must be diminishing to guarantee convergence. Recent works [DM23; IHC23] have proposed ways to increase $d_{k}$ in the update (2) and [KMJ23] even proved convergence of some Adagrad-type methods on smooth objectives. However, the stepsize in these methods eventually stops increasing, making them less adaptive. ", "page_idx": 7}, {"type": "text", "text": "In addition, Adagrad-type methods are usually sensitive to the initialization, as they either degrade in performance when $d_{k}\\,=\\,D$ and $D$ is not chosen carefully, or their convergence rate depends multiplicatively on $\\log(\\|x^{0}-x^{*}\\|/d_{0})$ . In contrast, in our methods, the cost of estimating $\\alpha_{0}$ to satisfy condition (16) is additive and its impact vanishes as the total number of iterations increases. ", "page_idx": 7}, {"type": "text", "text": "Refined results on GD with a fixed stepsize. Paper [TV22] summarizes quite well the difficulty of GD analysis with large steps. In it, the authors derive sharp convergence bounds separately for two cases $\\dot{\\alpha}L\\in(0,1]$ and $\\alpha L\\in(1,2)$ , and the latter case is considerably harder. In our analysis it is even harder, since the steps can go far beyond the global upper bound $\\frac{2}{L}$ . A surprising recent result [Gri23] showcases how little is understood in this case. ", "page_idx": 7}, {"type": "text", "text": "Small gradient. The lack-of-descent property makes it hard to deduce the $\\mathcal{O}(1/k)$ rate for the last-iterate $\\|\\nabla f(x^{k})\\|$ , which is known for GD with a fixed stepsize. We leave it as an open problem to establish a rate. ", "page_idx": 7}, {"type": "text", "text": "Extensions. Because the analysis of the algorithm is so special, it is not easy to extend it to basic generalizations of GD. However, some works have already built upon it. In [VMC21], the authors consider a convex smooth minimization subject to linear constraints and combined the adaptive GD [MM20] with the Chambolle-Pock algorithm [CP10]. The authors of $[\\mathrm{Lat}+23]$ went even further and considered a more general composite minimization problem subject to linear constraints, where the same two ideas as before were combined with a novel way of handling the prox mapping. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "If we consider variational inequalities settings in the monotone case, then it is not clear how such adaptivity can help, since the most natural extension, the forward-backward method will diverge. Furthermore, the adaptive golden ratio algorithm [Mal19], which inspired the development of AdProxGD, already includes all the features that AdProxGD has. ", "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In the experiments2 we compare our method to the ProxGD with Armijo\u2019s linesearch. We believe it is the best and arguably the most popular alternative to our method. An efficient implementation of Armijo\u2019s linesearch requires two parameters, $s>1$ and $r\\,<\\,1$ . In the $k$ -th iteration, the first iteration of linesearch starts from $\\alpha_{k}=s\\alpha_{k-1}$ , that is, we want to try a slightly larger step than in the previous iteration. If linesearch does not terminate, we start decreasing a stepsize geometrically with a ratio $r$ . Formally, we are looking for the largest $\\alpha_{k}=s r^{i}\\alpha_{k-1}$ , for $i=0,1,\\dots$ , such that for $x^{k+1}=\\mathrm{prox}_{\\alpha_{k}g}(x^{k}\\overset{\\cdot}{-}\\alpha_{k}\\nabla f(x^{k}))$ it holds that ", "page_idx": 8}, {"type": "equation", "text": "$$\nf({x}^{k+1})\\leqslant f({x}^{k})+\\langle\\nabla f({x}^{k}),{x}^{k+1}-{x}^{k}\\rangle+\\frac{1}{2\\alpha_{k}}\\|{x}^{k+1}-{x}^{k}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "It is evident that each iteration of this linesearch requires one evaluation of $f$ and $\\mathrm{prox}_{g}$ . However, it is important to highlight that in some cases, the last evaluation of $f(x^{k+1})$ (during linesearch) may not incur any additional costs, as certain expensive operations, such as matrix-vector multiplication, can be reused to compute the next gradient $\\bar{\\nabla}f(x^{k+1})$ . Throughout our comparisons, we consistently took these factors into account and reported only essential operations that cannot be further reused. ", "page_idx": 8}, {"type": "text", "text": "Our legend will stay the same for all plots: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{c c c}{\\qquad\\Longrightarrow\\mathrm{AdProxGD}}&{\\Longrightarrow(1.2,0.5)}&{\\Longrightarrow(1.5,0.8)}&{\\Longrightarrow(1.1,0.5)}\\\\ {\\qquad\\qquad(1.1,0.9)}&{\\Longrightarrow(1.5,0.5)}&{\\Longrightarrow(1.2,0.8)}&{\\Longrightarrow(1.1,0.8)}\\end{array}\\Longrightarrow(1.2,0.9)\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where each pair of numbers represents $(s,r)$ for ProxGD with linesearch described above. As we will see, the choice of $(s,r)$ matters a lot. More experiments are provided in the Appendix D. ", "page_idx": 8}, {"type": "text", "text": "Maximum likelihood estimate of the information matrix. We consider [BV04, Equation (7.5)], where our goal is to estimate the inverse of a covariance matrix $Y$ subject to eigenvalue bounds. Formally, this problem can be formulated as follows ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{X\\in\\mathbb{S}^{n}}f(X)=\\log\\operatorname*{det}X-\\operatorname{tr}(X Y)\\quad{\\mathrm{subject~to~}}\\ l I\\prec X\\prec u I,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathbb{S}^{n}$ denotes the space of $n$ -by- $n$ symmetric matrices and $A\\preccurlyeq B$ means that $B-A$ is positive semidefinite. ", "page_idx": 8}, {"type": "text", "text": "Computing projection onto the constraint set ${\\mathcal{C}}=\\{X\\colon l I\\preccurlyeq X\\preccurlyeq u I\\}$ requires computing matrix eigendecomposition. However, it is noteworthy that once the eigendecomposition is computed, both the objective and gradient evaluations can be carried out at a low cost. Consequently, when comparing methods, we only emphasized the number of projections conducted. We generated a random $y\\in\\mathbb{R}^{n}$ with entries from $N(0,10)$ and $\\delta_{i}\\,\\in\\,\\mathbb{R}^{n}$ with entries from $N(0,1)$ , and then set $y_{i}=y+\\delta_{i}$ , for i = 1, . . . , M. Then we computed Y =M1 $\\begin{array}{r}{Y=\\frac{1}{M}\\sum_{i=1}^{M}y_{i}y_{i}^{\\top}}\\end{array}$ . The results are presented in Figure 1. For two scenarios we generated, the proposed method converged faster than any of the linesearch versions. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The authors would like to thank Puya Latafat, who found a subtle error in the convergence proof of $(x^{k})$ in Theorem 3 in the first version of this manuscript. Thanks to him, we were able to simplify our proof considerably. We also thank anonymous reviewers who found many typos and inaccuracies. Yura Malitsky\u2019s research was partially funded by the Austrian Science Fund (FWF) [10.55776/STA223]. ", "page_idx": 8}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/a7db1e4f57cd7ed4abff8596acf798429e91c010e8ebec3605f99260e106498f.jpg", "img_caption": ["Figure 1: Maximum likelihood estimate, problem (24) "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[Arm66] L. Armijo. \u201cMinimization of functions having Lipschitz continuous first partial derivatives\u201d. In: Pacific J. Math. 16.1 (1966), pp. 1\u20133. DOI: 10.2140/pjm.1966.16.1.   \n[BB88] J. Barzilai and J. M. Borwein. \u201cTwo-point step size gradient methods\u201d. In: IMA J Numer Anal 8.1 (1988), pp. 141\u2013148. DOI: 10.1093/imanum/8.1.141.   \n[BN16] J. Y. Bello Cruz and T. T. Nghia. \u201cOn the convergence of the forward\u2013backward splitting method with linesearches\u201d. In: Optim. Methods Softw. 31.6 (2016), pp. 1209\u20131238.   \n[BV04] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004. DOI: 10.1017/cbo9780511804441.   \n[CP10] A. Chambolle and T. Pock. \u201cA first-order primal-dual algorithm for convex problems with applications to imaging\u201d. In: J Math Imaging Vis 40.1 (2010), pp. 120\u2013145. DOI: 10.1007/s10851- 010-0251-1.   \n[DM23] A. Defazio and K. Mishchenko. \u201cLearning-rate-free learning by D-adaptation\u201d. In: Proceedings of the 40th International Conference on Machine Learning. Vol. 202. 2023, pp. 7449\u20137479.   \n[DHS11] J. Duchi, E. Hazan, and Y. Singer. \u201cAdaptive subgradient methods for online learning and stochastic optimization\u201d. In: J. Mach. Learn. Res. 12 (2011), pp. 2121\u20132159.   \n[Gol62] A. A. Goldstein. \u201cCauchy\u2019s method of minimization\u201d. In: Numer. Math. 4.1 (1962), pp. 146\u2013150. DOI: 10.1007/bf01386306.   \n[Gri23] B. Grimmer. \u201cProvably faster gradient descent via long steps\u201d. In: (2023). arXiv: 2307.06324.   \n[IHC23] M. Ivgi, O. Hinder, and Y. Carmon. \u201cDoG is SGD\u2019s best friend: A parameter-free dynamic step size schedule\u201d. In: Proceedings of the 40th International Conference on Machine Learning. Vol. 202. 2023, pp. 14465\u201314499.   \n[KMJ23] A. Khaled, K. Mishchenko, and C. Jin. \u201cDoWG unleashed: An efficient universal parameter-free gradient descent method\u201d. In: (2023). arXiv: 2305.16284.   \n[Lat+23] P. Latafat, A. Themelis, L. Stella, and P. Patrinos. \u201cAdaptive proximal algorithms for convex optimization under local Lipschitz continuity of the gradient\u201d. In: (2023). arXiv: 2301.04431.   \n[Mal19] Y. Malitsky. \u201cGolden ratio algorithms for variational inequalities\u201d. In: Math. Program. 184.1-2 (2019), pp. 383\u2013410. DOI: 10.1007/s10107-019-01416-w. arXiv: 1803.08832.   \n[MM20] Y. Malitsky and K. Mishchenko. \u201cAdaptive gradient descent without descent\u201d. In: Proceedings of the 37th International Conference on Machine Learning. Vol. 119. Proceedings of Machine Learning Research. PMLR, 2020, pp. 6702\u20136712. arXiv: 1910.09529.   \n[MS10] H. B. McMahan and M. Streeter. \u201cAdaptive bound optimization for online convex optimization\u201d. In: Proceedings of the 23rd Annual Conference on Learning Theory (COLT). 2010.   \n[Sal17] S. Salzo. \u201cThe variable metric forward-backward splitting algorithm under mild differentiability assumptions\u201d. In: SIAM J. Optim. 27.4 (2017), pp. 2153\u20132181. DOI: 10.1137/16m1073741.   \n[TV22] M. Teboulle and Y. Vaisbourd. \u201cAn elementary approach to tight worst case complexity analysis of gradient based methods\u201d. In: Math. Program. 201.1-2 (2022), pp. 63\u201396. DOI: 10.1007/s10107- 022-01899-0.   \n[VMC21] M.-L. Vladarean, Y. Malitsky, and V. Cevher. \u201cA first-order primal-dual method with adaptivity to local smoothness\u201d. In: NeurIPS. Vol. 34. 2021, pp. 6171\u20136182. arXiv: 2110.15148. ", "page_idx": 9}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "A Counterexample ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Lemma 3. The function $f$ defined in (8) satisfies the following properties: ", "page_idx": 10}, {"type": "text", "text": "1. $f$ is convex.   \n2. $f^{\\prime}$ is $L$ -Lipschitz with $L=1$ .   \n3. $f$ is locally strongly convex, i.e., for any bounded set $\\mathcal{X}$ there exists a constant $\\mu_{\\mathcal{X}}>0$ such   \nthat $|f^{\\prime}(x)-f^{\\prime}({\\bar{y}})|\\geqslant\\mu_{X}|x-y|$ for any $x,y\\in\\mathcal{X}$ .   \n4. $|f^{\\prime}(x)|\\leqslant G$ with $G=2$ .   \n5. $f$ is 2-Lipschitz. ", "page_idx": 10}, {"type": "text", "text": "Proof. First, let us find $f^{\\prime}$ and $f^{\\prime\\prime}$ : ", "page_idx": 10}, {"type": "equation", "text": "$$\nf^{\\prime}(x)=\\left\\{x,\\qquad\\begin{array}{l l}{x\\in[-1,1]}\\\\ {\\frac{a x}{1+|x|},}&{x\\notin[-1,1]}\\end{array},\\right.\\qquad\\qquad f^{\\prime\\prime}(x)=\\left\\{\\frac{1}{(1+|x|)^{2}},\\quad x\\in[-1,1]\\right.,\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "so indeed $a=2$ and $b=2\\log2-{\\frac{3}{2}}$ . Convexity of $f$ follows from the fact that $f^{\\prime\\prime}(x)>0$ for any $x$ . Lipschitzness of $f^{\\prime}$ follows directly from the bound $f^{\\prime\\prime}(x)\\leqslant1$ for all $x$ . Similarly, local strong convexity follows from the bound $\\begin{array}{r}{f^{\\prime\\prime}(x)\\geq\\frac{1}{\\operatorname*{max}_{z\\in\\mathcal{X}}(1+|z|)^{2}}=:\\mu_{\\mathcal{X}}}\\end{array}$ for any $x\\in\\mathscr{X}$ . Finally, the last two properties trivially follow from the expression for $f^{\\prime}(x)$ . ", "page_idx": 10}, {"type": "text", "text": "Proof of Theorem 1. Let us choose $x^{0}=r+2$ with a sufficiently large $r>6c$ . This readily implies that ", "page_idx": 10}, {"type": "equation", "text": "$$\nx^{1}=x^{0}-{\\frac{2x^{0}}{1+x^{0}}}={\\frac{x^{0}(x^{0}-1)}{x^{0}+1}}>x^{0}-2=r.\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "Our goal is to show that the iterates follow a very specific pattern. Namely, we prove that for all $k\\geqslant0$ , ", "page_idx": 10}, {"type": "equation", "text": "$$\n\\mathrm{sign}(x^{2k})=\\mathrm{sign}(x^{2k+1}),\\quad\\mathrm{sign}(x^{2k+2})\\neq\\mathrm{sign}(x^{2k}),\\quad|x^{2k+2}|>2|x^{2k+1}|>|x^{2k}|.\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "If this condition holds true, then the sequence $(x^{k})$ must be divergent. ", "page_idx": 10}, {"type": "text", "text": "First, observe that if $|x^{k}|,|x^{k-1}|\\geqslant r$ and $\\mathrm{sign}(x^{k})=\\mathrm{sign}(x^{k-1})$ , then the smoothness estimate admits a simple expression: ", "page_idx": 10}, {"type": "equation", "text": "$$\nL_{k}={\\frac{|f^{\\prime}(x^{k})-f^{\\prime}(x^{k-1})|}{|x^{k}-x^{k-1}|}}={\\frac{2\\left|{\\frac{x^{k}}{1+|x^{k}|}}-{\\frac{x^{k-1}}{1+|x^{k-1}|}}\\right|}{|x^{k}-x^{k-1}|}}={\\frac{2\\left|{\\frac{|x^{k}|}{1+|x^{k}|}}-{\\frac{|x^{k-1}|}{1+|x^{k-1}|}}\\right|}{||x^{k}|-|x^{k-1}||}}\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "Therefore, in that case $\\begin{array}{r}{\\alpha_{k}|f^{\\prime}(x^{k})|\\,>\\,\\frac{r(1+|x^{k}|)}{2c}|f^{\\prime}(x^{k})|\\,=\\,\\frac{r|x^{k}|}{c}\\,>\\,3|x^{k}|,}\\end{array}$ . Since $\\operatorname{sign}(f^{\\prime}(x^{k}))\\,=$ $\\mathrm{sign}(x^{k})$ , it implies that $|x^{k+1}|>2|x^{k}|$ and $\\mathrm{sign}(x^{k+1})\\neq\\mathrm{sign}(x^{k})$ . ", "page_idx": 10}, {"type": "text", "text": "Next, if $|x^{k}|,|x^{k-1}|\\;\\geqslant\\;r\\;>\\;3$ with $|x^{k}|\\,\\geqslant\\,2|x^{k-1}|$ and $\\mathrm{sign}(x^{k})\\,\\neq\\,\\mathrm{sign}(x^{k-1})$ , then we have 12+||xxkk|| > 32 and ", "page_idx": 10}, {"type": "equation", "text": "$$\nL_{k}={\\frac{|f^{\\prime}(x^{k})-f^{\\prime}(x^{k-1})|}{|x^{k}-x^{k-1}|}}={\\frac{2\\left|{\\frac{x^{k}}{1+|x^{k}|}}-{\\frac{x^{k-1}}{1+|x^{k-1}|}}\\right|}{|x^{k}-x^{k-1}|}}={\\frac{2\\left({\\frac{|x^{k}|}{1+|x^{k}|}}+{\\frac{|x^{k-1}|}{1+|x^{k-1}|}}\\right)}{|x^{k}|+|x^{k-1}|}}\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "This implies $\\begin{array}{r}{\\alpha_{k}<\\frac{|x^{k}|}{2c}\\leqslant\\frac{|x^{k}|}{2}}\\end{array}$ . Since $\\operatorname{sign}(f^{\\prime}(x^{k}))=\\operatorname{sign}(x^{k})$ and $\\begin{array}{r}{\\frac{\\alpha_{k}}{1+|x^{k}|}\\,\\leqslant\\,\\frac{|x^{k}|}{2(1+|x^{k}|)}\\,<\\,\\frac{1}{2}}\\end{array}$ , we conclude that $\\mathrm{sign}(x^{k+1})=\\mathrm{sign}(x^{k})$ and ", "page_idx": 11}, {"type": "equation", "text": "$$\n|x^{k+1}|=\\left|x^{k}-\\alpha_{k}{\\frac{x^{k}}{1+|x^{k}|}}\\right|=|x^{k}|\\left(1-{\\frac{\\alpha_{k}}{1+|x^{k}|}}\\right)>{\\frac{1}{2}}|x^{k}|.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "As $x^{0}$ and $x^{1}$ satisfy the first case, by induction we deduce that all iterates $(x^{k})$ follow the described pattern. \u25a0 ", "page_idx": 11}, {"type": "text", "text": "B Analysis of Algorithm $^2$ ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "B.1 Initial stepsize (expanded discussion) ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Algorithm 2 requires an initial stepsize $\\alpha_{0}$ . While the algorithm converges for any value $\\alpha_{0}>0$ with the rate ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}(f(x^{i})-f_{*})\\leqslant\\frac{R^{2}}{2\\sum_{i=1}^{k}\\alpha_{i}},\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "(see eq. (17) for the definition of $R$ ), the choice of $\\alpha_{0}$ will impact further steps due to the bound $\\alpha_{k}\\leqslant\\sqrt{2/3+\\theta_{k-1}}\\alpha_{k-1}$ . Because of this reason, we do not want to choose $\\alpha_{0}$ too small. On the other hand, too large $\\alpha_{0}$ will make $R$ large. To counterbalance these two extremes, we suggest to do the following: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathrm{choose~}\\,\\alpha_{0}\\,\\mathrm{~such~that~}\\,\\,\\alpha_{0}L_{1}\\in\\,\\left[\\frac{1}{\\sqrt{2}},2\\right].\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "The upper bound ensures that $\\alpha_{0}$ is not too large, while the lower ensures that it is not too small either. In most scenarios, this requires to run a linesearch, but we emphasize one more time: it is only needed for the first iteration. In some sense, our condition (16) is similar to classical Goldstein\u2019s rule [Gol62] on selecting the stepsize: not too small and not too big. ", "page_idx": 11}, {"type": "text", "text": "Of course, if we start with a very small $\\alpha_{0}$ , only the first bound for $\\alpha_{k}$ will be active for some time, and we will eventually reach a reasonable range for a stepsize. However, linesearch with a more aggressive factor (say, 10) will allow us to reach this range faster. If we start with $\\alpha_{0}=10^{-8}$ when in fact a reasonable range for steps in this region is [1, 10], then we will need at least 100 iterations of our method, while linesearch with a factor 10 will find it in less than 10 iterations. ", "page_idx": 11}, {"type": "text", "text": "It may happen that the problem is degenerated in the sense that for any $\\alpha_{0}$ , $\\begin{array}{r}{\\alpha_{0}L_{1}<\\frac{1}{\\sqrt{2}}}\\end{array}$ . In other words, increasing $\\alpha_{0}$ leads to decreasing $L_{1}$ and linesearch may never stop. In this case we should terminate a linesearch after $\\alpha_{0}$ reaches any prescribed value, say 1. ", "page_idx": 11}, {"type": "text", "text": "B.2 Analysis of Algorithm 2 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Lemma 4. For iterates $(x^{k})$ of Algorithm 2 it holds ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\|x^{k+1}-x^{k}\\|^{2}\\leqslant{\\frac{1}{2}}\\|x^{k}-x^{k-1}\\|^{2}+{\\frac{3}{2}}\\alpha_{k}\\theta_{k}{\\big(}f(x^{k-1})-f(x^{k}){\\big)}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Before we continue, let us give some intuition for this lemma. Its analysis follows mostly the same steps as in (12). However, now we will split $\\alpha_{k}^{2}\\|\\nabla f(x^{k-1})\\|^{2}$ into two parts and use one of it to improve the smoothness bound for $\\alpha_{k}$ . ", "page_idx": 11}, {"type": "text", "text": "Proof. We start from the third line in (12) and then apply the above-mentioned splitting: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{x^{k+1}-x^{k}\\|^{2}=\\alpha_{k}^{2}L_{k}^{2}\\|x^{k}-x^{k-1}\\|^{2}-\\alpha_{k}^{2}\\|\\nabla f(x^{k-1})\\|^{2}+2\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&{}\\\\ {\\quad}&{=\\left(\\alpha_{k}^{2}L_{k}^{2}-\\frac{\\alpha_{k}^{2}}{2\\alpha_{k-1}^{2}}\\right)\\|x^{k}-x^{k-1}\\|^{2}-\\frac{\\alpha_{k}^{2}}{2}\\|\\nabla f(x^{k-1})\\|^{2}+2\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&{}\\\\ {\\quad}&{\\overset{(15)\\mathcal{K}(11)}{\\lesssim}\\frac{1}{2}\\|x^{k}-x^{k-1}\\|^{2}+\\frac{3}{2}\\alpha_{k}^{2}\\langle\\nabla f(x^{k}),\\nabla f(x^{k-1})\\rangle}&{}\\\\ {\\quad}&{=\\frac{1}{2}\\|x^{k}-x^{k-1}\\|^{2}+\\frac{3}{2}\\alpha_{k}\\theta_{k}\\langle\\nabla f(x^{k}),x^{k-1}-x^{k}\\rangle.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Convexity of $f$ completes the proof. ", "page_idx": 11}, {"type": "text", "text": "Lemma 5. For iterates $(x^{k})$ of Algorithm 2 and any solution $x^{*}$ it holds ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\|x^{k+1}-x^{k}\\|^{2}+\\alpha_{k}(2+3\\theta_{k})(f(x^{k})-f_{*})}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\|x^{k}-x^{k-1}\\|^{2}+3\\alpha_{k}\\theta_{k}(f(x^{k-1})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Proof. From (26) we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\|x^{k+1}-x^{k}\\|^{2}\\leqslant\\|x^{k}-x^{k-1}\\|^{2}-\\|x^{k+1}-x^{k}\\|^{2}+3\\alpha_{k}\\theta_{k}(f(x^{k-1})-f(x^{k})).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Using this inequality in (10), we get ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\|x^{k+1}-x^{k}\\|^{2}+2\\alpha_{k}\\big(f(x^{k})-f_{*}\\big)}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\|x^{k}-x^{k-1}\\|^{2}+3\\alpha_{k}\\theta_{k}\\big(f(x^{k-1})-f(x^{k})\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "which is equivalent to (28). ", "page_idx": 12}, {"type": "text", "text": "Proof of Lemma 2. The first bound for $\\alpha_{k}$ in Algorithm 2 gives us $3\\alpha_{k}\\theta_{k}\\leqslant(2+3\\theta_{k-1})\\alpha_{k-1}$ . We use it in (28) and telescope then to obtain ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\|x^{k+1}-x^{k}\\|^{2}+\\alpha_{k}(2+3\\theta_{k})(f(x^{k})-f_{*})}\\\\ &{\\leqslant\\|x^{1}-x^{*}\\|^{2}+\\|x^{1}-x^{0}\\|^{2}+\\alpha_{0}(2+3\\theta_{0})(f(x^{0})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "This immediately implies that $(x^{k})$ is bounded, but we would like to obtain the bound without an intermediate iterate $x^{\\dagger}$ . From (10) we know that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|x^{1}-x^{*}\\|\\leqslant\\|x^{0}-x^{*}\\|^{2}+\\alpha_{0}^{2}\\|\\nabla f(x^{0})\\|^{2}-2\\alpha_{0}(f(x^{0})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Combining it with (30), we deduce ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\|x^{k+1}-x^{k}\\|^{2}+\\alpha_{k}(2+3\\theta_{k})(f(x^{k})-f_{*})}\\\\ &{\\leqslant\\|x^{0}-x^{*}\\|^{2}+2\\alpha_{0}^{2}\\|\\nabla f(x^{0})\\|^{2}+3\\theta_{0}\\alpha_{0}(f(x^{0})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Using that $\\begin{array}{r}{\\theta_{0}=\\frac{1}{3}}\\end{array}$ completes the proof. ", "page_idx": 12}, {"type": "text", "text": "Remark 3. We could have used $\\theta_{0}=0$ as we did in Algorithm 1 which would have improved the final constant $R$ . However, since the first bound for $\\alpha_{k}$ is worse this time, we would need a more complicated initial bound for $\\alpha_{0}$ . We decided to keep it simple. ", "page_idx": 12}, {"type": "text", "text": "Notation. For brevity, we write $\\alpha_{k}\\mapsto1$ to denote that in the $k$ -th iteration $\\alpha_{k}$ satisfies the first bound, that is $\\begin{array}{r}{\\alpha_{k}=\\sqrt{\\frac{2}{3}+\\theta_{k-1}}}\\end{array}$ . Similarly, for $\\alpha_{k}\\mapsto2$ . Also let $L$ be the Lipschitz constant of $\\nabla f$ over the set $B(x^{*},\\stackrel{\\cdot}{R})$ . This means that $L_{k}\\leqslant L$ for all $k$ . ", "page_idx": 12}, {"type": "text", "text": "Next few statements are not very important for the first reading, as they only concern with a lower bound of $\\textstyle\\sum_{i=1}^{k}\\alpha_{i}$ . The main statement in Theorem 2 is valid independently of them, so the reader can go directly there. ", "page_idx": 12}, {"type": "text", "text": "Lemma 6. If $\\alpha_{k}\\mapsto2$ , then $\\begin{array}{r}{\\alpha_{k}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ and $\\begin{array}{r}{\\alpha_{k-1}+\\alpha_{k}\\geqslant\\frac{2}{L}}\\end{array}$ ", "page_idx": 12}, {"type": "text", "text": "Proof. Note that in this case \u03b1k = \u221a2\u03b1\u03b12kk\u2212\u221211L2k\u22121, and hence\u03b12k1\u22121 +\u03b112k = 2L2k. This implies that $\\begin{array}{r}{\\alpha_{k}\\geqslant\\frac{1}{\\sqrt{2}L_{k}}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ . By AM-GM inequality, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\left(\\frac{1}{\\alpha_{k-1}^{2}}+\\frac{1}{\\alpha_{k}^{2}}\\right)(\\alpha_{k-1}+\\alpha_{k})^{2}\\geqslant\\frac{2}{\\alpha_{k-1}\\alpha_{k}}\\cdot4\\alpha_{k-1}\\alpha_{k}=8\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and the conclusion $\\begin{array}{r}{\\alpha_{k-1}+\\alpha_{k}\\geqslant\\sqrt{\\frac{8}{2L_{k}^{2}}}=\\frac{2}{L_{k}}}\\end{array}$ =L2 follows. ", "page_idx": 12}, {"type": "text", "text": "Lemma 7. If $\\alpha_{0}$ satisfies (16), then $\\begin{array}{r}{\\alpha_{k}\\geqslant\\frac{1}{\\sqrt{3}L}}\\end{array}$ for all $k\\geqslant1$ . ", "page_idx": 12}, {"type": "text", "text": "Proof. We use induction. For $k=1$ , we have either $\\begin{array}{r}{\\alpha_{1}=\\sqrt{\\frac{2}{3}+\\theta_{0}}\\alpha_{0}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ or $\\alpha_{1}\\mapsto2$ , which in view of Lemma 6 also implies $\\begin{array}{r}{\\alpha_{1}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "Suppose that \u03b1k\u22121 \u2a7e \u221a13L and we must show that $\\begin{array}{r}{\\alpha_{k}\\,\\geqslant\\,\\frac{1}{\\sqrt{3}L}}\\end{array}$ . If $\\alpha_{k}\\mapsto2$ , then we are done. Therefore, suppose that $\\alpha_{k}\\mapsto1$ . Consider two options for $\\alpha_{k-1}$ . If $\\alpha_{k-1}\\mapsto1$ , then $\\theta_{k-1}\\geqslant\\sqrt{2/3}$ . Thus, for $\\alpha_{k}$ we have that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\alpha_{k}\\geqslant\\sqrt{\\frac{2}{3}+\\sqrt{\\frac{2}{3}}}\\alpha_{k-1}\\geqslant\\alpha_{k-1}\\geqslant\\frac{1}{\\sqrt{3}L}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "If $\\alpha_{k-1}\\mapsto2$ , then $\\begin{array}{r}{\\alpha_{k-1}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ and hence ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\alpha_{k}=\\sqrt{\\frac{2}{3}+\\theta_{k-1}}\\alpha_{k-1}\\geqslant\\sqrt{\\frac{2}{3}}\\cdot\\frac{1}{\\sqrt{2}L}=\\frac{1}{\\sqrt{3}L},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which completes the proof. ", "page_idx": 13}, {"type": "text", "text": "Remark 4. It is clear from above proof that condition $\\begin{array}{r}{\\alpha_{0}\\,\\geqslant\\,\\frac{1}{\\sqrt{2}L_{1}}}\\end{array}$ from (16) was used only to give us the basis for induction. Without that condition, one can still show in the same way that $\\begin{array}{r}{\\bar{\\alpha}_{k}\\geqslant\\operatorname*{min}\\{\\alpha_{0},\\frac{1}{\\sqrt{3}L}\\}}\\end{array}$ . ", "page_idx": 13}, {"type": "text", "text": "Summing this result from 1 to $k$ yields $\\begin{array}{r}{\\sum_{i=1}^{k}\\alpha_{i}\\,\\geqslant\\,\\frac{k}{\\sqrt{3}L}}\\end{array}$ . The stepsize in the previous section is lower bounded by a\u221ak2L, so it is natural to wonder: why does the current section contain a \u201clarger stepsize\u201d? The answer is that while we cannot show that each individual step is larger, we still show in the next theorem that its total length will be lower bounded by the same quantity. ", "page_idx": 13}, {"type": "text", "text": "Proof of Theorem 2. We proceed in the same way as in Lemma 2, but this time we keep all the terms that were discarded earlier. Specifically, summing (28) over all $k$ yields ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+\\|x^{k+1}-x^{k}\\|^{2}}\\\\ &{+\\,\\alpha_{k}(2+3\\theta_{k})(f(x^{k})-f_{*})+\\displaystyle\\sum_{i=1}^{k-1}(\\alpha_{i}(2+3\\theta_{i})-3\\alpha_{i+1}\\theta_{i+1})(f(x^{i})-f_{*})}\\\\ &{\\leqslant\\|x^{1}-x^{*}\\|^{2}+\\|x^{1}-x^{0}\\|^{2}+3\\alpha_{1}\\theta_{1}(f(x^{0})-f_{*})}\\\\ &{\\leqslant\\|x^{0}-x^{*}\\|^{2}+2\\alpha_{0}^{2}\\|\\nabla f(x^{0})\\|^{2}+\\alpha_{0}\\big(f(x^{0})-f_{*}\\big)=R^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the last two bounds follow from the same arguments as in Lemma 2. Note that each factor $(\\alpha_{k}(2+3\\theta_{k})-3\\alpha_{k+1}\\theta_{k+1})$ is nonnegative and their sum is ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\alpha_{k}(2+3\\theta_{k})+\\sum_{i=1}^{k-1}(\\alpha_{i}(2+3\\theta_{i})-3\\alpha_{i+1}\\theta_{i+1})=2\\sum_{i=1}^{k}\\alpha_{i}+3\\theta_{1}\\alpha_{1}\\geqslant2\\sum_{i=1}^{k}\\alpha_{i}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, we readily obtain that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{i\\in[k]}(f(x^{i})-f_{*})\\leqslant\\frac{R^{2}}{2\\sum_{i=1}^{k}\\alpha_{i}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In particular, if $\\alpha_{0}$ satisfies (16), then inequality (19) is a direct consequence of Lemma 11, which we prove in the next section. ", "page_idx": 13}, {"type": "text", "text": "It remains to prove that $(x^{k})$ converges to a solution. The next arguments will be similar to the ones in [MM20]. We have already proved that $(x^{k})$ is bounded. As $f$ is $L$ -smooth over $B(x^{*},R)$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\nf({\\boldsymbol{x}}^{*})-f({\\boldsymbol{x}}^{k})\\geqslant\\langle\\nabla f({\\boldsymbol{x}}^{k}),{\\boldsymbol{x}}^{*}-{\\boldsymbol{x}}^{k}\\rangle+\\frac{1}{2L}\\|\\nabla f({\\boldsymbol{x}}^{k})\\|^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using this sharper bound instead of plain convexity in (10) and repeating the same arguments as in Lemma 5, we end up with the same inequality plus the extra term ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle||x^{k+1}-x^{*}||^{2}+||x^{k+1}-x^{k}||^{2}+\\alpha_{k}(2+3\\theta_{k})(f(x^{k})-f_{*})+\\frac{\\alpha_{k}}{L}||\\nabla f(x^{k})||^{2}}\\\\ {\\ll||x^{k}-x^{*}||^{2}+||x^{k}-x^{k-1}||^{2}+3\\alpha_{k}\\theta_{k}(f(x^{k-1})-f_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Now, by telescoping this inequality we infer that $\\begin{array}{r}{\\sum_{i=1}^{k}\\frac{\\alpha_{i}}{L}\\|\\nabla f(x^{i})\\|^{2}\\leqslant R^{2}}\\end{array}$ . Since the sequence $\\left(\\alpha_{k}\\right)$ is separated from 0 (note that this is independ ent of condition (16) by Remark 4), we conclude that $\\nabla f(x^{k})\\,\\to\\,0$ as $k\\rightarrow\\infty$ . Hence, all limit points of $(x^{k})$ are solutions. Applying $3\\theta_{k}\\alpha_{k}\\leqslant$ $(2+3\\theta_{k-1})\\alpha_{k-1}$ in (32) we get ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\|x^{k+1}-x^{*}\\|^{2}+b_{k+1}\\leqslant\\|x^{k}-x^{*}\\|^{2}+b_{k},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $b_{k}=\\|x^{k}-x^{k-1}\\|^{2}+\\alpha_{k-1}(2+3\\theta_{k-1})(f(x^{k-1})-f_{*})$ . Then the convergence of $(x^{k})$ to a solution follows from the standard Opial-type arguments. \u25a0 ", "page_idx": 14}, {"type": "text", "text": "B.3 Better bounds for the sum of stepsizes ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we prove the bound ik=1 \u03b1i \u2a7e\u221ak2L. ", "page_idx": 14}, {"type": "text", "text": "Lemma 8. If $\\begin{array}{r}{\\theta_{k}<\\frac{1}{3}}\\end{array}$ , then $\\alpha_{k}\\mapsto2$ and $\\begin{array}{r}{\\alpha_{k-1}L_{k}>\\sqrt{5},\\alpha_{k-2}L_{k}\\geqslant\\frac{3}{2},\\alpha_{k-3}L_{k}\\geqslant1.}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "Proof. By definition, $\\alpha_{k}\\mapsto1$ means that $\\begin{array}{r}{\\alpha_{k}\\,=\\,\\sqrt{\\frac{2}{3}+\\theta_{k-1}}\\alpha_{k-1}}\\end{array}$ and thus $\\theta_{k}\\ \\geqslant\\ {\\sqrt{\\frac{2}{3}}}$ . Hence, $\\alpha_{k}\\mapsto2$ . Then we have that \u221a2\u03b121L2\u22121 < 13 which implies \u03b1k\u22121Lk > 5. Since we get a large $\\alpha_{k-1}$ , the first bound on stepsizes does not allow previous steps to be much smaller. That is the idea we shall use. ", "page_idx": 14}, {"type": "text", "text": "For any k, we have that \u03b8k \u2a7d 23 + \u03b8k\u22121. As \u03b80 \u2a7d1, it is trivial to prove that \u03b8k \u2a7d1+2131 =: t0, which is the root of $t-\\sqrt{\\frac{2}{3}+t}=0$ . From $\\alpha_{k-1}L_{k}>\\sqrt{5}$ , it follows that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sqrt{5}<\\alpha_{k-1}L_{k}\\leqslant\\sqrt{\\frac{2}{3}+\\theta_{k-2}}\\alpha_{k-2}L_{k}\\leqslant t_{0}\\alpha_{k-2}L_{k}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, to prove $\\begin{array}{r}{\\alpha_{k-2}L_{k}\\geqslant\\frac{3}{2}}\\end{array}$ , it only remains to check that $\\begin{array}{r}{\\frac{\\sqrt{5}}{t_{0}}\\geqslant\\frac{3}{2}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Similarly, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{3}{2}\\leqslant\\alpha_{k-2}L_{k}\\leqslant\\sqrt{\\frac{2}{3}+\\theta_{k-3}}\\alpha_{k-3}L_{k}\\leqslant t_{0}\\alpha_{k-3}L_{k}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "And to prove $\\alpha_{k-3}L_{k}\\geqslant1$ , we must check that $\\begin{array}{r}{\\frac{3}{2t_{0}}\\geqslant1}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Given the sequence $(\\alpha_{k})_{k\\geq1}$ , we call its element $\\alpha_{m}$ a breakpoint, if $\\textstyle\\theta_{m}<{\\frac{1}{3}}$ and $\\textstyle\\alpha_{m}<{\\frac{1}{L}}$ . The next lemma says that a small step can only occur shortly after a breakpoint. ", "page_idx": 14}, {"type": "text", "text": "Lemma 9. If $\\begin{array}{r}{\\alpha_{k}<\\frac{1}{\\sqrt{2}L}}\\end{array}$ , then exactly one of the following holds ", "page_idx": 14}, {"type": "text", "text": "Proof. In view of Lemma 6, the statement implies that $\\alpha_{k}\\mapsto1$ . Suppose that $\\alpha_{k-1}$ is not a breakpoint, since otherwise we are done. This means that either (a) $\\begin{array}{r}{\\alpha_{k-1}\\geqslant\\frac{1}{L}}\\end{array}$ or (b) $\\begin{array}{r}{\\alpha_{k-1}<\\frac{1}{L}}\\end{array}$ and $\\begin{array}{r}{\\theta_{k-1}\\stackrel{\\cdot}{\\geq}\\frac{1}{3}}\\end{array}$ . In the first case we immediately get a contradiction, since $\\begin{array}{r}{\\alpha_{k}=\\sqrt{\\frac{2}{3}+\\theta_{k-1}}\\alpha_{k-1}\\geqslant\\sqrt{\\frac{2}{3}}\\frac{1}{L}>\\frac{1}{\\sqrt{2}L}}\\end{array}$ Then if we consider (b), the bound $\\begin{array}{r}{\\theta_{k-1}\\geqslant\\frac{1}{3}}\\end{array}$ implies that $\\begin{array}{r}{\\alpha_{k-1}\\leqslant\\alpha_{k}<\\frac{1}{\\sqrt{2}L}}\\end{array}$ . Then we can apply the same arguments as above, but to $\\alpha_{k-1}$ . This means that either $\\alpha_{k-2}$ will be a breakpoint or we will have a chain $\\begin{array}{r}{\\alpha_{k-2}\\leqslant\\alpha_{k-1}\\leqslant\\alpha_{k}<\\frac{1}{\\sqrt{2}L}}\\end{array}$ . However, the latter option cannot occur, because using $\\theta_{k-1}\\geqslant1$ and $\\begin{array}{r}{\\alpha_{k-1}\\geqslant\\frac{1}{\\sqrt{3}L}}\\end{array}$ ensure us that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\alpha_{k}=\\sqrt{\\frac{2}{3}+\\theta_{k-1}}\\alpha_{k-1}\\geqslant\\sqrt{\\frac{2}{3}+1}\\frac{1}{\\sqrt{3}L}=\\frac{\\sqrt{5}}{3L}>\\frac{1}{\\sqrt{2}L}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Although a breakpoint indicates that we are in the region with a small stepsize, Lemma 8 guarantees that previous steps were quite large. The next lemma shows that in total we make significant progress. Lemma 10. If $\\alpha_{m}$ is a breakpoint, then $\\begin{array}{r}{\\sum_{j=-2}^{2}\\alpha_{m+j}>\\frac{5}{L}}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. If $\\alpha_{m}$ is a breakpoint, then on one hand Lemma 8 implies that $\\begin{array}{r}{\\alpha_{m-1}\\geqslant\\frac{\\sqrt{5}}{L_{m}}}\\end{array}$ m5 , \u03b1m\u22122 \u2a7e2L3m . On the other hand, we have that $\\begin{array}{r}{\\alpha_{m}\\geqslant\\frac{1}{\\sqrt{2}L}}\\end{array}$ \u221a2L, \u03b1m+1 \u2a7e $\\begin{array}{r}{\\alpha_{m+1}\\geqslant\\frac{1}{\\sqrt{3}L}}\\end{array}$ \u221a13L, and \u03b1m+2 \u2a7e \u221a13L. Combining, we get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{j=-2}^{2}\\alpha_{m+j}L\\geqslant\\frac{3}{2}+\\sqrt{5}+\\frac{1}{\\sqrt{2}}+\\frac{2}{\\sqrt{3}}>5.59.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma 11. If $\\alpha_{0}$ satisfies (16), then for any $k\\geqslant1$ we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}\\alpha_{i}\\geqslant{\\frac{k}{\\sqrt{2}L}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. Let $\\mathcal{M}=\\{m$ is a breakpoint: $\\textstyle\\alpha_{m+1}<{\\frac{1}{\\sqrt{2}L}}\\bigr\\}$ . We can split $\\textstyle\\sum_{i=1}^{k}\\alpha_{i}$ into two terms as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}\\alpha_{i}=\\sum_{m\\in\\mathcal{M}}\\sum_{j=-2}^{2}\\alpha_{m+j}+\\mathrm{rest}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We claim that elements in the \u201crest\u201d are greater or equal than $\\frac{1}{\\sqrt{2}L}$ 1 . Indeed, if \u03b1i < $\\begin{array}{r}{\\alpha_{i}<\\frac{1}{\\sqrt{2}L}}\\end{array}$ is in the \u201crest\u201d term, then either $\\alpha_{i-1}$ is a breakpoint or $\\begin{array}{r}{\\alpha_{i-1}<\\frac{1}{\\sqrt{2}L}}\\end{array}$ and $\\alpha_{i-2}$ is a breakpoint, as Lemma 9 suggests. In either case, $\\alpha_{i}$ must be included in the first sum, by the definition of $\\mathcal{M}$ . ", "page_idx": 15}, {"type": "text", "text": "Now let us estimate both terms. The first sum in (34) is greater than $\\begin{array}{r}{\\frac{5|{\\mathcal M}|}{L}>\\frac{5|{\\mathcal M}|}{\\sqrt{2}L}}\\end{array}$ , by Lemma 10. The total sum in the \u201crest\u201d term is not less than k\u2212\u221a5|M |. Hence, the desired inequality follows. It has to be only noted that if $k-1\\in\\mathcal{M}$ , we have to additionally consider the sum $\\begin{array}{r}{\\sum_{j=-2}^{1}\\alpha_{k-1+j}\\geqslant\\frac{4}{\\sqrt{2}L}}\\end{array}$ for which the bound follows from the same arguments as in Lemma 10. ", "page_idx": 15}, {"type": "text", "text": "uRsee $\\begin{array}{r}{\\alpha_{k-1}+\\alpha_{k}\\geqslant\\frac{2}{L}}\\end{array}$ oinuss ttehaadt  oofu r maonrael ycsiosn swearsv antoitv eo $\\frac{2}{\\sqrt{2}L}$ a.l .S iFmori lianrsltya, nwcee,  gwoht ean emvuerc $\\alpha_{k}\\mapsto2$ ,b owue ncdo uflodr every breakpoint. However, we did not want to overcomplicate an already tedious examination. We leave it as an open question if one can provide a bound closer to $\\frac{k}{L}$ (or better?) with a readable proof. ", "page_idx": 15}, {"type": "text", "text": "C Adaptive proximal gradient method ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Recall that the second bound for the stepsize $\\alpha_{k}$ is equivalent to ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\alpha_{k}^{2}\\left(L_{k}^{2}-\\frac{1}{2\\alpha_{k-1}^{2}}\\right)\\leqslant\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We can rewrite $x^{k+1}=\\operatorname{prox}_{\\alpha_{k}g}(x^{k}-\\alpha_{k}\\nabla f(x^{k}))$ as an implicit equation ", "page_idx": 15}, {"type": "equation", "text": "$$\nx^{k+1}=x^{k}-\\alpha_{k}(\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k+1})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\widetilde{\\nabla}g(x^{k+1})$ is a certain subgradient of $g$ at $x^{k+1}$ , that is $\\widetilde{\\nabla}g(x^{k+1})\\;\\in\\;\\partial g(x^{k+1})$ . For this particu lar subgradient we will also use the notation ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\widetilde{\\nabla}F(x^{k})=\\nabla F(x^{k})+\\widetilde{\\nabla}g(x^{k}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "First, we adapt our basic inequality (10) to the more general case. By prox-inequality, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\langle x^{k+1}-x^{k}+\\alpha_{k}\\nabla f(x^{k}),x-x^{k+1}\\rangle\\geqslant\\alpha_{k}(g(x^{k+1})-g(x)),\\quad\\forall x.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we set $x=x^{*}$ above and transform it into ", "page_idx": 16}, {"type": "equation", "text": "$$\nx^{k+1}-x^{*}\\|^{2}+2\\alpha_{k}(g(x^{k+1})-g(x^{*}))\\leqslant\\|x^{k}-x^{*}\\|^{2}+2\\alpha_{k}\\langle\\nabla f(x^{k}),x^{*}-x^{k+1}\\rangle-\\|x^{k+1}-x^{k}\\|\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This standard inequality is at the heart of the analysis of the proximal gradient method. To complete the full proof, or rather to get the final inequality, the classical analysis only requires applying one convexity inequality and one descent lemma to function $f$ . Our analysis, however, will be different. The main nuisance is that in the $k$ -th iteration the proximal map yields us $g(x^{k+1})-g(x^{*})$ term, while our adaptivity approach works with $f(x^{k})-f(x^{*})$ , as we remember from before. Thus, our first obstacle is to understand how to combine these two terms. ", "page_idx": 16}, {"type": "text", "text": "First, we estimate the term $\\langle\\nabla f(x^{k}),x^{*}-x^{k+1}\\rangle$ in the RHS of (38). We have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla f(x^{k}),x^{*}-x^{k+1}\\rangle=\\langle\\nabla f(x^{k}),x^{*}-x^{k}\\rangle+\\langle\\nabla f(x^{k}),x^{k}-x^{k+1}\\rangle}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\langle\\nabla f(x^{k}),x^{*}-x^{k}\\rangle+\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),x^{k}-x^{k+1}\\rangle+\\langle\\widetilde{\\nabla}g(x^{k}),x^{k+1}-x^{k+1}\\rangle}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\leqslant f(x^{*})-f(x^{k})+\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),x^{k}-x^{k+1}\\rangle+g(x^{k+1})-g(x^{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where in the last inequality we used separately convexity of $f$ and $g$ . Applying this inequality in (38) yields ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|x^{k+1}-x^{*}\\|^{2}+2\\alpha_{k}(F(x^{k})-F(x^{*}))}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+2\\alpha_{k}\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),x^{k}-x^{k+1}\\rangle-\\|x^{k+1}-x^{k}\\|^{2}}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\alpha_{k}^{2}\\|\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k})\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "As we see, the final inequality is very much in the spirit of (10). ", "page_idx": 16}, {"type": "text", "text": "Lemma 12 (Compare to Lemma 1). For iterates $(x^{k})$ with arbitrary stepsizes, it holds ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\rangle\\leqslant\\|\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\|^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. As before, this is just monotonicity of $\\nabla f$ in disguise: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\|^{2}-\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\rangle}\\\\ &{\\quad\\quad=\\langle\\nabla f(x^{k-1})-\\nabla f(x^{k}),\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\rangle}\\\\ &{\\quad\\quad=\\cfrac{1}{\\alpha_{k-1}}\\langle\\nabla f(x^{k-1})-\\nabla f(x^{k}),x^{k-1}-x^{k}\\rangle\\geqslant0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The next lemma is special for the composite case. Although it looks like this fact should be known in the literature, we were not able to identify it. ", "page_idx": 16}, {"type": "text", "text": "Lemma 13. For iterates $(x^{k})$ of the proximal gradient method with arbitrary stepsizes, it holds ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\nabla f(x^{k})+\\widetilde\\nabla g(x^{k+1})\\|\\leq\\|\\nabla f(x^{k})+\\widetilde\\nabla g(x^{k})\\|.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. This time it is just a monotonicity of $\\partial g$ in disguise: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k})\\|^{2}=\\|\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k+1})+\\widetilde{\\nabla}g(x^{k})-\\widetilde{\\nabla}g(x^{k+1})\\|^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\overset{(36)}{=}\\left\\|\\frac{1}{\\alpha_{k}}(x^{k}-x^{k+1})+\\widetilde{\\nabla}g(x^{k})-\\widetilde{\\nabla}g(x^{k+1})\\right\\|^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\frac{1}{\\alpha_{k}^{2}}\\|x^{k}-x^{k+1}\\|^{2}+\\frac{2}{\\alpha_{k}}\\langle x^{k}-x^{k+1},\\widetilde{\\nabla}g(x^{k})-\\widetilde{\\nabla}g(x^{k+1})\\rangle+\\|\\widetilde{\\nabla}g(x^{k})-\\widetilde{\\nabla}g(x^{k+1})\\|^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\geqslant\\frac{1}{\\alpha_{k}^{2}}\\|x^{k}-x^{k+1}\\|^{2}+\\frac{2}{\\alpha_{k}}\\langle x^{k}-x^{k+1},\\widetilde{\\nabla}g(x^{k})-\\widetilde{\\nabla}g(x^{k+1})\\rangle}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\geqslant\\|\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k+1})\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last inequality follows from monotonicity of $\\partial g$ and (36). ", "page_idx": 16}, {"type": "text", "text": "In Section 3 we estimated $\\|x^{k+1}\\,-\\,x^{k}\\|^{2}\\;=\\;\\alpha_{k}^{2}\\|\\nabla f(x^{k})\\|^{2}$ . This time, $\\|x^{k+1}\\,-\\,x^{k}\\|^{2}$ and $\\alpha_{k}^{2}\\|\\widetilde{\\nabla}F(\\boldsymbol{x}^{k})\\|^{2}$ are different and it is the latter term that matters to us. ", "page_idx": 17}, {"type": "text", "text": "Lemma 14 (Compare to Lemma 4). For iterates $(x^{k})$ of Algorithm 3 it holds ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\alpha_{k}^{2}\\|\\widetilde\\nabla F(x^{k})\\|^{2}\\leqslant\\frac{\\alpha_{k-1}^{2}}{2}\\|\\widetilde\\nabla F(x^{k-1})\\|^{2}+\\frac{3}{2}\\alpha_{k}\\theta_{k}(F(x^{k-1})-F(x^{k})).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. The main idea of the proof is exactly the same as in Lemma 4. However, the presence of $\\widetilde{\\nabla}g(x^{k})$ make it slightly more cumbersome. The previous two lemmata are instrumental on our way. We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha_{k}^{2}\\big|\\nabla f(x^{k})+\\widehat{\\nabla}g(x^{k})\\big|^{2}=\\alpha_{k}^{2}\\big|\\nabla f(x^{k})-\\nabla f(x^{k-1})\\big|^{2}-\\alpha_{k}^{2}\\big|\\nabla f(x^{k-1})+\\widehat{\\nabla}g(x^{k})\\big|^{2}}\\\\ &{\\qquad\\qquad+2\\alpha_{k}^{2}\\big|\\nabla f(x^{k})+\\widehat{\\nabla}g(x^{k}),\\nabla f(x^{k-1})+\\widehat{\\nabla}g(x^{k})\\big|\\big|\\nabla f(x^{k-1})+\\widehat{\\nabla}g(x^{k-1})+\\widehat{\\nabla}g(x^{k})\\big|^{2}}\\\\ &{=\\alpha_{k}^{2}L_{k}^{2}\\big|\\big|x^{k}-x^{k-1}\\big|^{2}-\\frac{\\alpha_{k}^{2}}{2\\alpha_{k}^{2}-1}\\big|x^{k}-x^{k-1}\\big|^{2}-\\frac{\\alpha_{k}^{2}}{2}\\big|\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\big|^{2}}\\\\ &{\\qquad\\qquad+2\\alpha_{k}^{2}\\big\\langle\\nabla f(x^{k})+\\widehat{\\nabla}g(x^{k}),\\nabla f(x^{k-1})+\\widehat{\\nabla}g(x^{k})\\big\\rangle}\\\\ &{\\overset{(i)^{2}}{\\leqslant}\\alpha_{k}^{2}\\left(L_{k}^{2}-\\frac{1}{2\\alpha_{k-1}^{2}}\\right)\\|x^{k}-x^{k-1}\\|^{2}+\\frac{3\\alpha_{k}^{2}}{2}\\big\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\big\\rangle}\\\\ &{\\overset{(b)\\leq k\\delta\\delta}{\\leqslant}\\frac{1}{2}\\big\\|x^{k}-x^{k-1}\\big\\|^{2}+\\frac{3}{2}\\alpha_{k}\\theta_{k}\\langle\\nabla f(x^{k})+\\widetilde{\\nabla}g(x^{k}),x^{k-1}-x^{k}\\rangle}\\\\ &{\\overset{(b)\\leq}\\frac{\\alpha_{k-1}^{2}}{2}\\big\\|\\nabla f(x^{k-1})+\\widetilde{\\nabla}g(x^{k})\\big\\|^{2}+\\frac{3}{2}\\alpha_{k}\\\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Convexity of $F$ completes the proof. ", "page_idx": 17}, {"type": "text", "text": "Lemma 15 (Compare to Lemma 5). For iterates $(x^{k})$ of Algorithm 3 and any solution $x^{*}$ it holds ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\|x^{k+1}-x^{*}\\|^{2}+\\alpha_{k}^{2}\\|\\widetilde{\\nabla}F(x^{k})\\|^{2}+\\alpha_{k}(2+3\\theta_{k})(F(x^{k})-F_{*})}\\\\ &{}&{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\alpha_{k-1}^{2}\\|\\widetilde{\\nabla}F(x^{k-1})\\|^{2}+3\\alpha_{k}\\theta_{k}(F(x^{k-1})-F_{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. The same as in Lemma 5. ", "page_idx": 17}, {"type": "text", "text": "Recall that we define $R$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\nR^{2}=\\|x^{0}-x^{*}\\|^{2}+2\\alpha_{0}^{2}\\|\\widetilde{\\nabla}F(x^{0})\\|^{2}+\\alpha_{0}(F(x^{0})-F_{*}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Lemma 16. The sequence $(x^{k})$ is bounded. In particular, for any solution $x^{*}$ of (20) we have $x^{k}\\in B(x^{*},R)$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. The same as in Lemma 2. We use (42) to telescope until $k=1$ and then apply (39) with $k=0$ to bound $\\|\\boldsymbol{x}^{1}-\\boldsymbol{x}^{*}\\|^{2}$ . \u25a0 ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 3. The proof of inequalities (22) and (23) is almost identical to the one in Theorem 2. The proof of convergence of $(x^{\\bar{k}})$ to a solution is, however, more nuanced. The nontrivial part is to show that all limit points of $(x^{k})$ are solutions. While on the surface, it should be no harder than before, the fact that $\\scriptstyle\\operatorname*{lim}_{k\\to+\\infty}\\alpha_{k}$ can be $+\\infty$ complicates things a bit. ", "page_idx": 17}, {"type": "text", "text": "Let $x^{*}$ be a solution of (20). By $L$ -smoothness of $f$ over $B(x^{*},R)$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nf({\\boldsymbol{x}}^{*})-f({\\boldsymbol{x}}^{k})\\geqslant\\langle\\nabla f({\\boldsymbol{x}}^{k}),{\\boldsymbol{x}}^{*}-{\\boldsymbol{x}}^{k}\\rangle+\\frac{1}{2L}\\|\\nabla f({\\boldsymbol{x}}^{k})-\\nabla f({\\boldsymbol{x}}^{*})\\|^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Using this improved bound, similarly to how it was done in (32), we get ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\|x^{k+1}-x^{*}\\|^{2}+\\alpha_{k}^{2}\\|\\tilde{\\nabla}F(x^{k})\\|^{2}+\\alpha_{k}(2+3\\theta_{k})(F(x^{k})-F_{*})+\\frac{\\alpha_{k}}{L}\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|^{2}}}\\\\ &{\\leqslant\\|x^{k}-x^{*}\\|^{2}+\\alpha_{k-1}^{2}\\|\\tilde{\\nabla}F(x^{k-1})\\|^{2}+3\\alpha_{k}\\theta_{k}(F(x^{k-1})-F_{*}).}&{\\quad{\\mathrm{(4)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By telescoping this inequality as before, we can now additionally infer that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\infty}\\alpha_{k}\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|^{2}<+\\infty\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and thus, $\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|\\to0.$ . Specifically, this implies $\\nabla f(x^{k})-\\nabla f(x^{k-1})\\rightarrow0$ as $k\\rightarrow\\infty$ . We want to prove that all limit points of $(x^{k})$ are solutions. To this end, we will use prox-inequality (37) rewritten as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{\\alpha_{k}}\\langle x^{k+1}-x^{k},x-x^{k+1}\\rangle+\\langle\\nabla f(x^{k}),x-x^{k+1}\\rangle\\geqslant g(x^{k+1})-g(x),\\forall x\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which in turn, by convexity of $f$ , leads to ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{\\alpha_{k}}\\langle x^{k+1}-x^{k},x-x^{k+1}\\rangle+\\langle\\nabla f(x^{k})-\\nabla f(x^{k+1}),x-x^{k+1}\\rangle\\geqslant F(x^{k+1})-F(x).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The left-hand side has two terms, and the second term evidently tends to 0 as $\\nabla f(x^{k+1})-\\nabla f(x^{k})\\rightarrow$ 0. If we can show the same for the first term, it will imply that all limit points of $(x^{k})$ are solutions. Consider (46) again, but this time we set $x=x^{k}$ . This yields ", "page_idx": 18}, {"type": "equation", "text": "$$\n-{\\frac{1}{\\alpha_{k}}}\\|x^{k+1}-x^{k}\\|^{2}+\\langle\\nabla f(x^{k}),x^{k}-x^{k+1}\\rangle\\geqslant g(x^{k+1})-g(x^{k}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We manipulate the inequality above as follows ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{\\gamma_{k}}\\|x^{k+1}-x^{k}\\|^{2}\\leqslant\\langle\\nabla f(x^{k}),x^{k}-x^{k+1}\\rangle+g(x^{k})-g(x^{k+1})\\quad}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\langle\\nabla f(x^{k})-\\nabla f(x^{*}),x^{k}-x^{k+1}\\rangle+\\underbrace{\\langle\\nabla f(x^{*}),x^{k}-x^{k+1}\\rangle+g(x^{k})-g(x^{k+1})}_{\\delta_{k}}}\\\\ &{\\qquad\\qquad\\qquad\\leqslant\\frac{\\alpha_{k}}{2}\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|^{2}+\\frac{1}{2\\alpha_{k}}\\|x^{k+1}-x^{k}\\|^{2}+\\delta_{k},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where in the last inequality we applied Cauchy-Schwarz and Young\u2019s inequalities. From this we deduce that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{\\alpha_{k}}\\|x^{k+1}-x^{k}\\|^{2}\\leqslant\\alpha_{k}\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|^{2}+2\\delta_{k}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that the sequence $\\left(\\alpha_{k}\\|\\nabla f(x^{k})-\\nabla f(x^{*})\\|^{2}\\right)$ is summable by (45). Also, the sequence $\\left(\\delta_{k}\\right)$ is summable, since $(x^{k})$ is bounded and $g(x^{k})$ is lower-bounded: $g(x^{k})\\geqslant F_{*}-f(x^{k})>-\\infty$ for all $k$ . Hence, $\\begin{array}{r}{\\sum_{k}\\frac{1}{\\alpha_{k}}\\|x^{k+1}-x^{k}\\|^{2}<+\\infty}\\end{array}$ and, thus, $\\begin{array}{r}{\\frac{1}{\\alpha_{k}}\\|x^{k+1}-x^{k}\\|^{2}\\rightarrow0}\\end{array}$ as $k\\to+\\infty$ . Given that $\\left(\\alpha_{k}\\right)$ is separated from zero, it immediately follows that $\\begin{array}{r}{\\frac{1}{\\alpha_{k}}\\|x^{k+1}-x^{k}\\|\\rightarrow0}\\end{array}$ as well. ", "page_idx": 18}, {"type": "text", "text": "Therefore, we have proved that all limit points of $(x^{k})$ are solutions. The proof of convergence of the whole sequence $(x^{k})$ runs as before in Theorem 2. \u25a0 ", "page_idx": 18}, {"type": "text", "text": "Remark 6. We didn\u2019t derive a linear convergence of the adaptive proximal gradient, when $F$ is strongly convex. We only mention that it is quite straightforward and goes along the same lines as the original AdGD in [MM20, Theorem 2] in the strongly convex regime. ", "page_idx": 18}, {"type": "text", "text": "D Additional experiments ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Low-rank matrix completion. We consider a famous low-rank matrix completion problem in the form ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{X\\in\\mathbb{R}^{n\\times n}}\\frac{1}{2}\\|P_{\\Omega}(X-A)\\|_{F}^{2}\\quad\\mathrm{subject}\\,\\,\\mathrm{to}\\quad\\|X\\|_{*}\\leqslant r,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\Omega$ is a subset of indices $(i,j)$ and $r$ is the supposed maximum rank. To project onto the spectral ball ${\\mathcal{C}}=\\{X\\colon\\|X\\|_{*}\\leqslant r\\}$ , computing the singular value decomposition (SVD) is required, making it the most computationally expensive operation in this setting. ", "page_idx": 18}, {"type": "text", "text": "We created matrix $A$ by multiplying matrices $U$ and $V^{\\top}$ , where $U$ and $V$ are $n$ -by- $r$ matrices with entries sampled from a normal distribution. The subset $\\Omega$ was randomly chosen as a fraction of $\\scriptstyle{\\frac{1}{5}}n^{2}$ entries from $[n]\\times[n]$ . The obtained results are depicted in Figure 2, where we solely compared the number of computed SVDs. For two scenarios we generated, the proposed method was always faster than any of the linesearch versions. ", "page_idx": 18}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/ac513034d9b2f4255edb7f4950f5a7f1eda10897589746de1b5abdabd34f25ad.jpg", "img_caption": ["Figure 2: Low-rank matrix completion, problem (48) "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Minimal length piecewise-linear curve subject to linear constraints. We consider [BV04, Example 10.4], where we want to minimize the length of a piecewise-linear curve passing through $n$ points in $\\mathbb{R}^{2}$ with coordinates $(1,x_{1}),\\ldots,(n,x_{n})$ while satisfying linear constraints $A x=b$ , where $\\boldsymbol{x}=(x_{1},\\dots,x_{n})$ . Given $A\\in\\mathbb{R}^{m\\times n}$ and $b\\in\\mathbb{R}^{m}$ , this can be modeled as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x\\in\\mathbb{R}^{n}}(1+x_{1}^{2})^{1/2}+\\sum_{i=1}^{n-1}(1+(x_{i+1}-x_{i})^{2})^{1/2}\\quad{\\mathrm{subject}}\\ \\mathrm{to}\\quad A x=b.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "While applying the proximal gradient method, the most computationally expensive operation is computing the projection onto ${\\mathcal{C}}=\\{x\\colon A x=b\\}$ . Assuming that $A$ is full rank with $m\\leqslant n$ , this projection can be computed as $P_{\\mathcal{C}}z=z-A^{\\top}(A A^{\\top})^{-1}(A z-b)$ . ", "page_idx": 19}, {"type": "text", "text": "In comparison, we focused solely on the number of computed projections. We generated a random $m$ -by- $n$ matrix $A$ and random vector $w$ with entries sampled from a normal distribution and set $b=A w$ . In Figure 3, we can see again that the proposed method converged faster than any of the linesearch versions. ", "page_idx": 19}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/0951fcf8ad385da6938e4f948644222ccc33a713c33a7929c4ef4131778c1d05.jpg", "img_caption": ["Figure 3: Minimal length piecewise-linear curve, problem (49) "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Nonnegative matrix factorization. We want to solve the matrix factorization problem subject to nonnegative constraints: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{U,V\\in\\mathbb{R}_{+}^{n\\times r}}f(U,V)=\\frac{1}{2}\\|U V^{\\top}-A\\|_{F}^{2},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $A$ is a given $n$ -by- ${\\mathbf{\\nabla}}n$ low-rank matrix. Although nonconvex, this problem is famously welltackled by first-order methods. In each iteration, the gradient $\\nabla f(x)$ involves 3 matrix-matrix multiplications, whereas evaluating the objective $f(x)$ only requires 1. Note that for the last iteration of the linesearch, the computed matrix product can be reused to compute the gradient for the next iteration. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "We created matrix $A$ by multiplying matrices $B$ and $C^{\\top}$ , where $B$ and $C$ are $n$ -by- $r$ matrices with entries sampled from a normal distribution. Negative entries in both matrices $B$ and $C$ were then set to zero. The results are presented in Figure 4, where the number of gradients roughly means the number of 3 matrix-matrix multiplications. In both cases we generated, the proposed method converged faster than any of the linesearch versions. ", "page_idx": 20}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/338c70ce7193c2ac57c713378f08e2c51916c75a8a560060265a72772b95a15d.jpg", "img_caption": ["Figure 4: Nonnegative matrix factorization, problem (50) "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Dual of the entropy maximization problem. Consider the entropy maximization problem subject to linear constraints ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\sum_{i=1}^{n}x_{i}\\log x_{i}\\quad{\\mathrm{subject~to~}}A x\\leqslant b,\\quad\\sum_{i=1}^{n}x_{i}=1,{\\mathrm{and}}\\ x_{i}>0,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $A\\in\\mathbb{R}^{m\\times n}$ . Its dual problem is given by ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\lambda\\in\\mathbb{R}_{+}^{m},\\mu\\in\\mathbb{R}}e^{-\\mu-1}\\sum_{i=1}^{n}e^{-a_{i}^{\\top}\\lambda}+\\langle b,\\lambda\\rangle+\\mu,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $a_{i}\\in\\mathbb{R}^{m}$ is the $i$ -th column of $A$ (the derivation is provided in [BV04, Chapter 5.1.6]). ", "page_idx": 20}, {"type": "image", "img_path": "qlH21Ig1IC/tmp/a44753b7f7fd836effe20ee48b25c2d8c3701281291c5e08fb12b75bd116f3ad.jpg", "img_caption": ["Figure 5: Dual of the entropy maximization, problem (52) "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "It is the latter problem (52) that we solved. We generated $m$ -by- ${\\boldsymbol{n}}$ matrix $A$ with entries sampled from a normal distribution. Then we generated a random $w\\,\\in\\,\\mathbb{R}^{n}$ from the unit simplex and set $b=A w$ . Each gradient requires two matrix-vector multiplications, while the objective evaluation requires only one (and, as before, the last one can be reused for the next gradient). The results are presented in Figure 5, where the number of gradients roughly means the number of 2 matrix-vector multiplications. In the first scenario, the proposed method is faster than all the linesearch versions, while in the second one, only one version of linesearch was comparable in performance. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Conclusion. Based on our preliminary experiments, it is evident that AdProxGD indeed performs better. To our surprise, a few specific pairs $(r,s)$ consistently outperform the rest among ProxGD with linesearch. We are not aware of any theoretical finding that would confirm this evidence. Also, from a numerical point of view, the linesearch implementation is not always robust. In particular, when we are already close to a solution, the linesearch condition can sometimes fail because the numbers it operates on are all very small. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The abstract and introduction describes our contributions in details. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We discuss the limitations in the Literature and Discussion section, as well as in other various parts of the paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Each statement has a proof either in the main text or in Appendix. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: We describe in details how a random data was generated for the experiments.   \nThe code is publicly available. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The code is publicly available. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: It is described in details which parameters were used. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: There are no error bars for the experiments. The paper is mostly of theoretical interest. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is not important for our experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is a theoretical paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is a theoretical work that does not have any foreseeable societal impacts. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This is a theoretical paper. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: All experiments were randomly generated. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 26}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: There are no new assets. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not contain a study involving human subjects. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not contain a study involving human subjects. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]