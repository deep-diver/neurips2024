{"references": [{"fullname_first_author": "L. Armijo", "paper_title": "Minimization of functions having Lipschitz continuous first partial derivatives", "publication_date": "1966-01-01", "reason": "This paper introduces a fundamental linesearch method used in many optimization algorithms, including those discussed in the current paper."}, {"fullname_first_author": "J. Barzilai", "paper_title": "Two-point step size gradient methods", "publication_date": "1988-01-01", "reason": "This paper proposes a popular heuristic for selecting step sizes in gradient descent, providing an alternative to the methods presented in the current paper."}, {"fullname_first_author": "A. Chambolle", "paper_title": "A first-order primal-dual algorithm for convex problems with applications to imaging", "publication_date": "2011-01-01", "reason": "This paper presents a well-known primal-dual algorithm for convex optimization problems, which is extended in the current paper to handle composite problems."}, {"fullname_first_author": "J. Duchi", "paper_title": "Adaptive subgradient methods for online learning and stochastic optimization", "publication_date": "2011-01-01", "reason": "This paper introduces the Adagrad algorithm, a seminal adaptive method for gradient-based optimization, which is analyzed and improved upon in this paper."}, {"fullname_first_author": "Y. Malitsky", "paper_title": "Adaptive gradient descent without descent", "publication_date": "2020-01-01", "reason": "This paper introduces the AdGD algorithm, which serves as the foundation for the adaptive methods presented in the current paper."}]}