[{"figure_path": "ZvQ4Bn75kN/figures/figures_1_1.jpg", "caption": "Figure 1: Characteristics of Motion FeaTure (MOFT). (a-b) Rich Motion Information: We extract MOFT at the red point in the reference video in (a) and draw similarity heatmaps in (b) across various videos (yellow indicates higher similarity). The heatmap aligns well with the motion flow in the bottom left. (c) MOFT serves as guidance for controlling motion direction in the light-masked region, with the motion direction signal illustrated by red arrows in the first image.", "description": "This figure demonstrates the characteristics of the Motion Feature (MOFT).  The first row shows how MOFT captures rich motion information.  Part (a) indicates the point where MOFT is extracted from a reference video, and (b) shows a similarity heatmap of the MOFT across different videos, illustrating the alignment between MOFT similarity and motion flow. The second row (c) shows how MOFT guides motion control by directing motion in a specific region, as shown by the red arrows.", "section": "3 MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_3_1.jpg", "caption": "Figure 2: Visualization of PCA on video diffusion features. The left side indicates the frame-wise panning direction, with each color representing a specific direction pattern. We apply PCA to diffusion features extracted from videos with different motion directions and plot their projections on the leading two principle components. (a) The result does not exhibit a distinguishable correlation with motion direction. (b) Features are clearly separated by their motion direction.", "description": "This figure visualizes the results of Principal Component Analysis (PCA) applied to video diffusion features.  It shows how the removal of content correlation from the features makes the motion direction more clearly distinguishable in the PCA analysis. The left subplot (a) shows PCA on vanilla features where motion direction isn't clearly separated. In contrast, the right subplot (b) shows the improved separability of motion directions after the content correlation is removed.", "section": "3 MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_3_2.jpg", "caption": "Figure 3: Cross-frame Channel Value. (a) We plot the histogram of the weight of P\u2081. It reveals that only a few channels significantly contribute to determining the principal components. (b-c) The motion channels exhibit a pronounced correlation with motion direction trends. (d) In contrast, the non-motion channels show little correspondence with motion direction.", "description": "The figure visualizes the relationship between principal components derived from video diffusion features and motion information.  Panel (a) shows that only a subset of channels heavily influence the principal components, suggesting the existence of motion-aware features. Panels (b) and (c) demonstrate a strong correlation between the values of these key channels and the direction of motion in the video.  Panel (d) shows that other channels show little to no such correlation.", "section": "3.1 Content Correlation Removal"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_4_1.jpg", "caption": "Figure 4: Similarity heatmap between feature of the source point and target features. Given the red source point in (a), we plot the similarity heatmap on target videos. Yellow indicates regions with higher similarity. We normalize all similarity to 0-1 for better illustration. (b-d) Similarity heatmap of features with different designs. \u201cCR\u201d indicates \u201ccontent removal\u201d. \u201cMCF\u201d indicates motion channel filter. (e-h) Similarity heatmap of MOFT in different layers in the U-Net. (2x) means relative spatial resolution scale 2. (i-l) Similarity heatmap of MOFT in different video generation models.", "description": "This figure visualizes the similarity heatmaps of Motion Feature (MOFT) across various videos and models.  It demonstrates MOFT's ability to capture rich motion information and its generalizability across different architectures and layers within a U-Net.  The heatmaps compare the MOFT extracted from a reference video point to corresponding features in different target videos and model outputs.  Different processing steps (content removal, motion channel filtering) and different layers/models are compared for their effectiveness.", "section": "3. MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_5_1.jpg", "caption": "Figure 5: Motion Control Pipeline. We use reference MOFT as guidance and optimize latents to alter the sampling process. In one denoising step, we get the intermediate features and extract MOFT from it with content correlation removal and motion channel filter. We optimize the latents to alter the sampling process with the loss of masked MOFT and reference MOFT.", "description": "This figure illustrates the training-free video motion control pipeline.  The pipeline takes noisy latents as input and uses a U-Net to generate features.  Content correlation removal and a motion channel filter are then applied to extract the Motion Feature (MOFT). A region mask is used to select a specific region of interest, and the masked MOFT is compared to a reference MOFT to generate a loss, which is used to optimize the latents and control the video generation process.", "section": "4 MOFT Guidance"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_6_1.jpg", "caption": "Figure 4: Similarity heatmap between feature of the source point and target features. Given the red source point in (a), we plot the similarity heatmap on target videos. Yellow indicates regions with higher similarity. We normalize all similarity to 0-1 for better illustration. (b-d) Similarity heatmap of features with different designs. \u201cCR\u201d indicates \u201ccontent removal\u201d. \u201cMCF\u201d indicates motion channel filter. (e-h) Similarity heatmap of MOFT in different layers in the U-Net. (2x) means relative spatial resolution scale 2. (i-1) Similarity heatmap of MOFT in different video generation models.", "description": "This figure visualizes the similarity heatmaps between the motion features (MOFT) extracted from a reference video and various target videos. The heatmaps illustrate the ability of MOFT to capture motion information across diverse video generation models and different layers within a single model's architecture. The impact of content removal and motion channel filtering on the performance of MOFT is also shown.", "section": "3.2 Motion Channel Filter"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_7_1.jpg", "caption": "Figure 7: Qualitative results. We illustrate several animation clips with different reference or synthesized motion control signals. The red boxes in (a-b) stand for reference videos. We highly recommend readers refer to the supplementary material for a better visual experience.", "description": "This figure shows several examples of video animation using the proposed method.  The top row displays a comparison between a reference video (with no motion control) and a video with motion control applied using reference video signals. The bottom row does the same, but instead uses synthesized motion control signals (i.e. not copied from another video). The red boxes highlight the area of focus in the original video.", "section": "5.2 Qualitative Results"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_8_1.jpg", "caption": "Figure 4: Similarity heatmap between feature of the source point and target features. Given the red source point in (a), we plot the similarity heatmap on target videos. Yellow indicates regions with higher similarity. We normalize all similarity to 0-1 for better illustration. (b-d) Similarity heatmap of features with different designs. \u201cCR\u201d indicates \u201ccontent removal\u201d. \u201cMCF\u201d indicates motion channel filter. (e-h) Similarity heatmap of MOFT in different layers in the U-Net. (2x) means relative spatial resolution scale 2. (i-l) Similarity heatmap of MOFT in different video generation models.", "description": "This figure demonstrates the effectiveness of the proposed Motion Feature (MOFT) in capturing motion information across various video generation models.  It compares the similarity heatmaps of MOFT (with and without content removal and motion channel filtering) at different layers of the U-Net architecture and across several different models (AnimateDiff, ModelScope, ZeroScope, SVD). The results indicate that MOFT consistently achieves high similarity with videos containing similar motions, highlighting its architecture-agnostic nature and ability to effectively capture motion features.", "section": "3 MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_8_2.jpg", "caption": "Figure 1: Characteristics of Motion FeaTure (MOFT). (a-b) Rich Motion Information: We extract MOFT at the red point in the reference video in (a) and draw similarity heatmaps in (b) across various videos (yellow indicates higher similarity). The heatmap aligns well with the motion flow in the bottom left. (c) MOFT serves as guidance for controlling motion direction in the light-masked region, with the motion direction signal illustrated by red arrows in the first image.", "description": "This figure demonstrates the characteristics of the Motion Feature (MOFT) proposed in the paper.  It shows that MOFT effectively captures rich motion information, as evidenced by the similarity heatmaps across different videos that align with motion flow.  Furthermore, the figure illustrates how MOFT can serve as guidance for motion control by specifying the direction of motion in a masked region of an image.", "section": "3 MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_8_3.jpg", "caption": "Figure 7: Qualitative results. We illustrate several animation clips with different reference or synthesized motion control signals. The red boxes in (a-b) stand for reference videos. We highly recommend readers refer to the supplementary material for a better visual experience.", "description": "This figure demonstrates the qualitative results of the proposed motion control method.  It shows several video clips where motion is controlled using different reference or synthesized signals. The top row shows examples with camera motion control, while the bottom shows object motion control. The 'reference' videos are marked with red boxes, and the authors suggest viewing supplementary materials for a better understanding of the results.", "section": "5.2 Qualitative Results"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_13_1.jpg", "caption": "Figure 5: Motion Control Pipeline. We use reference MOFT as guidance and optimize latents to alter the sampling process. In one denoising step, we get the intermediate features and extract MOFT from it with content correlation removal and motion channel filter. We optimize the latents to alter the sampling process with the loss of masked MOFT and reference MOFT.", "description": "This figure illustrates the pipeline for video motion control. The pipeline uses reference MOFT (Motion Feature) as guidance to optimize the latents and alter the sampling process during denoising.  It involves extracting MOFT from intermediate features using content correlation removal and a motion channel filter. The optimization process uses a loss function based on the masked MOFT and the reference MOFT. This training-free method allows controlling video motion by optimizing noisy latents.", "section": "4 MOFT Guidance"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_14_1.jpg", "caption": "Figure 12: Qualitative comparison on video consistency preservation. We compare the generated results w./wo. our introduced techniques. The control signal is shown in the first image of (a), with the red arrow indicating the motion control direction and the light region indicating the control region. We highlight the noticeable region with red boxes. It reveals that Shared K&V contributes to the consistency of the whole video. Gradient Clip adds consistency out of masked regions but meanwhile reduces motion scale.", "description": "This figure compares video generation results with different methods to preserve video consistency.  It shows the original video, results using only motion guidance, results using motion guidance plus shared K&V (key and value from spatial attention), and results using motion guidance, shared K&V and gradient clipping. Gradient clipping helps preserve consistency outside the control region but can reduce the scale of the motion.", "section": "8.2 More Analysis and Details"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_15_1.jpg", "caption": "Figure 1: Characteristics of Motion FeaTure (MOFT). (a-b) Rich Motion Information: We extract MOFT at the red point in the reference video in (a) and draw similarity heatmaps in (b) across various videos (yellow indicates higher similarity). The heatmap aligns well with the motion flow in the bottom left. (c) MOFT serves as guidance for controlling motion direction in the light-masked region, with the motion direction signal illustrated by red arrows in the first image.", "description": "This figure demonstrates the characteristics of the proposed Motion Feature (MOFT).  (a) shows a reference video with a red point indicating the location where MOFT is extracted. (b) displays similarity heatmaps comparing the extracted MOFT across different videos, showcasing that similar motion patterns yield high similarity scores (yellow).  (c) illustrates how MOFT is used as guidance to control motion direction, with the direction shown using red arrows in a light-masked region.", "section": "3 MOtion FeaTures (MOFT)"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_16_1.jpg", "caption": "Figure 1: Characteristics of Motion FeaTure (MOFT). (a-b) Rich Motion Information: We extract MOFT at the red point in the reference video in (a) and draw similarity heatmaps in (b) across various videos (yellow indicates higher similarity). The heatmap aligns well with the motion flow in the bottom left. (c) MOFT serves as guidance for controlling motion direction in the light-masked region, with the motion direction signal illustrated by red arrows in the first image.", "description": "This figure demonstrates the characteristics of the proposed Motion Feature (MOFT). The first row shows that MOFT successfully captures rich motion information.  The heatmap in (b) highlights the regions with similar motion patterns compared to the reference video (a). The second row shows how MOFT can be used as guidance for controlling motion in videos. The red arrows indicate the direction of the controlled motion.", "section": "1 Introduction"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_16_2.jpg", "caption": "Figure 7: Qualitative results. We illustrate several animation clips with different reference or synthesized motion control signals. The red boxes in (a-b) stand for reference videos. We highly recommend readers refer to the supplementary material for a better visual experience.", "description": "This figure shows several examples of video animations generated using the proposed training-free video motion control framework.  Each row demonstrates the application of the method with different control signals (reference or synthesized) and motion types (camera, object).  The red boxes highlight the original reference videos for comparison. The results showcase the ability to manipulate motion in a natural and faithful way while retaining high video quality.  Due to the complexity of the visuals, readers are encouraged to consult the supplementary material for a clearer understanding.", "section": "5.2 Qualitative Results"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_17_1.jpg", "caption": "Figure 7: Qualitative results. We illustrate several animation clips with different reference or synthesized motion control signals. The red boxes in (a-b) stand for reference videos. We highly recommend readers refer to the supplementary material for a better visual experience.", "description": "This figure shows several examples of video animations generated using different motion control methods. The top row shows the reference videos with their respective control signals represented by red boxes. The bottom row shows video results where both camera motion and object motion were controlled using synthesized signals. The results demonstrate the capability of the proposed training-free motion control framework to generate natural and authentic motion in various scenarios.  More results are available in the supplementary material.", "section": "5.2 Qualitative Results"}, {"figure_path": "ZvQ4Bn75kN/figures/figures_17_2.jpg", "caption": "Figure 4: Similarity heatmap between feature of the source point and target features. Given the red source point in (a), we plot the similarity heatmap on target videos. Yellow indicates regions with higher similarity. We normalize all similarity to 0-1 for better illustration. (b-d) Similarity heatmap of features with different designs. \u201cCR\u201d indicates \u201ccontent removal\u201d. \u201cMCF\u201d indicates motion channel filter. (e-h) Similarity heatmap of MOFT in different layers in the U-Net. (2x) means relative spatial resolution scale 2. (i-1) Similarity heatmap of MOFT in different video generation models.", "description": "This figure visualizes the similarity heatmaps of Motion Feature (MOFT) across various videos and models.  It demonstrates the effectiveness of the MOFT in capturing motion information, showing how content removal and motion channel filtering improve the alignment with reference motion. The heatmaps are shown for different model layers and various video generation models, highlighting the architecture-agnostic nature of MOFT.", "section": "3.2 Motion Channel Filter"}]