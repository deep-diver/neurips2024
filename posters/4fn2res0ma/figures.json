[{"figure_path": "4fN2REs0Ma/figures/figures_2_1.jpg", "caption": "Figure 1: A two-gram Markov chain with parent set pa = {-1, -2}.", "description": "This figure is a graphical representation of a two-gram Markov chain.  It shows how the (l+1)th token in the sequence (x_l+1) depends only on the two preceding tokens (x_l-1 and x_l). The parent set (pa) is defined as {-1, -2}, indicating that the token depends on the previous token (index l-1) and the token before that (index l-2). This illustrates a simple Markov model showing the conditional dependencies between tokens.", "section": "Problem Setup: In-Context Learning of Markov Chains"}, {"figure_path": "4fN2REs0Ma/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the relationship between RPE vector w(h) and corresponding matrix W(h).", "description": "This figure illustrates how relative positional embeddings (RPE) are used in the transformer model.  Panel (a) shows the RPE vector w(h) for a single head, where each element corresponds to a relative position within a window of size M.  Panel (b) shows the resulting RPE matrix W(h), which is used to compute attention scores between tokens. Note that W(h) only considers tokens within a window of size M, and that the values outside of this window are set to -\u221e. This is implemented using the relationship W(h)(i,j) = w(h)_|i-j| if 1 \u2264 |i - j| \u2264 M and W(h)(i,j) = -\u221e otherwise.", "section": "A Two-Layer Transformer Model"}, {"figure_path": "4fN2REs0Ma/figures/figures_9_1.jpg", "caption": "Figure 3: An illustration of the transformer parameters during the three-stage training. We train a transformer in TF(M = 3, H = 3, d = 3, D = 2) with L = 100, pa = {\u22121, \u22122}. See \u00a7B and Figure 4 for more details of the simulation.", "description": "This figure shows the training dynamics of a two-attention-layer transformer model. The training process is divided into three stages, each focusing on a specific subset of weights. Stage I trains the feed-forward network (FFN) weights, which aims to select relevant features. Stage II updates the relative positional embedding (RPE) weights of the first attention layer to establish copying mechanisms. Finally, Stage III trains the second attention layer's weight to aggregate the features and produces the final output. The plot demonstrates the changes in these parameters across these stages, validating the theoretical three-stage training dynamics.", "section": "Experiments"}, {"figure_path": "4fN2REs0Ma/figures/figures_18_1.jpg", "caption": "Figure 3: An illustration of the transformer parameters during the three-stage training. We train a transformer in TF(M = 3, H = 3, d = 3, D = 2) with L = 100, pa = {\u22121, -2}. See \u00a7B and Figure 4 for more details of the simulation.", "description": "This figure shows the training dynamics of a two-attention-layer transformer model during three stages. Stage I shows the evolution of the FFN layer parameters, where the parameter corresponding to the optimal information set S* dominates exponentially. Stage II shows how the first attention layer learns to copy tokens, focusing on the relevant parents selected by the FFN layer. Stage III shows the growth of the second attention layer's weight, implementing a softmax classifier that compares features learned in Stage II.", "section": "Experiments"}, {"figure_path": "4fN2REs0Ma/figures/figures_19_1.jpg", "caption": "Figure 3: An illustration of the transformer parameters during the three-stage training. We train a transformer in TF(M = 3, H = 3, d = 3, D = 2) with L = 100, pa = {\u22121, -2}. See \u00a7B and Figure 4 for more details of the simulation.", "description": "This figure shows the training dynamics of the transformer model with three stages. In the first stage, the FFN parameters are trained. In the second stage, RPE weights in the first attention layer are trained. In the third stage, the weight in the second attention layer is trained. The plots show the evolution of the parameters during these three stages.", "section": "Experiments"}, {"figure_path": "4fN2REs0Ma/figures/figures_20_1.jpg", "caption": "Figure 3: An illustration of the transformer parameters during the three-stage training. We train a transformer in TF(M = 3, H = 3, d = 3, D = 2) with L = 100, pa = {\u22121, -2}. See \u00a7B and Figure 4 for more details of the simulation.", "description": "This figure shows the training dynamics of the transformer parameters during the three-stage training paradigm. The left panel (a) shows the evolution of the ratio of FFN parameters, ps*(t)/ps(t), where ps*(t) represents the parameter for the optimal subset and ps(t) represents any other subsets.  The middle panel (b) shows the RPE weights for each head in the first attention layer. The right panel (c) shows the evolution of the scalar parameter 'a' in the second attention layer. Each panel corresponds to a training stage. ", "section": "Experiments"}, {"figure_path": "4fN2REs0Ma/figures/figures_21_1.jpg", "caption": "Figure 7: Generalization capability of our model to different sequence lengths and prior distributions. We plot the cross-entropy loss of the pre-trained transformer model on sequences with different lengths sampled from Markov chains with different prior distributions. The prior is Dirichlet distribution with \u03b1 \u2208 {0.05, 0.1, 0.2} and we vary the length L in {10, 20, 50, 100, 200, 400, 700, 1000}. The pre-training data contains sequences of length L = 100 and \u03b1 = 0.01. For different \u03b1, we see that the error has a decreasing trend as L increases. This shows that the pre-trained transformer can generalize in length and is robust to the distributional shift due to a change of prior.", "description": "The figure shows the generalization performance of the trained transformer model to different sequence lengths and prior distributions. The x-axis represents the sequence length (L) ranging from 10 to 1000, and the y-axis represents the validation loss.  Different lines represent different values of the concentration parameter \u03b1 in the Dirichlet prior distribution (\u03b1 = 0.05, 0.1, and 0.2). The results show a decreasing trend in validation loss as the sequence length increases, demonstrating that the model generalizes well to unseen lengths and is robust to changes in the prior distribution. The pre-training data consisted of sequences with length L = 100 and \u03b1 = 0.01.", "section": "Experiments"}, {"figure_path": "4fN2REs0Ma/figures/figures_21_2.jpg", "caption": "Figure 8: Illustration of the GIH mechanism in a two-attention-layer transformer model. Here, pa = {-1,-2}, M = 3 and S* = {1,2}. The first attention layer copies the parents (including the information set S*) to the current position. Then the FFN layer together with layer normalization generates the features u\u03b9 using the parent tokens within the information set S*. The second attention layer treats each x\u03b9 as the value, and aggregates x as the prediction by matching the keys and query that come from the learned features using the attention mechanism. The L + 1-th token is padded with zeros in the input.", "description": "This figure illustrates the Generalized Induction Head (GIH) mechanism implemented by a two-layer transformer model.  The first attention layer acts as a copier, copying relevant parent tokens to each position based on the learned information set S*. The feed-forward network (FFN) with normalization then generates feature vectors based on informationally relevant parents. Finally, the second attention layer acts as a classifier comparing these features to predict the output.", "section": "C.1 How Does Transformer Implement the GIH Mechanism?"}, {"figure_path": "4fN2REs0Ma/figures/figures_23_1.jpg", "caption": "Figure 3: An illustration of the transformer parameters during the three-stage training. We train a transformer in TF(M = 3, H = 3, d = 3, D = 2) with L = 100, pa = {\u22121, -2}. See \u00a7B and Figure 4 for more details of the simulation.", "description": "This figure shows the training dynamics of a two-layer transformer model during three stages. The first stage trains the feed-forward network (FFN) parameters, the second trains the relative positional embedding (RPE) weights in the first attention layer, and the third trains the weight of the second attention layer. The plots show that the FFN learns to select the relevant parents, the first attention layer learns to copy the selected parents, and the second attention layer learns to perform a generalized induction head mechanism.", "section": "Experiments"}]