[{"figure_path": "zkhyrxlwqH/figures/figures_1_1.jpg", "caption": "Figure 1: Examples of types of gaps. This paper will address both geometry and modality gaps simultaneously. Image pairs are introduced by DLKFM [11].", "description": "This figure shows examples of the two types of gaps addressed in the paper: the geometry gap and the modality gap.  The geometry gap refers to the difference in geometric alignment between two images of the same scene, while the modality gap refers to differences in image representation (e.g., a map versus a satellite image of the same location).  The image pairs shown are from the DLKFM dataset [11].", "section": "1 Introduction"}, {"figure_path": "zkhyrxlwqH/figures/figures_3_1.jpg", "caption": "Figure 2: Conceptual Diagram of the Barlow Twins Method [12]", "description": "The Barlow Twins method is a self-supervised learning method.  The diagram shows two inputs, A and B, which pass through an encoder network to produce representations rA and rB. These representations then go through a projector network to produce embedding vectors vA and vB.  The similarity matrix between vA and vB is calculated, and the loss function aims to make this similarity matrix close to the identity matrix, thereby encouraging the model to learn good representations that are similar for similar inputs and dissimilar for dissimilar inputs.", "section": "3.3 Metric Learning"}, {"figure_path": "zkhyrxlwqH/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of architecture. Upper diagram shows static view and lower diagrams illustrate phase switching between Geometry Learning (GL) phase and Modality-Agnostic Representation Learning (MARL) phase.", "description": "This figure illustrates the architecture of the AltO framework. The upper diagram provides a static overview of the network, showing the input images (from modalities A and B), the registration network (R), the encoder (E), the projector (P), the warping function (\u03c9), and the loss functions (Geometry and Modality). The lower diagrams demonstrate the two-phase alternating optimization process. In the Geometry Learning (GL) phase, the registration network is trained to align the warped moving image with the fixed image. In the Modality-Agnostic Representation Learning (MARL) phase, the encoder and projector are trained to learn a modality-invariant representation.  The figure highlights which components are trainable and frozen in each phase.", "section": "4 Method"}, {"figure_path": "zkhyrxlwqH/figures/figures_5_1.jpg", "caption": "Figure 4: Examples of image pair for each datasets. Google Map and Google Earth are introduced by DLKFM [11]. Deep NIR is proposed in [31]", "description": "This figure shows example image pairs from the three datasets used in the paper's experiments: Google Map, Google Earth, and Deep NIR.  Each dataset presents a different type of multimodal image pair, showcasing the challenges of homography estimation in diverse scenarios. Google Map pairs show satellite imagery and corresponding maps, Google Earth pairs show the same area at different times of the year, and Deep NIR pairs show images from RGB and NIR sensors.", "section": "5.1 Multimodal Datasets"}, {"figure_path": "zkhyrxlwqH/figures/figures_7_1.jpg", "caption": "Figure 5: Visualization of homography estimation using center box. The first row shows the state before applying homography (green rectangles). Subsequent rows compare the results after applying ground-truth (green) and predicted (red) homography matrices. Our method, AltO, closely matches supervised learning-based methods, while other unsupervised approaches underperform.", "description": "This figure visualizes the performance of different homography estimation methods on three datasets (Google Map, Google Earth, and Deep NIR).  Each column represents a dataset.  The top row shows the original images with a green box marking a region of interest. Subsequent rows show the warped result of applying ground truth homography (green box) and homography predicted by each method (red box). The results demonstrate that AltO achieves comparable performance to supervised methods, while other unsupervised approaches show significant misalignment.", "section": "5 Experiments"}, {"figure_path": "zkhyrxlwqH/figures/figures_13_1.jpg", "caption": "Figure 6: Moving, fixed, and warped images. The first row displays the moving image (IA), the second row shows the fixed image (IB), and the remaining rows present the warped images (\u0128A) derived from IA for each method.", "description": "This figure visualizes the results of homography estimation on three different datasets (Google Map, Google Earth, and Deep NIR).  The first row shows the original moving images (IA). The second row shows the corresponding fixed images (IB) that the moving images should be aligned to. The remaining rows display the warped moving images (\u0128A), which have been transformed using the predicted homography matrices from different methods (including supervised learning baselines and the proposed AltO method). By comparing the warped images (\u0128A) with the fixed images (IB), one can visually assess the accuracy of each method in aligning images, highlighting the superior performance of the AltO method compared to unsupervised learning baselines.", "section": "A.1 Additional Visualization of the Results from the Main Experiment"}, {"figure_path": "zkhyrxlwqH/figures/figures_14_1.jpg", "caption": "Figure 3: Overview of architecture. Upper diagram shows static view and lower diagrams illustrate phase switching between Geometry Learning (GL) phase and Modality-Agnostic Representation Learning (MARL) phase.", "description": "This figure illustrates the architecture of the proposed AltO framework. The upper diagram provides a high-level overview of the network, showing the input images (from modalities A and B), the registration network (R) that predicts the homography matrix, and the two loss functions (geometry and modality). The lower diagrams show the two alternating phases: Geometry Learning (GL) and Modality-Agnostic Representation Learning (MARL). In the GL phase, the registration network is trained to align the images by minimizing the geometry gap, while in the MARL phase, the encoder and projector are trained to learn a modality-agnostic representation. This alternating optimization strategy helps to address both the geometry and modality gaps in multimodal image pairs.", "section": "4 Method"}]