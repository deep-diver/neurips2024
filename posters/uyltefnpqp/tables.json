[{"figure_path": "uyLtEFnpQP/tables/tables_6_1.jpg", "caption": "Table 1: The performance of Du-IN with or without electrode selection.", "description": "This table presents the performance comparison of the Du-IN model with and without electrode selection. The results show a significant improvement in accuracy when using a reduced set of selected electrodes (12.25 on average), compared to using all electrodes (109.75 on average).  This highlights the effectiveness of focusing on specific brain regions relevant to speech production for enhanced decoding performance.", "section": "4.3 Channel Contribution and Selection"}, {"figure_path": "uyLtEFnpQP/tables/tables_7_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table presents the results of the Du-IN model and several advanced baselines designed for either brain signals or general time series.  It shows the token level used (region or channel), whether the model was pre-trained (PT), whether pre-training was done across multiple subjects (MS), the model size, and the accuracy with standard error. The table allows for comparison of different approaches to sEEG speech decoding, highlighting the superior performance of Du-IN.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_8_1.jpg", "caption": "Table 3: Ablation study on whether pre-training with the downstream dataset (DD) or not.", "description": "This table presents the ablation study comparing the performance of the Du-IN (mae) model trained with and without the downstream dataset.  It shows how including the downstream dataset in pre-training improves the accuracy of speech decoding.", "section": "4 Experiments"}, {"figure_path": "uyLtEFnpQP/tables/tables_16_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table presents the results of the Du-IN model and several advanced baseline models designed for either brain signals or general time series.  It compares the accuracy of different models on a 61-word speech decoding task using intracranial stereo-electroencephalography (sEEG) data.  The models are categorized by their approach to tokenization (region-level or channel-level), pre-training method (if any), and model size. The table highlights the superior performance of the Du-IN model, surpassing all baselines.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_20_1.jpg", "caption": "Table 5: The hyperparameters for Du-IN VQ-VAE training.", "description": "This table lists the hyperparameters used during the training of the Du-IN VQ-VAE model.  It provides details for each module, including the Du-IN Encoder, Vector Quantizer, and Du-IN Regressor.  Specific hyperparameters are listed, such as the number of layers, hidden sizes, kernel sizes, dropout ratios, learning rates, optimizers, and more.  These values are critical for reproducing the results reported in the paper.", "section": "C Model Details"}, {"figure_path": "uyLtEFnpQP/tables/tables_21_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table compares the performance of Du-IN against several state-of-the-art (SOTA) baselines on a 61-word speech decoding task using intracranial neural signals.  It shows the accuracy achieved by each method, along with details like model size, whether the model was pre-trained, and whether it was pre-trained across multiple subjects.  The results highlight Du-IN's superior performance, especially when compared to methods that utilize channel-level tokens instead of region-level tokens.", "section": "4 Experiments"}, {"figure_path": "uyLtEFnpQP/tables/tables_22_1.jpg", "caption": "Table 7: The hyperparameters for Du-IN CLS training.", "description": "This table lists the hyperparameters used for training the Du-IN CLS model.  It specifies values for various settings related to the Label Prediction Head (including a Flatten layer and a linear projection) and the Optimizer (including batch size, learning rate, scheduler, type, Adam beta parameters, weight decay, total epochs, and warm-up epochs).", "section": "4.2 Implementation Details"}, {"figure_path": "uyLtEFnpQP/tables/tables_25_1.jpg", "caption": "Table 8: Ablations to validate the effectiveness of region-specific channel selection.", "description": "This table presents the mean squared error (MSE) results of three different settings for reconstructing neural signals using the Du-IN VQ-VAE model.  Setting 1 uses the top 10 channels most relevant to speech decoding. Setting 2 randomly selects 10 channels. Setting 3 uses all channels.  The results demonstrate the impact of selecting region-specific channels for accurate signal reconstruction.", "section": "4.3 Channel Contribution and Selection"}, {"figure_path": "uyLtEFnpQP/tables/tables_25_2.jpg", "caption": "Table 9: The cross-entropy loss of different methods (with the best in bold and the second underlined).", "description": "This table presents the cross-entropy loss for various speech decoding methods.  It compares the performance of different models, indicating whether they were pre-trained (PT) and whether the pre-training was performed across multiple subjects (MS). The token level (Region or Channel) and model size are also shown.  Lower cross-entropy values indicate better performance.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_26_1.jpg", "caption": "Table 10: The performance of different methods from subjects (01-04).", "description": "This table presents the subject-wise accuracy of different speech decoding methods.  It shows the performance (accuracy and standard deviation) for each of four subjects (subj-01 to subj-04) across several methods.  The methods include various baseline models and the proposed Du-IN model with different pre-training configurations. The table allows for a comparison of the effectiveness of the different methods on individual subjects, revealing potential variations in performance due to individual biological differences.", "section": "4.3 Channel Contribution and Selection"}, {"figure_path": "uyLtEFnpQP/tables/tables_27_1.jpg", "caption": "Table 11: The performance of different methods from subjects (05-08).", "description": "This table presents the results of various speech decoding methods (TS-TCC, CNN-BiGRU, EEG-Conformer, Neuro-BERT, DeWave, BrainBERT, Brant, LaBraM, LaBraM-PopT, and Du-IN with various configurations) evaluated on subjects 05 through 08.  The results are presented as accuracy with standard deviation, indicating the performance variability of each model across different subjects. PT and MS columns specify whether the model was pre-trained before evaluation and whether it was pre-trained across multiple subjects, respectively.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_27_2.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table presents the results of the Du-IN model and advanced baselines designed for either brain signals or general time series.  It compares the accuracy of various methods for a 61-word speech decoding task using sEEG data.  The table shows model size, whether the model was pre-trained, whether pre-training was done across multiple subjects, the token level used (region or channel), and the accuracy achieved.  The results demonstrate that Du-IN outperforms all baselines.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_28_1.jpg", "caption": "Table 13: Ablations to validate the effectiveness of vector-quantized neural signal prediction.", "description": "This table presents the ablation study results on the effectiveness of vector-quantized neural signal prediction. It compares three different model settings: the Du-IN (mae) model, Setting 1 (directly predicting output embeddings of the Du-IN Encoder), and Setting 2 (directly reconstructing raw EEG patches without the encoder). The accuracy (with standard error) is reported for each setting, demonstrating the contribution of vector quantization.", "section": "4.5 Ablation Study"}, {"figure_path": "uyLtEFnpQP/tables/tables_28_2.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table compares the performance of the Du-IN model with other state-of-the-art (SOTA) methods on a 61-word classification task using sEEG data.  It shows the accuracy of each model, indicating the effectiveness of the Du-IN approach.  Various model characteristics are included to help understand performance differences; including whether the model uses region-level or channel-level tokens, whether it is pre-trained, and the model's size in terms of parameters.", "section": "4 Experiments"}, {"figure_path": "uyLtEFnpQP/tables/tables_28_3.jpg", "caption": "Table 15: Ablations to explore the impact of the pre-training epochs (of the Du-IN VQ-VAE model).", "description": "This table presents the ablation study on the number of pre-training epochs for the Du-IN VQ-VAE model.  The accuracy with standard error is shown for different numbers of epochs (5, 10, 50, 100, and 400). The results demonstrate the impact of the number of epochs on the final model performance after subsequent fine-tuning of the Du-IN MAE model.", "section": "4.5 Ablation Study"}, {"figure_path": "uyLtEFnpQP/tables/tables_28_4.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table compares the performance of the Du-IN model against several other state-of-the-art (SOTA) baselines on a 61-word speech decoding task using intracranial neural signals.  It shows the accuracy of each model, along with details such as whether the model was pre-trained and whether the training was done across multiple subjects. The table highlights Du-IN's superior performance.", "section": "4 Experiments"}, {"figure_path": "uyLtEFnpQP/tables/tables_32_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table compares the performance of the Du-IN model against several other state-of-the-art (SOTA) baselines on a 61-word speech decoding task using sEEG data.  It shows the accuracy of each model, along with details about whether they used pre-training (PT), multi-subject pre-training (MS), the type of token-level used (Region or Channel), and the model size.  The results demonstrate that Du-IN significantly outperforms all baselines, highlighting its effectiveness in decoding speech from sEEG signals.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_33_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table presents a comparison of the Du-IN model's performance against several other state-of-the-art (SOTA) baselines on a 61-word speech decoding task using sEEG data.  It shows the accuracy and standard error for each model, indicating whether the model was pre-trained before evaluation and across multiple subjects.  The table highlights Du-IN's superior performance compared to other methods, particularly those based on channel-level tokens instead of region-level tokens.", "section": "4.4 Comparasion with Other Models"}, {"figure_path": "uyLtEFnpQP/tables/tables_34_1.jpg", "caption": "Table 2: The performance of different methods (with the best in bold and the second underlined).", "description": "This table presents the results of the Du-IN model and advanced baselines designed for either brain signals or general time series.  It shows the token level (region or channel), whether the model was pre-trained, whether it was pre-trained across multiple subjects, model size, and accuracy with standard error for each model. The results demonstrate that the Du-IN model outperforms all baselines.", "section": "4.4 Comparasion with Other Models"}]