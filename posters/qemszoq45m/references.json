{"references": [{"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax regret bounds for reinforcement learning", "publication_date": "2017-00-00", "reason": "This paper establishes minimax regret bounds for reinforcement learning, a fundamental concept for evaluating RL algorithms and providing theoretical guarantees."}, {"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Regret bounds for the adaptive control of linear quadratic systems", "publication_date": "2011-00-00", "reason": "This paper provides regret bounds for adaptive control of linear quadratic systems, a specific class of continuous MDPs, establishing a benchmark for continuous RL."}, {"fullname_first_author": "Andrea Zanette", "paper_title": "Learning near optimal policies with low inherent Bellman error", "publication_date": "2020-00-00", "reason": "This paper introduces the concept of low inherent Bellman error, a weaker condition than linearity, and provides algorithms with sublinear regret bounds for this general class of MDPs."}, {"fullname_first_author": "Zhuoran Yang", "paper_title": "Provably efficient reinforcement learning with linear function approximation", "publication_date": "2020-00-00", "reason": "This paper provides provably efficient RL algorithms with linear function approximation, a crucial result for applying RL in high-dimensional state spaces."}, {"fullname_first_author": "Sayak Ray Chowdhury", "paper_title": "Online learning in kernelized Markov decision processes", "publication_date": "2019-00-00", "reason": "This paper extends RL to kernelized MDPs, introducing a new representation class of continuous MDPs and provides algorithms with sublinear regret bounds."}]}