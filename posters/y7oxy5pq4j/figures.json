[{"figure_path": "y7oxY5pq4j/figures/figures_2_1.jpg", "caption": "Figure 1: The pipeline of our method. During the pre-processing stage, we reconstruct the scene as an implicit representation by NeuS [47]. From the implicit representation, we extract scene priors such as normal, visibility, and indirect illumination (Sec. 3.2). In the BRDF estimation stage, we fix the scene priors and optimize the direct illumination and scaled parameter to compute an accurate BRDF of the object under the constraint of rendering equation (Sec. 3.3). To improve the visibility accuracy for direct illumination and decomposition stability, we introduce the regularized visibility estimation after 100 epochs (Sec. 3.4).", "description": "This figure illustrates the two-stage pipeline of RobIR, a novel implicit inverse rendering approach.  The pre-processing stage uses NeuS to reconstruct the scene and extract scene priors (normal, visibility, and indirect illumination). The BRDF estimation stage then optimizes direct illumination and a scaled parameter (\u03b3) to accurately reconstruct BRDF while using the extracted priors.  Regularized visibility estimation is applied after 100 epochs to further enhance accuracy. The figure visually represents each stage and the data flow between them.", "section": "3 Methodology"}, {"figure_path": "y7oxY5pq4j/figures/figures_4_1.jpg", "caption": "Figure 2: Smooth loss to fix broken part.", "description": "This figure shows a comparison of normal maps generated with and without a smooth loss. The image on the left (w/o smooth loss) shows a normal map with visible discontinuities and noise, while the image on the right (w/ smooth loss) shows a much smoother normal map with fewer artifacts.  The smooth loss helps to regularize the normal map, making it more suitable for subsequent BRDF estimation. The smooth loss prevents broken normals caused by specular reflection, which results in a higher quality normal map.", "section": "3.2 Stage 1: Pre-processing"}, {"figure_path": "y7oxY5pq4j/figures/figures_4_2.jpg", "caption": "Figure 2: Smooth loss to fix broken part.", "description": "This figure shows the effect of applying a smooth loss to the normal vectors predicted by the model.  The leftmost image is the input, the middle image shows the normal vectors before the smooth loss is applied, which contain artifacts and are noisy. The rightmost image shows the improved normal vectors after applying the smooth loss, resulting in smoother and more accurate normal prediction.", "section": "3.2 Stage 1: Pre-processing"}, {"figure_path": "y7oxY5pq4j/figures/figures_5_1.jpg", "caption": "Figure 4: Albedo in synthetic scenes. We compare our method to InvRender [56], NVDiffrec [34], TensoIR [17], NeRO [26], Relightable-GS [11], and GS-IR [24]. The results show that our method outperforms previous approaches without baking specular highlights and shadows into albedo.", "description": "This figure compares the albedo (the base color of an object) produced by RobIR and several other state-of-the-art inverse rendering methods.  RobIR's results show cleaner albedo than others, not having artifacts from shadows or reflections baked in.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_6_1.jpg", "caption": "Figure 13: Dataset Comparison. We choose a more challenging high-illumination dataset, which exposed the inability of previous neural field-based inverse rendering methods to decouple shadows from the object's PBR materials.", "description": "This figure compares the results of different inverse rendering methods on a challenging high-illumination dataset. It shows that previous methods struggle to separate shadows from the object's material properties (albedo and roughness), while the proposed method, RobIR, effectively decouples them, resulting in more accurate material estimation even in difficult lighting conditions.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_6_2.jpg", "caption": "Figure 4: Albedo in synthetic scenes. We compare our method to InvRender [56], NVDiffrec [34], TensoIR [17], NeRO [26], Relightable-GS [11], and GS-IR [24]. The results show that our method outperforms previous approaches without baking specular highlights and shadows into albedo.", "description": "This figure compares the albedo reconstruction results of RobIR against several state-of-the-art methods on synthetic scenes.  It visually demonstrates RobIR's superior performance in accurately decoupling shadows and specular reflections from the albedo, avoiding artifacts seen in other methods that bake these effects into the albedo map.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_7_1.jpg", "caption": "Figure 7: Comparisons on real-world scenes. Columns 2 to 5 are albedo, the last four columns are roughness. Even in complex real-world scenarios, our method can robustly decouple shadow and material, resulting in high-quality albedo and roughness.", "description": "This figure shows a comparison of albedo and roughness results on real-world scenes between the proposed method (Ours) and several other state-of-the-art methods (InvRender, TensoIR, Relight-GS). The results demonstrate that the proposed method effectively decouples shadows and materials, leading to higher-quality albedo and roughness estimations, even in complex real-world scenarios.", "section": "4.1 Comparisons with previous methods"}, {"figure_path": "y7oxY5pq4j/figures/figures_7_2.jpg", "caption": "Figure 8: Ablation. We conduct ablation experiments on the key components in the BRDF estimation stage. The ablation results emphasize the critical importance of each component in our proposed framework for attaining high-quality albedo.", "description": "This figure shows the results of ablation studies conducted on the key components of the proposed BRDF estimation framework.  The ablation experiments systematically remove one component at a time (e.g., ACES tone mapping, regularized visibility estimation) to assess its individual contribution to the overall quality of the albedo reconstruction. The results highlight the significance of each component in achieving high-quality albedo.", "section": "4.2 Ablation Studies"}, {"figure_path": "y7oxY5pq4j/figures/figures_8_1.jpg", "caption": "Figure 9: De-shadow. Given an input image from a specific viewpoint, our proposed method can accurately remove shadows caused by direct light occlusion without sacrificing rendering quality.", "description": "This figure demonstrates the de-shadowing capability of the proposed method.  Three different scenes are shown, each with an input image, a rendering with shadows, and a de-shadowed rendering. The de-shadowed renderings show the successful removal of shadows while preserving the overall quality of the image.", "section": "4.3 Application"}, {"figure_path": "y7oxY5pq4j/figures/figures_8_2.jpg", "caption": "Figure 12: Helmet Relighting. Our method achieves high-quality relighting results in scenarios with specular highlights and slight specular reflections.", "description": "This figure shows a comparison of relighting results for a helmet between the proposed method and several other state-of-the-art methods. The proposed method demonstrates high-quality results even in the presence of specular highlights and reflections, unlike other methods which suffer from artifacts such as shadow baking and inaccurate material representation.  The results are shown for four different lighting conditions (Light 0 - Light 3).", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_13_1.jpg", "caption": "Figure 11: Other results of our method. In each scene, we present the input ground-truth image (a), our rendering result (b), normal (c), light (d), albedo (e), and roughness (f) obtained through our method. These experiments illustrate the generalizability of our method across diverse datasets and demonstrate its ability to produce high-quality results.", "description": "This figure shows several examples of the RobIR method applied to different scenes. Each row represents a different scene, showing the ground truth image, the results obtained using the RobIR method, and the extracted normal map, lighting, albedo, and roughness. This showcases the versatility and high-quality results of the proposed method across diverse scenes and data sets.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_13_2.jpg", "caption": "Figure 12: Helmet Relighting. Our method achieves high-quality relighting results in scenarios with specular highlights and slight specular reflections.", "description": "This figure demonstrates the relighting capabilities of the proposed method, RobIR, on a helmet model.  It showcases the ability to produce high-quality results even in complex scenes containing specular highlights and reflections, which are challenging for existing inverse rendering techniques. The comparison highlights RobIR's superior performance in decoupling shadows and material properties, resulting in more accurate and realistic relighting.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_14_1.jpg", "caption": "Figure 13: Dataset Comparison. We choose a more challenging high-illumination dataset, which exposed the inability of previous neural field-based inverse rendering methods to decouple shadows from the object's PBR materials.", "description": "This figure compares the results of the proposed method (Ours) and a previous method (TensoIR) on two different scenes with strong illumination: a hotdog and a Lego construction.  The comparison highlights the proposed method's ability to accurately decouple shadows from the object's material properties (albedo), unlike the previous method which struggles to separate them under intense lighting conditions.  This showcases the robustness of the new approach in handling high-illumination scenarios.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_14_2.jpg", "caption": "Figure 10: Relighting. Our method not only achieves high-quality relighting results in scenarios with specular highlights but can also robustly decouple shadows, obtaining high-quality relighting outcomes without baked shadows even in scenes with severe shadows.", "description": "This figure showcases the relighting capabilities of the proposed RobIR method.  It compares the relighting results of RobIR against other state-of-the-art methods (InvRender, TensoIR, and GS-IR) in scenarios with significant specular reflections and shadows. The comparison highlights RobIR's ability to accurately reconstruct the scene's BRDF, resulting in realistic and high-quality relighting, free from artifacts caused by baked shadows.", "section": "4.3 Application"}, {"figure_path": "y7oxY5pq4j/figures/figures_15_1.jpg", "caption": "Figure 13: Dataset Comparison. We choose a more challenging high-illumination dataset, which exposed the inability of previous neural field-based inverse rendering methods to decouple shadows from the object's PBR materials.", "description": "This figure compares the results of different inverse rendering methods on a challenging dataset with high illumination.  It shows that existing methods struggle to separate shadows from the object's material properties (albedo, roughness), while the proposed method (Ours) achieves better separation, leading to higher-quality reconstructions.", "section": "4 Experiments"}, {"figure_path": "y7oxY5pq4j/figures/figures_15_2.jpg", "caption": "Figure 15: Albedo comparison with NvDiffRecMC on synthetic scenes. NvDiffRecMC cannot achieve the decouple of shadow, indirect illumination, and the PBR materials of the objects.", "description": "This figure compares the albedo reconstruction results of the proposed method (RobIR) and NVDiffRecMC on four synthetic scenes.  The comparison highlights RobIR's superior ability to decouple shadow and indirect illumination from the object's physical properties, leading to a cleaner and more accurate albedo reconstruction.  NVDiffRecMC, in contrast, struggles with this decoupling, resulting in albedo that is contaminated by shadows and indirect lighting effects.", "section": "Additional comparison with NVDiffRecMC"}, {"figure_path": "y7oxY5pq4j/figures/figures_15_3.jpg", "caption": "Figure 17: Environment map comparison with NvDiffRecMC.", "description": "This figure compares the environment maps generated by the proposed method (Ours), the NVDiffRecMC method, and the ground truth (GT) for three different scenes.  The top row shows the environment maps for a scene with a red, textured surface, and a blurry background. The middle row shows the environment maps for a scene with a dark, textured area and a bright light source. The bottom row shows the environment maps for an outdoor scene with a house, a car, and some greenery. The comparison highlights the ability of the proposed method to accurately reconstruct environment lighting, even in challenging scenes with high dynamic range and complex lighting conditions.", "section": "Additional comparison with NVDiffrecMC"}, {"figure_path": "y7oxY5pq4j/figures/figures_16_1.jpg", "caption": "Figure 18: Comparison on ACES and sRGB curve.", "description": "This figure compares the ACES and sRGB tone mapping curves.  The ACES curve shows a much wider input range than the sRGB curve, capable of handling a greater dynamic range of light intensities. This is significant because the ACES tone mapping is used to convert the PBR color output from the rendering equation to a range within [0, 1], making it suitable for use in the proposed inverse rendering method even in high-illumination scenes.", "section": "Visualization and evaluation on tone mapping"}, {"figure_path": "y7oxY5pq4j/figures/figures_16_2.jpg", "caption": "Figure 1: The pipeline of our method. During the pre-processing stage, we reconstruct the scene as an implicit representation by NeuS [47]. From the implicit representation, we extract scene priors such as normal, visibility, and indirect illumination. During BRDF estimation, we optimize environmental lighting, the scaled parameter y, albedo a, and roughness r, to minimize reconstruction loss under the constraint of the rendering equation. After 100 epochs, we perform regularized visibility estimation and employ an MLP to learn the visibility ratio Q of the direct SGs to obtain more accurate visibility specified for SGs, which is critical for eliminating stubborn shadows at the edges and boundaries.", "description": "This figure illustrates the two-stage pipeline of the proposed method, RobIR, for robust inverse rendering in high-illumination scenes.  The first stage involves pre-processing using NeuS to create an implicit scene representation from which normal, visibility, and indirect illumination are extracted. The second stage focuses on BRDF estimation, optimizing environmental lighting, a scaled parameter (\u03b3), albedo (\u03b1), and roughness (r) to minimize reconstruction loss using the rendering equation. Regularized visibility estimation is applied after 100 epochs to improve accuracy by learning the visibility ratio (Q) of direct spherical Gaussians (SGs), effectively removing persistent shadows.", "section": "3 Methodology"}, {"figure_path": "y7oxY5pq4j/figures/figures_16_3.jpg", "caption": "Figure 20: Evaluation tone mapping in chessboard. The ACES tone mapping with \u03b3 = 0.42 matches well with the sRGB curve.", "description": "This figure compares the ACES tone mapping curve with different gamma values (\u03b3) and the standard sRGB curve, demonstrating the effectiveness of a scene-specific ACES tone mapping approach. The plot shows that an optimized ACES curve (\u03b3 = 0.42) closely matches the sRGB curve in a chessboard scene. This highlights the method's ability to adapt to various lighting conditions and reduce information loss.", "section": "Visualization and evaluation on tone mapping"}]