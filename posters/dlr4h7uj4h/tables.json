[{"figure_path": "dLr4H7Uj4H/tables/tables_7_1.jpg", "caption": "Table 1: Results of bitrate savings achieved by the proposed optimal lattice vector quantization (OLVQ) method over the scalar quantizer across different image compression networks and context models. The lattice vector dimension is set to 32 here.", "description": "This table presents the bitrate savings achieved by using the Optimal Lattice Vector Quantization (OLVQ) method compared to a standard scalar quantizer. The results are shown for three different image compression networks (Bmshj2018, SwinT-ChARM, LIC-TCM) and four different context models (Factorized, Checkerboard, Channel-wise Autoregressive, Spatial-wise Autoregressive).  A negative percentage indicates bitrate savings, showing the improvement achieved by OLVQ over the scalar quantizer. The lattice vector dimension was set to 32 for all results shown.", "section": "4.2 Comparison with scalar quantizer"}, {"figure_path": "dLr4H7Uj4H/tables/tables_8_1.jpg", "caption": "Table 2: Results of bitrate savings achieved by classical pre-defined lattice vector quantizers and the learned optimal lattice vector quantizers over the scalar quantizer, across different image compression models and context models.", "description": "This table presents a comparison of bitrate savings achieved by various lattice vector quantization methods against a scalar quantizer.  It shows the performance of classical, pre-defined lattices (Gosset, Barnes-Wall, Leech) and the learned, optimized lattices of the proposed method. Results are broken down by autoencoder size (Bmshj2018, SwinT-CHARM), and context model (Factorized, Checkerboard).  The optimized lattices consistently outperform both the scalar quantizer and the pre-defined lattices, demonstrating the effectiveness of the proposed learning approach in adapting to specific data distributions.", "section": "4.3 Comparison with non-learned lattice vector quantizers"}, {"figure_path": "dLr4H7Uj4H/tables/tables_8_2.jpg", "caption": "Table 2: Results of bitrate savings achieved by classical pre-defined lattice vector quantizers and the learned optimal lattice vector quantizers over the scalar quantizer, across different image compression models and context models.", "description": "This table compares the bitrate savings achieved by using different types of lattice vector quantization methods (classical pre-defined and learned optimal) against the scalar quantizer. The comparison is done across various image compression models (Bmshj2018 and SwinT-ChARM) and context models (Factorized and Checkerboard).  The table shows how much better the learned optimal lattice vector quantizers perform in terms of bitrate savings compared to the other methods.", "section": "4.3 Comparison with non-learned lattice vector quantizers"}, {"figure_path": "dLr4H7Uj4H/tables/tables_9_1.jpg", "caption": "Table 4: Inference times of three different quantization methods: uniform scalar quantizer (USQ), lattice vector quantizer (LVQ), and general vector quantizer (GVQ) across different dimensions. For GVQ, the codebook size is adjusted to be larger as the dimension increases.", "description": "This table compares the inference times of three different quantization methods: uniform scalar quantization (USQ), lattice vector quantization (LVQ), and general vector quantization (GVQ) across different dimensions (1, 8, 16, and 32).  For the general vector quantizer, the codebook size was increased as the dimension increased. The table shows that USQ has the fastest inference time, followed by LVQ, and then GVQ, highlighting LVQ's balance between computational efficiency and scalability.", "section": "4.5 Inference time"}, {"figure_path": "dLr4H7Uj4H/tables/tables_13_1.jpg", "caption": "Table 1: Results of bitrate savings achieved by the proposed optimal lattice vector quantization (OLVQ) method over the scalar quantizer across different image compression networks and context models. The lattice vector dimension is set to 32 here.", "description": "This table presents the bitrate savings achieved by the proposed optimal lattice vector quantization (OLVQ) method compared to a standard scalar quantizer across various image compression network models and context models.  The results are presented as percentages of bitrate reduction.  The lattice vector dimension used in these experiments is 32.", "section": "4.2 Comparison with scalar quantizer"}, {"figure_path": "dLr4H7Uj4H/tables/tables_13_2.jpg", "caption": "Table 2: Results of bitrate savings achieved by classical pre-defined lattice vector quantizers and the learned optimal lattice vector quantizers over the scalar quantizer, across different image compression models and context models.", "description": "This table compares the bitrate savings achieved by using different lattice vector quantization methods against a scalar quantizer in image compression.  It shows results for both pre-defined (classical) lattices (Gosset, Barnes-Wall, Leech) and the learned optimal lattices, across two different compression network models (Bmshj2018 and SwinT-CHARM) and two context models (Factorized and Checkerboard). The table highlights how the proposed learned optimal lattice quantizer significantly outperforms both the scalar quantizer and the pre-defined lattices.", "section": "4.3 Comparison with non-learned lattice vector quantizers"}]