{"importance": "This paper is crucial because **it tackles a critical challenge in the field of adversarial attacks against image-to-text models**: decision-based black-box attacks, which are more realistic and harder to defend against than existing white-box or gray-box methods.  The proposed AAA framework offers a novel approach to generating targeted adversarial examples without semantic loss, thus advancing the understanding and development of defense mechanisms against such attacks. This work will **inspire further research in developing more robust and practical defense mechanisms**, leading to safer and more reliable image-to-text models.", "summary": "This paper introduces AAA, a novel three-stage decision-based black-box targeted attack against image-to-text models.  AAA efficiently generates semantically consistent adversarial examples by asking for specific target text semantics, attending to image regions critical for manipulation, and attacking those regions to achieve the desired text output.", "takeaways": ["AAA is the first decision-based black-box targeted attack for image-to-text models.", "AAA successfully generates semantically consistent adversarial examples without semantic loss.", "AAA outperforms existing gray-box methods on the evaluated image-to-text models."], "tldr": "Image-to-text models are vulnerable to adversarial attacks, with existing methods often suffering from semantic loss or requiring impractical access to model internals.  Current gray-box attacks, while more practical, still exhibit this semantic loss, limiting their effectiveness in targeted attacks.  Decision-based black-box attacks, where only the model's output text is accessible, pose an even greater challenge. \nThis paper introduces a novel three-stage method (AAA) to overcome these limitations.  AAA systematically constructs targeted attacks by first defining target text semantics (Ask), then identifying key image regions via attention mechanisms (Attend), and finally implementing these attacks via an evolutionary algorithm (Attack).  Experiments demonstrate AAA's efficacy in generating targeted attacks with minimal semantic loss, exceeding the performance of existing gray-box approaches on both transformer-based and CNN+RNN-based models.", "affiliation": "Xiamen University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Vision-Language Models"}, "podcast_path": "9uMJeCUeKk/podcast.wav"}