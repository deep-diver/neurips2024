[{"figure_path": "9uMJeCUeKk/figures/figures_1_1.jpg", "caption": "Figure 1: The semantic loss problem is existing in existing gray-box targeted attack methods.", "description": "This figure illustrates the problem of semantic loss in existing gray-box targeted attack methods.  Panel (a) shows a traditional approach where an adversarial perturbation is added to a clean image, leading the image-to-text model to produce an incorrect output text. The generated text (\u201cthere are two boys brushing their teeth in the bathroom\u201d) semantically mismatches the intended target text (\u201ca boy and a girl are looking at a camera in the mirror\u201d). This demonstrates semantic loss. In contrast, panel (b) depicts the proposed method's approach. Here, the adversarial image generated using the method results in an output text that closely matches the intended target text, showing that semantic loss is mitigated.", "section": "1 Introduction"}, {"figure_path": "9uMJeCUeKk/figures/figures_2_1.jpg", "caption": "Figure 2: Diagram of our decision-based black-box targeted attack method Ask, Attend, Attack.", "description": "This figure illustrates the three-stage process of the proposed AAA attack method.  The Ask stage involves selecting semantically related words to generate a target text. The Attend stage uses an attention mechanism to identify crucial image regions. Finally, the Attack stage employs a differential evolution algorithm to perturb these regions and achieve a targeted attack without semantic loss. The figure visually depicts the flow of information and the interaction between the three stages.", "section": "3 Methodology"}, {"figure_path": "9uMJeCUeKk/figures/figures_6_1.jpg", "caption": "Figure 3: We compared the convergence curves of populations with and without Attend under the same perturbation size e in (a-b). The fitness function is Sclip in Formula 12, where lower values mean stronger attacks. The dashed line is the average fitness value, and the solid line is the best fitness value. The green line is AAA and the red line is AAA w/o Attend. (c) shows the attention heatmap. (d) and (e) show the visual effects of adversarial image with and without Attend, with minimal perturbation of 100% attack success rate.", "description": "This figure compares the convergence curves of the proposed AAA attack method with and without the Attend stage.  It shows that incorporating the Attend stage leads to faster convergence and better attack performance.  The figure also visualizes the attention heatmap and the resulting adversarial images with and without the Attend stage, highlighting the impact on both the attack's efficiency and visual imperceptibility.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/figures/figures_6_2.jpg", "caption": "Figure 4: Grad-CAM attention heatmaps of different surrogate models for the same target text a woman is holding a pair of shoes. M is METEOR, B is BLEU, C is CLIP, S is SPICE.", "description": "This figure compares Grad-CAM attention heatmaps generated by three different surrogate models (ResNet50, DenseNet121, and Vision Transformer) for the same target text: \"a woman is holding a pair of shoes\".  The heatmaps highlight the image regions that the models focus on to generate the caption. The different colors represent the strength of the attention signal, with warmer colors indicating stronger attention. The figure also provides the evaluation metrics (METEOR, BLEU, CLIP, and SPICE) for each model's caption generation, showing the effectiveness of each model in generating the target text.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/figures/figures_7_1.jpg", "caption": "Figure 5: Performance of adversarial image attacks varies with perturbation size \n\u2208. The \u2208 of (a) and (f) is 25, \u2208 of (b) and (g) is 15, \u2208 of (c) and (h) is 10, \u2208 of (d) and (i) is 5. (e) is our attention heatmap of the target text on the image. (j) is the target image generated based on the target text used in existing works. M is METEOR score, B is BLEU score, and C is CLIP score.", "description": "This figure compares the performance of adversarial attacks with different perturbation sizes.  The top row shows the results of the proposed AAA method, while the bottom row shows results from existing methods.  Column (e) displays the attention heatmap generated by the model, highlighting which image regions are most crucial for the attack. Column (j) shows the target image from existing methods. The metrics used to evaluate the attack's success are METEOR, BLEU, and CLIP scores.", "section": "4.2 Experiment results"}, {"figure_path": "9uMJeCUeKk/figures/figures_8_1.jpg", "caption": "Figure 6: Comparison of computation time for generating a single adversarial sample using different adversarial attack methods. The y-axis is a measure of similarity between the generated text and the target text, with higher values indicating better target attack performance. The x-axis represents the computation time, and the shorter the time required to find a stable solution, the better.", "description": "This figure compares the computation time of three different attack methods: AAA (the proposed method), transfer, and transfer+query.  The y-axis shows the similarity score (CLIP or BLEU) between the generated adversarial text and the target text, indicating attack success. The x-axis represents the computation time needed to achieve that level of similarity.  The figure shows that while AAA takes longer to converge, it ultimately achieves higher similarity scores, demonstrating its effectiveness despite higher computational cost.", "section": "4.2 Experiment results"}, {"figure_path": "9uMJeCUeKk/figures/figures_16_1.jpg", "caption": "Figure 7: More examples of semantic loss of existing gray-box targeted attacks. The target text is the error-generated text of the image-to-text model that the attacker wants to obtain. The target image is the image generated by using the text-to-image model (Stable Diffusion) based on the target text. The output text is based on the target image using the image-to-text target model (VIT-GPT2/Show-Attend-Tell). similarity indicates the similarity between the target text and the output text. We also show the similarity between the target text and the output text. M stands for METEOR score, B for BLEU score, C for CLIP score, and S for SPICE score.", "description": "This figure presents four examples that illustrate the semantic loss problem in existing gray-box targeted attack methods. For each example, it shows the target image (generated from a target text using Stable Diffusion), the target text (the desired output), and the actual output text generated by the image-to-text model when given the target image.  The similarity scores (METEOR, BLEU, CLIP, and SPICE) are provided to quantify the semantic difference between the target and output texts.  The examples highlight how existing methods often fail to generate outputs with the intended semantics.", "section": "B.1 Analysis of semantic loss"}, {"figure_path": "9uMJeCUeKk/figures/figures_17_1.jpg", "caption": "Figure 3: We compared the convergence curves of populations with and without Attend under the same perturbation size e in (a-b). The fitness function is Sclip in Formula 12, where lower values mean stronger attacks. The dashed line is the average fitness value, and the solid line is the best fitness value. The green line is AAA and the red line is AAA w/o Attend. (c) shows the attention heatmap. (d) and (e) show the visual effects of adversarial image with and without Attend, with minimal perturbation of 100% attack success rate.", "description": "This figure compares the convergence curves of populations with and without the Attend stage of the AAA attack method.  It shows that using the Attend stage leads to faster convergence and a better attack success rate. The figure also visualizes the attention heatmap and demonstrates the visual difference between adversarial images generated with and without the Attend stage.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/figures/figures_18_1.jpg", "caption": "Figure 3: We compared the convergence curves of populations with and without Attend under the same perturbation size e in (a-b). The fitness function is Sclip in Formula 12, where lower values mean stronger attacks. The dashed line is the average fitness value, and the solid line is the best fitness value. The green line is AAA and the red line is AAA w/o Attend. (c) shows the attention heatmap. (d) and (e) show the visual effects of adversarial image with and without Attend, with minimal perturbation of 100% attack success rate.", "description": "This figure compares the convergence curves of populations with and without the Attend stage of the AAA attack method.  It shows that using the Attend stage improves the convergence speed and the overall attack effectiveness.  The figure also includes an attention heatmap and example images to illustrate the visual impact of the attack with and without Attend.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/figures/figures_19_1.jpg", "caption": "Figure 6: Comparison of computation time for generating a single adversarial sample using different adversarial attack methods. The y-axis is a measure of similarity between the generated text and the target text, with higher values indicating better target attack performance. The x-axis represents the computation time, and the shorter the time required to find a stable solution, the better.", "description": "This figure compares the computation time of different adversarial attack methods against two image-to-text models (VIT-GPT2 and Show, Attend, and Tell).  The y-axis shows the similarity (METEOR and SPICE scores) between the generated adversarial text and the target text. Higher values represent better attacks. The x-axis shows the computation time in seconds.  The figure demonstrates that the proposed AAA method, while achieving better attack performance, requires more computation time than existing gray-box methods (transfer and transfer+query).", "section": "4.2 Experiment results"}, {"figure_path": "9uMJeCUeKk/figures/figures_20_1.jpg", "caption": "Figure 11: Attention heatmaps, optimization convergence curves, target text, output text and attack performance for more adversarial samples.", "description": "This figure visualizes several examples of adversarial attacks. For each example, it shows the original image, the attention heatmap generated by a surrogate model, the adversarial image produced by the attack, the optimization convergence curve, the target text that the attacker aimed for, and the output text generated by the image-to-text model.  The results demonstrate the effectiveness of the proposed attack method in generating adversarial images that cause the target model to output the desired text. The optimization curves indicate how the attack process converges to produce the optimal adversarial sample.", "section": "B.7 Visualization of more adversarial samples"}]