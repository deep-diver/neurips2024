[{"figure_path": "9uMJeCUeKk/tables/tables_5_1.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table presents a quantitative comparison of different attack methods on two image-to-text models, VIT-GPT2 and Show-Attend-Tell.  The metrics used for comparison include METEOR, BLEU, CLIP, and SPICE scores, which assess different aspects of the generated text's quality and similarity to the ground truth.  The table shows results for both black-box and gray-box attacks, with and without certain components of the proposed AAA (Ask, Attend, Attack) method.  The epsilon (\u03b5) values represent different perturbation sizes applied to the input images.", "section": "Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/tables/tables_15_1.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table presents a quantitative comparison of the proposed AAA attack method against existing white-box and gray-box attack methods on two different image-to-text models: VIT-GPT2 and Show-Attend-Tell.  The comparison is done using four evaluation metrics: METEOR, BLEU, CLIP, and SPICE, which assess different aspects of the generated text's quality and similarity to the target text.  The table shows the performance of different attack methods under various conditions, highlighting the advantages of the proposed AAA approach, particularly in the challenging black-box attack scenario.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/tables/tables_17_1.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table presents a quantitative comparison of the proposed AAA attack method against existing white-box and gray-box attack methods on two different image-to-text models: VIT-GPT2 and Show-Attend-Tell.  The metrics used for comparison include METEOR, BLEU, CLIP, and SPICE, which measure the semantic similarity between the original and adversarial texts generated by each method.  The table also shows the average perturbation size (epsilon) for each method, indicating the magnitude of the image modifications needed for a successful attack.  This comparison highlights the effectiveness of the AAA method in a black-box setting, demonstrating better performance with less semantic loss compared to existing gray-box methods.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/tables/tables_17_2.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table presents a quantitative comparison of the proposed AAA attack method against existing state-of-the-art white-box and gray-box attack methods on two different image-to-text models: VIT-GPT2 and Show-Attend-Tell.  The comparison uses four evaluation metrics (METEOR, BLEU, CLIP, SPICE) to assess the performance of each method in terms of achieving semantic similarity between the generated adversarial text and the target text.  The table also shows the perturbation size (epsilon) used in each attack.  This allows for a direct comparison of the effectiveness and stealthiness of the various approaches.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/tables/tables_18_1.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table compares the performance of different attack methods on two image-to-text models, VIT-GPT2 and Show-Attend-Tell.  The metrics used for comparison are METEOR, BLEU, CLIP, and SPICE.  The table shows the performance of several existing white-box and gray-box attacks, as well as the proposed AAA method (with and without the Attend and Ask stages).  The results demonstrate the superiority of the AAA method in terms of achieving high semantic similarity with the target text and relatively low perturbation.", "section": "4 Evaluation and Results"}, {"figure_path": "9uMJeCUeKk/tables/tables_18_2.jpg", "caption": "Table 1: Performance comparison (%) of different attack methods.", "description": "This table presents a comparison of the performance of different attack methods on two image-to-text models: VIT-GPT2 and Show-Attend-Tell.  The metrics used for comparison include METEOR, BLEU, CLIP, and SPICE, which are common evaluation metrics for evaluating the quality of generated text in image captioning tasks.  The table shows the performance of several attack methods, including existing white-box and gray-box attacks, as well as the proposed AAA method (with and without certain components).  The results allow for a direct comparison of the proposed method's effectiveness against the state-of-the-art.", "section": "4 Evaluation and Results"}]