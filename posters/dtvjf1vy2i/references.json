{"references": [{"fullname_first_author": "Hugo Lauren\u00e7on", "paper_title": "OBELICS: An open web-scale filtered dataset of interleaved image-text documents", "publication_date": "2023", "reason": "This paper introduces a large-scale, open-source dataset crucial for training advanced vision-language models, directly impacting the development of Idefics2."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022", "reason": "This paper introduces Flamingo, a significant vision-language model that serves as a comparative benchmark and informs architectural choices in the Idefics2 model."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This foundational paper on CLIP provides a backbone model for Idefics2, influencing its vision capabilities and overall architecture."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023", "reason": "This paper introduces LLaMA, a key language model that forms the backbone for Idefics2, significantly influencing its language capabilities."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Pali: Scaling language-image learning in 100+ languages", "publication_date": "2022", "reason": "This work explores scaling up multilingual vision-language models, offering insights relevant to the multilingual capabilities and training strategies employed in Idefics2."}]}