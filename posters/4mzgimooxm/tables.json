[{"figure_path": "4mzGiMooXM/tables/tables_5_1.jpg", "caption": "Table 1: Coarse-grained comparison on the ABC-6k and CC-500 datasets for image quality, object disentanglement, and attribute disentanglement. Values are normalized to sum to 100.", "description": "This table presents a coarse-grained comparison of the proposed Magnet method against three baseline methods (Attend-and-Excite, Structure Diffusion, and Stable Diffusion) using two datasets, ABC-6K and CC-500.  The evaluation metrics are image quality, object disentanglement, and attribute disentanglement.  The values are normalized percentages, summing to 100 for each dataset.  It shows the relative performance of each method on different aspects of image generation quality.", "section": "4 Experiments"}, {"figure_path": "4mzGiMooXM/tables/tables_5_2.jpg", "caption": "Table 2: Fine-grained comparison on the CC-500 dataset. For reference, we provide the average confidence (Conf.) of GroundingDINO [22] to detect the object (Det.). Manual evaluation concerns the object existence (Obj.) and the attribute alignment (Attr.).", "description": "This table presents a fine-grained comparison of different methods on the CC-500 dataset.  It compares automatic object detection confidence and manual evaluations of object existence and attribute alignment accuracy.  The runtime and memory usage of each method are also included, showing the efficiency of Magnet.", "section": "4. Experiments"}, {"figure_path": "4mzGiMooXM/tables/tables_19_1.jpg", "caption": "Table 4: Quantitative comparison following Attend-and-Excite [7].", "description": "This table presents a quantitative comparison of different methods for addressing the attribute binding problem in text-to-image generation.  It compares the performance of Stable Diffusion, Structure Diffusion, Magnet (the proposed method), and Attend-and-Excite using two metrics: CLIP and BLIP scores.  Both metrics evaluate the similarity between generated images and their corresponding text prompts.  The \"Full Prompt\" score considers the entire prompt, while the \"Min. Object\" score considers only the minimum objects.  The table is categorized by whether the method is training-free or optimization-based.", "section": "4.4 Qualitative comparison"}, {"figure_path": "4mzGiMooXM/tables/tables_21_1.jpg", "caption": "Table 5: Ablation study on negative and positive binding vectors. In most cases, the images generated by three cases are equally good or bad, resulting in a high number of no winner.", "description": "This table presents the results of an ablation study evaluating the impact of using positive and negative binding vectors in the Magnet model.  It shows the object and attribute disentanglement scores for three scenarios: using both positive and negative vectors, using only positive vectors, and using only negative vectors. The results are compared to a baseline using Stable Diffusion, and also include the percentage of cases where no clear winner could be determined. The table aims to demonstrate the importance of using both vector types for effective disentanglement.", "section": "4.5 Ablation study"}]