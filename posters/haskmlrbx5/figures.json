[{"figure_path": "haSKMlrbX5/figures/figures_1_1.jpg", "caption": "Figure 1: BONBON alignment achieves high win rates while minimally affecting off-target attributes of generation. Left: Average length of responses versus win rate of models aligned using each method on the Anthropic helpful and harmless single turn dialogue task, using n = 8. As predicted by theory, best-of-n achieves an excellent win rate while minimally affecting the off-target attribute length. Moreover, the BONBON aligned model effectively mimics this optimal policy, achieving a much higher win rate at low off-target drift than other alignment approaches. Right: Sample responses from models with similar win rates to BoNBON. Other methods require higher off-target deviation to achieve a comparably high win rate. We observe that this significantly changes their behavior on off-target aspects. Conversely, BONBON only minimally changes off-target behavior. See section 5 for details.", "description": "This figure shows the results of BONBON alignment compared to other methods. The left panel shows a scatter plot of average response length vs. win rate, demonstrating BONBON's ability to achieve high win rates with minimal impact on response length.  The right panel provides example responses, highlighting the difference in quality and length between BONBON and other methods.", "section": "Experiments"}, {"figure_path": "haSKMlrbX5/figures/figures_4_1.jpg", "caption": "Figure 2: The BoN is essentially the same as the optimal policy in terms of win rate versus KL divergence. Left: The win rate versus KL divergence curves of BoN and optimal policy. Right: The win rate difference between optimal policy and BoN policy for different n.", "description": "This figure shows the comparison between the best-of-n (BoN) sampling policy and the theoretically optimal policy for LLM alignment, in terms of win rate against the baseline model versus KL divergence from the baseline. The left panel shows the win-rate vs KL divergence curves for both policies, illustrating their near-equivalence. The right panel displays the win rate gain of the optimal policy over the BoN policy for different values of 'n', the number of samples drawn. The results highlight that BoN is nearly optimal for maximizing win-rate with minimal changes to off-target aspects.", "section": "3 Best-of-n is Win-Rate vs KL Optimal"}, {"figure_path": "haSKMlrbX5/figures/figures_8_1.jpg", "caption": "Figure 1: BONBON alignment achieves high win rates while minimally affecting off-target attributes of generation. Left: Average length of responses versus win rate of models aligned using each method on the Anthropic helpful and harmless single turn dialogue task, using n = 8. As predicted by theory, best-of-n achieves an excellent win rate while minimally affecting the off-target attribute length. Moreover, the BONBON aligned model effectively mimics this optimal policy, achieving a much higher win rate at low off-target drift than other alignment approaches. Right: Sample responses from models with similar win rates to BoNBON. Other methods require higher off-target deviation to achieve a comparably high win rate. We observe that this significantly changes their behavior on off-target aspects. Conversely, BONBON only minimally changes off-target behavior. See section 5 for details.", "description": "This figure demonstrates the effectiveness of BONBON alignment in achieving high win rates (percentage of times the model's response is preferred to the base model's response) while minimizing changes to off-target attributes such as response length. The left panel shows a plot of average response length against win rate for different alignment methods, revealing that BONBON achieves a high win rate with minimal impact on response length, as predicted by theory. The right panel provides sample responses illustrating how BONBON maintains similar off-target behavior (e.g. response quality) compared to the base model despite improving the win rate significantly more than other methods.", "section": "Experiments"}, {"figure_path": "haSKMlrbX5/figures/figures_16_1.jpg", "caption": "Figure 1: BONBON alignment achieves high win rates while minimally affecting off-target attributes of generation. Left: Average length of responses versus win rate of models aligned using each method on the Anthropic helpful and harmless single turn dialogue task, using n = 8. As predicted by theory, best-of-n achieves an excellent win rate while minimally affecting the off-target attribute length. Moreover, the BONBON aligned model effectively mimics this optimal policy, achieving a much higher win rate at low off-target drift than other alignment approaches. Right: Sample responses from models with similar win rates to BoNBON. Other methods require higher off-target deviation to achieve a comparably high win rate. We observe that this significantly changes their behavior on off-target aspects. Conversely, BONBON only minimally changes off-target behavior. See section 5 for details.", "description": "This figure shows the results of BONBON alignment compared to other methods. The left panel shows that BONBON achieves a high win rate while maintaining similar average response length compared to the baseline model.  The right panel illustrates example responses, demonstrating BONBON's ability to maintain off-target behavior while achieving a high win rate, unlike other methods.", "section": "Experiments"}, {"figure_path": "haSKMlrbX5/figures/figures_22_1.jpg", "caption": "Figure 1: BONBON alignment achieves high win rates while minimally affecting off-target attributes of generation. Left: Average length of responses versus win rate of models aligned using each method on the Anthropic helpful and harmless single turn dialogue task, using n = 8. As predicted by theory, best-of-n achieves an excellent win rate while minimally affecting the off-target attribute length. Moreover, the BONBON aligned model effectively mimics this optimal policy, achieving a much higher win rate at low off-target drift than other alignment approaches. Right: Sample responses from models with similar win rates to BoNBON. Other methods require higher off-target deviation to achieve a comparably high win rate. We observe that this significantly changes their behavior on off-target aspects. Conversely, BONBON only minimally changes off-target behavior. See section 5 for details.", "description": "This figure demonstrates the effectiveness of BONBON alignment in achieving high win rates (model preferred over baseline) while minimizing changes in off-target attributes (response length in this example).  The left panel shows a scatter plot comparing average response length and win rate for different alignment methods.  The right panel showcases example responses, highlighting how BONBON produces high-quality responses with minimal impact on other attributes, unlike other methods.  The Anthropic helpful and harmless single-turn dialogue task was used with n=8 samples.", "section": "Experiments"}]