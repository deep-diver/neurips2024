[{"figure_path": "R1Rrb2d5BH/tables/tables_6_1.jpg", "caption": "Table 1: Unseen-verb (UV) comparison on HICO-DET with state-of-the-art methods. * indicates the model size is estimated according to papers [41, 4]. \u201cTP\u201d denotes the trainable parameters.", "description": "This table compares the performance of different zero-shot HOI detection methods on the HICO-DET dataset, specifically focusing on the unseen-verb setting.  It shows the mean average precision (mAP) for full, unseen, and seen verb categories. The table also lists the backbone network architecture used by each method and the number of trainable parameters (TP). The asterisk (*) indicates that the model sizes for some methods are estimated based on information from the cited papers.", "section": "4 Experiments"}, {"figure_path": "R1Rrb2d5BH/tables/tables_6_2.jpg", "caption": "Table 2: Rare-first unseen-composition (RF-UC) and Nonrare-first unseen composition (NF-UC) comparison on HICO-DET with state-of-the-art methods.", "description": "This table compares the performance of the proposed EZ-HOI method against other state-of-the-art methods on the HICO-DET dataset for two different zero-shot settings: Rare-first unseen composition (RF-UC) and Nonrare-first unseen composition (NF-UC).  The comparison includes the mean Average Precision (mAP) scores for the full dataset, unseen classes, and seen classes, providing insights into the model's ability to generalize to unseen data and handle different types of unseen compositions.  The backbone network used is also specified for each method.", "section": "4 Experiments"}, {"figure_path": "R1Rrb2d5BH/tables/tables_7_1.jpg", "caption": "Table 3: Unseen-object (UO) comparison on HICO-DET with state-of-the-art methods. * indicates the model size is estimated according to papers [41, 4]. \u2020 denotes methods that use a DETR object detection model pretrained on HICO-DET. Results without \u2020 indicate the use of a DETR object detection model pretrained on MS-COCO. \u201cTP\u201d denotes the trainable parameters.", "description": "This table compares the performance of different methods on the unseen-object (UO) zero-shot setting of the HICO-DET dataset.  It shows the mean average precision (mAP) achieved by various methods, broken down into full mAP, unseen mAP, and seen mAP.  The table also includes the backbone network used by each method, the number of trainable parameters (TP), and notes which methods used a DETR object detector pre-trained on HICO-DET versus MS-COCO.  The \"Ours\" rows represent the proposed EZ-HOI model with different configurations.", "section": "4 Experiments"}, {"figure_path": "R1Rrb2d5BH/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study of our method in zero-shot unseen verb setting on HICO-DET.", "description": "This ablation study analyzes the impact of different components of the EZ-HOI model on the zero-shot unseen verb setting of the HICO-DET dataset.  It shows the effect of including or excluding: Intra-HOI fusion, the visual adapter [27], LLM guidance, UTPL, Inter-HOI fusion, and VLM guidance. The results are presented in terms of mean average precision (mAP) for the full dataset, unseen classes, and seen classes.  This table helps to understand the contribution of each module to the overall performance, particularly in handling unseen data.", "section": "4.4 Ablation Studies"}, {"figure_path": "R1Rrb2d5BH/tables/tables_8_2.jpg", "caption": "Table 5: Prompt learning evaluation in zero-shot unseen verb setting on HICO-DET.", "description": "This table compares the performance of different prompt learning methods for zero-shot unseen verb Human-Object Interaction (HOI) detection on the HICO-DET dataset.  It shows the mean average precision (mAP) across three different settings: Full (overall performance), Unseen (performance on unseen verb-object combinations), and Seen (performance on seen verb-object combinations). The methods compared are CLIP [47], MaPLe [22], MaPLe with a visual adapter [27], and the proposed EZ-HOI method. The results demonstrate the improved performance of EZ-HOI in all categories, especially for unseen HOI classes.", "section": "4.5 Prompt Learning Evaluation"}, {"figure_path": "R1Rrb2d5BH/tables/tables_17_1.jpg", "caption": "Table 6: State-of-the-art Comparison on HICO-DET and V-COCO in the fully-supervised setting. Bold highlights the best-performing method within each of the two groups: one-stage and two-stage methods.", "description": "This table compares the performance of the proposed EZ-HOI method against other state-of-the-art methods on two benchmark datasets: HICO-DET and V-COCO.  The comparison is done in a fully supervised setting (not zero-shot).  The table shows the mean Average Precision (mAP) scores across different evaluation metrics (Full, Rare, Nonrare for HICO-DET and APs1, APs2 for V-COCO), highlighting the EZ-HOI's superior performance, especially when compared to other two-stage methods.", "section": "4.3 Comparison with State-of-the-Art Zero-Shot HOI Methods"}, {"figure_path": "R1Rrb2d5BH/tables/tables_18_1.jpg", "caption": "Table 7: Ablation study for hyperparameter N under the unseen-verb setting.", "description": "This table presents the results of an ablation study investigating the impact of the hyperparameter N on the performance of the EZ-HOI model in the unseen-verb zero-shot setting.  The hyperparameter N determines the number of transformer layers in both the text and visual encoders that are fine-tuned during the prompt learning process. The table shows that using N=9 yields the best performance on the unseen classes, balancing between optimizing for unseen and seen classes.", "section": "4.3 Comparison with State-of-the-Art Zero-Shot HOI Methods"}, {"figure_path": "R1Rrb2d5BH/tables/tables_18_2.jpg", "caption": "Table 8: Ablation study for hyperparameter N under the unseen-verb setting.", "description": "This ablation study investigates the impact of varying the number of layers (N) in the text and visual encoders on the model's performance. The results are shown for the full, unseen, and seen mAP metrics.  The study aims to determine the optimal number of layers for incorporating learnable prompts to enhance the zero-shot HOI detection.", "section": "4.3 Comparison with State-of-the-Art Zero-Shot HOI Methods"}]