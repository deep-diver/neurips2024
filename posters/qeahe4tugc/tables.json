[{"figure_path": "QEaHE4TUgc/tables/tables_7_1.jpg", "caption": "Table 1: Cumulative sum of mean episode reward for TRAC PPO, ADAM PPO, and CReLU on Procgen, Atari, and Gym Control environments. Rewards are scaled by 10<sup>5</sup>; higher is better.", "description": "This table presents a quantitative comparison of the cumulative sum of mean episode rewards achieved by three different algorithms (TRAC PPO, ADAM PPO, and CReLU) across various reinforcement learning environments.  The environments are categorized into Procgen, Atari, and Gym Control.  The cumulative reward is a measure of overall performance, and it's scaled by a factor of 10<sup>5</sup> for easier interpretation. Higher values indicate better performance.", "section": "4 Experiment"}, {"figure_path": "QEaHE4TUgc/tables/tables_15_1.jpg", "caption": "Table 1: Cumulative sum of mean episode reward for TRAC PPO, ADAM PPO, and CReLU on Procgen, Atari, and Gym Control environments. Rewards are scaled by 10<sup>5</sup>; higher is better.", "description": "This table presents a comparison of the cumulative sum of mean episode rewards achieved by three different methods: TRAC PPO, ADAM PPO, and CReLU, across various reinforcement learning environments.  The environments are categorized into Procgen (vision-based games), Atari (classic arcade games), and Gym Control (physics-based control tasks).  Higher values indicate better performance.  The rewards are scaled by a factor of 10<sup>5</sup> for easier interpretation.", "section": "Experiment"}, {"figure_path": "QEaHE4TUgc/tables/tables_20_1.jpg", "caption": "Table 3: Performance comparison between TRAC and MECHANIC across three Gym Control environments. The mean, standard error, and p-values reflect the performance over multiple runs, with bolded values highlighting TRAC's superior results.", "description": "This table presents a comparison of TRAC and MECHANIC, two optimization algorithms, across three Gym Control environments: LunarLander-v2, CartPole-v1, and Acrobot-v1.  The table shows the mean reward achieved by each algorithm in each environment, along with the standard error and the p-value from a statistical test comparing the two.  The bolded values indicate where TRAC significantly outperforms MECHANIC.", "section": "G Comparison to MECHANIC"}, {"figure_path": "QEaHE4TUgc/tables/tables_20_2.jpg", "caption": "Table 1: Cumulative sum of mean episode reward for TRAC PPO, ADAM PPO, and CReLU on Procgen, Atari, and Gym Control environments. Rewards are scaled by 10<sup>5</sup>; higher is better.", "description": "This table summarizes the cumulative sum of mean episode rewards achieved by three different methods (TRAC PPO, ADAM PPO, and CReLU) across three sets of reinforcement learning environments: Procgen, Atari, and Gym Control.  The rewards are scaled by a factor of 10<sup>5</sup> for easier comparison.  Higher values indicate better performance.", "section": "Experiment"}]