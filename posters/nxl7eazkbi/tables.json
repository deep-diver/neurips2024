[{"figure_path": "nxL7eazKBI/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of disassembling performance. In the classifier, each category corresponds to a task. 'Base.' refers to the average accuracy for \u2018Disassembled Task' in the source model. In \u2018Disa.\u2019, \u2018Score1 (+Score2)\u2019 represents two metrics: \u2018Score1\u2019 is the accuracy and \u2018Score2\u2019 is the improved accuracy compared to \u2018Base.\u2019 for the \u2018Disassembled Task\u2019 in the disassembled model.", "description": "This table presents the results of the model disassembling experiments.  It compares the accuracy of the original ('Base') model with the accuracy of models created by disassembling task-aware components ('Disa.') from the original model.  The improvement in accuracy is also shown. The experiments were performed using VGG-16, ResNet-50, and GoogleNet models on three different datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet). Each dataset had multiple tasks (categories) to test.", "section": "5.2.1 Model Disassembling Results"}, {"figure_path": "nxL7eazKBI/tables/tables_7_1.jpg", "caption": "Table 2: Comparison of assembling performance. 'Base.' indicates the average accuracy for the 'Assembled Task' in the source models. In \u2018Asse.', \u2018Score1 / Score2' represent the average accuracy scores for the 'Assembled Task' in the assembled models without fine-tuning and with ten epochs of fine-tuning, respectively.", "description": "This table presents the results of the model assembling experiments.  It compares the average accuracy of the assembled models ('Asse.') to the baseline accuracy ('Base.') of the source models for various assembled tasks across different datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet).  The 'Asse.' column shows two scores: 'Score1' represents the accuracy without any fine-tuning after assembling, and 'Score2' represents the accuracy after ten epochs of fine-tuning.", "section": "5.2 Model Assembling Results"}, {"figure_path": "nxL7eazKBI/tables/tables_7_2.jpg", "caption": "Table 3: Performance of the GCN model disassembling on the Cora Dataset. 'Base.' represents the average accuracy for the \u2018Disassembled Task' in the source model. In 'Disa.', 'Score1 (+Score2)' indicates the accuracy and the improvement in accuracy ('Score2') compared to 'Base.' for the 'Disassembled Task' of the disassembled model.", "description": "This table presents the results of applying the Model Disassembling and Assembling (MDA) method to a Graph Convolutional Network (GCN) model for node classification on the Cora dataset.  It compares the average accuracy ('Base.') of the original GCN model for specific tasks (categories 0, 1, 1-2, and 3-5) with the accuracy ('Disa.') achieved after disassembling the model using the MDA method.  The improvement in accuracy is also shown for each task.", "section": "5.3 MDA Applied to GCN Model"}, {"figure_path": "nxL7eazKBI/tables/tables_8_1.jpg", "caption": "Table 4: Comparison of assembling strategies. 'Base.' represents the average accuracy for the \u2018Assembled Task' in the source models. '+Padd.' and '+Padd. +Para.' denote the accuracy of the assembled classifier using only the padding alignment strategy and both the padding alignment and parameter scaling strategies, respectively.", "description": "This table compares the performance of different model assembling strategies. The 'Base' column shows the average accuracy of the assembled task in the source models. The '+Padd.' column presents the accuracy when only the alignment padding strategy is used, while the '+Padd. +Para.' column shows the accuracy when both alignment padding and parameter scaling strategies are applied. The results highlight the impact of both strategies on the final accuracy of the assembled model.", "section": "5.2.2 Model Assembling Results"}, {"figure_path": "nxL7eazKBI/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of disassembling performance. In the classifier, each category corresponds to a task. 'Base.' refers to the average accuracy for \u2018Disassembled Task' in the source model. In \u2018Disa.', 'Score1 (+Score2)' represents two metrics: 'Score1' is the accuracy and 'Score2' is the improved accuracy compared to 'Base.' for the 'Disassembled Task' in the disassembled model.", "description": "This table presents the results of the model disassembling experiments.  It compares the performance of the original model ('Base') against the performance after disassembling task-aware components ('Disa'). For each task (represented by a category in the classification problem), the table shows the base accuracy, the accuracy after disassembling, and the improvement in accuracy resulting from the disassembling process.  The dataset used is specified in the first column.", "section": "5.2.1 Model Disassembling Results"}, {"figure_path": "nxL7eazKBI/tables/tables_16_1.jpg", "caption": "Table 2: Comparison of assembling performance. 'Base.' indicates the average accuracy for the 'Assembled Task' in the source models. In \u2018Asse.', \u2018Score1 / Score2' represent the average accuracy scores for the 'Assembled Task' in the assembled models without fine-tuning and with ten epochs of fine-tuning, respectively.", "description": "This table presents the results of the model assembling process.  It compares the average accuracy of the assembled models ('Asse.') to the baseline accuracy from the source models ('Base.') for various assembled tasks on different datasets. The accuracy is reported with and without fine-tuning (10 epochs).  The 'Score1' represents the accuracy without fine-tuning, and 'Score2' the accuracy with fine-tuning (10 epochs).", "section": "5.2 Model Assembling Results"}, {"figure_path": "nxL7eazKBI/tables/tables_16_2.jpg", "caption": "Table 1: Comparison of disassembling performance. In the classifier, each category corresponds to a task. \u2018Base.\u2019 refers to the average accuracy for \u2018Disassembled Task\u2019 in the source model. In \u2018Disa.\u2019, \u2018Score1 (+Score2)\u2019 represents two metrics: \u2018Score1\u2019 is the accuracy and \u2018Score2\u2019 is the improved accuracy compared to \u2018Base.\u2019 for the \u2018Disassembled Task\u2019 in the disassembled model.", "description": "This table presents the results of the model disassembling experiments.  It compares the average accuracy ('Base.') of a given task (category) in the original trained model to the accuracy ('Disa.') achieved after disassembling that task into a separate, smaller model.  The improvement in accuracy ('Score2') is also shown, indicating how much better (or worse) the disassembled model performed compared to the original. The experiments were conducted on multiple datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) and with several different CNN architectures (VGG-16, ResNet-50, GoogleNet).", "section": "5.2 MDA Applied to CNN Models"}, {"figure_path": "nxL7eazKBI/tables/tables_17_1.jpg", "caption": "Table 8: Comparison of model compression performance. \u2018Base.\u2019 refers to the source model, while \u2018Ours.\u2019 represents the model compressed using the proposed method. \u2018Acc.\u2019, \u2018FLOPs\u2019, and \u2018Para.\u2019 indicate the accuracy, floating point operations, and parameter size of the model, respectively. All accuracy scores are presented as percentages.", "description": "This table compares the performance of three different model compression methods: the proposed MDA method, FPGM, and HRank.  It shows the accuracy, FLOPs (floating point operations), and the number of parameters for each method on three different CNN models (VGG-16, ResNet50, and GoogleNet) trained on the CIFAR-10 dataset.  The goal is to demonstrate the trade-offs between compression level and accuracy.", "section": "H.2 Model Compression"}, {"figure_path": "nxL7eazKBI/tables/tables_18_1.jpg", "caption": "Table 1: Comparison of disassembling performance. In the classifier, each category corresponds to a task. 'Base.' refers to the average accuracy for \u2018Disassembled Task' in the source model. In \u2018Disa.', \u2018Score1 (+Score2)' represents two metrics: 'Score1' is the accuracy and 'Score2' is the improved accuracy compared to 'Base.' for the 'Disassembled Task' in the disassembled model.", "description": "This table presents the results of the model disassembling experiments. It compares the performance of the original model ('Base.') with the performance of the model after disassembling ('Disa.') for various tasks (categories) on different datasets. The 'Disa.' column shows the accuracy of the disassembled model ('Score1') and the improvement in accuracy compared to the original model ('Score2').", "section": "5.2.1 Model Disassembling Results"}]