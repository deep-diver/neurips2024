[{"figure_path": "lZY9u0ijP7/figures/figures_1_1.jpg", "caption": "Figure 1: The CS Drafting algorithm features a recursive and resource-efficient design, implemented through two cascades: the horizontal cascade and the vertical cascade. The horizontal cascade involves using larger draft models to generate the earlier tokens and smaller models for the later tokens. The vertical cascade requires each model to review drafts from smaller models with the exception of the smallest model, which is a statistical language model. As the horizontal cascade and vertical cascade are orthogonal, CS Drafting combines both approaches for optimal efficiency. The figure shows an example of Cascade Speculative Drafting with target model Mt and draft models Md1, Md2, and Md3.", "description": "This figure illustrates the Cascade Speculative Drafting (CS Drafting) algorithm, which uses two cascades to improve efficiency.  The Vertical Cascade uses a series of increasingly smaller models to generate drafts, reducing the reliance on slow autoregressive generation. The Horizontal Cascade optimizes time allocation by using larger models for important tokens and smaller models for less important tokens. The combination of these cascades leads to significant speed improvements compared to baseline methods.", "section": "3 Cascade Speculative Drafting"}, {"figure_path": "lZY9u0ijP7/figures/figures_2_1.jpg", "caption": "Figure 2: The probability of acceptance of draft tokens in relation to their positions in a single step of speculative decoding, evaluated on FLAN-T5-SMALL, BASE, and LARGE models on GSM8K and MMLU. The draft model generates 30 tokens at each step.", "description": "This figure shows the acceptance rate of draft tokens generated by different sized language models (FLAN-T5-small, base, large) at various positions within a single decoding step.  The x-axis represents the token position in the sequence, and the y-axis shows the probability that the token will be accepted by the target model.  The data is shown for two different datasets: GSM8K and MMLU.  The figure illustrates that the probability of a token being accepted decreases as its position in the sequence increases, highlighting an inefficiency in standard speculative decoding.", "section": "Horizontal Cascade"}]