{"references": [{"fullname_first_author": "Yaniv Leviathan", "paper_title": "Fast inference from transformers via speculative decoding", "publication_date": "2023-00-00", "reason": "This paper introduces speculative decoding, a core concept that Cascade Speculative Drafting builds upon and improves."}, {"fullname_first_author": "Charlie Chen", "paper_title": "Accelerating large language model decoding with speculative sampling", "publication_date": "2023-02-01", "reason": "This paper presents the foundational work on speculative decoding, which Cascade Speculative Drafting enhances with novel cascade techniques."}, {"fullname_first_author": "Tianle Cai", "paper_title": "Medusa: Simple llm inference acceleration framework with multiple decoding heads", "publication_date": "2024-00-00", "reason": "This paper provides a comparative method that uses multiple decoding heads to achieve faster inference, which is directly compared against in the experiments."}, {"fullname_first_author": "Takeshi Kojima", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-00-00", "reason": "This paper is relevant because it discusses the zero-shot reasoning capabilities of LLMs, a context in which the proposed model operates and is evaluated."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-00-00", "reason": "This paper's dataset, GSM8K, is used for experimental evaluation and comparison, making it a crucial reference for the experimental methodology and results."}]}