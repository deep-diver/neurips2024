[{"figure_path": "hYMxyeyEc5/tables/tables_3_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the AUROC and FPR95 scores for various OOD detection methods on both far-shift and near-shift OOD scenarios.  The results are shown for two different language models (Llama2-7B and GPT2-XL) and are averaged across multiple samplings to account for variance.  The table compares a proposed trajectory volatility method (TV Score) against five baseline methods, highlighting its superior performance.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_6_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the results of the offline detection experiments.  It compares the Area Under the ROC Curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) of the proposed TV Score method against five baseline methods across two scenarios: far-shift OOD and near-shift OOD.  The results are averaged across multiple samplings and show the performance for both Llama2-7B and GPT2-XL models.  Detailed per-dataset results are available in the appendix.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_6_2.jpg", "caption": "Table 2: Accuracy and Robustness results of the Online Detection scenario. We mainly compare our method with embedding-based methods, and bold denotes the best among these methods.", "description": "This table presents the accuracy and robustness results of the online OOD detection. The accuracy reflects the correctness of identifying OOD samples, while the robustness indicates the stability of the performance across various sampling.  The results are compared against embedding-based methods, highlighting the superior performance of the proposed TV Score method.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_7_1.jpg", "caption": "Table 3: OOD Quality Estimation: Kendall's T and Spearman correlation between various OOD scores and benchmark quality metric binary matching. Each column shows the correlation when ID and OOD samples are merged. Underline denotes the SOTA among all baselines, and bold denotes the SOTA among our methods.", "description": "This table presents the Kendall's Tau and Spearman's rank correlation coefficients between different OOD detection methods' scores and a binary matching metric for OOD quality estimation.  The binary matching metric checks if the model-generated answer contains the correct answer.  The results are shown separately for far-shift and near-shift OOD scenarios, and the best-performing methods (SOTA) are highlighted.", "section": "5.1 Beyond Detection: OOD Quality Estimation"}, {"figure_path": "hYMxyeyEc5/tables/tables_8_1.jpg", "caption": "Table 3: OOD Quality Estimation: Kendall's T and Spearman correlation between various OOD scores and benchmark quality metric binary matching. Each column shows the correlation when ID and OOD samples are merged. Underline denotes the SOTA among all baselines, and bold denotes the SOTA among our methods. ", "description": "This table shows the Kendall's Tau and Spearman correlation coefficients between different out-of-distribution (OOD) detection scores and a benchmark quality metric (binary matching).  The results are presented separately for far-shift and near-shift OOD scenarios, comparing the performance of the proposed TV Score method against several baselines. The table highlights the best-performing methods for each scenario and metric.", "section": "5.1 Beyond Detection: OOD Quality Estimation"}, {"figure_path": "hYMxyeyEc5/tables/tables_8_2.jpg", "caption": "Table 5: AUROC score matrix produced after alternating the MATH dataset's five domains as ID and OOD data measured by (a) Input Embedding Mahalanobis Distance and (b) Output Embedding (w/ CoT) Mahalanobis Distance. Darker colors represent better performances.", "description": "This table presents the Area Under the ROC Curve (AUROC) scores for the input embedding Mahalanobis distance and the output embedding (with Chain-of-Thought) Mahalanobis distance methods.  Each cell shows the AUROC score when one of the five MATH domains is used as the in-distribution (ID) data and the remaining four are used as the out-of-distribution (OOD) data. The table is structured as a 5x5 matrix, with each row representing an ID domain and each column representing an OOD domain.  Darker colors indicate higher AUROC scores, showing better performance of the method in distinguishing between ID and OOD data. The table helps demonstrate the limitations of static embedding methods for out-of-distribution detection in mathematical reasoning.", "section": "6.1 Input Space: Representation Dilemma on Mathematical Expressions"}, {"figure_path": "hYMxyeyEc5/tables/tables_9_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the results of the offline detection experiments.  It shows the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) for different OOD detection methods, including the proposed TV Score and several baselines. The results are broken down by model (Llama2-7B and GPT2-XL) and OOD scenario (far-shift and near-shift). Underlined values indicate the best performance among baseline methods, and bold values show the best overall performance.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_16_1.jpg", "caption": "Table 7: Examples of inputs/outputs from different domains in the mathematical reasoning scenario.", "description": "This table shows four examples of input-output pairs from different mathematical domains (Algebra, Geometry, Number Theory, and Precalculus). Each row represents a different domain, showing the input question and the correct numerical output.  The examples highlight the fact that different domains can lead to the same numerical output, which is a challenge for existing methods based on comparing embedding distances.", "section": "B.2 More Examples"}, {"figure_path": "hYMxyeyEc5/tables/tables_16_2.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the results of the offline OOD detection experiment.  It compares the performance of the proposed TV Score method against five baselines (Maximum Softmax Probability, Monte-Carlo Dropout, Sequence Perplexity, Input Embedding, and Output Embedding) across two OOD scenarios (far-shift and near-shift).  The Area Under the ROC Curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) metrics are reported for each method and scenario.  The table highlights the best-performing method (SOTA) for each metric and scenario.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_21_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the AUROC and FPR95 scores for various offline OOD detection methods under two scenarios: far-shift OOD and near-shift OOD.  The results are shown for the Llama2-7B and GPT2-XL models, comparing the proposed TV Score method against several baselines.  The table highlights the best-performing methods for each metric and dataset, demonstrating the effectiveness of the TV Score method, particularly in near-shift OOD scenarios.  Detailed results for individual datasets are available in Appendix F.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_23_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) for different offline OOD detection methods.  The results are shown for both far-shift and near-shift OOD scenarios, using two different language models (Llama2-7B and GPT2-XL).  The table highlights the best-performing methods (SOTA) among all baseline methods and all methods.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_24_1.jpg", "caption": "Table 10: Accuracies of all datasets we select as the OOD data in pre-trained GLMs.", "description": "This table presents the accuracy of pre-trained Llama2-7B and GPT2-XL models on various datasets used as out-of-distribution (OOD) data.  It shows the number of correctly classified samples out of the total number of samples for each dataset in both far-shift and near-shift OOD scenarios. The results indicate the baseline performance of the GLMs and illustrate the difficulty of the OOD detection tasks.", "section": "4 Experiments"}, {"figure_path": "hYMxyeyEc5/tables/tables_25_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the results of offline OOD detection experiments using two different large language models (LLMs), Llama2-7B and GPT2-XL, on both far-shift and near-shift OOD scenarios.  It compares the performance of the proposed Trajectory Volatility (TV) score method with five baseline methods across multiple metrics (AUROC and FPR95).  The results are presented as averages across different datasets, showing the effectiveness of the TV score, especially in near-shift scenarios.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_25_2.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the Area Under the ROC Curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) for various offline OOD detection methods.  Results are shown for both far-shift and near-shift OOD scenarios, comparing the proposed TV Score method with several baselines.  The table highlights the best performing methods for both metrics in each scenario.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_26_1.jpg", "caption": "Table 1: AUROC and FPR95 results of the Offline Detection scenario. Underline and bold denote SOTA among all baselines and all methods, respectively. We report the average results under each setting in the main text, results of each dataset are shown in Table 11 and 12 (Appendix F).", "description": "This table presents the results of offline OOD detection experiments.  It shows the Area Under the ROC Curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) for different methods, including the proposed TV Score and several baselines.  Results are shown for both far-shift and near-shift out-of-distribution (OOD) scenarios using two different language models (Llama2-7B and GPT2-XL).  Detailed results for each individual dataset can be found in Appendix F.", "section": "4.2 Main Results"}, {"figure_path": "hYMxyeyEc5/tables/tables_26_2.jpg", "caption": "Table 3: OOD Quality Estimation: Kendall's T and Spearman correlation between various OOD scores and benchmark quality metric binary matching. Each column shows the correlation when ID and OOD samples are merged. Underline denotes the SOTA among all baselines, and bold denotes the SOTA among our methods.", "description": "This table presents the results of the OOD quality estimation experiment, comparing different methods' Kendall's Tau and Spearman's correlation coefficients against a binary matching benchmark.  It shows the correlation between each OOD detection method's score and the accuracy of the model's generated answer (whether it matches the correct answer). The table is divided into far-shift and near-shift OOD settings and shows the average correlation for each method across multiple datasets.", "section": "5.1 Beyond Detection: OOD Quality Estimation"}]