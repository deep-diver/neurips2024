{"references": [{"fullname_first_author": "Bergstra", "paper_title": "Random search for hyper-parameter optimization", "publication_date": "2012-MM-DD", "reason": "This paper is foundational in hyperparameter optimization (HPO), introducing a simple yet effective random search method that often outperforms more complex techniques."}, {"fullname_first_author": "Feurer", "paper_title": "Hyperparameter Optimization", "publication_date": "2019-MM-DD", "reason": "This comprehensive overview of HPO provides a foundational understanding of the challenges and approaches in the field, establishing a context for the current paper's work."}, {"fullname_first_author": "Bischl", "paper_title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges", "publication_date": "2023-MM-DD", "reason": "This recent review offers a current perspective on HPO, highlighting recent advancements and the field\u2019s ongoing challenges, which the present study builds upon."}, {"fullname_first_author": "Cowen-Rivers", "paper_title": "HEBO: Pushing the limits of sample-efficient hyper-parameter optimisation", "publication_date": "2022-MM-DD", "reason": "This paper introduces a state-of-the-art Bayesian Optimization method, HEBO, which is used as a benchmark in the current paper\u2019s experimental evaluation."}, {"fullname_first_author": "L\u00e9vesque", "paper_title": "Bayesian Hyperparameter Optimization: Overfitting, Ensembles and Conditional Spaces", "publication_date": "2018-MM-DD", "reason": "This thesis provides prior work on reshuffling, investigating its effect on generalization performance and setting the stage for the current paper\u2019s more thorough theoretical analysis."}]}