[{"type": "text", "text": "Transparent Networks for Multivariate Time Series ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Transparent models, which are machine learning models that produce inherently   \n2 interpretable predictions, are receiving significant attention in high-stakes domains.   \n3 However, despite much real-world data being collected as time series, there is a lack   \n4 of studies on transparent time series models. To address this gap, we propose a novel   \n5 transparent neural network model for time series called Generalized Additive Time   \n6 Series Model (GATSM). GATSM consists of two parts: 1) independent feature   \n7 networks to learn feature representations, and 2) a transparent temporal module to   \n8 learn temporal patterns across different time steps using the feature representations.   \n9 This structure allows GATSM to effectively capture temporal patterns and handle   \n10 dynamic-length time series while preserving transparency. Empirical experiments   \n1 show that GATSM significantly outperforms existing generalized additive models   \n12 and achieves comparable performance to black-box time series models, such as   \n13 recurrent neural networks and Transformer. In addition, we demonstrate that   \n14 GATSM finds interesting patterns in time series. The source code is available at   \n15 https://anonymous.4open.science/r/GATSM-78F4/. ", "page_idx": 0}, {"type": "text", "text": "16 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "17 Artificial neural networks excel at learning complex representations and demonstrate remarkable   \n18 predictive performance across various fields. However, their complexity makes interpreting the   \n19 decision-making processes of neural network models challenging. Consequently, post-hoc explainable   \n20 artificial intelligence (XAI) methods, which explain the predictions of trained black-box models,   \nhave been widely studied in recent years [1, 2, 3, 4]. XAI methods are generally effective at   \n22 providing humans with understandable explanations of model predictions. However, they may   \n23 produce incorrect and unfaithful explanations of the underlying black-box model and cannot provide   \n24 actual contributions of input features to model predictions [5, 6]. Therefore, their applicability to   \n25 high-stakes domains-such as healthcare and fraud detection, where faithfulness to the underlying   \n26 model and actual contributions of features are important-is limited.   \n27 Due to these limitations, transparent (i.e., inherently interpretable) models are attracting attention as   \n28 alternatives to XAI in high-stakes domains [7, 8, 9]. Modern transparent models typically adhere to   \n29 the generalized additive model (GAM) framework [10]. A GAM consists of independent functions,   \n30 each corresponding to an input feature, and makes predictions as a linear combination of these   \n31 functions (e.g., the sum of all functions). Therefore, each function reflects the contribution of its   \n32 respective feature. For this reason, interpreting GAMs is straightforward, making them widely used in   \n33 various fields, such as healthcare [11, 12], survival analysis [13], and model bias discovery [7, 14, 15].   \n34 However, despite much real-world data being collected as time series, research on GAMs for time   \n35 series remains scarce. Consequently, the applicability of GAMs in real-world scenarios is still limited.   \n36 To overcome this limitation, we propose a novel transparent model for multivariate time series   \n37 called Generalized Additive Time Series Model (GATSM). GATSM consists of independent feature   \n38 networks to learn feature representations and a transparent temporal module to learn temporal patterns.   \n39 Since employing distinct networks across different time steps requires a massive amount of learnable   \n40 parameters, the feature networks in GATSM share the weights across all time steps, while the   \n41 temporal module independently learns temporal patterns. GATSM then generates final predictions by   \n42 integrating the feature representations with the temporal information from the temporal module. This   \n43 strategy allows GATSM to effectively capture temporal patterns and handle dynamic-length time   \n44 series while preserving transparency. Additionally, this approach facilitates the separate extraction of   \n45 time-independent feature contributions, the importance of individual time steps, and time-dependent   \n46 feature contributions through the feature functions, temporal module, and final prediction. To   \n47 demonstrate the effectiveness of GATSM, we conducted empirical experiments on various time series   \n48 datasets. The experimental results show that GATSM significantly outperforms existing GAMs   \n49 and achieves comparable performances to black-box time series models, such as recurrent neural   \n50 networks and Transformer [16]. In addition, we provide visualizations of GATSM\u2019s predictions to   \n51 demonstrate that GATSM finds interesting patterns in time series. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "52 2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "53 Various XAI studies have been conducted over the past decade [7, 8, 9, 17, 18]; however, they are   \n54 less relevant to the transparent model that is the subject of this study. Therefore, we refer readers to   \n55 [19, 20] for more detailed information on recent XAI research. In this section, we review existing   \n56 transparent models closely related to our GATSM and discuss their limitations.   \n5578 Twhhee rsei e i lsi an elianr k mfoudneclt iiosn ,d ginnedidc taot efs itt thhe en cuomnbdietri oonf ailn pexutp feecattatuiroens, $\\begin{array}{r}{g\\left(\\mathbb{E}\\left(y\\mid\\mathbf{x}\\right)\\right)=\\sum_{i=1}^{M}x_{i}w_{i}}\\end{array}$   \n$g(\\cdot)$ $M$ $y$   \n59 given input features $\\mathbf{x}\\in\\mathbb{R}^{M}$ , and $w_{i}\\in\\mathbb{R}$ is the learnable weight for $x_{i}$ . This model captures only   \n60 linear relationships between the target $y$ and the inputs $\\mathbf{X}$ . To address this limitation, GAM [10]   \n61 extends the simple linear model to the generalized form as follows: ", "page_idx": 1}, {"type": "table", "img_path": "gsott1UXlq/tmp/147ea1c907711d2aa7e4b2e4a9387ee621ff5a44f1e18319d3a80284dbf0ba9a.jpg", "table_caption": ["Table 1: Advantages of GATSM. "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\ng\\left(\\mathbb{E}\\left(\\boldsymbol{y}\\mid\\mathbf{x}\\right)\\right)=\\sum_{i=1}^{M}f_{i}\\left(x_{i}\\right),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "62 where each $f_{i}(\\cdot)$ is a function that models the effect of a single feature, referred as a feature function.   \n63 Typically, $f_{i}$ (\u00b7) becomes a non-linear function such as a decision tree or neural network to capture   \n64 non-linear relationships.   \n65 Originally, GAMs were ftited via the backftiting algorithm using smooth splines [10, 21]. Later, Yin   \n66 Lou et al. [22] and Harsha Nori et al. [23] have proposed boosted decision tree-based GAMs, which   \n67 use boosted decision trees as feature functions. Spline- and tree-based GAMs have less flexibility   \n68 and scalability. Thus, extending them to transfer or multi-task learning is challenging. To overcome   \n69 this problem, various neural network-based GAMs have been proposed in recent years. Potts [24]   \n70 introduced generalized additive neural network, which employs 2-layer neural networks as feature   \n71 functions. Similarly, Rishabh Agarwal et al. [7] proposed neural additive model (NAM) that employs   \n72 multi-layer neural networks. To improve the scalability of NAM, Chun-Hao Chang et al. [8] and   \n73 Filip Radenovic et al. [9] proposed the neural oblivious tree-based GAM and the basis network-based   \n74 GAM, respectively. Xu et al. [25] introduced a sparse version of NAM using the group LASSO. One   \n75 disadvantage of GAMs is their limited predictive power, which stems from the fact that they only   \n76 learn first-order feature interactions-i.e., relationships between the target value and individual features.   \n77 To address this, various studies have been conducted to enhance the predictive powers of GAMs by   \n78 incorporating higher-order feature interactions, while still maintaining transparency. $\\mathrm{GA^{2}M}$ [26]   \n79 simply takes pairwise features as inputs to learn pairwise interactions. GAMI-Net [27], a neural   \n80 network-based GAM, consists of networks for main effects (i.e., first-order interactions) and pairwise   \n81 interactions. To enhance the interpretability of GAMI-Net, the sparsity and heredity constraints are   \n82 added, and trivial features are pruned in the training process. Sparse interaction additive network [28]   \n83 is a 3-phase method for exploiting higher-order interactions. Initially, a black-box neural network is   \n84 trained; subsequently, the top- $k$ important features are identified using explainable feature attribution   \n85 methods like LIME [1] and SHAP [2], and finally, NAM is trained with these extracted features.   \n86 Dubey et al. [29] introduced scalable polynomial additive model, an end-to-end model that learns   \n87 higher-order interactions via polynomials. Similarly, Kim et al. [15] proposed higher-order NAM that   \n88 utilizes the feature crossing technique to capture higher-order interactions. Despite their capabilities,   \n89 the aforementioned GAMs cannot process time series data, which limits their applicability in real  \n90 world scenarios. Recently, neural additive time series Model (NATM) [30], a time-series adaptation   \n91 of NAM, has been proposed. However, NATM handles each time step independently with separate   \n92 feature networks. This approach cannot capture effective temporal patterns and only takes fixed-length   \n93 time series as input. Our GATSM not only captures temporal patterns but also handles dynamic-length   \n94 time series. Table 1 shows the advantages of our GATSM compared to existing GAMs. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "image", "img_path": "gsott1UXlq/tmp/c4f060174f6138cacc946916753c1f9291cd43616ef6d28ac837146dfda13713.jpg", "img_caption": ["Figure 1: Architecture of GATSM. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "95 3 Problem Statement ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "96 We tackle the problem of the existing GAMs on time series. Equation (1) outlines the GAM framework   \n97 for tabular data, which fails to capture the interactions between current and previous observations in   \n98 time series. A straightforward method to extend GAM to time series, adopted in NATM, is applying   \n99 distinct feature functions to each time step and summing them to produce predictions: ", "page_idx": 2}, {"type": "equation", "text": "$$\ng\\left(\\mathbb{E}\\left(y_{t}\\mid\\mathbf{X}_{:t}\\right)\\right)=\\sum_{i=1}^{t}\\sum_{j=1}^{M}f_{i,j}\\left(x_{i,j}\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "100 where $\\mathbf{X}\\in\\mathbb{R}^{T\\times M}$ is a time series with $T$ time steps and $M$ features, and $t$ is the current time step.   \n101 This method can handle time series data as input but fails to capture effective temporal patterns   \n102 because the function $f_{i,j}\\left(\\cdot\\right)$ still does not interact with previous time steps. To overcome this problem, ", "page_idx": 2}, {"type": "text", "text": "103 we suggest a new form of GAM for time series defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\ng\\left(\\mathbb{E}\\left(y_{t}\\mid\\mathbf{X}_{:t}\\right)\\right)=\\sum_{i=1}^{t}\\sum_{j=1}^{M}f_{i,j}\\left(x_{i,j},\\mathbf{X}_{:t}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "104 Definition 3.1 GAMs for time series, which capture temporal patterns hold the form of Equation 3. ", "page_idx": 3}, {"type": "text", "text": "105 In Equation (3), the function $f\\left(\\cdot,\\cdot\\right)$ can capture interactions between current and previous time steps.   \n106 Therefore, GAMs adhering to Definition 3.1 are capable of capturing temporal patterns. However,   \n107 implementing such a model while maintaining transparency poses challenges. In the following   \n108 section, we will describe our approach to implementing a GAM that holds Definition 3.1. To the best   \n109 of our knowledge, no existing literature addresses Definition 3.1. ", "page_idx": 3}, {"type": "text", "text": "110 4 Our Method: Generalized Additive Time Series Model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "111 4.1 Architecture ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "112 Figure 1 shows the overall architecture of GATSM. Our model has two modules: 1) feature networks,   \n113 called time-sharing neural basis model, for learning feature representations, and 2) masked multi-head   \n114 attention for learning temporal patterns.   \n115 Time-Sharing NBM: Assume a time series with $T$ time steps and $M$ features. Applying GAMs   \n116 to this time series necessitates $T\\times M$ feature functions, which becomes problematic when dealing   \n117 with large $T$ or $M$ due to increased model size. This limits the applicability of GAMs to real-world   \n118 datasets. To overcome this problem, we extend neural basis model (NBM) [9] to time series as: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\tilde{x}_{i,j}=f_{j}\\left(x_{i,j}\\right)=\\sum_{k=1}^{B}h_{k}\\left(x_{i,j}\\right)w_{j,k}^{n b m}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "119 We refer to this extended version of NBM as time-sharing NBM. Time-sharing NBM has $B$ basis   \n120 functions, with each basis $h_{k}(\\cdot)$ taking a feature $x_{i,j}$ as input. The feature-specific weight $w_{j,k}^{n b m}$   \n121 then projects the basis to the transformed feature $\\tilde{x}_{i,j}$ . As depicted in Equation 4, the basis functions   \n122 are shared across all features and time steps, drastically reducing the number of required feature   \n123 functions $T\\times M$ to $B$ . We use $B=100$ and implement $h_{k}\\left(\\cdot\\right)$ using multi-layer perceptron (MLP).   \n124 Masked MHA: GATSM employs multi-head attention (MHA) to learn temporal patterns. Although   \n125 the dot product attention [16] is popular, simple dot operation has low expressive power [31].   \n126 Therefore, we adopt the 2-layer attention mechanism proposed by [31] to GATSM. We first transform   \n127 $\\tilde{\\mathbf{x}}_{i}=[\\tilde{x}_{i,1},\\tilde{x}_{i,2},\\cdot\\dot{\\cdot}\\cdot,\\tilde{x}_{i,M}]\\overset{\\cdot}{\\in}\\mathbb{R}^{M}$ produced by Equation 4 as follows: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{v}_{i}=\\tilde{\\mathbf{x}}_{i}^{\\mathsf{T}}\\mathbf{Z}+\\mathbf{p}\\mathbf{e}_{i},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "128 where $\\mathbf{Z}\\,\\in\\,\\mathbb{R}^{M\\times D}$ is a learnable weight, $\\mathbf{p}\\mathbf{e}_{i}\\,=\\,[p e_{i,1},p e_{i,2},\\cdot\\cdot\\cdot\\,,p e_{i,D}]\\,\\in\\,\\mathbb{R}^{D}$ is the positional   \n129 encoding for $i$ -th step, and $D$ indicates the hidden size. The positional encoding is defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p e_{i,j}=\\left\\{\\sin\\left(\\frac{i}{10000^{2j/D}}\\right)\\quad\\mathrm{if~}j\\bmod2=1,\\quad}\\\\ {\\cos\\left(\\frac{i}{10000^{2j/D}}\\right)\\quad\\mathrm{otherwise}.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "130 The positional encoding helps GATSM effectively capture temporal patterns. While learnable position   \n131 embedding also works in GATSM, we recommend positional encoding because position embedding   \n132 requires knowledge of the maximum number of time steps, which is often unknown in real-world   \n133 settings. After computing $\\mathbf{v}_{i}$ , we calculate the attention scores as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\boldsymbol e}_{k,i,j}=\\sigma\\left([{\\bf v}_{i}\\ |\\ {\\bf v}_{j}]^{\\top}{\\bf w}_{k}^{a t t n}\\right)m_{i,j},}\\\\ &{\\quad{\\boldsymbol a}_{k,i,j}=\\frac{\\exp\\left({\\boldsymbol e}_{k,i,j}\\right)}{\\sum_{t=1}^{T}\\exp\\left({\\boldsymbol e}_{k,i,t}\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "134 where $k$ is attention head index, $\\sigma\\left(\\cdot\\right)$ is an activation function, $\\mathbf{w}_{k}^{a t t n}\\in\\mathbb{R}^{2D}$ , and $m_{i,j}\\in\\mathbb{R}$ is the   \n135 mask value used to block future information. The time mask is defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nm_{i,j}=\\left\\{{1\\atop-\\infty}\\right.\\ \\mathrm{if}\\ i\\leq j,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "136 Inference: The prediction of GATSM is produced by combining the transformed features from   \n137 time-sharing NBM with the attention scores from masked MHA. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{y}_{t}=\\sum_{k=1}^{K}\\mathbf{a}_{k,t}^{\\top}\\tilde{\\mathbf{X}}\\mathbf{w}_{k}^{o u t},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "138 where $K$ is the number of attention heads, $\\mathbf{{a}}_{k,t}=[a_{k,i,1},a_{k,i,2},\\cdot\\cdot\\cdot\\;,a_{k,i,T}]\\in\\mathbb{R}^{T}$ is the attention   \n139 map in Equation 8, $\\tilde{\\mathbf{X}}=[\\tilde{\\mathbf{x}}_{1},\\tilde{\\mathbf{x}}_{2},\\cdot\\cdot\\cdot\\mathbf{\\mu},\\tilde{\\mathbf{x}}_{T}]\\in\\mathbb{R}^{T\\times M}$ is the transformed features in Equation 4, and   \n140 $\\mathbf{w}_{k}^{o\\bar{u}t}\\in\\mathbb{R}^{\\bar{M}}$ is the learnable output weight. ", "page_idx": 4}, {"type": "text", "text": "141 Interpretability: We can rewrite Equation 10 as the following scalar form: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k=1}^{K}\\mathbf{a}_{k,t}^{\\intercal}\\tilde{\\mathbf{X}}\\mathbf{w}_{k}^{o u t}=\\displaystyle\\sum_{u=1}^{t}\\sum_{m=1}^{M}\\sum_{k=1}^{K}\\sum_{b=1}^{B}a_{k,t,u}h_{b}\\left(x_{t,m}\\right)w_{m,b}^{n b m}w_{k,m}^{o u t}}\\\\ &{\\displaystyle=\\sum_{u=1}^{t}\\sum_{m=1}^{M}f_{u,m}\\left(x_{u,m},\\mathbf{X}_{:t}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "142 Equation 11 shows that GATSM satisfying Definition 3.1. We can derive three types of interpretations   \n143 from GATSM: 1) $a_{k,t,u}$ indicates the importance of time step $u$ at time step t, 2) $\\dot{h}_{b}\\left(x_{t,m}\\right)\\dot{w_{m,b}^{n b m}}w_{k,m}^{o u t}$   \n144 represents the time-independent contribution of feature $m$ , and 3) $a_{k,t,u}h_{b}\\left(x_{t,m}\\right)w_{m,b}^{n b m}w_{k,m}^{o u t}$ repre  \n145 sents the time-dependent contribution of feature $m$ at time step . ", "page_idx": 4}, {"type": "text", "text": "146 5 Experiments ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "147 5.1 Experimental Setup ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "148 Datasets: We conducted our experiments using eight publicly available real-world time series   \n149 datasets. From the Monash repository [32], we sourced three datasets: Energy, Rainfall, and   \n150 AirQuality. Another three datasets, Heartbeat, LSST, and NATOPS, were downloaded from the   \n151 UCR repository [33]. The remaining two datasets, Mortality and Sepsis, were downloaded from   \n152 the PhysioNet [34]. We perform ordinal encoding for categorical features and standardize features   \n153 to have zero-mean and unit-variance. For forecasting tasks, target value y is also standardized to   \n154 zero-mean and unit-variance. If the dataset contains missing values, we impute categorical features   \n155 with their modes and numerical features with their means. The dataset is split into a $60\\%/20\\%/20\\%$   \n156 ratio for training, validation, and testing, respectively. Table 2 shows the statistics of the experimental   \n157 datasets. Further details of the experimental datasets can be found in Appendix B.   \n158 Baselines: We compare our GATSM with 12 baselines, which can be categorized into four groups: 1)   \n159 Black-box tabular models include extreme gradient boosting (XGBoost) [35] and MLP. 2) Black-box   \n160 time series models include simple recurrent neural network (RNN), gated recurrent unit (GRU), long   \n161 short-term memory (LSTM), and Transformer [16]. 3) Transparent tabular models are simple linear   \n162 model (Linear), explainable boosting machine (EBM) [23], NAM [7], NodeGAM [8], and NBM [9].   \n163 4) NATM [30] is a transparent time series model.   \n164 Implementation: We implement XGBoost and EBM models using the xgboost and interpretml   \n165 libraries, respectively. For NodeGAM, we employ the official implementation provided by its authors   \n166 [8]. The remaining models are developed using PyTorch [36]. All models undergo hyperparameter   \n167 tuning via Optuna [37]. The pytorch-based models are optimized with the Adam with decoupled   \n168 weight decay (AdamW) [38] optimizer on an NVIDIA A100 GPU. Model training is halted if the   \n169 validation loss does not decrease over 20 epochs. We use mean squared error for the forecasting tasks,   \n170 and for classification tasks, we use cross-entropy loss. Further details of the model implementations   \n171 and hyper-parameters are provided in Appendix C. ", "page_idx": 4}, {"type": "table", "img_path": "gsott1UXlq/tmp/16ea14444615daa073c19e304ce53b69b179353af92ca62b3aebeec7fd4f003d.jpg", "table_caption": ["Table 2: Dataset statistics. "], "table_footnote": ["FCST: forecasting "], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "table", "img_path": "gsott1UXlq/tmp/7987e8676482a699fca75014453bc7a5efbfe69d7c7e7975298ffe3276bb9006.jpg", "table_caption": ["Table 3: Predictive performance comparison of various models. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "172 5.2 Comparison with baselines ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "173 Table 3 shows the predictive performances of the experimental models. We report mean scores   \n174 and standard deviations over five different random seeds. For the forecasting datasets, we evaluate   \n175 $R^{2}$ scores. For the binary classification datasets, we assess the area under the receiver operating   \n176 characteristic curve (AUROC). For the multi-class classification datasets, we measure accuracy. We   \n177 highlight the best-performing model in bold and underline the second-best model. Since the tabular   \n178 models cannot handle time series, they only take $\\mathbf{X}_{t}$ to produce $y_{t}$ .   \n179 On the Energy and Heartbeat datasets, which are small in size, our GATSM demonstrates the best   \n180 performance, indicating strong generalization ability. EBM, XGBoost, and Transformer struggle   \n181 with overfitting on the Energy dataset. For the Mortality and Sepsis datasets, there is no significant   \n182 performance difference between tabular and time series models, nor between black-box and trans  \n183 parent models. This suggests that these two healthcare datasets lack significant temporal patterns   \n184 and feature interactions. It is likely that seasonal patterns are hard to detect in medical data, and   \n185 the patient\u2019s current condition already encapsulates previous conditions, making historical data less   \n186 crucial. Since these datasets contain variable-length time series, the performance of NATM, which   \n187 can only handle fixed-length time series, is not available. On the Rainfall, AirQuality, LSST, and   \n188 NATOPS datasets, the time series models significantly outperform the tabular models, indicating   \n189 that these datasets contain important temporal patterns that tabular models cannot capture. Addition  \n190 ally, the black-box models outperform the transparent models, suggesting that these datasets have   \n191 higher-order feature interactions that transparent models cannot capture. Nevertheless, GATSM is the   \n192 best model within the transparent model group and performs comparably to Transformer. Overall,   \n193 GATSM achieved the best average rank in the experiments, followed by the Transformer, indicating   \n194 GATSM\u2019s superiority. Additional experiments on model throughput and an ablation study on the   \n195 basis functions are presented in Appendix D. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "table", "img_path": "gsott1UXlq/tmp/c2186ca0e9039d4afd921e825b7c80e59a791ce430638883415844da2ddd2d77.jpg", "table_caption": ["Table 4: Ablation study on different feature functions "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "gsott1UXlq/tmp/be35bbc3ffb7c1d79bfe54dfb774015277a072524a3e8e55c57ee3318364e589.jpg", "table_caption": ["Table 5: Ablation study on the temporal module "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "196 5.3 Ablation study ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "197 Choice of feature function: We evaluate the performance of GATSM by changing the feature   \n198 functions using three models: Linear, NAM, and NBM. Table 4 presents the results of this experiment.   \n199 The simple linear function performs poorly because it lacks the capability to capture non-linear   \n200 relationships. In contrast, NAM, which can capture non-linearity, shows improved performance over   \n201 the linear function. However, NBM stands out by achieving the best performance in six out of eight   \n202 datasets. This indicates that the basis strategy of NBM is highly effective for time series data.   \n203 Design of temporal module: We evaluate the performance of GATSM by modifying the design of   \n204 the temporal module. The results are presented in Table 5. GATSM without the temporal module   \n205 (Base) fails to learn temporal patterns and shows poor performance in the experiment. GATSM with   \n206 only positional encoding $\\mathrm{(Base+PE)}$ also shows similar performance to the Base, indicating that   \n207 positional encoding alone is insufficient for capturing effective temporal patterns. GATSM with only   \n208 multi-head attention $(\\mathrm{Base}+\\mathrm{MHA})$ outperforms the previous two methods, demonstrating that the   \n209 MHA mechanism is beneficial for capturing temporal patterns. Finally, our full GATSM $\\mathrm{(Base+PE+}$   \n210 MHA) significantly outperforms the other methods, suggesting that the combination of PE and MHA   \n211 creates a synergistic effect. Consistent with our previous findings in section 5.2, all four methods   \n212 show similar performances on the Mortality and Sepsis datasets, which lack significant temporal   \n213 patterns. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "214 5.4 Interpretation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "215 In this section, we visualize four interpretations of GATSM\u2019s predictions on the AirQuality dataset.   \n216 In addition, interpretations for the Rainfall dataset can be found in Appendix E.   \n217 Time-step importance: We plot the average attention scores at the last time step $T$ in Figure 2.   \n218 The process for extracting the average attention score of time step $u$ at time step $t$ is formalized as   \n219 $\\textstyle\\sum_{k=1}^{K^{-}}a_{k,t,u}$ . This process is repeated over all data samples, and the results are averaged. Based   \n220 on Figure 2, it seems that GATSM pays more attention to the initial and last states than to the   \n221 intermediate states. This indicates that the current concentration of particulate matter depends on the   \n222 initial state.   \n223 Global feature contribution: Figure 3 illustrates the global behavior of features in the   \n224 AirQuality dataset, with red bars indicating the density of training samples. We extract   \n225 $\\begin{array}{r}{\\sum_{k=1}^{K}h_{b}\\left(x_{t,m}\\right)w_{m,b}^{n b m}w_{k,m}^{o u t}}\\end{array}$ from GATSM and repeat this process over the range of minimum to   \n226 maximum feature values to plot the line. We found that the behavior of $S O2,O3$ , and windspeed is   \n227 inconsistent with prior human knowledge. Typically, high levels of $S O2$ and $O3$ are associated with   \n228 poor air quality. However, GATSM learned that particulate matter concentration starts to decrease   \n229 when $S O2$ exceeds 10 and $O3$ exceeds 5. This discrepancy may be due to sparse training samples in   \n230 these regions, leading to insufficient training, or there may be interactions with other features. Another   \n231 known fact is that high windspeed decreases particulate matter concentration. This is consistent when   \n232 windspeed is below 0.7 in our observation. However, particulate matter concentration drastically   \n233 increases when windspeed exceeds 0.7, likely due to the wind causing yellow dust.   \n234 Local time-independent feature contribution: To interpret the prediction of a data sample, we   \n235 plot the local time-independent feature contributions, $\\begin{array}{r}{\\sum_{k=1}^{K}h_{b}\\left(x_{t,m}\\right)w_{m,b}^{n b m}w_{k,m}^{o u t}}\\end{array}$ , in Figure 4. The   \n236 main -axis (blue) represents feature contribution, the sub $\\mathbf{X}$ -axis (red) represents feature value, and   \n237 the y-axis represents time steps. We found that SO2, NO2, $C O$ , and $O3$ have positive correlations.   \n238 In contrast, temperature, pressure, dew point, and windspeed have negative correlations. These are   \n239 consistent with the global interpretations shown in Figure 3. Rainfall has the same values across all   \n240 time steps.   \n241 Local time-dependent feature contribution: We also visualize the local time-dependent feature con  \n242 tributions, $\\begin{array}{r}{\\sum_{k=1}^{K}a_{k,t,u}h_{b}\\left(x_{t,m}\\right)w_{m,b}^{n b m}w_{k,m}^{o u t}}\\end{array}$ . Figure 5 illustrates the interpretation of the same data   \n243 sample as in Figure 4. The time-dependent interpretation differs slightly from the time-independent   \n244 interpretation. We found that there are time lags in SO2, NO2, CO, and $O3$ , meaning previous feature   \n245 values affect current feature contributions. For example, in the case of $S O2$ , low feature values around   \n246 time step 5 lead to low feature contributions around time step 13. ", "page_idx": 6}, {"type": "image", "img_path": "gsott1UXlq/tmp/669bc66b5f40b4341ca1e949d7c16b43a548732449ff6ccb4fb492e1211cb5fe.jpg", "img_caption": ["Figure 3: Global interpretations of features in the Air Quality dataset. "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "gsott1UXlq/tmp/5167bce752c8244cf0976ea6630e0996a03c1659c9b95627f562b6a108703a0b.jpg", "img_caption": ["Figure 4: Local time-independent feature contributions. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "gsott1UXlq/tmp/a00e4f9b880f0801127bd4e72c6179cfe268be0a3c4721c38911624dbefa6607.jpg", "img_caption": ["Figure 5: Local time-dependent feature contributions. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "247 6 Future Works & Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "248 Although GATSM achieved state-of-the-art performance within the transparent model category,   \n249 it has several limitations. This section discusses these limitations and suggests future work to   \n250 address them. GAMs have relatively slower computational times and larger model sizes compared to   \n251 black-box models because they require the same number of feature functions as input features. To   \n252 address this problem, methods such as the basis strategy can be proposed to reduce the number of   \n253 feature functions, or entirely new methods for transparent models can be developed. The attention   \n254 mechanism in GATSM may be a bottleneck. Fast attention mechanisms proposed in the literature   \n255 [39, 40, 41, 42, 43], or the recently proposed Mamba [44], can help overcome this limitation. Existing   \n256 time series models, including GATSM, only handle discrete time series and have limited length   \n257 generalization ability, resulting in significantly reduced performance when very long sequences,   \n258 unseen during training, are input. Extending GATSM to continuous models using NeuralODE [45]   \n259 or HiPPO [46] could address this issue. GATSM still cannot learn higher-order feature interactions   \n260 internally and shows low performance on complex datasets. Feature interaction methods proposed   \n261 for transparent models may help address this problem [29, 15].   \nIn this papre, we proposed a novel transparent model for time series named GATSM. GATSM   \n263 consists of time-sharing NBM and the temporal module to effectively learn feature representations   \n264 and temporal patterns while maintaining transparency. The experimental results demonstrated that   \n265 GATSM has superior generalization ability and is the only transparent model with performance   \n266 comparable to Transformer. We provided various visual interpretations of GATSM, demonstrated that   \n267 GATSM capture interesting patterns in time series data. We anticipate that GATSM will be widely   \n268 adopted in various fields and demonstrate strong performance. The broader impacts of GATSM   \nacross various fields can be found in Appendix A. ", "page_idx": 8}, {"type": "text", "text": "270 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "271 [1] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"Why Should I Trust You?\": Explain  \n272 ing the Predictions of Any Classifier. In ACM SIGKDD International Conference on Knowledge   \n273 Discovery and Data Mining, 2016.   \n274 [2] Scott M. Lundberg and Su-In Lee. A Unified Approach to Interpreting Model Predictions. In   \n275 Advances in Neural Information Processing Systems, 2017.   \n276 [3] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi   \n277 Parikh, and Dhruv Batra. Grad-CAM: Visual Explanations From Deep Networks via Gradient  \n278 Based Localization. 2017.   \n279 [4] Ramaravind K. Mothilal, Amit Sharma, and Chenhao Tan. Explaining Machine Learning   \n280 Classifiers through Diverse Counterfactual Explanations. In Proceedings of the 2020 Conference   \n281 on Fairness, Accountability, and Transparency, 2020.   \n282 [5] Cynthia Rudin. Please Stop Explaining Black Box Models for High Stakes Decisions. In   \n283 Advances in Neural Information Processing Systems, Workshop on Critiquing and Correcting   \n284 Trends in Machine Learning, 2018.   \n285 [6] Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions   \n286 and use interpretable models instead. Nature Machine Intelligence, 1:206\u2013215, May 2019.   \n287 [7] Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich, Rich   \n288 Caruana, and Geoffrey E. Hinton. Neural Additive Models: Interpretable Machine Learning   \n289 with Neural Nets. In Advances in Neural Information Processing Systems, 2021.   \n290 [8] Chun-Hao Chang, Rich Caruana, and Anna Goldenberg. NODE-GAM: Neural Generalized   \n291 Additive Model for Interpretable Deep Learning. In International Conference on Learning   \n292 Representations, 2022.   \n293 [9] Filip Radenovic, Abhimanyu Dubey, and Dhruv Mahajan. Neural Basis Models for Inter  \n294 pretability. In Advances in Neural Information Processing Systems, 2022.   \n295 [10] Trevor Hastie and Robert Tibshirani. Generalized Additive Models. Statistical Science, 1(3):   \n296 297\u2013318, August 1986.   \n297 [11] Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and No\u00e9mie Elhadad. Intel  \n298 ligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission.   \n299 In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015.   \n300 [12] Chun-Hao Chang, Sarah Tan, Ben Lengerich, Anna Goldenberg, and Rich Caruana. How   \n301 Interpretable and Trustworthy are GAMs? In ACM SIGKDD International Conference on   \n302 Knowledge Discovery and Data Mining, 2021.   \n303 [13] Lev V. Utkin, Egor D. Satyukov, and Andrei V. Konstantinov. SurvNAM: The machine learning   \n304 survival model explanation. Neural Networks, 147:81\u2013102, March 2022.   \n305 [14] Sarah Tan, Rich Caruana, Giles Hooker, and Yin Lou. Distill-and-Compare: Auditing Black  \n306 Box Models Using Transparent Model Distillation. In Proceedings of the 2018 AAAI/ACM   \n307 Conference on AI, Ethics, and Society, 2018.   \n308 [15] Minkyu Kim, Hyun-Soo Choi, and Jinho Kim. Higher-order Neural Additive Models: An Inter  \n309 pretable Machine Learning Model with Feature Interactions. arXiv preprint arXiv:2209.15409,   \n310 2022.   \n311 [16] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,   \n312 \u0141ukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. In Advances in Neural   \n313 Information Processing Systems, 2017.   \n314 [17] Sebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert   \n315 M\u00fcller, and Wojciech Samek. On Pixel-Wise Explanations for Non-Linear Classifier Decisions   \n316 by Layer-Wise Relevance Propagation. PLoS ONE, 10(7), July 2015.   \n317 [18] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. Learning Important Features   \n318 Through Propagating Activation Differences. In International Conference on Machine Learning,   \n319 2017.   \n320 [19] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M. Alonso-Moral,   \n321 Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia D\u00edaz-Rodr\u00edguez, and Francisco   \n322 Herrera. Explainable Artificial Intelligence (XAI): What we know and what is left to attain   \n323 Trustworthy Artificial Intelligence. Information Fusion, 99:101805, November 2023.   \n324 [20] Vikas Hassija, Vinay Chamola, Atmesh Mahapatra, Abhinandan Singal, Divyansh Goel, Kaizhu   \n325 Huang, Simone Scardapane, Indro Spinelli, Mufti Mahmud, and Amir Hussain. Interpreting   \n326 Black-Box Models: A Review on Explainable Artificial Intelligence. Cognitive Computation,   \n327 16(1):45\u201374, January 2024.   \n328 [21] Grace Wahba. Spline Models for Observational Data. SIAM, September 1990.   \n329 [22] Yin Lou, Rich Caruana, and Johannes Gehrke. Intelligible Models for Classification and   \n330 Regression. In ACM SIGKDD International Conference on Knowledge Discovery and Data   \n331 Mining, 2012.   \n332 [23] Harsha Nori, Samuel Jenkins, Paul Koch, and Rich Caruana. InterpretML: A Unified Framework   \n333 for Machine Learning Interpretability. arXiv preprint arXiv:1909.09223, 2019.   \n334 [24] William J. E. Potts. Generalized Additive Neural Networks. In ACM SIGKDD International   \n335 Conference on Knowledge Discovery and Data Mining, 1999.   \n336 [25] Shiyun Xu, Zhiqi Bu, Pratik Chaudhari, and Ian J. Barnett. Sparse Neural Additive Model:   \n337 Interpretable Deep Learning with Feature Selection via Group Sparsity. In Joint European   \n338 Conference on Machine Learning and Knowledge Discovery in Databases, 2023.   \n339 [26] Yin Lou, Rich Caruana, Johannes Gehrke, and Giles Hooker. Accurate intelligible models with   \n340 pairwise interactions. In ACM SIGKDD International Conference on Knowledge Discovery and   \n341 Data Mining, 2013.   \n342 [27] Zebin Yang, Aijun Zhang, and Agus Sudjianto. GAMI-Net: An Explainable Neural Network   \n343 based on Generalized Additive Models with Structured Interactions. Pattern Recognition, 120:   \n344 108192, December 2021.   \n345 [28] James Enouen and Yan Liu. Sparse Interaction Additive Networks via Feature Interaction   \n346 Detection and Sparse Selection. Advances in Neural Information Processing Systems, 35, 2022.   \n347 [29] Abhimanyu Dubey, Filip Radenovic, and Dhruv Mahajan. Scalable Interpretability via Polyno  \n348 mials. Advances in Neural Information Processing Systems, 2022.   \n349 [30] Wonkeun Jo and Dongil Kim. Neural additive time-series models: Explainable deep learning   \n350 for multivariate time-series prediction. Expert Systems with Applications, 228:120307, October   \n351 2023.   \n352 [31] Petar Velic\u02c7kovic\u00b4, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua   \n353 Bengio. Graph Attention Networks. In International Conference on Learning Representations,   \n354 2018.   \n355 [32] Chang Wei Tan, Christoph Bergmeir, Francois Petitjean, and Geoffrey I. Webb. Monash Univer  \n356 sity, UEA, UCR Time Series Extrinsic Regression Archive. arXiv preprint arXiv:2006.10996,   \n357 2020.   \n358 [33] Anthony Bagnall, Hoang Anh Dau, Jason Lines, Michael Flynn, James Large, Aaron Bostrom,   \n359 Paul Southam, and Eamonn Keogh. The UEA multivariate time series classification archive,   \n360 2018. arXiv preprint arXiv:1811.00075, 2018.   \n361 [34] Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov,   \n362 Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley.   \n363 PhysioBank, PhysioToolkit, and PhysioNet. Circulation, 101(23):e215\u2013e220, June 2000.   \n364 [35] Tianqi Chen and Carlos Guestrin. XGBoost: A Scalable Tree Boosting System. In Proceedings   \n365 of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,   \n366 2016.   \n367 [36] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,   \n368 Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas   \n369 Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,   \n370 Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style,   \n371 High-Performance Deep Learning Library. In Advances in Neural Information Processing   \n372 Systems, 2019.   \n373 [37] Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna:   \n374 A Next-generation Hyperparameter Optimization Framework. In Proceedings of the 25th ACM   \n375 SIGKDD International Conference on Knowledge Discovery & Data Mining, 2019.   \n376 [38] Ilya Loshchilov and Frank Hutter. Decoupled Weight Decay Regularization. In International   \n377 Conference on Learning Representations, 2019.   \n378 [39] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran\u00e7ois Fleuret. Transformers are   \n379 RNNs: Fast Autoregressive Transformers with Linear Attention. In International Conference   \n380 on Machine Learning, 2020.   \n381 [40] Lovish Madaan, Srinadh Bhojanapalli, Himanshu Jain, and Prateek Jain. Treeformer: Dense   \n382 Gradient Trees for Efficient Attention Computation. In International Conference on Learning   \n383 Representations, 2023.   \n384 [41] Sinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-Attention   \n385 with Linear Complexity. arXiv preprint arXiv:2006.04768, 2020.   \n386 [42] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane,   \n387 Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, David Belanger,   \n388 Lucy Colwell, and Adrian Weller. Rethinking Attention with Performers. In International   \n389 Conference on Learning Representations, 2021.   \n390 [43] Nikita Kitaev, \u0141ukasz Kaiser, and Anselm Levskaya. Reformer: The Efficient Transformer. In   \n391 International Conference on Learning Representations, 2020.   \n392 [44] Albert Gu and Tri Dao. Mamba: Linear-Time Sequence Modeling with Selective State Spaces,   \n393 2023.   \n394 [45] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural Ordinary   \n395 Differential Equations. In Advances in Neural Information Processing Systems, 2018.   \n396 [46] Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher R\u00e9. HiPPO: Recurrent Memory   \n397 with Optimal Polynomial Projections. In Advances in Neural Information Processing Systems,   \n398 2020.   \n399 [47] Eric J. Pedersen, David L. Miller, Gavin L. Simpson, and Noam Ross. Hierarchical generalized   \n400 additive models in ecology: an introduction with mgcv. PeerJ, 7:e6876, May 2019.   \n401 [48] Trevor Hastie and Robert Tibshirani. Generalized additive models for medical research. Statisti  \n402 cal Methods in Medical Research, 4(3):187\u2013196, September 1995.   \n403 [49] Appliances Energy Dataset, 2020. URL https://doi.org/10.5281/zenodo.3902637.   \n404 [50] Australia Rainfall Dataset, 2020. URL https://doi.org/10.5281/zenodo.3902654.   \n405 [51] Beijing PM10 Dataset, 2020. URL https://doi.org/10.5281/zenodo.3902667.   \n406 [52] Classification of Heart Sound Recordings: The PhysioNet/Computing in Cardiology Challenge   \n407 2016, 2016. URL https://physionet.org/content/challenge-2016/1.0.0/.   \n408 [53] Predicting Mortality of ICU Patients: The PhysioNet/Computing in Cardiology Challenge 2012,   \n409 2012. URL https://physionet.org/content/challenge-2012/1.0.0/.   \n410 [54] Early Prediction of Sepsis from Clinical Data: The PhysioNet/Computing in Cardiology Chal  \n411 lenge 2019, 2019. URL https://physionet.org/content/challenge-2019/1.0.0/.   \n412 [55] PLAsTiCC Astronomical Classification, 2018. URL https://www.kaggle.com/c/   \n413 PLAsTiCC-2018.   \n414 [56] AALTD\u201916 Time Series Classification Contest, 2016. URL https://aaltd16.irisa.fr/   \n415 challenge/.   \n416 [57] Ignacio Oguiza. tsai - a state-of-the-art deep learning library for time series and sequential data.   \n417 Github, 2023. URL https://github.com/timeseriesAI/tsai.   \n418 [58] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet Classification with Deep   \n419 Convolutional Neural Networks. In Advances in Neural Information Processing Systems, 2012.   \n420 [59] Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, and Kaiming He. Aggregated Residual   \n421 Transformations for Deep Neural Networks. In Proceedings of the IEEE Conference on   \n422 Computer Vision and Pattern Recognition, 2017.   \n423 [60] James Bergstra, R\u00e9mi Bardenet, Yoshua Bengio, and Bal\u00e1zs K\u00e9gl. Algorithms for Hyper  \n424 Parameter Optimization. In Advances in Neural Information Processing Systems, 2011.   \n425 [61] Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher R\u00e9. FlashAttention: Fast   \n426 and Memory-Efficient Exact Attention with IO-Awareness. arXiv preprint arXiv:2205.14135,   \n427 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "428 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "430 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n431 paper\u2019s contributions and scope?   \n432 Answer: [Yes]   \n433 Justification: The main claims made in the abstract and introduction accurately reflect the   \n434 paper\u2019s contributions and scope.   \n435 Guidelines:   \n436 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n437 made in the paper.   \n438 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n439 contributions made in the paper and important assumptions and limitations. A No or   \n440 NA answer to this question will not be perceived well by the reviewers.   \n441 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n442 much the results can be expected to generalize to other settings.   \n443 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n444 are not attained by the paper. ", "page_idx": 12}, {"type": "text", "text": "445 2. Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "49 Guidelines:   \n50 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n51 the paper has limitations, but those are not discussed in the paper.   \n52 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n53 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n54 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n55 model well-specification, asymptotic approximations only holding locally). The authors   \n56 should reflect on how these assumptions might be violated in practice and what the   \n57 implications would be.   \n58 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n59 only tested on a few datasets or with a few runs. In general, empirical results often   \n60 depend on implicit assumptions, which should be articulated.   \n61 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n62 For example, a facial recognition algorithm may perform poorly when image resolution   \n63 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n64 used reliably to provide closed captions for online lectures because it fails to handle   \n65 technical jargon.   \n66 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n67 and how they scale with dataset size.   \n68 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n69 address problems of privacy and fairness.   \n70 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n71 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n72 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n73 judgment and recognize that individual actions in favor of transparency play an impor  \n74 tant role in developing norms that preserve the integrity of the community. Reviewers   \n75 will be specifically instructed to not penalize honesty concerning limitations.   \n3. Theory Assumptions and Proofs ", "page_idx": 12}, {"type": "text", "text": "476 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "477 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n478 a complete (and correct) proof? ", "page_idx": 12}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 12}, {"type": "text", "text": "80 Justification: Our work does not include theoretical results.   \n81 Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 13}, {"type": "text", "text": "492 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "93 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n4 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n95 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We provided experimental setup and implementation details in section 5.1 and Appendix C. ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 13}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 13}, {"type": "text", "text": "535 Answer: [Yes]   \n536 Justification: We used public datasets and opened our code.   \n537 Guidelines:   \n538 \u2022 The answer NA means that paper does not include experiments requiring code.   \n539 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n540 public/guides/CodeSubmissionPolicy) for more details.   \n541 \u2022 While we encourage the release of code and data, we understand that this might not be   \n542 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n543 including code, unless this is central to the contribution (e.g., for a new open-source   \n544 benchmark).   \n545 \u2022 The instructions should contain the exact command and environment needed to run to   \n546 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n547 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n548 \u2022 The authors should provide instructions on data access and preparation, including how   \n549 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n550 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n551 proposed method and baselines. If only a subset of experiments are reproducible, they   \n552 should state which ones are omitted from the script and why.   \n553 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n554 versions (if applicable).   \n555 \u2022 Providing as much information as possible in supplemental material (appended to the   \n556 paper) is recommended, but including URLs to data and code is permitted.   \n557 6. Experimental Setting/Details   \n558 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n559 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n560 results?   \n561 Answer: [Yes]   \n562 Justification: We described the experimental setting in section 5.1.   \n563 Guidelines:   \n564 \u2022 The answer NA means that the paper does not include experiments.   \n565 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n566 that is necessary to appreciate the results and make sense of them.   \n567 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n568 material.   \n569 7. Experiment Statistical Significance   \n570 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n571 information about the statistical significance of the experiments?   \n572 Answer: [Yes]   \n573 Justification: We provided standard deviations with experimental results.   \n574 Guidelines:   \n575 \u2022 The answer NA means that the paper does not include experiments.   \n576 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n577 dence intervals, or statistical significance tests, at least for the experiments that support   \n578 the main claims of the paper.   \n579 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n580 example, train/test split, initialization, random drawing of some parameter, or overall   \n581 run with given experimental conditions).   \n582 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n583 call to a library function, bootstrap, etc.)   \n584 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n585 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n586 of the mean.   \n587 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n588 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n589 of Normality of errors is not verified.   \n590 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n591 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n592 error rates).   \n593 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n594 they were calculated and reference the corresponding figures or tables in the text.   \n595 8. Experiments Compute Resources   \n596 Question: For each experiment, does the paper provide sufficient information on the com  \n597 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n598 the experiments?   \n599 Answer: [Yes]   \n600 Justification: We provided information on the computational resource used in the experi  \n601 ments.   \n602 Guidelines:   \n603 \u2022 The answer NA means that the paper does not include experiments.   \n604 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n605 or cloud provider, including relevant memory and storage.   \n606 \u2022 The paper should provide the amount of compute required for each of the individual   \n607 experimental runs as well as estimate the total compute.   \n608 \u2022 The paper should disclose whether the full research project required more compute   \n609 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n610 didn\u2019t make it into the paper).   \n611 9. Code Of Ethics   \n612 Question: Does the research conducted in the paper conform, in every respect, with the   \n613 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n614 Answer: [Yes]   \n615 Justification: Our work conform with the NeurIPS Code of Ethics.   \n616 Guidelines:   \n617 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n618 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n619 deviation from the Code of Ethics.   \n620 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n621 eration due to laws or regulations in their jurisdiction).   \n622 10. Broader Impacts   \n623 Question: Does the paper discuss both potential positive societal impacts and negative   \n624 societal impacts of the work performed?   \n625 Answer: [Yes]   \n626 Justification: We discussed the potential impacts of GATSM in Appendix A.   \n627 Guidelines:   \n628 \u2022 The answer NA means that there is no societal impact of the work performed.   \n629 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n630 impact or why the paper does not address societal impact.   \n631 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n632 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n633 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n634 groups), privacy considerations, and security considerations.   \n635 \u2022 The conference expects that many papers will be foundational research and not tied   \n636 to particular applications, let alone deployments. However, if there is a direct path to   \n637 any negative applications, the authors should point it out. For example, it is legitimate   \n638 to point out that an improvement in the quality of generative models could be used to   \n639 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n640 that a generic algorithm for optimizing neural networks could enable people to train   \n641 models that generate Deepfakes faster.   \n642 \u2022 The authors should consider possible harms that could arise when the technology is   \n643 being used as intended and functioning correctly, harms that could arise when the   \n644 technology is being used as intended but gives incorrect results, and harms following   \n645 from (intentional or unintentional) misuse of the technology.   \n646 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n647 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n648 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n649 feedback over time, improving the efficiency and accessibility of ML).   \n650 11. Safeguards   \n651 Question: Does the paper describe safeguards that have been put in place for responsible   \n652 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n653 image generators, or scraped datasets)?   \n654 Answer: [NA]   \n655 Justification: Our work poses no such risks.   \n656 Guidelines:   \n657 \u2022 The answer NA means that the paper poses no such risks.   \n658 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n659 necessary safeguards to allow for controlled use of the model, for example by requiring   \n660 that users adhere to usage guidelines or restrictions to access the model or implementing   \n661 safety filters.   \n662 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n663 should describe how they avoided releasing unsafe images.   \n664 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n665 not require this, but we encourage authors to take this into account and make a best   \n666 faith effort.   \n667 12. Licenses for existing assets   \n668 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n669 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n670 properly respected?   \n671 Answer: [Yes]   \n672 Justification: We properly cited the used codes and data.   \n673 Guidelines:   \n674 \u2022 The answer NA means that the paper does not use existing assets.   \n675 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n676 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n677 URL.   \n678 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n679 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n680 service of that source should be provided.   \n681 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n682 package should be provided. For popular datasets, paperswithcode.com/datasets   \n683 has curated licenses for some datasets. Their licensing guide can help determine the   \n684 license of a dataset.   \n685 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n686 the derived asset (if it has changed) should be provided.   \n687 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n688 the asset\u2019s creators.   \n689 13. New Assets   \n690 Question: Are new assets introduced in the paper well documented and is the documentation   \n691 provided alongside the assets?   \n692 Answer: [Yes]   \n693 Justification: We opened the source code of GATSM, and the document to run the code is   \n694 provided along with the code.   \n695 Guidelines:   \n696 \u2022 The answer NA means that the paper does not release new assets.   \n697 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n698 submissions via structured templates. This includes details about training, license,   \n699 limitations, etc.   \n700 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n701 asset is used.   \n702 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n703 create an anonymized URL or include an anonymized zip file.   \n704 14. Crowdsourcing and Research with Human Subjects   \n705 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n706 include the full text of instructions given to participants and screenshots, if applicable, as   \n707 well as details about compensation (if any)?   \n708 Answer: [NA]   \n709 Justification: Our work does not involve crowdsourcing nor research with human subjects.   \n710 Guidelines:   \n711 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n712 human subjects.   \n713 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n714 tion of the paper involves human subjects, then as much detail as possible should be   \n715 included in the main paper.   \n716 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n717 or other labor should be paid at least the minimum wage in the country of the data   \n718 collector.   \n719 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n720 Subjects   \n721 Question: Does the paper describe potential risks incurred by study participants, whether   \n722 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n723 approvals (or an equivalent approval/review based on the requirements of your country or   \n724 institution) were obtained?   \n725 Answer: [NA]   \n726 Justification: Our work does not involve crowdsourcing nor research with human subjects.   \n727 Guidelines:   \n728 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n729 human subjects.   \n730 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n731 may be required for any human subjects research. If you obtained IRB approval, you   \n732 should clearly state this in the paper.   \n733 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n734 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n735 guidelines for their institution.   \n736 \u2022 For initial submissions, do not include any information that would break anonymity (if   \n737 applicable), such as the institution conducting the review. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "738 A Broader impact ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "739 We discuss the expected impacts of GATSM across various fields. ", "page_idx": 18}, {"type": "text", "text": "740 \u2022 Time series adaptation: GATSM extends existing GAMs to time series, enabling tasks that   \n741 traditional GAMs could not perform in this context - e.g., better performance on time series and   \n742 finding temporal patterns.   \n743 \u2022 Improved decision-making system: GATSM can show users their exact decision-making process,   \n744 providing trust and confidence in its predictions to users. This enables decision-makers to make   \n745 more informed choices, crucial in high-stakes domains such as healthcare.   \n746 \u2022 Ethical AI: GATSM can examine that their outcomes are biased or discriminatory by displaying   \n747 the shape of feature functions. This is particularly important in ethically sensitive domains, such as   \n748 recidivism prediction.   \n749 \u2022 Scientific discovery: Transparent models have already been used in various research fields for   \n750 scientific discovery [47, 48]. GATSM also can be applied to these domains to obtain novel scientific   \n751 insights.   \n752 Despite these advantages, it is important to remember that the interpretations of transparent models   \n753 do not necessarily reflect exact causal relationships. While transparent models provide clear and   \n754 faithful interpretations, they are still not capable of identifying causal relationships. Causal discovery   \n755 is a complex task that requires further research. ", "page_idx": 18}, {"type": "text", "text": "756 B Dataset details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "757 We use eight publicly available datasets for our experiments. Three datasets - Energy, Rainfall, and   \n758 AirQuality - can be downloaded from the Monash repository [32]. Another three datasets - Heartbeat,   \n759 LSST, and NATOPS - are available from the UCR repository [33]. The remaining two datasets can   \n760 be downloaded from the PhysioNet [34]. Details of the datasets are provided below:   \n761 \u2022 Energy [49]: This dataset consists of 24 features related to temperature and humidity from sensors   \n762 and weather conditions. These features are measured every 10 minutes. The goal of this dataset is   \n763 to predict total energy usage.   \n764 \u2022 Rainfall [50]: This dataset consists of temperatures measured hourly. The goal of this dataset is to   \n765 predict total daily rainfall in Australia.   \n766 \u2022 AirQuality [51]: This dataset consists of features related to air pollutants and meteorological data.   \n767 The goal of this dataset is to predict the PM10 level in Beijing.   \n768 \u2022 Heartbeat [52]: This dataset consists of heart sounds collected from various locations on the body.   \n769 Each sound was truncated to five seconds, and a spectrogram of each instance was created with a   \n770 window size of 0.061 seconds with a $70\\%$ overlap. The goal of this dataset is to classify the sounds   \n771 as either normal or abnormal.   \n772 \u2022 Mortality [53] This dataset consists of records of adult patients admitted to the ICU. The input   \n773 features include the patient demographics, vital signs, and lab results. The goal of this dataset is to   \n774 predict the in-hospital death of patients.   \n775 \u2022 Sepsis [54]: This dataset consists of records of ICU patients. The input features include patient   \n776 demographics, vital signs, and lab results. The goal of this dataset is to predict sepsis six hours in   \n777 advance at every time step.   \n778 \u2022 LSST [55]: This challenge dataset aims to classify astronomical time series. These time series   \n779 consist of six different light curves, simulated based on the data expected from the Large Synoptic   \n780 Survey Telescope (LSST).   \n781 \u2022 NATOPS [56]: This dataset aims to classify the Naval Air Training and Operating Procedures   \n782 Standardization (NATOPS) motions used to control aircraft movements. It consists of 24 features   \n783 representing the x, y, and z coordinates for each of the eight sensor locations attached to the body.   \n784 We used get_UCR_data() and get_Monash_regression_data() functions in the tsai library ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "785 [57] to load the UCR and Monash datasets. ", "page_idx": 18}, {"type": "table", "img_path": "gsott1UXlq/tmp/a5c30e345c7735fbd125a563de549265d153031a6aeb81aa0d9f0049adc4aa93.jpg", "table_caption": ["Table 6: Optimal hyper-parameters for GATSM. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "786 C Implementation details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "787 We use 13 models, including GATSM, for our experiments. We implement XGBoost and EBM   \n788 using the xgboost [35] and interpretml [23] libraries, respectively. For NodeGAM, we employ   \n789 the official implementation provided by its authors [8]. The remaining models are developed using   \n790 PyTorch [36]. In addition, we implement the feature functions in NAM and NBM using grouped   \n791 convolutions [58, 59] to enhance their efficiency. XGBoost and EBM are trained on two AMD EPYC   \n792 7513 CPUs, while the other models are trained on an NVIDIA A100 GPU with 80GB VRAM. All   \n793 models undergo hyperparameter tuning via Optuna [37] with the Tree-structured Parzen Estimator   \n794 (TPE) algorithm [60] in 100 trials. The hyperparameter search space and the optimal hyperparameters   \n795 for the models are provided below:   \n796 \u2022 XGBoost: We tune the n_estimators in the integer interval [1, 1000], max_depth in the integer   \n797 interval [0, 2000], learning rate in the continuous interval [1e-6, 1], subsample in the continuous   \n798 interval [0, 1], and colsample_bytree in the continuous interval [0, 1].   \n799 \u2022 MLP, NAM, NBM and NATM: We tune the batchnorm in the descret set {False, True}, dropout   \n800 in the continuous interval [0, 0.9], learning_rate in the continuous interval [1e-3, 1e-2], and   \n801 weight_decay in the continuous interval [1e-6, 1e-1] on a log scale.   \n802 \u2022 RNN, GRU and LSTM: We tune the hidden_size in the integer interval [8, 128], dropout   \n803 in the continuous interval [0, 0.9], learning_rate in the continuous interval [1e-3, 1e-2], and   \n804 weight_decay in the continuous interval [1e-6, 1e-1] on a log scale.   \n805 \u2022 Transformer: We tune the n_layers in the integer interval [1, 4], emb_size in the integer   \n806 interval [8, 32], hidden_size in the integer interval [8, 128], n_heads in the integer interval [1,   \n807 8], dropout in the continuous interval [0, 0.9], learning_rate in the continuous interval [1e-3,   \n808 1e-2], and weight_decay in the continuous interval [1e-6, 1e-1] on a log scale.   \n809 \u2022 Linear: We tune the learning_rate in the continuous interval [1e-3, 1e-2], and weight_decay   \n810 in the continuous interval [1e-6, 1e-1] on a log scale.   \n811 \u2022 EBM: We tune max_bins in the integer interval [8, 512], min_samples_leaf and max_leaves   \n812 in the integer interval [1, 50], inner_bags and outer_bags in the integer interval [1, 128],   \n813 learning_rate in the continuous interval [1e-6, 100] on a log scale, and max_rounds in the   \n814 integer interval [1000, 10000].   \n815 \u2022 NodeGAM: We tune n_trees in the integer interval [1, 256], n_layers and depth in the integer   \n816 intervals [1, 4], dropout in the continuous interval [0, 0.9], learning_rate in the continuous   \n817 interval [1e-3, 1e-2], and weight_decay in the continuous interval [1e-6, 1e-1] on a log scale.   \n818 \u2022 GATSM: We tune nbm_batchnorm in the descret set {False, True}, nbm_dropout in the con  \n819 tinuous interval [0, 0.9], attn_emb_size in the integer interval [8, 128], attn_n_heads in the   \n820 integer interval [1, 8], attn_dropout in the continuous interval [0, 0.9], learning_rate in the   \n821 continuous interval [1e-3, 1e-2], and weight_decay in the continuous interval [1e-6, 1e-1] on a   \n822 log scale. The optimal hyper-parameters for GATSM across all experimental datasets are provided   \n823 in Table 6. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "824 D Additional experiments ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "825 D.1 Inference speed ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "826 The inference speed of machine learning models is a crucial metric for real-world systems. We   \n827 evaluate the throughput of various models. The results are presented in Table 7. Since the datasets   \n828 have fewer features than the number of basis functions in NBM, NAM achieves higher throughput   \n829 than NBM. Transparent tabular models typically exhibit fast speeds. However, their throughput   \n830 significantly decreases in datasets with many features, such as Heartbeat, Mortality, and Sepsis,   \n831 because they require the same number of feature functions as the number of input features. Trans  \n832 former shows higher throughput than the transparent time series models because it does not require   \n833 feature functions, which are the main bottleneck of transparent models. Additionally, the PyTorch   \n834 implementation of Transformer uses the flash attention mechanism [61] to enhance its efficiency.   \n835 NATM has slightly higher throughput than GATSM, as it does not require the attention mechanism   \n836 and has fewer feature functions compared to the number of basis functions in GATSM. ", "page_idx": 20}, {"type": "table", "img_path": "gsott1UXlq/tmp/f81557fd55c35bc2f51726f6747743e437819b064158e073f6a9473eea23609b.jpg", "table_caption": ["Table 7: Inference throughput of different models. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "837 D.2 Number of basis functions ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "838 We evaluate GATSM by varying the number of basis functions in the time-sharing NBM. The results   \n839 for forecasting, binary classification, and multi-class classification datasets are presented in Figure 6.   \n840 For the Sepsis dataset, using 200 and 300 basis functions causes the out-of-memory error. For the   \n841 Energy and Heartbeat datasets, performance improves up to 100 basis functions but shows no further   \n842 benefit when the number of bases exceeds 100. In other datasets, performance changes are not   \n843 significant with different numbers of basis functions. In addition, there is a trade-off between the   \n844 number of basis functions and computational speed. Therefore, we recommend generally setting the   \n845 number of basis functions to 100. Note that the performance of GATSM with this hyper-parameter   \n846 depends on the dataset size and complexity. Hence, a larger number of basis functions may benefit   \n847 more complex datasets. ", "page_idx": 20}, {"type": "image", "img_path": "gsott1UXlq/tmp/1d710baa7dd1f2162a8a55af9f1f814a13e4dca053b5356d37e646e35489dac7.jpg", "img_caption": ["Figure 6: Performances of GATSM on the different number of basis functions. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "848 E Additional visualizations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "849 In addition to the interpretations on the AirQuality dataset in section 5.4, we present another interesting   \n850 interpretations of GATSM on the Rainfall dataset.   \n851 Time-step importance: Figure 7 illustrates the average importance of all time steps at the final time   \n852 step. The importance exhibit a cyclical pattern of rising and falling at regular intervals, indicating   \n853 that GATSM effectively captures seasonal patterns in the Rainfall dataset.   \n854 Global feature contribution: Figure 8 illustrates the global behavior of features in the Rainfall   \n855 dataset, with red bars indicating the density of training samples. Our findings indicate that low Max   \n856 Temperature and high Min Temperature contribute to an increase in rainfall.   \n857 Local time-independent feature contribution: Figure 9 shows the local time-independent feature   \n858 contributions. Consistent with the global interpretation, Avg. Temperature and Min Temperature have   \n859 positive correlations with rainfall, while Max Temperature has a negative correlation with rainfall.   \n860 Local time-dependent feature contribution: Figure 10 shows the local time-dependent feature   \n861 contributions. All features exhibit patterns similar to the local time-independent contributions.   \n862 However, we found that Avg. Temperature and Min Temperature have time lags between feature   \n863 values and contributions. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "image", "img_path": "gsott1UXlq/tmp/c87697f0cbdb43d8e8b069a9b2020b09d073367278941191b5ef7f4dc894b062.jpg", "img_caption": ["Figure 7: Average attention scores of time steps on the Rainfall dataset. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "gsott1UXlq/tmp/92044304c1fd74d8f9f289a6e8594d380f4d43b00269f89c6ced657ec1c92942.jpg", "img_caption": ["Figure 8: Global interpretations of features in the Rainfall dataset. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "gsott1UXlq/tmp/12e193203d0de64a9e49d39f8833289ae4263b1fb40facbadfe8881a26bdc962.jpg", "img_caption": ["Figure 9: Local time-independent contributions of features in the Rainfall dataset. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "gsott1UXlq/tmp/4eb088d7df6b1a8088c0da101325d46b3676034937a706cc7ca3746df0f035aa.jpg", "img_caption": ["Figure 10: Local time-dependent contributions of features in the Rainfall dataset. "], "img_footnote": [], "page_idx": 22}]