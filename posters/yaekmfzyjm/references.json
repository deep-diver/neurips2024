{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), a foundational model for many modern diffusion models used in image generation, making it highly relevant to the current work."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces Stable Diffusion, a prominent example of diffusion models, which is used extensively in the current work's experiments for validating the proposed approach."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial component of modern text-to-image diffusion models, forming the basis of the image generation process investigated in this study."}, {"fullname_first_author": "Yuxin Wen", "paper_title": "Detecting, Explaining, and Mitigating Memorization in Diffusion Models", "publication_date": "2024-01-01", "reason": "This paper directly addresses memorization in diffusion models, providing crucial background and context for the current work, which aims to enhance these mitigation strategies."}, {"fullname_first_author": "Nicolas Carlini", "paper_title": "Extracting training data from diffusion models", "publication_date": "2023-01-01", "reason": "This paper is highly relevant because it directly investigates the issue of training data leakage in diffusion models, which directly motivates the problem addressed by the current study."}]}