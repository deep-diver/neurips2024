[{"figure_path": "4jegYnUMHb/figures/figures_3_1.jpg", "caption": "Figure 1: The proposed MetaUAS consists of an encoder, a feature alignment module (FAM), and a decoder. It is trained on a synthesized dataset in a one-prompt meta-learning manner for change segmentation tasks. Once trained, it can segment any anomalies providing only one normal image prompt.", "description": "The figure illustrates the architecture of MetaUAS, a model for universal anomaly segmentation.  It uses a one-prompt meta-learning approach, meaning it only requires one normal image as a prompt to segment anomalies in a new image.  The model consists of three main components: an encoder (which extracts features from the input images), a feature alignment module (FAM) (which aligns features from the prompt and query images to handle geometric variations), and a decoder (which generates the anomaly segmentation map).  The model is trained on a synthetic dataset of image pairs with changes, simulating the appearance and disappearance of anomalies, before being applied to real-world anomaly segmentation tasks.", "section": "3 Method"}, {"figure_path": "4jegYnUMHb/figures/figures_5_1.jpg", "caption": "Figure 1: The proposed MetaUAS consists of an encoder, a feature alignment module (FAM), and a decoder. It is trained on a synthesized dataset in a one-prompt meta-learning manner for change segmentation tasks. Once trained, it can segment any anomalies providing only one normal image prompt.", "description": "This figure shows the architecture of the proposed MetaUAS model.  The model takes a query image and a normal image prompt as input. The encoder extracts multi-scale features from both images. The FAM aligns the features of the query and prompt images to handle geometric variations.  The decoder combines the aligned features to predict a change heatmap, which is then used to segment anomalies. The model is trained on a synthetic dataset using one-prompt meta-learning and can generalize to unseen anomalies.", "section": "3 Method"}, {"figure_path": "4jegYnUMHb/figures/figures_6_1.jpg", "caption": "Figure 3: Qualitative comparisons with state-of-the-art methods on MVTec, VisA and Goods. In both two sub-figures (left and right), (b) and (g) represent query images and their anomaly masks, while (a) represent the corresponding normal image prompts. The predicted anomaly maps are shown using different methods, including (c) WinCLIP+ [26], (d) AnomalyCLIP [76], (e) UniAD [70] and (f) our MetaUAS. Best viewed in color and zoom-in.", "description": "This figure shows a qualitative comparison of anomaly segmentation results between MetaUAS and other state-of-the-art methods on three different datasets (MVTec, VisA, Goods). For each dataset, several examples are presented, with (a) showing the normal image prompt used, (b) showing the query image, (g) the corresponding ground truth mask, and (c-f) showing the anomaly segmentation results from four other methods including WinCLIP+, AnomalyCLIP, UniAD and MetaUAS.  The goal is to visually demonstrate the effectiveness of MetaUAS compared to existing approaches.", "section": "4 Experiment"}, {"figure_path": "4jegYnUMHb/figures/figures_8_1.jpg", "caption": "Figure 4: Anomaly segmentation for query images with different normal image prompts including 5 random prompts and the optimal prompt (denoting as prompt*). The anomaly segmentation maps are generated with MetaUAS, MetaUAS and MetaUAS*+.", "description": "This figure shows the anomaly segmentation results of MetaUAS, MetaUAS*, and MetaUAS++ on three different types of anomalies from the MVTEC dataset.  For each anomaly type, a query image is shown along with segmentation results from the three methods using 5 different randomly selected normal image prompts, and the best performing prompt identified as 'prompt*'. The ground truth anomaly mask is also provided. The figure demonstrates the robustness and effectiveness of the proposed MetaUAS in handling variations in prompt selection and generating accurate anomaly maps. ", "section": "4.3 Ablation Study"}, {"figure_path": "4jegYnUMHb/figures/figures_14_1.jpg", "caption": "Figure 3: Qualitative comparisons with state-of-the-art methods on MVTec, VisA and Goods. In both two sub-figures (left and right), (b) and (g) represent query images and their anomaly masks, while (a) represent the corresponding normal image prompts. The predicted anomaly maps are shown using different methods, including (c) WinCLIP+ [26], (d) AnomalyCLIP [76], (e) UniAD [70] and (f) our MetaUAS. Best viewed in color and zoom-in.", "description": "This figure shows a qualitative comparison of anomaly segmentation results between MetaUAS and other state-of-the-art methods on three datasets (MVTec, VisA, and Goods). For each dataset and method, several examples of query images, ground truth anomaly masks, and predicted anomaly maps are displayed, allowing for visual comparison of performance.  The results show MetaUAS producing more accurate segmentations with fewer false positives compared to competing models.", "section": "4 Experiment"}]