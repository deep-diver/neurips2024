[{"figure_path": "4php6bGL2W/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the performance of the proposed DDM method against various state-of-the-art single-modality and multi-modal reinforcement learning methods on the CARLA driving simulation benchmark.  It evaluates performance across four challenging driving scenarios: Normal, Midnight, Dazzling, and Rainy. The results show episode return (ER) and driving distance (D(m)), with the best performance in each condition shown in bold.  The table helps illustrate the improved performance of the proposed method over existing techniques.", "section": "4.2 Comparison with State-of-the-art"}, {"figure_path": "4php6bGL2W/tables/tables_6_1.jpg", "caption": "Table 2: Comparing with state-of-the-art methods on DMControl. The best results are bolded.", "description": "This table presents a comparison of the proposed DDM method against several state-of-the-art methods on the DeepMind Control Suite benchmark.  It shows the average performance across six different control tasks (three easy and three hard) for each method, including SAC, DrQ, DeepMDP, SPR, TransFuser, EFNet, MuMMI, MAIE, HAVE, and the authors' DDM method. The results are reported as mean \u00b1 standard deviation, with the best performance for each task bolded.  The table demonstrates the superior performance of the DDM method across all tasks, especially on more challenging tasks.", "section": "4.2 Comparison with State-of-the-art"}, {"figure_path": "4php6bGL2W/tables/tables_14_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the performance of the proposed Dissected Dynamics Modeling (DDM) method against several state-of-the-art single-modality and multi-modality reinforcement learning methods on the CARLA autonomous driving benchmark.  The comparison is done under four different driving conditions (Normal, Midnight, Dazzling, Rainy).  The results are presented as the average episode return (ER) and the average driving distance (D(m)) in meters.  The best performance in each condition is highlighted in bold.", "section": "4.2 Comparison with State-of-the-art"}, {"figure_path": "4php6bGL2W/tables/tables_14_2.jpg", "caption": "Table A2: Results on CARLA benchmark with different perspectives RGB+Lidar-BEV.", "description": "This table presents a comparison of the performance of different methods on the CARLA benchmark using two modalities: RGB frames and LiDAR BEV images.  The results demonstrate the effectiveness of the proposed method (Ours-DDM) in achieving higher episode return (ER) and driving distance (D(m)) across various driving conditions compared to other state-of-the-art methods. The experiment demonstrates improved results over using single-modality or multi-modality approaches that do not explicitly model environmental dynamics.", "section": "A Additional Experimental Results"}, {"figure_path": "4php6bGL2W/tables/tables_14_3.jpg", "caption": "Table 2: Comparing with state-of-the-art methods on DMControl. The best results are bolded.", "description": "This table presents a comparison of the proposed Dissected Dynamics Modeling (DDM) method with several state-of-the-art methods on the DeepMind Control (DMControl) suite.  The comparison is performed across six robotic control tasks, divided into two groups based on difficulty level (easy and hard).  For each task, the table shows the average performance of each method in terms of episode reward, broken down by modality and task type.  The best performing method for each task and modality is highlighted in bold.", "section": "4.2 Comparison with State-of-the-art"}, {"figure_path": "4php6bGL2W/tables/tables_15_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the performance of the proposed DDM method against several state-of-the-art single-modality and multi-modal reinforcement learning methods on the CARLA autonomous driving benchmark.  It evaluates performance across four challenging driving scenarios (Normal, Midnight, Dazzling, Rainy) using two metrics: episode return (ER) and driving distance (D(m)).  The table distinguishes between single-modality reinforcement learning (S-RL), multi-modal computer vision (M-CV), and multi-modal reinforcement learning (M-RL) methods.  The best results for each metric and scenario are highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "4php6bGL2W/tables/tables_17_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the proposed Dissected Dynamics Modeling (DDM) method against various state-of-the-art methods on the CARLA autonomous driving benchmark.  The comparison includes single-modality reinforcement learning (S-RL) methods, multi-modal computer vision (M-CV) methods, and multi-modal reinforcement learning (M-RL) methods.  The performance is evaluated under four different weather conditions (Normal, Midnight, Dazzling, Rainy). The metrics used are episode return (ER) and driving distance (D(m)). The best performance for each metric and condition is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "4php6bGL2W/tables/tables_17_2.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the performance of the proposed DDM method against several state-of-the-art single-modality and multi-modal reinforcement learning methods on the CARLA benchmark for autonomous driving.  The comparison is made across four different driving scenarios (Normal, Midnight, Dazzling, Rainy) and evaluates two key metrics: episode return (ER) and driving distance (D(m)). The table categorizes methods by type (single-modality RL, multi-modal computer vision, and multi-modal RL) and highlights the best performance for each scenario and metric in bold.", "section": "4 Experiments"}, {"figure_path": "4php6bGL2W/tables/tables_18_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the proposed Dissected Dynamics Modeling (DDM) method with several state-of-the-art methods on the CARLA autonomous driving benchmark.  The comparison includes single-modality reinforcement learning (RL) methods, multi-modal computer vision methods, and multi-modal RL methods.  The performance metrics are episode return (ER) and driving distance (D(m)), evaluated under various driving conditions (Normal, Midnight, Dazzling, Rainy) to assess robustness. The best results for each metric and condition are highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "4php6bGL2W/tables/tables_18_2.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on CARLA benchmark. S-RL denotes single-modality RL methods, M-CV denotes multi-modal methods for conventional computer vision tasks, and M-RL denotes multi-modal RL methods. ER represents the episode return, and D(m) is the driving distance in meters. The best results are bolded.", "description": "This table compares the performance of the proposed Dissected Dynamics Modeling (DDM) method against several state-of-the-art single-modality and multi-modal reinforcement learning methods on the CARLA driving simulation benchmark.  The comparison is made across four challenging driving scenarios: Normal, Midnight, Dazzling, and Rainy.  The metrics used for comparison are episode return (ER) and driving distance (D(m)).  The best performance for each metric and scenario is highlighted in bold.", "section": "4.2 Comparison with State-of-the-art"}]