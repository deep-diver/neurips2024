[{"type": "text", "text": "Uniform Last-Iterate Guarantee for Bandits and Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Junyan Liu University of Washington junyanl1@cs.washington.edu ", "page_idx": 0}, {"type": "text", "text": "Yunfan Li University of California, Los Angeles yunfanli@g.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Ruosong Wang\u2217 CFCS and School of Computer Science Peking University ruosongwang@pku.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Lin F. Yang\u2217 University of California, Los Angeles linyang@ee.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Existing metrics for reinforcement learning (RL) such as regret, PAC bounds, or uniform-PAC [Dann et al., 2017], typically evaluate the cumulative performance, while allowing the agent to play an arbitrarily bad policy at any finite time $t$ . Such a behavior can be highly detrimental in high-stakes applications. This paper introduces a stronger metric, uniform last-iterate (ULI) guarantee, capturing both cumulative and instantaneous performance of RL algorithms. Specifically, ULI characterizes the instantaneous performance by ensuring that the per-round suboptimality of the played policy is bounded by a function, monotonically decreasing w.r.t. round $t$ , preventing revisiting bad policies when sufficient samples are available. We demonstrate that a near-optimal ULI guarantee directly implies near-optimal cumulative performance across aforementioned metrics, but not the other way around. To examine the achievability of ULI, we first provide two positive results for bandit problems with finite arms, showing that elimination-based algorithms and high-probability adversarial algorithms with stronger analysis or additional designs, can attain near-optimal ULI guarantees. We also provide a negative result, indicating that optimistic algorithms cannot achieve near-optimal ULI guarantee. Furthermore, we propose an efficient algorithm for linear bandits with infinitely many arms, which achieves the ULI guarantee, given access to an optimization oracle. Finally, we propose an algorithm that achieves near-optimal ULI guarantee for the online reinforcement learning setting. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In online decision-making problems with bandit feedback, a learner sequentially interacts with an unknown environment: in each round, the learner plays an policy and then observes the corresponding rewards of the played policy. Typically, the goal of the learner is to achieve good cumulative performance, commonly measured by regret or probably approximately correct (PAC) bound. For instance, in the online advertisement scenario, the goal of the website (learner) could be maximizing the cumulative click numbers [Li et al., 2010]. Hence, the website aims to minimize the regret that measures the cumulative clicks of the recommended advertisement compared to that of the unknown optimal advertisement. In addition to regret minimization, the goal could also be quickly identifying popular advertisements [Chen et al., 2014, Jin et al., 2019]. To this end, a PAC bound is suitable here to measure the sample complexity (i.e., cumulative time steps) that the algorithm needs to identify those popular advertisements. To reap the benefits of both measures, Dann et al. [2017] propose a new performance measure called uniform-PAC, ensuring that for all $\\epsilon>0$ , the total number of $\\epsilon$ -suboptimal policies played by the algorithm is bounded by a function polynomial in $1/\\epsilon$ . The uniform-PAC bound can simultaneously imply a high-probability sublinear regret bound and a polynomial sample complexity for any desired accuracy. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Although uniform-PAC provides a powerful framework to unify regret2 and PAC bound, it still fails to capture the instantaneous performance of the learning algorithm. In particular, a uniform-PAC algorithm could play a bad policy in some late but finite round $t$ , even if it enjoys a good cumulative performance. This drawback impedes the application of uniform-PAC algorithms into high-stakes fields. Clinical trials, for example, place high demands on instantaneous performance for every treatment test, since patients need to be assigned with increasingly better treatments when more experimental data are available [Villar et al., 2015]. Hence, two natural questions arise: ", "page_idx": 1}, {"type": "text", "text": ". Can we find a new metric that characterizes not only the cumulative performance but also the instantaneous performance? ", "page_idx": 1}, {"type": "text", "text": "2. If such a metric exists, is it optimally achievable by some algorithm? ", "page_idx": 1}, {"type": "text", "text": "In this paper, we answer both questions affirmatively. Our main contributions are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We introduce a new metric called uniform last-iterate (ULI), which simultaneously characterizes cumulative and instantaneous performance of sequential decision-making algorithms. On one hand, ULI can characterize the instantaneous performance: the per-round suboptimality of any algorithm with ULI guarantee is upper bounded by a function, monotonically decreasing for late time $t$ . On the other hand, we show that any algorithm with a (near-optimal) ULI guarantee is also (near-optimally) uniform-PAC, demonstrating that ULI can imply cumulative performance.   \n\u2022 To answer the question whether ULI is achievable, we examine three common types of bandit algorithms in the finite arm setting. First, we provide a stronger analysis to show that many existing elimination-based algorithms indeed enjoy a near-optimal ULI guarantee. Then, we propose a metaalgorithm that enables any high-probability adversarial bandit algorithms, with a mild condition, to achieve a near-optimal ULI guarantee, and we show that such condition naturally holds for many adversarial bandit algorithms. Finally, we provide a hardness result showing that optimistic algorithms (e.g., lil\u2019UCB [Jamieson et al., 2014]) cannot achieve near-optimal ULI guarantee. As lil\u2019UCB is near-optimally uniform-PAC, our hardness result also implies that ULI is strictly stronger than uniform-PAC.   \n\u2022 For linear bandits with infinitely-many arms, we propose an oracle-efficient3 linear bandit algorithm with the ULI guarantee (with access to an optimization oracle). In particular, we propose an adaptive barycentric spanner technique, selecting finitely many base arms that can linearly represent all (possibly infinitely many) well-behaved arms. This technique generalizes the one in [Awerbuch and Kleinberg, 2008] for elimination-based algorithms by adaptively identifying spaces that active arms span. Leveraging the phased elimination algorithm [Lattimore et al., 2020], our algorithm can conduct the elimination over all arms by only playing a finite subset of arms and querying a linearly-constrained optimization oracle for only a polynomial number of times.   \n\u2022 Finally, we propose a new algorithm for tabular episodic Markov decision processes (MDPs), which achieves a near-optimal ULI guarantee. In particular, our algorithm adapts uncertaintydriven reward functions to encourage exploration of the transition model, which ensures accurate estimations of value functions across all policies. The final ULI guarantee is achieved by conducting policy elimination. ", "page_idx": 1}, {"type": "text", "text": "Related work. In online decision-making problems, regret and PAC bounds are widely adopted to evaluate the cumulative performance of algorithms. More concretely, one line of research [Auer et al., 2002a,b, Abbasi-Yadkori et al., 2011, Li et al., 2010, Jin et al., 2018] aims to minimize the regret which measures the difference between the cumulative rewards of the selected policies and that of the best policy in hindsight. The PAC guarantees are more common than the regret when studying the pure-exploration/best policy identification problems [Even-Dar et al., 2006, Kalyanakrishnan et al., 2012, Wagenmaker et al., 2022]. One of the popular PAC measures is $(\\delta,\\epsilon)$ -PAC which suggests that with probability at least $1-\\delta$ , the algorithm can output a near-optimal policy at most $\\epsilon$ away from the optimal one by using a sample complexity polynomial in $1/\\epsilon$ . Later, Dann et al. [2017] introduce a new framework called uniform-PAC to unify both metrics and develop a uniform-PAC algorithm for episodic Markov decision processes (MDPs). Subsequent works design uniform-PAC algorithms for MDPs with linear function approximation [He et al., 2021] and bounded Eluder dimension [Wu et al., 2023]. Though uniform-PAC strengthens regret and $(\\delta,\\epsilon)$ -PAC bound, it still fails to characterize the instantaneous performance of online algorithms, i.e., a uniform-PAC algorithm, even with a good cumulative performance, can play bad policies for some late rounds. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "A seemingly related performance measure is last-iterate convergence (LIC) which has been studied for optimizing MDPs [Moskovitz et al., 2023, Ding et al., 2023] and they use the primal-dual approach to formulate the problem of identifying an optimal policy in the constrained MDPs from a gametheoretic perspective. These works often require additional knowledge of the value functions and the LIC does not characterize the unknown dynamics of the environment. However, in our problem, the dynamics need to be learned as the algorithm sequentially interacts with the environment. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Framework ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider a general online sequential decision-making framework where a learner interacts with an environment with a fixed decision set. At each round $t\\in\\mathbb{N}$ , the learner makes a decision from the set and observes the corresponding reward(s). In what follows, we instantiate this framework to multi-armed bandits, linear bandits, and tabular episodic Markov decision processes (MDPs). ", "page_idx": 2}, {"type": "text", "text": "Multi-armed bandits. In the stochastic MAB setting, the arm (decision) set follows that $\\mathcal{A}=[K]\\triangleq$ $\\{1,\\ldots,K\\}$ . Each arm $a\\in[K]$ is associated with a fixed and unknown $[0,1]$ -bounded distribution4 such that $\\forall t$ , reward $X_{t,a}$ is an i.i.d. sample from this distribution with mean $\\mu_{a}=\\mathbb{E}[X_{t,a}]$ . Let $A_{t}$ be the arm played at round $t$ and $\\Delta_{a}=\\mu^{\\star}-\\mu_{a}$ be the suboptimality gap where $\\mu^{\\star}=\\operatorname*{max}_{a\\in[K]}\\mu_{a}$ . ", "page_idx": 2}, {"type": "text", "text": "Linear bandits. In the stochastic linear bandits setup, we assume that the arm set $\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ is compact. The reward of played arm $A_{t}$ at round $t$ follows that $X_{t,A_{t}}=\\langle\\theta,A_{t}\\rangle+\\eta_{t}$ where $\\theta\\in\\ensuremath{\\mathbb{R}}^{d}$ is a fixed but unknown parameter, and $\\eta_{t}$ is conditionally 1-subgaussian. Let $\\Delta_{a}=\\operatorname*{sup}_{b\\in A}\\left\\langle\\theta,b-a\\right\\rangle$ . We follow standard assumptions that $\\|\\theta\\|_{2}\\leq1$ , $\\|a\\|_{2}\\leq1$ for all $a\\in A$ , and $\\Delta_{a}\\leq1$ for all $a\\in A$ . ", "page_idx": 2}, {"type": "text", "text": "Tabular episodic MDPs. A tabular episodic MDP is formalized as $\\mathcal{M}=(S,\\mathcal{A},H,r,P,\\mu)$ where $S,A$ are finite state and action spaces with $|S|=S,|A|=A,$ $H$ is the horizon length, $r=\\{r_{h}\\}_{h=1}^{H}$ where $r_{h}:S\\times A\\to[0,1]$ is a known reward function, $\\{P_{h}\\}_{h\\in[H]}$ where $P_{h}:S\\times A\\to\\Delta(S)$ is a transition function, and $\\mu$ is the initial state distribution. At the beginning of each episode $t$ , the learner executes a policy $\\bar{\\pi_{t}}=\\{\\pi_{t,h}:S\\rightarrow\\Delta(A)\\}_{h=1}^{H}$ . Then, starting from the initial state $s_{t,1}\\sim\\mu$ , for each stage $h\\in[H]$ , the learner repeatedly takes an action $a_{t,h}\\sim\\pi_{t,h}{(s_{t,h})}$ , observes reward $r_{h}(s_{t,h},a_{t,h})$ , and transits to the next state $s_{t+1,h}\\sim P_{h}(\\cdot|s_{t,h},a_{t,h})$ . ", "page_idx": 2}, {"type": "text", "text": "For any policy $\\pi$ and stage $h$ , we define action value function $Q_{h}^{\\pi}(s,a)$ and value function $V_{h}^{\\pi}(s)$ as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{I}_{h}^{\\pi}(s,a)=\\mathbb{E}\\left[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\mid s_{h}=s,a_{h}=a,\\pi\\right],\\;V_{h}^{\\pi}(s)=\\mathbb{E}\\left[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\mid s_{h}=s,\\pi\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The optimal action value function and value function at each stage $h$ are denoted by $V_{h}^{\\star}(s)\\,=$ $\\operatorname*{max}_{\\pi}V_{h}^{\\pi}(s)$ , and $Q_{h}^{\\star}(s,a)=\\operatorname*{max}_{\\pi}Q_{h}^{\\pi}(s,a)$ respectively. Let $\\Delta_{\\pi}\\ {\\stackrel{-}{=}}\\ \\mathbb{E}_{s_{1}\\sim\\mu}[V_{1}^{\\star}(s_{1})-{\\stackrel{\\cdot}{V_{1}^{\\pi}}}{\\stackrel{\\cdot}{(}}s_{1})]$ . ", "page_idx": 2}, {"type": "text", "text": "Suboptimality notations. For MAB and linear bandits settings, the instantaneous suboptimality is $\\Delta_{t}=\\Delta_{A_{t}}$ , and for episodic MDP, $\\Delta_{t}=\\Delta_{\\pi_{t}}$ . We use $\\Delta=\\operatorname*{inf}_{a\\in\\Pi:\\Delta_{a}>0}\\Delta_{a}$ to denote the minimum suboptimality gap. Notice that it is possible that $\\Delta=0$ when, for example, arm set $\\boldsymbol{\\mathcal{A}}$ is a ball. ", "page_idx": 2}, {"type": "text", "text": "2.2 Limitations of Existing Metrics ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Regret and $(\\delta,\\epsilon)$ -PAC are widely adopted to measure the performance. The regret is defined as: ", "page_idx": 3}, {"type": "text", "text": "Definition 2.1 (Regret). For each fixed $T\\in\\mathbb{N}$ , the regret $R_{T}$ is defined as $\\begin{array}{r}{R_{T}=\\sum_{t=1}^{T}\\Delta_{t}}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Let $\\begin{array}{r}{N_{\\epsilon}=\\sum_{t=1}^{\\infty}\\mathbb{I}\\{\\Delta_{t}>\\epsilon\\}}\\end{array}$ be the number of plays of policies whose suboptimality gap is greater than $\\epsilon$ . Th e definition of $(\\delta,\\epsilon)$ -PAC is given as: ", "page_idx": 3}, {"type": "text", "text": "Definition 2.2 ( $\\mathit{\\check{\\Psi}}(\\delta,\\epsilon)$ -PAC). For any fixed $\\delta,\\epsilon\\in(0,1)$ , an algorithm is $(\\delta,\\epsilon)$ -PAC (w.r.t. function $F_{P A C})$ if there exists a function $F_{P A C}\\left(\\delta,\\epsilon\\right)$ polynomial in $\\log(\\delta^{-1})$ and $\\epsilon^{-1}$ such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(N_{\\epsilon}\\leq F_{P A C}\\left(\\delta,\\epsilon\\right)\\right)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As shown by Dann et al. [2017], both regret and $(\\delta,\\epsilon)$ -PAC have limitations. Specifically, an algorithm with sublinear regret bound may play suboptimal policies infinitely often. For the algorithm with $(\\delta,\\epsilon)$ -PAC guarantee, it may not converge to the optimal policy when feeding the algorithm with more samples. Therefore, such an algorithm would play those policies with suboptimality gap, e.g., $\\epsilon/2$ infinitely often. Motivated by these limitations, Dann et al. [2017] introduce uniform-PAC as follows. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.3 (Uniform-PAC). An algorithm is uniform-PAC for some fixed $\\delta\\in(0,1)$ if there exists a function $F_{U P A C}\\left(\\delta,\\epsilon\\right)$ polynomial in $\\log(1/\\delta)$ and $\\epsilon^{-1}$ , such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\forall\\epsilon>0:N_{\\epsilon}\\le F_{U P A C}\\left(\\delta,\\epsilon\\right)\\right)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We also call $F_{\\mathrm{UPAC}}(\\delta,\\epsilon)$ the sample complexity function. Uniform-PAC is a stronger metric than regret and $(\\delta,\\epsilon)$ -PAC since it leads to the following implications. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.4 (Theorem 3 in [Dann et al., 2017]). If an algorithm is uniform-PAC for some $\\delta$ with function $F_{U P A C}(\\delta,\\epsilon)=\\widetilde{\\mathcal{O}}\\left(\\alpha_{1}/\\epsilon+\\alpha_{2}/\\epsilon^{2}\\right)^{5}$ , where $\\alpha_{1},\\alpha_{2}>0$ are constant in \u03f5 and depend on $\\log(1/\\delta)$ and $K$ for MAB, d for linear bandits, and $S,A,H$ for MDPs then, the algorithm guarantees: ", "page_idx": 3}, {"type": "text", "text": "\u2022 $\\begin{array}{r}{\\mathbb{P}\\left(\\operatorname*{lim}_{t\\to+\\infty}\\Delta_{t}=0\\right)\\geq1-\\delta,}\\end{array}$ ;   \n\u2022 $(\\delta,\\epsilon)$ -PAC with $F_{P4C}(\\delta,\\epsilon)=F_{U P A C}(\\delta,\\epsilon)$ for all $\\epsilon>0$ ;   \n\u2022 With probability at least $1-\\delta_{i}$ , for all $T\\in\\mathbb{N},$ , $R_{T}=\\widetilde{\\mathcal{O}}\\,\\big(\\sqrt{\\alpha_{2}T}+\\alpha_{1}+\\alpha_{2}\\big).$ . ", "page_idx": 3}, {"type": "text", "text": "Limitations of Uniform-PAC. According to Theorem 2.4, uniform-PAC can imply a long-term convergence (the first bullet) and good cumulative performance (the second and the third bullets), but it does not capture the convergence rate of $\\Delta_{t}$ for each round $t$ . In other words, even if an algorithm enjoys uniform-PAC, it could still play a significantly bad policy for some very large but finite $t$ . This would lead to catastrophic consequences in safety-critical applications. ", "page_idx": 3}, {"type": "text", "text": "2.3 New Metric: Uniform Last-Iterate Guarantee ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To address the aforementioned issue, we introduce a new metric, formally defined below. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.5 (Uniform last-iterate (ULI)). An algorithm is ULI for some $\\delta\\in(0,1)$ if there exists $a$ positive-valued function $F_{U L I}(\\cdot,\\cdot)$ , such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\forall t\\in\\mathbb{N}:\\Delta_{t}\\leq F_{U L I}(\\delta,t)\\right)\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $F_{U L I}(\\delta,t)$ is polynomial in $\\log(1/\\delta)$ and proportional to the product of power functions of $\\log t$ and $1/t$ (e.g., $F_{U L I}(\\delta,t)=\\mathtt{p o l y l o g}(1/\\delta)(\\log t)^{\\kappa_{1}}t^{-\\kappa_{2}}$ for some $\\kappa_{1},\\kappa_{2}\\geq0,$ ). ", "page_idx": 3}, {"type": "text", "text": "According to Definition 2.5, the instantaneous suboptimality of any algorithm with the ULI guarantee can be bounded by a function $F_{\\mathrm{ULI}}(\\delta,t)$ . Moreover, $F_{\\mathrm{ULI}}(\\delta,t)$ decreases monotonically for large $t$ if its power on $1/t$ is strictly positive, which captures the convergence rate of $\\Delta_{t}$ . ", "page_idx": 3}, {"type": "text", "text": "Note that the convergence rate of $\\Delta_{t}$ is mainly determined by the power on $1/t$ in $F_{\\mathrm{ULI}}$ . Moreover, as we will show shortly, an algorithm with the ULI guarantee automatically has a small regret bound. We therefore have the following lower bound on $F_{\\mathrm{ULI}}$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.6. For any bandit algorithm that achieves ULI guarantee for some $\\delta$ with function $F_{U L I}(\\delta,t)$ , there exists a MAB instance such that $F_{U L I}(\\delta,t)=\\bar{\\Omega}\\left(t^{-1/2}\\right)$ . ", "page_idx": 3}, {"type": "text", "text": "We provide the proof in Appendix A. In the rest of the paper\u221a, we say an algorithm is near-optimal ULI if it achieves the ULI guarantee with $F_{\\mathrm{ULI}}(\\delta,t)=\\dot{\\tilde{\\mathcal{O}}}(1/\\sqrt{t})$ . ", "page_idx": 4}, {"type": "text", "text": "Then, we present the following theorem to show that ULI directly leads to uniform-PAC, implying that ULI also characterizes the cumulative performance of bandit algorithms. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.7. Suppose an algorithm achieves the ULI guarantee for some $\\delta$ with function ${\\cal F}_{U L I}(\\delta,t)=$ $\\mathtt{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}$ where $\\kappa\\in(0,1)$ . Then, we have, ", "page_idx": 4}, {"type": "text", "text": "\u2022 the algorithm is uniform- $P A C$ with function $F_{U P A C}(\\delta,\\epsilon)=\\mathcal{O}\\bigl(\\epsilon^{-\\frac{1}{\\kappa}}\\cdot\\mathrm{po}1\\mathrm{y}1\\mathrm{og}(\\delta^{-1}\\epsilon^{-1})\\bigr).$ \u2022 with probability at least $\\begin{array}{r}{1-\\delta,\\forall T\\in\\mathbb{N},}\\end{array}$ , the regret $R_{T}$ is bounded by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{O}\\left(\\operatorname*{min}\\left\\{\\mathsf{p o l y L o g}(T/\\delta)\\cdot T^{1-\\kappa},\\Delta^{1-1/\\kappa}\\mathsf{p o l y L o g}^{2}\\left((\\delta\\Delta)^{-1}\\right)\\right\\}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "when the minimum suboptimality gap of the input instance $\\Delta$ satisfies $\\Delta>0$ . ", "page_idx": 4}, {"type": "text", "text": "According to Theorem 2.7, if an algorithm is with near-optimal ULI guarantee (i.e., $\\kappa={\\textstyle{\\frac{1}{2}}},$ ), then it implies the near-optimality for uniform-PAC bound (the first bullet point) and anytime sublinear high-probability regret bound (the second bullet point). On the other hand, an algorithm with nearoptimal uniform-PAC bound does not necessarily enjoy a near-optimal ULI guarantee as shown in Section 3.2. The proof of Theorem 2.7 can be found in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "Remark 2.8. Although a near-optimal ULI guarantee implies an anytime sublinear high-probability regret bound, it cannot give an anytime sublinear expected regret bound. This is because any algorithm with ULI guarantee is also uniform-PAC, but [Dann et al., 2017, Theorem 1] implies that no algorithm can be uniform-PAC and achieve anytime sublinear expected regret bound simultaneously. ", "page_idx": 4}, {"type": "text", "text": "3 Achieving Near-Optimal ULI in Bandits with Finite Arm-Space ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we answer the question whether ULI is achievable for bandit problems. To this end, we examine three common types of bandit algorithms, including elimination-based algorithms, optimistic algorithms, and high-probability adversarial algorithms, in the finite arm setting, i.e., $|{\\mathcal{A}}|=K$ . ", "page_idx": 4}, {"type": "text", "text": "3.1 Elimination Framework Achieving Near-Optimal ULI Guarantee ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To examine whether the elimination-type algorithms can achieve the ULI guarantee, we first provide an elimination framework in Algorithm 1 that ensures the ULI guarantee, and we then show that most elimination-based algorithms fall into this framework. The following result shows that with a proper function $f$ and a positive constant $\\beta$ , such an elimination framework ensures the ULI guarantee. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1. For any given $\\delta\\in(0,1)$ , if there exists function $f(\\delta,t)=t^{-\\kappa}\\mathrm{po1ylog}(t/\\delta)$ for some $\\kappa\\in(0,1)$ and $\\exists\\beta>0$ , such that with probability $1-\\delta$ , Eq. (1) holds for all $t$ , then algorithm is ULI with $F_{U L I}(\\delta,t)=\\mathcal{O}\\left(f(\\delta,t)\\right)$ . ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Elimination framework for ULI ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Input: $\\delta\\in(0,1)$ , set $\\boldsymbol{\\mathcal{A}}$ , function $f(\\cdot,\\cdot)$ , and constant $\\beta$ .   \nInitialize: active arm set $A_{0}=A$ . ", "page_idx": 4}, {"type": "text", "text": "Select an active set $A_{t}$ based on available observations as ( $a^{*}$ is one of optimal arms) ", "page_idx": 4}, {"type": "equation", "text": "$$\nA_{t}\\subseteq\\left\\{a\\in{\\mathcal{A}}_{t-1}:\\Delta_{a}\\leq\\beta\\cdot f\\left(\\delta,t\\right)\\right\\}\\cup\\left\\{a^{\\star}\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Play an arm $A_{t}\\in\\mathcal A_{t}$ and observe reward $X_{t,A_{t}}$ ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1 suggests that Eq. (1) is a sufficient condition for elimination-based algorithms to achieve the ULI guarantee. Now, we show that existing elimination algorithms indeed fall into such a framework. We here consider successive elimination (SE) and phased elimination (PE). Notice that we consider SE only for the MAB setting (called SE-MAB, e.g., Algorithm 3 in [Even-Dar et al., 2006]) but PE for both the MAB setting (called PE-MAB, e.g., exercise 6.8 in [Lattimore and Szepesv\u00e1ri, 2020]) and the linear bandit setting (called PE-L, e.g., Algorithm 12 of Chapter 22 in [Lattimore and Szepesv\u00e1ri, 2020]). Since those algorithms are standard, we defer their pseudocodes to Appendix D. Given Theorem 3.1, the following results show that the elimination framework can be instantiated by these algorithms with proper functions and therefore they achieve the ULI. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2. For any fixed $\\delta\\in(0,1)$ , elimination framework in Algorithm 1 can be instantiated by \u2022 SE-MAB for MAB to achieve the ULI with $F_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{K\\log(\\delta^{-1}K t)}\\big).$ . \u2022 PE-MAB for MAB to achieve the ULI with $F_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{K\\log(\\delta^{-1}K\\log(t+1))}\\big).$ \u2022 PE-L for linear bandits to achieve ULI with $F_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{d\\log(\\delta^{-1}K\\log(t+1)\\log d)}\\big).$ ", "page_idx": 5}, {"type": "text", "text": "Achieving ULI by adversarial bandit algorithms. Traditional elimination-based algorithms, including the ones mentioned above, typically require a carefully designed exploration strategy which is non-trivial even for linear bandits. Here, we provide an alternative way to achieve ULI by employing adversarial bandit algorithms to explore and then conduct the elimination. As shown in Appendix F, all adversarial bandit algorithms for both MAB and linear bandits that meet a certain condition can naturally be used to achieve the ULI guarantees similar to those of traditional elimination-based algorithms. ", "page_idx": 5}, {"type": "text", "text": "3.2 Lower Bound for Optimistic Algorithms ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present a lower bound to show that optimistic algorithms cannot achieve nearoptimal ULI guarantee. The procedure of optimistic algorithms is summarized as follows. After playing each arm once, at each round $t$ , the algorithm plays an arm $A_{t}$ that satisfies ", "page_idx": 5}, {"type": "equation", "text": "$$\nA_{t}\\in\\underset{a\\in\\mathcal{A}}{\\mathrm{argmax}}\\left\\{\\widehat{\\mu}_{a}(N_{a}(t))+U_{\\delta}(N_{a}(t))\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $N_{a}(t)$ is the number of plays of arm $a$ before round $t$ , $\\begin{array}{r}{\\widehat{\\mu}_{a}(N_{a}(t))=\\frac{\\sum_{s=1}^{t-1}X_{s,A_{s}}\\mathbb{I}\\{A_{s}=a\\}}{N_{a}(t)}}\\end{array}$ is the empirical mean of arm $a$ after $N_{a}(t)$ times play, and $U_{\\delta}(N_{a}(t))$ is a positive bonus function which encourages the exploration. ", "page_idx": 5}, {"type": "text", "text": "We first consider optimistic algorithms e.g., upper confidence bound (UCB) [Lattimore and Szepesv\u00e1ri, 2020, Algorithm 3, Chapter 7], which enjoy (near)-optimal regret bounds. This type of algorithms typically uses the bonus function in the form of $\\sqrt{\\log(2t^{2}/\\delta)/N_{a}(t)}^{6}$ . However, the $\\log t$ term forces the algorithm to play suboptimal arms infinitely often, and thus they cannot achieve the ULI guarantee (refer to Appendix E.3 for a detailed proof). Similarly, other variants [Audibert and Bubeck, 2010, Degenne and Perchet, 2016] with $\\log t$ term in bonus function, also cannot achieve the ULI guarantee. We then consider another optimistic-type algorithm, lil\u2019UCB [Jamieson et al., 2014] which obtains the order-optimal instance-dependent sample complexity and avoids $\\log(t)$ term in $U_{\\delta}(N_{a}(t))$ . The bonus function of lil\u2019UCB is as $\\sqrt{\\log{\\left(\\delta^{-1}\\log_{+}{(N_{a}(t))}\\right)/N_{a}(t)}}$ where $\\log_{+}(x)=\\log\\left(\\operatorname*{max}\\left\\{x,e\\right\\}\\right)$ . Our main result for lil\u2019UCB is presented as follows. The full analysis of lil\u2019UCB is deferred to Appendix E. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3. There exists a constant $\\alpha\\in(0,1)$ that for all $\\Delta\\in(0,\\alpha)$ , running lil\u2019UCB on the two-armed bandit instance with deterministic rewards and arm gap $\\Delta$ gives $\\exists t=\\Omega\\left(\\Delta^{-2}\\right)$ such that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Delta_{t}=\\Omega\\left(t^{-\\frac{1}{4}}\\sqrt{\\log\\log\\left(\\Delta^{-2}\\log(\\delta^{-1})\\right)+\\log(\\delta^{-1})}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3 shows that lil\u2019UCB is not near-optimal ULI, but it is unclear whether it can achieve the ULI guarantee. Recall from Theorem 3.2 that the elimination-based algorithms ensure that with high probability, $\\forall t$ , $\\Delta_{t}=\\widetilde{\\cal O}\\left(t^{-1/2}\\right)$ . Theorem 3.3 suggests that the convergence rate of lil\u2019UCB is strictly worse than that of elimination-based algorithms, even if it enjoys a near-optimal cumulative performance [Jamieson et al., 2014]. In fact, this lower bound holds for all optimistic algorithms as long as the bonus function is in a similar form. ", "page_idx": 5}, {"type": "text", "text": "Remark 3.4 (ULI is strictly stronger than uniform-PAC). For lil\u2019UCB, the number of times playing suboptimal arms is finite with an order-optimal instance-dependent sample complexity, which implies that lil\u2019UCB is near-optimal uniform-PAC. Therefore, Theorem 3.3 also shows that an algorithm with near-optimal uniform-PAC does not necessarily enjoy near-optimal ULI guarantee. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 2 PE with adaptive barycentric spanner Input: Compact arm set $\\boldsymbol{\\mathcal{A}}$ , confidence $\\delta\\in(0,1)$ , and constant $C>1$ . Initialize: $\\widehat{\\theta}_{1}=\\{0,\\dots,0\\}\\in\\mathbb{R}^{d}$ , $T_{0}=1$ and $\\boldsymbol{B_{0}}=\\{e_{1},\\ldots,e_{d}\\}$ .   \n1 for $m=1,2,\\ldots$ do   \n2 $\\begin{array}{r}{T_{m}=256C^{4}\\cdot\\frac{d^{3}}{4^{-m}}\\log\\left(\\delta^{-1}d^{3}4^{m}\\right).}\\end{array}$   \n3 Invoke Algorithm 12 with $(A,m,B_{m-1},T_{m},C,\\widehat{\\theta}_{m})$ to find a $C$ -approximate barycentric spanner $B_{m}$ for active arm set $A_{m}$ where $A_{m}$ is in Eq. ( 3). Set $\\textstyle\\pi_{m}(a)={\\frac{1}{d}}$ for each $a\\in\\mathcal{B}_{m}$ .   \n5 Play each arm $a\\in\\mathcal{B}_{m}$ for $n_{m}(a)=\\lceil T_{m}\\pi_{m}(a)\\rceil$ times. Compute $\\begin{array}{r}{V_{m}=I+\\sum_{a\\in\\mathcal{B}_{m}}n_{m}(a)a a^{\\top}}\\end{array}$ and $\\begin{array}{r}{\\widehat{\\theta}_{m+1}=V_{m}^{-1}\\sum_{t\\in\\mathcal{T}_{m}}A_{t}X_{t,A_{t}}}\\end{array}$ where $\\tau_{m}$ is a set that contains all rounds in phase $m$ . ", "page_idx": 6}, {"type": "text", "text": "4 Achieving Near-Optimal ULI for Linear Bandits in Large Arm-Space ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we propose a linear bandit algorithm that can handle the infinite number of arms. The compact arm set $\\boldsymbol{\\mathcal{A}}$ is assumed to span $\\mathbb{R}^{d}$ and $d$ is known. ", "page_idx": 6}, {"type": "text", "text": "4.1 Main Algorithm and Main Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The starting point of our algorithm design is the phased elimination (PE) algorithm [Lattimore et al., 2020, Algorithm 12, Chapter 22]. However, PE in general is not feasible when the arm space is large (e.g., a continuous space). In this section, we present a carefully-designed algorithm to address the new challenges from large arm-spaces. ", "page_idx": 6}, {"type": "text", "text": "Issues of PE for large arm-space. PE needs to (i) compute (approximately) $G$ -optimal design whose complexity scales linearly with $|{\\mathcal{A}}|$ and (ii) compare the empirical mean of each arm, both of which are impossible when the arm set is infinite, e.g., $\\boldsymbol{\\mathcal{A}}$ is a ball. A natural idea is to discretize $\\boldsymbol{\\mathcal{A}}$ , e.g., constructing a $\\epsilon$ -net, but the computational complexity has an exponential dependence on $d$ , and the optimal arm does not necessarily lie in the net, which prevents the convergence to the optimal arm. ", "page_idx": 6}, {"type": "text", "text": "High-level idea behind our solution. To address the aforementioned issues, we propose an oracleefficient linear bandit algorithm in Algorithm 2 which can eliminate bad arms by efficiently querying an optimization oracle. Our algorithm equips PE with a newly-developed adaptive barycentric spanner technique. The proposed technique selects a finite representative arm set to represent (possibly infinite) active arm set and adaptively adjusts the selection of arms across phases. By conducting the (approximate) $G$ -optimal design [Kiefer and Wolfowitz, 1960] on the representative arm set and playing each arm in the set according to the design, the algorithm can acquire accurate estimations uniformly over all active arms. Moreover, the adaptive barycentric spanner approach can be implemented by efficiently querying an optimization oracle in polynomial times. ", "page_idx": 6}, {"type": "text", "text": "The definition of barycentric spanner [Awerbuch and Kleinberg, 2008] is presented as follows. ", "page_idx": 6}, {"type": "text", "text": "Definition 4.1 ( $C$ -approximate barycentric spanner). Let $\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ be a compact set. The set $\\boldsymbol{B}=[b_{1},\\dots,b_{d}]\\subseteq\\bar{\\boldsymbol{A}}$ is a $C$ -approximate barycentric spanner for $\\boldsymbol{\\mathcal{A}}$ if each $a\\in A$ can be expressed as a linear combination of points in $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ with coefficients in the range of $[-C,C]$ . ", "page_idx": 6}, {"type": "text", "text": "Why adaptive barycentric spanner? The primary reason that the non-adaptive barycentric spanner technique [Awerbuch and Kleinberg, 2008] fails to work for PE is that it requires the knowledge of the space that the active arm set spans. However, acquiring such knowledge is often difficult because the active arm set, which may span a proper linear subspace of $\\mathbb{R}^{d}$ , varies for different phases and the number of active arms could be infinite. Our algorithm shown in Algorithm 12 (whose pseudocode is deferred to Appendix G.2 due to space limit) can identify a barycentric spanner for active arm set adaptively for each phase, even if they do not span $\\mathbb{R}^{d}$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm procedure. Our algorithm proceeds in phases $m=1,2,\\ldots$ , and each phase consists of consecutive rounds. At the beginning of phase $m$ , the algorithm invokes subroutine Algorithm 12 to identify a $C$ -approximate barycentric spanner $B_{m}$ which can linearly represent all arms in active arm set $A_{m}$ where $A_{1}=A$ and $\\forall m\\geq2$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{A}_{m}=\\left\\{a\\in\\mathcal{A}_{m-1}:\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1}\\right\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Algorithm 3 Tabular Episodic MDPs with ULI guarantee ", "page_idx": 7}, {"type": "text", "text": "Input: $\\delta\\in(0,1)$ , set $\\Pi_{\\mathsf{a11}}$ containing all deterministic policies, absolute constant $c_{1},c_{2}>0$ .   \nInitialize: $\\Pi_{1}=\\Pi_{\\mathsf{a11}}$ .   \nfor $m=1,2,\\dots{}$ do Set $\\delta_{m}=\\delta/(2m^{2})$ and duration $T_{m}=\\left[c_{1}2^{2m}S^{2}A H^{4}\\log^{2}\\left(c_{2}2^{2m}S^{2}A H^{4}|\\Pi_{\\mathrm{a11}}|/\\delta_{m}\\right)\\right]$ . Run Algorithm 4 with input $(\\delta_{m},\\Pi_{m},T_{m})$ to obtain $\\{\\widetilde{V}_{m}^{\\pi}\\}_{\\pi\\in\\Pi_{m}}$ . Update active policy set $\\Pi_{m+1}=\\left\\{\\pi\\in\\Pi_{m}:\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{m}}\\widetilde{V}_{m}^{\\pi^{\\prime}}-\\widetilde{V}_{m}^{\\pi}\\leq2^{-m}\\right\\}$ . ", "page_idx": 7}, {"type": "text", "text": "where $a_{m}^{\\star}$ is the empirical best arm and $\\widehat{\\theta}_{m}$ is the estimation of unknown parameter $\\theta$ . ", "page_idx": 7}, {"type": "text", "text": "Then, the algorithm assigns $\\textstyle\\pi_{m}(a)\\,=\\,{\\frac{1}{d}}$ for each $a\\,\\in\\,B_{m}$ . In fact, if we add $\\cup_{i\\in{\\mathcal{Z}}_{m}}{\\frac{e_{i}}{\\sqrt{T_{m}}}}$ (refer Appendix $\\mathrm{G}$ for $e_{i}$ and ${\\mathcal{T}}_{m}$ ) back to $B_{m}$ and denote the new set by $B_{m}^{\\prime}$ , then $\\pi_{m}:B_{m}^{\\prime}\\to{\\textstyle{\\frac{1}{d}}}$ forms an optimal design. It is noteworthy that our algorithm only plays arms in $B_{m}$ as these added elements do not necessarily exist in the arm set $A_{m}$ . As each added element $\\frac{e_{i}}{\\sqrt{T_{m}}}$ is close to zero, even if we only play arms in $B_{m}$ , we can still acquire accurate estimations uniformly over $A_{m}$ (refer to Appendix G.6 for details): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\forall a\\in\\mathcal{A}_{m}:\\quad\\left\\|a\\right\\|_{V_{m}^{-1}}=\\sqrt{a^{\\top}V_{m}^{-1}a}\\leq C\\cdot d/\\sqrt{T_{m}},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\begin{array}{r}{V_{m}=I+\\sum_{a\\in\\mathcal{B}_{m}}n_{m}(a)a a^{\\top}}\\end{array}$ is the least squares matrix, used to estimate $\\theta$ . ", "page_idx": 7}, {"type": "text", "text": "According to the standard analysis of linear bandit algorithms, the estimation error of $\\langle a,\\theta\\rangle$ is proportional to $\\|a\\|_{V_{m}^{-1}}$ . Hence, the estimation errors of $\\{\\langle a,\\theta\\rangle\\}_{a\\in\\mathcal{A}_{m}}$ can be uniformly bounded by $\\widetilde{\\mathcal{O}}\\big(C d/\\sqrt{T_{m-1}}\\big)$ , which is known to the learner. Finally, after playing each arm $a\\in\\mathcal{B}_{m}$ for $n_{m}(a)$ times, the algorithm updates the empirical estimates $V_{m}$ and $\\widehat{\\theta}_{m+1}$ , and then steps into the next phase. The main results of Algorithm 2 for achieving the ULI guarantee and computational complexity are given as follows. The full proof can be found in Appendix G. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.2. For any fixed $\\delta\\,\\in\\,(0,1)$ , Algorithm 2 achieves the ULI guarantee with function $F_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{d^{3}\\log(\\delta^{-1}d t)}\\big)$ . Moreover, in each phase, the number of calls to the optimization oracle given in Definition G.2 is $O\\left(d^{3}\\log_{C}d\\right)$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.2 and Theorem 2.7 jointly suggest $\\widetilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ worst-case regret bound for the infinitearmed setting, which matches those of [Dani et al., 2008, Agrawal and Goyal, 2013, Hanna et al., 2023]. Compared with the lower bound $\\Omega(d{\\sqrt{T}})$ given by Dani et al. [2008], our regret bound suffers an extra $\\sqrt{d}$ factor, caused by the spanner technique. Yet, it remains open to find a computationally efficient linear ba\u221andit algorithm that can handle the infinite arm setting with general compact $\\boldsymbol{\\mathcal{A}}$ and matches the $\\Omega(d{\\sqrt{T}})$ lower bound. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.2 also shows that, for each phase, the spanner can be constructed by calling the oracle for only polynomial times. Compared to the computational efficiency of the algorithm in [Awerbuch and Kleinberg, 2008], the efficiency of our algorithm is only $d$ times worse than theirs. ", "page_idx": 7}, {"type": "text", "text": "5 Achieving Near-Optimal ULI in Tabular Episodic MDPs ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we propose a novel algorithm that achieves a near-optimal ULI guarantee in tabular episodic MDPs setup. The algorithm is formally presented in Algorithm 3. ", "page_idx": 7}, {"type": "text", "text": "High-level idea. Algorithm 3 conducts policy elimination over a policy set $\\Pi_{\\mathsf{a11}}$ which enumerates all deterministic policies. The key challenge here is to acquire accurate estimations of value functions uniformly for all deterministic policies. Note that na\u00efvely playing all deterministic policies will incur linear dependence on $|\\Pi_{\\mathrm{a11}}|\\stackrel{\\cdot}{=}A^{S H}$ in $F_{\\mathrm{ULI}}$ , which is exponentially large. Hence, the algorithm invokes subroutine Algorithm 4 to exhaustively explore the environment, which ensures accurate estimations of the transition model and only suffers logarithmic dependence on $|\\Pi_{\\mathsf{a11}}|$ . Once the transition model can be well-approximated, the algorithm constructs an accurate estimation of the value function for every policy and then decides which policies should be eliminated. ", "page_idx": 7}, {"type": "text", "text": "Algorithm 4 Uniform estimation for value functions ", "page_idx": 8}, {"type": "text", "text": "Input: confidence $\\delta\\in(0,1)$ , policy set $\\Pi\\subseteq\\Pi_{\\mathsf{a11}}$ , duration $T$ .   \nInitialize: randomly pick a policy $\\pi_{1}\\in\\Pi$ , $N_{1,h}(s,a)=N_{1,h}(s,a,s^{\\prime})=0$ for all $(h,s,a,s^{\\prime})$ .   \nfor $t=1,\\dots,T$ do Observe initial state $s_{t,1}\\sim\\mu$ . for $h=1,\\ldots,H$ do Take action $a_{t,h}=\\pi_{t,h}{\\left(s_{t,h}\\right)}$ and observe $s_{t,h+1}\\sim\\mathbb{P}_{h}\\!\\left(\\cdot\\vert s_{t,h},a_{t,h}\\right)$ . Increase counters $N_{t,h}(s_{t,h},a_{t,h},s_{t,h+1})\\xleftarrow1$ and $N_{t,h}(s_{t,h},a_{t,h})\\gets1$ . Update estimatesP t,h(s\u2032|s, a) = maxN{t,1h,(Nst,,ah,(ss,)a)} for all $(s,a,s^{\\prime})\\in\\mathcal S\\times\\mathcal A\\times\\mathcal S$ . Update bonus function $b_{t}=\\{b_{t,h}\\}_{h\\in[H]}$ where $b_{t,h}(\\cdot,\\cdot)$ is updated according to Eq. (5). Get $\\{\\widehat{V}_{t,1}^{\\pi}(s_{1})\\}_{\\pi\\in\\Pi}$ by invoking Algorithm 5 with input $\\big(\\Pi,b_{t}/H,\\{\\widehat{\\mathbb{P}}_{T,h}\\}_{h\\in[H]},b_{t},s_{t,1}\\big).$ . Update policy $\\pi_{t+1}=\\operatorname{argmax}_{\\pi\\in\\Pi}\\widehat{V}_{t,1}^{\\pi}(s_{1})$ .   \nfor $t=1,\\dots,T\\,{\\bf d}$ o ", "page_idx": 8}, {"type": "text", "text": "Output: $\\{\\widetilde V^{\\pi}\\}_{\\pi\\in\\Pi}$ where $\\begin{array}{r}{\\widetilde V^{\\pi}=\\frac{1}{T}\\sum_{t=1}^{T}\\widehat{V}_{T,1}^{\\pi}(s_{t,1}).}\\end{array}$ . ", "page_idx": 8}, {"type": "text", "text": "Algorithm 5 Construct estimated value function ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Input: policy set $\\Pi\\subseteq\\Pi_{\\mathsf{a11}}$ , reward function $r$ , transitionP, bonus function $b$ , initial state $s_{1}$ .   \nfor $\\pi\\in\\Pi$ do $\\widehat{Q}_{H+1}^{\\pi}(\\cdot,\\cdot)=0$ and $\\widehat{V}_{H+1}^{\\pi}(\\cdot)=0$ . for $h=H,H-1,\\ldots,1$ do $\\widehat{Q}_{h}^{\\pi}(\\cdot,\\cdot)=\\operatorname*{min}\\left\\{\\left[\\widehat{\\mathbb{P}}_{h}\\widehat{V}_{h+1}^{\\pi}\\right](\\cdot,\\cdot)+r_{h}(\\cdot,\\cdot)+b_{h}(\\cdot,\\cdot),H\\right\\}$ and $\\widehat V_{h}^{\\pi}(\\cdot)=\\widehat Q_{h}^{\\pi}(\\cdot,\\pi(\\cdot)).$   \nOutput: $\\{\\widehat{V}_{1}^{\\pi}(s_{1})\\}_{\\pi\\in\\Pi}$ ", "page_idx": 8}, {"type": "text", "text": "More concretely, Algorithm 3 first accepts a set of all deterministic policies and then it proceeds in phases $m=1,2,\\ldots$ In each phase $m$ , subroutine Algorithm 4 is invoked to learn the transition model. Specifically, the subroutine inherits the structure of UCB-VI [Azar et al., 2017], but more importantly the algorithm pretends to be agnostic to the reward function and uses uncertainty-driven reward functions $\\{b_{t,h}(s,a)/H\\}_{t,h}$ where ", "page_idx": 8}, {"type": "equation", "text": "$$\nb_{t,h}(s,a)=H\\sqrt{\\frac{2S\\log\\iota}{\\operatorname*{max}\\{1,N_{t,h}(s,a)\\}}}+\\frac{2H S\\log\\iota}{3\\operatorname*{max}\\{1,N_{t,h}(s,a)\\}}\\mathrm{~where~}\\iota=\\frac{10S A H|\\Pi_{\\mathrm{all}}|T}{\\delta},\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $N_{t,h}(s,a)$ is the number of times of visiting $(s,a)$ at stage $h$ up to episode $t$ . Note that Eq. (5) captures the uncertainty of visitation a state-action pair, i.e., more visitations of $(s,a)$ , larger $N_{t,h}(s,a)$ , and less uncertainty. This modification, inspired by [Wang et al., 2020] forces the algorithm to aggressively explore the environment, in the sense that the algorithm prefers to play a policy that maximizes the uncertainty. ", "page_idx": 8}, {"type": "text", "text": "The following theorem shows that our algorithm achieves the ULI guarantee. ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.1. For a\u221any fixed $\\delta\\,\\in\\,(0,1)$ , Algorithm 3 achieves the ULI guarantee with function $F_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{S^{3}A H^{5}}\\log\\left(t S A H/\\delta\\right)\\big)$ . ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.1 shows near-optimality of Algorithm 3 w.r.t. episode $t$ . Unfortunately, the regret bound implied by our ULI result incurs suboptimal dependence on $S,H$ , and the logarithmic term, and our algorithm is not computational efficient. We leave these improvements for future work. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusions and Future Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we propose a new metric, the uniform last-iterate (ULI) guarantee, which captures both instantaneous and cumulative performance of sequential decision-making algorithms. To answer whether ULI is (optimally) achievable, we first examine three types of bandit algorithms in the finitearm setting. Specifically, we provide stronger analysis to show that elimination-based algorithms naturally achieve near-optimal ULI guarantees. We also provide a reduction-based approach to enable any high-probability adversarial algorithms, with a mild condition, to achieve near-optimal ULI guarantees. We further provide a negative result for optimistic bandit algorithms showing that they cannot achieve near-optimal ULI guarantee. Furthermore, in the large arm space setting, we propose an oracle-efficient linear bandit algorithm, equipped with the novel adaptive barycentric spanner technique. Finally, we propose a new algorithm, which adapts uncertainty-driven reward functions into policy elimination to achieve a ULI guarantee in tabular episodic MDPs. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Some natural directions are to improve our current results, including proposing a ULI algorithm for linear bandits with infinite arms and proposing a computationally efficient algorithm, possibly based on the action-elimination approach, for tabular MDPs. We also summarize other interesting directions as follows. ", "page_idx": 9}, {"type": "text", "text": "\u2022 Design (computationally efficient) algorithms for MDPs with linear function approximation. The main challenge is to bypass any dependence on the number of states which is possibly infinite. Thus, generalizing our RL algorithm, which enumerates all deterministic policies, to linear MDPs does not work. \u2022 Design (computationally efficient) algorithms for Episodic MDPs with only logarithmic dependence on $H$ (a.k.a. horizon-free). In our attempts, we use the doubling trick on $\\epsilon$ in existing $(\\delta,\\epsilon)$ -PAC horizon-free RL algorithms. In this case, we run the algorithm in phases with $\\epsilon,\\epsilon/2,\\epsilon/4,\\dots$ The main difficulty is to leverage the information learned from the previous phase to guide the algorithm to play an improved policy at the next phase as required by ULI. Thus, we conjecture that there might exist fundamental barriers to simultaneously achieve ULI guarantee and a logarithmic dependence on $H$ . \u2022 It could be also interesting to investigate some empirical issues when deploying ULI algorithms in high-stakes fields. Typically, optimistic algorithms initially incur a lower regret than ULI algorithms, but their regret will exceed those of ULI algorithms at a certain juncture. At this juncture, ULI algorithms have eliminated all suboptimal arms, whereas optimistic algorithms continue exploring as time evolves. Hence, identifying this turning point could be beneficial for deploying ULI algorithms in high-stakes domains. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Y. Abbasi-Yadkori, D. P\u00e1l, and C. Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. In Advances in Neural Information Processing Systems, 2011.   \nA. Agarwal, D. Hsu, S. Kale, J. Langford, L. Li, and R. Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning, 2014.   \nS. Agrawal and N. Goyal. Thompson sampling for contextual bandits with linear payoffs. In International conference on machine learning, 2013.   \nJ.-Y. Audibert and S. Bubeck. Regret bounds and minimax policies under partial monitoring. Journal of Machine Learning Research, 11(94):2785\u20132836, 2010.   \nJ.-Y. Audibert, S. Bubeck, and R. Munos. Best arm identification in multi-armed bandits. In Conference on Learning Theory, 2010.   \nP. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 2002a.   \nP. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit problem. SIAM journal on computing, 32(1):48\u201377, 2002b.   \nB. Awerbuch and R. Kleinberg. Online linear optimization and adaptive routing. Journal of Computer and System Sciences, 74(1):97\u2013114, 2008.   \nM. G. Azar, I. Osband, and R. Munos. Minimax regret bounds for reinforcement learning. In Proceedings of the International Conference on Machine Learning, 2017.   \nP. L. Bartlett, V. Dani, T. P. Hayes, S. M. Kakade, A. Rakhlin, and A. Tewari. High-probability regret bounds for bandit online linear optimization. In Conference on Learning Theory, 2008.   \nA. Bibaut, A. Chambaz, and M. Laan. Generalized policy elimination: an efficient algorithm for nonparametric contextual bandits. In Conference on Uncertainty in Artificial Intelligence, 2020.   \nS. Chen, T. Lin, I. King, M. R. Lyu, and W. Chen. Combinatorial pure exploration of multi-armed bandits. In Advances in Neural Information Processing Systems, 2014.   \nV. Dani, T. P. Hayes, and S. M. Kakade. Stochastic linear optimization under bandit feedback. In Conference on Learning Theory, 2008.   \nC. Dann, T. Lattimore, and E. Brunskill. Unifying pac and regret: Uniform pac bounds for episodic reinforcement learning. In Advances in Neural Information Processing Systems, 2017.   \nR. Degenne and V. Perchet. Anytime optimal algorithms in stochastic multi-armed bandits. In International Conference on Machine Learning, 2016.   \nD. Ding, C.-Y. Wei, K. Zhang, and A. Ribeiro. Last-iterate convergent policy gradient primal-dual methods for constrained mdps. arXiv preprint arXiv:2306.11700, 2023.   \nE. Even-Dar, S. Mannor, Y. Mansour, and S. Mahadevan. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of machine learning research, 7(6), 2006.   \nO. Hanna, L. Yang, and C. Fragouli. Efficient batched algorithm for contextual linear bandits with large action space via soft elimination. In Advances in Neural Information Processing Systems, 2023.   \nJ. He, D. Zhou, and Q. Gu. Uniform-pac bounds for reinforcement learning with linear function approximation. In Advances in Neural Information Processing Systems, 2021.   \nK. Jamieson, M. Malloy, R. Nowak, and S. Bubeck. lil\u2019ucb: An optimal exploration algorithm for multi-armed bandits. In Conference on Learning Theory, 2014.   \nC. Jin, Z. Allen-Zhu, S. Bubeck, and M. I. Jordan. Is q-learning provably efficient? In Proceedings of the International Conference on Neural Information Processing Systems, 2018.   \nC. Jin, T. Jin, H. Luo, S. Sra, and T. Yu. Learning adversarial markov decision processes with bandit feedback and unknown transition. In Proceedings of the International Conference on Machine Learning (ICML), 2020.   \nT. Jin, J. Shi, X. Xiao, and E. Chen. Efficient pure exploration in adaptive round model. In Advances in Neural Information Processing Systems, 2019.   \nS. Kalyanakrishnan, A. Tewari, P. Auer, and P. Stone. Pac subset selection in stochastic multi-armed bandits. In International Conference on Machine Learning, 2012.   \nJ. Kiefer and J. Wolfowitz. The equivalence of two extremum problems. Canadian Journal of Mathematics, 12:363\u2013366, 1960.   \nT. Lattimore and C. Szepesv\u00e1ri. Bandit algorithms. Cambridge University Press, 2020.   \nT. Lattimore, C. Szepesvari, and G. Weisz. Learning with good feature representations in bandits and in rl with a generative model. In International Conference on Machine Learning, 2020.   \nC.-W. Lee, H. Luo, C.-Y. Wei, and M. Zhang. Bias no more: high-probability data-dependent regret bounds for adversarial bandits and mdps. In Advances in neural information processing systems, 2020.   \nC.-W. Lee, H. Luo, C.-Y. Wei, M. Zhang, and X. Zhang. Achieving near instance-optimality and minimax-optimality in stochastic and adversarial linear bandits simultaneously. In International Conference on Machine Learning, 2021.   \nL. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In International Conference on World Wide Web, 2010.   \nZ. Li, L. Ratliff, K. G. Jamieson, L. Jain, et al. Instance-optimal pac algorithms for contextual bandits. In Advances in Neural Information Processing Systems, 2022.   \nT. Moskovitz, B. O\u2019Donoghue, V. Veeriah, S. Flennerhag, S. Singh, and T. Zahavy. Reload: Reinforcement learning with optimistic ascent-descent for last-iterate convergence in constrained mdps. In International Conference on Machine Learning, 2023.   \nO. Plevrakis and E. Hazan. Geometric exploration for online control. In Advances in Neural Information Processing Systems, 2020.   \nS. S. Villar, J. Bowden, and J. Wason. Multi-armed bandit models for the optimal design of clinical trials: beneftis and challenges. Statistical science: a review journal of the Institute of Mathematical Statistics, 30(2):199, 2015.   \nA. J. Wagenmaker, M. Simchowitz, and K. Jamieson. Beyond no regret: Instance-dependent pac reinforcement learning. In Conference on Learning Theory, pages 358\u2013418. PMLR, 2022.   \nR. Wang, S. S. Du, L. Yang, and R. R. Salakhutdinov. On reward-free reinforcement learning with linear function approximation. Advances in neural information processing systems, 2020.   \nY. Wu, J. He, and Q. Gu. Uniform-pac guarantees for model-based rl with bounded eluder dimension. In Conference on Uncertainty in Artificial Intelligence, 2023.   \nY. Zhu, D. J. Foster, J. Langford, and P. Mineiro. Contextual bandits with large action spaces: Made practical. In International Conference on Machine Learning, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A Proof of Theorem 2.6 14 ", "page_idx": 12}, {"type": "text", "text": "B Proof of Theorem 2.7 14   \nB.1 Proof of the first bullet: ULI guarantee implies uniform-PAC bound 14   \nB.2 Proof of the second bullet: ULI implies regret bounds 15 ", "page_idx": 12}, {"type": "text", "text": "C Proof of Theorem 3.1 17 ", "page_idx": 12}, {"type": "text", "text": "D Proof of Theorem 3.2 17   \nD.1 ULI guarantee for SE-MAB algorithm 17   \nD.2 ULI guarantee for PE-MAB 19   \nD.3 ULI guarantee for PE-linear 21   \nE Omitted Details of Section 3.2 24   \nE.1 Proof of Theorem 3.3 24   \nE.2 Proof of Supporting Lemmas 25   \nE.3 Traditional Optimistic Algorithms Fail to Achieve ULI Guarantee 27   \nF Achieving ULI by Adversarial Bandit Algorithms 29   \nF.1 Meta-algorithm Enabling Adversarial Algorithms to Achieve ULI 29   \nF.2 Proof of Theorem F.4 31   \nF.3 Proof of Proposition F.5 34   \nF.4 Proof of Theorem F.2 40 ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "G Omitted Details of Section 4 41 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "G.1 Notations 41   \nG.2 Key Technique: Adaptive Barycentric Spanner 41   \nG.3 Computational Analysis 42   \nG.4 Proof of Lemma G.4 . 43   \nG.5 Proof of Lemma G.1 . 44   \nG.6 Proof of Theorem 4.2: Regret Analysis 46   \nG.7 Proof of Theorem 4.2: Computational Analysis 49 ", "page_idx": 12}, {"type": "text", "text": "H Omitted Details of Section 5 50 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "H.1 Proof of Theorem 5.1 50   \nH.2 Construction of Nice Event 51   \nH.3 Supporting Lemmas 52   \nH.4 Proof of Proposition H.1 53 ", "page_idx": 12}, {"type": "text", "text": "I Limitations 55 ", "page_idx": 12}, {"type": "text", "text": "J Broader Impacts 55 ", "page_idx": 12}, {"type": "text", "text": "A Proof of Theorem 2.6 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We prove this claim by contradiction. Suppose that there exists an algorithm that can achieve the ULI guarantee with function $\\begin{array}{r}{F_{\\mathrm{ULI}}(\\delta,t)\\le c_{0}\\frac{1}{t^{\\frac{1}{2}+\\alpha}}}\\end{array}$ for some $\\alpha\\in(0,\\frac{1}{2})$ and constant $c_{0}>0$ which may depend on $\\log(1/\\delta)$ and $K$ for MAB or $d$ for linear bandits. We consider a $K$ -armed bandit instance $\\mathcal{K}\\geq2)$ ) with Gaussian rewards and all suboptimality gaps are bounded by one. ", "page_idx": 13}, {"type": "text", "text": "By the definition of ULI, we have that with probability at least $1-\\delta$ , for all $T\\in\\mathbb N$ with $T^{\\frac{1}{2}-\\alpha}>t_{0}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{R_{T}=\\sum_{t=1}^{T}\\Delta_{t}}}\\\\ &{=\\sum_{t=1}^{\\infty}\\Delta_{t}+\\sum_{t={\\bar{t}}+1}^{T}\\Delta_{t}}\\\\ &{\\leq t_{0}+\\sum_{t={\\bar{t}}+1}^{T}\\sum_{\\ell={\\bar{t}}+1}^{T}(\\delta_{t})}\\\\ &{\\leq t_{0}+\\sum_{\\ell={\\bar{t}}+1}^{T}F_{\\ell\\ell\\ell}(\\delta_{t})}\\\\ &{\\leq t_{0}+c_{0}\\sum_{\\ell=1+1}^{T}t^{-\\alpha-{\\frac{1}{2}}}}\\\\ &{\\leq T^{1-\\alpha}+\\frac{2c_{0}}{1-2\\alpha}T^{\\frac{1-\\alpha}{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first inequality holds as we assume all suboptimal gaps are bounded by one, and $\\Delta_{t}\\leq$ $F_{\\mathrm{ULI}}(\\delta,t)$ for all $t\\geq t_{0}$ . ", "page_idx": 13}, {"type": "text", "text": "Since ${\\scriptstyle{\\frac{1}{2}}}\\textrm{--}\\alpha\\ \\in\\ (0,{\\frac{1}{2}})$ , there will be a contradiction to the regret lower bound [Lattimore and Szepesv\u00e1ri, 2020, Corollary 17.3] for the Gaussian MAB setup. ", "page_idx": 13}, {"type": "text", "text": "B Proof of Theorem 2.7 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Theorem B.1 (Restatement of Theorem 2.7). Suppose an algorithm achieves the ULI guarantee for some $\\delta$ with function $F_{U L I}(\\delta,t)=\\mathtt{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}$ where $\\kappa\\in(0,1)$ . Then, we have, ", "page_idx": 13}, {"type": "text", "text": "\u2022 the algorithm is also uniform-PAC with ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F_{U P A C}(\\delta,\\epsilon)=\\mathcal{O}\\left(\\frac{\\mathtt{p o l y l o g}(\\delta^{-1}\\epsilon^{-1})}{\\epsilon^{1/\\kappa}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "\u2022 with probability at least $1-\\delta,\\forall T\\in\\mathbb{N}$ , the regret $R_{T}$ is bounded by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{O}\\left(\\operatorname*{min}\\left\\{\\mathrm{po1y1og}(T/\\delta)\\cdot T^{1-\\kappa},\\frac{\\mathrm{po1y1og}^{2}\\left(\\frac{1}{\\delta\\Delta}\\right)}{\\Delta^{1/\\kappa-1}}\\right\\}\\right),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "when the minimum suboptimality gap of the input instance $\\Delta$ satisfies $\\Delta>0$ . ", "page_idx": 13}, {"type": "text", "text": "B.1 Proof of the first bullet: ULI guarantee implies uniform-PAC bound ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this subsection, we show the first bullet of Theorem 2.7. We define the following events for $F_{\\mathrm{ULI}}=\\mathtt{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\nA=\\left\\{\\forall t\\in\\mathbb{N}:\\Delta_{t}\\leq F_{\\mathrm{ULI}}(\\delta,t)\\right\\},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which indicates the occurrence the ULI, and denote the event $B$ as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nB=\\left\\{\\forall\\epsilon>0:\\sum_{t=1}^{\\infty}\\mathbb{I}\\{\\Delta_{t}>\\epsilon\\}\\leq F_{\\mathrm{UPAC}}(\\delta,\\epsilon)\\right\\}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "For some $\\delta\\,\\in\\,(0,1)$ , if event $A$ holds for an algorithm with probability at least $1-\\delta$ , then the algorithm is with ULI guarantee. Therefore, to prove the claimed result, it suffices to show that conditioning on event $A$ that for any algorithm enjoys ULI guarantee with a function $F_{\\mathrm{ULI}}(\\delta,t)$ , one can find a function $F_{\\mathrm{UPAC}}(\\delta,\\epsilon)$ such that event $B$ also holds. ", "page_idx": 14}, {"type": "text", "text": "As for any fixed $\\delta\\in(0,1)$ , $F_{\\mathrm{ULI}}(\\delta,t)=\\mathtt{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}$ is monotonically decreasing for large $t$ , $\\exists U\\in\\mathbb{R}_{>0}$ such that $F_{\\mathrm{ULI}}(\\delta,t)\\leq U$ for all $t\\in\\mathbb{N}$ and ${\\cal F}_{\\mathrm{ULI}}(\\delta,t)=U$ is attainable by some $t$ . Then, we consider any given $\\epsilon>0$ with two cases as follows. ", "page_idx": 14}, {"type": "text", "text": "Case 1: $\\epsilon<U$ . Again, by the fact that $F_{\\mathrm{ULI}}(\\delta,t)=\\mathtt{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}$ is monotonically decreasing for large $t$ , there should exist a round $t\\in\\mathbb{N}$ such that $F_{\\mathrm{ULI}}(\\delta,s)\\leq\\epsilon$ for all $s\\geq t$ . Let $t_{0}$ be the round with the maximal index such that $F_{\\mathrm{ULI}}(\\delta,t_{0})>\\epsilon$ , which gives ", "page_idx": 14}, {"type": "equation", "text": "$$\nt_{0}\\leq\\frac{\\mathtt{p o l y l o g}^{\\frac{1}{\\kappa}}(t_{0}/\\delta)}{\\epsilon^{\\frac{1}{\\kappa}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "As a result, the number of times that $\\Delta_{t}>\\epsilon$ occurs is at most ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{\\infty}\\mathbb{I}\\{\\Delta_{t}>\\epsilon\\}\\le\\sum_{t=1}^{\\infty}\\mathbb{I}\\{F_{\\mathrm{ULI}}(\\delta,t)>\\epsilon\\}\\le t_{0}\\le\\frac{\\mathrm{po1y1og}^{\\frac{1}{\\kappa}}(t_{0}/\\delta)}{\\epsilon^{\\frac{1}{\\kappa}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then, one can find constants $c_{0}>0$ and $z\\in(0,\\kappa)$ such that pol $\\prime1\\circ\\mathtt{g}(t/\\delta)\\leq c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)t^{z}$ for all $t\\,\\in\\,\\mathbb{R}_{>1}$ , thereby poly $\\mathtt{l o g}(t_{0}/\\delta)\\,\\le\\,c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)t_{0}^{z}$ . Combining $\\mathtt{p o l y l o g}(t_{0}/\\delta)\\leq$ $c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)t_{0}^{z}$ and $F_{\\mathrm{ULI}}(\\delta,t_{0})>\\epsilon$ gives ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\epsilon\\le\\frac{\\mathtt{p o l y l o g}(t_{0}/\\delta)}{t_{0}^{\\kappa}}\\le\\frac{c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)t_{0}^{z}}{t_{0}^{\\kappa}}=c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)t_{0}^{z-\\kappa},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which immediately leads to ", "page_idx": 14}, {"type": "equation", "text": "$$\nt_{0}\\le\\left(\\frac{c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)}{\\epsilon}\\right)^{\\frac{1}{\\kappa-z}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then, we can further show that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{\\infty}\\mathbb{I}\\{\\Delta_{t}>\\epsilon\\}\\leq t_{0}\\leq\\frac{\\mathrm{po}\\mathrm{1}\\mathrm{y}\\mathrm{1}\\mathrm{o}\\mathrm{g}^{\\frac{1}{\\kappa}}(t_{0}/\\delta)}{\\epsilon^{\\frac{1}{\\kappa}}}\\leq\\frac{\\mathrm{po}\\mathrm{1}\\mathrm{y}\\mathrm{1}\\mathrm{o}\\mathrm{g}\\left(\\delta^{-1}\\left(\\frac{c_{0}\\cdot\\mathrm{po}\\mathrm{1}\\mathrm{y}\\mathrm{1}\\mathrm{o}\\mathrm{g}\\left(1/\\delta\\right)}{\\epsilon}\\right)^{\\frac{1}{\\kappa-z}}\\right)}{\\epsilon^{\\frac{1}{\\kappa}}}\\triangleq F_{\\mathrm{UPac}}(\\delta,\\epsilon)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the third inequality follows that polylog $(t/\\delta)$ is monotonically increasing for all $t>0$ and Eq. (7). ", "page_idx": 14}, {"type": "text", "text": "Case 2: $\\epsilon\\geq U$ . Conditioning on event $A$ and by the definition of $U$ , we have $\\Delta_{t}\\leq F_{\\mathrm{ULI}}(\\delta,t)\\leq$ $U\\leq\\epsilon$ for all $t\\in\\mathbb{N}$ , which implies $\\sum_{t=1}^{\\infty}\\mathbb{I}\\{\\Delta_{t}>\\epsilon\\}=0$ . Therefore, any positive function works there and we still choose $F_{\\mathrm{UPAC}}(\\delta,\\epsilon)$ the same as above. ", "page_idx": 14}, {"type": "text", "text": "This argument holds for all $\\epsilon\\,>\\,0$ . Therefore, if an algorithm satisfies the ULI guarantee, then $\\mathbb{P}(A)\\geq1-\\delta$ , and with the above statement, we can find a function $F_{\\mathrm{UPAC}}$ such that $\\mathbb{P}(B)\\geq1-\\delta$ , which concludes the proof. ", "page_idx": 14}, {"type": "text", "text": "B.2 Proof of the second bullet: ULI implies regret bounds ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For some fixed $\\delta\\,\\in\\,(0,1)$ , let us consider an algorithm enjoys the ULI guarantee with function $F_{\\mathrm{ULI}}(\\cdot,\\cdot)$ . The following analysis will condition on event $A$ given in Eq. (6). ", "page_idx": 14}, {"type": "text", "text": "Gap-dependent bound. Recall that $\\Delta\\,>\\,0$ is the minimum gap. We replace $\\epsilon$ with $\\Delta/2$ in the proof of in Appendix B.1, case 1, and similarly define $t_{0}~\\in\\mathbb{N}$ as the maximal round such that $\\scriptstyle F_{\\mathrm{ULI}}(\\delta,t_{0})\\ =\\ {\\bf\\dot{p o}}1\\!\\mathrm{y}1\\!\\circ\\ \\!\\mathbf{g}(t_{0}/\\delta)\\cdot t_{0}^{-\\kappa}>\\Delta/2$ . Then, we apply a similar argument (in Appendix B.1, ", "page_idx": 14}, {"type": "text", "text": "case 1), which gives that that for some constants $z\\in(0,\\kappa)$ and $c_{0}>0$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{s=1}^{\\infty}\\mathbb{I}\\{\\Delta_{A_{s}}>\\Delta/2\\}}\\\\ {\\displaystyle\\le t_{0}}\\\\ {\\displaystyle\\le\\operatorname*{min}\\left\\{\\left(\\frac{2c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)}{\\Delta}\\right)^{\\frac{1}{\\kappa-z}},\\frac{\\mathtt{p o l y l o g}\\left(\\delta^{-1}\\left(\\frac{2c_{0}\\cdot\\mathtt{p o l y l o g}(1/\\delta)}{\\Delta}\\right)^{\\frac{1}{\\kappa-z}}\\right)}{(\\Delta/2)^{\\frac{1}{\\kappa}}}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last inequality holds by taking the minimum of Eq. (7) and Eq. (8). Therefore, the algorithm will incur no regret, i.e., $\\Delta_{t}=0$ for all $t\\geq t_{0}$ For every $T\\in\\mathbb N$ , the regret $R_{T}$ is bounded by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{R_{T}}=\\displaystyle\\sum_{t=1}^{T}\\Delta_{t}}\\\\ &{\\phantom{\\sum}_{t=1}^{T}{\\mathrm{polylog}\\left(t/\\delta\\right)}\\cdot t^{-\\kappa}}\\\\ &{\\phantom{\\sum_{t=1}^{T}{\\mathrm{polylog}\\left(t/\\delta\\right)}\\cdot t^{-\\kappa}}}\\\\ &{\\phantom{\\sum_{t=1}^{t}{\\mathrm{polylog}\\left(t/\\delta\\right)}\\cdot t^{-\\kappa}}\\leq\\displaystyle\\sum_{t=1}^{t}{\\mathrm{polylog}\\left(t/\\delta\\right)}\\cdot t^{-\\kappa}}\\\\ &{\\leq\\mathrm{polylog}(t_{0}/\\delta)\\displaystyle\\sum_{t=1}^{t_{0}}t^{-\\kappa}}\\\\ &{\\leq\\frac{t_{0}^{1-\\kappa}}{1-\\kappa}\\cdot{\\mathrm{polylog}\\left(t^{-1}t_{0}\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the first inequality holds since we condition on the event $A$ , the second inequality holds due to the definition of $t_{0}$ , the third inequality uses the fact that poly $\\cdot\\mathtt{l o g}(t/\\delta)$ is monotonically increasing for all $t>0$ . ", "page_idx": 15}, {"type": "text", "text": "Then, one can further show ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T}\\leq\\frac{t_{0}^{1-\\kappa}\\cdot\\mathrm{polylog}\\left(\\delta^{-1}t_{0}\\right)}{1-\\kappa}}\\\\ &{\\qquad\\leq\\frac{\\mathrm{polylog}\\left(\\delta^{-1}\\left(\\frac{2c_{0}\\cdot\\mathrm{polylog}\\left(1/\\delta\\right)}{\\Delta}\\right)^{\\frac{1}{\\kappa-z}}\\right)\\cdot\\mathrm{polylog}\\left(\\delta^{-1}t_{0}\\right)}{(\\Delta/2)^{1/\\kappa-1}}}\\\\ &{\\qquad\\qquad\\geq\\frac{\\mathrm{polylog}\\left(\\delta^{-1}\\left(\\frac{2c_{0}\\cdot\\mathrm{polylog}\\left(1/\\delta\\right)}{\\Delta}\\right)^{\\frac{1}{\\kappa-z}}\\right)\\cdot\\mathrm{polylog}\\left(\\delta^{-1}\\left(\\frac{2c_{0}\\cdot\\mathrm{polylog}\\left(1/\\delta\\right)}{\\Delta}\\right)^{\\frac{1}{\\kappa-z}}\\right)}{(\\Delta/2)^{1/\\kappa-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second inequality applies the second term of Eq. (9) and the last inequality uses the first term of Eq. (9). ", "page_idx": 15}, {"type": "text", "text": "Notice that these bounds in all three cases hold for all $T\\in\\mathbb N$ , and thus the proof of gap-dependent bound is complete. ", "page_idx": 15}, {"type": "text", "text": "Gap-independent bound. We have ", "text_level": 1, "page_idx": 15}, {"type": "equation", "text": "$$\nR_{T}=\\sum_{t=1}^{T}\\Delta_{t}\\leq\\sum_{t=1}^{T}\\mathsf{p o l y l o g}(t/\\delta)\\cdot t^{-\\kappa}\\leq\\mathsf{p o l y l o g}(T/\\delta)\\sum_{t=1}^{T}t^{-\\kappa}\\leq\\frac{T^{1-\\kappa}\\cdot\\mathsf{p o l y l o g}(\\delta^{-1}T)}{1-\\kappa}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "For shorthand, we use $\\mathcal{E}$ to denote the event that Eq. (1) holds for all $t\\in\\mathbb{N}$ . From the assumption, $\\mathcal{E}$ holds with probability at least $1-\\delta$ . The following proof is straightforward by the definition of $\\mathcal{E}$ . We conditions on $\\mathcal{E}$ and consider an arbitrary round $t$ . If $A_{t}=a^{\\star}$ , the claim trivially holds as $\\Delta_{A_{t}}=0$ . We then consider $A_{t}\\neq a^{\\star}$ . Since Algorithm 1 pulls an arm $A_{t}\\in\\mathcal A_{t}$ at each $t$ . From the definition of $\\mathcal{E}$ , we have $\\Delta_{A_{t}}\\le\\beta\\cdot f(\\delta,t)$ . Therefore, Algorithm 1 achieves the ULI guarantee with $F_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(f(\\delta,t)\\right)$ . ", "page_idx": 16}, {"type": "text", "text": "D Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "D.1 ULI guarantee for SE-MAB algorithm ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Consider the successive elimination (SE-MAB) algorithm (e.g., Algorithm 3 in [Even-Dar et al., 2006]) in the MAB setting where $\\boldsymbol{A}=[K]$ . We present SE-MAB algorithm in Algorithm 6 and define some notations. Let $N_{a}(t)$ be the number of times that arm $a$ has been pulled before round $t$ and let $\\widehat{\\mu}_{a}(s)$ be the empirical mean of arm $a$ after $s\\in\\mathbb N$ number of plays. We define the confidence width f o r each $s\\in\\mathbb{N}$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{wd}(s)=\\sqrt{\\frac{\\log\\left(4K s^{2}/\\delta\\right)}{2s}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The SE-MAB algorithm always chooses the arm (from the current active arm set) with the minimum number of pulls. If there exist two arms $a,j\\in[K]$ such that $N_{a}(t)=N_{j}(t)$ , then, the algorithm chooses the arm with the smallest index. ", "page_idx": 16}, {"type": "text", "text": "Algorithm 6 Successive elimination for multi-armed bandit (SE-MAB) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Input: confidence $\\delta\\in(0,1)$ .   \nInitialize: active arm set $\\boldsymbol{A}_{1}=[K]$ and sample every arm once to update $N_{a}(K+1),\\widehat{\\mu}_{a}(N_{a}(K+$   \n1)), $\\operatorname{wd}(N_{a}(K+1))$ for all $a\\in[K]$ .   \nfor $t=K+1,K+2,\\dots\\mathbf{d}$ o Play an arm $A_{t}=\\operatorname*{argmin}_{a\\in A_{t}}{N}_{a}(t)$ and observe reward $X_{t,A_{t}}$ . Update counter $N_{a}(t\\!+\\!1)=\\!\\!\\!\\!N_{a}(t)\\!+\\!1$ for $A_{t}=a$ and $N_{a}(t\\!+\\!1)=N_{a}(t)$ for all $a\\in\\mathcal{A}_{t}-\\left\\{A_{t}\\right\\}$ . Update empirical means $\\begin{array}{r}{\\widehat{\\mu}_{A_{t}}(N_{A_{t}}(t+1))=\\frac{\\widehat{\\mu}_{A_{t}}(N_{A_{t}}(t))\\cdot N_{A_{t}}(t)+X_{t,A_{t}}}{N_{A_{t}}(t)+1}}\\end{array}$ and $\\widehat{\\mu}_{a}(N_{a}(t+1))=$ $\\widehat{\\mu}_{a}(N_{a}(t))$ for all $a\\in\\mathcal{A}_{t}-\\left\\{A_{t}\\right\\}$ . Update confidence width $\\mathrm{wd}(N_{a}(t+1))$ based on Eq. (11) for all $a\\in\\mathcal{A}_{t}$ . Update bad arm set $B_{t}$ as $B_{t}=\\{a\\in\\mathcal{A}_{t}:\\exists j\\in\\mathcal{A}_{t}$ such tha $\\widehat{\\mu}_{j}(N_{j}(t+1))-\\mathbf{wd}(N_{j}(t+1))-\\widehat{\\mu}_{a}(N_{a}(t+1))-\\mathbf{wd}(N_{a}(t+1))>0\\right\\}.$ Update active arm set $\\mathcal{A}_{t+1}=\\mathcal{A}_{t}-\\mathcal{B}_{t}$ . ", "page_idx": 16}, {"type": "text", "text": "Definition D.1. Let $\\mathcal{E}$ be the event that $|\\widehat{\\mu}_{a}(N_{a}(t))-\\mu_{a}|\\leq w d(N_{a}(t))$ holds for all $t\\in\\mathbb{N}$ and all $a\\in\\mathcal{A}_{t}$ . ", "page_idx": 16}, {"type": "text", "text": "Lemma D.2. $\\mathbb{P}\\left(\\mathcal{E}\\right)\\geq1-\\delta$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Following the standard trick (e.g., [Audibert et al., 2010]), we rewrite the empirical mean for every $a,n$ as $\\begin{array}{r}{\\widehat{\\mu}_{a}\\check{(}n\\mathscr{)}=\\frac{1}{n}\\sum_{i=1}^{n}R_{i,a}}\\end{array}$ where $R_{i,a}$ is the reward of $i$ -th pull of arm $a$ . Let us fix both $s\\in\\mathbb{N}$ and $a\\in[K]$ . By Hoeffding\u2019s inequality, with probability at least $1-\\delta^{\\prime}$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n|\\widehat{\\mu}_{a}(s)-\\mu_{a}|\\leq\\sqrt{\\frac{\\log{\\left(\\frac{2}{\\delta^{\\prime}}\\right)}}{2s}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Choosing $\\begin{array}{r}{\\delta^{\\prime}\\,=\\,\\frac{\\delta}{2K s^{2}}}\\end{array}$ and applying a union bound over $a\\,\\in\\,\\mathcal{A}_{t}\\,\\left(\\left|\\mathcal{A}_{t}\\right|\\,\\leq\\,K,\\,\\forall t\\right)$ , we have with probability at least $\\dot{1}-\\delta/(2s^{2})$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left|\\widehat{\\mu}_{a}(s)-\\mu_{a}\\right|\\leq\\sqrt{\\frac{\\log\\left(\\frac{4K s^{2}}{\\delta}\\right)}{2s}}=\\mathbf{wd}(s),\\quad\\forall a\\in[K].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We apply a union bound over all $s\\in\\mathbb{N}$ and use the fact that $\\begin{array}{r}{\\sum_{s=1}^{\\infty}\\frac{\\delta}{2s^{2}}\\leq\\delta}\\end{array}$ to finish the proof. ", "page_idx": 17}, {"type": "text", "text": "Lemma D.3. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.1. For all $t\\in\\mathbb{N}$ , $a^{\\star}\\in A_{t}$ holds. ", "page_idx": 17}, {"type": "text", "text": "Proof. We prove this by induction. For $t=1$ , $a^{\\star}\\in\\mathcal{A}_{1}$ trivially holds. Suppose that $a^{\\star}\\in A_{t}$ . To show $a^{\\star}\\in A_{t}$ , it suffices to show that at the end of round $t$ , arm $a^{\\star}$ is deemed as a good arm. One can use the definition of $\\mathcal{E}$ to show that for every $a\\in\\mathcal{A}_{t}$ , the following holds. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\leq\\mu^{\\star}-\\mu_{a}\\leq\\widehat{\\mu}_{a^{\\star}}(N_{a^{\\star}}(t+1))+\\mathbf{wd}(N_{a^{\\star}}(t+1))-\\widehat{\\mu}_{a}(N_{a}(t+1))+\\mathbf{wd}(N_{a}(t+1)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that the second inequality above can hold since the inductive hypothesis gives that $a^{\\star}\\in A_{t}$ . The above inequality shows that $a^{\\star}$ will not be eliminated at the end of round $t$ thereby still being active at round $t+1$ . Once the induction is done, the proof is complete. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Lemma D.4. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.1. For all $t\\in\\mathbb{N}$ and all arms $a\\in A$ if $a\\in\\mathcal{A}_{t}$ , then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Delta_{a}\\le\\sqrt{\\frac{14K\\log{(4K t^{2}/\\delta)}}{t}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Consider any round $t\\in\\mathbb{N}$ and any active arm $a\\in\\mathcal{A}_{t}$ . For simplicity, we assume that the first arm is the unique optimal $\\mathrm{arm}^{7}$ . If $a$ is an optimal arm, then $\\Delta_{a}=0$ and we hold the claim trivially. Then, it suffices to consider an arm $a\\in A_{t}$ with $\\Delta_{a}\\,>\\,0$ . Notice that $\\operatorname{wd}(x)$ is monotonically decreasing for all $x\\geq1$ as long as $K\\ge2$ . Thus, we find a minimum natural number $T_{a}\\in\\mathbb{N}$ such that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Delta_{a}\\ge5\\sqrt{\\frac{\\log{(4K T_{a}^{2}/\\delta)}}{2T_{a}}}=5{\\bf w}\\mathrm{d}(T_{a}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "With this definition, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Delta_{a}<5\\mathrm{wd}(s)\\quad\\forall1\\leq s<T_{a},\\quad\\mathrm{and}\\quad\\Delta_{a}\\geq5\\mathrm{wd}(s)\\quad\\forall s\\geq T_{a}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Recall that $N_{a}(t)$ is the number of plays of arm $a$ before round $t$ . We first show $N_{a}(t)\\leq T_{a}$ . As Algorithm 6 pulls arms in a round-robin fashion, if arm $a$ is pulled for $T_{a}$ times, then, the optimal arm $a^{\\star}$ is also pulled for $T_{a}$ times, thereby $T_{a}=T_{a^{\\star}}$ . From Lemma D.3, optimal arm $a^{\\star}$ is active for all $t\\in\\mathbb{N}$ and thus we can use it as a comparator. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\mu}_{a^{*}}(T_{a^{*}})-\\mathbf{w}\\mathbf{d}(T_{a^{*}})-\\widehat{\\mu}_{a}(T_{a})-\\mathbf{w}\\mathbf{d}(T_{a})}\\\\ &{\\geq\\mu^{\\star}-2\\mathbf{w}\\mathbf{d}(T_{a^{*}})-\\mu_{a}-2\\mathbf{w}\\mathbf{d}(T_{a})}\\\\ &{=\\mu^{\\star}-2\\mathbf{w}\\mathbf{d}(T_{a})-\\mu_{a}-2\\mathbf{w}\\mathbf{d}(T_{a})}\\\\ &{\\geq\\Delta_{a}-2\\times\\frac{\\Delta_{a}}{5}-2\\times\\frac{\\Delta_{a}}{5}}\\\\ &{=\\frac{\\Delta_{a}}{5}}\\\\ &{>0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "According to elimination rule, this inequality shows that arm $a$ will be eliminated after $T_{a}$ pulling times, which suggests that $N_{a}(t)\\leq T_{a}$ . Since the $T_{a}$ is the minimum natural number which holds Eq. (12), we use $N_{a}(t)\\leq T_{a}$ to show ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Delta_{a}<5\\sqrt{\\frac{\\log{\\left(4K(N_{a}(t)-1)^{2}/\\delta\\right)}}{2(N_{a}(t)-1)}}\\leq5\\sqrt{\\frac{\\log{\\left(4K t^{2}/\\delta\\right)}}{2(N_{a}(t)-1)}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inequality follows from the fact that $N_{a}(t)\\leq t$ . Rearranging the above, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nN_{a}(t)\\le1+\\frac{25\\log\\left(4K t^{2}/\\delta\\right)}{2\\Delta_{a}^{2}}\\le\\frac{13\\log\\left(4K t^{2}/\\delta\\right)}{\\Delta_{a}^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Again, as Algorithm 6 pulls arms in a round-robin fashion, we have $t\\leq K(N_{a}(t)+1)$ and show ", "page_idx": 18}, {"type": "equation", "text": "$$\nt\\le K(N_{a}(t)+1)\\le\\frac{14K\\log\\left(4K t^{2}/\\delta\\right)}{\\Delta_{a}^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which gives $\\begin{array}{r}{\\Delta_{a}\\,\\le\\,\\sqrt{\\frac{14K\\log(4K t^{2}/\\delta)}{t}}}\\end{array}$ 14K log(t4Kt2/\u03b4). Conditioning on event E the argument holds for all t \u2208N, which thus completes the proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Proof of Theorem 3.2 for SE-MAB. Once Lemma D.3 and Lemma D.4 hold, Theorem 3.1 gives that for any fixed $\\delta\\in(0,1)$ , SE-MAB achieves the ULI guarantee with a function ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(\\sqrt{\\frac{K\\log\\left(K t/\\delta\\right)}{t}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, the proof of Theorem 3.2 for SE-MAB is complete. ", "page_idx": 18}, {"type": "text", "text": "D.2 ULI guarantee for PE-MAB ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In MAB setting with $\\boldsymbol{A}=[K]$ , we further consider phased elimination algorithm (e.g., Exercise 6.8 of [Lattimore and Szepesv\u00e1ri, 2020]) shown in Algorithm 7 (called PE-MAB). The algorithm proceeds with phases $\\ell=1,2,\\ldots$ , and each phase $\\ell$ includes consecutive rounds, with an exponential increase. In phase $\\ell$ , the algorithm sequentially pulls every arm $a\\in[K]$ for $m_{\\ell}$ times where ", "page_idx": 18}, {"type": "equation", "text": "$$\nm_{\\ell}=\\left\\lceil2^{2\\ell+1}\\log\\left(4K\\ell^{2}/\\delta\\right)\\right\\rceil.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Once all arms are pulled $m_{\\ell}$ times, the algorithm steps into the next phase $\\ell+1$ . The counter $N_{a}(\\ell)$ records the number of times that arm $a$ is pulled in phase $\\ell$ and $\\widehat{\\mu}_{a}(m_{\\ell})$ is the empirical mean by using $m_{\\ell}$ samples only from phase $\\ell$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 7 Phased elimination for multi-armed bandit (PE-MAB) ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Initialize: active arm set $\\boldsymbol{A}_{1}=[K]$ .   \nfor $\\ell=1,2,\\ldots\\mathbf{de}$ o Play every arm $a\\in\\mathcal{A}_{\\ell}$ for $m_{\\ell}$ times and observe corresponding rewards. Update empirical means $\\{\\widehat{\\mu}_{a}(m_{\\ell})\\}_{a\\in A_{\\ell}}$ only using samples from phase $\\ell$ . Update active arm set $A_{\\ell+1}$ as $\\mathcal{A}_{\\ell+1}=\\mathcal{A}_{\\ell}-\\left\\{a\\in\\mathcal{A}_{\\ell}:\\operatorname*{max}_{j\\in\\mathcal{A}_{\\ell}}\\widehat{\\mu}_{j}(m_{\\ell})-\\widehat{\\mu}_{a}(m_{\\ell})>2^{-\\ell}\\right\\}.$ ", "page_idx": 18}, {"type": "text", "text": "Definition D.5. Let $\\mathcal{E}$ be the event that $|{\\widehat{\\mu}}_{a}(m_{\\ell})-\\mu_{a}|\\leq2^{-\\ell-1}$ holds for all $\\ell\\in\\mathbb{N}$ and all $a\\in\\mathcal{A}_{\\ell}$ . ", "page_idx": 18}, {"type": "text", "text": "We first give the following lemmas, whose proof is similar to those of Lemma D.2 and Lemma D.3.   \nLemma D.6. $\\mathbb{P}(\\pmb{\\mathscr{E}})\\geq1-\\delta$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. We first fix both $\\ell\\in\\mathbb{N}$ and $a\\in[K]$ . By Hoeffding\u2019s inequality, with probability at most $\\delta^{\\prime}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n|\\widehat{\\mu}_{a}(m_{\\ell})-\\mu_{a}|\\geq\\sqrt{\\frac{\\log{\\left(\\frac{2}{\\delta^{\\prime}}\\right)}}{2m_{\\ell}}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Choosing $\\begin{array}{r}{\\delta^{\\prime}=\\frac{\\delta}{2K\\ell^{2}}}\\end{array}$ and applying union bounds over $a\\in\\mathcal{A}_{\\ell}$ ( $A_{\\ell}$ is at most $K$ ), with probability at most $\\delta/2\\ell^{2}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left|\\widehat{\\mu}_{a}(m_{\\ell})-\\mu_{a}\\right|\\geq\\sqrt{\\frac{\\log{(4K\\ell^{2}/\\delta)}}{2m_{\\ell}}}=2^{-\\ell-1}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We apply union bounds over all $\\ell\\in\\mathbb{N}$ and use the fact that $\\begin{array}{r}{\\sum_{\\ell=1}^{\\infty}\\frac{\\delta}{2\\ell^{2}}\\le\\delta}\\end{array}$ to finish the proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Lemma D.7. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.5. For all $\\ell\\in\\mathbb{N}$ , $a^{\\star}\\in A_{\\ell}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. We prove this by induction. For the base case $\\ell=1$ , the claim trivially holds. Suppose the claim holds for $\\ell$ , and then we will show that $a\\in A_{\\ell+1}$ . For all $\\ell\\in\\mathbb{N}$ and all $a\\in A_{\\ell}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n0\\leq\\mu^{\\star}-\\mu_{a}\\leq\\widehat{\\mu}_{a^{\\star}}(m_{\\ell})-\\widehat{\\mu}_{a}(m_{\\ell})+2^{-\\ell},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the second inequality holds because the induction hypothesis ensures $a^{\\star}\\in\\mathcal{A}_{\\ell}$ and thus we can use the definition of $\\mathcal{E}$ . Based on the elimination rule, $a^{\\star}\\in\\mathcal{A}_{\\ell+1}$ . Once the induction is done, the proof is complete. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "Lemma D.8. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.5. For each arm a with $\\Delta_{a}>0$ , it will not be in $A_{\\ell}$ for all phases $\\ell\\geq\\ell_{a}+1$ where $\\ell_{a}$ is the smallest phase such that $\\frac{\\Delta_{a}}{2}>2^{-\\ell_{a}}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. Consider any arm $a$ with $\\Delta_{a}\\,>\\,0$ . We only need to consider $a\\in A_{\\ell_{a}}$ and otherwise, the claimed result holds trivially. Recall that $\\ell_{a}$ is the smallest phase such that $\\frac{\\Delta_{a}}{2}>2^{-\\ell_{a}}$ and one can show ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{j\\in\\mathcal{A}_{\\pmb{\\ell}_{a}}}{\\mathrm{max}}\\,\\widehat{\\mu}_{j}(m_{\\ell_{a}})-\\widehat{\\mu}_{a}(m_{\\ell_{a}})-2^{-\\ell_{a}}}\\\\ &{\\geq\\widehat{\\mu}_{a}\\star(m_{\\ell_{a}})-\\widehat{\\mu}_{a}(m_{\\ell_{a}})-2^{-\\ell_{a}}}\\\\ &{\\geq\\mu^{\\star}-2^{-\\ell_{a}}-\\mu_{a}-2^{-\\ell_{a}}}\\\\ &{>\\Delta_{a}-2\\times\\frac{\\Delta_{a}}{2}}\\\\ &{=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first inequality follows from Lemma D.7 that $a^{\\star}\\in\\mathcal{A}_{\\ell_{a}}$ and the second inequality holds due to $\\mathcal{E}$ . ", "page_idx": 19}, {"type": "text", "text": "According to the elimination rule, arm $a$ will not be in phases $\\ell$ for all $\\ell\\geq\\ell_{a}+1$ . ", "page_idx": 19}, {"type": "text", "text": "Lemma D.9. Let $\\ell(t)$ be the phase in which round $t$ lies. Then, $\\ell(t)\\leq\\log_{2}(t+1).$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. We prove this by contradiction. Suppose that $\\exists t\\in\\mathbb{N}$ that $\\ell(t)>\\log_{2}(t\\!+\\!1)$ . Note that we can further assume $\\ell(t)\\geq2$ since one can easily verify that for all $t$ such that $\\ell(\\bar{t})=1,\\ell(t)\\leq\\log_{2}(t+1)$ must hold. We have ", "page_idx": 19}, {"type": "equation", "text": "$$\nt\\geq m_{\\ell(t)-1}\\geq2^{2\\ell(t)-1}\\log\\left(4K(\\ell(t)-1)^{2}/\\delta\\right)>\\frac12(t+1)^{2}\\log\\left(4K/\\delta\\right)>t,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the third inequality bounds $\\ell(t)$ in the logarithmic term by $\\ell(t)\\,\\geq\\,2$ and bound the other $\\ell(t)>\\log_{2}(t+1)$ by assumption. Therefore, once a contradiction occurs, the proof is complete. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.10. Let $\\ell(t)$ be the phase in which round $t$ lies. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.5. For all $t\\in\\mathbb{N}$ and all $a\\in[K].$ , if $a\\in A_{\\ell(t)}$ , then ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Delta_{a}\\leq\\sqrt{\\frac{256K\\log\\left(4K\\left(\\log_{2}(t+1)\\right)^{2}/\\delta\\right)}{3t}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. If $a\\in\\mathcal{A}_{\\ell(t)}$ is optimal, then, $\\Delta_{a}=0$ and the claim trivially holds. In what follows, we only consider arm $a\\in\\mathcal{A}_{\\ell(t)}$ with $\\Delta_{a}>0$ . From Lemma D.8, if an arm $a\\in\\mathcal{A}_{\\ell(t)}$ is with $\\Delta_{a}>0$ , then, $\\ell(t)\\leq\\ell_{a}$ where $\\ell_{a}$ is defined in Lemma D.8. Thus, the total number of rounds that such an arm $a$ is active is at most ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K\\displaystyle\\sum_{s=1}^{\\ell(t)}m_{s}=K\\displaystyle\\sum_{s=1}^{\\ell(t)}\\left\\lceil2^{2s+1}\\log\\left(4K s^{2}/\\delta\\right)\\right\\rceil}\\\\ {\\le4K\\log\\left(4K\\ell(t)^{2}/\\delta\\right)\\displaystyle\\sum_{s=1}^{\\ell(t)}2^{2s}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq4K\\log\\big(4K\\ell(t)^{2}/\\delta\\big)\\displaystyle\\sum_{s=1}^{\\ell_{a}}2^{2s}}\\\\ &{\\leq\\frac{16K\\log\\big(4K\\ell(t)^{2}/\\delta\\big)}{3}\\cdot4^{\\ell_{a}}}\\\\ &{\\leq\\frac{256K\\log\\big(4K\\ell(t)^{2}/\\delta\\big)}{3\\Delta_{a}^{2}}}\\\\ &{\\leq\\frac{256K\\log\\big(4K\\log_{2}(t+1)\\big)^{2}/\\delta\\big)}{3\\Delta_{a}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the first inequality follows from $[x]\\ \\leq\\ 2x$ for all $x\\,\\geq\\,1$ , the second inequality bounds $\\ell(t)\\leq\\ell_{a}$ , the fourth inequality follows from the definition of $\\ell_{a}$ , i.e., $\\begin{array}{r}{\\frac{\\Delta_{a}}{2}\\leq2^{-(\\ell_{a}-1)}}\\end{array}$ , and the last inequality follows from Lemma D.9 that $\\ell(t)\\leq\\log_{2}(t+1)$ . ", "page_idx": 20}, {"type": "text", "text": "Since this argument holds for each round $t$ and each arm $a\\in\\mathcal{A}_{\\ell(t)}$ conditioning on $\\mathcal{E}$ , the proof is complete. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 3.2 for PE-MAB. Once Lemma D.7 and Lemma D.10 hold, Theorem 3.1 gives that for any fixed $\\delta\\in(0,1)$ , PE-MAB achieves the ULI guarantee with a function ", "page_idx": 20}, {"type": "equation", "text": "$$\nF_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(t^{-\\frac{1}{2}}\\sqrt{K\\log\\left(K\\log(t+1)/\\delta\\right)}\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, the proof of Theorem 3.2 for PE-MAB is complete. ", "page_idx": 20}, {"type": "text", "text": "D.3 ULI guarantee for PE-linear ", "text_level": 1, "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}_{\\ell}}\\|a\\|_{G_{\\ell}^{-1}}^{2}\\leq2d,\\quad\\mathrm{and}\\quad|\\mathrm{supp}(\\pi_{\\ell})|\\leq4d\\log\\log(d)+16,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n{\\widehat{\\theta}}_{\\ell}=V_{\\ell}^{-1}\\sum_{t\\in{\\mathcal{T}}_{\\ell}}A_{t}X_{t,A_{t}},\\quad{\\mathrm{where}}\\quad V_{\\ell}=\\sum_{a\\in A_{\\ell}}m_{\\ell}(a)a a^{\\top}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Update active arm set ", "page_idx": 20}, {"type": "equation", "text": "$$\nA_{\\ell+1}=A_{\\ell}-\\left\\{a\\in\\mathcal{A}_{\\ell}:\\operatorname*{max}_{b\\in\\mathcal{A}_{\\ell}}\\left\\langle\\widehat{\\theta}_{\\ell},b-a\\right\\rangle>2^{-\\ell+1}\\right\\}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We consider a phased elimination algorithm (e.g., algorithm in Chapter 22 of [Lattimore and Szepesv\u00e1ri, 2020]) for linear bandits setting with a finite arm set $\\boldsymbol{A}=[K]$ . The algorithm proceeds with phases $\\ell=1,2,\\ldots$ and in each phase $\\ell$ , the algorithm first computes a design $\\pi_{\\ell}\\in\\Delta(\\mathcal{A}_{\\ell})$ over all active arms where $\\Delta(\\mathcal{A}_{\\ell})$ is the set of all Radon probability measures over set $A_{\\ell}$ . Rather than computing an exact design in [Lattimore and Szepesv\u00e1ri, 2020], we follow Lattimore et al. [2020] to compute a nearly-optimal design (13), which can be efficiently implemented. Then, PE-linear plays each arm $a\\in\\mathcal{A}_{\\ell}$ for $m_{\\ell}(a)$ times and updates the active arm set by using the estimates in this phase. ", "page_idx": 20}, {"type": "text", "text": "Let us define $\\tau_{\\ell}$ be a set that contains all rounds in phase $\\ell$ and ", "page_idx": 20}, {"type": "equation", "text": "$$\nm_{\\ell}(a)=\\left\\lceil\\pi_{\\ell}(a)m_{\\ell}\\right\\rceil,\\quad\\mathrm{where}\\quad m_{\\ell}=\\frac{4d}{2^{-2\\ell}}\\operatorname*{max}\\left\\{\\log\\left(4K\\ell^{2}/\\delta\\right),\\log\\log d+4\\right\\}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.11. For all $\\ell\\in\\mathbb{N}$ and all $a\\in\\mathcal{A}_{\\ell}$ , $\\begin{array}{r}{\\|a\\|_{V_{\\ell}^{-1}}^{2}\\leq\\frac{2d}{m_{\\ell}}}\\end{array}$ holds. ", "page_idx": 21}, {"type": "text", "text": "Proof. For each $\\ell\\in\\mathbb{N}$ and $a\\in\\mathcal{A}_{\\ell}$ , one can show ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|a\\|_{V_{\\ell}^{-1}}^{2}=a^{T}V_{\\ell}^{-1}a\\le a^{T}\\left(m_{\\ell}\\sum_{a\\in\\mathcal{A}_{\\ell}}\\pi_{\\ell}(a)a a^{\\top}\\right)^{-1}a\\le\\frac{2d}{m_{\\ell}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the first inequality follows from Eq. (15) and the fact that if we let $\\begin{array}{r}{A=m_{\\ell}\\sum_{a\\in A_{\\ell}}\\pi_{\\ell}(a)a a^{\\top}}\\end{array}$ and $B\\,=\\,V_{\\ell}$ then, $\\|a\\|_{A^{-1}}\\,\\geq\\,\\|a\\|_{B^{-1}}$ holds since $A^{-1}\\,\\succeq\\,B^{-1}$ and the second inequality uses Eq. (13). \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Definition D.12. Let $\\mathcal{E}$ be the event that $\\left|\\left\\langle\\widehat{\\theta}_{\\ell}-\\theta,a\\right\\rangle\\right|\\leq2^{-\\ell}$ holds for all $\\ell\\in\\mathbb{N}$ and all $a\\in\\mathcal{A}_{\\ell}$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma D.13. $\\mathbb{P}(\\pmb{\\mathscr{E}})\\geq1-\\delta$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Consider a fixed phase $\\ell$ and a fixed arm $a\\in\\mathcal{A}_{\\ell}$ . We start from the following decomposition. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\langle\\widehat{\\theta}_{\\ell}-\\theta,a\\right\\rangle=\\left\\langle V_{\\ell}^{-1}\\displaystyle\\sum_{t\\in\\mathcal{T}_{\\ell}}A_{t}X_{t,A_{t}}-\\theta,a\\right\\rangle}\\\\ &{\\qquad\\quad=\\left\\langle V_{\\ell}^{-1}\\displaystyle\\sum_{t\\in\\mathcal{T}_{\\ell}}A_{t}\\left(A_{t}^{T}\\theta+\\eta_{t}\\right)-\\theta,a\\right\\rangle}\\\\ &{\\qquad\\quad=\\left\\langle V_{\\ell}^{-1}\\displaystyle\\sum_{t\\in\\mathcal{T}_{\\ell}}A_{t}\\eta_{t},a\\right\\rangle}\\\\ &{\\qquad\\quad=\\displaystyle\\sum_{t\\in\\mathcal{T}_{\\ell}}\\left\\langle V_{\\ell}^{-1}A_{t},a\\right\\rangle\\eta_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By Eq. (20.2) of [Lattimore and Szepesv\u00e1ri, 2020], we have with probability at least $1-\\delta/(2\\ell^{2}K)$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\left\\langle\\widehat{\\theta}_{\\ell}-\\theta,a\\right\\rangle\\right|=\\left|\\sum_{t\\in\\mathcal{T}_{\\ell}}\\left\\langle V_{\\ell}^{-1}A_{t},a\\right\\rangle\\eta_{t}\\right|\\leq\\sqrt{2\\left\\lVert a\\right\\rVert_{V_{\\ell}^{-1}}^{2}\\log(4\\ell^{2}K/\\delta)}\\le2\\sqrt{\\frac{d\\log(4\\ell^{2}K/\\delta)}{m_{\\ell}}}\\le2^{-\\ell},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last inequality applies Lemma D.11. Finally, applying union bounds over all $a,\\ell$ completes the proof. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Lemma D.14. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.12. We have $a^{\\star}\\in\\mathcal{A}_{\\ell}$ for all $\\ell\\in\\mathbb{N}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. This can be proved by using induction on $\\ell$ via the same reasoning of Lemma D.3. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.15. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition D.12. For each arm a with $\\Delta_{a}\\,>\\,0,$ , it will not be in $A_{\\ell}$ for all phases $\\ell\\geq\\ell_{a}+1$ where $\\ell_{a}$ is the smallest phase such that $\\begin{array}{r}{\\frac{\\Delta_{a}}{4}>2^{-\\ell_{a}}}\\end{array}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Consider any arm $a$ with $\\Delta_{a}>0$ . Let $\\ell_{a}$ be the smallest phase such that $\\frac{\\Delta_{a}}{4}>2^{-\\ell_{a}}$ and we have   \nma $\\mathrm{~s\\!\\!\\!\\!\\:}_{a}\\left\\langle\\widehat{\\theta}_{\\ell_{a}},b-a\\right\\rangle-2^{-\\ell_{a}+1}\\ge\\left\\langle\\widehat{\\theta}_{\\ell_{a}},a^{\\star}-a\\right\\rangle-2^{-\\ell_{a}+1}\\ge\\langle\\theta,a^{\\star}-a\\rangle-2^{-\\ell_{a}+2}>\\Delta_{a}-4\\times\\frac{\\Delta_{a}}{4}=0,$ , b\u2208A\u2113a   \nwhere the first inequality follows from Lemma D.14 that $a^{\\star}\\in A_{\\ell}$ for all $\\ell$ .   \nAccording to the elimination rule, arm $a$ will not be in $A_{\\ell}$ for all phases $\\ell\\geq\\ell_{a}\\!+\\!1$ . Since conditioning on $\\mathcal{E}$ , this argument holds for every arm $a$ , the proof is complete. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Lemma D.16. Let $\\ell(t)$ be the phase in which round $t$ lies. Then, $\\ell(t)\\leq\\log_{2}(t+1)$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. We prove this by contradiction. Suppose that $\\exists t\\in\\mathbb{N}$ that $\\ell(t)>\\log_{2}(t\\!+\\!1)$ . Note that we can further assume $\\ell(t)\\geq2$ since one can easily verify that for all $t$ such that $\\ell(\\bar{t})\\,=1,\\ell(t)\\le\\log_{2}(t\\!+\\!1)$ must hold. We have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t\\geq\\displaystyle\\sum_{a\\in A_{\\ell(t)-1}}\\left\\lceil\\pi_{\\ell(t)-1}m_{\\ell(t)-1}\\right\\rceil}\\\\ &{\\ge m_{\\ell(t)-1}\\ge\\displaystyle\\frac{4d}{2^{-2(\\ell(t)-1)}}\\left(\\log\\left(4K(\\ell(t)-1)^{2}/\\delta\\right)\\right)>d(t+1)^{2}\\log\\left(4K/\\delta\\right)>t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the fourth inequality bounds $\\ell(t)$ in the logarithmic term by $\\ell(t)\\geq2$ and bound the other $\\ell(t)>\\log_{2}(t+1)$ by assumption. Therefore, once a contradiction occurs, the proof is complete. ", "page_idx": 22}, {"type": "text", "text": "Lemma D.17. Let $\\ell(t)$ be the phase in which round $t$ lies. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is given in Definition $D.I2$ . For all $t\\in\\mathbb{N}$ and all $a\\in[K]$ , $i f a\\in\\mathcal{A}_{\\ell(t)}$ , then ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Delta_{a}\\leq\\sqrt{\\frac{512d\\log\\left(4\\log(d)K\\left(\\log_{2}(t+1)\\right)^{2}/\\delta\\right)+4}{3t}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. If $a\\in\\mathcal{A}_{\\ell(t)}$ is optimal, then, $\\Delta_{a}=0$ and the claim trivially holds. In what follows, we only consider arm $a\\in\\dot{\\mathcal{A}}_{\\ell(t)}$ with $\\Delta_{a}>0$ . From Lemma D.15, if an arm $a\\in\\mathcal{A}_{\\ell(t)}$ is with $\\Delta_{a}>0$ , then, $\\ell(t)\\leq\\ell_{a}$ where $\\ell_{a}$ is defined in Lemma D.15. Then, the total number of rounds that such an arm $a$ is active is at most ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{|\\langle t\\rangle|}{2-\\omega_{\\mathrm{L}}\\omega_{z}(a)\\gamma}}\\\\ &{:=\\cfrac{\\langle t\\rangle|}{1-\\omega_{\\mathrm{L}}\\omega_{z}(a)\\gamma}\\left[\\pi_{*}(a)m_{*}\\right]}\\\\ &{\\leq\\cfrac{\\langle t\\rangle|}{1-\\omega_{\\mathrm{L}}\\omega_{\\mathrm{L}}(a)\\gamma}\\cfrac{2\\langle t\\rangle+16+\\displaystyle\\sum_{a\\in A_{*},\\,\\gamma\\in(a)\\gamma}\\pi_{*}(a)m_{*}\\rangle}{\\gamma}}\\\\ &{\\leq2\\,\\sum_{s=1}^{t-\\omega_{\\mathrm{L}}\\omega_{s}}}\\\\ &{\\leq8d\\operatorname*{max}\\left\\{\\log(4K(t)^{2}/\\beta),\\,\\log\\log d+4\\right\\}\\underset{s=1}{\\overset{t}{\\sum}}\\frac{1}{2-2s}}\\\\ &{\\leq8d\\operatorname*{max}\\left\\{\\log\\left(4K(\\log_{2}(t+1))^{2}/\\beta\\right),\\,\\log\\log d+4\\right\\}\\underset{s=1}{\\overset{t}{\\sum}}\\frac{1}{2-2s}}\\\\ &{\\leq\\frac{512d}{3\\Delta^{2}}\\left(\\log\\left(4\\log(\\log_{2}(t+1))^{2}/\\beta\\right)+4\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first inequality applies $\\lceil\\pi_{s}(a)m_{s}\\rceil\\leq\\pi_{s}(a)m_{s}+1$ and Eq. (13), the second inequality uses the definition of $m_{s}$ (see Eq. (15)), the fourth inequality follows from $\\ell(t)\\leq\\ell_{a}$ and Lemma D.16 gives $\\ell(t)\\leq\\log_{2}(t+1)$ , and the last inequality uses $\\begin{array}{r}{\\frac{\\Delta\\dot{a}}{4}\\leq2^{-(\\ell_{a}-1)}}\\end{array}$ to apply $\\ell_{a}\\leq\\log_{2}\\left(8/\\Delta_{a}\\right)$ . ", "page_idx": 22}, {"type": "text", "text": "Since this argument holds for each round $t$ and each arm $a\\in\\mathcal{A}_{\\ell(t)}$ conditioning on $\\mathcal{E}$ , the proof is complete. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Proof of Theorem 3.2 for PE-linear. Once Lemma D.14 and Lemma D.17 hold, Theorem 3.1 gives that for any fixed $\\delta\\in(0,1)$ , PE-linear achieves the ULI guarantee with a function ", "page_idx": 22}, {"type": "equation", "text": "$$\nF_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(t^{-\\frac{1}{2}}\\sqrt{d\\log\\left(\\log(d)K\\left(\\log(t+1)\\right)/\\delta\\right)}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, the proof of Theorem 3.2 for PE-linear is complete. ", "page_idx": 22}, {"type": "text", "text": "E Omitted Details of Section 3.2 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The bonus function that we here consider for lil\u2019UCB is as: ", "page_idx": 23}, {"type": "equation", "text": "$$\nU_{\\delta}(x)=\\sqrt{\\frac{\\log\\log\\left(\\operatorname*{max}\\left\\{x,e\\right\\}\\right)+\\log\\left(6/\\delta\\right)}{x}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The choice of $U_{\\delta}(x)$ in Eq. (16) is slightly different from that of [Jamieson et al., 2014] because we consider for any $\\dot{\\delta}\\in(0,1)$ and they constrain the choice of $\\delta$ in a more restricted range. The choice of $U_{\\delta}(x)$ is motivated from another lemma of law of iterated logarithm, given in [Dann et al., 2017, Lemma F.1] with $\\sigma^{2}=1/4$ as we here consider $[0,1]$ -bounded rewards. Note that the concentration bounds in [Dann et al., 2017] apply for the conditionally subgaussian random variables, and one can get the same result for i.i.d. subgaussian random variables, by simply replacing the Doob\u2019s maximal inequality by Hoeffding\u2019s maximal inequality (see [Jamieson et al., 2014, Lemma 3]). ", "page_idx": 23}, {"type": "text", "text": "One caveat here is that our analysis still works for other choices of $U_{\\delta}(x)$ if one adjust constant or change $\\log\\log(\\cdot)$ to $\\log(\\cdot)$ . ", "page_idx": 23}, {"type": "text", "text": "Algorithm 9 lil\u2019UCB ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Input: confidence $\\delta\\in(0,1)$ and arm set $\\boldsymbol{\\mathcal{A}}$ .   \nInitialize: play each arm $a\\in A$ once to update $N_{a}(|A|+1)$ and $\\widehat{\\mu}_{a}(N_{a}(|A|+1))$ for all $a\\in A$ .   \nfor $t=|A|+^{\\cdot}1,|A|+2,\\ldots$ do   \nPlay an arm $A_{t}=\\underset{a\\in\\mathcal{A}}{\\mathrm{argmax}}\\left\\{\\widehat{\\mu}_{a}(N_{a}(t))+U_{\\delta}\\left(N_{a}(t)\\right)\\right\\},$ where $U_{\\delta}(N_{a}(t))$ is given in Eq. (16). Update counters $N_{a}(t+1)=N_{a}(t)+1$ for $A_{t}=a$ and $N_{a}(t+1)=N_{a}(t)$ for all $a\\neq A_{t}$ . Update empirical means $\\begin{array}{r}{\\widehat{\\mu}_{A_{t}}(N_{A_{t}}(t+1))=\\frac{\\widehat{\\mu}_{A_{t}}(N_{A_{t}}(t))\\cdot N_{A_{t}}(t)+\\bar{X}_{t,A_{t}}}{N_{A_{t}}(t)+1}}\\end{array}$ and $\\widehat{\\mu}_{a}(N_{a}(t+1))=$ $\\widehat{\\mu}_{a}(N_{a}(t))$ for all $a\\in\\mathcal{A}-\\{A_{t}\\}$ . ", "page_idx": 23}, {"type": "text", "text": "E.1 Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In the following proof, we consider the following instance. ", "page_idx": 23}, {"type": "text", "text": "Definition E.1 (Two-armed bandit instance). Consider a two-armed setting with $\\mu_{1}~>~\\mu_{2}$ . In each round, each arm generates deterministic rewards $\\mu_{1}$ and $\\mu_{2}$ , respectively. The arm gap is $\\Delta=\\mu_{1}-\\mu_{2}$ and $\\Delta\\in(0,0.6)$ . ", "page_idx": 23}, {"type": "text", "text": "According to Lemma E.2, the total number of plays of arm 2 is finite. Therefore, one can find a round $t_{0}\\in\\mathbb{N}$ that the last play of arm 2 occurs. At the beginning of this round, the algorithm compares $\\mu_{1}+U_{\\delta}(N_{1}(t_{0}))$ and $\\dot{\\mu_{2}}+U_{\\delta}(N_{2}(t_{0}))$ . Since arm 2 gets the last play at this round, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mu_{1}+U_{\\delta}(N_{1}(t_{0}))\\leq\\mu_{2}+U_{\\delta}(N_{2}(t_{0}))\\leq\\mu_{2}+(1+f(\\Delta))\\Delta,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the last inequality holds due to Lemma E.4 and $f(\\Delta)$ is defined as ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(\\Delta):=\\Delta\\cdot\\frac{\\sqrt{3}}{\\sqrt{\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Rearranging the above, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\nU_{\\delta}(N_{1}(t_{0}))\\leq f(\\Delta)\\Delta,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which immediately leads to ", "page_idx": 23}, {"type": "equation", "text": "$$\nN_{1}(t_{0})\\geq\\frac{\\log\\log\\left(\\frac{\\log(6/\\delta)}{f^{2}(\\Delta)\\Delta^{2}}\\right)+\\log(6/\\delta)}{f^{2}(\\Delta)\\Delta^{2}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Moreover, since arm 2 is played at round $t_{0}$ , $\\Delta=\\Delta_{A_{t_{0}}}$ , which further implies that ", "page_idx": 23}, {"type": "equation", "text": "$$\nt_{0}=N_{1}(t_{0})+N_{2}(t_{0})\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{>N_{1}(t_{0})}\\\\ &{>\\frac{\\log\\log\\left(\\frac{\\log(\\6/\\delta)}{f^{2}(\\Delta)\\Delta^{2}}\\right)+\\log(6/\\delta)}{f^{2}(\\Delta)\\Delta^{2}}}\\\\ &{\\geq\\frac{\\left(\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)\\right)^{2}}{3\\Delta^{4}}}\\\\ &{=\\frac{\\left(\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)\\right)^{2}}{3\\Delta_{A_{0}}^{4}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the third inequality uses $f(\\Delta)\\leq1$ for all $\\Delta\\in(0,0.6)$ , and the last equality holds due to $\\Delta=\\Delta_{A_{t_{0}}}$ (recall that in round $t_{0}$ , arm 2 gets the last play). ", "page_idx": 24}, {"type": "text", "text": "Rearranging the above, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\Delta_{A_{t_{0}}}>\\frac{\\sqrt{\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}{(3t_{0})^{\\frac{1}{4}}}=\\sqrt{\\frac{(3t_{0})^{\\frac{1}{2}}\\left(\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)\\right)}{3t_{0}}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Finally, by Lemma E.3, we have $t_{0}=\\Omega(\\Delta^{-2})$ , which completes the proof. ", "page_idx": 24}, {"type": "text", "text": "E.2 Proof of Supporting Lemmas ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Lemma E.2. Suppose that we run Algorithm 9 for the two-armed bandit instance given in Definition E.1. For any $\\delta\\in(0,1)$ , suboptimal arm 2 will be played at most ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left\\lceil\\frac{2\\left(\\log\\log\\left(\\frac{16\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log(6/\\delta)\\right)}{\\Delta^{2}}\\right\\rceil.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Note that for any fixed $\\delta\\in(0,1)$ , function $U_{\\delta}(x)$ is monotonically-decreasing for $x\\geq6$ . To show the claimed result, it suffices to find an integer $x\\geq6$ such that ", "page_idx": 24}, {"type": "equation", "text": "$$\nU_{\\delta}(x)<\\Delta.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Now, we consider the following choice. ", "page_idx": 24}, {"type": "equation", "text": "$$\nN=\\lceil n\\rceil\\,,\\quad\\mathrm{where}\\quad n=\\frac{2\\left(\\log\\log\\left(\\frac{16\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)\\right)}{\\Delta^{2}}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Notice that $N\\geq n\\geq6$ for all $\\Delta\\in(0,1]$ . Then, one can show ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{V}_{\\delta}(N)\\leq U_{\\delta}(n)}\\\\ &{\\qquad=\\Delta\\cdot\\sqrt{\\frac{\\log\\log\\left(\\frac{2(\\log\\log(\\frac{1+\\log(\\theta/\\delta)}{\\delta})+\\log(\\theta/\\delta))}{\\Delta^{2}}\\right)+\\log(6/\\delta)}{2\\log\\log\\left(\\frac{\\log(\\theta/\\delta)}{\\Delta^{2}}\\right)}+2\\log(6/\\delta)}}\\\\ &{\\qquad\\leq\\Delta\\cdot\\sqrt{\\frac{\\log\\log\\left(\\frac{4\\log\\log(\\frac{(1+\\log(\\theta/\\delta))}{\\delta^{2}})\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}{2\\log\\log\\left(\\frac{1+\\log(6/\\delta)}{\\Delta^{2}}\\right)}}}\\\\ &{\\qquad=\\Delta\\cdot\\sqrt{\\frac{\\log\\left(\\log\\left(\\frac{1}{4}\\log\\log\\left(\\frac{\\left|4\\log(6/\\delta)\\right|}{\\Delta^{2}}\\right)\\right)+1\\log\\left(\\frac{16\\log(6/\\delta)}{\\Delta^{2}}\\right)\\right)+\\log\\left(6/\\delta\\right)}{2\\log\\log\\left(\\frac{\\left|4\\log(6/\\delta)\\right|}{\\Delta^{2}}\\right)+2\\log\\left(6/\\delta\\right)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\Delta\\cdot\\sqrt{\\frac{2\\log\\log\\left(\\frac{16\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log\\left(6/\\delta\\right)}{2\\log\\log\\left(\\frac{16\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+2\\log(6/\\delta)}}}\\\\ &{\\leq\\Delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality uses the fact that for any fixed $\\delta\\in(0,1),U_{\\delta}(x)$ is monotonically-decreasing for $x\\ \\geq\\ 6$ , the second inequality uses $x+y\\,\\leq\\,2x y$ for all $x,y\\ >\\ 1$ (here $x\\,=\\,\\log(6/\\delta)$ and $\\begin{array}{r}{y=\\log\\log\\left(\\frac{16\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right))}\\end{array}$ , the last inequality first bounds $\\begin{array}{r}{\\frac{1}{4}\\log\\log\\left(\\frac{16\\log(6/\\delta)}{\\Delta^{2}}\\right)\\leq\\frac{16\\log(6/\\delta)}{\\Delta^{2}}}\\end{array}$ and then uses $2x\\leq x^{2}$ for all $x\\geq2$ with $\\begin{array}{r}{x=\\log\\left(\\frac{16\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)\\geq2}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "Thus, the proof is complete. ", "page_idx": 25}, {"type": "text", "text": "From Lemma E.2, the total number of plays of suboptimal arm is finite. Based on this fact, we present the following lemmas. ", "page_idx": 25}, {"type": "text", "text": "Lemma E.3. Suppose that we run Algorithm 9 for the two-armed bandit instance given in Definition E.1. Let $n+1$ be the total number of plays of arm 2. Then, ", "page_idx": 25}, {"type": "equation", "text": "$$\nn\\geq\\left\\lfloor\\frac{\\log\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}{\\Delta^{2}}\\right\\rfloor\\geq6.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. For shorthand, we define ", "page_idx": 25}, {"type": "equation", "text": "$$\nm=\\frac{\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}{\\Delta^{2}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "With this definition and $\\Delta\\in(0,0.6)$ , we have $m\\geq6$ and $\\lfloor m\\rfloor\\geq6$ . ", "page_idx": 25}, {"type": "text", "text": "Now, we show that $n~\\geq~\\lfloor m\\rfloor$ . To this end, it suffices to show $U_{\\delta}(\\lfloor m\\rfloor)\\;>\\;\\Delta$ . As $U_{\\delta}(x)$ is monotonically-decreasing for all $x\\geq6$ and $m\\geq\\lfloor m\\rfloor\\geq6$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{\\delta}(\\lfloor m\\rfloor)\\ge U_{\\delta}(m)}\\\\ &{\\quad\\quad\\quad=\\Delta\\cdot\\sqrt{\\frac{\\log\\log\\left(\\frac{\\log\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log\\left(6/\\delta\\right)}{\\log\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log\\left(6/\\delta\\right)}}}\\\\ &{\\quad\\quad\\quad\\quad\\ge\\Delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the last inequality holds as $\\begin{array}{r}{\\frac{\\log(6/\\delta)}{\\Delta^{2}}>\\frac{\\log(6)}{\\Delta^{2}}>e}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "Once $U_{\\delta}(\\lfloor m\\rfloor)>\\Delta$ holds, $\\lfloor m\\rfloor$ cannot be the last play of arm 2 (i.e., at least the one before the last), which completes the proof. \u53e3 ", "page_idx": 25}, {"type": "text", "text": "Lemma E.4. Suppose that we run Algorithm 9 for the two-armed bandit instance given in Definition E.1. Let $n+1$ be the total number of plays of arm 2. The following holds. ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U_{\\delta}(n)\\leq\\Delta\\left(1+\\Delta\\sqrt{\\frac{3}{\\log\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. From Lemma E.3, we have $n\\geq6$ , and thus $U_{\\delta}(n)\\geq U_{\\delta}(n+1)$ a\u221as $U_{\\delta}(x)$ is monotonically decreasing for all $x\\geq6$ . Using the fact that for all $a\\ge b\\ge0$ , $a-b\\leq\\sqrt{a^{2}-b^{2}}$ (here $a=U_{\\delta}(n)$ and $b=U_{\\delta}(n+1)$ ), one can show that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{\\delta}(n)-U_{\\delta}(n+1)}\\\\ &{=\\sqrt{\\cfrac{\\log\\log\\left(\\operatorname*{max}\\{n,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n}}-\\sqrt{\\cfrac{\\log\\log\\left(\\operatorname*{max}\\{n+1,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n+1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\sqrt{\\frac{\\log\\log\\left(\\operatorname*{max}\\{n,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n}-\\frac{\\log\\log\\left(\\operatorname*{max}\\{n+1,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n+1}}}\\\\ &{=\\sqrt{\\frac{(n+1)\\log\\log\\left(\\operatorname*{max}\\{n,e\\}\\right)-n\\log\\log\\left(\\operatorname*{max}\\{n+1,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n(n+1)}}}\\\\ &{\\leq\\sqrt{\\frac{\\log\\log\\left(\\operatorname*{max}\\{n,e\\}\\right)+\\log\\left(6/\\delta\\right)}{n(n+1)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Since for any fixed $\\delta\\in(0,1)$ , $U_{\\delta}(x)$ is monotonically-decreasing for all $x\\geq6$ , and thus by using the definition of $m$ (see Eq. (18)), one can show that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{i}(n)-U_{i}(n+1)}\\\\ &{\\leq\\sqrt{\\frac{\\log(\\log(n))+\\log(6/\\delta)}{|n|(n)+1}}}\\\\ &{\\leq\\sqrt{\\frac{\\log(\\log(n))+\\log(6/\\delta)}{|n|(n)+1}}}\\\\ &{=\\frac{\\sum_{j=1}^{n}\\log(\\frac{n}{\\delta})}{\\log(\\log(\\frac{\\log(j)}{\\delta}))+\\log(6/\\delta)}\\cdot\\sqrt{\\log\\left(\\frac{\\log\\log\\left(\\frac{6\\log(n)}{\\delta}\\right)+\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}\\\\ &{\\leq\\frac{\\Delta^{2}}{\\log\\log\\left(\\frac{\\log(n)}{\\delta}\\right)+\\log(6/\\delta)}\\cdot\\sqrt{\\log\\left(2\\log\\left(\\frac{\\log(\\beta)}{\\delta}\\right)\\right)+\\log(6/\\delta)}}\\\\ &{\\leq\\frac{\\Delta^{2}}{\\log\\log\\left(\\frac{\\log(n)}{\\delta}\\right)+\\log(6/\\delta)}\\cdot\\sqrt{3\\log\\log\\left(\\frac{\\log(\\beta)}{\\delta}\\right)+\\log(6/\\delta)}}\\\\ &{\\leq\\frac{\\sqrt{3\\Delta^{2}}}{\\sqrt{\\log\\log\\left(\\frac{\\log(n)}{\\delta}\\right)+\\log(6/\\delta)}}\\cdot\\sqrt{3\\log\\log\\left(\\frac{\\log(\\beta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}\\\\ &{\\leq\\frac{\\sqrt{3\\Delta^{2}}}{\\sqrt{\\log\\log\\left(\\frac{\\log(n)}{\\delta}\\right)+\\log(6/\\delta)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the first inequality uses Eq. (19) with $n\\geq\\lfloor m\\rfloor\\geq e$ and $U_{\\delta}(x)$ is monotonically decreasing for all $x~\\ge~6$ , the second inequality upper-bounds $\\lfloor m\\rfloor\\,\\leq\\,m$ in numerator and lower-bounds $\\lfloor m\\rfloor\\left(\\lfloor m\\rfloor+1\\right)\\geq m^{2}$ , the third inequality follows from ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\frac{\\log\\log\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}{\\Delta^{2}}\\leq\\frac{\\frac{\\log(6/\\delta)}{\\Delta^{2}}+\\log(6/\\delta)}{\\Delta^{2}}\\leq\\left(\\frac{\\log(6/\\delta)}{\\Delta^{2}}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and the fourth inequality follows $2x\\leq x^{3}$ for all $x\\ge\\sqrt{2}$ with $\\begin{array}{r}{x\\,=\\,\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)\\,\\ge\\,\\sqrt{2}\\;(\\Delta\\,\\in\\,}\\end{array}$ $(0,0.6)\\rangle$ ). ", "page_idx": 26}, {"type": "text", "text": "After arm 2 gets $n+1$ times play, it will not be played anymore, which implies that $U_{\\delta}(n+1)<\\Delta$ . Using this bound gives ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U_{\\delta}(n)\\leq\\Delta+\\Delta^{2}\\sqrt{\\frac{3}{\\log\\log\\left(\\frac{\\log\\left(6/\\delta\\right)}{\\Delta^{2}}\\right)+\\log(6/\\delta)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Therefore, we complete the proof. ", "page_idx": 26}, {"type": "text", "text": "E.3 Traditional Optimistic Algorithms Fail to Achieve ULI Guarantee ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We will show that the traditional optimistic algorithms fail to achieve the ULI guarantee due to the $\\log t$ term in the bonus. At a high level, $\\log t$ is increasing with time and forces the algorithm to play a bad arm indefinitely when $t$ evolves. We provide the formal proof in the following: ", "page_idx": 26}, {"type": "text", "text": "We prove the claim by contradiction. Consider a $K$ -armed bandit instance with at least one suboptimal arm, and let $\\Delta>0$ be the minimum arm gap. Suppose there exists an optimism-based algorithm with $\\log t$ in bonus term that can achieve the ULI guarantee in this setting. Then, for some fixed $\\delta\\in(0,1)$ , with probability $\\geq1-\\delta$ , for all $t\\in\\mathbb{N}$ , $\\Delta_{t}\\le F_{U L I}(\\delta,t)$ . Based on Definition 2.5, we have $\\begin{array}{r}{\\operatorname*{lim}_{t\\rightarrow\\infty}F_{U L I}(\\delta,t)=0}\\end{array}$ and $F_{U L I}(\\delta,t)$ is monotonically decreasing w.r.t. $t$ after a threshold. Thus, $\\exists t_{0}\\in\\mathbb{N}$ such that $F_{U L I}(\\delta,t)<\\Delta$ for all $t\\geq t_{0}$ . In other words, the algorithm cannot play any suboptimal arm after $t_{0}$ -th round. Recall that the bonus term is $\\sqrt{\\log t/N_{a}(t)}$ where $N_{a}(t)$ is the number of plays of arm $a$ before round $t$ . For any suboptimal arm $a$ , $N_{a}(t)$ should not increase after $t_{0}$ -th round, but $\\log t$ keeps increasing. This leads the bonus of arm $a$ goes to infinity, which will incur a play of arm $a$ at a round after $t_{0}$ . This makes a contradiction. ", "page_idx": 27}, {"type": "text", "text": "${\\tt A L g}$ ", "page_idx": 28}, {"type": "text", "text": "Input: \u03b4 \u2208(0, 1), finite arm set A, and base-algorithm with function g(\u03b4) that satisfies Condition. F.1. Initialize: $\\boldsymbol{A}_{1}=[K]$ .   \n1 for $m=1,2,\\ldots$ do   \n2 Set duration $T_{m}=\\lceil576g_{m}2^{m}\\rceil$ where $\\begin{array}{r}{g_{m}=g\\left(\\frac{\\delta}{2m^{2}}\\right)}\\end{array}$ .   \n3 Run Alg with active arm set $A_{m}$ for $T_{m}$ rounds and construct $\\begin{array}{r}{\\widehat{\\ell}_{t,a}=\\frac{\\ell_{t,a}\\cdot\\mathbb{I}\\{A_{t}=a\\}}{p_{t,a}}}\\end{array}$ for all $t,a$ in this phase. Update active arm set $\\mathscr{A}_{m+1}=\\mathscr{A}_{m}-\\mathscr{B}_{m}$ where: $\\mathcal{B}_{m}=\\left\\{a\\in\\mathcal{A}_{m}:\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\widehat{\\ell}_{s,k}\\right)>7\\sqrt{g_{m}T_{m}}\\right\\},$ (20) and $\\tau_{m}$ is a set that contains all rounds in phase $m$ and $k$ is the empirical best arm: $k\\in\\underset{a\\in\\mathcal{A}_{m}}{\\mathrm{argmin}}\\,\\sum_{s\\in\\mathcal{T}_{m}}\\widehat{\\ell}_{s,a}$ ", "page_idx": 28}, {"type": "text", "text": "F Achieving ULI by Adversarial Bandit Algorithms ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "F.1 Meta-algorithm Enabling Adversarial Algorithms to Achieve ULI ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In this subsection, we propose a meta-algorithm shown in Algorithm 10 which enables any highprobability adversarial algorithm, with a mild condition, to achieve the ULI guarantee. Then, we show that existing high-probability adversarial bandit algorithms naturally meet this condition in both MAB and linear bandit settings. For notational simplicity, we follow the convention of adversarial analysis to use loss $\\ell_{t,a}=1-X_{t,a}$ . Note that all algorithms in this subsection require $[0,1]$ -boundedness assumption on loss. ", "page_idx": 28}, {"type": "text", "text": "At a high-level, our meta-algorithm keeps running a base-algorithm ${\\tt A L g}$ to play arms and collects rewards. The meta-algorithm uses collected rewards to construct the importance-weighted (IW) estimator = \u2113t,a\u00b7Ip{t,Aat=a} for each t, a, which helps to eliminate bad arms, and then runs Alg on a reduced arm space. To achieve the ULI guarantee, our meta-algorithm requires the input base-algorithm to satisfy the following: ", "page_idx": 28}, {"type": "text", "text": "Condition F.1. An algorithm Alg runs for given consecutive $T$ rounds with a finite arm set $\\boldsymbol{\\mathcal{A}}$ and $a$ fixed $\\delta\\in(0,1)$ . At each round $t\\in[T],$ , Alg maintains a distribution $p_{t}$ over $\\boldsymbol{\\mathcal{A}}$ and samples an arm $A_{t}\\sim p_{t}$ . With probability at least $\\begin{array}{r}{\\bar{1}-\\frac{3}{5}\\delta}\\end{array}$ , Alg ensures for all $a\\in A$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(\\ell_{t,A_{t}}-\\ell_{t,a}\\right)\\leq\\sqrt{g(\\delta)T}-2\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-\\ell_{t,a}\\right)\\right|,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $g(\\delta)$ is a positive-valued function, monotonically decreasing for all $\\delta\\in(0,1)$ , polynomial in $\\log(1/\\delta)$ , and $g(\\delta)\\geq\\log\\left(10|\\cal{A}|/\\delta\\right),\\forall\\delta\\in(0,1).$ . ", "page_idx": 28}, {"type": "text", "text": "In fact, many high-probability adversarial bandit algorithms naturally meet Condition. F.1, but require stronger analysis. In particular, we show that EXP3.P [Auer et al., 2002b] for MAB holds this condition with $g(\\delta)\\,\\stackrel{*}{=}\\,{\\mathcal{O}}\\big(|A|\\log(|A|/\\delta)\\big)$ (omitted proof can be found in Appendix F) and Lee et al. [2021] show that GEOMETRICHEDGE.P [Bartlett et al., 2008] with John\u2019s exploration meets the condition for linear bandits with $g(\\delta)=\\mathcal{O}\\big(d\\log(|A|/\\delta)\\big)$ . Hence, feeding those algorithms to Algorithm 10 yields the following: ", "page_idx": 28}, {"type": "text", "text": "Theorem F.2. For any fixed $\\delta\\in(0,1)$ , if Algorithm 10 uses \u2022 EXP3.P as a base-algorithm, then, for $K$ -armed bandit, ULI guarantee is achieved with ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "equation", "text": "$$\nF_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{K\\log\\left(\\delta^{-1}K\\log(t+1)\\right)}\\big).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "\u2022 GEOMETRICHEDGE.P as a base-algorithm then for linear bandits with $K$ arms, ULI guarantee is achieved with ", "page_idx": 29}, {"type": "equation", "text": "$$\nF_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{d\\log\\big(\\delta^{-1}K\\log(t+1)\\big)}\\big).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Theorem F.2 suggests that Algorithm 10 enables EXP3.P and GEOMETRICHEDGE.P to achieve nearoptimal ULI guarantees for MAB and linear bandits, respectively. Moreover, their ULI guarantees are as good as those of conventional elimination-based algorithms (refer to Theorem 3.2). ", "page_idx": 29}, {"type": "text", "text": "Our main objective in this section is to prove the following results. ", "page_idx": 29}, {"type": "text", "text": "Theorem F.3 (Restatement of Theorem F.2). For any fixed $\\delta\\in(0,1)$ , if Algorithm 10 uses ", "page_idx": 29}, {"type": "text", "text": "\u2022 EXP3.P as a base-algorithm, then, for $K$ -armed bandit, ULI guarantee is achieved with ", "page_idx": 29}, {"type": "equation", "text": "$$\nF_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{K\\log\\left(\\delta^{-1}K\\log(t+1)\\right)}\\big).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "\u2022 GEOMETRICHEDGE.P as a base-algorithm then for linear bandits with $K$ arms, ULI guarantee is achieved with ", "page_idx": 29}, {"type": "equation", "text": "$$\nF_{U L I}(\\delta,t)=\\mathcal{O}\\big(t^{-\\frac{1}{2}}\\sqrt{d\\log\\big(\\delta^{-1}K\\log(t+1)\\big)}\\big)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We decompose the proof of Theorem F.2 into two parts. In the first part, we first show that any algorithm with Condition. F.1 for some $\\delta\\in(0,1)$ can achieve the ULI guarantee. Then, we only need to show that EXP3.P and GEOMETRICHEDGE.P satisfy Condition. F.1, which completes the proof of Theorem F.2. ", "page_idx": 29}, {"type": "text", "text": "The following result suggests that showing an algorithm enjoys the ULI guarantee is reduced to show that this algorithm meets Condition. F.1. ", "page_idx": 29}, {"type": "text", "text": "Theorem F.4. For any fixed $\\delta\\in(0,1)$ , if Algorithm $I O$ uses a base-algorithm that satisfies Condition. F.1, then, it achieves the ULI guarantee that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\forall t\\in\\mathbb{N}:\\Delta_{A_{t}}=\\mathcal{O}\\left(\\sqrt{\\frac{g\\left(\\delta^{-1}\\log^{2}(t+1)\\right)}{t}}\\right)\\right)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We sketch the proof of Theorem F.4 as follows. The full proof can be found in Appendix F.2. ", "page_idx": 29}, {"type": "text", "text": "Proof Sketch. The high-level objectives are to show the sufficient condition of Eq. (1) given in Algorithm 1 to achieve the ULI. We first show that the optimal arm will not be eliminated, i.e., $a^{\\star}\\in\\mathcal{A}_{m}$ for all phases $m\\in\\mathbb{N}$ . To show this, we only need show ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall m\\in\\mathbb{N}\\quad\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a^{\\star}}-\\widehat{\\ell}_{s,k}\\right)\\leq7\\sqrt{g_{m}T_{m}},\\mathrm{~where~}k\\in\\underset{a\\in\\mathcal{A}_{m}}{\\operatorname{argmin}}\\sum_{s\\in\\mathcal{T}_{m}}\\widehat{\\ell}_{s,a},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which does not meet the elimination rule in Eq. (20). ", "page_idx": 29}, {"type": "text", "text": "For analysis purpose, we decompose Eq. (22) as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a^{\\star}}-\\widehat{\\ell}_{s,k}\\right)=\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a^{\\star}}-\\ell_{s,a^{\\star}}\\right)+\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a^{\\star}}-\\ell_{s,k}\\right)+\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,k}-\\widehat{\\ell}_{s,k}\\right).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The first and the third term in Eq. (23) can be handled thanks to the bound on $\\left|\\sum_{t}(\\widehat{\\ell}_{t,a}-\\ell_{t,a})\\right|$ in Eq. (21), and the second term in Eq. (23) can be handled by invoking the standard concentration inequality as losses are drawn from fixed distributions. ", "page_idx": 29}, {"type": "text", "text": "Then, we show that if an arm is still active at a round $t$ , then, for all active arms $a\\in\\mathcal{A}_{t}$ , $\\Delta_{a}$ is bounded by a function, monotonically decreasing for large $t$ . This can be proved again via a similar decomposition of Eq. (23) to get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\widehat{\\ell}_{s,k}\\right)\\geq0.5T_{m}\\Delta_{a}-5\\sqrt{g_{m}T_{m}}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, for some large $T_{m}$ such that $0.5T_{m}\\Delta_{a}\\,-\\,5\\sqrt{g_{m}T_{m}}\\;>\\;7\\sqrt{g_{m}T_{m}}$ , bad arms will be eliminated. Putting two pieces together, we complete the proof. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "With Theorem F.4 in hand, our next objective is to show that EXP3.P and GEOMETRICHEDGE.P are able to satisfy Condition. F.1. For GEOMETRICHEDGE.P with John\u2019s exploration (which improves the original bound [Bartlett et al., 2008]), Lee et al. [2021] have already shown that it achieves the condition, and the rest result will show that EXP3.P also holds it. The full proof can be found in Appendix F.3. ", "page_idx": 30}, {"type": "text", "text": "Proposition F.5. In MAB setting, for any $\\delta~\\in~(0,1)$ , EXP3.P with given arm set $\\boldsymbol{\\mathcal{A}}$ , satisfies Condition. F.1 with $g(\\delta)=\\mathcal{O}\\left(|\\mathcal{A}|\\log\\left(|\\mathcal{A}|/\\delta\\right)\\right)$ . ", "page_idx": 30}, {"type": "text", "text": "The key that EXP3.P as well as GEOMETRICHEDGE.P can fulflil Condition. F.1 is because it adds a small amount of probability for uniform exploration to each arm. Therefore, the importance-weighted (IW) estimator can be lower-bounded and the term $\\left|\\sum_{t}(\\widehat{\\ell}_{t,a}-\\ell_{t,a})\\right|$ will not be too large. ", "page_idx": 30}, {"type": "text", "text": "Apart from EXP3.P for MAB and GEOMETRICHEDGE.P for linear bandits, Lee et al. [2021] show that refined version of SCRIBLE [Lee et al., 2020] can be used as a base-algorithm for Algorithm 10 to achieve the ULI guarantee for linear bandits, but the ULI guarantee is inferior to that of GEOMETRICHEDGE.P (i.e., inferior $F_{\\mathrm{ULI}}$ w.r.t. $d)$ ). ", "page_idx": 30}, {"type": "text", "text": "F.2 Proof of Theorem F.4 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Lemma F.6. If Algorithm $I O$ accepts a base-algorithm which satisfies Condition. F.1 as an input, then, with probability at least $\\begin{array}{r}{1-\\frac{\\hat{3}}{5}\\delta}\\end{array}$ , for all $m\\in\\mathbb{N}$ and $a\\in A_{m}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,A_{s}}-\\ell_{s,a}\\right)\\leq\\sqrt{g_{m}T_{m}}-2\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a}-\\widehat{\\ell}_{s,a}\\right)\\right|.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. We first consider a fixed phase $m$ . Since the base-algorithm satisfies Condition. F.1, if the base-algorithm runs for consecutive $T_{m}$ and active arm set ${\\mathcal{A}}_{m}\\subseteq A$ , then, with probability at least $\\begin{array}{r}{1-\\frac{3}{5}\\delta^{\\bar{\\prime}}}\\end{array}$ , for all $a\\in A_{m}$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,A_{s}}-\\ell_{s,a}\\right)\\leq\\sqrt{g(\\delta^{\\prime})T_{m}}-2\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a}-\\widehat{\\ell}_{s,a}\\right)\\right|.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By setting $\\delta^{\\prime}=\\delta/(2m^{2})$ for phase $m$ and applying a union bound over all $m\\in\\mathbb{N}$ , we complete the proof. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "Recall from the second bullet of Condition. F.1 that ", "page_idx": 30}, {"type": "equation", "text": "$$\ng(\\delta^{\\prime})\\geq\\log\\left(10|A|/\\delta^{\\prime}\\right),\\quad\\forall\\delta^{\\prime}\\in(0,1).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "As the above holds for all $\\delta^{\\prime}\\in(0,1)$ , according to the definition $g_{m}=g(\\delta/(2m^{2}))$ , we also have that ", "page_idx": 30}, {"type": "equation", "text": "$$\ng_{m}\\geq\\log\\left(\\frac{20m^{2}|\\!|A|}{\\delta}\\right),\\quad\\forall m\\in\\mathbb{N}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Lemma F.7. With probability at least $1-\\delta/5,$ , for all $m\\in\\mathbb{N}$ and $a\\in A_{m}$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a}-\\sum_{s\\in\\mathcal{T}_{m}}(1-\\mu_{a})\\right|\\leq\\sqrt{\\frac{g_{m}T_{m}}{2}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. Consider any fixed $m$ and $a\\in A_{m}$ . By applying Hoeffding\u2019s inequality with probability at least $1-\\delta^{\\prime}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a}-\\sum_{s\\in\\mathcal{T}_{m}}(1-\\mu_{a})\\right|\\leq\\sqrt{\\frac{T_{m}\\log(2/\\delta^{\\prime})}{2}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Choosing $\\delta^{\\prime}\\,=\\,\\delta/(10|A|m^{2})$ , applying union bounds over all $m\\,\\in\\,\\mathbb{N}$ and $a\\in A_{m}$ , and using Eq. (25), we complete the proof. ", "page_idx": 30}, {"type": "text", "text": "Lemma F.8. With probability at least $1-\\delta/5,$ , for all $m\\in\\mathbb{N}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,A_{s}}-\\sum_{s\\in\\mathcal{T}_{m}}\\sum_{a\\in\\mathcal{A}_{m}}p_{s,a}(1-\\mu_{a})\\right|\\leq\\sqrt{8g_{m}T_{m}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Consider a fixed $m$ . For each round $s$ in this phase, let us define ", "page_idx": 31}, {"type": "equation", "text": "$$\nM_{s}=\\ell_{s,A_{s}}-\\mathbb{E}_{s}\\left[\\ell_{s,A_{s}}\\right]=\\sum_{a\\in{\\cal A}_{m}}\\left(\\ell_{s,a}B_{s,a}-p_{s,a}(1-\\mu_{a})\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "By applying Azuma-inequality with the fact that $|M_{s}-M_{s-1}|\\leq2$ for all $s$ and also using a union bound over all $m\\in\\mathbb{N}$ , with probability at least $1-\\delta/5$ , for all $m\\in\\mathbb{N}$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left|\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,A_{s}}-\\sum_{s\\in\\mathcal{T}_{m}}\\sum_{a\\in\\mathcal{A}_{m}}p_{s,a}(1-\\mu_{a})\\right|\\leq\\sqrt{8T_{m}\\log(20m^{2}/\\delta)}\\leq\\sqrt{8g_{m}T_{m}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the last inequality uses Eq. (25), which thus completes the proof. ", "page_idx": 31}, {"type": "text", "text": "Definition F.9. Let $\\mathcal{E}$ be the event in which the concentration inequalities in Lemma F.6, Lemma $F.7,$ , and Lemma $F.8$ hold simultaneously. ", "page_idx": 31}, {"type": "text", "text": "By a union bound, we have the following fact. ", "page_idx": 31}, {"type": "text", "text": "Fact. With the definition of $\\mathcal{E}$ in Definition F.9, $\\mathcal{E}$ occurs with probability at least $1-\\delta$ . ", "page_idx": 31}, {"type": "text", "text": "Lemma F.10. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is defined Definition $F.^{g}$ , and then for all $m\\in\\mathbb{N}$ and $a\\in A_{m}$ , ", "page_idx": 31}, {"type": "equation", "text": "$$\n2\\left\\lvert\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a}-\\widehat{\\ell}_{s,a}\\right)\\right\\rvert\\leq5\\sqrt{g_{m}T_{m}}+T_{m}\\Delta_{a}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Conditioning on $\\mathcal{E}$ , for each $m\\in\\mathbb{N}$ and $a\\in A_{m}$ , one can show ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2\\left|\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a}-\\widehat{\\ell}_{s,a}\\right)\\right|}\\\\ &{\\le\\sqrt{g_{m}T_{m}}+\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\ell_{s,a}-\\ell_{s,A_{s}}\\right)}\\\\ &{\\le\\sqrt{g_{m}T_{m}}-\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\sum_{j\\in A_{m}}p_{s,j}(1-\\mu_{j})+\\sqrt{8g_{m}T_{m}}+\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\left(1-\\mu_{a}\\right)+\\sqrt{\\frac{g_{m}T_{m}}{2}}}\\\\ &{\\le5\\sqrt{g_{m}T_{m}}+\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\sum_{j\\in A_{m}}p_{s,j}(\\mu_{j}-\\mu_{a})}\\\\ &{\\le5\\sqrt{g_{m}T_{m}}+T_{m}\\Delta_{a},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the first inequality holds due to Lemma F.6, the second inequality uses Lemma F.7 and Lemma F.8, and the last inequality bounds $\\mu_{j}\\leq\\mu^{\\star}$ for all $j$ . \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Corollary F.11. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is defined Definition $F.9_{;}$ , and then for all $m\\in\\mathbb{N}$ and $a\\in A$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a^{\\star}}-\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a}\\leq-T_{m}\\Delta_{a}+\\sqrt{2g_{m}T_{m}},}\\\\ &{\\displaystyle\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a}-\\sum_{s\\in\\mathcal{T}_{m}}\\ell_{s,a^{\\star}}\\leq T_{m}\\Delta_{a}+\\sqrt{2g_{m}T_{m}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. The proof is immediate by applying Lemma F.7. ", "page_idx": 31}, {"type": "text", "text": "Lemma F.12. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is defined Definition $F.9$ , and then $a^{\\star}\\in\\mathcal{A}_{m}$ for all $m\\in\\mathbb{N}$ . ", "page_idx": 31}, {"type": "text", "text": "Proof. We prove the claimed result by induction. For the base case, the claim holds for the first phase $m=1$ as $A_{1}=A$ . Suppose that $a^{\\star}\\in\\mathcal{A}_{m}$ . Then, we show that $a^{\\star}$ will not be eliminated at the end of phase $m$ , thereby active for phase $m+1$ . Then, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{s\\in T_{m}}\\left(\\widehat{\\ell}_{s,a^{*}}-\\widehat{\\ell}_{s,k}\\right)}\\\\ &{=\\displaystyle\\sum_{s\\in T_{m}}\\left(\\widehat{\\ell}_{s,a^{*}}-\\ell_{s,a^{*}}\\right)+\\sum_{s\\in T_{m}}\\left(\\ell_{s,a^{*}}-\\ell_{s,k}\\right)+\\sum_{s\\in T_{m}}\\left(\\ell_{s,k}-\\widehat{\\ell}_{s,k}\\right)}\\\\ &{\\leq\\displaystyle\\frac{5}{2}\\sqrt{g_{m}T_{m}}+\\left(-T_{m}\\Delta_{k}+\\sqrt{2g_{m}T_{m}}\\right)+\\frac{1}{2}\\left(5\\sqrt{g_{m}T_{m}}+T_{m}\\Delta_{k}\\right)}\\\\ &{=\\displaystyle\\frac{13}{2}\\sqrt{g_{m}T_{m}}-0.5T_{m}\\Delta_{k}}\\\\ &{<\\displaystyle7\\sqrt{g_{m}T_{m}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality uses Lemma F.10 together with $\\Delta_{a^{\\star}}=0$ and Corollary F.11. ", "page_idx": 32}, {"type": "text", "text": "Once the induction is done, we complete the proof (recall the elimination rule in Algorithm 10). ", "page_idx": 32}, {"type": "text", "text": "Lemma F.13. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is defined Definition F.9. For each arm $a\\in{\\mathcal{A}}$ with $\\Delta_{a}~>~0,$ , it will not be in $A_{m}$ for all $m\\,\\geq\\,m_{a}+1$ , where $m_{a}$ is the smallest phase such that 2ma >\u220612 . ", "page_idx": 32}, {"type": "text", "text": "Proof. Consider fixed phase $m$ and arm $a\\in A$ with $\\Delta_{a}>0$ . Suppose that arm $a$ is still active in an phase $m$ . One can show ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{s\\in{\\mathcal{T}}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\widehat{\\ell}_{s,b}\\right)}}\\\\ &{\\ge\\sum_{s\\in{\\mathcal{T}}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\widehat{\\ell}_{s,a^{\\star}}\\right)}\\\\ &{=\\displaystyle\\sum_{s\\in{\\mathcal{T}}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\ell_{s,a}\\right)+\\sum_{s\\in{\\mathcal{T}}_{m}}\\left(\\ell_{s,a}-\\ell_{s,a^{\\star}}\\right)+\\sum_{s\\in{\\mathcal{T}}_{m}}\\left(\\ell_{s,a^{\\star}}-\\widehat{\\ell}_{s,a^{\\star}}\\right)}\\\\ &{\\ge\\displaystyle\\frac{-1}{2}\\left(5\\sqrt{g_{m}T_{m}}+T_{m}\\Delta_{a}\\right)+\\left(T_{m}\\Delta_{a}-\\sqrt{2g_{m}T_{m}}\\right)+\\frac{-5}{2}\\sqrt{g_{m}T_{m}}}\\\\ &{\\ge0.5T_{m}\\Delta_{a}-5\\sqrt{g_{m}T_{m}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds since Lemma F.12 implies that $a^{\\star}\\in\\mathcal{A}_{m}$ for all $m\\in\\mathbb{N}$ , and the second inequality uses Lemma F.10 together with $\\Delta_{a^{\\star}}=0$ and Corollary F.11. ", "page_idx": 32}, {"type": "text", "text": "Let $m_{a}$ be the minimum phase such that $\\begin{array}{r}{2^{m_{a}}>\\frac{1}{\\Delta_{a}^{2}}}\\end{array}$ (i.e., $2^{m_{a}-1}\\leq\\frac{1}{\\Delta_{a}^{2}})$ , which further gives that ", "page_idx": 32}, {"type": "equation", "text": "$$\nT_{m_{a}}=\\lceil576g_{m_{a}}2^{m_{a}}\\rceil\\geq576g_{m_{a}}2^{m_{a}}>\\frac{576g_{m_{a}}}{\\Delta_{a}^{2}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Hence, by the definition of $m_{a}$ , we have $\\begin{array}{r}{T_{m}>\\frac{576g_{m}}{\\Delta_{a}^{2}}}\\end{array}$ 57\u22066g2mfor all m \u2265ma, which gives that Tm\u2206a > $24\\sqrt{g_{m}T_{m}}$ for all $m\\geq m_{a}$ . Plugging this into Eq. (30), we arrive at ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\sum_{s\\in\\mathcal{T}_{m}}\\left(\\widehat{\\ell}_{s,a}-\\widehat{\\ell}_{s,k}\\right)\\geq0.5T_{m}\\Delta_{a}-5\\sqrt{g_{m}T_{m}}>7\\sqrt{g_{m}T_{m}},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which implies that arm $a$ will not be active in all phases $m\\geq m_{a}+1$ according to the elimination rule. ", "page_idx": 32}, {"type": "text", "text": "Finally, one can repeat this argument for each $a\\in A$ with $\\Delta_{a}>0$ conditioning on $\\mathcal{E}$ . ", "page_idx": 32}, {"type": "text", "text": "Lemma F.14. Let $m(t)$ be the phase in which round $t$ lies. Then, $m(t)\\leq\\log_{2}(t+1)$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 32}, {"type": "text", "text": "Proof. We prove this by contradiction. Suppose that $\\exists t\\in\\mathbb{N}$ that $m(t)>\\log_{2}(t+1)$ . Note that we can further assume $m(t)\\,\\geq\\,2$ since one can easily verify that for all $t$ such that $m(t)\\,=\\,1$ , ", "page_idx": 32}, {"type": "text", "text": "$m(t)\\leq\\log_{2}(t+1)$ must hold. Recall that in phase $m(t)$ , each active arm will be played for $m_{\\ell(t)}$ times, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\nt\\geq T_{m(t)-1}\\geq576g_{m(t)-1}2^{m(t)-1}>288(t+1)g_{m(t)-1}>t,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the third inequality bounds $\\ell(t)>\\log_{2}(t+1)$ by assumption. Therefore, once a contradiction occurs, the proof is complete. \u53e3 ", "page_idx": 33}, {"type": "text", "text": "Lemma F.15. Let $m(t)$ be the phase in which round $t$ lies. Suppose that $\\mathcal{E}$ occurs. For all $t\\in\\mathbb{N}$ and all $a\\in{\\mathcal{A}}$ , if $\\dot{\\b{a}}\\in\\b{\\mathcal{A}}_{m(t)}$ , then, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\Delta_{a}\\leq\\sqrt{\\frac{4608g(\\delta/(2\\log_{2}^{2}(t+1)))}{t}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. If $a\\in A_{m(t)}$ is optimal, then, $\\Delta_{a}=0$ and the claim trivially holds. In what follows, we only consider arm $a\\in\\mathcal{A}_{m(t)}$ with $\\Delta_{a}>0$ . Then, $t$ can be bounded by ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{t\\sum_{n=1}^{m(t)}\\sum_{n=0}^{\\lfloor\\gamma\\rfloor}\\zeta(g_{n})^{2}}\\quad}\\\\ &{}&\\\\ &{\\leq1152\\sum_{n=1}^{m(t)}g_{n}2^{n}}\\\\ &{}&\\\\ &{}&{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ &{}&{\\leq1152g_{m(t)}\\displaystyle\\sum_{n=1}^{m(t)}2^{n}}\\\\ &{}&{\\leq1152g_{m(t)}\\displaystyle\\sum_{n=1}^{m_{0}}2^{n}}\\\\ &{}&\\\\ &{}&{\\leq\\frac{4608g_{m(t)}}{\\Delta^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the second inequality simply bounds $7576g_{n}2^{n}7\\leq2\\times576g_{n}2^{n}$ for all phases $n$ , the fourth inequality holds because Lemma F.13 implies that if $a\\in A_{m(t)}$ , then, $m(t)\\leq m_{a}$ holds, and the last inequality uses $\\begin{array}{r}{\\frac{1}{\\Delta_{a}^{2}}\\geq2^{m_{a}-1}}\\end{array}$ . ", "page_idx": 33}, {"type": "text", "text": "Since for any fixed $\\delta\\in(0,1)$ , $g(\\delta/x^{2})$ is monotonically increasing for $x\\geq1$ (recall Condition. F.1) and Lemma F.14 gives $m(t)\\leq\\log_{2}(t+1)$ , we have ", "page_idx": 33}, {"type": "equation", "text": "$$\ng_{m(t)}=g(\\delta/(2m(t)^{2}))\\leq g(\\delta/(2\\log_{2}^{2}(t+1))),\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "which gives 4608g(\u03b4/(2\u2206 l2og22(t+1))). Conditioning on E, this argument holds for each t, a, which completes the proof. \u53e3 ", "page_idx": 33}, {"type": "text", "text": "Proof of Theorem $F.4.$ . Once Lemma F.12 and Lemma F.15 hold, and $g(x)$ is polynomial in $\\log(1/x)$ , Theorem 3.1 gives that for any fixed $\\delta\\in(0,1)$ , Algorithm 10 achieves the ULI guarantee with a function ", "page_idx": 33}, {"type": "equation", "text": "$$\nF_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(\\sqrt{\\frac{g(\\delta/(2\\log_{2}^{2}(t+1)))}{t}}\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "According to the first bullet of Condition. F.1, the proof is complete. ", "page_idx": 33}, {"type": "text", "text": "F.3 Proof of Proposition F.5 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "In this section, we prove that EXP3.P [Auer et al., 2002b] meets Condition. F.1. In our setting, arm set is $\\boldsymbol{A}=[K]$ , and the loss $\\ell_{t,a}$ generated by each arm $a$ at each round $t$ is assumed to be $[0,1]$ -bounded. ", "page_idx": 33}, {"type": "text", "text": "Algorithm 11 EXP3.P ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Input: Time horizon $T$ , arm set $[K]$ , confidence $\\delta\\in(0,1)$ . ", "page_idx": 34}, {"type": "text", "text": "Initialize: $\\forall a\\in[K]$ , $w_{1,a}=1$ and parameters $\\eta=\\eta_{\\delta}(T),\\gamma\\,=\\gamma_{\\delta}(T),\\beta\\,=\\,\\beta_{\\delta}(T)$ according to Eq. (33). ", "page_idx": 34}, {"type": "text", "text": "for $t=1,2,\\ldots,T$ do Play an arm $A_{t}\\in[K]$ from distribution $p_{t}=[p_{t,1},\\ldots,p_{t,K}]$ and observe loss $\\ell_{t,A_{t}}$ where ", "page_idx": 34}, {"type": "equation", "text": "$$\np_{t,a}=(1-\\gamma)\\frac{w_{t,a}}{W_{t}}+\\frac{\\gamma}{K}\\quad\\mathrm{where}\\quad W_{t}=\\sum_{a\\in[K]}w_{t,a}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Update $w_{t+1,a}=w_{t,a}\\exp(-\\eta\\widetilde{\\ell}_{t,a})$ for all $a\\in[K]$ with ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\widetilde{\\ell}_{t,a}=\\widehat{\\ell}_{t,a}-\\frac{2\\beta}{p_{t,a}},\\quad\\mathrm{where}\\quad\\widehat{\\ell}_{t,a}=\\frac{\\ell_{t,a}B_{t,a}}{p_{t,a}},\\,\\,\\mathrm{and}\\,\\,B_{t,a}=\\mathbb{I}\\left\\{A_{t}=a\\right\\}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The pseudocode of $\\mathrm{EXP3.P}$ is given in Algorithm 11 and we briefly review its procedure. Ahead of time, $\\mathrm{EXP3.P}$ accepts a fixed time horizon $T\\in\\mathbb N$ arm set $[K]$ , and confidence $\\delta\\in(0,1)$ as inputs. tAhte en aocbh sreoruvnesd $t\\in[T]$ s, 3. .PT hpeu lplrs oabna bairlimt $A_{t}\\sim p_{t}$ ifnrog ma na  adrismt b uatt iroon $p_{t}=[p_{t,1},\\ldots,p_{t,K}]$ $\\ell_{t,A_{t}}$ $a$ $t$ $\\begin{array}{r}{(1-\\gamma)\\frac{w_{t,a}}{W_{t}}+\\frac{\\gamma}{K}}\\end{array}$ where is a fixed parameter, which encourages the exploration, $w_{t,a}$ is the weight of arm $a$ , and $\\begin{array}{r}{W_{t}=\\sum_{a\\in[K]}w_{t,a}.}\\end{array}$ . After pulling the arm, the algorithm uses the observed reward to construct the shifted IW-estimators $\\widetilde{\\ell}_{t,a}$ according to Eq. (32), and finally uses the shifted IW-estimators to update the weight $w_{t,a}$ for each arm. ", "page_idx": 34}, {"type": "text", "text": "The parameters of $\\gamma_{\\delta}(T),\\eta_{\\delta}(T),\\beta_{\\delta}(T)$ are as a function $T$ , given as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\gamma_{\\delta}(T)=\\operatorname*{min}\\left\\{\\frac{1}{2},\\sqrt{\\frac{K\\log(10K/\\delta)}{T}}\\right\\},\\quad\\beta_{\\delta}(T)=\\eta_{\\delta}(T)=\\frac{\\gamma_{\\delta}(T)}{K}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Let $\\mathbb{E}_{t}[\\cdot]$ be the conditional expectation given the history prior to round $t$ . ", "page_idx": 34}, {"type": "text", "text": "Lemma F.16 (Exercise 5.15 of [Lattimore and Szepesv\u00e1ri, 2020]). Let $\\{X_{t}\\}_{t=1}^{T}$ be a sequence of random variables adapted to filtration $\\{\\mathcal{F}_{t}\\}_{t=1}^{T}$ and let $\\beta>0$ such that $\\beta X_{t}\\leq1$ almost surely for all $t\\in[T]$ . With probability at least $1-\\delta$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(X_{t}-\\mathbb{E}_{t}[X_{t}]\\right)\\leq\\beta\\sum_{t=1}^{T}\\mathbb{E}_{t}[X_{t}^{2}]+\\frac{\\log(1/\\delta)}{\\beta}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Corollary F.17. With probability at least $1-\\delta/5,$ , for all $a\\in[K].$ ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(\\widetilde{\\ell}_{t,a}-\\ell_{t,a}\\right)\\leq\\frac{\\log(5K/\\delta)}{\\beta}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. Consider a fixed arm $a$ . For all $t,a$ , we have $\\ell_{t,a}\\in[0,1]$ , and thus ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t}\\left[\\widehat{\\ell}_{t,a}^{2}\\right]=\\mathbb{E}_{t}\\left[\\frac{\\ell_{t,a}^{2}B_{t,a}^{2}}{p_{t,a}^{2}}\\right]=\\mathbb{E}_{t}\\left[\\frac{\\ell_{t,a}^{2}B_{t,a}}{p_{t,a}^{2}}\\right]\\leq\\mathbb{E}_{t}\\left[\\frac{B_{t,a}}{p_{t,a}^{2}}\\right]=\\frac{1}{p_{t,a}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Then, we check $\\beta\\widehat{\\ell}_{t,a}\\leq1$ almost surely for all $t\\in[T]$ . Specifically, we use $p_{t,a}\\ge\\gamma/K$ to show ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\beta\\widehat{\\ell}_{t,a}=\\beta\\frac{B_{t,a}\\ell_{t,a}}{p_{t,a}}\\leq\\beta\\frac{1}{p_{t,a}}\\leq\\frac{\\beta K}{\\gamma}=1,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the last equality holds due to $\\beta=\\gamma/K$ according to Eq. (33). ", "page_idx": 34}, {"type": "text", "text": "For the fixed $a$ , applying Lemma F.16 with $X_{t}=\\widehat{\\ell}_{t,a}$ , we have that with probability at least $1-\\delta^{\\prime}$ ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(\\widetilde{\\ell}_{t,a}-\\ell_{t,a}\\right)=\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-\\ell_{t,a}\\right)-\\sum_{t=1}^{T}\\frac{2\\beta}{p_{t,a}}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\beta\\displaystyle\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}+\\frac{\\log(1/\\delta^{\\prime})}{\\beta}-\\displaystyle\\sum_{t=1}^{T}\\frac{2\\beta}{p_{t,a}}}\\\\ &{\\leq\\frac{\\log(1/\\delta^{\\prime})}{\\beta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Choosing $\\delta^{\\prime}=\\delta/(5K)$ and applying a union bound over all $a\\in[K]$ yield the claimed bound. ", "page_idx": 35}, {"type": "text", "text": "Lemma F.18. With probability at least $1-\\delta/5$ , for all $a\\in[K]$ , we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left|\\sum_{t=1}^{T}\\ell_{t,a}-\\sum_{t=1}^{T}(1-\\mu_{a})\\right|\\leq\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. Consider any fixed arm $a$ . By applying Hoeffding\u2019s inequality with probability at least $1-\\delta^{\\prime}$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left|\\sum_{t=1}^{T}\\ell_{s,a}-\\sum_{t=1}^{T}(1-\\mu_{a})\\right|\\leq\\sqrt{\\frac{T\\log(2/\\delta^{\\prime})}{2}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Choosing $\\delta^{\\prime}=\\delta/(5K)$ and applying a union bound over all arms, we complete the proof. ", "page_idx": 35}, {"type": "text", "text": "Lemma F.19 (Freedman\u2019s inequality). Let $\\{X_{t}\\}_{t=1}^{T}$ be a martingale difference sequence with respect to flitration $\\{\\mathcal{F}_{t}\\}_{t=1}^{T}$ and $|X_{t}|\\leq M$ almost surely for all $t$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left|\\sum_{t=1}^{T}X_{t}\\right|\\leq\\frac{2M}{3}\\log(2/\\delta)+\\sqrt{2\\log(2/\\delta)\\sum_{t=1}^{T}\\mathbb{E}_{t}[X_{t}^{2}]}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Corollary F.20. With probability at least $1-\\delta/5,$ , the following holds for all $a$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-(1-\\mu_{a})\\right)\\right|\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\sqrt{2\\log(10K/\\delta)\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. Consider a fixed arm $a$ . Let $M_{t,a}=\\widehat{\\ell}_{t,a}-(1-\\mu_{a})$ and $\\{M_{t,a}\\}_{t=1}^{T}$ is a martingale difference sequence. We have $\\mathbb{E}_{t}[M_{t,a}]=0$ , $\\begin{array}{r}{|M_{t,a}|\\leq\\frac{K}{\\gamma}}\\end{array}$ and also ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sqrt{\\sum_{t=1}^{T}\\mathbb{E}_{t}\\left[M_{t,a}^{2}\\right]}\\le\\sqrt{\\sum_{t=1}^{T}\\mathbb{E}_{t}\\left[\\widehat{\\ell}_{t,a}^{2}\\right]}\\le\\sqrt{\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the last step holds due to Eq. (34). ", "page_idx": 35}, {"type": "text", "text": "By Lemma F.19 and a union bound over all $a$ , with probability at least $1-\\delta^{\\prime}$ for all $a$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-(1-\\mu_{a})\\right)\\right|\\leq\\frac{2\\log(2K/\\delta^{\\prime})}{3}\\frac{K}{\\gamma}+\\sqrt{2\\log(2K/\\delta^{\\prime})\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Choosing $\\delta^{\\prime}=\\delta/5$ completes the proof. ", "page_idx": 35}, {"type": "text", "text": "Definition F.21. Let $\\mathcal{E}_{0}$ be the event in which all inequalities of Corollary F.17, Lemma F.18, and Corollary $F2O$ hold simultaneously. With this definition, ${\\mathcal{E}}_{0}$ occurs with probability at least $\\textstyle1-{\\frac{3\\delta}{5}}$ ", "page_idx": 35}, {"type": "text", "text": "Lemma F.22. Let $\\theta_{0}$ be an arbitrary constant such that $\\theta_{0}\\geq1$ . Suppose that $\\mathcal{E}_{0}$ occurs where ${\\mathcal{E}}_{0}$ is defined in Definition F.21, and then for all $a\\in[K]$ , we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n-\\sum_{t=1}^{T}\\frac{\\beta}{p_{t,a}}\\leq-\\theta_{0}\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-\\ell_{t,a}\\right)\\right|+\\frac{2K\\theta_{0}\\log(10K/\\delta)}{3\\gamma}+\\frac{\\theta_{0}^{2}\\log(10K/\\delta)}{\\beta}+\\theta_{0}\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}+\\frac{2K\\log\\left(10K/\\delta\\right)}{\\gamma}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(\\widetilde{\\ell}_{t,a}-\\ell_{t,a}\\right)\\leq\\frac{2K\\log(10K/\\delta)}{3\\gamma}+\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}-\\beta\\sum_{t=1}^{T}\\frac{1}{p_{t,a}},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. Let $\\theta_{0}>0$ be an arbitrary constant. By Corollary F.20, for all $a\\in[K]$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|\\displaystyle\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-(1-\\mu_{a})\\right)\\right|\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\sqrt{2\\log(10K/\\delta)\\displaystyle\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}}}&{}\\\\ {=\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\sqrt{2\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}\\cdot\\frac{\\beta}{\\theta_{0}}\\displaystyle\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}}}&{}\\\\ {\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}+\\frac{\\beta}{\\theta_{0}}\\displaystyle\\sum_{t=1}^{T}\\frac{1}{p_{t,a}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the second inequality uses ${\\sqrt{2a b}}\\leq a+b$ for all $a,b\\ge0$ . ", "page_idx": 36}, {"type": "text", "text": "Moreover, by the triangle inequality, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-\\ell_{t,a}\\right)\\right|\\leq\\left|\\displaystyle\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-(1-\\mu_{a})\\right)\\right|+\\left|\\displaystyle\\sum_{t=1}^{T}(\\ell_{t,a}-(1-\\mu_{a}))\\right|}}\\\\ &{\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}+\\frac{\\beta}{\\theta_{0}}\\displaystyle\\sum_{t=1}^{T}\\frac{1}{p_{t,a}}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the last inequality applies Lemma F.18 and uses Eq. (38). ", "page_idx": 36}, {"type": "text", "text": "Rearranging the above gives ", "page_idx": 36}, {"type": "equation", "text": "$$\n-\\sum_{t=1}^{T}\\frac{\\beta}{p_{t,a}}\\leq-\\theta_{0}\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,a}-\\ell_{t,a}\\right)\\right|+\\frac{2\\theta_{0}\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{\\theta_{0}^{2}\\log(10K/\\delta)}{\\beta}+\\theta_{0}\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}\\frac{K}{\\gamma}+\\frac{2\\theta_{0}\\log(10K/\\delta)}{\\gamma}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Finally, if we constrain $\\theta_{0}\\geq1$ , then ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\left(\\tilde{\\ell}_{t,a}-\\ell_{t,a}\\right)}\\\\ &{\\displaystyle=\\sum_{t=1}^{T}\\left(\\hat{\\ell}_{t,a}-\\ell_{t,a}\\right)-\\sum_{t=1}^{T}\\frac{2\\beta}{p_{t,a}}}\\\\ &{\\displaystyle\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}+\\frac{1}{\\theta_{0}}\\sum_{t=1}^{T}\\frac{\\beta\\ell_{t,a}}{p_{t,a}}-\\sum_{t=1}^{T}\\frac{2\\beta}{p_{t,a}}}\\\\ &{\\displaystyle\\leq\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{\\theta_{0}\\log(10K/\\delta)}{\\beta}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}-\\sum_{t=1}^{T}\\frac{\\beta}{p_{t,a}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the first inequality uses Eq. (39) and the last one bounds $\\theta_{0}\\geq1$ . ", "page_idx": 36}, {"type": "text", "text": "Since this argument holds for all $a\\in[K]$ conditioning on ${\\mathcal{E}}_{0}$ , we complete the proof. ", "page_idx": 36}, {"type": "text", "text": "Lemma F.23. The following holds for all $t\\in[T]$ . ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}^{2}\\leq\\sum_{a=1}^{K}\\widetilde{\\ell}_{t,a}+\\frac{4K^{2}\\beta^{2}}{\\gamma}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Proof. For any fixed $t$ , we can show ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}^{2}=\\sum_{a=1}^{K}p_{t,a}\\left(\\widehat{\\ell}_{t,a}-\\frac{2\\beta}{p_{t,a}}\\right)^{2}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=\\sum_{a=1}^{K}p_{t,a}\\left(\\widehat{\\ell}_{t,a}^{2}-\\frac{4\\beta}{p_{t,a}}\\widehat{\\ell}_{t,a}+\\frac{4\\beta^{2}}{p_{t,a}^{2}}\\right)}\\\\ {\\displaystyle=\\sum_{a=1}^{K}p_{t,a}\\widehat{\\ell}_{t,a}\\left(\\widehat{\\ell}_{t,a}-\\frac{4\\beta}{p_{t,a}}\\right)+\\sum_{a=1}^{K}\\frac{4\\beta^{2}}{p_{t,a}}}\\\\ {\\displaystyle\\leq\\sum_{a=1}^{K}p_{t,a}\\widehat{\\ell}_{t,a}\\widetilde{\\ell}_{t,a}+\\frac{4K^{2}\\beta^{2}}{\\gamma}}\\\\ {\\displaystyle\\leq\\sum_{a=1}^{K}\\widetilde{\\ell}_{t,a}+\\frac{4K^{2}\\beta^{2}}{\\gamma},}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality uses $\\begin{array}{r}{\\widehat{\\ell}_{t,a}-\\frac{4\\beta}{p_{t,a}}\\leq\\widehat{\\ell}_{t,a}-\\frac{2\\beta}{p_{t,a}}=\\widetilde{\\ell}_{t,a}}\\end{array}$ and $p_{t,a}\\geq\\frac{\\gamma}{K}$ , and the last inequality bounds $p_{t,a}\\widehat{\\ell}_{t,a}\\leq1$ for each $a\\in[K]$ . Since the claim deterministically holds for all , the proof is complete. \u53e3 ", "page_idx": 37}, {"type": "text", "text": "Lemma F.24. The following holds for all arms $k\\in[K]$ . ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}-\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,k}\\leq\\frac{\\log(K)}{\\eta}+2\\eta\\sum_{a=1}^{K}\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,a}+4T K\\beta^{2}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Proof. Let us define ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\Phi_{0}=0,\\quad\\Phi_{t}=\\frac{1-\\gamma}{\\eta}\\log\\left(\\frac{1}{K}\\sum_{a=1}^{K}\\exp\\left(-\\eta\\sum_{s=1}^{t}\\widetilde{\\ell}_{s,a}\\right)\\right),\\,\\forall t\\geq1.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "With this definition, one can show for $t\\geq2$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Phi_{t}-\\Phi_{1-}=\\frac{1}{\\eta_{s}}\\nabla_{t}\\Bigg(\\frac{\\sum_{k=1}^{K}w_{k}}{\\sum_{k=1}^{K}w_{k}}\\Big(\\frac{\\sum_{k=1}^{K}w_{k}}{\\sqrt{\\eta_{k}}\\int_{\\frac{(k)^{2}}{\\Gamma_{1-k}}}}\\Big)\\Bigg)}\\\\ {=}&{\\frac{1-\\eta_{s}}{\\eta_{s}}\\nabla_{t}\\Bigg(\\frac{\\sum_{k=1}^{K}w_{k}}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{1-k}}(\\eta_{s})\\int_{\\Gamma_{1-k}}^{\\Gamma_{1-k}}\\Big(\\eta_{s})\\int_{\\Gamma_{2-k}}\\Big(\\eta_{s}^{\\prime}\\Big(\\frac{1}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{1-k}}}\\Big)w_{k}\\Big)}\\\\ {=}&{\\frac{1-\\eta_{s}}{\\eta_{s}}\\nabla_{t}\\Bigg(\\frac{\\sum_{k=1}^{K}w_{k}}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{1-k}}(\\eta_{s})\\int_{\\Gamma_{2-k}}^{\\Gamma_{1-k}}\\Big(\\eta_{s}^{\\prime}\\Big(\\frac{1}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{2-k}}}\\Big)\\Bigg)}\\\\ {=}&{\\frac{1-\\eta_{s}}{\\eta_{s}}\\nabla_{t}\\Bigg(\\frac{\\sum_{k=1}^{K}w_{k}}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{1-k}}(\\eta_{s})\\int_{\\Gamma_{2-k}}^{\\Gamma_{1-k}}\\Big(\\eta_{s}^{\\prime}\\Big(\\frac{1}{\\sqrt{\\eta_{k}}\\int_{\\Gamma_{2-k}}}\\Big)\\Bigg)}\\\\ {=}&{-\\frac{1-\\eta_{s}}{\\eta_{s}}\\nabla_{t}\\Bigg(1+\\frac{\\eta_{s}}{\\sqrt{\\eta_{s}}\\int_{\\Gamma_{1-k}}(\\eta_{s})\\int_{\\Gamma_{2-k}}^{\\Gamma_{1-k}}\\Big(\\eta_{s}^{\\prime}\\Big(\\frac{1}{\\sqrt{\\eta_{s}}\\int_{\\Gamma_{2-k}}}\\Big)\\Bigg)}\\\\ {=}&{\\frac{1-\\eta_{s}}{\\eta_{s}}\\nabla_{t}\\Bigg(1+ \n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality uses $e^{-x}\\leq1-x+x^{2}$ whenever $x\\geq-1$ (here we repeat $x=\\eta\\widetilde{\\ell}_{t,a}$ for every $a$ ), and the second inequality follows from $\\log(1+x)\\leq x$ for all $x>-1$ . ", "page_idx": 37}, {"type": "text", "text": "By summing over all $t$ and using Lemma F.23 with $\\begin{array}{r}{\\eta=\\frac{\\gamma}{K}}\\end{array}$ , the above result yields ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{t=1}^{T}\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}\\leq\\displaystyle\\sum_{t=1}^{T}\\left(\\Phi_{t-1}-\\Phi_{t}\\right)+\\eta\\sum_{t=1}^{T}\\sum_{a=1}^{K}\\widetilde{\\ell}_{t,a}+\\eta\\sum_{t=1}^{T}\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}^{2}}\\\\ {\\displaystyle\\leq\\sum_{t=1}^{T}\\left(\\Phi_{t-1}-\\Phi_{t}\\right)+2\\eta\\sum_{t=1}^{T}\\sum_{a=1}^{K}\\widetilde{\\ell}_{t,a}+4T K\\beta^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "As $\\Phi_{0}=0$ and $1-\\gamma\\leq1$ , we have for an arbitrary arm $k\\in[K]$ , ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}(\\Phi_{t-1}-\\Phi_{t})=-\\Phi_{T}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\quad\\leq\\frac{(1-\\gamma)\\log(K)}{\\eta}-\\frac{1-\\gamma}{\\eta}\\log\\left(\\displaystyle\\sum_{u=1}^{K}\\exp\\left(-\\eta\\displaystyle\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,a}\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\quad\\leq\\frac{(1-\\gamma)\\log(K)}{\\eta}-\\frac{1-\\gamma}{\\eta}\\log\\left(\\exp\\left(-\\eta\\displaystyle\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,k}\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\quad\\leq\\frac{\\log(K)}{\\eta}+\\displaystyle\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "As this argument deterministically holds for all $k\\in[K]$ , we complete the proof. ", "page_idx": 38}, {"type": "text", "text": "Proof of Proposition $F.5$ . The following analysis will condition on event ${\\mathcal{E}}_{0}$ which is defined in Definition F.21. As mentioned in Definition F.21, this event occurs with probability at least $\\textstyle{1-{\\frac{3}{5}}\\delta}$ . We first note that for all $t,a$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}=\\sum_{a=1}^{K}p_{t,a}\\left(\\frac{\\ell_{t,a}B_{t,a}}{p_{t,a}}-\\frac{2\\beta}{p_{t,a}}\\right)=\\sum_{a=1}^{K}\\left(\\ell_{t,a}B_{t,a}-2\\beta\\right)=\\ell_{t,A_{t}}-2\\beta K.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Recall that we choose parameters as ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\gamma=\\operatorname*{min}\\left\\{{\\frac{1}{2}},{\\sqrt{\\frac{K\\log(10K/\\delta)}{T}}}\\right\\},\\quad\\beta=\\eta={\\frac{\\gamma}{K}}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "In what follows, we consider $T>4K\\log(10K/\\delta)^{8}$ . In this case, we have $\\eta,\\gamma,\\beta\\in(0,\\frac{1}{2}]$ . ", "page_idx": 38}, {"type": "text", "text": "Then, for an arbitrary arm $k\\in[K]$ , we pick $\\theta_{0}=2$ and show ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{I}\\left(\\ell_{t,A_{t}}-\\ell_{t,k}\\right)}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\left(\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}-\\ell_{t,k}\\right)+2\\beta K T}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{T}\\left(\\sum_{a=1}^{K}p_{t,a}\\widetilde{\\ell}_{t,a}-\\widetilde{\\ell}_{t,b}\\right)+\\underbrace{2\\beta K T+\\frac{2\\log(10K/\\delta)}{3}\\frac{K}{\\gamma}+\\frac{2\\log(10K/\\delta)}{\\beta}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}}_{\\mathrm{TERM}~2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the equality uses Eq. (40) and the inequality applies Lemma F.22. ", "page_idx": 38}, {"type": "text", "text": "We first apply Lemma F.24 to bound TERM 1 as ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\mathrm{TERM}\\ 1\\leq\\frac{\\log(K)}{\\eta}+2\\eta\\sum_{a=1}^{K}\\sum_{t=1}^{T}\\widetilde{\\ell}_{t,a}+4T K\\beta^{2}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "8With the choice of $g(\\delta)$ in Proposition F.5, this requirement always holds if EXP3.P is a base-algorithm in Algorithm 10. ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\frac{\\log(K)}{\\eta}+2\\eta\\sum_{a=1}^{K}\\left(\\sum_{t=1}^{T}\\ell_{t,a}+\\frac{\\log(10K/\\delta)}{\\beta}\\right)+4T K\\beta^{2}}\\\\ &{\\leq\\displaystyle\\frac{\\log(K)}{\\eta}+2\\eta K T+\\frac{2\\eta K\\log(10K/\\delta)}{\\beta}+4T K\\beta^{2}}\\\\ &{\\leq3\\sqrt{K T\\log(10K/\\delta)}+2K\\log(10K/\\delta)+4\\log(10K/\\delta)}\\\\ &{\\leq6\\sqrt{K T\\log(10K/\\delta)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the second inequality uses Corollary F.17, the third inequality uses $\\textstyle\\sum_{i}\\ell_{t,a}\\leq K$ , and the last inequality uses T \u22654K log(10K/\u03b4) (i.e., K \u2264 4 log(K10TK/\u03b4)). ", "page_idx": 39}, {"type": "text", "text": "Then, we use $K/\\gamma=1/\\eta$ to bound TERM 2: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathtt{1R M}\\displaystyle2=2\\beta K T+\\frac{2\\log(10K/\\delta)}{3\\eta}+\\frac{2\\log(10K/\\delta)}{\\beta}+\\sqrt{\\frac{T\\log\\left(10K/\\delta\\right)}{2}}}\\\\ &{\\qquad=2\\sqrt{K T\\log(10K/\\delta)}+\\frac{2}{3}\\sqrt{K T\\log(10K/\\delta)}+2\\sqrt{K T\\log(10K/\\delta)}+\\sqrt{\\frac{T\\log(10K/\\delta)}{2}}}\\\\ &{\\qquad\\leq\\frac{14}{3}\\sqrt{K T\\log(10K/\\delta)}+\\sqrt{\\frac{T\\log(10K/\\delta)}{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Finally, we apply Eq. (36) with $\\theta_{0}=2$ to bound TERM 3. ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{TERM}~3\\leq-2\\left|\\displaystyle\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,k}-\\ell_{t,k}\\right)\\right|+\\frac{4\\log(10K/\\delta)}{3\\eta}+\\frac{4\\log(10K/\\delta)}{\\beta}+\\sqrt{2T\\log\\left(10K/\\delta\\right)}}\\\\ &{\\qquad\\,=-2\\left|\\displaystyle\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,k}-\\ell_{t,k}\\right)\\right|+\\frac{16}{3}\\sqrt{K T\\log(10K/\\delta)}+\\sqrt{2T\\log(10K/\\delta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Putting bounds of TERM 1, TERM 2, and TERM 3 together gives ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\left(\\ell_{t,A_{t}}-\\ell_{t,k}\\right)\\leq-2\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,k}-\\ell_{t,k}\\right)\\right|+16\\sqrt{K T\\log(10K/\\delta)}+\\frac{3\\sqrt{2}}{2}\\sqrt{T\\log(10K/\\delta)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq-2\\left|\\sum_{t=1}^{T}\\left(\\widehat{\\ell}_{t,k}-\\ell_{t,k}\\right)\\right|+19\\sqrt{K T\\log(10K/\\delta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "As this argument holds for all $k\\in[K]$ conditioning on ${\\mathcal{E}}_{0}$ , the proof is thus complete. ", "page_idx": 39}, {"type": "text", "text": "F.4 Proof of Theorem F.2 ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "For EXP3.P, we apply $g(\\delta)=\\mathcal{O}\\left(K\\log\\left(K/\\delta\\right)\\right)$ given in Proposition F.5 into Theorem F.4 to get the claimed result. ", "page_idx": 39}, {"type": "text", "text": "As for GEOMETRICHEDGE.P, we consider an improved version in [Lee et al., 2021] which uses John\u2019s exploration and shows that $g(\\delta)\\,=\\,d\\log(\\bar{K}/\\delta)$ . Note that this is slightly different from $d\\log(K\\log_{2}T/\\delta)$ presented in [Lee et al., 2021]. The extra $\\log_{2}T$ term is caused by Lemma 2 of [Bartlett et al., 2008], a concentration inequality for martingales, but one can invoke Lemma F.19 to avoid it. By applying such a function $g(\\delta)^{\\overline{{{}}}}$ into Theorem F.4, we obtain the claimed result. ", "page_idx": 39}, {"type": "text", "text": "Input: compact arm set $\\boldsymbol{\\mathcal{A}}$ , phase $m$ , spanner $\\scriptstyle B_{m-1}$ , parameters $T_{m}$ , $C$ , and estimation $\\widehat{\\theta}_{m}$ .   \nInitialize: matrix $A=[a_{1},\\ldots,a_{d}]$ by setting $\\begin{array}{r}{a_{i}=\\frac{\\mathbf{\\bar{\\alpha}}_{i}}{\\sqrt{T_{m}}}\\in\\mathbb{R}^{d}}\\end{array}$ for all $i\\in[d]$ , and $\\mathcal{Z}_{m}=[d]$ .   \n1 Let $B_{m-1}\\in\\mathbb{R}^{d\\times|B_{m-1}|}$ be a matrix whose the $i$ -th column vector is the $i$ -th element of set $\\scriptstyle B_{m-1}$ .   \n2 if $|B_{m-1}|<d$ then   \n3 Use Gaussian elimination to get $M_{m}\\,\\in\\,\\mathbb{R}^{(d-|\\mathcal{B}_{m-1}|)\\,\\times\\,d}$ such that $\\mathrm{Span}({\\mathcal{B}}_{m-1})\\,=\\,\\{x\\,\\in\\,\\mathbb{R}^{d}$ : $M_{m}x=\\vec{0}\\}$ . ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "4 else   \n5 Remove constraints in (42), (43) related to $B_{m-1},M_{m}$ ", "page_idx": 40}, {"type": "text", "text": ". 6 Query oracle to get empirical best arm $a_{m}^{\\star}$ , the solution of ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\underset{a\\in\\mathcal{A}}{\\mathrm{argmax}}\\left\\langle\\widehat{\\theta}_{m},a\\right\\rangle\n$$", "text_format": "latex", "page_idx": 40}, {"type": "equation", "text": "$\\mathrm{t.~}M_{m}\\boldsymbol{a}=\\vec{0},\\ -\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}\\boldsymbol{a}\\leq\\vec{C}.$ ", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "7 for $i=1,\\ldots,d$ do   \n8 Set $s_{i}=\\mathrm{LI-Argmax}(\\mathcal{A},A,\\widehat{\\theta}_{m},B_{m-1},m,C,a_{m}^{\\star}).$   \n9 if $s_{i}\\neq\\mathrm{NULL}$ then   \n10 Update $a_{i}=s_{i}$ and ${{Z}_{m}}={{Z}_{m}}-\\{i\\}$ .   \n11 for $i=1,\\ldots,d$ do   \n12 Set $s_{i}=\\mathrm{LI-Argmax}(\\mathcal{A},A,\\widehat{\\theta}_{m},B_{m-1},m,C,a_{m}^{\\star}).$   \n13 if $s_{i}\\neq\\mathrm{NULL}$ then   \n14 if $\\left|\\operatorname*{det}\\left(s_{i},A_{-i}\\right)\\right|\\geq C\\left|\\operatorname*{det}(A)\\right|$ or $i\\in\\mathcal{Z}_{m}$ then   \n15 Update ${{\\mathcal{I}}_{m}}={{\\mathcal{I}}_{m}}-\\{i\\}$ and $a_{i}=s_{i}$ .   \n16 Restart this for-loop with current parameters.   \n17 Return: {ai}id=1 \u2212\u222ai\u2208Im\u221aeTim . ", "page_idx": 40}, {"type": "text", "text": "G Omitted Details of Section 4 ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "G.1 Notations ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "We use $e_{i}\\in\\mathbb{R}^{d}$ to denote a vector whose $i$ -th coordinate is one and all others are zero. For any two vectors $x,y\\in\\mathbb{R}^{d}$ , $x\\leq y$ indicates that $x_{i}\\leq y_{i}$ holds for each coordinate $i$ . Fo\u221ar a positive definite matrix $A\\in\\mathbb{R}^{d\\times d}$ , the weighted 2-norm of vector $\\boldsymbol{x}\\in\\mathbb{R}^{d}$ is given by $\\|x\\|_{A}={\\sqrt{x^{\\top}A x}}$ . For matrix $A=[a_{1},\\cdot\\cdot\\cdot\\,,a_{d}]\\in\\mathbb{R}^{d\\times d}$ with each $a_{i}\\in\\mathbb{R}^{d}$ , we use $A_{-i}$ to denote the $(d-1)$ -tuple of vectors $[a_{1},\\cdot\\cdot\\cdot\\ ,a_{i-1},a_{i+1},\\cdot,a_{d}]$ . For matrices $A,B$ , we use $A\\succ B$ to indicate that $A-B$ is positive definite. For two sets $A,B$ , we use $A-B$ to indicate the exclusion. For any scalar $C\\in\\mathbb{R}$ , we use $\\vec{C}$ to denote a vector, with all coordinates equal to $C$ . ", "page_idx": 40}, {"type": "text", "text": "G.2 Key Technique: Adaptive Barycentric Spanner ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Algorithm description. Algorithm 12 aims to identify a finite arm set $B_{m}$ to linearly represent the (possibly infinite) active arm set $A_{m}$ , so that playing arms in $B_{m}$ allows us to obtain an accurate estimation of $\\langle a,\\theta\\rangle$ for each $a\\in A_{m}$ . ", "page_idx": 40}, {"type": "text", "text": "Algorithm 12\u221a initializes a matrix $A=[a_{1},\\ldots,a_{d}]$ whose column vectors are linearly independent, and $a_{i}=e_{i}/\\sqrt{T_{m}}$ . At the beginning, the algorithm solves (42) to find an empirical best arm $a_{m}^{\\star}$ (line 1-6). Then, in two for-loops (line 7-10 and line 11-16), the algorithm tries to replace each column vector of $A$ with an active arm $a\\in A_{m}$ by invoking the subroutine LI-Argmax in Algorithm 13, while keeping column vectors of $A$ linearly independent. For each column $i$ , LI-Argmax attempts to find $\\operatorname*{max}_{a\\in\\mathcal{A}_{m}}|\\operatorname*{det}(a,A_{-i})|^{9}$ by solving (43) with $a_{m}^{\\star}$ . If $\\mathrm{max}_{a\\in\\mathcal{A}_{m}}\\,|\\,\\mathrm{det}(a,A_{-i})|=0$ , then, ", "page_idx": 40}, {"type": "text", "text": "Algorithm 13 Linear-independent argmax (LI-Argmax) ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Input: compact arm set $\\boldsymbol{\\mathcal{A}}$ , matrix $A$ , estimation $\\widehat{\\theta}_{m}$ , spanner $\\scriptstyle B_{m-1}$ , and phase $m$ , parameter $C$ , and arm $a_{m}^{\\star}$ . 1 Find $u\\in\\mathbb{R}^{d}$ s.t. $\\langle u,x\\rangle=\\operatorname*{det}{(x,A_{-i})},\\forall x\\in\\mathbb{R}^{d}$ . 2 Query oracle to obtain $a^{+}$ , the solution of ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in\\cal{A}}{\\mathrm{argmax}}\\left\\langle u,a\\right\\rangle}\\\\ &{\\quad\\quad\\mathrm{s.t.}\\,\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1},}\\\\ &{M_{m}a=\\vec{0},\\,-\\,\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a\\leq\\vec{C}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "3 Query oracle to get $a^{-}$ from (43) by replacing $u$ with $-u$ . 4 if $\\langle u,a^{+}\\rangle=0$ and $\\langle u,a^{-}\\rangle=0$ then Return: NULL. ", "page_idx": 41}, {"type": "text", "text": "Return: $\\begin{array}{r}{\\operatorname{argmax}_{b\\in\\{a^{+},a^{-}\\}}|\\langle u,b\\rangle|.}\\end{array}$ ", "page_idx": 41}, {"type": "text", "text": "the algorithm returns NULL, since there does not e\u221axist an active arm that can maintain the linear independence. In this case, the algorithm keeps $e_{i}/\\sqrt{T_{m}}$ in the $i$ -th column of $A$ . Otherwise, $a_{i}$ will be updated to $s_{i}\\,\\in\\,\\mathrm{argmax}_{a\\in{\\cal A}_{m}}\\,|\\,\\mathrm{det}(a,{\\cal A}_{-i})|$ . We use set ${\\mathcal{T}}_{m}$ to record the indices of columns where the replacement fails. According to the conditions in line 14, the second for-loop will be repeatedly restarted to ensure that the linear combination of elements in $B_{m}$ can represent all active arms in $A_{m}$ with coefficients in the range of $[-C,C]$ . Also note that, as shown in Theorem 4.2, LI-Argmax will be oracle-efficient as it only queries the oracle $\\widetilde{\\mathcal{O}}\\left(d^{3}\\right)$ times. ", "page_idx": 41}, {"type": "text", "text": "Formally, we have the following result. ", "page_idx": 41}, {"type": "text", "text": "Lemma G.1. Suppose $C>1$ and $B_{m}$ is the output of Algorithm $^{12}$ in phase m. Then, for all $m\\in\\mathbb{N}$ , $B_{m}$ is a $C$ -approximate barycentric spanner of $A_{m}$ . ", "page_idx": 41}, {"type": "text", "text": "G.3 Computational Analysis ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Recall from the previous subsection that Algorithm 12 and LI-Argmax needs to find the empirical best arm $a_{m}^{\\star}$ and $\\operatorname{argmax}_{a\\in\\mathcal{A}_{m}}|\\operatorname*{det}(a,A_{-i})|$ , both of which rely on the access to the following optimization oracle. ", "page_idx": 41}, {"type": "text", "text": "Definition G.2 (Optimization oracle). Given a compact set $\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ , the oracle can solve problems of the form ", "page_idx": 41}, {"type": "equation", "text": "$$\n{\\underset{a\\in\\mathcal{A}}{\\operatorname{argmax}}}\\left\\langle\\theta,a\\right\\rangle,\\quad{\\mathrm{s.t.}}\\quad U a=\\vec{\\beta_{1}},\\quad V a\\leq\\vec{\\beta_{2}},\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "for any $\\beta_{1},\\beta_{2}\\in\\mathbb{R},$ , $\\theta\\in\\ensuremath{\\mathbb{R}}^{d}$ , $U\\in\\mathbb{R}^{\\tau_{1}\\times d},$ , $V\\in\\mathbb{R}^{\\tau_{2}\\times d}$ , where $\\tau_{1},\\tau_{2}$ are at most $O(d)$ . If the optimal solution is not unique, the oracle returns any one of them. ", "page_idx": 41}, {"type": "text", "text": "We note that the constrained optimization oracles are commonly-used and also crucial for eliminationtype approaches e.g., [Bibaut et al., 2020, Li et al., 2022]. Although this oracle is slightly powerful than that used for non-elimination based approaches [Dani et al., 2008, Agarwal et al., 2014], linear constrained oracle, in fact, can be implemented efficiently in many cases (e.g., a common assumption that $\\boldsymbol{\\mathcal{A}}$ is a ball [Plevrakis and Hazan, 2020]) via the ellipsoid method. We refer readers to [Bibaut et al., 2020, Plevrakis and Hazan, 2020] for more discussions. ", "page_idx": 41}, {"type": "text", "text": "With the optimization oracle in hand, our goal here is to query the oracle to solve the optimization problem $\\operatorname*{argmax}_{a\\in\\mathcal{A}_{m}}|\\operatorname*{det}(a,A_{-i})|$ , which can be rewritten as follows based on Eq. (3). ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\operatorname*{argmax}_{a\\in\\mathcal{A}_{m-1}}|\\operatorname*{det}(a,A_{-i})|{\\mathrm{s.t.}}\\left\\langle{\\widehat{\\theta}}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Problem (44) also needs to find the empirical best arm $a_{m}^{\\star}$ . A natural idea to compute the empirical best arm $a_{m}^{\\star}$ is to solve $\\operatorname{argmax}_{a\\in A_{m-1}}\\langle\\widehat{\\theta}_{m},a\\rangle$ . Notice that both finding $a_{m}^{\\star}$ and solving Eq. (44) ", "page_idx": 41}, {"type": "text", "text": "require to deal with constraint $a\\in A_{m-1}$ . However, this constrain prevents us from querying the optimization oracle due to the following reason. ", "page_idx": 42}, {"type": "text", "text": "Issue: $a\\in A_{m-1}$ may cause a large (even infinite) number of constraints. One can rewrite $a\\in A_{m-1}$ as: ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\left\\{a\\in\\mathcal{A}:\\left\\langle\\widehat{\\theta}_{\\tau},a_{\\tau}^{\\star}-a\\right\\rangle\\leq2^{-\\tau+1},\\forall\\tau\\leq m-1\\right\\}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "However, the evolution of phases blows up the number of constraints in (45) (e.g., when $m=$ $\\Omega(\\exp(d))$ , which prevents LI-Argmax from directly querying the optimization oracle defined in Definition G.2, since it requires the number of constraints at most $O(d)$ . To address this issue, one needs to remove the dependence on $m$ . ", "page_idx": 42}, {"type": "text", "text": "Solution: enlarging active arm set $A_{m-1}$ . Our solution is to slightly enlarge the active arm set $A_{m-1}$ in Eq. (45) so that the enlarged set can be expressed by finitely-many linear constraints, independent of $m$ . Before showing the way to enlarging $A_{m-1}$ , we first give the following definition. ", "page_idx": 42}, {"type": "text", "text": "Definition G.3 ( $C$ -bounded spanner). For any given set $\\mathcal{S}\\subseteq\\mathbb{R}^{d}$ and constant $C>0$ , $S p a n_{[-C,C]}(S)$ , defined as follows, is a set that contains all possible linear combinations from $\\boldsymbol{S}$ with coefficients within $[-C,C]$ . ", "page_idx": 42}, {"type": "equation", "text": "$$\nS p a n_{[-C,C]}(S)=\\left\\{\\sum_{s\\in\\cal S}c_{s}\\cdot s:\\forall c_{s}\\in[-C,C]\\right\\},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where $c_{s}$ is the coefficient associated with element $s$ . ", "page_idx": 42}, {"type": "text", "text": "We enlarge $A_{m-1}$ to $A\\cap\\operatorname{Span}_{[-C,C]}(B_{m-1})$ , and one can easily verify that this is true since $A_{m-1}\\cap A=A_{m-1}$ and Lemma G.1 implies that $A_{m-1}\\subseteq\\operatorname{Span}_{[-C,C]}(B_{m-1})$ . ", "page_idx": 42}, {"type": "text", "text": "Now, it remains to show that $\\mathrm{Span}_{[-C,C]}(B_{m-1})$ can be expressed by ${\\mathcal{O}}\\left(d\\right)$ number of linear constraints. The following lemma gives the desired result. ", "page_idx": 42}, {"type": "text", "text": "Lemma G.4. Suppose that $|B_{m-1}|\\ \\ <\\ \\ d.$ . For $M_{m}$ and $B_{m-1}$ given in Algorithm 12, $S p a n_{[-C,C]}(B_{m-1})$ can be equivalently written as ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\left\\{a\\in\\mathbb{R}^{d}:M_{m}a=\\vec{0},-\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a\\leq\\vec{C}\\right\\}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Hence, LI-Argmax can invoke the optimization oracle in Definition G.2 to solve problems of $\\operatorname{argmax}_{a\\in\\mathcal{A}_{m-1}}\\langle\\widehat{\\theta}_{m},a\\rangle$ and (44) approximately by solving (42) and (43), respectively. ", "page_idx": 42}, {"type": "text", "text": "Computational efficiency. We mainly focus on two costly steps in Algorithm 12. The first step is to use Gaussian elimination to obtain the matrix $M_{m}\\in\\dot{\\mathbb{R}}^{n\\breve{\\times}d}$ for some $n\\leq d$ . This step can be done with at most $O(d^{3})$ complexity and is implemented at most once for each phase $m$ . The other expensive step is to query the optimization oracle to construct a $C$ -approximate barycentric spanner. The number of calls to the oracle depends on the number of times that Algorithm 12 invokes LI-Argmax subroutine. The LI-Argmax will be invoked for $d$ times in the first for-loop. For the second for-loop, LI-Argmax will be invoked for $\\widetilde{\\mathcal{O}}\\left(d^{3}\\right)$ times. Compared with $\\widetilde{\\mathcal{O}}\\left(d^{2}\\right)$ in [Awerbuch and Kleinberg, 2008], the extra $d$ in our complexity comes from the additional restart-condition $i\\in{\\mathcal{Z}}_{m}$ in line 14 of Algorithm 12. As $|\\bar{Z_{m}}\\bar{|}\\leq\\,\\bar{d}$ and ${\\mathcal{T}}_{m}$ is non-increasing when update, this condition will be met for at most $d$ times. ", "page_idx": 42}, {"type": "text", "text": "G.4 Proof of Lemma G.4 ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Lemma G.5 (Restatement of Lemma G.4). Suppose that $|B_{m-1}|<d.$ . For $M_{m}$ and $B_{m-1}$ given in Algorithm $^{12}$ , the set Sp $a n_{[-C,C]}(\\beta_{m-1})=\\bar{\\mathcal{H}_{m}}$ where ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}_{m}=\\left\\{a\\in\\mathbb{R}^{d}:M_{m}a=\\vec{0},-\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a\\leq\\vec{C}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Proof. For this proof, we show that $a\\in\\mathrm{Span}_{[-C,C]}(B_{m-1})$ if and only if $a\\in\\mathcal{H}_{m}$ . ", "page_idx": 42}, {"type": "text", "text": "We first show that if $a\\,\\in\\,\\mathrm{Span}_{[-C,C]}({\\mathcal{B}}_{m-1})$ , then $a\\in\\mathcal{H}_{m}$ . As matrix $M_{m}\\,\\in\\,\\mathbb{R}^{(d-|\\mathcal{B}_{m-1}|)\\,\\times\\,d}$ is defined by $\\operatorname{Span}(\\mathcal{B}_{m-1})=\\{x\\in\\mathbb{R}^{d}:M_{m}x=\\vec{0}\\},$ , $a\\in\\mathrm{Span}_{[-C,C]}(\\mathscr{B}_{m-1})\\subseteq\\mathrm{Span}(\\mathscr{B}_{m-1})$ gives that $M_{m}a=\\vec{0}$ . Recall that $B_{m-1}\\in\\mathbb{R}^{d\\times|B_{m-1}|}$ is a matrix whose the $i$ -th column is the $i$ -th element of set $\\boldsymbol{B}_{m-1}$ and $\\mathrm{rank}(B_{m-1})=|B_{m-1}|$ because $\\scriptstyle B_{m-1}$ is linearly independent. Therefore, for each $a\\in\\mathrm{Span}_{[-C,C]}({\\mathcal{B}}_{m-1})$ , there exists a unique vector10 $\\boldsymbol{x}_{a}\\in\\mathbb{R}^{|\\boldsymbol{B}_{m-1}|}$ such that $B_{m-1}x_{a}=a$ and the value of each coordinate of $x_{a}$ is no larger than $C$ . As $\\boldsymbol{B}_{m-1}$ is linearly independent, $B_{m-1}$ is a full-column rank matrix, which gives that $x_{a}\\;=\\;\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a$ . As a result, if $a\\in\\mathrm{Span}_{[-C,C]}({\\cal B}_{m-1})$ , then, $-\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}\\vec{B_{m-1}^{\\top}}a\\leq\\vec{C}$ , which concludes the proof of this argument. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "Then, we show that if $a\\ \\in\\ \\mathcal{H}_{m}$ , then, $a\\;\\;\\in\\;\\;\\mathrm{Span}_{[-C,C]}({\\cal B}_{m-1})$ . If $M_{m}a~=~{\\vec{0}}$ , then, we have $a\\ \\in\\ \\operatorname{Span}(B_{m-1})$ due to the definition of $M_{m}$ . As $\\mathrm{rank}(B_{m-1})~=~|B_{m-1}|$ , for each $a\\;\\in\\;\\mathrm{Span}(B_{m-1})$ , there exists a unique vector $x_{a}\\ \\in\\ \\mathbb{R}^{|B_{m-1}|}$ such that $B_{m-1}x_{a}\\;=\\;a$ , which gives that $x_{a}\\,=\\,\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a$ . Thus, $-\\vec{C}\\,\\le\\,\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a\\,\\le\\,\\vec{C}$ requires each coordinate of $x_{a}$ no larger than $C$ . As a consequence, if $a\\in\\mathcal{H}_{m}$ , then, $a\\in\\mathrm{Span}_{[-C,C]}(B_{m-1})$ . Combining the above analysis, we complete the proof. ", "page_idx": 43}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "G.5 Proof of Lemma G.1 ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "In this section, we aim to show that $B_{m}$ is a $C$ -approximate barycentric spanner of $A_{m}$ . To this end, we first show that $B_{m}$ is a $C$ -approximate barycentric spanner of ${\\mathcal{S}}_{m}$ which is defined below and ${\\mathcal{A}}_{m}\\subseteq S_{m}$ results in the desired claim. In fact, throughout our analysis, we stick with ${\\mathcal{S}}_{m}$ rather than Am. ", "page_idx": 43}, {"type": "equation", "text": "$$\nS_{1}=A,\\quad S_{m}=\\left\\{a\\in A:\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1},\\,a\\in\\mathrm{Span}_{[-C,C]}\\left(\\mathbb{B}_{m-1}\\right)\\right\\},\\,\\forall m\\geq2.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Moreover, according to Lemma G.4, for all $m\\geq2$ , $S_{m}$ can also be equivalently rewritten as: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{S_{m}=\\left\\{a\\in A:\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1},\\ M_{m}a=\\vec{0},\\ -\\vec{C}\\leq\\left(B_{m-1}^{\\top}B_{m-1}\\right)^{-1}B_{m-1}^{\\top}a\\leq\\vec{C}\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Lemma G.6. Let $C\\,>\\,1$ and $B_{m}$ is in Algorithm 2. For all $m\\,\\in\\,\\mathbb{N}$ , $B_{m}$ is a $C$ -approximate barycentric spanner of $\\ensuremath{\\boldsymbol{S}}_{m}$ . ", "page_idx": 43}, {"type": "text", "text": "Proof. For all $m~\\in~\\mathbb{N}$ , we define $\\begin{array}{r}{\\mathcal{B}_{m}^{\\prime}\\;=\\;\\mathcal{B}_{m}\\cup\\left(\\cup_{i\\in\\mathbb{Z}_{m}}\\frac{e_{i}}{\\sqrt{T_{m}}}\\right)}\\end{array}$ . We further define set ${\\cal{S}}_{m}^{\\prime}\\;=\\;$ $\\begin{array}{r}{S_{m}\\cup\\left(\\cup_{i\\in\\mathcal{Z}_{m}}\\frac{e_{i}}{\\sqrt{T_{m}}}\\right)}\\end{array}$ , and matrix $B_{m}^{\\prime}\\;=\\;[b_{1},\\cdot\\cdot\\cdot\\;,b_{d}]$ where $b_{i}$ is the $i$ -th element of $B_{m}^{\\prime}$ . By these definitions, $\\begin{array}{r}{b_{i}=\\frac{e_{i}}{\\sqrt{T_{m}}}}\\end{array}$ for all $i\\in\\mathcal{Z}_{m}$ . The proof consists of three steps, and we first proceed step 1. ", "page_idx": 43}, {"type": "text", "text": "Step 1: each solution of (43) is in ${\\mathcal{S}}_{m}$ . According to the optimization problem (43), for each phase $m$ , the solution is drawn from (see Eq. (47) for definition of $\\mathcal{H}_{m}$ ) ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{H}_{m}\\cap\\left\\{a\\in\\mathcal{A}:\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1}\\right\\}}\\\\ &{={\\mathrm{Span}}_{[-C,C]}(\\mathcal{B}_{m-1})\\cap\\left\\{a\\in\\mathcal{A}:\\left\\langle\\widehat{\\theta}_{m},a_{m}^{\\star}-a\\right\\rangle\\leq2^{-m+1}\\right\\}}\\\\ &{=S_{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first equality holds due to Lemma G.4 and the last equality holds due to Eq. (48). ", "page_idx": 43}, {"type": "text", "text": "Step 2: $B_{m}^{\\prime}$ is a $C$ -approximate barycentric spanner of ${\\cal{S}}_{m}^{\\prime}$ . The proof idea of this step follows a similar arguments of Proposition 2.2 and Proposition 2.5 in [Awerbuch and Kleinberg, 2008]. In Algorithm 12, each update for matrix $A\\in\\mathbb{R}^{d\\times d}$ always maintains $|\\operatorname*{det}(A)|>0$ , and thus $B_{m}^{\\prime}$ spans $\\mathbb{R}^{d}$ . As $S_{m}^{\\prime}\\subseteq\\mathbb{R}^{d}$ , every element $a\\in S_{m}^{\\prime}$ can be linearly represented by $\\textstyle a=\\sum_{i=1}^{d}w_{i}b_{i}$ for some coefficients $\\{w_{i}\\}_{i=1}^{d}$ , and then we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\left|\\operatorname*{det}\\left(a,(B_{m}^{\\prime})_{-i}\\right)\\right|=\\left|\\operatorname*{det}\\left(\\sum_{i=1}^{d}w_{i}b_{i},(B_{m}^{\\prime})_{-i}\\right)\\right|=\\left|\\sum_{i=1}^{d}w_{i}\\operatorname*{det}\\left(b_{i},(B_{m}^{\\prime})_{-i}\\right)\\right|=\\left|w_{i}\\right|\\left|\\operatorname*{det}(B_{m}^{\\prime})\\right|.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Step 1 shows that each solution of (43) is in ${\\mathcal{S}}_{m}$ , and thus $B_{m}\\subseteq S_{m}$ , which further implies $B_{m}^{\\prime}\\subseteq S_{m}^{\\prime}$ . Recall that before the termination, the algorithm will scan each column vector of matrix $A$ to ensure that no more replacement can be made. Hence, once Algorithm 12 terminates, we have that $\\forall i\\in[d]$ , $\\begin{array}{r}{\\operatorname*{sup}_{a\\in S_{m}^{\\prime}}|\\operatorname*{det}(\\bar{a},(B_{m}^{\\prime})_{-i})|\\leq C\\,|\\mathrm{det}(B_{m}^{\\prime})|}\\end{array}$ , and then $\\forall i\\in[d],|w_{i}|\\leq C$ , which implies that $B_{m}^{\\prime}$ is a $C$ -approximate barycentric spanner of ${\\cal{S}}_{m}^{\\prime}$ . ", "page_idx": 44}, {"type": "text", "text": "Step 3: $B_{m}$ is a $C$ -approximate barycentric spanner of ${\\mathcal{S}}_{m}$ . Here, we show that every $a\\in S_{m}$ can be written as a linear combination of elements only in $B_{m}$ with coefficients in $[-C,C]$ . Notice that we only need to consider $a\\,\\in\\,S_{m}\\,-\\,B_{m}$ since if $a\\,\\in\\,B_{m}$ , then, one can find a trivial linear combination by itself (recall that we assume $C\\,>\\,1$ ). Then, we prove the desired claim for all $a\\in S_{m}-B_{m}$ by contradiction. Suppose that there exists an arm $a\\in S_{m}-B_{m}$ such that it cannot be linearly represented only by elements in $B_{m}$ with coefficients in $[-C,C]$ . As $S_{m}\\subseteq S_{m}^{\\prime}$ and $B_{m}^{\\prime}$ is a $C$ -approximate barycentric spanner of ${\\cal{S}}_{m}^{\\prime}$ (shown in step 2), there must exist coefficients $\\{d_{i}\\}_{i=1}^{d}$ to linearly represent $a$ as: ", "page_idx": 44}, {"type": "equation", "text": "$$\na=\\sum_{i=1}^{d}d_{i}b_{i},\\quad\\forall i\\in[d],\\ d_{i}\\in[-C,C],\\quad{\\mathrm{and}}\\quad\\exists i\\in{\\mathbb{Z}}_{m}{\\mathrm{~such~that~}}d_{i}\\neq0.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "As for Eq. (49), we assume without loss of generality that the coefficient index $j\\in\\mathcal{Z}_{m}$ satisfies $d_{j}\\neq0$ . Since $a\\notin B_{m}$ , the second for-loop in Algorithm 12 ensures that $a$ can be represented as a linear combination of $\\{b_{i}\\}_{i\\in[d]:i\\neq j}$ , and it would be put in $B_{m}$ otherwise (recall that Algorithm 12 terminates the second for-loop, when it scans every column vector of $A$ and makes no replacement). Hence, there exist coefficients $\\{c_{i}\\}_{i\\in[d]:i\\neq j}$ such that ", "page_idx": 44}, {"type": "equation", "text": "$$\na=\\sum_{i\\in[d]:i\\neq j}c_{i}b_{i},\\quad\\forall i\\neq j,\\,c_{i}\\in\\mathbb{R},.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Bridging Eq. (49) and Eq. (50), we have ", "page_idx": 44}, {"type": "equation", "text": "$$\nd_{j}b_{j}=\\sum_{i\\neq j}\\left(c_{i}-d_{i}\\right)b_{i}\\;\\longrightarrow\\;b_{j}=\\frac{1}{d_{j}}\\sum_{i\\neq j}\\left(c_{i}-d_{i}\\right)b_{i},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "which implies that the $j$ -th element of $B_{m}^{\\prime}$ , i.e., $b_{j}$ can be expressed as a linear combination of other elements of $B_{m}^{\\prime}$ , i.e., $\\{b_{i}\\}_{i\\neq j}$ . This leads to a contradiction because Algorithm 12 ensures $B_{m}^{\\prime}$ to be linearly independent. As a consequence, every element of $a\\in S_{m}$ can be written as a linear combination of elements only in $B_{m}$ with coefficients in $[-C,C]$ , which completes the proof. ", "page_idx": 44}, {"type": "text", "text": "Proof of Lemma G.1. Recall from Eq. (3) that $A_{m}$ is defined as ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}_{1}=\\mathcal{A},\\quad\\mathcal{A}_{m}=\\left\\{\\boldsymbol{a}\\in\\mathcal{A}_{m-1}:\\left\\langle\\widehat{\\theta}_{m},\\boldsymbol{a}_{m}^{\\star}-\\boldsymbol{a}\\right\\rangle\\leq2^{-m+1}\\right\\},\\quad\\forall m\\geq2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Since Lemma G.6 gives that $B_{m}$ is a $C$ -approximate barycentric spanner of ${\\mathcal{S}}_{m}$ , it suffices to show that ${\\mathcal{A}}_{m}\\subseteq S_{m}$ to prove the claimed result. We prove this by induction. For the base case $m=1$ , ${\\mathcal{A}}_{1}\\subseteq S_{1}$ trivially holds based on definitions. Suppose that ${\\mathcal{A}}_{m}\\subseteq S_{m}$ holds for $m\\geq2$ . For $m+1$ , $A_{m+1}$ is defined as: ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}_{m+1}=\\left\\{\\boldsymbol{a}\\in\\mathcal{A}_{m}:\\left\\langle\\widehat{\\theta}_{m+1},\\boldsymbol{a}_{m+1}^{\\star}-\\boldsymbol{a}\\right\\rangle\\leq2^{-m}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Since Lemma G.6, gives that $B_{m}$ is a $C$ -approximate barycentric spanner of ${\\mathcal{S}}_{m}$ , and the inductive hypothesis gives ${\\mathcal{A}}_{m}\\subseteq S_{m}$ , we have $\\mathcal{A}_{m}\\subseteq\\mathrm{Span}_{[-C,C]}(\\mathcal{B}_{m})$ , which implies that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\cal A}_{m+1}=\\Bigl\\{a\\in{\\cal A}_{m}:\\Bigl\\langle\\widehat{\\theta}_{m+1},a_{m+1}^{\\star}-a\\Bigr\\rangle\\le2^{-m}\\Bigr\\}}\\\\ &{\\qquad=\\Bigl\\{a\\in{\\cal A}:\\Bigl\\langle\\widehat{\\theta}_{m+1},a_{m+1}^{\\star}-a\\Bigr\\rangle\\le2^{-m},a\\in{\\cal A}_{m}\\Bigr\\}}\\\\ &{\\qquad\\subseteq\\Bigl\\{a\\in{\\cal A}:\\Bigl\\langle\\widehat{\\theta}_{m+1},a_{m+1}^{\\star}-a\\Bigr\\rangle\\le2^{-m},\\ a\\in\\mathrm{Span}_{[-C,C]}\\left({\\cal B}_{m}\\right)\\Bigr\\}}\\\\ &{\\qquad=S_{m+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Once the induction is done, the proof is complete. ", "page_idx": 44}, {"type": "text", "text": "G.6 Proof of Theorem 4.2: Regret Analysis ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Before proving Theorem 4.2, we first present technical concept and lemmas. We first formally introduce the concept of $C$ -approximate optimal design, both of which help us to prove a stronger result of Eq. (4), paving the way to prove the main theorem. Let $\\Delta(A)$ be the set of all Radon probability measures over set $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 45}, {"type": "text", "text": "Definition G.7 ( $C$ -approximate optimal design). Suppose that $\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ is a finite and compact set. A distribution $\\pi\\in\\Delta({\\mathcal{A}})$ is called a $C$ -approximate optimal design with an approximation factor $C\\geq1$ , $i f$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{a\\in\\mathcal{A}}\\|a\\|_{V(\\pi;\\mathcal{A})^{-1}}^{2}\\leq C\\cdot d,\\quad w h e r e\\quad V(\\pi;\\mathcal{A})=\\sum_{a\\in\\mathcal{A}}\\pi(a)a a^{\\top}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Then, the following lemma shows that if one computes a uniform design for set $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , a barycentric spanner for another set $\\boldsymbol{\\mathcal{A}}$ , then, playing arms in $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ can guarantee accurate estimations over $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 45}, {"type": "text", "text": "Lemma G.8 (Lemma 2 of [Zhu et al., 2022]). Suppose that $\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ is a compact set that spans $\\mathbb{R}^{d}$ . If $B\\,=\\,[b_{1},\\cdot\\cdot\\cdot\\,,b_{d}]$ is a $C$ -approximate barycentric spanner for $\\mathcal{A}$ , then, $\\pi:\\textstyle B\\;\\to\\;{\\frac{1}{d}}$ is $a$ $(C^{2}\\cdot d)$ -approximate optimal design, which guarantees ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{a\\in\\mathcal{A}}\\|a\\|_{V(\\pi;\\mathcal{B})^{-1}}^{2}\\leq C^{2}\\cdot d^{2},\\quad w h e r e\\quad V(\\pi;\\mathcal{B})=\\sum_{b\\in\\mathcal{B}}\\pi(b)b b^{\\top}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "We then present the following lemma which provides a stronger result than that of Eq. (4). More specifically, we are supposed to show that $\\|a\\|_{V_{m}^{-1}}\\leq C\\cdot d/\\sqrt{T_{m}}$ holds for all $a\\in A_{m}$ in Eq. (4), but we will show that this holds for all $a\\in S_{m}$ . This is stronger since ${\\mathcal{A}}_{m}\\subseteq S_{m}$ for all $m\\in\\mathbb{N}$ . ", "page_idx": 45}, {"type": "text", "text": "Lemma G.9. For ${\\mathcal{S}}_{m}$ defined in Eq. (48) and $B_{m}$ returned by Algorithm $^{12}$ , setting $\\textstyle\\pi_{m}(a)={\\frac{1}{d}}$ for each $a\\in\\boldsymbol{B_{m}}$ and playing each arm $a\\in B_{m}$ for $n_{m}(a)=\\lceil\\dot{T_{m}}\\pi_{m}^{-}(a)\\rceil$ times ensure that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\forall a\\in S_{m},\\quad\\|a\\|_{V_{m}^{-1}}\\leq\\frac{C\\cdot d}{\\sqrt{T_{m}}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Proof. For all $m\\in\\mathbb{N}$ , we define $\\begin{array}{r}{\\mathcal{B}_{m}^{\\prime}=\\mathcal{B}_{m}\\cup\\left(\\cup_{i\\in\\mathcal{Z}_{m}}\\frac{e_{i}}{\\sqrt{T_{m}}}\\right)}\\end{array}$ and ", "page_idx": 45}, {"type": "equation", "text": "$$\nV(\\pi_{m};B_{m}^{\\prime})=\\sum_{a\\in B_{m}^{\\prime}}\\pi_{m}(a)a a^{\\top}=\\sum_{a\\in B_{m}}\\pi_{m}(a)a a^{\\top}+\\sum_{a\\in B_{m}^{\\prime}-B_{m}}\\pi_{m}(a)a a^{\\top}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "With this definition and also the definition $\\begin{array}{r}{n_{m}(a)=\\lceil T_{m}\\pi_{m}(a)\\rceil}\\end{array}$ , we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{V_{m}=I+\\displaystyle\\sum_{a\\in\\mathcal{B}_{m}}n_{m}(a)a a^{\\top}}}\\\\ {{\\phantom{V_{m}=\\Gamma+\\displaystyle\\sum_{i=1}^{r}\\displaystyle\\sum_{a\\in\\mathcal{B}_{m}}\\pi_{m}(a)a a^{\\top}}}}\\\\ {{\\phantom{\\sum}\\sim T_{m}V(\\pi_{m};\\mathcal{B}_{m}^{'}),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where the last step follows from the fact that ", "page_idx": 45}, {"type": "equation", "text": "$$\nI=T_{m}\\sum_{i=1}^{d}\\frac{e_{i}}{\\sqrt{T_{m}}}\\frac{e_{i}^{\\top}}{\\sqrt{T_{m}}}\\succ T_{m}\\sum_{i\\in\\mathbb{Z}_{m}}\\pi_{m}\\left(\\frac{e_{i}}{\\sqrt{T_{m}}}\\right)\\frac{e_{i}}{\\sqrt{T_{m}}}\\frac{e_{i}^{\\top}}{\\sqrt{T_{m}}}=T_{m}\\sum_{a\\in B_{m}^{\\prime}-B_{m}}\\pi_{m}(a)a a^{\\top}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Since $B_{m}^{\\prime}$ spans $\\mathbb{R}^{d}$ and $B_{m}^{\\prime}\\subseteq\\operatorname{Span}_{[-C,C]}\\left(B_{m}^{\\prime}\\right)$ , set $\\mathrm{Span}_{[-C,C]}\\left(\\!B_{m}^{\\prime}\\right)$ also spans $\\mathbb{R}^{d}$ . Lemma G.8 gives that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\forall a\\in\\mathbf{Span}_{[-C,C]}\\left(\\mathcal{B}_{m}^{\\prime}\\right),\\quad\\|a\\|_{(V(\\pi_{m};B_{m}^{\\prime}))^{-1}}\\leq C\\cdot d.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Thus, one can use Eq. (52) to show that for all ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\forall a\\in\\mathsf{S p a n}_{[-C,C]}\\left(\\mathcal{B}_{m}^{\\prime}\\right),\\quad\\|a\\|_{V_{m}^{-1}}\\leq\\frac{\\|a\\|_{(V(\\pi_{m};\\mathcal{B}_{m}^{\\prime}))^{-1}}}{\\sqrt{T_{m}}}\\leq\\frac{C\\cdot d}{\\sqrt{T_{m}}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "As $B_{m}$ is a $C$ -approximate barycentric spanner of $\\ensuremath{\\boldsymbol{S}}_{m}$ , we have $S_{m}\\ \\subseteq\\ \\operatorname{Span}_{[-C,C]}\\left({\\mathcal{B}}_{m}\\right)\\ \\subseteq$ $\\mathrm{Span}_{[-C,C]}\\left(\\mathscr{B}_{m}^{\\prime}\\right)$ , the proof is thus complete. \u53e3 ", "page_idx": 45}, {"type": "text", "text": "The following analysis will condition on the nice event $\\mathcal{E}$ , defined as: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathcal{E}=\\left\\{\\forall m\\in\\mathbb{N}:\\left|\\left\\langle a,\\widehat{\\theta}_{m+1}-\\theta\\right\\rangle\\right|\\leq2^{-m-1}\\operatorname{for}\\mathrm{all}\\;a\\in S_{m}\\right\\},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where ${\\mathcal{S}}_{m}$ is defined in Eq. (48). ", "page_idx": 46}, {"type": "text", "text": "Lemma G.10. We have $\\mathbb{P}(\\pmb{\\mathscr{E}})\\geq1-\\delta$ . ", "page_idx": 46}, {"type": "text", "text": "Proof. One can show that ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\forall a\\in S_{m},\\quad\\left|\\left\\langle a,\\widehat{\\theta}_{m+1}-\\theta\\right\\rangle\\right|\\leq\\left\\|a\\right\\|_{V_{m}^{-1}}\\left\\|\\widehat{\\theta}_{m+1}-\\theta\\right\\|_{V_{m}}\\leq\\frac{C\\cdot d}{\\sqrt{T_{m}}}\\left\\|\\widehat{\\theta}_{m+1}-\\theta\\right\\|_{V_{m}},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where the first inequality uses Cauchy-Schwartz inequality and the second inequality uses Lemma G.9. ", "page_idx": 46}, {"type": "text", "text": "Notice that the above inequality holds for all $m\\,\\in\\,\\mathbb{N}$ . Finally, Theorem 20.5 of [Lattimore and Szepesv\u00e1ri, 2020] shows that with probability at least $1-\\delta$ , for all $m\\in\\mathbb{N}$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\widehat{\\theta}_{m+1}-\\theta\\right\\rVert_{V_{m}}\\leq2\\sqrt{\\log(1/\\delta)+d\\log(T_{m})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Combining Eq. (55) and Eq. (54), we have that $\\forall a\\in S_{m}$ , ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\langle a,\\hat{\\theta}_{m+1}-\\theta\\right\\rangle\\Big|}\\\\ &{\\le2C d\\gamma\\frac{\\left\\langle\\log(1/\\delta)+d\\log(T_{m})\\right.}{T_{m}}}\\\\ &{\\le\\frac{1}{N C}\\cdot2^{-m}\\sqrt{\\frac{\\log(1/\\delta)}{2}+\\log(2\\zeta\\upsilon C^{4}\\cdot\\frac{a^{2}}{N C}\\log(\\frac{\\theta^{4/4}\\upsilon}{\\delta}))}}\\\\ &{=\\frac{1}{N C}\\cdot2^{-m}\\sqrt{\\frac{4\\log(4C/\\delta)}{16}+\\log(\\frac{\\theta^{4/4}\\upsilon}{\\delta})\\log(\\frac{\\theta^{4/4}\\upsilon}{\\delta})}}\\\\ &{\\le\\frac{1}{N C}\\cdot2^{-m}\\sqrt{\\frac{\\log(4C/\\delta)}{16}+\\log(\\frac{\\theta^{4}\\upsilon}{\\delta})}}\\\\ &{\\le\\frac{1}{N C}\\cdot2^{-m}\\sqrt{\\frac{4C}{N\\theta}\\log(\\frac{\\theta^{4}\\upsilon}{\\delta})}}\\\\ &{\\le\\frac{1}{N C}\\cdot2^{-m}\\sqrt{\\frac{\\log(1/\\delta)}{16}+\\frac{\\log(1)}{N}}}\\\\ &{=2^{-m-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where the third inequality uses $4\\log(4x)\\leq8x$ for all $x\\in\\mathbb{R}_{>0}$ , the fourth inequality follows from $a+b\\leq2a b$ whenever $a,b>1$ (here $a=8C$ and $b=2\\log(d^{3}4^{m}/\\delta))$ , and the last inequality holds due to $C>1$ . ", "page_idx": 46}, {"type": "text", "text": "Hence, the proof is complete. ", "page_idx": 46}, {"type": "text", "text": "Lemma G.11. Suppose $\\mathcal{E}$ occurs where $\\mathcal{E}$ is in Eq. (53). For all $m\\in\\mathbb{N}$ , $a^{\\star}\\in\\mathcal{S}_{m}$ holds where ${\\mathcal{S}}_{m}$ is defined in Eq. (48). ", "page_idx": 46}, {"type": "text", "text": "Proof. We prove this by induction. For the base case $m=1$ , the claim holds trivially. Suppose that it holds for phase $m$ (i.e., $a^{\\star}\\in\\ensuremath{\\mathcal{S}}_{m},$ ) and then we aim to show $a^{\\star}\\in S_{m+1}$ . For all $a\\in S_{m}$ , one can show ", "page_idx": 46}, {"type": "equation", "text": "$$\n0\\leq\\left\\langle\\theta,a^{\\star}\\right\\rangle-\\left\\langle\\theta,a\\right\\rangle\\leq\\left\\langle\\widehat{\\theta}_{m+1},a^{\\star}\\right\\rangle-\\left\\langle\\widehat{\\theta}_{m+1},a\\right\\rangle+2\\times2^{-m-1}=\\left\\langle\\widehat{\\theta}_{m+1},a^{\\star}-a\\right\\rangle+2^{-m},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where the second inequality follows from the definition of $\\mathcal{E}$ (see Eq. (53)) and $a^{\\star}\\in\\mathcal{S}_{m}$ by inductive hypothesis. Then, we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\left\\langle\\widehat{\\theta}_{m+1},a^{\\star}-a_{m+1}^{\\star}\\right\\rangle+2^{-m}\\geq0.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "The inductive hypothesis gives $a^{\\star}\\in\\mathcal{S}_{m}$ , and thus ", "page_idx": 46}, {"type": "equation", "text": "$$\na^{\\star}\\in\\mathrm{Span}_{[-C,C]}({\\mathcal{B}}_{m})\\cap{\\mathcal{A}},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "since Lemma G.6 gives that $B_{m}$ is a $C$ -approximate barycentric spanner of ${\\mathcal{S}}_{m}$ . Combining $\\left\\langle\\widehat{\\theta}_{m+1},a^{\\star}-a_{m+1}^{\\star}\\right\\rangle+2^{-m}\\,\\geq\\,0$ and Eq. (56), we have $a^{\\star}\\,\\in\\,S_{m+1}$ according to definition of ${\\dot{S}}_{m}$ in Eq. (48). Once the induction is done, the proof is complete. \u53e3 ", "page_idx": 47}, {"type": "text", "text": "Lemma G.12. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is in Eq. (53). For each arm $a\\in{\\mathcal{A}}$ with $\\Delta_{a}>0;$ , it will not be in ${\\mathcal{S}}_{m}$ for all phases $m\\geq m_{a}+1$ , where $m_{a}$ is the smallest phase such that $\\frac{\\Delta_{a}}{2}>2^{-m_{a}}$ . ", "page_idx": 47}, {"type": "text", "text": "Proof. Consider an arbitrary arm $a\\in{\\mathcal{A}}$ with $\\Delta_{a}\\,>\\,0$ . Let $m_{a}$ be the smallest phase such that $\\frac{\\Delta_{a}}{2}>2^{-m_{a}}$ (i.e., $\\frac{\\Delta_{a}}{2}\\leq2^{-(m_{a}-1)})$ . Then, we will show that arm $a$ will be not in $\\textstyle S_{\\tau}$ for all $\\tau\\geq m_{a}$ . Suppose that $a\\in\\bar{S_{m_{a}}}$ (if not, it does not impact the claim). One can show that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Biggl\\langle\\widehat{\\theta}_{m_{a}+1},a_{m_{a}+1}^{\\star}-a\\Biggr\\rangle-2^{-m_{a}}}\\\\ &{=\\displaystyle\\operatorname*{sup}_{b\\in S_{m_{a}}}\\Biggl\\langle\\widehat{\\theta}_{m_{a}+1},b-a\\Biggr\\rangle-2^{-m_{a}}}\\\\ &{\\geq\\Big\\langle\\widehat{\\theta}_{m_{a}+1},a^{\\star}-a\\Big\\rangle-2^{-m_{a}}}\\\\ &{\\geq\\displaystyle\\langle\\theta,a^{\\star}-a\\rangle-2^{-m_{a}+1}}\\\\ &{>\\Delta_{a}-2\\times\\displaystyle\\frac{\\Delta_{a}}{2}}\\\\ &{=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where the first inequality uses Lemma G.11 that $a^{\\star}\\in\\mathcal{S}_{m}$ for all $m\\in\\mathbb{N}$ , the second inequality follows from the definition of $\\mathcal{E}$ (see Eq. (53)), and the last inequality holds due to the choice of $m_{a}$ . According to the definition of $\\ensuremath{\\boldsymbol{S}}_{m}$ in Eq. (48), arm $a$ will not be in ${\\mathcal{S}}_{m}$ for all $m\\geq m_{a}+1$ as long as $\\mathcal{E}$ occurs. \u53e3 ", "page_idx": 47}, {"type": "text", "text": "Lemma G.13. Let $m(t)$ be the phase in which round $t$ lies. Then, $m(t)\\leq\\log_{2}(t+1)$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 47}, {"type": "text", "text": "Proof. We prove this by contradiction. Suppose that $\\exists t\\in\\mathbb{N}$ that $m(t)>\\log_{2}(t+1)$ . Note that we can further assume $m(t)\\,\\geq\\,2$ since one can easily verify that for all $t$ such that $m(t)\\,=\\,1$ , $m(t)\\leq\\log_{2}(t+1)$ must hold. Recall that in phase $m(t)$ , each active arm will be played for $m_{\\ell(t)}$ times, we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\colon\\geq\\displaystyle\\sum_{a\\in B_{m(t)-1}}\\left[\\pi_{m(t)-1}(a)T_{m(t)-1}\\right]}\\\\ &{\\ge\\displaystyle\\frac{T_{m(t)-1}}{d}=256C^{4}\\cdot\\frac{d^{2}}{4^{-(m(t)-1)}}\\log\\left(\\delta^{-1}d^{3}4^{m(t)-1}\\right)\\geq64C^{4}\\cdot d^{2}(t+1)^{2}\\log\\left(4\\delta^{-1}d^{3}\\right)>t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where the third inequality bounds $\\ell(t)$ in the logarithmic term by $\\ell(t)\\,\\geq\\,2$ and bound the other $\\ell(t)>\\log_{2}(t+1)$ by assumption. Therefore, once a contradiction occurs, the proof is complete. ", "page_idx": 47}, {"type": "text", "text": "Lemma G.14. Let $m(t)$ be the phase in which round $t$ lies. Suppose that $\\mathcal{E}$ occurs where $\\mathcal{E}$ is in $E q$ . (53) and Algorithm 2 computes a $C$ -approximate barycentric spanner with $C>1$ . For all $t\\in\\mathbb{N}$ and all $a\\in{\\mathcal{A}},$ , if $a\\in S_{m(t)}$ , then, ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\Delta_{a}\\leq\\sqrt{\\frac{64\\times512C^{4}d^{3}\\log\\left(\\frac{d^{3}4(t+1)^{2}}{\\delta}\\right)}{3t}}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Proof. If $a\\,\\in\\,S_{m(t)}$ is optimal, then, $\\Delta_{a}\\,=\\,0$ and the claim trivially holds. In what follows, we only consider arm $\\dot{a}\\in S_{m(t)}$ with $\\Delta_{a}>0$ . Consider an arbitrary round $t\\in\\mathbb{N}$ and an arbitrary arm $a\\in S_{m(t)}$ . Then, $t$ can be bounded by ", "page_idx": 47}, {"type": "equation", "text": "$$\nt\\leq\\sum_{s=1}^{m(t)}\\sum_{a\\in\\mathcal{B}_{s}}\\lceil\\pi_{s}(a)T_{s}\\rceil\n$$", "text_format": "latex", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq2\\frac{m!}{\\sum_{t=1}^{n}C_{1}}\\sum_{s=0}^{\\pi_{t}}\\alpha_{s}(a)T_{s}}\\\\ &{=512C_{1}^{\\pi_{t}}\\frac{\\alpha_{s}^{2}}{4}\\log\\left(\\frac{\\theta^{4}+\\alpha}{2}\\right)}\\\\ &{\\leq512C_{4}^{\\pi_{t}}4^{\\pi_{t}}\\log\\left(\\frac{\\theta^{4}+\\alpha}{2}\\right)\\sum_{s=0}^{\\pi_{t}}\\frac{1}{4^{-\\alpha}}}\\\\ &{\\stackrel{(a)}{\\leq}512C^{\\pi_{t}}4^{\\pi_{t}}\\log\\left(\\frac{d^{2}+\\alpha(1)}{5}\\right)\\sum_{s=0}^{\\pi_{t}}\\frac{1}{4^{-\\alpha}}}\\\\ &{\\stackrel{(b)}{\\leq}512C^{\\pi_{t}}4^{\\pi_{t}}3^{\\alpha}\\log\\left(\\frac{(d^{2}+\\alpha)^{2}}{10}\\right)\\sum_{s=0}^{\\pi_{t}}\\frac{1}{4^{-\\alpha}}}\\\\ &{\\stackrel{(b)}{\\leq}\\frac{612\\pi^{4}\\log\\left(\\frac{(d^{2}+\\alpha)^{2}}{10}\\right)\\log\\left(\\frac{(d^{2}+\\alpha)^{2}}{10}\\right)}{328}}\\\\ &{\\stackrel{(c)}{\\leq}\\frac{61\\times512C^{\\pi_{t}}4^{\\pi_{t}}\\log\\left(\\frac{(d^{2}+\\alpha)^{2}\\alpha}{10}\\right)}{328}}\\\\ &{\\leq\\frac{64\\times512C^{\\pi_{t}}4^{\\pi_{t}}\\log\\left(\\frac{d^{2}+\\alpha(1+1)^{2}}{10}\\right)}{10}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where the second inequality holds because $\\pi_{s}(a)\\;=\\;{\\textstyle\\frac{1}{d}}$ for all $s~\\in~\\mathbb{N}$ and all $a\\ \\in\\ B_{s}$ , thereby $\\pi_{s}(a)T_{s}\\geq1$ , which gives $\\lceil\\bar{\\pi}_{s}(a)T_{s}\\rceil\\leq2\\pi_{s}(a)\\dot{T_{s}}$ , the inequality (a) bounds $m(t)\\leq m_{a}$ where $m_{a}$ is defined in Lemma G.12, the inequality (b) uses $\\begin{array}{r}{\\frac{\\Delta_{a}}{2}\\leq2^{-m_{a}+1}}\\end{array}$ to bound $m_{a}\\leq\\log_{2}\\left(4/\\Delta_{a}\\right)$ , and the inequality (c) follows from Lemma G.13 that $m(\\mathbf{\\tilde{t}})\\leq\\log_{2}(t+1)$ . ", "page_idx": 48}, {"type": "text", "text": "Conditioning on $\\mathcal{E}$ , this argument holds for each $t,a$ , which completes the proof. ", "page_idx": 48}, {"type": "text", "text": "Proof of Theorem 4.2. Once Lemma G.11 and Lemma G.14 hold, Theorem 3.1 gives that for any fixed $\\delta\\,\\in\\,(0,1)$ , Algorithm 10 achieves the ULI guarantee with a function (omitting $C$ as it is a constant) ", "page_idx": 48}, {"type": "equation", "text": "$$\nF_{\\mathrm{ULI}}(\\delta,t)=\\mathcal{O}\\left(\\sqrt{\\frac{d^{3}\\log\\left(d t/\\delta\\right)}{t}}\\right).\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Therefore, the proof is complete. ", "page_idx": 48}, {"type": "text", "text": "G.7 Proof of Theorem 4.2: Computational Analysis ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "As the second for-loop restarts repeatedly, and we first present the following lemma to bound the number of times that it restarts. ", "page_idx": 48}, {"type": "text", "text": "Lemma G.15. Under the same setting of Lemma $G.I$ , Algorithm 12 outputs a $C$ -barycentric spanner by restarting the second for-loop for ${\\mathcal{O}}\\left(d^{2}\\log_{C}(d)\\right)$ times. ", "page_idx": 48}, {"type": "text", "text": "Proof. According to [Awerbuch and Kleinberg, 2008, Lemma 2.6], if ${\\mathcal{T}}_{m}$ never changes after entering the second for-loop, then, the second for-loop restarts for at most ${\\mathcal{O}}(d\\log_{C}(d))$ times, and then the algorithm terminates. In Algorithm 12, if ${\\mathcal{T}}_{m}$ changes, the second for-loop restarts. As set ${\\mathcal{T}}_{m}$ is always non-increasing, it suffices to consider the worst case ( ${\\mathcal{Z}}_{m}$ changes at most $O(d)$ times). Hence, the second for-loop restarts at most $O(d^{2}\\log_{C}(d))$ times. \u53e3 ", "page_idx": 48}, {"type": "text", "text": "Now, we are ready to show the computational complexity. ", "page_idx": 48}, {"type": "text", "text": "From Lemma G.15, Algorithm 12 restarts the second for-loop at most $O(d^{2}\\log_{C}(d))$ times. For each run of the second for-loop, the optimization oracle is invoked at most $d$ times. Thus, the number of calls to the oracle is at most ${\\hat{O}}(d^{3}\\log_{C}(d))$ . Apart from the second for-loop, the first for-loop invokes the oracle $d$ times and computing the empirical best arm $a_{m}^{\\star}$ requires once call to the oracle. Combining all together, we obtain the claimed bound. ", "page_idx": 48}, {"type": "text", "text": "H Omitted Details of Section 5 ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "H.1 Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "The proof of main theorem conditions on a nice event $\\mathcal{E}$ in which some high-probability bounds hold simultaneously. We defer the formal definition of $\\mathcal{E}$ to Appendix H.2. ", "page_idx": 49}, {"type": "text", "text": "The key to conducting policy elimination is to ensure that the estimated value functions will be closer to the true value functions as phases evolve. The following proposition gives us the desired result. ", "page_idx": 49}, {"type": "text", "text": "Proposition H.1. Suppose that $\\mathcal{E}$ occurs. For all $m\\in\\mathbb{N}$ and $\\pi\\in\\Pi_{m}$ , we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widetilde{V}_{m}^{\\pi}-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1})\\right]\\right|\\leq2^{m-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "With the above result at hand, one can treat each policy as an arm and repeat the same arguments in Appendix D.2 (counterparts are Lemma D.7, Lemma D.8, and Lemma D.9) to get the following three lemmas. ", "page_idx": 49}, {"type": "text", "text": "Lemma H.2. Suppose that $\\mathcal{E}$ occurs. For each $m\\in\\mathbb{N}$ , $\\pi^{\\star}\\in\\Pi_{m}$ holds. ", "page_idx": 49}, {"type": "text", "text": "Lemma H.3. Suppose that $\\mathcal{E}$ occurs. For each policy $\\pi$ with $\\Delta_{\\pi}>0$ , it will not be in $\\Pi_{m}$ for all phases $m\\geq m_{\\pi}+1$ where $m_{\\pi}$ is the smallest phase such that $\\frac{\\Delta_{\\pi}}{2}>2^{-m_{\\pi}}$ . ", "page_idx": 49}, {"type": "text", "text": "Lemma H.4. Let $m(t)$ be the phase that round $t$ lies in. Then, $m(t)\\leq\\log_{2}(t+1)$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 49}, {"type": "text", "text": "The next lemma shows that if a policy is not eliminated, then, the policy gap is in order of $\\widetilde{\\mathcal{O}}(t^{-1/2})$ ", "page_idx": 49}, {"type": "text", "text": "Lemma H.5. Let $m(t)$ be the phase in which episode/round $t$ lies. Suppose that $\\mathcal{E}$ occurs. For all $t\\in\\mathbb{N}$ and all $\\pi\\in\\Pi$ , $i f\\pi\\in\\Pi_{m(t)}$ , then ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\Delta_{\\pi}\\leq\\sqrt{\\frac{S^{3}A H^{5}\\log^{2}\\left(t S A H/\\delta\\right)}{t}}.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Proof. If $\\pi\\in\\Pi_{m(t)}$ is optimal, then, $\\Delta_{\\pi}=0$ and the claim trivially holds. In what follows, we only consider policy $\\pi\\overset{\\cdot}{\\in}\\Pi_{m(t)}$ with $\\Delta_{\\pi}>0$ . From Lemma H.3, if a policy $\\pi\\in\\Pi_{m(t)}$ is with $\\Delta_{\\pi}>0$ then, $m(t)\\leq m_{\\pi}$ where $m_{\\pi}$ is defined in Lemma H.3. Thus, the total number of episodes/rounds that such a policy $\\pi$ is active is at most ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t\\leq\\displaystyle\\sum_{s=1}^{m(t)}T_{s}}\\\\ &{\\leq2c_{1}S^{2}A H^{4}\\displaystyle\\sum_{s=1}^{m(t)}2^{2s}\\log^{2}\\left(2c_{2}s^{2}2^{2s}S^{2}A H^{4}|\\Pi_{\\mathrm{all}}|\\delta\\right)}\\\\ &{\\leq2c_{1}S^{2}A H^{4}\\log^{2}\\left(2c_{2}\\log^{2}t(t+1)^{2}S^{2}A H^{4}|\\Pi_{\\mathrm{all}}|\\delta\\right)\\displaystyle\\sum_{s=1}^{m(t)}2^{2s}}\\\\ &{\\leq\\mathcal{O}\\left(\\frac{S^{2}A H^{4}\\log^{2}\\left(t S A H|\\Pi_{\\mathrm{all}}|\\delta\\right)}{\\Delta_{\\mathrm{a}}^{2}}\\right)}\\\\ &{=\\mathcal{O}\\left(\\frac{S^{3}A H^{5}\\log^{2}\\left(t S A H/\\delta\\right)}{\\Delta_{\\mathrm{a}}^{2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where the second inequality holds due to $s\\leq m(t)\\leq\\log_{2}(t+1)$ , and the last step uses the fact that $\\Pi_{\\mathbf{a}\\mathbf{1}\\mathbf{1}}=A^{S H}$ . Rearranging the above, we complete the proof. \u53e3 ", "page_idx": 49}, {"type": "text", "text": "Now, Theorem 5.1 is immediate if we treat each policy as an arm and invokes Theorem 3.1. ", "page_idx": 49}, {"type": "text", "text": "H.2 Construction of Nice Event ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "We extend the definitions of value function and action value functions to reward-dependent ones. ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{Q_{h}^{\\pi}(s,a,r)=\\mathbb{E}\\left[\\displaystyle\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\mid s_{h^{\\prime}}=s,a_{h^{\\prime}}=a,\\pi\\right],}}\\\\ {{V_{h}^{\\pi}(s,r)=\\mathbb{E}\\left[\\displaystyle\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\mid s_{h^{\\prime}}=s,\\pi\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Next, we start to construct high-probability event. We first construct an event that high-probability bounds occur for a single phase (i.e., a single execution of Algorithm 4), and then extend it to the case in which those bounds simultaneously hold for all phases. ", "page_idx": 50}, {"type": "text", "text": "Lemma H.6. Suppose that Algorithm $^{4}$ is executed with input $(\\delta,\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\ell}$ . With probability at least $1-\\delta/5,$ , for all $(t,h,\\pi,s,a)\\in[T]\\times[H]^{-}\\times\\Pi\\times{\\mathcal{S}}\\times{\\mathcal{A}}$ : ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\left|\\left[(\\mathbb{P}_{h}-\\widehat{\\mathbb{P}}_{t,h})V_{h+1}^{\\pi}\\right](s,a)\\right|\\leq H\\sqrt{\\frac{\\log(10H S A|\\Pi_{a l l}|T/\\delta)}{2\\operatorname*{max}\\{N_{t,h}(s,a),1\\}}}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Proof. For $(s,a)$ has been visited, we apply Hoeffding\u2019s inequality and union bounds to complete the proof. For those $(s,a)$ that has not been visited yet, the claim trivially holds true. \u53e3 ", "page_idx": 50}, {"type": "text", "text": "Lemma H.7. Suppose that Algorithm $^{4}$ is executed with input $(\\delta,\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\ell}$ . With probability at least $1-\\delta/5,$ , for all $(h,s,a,\\pi,t)\\in[H]\\times\\mathcal{S}\\ \\times\\ A\\times\\Pi\\times[T],$ , ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\left|\\left[(\\widehat{\\mathbb{P}}_{t,h}-\\mathbb{P}_{h})\\widehat{V}_{t,h+1}^{\\pi}\\right](s,a)\\right|\\leq b_{t,h}(s,a).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Proof. For those $(s,a)$ that has not been visited yet, the claim trivially holds true. For $(s,a)$ has been visited, by Bernstein\u2019s inequality, with probability at least $1-\\delta^{\\prime}$ , ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left[(\\widehat{\\mathbb{P}}_{t,h}-\\mathbb{P}_{h})\\widehat{V}_{t,h+1}^{\\pi}\\right](s,a)\\right|\\leq\\displaystyle\\sum_{s^{\\prime}\\in S}\\left(\\sqrt{\\frac{2P(s^{\\prime}|s,a)\\log(2/\\delta^{\\prime})}{N_{t,h}(s,a)}}+\\frac{2\\log(2/\\delta^{\\prime})}{3N_{t,h}(s,a)}\\right)\\widehat{V}_{t,h+1}^{\\pi}(s^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{s^{\\prime}\\in S}H\\sqrt{\\frac{2P(s^{\\prime}|s,a)\\log(2/\\delta^{\\prime})}{N_{t,h}(s,a)}}+\\frac{2H S\\log(2/\\delta^{\\prime})}{3N_{t,h}(s,a)}}\\\\ &{\\qquad\\qquad\\qquad\\leq H\\sqrt{\\frac{2S\\log(2/\\delta^{\\prime})}{N_{t,h}(s,a)}}+\\frac{2H S\\log(2/\\delta^{\\prime})}{3N_{t,h}(s,a)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where the last inequality uses the Cauchy-Schwarz inequality. By taking a union bound, choosing a proper $\\delta^{\\prime}$ , and using the definition of $b_{t,h}(s,a)$ , we complete the proof. \u53e3 ", "page_idx": 50}, {"type": "text", "text": "In the following high-probability bounds, we again assume that Algorithm 4 is executed with input $(\\delta,\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{\\mathsf{a11}}$ . By Azuma-Hoeffding\u2019s inequality and union bounds, with probability at least $1-\\delta/5$ , for all $\\pi\\in\\Pi$ , ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{1},b_{t}/H)\\right]\\le\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{t,1},b_{t}/H)+H\\sqrt{8T\\log(5|\\Pi_{\\mathrm{all}}|/\\delta)}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "For shorthand, we denote ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\xi_{t,h}=\\mathbb{P}_{h}\\widehat{V}_{t,h+1}^{\\pi_{t}}(s_{t,h},a_{t,h})-\\widehat{V}_{t,h+1}^{\\pi_{t}}(s_{t,h}).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "By Azuma-Hoeffding\u2019s inequality and union bounds, with probability at least $1\\,-\\,\\delta/5$ , for all $(t,h)\\in[T]\\times[H]$ , ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{h=1}^{H-1}\\xi_{t,h}\\leq H^{2}\\sqrt{8T\\log(5H T/\\delta)},\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where $c_{2}>0$ is some absolute constant. ", "page_idx": 51}, {"type": "text", "text": "Again, by the fact that $|\\Pi_{\\mathsf{a11}}|\\geq|\\Pi|$ and Azuma-Hoeffding\u2019s inequality and union bounds, with probability at least $1-\\delta_{m}/5$ , for all $\\pi\\in\\Pi$ , ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widetilde{V}^{\\pi}-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})\\right]\\right|\\leq H\\sqrt{8T\\log\\left(10|\\Pi_{\\mathrm{a1}1}|/\\delta_{m}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Definition H.8 (definition of $\\widehat{\\mathcal E}$ , single phase). Suppose that Algorithm $^{4}$ is executed with input $(\\delta^{\\prime},\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\i}$ . Let $\\widehat{\\mathcal E}$ be the event that all high probability bounds in Eq. (58), Eq. (60), and $E q$ . (61) hold simultaneously. ", "page_idx": 51}, {"type": "text", "text": "Taking a union bound over those high-probability bounds, we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\widehat{\\mathcal{E}}\\right)\\geq1-\\delta^{\\prime}.\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Definition H.9 (definition of $\\mathcal{E}$ ). Let $\\mathcal{E}$ be the event that when running Algorithm 3, all high probability bounds in Eq. (58), Eq. (60), and Eq. (61) hold for all phases $m\\in\\mathbb{N}$ simultaneously. ", "page_idx": 51}, {"type": "text", "text": "Recall that Algorithm 3 runs Algorithm 4 in phases with input $(\\delta_{m},\\Pi_{m},T_{m})$ where $\\delta_{m}=\\delta/(2m^{2})$ and $\\forall m\\in\\mathbb{N}$ , $|\\Pi_{m}|\\leq|\\Pi_{\\mathbf{a}11}|$ holds. By a union bound over all $m\\in\\mathbb{N}$ , $\\mathbb{P}\\left(\\mathcal{E}\\right)\\geq1-\\delta$ . ", "page_idx": 51}, {"type": "text", "text": "H.3 Supporting Lemmas ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Recall the reward-dependent value function given in Eq. (57), and we give the following lemmas. ", "page_idx": 51}, {"type": "text", "text": "Lemma H.10. Suppose that Algorithm $^{4}$ is executed with input $(\\delta^{\\prime},\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\lambda},$ , and suppose $\\widehat{\\mathcal E}$ occurs. For all $(\\pi,t,h,s)\\in\\Pi\\times[T]\\times[H]\\times S$ , $V_{h}^{\\pi}(s,b_{t}/H)\\le\\widehat{V}_{h,t}^{\\pi}(s)$ holds. ", "page_idx": 51}, {"type": "text", "text": "Proof. Conditioning onE, one can use Lemma H.6 and follow the same idea of Lemma 18 in [Azar et al., 2017] to complete the proof. \u53e3 ", "page_idx": 51}, {"type": "text", "text": "Lemma H.11. Suppose that Algorithm $^{4}$ is executed with input $(\\delta^{\\prime},\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\lambda},$ , and suppose $\\widehat{\\mathcal E}$ occurs. For all policy $\\pi\\in\\Pi_{i}$ , the following holds. ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\forall\\pi\\in\\Pi,\\quad\\left|\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})-V_{1}^{\\pi}(s_{1})\\right]\\right|\\leq\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1},b_{T})\\right].\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Proof. One can show the following: ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})-V_{1}^{\\pi}(s_{1})\\right]}\\\\ &{=\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{Q}_{T,1}^{\\pi}(s_{1},\\pi_{1}(s_{1}))-Q_{1}^{\\pi}(s_{1},\\pi_{1}(s_{1}))\\right]}\\\\ &{\\leq\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{\\mathbb{P}}_{T,1}\\widehat{V}_{T,2}\\!\\left[(s_{1},\\pi_{1}(s_{1}))-\\left[\\mathbb{P}_{1}V_{2}\\right](s_{1},\\pi_{1}(s_{1}))\\right]\\right.}\\\\ &{\\leq\\mathbb{E}_{s_{1}\\sim\\mu}\\left[b_{T,1}\\!\\left(s_{1},\\pi_{1}(s_{1})\\right)+\\left[\\mathbb{P}_{1}\\widehat{V}_{T,2}\\!\\left[(s_{1},\\pi_{1}(s_{1}))-\\left[\\mathbb{P}_{1}V_{2}\\right](s_{1},\\pi_{1}(s_{1}))\\right]\\right.}\\\\ &{=\\mathbb{E}_{s_{1}\\sim\\mu,s_{2}\\sim\\mathbb{P}_{1}(\\cdot|s_{1},\\pi_{1}(s_{1}))}\\left[b_{T,1}(s_{1},\\pi_{1}(s_{1}))+\\widehat{V}_{T,2}(s_{2})-V_{2}(s_{2})\\right]}\\\\ &{\\leq\\cdots.}\\\\ &{\\leq\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1},b_{T})\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where the second inequality follows from Lemma H.7. ", "page_idx": 51}, {"type": "text", "text": "Since those concentration bounds are also two-sided, the other side of desired claim can be similarly proved. Note that for the other side, one only need to consider $\\widehat{Q}_{T,1}^{\\pi}(s,a)\\leq{\\cal H}$ for all $(s,a)$ , and otherwise, the difference is negative, which implies that the claim trivially holds. \u53e3 ", "page_idx": 51}, {"type": "text", "text": "Lemma H.12. Suppose that Algorithm $^{4}$ is executed with input $(\\delta^{\\prime},\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\lambda},$ , and supposeE occurs. For $\\xi_{t,h}$ defined in Eq. (59), we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\widehat{V}_{t,1}^{\\pi_{t}}\\big(s_{t,1}\\big)\\leq\\sum_{t=1}^{T}\\sum_{h=1}^{H-1}\\xi_{t,h}+\\sum_{t=1}^{T}\\sum_{h=1}^{H-1}\\left(2+\\frac{1}{H}\\right)b_{t,1}\\big(s_{t,1},a_{t,1}\\big).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Proof. Conditioning on $\\widehat{\\mathcal E}$ , we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=1}^{T}\\hat{V}_{t,1}^{\\pi_{t}}(s_{t,1})\\leq\\sum_{t=1}^{T}\\left(\\left\\{\\hat{\\mathbb{P}}_{1}^{t}\\hat{V}_{t,2}^{\\pi_{t}}[(s_{t,1},a_{t,1})+r_{t,1}(s_{t,1},a_{t,1})+b_{t,1}(s_{t,1},a_{t,1})\\right\\}\\right.\\right.}}\\\\ &{\\left.\\left.=\\sum_{t=1}^{T}\\left(\\left\\|\\hat{\\mathbb{P}}_{1}^{t}\\hat{V}_{t,2}^{\\pi_{t}}[(s_{t,1},\\pi_{t}(s_{t,1}))+\\left(1+\\frac{1}{H}\\right)b_{t,1}(s_{t,1},a_{t,1})\\right)\\right.\\right.\\right.}\\\\ &{\\left.\\left.\\left.\\leq\\sum_{t=1}^{T}\\left(\\left\\|\\hat{\\mathbb{P}}_{1}^{t}\\hat{V}_{t,2}^{\\pi_{t}}[(s_{t,1},a_{t,1})+\\left(2+\\frac{1}{H}\\right)b_{t,1}(s_{t,1},a_{t,1})\\right)\\right.\\right.\\right.}\\\\ &{\\left.\\left.\\left.\\leq\\sum_{t=1}^{T}\\left(\\xi_{t,1}+\\hat{V}_{t,2}^{\\pi_{t}}(s_{t,2})+\\left(2+\\frac{1}{H}\\right)b_{t,1}(s_{t,1},a_{t,1})\\right)\\right.\\right.}\\\\ &{\\left.\\left.\\leq\\cdots\\right.}\\\\ &{\\left.\\left.\\left.\\leq\\sum_{t=1}^{T}\\xi_{t,1}+\\left(2+\\frac{1}{H}\\right)\\sum_{t=1}^{T}b_{t,h}(s_{t,h},a_{t,h}),\\right.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where the first inequality holds due to Lemma H.7. ", "page_idx": 52}, {"type": "text", "text": "Then, we turn to bound two terms in Eq. (63). Note that Eq. (60) already gives the bound of the first term, and thus we only need to bound the second term. Before that, we first present an auxiliary lemma. The proof of this lemma can be found in [Jin et al., 2020, Lemma 10] ", "page_idx": 52}, {"type": "text", "text": "Lemma H.13. Suppose that Algorithm 4 is executed with input $(\\delta^{\\prime},\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{a\\i\\ell}$ . For all $h\\in[H]$ , the followings hold. ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{(s,a)\\in S\\times A}\\sum_{t=1}^{T}\\frac{\\mathbb{I}\\{\\left(s_{t,h},a_{t,h}\\right)=(s,a)\\}}{\\operatorname*{max}\\{1,N_{t,h}(s,a)\\}}=\\mathcal{O}\\left(S A\\log T\\right),}\\\\ &{\\displaystyle\\sum_{(s,a)\\in S\\times A}\\sum_{t=1}^{T}\\frac{\\mathbb{I}\\{\\left(s_{t,h},a_{t,h}\\right)=(s,a)\\}}{\\sqrt{\\operatorname*{max}\\{1,N_{t,h}(s,a)\\}}}=\\mathcal{O}\\left(\\sqrt{S A T}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "With the above lemma in hand, one can show: ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=1}^{H}b_{t,h}(s_{t,h},a_{t,h})}\\\\ &{\\displaystyle=\\sum_{h=1}^{H}\\sum_{t=1}^{T}\\left(H\\sqrt{\\frac{2S\\log\\iota}{\\operatorname*{max}\\{1,N_{t,h}(s_{t,h},a_{t,h})\\}}}+\\frac{2H S\\log\\iota}{3\\operatorname*{max}\\{1,N_{t,h}(s_{t,h},a_{t,h})\\}}\\right)}\\\\ &{\\displaystyle=\\sum_{h=1}^{H}\\sum_{(s,a)\\in S\\times A}\\sum_{t=1}^{T}\\left(H\\sqrt{2S\\log\\iota}\\frac{\\mathbb{I}\\{(s_{t,h},a_{t,h})=(s,a)\\}}{\\sqrt{\\operatorname*{max}\\{1,N_{t,h}(s_{t,h},a_{t,h})\\}}}+\\frac{2H S\\mathbb{I}\\{(s_{t,h},a_{t,h})=(s,a)\\}\\log}{3\\operatorname*{max}\\{1,N_{t,h}(s_{t,h},a_{t,h})\\}}\\right)}\\\\ &{\\displaystyle=\\mathcal{O}\\left(S H^{2}\\sqrt{A T\\log\\iota}+H S^{2}A\\log(T)\\log\\iota\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where the last step holds due to Lemma H.13. ", "page_idx": 52}, {"type": "text", "text": "Therefore, we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\widehat{V}_{t,1}^{\\pi_{t}}(s_{t,1})=\\mathcal{O}\\left(S H^{2}\\sqrt{A T\\log\\iota}+H S^{2}A\\log(T)\\log\\iota\\right).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "H.4 Proof of Proposition H.1 ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "We first consider a single execution of Algorithm 4 with input $(\\delta,\\Pi,T)$ where $\\Pi\\subseteq\\Pi_{\\mathsf{a11}}$ . With the above supporting results, we are now ready to prove the claimed result. The following proof will ", "page_idx": 52}, {"type": "text", "text": "condition on event $\\mathcal{E}$ . First, one can show that for all $\\pi\\in\\Pi$ : ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big|\\widetilde{V}^{\\pi}-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1})\\right]\\Big|}\\\\ &{\\le\\Big|\\widetilde{V}^{\\pi}-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})\\right]\\Big|+\\Big|\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})\\right]-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1})\\right]\\Big|}\\\\ &{\\le H\\sqrt{8T\\log(10|\\Pi_{\\mathrm{all}}|/\\delta)}+\\Big|\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})\\right]-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1})\\right]\\Big|\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Then, we turn to bound the second term. Recall the reward dependent value function defined in Eq. (57), and we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\widehat{V}_{T,1}^{\\pi}(s_{1})-V_{1}^{\\pi}(s_{1})\\right]\\right|\\le\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1},b_{T})\\right]~~~}&{}\\\\ {=H\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1},b_{T}/H)\\right]~~~}&{}\\\\ {\\ }&{\\le\\displaystyle\\frac{H}{T}\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{1},b_{t}/H)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "From Eq. (58), we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{1},b_{t}/H)\\right]\\le\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{t,1},b_{t}/H)+c_{1}H\\sqrt{T\\log{\\iota}}}}\\\\ &{}&{\\le\\displaystyle\\sum_{t=1}^{T}\\hat{V}_{t,1}^{\\pi}(s_{t,1})+c_{1}H\\sqrt{T\\log{\\iota}}}&{\\quad\\mathrm{(By~Lemma~H.10)}}\\\\ &{}&{\\le\\displaystyle\\sum_{t=1}^{T}\\hat{V}_{t,1}^{\\pi_{t}}(s_{t,1})+c_{1}H\\sqrt{T\\log{\\iota}}.}&{\\quad\\displaystyle(\\pi_{t}\\in\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\hat{V}_{t,1}^{\\pi}(s_{t,1}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Combining the above with Eq. (64), we arrive at ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\mathbb{E}_{s_{1}\\sim\\mu}\\left[\\sum_{t=1}^{T}V_{1}^{\\pi}(s_{1},b_{t}/H)\\right]=\\mathcal{O}\\left(S H^{2}\\sqrt{\\frac{A\\log\\iota}{T}}+\\frac{H S^{2}A\\log^{2}\\iota}{T}\\right).\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Now, we consider a fixed phase $m$ where the input of Algorithm 4 is $(\\delta_{m},\\Pi_{m},T_{m})$ . There always exist two absolute constants $c_{1},c_{2}>0$ for $T_{m}=c_{1}2^{-2m}S^{2}A H^{4}\\log^{2}\\left(c_{2}2^{-2m}S^{2}A H^{4}|\\Pi_{\\mathrm{a11}}|\\delta^{-1}\\right)$ such that ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\left|\\widetilde{V}_{m}^{\\pi}-\\mathbb{E}_{s_{1}\\sim\\mu}\\left[V_{1}^{\\pi}(s_{1})\\right]\\right|\\leq\\frac{2^{-m}}{2}.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "As conditioning on event $\\mathcal{E}$ , the above holds for all $m\\in\\mathbb{N}$ . Thus, the proof is complete. ", "page_idx": 53}, {"type": "text", "text": "I Limitations ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "One limitation is that the regret bound i\u221amplied by the ULI guarantee for linear \u221abandits with infinitelymany arms is suboptimal, i.e., $\\widetilde{\\mathcal{O}}(d^{1.5}\\sqrt{T})$ compared with lower bound $\\Theta(d{\\sqrt{T}})$ but note that this problem is long-standing open.  This is discussed below Theorem 4.2. We also mention the limitation of Algorithm 3 (below Theorem 5.1) that it is computational inefficient and the regret bound implied by ULI guarantee is also suboptimal. ", "page_idx": 54}, {"type": "text", "text": "J Broader Impacts ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "This paper proposes a new metric for online RL, called uniform last-iterate, which could be helpful for high-stacks applications, since a near-optimal result under our metric ensures both good cumulative and instantaneous results. ", "page_idx": 54}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: We itemize two main questions in introduction section and also itemize our contributions on how to approach and resolve those issues in our paper. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 55}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Justification: Please refer to Appendix I. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 55}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: All assumptions can be found in Section 2 and all proofs can be found in appendix. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 56}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 56}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 56}, {"type": "text", "text": "Justification: This paper is theoretically oriented and does not conduct any experiment. Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 56}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 56}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 57}, {"type": "text", "text": "Justification: This paper is theoretically oriented and does not conduct any experiment. Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 57}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 57}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 57}, {"type": "text", "text": "Justification: This paper is theoretically oriented and does not conduct any experiment. Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 57}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 57}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 57}, {"type": "text", "text": "Justification: This paper is theoretically oriented and does not conduct any experiment. Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 57}, {"type": "text", "text": "", "page_idx": 58}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 58}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 58}, {"type": "text", "text": "Justification: This paper is theoretically oriented and does not conduct any experiment. Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 58}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: We have reviewed NeurIPS Code of Ethics and commit to it. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 58}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: Please refer to Appendix J. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 58}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 59}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 59}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 59}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 59}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 59}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 59}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 59}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 59}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 59}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 60}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 60}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 60}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 60}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 60}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 60}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 60}, {"type": "text", "text": "Justification: This the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 60}]