[{"type": "text", "text": "Convergence of $\\mathbf{log}(1/\\epsilon)$ for Gradient-Based Algorithms in Zero-Sum Games without the Condition Number: A Smoothed Analysis ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ioannis Anagnostides ", "page_idx": 0}, {"type": "text", "text": "Carnegie Mellon University ianagnos@cs.cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Tuomas Sandholm ", "page_idx": 0}, {"type": "text", "text": "Carnegie Mellon University Strategic Machine, Inc. Strategy Robot, Inc. Optimized Markets, Inc. sandholm@cs.cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Gradient-based algorithms have shown great promise in solving large (two-player) zero-sum games. However, their success has been mostly confined to the lowprecision regime since the number of iterations grows polynomially in $1/\\epsilon$ where $\\epsilon\\mathrm{~>~0~}$ is the duality gap. While it has been well-documented that linear convergence\u2014\u2014an iteration complexity scaling as $\\log(1/\\epsilon)$ canbe attained even with gradient-based algorithms, that comes at the cost of introducing a dependency on certain condition number-like quantities which can be exponentially large in the description of the game. ", "page_idx": 0}, {"type": "text", "text": "To address this shortcoming, we examine the iteration complexity of several gradient-based algorithms in the celebrated framework of smoothed analysis, and we show that they have polynomial smoothed complexity, in that their number of iterations grows as a polynomial in the dimensions of the game, $\\log(1/\\epsilon)$ ,and $1/\\sigma$ ,where $\\sigma$ measures the magnitude of the smoothing perturbation. Our result applies to optimistic gradient and extra-gradient descent/ascent, as well as a certain iterative variant of Nesterov's smoothing technique. From a technical standpoint, the proof proceeds by characterizing and performing a smoothed analysis of a certain error bound, the key ingredient driving linear convergence in zero-sum games. En route, our characterization also makes a natural connection between the convergence rate of such algorithms and perturbation-stability properties of the equilibrium, which is of interest beyond the model of smoothed complexity. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the fundamental problem of computing an equilibrium strategy for a (two-player) zero-sumgame ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pmb{x}\\in\\Delta^{n}}\\operatorname*{max}_{\\pmb{y}\\in\\Delta^{m}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}\\rangle,\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $\\Delta^{d+1}\\,:=\\,\\{\\pmb{x}\\,\\in\\,\\mathbb{R}_{\\ge0}^{d+1}\\,:\\,\\pmb{x}^{\\top}\\mathbf{1}_{d+1}\\,=\\,1\\}$ represensthe $d$   \nand $\\mathbf{A}\\in\\mathbb{R}^{n\\times m}$ is the payoff matrix of the game. Tracing all the way back to Von Neumann's celebrated minimax theorem [von Neumann, 1928], zero-sum games played a pivotal role in the early development of game theory [von Neumann and Morgenstern, 1947] and the crystallization of linear programming duality [Dantzig, 1951]. Indeed, in light of the equivalence between zero-sum games and linear programming [Adler, 2013, von Stengel, 2023, Brooks and Reny, 2023], many central optimization problems can be cast as (1). ", "page_idx": 0}, {"type": "text", "text": "State of the art algorithms for solving zero-sum games can be coarsely classified based on the desired accuracy of a feasible solution $\\left({\\pmb x},{\\pmb y}\\right)$ , measured in terms of the duality gap ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\Phi(x,\\pmb{y}):=\\operatorname*{max}_{\\pmb{y}^{\\prime}\\in\\Delta^{m}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle-\\operatorname*{min}_{\\pmb{x}^{\\prime}\\in\\Delta^{n}}\\langle\\pmb{x}^{\\prime},\\mathbf{A}\\pmb{y}\\rangle.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "In the so-called low-precision regime, where one is content with a crude solution $(x^{\\star},y^{\\star})$ such that $\\Phi(x^{\\star},y^{\\star})=:\\epsilon\\gg0$ , the best available algorithms typically revolve around the framework of regret minimization, both in practice [Farina et al., 2021, Brown and Sandholm, 2019, Zinkevich et al., 2007, Tang et al., 2023] and in theory [Carmon et al., 2020, 2019, 2024, Grigoriadis and Khachiyan, 1995, Clarkson et al., 2012, Alacaoglu and Malitsky, 2022]\u2014in conjunction with other techniques to speed up the per-iteration complexity, such as variance reduction, data structure design, and sparsification [Zhang and Sandholm, 2020, Farina and Sandholm, 2022]. Such algorithms have been central to landmark results in practical computation of equilibrium strategies even in enormous games [Brown and Sandholm, 2018, Bowling et al., 2015, Moravcik et al., 2017, Perolat et al., 2022]. ", "page_idx": 1}, {"type": "text", "text": "The high-precision regime, where poly(rom), has turned out to be more elusive, with current LP-based techniques struggling to scale favorably in large instances. This deficiency can be in part attributed to the relatively high per-iteration complexity of LP-based approaches, such as interiorpoint methods or the ellipsoid algorithm, as well as their intense memory requirements. A promising antidote is to instead rely on iterative gradient-based methods that have a minimal per-iteration cost. Indeed, in a line of work pioneered by Tseng [1995], it is by known well-documented that linear convergencean iteration complexity scaling only as $\\log(1/\\epsilon)$ can been achieved even with such methods [Tseng, 1995, Gilpin et al., 2012, Wei et al., 2021, Applegate et al., 2023, Fercoq, 2023]. There is, however, a major caveat to those results: the number of iterations no longer grows polynomially with the dimensions of the game $n$ and $m$ , but instead depends on certain condition number-like quantities that could be exponentially large in the description of the problem; it is thus unclear how to interpret those results from a computational standpoint. ", "page_idx": 1}, {"type": "text", "text": "To address those shortcomings, in this paper we work in the celebrated framework of smoothed analysis pioneered by Spielman and Teng [2004]. Namely, our goal is to characterize the iteration complexity of certain gradient-based algorithms in zero-sum games when the payoff matrix A is subjected to small but random perturbations, as formally introduced below. ", "page_idx": 1}, {"type": "text", "text": "Definition 1.1 (Zero-sum games under Gaussian perturbations). Let $\\bar{\\mathbf{A}}\\in[-1,1]^{n\\times m}$ Weassume that the payoff matrix is given by $\\mathbf{A}:=\\bar{\\mathbf{A}}+\\mathbf{G}$ , where each entry of $\\mathbf{G}$ is an independent (univariate) Gaussian random variable with zero mean and variance $\\sigma^{2}\\leq1$ ", "page_idx": 1}, {"type": "text", "text": "Randomness here is only injected into the payoff matrix and not the set of constraints (that is, the probability simplex), which is the natural model; after applying the perturbation, the problem should still be a zero-sum game in the form of (1). Under this model, we investigate the convergence of the following gradient-based algorithms.1 (Their formal description is given later in Appendix B.) ", "page_idx": 1}, {"type": "text", "text": "1. optimistic gradient descent/ascent (0GDA) [Popov, 1980];   \n2. optimistic multiplicative weights update (0Mwu) [Syrgkanis et al., 2015, Chiang et al., 2012, Rakhlin and Sridharan, 2013];   \n3. extra-gradient descent/ascent (EGDA) [Korpelevich, 1976]; and   \n4. an iterative variant of Nesterov's smoothing technique ( IterSmooth) [Gilpin et al., 2012, Nesterov, 2005]. ", "page_idx": 1}, {"type": "text", "text": "Smoothed complexity allows interpolating between worst-case analysis-when the variance of the noise $\\sigma^{2}$ is negligible\u2014-and average-case analysis when the noise dominates over the underlying input. An average-case analysis is often unreliable since\u2014-as Edelman [1993] convincingly argued\u2014a fully random matrix does not necessarily capture typical instances encountered in practice. Spielman and Teng [2004] put forward the framework of smoothed analysis as an attempt to explain the performance of algorithms in realistic scenarios; to understand how brittle worst-case instances really are. They famously proved that the simplex algorithm, under a certain pivoting rule, enjoys polynomial smoothed complexity, meaning that its running time is bounded by some polynomial in the size of the input and $1/\\sigma$ . Smoothed analysis is by now a well-accepted algorithmic framework with a tremendous impact in the analysis of algorithms. We also argue that it is particularly well-motivated from a game-theoretic perspective: there is often misspecification or noise when modeling a game, so smoothed analysis offers a compelling way of bypassing pathological instances that are perhaps artificial in the first place. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Nevertheless, we are not aware of any prior work operating in the smoothed complexity model per Definition 1.1 in the context of zero-sum games. To clarify this point, it is important to stress here that although zero-sum games can be immediately reduced to linear programs, that reduction is less clear in the smoothed complexity model. In particular, one set of constraints in the induced linear program takes the form $\\mathbf{A}y\\leq v\\mathbf{1}_{n}=:b$ ,where $\\mathbf{1}_{n}\\in\\mathbb{R}^{n}$ is the all-ones vector. According to the usual model of smoothed complexity in the context of linear programs, randomness has to be injected into both A and $^{b}$ , but that clearly disturbs the validity of the equivalence. More broadly, reductions in the smoothed complexity model are quite delicate [Blaser and Manthey, 2015]; as a further example, even reductions involving solely linear transformations can break in the smoothed complexity model since independence\u2014-a crucial assumption in this framework\u2014-is not guaranteed to carry over. Relatedly, one interesting direction arising from the work of Spielman and Teng [2003] is to perform smoothed analysis in linear programs which are guaranteed to be feasible and bounded, no matter the perturbation; zero-sum games under Definition 1.1 constitute such a class. Besides the point above, different algorithms designed for the same problem can have entirely different properties, not least in terms of their smoothed complexity. The class of algorithms we consider in this paper is quite distinct from the ones shown to have polynomial smoothed complexity in the context of linear programs (described further in Appendix A). In many ways, gradient-based methods are simpler and more natural, which partly justifies their tremendous practical use. As a result, understanding their smoothed complexity is an important question. ", "page_idx": 2}, {"type": "text", "text": "1.1 Our results ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our main contribution is to show that, with the exception of OMwU, the other gradient-based algorithms mentioned above (Items 1, 3 and 4) have polynomial smoothed complexity with high probability\u2014-that is to say, with probability at least $1-{\\frac{1}{\\mathsf{p o l y}(n m)}}$ ", "page_idx": 2}, {"type": "text", "text": "Theorem 1.2. With high probability over the randomness of $\\mathbf{A}\\in\\mathbb{R}^{n\\times m}$ (Definition 1.1), 0GDA, EGDA and IterSmooth converge to an e-equilibrium after pol $y(n,m,1/\\sigma)\\cdot\\log(1/\\epsilon)$ iterations. ", "page_idx": 2}, {"type": "text", "text": "The main takeaway of this result is that, modulo pathological instances, certain gradient-based algorithms are reliable solvers in zero-sum games even in the high-precision regime. Similarly to earlier endeavors in the context of linear programs [Spielman and Teng, 2004, Blum and Dunagan, 2002], a dependency of poly $(1/\\sigma)$ (as in Theorem 1.2) is what we should expect; the one exception is the class of interior-point methods whose running time grows as $\\log(1/\\sigma)$ , but those algorithms are (weakly) polynomial even in the worst case. We further remark that the polynomial dependency on $n$ and $m$ in Theorem 1.2 can almost certainly be improved, and we made no effort to optimize it. ", "page_idx": 2}, {"type": "text", "text": "Regarding OMwU, which is not covered by Theorem 1.2, we also obtain a significant improvement in the iteration complexity compared to the worst-case analysis of Wei et al. [2021], but our bound is still not polynomial. As we explain further in Appendix C.3, the main diffculty pertaining to OMWU is that the analysis of Wei et al. [2021] gives (at best) an exponential bound no matter the geometry of the problem. With that mind, our result is essentially the best one could hope for without refining the worst-case analysis of OMwU, which is not within our scope here. We anticipate that our characterization herein will prove useful in conjunction with future developments in the worst-case complexity of OMwU, as well as in the analysis of other iterative methods. ", "page_idx": 2}, {"type": "text", "text": "The error bound   The central ingredient that enables gradient-based algorithms to exhibit linear convergence is a certain error bound, given below as Definition 1.3. For compactness in our notation, we let $\\mathcal{X}:=\\Delta^{n}$ and $\\mathcal{V}:=\\Delta^{m}$ .Wethen let $z:=(x,y)$ \uff0c $\\mathcal{Z}:=\\mathcal{X}\\times\\mathcal{Y}$ , and $\\mathcal{Z}^{\\star}:=\\mathcal{X}^{\\star}\\times\\mathcal{Y}^{\\star}$ , where $\\varkappa^{\\star}$ and $y^{\\star}$ represent the (convex) set of equilibria for Player $x$ andPlayer $y$ ,respectively. ", "page_idx": 2}, {"type": "text", "text": "Definition 1.3 (Error bound). Let $\\Phi(z)$ denote the duality gap as introduced in (2). We say that the zero-sum game (1) satisfies an error bound with modulus $\\kappa\\in\\mathbb{R}_{>0}$ if ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Phi(z)\\geq\\kappa\\|z-\\Pi_{\\mathcal{Z}^{\\star}}(z)\\|\\quad\\forall z\\in\\mathcal{Z}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Above, $\\Pi_{\\mathcal{Z}^{\\star}}(\\cdot)$ denotes the (Euclidean) projection operator; the set of games with a unique equilibrium has measure one, so we can safely replace $\\Pi_{\\mathcal{Z}^{\\star}}(z)$ by the unique equilibrium $z^{\\star}\\in\\mathcal{Z}^{\\star}$ . It has been known at least since the work of Tseng [1995] that affine variational inequalities indeed satisfy (3). Nevertheless, it should come to no surprise that, even in $3\\times3$ games, $\\kappa$ can be arbitrarily small (Proposition 3.1), which in turn means that, linear convergence notwithstanding, the number of iterations prescribed by an analysis revolving around (3) can be arbitrarily large. In fact, with the exception of OMwU, which is to be discussed further below, Definition 1.3 suffices to establish linear convergence (essentially) based on existing results.2 Our main result pertaining to Definition 1.3 is that the modulus $\\kappa$ is likely to be polynomial in the smoothed complexity model: ", "page_idx": 3}, {"type": "text", "text": "Theorem 1.4. With high probability over the randomness of A (Definition 1.1), the error bound perDefinition 1.3 is satisfied for any sufficiently small $\\kappa\\geq\\mathsf{p o l y}(\\sigma,1/(n m))$ ", "page_idx": 3}, {"type": "text", "text": "To establish this result, the first step is to lower bound $\\kappa$ in terms of certain natural geometric features of the problem (Theorem 3.6), which is discussed further in Section 3.1. Establishing Theorem 1.4 then reduces to analyzing each of those quantities under Definition 1.1. It turns out that bounding those quantities also suffices for characterizing OMwU, whose existing analysis due to Wei et al. [2021] involves some further ingredients besides the error bound of Definition 1.3. ", "page_idx": 3}, {"type": "text", "text": "Further implications Our characterization of the error bound given in Theorem 3.6 has some further important implications. First, a well-known vexing issue regarding computing equilibria even in zero-sum games is that a solution with small duality gap can still be relatively far from the equilibrium in the geometric sense, a phenomenon further exacerbated in multi-player games [Etessami and Yannakakis, 2007]. Therefore, results providing guarantees in terms of the duality gap are not particularly informative when it comes to computing strategies close to the equilibrium in a geometric sense. At the same time, there are ample reasons why the latter guarantee is more appealing [Etessami and Yannakakis, 2007]. Theorem 1.4 implies that such concerns can be alleviated in the smoothed complexity model: ", "page_idx": 3}, {"type": "text", "text": "Corollary 1.5. With high probability over the randomness of A (Definition 1.1), any point $z\\in{\\mathcal{Z}}$ With $\\Phi(z)\\leq\\epsilon$ satisfies $\\|z-z^{\\star}\\|\\leq\\epsilon\\cdot\\mathsf{p o l y}(n,m,1/\\sigma)$ ", "page_idx": 3}, {"type": "text", "text": "Beyond smoothed analysis, Theorem 3.6 applies to any non-degenerate game (Definition 3.2), and can be thereby used to parameterize the rate of convergence of gradient-based algorithms based on natural and interpretable game-theoretic quantities of the underlying game, which has eluded prior work. In particular, we make a natural connection between the complexity of gradient-based algorithms and perturbation stability properties of the equilibrium. In light of misspecifications which are often present in game-theoretic modeling, focusing on games with perturbation-stable equilibria is well-motivated and has already received ample of interest in prior work [Balcan and Braverman, 2017, Awasthi et al., 2010]; more broadly, perturbation stability is a common assumption in the analysis of algorithms beyond the worst-case model [Makarychev and Makarychev, 2021]. There are different natural ways of defining perturbation-stable games; here, we assume that any perturbation with magnitude below $\\delta>0$ , in that $\\|\\mathbf{A}^{\\prime}-\\mathbf{A}\\|_{2}\\leq\\delta$ , maintains the support of the equilibrium and the non-degeneracy of the game; we call such games $\\delta$ -support-stable (Definition 4.1). In this context, we show the following result. ", "page_idx": 3}, {"type": "text", "text": "Corollary 1.6. For any $\\delta$ -support-stable zero-sum game, OGDA, EGDA and IterSmooth converge to anE-equilibriumafter $\\mathsf{p o l y}(n,m,1/\\delta)\\cdot\\mathsf{l o g}(1/\\epsilon)$ iterations. ", "page_idx": 3}, {"type": "text", "text": "That is, games in which $\\delta$ is not too close to O are more amenable to gradient-based algorithms, which is a quite natural connection. Corollary 1.6 is shown by relating each of the quantities involved in Theorem 3.6 to parameter $\\delta$ defined above. ", "page_idx": 3}, {"type": "text", "text": "2 Notation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Before we proceed with our technical content, we first take the opportunity to streamline our notation; further background on smoothed analysis and a description of the algorithms referred to earlier (Items 1 to 4) is given later in Appendix B, as it is not important for the purpose of the main body. ", "page_idx": 3}, {"type": "text", "text": "We use boldface letters, such as $\\textstyle\\mathbf{{x}},\\pmb{{y}},\\pmb{{b}},\\pmb{{c}},$ . to represent vectors in a Euclidean space. For a vector $\\textbf{\\em x}\\in\\mathbb{R}^{n}$ , we access its ith coordinate via a subscript, namely $\\pmb{x}_{i}$ .Superscripts (together with parantheses) are typically reserved for the (discrete) time index. We denote by $\\|x\\|$ the Euclidean norm, $\\begin{array}{r}{\\|\\pmb{x}\\|:=\\sqrt{\\sum_{i=1}^{n}\\pmb{x}_{i}^{2}}}\\end{array}$ the $\\ell_{\\infty}$ norm by $\\|\\pmb{x}\\|_{\\infty}:=\\operatorname*{max}_{1\\leq i\\leq n}|\\pmb{x}_{i}|$ and the $\\ell_{1}$ norm by $\\|\\pmb{x}\\|_{1}:=$ $\\textstyle\\sum_{i=1}^{n}|\\pmb{x}_{i}|$ . For $\\mathbf{\\Delta}\\mathbf{x},\\mathbf{\\Delta}\\mathbf{x}^{\\prime}\\,\\in\\,\\mathbb{R}^{n}$ , we let $\\mathsf{d i s t}(\\boldsymbol{\\mathscr{x}},\\boldsymbol{\\mathscr{x}}^{\\prime}):=\\|\\boldsymbol{\\mathscr{x}}-\\boldsymbol{\\mathscr{x}}^{\\prime}\\|$ . span(-) represents the linear space spanned by a given set of vectors. For $\\pmb{x}\\in\\mathbb{R}^{n}$ and a subset $B\\subseteq[n]$ , we denote by $\\mathbf{\\boldsymbol{x}}_{B}\\,\\in\\,\\mathbb{R}^{B}$ the subvector of $\\textbf{\\em x}$ induced by $B$ . We let $\\mathbf{1}_{n}\\in\\mathbb{R}^{n}$ be the all-ones vector of dimension $n$ ; we will typically omit the subscript when it is clear from the context. For vectors $\\pmb{x}\\in\\mathbb{R}^{n}$ and $\\pmb{y}\\in\\mathbb{R}^{m}$ ,we write $(\\pmb{x},\\pmb{y})\\in\\mathbb{R}^{n+m}$ to denote their concatenation. Throughout this paper, we use $\\textbf{\\em x}$ and $\\textit{\\textbf{y}}$ to denote the strategy of Player $x$ and Player $y$ , respectively. ", "page_idx": 4}, {"type": "text", "text": "To represent matrices, we use boldface capital letter, such as A, Q. It will sometimes be convenient to use $\\mathbf{A}^{\\flat}\\in\\mathbb{R}^{n m}$ to represent a vectorization of $\\mathbf{A}\\in\\mathbb{R}^{n\\times m}$ . We overload notation by letting $\\lVert\\mathbf{A}\\rVert$ be the spectral norm of A. For a matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times m}$ and subsets $B\\,\\subseteq\\,[n],N\\,\\subseteq\\,[{\\dot{m}}]$ ,we denote by $\\mathbf{A}_{B,N}\\in\\mathbb{R}^{B\\times N}$ the submatrix of $\\mathbf{A}$ induced by $B$ and $N$ ${\\bf A}_{i}.$ : and $\\mathbf{A}_{:,j}$ represent the $i$ throw and $j$ th column of $\\mathbf{A}$ , respectively. The singular values of a matrix $\\mathbf{M}\\in\\mathbb{R}^{d\\times d}$ are denoted by $\\sigma_{1}(\\overset{\\cdot}{\\mathbf{M}})\\geq\\sigma_{2}(\\mathbf{M})\\geq\\cdots\\geq\\sigma_{d}(\\mathbf{M})\\geq0$ (not to be confused with our notation for the variance $\\sigma^{2}$ To be more explicit, we may also use $\\sigma_{\\mathrm{max}}(\\mathbf{M}):=\\sigma_{1}(\\mathbf{M})$ and $\\sigma_{\\operatorname*{min}}(\\mathbf{M}):=\\sigma_{d}(\\mathbf{M})$ ", "page_idx": 4}, {"type": "text", "text": "3  Smoothed analysis of the error bound ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we perform a smoothed analysis of the error bound\u2014-as introduced earlier in Definition 1.3\u2014in (two-player) zero-sum games. It is first instructive to point out why smoothed analysis is useful in the first place: the modulus $\\kappa$ can be arbitrarily close to O even when $n=m=3$ (that is, $3\\times3$ games); this is detrimental as the iteration complexity of algorithms such as OGDA grows as a polynomial in $1/\\kappa$ ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.1. There exists a $3\\times3$ zero-sum game such that K per Definition 1.3 is arbitrarily closeto O. ", "page_idx": 4}, {"type": "text", "text": "In proof, it is enough to consider the ill-conditioned diagonal matrix ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\bf A}=\\left(\\!\\!\\begin{array}{c c c}{{\\gamma}}&{{0}}&{{0}}\\\\ {{0}}&{{2\\gamma}}&{{0}}\\\\ {{0}}&{{0}}&{{1}}\\end{array}\\!\\!\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $0<\\gamma\\ll1$ . The unique) equilibium o (4) reads $\\begin{array}{r}{\\pmb{x}^{\\star}=\\pmb{y}^{\\star}=\\frac{1}{3+2\\gamma}(2,1,2\\gamma)\\in\\Delta^{3}}\\end{array}$ Now, considering $\\pmb{x}=(1,0,0)$ and $\\pmb{y}=(0,0,1)$ , for the duality gap we have $\\Phi({\\boldsymbol{x}},{\\boldsymbol{y}})={\\boldsymbol{\\gamma}}$ , while the distancef,yfthepimal solion (x\\*isa ast . In turn, by Definition 1.3, this means that $\\kappa\\leq2\\gamma$ . So, Proposition 3.1 follows by taking $\\gamma\\to0$ 3 ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.1 exposes one type of pathology that can decelerate gradient-based algorithms, which is evidently related to the poor spectral properties of the payoff matrix. This intuition is quite helpful when equilibria are fully supported\u2014-as is the case in (4)\u2014-but has to be significantly refined more broadly, as we formalize in the sequel. ", "page_idx": 4}, {"type": "text", "text": "To sidestep such pathological examples, we thus turn to the smoothed analysis framework of Definition 1.1. ", "page_idx": 4}, {"type": "text", "text": "3.1 Overview ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The most natural approach to analyze the error bound in the smoothed complexity model is to rely on an existing (worst-case) analysis proving that a positive $\\kappa$ exists, and then attempt to refine that analysis. Yet, at least based on such prior results we are aware of, that turns out to be challenging. As an example, let us consider the recent analysis of Wei et al. [2021]. As we explain in more detail in Appendix C.3, Wei et al. [2021] relate the modulus $\\kappa$ of the error bound to the (inverse of the) norm of a solution to a certain feasible linear program; the existence of a legitimate $\\kappa>0$ then follows readily from feasibility. Now, this reduction seems quite promising: Renegar [1994] has shown that the norm of a solution to a linear program can be bounded in terms of its condition number\u2014the distance to infeasibility in our case, and Dunagan et al. [2011] later proved that the condition number of linear programs is polynomial in the smoothed complexity model. Nevertheless, there are some difficulties in materializing that argument. First, the induced linear program involves terms depending on both the payoff matrix and the geometry of the constraints (the probability simplex in our case). Consequently, the analysis of Dunagan et al. [2011] does not carry over since randomness is only injected into the payoff matrix. The second and more important obstacle is that the induced linear program depends on the optimal solution, which in turn depends on the randomness of the payoff matrix; this significantly entangles the underlying distribution. As there are exponentially many possible configurations, we cannot afford to argue about each one separately and then apply the union bound. This difficulty is in fact known to be the crux in performing smoothed analysis [Spielman and Teng, 2004].4 ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "To address those challenges, we provide a new characterization of the error bound in terms of some natural quantities of the underlying game (Theorem 3.6), which in some sense capture the difficulty of the problem. We are then able to use a technique due to Spielman and Teng [2004], exposed in Section 3.3, to bound the probability that each of the involved quantities is close to 0 (Propositions 3.8 to 3.10), even though the underlying distribution is quite convoluted. The resulting analysis follows the one given by Spielman and Teng [2003] in the context of termination of linear programs, but still has to account for a number of structural differences. ", "page_idx": 5}, {"type": "text", "text": "In what follows, we structure our argument as follows. First, in Section 3.2, we relate the modulus $\\kappa$ to some natural quantities capturing key geometric features of the problem. Section 3.3 then proceed by analyzing those quantities in the smoothed analysis framework. ", "page_idx": 5}, {"type": "text", "text": "3.2  Characterization of the error bound ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our first goal is to characterize the error bound in terms of certain natural quantities, which will then enable us to provide polynomial error bounds in the smoothed complexity model. Our only assumption here is that the zero-sum game is non-degenerate, in the sense of Definition 3.2 below; this can always be met with the addition of an arbitrarily small amount of noise (Lemma C.1). As such, our characterization here has an interest beyond the smoothed analysis framework, casting the error bound in terms of more interpretable game-theoretic quantities; for example, a concrete implication is given in Section 4. ", "page_idx": 5}, {"type": "text", "text": "Let us denote by $v$ the value of game (1), that is, ", "page_idx": 5}, {"type": "equation", "text": "$$\nv=\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}}\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}\\rangle=\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}\\rangle,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which is a consequence of the minimax theorem [von Neumann, 1928]. We are now ready to state the formal definition of a non-degenerate game. ", "page_idx": 5}, {"type": "text", "text": "Definition 3.2 (Non-degenerate game). A zero-sum game described with a payoff matrix A and value $v$ is said to be non-degenerate if it admits a unique equilibrium $({\\pmb x}^{\\star},{\\pmb y}^{\\star})\\in\\mathcal{Z}$ , and $x^{\\star}$ and $\\boldsymbol{y}^{\\star}$ maketight exactly $n$ of the inequalities $\\{x_{i}\\geq0\\}_{i\\in[n]}\\cup\\{\\langle x,\\mathbf{A}_{:,j}\\rangle\\,\\leq\\,v\\}_{j\\in[m]}$ and $m$ of the inequalities $\\{y_{j}\\geq0\\}_{j\\in[m]}\\cup\\{\\langle{\\pmb y},{\\bf A}_{i,:}\\rangle\\geq v\\}_{i\\in[n]}$ ,respectively. ", "page_idx": 5}, {"type": "text", "text": "In the sequel, we will make constant use of the fact that the set of degenerate games has measure zero under the law induced by Definition 1.1 (Lemma C.1). ", "page_idx": 5}, {"type": "text", "text": "In this context, we let $B(\\pmb{x}^{\\star}):=\\{i\\in[n]:\\pmb{x}_{i}^{\\star}>0\\}$ denote the support of $x^{\\star}$ (corresponding to Player $x$ ), and similarly $N(\\pmb{y}^{\\star}):=\\{j\\,\\in\\,[m]\\,:\\,\\pmb{y}_{j}^{\\star}>0\\}$ for the support of Player $y$ . The strict complementarity theorem [Ye, 2011] tells us that $B$ indexes exactly the set of tight inequalities $\\{\\langle\\pmb{y},\\mathbf{\\bar{A}}_{i,:}\\rangle\\geq v\\}_{i\\in[n]}$ and symmetrically, $N$ indexes exactly the set of tight inequalities $\\{\\langle\\mathbf{x},\\mathbf{\\bar{A}}_{:,j}\\rangle\\leq$ $v\\}_{j\\in[m]}$ . In particular, this implies that $|B|=|N|$ with probability 1. It will also be convenient to define $\\overline{{B}}:=[n]\\setminus B$ and $\\overline{{N}}:=[m]\\setminus N$ ", "page_idx": 5}, {"type": "text", "text": "Now, at a high level, one can split solving a zero-sum game into two subproblems: i) identifying the support of the equilibrium, and ii) solving the induced linear system to specify the exact probabilities within the support. It will be helpful to have that viewpoint in mind in the upcoming analysis, and in particular in the proof of Theorem 3.6. Roughly speaking, thinking of $\\kappa$ as a measure of the problem's difficulty,we will relate $\\kappa$ to i) the difficulty of identifying the support of the equilibrium, and i) the difficulty of solving the induced linear system. To be clear, those two subproblems are only helpful for the purpose of the analysis, and they are certainty intertwined when using algorithms such as OGDA. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Staying on the latter task, we will make use of a certain transformation so as to eliminate one of the redundant variables. Namely, for any $\\widehat{\\pmb{x}}_{B}\\in\\Delta(B)$ and ${\\widehat{\\pmb{y}}}_{N}\\in\\Delta(N)$ , let us select a fixed pair of coordinates $(i,j)\\in B\\times N$ (for example, the ones with the smallest index). Using the fact that $\\langle{\\widehat x}_{B},\\mathbf{1}\\rangle=1$ and $\\langle\\widehat{\\pmb y}_{N},\\mathbf{1}\\rangle=1$ , we can eliminate ${\\widehat{\\pmb{x}}}_{i}$ and ${\\widehat{\\pmb{y}}}_{j}$ by writing ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\langle\\widehat{\\pmb x}_{B},\\mathbf{A}_{B,N}\\widehat{\\pmb y}_{N}\\rangle=\\langle\\widetilde{\\pmb x},\\mathbf{Q}\\widetilde{\\pmb y}\\rangle-\\langle\\widetilde{\\pmb x},\\pmb c\\rangle-\\langle\\widetilde{\\pmb y},\\pmb b\\rangle+d,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where  E R, $\\widetilde{\\pmb{x}}\\in\\mathbb{R}_{\\ge0}^{\\widetilde{B}},\\widetilde{\\pmb{y}}\\in\\mathbb{R}_{\\ge0}^{\\widetilde{N}}$ $\\widetilde{B}:=B\\setminus\\{i\\}$ $\\widetilde{N}\\,:=\\,N\\setminus\\{j\\})$ ${\\widehat{\\pmb{x}}}_{B}$ $\\widehat{\\pmb{y}}_{N}$ $\\widetilde{B}$ $\\widetilde{N}$ $\\mathbf{A}_{B,N}^{\\flat}=\\mathbf{T}(\\mathbf{Q}^{\\flat},b,c,d)$   \ntransformation $\\mathbf{T}\\,\\in\\,\\mathbb{R}^{(B N)\\,\\times\\,(B N)}$ (We spell out the exact definition of $\\mathbf{T}$ later in Appendix C.1, as it is not important for our purposes here; it follows by simply writing $\\widehat{\\pmb{x}}_{i}\\,=\\,1\\,-\\,\\langle\\widetilde{\\pmb{x}},{\\bf1}\\rangle$ and $\\widehat{\\pmb{y}}_{j}\\,=\\,1\\,-\\,\\langle\\widetilde{\\pmb{y}},\\mathbf{\\bar{1}}\\rangle$ ) The point of transformation (5) is that, by eliminating one of the redundant variables, there is a convenient characterization of the equilibrium (Claim C.3); namely, $\\mathbf{Q}\\mathbf{\\boldsymbol{y}}^{\\star}=\\mathbf{\\boldsymbol{c}}$ and $\\mathbf{Q}^{\\top}\\boldsymbol{\\mathbf{x}}^{\\star}=\\pmb{b}$ ", "page_idx": 6}, {"type": "text", "text": "We are now ready to introduce the key quantities upon which our characterization relies on. It turns out that those are analogous to the ones considered by Spielman and Teng [2003] in the context of analyzing the termination of linear programs; this is not coincidental, as our analysis was especially targetedtodoso. ", "page_idx": 6}, {"type": "text", "text": "Definition 3.3. Let A be the payoff matrix of a non-degenerate game, $({\\boldsymbol{x}}^{\\star},{\\boldsymbol{y}}^{\\star})\\in\\mathcal{Z}$ the unique equilibrium, and $B\\,\\subseteq\\,[n],N\\,\\subseteq\\,[m]$ the support of $x^{\\star}$ and $\\boldsymbol{y}^{\\star}$ respectively. We introduce the following quantities. ", "page_idx": 6}, {"type": "text", "text": "(Above, we adopt the convention that if a minimization problem is with respect to an empty set, the minimum is to be evaluated as 1.) ", "page_idx": 6}, {"type": "text", "text": "Item 3 above will enable us to control the norm of solutions to any linear system induced by $\\mathbf{Q}$ as we explain in the sequel. Our proof will actually rely on a slightly different matrix, which we call $\\overline{{\\mathbf{Q}}}$ the lemma below relates the geometry of $\\overline{{\\mathbf{Q}}}$ to $\\mathbf{Q}$ , and reassures us that the condition number of $\\overline{{\\mathbf{Q}}}$ cannot be far from that of $\\mathbf{Q}$ so long as $\\begin{array}{r}{1-\\sum_{j\\in\\tilde{N}}\\pmb{y}_{j}^{\\star}\\geq\\alpha_{D}(\\mathbf{A})}\\end{array}$ (by Item 1) is not to close to 0. (A symmetric statement holds when focusing on Player $y$ ) ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.4. Let $\\begin{array}{r}{\\pmb{c}=\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\sum_{j\\in\\widetilde{N}}\\widetilde{\\pmb{y}}_{j}^{\\star}\\mathbf{Q}_{:,j}}\\end{array}$ and suppose that $\\overline{{\\mathbf{Q}}}\\in\\mathbb{R}^{\\widetilde{B}\\times\\widetilde{N}}$ is such that its th column is equal to $\\mathbf{Q}_{:,j}-c$ Then, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{j\\in\\tilde{N}}\\mathsf{d i s t}(\\mathbf{Q}_{:,j},\\mathsf{s p a n}(\\mathbf{Q}_{:,\\tilde{N}-j}))\\leq\\left(1+\\frac{|\\widetilde{N}|}{1-\\sum_{j\\in\\tilde{N}}y_{j}^{\\star}}\\right)\\operatorname*{min}_{j\\in\\tilde{N}}\\mathsf{d i s t}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\tilde{N}-j})).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Next, we recall a fairly standard bound relating the magnitude of a solution to a linear system $\\widetilde{\\pmb{x}}=\\mathbf{M}p$ with the smallest singular value of a full-rank matrix $\\mathbf{M}$ ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.5. Let $\\textbf{M}\\in\\~\\mathbb{R}^{d\\times d}$ be a full-rank matrix. For any $\\widetilde{\\textbf{\\em x}}\\in\\mathbb{R}^{d}$ there is $\\textbf{\\textit{p}}\\in\\~\\mathbb{R}^{d}$ with $\\|p\\|\\leq\\frac{1}{\\sigma_{\\operatorname*{min}}(\\mathbf{M})}\\|\\widetilde{\\pmb{x}}\\|$ suchthat ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}=\\mathbf{M}\\pmb{p}=\\sum_{j=1}^{d}p_{j}\\mathbf{M}_{:,j}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Moreover, to connect Lemma 3.5 with $\\gamma_{P}(\\mathbf{A})$ , we observe that the smallest singular value can also be lower bounded in terms of the smallest distance of a column from the linear space spanned by the rest of the columns\u2014-which now matches the expression of Item 3 we saw earlier. In particular, we will make use of the so-called negative second moment identity [Tao et al., 2010] (Proposition C.4), which implies that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\geq\\sqrt{\\frac{1}{\\sum_{j\\in\\widetilde{N}}\\mathrm{dist}^{-2}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\widetilde{N}-j}))}}\\geq\\frac{1}{\\sqrt{|\\widetilde{N}|}}\\operatorname*{min}_{j\\in\\widetilde{N}}\\mathrm{dist}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\widetilde{N}-j})).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Proposition C.4 also implies that $\\begin{array}{r}{\\gamma_{D}(\\mathbf{A})\\geq\\frac{1}{\\sqrt{|\\widetilde{B}|}}\\gamma_{P}(\\mathbf{A})}\\end{array}$ YP(A), and soit wlsufice t lower bound yPA ) in the sequel. We are now ready to proceed with the main result of this subsection. Below, we use the notation $\\stackrel{\\bullet\\bullet}{\\sim}$ to suppresslower-order terms and absolute constants. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.6. Let A be a non-degenerate payoff matrix, and suppose that $(\\alpha_{P}(\\mathbf{A}),\\alpha_{D}(\\mathbf{A}))$ $(\\beta_{P}(\\mathbf{A}),\\beta_{D}(\\mathbf{A}))$ and $(\\gamma_{P}(\\mathbf{A}),\\gamma_{D}(\\mathbf{\\bar{A}}))$ are as in Definition 3.3. Then, the error bound (Definition1.3)is satisfiedfor any sufficiently small modulus ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\kappa\\gtrsim\\frac{1}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\frac{1}{\\operatorname*{min}(n,m)^{3}}\\operatorname*{min}\\left\\{(\\alpha_{D}(\\mathbf{A}))^{2}\\beta_{D}(\\mathbf{A})\\gamma_{P}(\\mathbf{A}),(\\alpha_{P}(\\mathbf{A}))^{2}\\beta_{P}(\\mathbf{A})\\gamma_{D}(\\mathbf{A})\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "It is enough to explain how to lower bound $\\kappa\\,>\\,0$ such that $\\begin{array}{r}{\\operatorname*{max}_{\\pmb{y}^{\\prime}\\in\\mathcal{Y}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle\\mathrm{~-~}v\\mathrm{~\\ge~}\\kappa\\|\\pmb{x}\\mathrm{~-~}}\\end{array}$ $\\Pi_{\\mathcal{X}^{\\star}}({\\pmb x})\\|\\,\\dot{=}\\,\\kappa\\|{\\pmb x}^{\\,\\^}-{\\pmb x}^{\\star}\\|$ for any $\\textbf{\\em x}\\in\\ \\mathcal{X}$ . In a nutshell, our argument is divided based on the magnitude $\\lambda:=\\|\\pmb{x}_{B}\\|$ , which can be thought of as a measure of closeness from the support of the equilibrium. When $\\lambda\\ll1$ , which means that $\\textbf{\\em x}$ is still far from the support of the equilibrium, $\\bar{\\mathrm{max}_{\\pmb{y}^{\\prime}\\in\\mathcal{Y}}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle\\,-v$ is governed by $\\beta_{D}(\\mathbf{A})$ . In the contrary case, our basic strategy revolves around showing that the error bound can be treated as in the unconstrained case, which would then relate the modulus $\\kappa$ to the smallest singular value of the underlying matrix (essentially by Lemma 3.5)\u2014and subsequently to $\\gamma_{P}(\\mathbf{A})$ due to (6). Indeed, this turns out to be possible by working with matrix $\\overline{{\\mathbf{Q}}}$ as defined earlier in Lemma 3.4. We defer the precise argument to Appendix C.1. ", "page_idx": 7}, {"type": "text", "text": "3.3  Smoothed analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Having established Theorem 3.6, our next step is to show that each of the quantities introduced in Definition 3.3 is unlikely to be too close to 0 in the smoothed complexity model, which would then imply Theorem 1.4. The main difficulty lies in the fact that each configuration that may arise depends on the support of the equilibrium, which in turn depends on the underlying randomization of A, thereby significantly complicating the underlying distribution. Further, one cannot afford to argue about each configuration separately and then apply the union bound as there are too many possible configurations. To tackle this challenge, we follow the approach put forward by Spielman and Teng [2003]. ", "page_idx": 7}, {"type": "text", "text": "In particular, given that all quantities of interest in Theorem 3.6 depend on the support of the equilibrium, it is natural to proceed by partitioning the probability space over all possible supports, and then bound the worst possible one\u2014that is, the one maximizing the probability we want to minimize. In doing so, the challenge is that one has to condition on the equilibrium having a given support (formally justified by Proposition C.5). To argue about the induced probability density function upon such a conditioning, it is convenient to perform a change of variables from A to a new set of variables that now contains the equilibrium $(x^{\\star},y^{\\star})$ (Lemma C.6). The basic idea here is that since the event we condition on concerns the equilibrium, it is helpful to have that equilibrium being part of our set of variables. The induced probability density function is now quite complicated, but can still be analyzed using the following lemma. ", "page_idx": 7}, {"type": "text", "text": "Lemma 3.7 (Spielman and Teng, 2003). Let $\\rho$ be the probability density function of a random variable $X$ .Ifthere exist $\\delta>0$ and $c\\in(0,1]$ suchthat ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\leq t\\leq t^{\\prime}\\leq\\delta\\implies\\frac{\\rho(t^{\\prime})}{\\rho(t)}\\geq c,}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}[X\\leq\\epsilon\\mid X\\geq0]\\leq\\frac{\\epsilon}{c\\delta}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "In words, random variables whose density is smooth\u2014in the sense of (7)\u2014are unlikely to be too close to 0. Gaussian random variables certainly have that property (Lemma C.8), but it is not confined to the Gaussian law; the analysis of Spielman and Teng [2003]\u2014and subsequently our resultis not tailored to the Gaussian case. ", "page_idx": 8}, {"type": "text", "text": "We are now ready to state our main results in the smoothed complexity model; the proofs are deferred to Appendix C.2. We commence with $\\beta_{P}(\\mathbf{A})$ , which is the easiest to analyze. In particular, the following result is a consequence of an anti-concentration bound with respect to a conditional Gaussian random variable (Lemma C.7). ", "page_idx": 8}, {"type": "text", "text": "Proposition 3.8. Let $\\beta_{P}(\\mathbf{A})$ be defined as in Item 2. For any $\\epsilon\\geq0$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\beta_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{5\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\right]\\leq\\epsilon\\frac{e\\operatorname*{min}(n,m)^{2}}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The analysis of $\\gamma_{P}(\\mathbf{A})$ is more challenging, and makes crucial use of Lemma 3.7. As we alluded to earlier, a key step is to change variables from ${\\bf A}_{B,N}$ to $(\\mathbf{Q},b,c,\\cdot)$ in accordance with (5)\u2014and then to $(\\mathbf{Q},\\mathbf{x}^{\\star},\\mathbf{y}^{\\star},\\cdot)$ based on $\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star}=\\boldsymbol{c}$ $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}=\\pmb{b}$ . It is important to note that $\\mathbf{Q}$ no longer contains independent random variables even though ${\\bf A}_{B,N}$ is (by Definition 1.1); this stems from the presence of a redundant variable in $\\pmb{x}_{B}^{\\star}$ (since $\\langle\\pmb{x}_{B}^{\\star},\\mathbf{1}\\rangle=1\\,$ ). Nevertheless, we can still overcome this issue using Lemma 3.7, leading to the following bound. ", "page_idx": 8}, {"type": "text", "text": "Proposition 3.9. Let $\\gamma_{P}(\\mathbf{A})$ be defined as in Item 3. For any $\\epsilon\\geq0$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\gamma_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{4\\operatorname*{max}_{j\\in\\tilde{N}}\\|\\mathbf{Q}_{:,j}\\|+20\\|\\mathbf{A}^{\\flat}\\|_{\\infty}+3}\\right]\\leq\\epsilon\\frac{4e\\operatorname*{min}(n,m)^{3}}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Similar reasoning, albeit with some further complications, provides a bound for $\\alpha_{P}(\\mathbf{A})$ , which is givenbelow. ", "page_idx": 8}, {"type": "text", "text": "Proposition 3.10. Let $\\alpha_{P}(\\mathbf{A})$ be defined as in Item 1. For any $\\epsilon\\geq0$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\alpha_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{25(\\|\\mathbf{A}^{\\flat}\\|_{\\infty}+1)^{2}}\\right]\\leq\\epsilon\\frac{8e^{2}m n\\operatorname*{min}(n,m)}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Armed with Propositions 3.8 to 3.10 and Theorem 3.6, we can establish Theorem 1.2 by suitably leveraging existing results, as we formalize in Appendix C.3. ", "page_idx": 8}, {"type": "text", "text": "4   Parameterized results for perturbation-stable games ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Another important implication of our characterization in Theorem 3.6 is that it enables connecting the convergence rate of gradient-based algorithms to natural and interpretable game-theoretic quantities. In particular, here we highlight a connection with perturbation-stable games, in the following formal sense. ", "page_idx": 8}, {"type": "text", "text": "Definition 4.1 (Perturbation-stable games). Let A be the payoff matrix of a non-degenerate game. We say that the game is $\\delta$ -support-stable,with $\\delta>0$ , if for any $\\mathbf{A}^{\\prime}$ With $\\|\\mathbf{A}-\\mathbf{A}^{\\prime}\\|\\leq\\delta$ it holds that $\\mathbf{A}^{\\prime}$ is a non-degenerate game whose equilibrium has the same support as A. ", "page_idx": 8}, {"type": "text", "text": "Perhaps the simplest example of a support-stable game with a favorable parameter $\\delta\\,>\\,0$ arises when $\\mathbf{A}$ is the $2\\times2$ identity matrix. Indeed, as long as the perturbation parameter $\\delta$ remains below a certain absolute constant, the perturbed game still admits a unique full-support equilibrium. To see this, suppose for the sake of contradiction that the perturbed game has an equilibrium such that Player $x$ plays one of the two actions with probability 1. Player $y$ would then obtain a utility of at least $1-O(\\delta)$ . But the value of the original game was $1/2$ , which in turn implies that the value of the perturbed game is $1/2\\pm\\Theta(\\delta)$ ; for a sufficiently small $\\delta$ this leads to a contradiction. Similar reasoning applies with respect to Player $y$ (The previous argument carries over more broadly to diagonally dominant $2\\times2$ payoff matrices.) ", "page_idx": 8}, {"type": "text", "text": "As we have highlighted already, games with perturbation-stable equilibria\u2014albeit under different notions of stability\u2014have already received attention in the literature [Balcan and Braverman, 2017, Awasthi et al., 2010] (cf. Cohen [1986]), and are part of a broader trend in the analysis of algorithms beyond the worst case (for further background, we refer to the excellent book edited by Roughgarden [2021]). Our goal here is to make the following natural connection. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.2. Any $\\delta$ -support-stable game (per Definition 4.1\uff09 satisfies the error bound for any sufficientlysmallmodulus ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\kappa\\geq\\mathsf{p o l y}\\left(\\frac{1}{n},\\frac{1}{m},\\delta\\right).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "By virtue of our discussion in Appendix C.3, Theorem 4.2 immediately implies Corollary 1.6. Indeed, we observe that all parameters involved in Theorem 3.6 can be lower bounded in terms of the stability parameter of Definition 4.1, as we formalize in Appendix C.4. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusions and future research ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In conclusion, we performed the first smoothed analysis with respect to a number of well-studied gradient-based algorithms in zero-sum games. In particular, we showed that OGDA, EGDA and IterSmooth all enjoy polynomial smoothed complexity, meaning that their iteration complexity grows as a polynomial in the dimensions of the game, $1/\\sigma$ ,and $\\log(1/\\epsilon)$ ; for OMwU, our analysis reveals a significant improvement over the worst-case bound due to Wei et al. [2021], but it still remains superpolynomial. We also made a connection between the rate of convergence of the above algorithms and a natural perturbation-stability property of the equilibrium, which is interesting beyond the model of smoothed complexity. ", "page_idx": 9}, {"type": "text", "text": "A number of interesting avenues for future research remain open. First, is it the case that OMwU has polynomial smoothed complexity or is there an inherent separation with the other algorithms we studied? Answering this question in the positive would necessitate significantly improving the worst-case analysis of 0MwU due to Wei et al. [2021] (cf. Cai et al. [2024] for a recent development concerning the last-iterate convergence of OMwU). Beyond OMWU, our results could also prove useful for establishing polynomial bounds for other natural dynamics in the smoothed analysis framework. Moreover, our characterization of the error bound in Theorem 3.6 assumes that the game is non-degenerate. This is an innocuous assumption in the smoothed complexity model, as it holds with probability 1, but nevertheless it would be interesting to generalize it to any game. Doing so could shed some light into whether Theorem 4.2 holds with respect to other, perhaps more natural notions of perturbation stability beyond Definition 4.1. It would also be interesting to investigate other models of smoothed complexity that account for dependencies between the entries of the payoff matrix [Bhaskara et al., 2024]. Moreover, our focus has been on zero-sum games under simplex constraints, but we suspect that more general positive results should be attainable under polyhedral constraint sets; perhaps the most notable such candidate is the class of extensive-form games [Romanovskii, 1962, von Stengel, 1996]. Even beyond (two-player) zero-sum games, Theorem 1.2 could apply to (multi-player) polymatrix zero-sum games [Cai et al., 2016]. It is less clear whether the model of smoothed complexity can be informative when it comes to convergence to coarse correlated equilibria in multi-player games. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We are grateful to the anonymous reviewers at NeurIPS for their helpful feedback. The first author is indebted to Ioannis Panageas for many insightful discussions. This material is based on work supported by the Vannevar Bush Faculty Fellowship ONR N00014-23-1-2876, National Science Foundation grants RI-2312342 and RI-1901403, ARO award W911NF2210266, and NIH award A240108S001. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Kenshi Abe, Kaito Ariu, Mitsuki Sakamoto, Kentaro Toyoshima, and Atsushi Iwasaki. Last-iterate convergence with full and noisy feedback in two-player zero-sum games. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2023. ", "page_idx": 9}, {"type": "text", "text": "Ilan Adler. The equivalence of linear programs and zero-sum games. Int. J. Game Theory, 42(1): 165-177,2013. ", "page_idx": 9}, {"type": "text", "text": "Ahmet Alacaoglu and Yura Malitsky. Stochastic variance reduction for variational inequality methods. In Conference on Learning Theory (COLT), 2022. ", "page_idx": 9}, {"type": "text", "text": "Kimon Antonakopoulos, Elena Veronica Belmega, and Panayotis Mertikopoulos. Adaptive extragradient methods for min-max optimization and games. In International Conference on Learning Representations (ICLR), 2021.   \nDavid L. Applegate, Oliver Hinder, Haihao Lu, and Miles Lubin. Faster first-order primal-dual methods for linear programming using restars and sharpness. Mathematical Programming, 201 (1):133-184, 2023.   \nPranjal Awasthi, Maria-Florina Balcan, Avrim Blum, Or Sheffet, and Santosh S. Vempala. On nash-equilibria of approximation-stable games. In International Symposium on Algorithmic Game Theory (SAGT), 2010.   \nWaiss Azizian, Damien Scieur, Ioannis Mitliagkas, Simon Lacoste-Julien, and Gauthier Gidel. Accelerating smooth games by manipulating spectral shapes. In International Conference on Artijficial Intelligence and Statistics (2020), Proceedings of Machine Learning Research, 2020.   \nMaria-Florina Balcan and Mark Braverman. Nash equilibria in perturbation-stable games. Theory Comput., 13(1):1-31, 2017.   \nAditya Bhaskara, Eric Evert, Vaidehi Srinivas, and Aravindan Vijayaraghavan. New tools for smoothed analysis: Least singular value bounds for random matrices with dependent entries. In Proceedings of the Annual Symposium on Theory of Computing (STOC), 2024.   \nMarkus Blaser and Bodo Manthey. Smoothed complexity theory. ACM Trans. Comput. Theory, 7(2): 6:1-6:21, 2015.   \nAvrim Blum and John Dunagan. Smothed analysis of the perceptron algorithm for linear programming. In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2002.   \nShant Boodaghians, Joshua Brakensiek, Samuel B. Hopkins, and Aviad Rubinstein. Smoothed complexity of 2-player nash equilibria. In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2020.   \nMichael Bowling, Neil Burch, Michael Johanson, and Oskari Tammelin. Heads-up limit hold'em poker is solved. Science, 347(6218):145-149, 2015.   \nBenjamin Brooks and Philip J. Reny. A canonical game\u2014-75 years in the making-showing the equivalence of matrix games and linear programming. Economic Theory Bulletin, 2023.   \nNoam Brown and Tuomas Sandholm. Superhuman AI for heads-up no-limit poker: Libratus beats top professionals. Science, 359(6374):418-424, 2018.   \nNoam Brown and Tuomas Sandholm. Solving imperfect-information games via discounted regret minimization. In Conference on Artificial Intelligence (AAAl), 2019.   \nLuciana S. Buriol, Marcus Ritt, Felix Carvalho Rodrigues, and Guido Schafer. On the smoothed price of anarchy of the traffic assignment problem. In Workshop on Algorithmic Approaches for Transportation Modeling, Optimization, and Systems (ATMOS), 2011.   \nYang Cai, Ozan Candogan, Constantinos Daskalakis, and Christos H. Papadimitriou. Zero-sum polymatrix games: A generalization of minmax. Mathematics of Operations Research, 41(2): 648-655, 2016.   \nYang Cai, Argyris Oikonomou, and Weiqiang Zheng. Finite-time last-iterate convergence for learning inmulti-player gamesInProceedings of the Anual ConferenceonNeural InformationProcessing Systems (NeurIPS), 2022.   \nYang Cai, Gabriele Farina, Julien Grand-Clment, Christian Kroer, Chung-Wei Lee, Haipeng Luo, and Weiqiang Zheng. Fast last-iterate convergence of learming in games requires forgetful algorithms. InProceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2024.   \nYair Carmon, Yujia Jin, Aaron Sidford, and Kevin Tian. Variance reduction for matrix games. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2019.   \nYair Carmon, Yujia Jin, Aaron Sidford, and Kevin Tian. Coordinate methods for matrix games. In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2020.   \nYair Carmon, Arun Jambulapati, Yujia Jin, and Aaron Sidford. A whole new ball game: A primal accelerated method for matrix games and minimizing the maximum of smooth functions. In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2024.   \nXi Chen, Xiaotie Deng, and Shang-Hua Teng. Settling the complexity of computing two-player Nash equilibria. Journal of the ACM, 2009.   \nXi Chen, Chenghao Guo, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Mihalis Yannakakis, and Xinzhi Zhang. Smoothed complexity of local max-cut and binary max-csp. In Proceedings of the Annual Symposium on Theory of Computing (STOC), 2020.   \nXi Chen, Chenghao Guo, Emmanouil-Vasileios Vlatakis-Gkaragkounis, and Mihalis Yannakakis. Smoothed complexity of SWAP in local graph partitioning. Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2024.   \nChao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and ShenghuoZhu. Online optimization with gradual variations. In Conference on Learning Theory (COLT), 2012.   \nMiranda Christ and Mihalis Yannakakis The smoothed complexity of policy iteration for markov decision processes. In Proceedings of the Annual Symposium on Theory of Computing (STOC), 2023.   \nKenneth L. Clarkson, Elad Hazan, and David P. Woodruff. Sublinear optimization for machine learning. Journal of the ACM, 59(5):23:1-23:49, 2012.   \nJoel E. Cohen. Perturbation theory of completely mixed matrix games. Linear Algebra and its Applications, 79:153-162, 1986.   \nJohanne Cohen, Amelie H\u00e9liou, and Panayotis Mertikopoulos. Hedging under uncertainty: Regret minimization meets exponentially fast convergence. In International Symposium on Algorithmic Game Theory (SAGT), 2017.   \nMichael B. Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matix multiplication time. Journal of the ACM, 68(1):3:1-3:39, 2021.   \nLeonardo Cunha, Gauthier Gidel, Fabian Pedregosa, Damien Scieur, and Courtney Paquette. Only tails matter: Average-case universality and robustness in the convex regime. In International Conference on Machine Learning (ICML), 2022.   \nGeorge Dantzig. A proof of the equivalence of the programming problem and the game problem. In Tjalling Koopmans, editor, Activity Analysis of Production and Allocation, pages 330-335. John Wiley & Sons, 1951.   \nConstantinos Daskalakis and Ioannis Panageas. Last-iterate convergence: Zero-sum games and constrained min-max optimization. In Innovations in Theoretical Computer Science Conference (ITCS), 2019.   \nConstantinos Daskalakis, Alan Deckelbaum, and Anthony Kim. Near-optimal no-regret algorithms for zero-sum games. Games and Economic Behavior, 92:327-348, 2015.   \nConstantinos Daskalakis, Noah Golowich, Nika Haghtalab, and Abhishek Shetty. Smooth nash equilibria: Algorithms and complexity. In Innovations in Theoretical Computer (ITCS), 2024.   \nAsen L Dontchev and R Tyrrell Rockafellar. Implicit functions and solution mappings: A view from variational analysis, volume 616. Springer, 2009.   \nJohn Dunagan, Daniel A. Spielman, and Shang-Hua Teng. Smoothed analysis of condition numbers and complexity implications for linear programming. Mathematical Programming, 126(2):315- 350, 2011.   \nAlan Edelman. Eigenvalue roulette and random test matrices. Linear Algebra for Large Scale and Real-Time Applications, pages 365-368, 1993.   \nKousha Etessami and Mihalis Yannakakis. On the complexity of Nash equilibria and other fixed points (extended abstract). In Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2007.   \nGabriele Farina and Tuomas Sandholm. Fast payoff matrix sparsification techniques for structured extensive-form games. In Conference on Artificial Intelligence (AAAI), 2022.   \nGabriele Farina, Christian Kroer, and Tuomas Sandholm. Faster game solving via predictive blackwell approachability: Connecting regret matching and mirror descent. In Conference on Artificial Intelligence (AAAl), 2021.   \nOlivier Fercoq. Quadratic error bound of the smoothed gap and the restarted averaged primal-ual hybrid gradient, 2023.   \nNicola Gatti, Marco Rocco, and Tuomas Sandholm. Strong Nash equilibrium is in smoothed P. In Conference on Artificial Intelligence (AAAI), 2013. Late-breaking paper track.   \nYiannis Giannakopoulos. A smoothed FPTAS for equilibria in congestion games. CoRR, abs/2306.10600, 2023.   \nYiannis Giannakopoulos, Alexander Grosz, and Themistoklis Melissourgos. On the smoothed complexity of combinatorial local search. CoRR, abs/2211.07547, 2022.   \nAngeliki Giannou, Emmanouil- Vasileios Vlatakis-Gkaragkounis, and Panayotis Mertikopoulos. On the rate of convergence of regularized learning in games: From bandits and uncertainty to optimism and beyond. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2021.   \nAndrew Gilpin, Javier Pena, and Tuomas Sandholm. First-order algorithm with $\\mathcal{O}(\\ln(1/\\epsilon))$ convergence for $\\epsilon$ -equilibrium in two-person zero-sum games. Mathematical Programming, 133(1-2): 279-298, 2012.   \nNoah Golowich, Sarath Pattathil, and Constantinos Daskalakis. Tight last-iterate convergence rates for no-regret learning in multi-player games. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2020a.   \nNoah Golwich, arath Patathil Constantinos Daskalakis and Asuman  Ozdaglar. Last iterate is slower than averaged iterate in smooth convex-concave saddle point problems. In Conference on Learning Theory (COLT), 2020b.   \nEduard Gorbunov, Adrien Taylor and Gauthier idel. Last-iterate convergence of optimistic gradint method for monotone ariational inequalities. InProceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2022.   \nMichael D. Grigoriadis and Leonid G. Khachiyan. A sublinear-time randomized approximation algorithm for matrix games. Operations Research Letters, 18(2):53-58, 1995.   \nNika Haghtalab, Michael I Jordan, and Eric Zhao. On-demand sampling: Learning optimally from multiple distributions.InProceedings of the Annual Conference on Neural InformationProcessing Systems (NeurIPS), 2022.   \nNika Haghtalab, Michael I Jordan, and Eric Zhao. A unifying perspective on multi-calibration: Unleashing game dynamics for multi-objective learning. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2023.   \nYu-Guan Hsieh, Franck Iutzeler, J\u00e9rome Malick, and Panayotis Mertikopoulos. On the convergence of single-call stochastic extra-gradient methods. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2019.   \nSophie Huiberts, Yin Tat Lee, and Xinzhi Zhang. Upper and lower bounds on the smoothed complexity of the simplex method. In Proceedings of the Annual Symposium on Theory of Computing (STOC), 2023.   \nGalina M Korpelevich. The extragradient method for finding saddle points and other problems. Matecon, 12:747-756, 1976.   \nChung-Wei Lee, Christian Kroer, and Haipeng Luo. Last-iterate convergence in extensive-form games. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2021.   \nChris Junchi Li, Huizhuo Yuan, Gauthier Gidel, Quanquan Gu, and Michael I. Jordan. Nesterov meets optimism: Rate-optimal separable minimax optimization. In International Conference on Machine Learning (ICML), 2023.   \nPouria Mahdavinia, Yuyang Deng, Haochuan Li, and Mehrdad Mahdavi. Tight analysis of extragradient and optimistic gradient methods for nonconvex minimax problems. In Proceedings of the Annual Conference on Neural Information Processing Systems (NeurIPS), 2022.   \nArnab Maiti, KevinG.Jamieson, and Lillian . Ratliff Instance-dependent sample complexity bous for zero-sum matrix games. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.   \nKonstantin Makarychev and Yury Makarychev. Perturbation Resilience, page 95-119. Cambridge University Press, 2021.   \nPanayotis Mertikopoulos, Christos H. Papadimitriou, and Georgios Piliouras. Cycles in adversarial regularized learning. In Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2018.   \nPanayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chandrasekhar, and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile. In International Conference on Learning Representations (ICLR), 2019.   \nAryan Mokhtari, Asuman E. Ozdaglar, and Sarath Pattathil. A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2020.   \nMatej Morav&ik, Martin Schmid, Neil Burch, Viliam Lisy, Dustin Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael Bowling. Deepstack: Expert-level artificial inteligence in heads-up no-limit poker. Science, 356(6337):508-513, 2017.   \nYuri Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103, 2005.   \nCourtney Paquette, Bart van Merrienboer, Elliot Paquette, and Fabian Pedregosa. Halting time is predictable for large models: A universality property and average-case analysis. Found. Comput. Math., 23(2):597-673, 2023.   \nJulien Perolat, Bart De Vylder, Daniel Hennes, Eugene Tarassov, Florian Strub, Vincent de Boer, Paul Mullr, Jerome T. Connor, Neil Burch, Thomas Anthony, Stephen McAleer, Romuald Elie, Sarah H. Cen, Zhe Wang, Audrunas Gruslys, Aleksandra Malysheva, Mina Khan, Sherjil Ozair, Finbarr Timbers, Toby Pohlen, Tom Eccles, Mark Rowland, Marc Lanctot, Jean-Baptiste Lespiau, Bilal Piot, Shayegan Omidshafei, Edward Lockhart, Laurent Sifre,Nathali Beauguerlange, Rmi Munos, David Silver, Satinder Singh, Demis Hassabis, and Karl Tuyls. Mastering the game of stratego with model-free multiagent reinforcement learning. Science, 378(6623):990-996, 2022.   \nL.D. Popov. A modification to the Arrow-Hurwicz method for search of saddle-points. Mathematical Notes of the Academy of Sciences of the USSR, 28(5):845-848, 1980.   \nAlexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In Conference on Learning Theory, pages 993-1019, 2013.   \nJames Renegar. Incorporating condition measures into the complexity theory of linear programming. SIAM Journal on Optimization, 5(3):506-524, 1995.   \nJarnes Renegar. Some perturbation theory for linear programming. Mathematical Programming, 65: 73-91, 1994. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Ralph Tyrell Rockafellar. Convex Analysis. Princeton university press, 2015. ", "page_idx": 14}, {"type": "text", "text": "I. Romanovski. Reduction of a game with complete memory to a matrix game. Soviet Mathematics, 3,1962.   \nTim Roughgarden. Beyond the Worst-Case Analysis of Algorithms. Cambridge University Press, 2021.   \nAviad Rubinstein.Setting thecomlexityof computing approxmate two-layernashquiba. In Irit Dinur, editor, Proceedings of the Annual Symposium on Foundations of Computer Science (FOCS), 2016.   \nDamien Scieur and Fabian Pedregosa. Universal average-case optimality of polyak momentum. In International Conference on Machine Learning (ICML), 2020.   \nZhuoqing Song, Jason D. Lee, and Zhuoran Yang. Can we find nash equilibria at a linear rate in markov games? In International Conference on Learning Representations (ICLR), 2023.   \nDaniel A. Spielman and Shang-Hua Teng. Smoothed analysis of termination of linear programming algorithms. Math. Program., 97(1-2):375-404, 2003.   \nDaniel A. Spielman and Shang-Hua Teng. Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time. Journal of the ACM, 51(3):385-463, 2004.   \nDaniel A. Spielman and Shang-Hua Teng. Smoothed analysis: an attempt to explain the behavior of algorithms in practice. Commun. ACM, 52(10):76-84, 2009.   \nVasilis Syrgkanis, Alekh Agarwal, Haipeng Luo, and Robert E Schapire. Fast convergence of regularized learning in games. In Advances in Neural Information Processing Systems, 2015.   \nXiaohang Tang, Le Cong Dinh, Stephen Marcus McAleer, and Yaodong Yang. Regret-minimizing double oracle for extensive-form games. In International Conference on Machine Learning (ICML), Proceedings of Machine Learning Research, 2023.   \nTerence Tao. Topics in random matrix theory, volume 132. American Mathematical Society, 2023.   \nTerence Tao, Van Vu, and Manjunath Krishnapur. Random matrices: Universality of ESDs and the circular law. The Annals of Probability, 38(5):2023 - 2065, 2010.   \nPaul Tseng. On linear convergence of iterative methods for the variational inequality problem. Journal of Computational and Applied Mathematics, 60(1):237-252, 1995.   \nEric van Damme. Stability and perfection of Nash equilibria, volume 339. Springer, 1991.   \nJan van den Brand, Yin Tat Lee, Yang P. Liu, Thatchaphol Saranurak, Aaron Sidford, Zhao Song, and Di Wang. Minimum cost flows, mdps, and $\\ell_{1}$ -regression in nearly linear time for dense instances. In Proceedings of the Annual Symposium on Theory of Computing (STOC), 2021.   \nDanil Vankov, Angelia Nedi, and Lalitha Sankar. Last iterate convergence of popov method for non-monotone stochastic variational inequalities, 2023.   \nJohn von Neumann. Zur Theorie der Gesellchaftsspiele. Mathematische Annalen, 100:295-320, 1928.   \nJohn von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior. Princeton University Press, 1947.   \nBernhard von Stengel. Effcient computation of behavior strategies. Games and Economic Behavior, 14(2):220-246, 1996.   \nBermhard von Stengel. Zero-sum games and linear programming duality. Mathematics of Operations Research, 2023.   \nChen-YuWei ChungW LMngxiahang,adHaipg Lu.Lnea lastiteate converg in constrained saddle-point optimization. In International Conference on Learning Representations (ICLR), 2021.   \nNikos Zarifis, Puqian Wang, Ilias Diakonikolas, and Jelena Diakonikolas. Robustly learning singleindex models via alignment sharpness. In International Conference on Machine Learning (ICML), 2024.   \nBrian Hu Zhang and Tuomas Sandholm. Sparsified linear programming for zero-sum equilibrium finding. In International Conference on Machine Learning (ICML), 2020.   \nMartin Zinkevich, Michael Bowling, Michael Johanson, and Carmelo Piccione. Regret minimization in games with incomplete information. In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS), 2007. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A Further related work ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Besides the pioneering work of Spielman and Teng [2004], which revolved around the simplex algorithm, other prominent algorithms for solving linear programs have also been investigated through the lens of smoothed complexity. Blum and Dunagan [2002] showed that perceptron, a popular algorithm in machine learning, also enjoys a polynomial smoothed complexity (with high probability) for solving linear programming feasibility problems, which can also capture general linear programs via a binary search procedure. Further, Dunagan et al. [2011] performed a smoothed analysis of interior-point methods by relying on an earlier characterization due to Renegar [1995]. ", "page_idx": 16}, {"type": "text", "text": "Beyond linear programming and (two-player) zero-sum games, there has been a considerable interest in understanding the smoothed complexity of Nash equilibria in general-sum games, but the outlook that has emerged from this endeavor is rather bleak [Chen et al., 2009, Boodaghians et al., 2020, Rubinstein, 2016]. On a more positive note, Daskalakis et al. [2024] recently considered a more permissive solution concept they refer to as a smooth Nash equilibrium; the basic idea of their relaxation is that instead of considering best-response deviations, they restrict to deviations that do not assign too much probability mass on any pure strategy, as controlled by a certain parameter. For a certain regime of that parameter, they obtained positive results, bypassing the intractability of the usual Nash equilibrium. Considering smooth Nash equilibria could also be fruitful in the context of zero-sum games. In particular, we surmise that, if one is content with convergence to smooth Nash equilibria, the error bound could exhibit more favorable properties. Smoothed analysis has also been applied to more structured classes of games, such as congestion or potential games [Giannakopoulos, 2023, Giannakopoulos et al., 2022, Chen et al., 2020], as well as other important problems in game theory [Gatti et al., 2013, Buriol et al., 2011]. Other notable developments in a broader context were covered in an older survey by Spielman and Teng [2009]; for more recent developments, we point to, for example, Christ and Yannakakis [2023], Chen et al. [2024], Huiberts et al. [2023], and the many references therein. ", "page_idx": 16}, {"type": "text", "text": "Average-case analysis has also been a popular topic in the optimization literature [Cunha et al., 2022, Paquette et al., 2023, Scieur and Pedregosa, 2020], and so it is worth relating our results to that line of work. In particular, let us focus on the recent work of Cunha et al. [2022]. First, that paper targets a certain class of convex quadratic problems, whereas we examine zero-sum games. They also operate under a different perturbation model, deriving a parametrization based on the concentration of the eigenvalues of a certain matrix. Further, without strong convexity, Cunha et al. [2022] establish a complexity scalingwith $\\mathsf{p o l y}(1/\\epsilon)$ , while here we target the $\\log(1/\\epsilon)$ regime. We finally remark that the techniques employed are also quite different. In particular, Cunha et al. [2022, Problem 2.1] posit that the optimal solution does not depend on the underlying randomization. In contrast, as we have already highlighted, the fact that the equilibrium is a function of the randomization constitutes the main technical crux in our setting. At the same time, Cunha et al. [2022] encountered several challenges not present in our setting, so overall those results are complementary. ", "page_idx": 16}, {"type": "text", "text": "Beyond smoothed complexity, understanding the last-iterate convergence of gradient-based methods such as OGDA and EGDA has received tremendous interest in the literature; e.g., [Golowich et al., 2020a, Cai et al., 2022, Gorbunov et al., 2022, Vankov et al., 2023, Golowich et al., 2020b, Mahdavinia et al., 2022, Antonakopoulos et al., 2021, Mertikopoulos et al., 2019, Abe et al., 2023]. It is worth noting that linear convergence has also been documented for the more challenging class of extensive-form games [Lee et al., 2021], as well as Markov games [Song et al., 2023]. Nevertheless, there are lower bounds precluding linear convergence beyond affine variational inequalities [Golowich et al., 2020a, Wei et al., 2021]. We also refer to the works of Cohen et al. [2017] and Giannou et al. [2021] for further characterizations of the convergence rate of no-regret dynamics in multi-player games. ", "page_idx": 16}, {"type": "text", "text": "Contrary to the above line of work, which focuses on last-iterate convergence, the most common approach to solving zero-sum games revolves around regret minimization whereby optimality guarantees concern the average strategies. Learning in such settings has been a popular research topic as it captures many central problems; two notable recent applications are learning from multiple distributions [Haghtalab et al., 2022] and multi-calibration [Haghtalab et al., 2023]. Yet, there are at least three limitations of the no-regret framework worth highlighting here. The first one, which has been stressed extensively already, is that the number of iterations must grow at least as $\\Omega(1/\\epsilon)$ when one insists on taking (uniform) averages [Daskalakis et al., 2015]. The second and more nuanced caveat is that the no-regret framework does not provide instance-based guarantees based on natural game-theoretic parameters of the problem (see, for example, the discussion of Maiti et al. [2023]). Building on earlier work [Wei et al., 2021, Tseng, 1995], some of our results here attempt to address this shortcoming by coming up with a more interpretable parameterization of the iteration complexity of algorithms such as OGDA. The final limitation is that, convergence to the set of equilibria notwithstanding, no-regret guarantees provide no information regarding properties of the equilibrium reached. Although not an issue in non-degenerate zero-sum games, equilibrium selection still remains a central problem. Earlier results [Wei et al., 2021, Tseng, 1995] provide an interesting characterization for the last iterate of OGDA and EGDA by showing that the limit point is the projection of the initial point to the set of equilibria. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Finally, it is worth pointing out the best available theoretical guarantees for solving zero-sum games. Assuming that each entry of A has absolute value bounded by 1, (1) can be solved in $\\tilde{O}(\\operatorname*{max}\\{n,m\\}^{\\omega})$ [Cohen et al., 2021] or $\\tilde{O}(n m\\!+\\!\\operatorname*{min}\\{n,m\\}^{5/2})$ [van den Brand et al., 2021]. Here, $\\omega$ is the exponent of matrix multiplication and $\\tilde{O}$ suppresses polylogarithmic factors in $n$ and $m$ The complexity we obtain for algorithms such as OGDA is not competitive even though we work in the more benign smoothed complexity model; we reiterate that we did not attempt to optimize the polynomial factors in terms of $n$ and $m$ , and those can almost certainly be improved. On the other hand, there are two main aspects in which algorithms such as OGDA are more appealing in terms of their scalability: the per-iteration complexity and the memory requirements. An algorithm such as OGDA requires a single matrix-vector product in each iteration, which can be implemented in linear time for sparse matrices, and has a limited memory footprint. In contrast, implementing interior-point methods in large games can be prohibitive. ", "page_idx": 17}, {"type": "text", "text": "B Preliminaries ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we introduce some further background on smoothed complexity and define the algorithms cited earlier (Items 1 to 4). ", "page_idx": 17}, {"type": "text", "text": "Further notation For a random variable $X$ ,we denote by $\\mathbb{E}[X]$ its expectation and by $\\mathbb{V}[X]$ its variance, under the assumption that both are finite. For a sequence of random variables $X_{1},\\ldots,X_{d}$ and scalars $\\alpha_{1},\\ldots,\\alpha_{d}\\in\\mathbb{R}$ , linearity of expectation yields that $\\mathbb{E}[\\alpha_{1}X_{1}+\\cdot\\cdot\\cdot+\\alpha_{d}X_{d}]=\\alpha_{1}\\mathbb{E}[X_{1}]+$ $\\cdot\\cdot\\cdot+\\alpha_{d}\\mathbb{E}[X_{d}]$ . Assuming independence, it also holds that $\\mathbb{V}[\\alpha_{1}X_{1}+\\cdot\\cdot\\cdot+\\alpha_{d}X_{d}]=(\\alpha_{1})^{2}\\mathbb{V}[X_{1}]+$ $\\cdots+(\\alpha_{d})^{2}\\mathbb{V}[X_{d}]$ . We will also use the fact that a linear combination of independent Gaussian random variables is also Gaussian. More broadly, linear combinations can be understood through a convolution in the space of probability density functions, which means that smoothness (in the sense of Lemma C.7) is preserved in a certain regime. ", "page_idx": 17}, {"type": "text", "text": "B.1  Smoothed complexity ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "To fully specify Definition 1.1, we first recall that a (univariate) Gaussian random variable with zero mean and variance $\\sigma^{2}$ admits a probability density function of the form ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mu:t\\mapsto\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{t^{2}}{2\\sigma^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The law of such a Gaussian random variable will be denoted by ${\\mathcal{N}}(0,\\sigma^{2})$ . In the original work of Spielman and Teng [2004], smoothed complexity was defined as the expected running time (or some other cost function) of some algorithm over the perturbed input. More precisely, let $\\boldsymbol{\\mathcal{A}}$ be an algorithm whose inputs can be expressed as vectors in $\\mathbb{R}^{d}$ , and let $T_{A}(\\mathcal{T})$ be the running time of algorithm $\\boldsymbol{\\mathcal{A}}$ on input $\\mathcal{I}\\in\\mathbb{R}^{d}$ .Then, the smoothed complexity of $\\boldsymbol{\\mathcal{A}}$ is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\cal A}(d,\\sigma):=\\operatorname*{max}_{{\\cal Z}\\in\\mathbb R^{d}}\\mathbb{E}_{g\\sim\\mathcal{N}({\\bf0}_{d},\\sigma^{2}{\\bf I}_{d\\times d})}[{\\cal T}_{\\cal A}({\\cal Z}+\\|{\\cal Z}\\|g)].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "As pointed out by Spielman and Teng [2003], one does not need to limit smoothed analysis to measure the expected running time, and high probability guarantees are also quite natural; see, for example, the smoothed analysis of the perceptron algorithm due to Blum and Dunagan [2002]. Our main result also provides a guarantee with high probability; it is not clear whether the expected running time can alsobe boundedbypoly $(n,m,1/\\sigma)$ , which is left for future work. ", "page_idx": 17}, {"type": "text", "text": "B.2 Algorithms ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Next, we specify the algorithms we consider in this work. ", "page_idx": 17}, {"type": "text", "text": "Optimistic gradient descent/ascent Originally proposed by Popov [1980], optimistic gradient descent/ascent (OGDA)\u2014-and variants thereof [Hsieh et al., 2019]\u2014-has been recently revived in the online learning literature commencing from the pioneering works of Rakhlin and Sridharan [2013] and Chiang et al. [2012]. If we denote for compactness $F(z)\\;:=\\;(\\mathbf{A}\\pmb{y},-\\mathbf{A}^{\\top}\\pmb{x})$ ,OGDAcanbe expressed as follows for $t\\in\\mathbb{N}(=\\{1,2,\\dots,\\})$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{z^{(t)}:=\\Pi_{\\mathcal{Z}}(\\widehat{z}^{(t)}-\\eta F(z^{(t-1)}),}\\\\ {\\widehat{z}^{(t+1)}:=\\Pi_{\\mathcal{Z}}(\\widehat{z}^{(t)}-\\eta F(z^{(t)}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, $\\eta>0$ is the learning rate; $\\Pi_{\\mathcal{Z}}(\\cdot)$ denotes the (Euclidean) projection operator on set $\\mathcal{Z}:=\\mathcal{X}\\!\\times\\!\\mathcal{Y}$ and $z^{(0)}=\\widehat{z}^{(1)}\\in\\mathcal{Z}$ is the initialization. That is, players simultaneously update their strategies through optimistic gradient steps. Given that $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ are probability simplexes, each projection can be computed exactly in nearly linear time. The key reference point for OGDA in affne variational inequalities is the work of Wei et al. [2021] who established linear convergence using the notion of metric subregularity (Definition C.9), which is strongly related to Definition 1.3; we discuss their approach later in Appendix C.3. ", "page_idx": 18}, {"type": "text", "text": "Optimistic multiplicative weights update Deriving from the same class of online learning algorithms as OGDA, optimistic multiplicative weights (OMwU) is the incarnation of optimistic mirror descent with an entropic regularizer, namely ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\pmb{x}^{(t)}\\propto\\pmb{x}^{(t-1)}\\circ\\exp\\left(-2\\eta\\mathbf{A}\\pmb{y}^{(t-1)}+\\eta\\mathbf{A}\\pmb{y}^{(t-2)}\\right),}\\\\ &{\\pmb{y}^{(t)}\\propto\\pmb{y}^{(t-1)}\\circ\\exp\\left(2\\eta\\mathbf{A}^{\\top}\\pmb{x}^{(t-1)}-\\eta\\mathbf{A}^{\\top}\\pmb{x}^{(t-2)}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for $t\\in\\mathbb{N}$ 5 Above, $\\circ$ denotes the component-wise product; the exponential mapping $\\exp(\\cdot)$ is also to be applied component-wise; and $\\bar{z^{(-1)}}:=z^{(0)}:=(\\textstyle{\\frac{1}{n}}\\mathbf{1}_{n},\\textstyle{\\frac{1}{m}}\\mathbf{1}_{m})$ . Daskalakis and Panageas [2019] first proved that OMwU exhibits asymptotic (last-iterate) convergence, and Wei et al. [2021] later established linear convergence. ", "page_idx": 18}, {"type": "text", "text": "Remark B.1. It is important to note here that the exponential map of OMwU can produce iterates with an arbitrarily large number of bits. Nevertheless, it is not hard to show that the analysis of Wei et al. [2021] carries over when the iterates are truncated up to a certain length of the most significant bits, and so we will not dwell further on this issue here. ", "page_idx": 18}, {"type": "text", "text": "Extra-gradient descent/ascent  The extra-gradient method of Korpelevich [1976] is quite similar to OGDA,namely ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\pmb{z}}^{(t)}:=\\Pi_{\\mathcal{Z}}({\\pmb{z}}^{(t)}-\\eta F({\\pmb{z}}^{(t)}),}\\\\ {\\pmb{z}^{(t+1)}:=\\Pi_{\\mathcal{Z}}({\\pmb{z}}^{(t)}-\\eta F(\\widehat{\\pmb{z}}^{(t)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for $t\\in\\mathbb N$ . Unlike OGDA, one caveat is that it requires two gradient evaluations per each iteration $t$ . EGDA is also less suited to use in an online environment: it requires more feedback than what is provided in the online learning setting, and in fact, even legitimate variants of EGDA can still incur substantial regret [Golowich et al., 2020a]. Tseng [1995] first established that EGDA exhibits linear convergence for problems such as (1), discussed further in Appendix C.3. ", "page_idx": 18}, {"type": "text", "text": "Iterative smoothing  This is a refinement of Nesterov's classical smoothing technique [Nesterov, 2005] due to Gilpin et al. [2012]. Let us first recall the vanilla version of Nesterov, which we refer to asSmoothin ${\\bf g}({\\bf A},z^{(0)},\\epsilon)$ ", "page_idx": 18}, {"type": "text", "text": "1. Initialize $\\begin{array}{r}{\\eta:=\\frac{\\epsilon}{D_{\\mathcal{Z}}}}\\end{array}$ and $\\widehat{z}^{(0)}:=z^{(0)}$ , where $D_{\\mathcal{Z}}$ is the $\\ell_{2}$ diameter of $\\mathcal{Z}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\nz^{(t+1)}:=\\arg\\operatorname*{min}_{z\\in\\mathcal{Z}}\\left\\{\\langle\\nabla F_{\\eta}(\\boldsymbol{u}^{(t)}),\\boldsymbol{z}-\\boldsymbol{u}^{(t)}\\rangle+\\frac{L^{2}}{2\\eta}\\|\\boldsymbol{z}-\\boldsymbol{u}^{(t)}\\|^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{F_{\\eta}(z):=\\operatorname*{max}_{\\hat{z}\\in\\mathcal{Z}}\\{\\langle F(z),z-\\widehat{z}\\rangle-\\frac{\\eta}{2}\\|z-\\widehat{z}\\|^{2}\\}}\\end{array}$ and $L$ is a suitable matrix norm. (c) If $\\Phi(z^{(t+1)})<\\epsilon$ return. ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{z}^{(t+1)}:=\\arg\\operatorname*{min}_{\\widehat{z}\\in\\mathcal{Z}}\\left\\{\\sum_{\\tau=0}^{t}\\frac{\\tau+1}{2}\\langle\\nabla F_{\\eta}(\\pmb{u}^{(\\tau)}),\\widehat{z}-\\pmb{u}^{(\\tau)}\\rangle+\\frac{L^{2}}{2\\eta}\\|\\widehat{z}-z^{(0)}\\|^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In this context, IterSmooth $\\mathbf{\\Phi}_{1}(\\mathbf{A},z^{(0)},\\rho,\\epsilon)$ is simple refinement of Smoothing, which nonetheless attains linear convergence [Gilpin et al., 2012]. ", "page_idx": 19}, {"type": "text", "text": "C Omitted proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We dedicate this section to the proofs omitted earlier from the main body. ", "page_idx": 19}, {"type": "text", "text": "C.1 Proofs from Section 3.2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We first point out that degenerates games have measure zero (cf. Spielman and Teng [2003, Proposition 5.1]). ", "page_idx": 19}, {"type": "text", "text": "Lemma C.1. For a Gaussian distributed payoff matrix A per Definition 1.1, the game is nondegenerate (Definition 3.2) with probability 1 (almost surely). ", "page_idx": 19}, {"type": "text", "text": "Indeed, the set of games with a non unique equilibrium has measure zero [van Damme, 1991, Theorem 3.5.1]. Regarding the characterization in terms of the number of tight inequalities of the corresponding (primal and dual) linear programs, gathered in Definition 3.2, we note that if $n+1$ of the inequalities were tight at $x^{\\star}$ , that would induce a feasible linear system of $n$ equalities (by eliminating $v$ )in $n-1$ variables (by eliminating one of the redundant variables); such degeneracies have measure zero, and there are only finitely many possible such degeneracies, leading to Lemma C.1. As a result, in the smoothed complexity model, we can safely assume that the game is non-degenerate. ", "page_idx": 19}, {"type": "text", "text": "Now, as we alluded to earlier, establishing Definition 1.3 reduces to showing that for any points $\\pmb{x}\\in\\mathcal{X}$ and $\\pmb{y}\\in\\mathcal{V}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{{\\pmb y}^{\\prime}\\in\\mathcal{V}}{\\operatorname*{max}}\\langle{\\pmb x},{\\pmb A}{\\pmb y}^{\\prime}\\rangle-v\\geq\\kappa\\|{\\pmb x}-\\Pi_{\\mathcal{X}^{\\star}}({\\pmb x})\\|=\\kappa\\|{\\pmb x}-{\\pmb x}^{\\star}\\|,}\\\\ &{v-\\underset{{\\pmb x}^{\\prime}\\in\\mathcal{X}}{\\operatorname*{min}}\\langle{\\pmb x}^{\\prime},{\\pmb A}{\\pmb y}\\rangle\\geq\\kappa\\|{\\pmb y}-\\Pi_{\\mathcal{Y}^{\\star}}({\\pmb y})\\|=\\kappa\\|{\\pmb y}-{\\pmb y}^{\\star}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "(Definition 1.3 then indeed follows from the obvious fact $\\|x-x^{\\star}\\|+\\|y-y^{\\star}\\|\\geq\\|z-z^{\\star}\\|.)$ Accordingly, our proof of Theorem 3.6 below will focus on lower bounding $\\kappa$ so that (8) holds, and (9) can then be treated similarly. ", "page_idx": 19}, {"type": "text", "text": "Before we proceed, let us make some observations regarding transformation (5) we saw earlier. First, one can understand the transformation $\\mathbf{A}_{B,N}^{\\flat}=\\mathbf{T}(\\mathbf{Q}^{\\flat},b,c,d)$ through the equations ", "page_idx": 19}, {"type": "equation", "text": "$$\nd={\\bf A}_{i,j};b_{j^{\\prime}}=-{\\bf A}_{i,j^{\\prime}}+{\\bf A}_{i,j};c_{i^{\\prime}}=-{\\bf A}_{i^{\\prime},j}+{\\bf A}_{i,j};{\\bf Q}_{i^{\\prime},j^{\\prime}}={\\bf A}_{i^{\\prime},j^{\\prime}}-{\\bf A}_{i,j^{\\prime}}-\\mathrm{\\bfA}_{i^{\\prime},j}+{\\bf A}_{i,j};\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "for all $(i^{\\prime},j^{\\prime})\\in\\widetilde{B}\\times\\widetilde{N}$ . This can easily be derived from (5) by using the fact that ${\\pmb{\\hat{x}}}_{B}=({\\widetilde{\\pmb{x}}},1-\\mathbf{1}^{\\top}{\\widetilde{\\pmb{x}}})$ and $\\widehat{\\pmb{y}}_{N}=(\\widetilde{\\pmb{y}},1-\\mathbf{1}^{\\top}\\widetilde{\\pmb{y}})$ . From (10), we see that there is a permutation of the rows of $\\mathbf{T}$ that is upper triangular, with every entry being either 1 or $-1$ . This implies that $|\\operatorname*{det}(\\mathbf{T})|=1$ .With a slight abuse of notation, we will write $\\mathbf{T}_{i,j}$ (as opposed to $\\mathbf{T}_{(i,j),:})$ to access the $(i,j)$ row of $\\mathbf{T}$ , so that $\\mathbf{A}_{i,j}=\\langle\\mathbf{T}_{i,j},(\\mathbf{Q}^{\\flat},b,c,d)\\rangle$ From (10), we also see that $\\mathbf{T}_{i,j}$ contains at most 4 non-zero entries. In turn, this implies that $\\|\\mathbf{T}_{i,j}\\|\\leq2$ and $\\|\\mathbf{T}_{i,j}\\|_{1}\\leq4$ We gather the above observations in the claim below, which will be used in the sequel. ", "page_idx": 19}, {"type": "text", "text": "ClaimC.2.Forth(linear transformation $\\mathbf{T}\\in\\mathbb{R}^{(B N)\\times(B N)}$ given in (10) it holds that $|\\operatorname*{det}(\\mathbf{T})|=$ 1. Further, $\\|\\mathbf{T}_{i,j}\\|\\leq2$ and $\\|\\mathbf{T}_{i,j}\\|_{1}\\leq4$ for all $(i,j)\\in B\\times\\bar{N}$ ", "page_idx": 20}, {"type": "text", "text": "The point of transformation (5) is that, as we claimed earlier, the spectral properties of matrix $\\mathbf{Q}$ (as opposedto ${\\bf A}_{B,N}$ , which is a natural candidate) suffice to capture the difficulty of addressing the second subproblem identified in Section 3.2. In addition, there is a straightforward but convenient characterization of the equilibrium $(x^{\\star},y^{\\star})$ in terms of the transformed game in (5), as stated below. ", "page_idx": 20}, {"type": "text", "text": "Claim C.3. It holds that $\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\pmb{c}$ and $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}=\\pmb{b}$ ", "page_idx": 20}, {"type": "text", "text": "Proof. It is clear that the vector $\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}-\\pmb{c}$ must have the same value in every coordinate since $\\widetilde{\\mathbf{x}}^{\\star}$ is fully supported and a best response (by assumption). If that entry was positive, then $\\widetilde{\\mathbf{x}}^{\\star}$ would not be a best response since Player $x$ could profit from removing all the probability mass (which is possible since $\\bar{\\sum_{i\\in\\tilde{B}}{\\bf x}_{i}^{\\star}}>0)$ If there was anegative entry, Payer $x$ would profit from increasing its probability mass (which is possible since $\\textstyle\\sum_{i\\in{\\widetilde{B}}}\\mathbf{x}_{i}^{\\star}<1)$ . Similar reasoning yields $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}=\\pmb{b}$ \u53e3 ", "page_idx": 20}, {"type": "text", "text": "Having made the above observations, we next prove some lemmas claimed earlier in Section 3.2 which will be used for the proof of Theorem 3.6. First, we give the proof of Lemma 3.4. ", "page_idx": 20}, {"type": "text", "text": "Lemma 3.4. Let $\\begin{array}{r}{\\pmb{c}=\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\sum_{j\\in\\widetilde{N}}\\widetilde{\\pmb{y}}_{j}^{\\star}\\mathbf{Q}_{:,j}}\\end{array}$ and supposethat $\\overline{{\\mathbf{Q}}}\\in\\mathbb{R}^{\\widetilde{B}\\times\\widetilde{N}}$ is such that its th column is equal to $\\mathbf{Q}_{:,j}-c$ Then, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{j\\in\\tilde{N}}\\mathsf{d i s t}(\\mathbf{Q}_{:,j},\\mathsf{s p a n}(\\mathbf{Q}_{:,\\tilde{N}-j}))\\leq\\left(1+\\frac{|\\widetilde{N}|}{1-\\sum_{j\\in\\tilde{N}}y_{j}^{\\star}}\\right)\\operatorname*{min}_{j\\in\\tilde{N}}\\mathsf{d i s t}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\tilde{N}-j})).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{\\widetilde{N}\\ni j^{\\prime}\\in\\arg\\operatorname*{min}_{j\\in\\widetilde{N}}{\\mathsf{d i s t}}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\widetilde{N}-j}))}\\end{array}$ By definition, there is $\\pmb{\\rho}\\in\\mathbb{R}^{\\widetilde{N}-j^{\\prime}}$ and $r\\in\\mathbb{R}^{\\widetilde{N}}$ with $\\|\\pmb{r}\\|=1$ such that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\overline{{\\mathbf{Q}}}_{:,j}:=-\\sum_{j\\in\\widetilde{N}-j^{\\prime}}\\widetilde{y}_{j}^{\\star}\\mathbf{Q}_{:,j}+(1-y_{j^{\\prime}}^{\\star})\\mathbf{Q}_{:,j^{\\prime}}=\\sum_{j\\in\\widetilde{N}-j^{\\prime}}\\rho_{j}(\\mathbf{Q}_{:,j}-c)+\\epsilon r,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\begin{array}{r}{\\epsilon:=\\operatorname*{min}_{j\\in\\tilde{N}}\\mathsf{d i s t}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\tilde{N}-j}))}\\end{array}$ . Rearranging, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{Q}_{:,j}\\overbrace{\\left(1-y_{j^{\\prime}}^{\\star}+y_{j^{\\prime}}^{\\star}\\sum_{j\\in\\tilde{N}-j^{\\prime}}\\rho_{j}\\right)}^{\\phi_{j^{\\prime}}}+\\sum_{j\\in\\tilde{N}-j^{\\prime}}\\mathbf{Q}_{:,j}\\overbrace{\\left(-y_{j}^{\\star}-\\rho_{j}+y_{j}^{\\star}\\sum_{j^{\\prime\\prime}\\in\\tilde{N}-j^{\\prime}}\\rho_{j^{\\prime\\prime}}\\right)}^{\\phi_{j}}=\\epsilon r.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Nowletusustaalls aboveae ha for all $j\\in\\widetilde{N}$ Then, $\\begin{array}{r}{\\sum_{j\\in\\tilde{N}}\\phi_{j}=\\pm|\\tilde{N}|\\epsilon^{\\prime}}\\end{array}$ since $\\begin{array}{r}{|\\sum_{j\\in\\tilde{N}}\\phi_{j}|\\le\\sum_{j\\in\\tilde{N}}|\\phi_{j}|\\le\\epsilon|\\tilde{N}|}\\end{array}$ where for convenience we used the notation $\\begin{array}{r}{\\sum_{j\\in\\widetilde{N}}\\phi_{j}=\\pm|\\widetilde{N}|\\epsilon^{\\prime}\\iff-|\\widetilde{N}|\\epsilon^{\\prime}\\leq\\sum_{j\\in\\widetilde{N}}\\phi_{j}\\leq|\\widetilde{N}|\\epsilon^{\\prime}}\\end{array}$ . Thus, by definition of $\\phi_{j}$ \uff0c ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left(1-\\sum_{j\\in\\tilde{N}}\\pmb{y}_{j}^{\\star}\\right)\\left(\\sum_{j\\in\\tilde{N}-j^{\\prime}}\\pmb{\\rho}_{j}\\right)=\\left(1-\\sum_{j\\in\\tilde{N}}\\pmb{y}_{j}^{\\star}\\right)\\pmb{\\pmb{\\pmb{\\epsilon}}}\\epsilon^{\\prime}|\\tilde{N}|.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\begin{array}{r}{0<1-\\sum_{j\\in\\tilde{N}}{\\pmb y}_{j}^{\\star}}\\end{array}$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left(\\sum_{j\\in\\widetilde{N}-j^{\\prime}}\\rho_{j}\\right)=1\\pm\\epsilon^{\\prime}\\frac{|\\widetilde{N}|}{1-\\sum_{j\\in\\widetilde{N}}{\\pmb y}_{j}^{\\star}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\phi_{j^{\\prime}}=1-y_{j^{\\prime}}^{\\star}+y_{j^{\\prime}}^{\\star}\\sum_{j\\in\\tilde{N}-j^{\\prime}}\\rho_{j}=1\\pm\\epsilon^{\\prime}\\frac{|\\tilde{N}|}{1-\\sum_{j\\in\\tilde{N}}y_{j}^{\\star}}>\\epsilon^{\\prime}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "$\\begin{array}{r}{\\epsilon^{\\prime}\\,\\le\\,\\frac{1-\\sum_{j\\in\\widetilde{N}}{\\pmb y}_{j}^{\\star}}{1-\\sum_{j\\,\\in\\,\\widetilde{N}}{\\pmb y}_{j}^{\\star}+|\\widetilde{N}|}}\\end{array}$ The last displayed inequality contradicts our earlier assumption that $|\\phi_{j^{\\prime}}|\\leq\\epsilon^{\\prime}$ . As a result, we conclude that at least one coefficient $\\phi_{j}$ has an absolute value at least $\\epsilon^{\\prime}$ Dividing (11) by that coefficient, we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{j\\in\\tilde{N}}\\mathrm{dist}(\\mathbf{Q}_{:,j},\\mathbf{span}(\\mathbf{Q}_{:,\\tilde{N}-j}))\\leq\\frac{\\epsilon}{\\epsilon^{\\prime}}\\leq\\left(1+\\frac{|\\widetilde{N}|}{1-\\sum_{j\\in\\tilde{N}}y_{j}^{\\star}}\\right)\\operatorname*{min}_{j\\in\\tilde{N}}\\mathrm{dist}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathbf{span}(\\overline{{\\mathbf{Q}}}_{:,\\tilde{N}-j})).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This completes the proof. ", "page_idx": 21}, {"type": "text", "text": "We continue with the proof of Lemma 3.5. ", "page_idx": 21}, {"type": "text", "text": "Lemma 3.5. Let $\\textbf{M}\\in\\~\\mathbb{R}^{d\\times d}$ be a full-rank matrix. For any $\\widetilde{\\textbf{\\em x}}\\in\\mathbb{R}^{d}$ there is $\\textbf{\\textit{p}}\\in\\~\\mathbb{R}^{d}$ with $\\|p\\|\\leq\\frac{1}{\\sigma_{\\operatorname*{min}}(\\mathbf{M})}\\|\\widetilde{\\pmb{x}}\\|$ suchthat ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}=\\mathbf{M}\\pmb{p}=\\sum_{j=1}^{d}p_{j}\\mathbf{M}_{:,j}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Let $\\mathbf{M}=\\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\top}$ be a singular value decomposition (SVD) of $\\mathbf{Q}$ where $\\mathbf{U}$ and $\\mathbf{V}$ are orthonormal. Then, given that $\\mathbf{Q}$ is invertible (by assumption), ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\pmb{p}=\\mathbf{V}\\pmb{\\Sigma}^{-1}\\mathbf{U}^{\\top}\\widetilde{\\pmb{x}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\pmb{\\Sigma}^{-1}=\\mathsf{d i a g}(\\sigma_{\\operatorname*{min}}^{-1},\\dots,\\sigma_{\\operatorname*{max}}^{-1})$ (Here, $\\sigma_{\\mathrm{max}}$ and $\\sigma_{\\mathrm{min}}$ are the maximum and minimum snglar vales fMl $\\begin{array}{r}{\\|p\\|\\leq\\|\\mathbf{V}\\|\\|\\Sigma^{-1}\\|\\|\\mathbf{U}^{\\top}\\|\\|\\widetilde{\\mathbf{x}}\\|\\leq\\frac{1}{\\sigma_{\\operatorname*{min}}(\\mathbf{Q})}\\|\\widetilde{\\mathbf{x}}\\|}\\end{array}$ . where we used the fact that the spectral norm of any orthonormal matrix is 1 and the spectral norm of any diagonal matrix is its maximum entry in asbolute value. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "We next state the negative second moment identity that connects the smallest singular values in terms of a certain geometric property of the matrix (namely, Item 3) (see also [Tao, 2023] for further background). ", "page_idx": 21}, {"type": "text", "text": "Proposition C.4 (Negative second moment identity [Tao et al., 2010]). Let $\\textbf{M}\\in\\mathbb{R}^{d\\times d}$ bean invertiblematrix.Then, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{r=1}^{d}\\frac{1}{\\sigma_{r}^{2}(\\mathbf{M})}=\\sum_{r=1}^{d}\\frac{1}{\\mathsf{d i s t}^{2}(\\mathbf{M}_{r,:},H_{-r,:})}=\\sum_{r=1}^{d}\\frac{1}{\\mathsf{d i s t}^{2}(\\mathbf{M}_{:,r},H_{:,-r})},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $H_{-r,:}:=\\mathsf{s p a n}(\\mathbf{M}_{1,:},\\ldots,\\mathbf{M}_{r-1,:},\\mathbf{M}_{r+1,:},\\ldots,\\mathbf{M}_{d,:}).$ ", "page_idx": 21}, {"type": "text", "text": "One can readily prove this identity by equivalently expressing the negative second moment $\\mathrm{tr}((\\mathbf{M}^{-1})^{\\top}\\mathbf{M}^{-1})$ as either $\\begin{array}{r}{\\sum_{r=1}^{d}\\sigma_{r}^{\\bar{2}}(\\overset{\\cdot}{\\mathbf{M}}^{-1})=\\sum_{r=1}^{d}\\sigma_{r}^{-\\bar{2}}(\\mathbf{M})}\\end{array}$ or $\\sum_{r=1}^{d}\\Vert\\mathbf{M}_{:,r}^{-1}\\Vert^{2}$ , leading to the first identity in (12). The second one follows from the fact that the singular values of $\\mathbf{M}^{\\top}$ coincide with the singular values of $\\mathbf{M}$ ", "page_idx": 21}, {"type": "text", "text": "We are now ready to prove Theorem 3.6, restated below. ", "page_idx": 21}, {"type": "text", "text": "Theorem 3.6. Let A be a non-degenerate payoff matrix, and suppose that $(\\alpha_{P}(\\mathbf{A}),\\alpha_{D}(\\mathbf{A}))$ $(\\beta_{P}(\\mathbf{A}),\\beta_{D}(\\mathbf{A}))$ and $(\\gamma_{P}(\\mathbf{A}),\\gamma_{D}(\\mathbf{\\bar{A}}))$ are as in Definition 3.3. Then, the error bound (Definition 1.3) is satisfied for any sufficiently small modulus ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\kappa\\gtrsim\\frac{1}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\frac{1}{\\operatorname*{min}(n,m)^{3}}\\operatorname*{min}\\left\\{(\\alpha_{D}(\\mathbf{A}))^{2}\\beta_{D}(\\mathbf{A})\\gamma_{P}(\\mathbf{A}),(\\alpha_{P}(\\mathbf{A}))^{2}\\beta_{P}(\\mathbf{A})\\gamma_{D}(\\mathbf{A})\\right\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof.We lower bound $\\kappa$ so that (8) holds; bound (9) will then be treated in a symmetric fashion, and Definition 1.3 will follow. ", "page_idx": 21}, {"type": "text", "text": "Let us fix any point $\\pmb{x}\\in\\mathcal{X}$ . We can write $\\textbf{\\em x}$ as $\\lambda\\widehat{\\pmb{x}}_{B}+(1-\\lambda)\\widehat{\\pmb{x}}_{\\overline{{B}}}$ for some $\\lambda\\in[0,1]$ such that ${\\widehat{\\mathbf{x}}}_{B}\\in{\\mathcal{X}}$ and all coordinates of ${\\widehat{\\pmb{x}}}_{B}$ in $\\overline{B}$ are zero, and $\\widehat{\\pmb{x}}_{\\overline{{B}}}\\in\\mathcal{X}$ and all coordinates of $\\widehat{\\pmb{x}}_{\\overline{{B}}}$ in $B$ are zero. For notational convenience, we define ", "page_idx": 21}, {"type": "equation", "text": "$$\nP(\\mathbf{A}):=\\frac{1}{2|N|\\sqrt{|B|}}\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\left(1+\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)^{-1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We consider the following two cases. ", "page_idx": 21}, {"type": "text", "text": "Case I: $\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|\\geq4(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty}.$ If $\\widehat{\\pmb{x}}_{B}=\\pmb{x}_{B}^{\\star}$ , it follows that $\\pmb{x}=\\pmb{x}^{\\star}$ (since $\\lambda=1$ and the conclusion trivially follows. We can thus assume that $\\widehat{\\mathbf{x}}_{B}\\neq\\mathbf{x}_{B}^{\\star}$ . In this case, it follows that $\\ensuremath{\\widetilde{B}}\\neq\\ensuremath{\\varnothing}$ , and we proceed as follows. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\operatorname*{max}}\\langle\\mathbf{x},\\mathbf{A}y^{\\prime}\\rangle-v\\ge\\lambda\\underset{j\\in N}{\\operatorname*{max}}\\langle\\widehat{\\mathbf{x}}_{B}-\\mathbf{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle+(1-\\lambda)\\left(\\langle\\mathbf{x}_{\\overline{{B}}},\\mathbf{A}_{\\overline{{B}},j}\\rangle-v\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\ge\\lambda\\underset{j\\in N}{\\operatorname*{max}}\\langle\\widehat{\\mathbf{x}}_{B}-\\mathbf{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle-2(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where (14) follows from the definition $\\pmb{x}:=\\lambda\\widehat{\\pmb{x}}_{B}+(1-\\lambda)\\widehat{\\pmb{x}}_{\\overline{{B}}}$ and the fact that $v=\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle$ for all $j\\in N$ ; and (15) uses definition of $\\|\\mathbf{A}^{\\flat}\\|_{\\infty}$ to lower bound the second term in (14). Continuing from (15), we can use the transformation defined in (5) to get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{j\\in N}\\langle\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle=\\operatorname*{max}_{j\\in N}\\langle\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star},\\mathbf{Q}_{:,j}-\\pmb{c}\\rangle,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where, with an abuse of notation, the convention above is that $\\mathbf{Q}_{:,j}=\\mathbf{0}$ if $j\\neq\\widetilde{N}$ . For convenience, let us define $\\chi_{j}:=\\langle\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star},\\mathbf{Q}_{:,j}-\\pmb{c}\\rangle$ for all $j\\in N$ Our goal is to lower bound $\\operatorname*{max}_{j\\in N}\\chi_{j}$ . To that end, we first observe that, by the fact that $\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\pmb{c}$ (Claim C.3), ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle0=\\langle\\widetilde{\\pmb x}-\\widetilde{\\pmb x}^{\\star},\\mathbf Q\\widetilde{\\pmb y}^{\\star}-\\pmb c\\rangle=\\sum_{j\\in\\widetilde{N}}\\widetilde{\\pmb y}_{j}^{\\star}\\langle\\widetilde{\\pmb x}-\\widetilde{\\pmb x}^{\\star},\\mathbf Q_{\\cdot;j}\\rangle-\\langle\\widetilde{\\pmb x}-\\widetilde{\\pmb x}^{\\star},\\pmb c\\rangle}}\\\\ {{\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad=\\sum_{j\\in\\widetilde{N}}\\widetilde{\\pmb y}_{j}^{\\star}\\langle\\widetilde{\\pmb x}-\\widetilde{\\pmb x}^{\\star},\\mathbf Q_{\\cdot;j}-\\pmb c\\rangle+\\left(1-\\sum_{j\\in\\widetilde{N}}\\widetilde{\\pmb y}_{j}^{\\star}\\right)\\langle\\widetilde{\\pmb x}-\\widetilde{\\pmb x}^{\\star},-\\pmb c\\rangle}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In other words, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{j\\in N}{\\pmb{y}}_{j}^{\\star}\\chi_{j}=0,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which in turn implies that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{j\\in N}\\operatorname*{max}(0,\\chi_{j})\\ge\\sum_{j\\in N}y_{j}^{\\star}\\operatorname*{max}(0,\\chi_{j})=-\\sum_{j\\in N}y_{j}^{\\star}\\operatorname*{min}(0,\\chi_{j})}}\\\\ &{}&{\\ge-\\alpha_{D}(\\mathbf A)\\sum_{j\\in N}\\operatorname*{min}(0,\\chi_{j}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where we made use of the obvious identity $t=\\mathrm{max}(0,t)+\\mathrm{min}(0,t)$ for all $t\\in\\mathbb R$ , as well as the definition of $\\alpha_{D}(\\mathbf{A})$ (Item 1). We let $\\pmb{p}\\in\\mathbb{R}^{\\widetilde{N}}$ be the (unique) solution to the linear system ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}=\\overline{{\\pmb{\\mathrm{Q}}}}\\pmb{p}=\\sum_{j\\in\\widetilde{N}}(\\mathbf{Q}_{:,j}-\\pmb{c})\\pmb{p}_{j},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and $p_{j}=0$ for $j\\in N\\backslash\\widetilde{N}$ .By Lemma 3.5, we know that $\\|p\\|\\leq(\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}}))^{-1}\\|\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}\\|$ Then, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{j\\in N}\\chi_{j}\\pmb{p}_{j}=\\sum_{j\\in\\tilde{N}}\\chi_{j}\\pmb{p}_{j}=\\left\\langle\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star},\\sum_{j\\in\\tilde{N}}(\\mathbf{Q}_{:,j}-\\pmb{c})\\pmb{p}_{j}\\right\\rangle=\\|\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Moreover, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j\\in N}\\chi_{j}p_{j}=\\sum_{j\\in N}p_{j}\\operatorname*{max}(0,\\chi_{j})+\\displaystyle\\sum_{j\\in N}p_{j}\\operatorname*{min}(0,\\chi_{j})}\\\\ &{\\leq\\displaystyle\\sum_{j\\in N}\\operatorname*{max}(0,p_{j})\\operatorname*{max}(0,\\chi_{j})+\\displaystyle\\sum_{j\\in N}\\operatorname*{min}(0,p_{j})\\operatorname*{min}(0,\\chi_{j})}\\\\ &{\\leq\\|p\\|_{\\infty}\\displaystyle\\sum_{j\\in N}\\operatorname*{max}(0,\\chi_{j})-\\|p\\|_{\\infty}\\displaystyle\\sum_{j\\in N}\\operatorname*{min}(0,\\chi_{j})}\\\\ &{\\leq\\|p\\|_{\\infty}\\left(1+\\displaystyle\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)\\displaystyle\\sum_{j\\in N}\\operatorname*{max}(0,\\chi_{j})}\\\\ &{\\leq\\displaystyle\\frac{1}{\\sigma_{\\operatorname*{min}}(\\overline{{0}})}\\left(1+\\displaystyle\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)|N|_{\\mathbf{\\overline{{j\\inN}}}}\\chi_{j}||\\widetilde{\\boldsymbol{x}}-\\widetilde{\\boldsymbol{x}}^{\\star}||,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where (19) follows from the fact that $p_{j}\\operatorname*{max}(0,\\chi_{j})\\leq\\operatorname*{max}(0,p_{j})\\operatorname*{max}(0,\\chi_{j})$ (by nonnegativity of $\\operatorname*{max}(0,\\chi_{j}))$ and $p_{j}\\operatorname*{min}(0,\\chi_{j})\\leq\\operatorname*{min}\\!\\left(0,p_{j}\\right)\\operatorname*{min}\\!\\left(0,\\chi_{j}\\right)$ (by nonpositivity of $\\operatorname*{min}(0,\\chi_{j}))$ ; (20) uses that $\\mathrm{min}(0,{\\pmb p}_{j})\\,\\geq\\,-|{\\pmb p}_{j}|\\,\\geq\\,-\\|{\\pmb p}\\|_{\\infty}$ , which gives $\\begin{array}{r}{\\operatorname*{min}(0,\\pmb{p}_{j})\\operatorname*{min}(0,\\chi_{j})\\,\\leq\\,-\\|\\pmb{p}\\|_{\\infty}\\operatorname*{min}(0,\\chi_{j})}\\end{array}$ (21) follows from (17); and (22) uses the bound $\\|p\\|_{2}\\,\\leq\\,(\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}}))^{-1}\\|\\widetilde{\\pmb{x}}\\-\\widetilde{\\pmb{x}}^{\\star}\\|$ (Lemma 3.5). Combining (18) and (22), ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{j\\in N}{\\operatorname*{max}}\\langle\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\geq\\frac{1}{|N|}\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\left(1+\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)^{-1}\\|\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq\\frac{1}{2|N|\\sqrt{|B|}}\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\left(1+\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)^{-1}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where (23) uses the definition of $\\chi_{j}$ and the assumption that $\\widetilde{\\mathbf{x}}\\neq\\widetilde{\\mathbf{x}}^{\\star}$ (equivalently, $\\pmb{x}_{B}^{\\star}\\neq\\widehat{\\pmb{x}}_{B}$ and (24) follows from the bound ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widehat{x}_{B}-x_{B}^{\\star}\\|\\leq\\|\\widehat{\\pmb{x}}_{B}-{\\pmb x}_{B}^{\\star}\\|_{1}\\leq\\sum_{i\\in\\widetilde{B}}|x_{i}-{\\pmb x}_{i}^{\\star}|+\\left|\\sum_{i\\in\\widetilde{B}}({\\pmb x}_{i}-{\\pmb x}_{i}^{\\star})\\right|\\leq2\\|\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}\\|_{1}\\leq2\\sqrt{|{\\pmb B}|}\\|\\widetilde{\\pmb{x}}-\\widetilde{\\pmb{x}}^{\\star}\\|.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Returning to (15), we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\operatorname*{max}_{y^{\\prime}\\in\\mathcal{Y}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle-v\\geq\\lambda\\frac{1}{2|N|\\sqrt{|B|}}\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\left(1+\\frac{1}{\\alpha_{D}(\\mathbf{A})}\\right)^{-1}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|-2(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\\\ {\\displaystyle=\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|-2(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty},\\qquad\\qquad\\qquad\\qquad(2\\lambda)^{2}\\|\\mathbf{A}^{\\circ}\\|_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the equality above follows from the definition of $P(\\mathbf{A})$ in (13). Next, we bound ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\pmb{x}-\\pmb{x}^{\\star}\\|^{2}=\\|\\lambda\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}+(1-\\lambda)^{2}\\|\\widehat{\\pmb{x}}_{\\overline{{B}}}\\|^{2}}\\\\ &{\\quad\\quad\\quad\\quad=\\|\\lambda(\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star})-(1-\\lambda)\\pmb{x}_{B}^{\\star}\\|^{2}+(1-\\lambda)^{2}\\|\\widehat{\\pmb{x}}_{\\overline{{B}}}\\|^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\leq2\\lambda^{2}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}+2(1-\\lambda)^{2}\\|\\pmb{x}_{B}^{\\star}\\|^{2}+(1-\\lambda)^{2}\\|\\widehat{\\pmb{x}}_{\\overline{{B}}}\\|^{2}}\\\\ &{\\quad\\quad\\quad\\leq2\\lambda^{2}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}+3(1-\\lambda)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where (26) uses triangle inequality with respect to $\\parallel\\cdot\\parallel$ along with the inequality. $(t_{1}+t_{2})^{2}\\,\\leq$ $2t_{1}^{2}+2t_{2}^{2}$ , and (27) uses that $\\|\\pmb{x}_{B}^{\\star}\\|,\\|\\pmb{\\hat{x}}_{\\overline{{B}}}\\|\\leq\\bar{1}$ . Since we are assuming that $\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|\\geq$ $4(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty}$ , (27) in turn implies that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\pmb{x}-\\pmb{x}^{\\star}\\|^{2}\\leq2\\lambda^{2}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}+\\lambda^{2}\\left(\\frac{P(\\mathbf{A})}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\right)^{2}\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}}\\\\ &{\\qquad\\qquad=\\lambda^{2}\\left(2+\\left(\\frac{P(\\mathbf{A})}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\right)^{2}\\right)\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining (25) and (28) with the assumption that $\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|\\geq4(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty},$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\operatorname*{max}}\\langle x,\\mathbf{A}y^{\\prime}\\rangle-v\\geq\\frac{\\lambda}{2}P(\\mathbf{A})\\|\\widehat{x}_{B}-x_{B}^{\\star}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq\\frac{1}{2}P(\\mathbf{A})\\left(2+\\left(\\frac{P(\\mathbf{A})}{\\|\\mathbf{A}^{\\star}\\|_{\\infty}}\\right)^{2}\\right)^{-2}\\|x-x^{\\star}\\|\\geq\\kappa(\\mathbf{A})\\|x-x^{\\star}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "It is easy to see that $P(\\mathbf{A})/\\|\\mathbf{A}^{\\flat}\\|_{\\infty}$ is upper bounded by an absolute constant, and so we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\operatorname*{max}}\\langle x,\\mathbf{A}y^{\\prime}\\rangle-v\\gtrsim P(\\mathbf{A})\\|x-x^{\\star}\\|=\\cfrac{1}{2|N|\\sqrt{|B|}}\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\left(1+\\cfrac{1}{\\alpha_{D}(\\mathbf{A})}\\right)^{-1}\\|x-x^{\\star}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\gtrsim\\cfrac{1}{|B|^{3}}(\\alpha_{D}(\\mathbf{A}))^{2}\\gamma_{P}(\\mathbf{A})\\|x-x^{\\star}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Above, the last bound uses the fact that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{\\operatorname*{min}}(\\overline{{\\mathbf{Q}}})\\geq\\frac{1}{\\sqrt{|\\widetilde{B}|}}\\operatorname*{min}_{j\\in\\widetilde{N}}\\mathrm{dist}(\\overline{{\\mathbf{Q}}}_{:,j},\\mathsf{s p a n}(\\overline{{\\mathbf{Q}}}_{:,\\widetilde{N}-j}))}\\\\ &{\\qquad\\qquad\\geq\\frac{1}{|\\widetilde{B}|^{3/2}}\\operatorname*{min}_{j\\in\\widetilde{N}}\\mathrm{dist}(\\mathbf{Q}_{:,j},\\mathsf{s p a n}(\\mathbf{Q}_{:,\\widetilde{N}-j}))\\alpha_{D}(\\mathbf{A})=\\frac{1}{|\\widetilde{B}|^{3/2}}\\gamma_{P}(\\mathbf{A})\\alpha_{D}(\\mathbf{A}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the first inequality uses (6), while the second one is a consequence of Lemma 3.4. ", "page_idx": 23}, {"type": "text", "text": "Case II: $\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}\\,-\\,\\pmb{x}_{B}^{\\star}\\|\\,<\\,4(1\\,-\\,\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty}$ .This case can only arise when $\\overline{{B}}\\,\\neq\\,\\emptyset$ (for otherwise $\\lambda=1$ ). Then, we bound ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\operatorname*{max}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle-v\\geq\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\star}\\rangle-v}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\geq\\lambda(\\langle\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,N}\\pmb{y}_{N}^{\\star}\\rangle)+(1-\\lambda)(\\langle\\widehat{\\pmb{x}}_{\\overline{{B}}},\\mathbf{A}_{\\overline{{B}},N}\\pmb{y}_{N}^{\\star}-v\\rangle)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\geq(1-\\lambda)\\beta_{D}(\\mathbf{A}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "by definition of $\\beta_{D}(\\mathbf{A})$ (Item 2) and the fact that $\\langle{\\widehat{\\pmb x}}_{B}-{\\pmb x}_{B}^{\\star},{\\bf A}_{B,N}{\\pmb y}_{N}^{\\star}\\rangle\\,=\\,v\\langle{\\widehat{\\pmb x}}_{B}-{\\pmb x}_{B}^{\\star},{\\bf1}\\rangle\\,=\\,0$ Moreover, by (27) together with the assumption that $\\lambda P(\\mathbf{A})\\|\\widehat{\\pmb{x}}_{B}-\\pmb{x}_{B}^{\\star}\\|<4(1-\\lambda)\\|\\mathbf{A}^{\\flat}\\|_{\\infty}$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|x-x^{\\star}\\|^{2}\\leq32\\left(\\frac{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}{P(\\mathbf{A})}\\right)^{2}(1-\\lambda)^{2}+3(1-\\lambda)^{2}=\\left(32\\left(\\frac{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}{P(\\mathbf{A})}\\right)^{2}+3\\right)(1-\\lambda)^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combining with (29) yields ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y^{\\prime}\\in\\mathcal{Y}}{\\operatorname*{max}}\\langle\\pmb{x},\\mathbf{A}\\pmb{y}^{\\prime}\\rangle-v\\geq\\left(32\\left(\\frac{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}{P(\\mathbf{A})}\\right)^{2}+3\\right)^{-2}\\beta_{D}(\\mathbf{A})\\|\\pmb{x}-\\pmb{x}^{\\star}\\|}\\\\ &{\\qquad\\qquad\\gtrsim\\frac{P(\\mathbf{A})}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\beta_{D}(\\mathbf{A})\\|\\pmb{x}-\\pmb{x}^{\\star}\\|}\\\\ &{\\qquad\\qquad\\gtrsim\\frac{1}{\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\frac{1}{|B|^{3}}\\alpha_{D}(\\mathbf{A})^{2}\\beta_{D}(\\mathbf{A})\\gamma_{P}(\\mathbf{A})\\|\\pmb{x}-\\pmb{x}^{\\star}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "C.2 Proofs from Section 3.3 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We continue with the proofs from Section 3.3. As we have noted already, given that all quantities of interest in Definition 3.3 depend on the support of the equilibrium, it is natural to proceed by partitioning the probability space over all possible such configurations. To do so, we will use the following simple fact [Spielman and Teng, 2003, Proposition 8.1]. ", "page_idx": 24}, {"type": "text", "text": "Proposition C.5 (Spielman and Teng, 2003). Let $X$ and $Y$ be randomvariables distributed according to an integrable density function. For any event $\\mathcal{E}(X,Y)$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{P}_{X,Y}[\\mathcal{E}(X,Y)]\\leq\\operatorname*{max}_{y}\\frac{\\mathbb{P}}{X,Y}[\\mathcal{E}(X,Y)~|~Y=y]=:\\operatorname*{max}_{Y}\\frac{\\mathbb{P}}{X,Y}[\\mathcal{E}(X,Y)~|~Y].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In our application, we want to condition on the event that $B$ is the support of $x^{\\star}$ and $N$ is the support of $\\boldsymbol{y}^{\\star}$ . For convenience, we let $\\mathsf{T y p e}_{B,N}(\\mathbf{A})$ denote the indicator random variable representing whether $B$ and $N$ indeed index the positive coordinates of the equilibrium; that is, $\\mathsf{T y p e}_{B,N}(\\mathbf{A}):=$ $\\mathbb{1}\\{B=\\{i\\in[n]:x_{i}^{\\star}(\\mathbf{A})>0\\}\\wedge N=\\{j\\in[m]:y_{j}^{\\star}(\\mathbf{A})>0\\}\\}$ . Unlike general linear programs, which can be infeasible or unbounded, the linear program induced by a zero-sum game is guaranteed to be primal and dual feasible, no matter the perturbation (under Definition 1.1). We will thus only have to condition on events in which $B$ and $N$ are both nonempty. To be able to control the probability density function upon conditioning on $\\mathsf{T y p e}_{B,N}(\\mathbf{A})$ , it will be convenient to perform a certain change of variables, which is described next. ", "page_idx": 24}, {"type": "text", "text": "Change of variables  Let us denote by $\\mathbf{A}_{\\overline{{B,N}}}$ the entries of A excluding those in ${\\bf A}_{B,N}$ We first perform a change of variables from ${\\bf A}_{\\overline{{B,N}}},{\\bf A}_{B,N}$ to ${\\bf A}_{\\overline{{B,N}}},{\\bf Q},c,b,d$ , which uses the linear transformation $\\mathbf{T}$ associated with (5). With this new set of variables at hand, we can conveniently express $\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\pmb{c}$ and $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}=\\pmb{b}$ (Claim C.3). Accordingly, we next perform a change of variables from ${\\bf A}_{\\overline{{B,N}}},{\\bf Q},c,b,d$ $\\mathbf{A}_{\\overline{{B,N}}},\\mathbf{Q},\\mathbf{x}^{\\star},\\mathbf{y}^{\\star},v$ When performing those change of variables one has to account for the transformed probability density function. This can be understood as follows. The probability of an event $\\mathcal{E}(\\mathbf{A})$ can be expressed as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\int_{\\mathbf{A}}\\mathcal{E}(\\mathbf{A})\\mu_{\\mathbf{A}}(\\mathbf{A})d\\mathbf{A}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The integral above can be cast in terms of a new set of variables $\\mathbf{B}$ by computing the corresponding Jacobian, assuming that it is non-singular. We will make use of this fact in the sequel. The following lemma gathers some of the above observations regarding the change of variables. ", "page_idx": 24}, {"type": "text", "text": "Lemma C.6 (Change of variables). Let $\\mathcal{E}(\\mathbf{A})$ be any event that depends on the randomness of A. Then, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}[\\mathcal{E}(\\mathbf{A})]\\leq\\underset{B,N}{\\operatorname*{max}}\\,\\mathbb{P}[\\mathcal{E}(\\mathbf{A})\\mid\\mathsf{T y p e}_{B,N}(\\mathbf{A})]}\\\\ &{\\qquad\\qquad=\\underset{B,N}{\\operatorname*{max}}\\,\\underset{\\mathbf{A}_{B,N}}{\\mathbb{P}},\\underset{\\mathbf{Q},\\mathbf{x}^{\\star},\\mathbf{y}^{\\star},v}{\\mathbb{P}}[\\mathcal{E}(\\mathbf{A})\\mid\\mathbf{A}_{\\overline{{B}},N}\\mathbf{y}_{N}^{\\star}\\geq v\\mathbf{1}\\ a n d\\,\\mathbf{A}_{\\overline{{N}},B}^{\\top}\\mathbf{x}_{B}^{\\star}\\leq v\\mathbf{1}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Indeed, the first inequality above is a consequence of Proposition C.5. The equality then follows from noting that, when ", "page_idx": 25}, {"type": "equation", "text": "$$\nc=\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star},\\boldsymbol{b}=\\mathbf{Q}^{\\intercal}\\widetilde{\\pmb{x}}^{\\star},\\boldsymbol{v}=d-\\langle\\widetilde{\\pmb{x}}^{\\star},\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}\\rangle\\iff\\mathbf{A}_{B,N}\\pmb{y}^{\\star}=\\boldsymbol{v}\\mathbf{1},\\mathbf{A}_{N,B}^{\\intercal}\\pmb{x}^{\\star}=\\boldsymbol{v}\\mathbf{1},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "the event $\\mathsf{T y p e}_{B,N}(\\mathbf{A})$ can be equivalently expressed as $\\mathbf{A}_{\\overline{{B}},N}\\mathbf{y}_{N}^{\\star}\\geq v\\mathbf{1}$ and $\\mathbf{A}_{N,B}^{\\top}\\mathbf{x}_{B}^{\\star}\\leq v\\mathbf{1}$ ", "page_idx": 25}, {"type": "text", "text": "We first bound the probability that $\\begin{array}{r}{\\beta_{P}(\\mathbf{A}):=\\operatorname*{min}_{j\\in\\overline{{N}}}(v-\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle)}\\end{array}$ is close to O; the proof for $\\beta_{D}(\\mathbf{A})$ is then symmetric. The key ingredient is the following anti-concentration lemma pertaining to a conditional Gaussian distribution [Spielman and Teng, 2003, Lemma 8.3]. ", "page_idx": 25}, {"type": "text", "text": "Lemma C.7 (Spielman and Teng, 2003). Let g be a Gaussian random variable of variance $\\sigma^{2}$ and mean of absolute value at most 1.For $\\epsilon\\geq0$ $\\tau\\geq1$ and $t\\leq\\tau$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}[g\\le t+\\epsilon\\mid g\\ge t]\\le\\frac{\\epsilon\\tau}{\\sigma^{2}}e^{\\frac{\\epsilon(\\tau+3)}{\\sigma^{2}}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proposition 3.8. Let $\\beta_{P}(\\mathbf{A})$ be defined as in Item 2. For any $\\epsilon\\geq0$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\beta_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{5\\|\\mathbf{A}^{\\flat}\\|_{\\infty}}\\right]\\leq\\epsilon\\frac{e\\operatorname*{min}(n,m)^{2}}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. By Lemma C.6, it suffices to bound ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{B,N\\;\\mathbf{A}_{\\overline{{B}},N},\\mathbf{Q},x^{\\star},y^{\\star},v}[\\beta_{P}(\\mathbf{A})\\leq\\epsilon^{\\prime}\\mid\\mathbf{A}_{\\overline{{B}},N}y_{N}^{\\star}\\geq v\\mathbf{1}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By Proposition C.5, it suffices to prove that for all $B,N,{\\bf A}_{\\overline{{{B}}},N},{\\bf A}_{\\overline{{{B}}},\\overline{{{N}}}},{\\bf Q},x^{\\star},y^{\\star},v$ satisfying $\\mathbf{A}_{\\overline{{B}},N}\\mathbf{y}_{N}^{\\star}\\geq v\\mathbf{1}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{A}_{B,\\overline{{N}}}}{\\mathbb{P}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\subset\\overline{{\\mathbf{\\mathcal{B}}}}\\times\\overline{{\\mathcal{B}}}:v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\leq\\epsilon^{\\prime}\\:\\big|\\:\\forall j\\in N:v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\geq0\\big|}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\displaystyle\\sum_{j\\in\\overline{{N}}}\\underset{\\mathbf{A}_{B,j}}{\\mathbb{P}}\\big[v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\leq\\epsilon^{\\prime}\\:\\big|\\:\\forall j\\in N:v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\geq0\\big]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq\\displaystyle\\sum_{j\\in\\overline{{N}}}\\underset{\\mathbf{A}_{B,j}}{\\mathbb{P}}\\big[v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\leq\\epsilon^{\\prime}\\:\\big|\\:v-\\langle x_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\geq0\\big]}\\\\ &{\\quad\\quad\\quad\\quad=\\displaystyle\\sum_{j\\in\\overline{{N}}}\\!\\!\\!\\!\\!\\!\\!\\mathbb{P}_{j}[g_{j}\\leq\\epsilon^{\\prime}-v\\:|\\:g_{j}\\geq-v].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where in (30) the distribution of $\\mathbf{A}_{B,\\overline{{N}}}$ after conditioning on ${\\bf A}_{\\overline{{B}},N},{\\bf A}_{\\overline{{B}},\\overline{{N}}}$ Q, $x^{\\star}$ \uff0c $\\boldsymbol{y}^{\\star}$ $v$ remains the same, which is a consequence of independence per Definition 1.1; (31) is an application of the union bound; (32) uses the fact that the events $\\{v\\overset{\\cdot}{-}\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle\\,\\geq\\,0\\}_{j\\in N}$ are pairwise independent; and (33) defines $\\pmb{g}_{j}:=-\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j}\\rangle$ , which is a Gaussian random variable with expectation $\\lvert\\mathbb{E}[\\pmb{g}_{j}]\\rvert\\ \\leq\\ \\operatorname*{max}_{i\\in B}\\lvert\\mathbf{A}_{i,j}\\rvert$ and variance $\\begin{array}{r}{\\mathbb{V}[\\pmb{g}_{j}]\\;=\\;\\sum_{i\\in B}(\\pmb{x}_{i}^{\\star})^{2}\\mathbb{V}[\\mathbf{A}_{i,j}]\\;=\\;\\sigma^{2}\\sum_{i\\in B}(\\pmb{x}_{i}^{\\star})^{2}}\\end{array}$ (by independence). In particular, by Cauchy-Schwarz, $\\begin{array}{r}{\\mathbb{V}[g_{j}]\\;\\ge\\;\\frac{1}{|B|}\\sigma^{2}}\\end{array}$ . Further, by Lemma C.7 (for $\\tau=\\operatorname*{max}(1,|v|/|\\mathbb{E}[g_{j}]|))$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{g}\\!\\left[g_{j}\\leq\\epsilon^{\\prime}-v\\mid g_{j}\\geq-v\\right]\\leq\\epsilon^{\\prime}\\frac{\\operatorname*{max}(|v|,\\,|\\mathbb{E}[g_{j}]|)}{\\mathbb{V}[g_{j}]}e^{\\epsilon^{\\frac{\\operatorname*{max}(4|\\mathbb{E}[g_{j}]|,\\,|\\mathbb{A}|\\mathbb{E}[g_{j}]|+|v|)}{\\mathbb{V}[g_{j}]}}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\epsilon^{\\prime}\\frac{\\operatorname*{min}(n,\\,m)\\operatorname*{max}(|v|,\\,|\\mathbb{E}[g_{j}]|)}{\\sigma^{2}}e^{\\epsilon^{\\prime}\\frac{\\operatorname*{min}(n,\\,m)\\operatorname*{max}(4|\\mathbb{E}[g_{j}]|,\\,3|\\mathbb{E}[g_{j}]|+|v|)}{\\sigma^{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "for any $\\epsilon^{\\prime}\\ge0$ and $j\\,\\in\\,{\\overline{{N}}}$ , where we note that we applied Lemma C.7 for $g_{j}/|\\mathbb{E}[g_{j}]|$ (since the absolute value of the mean has to be at most 1), which has variance $\\mathbb{V}[{\\pmb g}_{j}]/(\\mathbb{E}[{\\pmb g}_{j}])^{2}$ . So, setting $\\epsilon:=\\epsilon^{\\prime}(|v|+4|\\mathbb{E}[{\\pmb g}_{j}]|)$ \uff0c ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{P}_{g}\\left[g_{j}\\leq\\frac{\\epsilon}{|v|+4\\operatorname*{max}_{i\\in B}|\\mathbf{A}_{i,j}|}-v\\,|\\,g_{j}\\geq-v\\right]\\leq\\frac{\\mathbb{P}}{g_{j}}\\left[g_{j}\\leq\\frac{\\epsilon}{|v|+4\\left|\\mathbb{E}[g_{j}]\\right|}-v\\,|\\,g_{j}\\geq-v\\right]}}\\\\ &{}&{\\leq\\epsilon\\frac{\\operatorname*{min}(n,m)}{\\sigma^{2}}e^{\\epsilon\\frac{\\operatorname*{min}(n,m)}{\\sigma^{2}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Now,when $\\epsilon\\frac{\\operatorname*{min}(n,m)}{\\sigma^{2}}>1$ the proposition is vacuously true, while in the contrary case the claim follows from (34) and (33). \u53e3 ", "page_idx": 26}, {"type": "text", "text": "Next, we proceed with the bound on $\\gamma_{P}(\\mathbf{A})$ . The key ingredient is the observation that a random variable with a slowly changing density function cannot be too concentrated on any any interval (Lemma 3.7 due to Spielman and Teng [2003, Lemma 8.2]; we restate it below for convenience). Gaussian random variables have this property, as pointed out by Spielman and Teng [2003, Lemma 8.1]. ", "page_idx": 26}, {"type": "text", "text": "Lemma C.8 (Spielman and Teng, 2003). Let $\\mu$ be the probability density function of a Gaussian randomvariablein $\\mathbb{R}^{d}$ ofvariance $\\sigma^{2}$ centered at a point of norm at most i. If dis $\\mathtt{t}(\\boldsymbol{r},\\boldsymbol{r}^{\\prime})\\leq\\epsilon\\leq1$ then ", "page_idx": 26}, {"type": "equation", "text": "$$\n{\\frac{\\mu(\\pmb{r}^{\\prime})}{\\mu(\\pmb{r})}}\\geq e^{-{\\frac{\\epsilon(\\|\\pmb{r}\\|+2)}{\\sigma^{2}}}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma 3.7 (Spielman and Teng, 2003). Let $\\rho$ be the probability density function of a random variable $X$ If there exist $\\delta>0$ and $c\\in(0,1]$ suchthat ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\leq t\\leq t^{\\prime}\\leq\\delta\\implies\\frac{\\rho(t^{\\prime})}{\\rho(t)}\\geq c,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}[X\\leq\\epsilon\\mid X\\geq0]\\leq\\frac{\\epsilon}{c\\delta}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proposition 3.9. Let $\\gamma_{P}(\\mathbf{A})$ be defined as in Item 3. For any $\\epsilon\\geq0$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\gamma_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{4\\operatorname*{max}_{j\\in\\tilde{N}}\\|\\mathbf{Q}_{:,j}\\|+20\\|\\mathbf{A}^{\\flat}\\|_{\\infty}+3}\\right]\\leq\\epsilon\\frac{4e\\operatorname*{min}(n,m)^{3}}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. Let $\\mu_{\\mathbf{A}}(\\mathbf{A})$ be the probability density function of $\\mathbf{A}$ , which, by independence (Definition 1.1), can be expressed as $\\begin{array}{r}{\\prod_{i\\in[n],j\\in[m]}\\mu_{{\\bf A}_{i,j}}}\\end{array}$ , where $\\mu_{\\mathbf{A}_{i,j}}$ is aGaussian randm variableWefrst pefom a change of variables from ${\\bf A}_{\\overline{{B,N}}},{\\bf A}_{B,N}$ to ${\\bf A}_{\\overline{{B,N}}},{\\bf Q},b,c,d$ in accordance with (5); this can be understod tbrough the non-singlar; Clain C.2) linartransformation $\\mathbf{A}_{B,N}^{\\flat}\\,=\\,\\mathbf{T}(\\mathbf{Q}^{\\flat},b,c,d)_{.}$ To express the density in the new variables, we first note that the Jacobian of the change of variables is $|\\operatorname*{det}(\\mathbf{T})|{\\}=1$ (Claim C.2), and so the density on $\\mathbf{Q},\\boldsymbol{b},c,d$ can be expressed as $\\mu_{{\\bf A}_{B,N}}({\\bf T}({\\bf Q}^{\\flat},b,c,d))\\mu_{{\\bf A}_{\\overline{{B}},N}}({\\bf A}_{\\overline{{B}},N})$ ", "page_idx": 26}, {"type": "text", "text": "Next, we perform a change of variables from ${\\bf A}_{\\overline{{B,N}}},{\\bf Q},b,c,d$ $\\mathbf{A}_{\\overline{{B,N}}},\\mathbf{Q},\\widetilde{\\pmb{x}}^{\\star},\\widetilde{\\pmb{y}}^{\\star},\\boldsymbol{v}$ according to the transformations $\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}=\\pmb{c}$ $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}=\\pmb{b}$ ; and $v=d-\\langle\\widetilde{\\mathbf{x}}^{\\star},\\mathbf{Q}\\widetilde{y}^{\\star}\\rangle$ . It is easy to see that the Jacobian of the change of variables is ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left|\\operatorname*{det}\\left(\\frac{\\partial(\\mathbf{A}_{\\overline{{B,N}}},\\mathbf{Q},b,c,d)}{\\partial(\\mathbf{A}_{\\overline{{B,N}}},\\mathbf{Q},\\widetilde{\\boldsymbol{x}}^{\\star},\\widetilde{\\boldsymbol{y}}^{\\star},\\boldsymbol{v})}\\right)\\right|=\\left|\\operatorname*{det}\\left(\\frac{\\partial(b,c,d)}{\\partial(\\widetilde{\\boldsymbol{x}}^{\\star},\\widetilde{\\boldsymbol{y}}^{\\star},\\boldsymbol{v})}\\right)\\right|=\\operatorname*{det}(\\mathbf{Q})^{2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "So, the density on $\\mathbf{A}_{\\overline{{B,N}}},\\mathbf{Q},\\widetilde{\\pmb{x}}^{\\star},\\widetilde{\\pmb{y}}^{\\star},\\boldsymbol{v}$ reads ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mu_{\\mathbf{A}_{B,N}}(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star},\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star},v+\\langle\\widetilde{\\pmb{x}}^{\\star},\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star}\\rangle))\\mu_{\\mathbf{A}_{\\overline{{B}},N}}(\\mathbf{A}_{\\overline{{B}},N})\\operatorname*{det}(\\mathbf{Q})^{2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By Lemma C.6, it suffices to upper bound ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{B,N\\;\\mathbf{A}_{\\overline{{B}},N},\\mathbf{Q},x^{\\star},y^{\\star},v}\\bigl[\\gamma_{P}(\\mathbf{A})\\leq\\epsilon\\;|\\;\\mathbf{A}_{\\overline{{B}},N}y_{N}^{\\star}\\geq v\\mathbf{1}\\bigr]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Further, by Proposition C.5, it is in turn enough to bound $\\mathbb{P}_{\\mathbf{Q}}[\\gamma_{P}(\\mathbf{A})\\,\\leq\\,\\epsilon]$ for all $B,\\,N$ (for the non-trivial case where $\\widetilde{B},\\widetilde{N}\\neq\\emptyset_{.}$ $\\mathbf{A}_{\\overline{{B,N}}}$ $\\widetilde{\\mathbf{x}}^{\\star}$ \uff0c $\\widetilde{\\pmb{y}}^{\\star}$ \uff0c $v$ such that $\\mathbf{A}_{\\overline{{B}},N}\\mathbf{y}_{N}^{\\star}\\geq v\\mathbf{1}$ and ${\\bf A}_{\\overline{{N}},B}^{\\top}{\\bf x}_{B}^{\\star}\\leq v{\\bf1}$ where the induced distribution on $\\mathbf{Q}$ is ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mu_{{\\bf A}_{B,N}}({\\bf T}({\\bf Q}^{\\flat},{\\bf Q}^{\\top}\\widetilde{\\pmb x}^{\\star},{\\bf Q}\\widetilde{\\pmb y}^{\\star},\\boldsymbol{v}+\\langle\\widetilde{\\pmb x}^{\\star},{\\bf Q}\\widetilde{\\pmb y}^{\\star}\\rangle))\\operatorname*{det}({\\bf Q})^{2}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We will prove that for any j E N and Q.--? ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{Q};\\,,\\,j}\\left[\\mathrm{dist}(\\mathbf{Q}_{:,j},\\mathbf{span}(\\mathbf{Q}_{:,\\tilde{N}-j}))\\leq\\frac{\\epsilon}{4\\|\\mathbf{Q}_{:,j}\\|+4|v|+4\\|\\mathbf{Q}_{:,\\tilde{N}-j}^{\\flat}\\|_{\\infty}+3}\\right]\\leq\\epsilon\\frac{4e\\operatorname*{min}(n,m)^{2}}{\\sigma^{2}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and then apply a union bound over $j\\in\\widetilde{N}$ . Having fixed $\\mathbf{Q}_{:,\\widetilde{N}-j}$ , we can express $\\mathbf{Q}_{:,j}$ as $\\pmb q^{\\parallel}+t\\pmb q^{\\perp}$ \uff0c where $\\mathbb{R}^{\\tilde{B}}\\ni\\pmb{q}^{\\parallel}\\in\\mathsf{s p a n}(\\mathbf{Q}_{:,\\tilde{N}-j})$ and $\\mathbb{R}^{\\widetilde B}\\ni\\mathbf{q}^{\\perp}$ is the unit vector orthogonal to spar ${\\sf\\Pi}({\\bf Q}_{:,\\widetilde{N}-j})$ . Then, $|t|=\\mathsf{d i s t}(\\mathbf{Q}_{:,j},\\mathsf{s p a n}(\\mathbf{Q}_{:,\\widetilde{N}-j}))$ and $|\\operatorname*{det}(\\mathbf{Q})|=t C(\\mathbf{Q}_{:,\\tilde{N}-j})$ , where $C(\\mathbf{Q}_{:,\\widetilde{N}-j})$ does not depend on $\\mathbf{Q}_{:,j}$ (this can be obtained by expressing the determinant using the formula for parallelepipeds). By symmetry, we can prove (35) by bounding the probability that $t$ is at most $\\epsilon$ given that $t$ is at least 0. We can thus focus on proving ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q\\mid\\leqslant\\mathsf{s p a n}(\\mathbf{Q}_{:,\\widetilde{N}-j})}\\mathbb{P}[t\\leq\\epsilon\\mid t\\geq0]\\leq\\epsilon\\frac{4e\\operatorname*{min}(n,m)^{2}(4\\|q^{\\|}\\|_{\\infty}+4|v|+4\\|\\mathbf{Q}_{:,\\widetilde{N}-j}^{\\flat}\\|_{\\infty}+3)}{\\sigma^{2}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and then (35) follows from the fact that $\\|\\mathbf{Q}_{:,j}\\|\\,\\geq\\,\\|\\mathbf{q}^{\\|}\\|$ . Now, the induced distribution on $t$ is proportional to ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\rho(t):=t^{2}\\prod_{(i,j)\\in B\\times N}\\mu_{{\\bf A}_{i,j}}\\left(\\langle{\\bf T}_{i,j},{\\pmb r}_{i,j}(t)\\rangle\\right)\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for $\\pmb{r}_{i,j}(t)$ defined as ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{(\\pmb{q}^{\\|}+t\\pmb{q}^{\\perp},\\mathbf{Q}_{:,\\tilde{N}-j}^{\\flat},\\mathbf{Q}_{\\tilde{N}-j,:}^{\\top}\\tilde{\\pmb{x}}^{\\star},\\langle\\tilde{\\pmb{x}}^{\\star},\\pmb{q}^{\\|}+t\\pmb{q}^{\\perp}\\rangle,\\mathbf{Q}_{:,\\tilde{N}-j}\\tilde{\\pmb{y}}_{\\tilde{N}-j}^{\\star}+\\tilde{\\pmb{y}}_{j}^{\\star}(\\pmb{q}^{\\|}+t\\pmb{q}^{\\perp}),}\\\\ &{}&{\\quad\\quad\\quad\\quad\\quad v+\\langle\\tilde{\\pmb{x}}^{\\star},\\mathbf{Q}_{:,\\tilde{N}-j}\\tilde{\\pmb{y}}_{\\tilde{N}-j}^{\\star}\\rangle+\\tilde{\\pmb{y}}_{j}^{\\star}\\langle\\tilde{\\pmb{x}}^{\\star},\\pmb{q}^{\\|}+t\\pmb{q}^{\\perp}\\rangle).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We now want to apply Lemma 3.7. To that end, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\langle\\mathbf T_{i,j},r_{i,j}(t)-r_{i,j}(t^{\\prime})\\rangle|^{2}\\leq\\|\\mathbf T_{i,j}\\|^{2}\\|r_{i,j}(t)-r_{i,j}(t^{\\prime})\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq4(t-t^{\\prime})^{2}\\|(q^{\\perp},\\langle\\tilde{\\mathbf x}^{\\star},q^{\\perp}\\rangle,\\tilde{y}_{j}^{\\star}q^{\\perp},\\tilde{y}_{j}^{\\star}\\langle\\tilde{\\mathbf x}^{\\star},q^{\\perp}\\rangle)\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq16(t-t^{\\prime})^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where (37) follows from $\\|\\mathbf{T}_{i,j}\\|_{2}\\;\\;\\leq\\;\\;2$ (Claim C.2), and (38) follows from the fact that $\\|\\pmb{q}^{\\perp}\\|,\\|\\pmb{\\widetilde{x}}^{\\star}\\|,\\|\\pmb{\\widetilde{y}}^{\\star}\\|\\leq1$ . Moreover, again by Claim C.2, ", "page_idx": 27}, {"type": "equation", "text": "$$\n|\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t)\\rangle|\\leq\\|\\mathbf{T}_{i,j}\\|_{1}\\|\\boldsymbol{r}_{i,j}(t)\\|_{\\infty}\\leq4(\\|\\boldsymbol{q}^{\\|}\\|_{\\infty}+|\\boldsymbol{v}|+\\|\\mathbf{Q}_{:,\\tilde{N}-j}^{\\flat}\\|_{\\infty}+t).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Let $0\\leq t\\leq t^{\\prime}\\leq\\delta\\leq\\frac{1}{4}$ $\\begin{array}{r}{\\delta=\\frac{\\sigma^{2}}{4|B||N|(4||\\pm||\\pm4|v|+4||\\mathbf{Q}_{:,\\widetilde{N}-j}^{\\flat}||\\infty^{+3})}}\\end{array}$ Lemma C.8 then implies that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mu_{\\mathbf{A}_{i,j}}\\left(\\langle\\mathbf T_{i,j},r_{i,j}(t^{\\prime})\\rangle\\right)}{\\mu_{\\mathbf{A}_{i,j}}\\left(\\langle\\mathbf T_{i,j},r_{i,j}(t)\\rangle\\right)}\\geq e^{-\\frac{1}{|B||N|}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\frac{\\rho(t^{\\prime})}{\\rho(t)}\\geq\\left(\\frac{t^{\\prime}}{t}\\right)^{2}\\prod_{(i,j)\\in B\\times N}\\frac{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t^{\\prime})\\rangle)}{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t)\\rangle)}\\geq e^{-1}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We conclude that (36) can be obtained from Lemma 3.7, and the theorem follows. ", "page_idx": 27}, {"type": "text", "text": "Finally, we bound the probability that $\\alpha_{P}(\\mathbf{A})$ (Item 1) is close to $0$ $\\alpha_{D}(\\mathbf{A})$ can be bounded in a similar fashion. ", "page_idx": 27}, {"type": "text", "text": "Proposition 3.10. Let $\\alpha_{P}(\\mathbf{A})$ be defined as in Item 1. For any $\\epsilon\\geq0$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{A}}\\left[\\alpha_{P}(\\mathbf{A})\\leq\\frac{\\epsilon}{25(\\|\\mathbf{A}^{\\flat}\\|_{\\infty}+1)^{2}}\\right]\\leq\\epsilon\\frac{8e^{2}m n\\operatorname*{min}(n,m)}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. By Lemma C.6, it suffices to bound ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{B,N}\\mathbf{A}_{\\overline{{B}},N},\\mathbb{P}_{\\mathbf{0},x^{\\star},y^{\\star},v}[\\alpha_{P}(\\mathbf{A})\\leq\\epsilon\\mid\\mathbf{A}_{\\overline{{B}},N}y_{N}^{\\star}\\geq v\\mathbf{1}\\mathrm{~and~}\\mathbf{A}_{N,B}^{\\top}x_{B}^{\\star}\\leq v\\mathbf{1}],\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where we recall that the induced probability density function on ${\\bf A}_{\\overline{{B,N}}},{\\bf Q},x^{\\star},y^{\\star},$ $v$ reads ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\iota_{\\mathbf{A}_{B,N}}(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}^{\\top}\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star},v+\\langle\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star}\\rangle))\\mu_{\\mathbf{A}_{B,\\overline{{N}}}}(\\mathbf{A}_{B,\\overline{{N}}})\\mu_{\\mathbf{A}_{\\overline{{B}},N}}(\\mathbf{A}_{\\overline{{B}},N})\\mu_{\\mathbf{A}_{\\overline{{B}},\\overline{{N}}}}(\\mathbf{A}_{\\overline{{B}},\\overline{{N}}})\\operatorname*{det}(\\mathbf{Q})^{2}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We consider the non-trivial case where $\\widetilde{B},\\widetilde{N}\\neq\\emptyset$ . We will perform a further change of variables. Namely, let $\\pmb{a}\\;=\\;\\mathbf{A}_{\\overline{{N}},i}$ for $i\\;\\in\\;B\\;\\backslash\\;\\widetilde{B}$ .We map $\\mathbf{A}_{B,\\overline{{N}}}$ to $\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}\\,:=\\,\\mathbf{A}_{\\widetilde{B},\\overline{{N}}}\\,-\\,\\mathbf{1}a^{\\top},\\,a$ , so that $\\mathbf{A}_{\\overline{{N}},B}^{\\top}\\mathbf{x}_{B}^{\\star}\\leq v\\mathbf{1}$ can be equivalently expressed as $\\overline{{\\mathbf{A}}}_{N,\\widetilde{B}}^{\\top}\\widetilde{\\pmb{x}}^{\\star}\\le v\\mathbf{1}-\\pmb{a}$ The induced denstyfuntion is now proportional to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mu_{\\mathbf{A}_{B,N}}(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}^{\\top}\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star},\\boldsymbol{v}+\\langle\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star}\\rangle))\\mu_{a}(a)\\mu_{\\mathbf{A}_{\\widetilde{B},\\widetilde{N}}}(\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}+\\mathbf{1}a^{\\top})\\nu(\\cdot),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\nu(\\cdot)$ does not depend on $\\widetilde{\\mathbf{x}}^{\\star}$ and $\\textbf{\\em a}$ . By Proposition C.5, it is enough to show that for any $B,N,\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}},\\mathbf{A}_{\\overline{{B}},N},\\mathbf{A}_{\\overline{{B}},\\overline{{N}}},\\mathbf{Q},y^{\\star},v$ satisfying ${\\bf A}_{\\overline{{B}},N}{\\bf y}^{\\star}\\geq v{\\bf1}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{*,\\,a}\\Bigg[\\alpha_{P}\\leq\\frac{\\epsilon}{\\operatorname*{max}((\\|\\mathbf{Q}^{\\flat}\\|_{\\infty}+1)^{2},(1+\\|\\overline{{\\mathbf{A}}}_{\\mathcal{\\tilde{B}},\\overline{{N}}}^{\\flat}\\|_{\\infty})(5\\|\\overline{{\\mathbf{A}}}_{\\mathcal{\\tilde{B}},\\overline{{N}}}^{\\flat}\\|_{\\infty}+|v|+4))}\\mid\\overline{{\\mathbf{A}}}_{N,\\widetilde{B}}^{\\top}\\widetilde{\\pmb{x}}^{\\star}\\leq v\\mathbf{1}-a\\Bigg]}\\\\ {\\leq\\epsilon\\frac{8e^{2}m n\\operatorname*{min}(n,m)}{\\sigma^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the induced distribution on $\\widetilde{\\mathbf{x}}^{\\star}$ and $\\textbf{\\em a}$ is proportional to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mu_{\\mathbf{A}_{B,N}}(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}^{\\top}\\widetilde{\\mathbf{x}}^{\\star},\\mathbf{Q}\\widetilde{y}^{\\star},v+\\langle\\widetilde{\\mathbf{x}}^{\\star},\\mathbf{Q}\\widetilde{y}^{\\star}\\rangle))\\mu_{a}(a)\\mu_{\\mathbf{A}_{\\widetilde{B},\\widetilde{N}}}(\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}+\\mathbf{1}a^{\\top}).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We see that $\\widetilde{\\mathbf{x}}^{\\star}$ is independent of $\\textbf{\\em a}$ and $\\{\\pmb{a}_{j}\\}_{j\\in\\overline{{N}}}$ are pairwise independent. Thus, conditioning on the event $\\overline{{\\mathbf{A}}}_{N,\\widetilde{B}}^{\\top}\\widetilde{\\pmb{x}}^{\\star}\\le v\\mathbf{1}-\\pmb{a}$ , the induced distribution on $\\widetilde{\\mathbf{x}}^{\\star}$ is proportional to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mu_{\\mathbf{A}_{B,N}}\\big(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}^{\\top}\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star},\\boldsymbol{v}+\\langle\\widetilde{\\boldsymbol{x}}^{\\star},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star}\\rangle)\\big)\\prod_{j\\in\\overline{{N}}}\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B},j},\\widetilde{\\boldsymbol{x}}^{\\star}\\rangle\\leq\\boldsymbol{v}-\\mathbf{a}_{j}].\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We can proceed by showing that for any fixed i E B and $\\widetilde{\\mathbf{x}}_{\\widetilde{B}-i}^{\\star}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\mathbb{P}}{v_{i}^{*}}\\left[\\widetilde{\\boldsymbol{x}}_{i}^{\\star}\\leq\\frac{\\epsilon}{\\operatorname*{max}((\\|\\mathbf{Q}^{\\flat}\\|_{\\infty}+1)^{2},(1+\\|\\overline{{\\mathbf{A}}}_{\\mathcal{\\tilde{B}},\\overline{{N}}}^{\\star}\\|_{\\infty})(5\\|\\overline{{\\mathbf{A}}}_{\\mathcal{\\tilde{B}},\\overline{{N}}}^{\\star}\\|_{\\infty}+|v|+4))}\\mid\\overline{{\\mathbf{A}}}_{N,\\widetilde{B}}^{\\top}\\widetilde{\\boldsymbol{x}}^{\\star}\\leq v\\mathbf{1}-a\\right]}\\\\ &{}&{\\quad\\quad\\leq\\epsilon\\frac{8e^{2}m\\operatorname*{min}(n,m)}{\\sigma^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "adh $i\\in\\widetilde{B}$ Having ised $\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}$ $\\widetilde{\\pmb{x}}_{i}^{\\star}$ \uff0c say $\\rho(t)$ , is proportional to $\\rho_{1}(t)\\cdot\\rho_{2}(t)$ , where ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\rho_{1}(t):=\\mu_{\\mathbf{A}_{B,N}}(\\mathbf{T}(\\mathbf{Q}^{\\flat},\\mathbf{Q}_{:,\\widetilde{B}-i}^{\\top}\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}+t\\mathbf{Q}_{:,i}^{\\top},\\mathbf{Q}\\widetilde{\\pmb{y}}^{\\star},v+\\langle\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star},\\mathbf{Q}_{\\widetilde{B}-i,:}\\widetilde{\\pmb{y}}^{\\star}\\rangle+t\\langle\\mathbf{Q}_{i,:},\\widetilde{\\pmb{y}}^{\\star}\\rangle))\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\rho_{2}(t):=\\prod_{j\\in\\overline{{N}}}\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{j,\\widetilde{B}-i},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t\\leq v-\\pmb{a}_{j}].\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We will first apply Lemma 3.7 to bound $\\rho_{1}(t^{\\prime})/\\rho_{1}(t)$ for $0\\leq t\\leq t^{\\prime}\\leq\\delta\\leq1$ and a sufficiently small $\\delta$ Wedefine ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\boldsymbol{r}_{i,j}(t):=(\\mathbf{Q}^{\\flat},\\mathbf{Q}_{:,\\widetilde{B}-i}^{\\top}\\widetilde{\\boldsymbol{x}}_{\\widetilde{B}-i}^{\\star}+t\\mathbf{Q}_{:,i}^{\\top},\\mathbf{Q}\\widetilde{\\boldsymbol{y}}^{\\star},\\boldsymbol{v}+\\langle\\widetilde{\\boldsymbol{x}}_{\\widetilde{B}-i}^{\\star},\\mathbf{Q}_{\\widetilde{B}-i,:}\\widetilde{\\boldsymbol{y}}^{\\star}\\rangle+t\\langle\\mathbf{Q}_{i,:},\\widetilde{\\boldsymbol{y}}^{\\star}\\rangle),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "so that $\\begin{array}{r}{\\rho_{1}(t)=\\prod_{(i,j)\\in B\\times N}\\mu_{{\\bf A}_{i,j}}\\big(\\langle{\\bf T}_{i,j},{\\pmb r}_{i,j}(t)\\rangle\\big)}\\end{array}$ . Then, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t)-\\boldsymbol{r}_{i,j}(t^{\\prime})\\rangle|\\leq4|t-t^{\\prime}|\\|\\mathbf{Q}^{\\flat}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where we used Claim C.2. Further, ", "page_idx": 29}, {"type": "equation", "text": "$$\n|\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t)\\rangle|\\leq(t+1)\\|\\mathbf{Q}^{\\flat}\\|_{\\infty},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and so Lemma C.8 implies that for \u2264 4le ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf T_{i,j},\\boldsymbol r_{i,j}(t^{\\prime})\\rangle)}{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf T_{i,j},\\boldsymbol r_{i,j}(t)\\rangle)}\\geq e^{-\\frac{8\\delta\\|\\mathbf{Q}^{\\flat}\\|_{\\infty}(\\|\\mathbf{Q}^{\\flat}\\|_{\\infty}+1)}{\\sigma^{2}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "As a result, for 8 \u2264 g[BIINQ(IIQl+1) \u2019 ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{\\rho_{1}(t^{\\prime})}{\\rho_{1}(t)}=\\prod_{(i,j)\\in B\\times N}\\frac{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t^{\\prime})\\rangle)}{\\mu_{\\mathbf{A}_{i,j}}(\\langle\\mathbf{T}_{i,j},\\boldsymbol{r}_{i,j}(t)\\rangle)}\\geq e^{-1}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Next, we focus on lower bounding $\\rho_{2}(t^{\\prime})/\\rho_{2}(t)$ .From (39), it is not hard to see that $\\pmb{a}_{j}$ is a Gaussian random variable with expectation $|\\mathbb{E}[\\pmb{a}_{j}]|\\le1+||\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}||\\infty$ and variance $\\begin{array}{r}{\\mathbb{V}[{\\pmb a}_{j}]\\ge\\frac{\\sigma^{2}}{\\operatorname*{min}(n,m)}}\\end{array}$ 2 min(n,m) . Also, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\rho_{2}(t^{\\prime})}{\\rho_{2}(t)}=\\displaystyle{\\prod_{j\\in\\overline{{N}}}\\frac{\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t^{\\prime}\\leq v-\\mathbf{a}_{j}]}{\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t\\leq v-\\mathbf{a}_{j}]}}}\\\\ &{\\qquad\\geq\\displaystyle{\\prod_{j\\in\\overline{{N}}}\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t^{\\prime}\\leq v-\\mathbf{a}_{j}\\ |\\ \\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t\\leq v-\\mathbf{a}_{j}]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "By Lemma C.7 (for $\\tau=(2\\|\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty}+|v|+1)/(1+\\|\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty})),$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf A}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb x}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf A}}_{i,j}t^{\\prime}\\leq v-\\pmb_{a_{j}}\\,|\\,\\,\\langle\\overline{{\\mathbf A}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb x}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf A}}_{i,j}t\\leq v-\\pmb_{a_{j}}]}\\\\ &{\\qquad\\geq1-\\delta\\frac{\\operatorname*{min}(n,m)\\|\\overline{{\\mathbf A}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty}(2\\|\\overline{{\\mathbf A}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty}+|v|+1)}{\\sigma^{2}}e^{\\delta\\frac{\\operatorname*{min}(n,m)\\|\\overline{{\\mathbf A}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty}(\\mathbb{S}\\|\\overline{{\\mathbf A}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|_{\\infty}+|v|+4)}{\\sigma^{2}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Thus for $\\begin{array}{r}{\\delta\\leq\\frac{1}{2e m}\\frac{\\sigma^{2}}{\\operatorname*{min}(n,m)\\|\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|\\infty(5\\|\\overline{{\\mathbf{A}}}_{\\widetilde{B},\\overline{{N}}}^{\\flat}\\|\\infty+\\vert v\\vert+4)},}\\end{array}$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{P}_{a_{j}}[\\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t^{\\prime}\\leq v-\\pmb{a}_{j}\\ |\\ \\langle\\overline{{\\mathbf{A}}}_{\\widetilde{B}-i,j},\\widetilde{\\pmb{x}}_{\\widetilde{B}-i}^{\\star}\\rangle+\\overline{{\\mathbf{A}}}_{i,j}t\\leq v-\\pmb{a}_{j}]\\geq1-\\frac{1}{2m},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which in turn implies that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{\\rho_{2}(t^{\\prime})}{\\rho_{2}(t)}\\geq\\left(1-\\frac{1}{2m}\\right)^{\\overline{N}}\\geq e^{-1}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We conclude that $\\begin{array}{r}{\\frac{\\rho(t^{\\prime})}{\\rho(t)}\\geq e^{-2}}\\end{array}$ , and the proof follows from Lemma 3.7 by lower bounding the value of $\\delta$ \u53e3 ", "page_idx": 29}, {"type": "text", "text": "Armed with Propositions 3.8 to 3.10, Theorem 1.4 can be obtained from Theorem 3.6, in conjunction with a union bound and the fact that $\\|\\mathbf{A}^{\\flat}\\|_{\\infty}\\,\\leq\\,\\mathsf{p o l y}(n,m)$ with high probability (by Gaussian concentration). ", "page_idx": 29}, {"type": "text", "text": "C.3Proof of Theorem 1.2 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Having established Theorem 1.4, here we explain how existing results imply Theorem 1.2. We first focus on 0GDA. We also take the opportunity to explain in more detail how Wei et al. [2021] established Definition 1.3, which was sketched earlier in Section 3.1. Our treatment of the rest of the algorithms will be more brief. ", "page_idx": 29}, {"type": "text", "text": "Metric subregularity  A central ingredient in the approach of Wei et al. [2021] is what they refer to as saddle-point metric subregularity, stated below as Definition C.9. For the sake of generality, we give the definition for a general objective function $f:\\mathcal{X}\\times\\mathcal{Y}\\ni(x,y)\\mapsto f(x,y),$ assumed to be continuously differentiable; (1) corresponds to the bilinear case $f(\\boldsymbol{x},\\boldsymbol{y})=\\langle\\boldsymbol{x},\\mathbf{A}\\boldsymbol{y}\\rangle$ . We use again the notation $\\bar{F(z)}:=(\\nabla_{x}f({\\pmb x},{\\pmb y}),-\\nabla_{{\\pmb y}}\\bar{f}({\\pmb x},{\\pmb y}))$ , where $\\mathbb{R}^{n+m}\\ni z:=\\left(\\pmb{x},\\pmb{y}\\right)$ . We also let $L\\in\\mathbb{R}_{>0}$ be a Lipschitz continuity parameter for $F$ with respect to $\\Vert\\cdot\\Vert$ , so that $\\|F(z)-F(z^{\\prime})\\|\\le L\\|z-z^{\\prime}\\|$ in the context of (1), one can always take $L:=\\|\\mathbf{A}\\|$ ", "page_idx": 30}, {"type": "text", "text": "Definition C.9 (Metric subregularity for saddle-point problems [Wei et al., 2021]). A saddle-point problem satisfies metric subregularity if there exists a problem-dependent parameter $\\kappa^{\\prime}\\in\\mathbb{R}_{>0}$ Such that for any $z\\in{\\mathcal{Z}}$ and $z^{\\star}:=\\Pi_{\\mathcal{Z}^{\\star}}(z)$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{z^{\\prime}\\in\\mathcal{Z}}\\frac{\\langle F(z),z-z^{\\prime}\\rangle}{\\|z-z^{\\prime}\\|}\\geq\\kappa^{\\prime}\\|z-z^{\\star}\\|.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The nomenclature of Definition C.9 can be justified by the fact that (40) is equivalent to a common type of metric subregularity [Wei et al., 2021, Appendix F]; for more background, we refer to Dontchev and Rockafellar [2009]. We further remark that Wei et al. [2021] introduced (40) in a more general form by allowing an exponent $\\beta\\in\\mathbb{R}_{\\geq0}$ in the right-hand side, but that additional flexibility is not relevant for our purposes.6 ", "page_idx": 30}, {"type": "text", "text": "Now, there an obvious connection between Definition 1.3 and Definition C.9 in bilinear problems with bounded domain; namely, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{z^{\\prime}\\in\\mathcal{Z}}\\frac{\\langle F(z),z-z^{\\prime}\\rangle}{\\|z-z^{\\prime}\\|}\\geq\\frac{1}{2}\\Phi(z),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we used the fact that $\\langle F(z),z)=0$ and $\\|z-z^{\\prime}\\|\\leq D_{\\mathcal{Z}}=2$ . So, Definition 1.3 with respect to parameter $\\kappa$ implies Definition C.9 with parameter $\\kappa^{\\prime}:=\\kappa/2$ ", "page_idx": 30}, {"type": "text", "text": "Linear convergence of OGDA Under metric subregularity, in the sense of Definition C.9, Wei et al. [2021] were able to establish that OGDA converges to the set $\\mathcal{Z}^{\\star}$ at a linear rate: ", "page_idx": 30}, {"type": "text", "text": "Theorem C.10 (Wei et al.,2021). Considera saddle-point problem (1) satisfying metric subregularity withrespect tosome $\\kappa^{\\prime}\\in\\mathbb{R}_{>0}$ For any $\\begin{array}{r}{\\eta\\le\\frac{1}{8L}}\\end{array}$ ,the iterates $(\\pmb{z}^{(\\tau)})_{1\\leq\\tau\\leq t}$ ofOGDA satisfy ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathsf{d i s t}(z^{(t)},\\mathcal{Z}^{\\star})\\leq8\\left(1+\\frac{16\\eta^{2}(\\kappa^{\\prime})^{2}}{81}\\right)^{-t/2}\\mathsf{d i s t}(\\widehat{z}^{(1)},\\mathcal{Z}^{\\star}).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "As a result, Theorem C.10 implies that OGDA guarantees dis $\\because(z^{(t)},\\mathcal{Z}^{\\star})\\leq\\epsilon$ so long as ", "page_idx": 30}, {"type": "equation", "text": "$$\nt\\geq2\\left\\lceil\\frac{\\log\\left(\\frac{8D_{\\mathcal{Z}}}{\\epsilon}\\right)}{\\log\\left(1+\\frac{(\\kappa^{\\prime})^{2}}{324\\|\\mathbf{A}\\|^{2}}\\right)}\\right\\rceil.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In conjunction with Theorem 3.6 and Propositions 3.8 to 3.10, this immediately implies that OGDA has a polynomial smoothed complexity with high probability, as claimed earlier in Theorem 1.2. ", "page_idx": 30}, {"type": "text", "text": "Before we proceed, it is instructive to explain how Wei et al. [2021] treated the error bound in bilinear problemswhere $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ are polyhedral sets. As we explained earlier, it is enough to show that for any $x\\in\\mathcal{X}$ and $\\pmb{y}\\in\\mathcal{V}$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{{\\pmb{y}}\\in{\\mathcal{Y}}}{\\operatorname*{max}}\\mathbf{\\boldsymbol{x}}^{\\top}{\\mathbf{A}}{\\pmb{y}}-\\boldsymbol{v}\\geq\\kappa\\|{\\pmb{x}}-\\Pi_{{\\mathcal{X}}^{\\star}}({\\pmb{x}})\\|,}\\\\ &{\\quad\\boldsymbol{v}-\\underset{{\\pmb{x}}\\in{\\mathcal{X}}}{\\operatorname*{min}}\\,\\mathbf{\\boldsymbol{x}}^{\\top}{\\mathbf{A}}{\\pmb{y}}\\geq\\kappa\\|{\\pmb{y}}-\\Pi_{{\\mathcal{Y}}^{\\star}}({\\pmb{y}})\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We focus on the first inequality, which is with respect to Player $x$ .We let $\\pmb{\\mathcal{X}}:=\\{\\pmb{x}\\in\\mathbb{R}^{n}:\\pmb{c}_{i}^{\\top}\\pmb{x}\\leq$ $b_{i}\\quad\\forall i\\in[\\ell_{x}]\\}$ , where $\\ell_{x}$ denotes the number of vertices of $\\mathcal{X}$ . We also let $o_{j}:=\\mathbf{A}y_{j}$ ,where $\\pmb{y}_{j}$ denotes the $j$ th vertex of $\\boldsymbol{\\wp}$ ; for simplicity, we will denote by $k_{y}\\in\\mathbb{N}$ the number of vertices of $\\boldsymbol{\\wp}$ We consider a fixed $\\pmb{x}\\in\\mathcal{X}\\setminus\\mathcal{X}^{\\star}$ and $\\pmb{x}^{\\star}=\\Pi_{\\mathcal{X}^{\\star}}(\\pmb{x})$ ", "page_idx": 30}, {"type": "text", "text": "It is easy to see that the set of optimal strategies for Player $x$ $\\begin{array}{r}{\\mathcal{X}^{\\star}:=\\{\\pmb{x}\\in\\mathcal{X}:\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{y}}\\langle\\pmb{x},\\pmb{\\mathrm{A}}\\pmb{y}\\rangle\\leq v\\},}\\end{array}$ can be expressed as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\ensuremath{\\mathcal{X}}^{\\star}:=\\left\\{x\\in\\mathbb{R}^{n}:c_{i}^{\\top}x\\leq b_{i},o_{j}^{\\top}x\\leq v\\quad\\forall(i,j)\\in[\\ell_{x}]\\times[k_{y}]\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Indeed, any point $\\pmb{y}\\in\\mathcal{V}$ is a convex combination of the vertices of $\\boldsymbol{\\wp}$ , and the converse direction is also obvious. A feasibility constraint $i\\in[\\ell_{x}]$ is said to be tight if $c_{i}^{\\top}x^{\\star}=b_{i}$ ; similarly, an optimality constraint $j\\in[k_{y}]$ is tight if $o_{j}^{\\top}\\mathbf{x}^{\\star}=v$ .We let $L_{x}=L_{x}(\\pmb{x}^{\\star})\\subseteq[\\ell_{x}]$ be the set of tight feasibility constraints and $K_{y}\\,=\\,K_{y}(\\pmb{x}^{\\star})\\,\\subseteq\\,[k_{y}]$ be the set of tight optimality constraints. We can assume without any loss that $L_{x},K_{y}\\ne\\emptyset$ . It is well-known (e.g.,[Rockafellar, 2015]) that the normal cone of $\\varkappa^{\\star}$ at $x^{\\star}$ with respect to $\\varkappa^{\\star}$ can be expressed as ", "page_idx": 31}, {"type": "equation", "text": "$$\nN_{\\mathbf{x}^{\\star}}:=\\left\\{\\sum_{i\\in L_{x}}p_{i}c_{i}+\\sum_{j\\in K_{y}}q_{j}o_{j}\\quad\\forall(\\pmb{p},\\pmb{q})\\in\\mathbb{R}_{\\ge0}^{L_{x}}\\times\\mathbb{R}_{\\ge0}^{K_{y}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Wei et al. [2021] also define $M_{\\pmb{x}^{\\star}}\\subseteq N_{\\pmb{x}^{\\star}}$ as ", "page_idx": 31}, {"type": "equation", "text": "$$\nN_{\\mathbf{x}^{\\star}}\\cap\\left\\{c_{i}^{\\top}x\\leq0\\quad\\forall i\\in L_{x}\\right\\}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Now, the main parameter of interest that relates to Definition 1.3 in the analysis of Wei et al. [2021] stems from the following quantity. ", "page_idx": 31}, {"type": "text", "text": "Definition C.11. We let $C\\in\\mathbb{R}_{>0}$ be defined as the infimum over $(0,\\infty)$ so that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left\\{\\sum_{i\\in L_{x}}p_{i}\\mathbf{c}_{i}+\\sum_{j\\in K_{y}}q_{j}\\mathbf{o}_{j},0\\leq p_{i},q_{j}\\leq C\\right\\}\\supseteq M_{x^{\\star}}\\cap B_{\\infty},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $B_{\\infty}\\subseteq\\mathbb{R}^{n}$ is the set of points with $\\ell_{\\infty}$ norm upper bounded by 1. ", "page_idx": 31}, {"type": "text", "text": "By definition of $M_{x^{\\star}}$ , it is evident that there always exists a finite problem-dependent parameter $C\\in\\mathbb{R}_{>0}$ such that Definition C.11 is satisfied. It is then not hard to show that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\pmb{x}^{\\top}\\mathbf{A}\\pmb{y}-\\boldsymbol{v}\\geq\\frac{1}{C|K_{y}|}\\|\\pmb{x}-\\Pi_{\\mathcal{X}}(\\pmb{x}^{\\star})\\|.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Assuming that the number of vertices is polynomial in the dimensions,7 this shows that Definition C.11 essentially captures the complexity of satisfying Definition 1.3. As we explained earlier in Section 3.1, the constraint matrix of the linear program induced by Definition C.11 depends both on the payoff matrix A as well as the set of constraints. It is thus unclear how to use existing results in the model of smoothed complexity [Dunagan et al., 2011] to bound $C$ . The second and more important challenge revolves around the fact that Definition C.11 depends solely on the tight constraints of the optimal solution, which in turn depends on the randomness of A. Under our characterization, the latter challenge was addressed earlier in Section 3.3. ", "page_idx": 31}, {"type": "text", "text": "Continuing for OMwU, we again rely on the analysis of Wei et al. [2021], which relates the rate of convergence of 0MwU to three quantities. The first one [Wei et al., 2021, Definition 3] is similar to Definition C.9, but with the difference that the maximization is now constrained to be over points whose support is a subset of the support of the equilibrium; namely, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\kappa_{x}:=\\operatorname*{min}_{\\substack{{\\pmb x}\\in\\mathcal{X}\\backslash\\{{\\pmb x}^{\\star}\\}}}\\operatorname*{max}_{{\\pmb y}\\in\\mathcal{V}^{\\star}(\\mathcal{Y})}\\frac{\\langle{\\pmb x}-{\\pmb x}^{\\star},{\\bf A}{\\pmb y}\\rangle}{\\|{\\pmb x}-{\\pmb x}^{\\star}\\|_{1}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\mathcal{V}^{\\star}(\\mathcal{V}):=\\{\\pmb{y}\\in\\Delta^{m}:\\mathsf{s u p p}(\\pmb{y})\\subseteq\\mathsf{s u p p}(\\pmb{y}^{\\star})\\}$ A symmetric definition is to be considered with respect to Player $y$ . To connect this to (8), we note that, when ${\\pmb y}\\in\\mathcal{V}^{\\star}(\\mathcal{V})$ \uff0c $\\langle\\mathbf{x}^{\\star},\\mathbf{A}\\mathbf{y}\\rangle=v$ .We are thus left to lower bound $\\operatorname*{max}_{y}\\langle x,\\mathbf{A}y\\rangle-v$ in terms of $\\|{\\boldsymbol{x}}-{\\boldsymbol{x}}^{\\star}\\|_{1}$ ,but under the constraint that ${\\pmb y}\\in\\mathcal{V}^{\\star}(\\mathcal{V})$ . An inspection of our proof of Theorem 3.6 (and in particular the proof of (8)) reveals that its conclusion holds even when the maximization is subject to the above constraint, and so our analysis immediately lower bounds (44) as well. The second quantity introduced by Wei et al. [2021, Definition 2] corresponds exactly to Item 2, which was bounded in Proposition 3.8. The third quantity [Wei et al., 2021, Definition 4] is where the exponential overhead is introduced. Namely, the iteration complexity of OMwU in their analysis depends on e $\\operatorname{xp}\\left(\\operatorname*{min}(\\alpha_{P}(\\mathbf{A}),\\alpha_{D}(\\mathbf{A}))^{-1}\\right)$ , where we recall the definition in Item 1.8 Unfortunately, for any game, it holds that $\\alpha_{P}(\\mathbf{A})\\leq1/n$ and $\\alpha_{D}(\\mathbf{A})\\leq1/m$ , and so even if the geometry of the problem is favorable, the obtained bound is exponential. (The reason the above quantity is crucial in their analysis is because it lower bounds the probability of playing any action through the trajectory of OMwu.) Nevertheless, using Proposition 3.10, our analysis provides instead a bound of $\\exp(\\mathsf{p o l y}(n,m,1/\\sigma))$ with high probability, which is still a major improvement over the worst-case bound of Wei et al. [2021], which can be doubly exponential in the number of bits $L$ describing the game\u2014one can easily make sure that $\\alpha_{P}(\\mathbf{A})\\stackrel{!}{\\approx}1/\\stackrel{\\cdot}{2}^{L}$ (Proposition 3.1). ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "Next, for EGDA, Tseng [1995] established linear convergence under the error bound ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathrm{dist}(z,z^{\\star})\\leq\\tau\\|z-\\Pi_{\\mathcal{Z}}(z-\\eta F(z))\\|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "for some $\\tau>0$ and a suitable $\\eta>0$ [Tseng, 1995, Corollary 3.3]. It is easy to make the following connection. ", "page_idx": 32}, {"type": "text", "text": "Lemma C.12. It holds that $\\begin{array}{r}{\\Phi(z)\\leq\\frac{2}{\\eta}\\|z-\\Pi_{\\mathcal{Z}}(z-\\eta F(z))\\|.}\\end{array}$ ", "page_idx": 32}, {"type": "text", "text": "Proof. Indeed, by the first-order optimality condition for the optimization problem associated with ", "page_idx": 32}, {"type": "equation", "text": "$$\nz^{\\prime}:=\\Pi_{\\mathcal{Z}}(z-\\eta F(z))=\\arg\\operatorname*{min}_{z^{\\prime}\\in\\mathcal{Z}}\\left\\{\\|z^{\\prime}-(z-\\eta F(z))\\|^{2}:=h(z^{\\prime})\\right\\},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "we get $\\langle\\widehat{z}-z^{\\prime},\\nabla h(z^{\\prime})\\rangle\\geq0$ for any $\\widehat{z}\\in\\mathcal{Z}$ , or equivalently, $\\begin{array}{r}{\\operatorname*{min}_{\\hat{z}\\in\\mathcal{Z}}\\langle\\widehat{z}-z^{\\prime},z^{\\prime}-z+\\eta F(z)\\rangle\\geq0}\\end{array}$ Observing that $\\begin{array}{r}{\\operatorname*{min}_{\\hat{z}\\in\\mathcal{Z}}\\langle\\hat{z},F(z)\\rangle=-\\Phi(z)}\\end{array}$ and bounding ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\langle z-z^{\\prime},\\widehat{z}-z^{\\prime}\\rangle\\geq-\\|z-z^{\\prime}\\|\\|\\widehat{z}-z^{\\prime}\\|\\geq-D_{\\mathcal{Z}}\\|z-z^{\\prime}\\|=-2\\|z-\\Pi_{\\mathcal{Z}}(z-\\eta F(z))\\|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "leads to the claim. ", "page_idx": 32}, {"type": "text", "text": "It can thus be shown that Definition 1.3 is again sufficient to dictate the rate of convergence of EGDA. Finally, for IterSmooth, Gilpin et al. [2012] introduced a \u201ccondition measure\u201d of the payoff matrix A, which in fact corresponds precisely to Definition 1.3. Thus, Theorem 1.2 with respect to IterSmooth follows readily from [Gilpin et al., 2012, Theorem 2]. ", "page_idx": 32}, {"type": "text", "text": "C.4 Proof of Theorem 4.2 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Finally, we conclude with the proof of Theorem 4.2, which is restated below. ", "page_idx": 32}, {"type": "text", "text": "Theorem 4.2.Any $\\delta$ -support-stable game (per Definition 4.1) satisfies the error bound for any sufficientlysmallmodulus ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\kappa\\geq\\mathsf{p o l y}\\left(\\frac{1}{n},\\frac{1}{m},\\delta\\right).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Proof of Theorem 4.2. We treat each parameter separately. ", "page_idx": 32}, {"type": "text", "text": "\u00b7 Let us start from $\\beta_{P}(\\mathbf{A})$ (Item 2). We let $j^{\\prime}\\in\\arg\\operatorname*{min}_{j\\in\\overline{{N}}}(v-\\langle{\\pmb x}_{B}^{\\star},{\\bf A}_{B,j}\\rangle)$ , where we assume that $\\overline{{N}}\\neq\\emptyset$ . We consider a perturbed matrix $\\mathbf{A}^{\\prime}$ such that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbf{A}_{i,j}^{\\prime}=\\left\\{\\!\\!\\begin{array}{l l}{\\mathbf{A}_{i,j}-\\beta_{P}(\\mathbf{A})}&{\\mathrm{if}\\;i\\in B,j=j^{\\prime},}\\\\ {\\mathbf{A}_{i,j}}&{\\mathrm{otherwise}.}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Then, the game described by $\\mathbf{A}^{\\prime}$ cannot be non-degenerate with the same support as A. Indeed, in the contrary case it would follow that the (unique) equilibrium $(\\pmb{x}_{B}^{\\star},\\pmb{y}_{N}^{\\star})$ remains the same since $\\mathbf{A}_{B,N}^{\\prime}=\\mathbf{A}_{B,N}$ But then, $v-\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j^{\\prime}}^{\\prime}\\rangle=v-\\langle\\pmb{x}_{B}^{\\star},\\mathbf{A}_{B,j^{\\prime}}\\rangle-\\dot{\\beta}_{P}^{\\star}(\\mathbf{A})=0$ by definition of $j^{\\prime}$ and $\\beta_{P}(\\mathbf{A})$ , which is a contradiction. Further, $\\|\\mathbf{A}-\\mathbf{A}^{\\prime}\\|=\\beta_{P}(\\mathbf{A})$ . In turn, this implies that $\\delta\\leq\\beta_{P}(\\mathbf{A})$ . Similar reasoning yields that $\\delta\\leq\\beta_{D}(\\mathbf{A})$ ", "page_idx": 33}, {"type": "text", "text": "\u00b7 Continuing_ for $\\gamma_{P}(\\mathbf{A})$ (Item 3), we assume that $\\widetilde{B},\\widetilde{N}\\ \\ne\\ \\emptyset$ . We let $\\mathbf{U}\\pmb{\\Sigma}\\mathbf{V}^{\\top}$ be a singular value decomposition (SVD) of $\\mathbf{Q}$ \uff1aThen, a perturbation to $\\mathbf{Q}$ of the form $\\mathbf{U}\\bar{\\mathrm{d}}{\\mathbf{\\upmu}}{\\mathbf{g}}(0,0,\\ldots,\\sigma_{\\operatorname*{min}}(\\mathbf{\\bar{Q}}))\\mathbf{V}^{\\top}$ leads to a singular matrix $\\mathbf{Q}^{\\prime}$ which cannot be the case if the perturbed game is non-degenerate with the same support. This perturbation can be cast in terms of ${\\bf A}_{B,N}^{\\prime}$ through transformation $\\mathbf{T}$ in (5). This lower bounds $\\sigma_{\\mathrm{min}}(\\mathbf{Q})$ in terms of $\\delta$ , and Proposition C.4 can in turn lower bound $\\gamma_{P}(\\mathbf{A})$ in terms of $\\sigma_{\\mathrm{min}}(\\mathbf{Q})$ ", "page_idx": 33}, {"type": "text", "text": "\u00b7 Finally, we treat $\\alpha_{P}(\\mathbf{A})$ (Item 1). The non-trivial case is again when $\\widetilde{B},\\widetilde{N}\\,\\neq\\,\\emptyset$ . Let $i^{\\prime}\\in\\arg\\operatorname*{min}_{i\\in B}(\\pmb{x}_{i}^{\\star})$ .If $i^{\\prime}\\in\\widetilde{B}$ ,wedefine ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{R}^{\\widetilde B}\\ni\\widetilde{\\pmb{x}}_{i}^{\\prime}=\\left\\{0\\begin{array}{l l}{\\mathrm{\\if\\}i=i^{\\prime},}\\\\ {\\pmb{x}_{i}^{\\star}}&{\\mathrm{otherwise.}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We know that $\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\star}\\,=\\,\\pmb{b}$ .We then consider the perturbed vector $b^{\\prime}:=\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\prime}$ . If the perturbed game was non-degenerate with the same support, it would follow that $(\\widetilde{\\mathbf{x}}^{\\prime},\\cdot)$ is the unique equilibrium, which is a contradiction since $\\widetilde{\\mathbf{x}}_{i^{\\prime}}=0$ . Further, the norm of the perturbation $\\left|\\left|b-b^{\\prime}\\right|\\right|$ is upper bounded in terms of $\\alpha_{P}(\\mathbf{A})$ , which can be again expressed in terms of ${\\bf A}_{B,N}$ through transformation (5). Similarly, if $i^{\\prime}\\notin\\tilde{B}$ , we define ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{R}^{\\tilde{B}}\\ni\\pmb{\\widetilde{x}}_{i}^{\\prime}=\\pmb{x}_{i}^{\\star}+\\frac{\\alpha_{P}(\\mathbf{A})}{\\vert\\widetilde{B}\\vert},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "and we consider the perturbed vector $b^{\\prime}:=\\mathbf{Q}^{\\top}\\widetilde{\\pmb{x}}^{\\prime}$ . If the perturbed game was non-degenerate with the same support, it would follow that $(\\widetilde{\\mathbf{x}}^{\\prime},\\cdot)$ is the unique equilibrium, which is a contradiction since $\\begin{array}{r}{\\dot{\\sum_{i\\in\\widetilde{B}}\\pmb{x}_{i}^{\\prime}}=\\sum_{i\\in\\widetilde{B}}\\pmb{x}_{i}^{\\star}+\\alpha_{D}\\pmb{(\\dot{A})}^{\\prime}=1}\\end{array}$ . The norm of the perturbation is again upper bounded in terms of $\\alpha_{P}(\\mathbf{A})$ . Overall, we have shown that $\\delta\\leq\\alpha_{P}(\\mathbf{A})\\mathsf{p o l y}(n,m)$ Similar reasoning applies with respect to $\\alpha_{D}(\\mathbf{A})$ . This completes the proof. ", "page_idx": 33}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: All claims made in the abstract and introduction are proven in Appendices C.1 to C.4. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 34}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: All limitations and assumptions are stated in Section 1. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 34}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The full set of assumptions and proofs are given in Appendices C.1 to C.4. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 35}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 35}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with suficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips .cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 36}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 36}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 37}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The contribution of the paper is theoretical, and conforms in every respect with the NeurIPS Code of Ethics. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 37}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: The contribution of the paper is theoretical, and we do not foresee any societal impact. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u00b7 Ihe answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u00b7 'T'he answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 38}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 39}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 39}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 39}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 39}]