[{"figure_path": "CscowTrOP9/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of our method with other methods on the CAVE(\u00d7 4, \u00d7 8) and Harvard(\u00d7 4, \u00d7 8) datasets. Closer to the top-right corner indicates better performance and the size of the circle indicates the number of parameters in the model.", "description": "This figure compares the performance of the proposed FeINFN model with other state-of-the-art methods on two benchmark datasets, CAVE and Harvard, at different upscaling factors (\u00d74 and \u00d78).  The x and y axes represent PSNR values for the CAVE and Harvard datasets respectively. The size of each circle corresponds to the number of parameters in each model, and the position of the circle represents the model's performance in terms of PSNR.  The figure shows that FeINFN achieves superior performance with fewer parameters compared to other models.", "section": "Experiments"}, {"figure_path": "CscowTrOP9/figures/figures_2_1.jpg", "caption": "Figure 2: (a) The amplitude of latent code from the encoder fed by HR-HSI and LR-HSI (combined with HR-MSI) share a similarity, but the phases differ from each other. Ep* is a trained encoder. (b) 3 \u00d7 3 convolution would suffer from the issue of spectrum leakage, which can be alleviated by 1 \u00d7 1 convolution.", "description": "This figure shows that the amplitudes of latent codes from the encoder fed by HR-HSI and LR-HSI (combined with HR-MSI) are similar, but their phases are different.  The authors explain that this is because the high-frequency information is mainly contained in the phase component.  The figure also compares the effect of 3x3 and 1x1 convolutions on spectrum leakage, illustrating that 1x1 convolution is preferred to avoid such issues. This supports the design choice of the proposed method, which processes the amplitude and phase components separately in the frequency domain.", "section": "2 Related works"}, {"figure_path": "CscowTrOP9/figures/figures_3_1.jpg", "caption": "Figure 3: The flowchart of the FeINFN framework which is composed of a spectral encoder Ex, a spatial encoder Ey, MHIF task-designed spatial and Fourier domains implicit fusion functions, and a pixel space mapping decoder. Please note that ILR is the LR-HSI, IHR is the HR-MSI, ILR is the bicubic interpolation LR-HSI, and XHR is the HR normalized 2D coordinate map. zspe, Zspa, Zhp, dx correspond to individual pixel units, A and P represents amplitude and phase, respectively.", "description": "This figure illustrates the architecture of the proposed Fourier-enhanced Implicit Neural Fusion Network (FeINFN).  It shows the flow of data through the network, starting with the low-resolution hyperspectral image (LR-HSI) and high-resolution multispectral image (HR-MSI) as inputs.  The inputs are processed by spectral and spatial encoders, and then fed into a spatial-frequency implicit fusion function (Spa-Fre IFF) which operates in both spatial and frequency domains.  The output of the Spa-Fre IFF is then decoded using a spatial-frequency interactive decoder (SFID) to produce the final high-resolution hyperspectral image (HR-HSI).  Key components of the architecture are highlighted, including the use of FFT and IFFT for frequency domain processing, and the use of a Gabor wavelet activation function in the decoder.", "section": "3.2 Overview of the FeINFN Framework"}, {"figure_path": "CscowTrOP9/figures/figures_6_1.jpg", "caption": "Figure 4: Detailed composition of the proposed SFID.", "description": "The figure shows the architecture of the Spatial-Frequency Interactive Decoder (SFID), a crucial component of the FeINFN framework.  The SFID takes spatial features (Es) and frequency features (Ef) as inputs. It processes these features through three layers. Each layer employs 1x1 convolutions, Gabor wavelet activation functions, channel-wise concatenation (C), and matrix multiplications (\u2297) to integrate spatial and frequency information. The final output of the SFID is a refined residual image (IHR) that is added to the upsampled low-resolution image to obtain the final high-resolution hyperspectral image.  The diagram clearly depicts the flow of information and the operations performed at each stage.", "section": "3.5 Spatial-Frequency Interactive Decoder"}, {"figure_path": "CscowTrOP9/figures/figures_6_2.jpg", "caption": "Figure 5: The complex Gabor wavelet function. (a) and (b) depict the visualization of the complex Gabor wavelet function. (c), (d), and (e) represent the frequency responses of GT and decoder's mean feature using Gabor and regular ReLU activations, respectively.", "description": "This figure visualizes the complex Gabor wavelet function in both time and frequency domains, highlighting its time-frequency tightness property. It compares the frequency responses of the ground truth (GT) and decoder features when using Gabor and ReLU activations, demonstrating the Gabor wavelet's superior ability to capture optimal bandwidths.", "section": "3.5 Spatial-Frequency Interactive Decoder"}, {"figure_path": "CscowTrOP9/figures/figures_8_1.jpg", "caption": "Figure 6: The upper and lower parts respectively showcase the results of \"Chart and Stuffed Toy\" from the CAVE dataset and \"Backpack\" from the Harvard dataset using pseudo-color representation. Green rectangles depict some close-up shots. The second and fourth rows show the residuals between the ground truth (GT) and the fusion products.", "description": "This figure compares the visual results of the proposed FeINFN method against other state-of-the-art methods for hyperspectral image fusion. The top row shows the fusion results for the \"Chart and Stuffed Toy\" image from the CAVE dataset, while the bottom row shows the fusion results for the \"Backpack\" image from the Harvard dataset.  The images are displayed using a pseudo-color representation for better visualization of spectral information.  The green boxes highlight specific areas for a closer comparison. The second and fourth rows show the error maps, which represent the difference between the fused images and the ground truth. Darker colors in the error maps indicate a smaller difference and better fusion performance.", "section": "4 Experiments"}, {"figure_path": "CscowTrOP9/figures/figures_8_2.jpg", "caption": "Figure 7: Changes in PSNR on the CAVE dataset of our FeINFN over iterations with and without the \\\"Fourier Domain\\\". The Frequency IFF can help the network learn the high-frequency details and converge faster.", "description": "This figure shows the PSNR (Peak Signal-to-Noise Ratio) values over training iterations for the proposed FeINFN model with and without the Fourier domain component. The blue line represents the model incorporating the spatial and frequency implicit fusion function (Spa-Fre IFF) which includes the Fourier transform for frequency feature fusion. The orange line represents the model without the frequency domain component. The figure demonstrates that incorporating the Fourier domain component significantly improves PSNR, implying better performance in capturing high-frequency details and faster convergence during training.", "section": "4.1 Ablation Studies"}, {"figure_path": "CscowTrOP9/figures/figures_14_1.jpg", "caption": "Figure 8: Convolving an image in the frequency domain is globally impactful in the spatial domain.", "description": "This figure demonstrates the global impact of convolution in the frequency domain on the spatial domain.  It shows a spatial domain image, its corresponding frequency domain representation (a spectrogram), and the result of a localized convolution in the frequency domain. The localized convolution in the frequency domain results in a global change to the spatial domain image, highlighting how operations in the frequency domain affect the entire spatial image, expanding the receptive field of the implicit neural representation.", "section": "A.5 The Receptive Field of INR in the Fourier Domain"}, {"figure_path": "CscowTrOP9/figures/figures_15_1.jpg", "caption": "Figure 6: The upper and lower parts respectively showcase the results of \"Chart and Stuffed Toy\" from the CAVE dataset and \"Backpack\" from the Harvard dataset using pseudo-color representation. Green rectangles depict some close-up shots. The second and fourth rows show the residuals between the ground truth (GT) and the fusion products.", "description": "This figure compares the visual results of the proposed FeINFN method with other state-of-the-art methods on two benchmark datasets: CAVE and Harvard.  It shows both the fused images and the residual error maps (differences between the fused image and the ground truth) for several sample images. The close-up shots highlight the details and differences between different fusion methods.", "section": "4 Experiments"}, {"figure_path": "CscowTrOP9/figures/figures_15_2.jpg", "caption": "Figure 6: The upper and lower parts respectively showcase the results of \"Chart and Stuffed Toy\" from the CAVE dataset and \"Backpack\" from the Harvard dataset using pseudo-color representation. Green rectangles depict some close-up shots. The second and fourth rows show the residuals between the ground truth (GT) and the fusion products.", "description": "This figure compares the visual results of the proposed FeINFN model against other state-of-the-art methods on the CAVE and Harvard datasets.  It shows the fused images, alongside close-up views highlighting details, and the residual images which demonstrate the differences between the model's output and the ground truth. The pseudo-color representation aids in the visualization of spectral details.", "section": "4 Experiments"}, {"figure_path": "CscowTrOP9/figures/figures_17_1.jpg", "caption": "Figure 11: Error map for fusing an image with edges. The Gabor wavelet activation demonstrates high representational power for visual signals, as depicted in Fig. 11. Compared to other activation functions, we observe that models utilizing the Gabor wavelet function exhibit lower error and spatial compactness.", "description": "This figure compares the error maps produced by the proposed FeINFN model using Gabor wavelet activation against those using ReLU and GELU activations.  The Gabor wavelet method shows significantly lower error and better spatial compactness, indicating its effectiveness in representing high-frequency details and edges.", "section": "A.11 Ablation Study: The Effectiveness of Decoder with Complex Gabor Wavelet Activation"}]