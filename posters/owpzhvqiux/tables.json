[{"figure_path": "OWPzhVqIux/tables/tables_20_1.jpg", "caption": "Figure 4: GPT-4 for T = 100: a per-configuration summary table on the hard MAB instance with N = 10 replicates. Only three GPT-4 configurations do not exhibit suffix failures; two of these (BNRND and BSSCD) exhibit uniform-like failures. The final configuration (BSSCO) succeeds.", "description": "This table summarizes the results of experiments using GPT-4 on a 5-armed bandit problem with a reward gap of 0.2 (hard instance).  It shows several key statistics for 12 different prompt configurations.  The statistics include the median reward achieved, the suffix failure frequency (the percentage of times the best arm was not chosen after the midpoint of the trial), and the minimum fraction of times each arm was played (K * MinFrac).  The table highlights the only successful configuration which avoided both suffix failures and uniform-like failures. ", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_20_2.jpg", "caption": "Figure 11: GPT-4 for T = 100: the per-configuration summary tables. The \"fails\" row indicates that all replicates completed successfully.", "description": "This table summarizes the results of the GPT-4 experiments on different configurations of the multi-armed bandit problem.  It shows key statistics for each configuration, including the median reward achieved, the frequency of suffix failures (where the best arm is never selected after a certain point), the minimum fraction of times each arm was chosen (indicating uniform-like behavior), and the fraction of times the greedy algorithm was mimicked.  The table also shows the number of replicates used for each configuration.  The 'fails' row shows whether all replicates completed successfully for each configuration.", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_21_1.jpg", "caption": "Figure 11: GPT-4 for T = 100: the per-configuration summary tables. The \"fails\" row indicates that all replicates completed successfully.", "description": "This table summarizes the results of experiments using GPT-4 with different prompt designs and temperature settings on four different multi-armed bandit (MAB) problem instances. The table includes statistics such as median reward, suffix failure frequency, the minimum fraction of times each arm was pulled, and the fraction of times the greedy algorithm's choice was made.  The \"fails\" row indicates whether any replicates failed to converge.  The table provides a compact representation of the performance variations across different experimental settings.", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_22_1.jpg", "caption": "Figure 11: GPT-4 for T = 100: the per-configuration summary tables. The \"fails\" row indicates that all replicates completed successfully.", "description": "This table presents a summary of the experimental results for GPT-4 with a time horizon of 100 time steps.  It shows several key statistics for various LLM configurations, including median reward, suffix failure frequency, minimum fraction (an indicator of uniform-like failures), and greedy fraction.  The configurations are systematically varied across different prompt designs, allowing for comparison of how different prompt choices impact performance. The \"fails\" row indicates whether any of the replicates failed to complete successfully. This table helps in understanding which configurations exhibited successful exploration behavior (i.e., those with high reward and low failure rates).", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_23_1.jpg", "caption": "Figure 11: GPT-4 for T = 100: the per-configuration summary tables. The \"fails\" row indicates that all replicates completed successfully.", "description": "This table summarizes the results of experiments using GPT-4 with different prompt designs in a multi-armed bandit (MAB) task with time horizon T=100.  Each row represents a different prompt configuration, and includes metrics such as median reward, suffix failure frequency (SuffFailFreq(T/2)), the minimum fraction of times the least played arm was selected (K*MinFrac), the fraction of rounds the greedy algorithm was mimicked (GreedyFrac), and the number of replicates.  The \"fails\" row indicates if all replicates succeeded in finding the optimal arm.  The table provides a quantitative comparison of the performance of different prompt designs in promoting successful exploration in the MAB task.", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_24_1.jpg", "caption": "Figure 11: GPT-4 for T = 100: the per-configuration summary tables. The \"fails\" row indicates that all replicates completed successfully.", "description": "This table summarizes the results of experiments using GPT-4 with different prompt configurations on a multi-armed bandit (MAB) problem.  For each configuration, it shows the median reward, suffix failure frequency (SuffFailFreq(T/2)), the minimum fraction of times each arm was chosen (K*MinFrac), and the fraction of times the greedy algorithm was used (GreedyFrac). It also indicates the number of replicates for each configuration.  The \"fails\" row shows whether any replicates failed to complete.", "section": "3 Experimental results"}, {"figure_path": "OWPzhVqIux/tables/tables_25_1.jpg", "caption": "Figure 16: LLAMA2 for T = 100: the per-configuration summary tables. The buttons scenario, hard MAB instance.", "description": "This table presents a summary of the experimental results for LLAMA2 on the hard multi-armed bandit (MAB) instance using the buttons scenario.  It shows the median reward achieved by each of the 32 LLM configurations, along with the suffix failure frequency at T/2, the minimum fraction of times each arm is chosen (K*MinFrac), and the fraction of greedy rounds (GreedyFrac).  The results highlight the relative performance of various prompt designs and their impact on exploration behavior in the context of LLMs. The table also includes the number of replicates used for each configuration.", "section": "3.1 Identifying failures"}, {"figure_path": "OWPzhVqIux/tables/tables_26_1.jpg", "caption": "Figure 16: LLAMA2 for T = 100: the per-configuration summary tables. The buttons scenario, hard MAB instance.", "description": "This table summarizes the results of experiments using LLAMA2 on a hard multi-armed bandit problem with a time horizon of 100.  It shows various performance metrics for different prompt designs, including the median reward, the frequency of suffix failures (where the best arm is never selected in the latter half of the rounds), the minimum fraction of times each arm was chosen, and the fraction of times a greedy approach (choosing the current best arm) was used.  The goal is to assess the exploration capabilities of LLAMA2 under different prompt configurations.", "section": "3.2 Investigating successes"}, {"figure_path": "OWPzhVqIux/tables/tables_28_1.jpg", "caption": "Figure 4: GPT-4 for T = 100: a per-configuration summary table on the hard MAB instance with N = 10 replicates. Only three GPT-4 configurations do not exhibit suffix failures; two of these (BNRND and BSSCD) exhibit uniform-like failures. The final configuration (BSSCO) succeeds.", "description": "This table summarizes the results of experiments using GPT-4 on a 5-armed bandit problem with a reward gap of 0.2.  It shows the performance of various prompt configurations across several key metrics, including median reward, suffix failure frequency, uniform failure frequency, and the frequency of greedy choices. The table highlights that only one configuration (BSSCO) achieves satisfactory exploratory behavior, while others suffer from suffix failures (where the best arm is not selected after a certain point) or uniform-like failures (where all arms are selected nearly equally).", "section": "3.1 Identifying failures"}]