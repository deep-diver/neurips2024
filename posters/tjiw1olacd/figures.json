[{"figure_path": "TJiw1oLAcD/figures/figures_1_1.jpg", "caption": "Figure 1: Active viewpoint selection framework. Our proposed method iteratively selects viewpoints from the unknown set to form a small yet informative observation set, enabling effective training with fewer images. The active viewpoint selection strategy evaluates the information gain of the unknown viewpoints using the predicted images and selects the viewpoint with the maximum information gain as the next observation. The real image of the selected viewpoint is then added to the observation set, and this process continues until the observation set reaches a predefined size.", "description": "This figure illustrates the active viewpoint selection framework proposed in the paper.  The process starts with a multi-viewpoint dataset divided into an observation set (known viewpoints) and an unknown set (unknown viewpoints). The model predicts images from the unknown set based on the known images in the observation set. A selection strategy compares the object-centric representations of known and predicted images, choosing the viewpoint with the highest information gain (largest disparity). This chosen viewpoint's image is added to the observation set, and the process repeats until a sufficient number of viewpoints are included in the observation set, improving the model's training effectiveness and efficiency.", "section": "3 Method"}, {"figure_path": "TJiw1oLAcD/figures/figures_3_1.jpg", "caption": "Figure 2: Model architecture overview. Given the observation set O, model learns viewpoint-independent object-centric representations S'prev from Multi-Viewpoint Slot Attention and viewpoint representations Sview from Viewpoint Encoder. These representations are concatenated and input into the Diffusion-base Decoder to reconstruct the observation set. For the unknown set P, model obtains viewpoint representations Spiew from Viewpoint Encoder. Sprev and Spiew are concatenated and input into the Diffusion-base Decoder to predict images. The object representations Snew are obtained from the predicted image and compared with Sprev to evaluate the information gain of the unknown viewpoint. The viewpoint with the maximum information gain is selected and its corresponding real image xsel is added to the observation set.", "description": "This figure illustrates the architecture of the proposed AVS model, which consists of a Multi-Viewpoint Object-Centric Learning Model and an Active Viewpoint Selection Strategy. The model learns viewpoint-independent object-centric representations from an observation set of images and uses these representations to predict images from an unknown set. The active viewpoint selection strategy iteratively selects viewpoints from the unknown set that maximize the information gain, adding them to the observation set to improve the model's performance. The process continues until a predefined number of viewpoints are in the observation set.", "section": "3 Method"}, {"figure_path": "TJiw1oLAcD/figures/figures_7_1.jpg", "caption": "Figure 3: Visualization of segmentation results on CLEVRTEX and GSO.", "description": "This figure visualizes the qualitative results of unsupervised object segmentation on two datasets, CLEVRTEX and GSO. It compares the ground truth segmentation with the results produced by different methods including SIMONe, OCLOC, LSD, and the proposed AVS model with both random and active viewpoint selection strategies. The visualization helps in understanding the performance of each method in terms of accuracy and detail in segmenting objects within complex scenes.", "section": "4.1 Unsupervised Object Segmentation"}, {"figure_path": "TJiw1oLAcD/figures/figures_8_1.jpg", "caption": "Figure 4: Visualization of reconstruction results on CLEVRTEX, GSO, and ShapeNet.", "description": "This figure visualizes the scene reconstruction results on three different datasets: CLEVRTEX, GSO, and ShapeNet.  For each dataset, it shows ground truth images and reconstruction results from four different methods: SIMONe, OCLOC, LSD, and the proposed AVS (Active Viewpoint Selection) model. The figure demonstrates the superior reconstruction quality of the AVS model compared to baseline methods, particularly in capturing fine details and producing clearer, more realistic images.", "section": "4.2 Scene Reconstruction"}, {"figure_path": "TJiw1oLAcD/figures/figures_8_2.jpg", "caption": "Figure 5: Multi-viewpoint compositional generation samples and interpolation.", "description": "This figure visualizes the results of compositional generation and interpolation using the proposed model.  The top row shows multi-viewpoint generation, demonstrating the model's ability to generate images of the same scene from multiple viewpoints using different timesteps as viewpoint annotations. The bottom row shows interpolation, expanding the range of timesteps to generate a smoother sequence of images representing novel viewpoints between the initial set of viewpoints.", "section": "4.3 Compositional Generation"}, {"figure_path": "TJiw1oLAcD/figures/figures_9_1.jpg", "caption": "Figure 6: Novel viewpoint synthesis results on CLEVRTEX and GSO.", "description": "This figure visualizes the novel viewpoint synthesis results of the proposed AVS model on two datasets, CLEVRTEX and GSO.  For each dataset, the top row shows the ground truth images from multiple viewpoints. The middle row shows the reconstruction images generated by the model, and the bottom row displays the segmentation masks predicted by the model for the synthesized images. Red boxes highlight the newly predicted viewpoints by the model.", "section": "4.4 Novel Viewpoint Synthesis"}, {"figure_path": "TJiw1oLAcD/figures/figures_15_1.jpg", "caption": "Figure 7: Multi-Viewpoint image editing. Our model enables object manipulation across different viewpoints, including object removal, insertion, and swapping. In the figure, yellow arrows indicate objects randomly selected for manipulation, red arrows indicate objects removed from the scene, and blue arrows point to newly inserted objects from another scene.", "description": "This figure shows the results of image editing experiments using the proposed multi-viewpoint object-centric learning model.  The model demonstrates its ability to manipulate objects across multiple viewpoints (removal, insertion, and swapping) while maintaining consistency and accurately rendering occluded areas and object shadows.  The arrows indicate the manipulation actions.", "section": "D.1 Multi-Viewpoint Image Editing"}, {"figure_path": "TJiw1oLAcD/figures/figures_16_1.jpg", "caption": "Figure 3: Visualization of segmentation results on CLEVRTEX and GSO.", "description": "This figure visualizes the qualitative results of unsupervised object segmentation on the CLEVRTEX and GSO datasets.  It compares the ground truth segmentations (GT) to the segmentations produced by various methods: SIMONe, OCLOC, LSD, and the authors' proposed method (both random and active viewpoint selection).  The visualization shows that the authors' active viewpoint selection method produces segmentations that are more accurate and detailed than the other methods, especially in capturing the fine-grained textures and details of objects.", "section": "4.1 Unsupervised Object Segmentation"}, {"figure_path": "TJiw1oLAcD/figures/figures_16_2.jpg", "caption": "Figure 3: Visualization of segmentation results on CLEVRTEX and GSO.", "description": "This figure visualizes the qualitative results of unsupervised object segmentation on the CLEVRTEX and GSO datasets.  It shows ground truth segmentations alongside the results produced by different methods, including SIMONe, OCLOC, LSD, and the proposed AVS model (both with random and active viewpoint selection). The visualizations allow for a direct comparison of the segmentation accuracy and quality of the different approaches.", "section": "4.1 Unsupervised Object Segmentation"}, {"figure_path": "TJiw1oLAcD/figures/figures_17_1.jpg", "caption": "Figure 3: Visualization of segmentation results on CLEVRTEX and GSO.", "description": "This figure visualizes the qualitative results of unsupervised object segmentation on two datasets: CLEVRTEX and GSO.  For each dataset, it shows the ground truth segmentation (GT) and the segmentation results produced by several methods (SIMONE, OCLOC, LSD, Ours (Random), Ours (Active)).  The visualization allows for a visual comparison of the different methods' performance in terms of accuracy and detail in segmenting objects within complex scenes.", "section": "4.1 Unsupervised Object Segmentation"}, {"figure_path": "TJiw1oLAcD/figures/figures_17_2.jpg", "caption": "Figure 11: Novel viewpoint synthesis results on CLEVRTEX.", "description": "This figure visualizes the novel viewpoint synthesis results of the proposed model, AVS, on the CLEVRTEX dataset.  The top row shows the ground truth images from various viewpoints (timesteps t=1 to 12), followed by the reconstruction results.  The bottom row displays the segmentation results from the predicted images. Red boxes highlight the predicted images from unknown viewpoints.  The figure demonstrates the model's ability to accurately predict images and segment objects from novel viewpoints, showcasing its capacity for viewpoint synthesis.", "section": "4.4 Novel Viewpoint Synthesis"}, {"figure_path": "TJiw1oLAcD/figures/figures_18_1.jpg", "caption": "Figure 6: Novel viewpoint synthesis results on CLEVRTEX and GSO.", "description": "This figure visualizes the novel viewpoint synthesis capabilities of the proposed AVS model on two datasets, CLEVRTEX and GSO.  It demonstrates the model's ability to generate images from viewpoints not included in the training data. The top row shows the ground truth images for each viewpoint. The middle row displays the model's reconstruction of these images.  The bottom row presents the generated images from novel viewpoints.  Red boxes highlight the generated images. The results indicate that the model successfully synthesizes images and segmentation masks from novel viewpoints, showing a good grasp of object relationships and scene context.", "section": "4.4 Novel Viewpoint Synthesis"}, {"figure_path": "TJiw1oLAcD/figures/figures_19_1.jpg", "caption": "Figure 6: Novel viewpoint synthesis results on CLEVRTEX and GSO.", "description": "This figure shows the results of novel viewpoint synthesis on two datasets, CLEVRTEX and GSO.  For each dataset, there are two rows of images. The top row shows the ground truth images from various viewpoints, with corresponding segmentation masks below. The bottom row displays the images generated by the model from viewpoints not included in the training data.  Red boxes highlight the predicted segmentation mask for each image.  The experiment aims to demonstrate the model's ability to accurately predict and segment images from novel viewpoints, using only object-centric representations from known viewpoints.", "section": "4.4 Novel Viewpoint Synthesis"}]