[{"figure_path": "hE6ZxU0N3c/figures/figures_0_1.jpg", "caption": "Figure 1: Prediction results of our PartCLIPSeg for unseen categories in the Pascal-Part-116 [7, 46] validation set. A \u201cdog\u201d is unseen during training. The final prediction of PartCLIPSeg utilizes (b) object-level context and (c) generalized parts, incorporating disjoint activation among (e)\u2013(i) parts, and enhancing activation for smaller parts (e.g., (h) \u201cnose\u201d).", "description": "This figure shows the prediction results of the PartCLIPSeg model on unseen categories from the Pascal-Part-116 dataset.  The image shows a dog, which was not seen during training. The model successfully segments the dog into several parts (head, torso, ear, nose, paw) by incorporating both object-level context and generalized parts. Note that the model successfully handles the smaller part (nose) despite the intricate boundaries and diversity of the granularity.", "section": "Introduction"}, {"figure_path": "hE6ZxU0N3c/figures/figures_1_1.jpg", "caption": "Figure 2: Limitations of existing OVPS methods in predicting unseen categories. (a) Lack of generalization: Classification of a \u201cdog's parts\u201d involving categories like \u201ccats\u201d and \u201csheep\u201d, \u201cdog's tail\u201d misclassified as \u201csheep's ear\u201d. (VLPart [40]) (b) Ambiguous boundaries: Vague boundary output of \u201caeroplane's body\u201d. (c) Missing underrepresented parts: Neglecting parts such as \u201cbeak\u201d and \u201cleg\u201d. (CLIPSeg [32, 46]).", "description": "This figure illustrates three major limitations of existing open-vocabulary part segmentation (OVPS) methods. (a) shows the lack of generalization ability, where the model misidentifies parts of a novel object as parts of other objects. For example, a dog's tail is misclassified as a sheep's ear. (b) highlights the ambiguous boundaries issue, where the predicted part boundaries are vague and overlap with other parts, such as the aeroplane's body overlapping with other components. (c) demonstrates the problem of missing underrepresented parts, where the model fails to predict smaller parts, such as a bird's beak and leg.", "section": "1 Introduction"}, {"figure_path": "hE6ZxU0N3c/figures/figures_3_1.jpg", "caption": "Figure 3: The overall architecture of PartCLIPSeg. The embeddings derived from the object category name and the part category name are conditioned using the FiLM operation. Each embedding, modified through attention control, is subsequently reconstructed to predict the final object-specific part results.", "description": "This figure illustrates the architecture of PartCLIPSeg, a novel framework for open-vocabulary part segmentation. It shows how object and part embeddings are generated using CLIP, modulated by FiLM, and processed through a transformer decoder and attention control mechanisms to produce object-specific part segmentations.  Generalized parts with object-level contexts are used to address challenges in generalization, and attention control addresses ambiguity in part boundaries and under-represented parts. The overall process integrates object-level and part-level information to improve the accuracy and detail of the segmentation results.", "section": "3 Methodology"}, {"figure_path": "hE6ZxU0N3c/figures/figures_5_1.jpg", "caption": "Figure 4: Example of attention control using separation and enhance losses. The proposed method manipulates attention maps to accurately identify and segment small parts.", "description": "This figure illustrates the attention control mechanism in PartCLIPSeg, designed to address ambiguity in part boundaries and the omission of small parts. It shows how the method uses separation and enhancement losses to refine attention maps.  The separation loss (Lsep) minimizes overlaps between predicted parts, while the enhancement loss (Lenh) boosts the activation of underrepresented parts. The result is a refined segmentation where small parts are more accurately identified and segmented, even those that might be close to larger parts.", "section": "3.3 Attention Control for Ambiguity and Omission"}, {"figure_path": "hE6ZxU0N3c/figures/figures_8_1.jpg", "caption": "Figure 1: Prediction results of our PartCLIPSeg for unseen categories in the Pascal-Part-116 [7, 46] validation set. A \u201cdog\u201d is unseen during training. The final prediction of PartCLIPSeg utilizes (b) object-level context and (c) generalized parts, incorporating disjoint activation among (e)\u2013(i) parts, and enhancing activation for smaller parts (e.g., (h) \u201cnose\u201d).", "description": "This figure shows the prediction results of the PartCLIPSeg model on unseen categories from the Pascal-Part-116 dataset.  The model successfully segments various parts of a dog, even though the 'dog' category was not seen during training. It demonstrates the model's ability to leverage both object-level context and generalized parts to achieve accurate and detailed part segmentation, particularly highlighting its capability to handle smaller parts such as the nose.", "section": "Introduction"}, {"figure_path": "hE6ZxU0N3c/figures/figures_9_1.jpg", "caption": "Figure 1: Prediction results of our PartCLIPSeg for unseen categories in the Pascal-Part-116 [7, 46] validation set. A \u201cdog\u201d is unseen during training. The final prediction of PartCLIPSeg utilizes (b) object-level context and (c) generalized parts, incorporating disjoint activation among (e)\u2013(i) parts, and enhancing activation for smaller parts (e.g., (h) \u201cnose\u201d).", "description": "This figure shows the prediction results of the PartCLIPSeg model for unseen categories in the Pascal-Part-116 dataset.  The model successfully segments parts of a dog, an unseen category during training, by combining object-level context and generalized parts information.  The figure highlights the model's ability to handle different granularity levels and to distinguish between overlapping parts. ", "section": "Introduction"}, {"figure_path": "hE6ZxU0N3c/figures/figures_17_1.jpg", "caption": "Figure A1: Example of part annotations in PartImageNet on our experiment.", "description": "This figure shows a comparison between the ground truth part annotations and the result from the PartCLIPSeg model for a goldfish image from the PartImageNet dataset.  The ground truth shows distinct segmentation masks for the goldfish's body, head, fin, and tail. The PartCLIPSeg result shows that the model accurately segments these parts, although with some minor discrepancies in the boundary regions. This figure illustrates the model's ability to perform accurate part segmentation on unseen categories, even when dealing with fine-grained details.", "section": "B.2 Implementation Details"}, {"figure_path": "hE6ZxU0N3c/figures/figures_19_1.jpg", "caption": "Figure 4: Example of attention control using separation and enhance losses. The proposed method manipulates attention maps to accurately identify and segment small parts.", "description": "This figure shows an example of how the attention control mechanism in PartCLIPSeg helps in accurately identifying and segmenting small parts.  The left side illustrates the results without attention control, showing ambiguities and missed small parts (e.g., the dog's tail). The right side shows the results with the attention control, showcasing improved segmentation, clearly defining even small parts like the tail and paws, and minimizing overlaps between parts.", "section": "3.3 Attention Control for Ambiguity and Omission"}, {"figure_path": "hE6ZxU0N3c/figures/figures_20_1.jpg", "caption": "Figure 3: The overall architecture of PartCLIPSeg. The embeddings derived from the object category name and the part category name are conditioned using the FiLM operation. Each embedding, modified through attention control, is subsequently reconstructed to predict the final object-specific part results.", "description": "This figure presents the architecture of the PartCLIPSeg model, which uses a modified CLIPSeg encoder-decoder architecture. It shows how object and part embeddings are generated using a FiLM (Feature-wise Linear Modulation) operation, and how attention control is applied to refine the prediction of object-specific parts. The model leverages both generalized part information and object-level contexts to achieve robust multi-granularity segmentation.", "section": "3. Methodology"}, {"figure_path": "hE6ZxU0N3c/figures/figures_21_1.jpg", "caption": "Figure 1: Prediction results of our PartCLIPSeg for unseen categories in the Pascal-Part-116 [7, 46] validation set. A \u201cdog\u201d is unseen during training. The final prediction of PartCLIPSeg utilizes (b) object-level context and (c) generalized parts, incorporating disjoint activation among (e)\u2013(i) parts, and enhancing activation for smaller parts (e.g., (h) \u201cnose\u201d).", "description": "This figure shows the prediction results of the PartCLIPSeg model on unseen categories from the Pascal-Part-116 dataset.  The model successfully segments various parts of a dog, an object not seen during training. It leverages both object-level context and generalized parts, resulting in accurate segmentation, especially for smaller parts like the nose, despite the inherent ambiguity of part boundaries and variations in granularity.", "section": "Introduction"}, {"figure_path": "hE6ZxU0N3c/figures/figures_22_1.jpg", "caption": "Figure 1: Prediction results of our PartCLIPSeg for unseen categories in the Pascal-Part-116 [7, 46] validation set. A \u201cdog\u201d is unseen during training. The final prediction of PartCLIPSeg utilizes (b) object-level context and (c) generalized parts, incorporating disjoint activation among (e)\u2013(i) parts, and enhancing activation for smaller parts (e.g., (h) \u201cnose\u201d).", "description": "This figure showcases the results of PartCLIPSeg on unseen categories from the Pascal-Part-116 dataset.  The model successfully segments different parts of a dog (an unseen class) by combining object-level context with generalized part predictions. The final segmentation highlights the model's ability to handle different granularities and accurately identify smaller parts, such as the nose.", "section": "Introduction"}]