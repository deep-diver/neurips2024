[{"figure_path": "eWiGn0Fcdx/tables/tables_7_1.jpg", "caption": "Table 1: Classification results of different models on ImageNet-1K. We compare the proposed token pruning method with existing methods under comparable GFLOPs.", "description": "This table presents the results of image classification experiments conducted on the ImageNet-1K dataset.  It compares various vision transformer models (ViT, DeiT, ViM, PlainMamba) and their performance after applying different token pruning methods (EViT and the proposed TOP method).  The table shows the model size (image size, parameters, and FLOPs), along with the top-1 accuracy achieved. This allows for a direct comparison of the efficiency gains (FLOP reduction) obtained by each pruning method, while maintaining classification accuracy.", "section": "5.1 Image Classification on ImageNet-1K"}, {"figure_path": "eWiGn0Fcdx/tables/tables_7_2.jpg", "caption": "Table 1: Classification results of different models on ImageNet-1K. We compare the proposed token pruning method with existing methods under comparable GFLOPs.", "description": "This table presents the comparison of top-1 accuracy and GFLOPs for various models on the ImageNet-1K dataset.  It compares different Vision Transformers (ViTs) and State Space Models (SSMs), both with and without the proposed token pruning method (ToP) and a baseline ViT token pruning method (EViT). The table shows the impact of different pruning strategies on model performance and computational efficiency.", "section": "5.1 Image Classification on ImageNet-1K"}, {"figure_path": "eWiGn0Fcdx/tables/tables_8_1.jpg", "caption": "Table 3: Semantic Segmentation", "description": "This table presents the results of semantic segmentation on the ADE20K dataset.  It compares the mean Intersection over Union (mIoU) achieved by several different models, including various sizes of ViM and PlainMamba, and their corresponding versions with token pruning using the EViT method and the proposed ToP method.  The purpose is to show the effectiveness of the proposed token pruning method for achieving comparable performance with significantly reduced computational cost.", "section": "5.3 Semantic Segmentation on ADE20K"}, {"figure_path": "eWiGn0Fcdx/tables/tables_8_2.jpg", "caption": "Table 5: Comparison of w/o and w/ our alignment (both using Eq. (9) as token importance metric).", "description": "This table presents a quantitative comparison of the proposed token pruning method with and without the pruning-aware hidden state alignment.  It shows the FLOPs, Top-1 accuracy, and throughput for two models, ViM-S and PlainMamba-L3, under different conditions: dense (no pruning), pruning without alignment, and pruning with alignment.  The results highlight the effectiveness of the proposed alignment technique in maintaining accuracy while reducing FLOPs and improving throughput.", "section": "5.4.2 Quantitative Evaluation of pruning-aware hidden state alignment"}, {"figure_path": "eWiGn0Fcdx/tables/tables_8_3.jpg", "caption": "Table 4: Ablation study of token importance metric with pruning-aware hidden state alignment", "description": "This table presents the ablation study of different token importance metrics used in the proposed token pruning method. It compares the performance of using l1-norm, l2-norm, unclipped values (w/o Clip), and the proposed clipping method (Clip) for two different models, ViM-S and L3. The results show that the proposed clipping method consistently achieves higher accuracy than the other methods, suggesting its effectiveness in mitigating the adverse effects of extreme token importance values.", "section": "5.4 Ablation & Analysis"}]