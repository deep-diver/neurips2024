[{"figure_path": "SRWs2wxNs7/figures/figures_1_1.jpg", "caption": "Figure 1: Comparing U-DiTs with DiTs and their improvements. We plot FID-50K versus denoiser GFLOPs (in log scale) after 400K training steps. U-DiTs could achieve better performance than its counterparts.", "description": "This figure compares the performance of U-DiTs (U-shaped Diffusion Transformers) with DiTs (Diffusion Transformers) and their variations across different model sizes. The x-axis represents the computational cost (GFLOPs) of the denoising models, and the y-axis represents the Fr\u00e9chet Inception Distance (FID) score, a metric for evaluating the quality of generated images. Lower FID values indicate better image generation quality. The plot shows that U-DiTs consistently achieve lower FID scores compared to DiTs and other related methods at similar computational costs, suggesting superior efficiency and performance.", "section": "1 Introduction"}, {"figure_path": "SRWs2wxNs7/figures/figures_1_2.jpg", "caption": "Figure 2: The performance of U-DiTs and DiTs of various size. U-DiTs perform consistently better than DiTs with the increase of training steps. The marker size represents the computation cost of the model qualitatively.", "description": "This figure compares the performance of U-DiTs and DiTs of different sizes over various training iterations.  The y-axis represents the FID-50K score, a lower score indicating better image generation quality. The x-axis shows the number of training iterations in thousands. Different colored lines represent different model sizes (U-DiT-B, U-DiT-L, DiT-B/2, DiT-L/2, and DiT-XL/2). The size of the markers on the lines corresponds to the model's computational cost, larger markers representing more computationally expensive models.  The results demonstrate that U-DiTs consistently outperform DiTs across all sizes and training steps.", "section": "4 Scaling the Model Up"}, {"figure_path": "SRWs2wxNs7/figures/figures_2_1.jpg", "caption": "Figure 3: The evolution from the DiT to the proposed U-DiT. Left (a): the original DiT, which uses an isotropic architecture. Middle (b): DiT-UNet, which is a plain U-Net-style DiT. We try this as a simple combination of DiT and U-Net in the toy experiment. Right (c): the proposed U-DiT. We propose to downsample the input features for self-attention. The downsampling operation could amazingly improve DiT-UNet with a huge cut on the amount of computation.", "description": "This figure illustrates the architectural evolution from the original Diffusion Transformer (DiT) to the proposed U-shaped DiT (U-DiT).  It starts with the isotropic DiT (a), which uses a standard transformer architecture. It then shows DiT-UNet (b), a simple attempt to integrate the U-Net architecture with DiT blocks.  Finally, it presents the U-DiT (c), which incorporates downsampled tokens in the self-attention mechanism for computational efficiency and performance improvement. The key difference is the introduction of a downsampler in U-DiT, leading to improved efficiency and performance compared to DiT-UNet.", "section": "3 Investigating U-Net DiTs in Latent"}, {"figure_path": "SRWs2wxNs7/figures/figures_6_1.jpg", "caption": "Figure 4: Quality improvements of generated samples as training continues. We sample from U-DiT models trained for different numbers of iterations on ImageNet 256\u00d7256. More training does improve generation quality. Best viewed on screen.", "description": "This figure shows the visual quality of images generated by U-DiT models at various training iterations (200k, 400k, 600k, 800k).  Each row represents a different object class, demonstrating how the model's generation quality improves with increased training. The improvement in detail, sharpness, and overall realism is clearly noticeable as the training iterations increase.", "section": "4 Scaling the Model Up"}, {"figure_path": "SRWs2wxNs7/figures/figures_9_1.jpg", "caption": "Figure 5: Generated samples by U-DiT-L at 1M iterations. It is astonishing that U-DiT could achieve authentic visual quality at merely 1 Million training steps. Best viewed on screen.", "description": "This figure shows various images generated by the U-DiT-L model after being trained for 1 million iterations.  The images demonstrate the model's ability to generate high-quality, realistic images of diverse subjects, including animals, objects, and scenes, highlighting the model's capability even with relatively fewer training steps compared to other models.", "section": "4 Scaling the Model Up"}]