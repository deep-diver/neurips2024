[{"type": "text", "text": "SARAD: Spatial Association-Aware Anomaly Detection and Diagnosis for Multivariate Time Series ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhihao Dai Department of Computer Science University of Warwick Coventry, UK zhihao.dai@warwick.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Ligang He\u2217   \nDepartment of Computer Science   \nUniversity of Warwick   \nCoventry, UK   \nligang.he@warwick.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Shuang-Hua Yang Department of Computer Science University of Reading Reading, UK shuang-hua.yang@reading.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Matthew Leeke   \nSchool of Computer Science   \nUniversity of Birmingham   \nBirmingham, UK   \nm.leeke@bham.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anomaly detection in time series data is fundamental to the design, deployment, and evaluation of industrial control systems. Temporal modeling has been the natural focus of anomaly detection approaches for time series data. However, the focus on temporal modeling can obscure or dilute the spatial information that can be used to capture complex interactions in multivariate time series. In this paper, we propose SARAD, an approach that leverages spatial information beyond data autoencoding errors to improve the detection and diagnosis of anomalies. SARAD trains a Transformer to learn the spatial associations, the pairwise inter-feature relationships which ubiquitously characterize such feedback-controlled systems. As new associations form and old ones dissolve, SARAD applies subseries division to capture their changes over time. Anomalies exhibit association descending patterns, a key phenomenon we exclusively observe and attribute to the disruptive nature of anomalies detaching anomalous features from others. To exploit the phenomenon and yet dismiss non-anomalous descent, SARAD performs anomaly detection via autoencoding in the association space. We present experimental results to demonstrate that SARAD achieves state-of-the-art performance, providing robust anomaly detection and a nuanced understanding of anomalous events. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Time series anomaly detection is critical for industrial automation (Rieth et al., 2018), intrusion detection (Mathur and Tippenhauer, 2016), and healthcare sensing (Goldberger et al., 2000). Anomaly detection in these contexts is typically treated as an unsupervised learning problem, owing to the novelty of anomalies and the scarcity of labeled anomalies. ", "page_idx": 0}, {"type": "text", "text": "Temporal modeling is the mainstream basis of current time series anomaly detectors. By learning the dependencies between discrete time steps, temporal modeling can pinpoint the time spans of anomalies. During anomalies, unseen and peculiar temporal dependence patterns degrade data autoencoding (Wang et al., 2023b) or autoregression (Zhao et al., 2020) performance, thereby enabling detection. Alternatively, irregular temporal representations can be driven to breach learned enclosing ", "page_idx": 0}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/abc2bd2f0acc8bd41724072125b0505d7c6657f2691194c7bde1c20f47a26187.jpg", "img_caption": ["(a) Raw time series before, during, and after an anomaly $p_{i}$ . "], "img_footnote": [], "page_idx": 1}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/dcfefff95ae594daf7ce569c0cffd4712d9dde120e5b942be5e0734e1289fabb.jpg", "img_caption": ["(b) Pre-pi\u2019s A. (c) In-pi\u2019s A. (d) Post- $p_{i}$ \u2019s A. (e) Pre-reduction.(f) Post-reduction. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: Spatial associations captured by Transformer on a service monitoring benchmark. 1a shows the raw time series right before, during, and after an anomaly (colored in red). Association mapping $A_{h}^{L}$ by final $L$ -th layer\u2019s MHSA are averaged across heads to derive $\\pmb{A}$ before (1b), during (1c), and after (1d) the anomaly. Darker cells have larger values. Anomalous features (#12 and $\\#15$ ) are highlighted with red bounding boxes. The reduction-only changes from before or after the anomaly to during the anomaly are shown in 1e and 1f, i.e., ReLU $\\mathbf{\\bar{A}}_{\\mathrm{pre}}-\\mathbf{A}_{\\mathrm{in}})$ and ReLU $(A_{\\mathrm{post}}-A_{\\mathrm{in}})$ . The anomaly leads to association reductions on anomalous features, prominently column-wise on $\\pmb{A}$ . ", "page_idx": 1}, {"type": "text", "text": "hyperspheres (Shen et al., 2020), resulting in high anomaly scores that enable detection. Despite its temporal precision in anomaly detection, temporal modeling either assumes feature independence or combines variables of diverse physical nature, the former simplifying the modeling and the latter mitigating the multicollinearity issue. Such assumptions lead to either omission or dilution of spatial information crucial to anomaly detection. Specifically, it overlooks the long-time-range spatial associations, the relationships between various features which ubiquitously characterize normal behaviors of multivariate time series. Where anomaly detection pinpoints the temporal locations of an anomaly, anomaly diagnosis identifies the spatial locations, i.e., the anomalous feature set, of an anomaly. Temporal methods also restrict diagnostic capabilities, as the lack of spatial information mismatches autoencoding-based or autoregression-based anomaly criterion, which de facto measures temporal novelty, with its objective of capturing spatial novelty. ", "page_idx": 1}, {"type": "text", "text": "Furthermore, time series anomalies frequently dissolve spatial associations, motivating anomaly detection in the association space. Using an vanilla Transformer (Vaswani et al., 2017), we investigate the changes in spatial associations throughout anomalies. Applied on transposed time windows (the spatial dimension comes before the temporal), an encoder-only Transformer is trained to minimize reconstruction errors on unlabeled $N$ -variate time series and, by doing so, learns to model the multivariate series spatially via the Multi-Head Self-Attention (MHSA) illustrated in Figure 2. MHSA at each stacked $l$ -th layer computes an intermediate association mapping $\\pmb{A}_{h}^{l}\\in\\mathbb{R}^{N\\times N}$ per $h$ -th head, mapping back input $\\mathcal{X}$ to produce attention scores. The last layer\u2019s mapping $A_{h}^{\\bar{L}}$ thus effectively captures the contributions of $k$ -th feature to the reconstruction of $j$ -th feature at each location $(j,k)$ , not least for its architectural proximity to the reconstructed output. Recent research (Liu et al., 2024) also highlights the important role MHSA plays in capturing the inter-feature associative relationships when applied on the multi-variate dimension. As new associations emerge and old ones dissolve over time, Figure 1 shows the association changes on a real-world benchmark. We observe that anomalies exhibit reductions for anomalous features, a phenomenon we herein coin as Spatial ", "page_idx": 1}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/b473c6742b6be2942a1f55fbc72176bcad3849aa0e53d543b759a240a0cd463f.jpg", "img_caption": ["Figure 2: MHSA. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Association Reduction (SAR). The rationale is that anomalies either originate from or result in dissolution of pre-existing associations, detaching anomalous features from their non-anomalous counterparts. Additionally, we make the observation that SAR is most prominent column-wise on $A_{h}^{L}$ , since each $j$ -th column characterizes the dropouts of $j$ from associating with other, mostly non-anomalous, features. Due to lack of explicit spatial information, temporal modeling is inadequate for exploiting SAR. More examples are given in Appendix C. ", "page_idx": 2}, {"type": "text", "text": "From a spatial modeling perspective, we propose SARAD to leverage spatial information and to exploit SAR for enabling robust time series anomaly detection and diagnosis. For quantifying anomalous spatial novelty in the data space, we train a Transformer on transposed time windows as an autoencoder. To capture the spatial association progression, the reduction-only changes of associations over time, the data reconstruction divides the input window by time into two halves to be processed in parallel. Consequently, the progression is the non-negative backward difference of the intermediate association mappings via MHSA. Subseries division circumvents memory storage of latest association mappings and enables time window shuffling during training, which reduces order bias, enhances generalization, and prevents catastrophic forgetting. For quantifying anomalous reduction novelty, we train a Multi-Layer Perceptron (MLP) as an antuencoder on progression in the association space. Whereas progression encompass all association reduction, autoencoding rules out those not caused by anomalies. The reconstruction errors via the data module measure data-only anomalous deviation from expected system behaviors and falter when such deviations are not prominent, e.g., at the start of an anomaly. The reconstruction errors via the progression module are sensitive to change in spatial associations, thus complementing the former. We develop a joint anomaly detection criterion that combines both. Experiments show SARAD delivers stateof-the-art detection and diagnosis performance with architectural elegance. Code is available at https://github.com/daidahao/SARAD/. We summarize our contributions as follows. ", "page_idx": 2}, {"type": "text", "text": "\u2022 We reveal and extract spatial association descending patterns of time series anomalies with a bespoke Transformer and subseries division. The former learns the pairwise inter-feature associations via autoencoding in the data space and the latter enables shuffled autoencoding training and memory-less progression aggregation.   \n\u2022 We propose progression autoencoding to quantify anomalous descent in the association space and a joint detection criterion in both data and association spaces, which complement each other.   \n\u2022 Experimentally, SARAD performs state-of-the-art anomaly detection and diagnosis on multivariate time series and ablation studies support our design choices. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Influenced by the dominance of temporal modeling in time series forecasting (Wang et al., 2023a; Zhang et al., 2023; Wu et al., 2021), temporal modeling is also prevalent in time series anomaly detection. Recurrent neural networks such as LSTM (Hochreiter and Schmidhuber, 1997) have innate capabilities for handling sequential data. These approaches use hidden states for past input memorization, enabling detection (Li et al., 2019; Malhotra et al., 2015) and diagnosis (Qian et al., 2021). Transformer (Vaswani et al., 2017) network is widely adopted (Fan et al., 2023; Xu et al., 2022) approach that is commonly applied to model temporal associations between different time points using its attention mechanism. Linear regression (Zeng et al., 2023) and MLP (Wang et al., 2024; Audibert et al., 2020) directly model temporal dependencies. TranAD (Tuli et al., 2022) replaces the MLP in Audibert et al. (2020) with a Transformer, making the detection criterion more robust through its adversarial training paradigm. Temporal modeling, however, is restricted by the exceptionally small receptive field in time and adversely impacted by the timestamp misalignment across features. In the context of anomaly detection, temporal modeling helps capture anomalous temporal associations (Xu et al., 2022; Yang et al., 2023), but offers limited detection capabilities in absence of spatial information. In a diagnostic context, temporal detectors mismatch anomaly criterion of temporal novelty with spatial interpretation. ", "page_idx": 2}, {"type": "text", "text": "Spatial associations characterize the multivariate time series commonly found in such supervisory systems for industrial control. The relationships range from strongly correlated, e.g., due to spatial proximity, to fully independent, e.g., due to mechanical disconnection. For forecasting, iTransformer (Liu et al., 2024) applies Transformer on the transposed time series to enable direct spatial modeling. Crossformer (Zhang and Yan, 2023) screens the time series through custom Two-Stage Attention layers for more efficient spatial modeling. In terms of detection, GDN (Deng and Hooi, 2021) learns a directed graph of features for the prediction of last time points, whose errors serve as anomaly scores. GDN is partially limited by a mismatch between its singe-timestamp prediction target and the prevalent range-wise anomalies as well as unstable Top-K node selection during training. InterFusion (Li et al., 2021) learns compressed spatial and temporal dependencies, using a hierarchical Variational Auto-Encoder (Kingma and Welling, 2014) to reconstruct the series. Neither inspects temporal changes in associations throughout anomalies. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "On another front, Isolation Forest (IF) models build a binary decision tree ensemble by partitioning either the data space (Liu et al., 2008) or the deep embedding space (Xu et al., 2023) formed by randomized neural networks. They are constrained by the lack of temporal and spatial (in the former case) or spatial (in the latter case) information, and their anomaly scores are not reflective of the degrees of anomalies. ", "page_idx": 3}, {"type": "text", "text": "We emphasize anomalous association descending patterns towards better time series detection and diagnosis. Different from previous work, we explicitly utilize the reduction in spatial associations over time during an anomaly, an insight we derived from the cyber-physical defense space. Dynamic watermarking (Satchidanandan and Kumar, 2017) and similar defense techniques (Dai et al., 2023) overlay actuation with private signals to reveal attacks resulting in correlational breakdowns. While their approaches are intrusive and actively alter system behaviors, our detector remains non-intrusive, passively monitors the spatial associations, and is applicable to any supervisory system. ", "page_idx": 3}, {"type": "text", "text": "We refer to spatiality in this work as the multi-dimensional vector nature inherent to multivariate time series data. The terminology is also used in literature on time series related tasks (Gangopadhyay et al., 2021; Zheng et al., 2023). We note that spatiality may carry different meanings in other AI contexts, such as geographic positions or characteristics on Earth. We differentiate those meanings from our definition of spatiality, which traces its root to the spatial distribution of sensors and actuators in control systems where time series are routinely collected. ", "page_idx": 3}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The problems of anomaly detection and diagnosis are specified as follows. ", "page_idx": 3}, {"type": "text", "text": "Anomaly Detection Given a $N$ -feature time series $\\mathcal{T}=\\{x^{1},\\cdots\\,,x^{N}\\}$ where $x^{n}\\in\\mathbb{R}^{T}$ is of the same length $T$ , the objective is to predict the anomaly label $y_{t}\\in\\{0,1\\}$ at each timestamp $t$ . ", "page_idx": 3}, {"type": "text", "text": "Anomaly Diagnosis Given the same time series $\\tau$ , the objective is to predict the diagnosis label $g_{t}\\subseteq[N]$ , the set of anomalous features at each timestamp $t$ . ", "page_idx": 3}, {"type": "text", "text": "3.1 Overview ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "SARAD comprises two sequential modules; a Transformer for time series data reconstruction and a MLP network for spatial progression reconstruction. Table 1 decomposes the system framework of SARAD. The Transformer temporally divides by 2 and reconstructs the input time series to learn pairwise inter-feature associations and to enable order-free memory-efficient progression aggregation. The MLP reconstructs the aggregated progression to quantify anomalous association reduction while dismissing non-anomalous reduction. Towards robust anomaly detection, reconstruction errors from the two modules jointly serve as a criterion, sensitive to data-only anomalous deviation and anomalous association reduction. ", "page_idx": 3}, {"type": "text", "text": "3.2 Data Reconstruction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In light of restricted capabilities of temporal detectors, here we adapt Transformer to spatially reconstruct the series data. The data module contains two components, Subseries Split & Merge and Subseries Reconstruction, shown in the first and second columns in Table 1. The former wraps around the second by temporally splitting a multivariate input series in half at its beginning and temporally merging at its end. Subseries division enables capturing of spatial progression within a single time window. Without the former, the model must store in memory the last association mappings at each step and keep to the time ordering during training, which is prone to overftiting and catastrophic forgetting. The latter is an encoder-only Transformer composed of an embedding layer, a $L$ -layer attention-based encoder, and finally a linear projection layer. Encoder-only Transformers are commonly found in Transformer-based detectors (Kang and Kang, 2024; Kim et al., 2023) due to its simplicity and the length uniformity of the target output, i.e., the reconstructed series. Ours exclusively models spatial associations, unconventional to the aforenamed detectors and most temporal forecasters (Nie et al., 2023; Zhou et al., 2022; Liu et al., 2022) and yet more aligned with recent spatial-aware forecasters (Liu et al., 2024; Zhang and Yan, 2023). At each encoding layer, MHSA computes pairwise association mappings, a representation of inter-feature dependencies which ubiquitously characterize the multivariate time series and are crucial to anomaly detection. ", "page_idx": 3}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/4a26870e47426c2ca00c08b121610b5f066a8f0ee7137ddbebee7ac37d63c25d.jpg", "table_caption": ["Table 1: SARAD is a composition of two modules and three components: data reconstruction (subseries split and merge, and subseries reconstruction) and spatial progression reconstruction. "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Subseries Split and Merge We suppose the input series is a time window $\\boldsymbol{X}\\in\\mathbb{R}^{2W\\times N}$ of length $2W$ , where 2 is for the convenience of a temporal split. Before reconstruction, $\\mathbf{\\deltaX}$ is split into two half multivariate subseries of equal temporal length: $\\pmb{X}=\\{\\pmb{X}_{1}\\in\\mathbb{R}^{W\\times N},\\pmb{X}_{2}\\in\\dot{\\mathbb{R}}^{W\\times N}\\}$ reconstructed After subseries reconstruction, the two reconstructed subseries are concatenated to form the full $\\hat{\\pmb X}=\\{\\hat{\\pmb X}_{1}\\in\\mathbb R^{\\hat{W}\\times N},\\hat{\\pmb X}_{2}\\in\\mathbb R^{W\\times N}\\}$ . ", "page_idx": 4}, {"type": "text", "text": "Embedding To lead subseries reconstruction, each $X_{i}$ is embedded as $\\pmb{\\chi}_{i}^{0}=\\pmb{E}_{i}+\\pmb{M}$ , wherein $\\pmb{E}_{i}=\\mathrm{Linear}(\\pmb{X}_{i}^{T})\\in\\mathbb{R}^{N\\times D}$ and $M=\\{\\pmb{m}_{i}\\in\\mathbb{R}^{D}|i\\in[N]\\}$ is a learnable feature-level embedding. ", "page_idx": 4}, {"type": "text", "text": "Spatial-Aware Encoding A stack of $L$ Transformer encoding layers is used to encode the series in the $D$ -length attention space. Each layer is stacked with MHSA and MLP with residual connections: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{i}^{l}=\\mathrm{LN}(\\mathrm{MHSA}(\\pmb{\\mathscr{X}}_{i}^{l-1})+\\pmb{\\mathscr{X}}_{i}^{l-1}),\\;\\pmb{\\mathscr{X}}_{i}^{l}=\\mathrm{LN}(\\mathrm{MLP}(\\pmb{\\mathscr{Z}}_{i}^{l})+\\pmb{\\mathscr{Z}}_{i}^{l})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\pmb{\\mathscr{X}}_{i}^{l-1},\\pmb{\\mathscr{Z}}_{i}^{l},\\pmb{\\mathscr{X}}_{i}^{l}\\in\\mathbb{R}^{N\\times D}$ are $l\\!-\\!1$ layer\u2019s output, $l_{\\cdot}$ -th layer\u2019s hidden state and output respectively and $L N(\\cdot)$ is Layer Normalization (Ba et al., 2016). It is spatial-aware because MHSA explicitly learns a pairwise inter-feature association mapping to exchange information in between feature representations. Notably within the MHSA with $H$ heads as shown in Figure 2, each $(j,k)$ -th element on the association mapping $A_{h}\\in\\mathbb{R}^{N\\times N}$ of its $h$ -th head computes how much $j$ -th feature\u2019s attention scores should originate from the $k$ -th feature\u2019s key. From a broader perspective of data reconstruction, it is the quantification of the residual impact of $k$ -th feature\u2019s originals on the $j$ -th feature\u2019s reconstructions. We refactor MHSA implementation to enable parallel encoding of subseries. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Linear Projection Output from the last encoding layer $\\pmb{\\chi}_{i}^{L}$ is linearly projected and transposed to derive the reconstructed subseries $\\hat{\\pmb{X}}_{i}\\in\\mathbb{R}^{W\\times N}$ . ", "page_idx": 5}, {"type": "text", "text": "3.3 Spatial Progression Reconstruction ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To exploit SAR caused by anomalies, the module first extracts and aggregates the spatial progression, the non-negative backward difference of the association mappings via MHSA. In line with general anomaly detectors (Aggarwal, 2013), the module conducts autoencoding in the association space to quantify anomalous SAR and to dismiss non-anomalous SAR. Anomalous SAR occurs when, say, a compromised sensor\u2019s readings are no longer correlating with its spatially adjacent or mechanically related counterparts. ", "page_idx": 5}, {"type": "text", "text": "Association Progression We define association progression $S_{h}^{l}\\in\\mathbb{R}^{N\\times N}$ at the $h$ -th attention head in the $l$ -th layer to be the non-negative backward difference in association mappings $\\{A_{1,h}^{l},A_{2,h}^{l}\\}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{S}_{h}^{l}=\\operatorname{ReLU}(\\pmb{A}_{1,h}^{l}-\\pmb{A}_{2,h}^{l})}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ${\\mathrm{ReLU}}(\\cdot)$ passes through only non-negative values and outputs zeros otherwise. ", "page_idx": 5}, {"type": "text", "text": "Progression Aggregation To center the detection on association dropouts, we aggregate the column sums of progression $S_{h}^{l}$ from all attention heads in the final $L$ -th layer to form $\\pmb{S}\\in\\mathbb{R}^{H\\times N}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pmb{\\mathcal{S}}=\\{\\sum_{j=1}^{N}S_{h,(j,k)}^{L}|h\\in[H],k\\in[N]\\}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We recall from the data module, each $k$ -th column in $A_{i,h}^{l}$ quantifies the impact of $k$ -th feature on all features\u2019 reconstruction. Taking the sum per each $k$ -th column, we measure with $_s$ the dropout rates of $k$ from participating all features\u2019 reconstruction. As we have observed in Section 1, SAR at the column level is indicative of time series anomalies, more so than at the row level. The last layer\u2019s progression is focused not least for its proximity to the final reconstructed output, whereafter no more information is exchanged between features. Liu et al. (2024) manifests that final layer\u2019s mappings resemble closely with the inter-feature correlations of the target, in our case, the reconstructed. ", "page_idx": 5}, {"type": "text", "text": "Autoencoding With $_s$ flattened as an one-dimensional vector, a 2-layer MLP is trained to output the reconstructed and reshaped $\\hat{\\pmb{S}}\\in\\mathbb{R}^{H\\times N}$ , synchronously with the data module training. ", "page_idx": 5}, {"type": "text", "text": "3.4 Joint Training and Anomaly Detection ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Training Objective We train an end-to-end model with a joint minimization objective: ", "page_idx": 5}, {"type": "equation", "text": "$$\nL_{R}=||\\hat{\\pmb{X}}-\\pmb{X}||_{2}^{2},\\,L_{S}=||\\hat{\\pmb{S}}-\\pmb{S}||_{2}^{2},\\,L=L_{R}+\\lambda_{L_{S}}L_{S}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $L_{R}$ is the data reconstruction loss, $L_{S}$ the progression reconstruction loss, and $\\lambda_{L_{S}}$ a weight hyper-parameter. Gradients are stopped from flowing into $_s$ to prevent updates to the data module and collapses in association representation. We are training two anomaly detectors simultaneously, one working in the original data space, the other in the spatial progression space. ", "page_idx": 5}, {"type": "text", "text": "Anomaly Detection Criterion For an input series $\\mathbf{\\deltaX}$ , the anomaly score $s$ is a scalar defined to be: ", "page_idx": 5}, {"type": "equation", "text": "$$\nr=||\\hat{\\boldsymbol X}-\\boldsymbol X||_{2}^{2},\\,p=||\\hat{\\boldsymbol S}-\\boldsymbol S||_{2}^{2},\\,s=(r-\\mu_{r})/\\sigma_{r}+(p-\\mu_{p})/\\sigma_{p}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $r$ is the data reconstruction error, $p$ the progression reconstruction error, $\\mu_{r},\\mu_{p}$ the means of $r,p$ on the validation set, and $\\sigma_{r},\\sigma_{p}$ the standard deviation of $r,p$ . The criterion takes into account the normalized errors in the data space and the progression space, each of which quantifies the anomalous magnitude in respective spaces and complment the other. ", "page_idx": 5}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/883e613afbd5b19c3cbd8bcf515bdd95cc6c0e8ae6afdc87f63d348f13a1078c.jpg", "table_caption": ["Table 2: Statistics of the main datasets. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Anomaly Diagnosis Criterion For an input series $\\mathbf{\\deltaX}$ and its $j$ -th feature, its anomaly score $s_{j}$ is a scalar defined to be: ", "page_idx": 6}, {"type": "equation", "text": "$$\ns_{j}=r_{j}=||\\hat{\\mathbf{X}}_{(j,\\cdot)}-\\mathbf{X}_{(j,\\cdot)}||_{2}^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $r_{j}$ is feature $j$ \u2019s data reconstruction error. The criterion is sensitive to spatial novelty. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "SARAD is compared against state-of-the-art detectors on real-world benchmarks for detection and diagnosis, the latter only when diagnostic labels are available. ", "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets We evaluate on four real-world datasets collected under industrial control and service monitoring settings. These dataset are: 1) Server Machine Dataset (SMD) (Su et al., 2019b,a), 2) Pooled Server Metrics (PSM) dataset (Abdulaal et al., 2021a,b) 3) Secure Water Treatment (SWaT) dataset (Mathur and Tippenhauer, 2016; iTrust, 2023), and 4) Hardware-In-the-Loop-based Augmented ICS (HAI) dataset (Shin et al., 2021b,a). All training sets contain only unlabeled data and the test sets contain data with anomaly labels. Anomalies range from service outages to external cyber-physical attacks. We summarize the statistics of the datasets in Table 2. Descriptions of each dataset are detailed in Appendix E. ", "page_idx": 6}, {"type": "text", "text": "Detection Metrics Real-world benchmarks are rife with range-wise anomalies spanning consecutive time points (Wagner et al., 2023). We use the range-based metrics proposed in (Paparrizos et al., 2022). Compared against their point-based counterparts, they provide robustness to labeling delay and scoring noises as well as performant detector separability and series consistency. We compute the threshold-independent AUC-ROC and AUC-PR scores to be rid of thresholding impact and fully parameter-free Volume Under the Surface (VUS) AUC-ROC and AUC-PR scores. Full details are discussed in Appendix I. ", "page_idx": 6}, {"type": "text", "text": "Diagnosis Metrics Consistent with previous works (Tuli et al., 2022; Zhao et al., 2020), we use common metrics such as Hit Rate (HR) (Su et al., 2019b) and Normalized Discounted Cumulative Gain (NDCG) (J\u00e4rvelin and Kek\u00e4l\u00e4inen, 2002) where diagnosis labels are available. At the range level, we measure the Interpretation Score (IPS) initially proposed in Li et al. (2021) and here expanded to fit the $P\\%$ parameterization. Full details are discussed in Appendix J. ", "page_idx": 6}, {"type": "text", "text": "Baselines We compare SARAD against state-of-the-art anomaly detection baselines, including Isolation Forest-based IF (Liu et al., 2008), Deep IF (DIF) (Xu et al., 2023); MLP-based USAD (Audibert et al., 2020); graph-based GDN (Deng and Hooi, 2021); LSTM-based MAD-GAN (Li et al., 2019); CNN-based DiffAD (Xiao et al., 2023); and Transformer-based TranAD (Tuli et al., 2022), ATF-UAD (Fan et al., 2023), AT (Xu et al., 2022), DCdetector (Yang et al., 2023). Noticeably, GDN employs explicit spatial modeling in its graph construction although spatial associations are not directly involved in anoamly scoring. MAD-GAN emphasizes on anomaly detection within cyber-physical systems. All baselines are trained using official implementations where available and recommended hyperparameters from respectively papers are used. ", "page_idx": 6}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/02afb48547834b316f8fdd103d137cf7c7254efa3c09d489b8c73c31d62ed392.jpg", "table_caption": ["Table 3: Anomaly detection performance. Threshold-independent AUC-ROC and AUC-PR metrics and fully parameter-free VUS-ROC and VUS-PR metrics are reported. All values are average percentages from five random seeds. The best values are in bold and the second best underlined. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.2 Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Anomaly Detection Table 3 shows the anomaly detection performance in metrics defined in Section 4.1. It demonstrates that, despite its architectural elegance, SARAD either outperforms all baselines by significant margins on the threshold-independent VUS-ROC scores (SMD: $+15.51\\%$ MAD-GAN, HAI: $+9.92\\%$ DiffAD) or performs on par with current best detectors (PSM: $-1.36\\%$ GDN, SWaT: $-0.36\\%$ DIF). IF scrutinizes the distributional shifts of anomalies with random data partitions and delivers consistent performance across datasets. DIF extends IF into randomized deep representation spaces and archives decent improvements due to more flexible partitions and temporally local information extraction via dilated convolutions. Temporal modeling methods such as DiffAD, ATF-UAD, and AT rely solely or heavily on reconstruction errors and when the errors do not correspond the the underlying anomalies their performance plummet. Adversarial training in USAD and MAD-GAN amplifies reconstruction errors of anomalies to mitigate but not eliminate such issues and thus suffer less performance drops. In contrast, our SARAD additionally accounts for the SAR frequent with anomalies and independent of data distributional shifts, thus outperforming all. SARAD also overpasses GDN, which despite its explicit spatial modeling adopts prediction errors as its sole detection criterion, limiting its performance. SARAD\u2019s top performance on $\\mathrm{{SWaT}}$ and HAI underlines its ability to unravel complex spatial associations even in complex large-scale systems. Standard deviations of Table 3 are reported in Appendix K. ", "page_idx": 7}, {"type": "text", "text": "Anomaly Diagnosis Table 4 shows the anomaly diagnosis performance in metrics defined in Section 4.1. DiffAD uses a subset of SMD features and thus is discarded from comparisons for fairness. SARAD outperforms baselines on the point-based $\\mathrm{HR}@150\\%$ (SMD: $+26.67\\%$ TranAD, SWaT: $+5.10\\%$ USAD, HAI: $+3.81\\%$ GDN) and $\\mathrm{NDCG@150\\%}$ (SMD: $+27.97\\%$ TranAD, SWaT: $+4.76\\%$ GDN, HAI: $+2.93\\%$ GDN). SARAD also outperforms on the range-based $\\mathrm{IPS@150\\%}$ on most datasets (SMD: $43.19\\%$ TranAD, SWaT: $33.43\\%$ TranAD). Unlike SMD which performs forensic diagnosis to label anomalous features, SWaT and HAI label only the origins of cyberattacks as diagnosis labels. Consequentially, attack origins sometimes might not behave anomalously, e.g., attacks had failed, or the full set of anomalous features were not identified, thus diminishing the performance numbers on SWaT and HAI. SARAD generally outperforms detectors underpinned by temporal modeling due to its sensitivity to spatial associative changes. SARAD also outperforms spatial detectors such as GDN whose prediction errors limit its temporal scope to a single time point. Standard deviations of Table 4 are reported in Appendix L. ", "page_idx": 7}, {"type": "text", "text": "Visualization Figure 3 visualizes a real-world anomaly example via SARAD. Our detector captures the significant SAR caused by the anomalous features. The loose reconstruction of the progression raises the progression-based score $p$ and, in turn, the joint detection score $s$ . Taking a broader view of the series in Fig. 3h, SAR significantly raises the scores at the start of the anomaly, even when the data-based errors $r$ are small. SARAD exploits SAR to achieve more robust anomaly detection. ", "page_idx": 7}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/bf7afef3c1a47117a2de193ea3edb88384cb0cab5f25685d9f37cc8a20b5ff8e.jpg", "table_caption": ["Table 4: Anomaly diagnosis performance. Point-based $\\mathrm{HR@}P\\%$ , $\\mathrm{NDCG@\\itP\\%}$ , and range-based $\\mathrm{IPS@}P\\%$ are reported. All values are average percentages from five random seeds. "], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/49ba02ee6237b7ec40faf10e108815ce5ebab7b25e0e4e0585067c76c9622a3a.jpg", "img_caption": ["(i) "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 3: Visualization of applying SARAD for detection on SMD. 3a shows the raw time series right before and during an anomaly $p_{i}$ (colored in red). An input time window for SARAD is bounded in the black box. 3b and 3c show the average association mapping $\\bar{A}^{L}$ via final $L$ -th layer\u2019s MHSA. 3d shows the aggregated progression $_s$ according to Eq. 3. 3e is its reconstruction. 3f, 3g, 3h show the scores $p,r$ , and joint $s$ according to Eq. 5 per feature. 3i shows the anomaly scores for 3a\u2019s segment. Anomalous features (#1, #9, #10, #12, #13, #14 ,and $\\#15$ ) are highlighted with red bounding boxes. ", "page_idx": 8}, {"type": "text", "text": "Complexity and Time Overheads SARAD incurs 32 mins for training and and $0.39~\\mathrm{ms}$ for inference per sample on HAI, the largest dataset, falling far below the data collection time and sampling frequency. Those numbers are comparable with baselines and detailed in Appendix N. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Studies ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Spatial Progression Reconstruction To evaluate the effectiveness of the progression module, we perform ablation studies on its submodules in Table 5. Standard deviations are reported in Appendix K. Removing the ReLU, i.e., to capture both association increases and reductions, in progression loses the focus on asscoation reduction and impairs the detection performance. Replacing the column sum operation in aggregation with the row sum which characterizes the disconnection of anomalous features from others and is shown to be less effectiveness than the column sum representing the drop out rates. Fully concatenating without sum operation dilutes the reduction patterns and significantly hurts the detection, at a cost of complexity. For the detection submodule, using the progression directly instead of the reconstruction errors registers reductions as anomalies directly and underperforms except on SMD due to its inability to rule out normal reduction patterns. ", "page_idx": 8}, {"type": "text", "text": "Choice of Detection Criterion Table 6 compares the detection performance using Eq. 5 (Joint), using only data-based $r$ (DR), and using only progression-based $p$ (SPR). While the data reconstruction is a robust criterion of anomalousness, SARAD embeds the spatial information into the joint criterion and outperforms either single criterion overall. Standard deviations are reported in Appendix K. ", "page_idx": 8}, {"type": "text", "text": "Additional ablation studies on the choice of diagnosis criterion are detailed in Appendix D. ", "page_idx": 8}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/a907c01d55aa088b36c14b02e2392e37d238f7c209da1b3261656b090d974d98.jpg", "table_caption": ["Table 5: Anomaly detection performance under progression reconstruction changes. "], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/cd006ca60728131342728177facde5bbf1dd1916ed9499afe2a5dd5f66e9b913.jpg", "table_caption": ["Table 6: Anomaly detection performance under different choices of detection criterion. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we propose SARAD for time series anomaly detection and diagnosis. The approach effectively exploits the spatial association descending patterns of anomalies. Data reconstruction with Transformer guides learning of spatial associations from data and captured as progression, while progression reconstruction quantifies the anomalous association descent and complements the insensitivity of the former to spatial disassociation during anomalies. SARAD experimentally demonstrates state-of-the-art detection and diagnosis performance and foreshadows the power of spatial modeling for related time series tasks. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Calculations were performed using the Sulis Tier 2 HPC platform hosted by the Scientific Computing Research Technology Platform at the University of Warwick. Sulis is funded by EPSRC Grant EP/T022108/1 and the HPC Midlands $^+$ consortium. The authors acknowledge the use of the Batch Compute System in Department of Computer Science at the University of Warwick, and associated support services, in the completion of this work. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Ahmed Abdulaal, Zhuanghua Liu, and Tomer Lancewicki. 2021a. Practical Approach to Asynchronous Multivariate Time Series Anomaly Detection and Localization. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (Virtual Event, Singapore) $(K D D\\ ^{\\prime}2I,$ ). Association for Computing Machinery, New York, NY, USA, 2485\u20132494. https://doi.org/10.1145/3447548.3467174 ", "page_idx": 9}, {"type": "text", "text": "Ahmed Abdulaal, Zhuanghua Liu, and Tomer Lancewicki. 2021b. RANSynCoders. https:// github.com/icsdataset/hai. ", "page_idx": 9}, {"type": "text", "text": "Charu C. Aggarwal. 2013. Outlier Analysis. Springer. http://dx.doi.org/10.1007/ 978-1-4614-6396-2 ", "page_idx": 9}, {"type": "text", "text": "Julien Audibert, Pietro Michiardi, Fr\u00e9d\u00e9ric Guyard, S\u00e9bastien Marti, and Maria A. Zuluaga. 2020. USAD: UnSupervised Anomaly Detection on Multivariate Time Series. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Virtual Event, CA, USA) (KDD \u201920). Association for Computing Machinery, New York, NY, USA, 3395\u20133404. https://doi.org/10.1145/3394486.3403392 ", "page_idx": 9}, {"type": "text", "text": "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016). ", "page_idx": 9}, {"type": "text", "text": "James Bergstra, R\u00e9mi Bardenet, Yoshua Bengio, and Bal\u00e1zs K\u00e9gl. 2011. Algorithms for HyperParameter Optimization. In Advances in Neural Information Processing Systems, J. ShaweTaylor, R. Zemel, P. Bartlett, F. Pereira, and K.Q. Weinberger (Eds.), Vol. 24. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2011/file/ 86e8f7ab32cfd12577bc2619bc635690-Paper.pdf ", "page_idx": 10}, {"type": "text", "text": "Zhihao Dai, Ligang He, Shuang-Hua Yang, and Matthew Leeke. 2023. Revealing Ongoing Sensor Attacks in Industrial Control System Via Setpoint Modification. In 2023 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech). 0191\u20130199. https://doi.org/10.1109/ DASC/PiCom/CBDCom/Cy59711.2023.10361334 ", "page_idx": 10}, {"type": "text", "text": "Ailin Deng and Bryan Hooi. 2021. Graph Neural Network-Based Anomaly Detection in Multivariate Time Series. Proceedings of the AAAI Conference on Artificial Intelligence 35, 5 (May 2021), 4027\u20134035. https://doi.org/10.1609/aaai.v35i5.16523 ", "page_idx": 10}, {"type": "text", "text": "Jin Fan, Zehao Wang, Huifeng Wu, Danfeng Sun, Jia Wu, and Xin Lu. 2023. An Adversarial Time\u2013Frequency Reconstruction Network for Unsupervised Anomaly Detection. Neural Networks 168 (2023), 44\u201356. https://doi.org/10.1016/j.neunet.2023.09.018 ", "page_idx": 10}, {"type": "text", "text": "Tryambak Gangopadhyay, Sin Yong Tan, Zhanhong Jiang, Rui Meng, and Soumik Sarkar. 2021. Spatiotemporal Attention for Multivariate Time Series Prediction and Interpretation. In ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 3560\u20133564. https://doi.org/10.1109/ICASSP39728.2021.9413914 ", "page_idx": 10}, {"type": "text", "text": "Astha Garg, Wenyu Zhang, Jules Samaran, Ramasamy Savitha, and Chuan-Sheng Foo. 2022. An Evaluation of Anomaly Detection and Diagnosis in Multivariate Time Series. IEEE Transactions on Neural Networks and Learning Systems 33, 6 (2022), 2508\u20132517. https://doi.org/10. 1109/TNNLS.2021.3105827 ", "page_idx": 10}, {"type": "text", "text": "Ary L Goldberger, Luis AN Amaral, Leon Glass, Jeffrey M Hausdorff, Plamen Ch Ivanov, Roger G Mark, Joseph E Mietus, George B Moody, Chung-Kang Peng, and H Eugene Stanley. 2000. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals. circulation 101, 23 (2000), e215\u2013e220. ", "page_idx": 10}, {"type": "text", "text": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (1997), 1735\u20131780. https://doi.org/10.1162/neco.1997.9.8.1735 ", "page_idx": 10}, {"type": "text", "text": "iTrust. 2023. Datasets. https://itrust.sutd.edu.sg/itrust-labs_datasets/. ", "page_idx": 10}, {"type": "text", "text": "Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. 2002. Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Syst. 20, 4 (oct 2002), 422\u2013446. https://doi.org/10.1145/582415.582418 ", "page_idx": 10}, {"type": "text", "text": "Hyeongwon Kang and Pilsung Kang. 2024. Transformer-based multivariate time series anomaly detection using inter-variable attention mechanism. Knowledge-Based Systems 290 (2024), 111507. https://doi.org/10.1016/j.knosys.2024.111507 ", "page_idx": 10}, {"type": "text", "text": "Jina Kim, Hyeongwon Kang, and Pilsung Kang. 2023. Time-series anomaly detection with stacked Transformer representations and 1D convolutional network. Engineering Applications of Artificial Intelligence 120 (2023), 105964. https://doi.org/10.1016/j.engappai.2023.105964 ", "page_idx": 10}, {"type": "text", "text": "Diederik Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In International Conference on Learning Representations. ", "page_idx": 10}, {"type": "text", "text": "Diederik P Kingma and Max Welling. 2014. Auto-encoding variational bayes. In International Conference on Learning Representations. ", "page_idx": 10}, {"type": "text", "text": "Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh, and See-Kiong Ng. 2019. MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks. In Artificial Neural Networks and Machine Learning \u2013 ICANN 2019: Text and Time Series, Igor V. Tetko, V\u02c7era K\u02daurkov\u00e1, Pavel Karpov, and Fabian Theis (Eds.). Springer International Publishing, Cham, 703\u2013716. ", "page_idx": 10}, {"type": "text", "text": "Zhihan Li, Youjian Zhao, Jiaqi Han, Ya Su, Rui Jiao, Xidao Wen, and Dan Pei. 2021. Multivariate Time Series Anomaly Detection and Interpretation using Hierarchical Inter-Metric and Temporal Embedding. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (Virtual Event, Singapore) (KDD \u201921). Association for Computing Machinery, New York, NY, USA, 3220\u20133230. https://doi.org/10.1145/3447548.3467075   \nFei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation Forest. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, Pisa, Italy, 413\u2013422. https://doi.org/10. 1109/ICDM.2008.17   \nYong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. 2024. iTransformer: Inverted Transformers Are Effective for Time Series Forecasting. In The Twelfth International Conference on Learning Representations. https://openreview.net/ forum?id $\\equiv$ JePfAI8fah   \nYong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long. 2022. Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 9881\u20139893. https://proceedings.neurips.cc/paper_files/ paper/2022/file/4054556fcaa934b0bf76da52cf4f92cb-Paper-Conference.pdf   \nPankaj Malhotra, Lovekesh Vig, Gautam Shroff, Puneet Agarwal, et al. 2015. Long Short Term Memory Networks for Anomaly Detection in Time Series.. In Esann, Vol. 2015. 89.   \nAditya P. Mathur and Nils Ole Tippenhauer. 2016. SWaT: a water treatment testbed for research and training on ICS security. In 2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater). IEEE, Vienna, Austria, 31\u201336. https://doi.org/10.1109/ CySWater.2016.7469060   \nYuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2023. A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. In The Eleventh International Conference on Learning Representations. https://openreview.net/forum?id $=$ Jbdc0vTOcol   \nJohn Paparrizos, Paul Boniol, Themis Palpanas, Ruey S Tsay, Aaron Elmore, and Michael J Franklin. 2022. Volume Under the Surface: A New Accuracy Evaluation Measure for Time-Series Anomaly Detection. Proceedings of the VLDB Endowment 15, 11 (2022), 2774\u20132787.   \nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, HighPerformance Deep Learning Library. In Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett (Eds.), Vol. 32. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2019/ file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf   \nKai Qian, Jie Jiang, Yulong Ding, and Shuang-Hua Yang. 2021. DLGEA: a deep learning guided evolutionary algorithm for water contamination source identification. Neural Comput. Appl. 33, 18 (sep 2021), 11889\u201311903. https://doi.org/10.1007/s00521-021-05894-y   \nCory A. Rieth, Ben D. Amsel, Randy Tran, and Maia B. Cook. 2018. Issues and Advances in Anomaly Detection Evaluation for Joint Human-Automated Systems. In Advances in Human Factors in Robots and Unmanned Systems, Jessie Chen (Ed.). Springer International Publishing, Cham, 52\u201363.   \nBharadwaj Satchidanandan and P. R. Kumar. 2017. Dynamic Watermarking: Active Defense of Networked Cyber\u2013Physical Systems. Proc. IEEE 105, 2 (2017), 219\u2013240. https://doi.org/ 10.1109/JPROC.2016.2575064   \nLifeng Shen, Zhuocong Li, and James Kwok. 2020. Timeseries Anomaly Detection using Temporal Hierarchical One-Class Network. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 13016\u201313026. https://proceedings.neurips.cc/paper_files/paper/ 2020/file/97e401a02082021fd24957f852e0e475-Paper.pdf ", "page_idx": 11}, {"type": "text", "text": "Hyeok-Ki Shin, Woomyo Lee, Seungoh Choi, Jeong-Han Yun, and Byung-Gi Min. 2021a. HAI security datasets. https://github.com/icsdataset/hai. ", "page_idx": 12}, {"type": "text", "text": "Hyeok-Ki Shin, Woomyo Lee, Jeong-Han Yun, and Byung-Gi Min. 2021b. Two ICS Security Datasets and Anomaly Detection Contest on the HIL-Based Augmented ICS Testbed. In Cyber Security Experimentation and Test Workshop (Virtual, CA, USA) (CSET \u201921). Association for Computing Machinery, New York, NY, USA, 36\u201340. https://doi.org/10.1145/3474718.3474719   \nYa Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019a. OmniAnomaly. https://github.com/NetManAIOps/OmniAnomaly.   \nYa Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019b. Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD \u201919). Association for Computing Machinery, New York, NY, USA, 2828\u20132837. https://doi.org/10.1145/3292500.3330672   \nNesime Tatbul, Tae Jun Lee, Stan Zdonik, Mejbah Alam, and Justin Gottschlich. 2018. Precision and Recall for Time Series. In Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.), Vol. 31. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2018/ file/8f468c873a32bb0619eaeb2050ba45d1-Paper.pdf   \nShreshth Tuli, Giuliano Casale, and Nicholas R. Jennings. 2022. TranAD: deep transformer networks for anomaly detection in multivariate time series data. Proc. VLDB Endow. 15, 6 (feb 2022), 1201\u20131214. https://doi.org/10.14778/3514061.3514067   \nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/ paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf   \nDennis Wagner, Tobias Michels, Florian C.F. Schulz, Arjun Nair, Maja Rudolph, and Marius Kloft. 2023. TimeSeAD: Benchmarking Deep Multivariate Time-Series Anomaly Detection. Transactions on Machine Learning Research (2023). https://openreview.net/forum?id $\\equiv$ iMmsCI0JsS   \nChengsen Wang, Zirui Zhuang, Qi Qi, Jingyu Wang, Xingyu Wang, Haifeng Sun, and Jianxin Liao. 2023b. Drift doesn't Matter: Dynamic Decomposition with Diffusion Reconstruction for Unstable Multivariate Time Series Anomaly Detection. In Advances in Neural Information Processing Systems, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (Eds.), Vol. 36. Curran Associates, Inc., 10758\u201310774. https://proceedings.neurips.cc/paper_files/ paper/2023/file/22f5d8e689d2a011cd8ead552ed59052-Paper-Conference.pdf   \nHuiqiang Wang, Jian Peng, Feihu Huang, Jince Wang, Junhui Chen, and Yifei Xiao. 2023a. MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting. In The Eleventh International Conference on Learning Representations. https://openreview.net/forum? id=zt53IDUR1U   \nShiyu Wang, Haixu Wu, Xiaoming Shi, Tengge Hu, Huakun Luo, Lintao Ma, James Y. Zhang, and JUN ZHOU. 2024. TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting. In The Twelfth International Conference on Learning Representations. https://openreview. net/forum?id $\\equiv$ 7oLshfEIC2   \nHaixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021. Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting. In Advances in Neural Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34. Curran Associates, Inc., 22419\u201322430. https://proceedings.neurips.cc/paper_files/paper/2021/file/ bcc0d400288793e8bdcd7c19a8ac0c2b-Paper.pdf   \nChunjing Xiao, Zehua Gou, Wenxin Tai, Kunpeng Zhang, and Fan Zhou. 2023. Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD \u201923). Association for Computing Machinery, New York, NY, USA, 2742\u20132751. https://doi.org/10.1145/3580305.3599391   \nHaowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, Jie Chen, Zhaogang Wang, and Honglin Qiao. 2018. Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications. In Proceedings of the 2018 World Wide Web Conference (Lyon, France) (WWW \u201918). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 187\u2013196. https: //doi.org/10.1145/3178876.3185996   \nHongzuo Xu, Guansong Pang, Yijie Wang, and Yongjun Wang. 2023. Deep Isolation Forest for Anomaly Detection. IEEE Transactions on Knowledge and Data Engineering 35, 12 (2023), 12591\u201312604. https://doi.org/10.1109/TKDE.2023.3270293   \nJiehui Xu, Haixu Wu, Jianmin Wang, and Mingsheng Long. 2022. Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy. In International Conference on Learning Representations. https://openreview.net/forum?id=LzQQ89U1qm_   \nOmry Yadan. 2019. Hydra - A framework for elegantly configuring complex applications. Github. https://github.com/facebookresearch/hydra   \nYiyuan Yang, Chaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun. 2023. DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>) (KDD \u201923). Association for Computing Machinery, New York, NY, USA, 3033\u20133045. https://doi. org/10.1145/3580305.3599295   \nAiling Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. 2023. Are Transformers Effective for Time Series Forecasting? 37 (Jun. 2023), 11121\u201311128. https://doi.org/10.1609/aaai.v37i9.26317   \nChaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun. 2022. TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management (Atlanta, GA, USA) (CIKM \u201922). Association for Computing Machinery, New York, NY, USA, 2497\u20132507. https://doi.org/10.1145/3511808.3557470   \nMichael Zhang, Khaled Kamal Saab, Michael Poli, Tri Dao, Karan Goel, and Christopher Re. 2023. Effectively Modeling Time Series with Simple Discrete State Spaces. In The Eleventh International Conference on Learning Representations. https://openreview.net/forum? id=2EpjkjzdCAa   \nYunhao Zhang and Junchi Yan. 2023. Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting. In The Eleventh International Conference on Learning Representations. https://openreview.net/forum?id $=$ vSVLM2j9eie   \nHang Zhao, Yujing Wang, Juanyong Duan, Congrui Huang, Defu Cao, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, and Qi Zhang. 2020. Multivariate Time-Series Anomaly Detection via Graph Attention Network. In 2020 IEEE International Conference on Data Mining (ICDM). 841\u2013850. https://doi.org/10.1109/ICDM50108.2020.00093   \nYu Zheng, Huan Yee Koh, Ming Jin, Lianhua Chi, Khoa T. Phan, Shirui Pan, Yi-Ping Phoebe Chen, and Wei Xiang. 2023. Correlation-Aware Spatial\u2013Temporal Graph Learning for Multivariate Time-Series Anomaly Detection. IEEE Transactions on Neural Networks and Learning Systems (2023), 1\u201315. https://doi.org/10.1109/TNNLS.2023.3325667   \nTian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. 2022. FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting. In Proceedings of the 39th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 162), Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "and Sivan Sabato (Eds.). PMLR, 27268\u201327286. https://proceedings.mlr.press/v162/ zhou22g.html ", "page_idx": 14}, {"type": "text", "text": "Tian Zhou, Peisong Niu, xue wang, Liang Sun, and Rong Jin. 2023. One Fits All: Power General Time Series Analysis by Pretrained LM. In Advances in Neural Information Processing Systems, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (Eds.), Vol. 36. Curran Associates, Inc., 43322\u201343355. https://proceedings.neurips.cc/paper_files/paper/ 2023/file/86c17de05579cde52025f9984e6e2ebb-Paper-Conference.pdf ", "page_idx": 14}, {"type": "text", "text": "A Broader Impacts ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The broader impact of the work presented rests in the increasingly pervasive nature of industrial control systems, intrusion detection systems, and remote monitoring solutions in healthcare contexts, all of which commonly utilize some form of anomaly detection. Further to the time series analysis that is commonplace, the work presented in this paper demonstrates how Transformer can be used to learn the spatial associations that ubiquitously characterize these feedback-controlled systems, supplementing time series analysis to provide state-of-the-art performance. As such, the work presented has broad applicability, whilst explicitly targeting automated industrial control systems. ", "page_idx": 15}, {"type": "text", "text": "B Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "While the model size scales linearly with the number of features, the time complexity of SARAD is quadratic with respect to the features. SARAD could incur significant training and inference overheads when the supervisory system is extensively large. We caution that the overheads of the largest dataset in our experiments fall well below data collection overhead and sampling frequency (see Appendix N). To scale, we will explore hierarchical time series anomaly detection via clustering. Another limitation of this work is the scarcity of forensically labeled datasets like SMD for anomaly diagnosis, not least due to the intensive labor and domain knowledge implied. To address that gap, we will explore publicly available audit and operational time series data for sources. ", "page_idx": 15}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/135afb8ab79d1936f66947a91b40b50d254a7d8cb7ee470415cfe670f2841a38.jpg", "img_caption": ["Figure 4: Spatial associations captured by Transformer on SMD (Su et al., 2019b). "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/93008d1fa911491d22b4ca1feef72785b5d953d6b62d14f7cc85915e20fcc04a.jpg", "img_caption": ["Figure 5: Spatial associations captured by Transformer on SMD (Su et al., 2019b). "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "C Examples of Spatial Association Reduction ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "As mentioned in Section 1, herein we provide more real-world examples of Spatial Association Reduction (SAR) exhibited by time series anomalies. Figures 4, 5, 6, 7 showcase the spatial associations captured within Transformer via MHSA. Subfigures in each aforementioned figure show, in that order, (a) the raw time series right before, during, and after an anomaly $p_{i}\\in\\mathcal{P}$ (colored in red), (b) association mapping $A_{h}^{L}$ output by final $L$ -th layer\u2019s MHSA are averaged across heads to derive average association $\\pmb{A}$ before $p_{i}$ , (c) $A_{h}^{L}$ during $p_{i}$ , (d) $A_{h}^{L}$ after $p_{i}$ wherein brighter cells have smaller values and anomalous features are highlighted with red bounding boxes, (e) the reduction-only changes from before the anomaly to during the anomaly, i.e., ReLU $\\!\\!\\!A_{\\mathrm{pre}}-A_{\\mathrm{in}})$ , and finally (f) the reduction-only changes from after the anomaly to during the anomaly, i.e., ReLU $?A_{\\mathrm{post}}-A_{\\mathrm{in}})$ . ", "page_idx": 16}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/f999ff046bf6130ac278b25898fbfe5247eaf3404b0967bedbcbf578d25328fb.jpg", "img_caption": ["(a) Raw time series before, during, and after an anomaly $p_{i}$ . "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/bc7ecd38406c83eb142444d488a1ad549d2b554b29046348ab2451f4ddf49ae3.jpg", "img_caption": ["(b) Pre- $p_{i}$ \u2019s A. (c) In- $p_{i}$ \u2019s A. (d) Post- $p_{i}$ \u2019s A. (e) Pre-reduction.(f) Post-reduction. Figure 6: Spatial associations captured by Transformer on SWaT (Mathur and Tippenhauer, 2016). "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/f73c88a8c9a8bb58684c3a1ca7d41a61f6e2867de9ed5af9485e4c61e516fc5d.jpg", "img_caption": ["(a) Raw time series before, during, and after an anomaly $p_{i}$ . "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/5ec24b95f9b9b01e402a531bda4d16959037e9f788fdaf542209ecbe98e508fc.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "(b) Pre- $p_{i}$ \u2019s A. (c) In- $p_{i}$ \u2019s A. (d) Post- $p_{i}$ \u2019s A. (e) Pre-reduction.(f) Post-reduction. Figure 7: Spatial associations captured by Transformer on SWaT (Mathur and Tippenhauer, 2016). ", "page_idx": 17}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/ca7e0e2b86d1e1f5b2bf9dc930db5852981a56b082b50be3303f6ab2bbda9a08.jpg", "table_caption": ["Table 7: Anomaly diagnosis performance under different choices of diagnosis criterion. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "D Choice of Diagnosis Criterion ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Concerning the rationality of data-only diagnosis criterion in Eq. 6, we consider an alternate joint diagnosis criterion in line with the detection criterion in Eq. 5. ", "page_idx": 18}, {"type": "equation", "text": "$$\nr_{j}=||\\hat{X}_{(j,:)}-X_{(j,:)}||_{2}^{2},\\,p_{j}=||\\hat{S}_{(\\cdot,j)}-\\pmb{S}_{(\\cdot,j)}||_{2}^{2},\\,s_{j}=(r_{j}-\\mu_{r_{j}})/\\sigma_{r_{j}}+(p_{j}-\\mu_{p_{j}})/\\sigma_{p_{j}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $r_{j}$ is feature $j$ \u2019s data reconstruction error, $p_{j}$ its progression reconstruction error, $\\mu_{r_{j}},\\mu_{p_{j}}$ the means of $r_{j},p_{j}$ on the validation set, and $\\sigma_{r_{j}},\\sigma_{p_{j}}$ the standard deviation of $r_{j},p_{j}$ . Table 7 compares the diagnosis performance using only $r_{j}$ (SARAD), using only $p_{j}$ (SPR), and using Eq. 7 (Joint). Unlike in anomaly detection, the great discrepancy between $r_{j}$ and $p_{j}$ more than often degrades the performance of the joint criterion. SARAD uses $r_{j}$ only which produces suboptimal and yet reliable performance in the longer anomalous horizons. Standard deviations are reported in Appendix L. ", "page_idx": 18}, {"type": "text", "text": "E Datasets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We include four real-world datasets collected under industrial control and IT service monitoring settings for evaluations. Anomalies range from IT service outages to external cyber-physical attacks against control systems. ", "page_idx": 19}, {"type": "text", "text": "E.1 Dataset Descriptions ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Server Machine Dataset (SMD) (Su et al., 2019b,a) is a server metric dataset from a large-scale IT company. Engineers annotated anomalous events in the second half of the data with indicator-level attributions.   \n2. Pooled Server Metrics (PSM) dataset (Abdulaal et al., 2021a,b) captures key performance indicators of servers on an online shopping platform. Website engineers annotated anomalous events for data in the last eight weeks.   \n3. Secure Water Treatment (SWaT) dataset (Mathur and Tippenhauer, 2016; iTrust, 2023) contains sensor readings and actuator status on a minuscule real-world water treatment system during a six-day normal operational period. A knowledgeable attacker performed 36 cyber-physical attacks during a five-day attack period and they are labelled as anomalous accordingly.   \n4. HIL-based Augmented ICS (HAI) dataset (Shin et al., 2021b,a) records measurements and control actions within a Hardware-In-the-Loop (HIL) dual power (steam-turbine and hydropower) generation testbed during its two-week operation. Both single-point primitive and multi-point combined attacks are performed on the testbed to emulate a threat actor with cyber-physical capacities. We use the 21.03 version of HAI. All training sets contain only unlabeled data and the test sets contain data with anomaly labels.   \nStatistics of the datasets are given in Table 2. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "E.2 Lengths of Anomalies ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We further characterize the detection datasets by the lengths of the anomalous events. Figure 8 shows the empirical cumulative distribution function of the anomalous lengths. SWaT has the longest median length of 447 among the four datasets considered, followed by HAI (162), SMD (11), and lastly PSM (5). The very short lengths on SMD and PSM benefti temporal detectors which tend to embed a single or few time points (see Appendix M), whereas SARAD adopts a half time window embedding strategy. The catch is that SARAD can learn spatial relationships with temporal aggregated information per feature, while temporal detectors could not, bringing about benefits of performing anomaly detection in the spatial association space. A more scalable approach for temporal aggregation is to be explored in the future, though variable window sizes or subseries splits might be implied. ", "page_idx": 19}, {"type": "text", "text": "E.3 Lengths of Diagnosis Labels ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Figure 8 shows the empirical cumulative distribution function of the diagnosis label lengths. Whereas SMD forensically labels features which deviate from their normal behavioral patterns as anomalous, SWaT and HAI only label the points of attacks as anomalous as the their creators have advanced knowledge of such attacks. The latter labeling strategy results in incomplete sets of anomalous features and diminishes the diagnosis performance of all models, as evidence in Table 4 in Section 4.2. ", "page_idx": 19}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/236974dc0a7b0db8076322e12b361315fe929a21117533621a7b20d3ebbd1967.jpg", "img_caption": ["Figure 8: Empirical distribution function of the lengths of anomalies. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/d58fa8fa81f4324fd10430908f5ad6f8f82b3f7c1019263a4dea105bd9de2d50.jpg", "img_caption": ["(a) SMD. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/75eace802d93ff368af49d7f85221cec96a64f57a160fdb9d46fbd0cbfc23a71.jpg", "img_caption": ["Figure 9: Empirical distribution function of the lengths of diagnosis labels. ", ""], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "F Implementation Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We implement SARAD in Python using pyTorch library (Paszke et al., 2019) and Hydra framework (Yadan, 2019). All experiments are run on a single NVIDIA A10 (24GB) GPU. Adam optimizer (Kingma and Ba, 2015) is used and learning rate is halved every epoch for 3 epochs to prevent over-fitting. The time window size is $2W\\,=\\,100$ . The data reconstruction module has $H=8$ attention heads per layer with attention length $D=512$ and hidden length $D_{F F}=2048$ . For hyperparameter tuning, training set is temporally partitioned into $80\\%$ for training and $20\\%$ for validation. On each dataset we first perform TPE sampling (Bergstra et al., 2011) for number of encoding layers $L\\in\\{3,5\\}$ and learning rate $\\in[10^{-4},\\dot{1}0^{-\\tilde{2}}]$ to derive the best data reconstruction loss $L_{R}$ on the validation set. The progression module by default has hidden length of $D_{P}=64$ . We then perform TPE sampling to search weight $\\lambda_{L_{S}}\\in[10^{-2},10^{2}]$ for the progression reconstruction loss $L_{S}$ on the validation set. ", "page_idx": 21}, {"type": "text", "text": "G Open-accessed Code and Data ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "During the review period, code is anonymized and openly available at https://github.com/ daidahao/SARAD/ with specific instructions and scripts to reproduce experimental results. All data used in our experiments can be openly accessed from public repositories or requested via original authors\u2019 websites. Full links are provided in Appendix E. ", "page_idx": 21}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/8761a1795d81db1d68998adf6807233bc958f1f845b945ef0ced6de29ba4b17e.jpg", "img_caption": ["Figure 10: Hyperparameter Sensitivity of detection performance in VUS-ROC scores. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "H Hyperparameter Sensitivity ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We examine the hyperparameter sensitivity of SARAD\u2019s detection performance. Concretely, we consider the effects of the sliding window size (default is 100), the number of training epochs (3), the attention length of Transformer encoding layers $D$ (512), and the hidden length of the progression reconstruction module $D_{P}$ (64). Figure 10 and 11 present the results. On the window size, a sliding window too small confines temporal modeling to small temporal receptive fields and contains anomaly detection in the association space. However, a sliding window too large incurs higher computational costs, although unlike temporal modeling the costs here are linear. On datasets with shorter anomalous lengths such as SMD and PSM, the anomalous patterns are diluted even further, resulting in performance degradation. ", "page_idx": 22}, {"type": "text", "text": "On the number of training epochs, fewer epochs lead to model underfitting, and yet overfitting is largely prevented with more epochs due to the aggressive learning rate halving per epoch. On the attention length $D$ , a larger Transformer is prone to overfitting with visible performance drops on SMD and PSM as $D$ passes the default 512, both of whose monitored systems are smaller in scale. On the hidden length $D_{P}$ , a more complex progression anomaly detector does not adversely impact the performance, suggesting that the association space is less prone to detection overfitting than the data space. ", "page_idx": 22}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/6a99114f4f5a13beb480d42b08dc7959565861f32b797b79abf795c9dd59e81f.jpg", "img_caption": ["Figure 11: Hyperparameter Sensitivity of detection performance in VUS-PR scores. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "I Detection Metrics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Conventional metrics such as precision, recall, F1 and the threshold-independent Area Under the Curve (AUC) scores are commonly point-based, i.e., predicted labels are scored individually by time points (Zhou et al., 2023; Zhang et al., 2022; Xu et al., 2018). Real-world benchmarks are rife with range-wise anomalies spanning consecutive time points (Wagner et al., 2023). Point-based metrics are generally ill-suited for evaluating detection performance due to the continuous-discrete conversion and the series-label misalignment (labeling anomalies precisely is hard) (Garg et al., 2022; Tatbul et al., 2018). Here, we use the range-based metrics proposed in (Paparrizos et al., 2022). Compared against their point-based counterparts, they provide robustness to labeling delay and scoring noises as well as performant detector separability and series consistency. ", "page_idx": 24}, {"type": "text", "text": "Given a set of anomalous ranges $\\mathcal{P}=\\{p_{i}=(s_{i},e_{i})\\}$ wherein each anomaly $p_{i}$ starts at timestamp $s_{i}$ and ends at $e_{i}$ , we enclose each range with uniform $l/2$ -length preceding and succeeding buffers. Given the anomaly label $y_{t}\\in\\{0,1\\}$ at each timestamp $t$ , we derive a new soft label $\\tilde{y}_{t}\\in[0,1]$ as per the minimum temporal distance of $t$ to any anomaly $p_{i}\\in\\mathcal{P}$ : ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\tilde{y}_{t}=\\left\\{\\!\\!\\begin{array}{l l}{\\sqrt{1-|s_{i}-t|/l},}&{\\exists p_{i}\\in\\mathcal{P},t\\in[s_{i}-l/2,s_{i})}\\\\ {\\sqrt{1-|t-e_{i}|/l},}&{\\exists p_{i}\\in\\mathcal{P},t\\in(e_{i},e_{i}+l/2]}\\\\ {y_{t},}&{\\mathrm{otherwise}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $l$ is the buffer length, nor\u221amally set to the median segment length in $\\mathcal{P}$ . Within the buffers, $\\tilde{y}_{t}$ monotonically increases from ${\\sqrt{2}}/2$ to 1 as the distance decreases. With the new soft label series $\\tilde{\\mathcal{Y}}=\\{\\tilde{y}_{t}\\}$ , we define the True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN) accordingly: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{T P=\\tilde{\\mathcal{Y}}^{T}\\cdot\\hat{\\mathcal{Y}},\\;F P=(1-\\tilde{\\mathcal{Y}})^{T}\\cdot\\hat{\\mathcal{Y}},\\;T N=(1-\\tilde{\\mathcal{Y}})^{T}\\cdot(1-\\hat{\\mathcal{Y}}),\\;F N=\\tilde{\\mathcal{Y}}^{T}\\cdot(1-\\hat{\\mathcal{Y}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We then compute the threshold-independent AUC for the Receiver Operating Characteristic (AUCROC), i.e., TP rate vs FP rate, and the Precision-Recall (AUC-PR) curves respectively to be rid of thresholding impact. Fully parameter-free Volume Under the Surface (VUS) scores for AUC-ROC (VUS-ROC) and AUC-PR (VUS-PR) are also computed under different buffer lengths $\\hat{l}\\in[0,2l]$ . ", "page_idx": 24}, {"type": "text", "text": "J Diagnosis Metrics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In line with previous works (Tuli et al., 2022; Zhao et al., 2020), we use common metrics such as Hit Rate (HR) (Su et al., 2019b) and Normalized Discounted Cumulative Gain (NDCG) (J\u00e4rvelin and Kek\u00e4l\u00e4inen, 2002) to measure performance where diagnosis labels are available. Given a set of anomalous features $G_{i}\\subseteq[N]$ at an anomalous timestamp $t\\in p_{i}\\in\\mathcal{P}$ as a diagnosis ground-truth and the set of top $k$ -ranked features $\\Gamma_{t}\\ @P\\%$ according to Eq. 5 where $k=\\lceil|G_{i}\\bar{|}\\times P\\%\\rceil$ , say $k=5$ when $|G_{i}|=3$ and $P=150$ , the HR at $P\\%$ $P\\ge100]$ ) features is the overlap ratio between the two: ", "page_idx": 25}, {"type": "equation", "text": "$$\n{\\mathrm{HR}}_{t}@P\\%={\\frac{|G_{i}\\cap\\Gamma_{t}@P\\%|}{|G_{i}|}}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "In information retrieval, DCG measures the cumulative utility of retrieved documents by their ranking order up to a certain position. NDCG normalizes the DCG by the maximum possible DCG. They are parameterized by $P\\%$ to determine the location in our evaluation and calculated as follows. ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbf{DCG}_{t}\\ @P\\mathcal{V}_{0}=\\sum_{j=1}^{k}\\frac{r_{j}}{\\log_{2}(j+1)},\\,\\mathbf{IDCG}_{t}=\\sum_{j=1}^{|G_{i}|}\\frac{1}{\\log_{2}(j+1)},\\,\\mathbf{NDCG}_{t}\\ @P\\mathcal{V}_{0}=\\frac{\\mathbf{DCG}_{t}\\ @P\\mathcal{V}_{0}}{\\mathbf{IDCG}_{t}}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $r_{j}\\,\\in\\,\\{0,1\\}$ is the relevance value of the $j$ -th element and, in this case, the membership of $\\Gamma_{t}@P\\%$ \u2019s $j$ -th feature in $G_{i}$ . NDCG has a value strictly between 0 and 1. ", "page_idx": 25}, {"type": "text", "text": "At the range level, we measure the Interpretation Score (IPS) initially proposed in Li et al. (2021) and here expanded to fit the $P\\%$ parameterization. For each anomalous range $p_{i}$ , the IPS score is: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathrm{IPS}_{i}@P\\%=\\frac{|G_{i}\\cap\\Omega_{i}@P\\%|}{|G_{i}|}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\Omega_{i}@P\\%$ is the top $k$ -ranked features according to $\\operatorname*{max}_{t\\in p_{i}}\\boldsymbol{s}_{j,t}$ , the $j$ -th feature\u2019s maximum anomaly score during $p_{i}$ and $k=\\lceil|G_{i}|\\times P\\%\\rceil$ . It is the HR equivalence at the range level as per the highest anomalous scores per feature. ", "page_idx": 25}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/f1097114571d2d290664a0deec972e77883c311704cbabc595412dc7cfd4d1ee.jpg", "table_caption": ["Table 8: Standard deviations of anomaly detection performance in Table 3. Standard deviations of threshold-independent AUC-ROC and AUC-PR metrics and fully parameter-free VUS-ROC and VUS-PR metrics are reported. All values are percentages. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 9: Standard deviations of anomaly detection performance in Table 5. Standard deviations of threshold-independent AUC-ROC and AUC-PR metrics and fully parameter-free VUS-ROC and VUS-PR metrics are reported. All values are percentages. ", "page_idx": 26}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/089e5deb9d86bbf13ecd09abe46d00456c8969f7153be2c4d2d318c585bb7ed8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "K Standard Deviations of Detection Performance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Table 8 reports the standard deviations of anomaly detetion performance as reported in Table 3 in Section 4.2. ", "page_idx": 26}, {"type": "text", "text": "Table 9 reports the standard deviations of anomaly diagnosis performance as reported in Table 5 in Section 4.3. ", "page_idx": 26}, {"type": "text", "text": "Table 10 reports the standard deviations of anomaly detection performance as reported in Table 6 in Section 4.3. ", "page_idx": 26}, {"type": "text", "text": "Table 10: Standard deviations of anomaly detection performance in Table 3. Standard deviations of threshold-independent AUC-ROC and AUC-PR metrics and fully parameter-free VUS-ROC and VUS-PR metrics are reported. All values are percentages. ", "page_idx": 26}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/b856411ab141d759bd046ad5cdd9f245a60c8db8bc1769a2250a2fd82e7bc35f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 11: Standard deviations of anomaly diagnosis performance in Table 4. Standard deviations of point-based $\\mathrm{HR@}P\\%$ , $\\mathrm{NDCG@\\itP\\%}$ , and range-based $\\mathrm{IPS@}P\\%$ are reported. All values are percentages. ", "page_idx": 27}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/821a390160c3fb771cb304e8cf0e3d831fac4c8b2240d5bf1b7a15d435f8e2fd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/73e0614f41a83420acfc7927405ce4209ff38207a888b7974210e0dd61d980cd.jpg", "table_caption": ["Table 12: Standard deviations of anomaly diagnosis performance in Table 7. Standard deviations of point-based $\\mathrm{HR@}P\\%$ , $\\mathrm{NDCG@\\itP\\%}$ , and range-based $\\mathrm{IPS@}P\\%$ are reported. All values are percentages. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "L Standard Deviations of Diagnosis Diagnosis ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Table 11 reports the standard deviations of anomaly diagnosis performance as reported in Table 4 in Section 4.2. ", "page_idx": 27}, {"type": "text", "text": "Table 12 reports the standard deviations of anomaly diagnosis performance as reported in Table 7 in Appendix D. ", "page_idx": 27}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/a2b7584b0a86108908cee6e0a3f422b7e3d0664fa17f0ef249707c66f69a6e60.jpg", "table_caption": ["Table 13: Anomaly detection point-based performance. Threshold-dependent Precision, Recall, F1 scores and threshold-independent AUC-ROC and AUC-PR scores are reported. All values are average percentages from five random seeds. The best values are in bold and the second best underlined. "], "table_footnote": [], "page_idx": 28}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/c4f57453a10c7573008aee7e1f09f7ac5bd88b9c90e36de1607b40af059a66d0.jpg", "table_caption": ["Table 14: Standard deviations of anomaly detection point-based performance in Table 14. Standard deviations of threshold-dependent Precision, Recall, F1 scores and threshold-independent AUC-ROC and AUC-PR scores are reported. All values are percentages. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "M Point-based Evaluations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In addition to the model evaluations using range-based metrics such as VUS-ROC and VUS-PR in Sections 4.2 and 4.3, we conduct point-based evaluations herein using point-based metrics exclusively. Table 13 reports report the Precision, Recall, and F1 scores under the threshold where the method of interest achieves the best F1 score. To mitigate the impact of thresholding protocol, Table 13 also reports the threshold-independent AUC-ROC and AUC-PR scores. Table 14 reports the standard deviations. ", "page_idx": 28}, {"type": "text", "text": "SARAD achieves state-of-the-art performance on most datasets except PSM. The enlarged temporal receptive field of SARAD (half input window) contributes to its underperformance by point-based metrics, especially on datasets where anomalous ranges are short (see Table 2), when compared against most others\u2019 receptive filed of single or few time points (typical 1D Conv kernel size is 3). We again underline that most real-world anomalies are continuous and point-based metrics are mismatched for such anomalies (see Appendix I for discussion). ", "page_idx": 28}, {"type": "text", "text": "Table 15: Model complexity and overheads. The total training time (in minutes), the inference time per sample (in milliseconds), and the total number of parameters (where applicable) are reported. The best values are in bold and the second best underlined. ", "page_idx": 29}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/a90277339adb92911850555140f1950e023b839afa2ffdb3ec9df597bfdf170a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "N Model Complexity and Overheads ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We study and compare the complexity and time overheads of all baselines and SARAD. Concretely, we evaluate the model complexity by the number of parameters being used and the total training time as well as the inference time per sample. All experiments on time overheads are performed on a compute node with AMD EPYC 7443 (48 cores, 96 threads) CPU, NVIDIA A10 (24GB) GPU, and 512 GB RAM. ", "page_idx": 29}, {"type": "text", "text": "Table 15 reports the total training time (in minutes), the inference time per sampling point, and the number of network parameters used (where applicable) of all baselines on the main datasets. The size of the training set $T$ , the number of features $N$ , and the sampling period $\\mathfrak{T}$ are also reported per dataset for easy reference. SARAD, while not the fastest nor the lightest model, incurs moderate time overheads and model complexity. ", "page_idx": 29}, {"type": "text", "text": "We note that even SWaT, the smallest dataset in terms of actual clock time, spans approximately 6 days for collection. This is far exceeding most detectors\u2019 training time besides MAD-GAN and levigates concerns for training overheads for them. All detectors also incur an inference per sample time several magnitudes below the smallest sampling frequency of 1 second, guaranteeing real-time deployment of all detectors once trained. ", "page_idx": 29}, {"type": "text", "text": "O Baselines ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We trained all baselines using official implementations where available and recommended hyperparameters from respectively papers are used. Some baselines, such as DiffAD and AT, have dataset-specific hyperparameters and here we adopted them as well. The open-accessed URLs of the baselines used are listed as followed. ", "page_idx": 30}, {"type": "text", "text": "\u2022 IF (ICDM\u201908) (Liu et al., 2008): https://github.com/xuhongzuo/deep-iforest.   \n\u2022 DIF (TKDE\u201923) (Xu et al., 2023): https://github.com/xuhongzuo/deep-iforest.   \n\u2022 TranAD (VLDB\u201922) (Tuli et al., 2022): https://github.com/imperial-qore/ TranAD.   \n\u2022 ATF-UAD (NN\u201923) (Fan et al., 2023): https://github.com/wzhSteve/ATF-UAD.   \n\u2022 AT (ICLR\u201922) (Xu et al., 2022): https://github.com/thuml/Anomaly-Transformer.   \n\u2022 DCdetector (KDD\u201923) (Yang et al., 2023): https://github.com/DAMO-DI-ML/ KDD2023-DCdetector.   \n\u2022 USAD (KDD\u201920) (Audibert et al., 2020): https://github.com/manigalati/usad.   \n\u2022 GDN (AAAI\u201921) (Deng and Hooi, 2021): https://github.com/d-ailin/GDN.   \n\u2022 MAD-GAN (ICANN\u201919) (Li et al., 2019): https://github.com/LiDan456/MAD-GANs. Official implementation was migrated to pyTorch for uniform environmental set-up. See our codebase for details.   \n\u2022 DiffAD (KDD\u201923) (Xiao et al., 2023): https://github.com/ChunjingXiao/DiffAD. ", "page_idx": 30}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/f7d8214566848acac954deb70e69d1eaf8401befd3c7eb1a5be372ff998a80db.jpg", "img_caption": ["Figure 12: Joint detection criterion $s$ of data reconstruction error $r$ and progression reconstruction error $p$ . "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "P Joint Detection Criterion ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Figure 12 visualizes the two components of the joint detection criterion $s$ in Eq. 5, i.e., the data reconstruction error $r$ and the progression reconstruction error $p$ . Balanced resampling is applied here. Recall that $s$ is the sum of normalized $r$ and $p$ . Most anomalous samples (input series) either has high $r$ or high $p$ , and oftentimes both. The former measures the magnitude of anomalousness in the data space, the latter in the spatial association space. The basis underpins the formalization of the joint detection criterion. ", "page_idx": 31}, {"type": "image", "img_path": "gmf5Aj01Hz/tmp/e93448029a9c8de2117b20dee6efb2314bd43c7d3f5b34fdb8d7648f8ac24d88.jpg", "img_caption": ["Figure 13: Distributions of anomalies scores. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "Q Distributions of Anomaly Scores ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Figure 13 the distributions of the joint anomaly scores. On SMD and PSM, the scores of the normal and anomalous samples (input series) overlap more heavily than on SWaT and HAI. The observations here highlight the difficulty of anomaly detection in the service monitoring space, more so than in industrial control where measurements and actuation result from well-defined control logics. The hardness is evident is Table 3 of detection performance and 4 of diagnosis performance. ", "page_idx": 32}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/6c864840a1f9944ecbe423882d1edd07e68165d5aae590748b9ec794e4b694b1.jpg", "table_caption": ["Table 16: Anomaly detection performance under different thresholds. TPRs under thresholds set by pre-defined $\\mathrm{FPRs}\\,\\dot{\\in}\\,\\{1\\%,5\\%,10\\%\\}$ are reported. Higher TPRs are better. Similarly, FPRs under thresholds set by pre-defined T $\\mathrm{PRs}\\in\\{90\\%,95\\%,99\\%\\}$ are reported. Lower FPRs are better. All values are average percentages from five random seeds. The best values are in bold and the second best underlined. "], "table_footnote": [], "page_idx": 33}, {"type": "table", "img_path": "gmf5Aj01Hz/tmp/44a374b4b8b7ba1f2ae5d6eac1744819134f0f676586342eb7a369540342abc5.jpg", "table_caption": ["Table 17: Standard deviations of anomaly detection performance under different thresholds in Table 16. Standard deviations of TPRs under thresholds set by pre-defined $\\mathrm{FPRs}\\in\\{1\\%,5\\%,10\\%\\}$ are reported. Similarly, standard deviations of FPRs under thresholds set by pre-defined TPRs $\\in\\{90\\bar{\\%},95\\%,99\\%\\}$ are reported. All values are percentages. "], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "R Detection Performance Under Thresholds ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Effectiveness of each anomaly detector is influenced by the selection of thresholds. Previously, we reported the range-based and point-based threshold-independent performance metrics. Here, we study the influence of threshold selection on the detection performance. Table 16 reports the range-based True Positive Rates (TPRs) under thresholds set by pre-defined False Positive Rates (FPRs)as well as the FPRs under different thresholds set by pre-defined TPRs. Table 17 reports the standard deviations. ", "page_idx": 33}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The main claims clearly reflect the paper\u2019s contributions and scope of time series anomaly detection in the abstract and Section 1. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 34}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: We discuss the limitations in Appendix B ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 34}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not include theoretical results. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 35}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We disclose full details of our experiments in Appendixes F and O. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 35}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We provide open access to the data and code in Appendix G. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 36}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We disclose essential experimental settings in Section 4.1 and full details in Appendix F. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 36}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: We report standard deviations of the experiments in Appendices K and L. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: We disclose information on compute resources for experiments in Appendix F. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 37}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The research conform with the NeurIPS Code of Ethics. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 37}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: We discuss the broader impacts in Appendix A. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper poses no risks of misuse. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: We cite and properly credit all datasets, baselines, and libraries used in this paper (see Appendices E and O for details). ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 38}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 39}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 39}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 39}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not involve IRB approvals and equivalent approvals/reviews. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 39}]