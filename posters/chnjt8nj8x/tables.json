[{"figure_path": "chnJT8Nj8X/tables/tables_7_1.jpg", "caption": "Table 1: Performance of Transformer Doctor on various SOTA Transformers. '+Doctor' indicates the performance of model treated with Transformer Doctor (All Score are in %)", "description": "This table presents the performance comparison of several state-of-the-art (SOTA) Transformer models before and after applying the proposed Transformer Doctor method.  The models are evaluated on five different datasets (CIFAR-10, CIFAR-100, ImageNet-10, ImageNet-50, and ImageNet-1K) and the improvement in accuracy after applying Transformer Doctor is shown in parentheses. The results demonstrate that the Transformer Doctor method consistently improves the performance of different Transformer architectures across various datasets.", "section": "6.2 Quantitative Analysis"}, {"figure_path": "chnJT8Nj8X/tables/tables_8_1.jpg", "caption": "Table 1: Performance of Transformer Doctor on various SOTA Transformers. '+Doctor' indicates the performance of model treated with Transformer Doctor (All Score are in %).", "description": "This table shows the performance improvements achieved by applying the Transformer Doctor method to various state-of-the-art (SOTA) vision transformer models.  The performance is measured as accuracy (%) on five different datasets (CIFAR-10, CIFAR-100, ImageNet-10, ImageNet-50, and ImageNet-1K) for several transformer architectures. For each model and dataset, both the baseline accuracy (without Transformer Doctor) and the accuracy after treatment with Transformer Doctor are presented, showing the percentage improvement.", "section": "6.2 Quantitative Analysis"}, {"figure_path": "chnJT8Nj8X/tables/tables_18_1.jpg", "caption": "Table 1: Performance of Transformer Doctor on various SOTA Transformers. '+Doctor' indicates the performance of model treated with Transformer Doctor (All Score are in %)", "description": "This table presents the performance comparison of several state-of-the-art (SOTA) vision transformers before and after applying the Transformer Doctor method.  The table shows accuracy improvements (in percentage points) across five different datasets (CIFAR-10, CIFAR-100, ImageNet-10, ImageNet-50, and ImageNet-1K) for various transformer architectures such as ViT-Tiny, DeiT-Tiny, CaiT-XXS, TNT-Small, PVT-Tiny, Eva-Tiny and BeiT-Tiny. The '+Doctor' column indicates the performance after treatment with the Transformer Doctor. The table highlights the effectiveness of the Transformer Doctor method in enhancing model performance across diverse datasets and architectures.", "section": "6.2 Quantitative Analysis"}, {"figure_path": "chnJT8Nj8X/tables/tables_20_1.jpg", "caption": "Table 1: Performance of Transformer Doctor on various SOTA Transformers. '+Doctor' indicates the performance of model treated with Transformer Doctor (All Score are in %).", "description": "This table presents the performance improvement achieved by applying the Transformer Doctor framework to several state-of-the-art (SOTA) vision transformers.  The results are shown for five different datasets (CIFAR-10, CIFAR-100, ImageNet-10, ImageNet-50, and ImageNet-1K) and across various transformer architectures. For each model and dataset, the baseline accuracy is given, along with the accuracy after treatment with Transformer Doctor, showing the percentage increase in performance.  The '+Doctor' designation indicates the model's performance after treatment.", "section": "6.2 Quantitative Analysis"}]