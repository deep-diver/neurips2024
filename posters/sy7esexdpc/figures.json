[{"figure_path": "sy7eSEXdPC/figures/figures_7_1.jpg", "caption": "Figure 1: Probability that each model echoes the majority answer at round t = 11, as the number of responses at time t = 0 gives that majority answer (debate between 12 models are used).", "description": "This figure shows the probability that a model will echo the majority answer at round 11 of a debate, given that a certain number of models provided that same answer at round 0.  The x-axis represents the number of models giving the majority answer at round 0 (m), and the y-axis shows the probability of a single model echoing this majority opinion at round 11. Different colored bars represent different language models (Llama-3, Mistral, GPT-3.5).  The striped bars show the result after applying a diversity pruning intervention. The figure illustrates the effect of \"echo chambers\" in multi-agent debate and how diversity pruning mitigates this effect.", "section": "7 Experiments"}, {"figure_path": "sy7eSEXdPC/figures/figures_7_2.jpg", "caption": "Figure 2: Average accuracy improvement as a function of response diversity at round 0 of debate.", "description": "This figure shows how the accuracy improvement of the proposed method and the baseline method (SoM) changes as a function of response diversity at round 0. Response diversity is measured by the average pairwise similarity between responses at round 0.  The results are shown separately for four datasets: BoolQ, MMLU, TruthfulQA, and MathQ. The figure demonstrates that the proposed method consistently outperforms the baseline method, especially when the response diversity is low (high similarity). The effectiveness is more significant in BoolQ, MMLU, and TruthfulQA, while the improvement is not that substantial in MathQ.", "section": "7 Experiments"}, {"figure_path": "sy7eSEXdPC/figures/figures_8_1.jpg", "caption": "Figure 3: Accuracy per round, our method and SoM when combing GPT-3.5 with Llama-3 or Mistral.", "description": "This figure compares the accuracy of the proposed method and the Society of Minds (SoM) method across different rounds of debate.  Two model combinations are shown: GPT-3.5 and Llama-3, and GPT-3.5 and Mistral. For each combination, two lines are plotted, representing the accuracy of SoM and the proposed method. The shaded area around each line represents the confidence interval.  The plot shows how accuracy evolves over the course of the debate for each method and model pair, highlighting the differences in performance between the proposed method and SoM. The x-axis represents the round of debate, and the y-axis shows the accuracy.", "section": "7 Experiments"}]