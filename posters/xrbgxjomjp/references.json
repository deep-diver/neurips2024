{"references": [{"fullname_first_author": "Abbeel", "paper_title": "Apprenticeship learning via inverse reinforcement learning", "publication_date": "2004-00-00", "reason": "This paper introduces the foundational concept of apprenticeship learning, which is the basis for the inverse reinforcement learning methods explored in the target paper."}, {"fullname_first_author": "Arora", "paper_title": "A survey of inverse reinforcement learning: Challenges, methods and progress", "publication_date": "2021-00-00", "reason": "This survey paper provides a comprehensive overview of the field of inverse reinforcement learning, contextualizing the target paper's contribution within the broader literature."}, {"fullname_first_author": "Garg", "paper_title": "Iq-learn: Inverse soft-q learning for imitation", "publication_date": "2021-00-00", "reason": "This paper introduces the Inverse Soft Q-Learning algorithm, which is the foundation upon which the multi-agent version proposed in the target paper is built."}, {"fullname_first_author": "Rashid", "paper_title": "Monotonic value function factorization for deep multi-agent reinforcement learning", "publication_date": "2020-00-00", "reason": "This paper introduces the QMIX algorithm and its value function factorization, which is leveraged in the target paper's multi-agent approach to overcome the limitations of centralized value function learning."}, {"fullname_first_author": "Song", "paper_title": "Multi-agent generative adversarial imitation learning", "publication_date": "2018-00-00", "reason": "This paper explores multi-agent imitation learning using a generative adversarial approach, offering a contrasting method to the inverse soft Q-learning technique developed in the target paper."}]}