[{"figure_path": "2TXDHUqyrQ/figures/figures_0_1.jpg", "caption": "Figure 1: Performance overview. We present DiffuserLite, a lightweight framework that utilizes progressive refinement planning to reduce redundant information generation and achieves real-time diffusion planning. DiffuserLite significantly outperforms predominant frameworks, Diffuser and DD, regarding scores, inference time, and model size on three popular D4RL benchmarks. The decision-making frequency of DiffuserLite achieves 122.2Hz, which is 112.7 times higher than predominant frameworks.", "description": "This figure provides a comparison of the performance of DiffuserLite against two existing diffusion planning methods (Diffuser and DD) across three different benchmark tasks (MuJoCo, Kitchen, and AntMaze).  Key metrics compared include task scores, decision frequency (Hz), and model size (in millions of parameters).  The results demonstrate that DiffuserLite achieves significantly higher scores, a much faster decision frequency, and a smaller model size compared to the other methods, highlighting its efficiency and improved performance.", "section": "Abstract"}, {"figure_path": "2TXDHUqyrQ/figures/figures_1_1.jpg", "caption": "Figure 2: Comparison of one-shot planning (top) and PRP (down) on Antmaze. The former directly generates plans with a temporal horizon of 129. The latter consists of three coarse to fine-grained levels with temporal horizons of 0-128, 0-32, and 0-8, and temporal jumps of 32, 8, and 1, respectively. The visualization in the figure illustrates the x-y coordinates of 100 plans. It shows that one-shot planning exhibits a significant amount of redundant information and a large search space. In contrast, PRP demonstrates better plan consistency and a smaller search space.", "description": "This figure compares one-shot planning and the proposed plan refinement process (PRP) in the AntMaze environment.  It visually demonstrates how PRP reduces redundant information and the search space, leading to more consistent plans compared to the one-shot approach.", "section": "1 Introduction"}, {"figure_path": "2TXDHUqyrQ/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of DiffuserLite. Observing the current state o<sub>t</sub>, level 0 of DiffuserLite fixes o<sub>t</sub> as o<sub>0</sub> and generates multiple candidate trajectories. A critic is then used to select the optimal one, in which o<sub>H0</sub> is then passed to the next level as its terminal o<sub>H1-1</sub>. The plan refinement process continues iteratively until the last level with a temporal jump of I<sub>L\u22121</sub> = 1. Finally, the action a<sub>t</sub> to be executed is extracted using an inverse dynamic model a<sub>t</sub> = h(o<sub>0</sub>,o<sub>1</sub>).", "description": "This figure provides a visual overview of the DiffuserLite architecture. It shows how the model generates trajectories level by level, refining the plan at each stage using a critic to select the optimal trajectory and an inverse dynamic model to extract the action. The process starts with the current state and iteratively refines the plan until the final action is determined.", "section": "4 A Lite Architecture for Real-time Diffusion Planning"}, {"figure_path": "2TXDHUqyrQ/figures/figures_5_1.jpg", "caption": "Figure 4: Runtime and performance comparison in FrankaKitchen. The y-axis represents the number of completed tasks (maximum of 4), and the x-axis represents the required wall-clock time. Task success rates are presented in colored circles. All results are averaged over 250 rollouts. DiffuserLite demonstrates significant advantages in both wallclock time and success rate.", "description": "This figure compares the runtime and performance of DiffuserLite against Diffuser and DD on the FrankaKitchen benchmark.  The y-axis shows the number of tasks completed (out of a maximum of 4), while the x-axis represents the time taken.  Each point represents the average of 250 rollouts.  The colored circles indicate task success rates, and the lines illustrate how the number of tasks completed changes with time for each method. The figure highlights that DiffuserLite achieves a significantly higher number of completed tasks in a much shorter time than the baselines.", "section": "5.1 Experimental Setup"}, {"figure_path": "2TXDHUqyrQ/figures/figures_13_1.jpg", "caption": "Figure 5: Part of selected benchmarks. From left to right, they are HalfCheetah, Hopper, Walker2d, FrankaKitchen, Robomimic, and Antmaze.", "description": "This figure shows six different benchmark environments used in the paper to evaluate the performance of the proposed DiffuserLite model and compare it with other baseline methods.  The environments represent diverse robotic control tasks, including locomotion (HalfCheetah, Hopper, Walker2d), manipulation (FrankaKitchen, Robomimic), and navigation (Antmaze). These diverse tasks provide a comprehensive evaluation of the model's generalization and adaptability across different domains.", "section": "A Details of Experimental Setup"}, {"figure_path": "2TXDHUqyrQ/figures/figures_20_1.jpg", "caption": "Figure 7: Visual comparison of DiffuserLite using conditions with (upper) or without (lower) values. It displays 100 plans generated at the current state, where darker colors indicate closer proximity to the current state, and lighter colors indicate further. With the pure-rewards condition, we can observe that the planned states in lighter colors tend to cluster together at a certain point on the map, indicating the planner tries to stop at that non-endpoint. However, with the introduction of values, the planner can make correct long-term plans that lead to the endpoint.", "description": "This figure compares the plans generated by DiffuserLite with and without value conditions in the AntMaze environment.  The darker the color of a plan, the closer it is to the current state. Using only rewards, plans tend to cluster prematurely, away from the goal. Adding value conditions results in plans that more directly reach the goal.", "section": "E.4 Performance with or without Value Condition"}]