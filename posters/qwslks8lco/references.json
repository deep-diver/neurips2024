{"references": [{"fullname_first_author": "Richard S Sutton", "paper_title": "Integrated architectures for learning, planning, and reacting based on approximating dynamic programming", "publication_date": "1990-01-01", "reason": "This paper introduces the Dyna architecture, a foundational model-based reinforcement learning framework that inspires the core idea of integrating a simulator into the multi-agent reinforcement learning pipeline in the current work."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering the game of go with deep neural networks and tree search", "publication_date": "2016-01-01", "reason": "This paper demonstrates the power of combining deep learning with tree search for solving complex decision-making problems, a technique that is relevant to the approach used in this paper."}, {"fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "publication_date": "2021-01-01", "reason": "This paper introduces the decision transformer, a sequence modeling approach to reinforcement learning, which is used as a key component in the proposed framework."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Off-policy deep reinforcement learning without exploration", "publication_date": "2019-01-01", "reason": "This paper introduces an off-policy deep reinforcement learning algorithm that is used as a baseline method and compared with the proposed method in the paper."}, {"fullname_first_author": "Mikayel Samvelyan", "paper_title": "The StarCraft multi-agent challenge", "publication_date": "2019-01-01", "reason": "This paper introduces the StarCraft Multi-Agent Challenge (SMAC) benchmark, which is used for evaluating the proposed method and comparing it with other existing methods."}]}