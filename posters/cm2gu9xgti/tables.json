[{"figure_path": "cM2gU9XGti/tables/tables_2_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the median number of function evaluations and success rates for different Bayesian optimization stopping rules across various benchmark functions.  It compares the proposed Probabilistic Regret Bound (PRB) method with several baselines (Oracle, Budget, Acq, ACB, AES), showing the median number of function evaluations needed to find a solution within \u03b5 of the optimum with probability at least 1-\u03b4.  The best-performing non-oracle methods are highlighted in blue.  The table also includes the dimensionality (D) of the problem and the noise level (\u03b3\u00b2) for Gaussian process (GP) objective functions.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_5_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2212 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different stopping rules for Bayesian optimization across various test functions (GP, Branin, Hartmann, Rosenbrock, CNN, XGBoost).  For each function, the table presents the median number of function evaluations until a solution within \u03b5 of the optimum is found with probability at least 1-\u03b4. The table compares six different stopping rules, including the proposed Probabilistic Regret Bound (PRB) method, with success rates showing how often these rules actually returned an \u03b5-optimal solution. The noise levels (\u03b3\u00b2) are also specified for Gaussian Process objectives.  Solutions found using the fewest function evaluations are highlighted in blue.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_7_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels y\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different stopping rules for Bayesian Optimization across various test problems.  It shows the median number of function evaluations needed to find a solution within a specified error bound (\u20ac) of the optimum with a given probability (1-\u03b4). The table compares the proposed Probabilistic Regret Bound (PRB) method to several baseline methods, including an oracle, fixed budget, and acquisition function based methods (Acq, ACB, AES).  Success rates (percentage of runs that found an \u03b5-optimal solution) are also presented.  Methods that achieved at least the desired success rate and used the fewest evaluations are highlighted in blue.  The table highlights the impact of noise levels in the objective function and the influence of oracle information on stopping criteria.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_18_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2212 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the results of applying different stopping criteria to Bayesian Optimization runs on several test problems.  For each problem, several metrics are compared, including median stopping times and the percentage of runs which successfully found an \u03b5-optimal solution.  Methods are compared against an oracle which knows the optimal solution and a budget-based approach (using an oracle to set the budget).  The table highlights methods which used the fewest function evaluations while maintaining a high success rate, indicating the efficiency of different stopping rules.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_19_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the median number of function evaluations and success rates for different stopping criteria across various benchmark problems.  The problems include synthetic Gaussian process functions with varying noise levels and dimensions, as well as real-world problems such as hyperparameter tuning for a convolutional neural network (CNN) and XGBoost.  The stopping criteria compared are an oracle (optimal stopping), fixed budget, acquisition function value, several model-based methods, and the proposed probabilistic regret bound (PRB).  Success is defined as achieving an \u03b5-optimal solution with at least 1-\u03b4 probability (\u03b5 and \u03b4 being hyperparameters).  The table highlights the PRB method's performance relative to other methods, indicating the number of function evaluations it required to achieve a similar success rate.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_19_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table compares the performance of different stopping rules (Oracle, Budget, Acq, ACB, AES, PRB) for Bayesian Optimization across several problems with different dimensions and noise levels.  It shows the median number of function evaluations before stopping and the percentage of runs that successfully found an \u03b5-optimal solution. The best-performing methods (non-oracle) that achieved at least a 95% success rate with the fewest evaluations are highlighted in blue.  The table helps to evaluate the efficiency and effectiveness of the proposed Probabilistic Regret Bound (PRB) stopping rule compared to existing methods.  Note that some methods were given oracle parameters for a fairer comparison.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_20_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the median number of function evaluations and success rates of different Bayesian Optimization stopping rules for various benchmark problems.  It compares the proposed probabilistic regret bound (PRB) method against several baselines, including an oracle (that knows the true optimum), a fixed budget, and other model-based methods.  The problems encompass different dimensions and noise levels, allowing for a comprehensive comparison of the stopping rule performance. The best performing methods are highlighted.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_21_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the results of experiments comparing different stopping rules for Bayesian Optimization.  For various benchmark problems (GP, Branin, Hartmann, Rosenbrock, CNN, XGBoost) with different dimensions and noise levels, the table shows the median number of function evaluations needed to find a near-optimal solution (within \u03b5 of the optimum with probability at least 1-\u03b4), as well as the percentage of successful runs that achieved this. The results are presented separately for oracle and non-oracle methods, with oracle methods having access to perfect information not typically available in practice.  The table highlights methods that achieved the desired accuracy while using fewer evaluations, with those results marked in blue.  This allows for a comparison of stopping criteria efficiency and performance in different problem settings.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_21_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different stopping rules for Bayesian Optimization on various test functions.  It shows the median number of function evaluations until the stopping criterion was met, and the percentage of runs that successfully found an \u03b5-optimal solution (within \u03b5 of the optimum with probability at least 1-\u03b4).  The table compares the proposed Probabilistic Regret Bound (PRB) method against several baselines, including an oracle (which knows the optimal solution), a fixed budget, and several other model-based approaches. The best-performing method (in terms of fewest function evaluations while achieving at least the target success rate) is highlighted in blue for each problem. Different noise levels are tested for Gaussian process (GP) objectives, and the use of an oracle (which gives the algorithm the best parameters and budget) is noted.  The problems include synthetic benchmark functions and more realistic machine learning hyperparameter tuning tasks.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_21_3.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different stopping criteria for Bayesian Optimization across various test functions.  It shows the median number of function evaluations until termination and the percentage of successful runs (those finding a solution within \u03b5 of the optimum with at least 1-\u03b4 probability).  Different noise levels and dimensions are tested.  The table highlights the proposed probabilistic regret bound (PRB) method's performance in comparison to several baselines, with the best-performing methods (fewest evaluations and high success rate) shown in blue.  The 'Oracle' column represents an idealized scenario where the algorithm knows optimal solutions.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_22_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different Bayesian optimization stopping rules across various benchmark problems.  For each problem, it shows the median number of function evaluations until stopping, the percentage of runs that successfully found a good-enough solution, and the best performing stopping rule (in blue).  The problems include Gaussian process (GP) regression with varying noise levels, and several black-box optimization problems.  The results highlight the relative efficiency and robustness of the proposed probabilistic regret bound (PRB) method compared to existing baselines, particularly in scenarios with significant model uncertainty or noise.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_22_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the results of the experiments comparing different stopping rules (Oracle, Budget, Acq, ACB, AES, PRB) for Bayesian optimization on various benchmark problems.  For each problem, the median number of function evaluations until stopping and the percentage of successful runs (finding an \u03b5-optimal solution with probability at least 1-\u03b4) are reported.  The table highlights the performance of the proposed PRB (Probabilistic Regret Bound) method, comparing its efficiency and success rate with established methods.  The problems include synthetic Gaussian processes with varying noise levels and dimensions, along with several real-world black-box optimization problems (Branin, Hartmann, Rosenbrock, CNN, XGBoost).  Note that some methods used oracle information (indicated by \u2020) to set hyperparameters or stopping criteria for a fairer comparison.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_22_3.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels y2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned e-optimal points at least 1 \u2212 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the median number of function evaluations and success rates for different Bayesian optimization stopping rules on various benchmark problems.  The problems include synthetic functions generated from Gaussian Processes with different noise levels, and real-world problems such as hyperparameter optimization for a convolutional neural network (CNN) on the MNIST dataset and an XGBoost model for income prediction. The stopping rules compared are: Oracle (optimal stopping time with perfect knowledge), Budget (predefined number of evaluations), Acquisition (stopping when acquisition function values are negligible), ACB (stopping when the gap between upper and lower confidence bounds is small), \u2206\u0395\u03a3 (stopping when the difference in expected supremums between consecutive steps is small), and PRB (the proposed probabilistic regret bound). The best-performing non-oracle method for each problem is highlighted in blue.  The table shows that the PRB method performs competitively with oracle methods, often with the fewest evaluations. ", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_23_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2212 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the median stopping times and success rates of different Bayesian Optimization (BO) stopping rules for various test functions.  The goal is to find a solution within \u03b5 of the optimum with probability at least 1-\u03b4. The table compares the performance of the proposed Probabilistic Regret Bound (PRB) method against several baselines.  Metrics include the median number of function evaluations performed before stopping and the percentage of successful runs (finding an \u03b5-optimal solution).  The table highlights the situations where PRB performs best, indicating when its adaptive nature provides benefits.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_23_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels y2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned e-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different stopping rules in Bayesian optimization across various benchmark problems.  It shows the median number of function evaluations required to reach an e-optimal solution, along with the percentage of successful runs that achieved this. The problems include both synthetic (Gaussian processes with varying noise levels) and real-world (hyperparameter optimization for neural networks and gradient boosting) tasks. The table highlights the proposed probabilistic regret bound (PRB) method's performance compared to several baselines, indicating its effectiveness in finding good solutions efficiently.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_23_3.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the median number of function evaluations and success rates for different Bayesian optimization stopping rules across various benchmark problems.  The problems include Gaussian process (GP) regression problems with varying dimensionality (D) and noise levels, along with the Branin, Hartmann, Rosenbrock, convolutional neural network (CNN) training, and XGBoost hyperparameter tuning tasks.  The stopping rules compared are: Oracle (optimal stopping time with perfect knowledge), Budget (predefined evaluation budget), Acquisition function (stopping when the acquisition function value is negligible), ACB (stopping when upper and lower confidence bounds are close), \u2206\u0395\u03a3 (stopping based on the change in expected improvement), and the proposed PRB (probabilistic regret bounds) method.  The table highlights the performance of each method in terms of the number of function evaluations required to achieve a 95% success rate (finding an \u03b5-optimal solution with at least 95% probability). Methods shown in blue achieved this success rate with fewer function evaluations than others.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_24_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the median stopping times and success rates of different Bayesian Optimization stopping rules on various test functions.  The test functions include synthetic Gaussian Processes (GPs) with varying noise levels and dimensionality, as well as real-world problems such as the Branin function, Hartmann functions, Rosenbrock function, and optimization tasks for Convolutional Neural Networks (CNNs) and XGBoost models.  The table compares the proposed Probabilistic Regret Bound (PRB) stopping rule to several baseline methods, including an oracle, a fixed budget, and methods that rely on acquisition functions, confidence bounds, or changes in the expected supremum.  The best performing method for each problem (non-oracle) is highlighted in blue.  The table provides insights into the performance and efficiency of the proposed PRB stopping rule in various settings.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_24_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different Bayesian optimization stopping rules across various test problems.  It presents the median number of function evaluations required to reach a solution and the percentage of trials where such a solution is within a specified tolerance (\u03b5) of the true optimum with a given probability (1-\u03b4).  The test problems include Gaussian processes with different noise levels and dimensions, as well as several common benchmark black-box optimization functions (Branin, Hartmann, Rosenbrock) and real-world problems (CNN hyperparameter tuning, XGBoost hyperparameter tuning).  The 'Oracle' column represents the optimal stopping time given perfect knowledge; other columns show the performance of the proposed probabilistic regret bound (PRB) method and several baseline methods.  Methods achieving the highest success rate with fewest evaluations are highlighted.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_24_3.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "The table presents the median stopping times and success rates of different Bayesian Optimization stopping rules for various benchmark functions.  It compares the proposed Probabilistic Regret Bound (PRB) method against several baselines, including an oracle, fixed budget, and other model-based approaches. The functions tested include Gaussian Processes (GPs) with varying noise levels and dimensionality, as well as more complex functions such as Branin, Hartmann, Rosenbrock, a convolutional neural network (CNN) on MNIST, and XGBoost on the Adult dataset.  The table highlights which methods successfully returned \u03b5-optimal solutions (i.e., solutions within \u03b5 of the optimum) with at least 1-\u03b4 probability, and it indicates which non-oracle method achieved this with the fewest function evaluations for each problem.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_25_1.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2013 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table summarizes the performance of different Bayesian Optimization (BO) stopping rules on various benchmark functions, including Gaussian process (GP) regression tasks with varying noise levels, and real-world problems such as hyperparameter optimization for convolutional neural networks (CNNs) and XGBoost models.  For each problem and stopping rule, the table reports the median number of function evaluations (stopping time) required to find a solution within a specified error tolerance (\u03b5) with at least a specified probability (1-\u03b4). The \"success rate\" indicates the percentage of runs that successfully found an \u03b5-optimal solution.  The table highlights the proposed Probabilistic Regret Bound (PRB) method and compares it to several baseline methods (Oracle, Budget, Acq, ACB, AES), indicating instances where PRB outperforms other methods in terms of efficiency and/or success rate. The color-coding helps to identify the best-performing non-oracle method for each problem.", "section": "5 Experiments"}, {"figure_path": "cM2gU9XGti/tables/tables_25_2.jpg", "caption": "Table 1: Median stopping times and success rates when seeking (\u20ac, \u03b4)-optimal points on X = [0, 1]D given an upper limit of T \u2208 N function evaluations. For GP objectives, number beside each name specify noise levels \u03b3\u00b2. Superscripts \u2020 indicate that model or stopping rule parameters were given by an oracle. For each problem, non-oracle methods that returned \u03b5-optimal points at least 1 \u2212 \u03b4 percent of the time using the fewest function evaluations are shown in blue.", "description": "This table presents the median number of function evaluations and success rates for different Bayesian optimization stopping rules across various test functions.  It compares the proposed probabilistic regret bound (PRB) method against several baseline methods (Oracle, Budget, Acq, ACB, \u2206\u0395\u03a3).  The test functions include Gaussian process (GP) functions with different noise levels and dimensions, and real-world black-box functions like Branin, Hartmann, Rosenbrock, CNN (convolutional neural network on MNIST), and XGBoost. The table highlights the performance of each method in terms of the number of evaluations required to find an \u03b5-optimal solution with at least 1-\u03b4 probability, showing which methods are most efficient in various scenarios.", "section": "5 Experiments"}]