[{"figure_path": "B0OWOkMwhz/figures/figures_1_1.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the novel view synthesis results of MVSplat360 against other state-of-the-art methods on the DL3DV-10K dataset.  It showcases various scenes with diverse characteristics (indoor/outdoor, high/low texture, reflective/non-reflective surfaces) to demonstrate the superior performance and robustness of MVSplat360 in handling challenging conditions.  The visual differences highlight MVSplat360's ability to produce more realistic and detailed novel views, particularly where other methods struggle with artifacts or missing information.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}, {"figure_path": "B0OWOkMwhz/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our MVSplat360. (a) Given sparse posed images as input, we first match and fuse the multi-view information using a multi-view Transformer and cost volume-based encoder. (b) Next, a 3DGS representation is constructed to represent the coarse geometry of the entire scene. (c) Considering such coarse reconstruction is imperfect, we further adapt a pre-trained SVD, using features rendered from the 3DGS representation as conditions to achieve 360\u00b0 novel view synthesis.", "description": "This figure illustrates the overall architecture of the MVSplat360 model. It consists of three main stages: (a) Multi-view feature fusion using a transformer and cost volume to combine information from sparse input views; (b) Coarse 3D geometry reconstruction using a 3D Gaussian Splatting (3DGS) model to obtain a rough 3D representation of the scene; and (c) Appearance refinement using a pre-trained Stable Video Diffusion (SVD) model, conditioned on features from the 3DGS model, to generate photorealistic and temporally consistent novel views.", "section": "3 Methodology"}, {"figure_path": "B0OWOkMwhz/figures/figures_7_1.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the novel view synthesis results of four different methods (pixelSplat, MVSplat, latentSplat, and MVSplat360) against ground truth images on the DL3DV-10K dataset.  It demonstrates the superior visual quality of MVSplat360, particularly in handling scenes with varying levels of complexity (indoor/outdoor, texture, reflections, transparency). The results showcase MVSplat360's ability to produce more realistic and detailed novel views, especially when compared to other feed-forward methods.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}, {"figure_path": "B0OWOkMwhz/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the novel view synthesis results of four different methods (pixelsplat, MVSplat, latentSplat, and MVSplat360) on the DL3DV-10K dataset.  It highlights the superior performance of MVSplat360 in generating high-quality, visually appealing results across a variety of scene types (indoor/outdoor, high/low texture, reflective/non-reflective). Red boxes highlight specific areas where MVSplat360's performance is particularly impressive, showcasing its ability to reconstruct details missing from other methods. The ground truth images are also shown for comparison.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}, {"figure_path": "B0OWOkMwhz/figures/figures_9_1.jpg", "caption": "Figure 5: SfM on input and rendered views. Images with red borders are the input views, while others are rendered by our MVSplat360. The reasonably recovered camera poses and 3D point clouds via VGGSfM imply that our outputs are multi-view consistent and geometrically correct.", "description": "This figure shows the results of Structure from Motion (SfM) applied to both the input views and the novel views generated by MVSplat360.  The input views are marked with red borders.  The SfM process, using VGGSfM, successfully reconstructs the camera poses and a 3D point cloud from both the input and generated views. This demonstrates the multi-view consistency and geometric accuracy of the novel views produced by the MVSplat360 model.", "section": "5 Conclusion"}, {"figure_path": "B0OWOkMwhz/figures/figures_14_1.jpg", "caption": "Figure A: Autoencoder using inputs with different resolutions. The SVD's first-stage encoder and decoder are sensitive to image resolution. Hence, to ensure that images are encoded to the expected latent space, we upscale them 2 times via bilinear interpolation before feeding them to SVD.", "description": "This figure shows the impact of input image resolution on the SVD's first-stage autoencoder.  The autoencoder's performance is sensitive to resolution differences between training and inference.  The images on the left are the original inputs. The middle column shows results when using the original input resolution, illustrating the significant loss of detail.  The right column shows the effect of upscaling the input images by a factor of 2 using bilinear interpolation before passing to the autoencoder; this improves results substantially, demonstrating that resolution matching is crucial for effective encoding into the latent space.", "section": "A More Experiment Results"}, {"figure_path": "B0OWOkMwhz/figures/figures_15_1.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the visual quality of novel view synthesis generated by MVSplat360 and other state-of-the-art methods on the DL3DV-10K dataset.  It showcases the superior performance of MVSplat360 in handling diverse scene complexities, including variations in lighting, texture, and occlusion. The results demonstrate that MVSplat360 produces more visually appealing and realistic novel views than the other methods.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}, {"figure_path": "B0OWOkMwhz/figures/figures_15_2.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the novel view synthesis results of four different methods on the DL3DV-10K dataset.  The methods compared are pixelsplat, MVSplat, latentsplat, and the authors' proposed method MVSplat360.  The ground truth images are also shown for comparison.  The figure highlights the superior visual quality of MVSplat360, particularly in handling challenging scenes with diverse lighting conditions, levels of texture and occlusion, and indoor vs outdoor settings.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}, {"figure_path": "B0OWOkMwhz/figures/figures_16_1.jpg", "caption": "Figure 3: Qualitative comparisons on DL3DV-10K. MVSplat360 shows significant improvement compared to existing SoTA models. Here, we showcase with a rich mix of diversity and complexity, including indoor (bounded) vs. outdoor (unbounded), high vs. low texture frequency, more vs. less reflection, and more vs. less transparency. More results are provided in Appendix E.", "description": "This figure compares the novel view synthesis results of MVSplat360 against other state-of-the-art methods on the DL3DV-10K dataset.  It demonstrates MVSplat360's superior performance in generating high-quality, visually appealing novel views even in challenging scenarios with diverse scene complexities (indoors/outdoors, high/low texture, reflections, transparency). The results highlight the advantages of MVSplat360's approach in handling scenes with limited overlapping sparse views.", "section": "4.2 Results on the New DL3DV-10K Benchmark"}]