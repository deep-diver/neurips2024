{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is crucial to many open-vocabulary semantic segmentation methods, including the method proposed in this paper."}, {"fullname_first_author": "Chao Jia", "paper_title": "Scaling up visual and vision-language representation learning with noisy text supervision", "publication_date": "2021-07-01", "reason": "This paper introduces a method for scaling up vision-language representation learning, which is relevant to the open-vocabulary semantic segmentation task addressed in this paper."}, {"fullname_first_author": "Amanpreet Singh", "paper_title": "Flava: A foundational language and vision alignment model", "publication_date": "2022-06-01", "reason": "This paper introduces another powerful vision-language model, FLAVA, which is used as a backbone for many open-vocabulary semantic segmentation methods, and provides another approach for addressing the task presented in this paper."}, {"fullname_first_author": "Jian Ding", "paper_title": "Decoupling zero-shot semantic segmentation", "publication_date": "2022-06-01", "reason": "This paper proposes a decoupling method for zero-shot semantic segmentation that improves efficiency and performance, and is highly relevant to the efficiency and performance improvements claimed in this paper."}, {"fullname_first_author": "Chong Zhou", "paper_title": "Extract free dense labels from clip", "publication_date": "2022-06-01", "reason": "This paper introduces a method for extracting dense labels from CLIP, providing a strong baseline for open-vocabulary semantic segmentation methods that is compared against in this paper."}]}