[{"figure_path": "dz6ex9Ee0Q/figures/figures_2_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "The figure shows the robustness of several graph neural networks (GNNs) against adaptive local attacks.  The x-axis represents the percentage of edges perturbed relative to the target node's degree, which acts as a measure of attack strength. The y-axis shows the classification accuracy of the GNNs. The results indicate that SoftMedian, TWIRLS, and ElasticGNN exhibit similar and relatively higher robustness initially but all selected GNNs show a catastrophic drop in accuracy as the attack budget increases.", "section": "2.1 Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_3_1.jpg", "caption": "Figure 2: Different mean estimators in the presence of outliers. The clean samples are the majority of data points following the Gaussian distribution N((0, 0), 1 \u00b7 I), while the outliers are data points that deviate significantly from the main data pattern, following N((8, 8), 0.5 \u00b7 I). l2-estimator deviates far from the true mean, while the l\u2081-based estimator is more resistant to outliers. However, as the ratio of outliers escalates, the l\u2081-based estimator encounters a greater shift from the true mean, but our estimator still maintains a position close to the ground truth.", "description": "This figure compares different mean estimators (l1, l2, and the proposed method) in the presence of outliers. It shows that the l1 estimator is more robust to outliers than the l2 estimator, but still suffers from bias as the number of outliers increases. The proposed method is shown to be more robust and less biased than both l1 and l2 estimators.", "section": "Bias Analysis and Performance Degradation"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_4_1.jpg", "caption": "Figure 3: Penalties.", "description": "This figure compares three penalty functions: MCP (blue), l1 (green), and l2 (orange).  The MCP penalty function is a non-convex function that approximates the l1 norm for small values of y and becomes constant for larger values of y. This property helps mitigate estimation bias in the presence of outliers and enhances the robustness of the model. The l1 penalty is a linear function that is robust to outliers but can induce estimation bias, whereas the l2 penalty is a quadratic function that is less robust to outliers but has desirable mathematical properties. The figure shows how the MCP penalty balances these properties, combining the robustness of l1 and the mathematical convenience of l2.", "section": "3 Robust GNNs with Unbiased Aggregation"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_6_1.jpg", "caption": "Figure 3. Penalties.", "description": "The figure shows a comparison of three penalty functions used in graph signal smoothing: RUGE (Robust and Unbiased Graph signal Estimator), l1, and l2.  The x-axis represents the magnitude of the feature difference between adjacent nodes (y), while the y-axis represents the penalty value (Wij). RUGE is a hybrid approach combining properties of l1 and l2, providing a balance between robustness and unbiasedness.  The vertical dotted line indicates a threshold (\u03b3) where the behavior of RUGE transitions from a sharp penalty (similar to l1) to a flatter penalty (similar to l2).", "section": "3 Robust GNNs with Unbiased Aggregation"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_8_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "The figure shows the robustness of different graph neural networks (GNNs) against adaptive local attacks. The x-axis represents the percentage of edges perturbed relative to the target node's degree, and the y-axis represents the node classification accuracy.  The results show that SoftMedian, TWIRLS, and ElasticGNN perform similarly and better than other methods initially, but their performance drops significantly as the attack budget increases.  This demonstrates the vulnerability of these models to adaptive attacks.", "section": "Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_14_1.jpg", "caption": "Figure 2: Different mean estimators in the presence of outliers. The clean samples are the majority of data points following the Gaussian distribution N((0, 0), 1 \u00b7 I), while the outliers are data points that deviate significantly from the main data pattern, following N((8, 8), 0.5 \u00b7 I). l2-estimator deviates far from the true mean, while the l\u2081-based estimator is more resistant to outliers. However, as the ratio of outliers escalates, the l\u2081-based estimator encounters a greater shift from the true mean, but our estimator still maintains a position close to the ground truth.", "description": "This figure compares different mean estimators (l2, l1, and the proposed MCP-based estimator) under different outlier ratios. It demonstrates that the l1-based estimator is more robust to outliers than the l2-based estimator, but it still suffers from bias as the outlier ratio increases.  The proposed MCP-based estimator is shown to be less susceptible to this bias.", "section": "Bias Analysis and Performance Degradation"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_21_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "The figure shows the robustness of several GNN models against adaptive local attacks.  The x-axis represents the percentage of edges perturbed relative to the target node's degree, simulating different attack strengths.  The y-axis shows the classification accuracy.  SoftMedian, TWIRLS, and ElasticGNN exhibit similar, relatively high robustness initially, but their performance drastically decreases as the attack budget increases, eventually performing worse than a simple MLP (which doesn't use graph structure).  Other GNN models show less improvement and similar performance degradation.", "section": "Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_22_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "This figure shows the robustness of various graph neural networks (GNNs) against adaptive local attacks. The x-axis represents the attack budget (percentage of edges perturbed relative to the node degree), and the y-axis represents the accuracy of the GNNs.  The results show that SoftMedian, TWIRLS, and ElasticGNN exhibit relatively better robustness compared to other GNNs, but their performance degrades significantly as the attack budget increases.", "section": "2.1 Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_22_2.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "This figure presents the results of a robustness analysis conducted on several Graph Neural Networks (GNNs) under adaptive local attacks. The x-axis represents the attack budget (percentage of edges perturbed relative to the node's degree), and the y-axis shows the node classification accuracy.  The results indicate that while SoftMedian, TWIRLS, and ElasticGNN show better initial robustness than other GNNs, all models eventually exhibit a significant drop in performance as the attack budget increases, underperforming a simple Multilayer Perceptron (MLP) that does not consider graph topology.", "section": "2.1 Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_25_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node\u2019s degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "This figure shows the robustness of several GNN models against adaptive local attacks.  The x-axis represents the percentage of edges perturbed relative to the degree of the target node. The y-axis represents the accuracy of node classification.  The figure highlights that while SoftMedian, TWIRLS, and ElasticGNN show initially better robustness than other models, their performance sharply decreases as the attack budget increases, eventually performing worse than graph-agnostic MLPs.", "section": "Robustness Analysis"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_26_1.jpg", "caption": "Figure 13: The performance dependence of RUNG on the number of aggregation layers.", "description": "This figure shows how the accuracy of the RUNG model changes as the number of aggregation layers increases under different attack budgets (5%, 10%, 20%, 40%).  It demonstrates the convergence behavior of the QN-IRLS algorithm within the RUNG architecture.  As the number of layers increases, the accuracy tends to improve, especially under higher attack budgets. The results suggest that a sufficient number of layers is necessary for the model to converge and achieve optimal robustness.", "section": "G.2 GNN Layers"}, {"figure_path": "dz6ex9Ee0Q/figures/figures_27_1.jpg", "caption": "Figure 1: Robustness analysis under adaptive local attack. The perturbation budget (x-axis) is the number of edges allowed to be perturbed relative to the target node's degree. SoftMedian, TWIRLS, and ElasticGNN (blue curves) exhibit similarly aligned competitive robustness among all the selected robust GNNs, but all models experience catastrophic performance degradation as the attack budget increases.", "description": "This figure shows the robustness of various GNN models against adaptive local attacks.  The x-axis represents the percentage of edges perturbed relative to the node's degree, simulating the attack budget.  The y-axis shows the node classification accuracy.  SoftMedian, TWIRLS, and ElasticGNN show initially better robustness than other models, but their performance degrades significantly as the attack budget increases, eventually performing worse than graph-agnostic MLPs.", "section": "Robustness Analysis"}]