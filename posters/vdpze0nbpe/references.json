{"references": [{"fullname_first_author": "Nicolo Cesa-Bianchi", "paper_title": "How to use expert advice", "publication_date": "1997-00-00", "reason": "This paper introduces the Hedge algorithm, a fundamental building block for many online learning algorithms, including those discussed in the target paper."}, {"fullname_first_author": "Peter Auer", "paper_title": "The nonstochastic multiarmed bandit problem", "publication_date": "2002-00-00", "reason": "This seminal paper introduces the EXP3 algorithm, a cornerstone of adversarial multi-armed bandit research, which is directly relevant to the target paper's exploration of Prod algorithms in bandit settings."}, {"fullname_first_author": "Jacob D Abernethy", "paper_title": "Competing in the dark: An efficient algorithm for bandit linear optimization", "publication_date": "2008-00-00", "reason": "This paper provides a crucial connection between online mirror descent (OMD) and multi-armed bandits, which is central to the target paper's analysis of Prod algorithms as OMD approximations."}, {"fullname_first_author": "Nicolo Cesa-Bianchi", "paper_title": "Improved second-order bounds for prediction with expert advice", "publication_date": "2007-00-00", "reason": "This paper introduces the Prod algorithm, which is the central focus of the target paper's investigation and analysis in the context of multi-armed bandit problems."}, {"fullname_first_author": "Rupert Freeman", "paper_title": "No-regret and incentive-compatible online learning", "publication_date": "2020-00-00", "reason": "This paper introduces the concept of incentive-compatible online learning and the WSU algorithm, which is closely related to Prod and directly motivates the target paper's investigation of Prod's applicability to incentive-compatible bandits."}]}