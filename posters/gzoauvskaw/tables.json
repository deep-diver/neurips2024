[{"figure_path": "GZoAUVSkaw/tables/tables_7_1.jpg", "caption": "Table 1: Test AUC score with 95% confidence interval on different datasets for AUC maximization.", "description": "This table presents the test AUC scores achieved by three different methods (mAUC, mAUC-CT, and FOSL) on four datasets (CIFAR100, CelebA, CheXpert, and OGBG-MolPCBA).  The scores represent the area under the receiver operating characteristic curve, a common metric for evaluating the performance of binary classification models. The confidence intervals provide a measure of the uncertainty in these estimates.", "section": "5.1 Deep AUC Maximization"}, {"figure_path": "GZoAUVSkaw/tables/tables_15_1.jpg", "caption": "Table 2: Test accuracy (%) on the Mini-ImageNet and the Tiered-ImageNet datasets for meta-learning.", "description": "This table presents the test accuracy results achieved by the MemCS algorithm and the baseline MAML algorithm on the Mini-ImageNet and Tiered-ImageNet datasets. The results are categorized into 'Clean', 'Flip', and 'Rand' scenarios, representing different noise levels in the training data. The 'Clean' scenario uses clean datasets without noise, while 'Flip' randomly flips a certain portion of labels, and 'Rand' assigns a random noisy ratio to each task.  This allows for a comparison of the algorithms' performance under various levels of data corruption.", "section": "5.2 Results"}]