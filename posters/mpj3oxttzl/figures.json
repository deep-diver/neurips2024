[{"figure_path": "MPJ3oXtTZl/figures/figures_1_1.jpg", "caption": "Figure 1: We develop a flexible question-answering framework targeting real-world textual graph applications via a unified conversational interface. Presented here are examples showcasing the model's adeptness in handling generative and creative queries in practical graph-related tasks: common sense reasoning, scene understanding, and knowledge graph reasoning, respectively.", "description": "This figure showcases the model's ability to answer complex and creative questions about three different types of textual graphs: explanation graphs, scene graphs, and knowledge graphs.  The unified conversational interface allows users to interact with the graphs using natural language. The examples demonstrate the model's versatility across multiple graph-related applications.", "section": "The Need for a Comprehensive GraphQA Benchmark"}, {"figure_path": "MPJ3oXtTZl/figures/figures_4_1.jpg", "caption": "Figure 2: Illustrative examples from the GraphQA benchmark datasets.", "description": "This figure shows three example questions from the GraphQA benchmark dataset.  The first example shows a commonsense reasoning task, where an explanation graph is given and the model is asked to determine if two arguments support or counter each other. The second example is a scene graph question-answering task where the question asks about the presence of a woman in a particular location relative to other objects. The third example is a knowledge-based question-answering task, where the question asks for the name of a sibling.", "section": "4 Proposed GraphQA Benchmark"}, {"figure_path": "MPJ3oXtTZl/figures/figures_5_1.jpg", "caption": "Figure 3: Overview of the proposed G-Retriever: 1) Indexing: Graphs are indexed for efficient query processing; 2) Retrieval: The most semantically relevant nodes and edges are retrieved, conditioned on the query; 3) Subgraph Construction: A connected subgraph is extracted, covering as many relevant nodes and edges as possible while maintaining a manageable graph size; 4) Generation: An answer is generated using a 'graph prompt', a textualized graph, and the query.", "description": "This figure illustrates the four main steps of the G-Retriever model for graph question answering.  First, the graph is indexed to allow for efficient query processing. Second, the most relevant nodes and edges are retrieved based on the input query.  Third, a connected subgraph containing many of these relevant nodes and edges is constructed, while keeping the size manageable for the LLM. Finally, an answer is generated using a textual representation of the subgraph as a prompt, along with the original query.", "section": "New Architecture for GraphQA"}, {"figure_path": "MPJ3oXtTZl/figures/figures_14_1.jpg", "caption": "Figure 3: Overview of the proposed G-Retriever: 1) Indexing: Graphs are indexed for efficient query processing; 2) Retrieval: The most semantically relevant nodes and edges are retrieved, conditioned on the query; 3) Subgraph Construction: A connected subgraph is extracted, covering as many relevant nodes and edges as possible while maintaining a manageable graph size; 4) Generation: An answer is generated using a 'graph prompt', a textualized graph, and the query.", "description": "This figure illustrates the four main steps of the G-Retriever model: indexing the graph for efficient query processing, retrieving the most relevant nodes and edges based on the query, constructing a manageable connected subgraph from the retrieved elements, and generating the final answer using the query and a textual representation of the subgraph.", "section": "New Architecture for GraphQA"}, {"figure_path": "MPJ3oXtTZl/figures/figures_15_1.jpg", "caption": "Figure 3: Overview of the proposed G-Retriever: 1) Indexing: Graphs are indexed for efficient query processing; 2) Retrieval: The most semantically relevant nodes and edges are retrieved, conditioned on the query; 3) Subgraph Construction: A connected subgraph is extracted, covering as many relevant nodes and edges as possible while maintaining a manageable graph size; 4) Generation: An answer is generated using a 'graph prompt', a textualized graph, and the query.", "description": "This figure illustrates the four main steps of the G-Retriever model.  First, the graph is indexed to allow for efficient searching. Second, nodes and edges relevant to the query are retrieved. Third, a subgraph is constructed from the retrieved elements to optimize size and relevance. Finally, an answer is generated using the textualized subgraph and the original query as input to the language model.", "section": "New Architecture for GraphQA"}, {"figure_path": "MPJ3oXtTZl/figures/figures_15_2.jpg", "caption": "Figure 3: Overview of the proposed G-Retriever: 1) Indexing: Graphs are indexed for efficient query processing; 2) Retrieval: The most semantically relevant nodes and edges are retrieved, conditioned on the query; 3) Subgraph Construction: A connected subgraph is extracted, covering as many relevant nodes and edges as possible while maintaining a manageable graph size; 4) Generation: An answer is generated using a 'graph prompt', a textualized graph, and the query.", "description": "This figure shows the four main steps of the G-Retriever model for graph question answering.  First, the graph is indexed to allow efficient retrieval of relevant parts. Second, the most relevant nodes and edges are retrieved based on semantic similarity to the query. Third, a connected subgraph is constructed using the prize-collecting Steiner tree optimization, balancing subgraph size and relevance. Finally, the textualized subgraph and the query are fed to an LLM to generate the answer.", "section": "New Architecture for GraphQA"}, {"figure_path": "MPJ3oXtTZl/figures/figures_16_1.jpg", "caption": "Figure 3: Overview of the proposed G-Retriever: 1) Indexing: Graphs are indexed for efficient query processing; 2) Retrieval: The most semantically relevant nodes and edges are retrieved, conditioned on the query; 3) Subgraph Construction: A connected subgraph is extracted, covering as many relevant nodes and edges as possible while maintaining a manageable graph size; 4) Generation: An answer is generated using a 'graph prompt', a textualized graph, and the query.", "description": "This figure illustrates the four main steps of the G-Retriever model: indexing the graph for efficient query processing, retrieving the most relevant nodes and edges based on the query, constructing a connected subgraph containing those relevant elements, and finally generating the answer using the subgraph, textualized graph, and the query as input to the LLM. The figure visually represents each step with diagrams and text descriptions for clarity.", "section": "New Architecture for GraphQA"}, {"figure_path": "MPJ3oXtTZl/figures/figures_23_1.jpg", "caption": "Figure 1: We develop a flexible question-answering framework targeting real-world textual graph applications via a unified conversational interface. Presented here are examples showcasing the model's adeptness in handling generative and creative queries in practical graph-related tasks: common sense reasoning, scene understanding, and knowledge graph reasoning, respectively.", "description": "This figure shows examples of how the G-Retriever model answers complex and creative questions using a conversational interface with different types of textual graphs (explanation graph, scene graph, and knowledge graph).  It highlights the model's ability to handle various question types and provide accurate and relevant answers by highlighting the relevant parts of the input graph.", "section": "The Need for a Comprehensive GraphQA Benchmark"}]