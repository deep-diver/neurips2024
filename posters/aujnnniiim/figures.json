[{"figure_path": "aujnNnIiiM/figures/figures_1_1.jpg", "caption": "Figure 1: Given a scene, we select the modules corresponding to its attributes, such as lighting and indoor/outdoor. These modules are composed and then deployed, yielding a specialized model.", "description": "This figure illustrates the PASTA framework's workflow.  First, a \"Domain Expert\" (either a human operator or an automated system) analyzes the input scene and selects the appropriate modules based on scene attributes like lighting conditions, indoor/outdoor setting etc. These individual modules, pre-trained on specific conditions, are then combined (composed) in the parameter space, which creates a specialized model for that scene. Finally, this combined model is deployed to the end-to-end tracker for processing.", "section": "1 Introduction"}, {"figure_path": "aujnNnIiiM/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our modular architecture. A domain expert selects PEFT modules based on sequence attributes such as lighting and camera movement. These selected modules are then composed and applied to each model layer, adapting the backbone and encoder-decoder architecture.", "description": "This figure illustrates the PASTA architecture.  A domain expert selects pre-trained PEFT (Parameter-Efficient Fine-Tuning) modules based on scene attributes (lighting, viewpoint, occupancy, location, camera movement). These selected modules are then combined in the parameter space, modifying the backbone and encoder-decoder. The process results in a specialized model tailored to the input scene.", "section": "4 Method"}, {"figure_path": "aujnNnIiiM/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of our modular architecture. A domain expert selects PEFT modules based on sequence attributes such as lighting and camera movement. These selected modules are then composed and applied to each model layer, adapting the backbone and encoder-decoder architecture.", "description": "This figure illustrates the modular architecture of the proposed PASTA framework.  It shows how a domain expert selects pre-trained PEFT (Parameter-Efficient Fine-Tuning) modules based on attributes of the input video sequence (lighting, camera viewpoint, etc.). These selected modules are then composed (combined) and applied to different layers of the backbone and encoder-decoder architecture of the query-based multiple object tracking model. This modular approach allows the model to adapt to different scenarios and domains without requiring extensive retraining.", "section": "Method"}, {"figure_path": "aujnNnIiiM/figures/figures_9_1.jpg", "caption": "Figure 4: IDF1 and MOTA when adding new attributes on MOTSynth.", "description": "This figure shows the impact of incrementally adding specialized modules on the MOTSynth dataset. The x-axis represents the cumulative addition of attributes (lighting, occupancy, motion, location, viewpoint), and the y-axis represents the IDF1 and HOTA metrics. We observe a clear upward trend in both metrics as more attributes (and modules) are incorporated, demonstrating that a more specialized model (as generated by our modular approach) improves performance.", "section": "5.4 Performance in the in-domain setting"}]