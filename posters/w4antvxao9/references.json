{"references": [{"fullname_first_author": "T. B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-06", "reason": "This paper is foundational for demonstrating the few-shot learning capabilities of large language models, a crucial concept for the current study on step-skipping abilities."}, {"fullname_first_author": "S. R. Bowman", "paper_title": "Measuring progress on scalable oversight for large language models", "publication_date": "2022-11-03", "reason": "This paper addresses the critical issue of oversight for large language models, which is relevant to the present work's aim of guiding models toward more efficient reasoning through step-skipping."}, {"fullname_first_author": "S. Bubeck", "paper_title": "Sparks of artificial general intelligence: Early experiments with GPT-4", "publication_date": "2023-03-12", "reason": "This paper explores the emergent reasoning abilities of large language models, providing a context for investigating the human-like step-skipping behavior in the current study."}, {"fullname_first_author": "J. Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting method, which is directly relevant to the current study's approach of iteratively refining models to generate shorter reasoning paths."}, {"fullname_first_author": "M. Kosinski", "paper_title": "Theory of mind may have spontaneously emerged in large language models", "publication_date": "2023-02-02", "reason": "This paper investigates the emergence of theory of mind in large language models, which offers a related perspective on human-like cognitive abilities and motivates the exploration of step-skipping as a similar capacity."}]}