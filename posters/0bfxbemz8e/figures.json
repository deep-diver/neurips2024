[{"figure_path": "0bFXbEMz8e/figures/figures_1_1.jpg", "caption": "Figure 1: FlowLLM generative process: the fine-tuned LLM is first prompted with an unconditional query to generate an initial material representation. This material is then iteratively transformed by the RFM model to update its atom positions and lattice parameters. The atom types are static in RFM.", "description": "The figure illustrates the two-step process of FlowLLM.  First, an unconditional prompt is given to a fine-tuned large language model (LLM) which generates a noisy initial material representation (text). This representation is then converted to a graph representation containing atom types, coordinates, and unit cell geometry. Then, a Riemannian Flow Matching (RFM) model iteratively refines this noisy material by updating atom positions and lattice parameters, finally producing a generated crystalline material structure. Atom types remain unchanged throughout the RFM refinement process.", "section": "4 Method"}, {"figure_path": "0bFXbEMz8e/figures/figures_3_1.jpg", "caption": "Figure 2: Left: String encoding of materials used to train the LLM based on Gruver et al.[11]. Right: An example prompt used during training. The conditioning information in blue is optional, and can be replaced with conditioning on other properties as well. The text in red is replaced with the crystal string representation shown on the left.", "description": "This figure illustrates the string encoding method used for representing materials in the LLM training process.  The left side shows how the chemical formula and lattice parameters are converted into a string format used as input for the LLM.  The right side shows an example of a prompt used to generate material representations during training.  This prompt uses a conditional approach and indicates that the LLM should take the chemical formula (optional) and generate a detailed crystal structure description. The parts in red and blue represent where the inputs are replaced in the prompt for training.", "section": "4.1 Large Language Model (PLLM) for Crystals"}, {"figure_path": "0bFXbEMz8e/figures/figures_8_1.jpg", "caption": "Figure 3: (a) Histogram of Ehull values comparing FlowLLM with prior models. The dashed line shows thermodynamic stability threshold (Ehull = 0). (b) Histogram of N-ary compared to the data distribution. (c) Structural validity as a function of number of integration steps.", "description": "This figure compares FlowLLM's performance against other models in terms of energy above the hull (Ehull), the number of unique elements per material (N-ary), and structural validity.  Panel (a) shows histograms of Ehull, demonstrating FlowLLM's generation of more stable materials. Panel (b) presents N-ary distributions, highlighting FlowLLM's better match to the data distribution. Finally, panel (c) illustrates how the structural validity of generated materials improves with more integration steps during the FlowLLM process.", "section": "5.3 Results"}]