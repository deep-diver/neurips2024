[{"figure_path": "yBHbeSpwYS/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of the concept and effect of contextual bias in training. It is common that \"Person\", \"Dog\", and \"Cat\" co-occur in training images (we only show one image), while the test image may only contain \"Person\" and \"Dog\". Excessive reliance on the label co-occurrence in the training set may lead the recognition model to predict the \"Cat\" solely based on the presence of \"Person\" and \"Dog\".", "description": "The figure shows an example of contextual bias in multi-label image recognition. In the training image, a person, a dog, and a cat are present together.  The model learns a strong correlation between these three labels.  However, in the testing image, only a person and a dog are present.  Because of the learned correlation, the model incorrectly predicts a high probability for 'cat', even though a cat isn't in the image.", "section": "1 Introduction"}, {"figure_path": "yBHbeSpwYS/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of causal label correlations and spurious correlations revealed by causal intervention, in a probability-raising sense that if P(Y|do(X)) > P(Y), then a causal correlation exists from X (\"Person\") to Y (categories in this figure).", "description": "The figure shows the results of causal intervention on a multi-label image recognition task. It compares the probability of predicting different object categories (Y) with and without the presence of a \"Person\" (X).  Bars represent the base probability of each category and the probability of the category given the presence of a person.  Categories where the probability increases significantly due to the presence of a person show causal correlation, while categories where the probability remains similar or decreases show spurious correlations. This illustrates the concept of causal intervention used in the proposed method to distinguish useful contextual information from misleading information. ", "section": "3 Preliminaries and Motivation of Causal Correlations"}, {"figure_path": "yBHbeSpwYS/figures/figures_3_1.jpg", "caption": "Figure 3: (a): Causal correlation between label X and Y, which is not affected by confounder set C. (b): Spurious correlation, where the co-occurence of X and Y is caused by confounder set C.", "description": "This figure illustrates the difference between causal and spurious correlations using a causal graph.  Panel (a) depicts a causal correlation where variable X causally influences variable Y, and this relationship isn't influenced by a confounder C.  In contrast, panel (b) shows a spurious correlation: X and Y appear correlated only because they both share a common cause, the confounder C. This highlights the importance of causal inference in discerning true relationships from mere statistical associations.", "section": "3 Preliminaries and Motivation of Causal Correlations"}, {"figure_path": "yBHbeSpwYS/figures/figures_4_1.jpg", "caption": "Figure 4: The overall framework of our proposed method.", "description": "The figure shows the overall framework of the proposed method for multi-label image recognition. It consists of two main branches: the decoupling label-specific features branch and the summarizing causal label correlations branch. The decoupling branch uses a transformer decoder to extract label-specific features from the input image's spatial features.  The causal correlations branch uses a cross-attention module with confounders (representing contextual information) to calculate causal correlations between object categories. Finally, the predictions from both branches are combined to produce the final multi-label prediction. ", "section": "4 Approach"}, {"figure_path": "yBHbeSpwYS/figures/figures_6_1.jpg", "caption": "Figure 4: The overall framework of our proposed method.", "description": "This figure shows the overall framework of the proposed method, which consists of two main branches: the decoupled label-specific features branch and the causal label correlations branch. The input image is first processed by a backbone network to extract spatial features. These features are then fed into a Transformer decoder to decouple label-specific features. These decoupled features are used to predict image labels based on the objects themselves. In parallel, the spatial features are also used to model confounders, which are then used with the decoupled features in a cross-attention module to implement causal intervention.  The predictions from both branches are then combined to generate the final multi-label prediction.", "section": "4 Approach"}, {"figure_path": "yBHbeSpwYS/figures/figures_13_1.jpg", "caption": "Figure 5: Visualization for the spatial feature map of baseline and our proposed method using the Grad-CAM [24].", "description": "The figure shows the Grad-CAM visualization for baseline and proposed methods on four images.  Grad-CAM highlights image regions that are most important for a specific prediction. This figure demonstrates that the proposed method better localizes the relevant object features compared to the baseline, especially when dealing with negative labels (where the object is not present in the image). The baseline tends to highlight spurious correlations, while the proposed method focuses specifically on the target object. In images (a) and (b), the model correctly predicts the presence of objects like \"cell phone\" and \"dog\" by focusing on those respective objects only. In images (c) and (d), which contain no baseball bat or spoon, the proposed method suppresses spurious correlations, unlike the baseline method.", "section": "A.2.4 Visualizations"}, {"figure_path": "yBHbeSpwYS/figures/figures_14_1.jpg", "caption": "Figure 6: t-SNE [29] visualization for confounders and label-specific features of \u201cBaseball Glove\u201d and \u201cPerson\u201d.", "description": "This figure shows the t-SNE visualization of confounders and two typical label-specific features (\u201cBaseball Glove\u201d and \u201cPerson\u201d) from the baseline and proposed methods.  In the baseline, the label-specific features for \"Baseball Glove\" and \"Person\" are mixed with each other and the confounders, indicating a strong correlation between them. In the proposed method, these features are pulled apart and away from the confounders, indicating that causal intervention successfully removes the influence of confounders and captures only causal label correlations.", "section": "A.2.5 t-SNE Visualization of Features"}]