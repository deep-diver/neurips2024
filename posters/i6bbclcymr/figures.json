[{"figure_path": "i6BBclCymR/figures/figures_1_1.jpg", "caption": "Figure 1: Dilemma of SDS. Average PSNR\u2191, SSIM\u2191, and LPIPS\u2193 of each iteration on the LLFF test dataset [22] with Base (without SDS), SDS (CFG=7.5), and SDS (CFG=100). The prior-added period starts from the 2K iteration and ends at the 9.5K iteration. The opacity is also reset at 2K. The details and final training results of SDS are shown in Sec. 4.4.", "description": "This figure shows the performance of Score Distillation Sampling (SDS) on the LLFF dataset during training.  It compares three settings: a baseline without SDS, SDS with a configuration factor (CFG) of 7.5, and SDS with a CFG of 100.  The graphs display PSNR (higher is better), SSIM (higher is better), and LPIPS (lower is better) over training iterations.  The results highlight a performance issue with SDS under sparse views (the 'SDS dilemma'), where the addition of the diffusion prior doesn't improve results, and can even hinder them. This issue is most evident in the CFG=100 case.  The figure indicates that the use of a diffusion prior via SDS is not directly beneficial for novel view synthesis from sparse views.", "section": "1 Introduction"}, {"figure_path": "i6BBclCymR/figures/figures_3_1.jpg", "caption": "Figure 2: Comparison of SDS and IPSM. Left: Tending to seek nearest mode, causing mode deviation. Right: Rectifying distribution to seek the target mode.", "description": "This figure compares the optimization processes of Score Distillation Sampling (SDS) and Inline Prior Guided Score Matching (IPSM).  The left panel illustrates SDS, showing how the rendered image distribution (red) is drawn towards the nearest mode (red star) in the diffusion prior (blue), even if it is not the desired target mode (yellow star). This deviation leads to suboptimal results.  The right panel shows IPSM, demonstrating how it rectifies the rendered image distribution (green) using inline priors, guiding the optimization towards the correct target mode (yellow star). This rectified distribution helps to suppress mode deviation and leads to improved reconstruction.", "section": "3 Method"}, {"figure_path": "i6BBclCymR/figures/figures_4_1.jpg", "caption": "Figure 3: IPSM-Gaussian obtains the inline prior within sparse views through inversely warping seen views to unseen pseudo views, thus modifying the rendered image distribution to the rectified distribution. Consequently taking the rectified distribution as the intermediate state, two sub-optimization objectives are utilized for controlling the optimization direction.", "description": "The figure illustrates the IPSM-Gaussian pipeline. It starts with sparse views and initializes 3D Gaussians.  Seen views are inversely warped to generate pseudo unseen views. These pseudo views, along with depth information, are used to create inline priors.  These priors modify the rendered image distribution, creating a rectified distribution.  The rectified distribution then guides the optimization process using score matching, improving the final reconstruction quality. This process leverages visual knowledge from diffusion priors to improve sparse-view 3D reconstruction without the need for fine-tuning or pre-training.", "section": "3 Method"}, {"figure_path": "i6BBclCymR/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparison on the LLFF dataset.", "description": "This figure shows a qualitative comparison of novel view synthesis results on the LLFF dataset.  The ground truth image is compared to results from 3DGS, FreeNeRF, DNGaussian, and the proposed IPSM method.  Red boxes highlight regions of interest where differences are readily apparent, demonstrating the improved accuracy and detail of the IPSM results, particularly in reconstructing smaller, finer features.", "section": "4. Experiments"}, {"figure_path": "i6BBclCymR/figures/figures_7_2.jpg", "caption": "Figure 5: Qualitative comparison on the LLFF dataset.", "description": "This figure shows a qualitative comparison of novel view synthesis results on the LLFF dataset.  It compares the ground truth images with results from three different methods: 3DGS, FreeNeRF, and DNGaussian, alongside the results from the authors' proposed method. The visual differences highlight the relative strengths and weaknesses of each technique in terms of detail, texture, and overall reconstruction quality.", "section": "4 Experiments"}, {"figure_path": "i6BBclCymR/figures/figures_8_1.jpg", "caption": "Figure 3: IPSM-Gaussian obtains the inline prior within sparse views through inversely warping seen views to unseen pseudo views, thus modifying the rendered image distribution to the rectified distribution. Consequently taking the rectified distribution as the intermediate state, two sub-optimization objectives are utilized for controlling the optimization direction.", "description": "This figure illustrates the IPSM-Gaussian pipeline.  It shows how seen views are inversely warped to create pseudo-unseen views. This warping, combined with depth and geometry consistency, refines the rendered image distribution, aligning it more closely with the target distribution from the diffusion model. The rectified distribution acts as an intermediate step in the optimization process, guiding the mode-seeking behavior of Score Distillation Sampling (SDS) to improve reconstruction quality.  Two sub-objectives, one for rectifying and one for aligning with the diffusion prior, are used to control this optimization process.", "section": "3 Method"}, {"figure_path": "i6BBclCymR/figures/figures_9_1.jpg", "caption": "Figure 2: Comparison of SDS and IPSM. Left: Tending to seek nearest mode, causing mode deviation. Right: Rectifying distribution to seek the target mode.", "description": "This figure compares the optimization process of Score Distillation Sampling (SDS) and Inline Prior Guided Score Matching (IPSM).  SDS, shown on the left, tends to converge to the nearest mode in the diffusion prior, leading to mode deviation and suboptimal results, especially under sparse views.  The rendered image distribution (red) fails to align well with the target mode (black). In contrast, IPSM (right) rectifies the rendered image distribution (red) by leveraging inline priors, thereby guiding the optimization towards the true target mode and enhancing visual guidance.", "section": "3 Method"}, {"figure_path": "i6BBclCymR/figures/figures_23_1.jpg", "caption": "Figure 8: Intuitive explanation of the inline priors.", "description": "This figure provides a visual illustration of how inline priors are used in the IPSM method.  It shows a series of image transformations for several example scenes. The first column displays the ground truth image. The second shows the rendered image from a pseudo-unseen viewpoint. The third is the rendered depth for that pseudo-viewpoint.  The fourth column displays the image from the seen viewpoint, warped to align with the pseudo-viewpoint. The fifth column presents a mask based on depth differences between the warped and rendered images. The sixth column shows the warped masked image, representing the inline prior. Finally, the seventh column depicts the image produced using the Stable Diffusion Inpainting model, conditioned on the noisy rendered image and the inline prior, demonstrating how the inline prior guides the mode-seeking process of the diffusion model.", "section": "3.2 IPSM: Inline Prior Guided Score Matching"}, {"figure_path": "i6BBclCymR/figures/figures_23_2.jpg", "caption": "Figure 3: IPSM-Gaussian obtains the inline prior within sparse views through inversely warping seen views to unseen pseudo views, thus modifying the rendered image distribution to the rectified distribution. Consequently taking the rectified distribution as the intermediate state, two sub-optimization objectives are utilized for controlling the optimization direction.", "description": "The figure shows the architecture of the IPSM-Gaussian pipeline, which consists of three main components: 1) a 3D Gaussian splatting module that represents the scene using a set of Gaussian points, 2) an inverse warping module that generates pseudo views from the given sparse views, and 3) an IPSM module that leverages the inline priors obtained from the pseudo views to refine the rendered image distribution and guide the optimization process. The pipeline is designed to effectively use the visual information provided by the diffusion model without requiring fine-tuning or pre-training.", "section": "3 Method"}, {"figure_path": "i6BBclCymR/figures/figures_24_1.jpg", "caption": "Figure 1: Dilemma of SDS. Average PSNR\u2191, SSIM\u2191, and LPIPS\u2193 of each iteration on the LLFF test dataset [22] with Base (without SDS), SDS (CFG=7.5), and SDS (CFG=100). The prior-added period starts from the 2K iteration and ends at the 9.5K iteration. The opacity is also reset at 2K. The details and final training results of SDS are shown in Sec. 4.4.", "description": "The figure shows the training process of Score Distillation Sampling (SDS) on the LLFF dataset. Three different settings are compared: Baseline (no SDS), SDS with CFG=7.5, and SDS with CFG=100. The metrics PSNR, SSIM, and LPIPS are plotted against the number of training steps.  The results indicate that adding the diffusion prior (starting at 2000 iterations) significantly affects the performance, with varying results depending on the configuration (CFG).  The opacity reset at step 2000 indicates a change in the training process at that point. The detailed analysis of these results is further discussed in Section 4.4 of the paper.", "section": "1 Introduction"}]