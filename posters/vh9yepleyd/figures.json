[{"figure_path": "vh9yEPLeyD/figures/figures_1_1.jpg", "caption": "Figure 1: 1a: The detection performance experiences an abnormal decline when naively combining deepfake and blendfake as the negative sample for training, even though the forgery information is enriched in this process. 1b: Illustration Example for illustrating latent space organization. With progressively organized latent space (ours), information in both deepfake and blendfake is effectively leveraged, and deepfake samples become easier to distinguish from the real. See Fig. 4a and 9 for experimental results of actual latent-space distribution.", "description": "This figure shows the results of experiments comparing the performance of deepfake detectors trained with different negative sample combinations. (a) shows that simply combining deepfake and blendfake data for training leads to reduced performance, despite an increase in forgery information. (b) illustrates how organizing the latent space during training (as done by the proposed method) allows effective use of both deepfake and blendfake data, leading to improved performance and better separability between deepfake and real samples.  The latent space organization makes deepfakes easier to distinguish from real images.", "section": "1 Introduction"}, {"figure_path": "vh9yEPLeyD/figures/figures_2_1.jpg", "caption": "Figure 2: The progressive transition from real to fake, where blendfake and deepfake are explicitly delineated as the oriented pivot anchors according to their inherent forgery attributes.", "description": "This figure illustrates the concept of a progressive transition from real images to deepfakes, with blendfake images acting as intermediate steps.  It highlights three key forgery attributes that accumulate progressively: blending clues, identity inconsistency, and generative artifacts.  The blendfake images (Self-Blended Image (SBI) and Cross-Blended Image (CBI)) serve as \"oriented pivot anchors\" in this transition, guiding the model's learning process to effectively leverage information from both blendfake and deepfake data.", "section": "3 Methodology"}, {"figure_path": "vh9yEPLeyD/figures/figures_3_1.jpg", "caption": "Figure 3: Overall pipeline of our method.", "description": "This figure illustrates the overall pipeline of the proposed method, ProDet. It shows the three main components: Training Data, Feature Bridging & Transition, and Oriented Progressive Regularizor.  The Training Data component shows the four types of data used: Real, Blendfake (SBI), Blendfake (CBI), and Deepfake. The Feature Bridging & Transition component demonstrates how the features of these data types are bridged to create a smooth transition in the latent space. This is achieved through feature bridging and feature transition, explicitly aiming for a progressive accumulation of forgery information. The Oriented Progressive Regularizor uses this progressively organized latent space to train the model effectively. The regularizer utilizes multi-attribute classification to assign labels based on forgery attributes (blending clues, identity inconsistency, generative artifacts), creating a progressive accumulation of forgery information. The output from the attribute classifier is then projected and integrated with the features to inform the final deepfake detection results.", "section": "3 Methodology"}, {"figure_path": "vh9yEPLeyD/figures/figures_8_1.jpg", "caption": "Figure 4: 4a: Illustration of feature organization, where our method can organize different anchors in a progressive manner, while VHT is unorganized and fails to discern blendfake and deepfake. 4b: Illustration of feature regularity. The heatmap values represent the PD at each point, and mPD is the mean PD in the distribution, while smaller mPD implies better feature regularity. The results show that our method has a smaller mPD and superior regularity.", "description": "This figure shows the comparison of feature organization and regularity between the proposed method (ProDet) and the vanilla hybrid training (VHT) method.  (a) illustrates the latent space distribution of features extracted from both methods. ProDet organizes features in a progressive manner, clearly separating real, blendfake (SBI and CBI), and deepfake data. VHT, however, shows a mixed and unorganized distribution. (b) visualizes feature regularity using a heatmap representing Perturbed Distance (PD) and the average PD (mPD). Lower mPD indicates better regularity. ProDet exhibits significantly lower mPD than VHT, indicating better feature regularity and consequently better generalization ability.", "section": "4.5 Analysis of Learned Feature in Latent Space"}, {"figure_path": "vh9yEPLeyD/figures/figures_8_2.jpg", "caption": "Figure 5: Robustness against unseen perturbation with different intensity levels.", "description": "This figure shows the robustness of different deepfake detection methods against three types of unseen perturbations: Block-wise masking, Gaussian noise, and Shifting.  Each perturbation type is applied at four different intensity levels (Levels 0-4). The y-axis represents the AUC (Area Under the Curve), a metric measuring the performance of the deepfake detectors.  The results show how the AUC changes as the intensity of the perturbation increases. The various lines in the graph represent different deepfake detection methods including Xception, EfficientNet, IID, UCF, and the proposed method (Ours). It illustrates that the proposed method is more robust against unseen perturbations compared to other state-of-the-art methods.", "section": "4 Experiments"}, {"figure_path": "vh9yEPLeyD/figures/figures_13_1.jpg", "caption": "Figure 2: The progressive transition from real to fake, where blendfake and deepfake are explicitly delineated as the oriented pivot anchors according to their inherent forgery attributes.", "description": "This figure illustrates the concept of a progressive transition from real images to fake images (deepfakes).  It visually represents how the characteristics of manipulated images change gradually. Real images are at one end, deepfakes at the other, and two types of blendfakes (SBI and CBI) act as intermediate pivot points.  The arrows show the progression, highlighting the accumulation of forgery attributes (blending clues, identity inconsistencies, and generative artifacts) as the transition moves from real to deepfake.  This visual representation is crucial to understanding the authors' proposed method for deepfake detection.", "section": "Methodology"}, {"figure_path": "vh9yEPLeyD/figures/figures_13_2.jpg", "caption": "Figure 3: Overall pipeline of our method.", "description": "This figure illustrates the overall pipeline of the proposed deepfake detection method, ProDet. It shows how the real, blendfake (SBI and CBI), and deepfake images are processed through a backbone network to extract features. These features are then passed through feature bridging and transition modules to simulate a continuous transition in the latent space. Finally, an oriented progressive regularizer (OPR) module is used to constrain the distribution of anchors and facilitate the progressive transition.  The final deepfake detection result is obtained through a final classifier. The figure highlights the progressive transition from real to fake, with blendfake acting as intermediate anchors.", "section": "3 Methodology"}, {"figure_path": "vh9yEPLeyD/figures/figures_15_1.jpg", "caption": "Figure 8: Saliency map visualization for VHT (left) and our method (right).", "description": "The figure shows a comparison of saliency map visualizations between the vanilla hybrid training (VHT) method and the proposed method. The visualizations highlight the regions of interest in the network when processing images of different types: real, blendfake (SBI), blendfake (CBI), and deepfake.  VHT shows inconsistent focus on facial regions, struggling to clearly distinguish between the types of images. In contrast, the proposed method exhibits more consistent and comprehensive attention to relevant forgery features across the different image types.", "section": "7.6 Analysis of Attention Regions"}, {"figure_path": "vh9yEPLeyD/figures/figures_16_1.jpg", "caption": "Figure 9: The t-SNE visualization for both toy and original models.", "description": "This figure visualizes the latent space representations learned by both the proposed method and the vanilla hybrid training (VHT) method using t-SNE.  The left panel shows the results for simplified toy models, while the right panel shows the results for the original, more complex models.  The visualizations help to illustrate the key difference between the two methods: the proposed method achieves a more organized and progressive transition of features from real to fake data, while VHT results in a more entangled and less organized representation.", "section": "7.7 Further experiments for learned feature representations"}, {"figure_path": "vh9yEPLeyD/figures/figures_16_2.jpg", "caption": "Figure 1: 1a: The detection performance experiences an abnormal decline when naively combining deepfake and blendfake as the negative sample for training, even though the forgery information is enriched in this process. 1b: Illustration Example for illustrating latent space organization. With progressively organized latent space (ours), information in both deepfake and blendfake is effectively leveraged, and deepfake samples become easier to distinguish from the real. See Fig. 4a and 9 for experimental results of actual latent-space distribution.", "description": "Figure 1 shows that naively combining deepfake and blendfake data for training a deepfake detector leads to worse performance than using only blendfake data (1a).  This is because the latent space is disorganized, hindering effective learning. In contrast, the proposed method (Ours) uses a progressively organized latent space (1b), effectively leveraging information from both deepfake and blendfake data and improves deepfake detection.", "section": "1 Introduction"}]