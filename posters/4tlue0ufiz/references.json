{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of large language models (LLMs) and their emergent capabilities, directly informing the capabilities of LLMs used in this research."}, {"fullname_first_author": "Anastasios N Angelopoulos", "paper_title": "A gentle introduction to conformal prediction and distribution-free uncertainty quantification", "publication_date": "2021-07-27", "reason": "This paper provides the theoretical underpinnings for conformal prediction, a crucial statistical method used for uncertainty quantification, improving the reliability of robot planning."}, {"fullname_first_author": "Wenlong Huang", "paper_title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents", "publication_date": "2022-07-15", "reason": "This paper directly addresses using LLMs for robotic planning, establishing a key connection between natural language processing and robotics that this research builds upon."}, {"fullname_first_author": "Allen Z. Ren", "paper_title": "Robots that ask for help: Uncertainty alignment for large language model planners", "publication_date": "2023-07-15", "reason": "This paper is highly relevant as it directly tackles uncertainty in LLM-based robot planning, a central theme of this research, proposing a related approach (KnowNo) that is compared against."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting technique that significantly improves LLM reasoning capabilities, a method leveraged and extended in this research."}]}