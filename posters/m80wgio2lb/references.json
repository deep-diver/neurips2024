{"references": [{"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-00-00", "reason": "This paper introduces the T5 model, a unified text-to-text transformer architecture used as the backbone for the SLT model in this paper, demonstrating the effectiveness of transfer learning in NLP tasks."}, {"fullname_first_author": "Necati Cihan Camgoz", "paper_title": "Neural sign language translation", "publication_date": "2018-00-00", "reason": "This paper is a foundational work in neural sign language translation, providing early progress in the field and establishing neural methods as a viable approach."}, {"fullname_first_author": "Dave Uthus", "paper_title": "Youtube-asl: A large-scale, open-domain american sign language-english parallel corpus", "publication_date": "2024-00-00", "reason": "This paper introduces a large-scale, open-domain dataset for American Sign Language translation (YouTube-ASL), used for pretraining the SLT model, significantly improving the scale and diversity of training data."}, {"fullname_first_author": "Garrett Tanzer", "paper_title": "Fleurs-asl: Including american sign language in massively multilingual multi-task evaluation", "publication_date": "2024-00-00", "reason": "This paper introduces FLEURS-ASL, a benchmark dataset crucial for evaluating multilingual SLT models, providing a standardized evaluation for the proposed model."}, {"fullname_first_author": "Amanda Duarte", "paper_title": "How2Sign: A Large-scale Multimodal Dataset for Continuous American Sign Language", "publication_date": "2021-00-00", "reason": "This paper presents How2Sign, a large-scale multimodal dataset for continuous American Sign Language, used for downstream evaluation of the SLT model, providing a comprehensive evaluation for the proposed method."}]}