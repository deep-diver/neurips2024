[{"type": "text", "text": "DMesh: A Differentiable Mesh Representation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Sanghyun Son1 Matheus Gadelha2 Yang Zhou2 Zexiang $\\mathbf{X}\\mathbf{u}^{2}$ Ming C. Lin1 Yi Zhou2 1University of Maryland, College Park, {shh1295,lin}@umd.edu 2Adobe Research, {gadelha,yazhou,zexu,yizho}@adobe.com ", "page_idx": 0}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/c2d4b15d15e960c941c3efe8c99867a8b563a42fbd3e05283970a4c70275e82f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Figure 1: $(\\rightarrow)$ Optimization process. We can optimize our mesh starting from either (a) random state or (b) initialization based on sample points for faster convergence. Mesh connectivity changes dynamically during the optimization. To make this topology change possible, we compute existence probability for an arbitrary set of faces in a differentiable manner. ", "page_idx": 0}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/aa91234befed52b1305ad2c9f68fa6e401b12fee1de4b09cc3288cfc67c316cf.jpg", "img_caption": ["Figure 2: Versatility of DMesh. DMesh can represent diverse geometry in differentiable manner, including (a) non-convex polyhedra of different Euler characteristics, (b) non-orientable geometries (M\u00f6bius strip, Klein bottle), and (c) complex protein structure (colored for aesthetic purpose). "], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present a differentiable representation, DMesh, for general 3D triangular meshes. DMesh considers both the geometry and connectivity information of a mesh. In our design, we first get a set of convex tetrahedra that compactly tessellates the domain based on Weighted Delaunay Triangulation (WDT), and select triangular faces on the tetrahedra to define the final mesh. We formulate probability of faces to exist on the actual surface in a differentiable manner based on the WDT. This enables DMesh to represent meshes of various topology in a differentiable way, and allows us to reconstruct the mesh under various observations, such as point clouds and multi-view images using gradient-based optimization. We publicize the source code and supplementary material at our project page 1. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Polygonal meshes are widely used in modeling and animation due to their diverse, compact and explicit configuration. Recent AI progress has spurred efforts to integrate mesh generation into machine learning, but challenges like varying topology hinder suitable differentiable mesh representations. This limitation leads to reliance on differentiable intermediates like implicit functions, and subsequent iso-surface extraction for mesh creation (Liao u. a., 2018; Guillard u. a., 2021; Munkberg u. a., 2022; Shen u. a., 2023, 2021; Liu u. a., 2023b). However, meshes generated by such approaches can be misaligned at sharp regions and unnecessarily dense (Shen u. a., 2023), not suitable for down-stream applications that require light-weight meshes. This limitation necessitates us to develop a truly differentiable mesh representation, not the intermediate forms. ", "page_idx": 1}, {"type": "text", "text": "The fundamental challenge in creating a differentiable mesh representation lies in formulating both the vertices\u2019 geometric features and their connectivity, defined as edges and faces, in a differentiable way. Given a vertex set, predicting their connectivity in a free-form way using existing machine learning data-structures can cost significant amount of computation and be difficult to avoid irregular and intersecting faces. Consequently, most studies on differentiable meshes simplify the task by using a mesh with a pre-determined topology and modifying it through various operations (Zhou u. a., 2020; Hanocka u. a., 2019; Palfinger, 2022; Nicolet u. a., 2021). This work, on the contrary, ambitiously aims to establish a general 3D mesh representation, named as DMesh, where both mesh topology and geometric features (e.g. encoded in vertex location) can be simultaneously optimized through gradient-based techniques. ", "page_idx": 1}, {"type": "text", "text": "Our core insight is to use differentiable Weighted Delaunay Triangulation (WDT) to divide a convex domain, akin to amber encapsulating a surface mesh, into tetrahedra to form a mesh. To create a mesh with arbitrary topology, we select only a subset of triangular faces from the tetrahedra, termed the \u201creal part\", as our final mesh. The other faces, the \u201cimaginary part\", support the real part but are not part of the final mesh (Figure 4). We introduce a method to assess the probability of a face being part of the mesh based on weighted points that carry positional and inclusiveness information. Optimization is then focused on the points\u2019 features to generate the triangular mesh. The probability determination allows us to compute geometric losses and rendering losses during gradient-based optimization that optimizes connectivity and positioning. ", "page_idx": 1}, {"type": "text", "text": "The key contributions of our work can be summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We present a novel differentiable mesh representation, DMesh, which is versatile to accommodate various types of mesh (Figure 2). The generated meshes can represent shapes more effectively, with much less number of vertices and faces (Table 2).   \n\u2022 We propose a computationally efficient approach to differentiable WDT, which produces robust probability estimations. While exhaustive approach (Rakotosaona u. a., 2021) requires quadratic computational cost, our method runs in approximately linear time.   \n\u2022 We provide efficient algorithms for reconstructing surfaces from both point clouds and multi-view images using DMesh as an intermediate representation.   \n\u2022 We finally propose an effective regularization term which can be used for mesh simplification and enhancing triangle quality. ", "page_idx": 1}, {"type": "text", "text": "Additionally, to further accelerate the algorithm, we implemented our main algorithm and differentiable renderer in CUDA, which is made available for further research. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Shape Representations for Optimization ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Recently, using neural implicit functions for shape representation gained popularity in graphics and vision applications (Mildenhall u. a., 2021; Zhang u. a., 2020; Liu u. a., 2020; Chen u. a., 2022a, 2023; Wang u. a., 2021; Yariv u. a., 2020). They mainly use volume density, inspired by (Mildenhall u. a., 2021), to represent a shape. However, because of its limited accuracy in 3D surface representation, neural signed distance functions (SDFs) (Yariv u. a., 2021; Wang u. a., 2021, 2023; Oechsle u. a., 2021) or unsigned distance functions (UDFs) (Liu u. a., 2023a; Long u. a., 2023) are often preferred. ", "page_idx": 1}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/f9eb584537d79812a9f265e6093ee33fdf53816a973815503efbf7671668ef6f.jpg", "img_caption": ["Figure 3: Our overall framework to optimize mesh according to the given observations. (a): Each point is defined by a 5-dimensional feature vector: position, weight, and real value. Points with larger real values are rendered in red. (b): Given a set of points, we gather possibly existing faces in the mesh and evaluate their probability in differentiable manner. (c): We can compute reconstruction loss based on given observations, such as mesh, point cloud, or multi-view images. (d): To facilitate the optimization process and enhance the mesh quality, we can use additional regularizations. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "After optimization, one can recover meshes using iso-surface extraction techniques (Lorensen und Cline, 1998; Ju u. a., 2002). ", "page_idx": 2}, {"type": "text", "text": "Differing from neural representations, another class of methods directly produce meshes and optimize them. However, they assume that the overall mesh topology is fixed (Chen u. a., 2019; Nicolet u. a., 2021; Liu u. a., 2019; Laine u. a., 2020), only allowing local connectivity changes through remeshing (Palfinger, 2022). Learning-based approaches like BSP-Net (Chen u. a., 2020) allow topological variation, but their meshing process is not differentiable. Recently, differentiable isosurface extraction techniques have been developed, resulting in high-quality geometry reconstruction of various topologies (Liao u. a., 2018; Shen u. a., 2021, 2023; Wei u. a., 2023; Munkberg u. a., 2022; Liu u. a., 2023b; Mehta u. a., 2022). Unfortunately, meshes relying on iso-surface extraction algorithms (Lorensen und Cline, 1998; Ju u. a., 2002) often result in unnecessarily dense meshes that could contain geometric errors. In contrast, our approach addresses these issues: we explicitly define faces and their existence probabilities, and devise regularizations that yield simplified, but accurate meshes based on them (Table 2). See Table 3 for more detailed comparisons to these other methods. ", "page_idx": 2}, {"type": "text", "text": "2.2 Delaunay Triangulation for Geometry Processing ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Delaunay Triangulation (DT) (Aurenhammer u. a., 2013) has been proven to be useful for reconstructing shapes from unorganized point sets. It\u2019s been shown that DT of dense samples on a smooth 2D curve includes the curve within its edges (Brandt und Algazi, 1992; Amenta u. a., 1998a). This idea of using DT to approximate shape has been successfully extended to 3D, to reconstruct threedimensional shapes (Amenta u. a., 1998b) for point sets that satisfy certain constraints. However, these approaches are deterministic. Our method can be considered as a differentiable version of these approaches, which admits gradient-based optimization. ", "page_idx": 2}, {"type": "text", "text": "More recently, Rakotosaona u. a. (2021) focused on this DT\u2019s property to connect points and tessellate the domain, and proposed a differentiable WDT algorithm to compute smooth inclusion, namely existence score of 2-simplexes (triangles) in 2 dimensional space. However, it is not suitable to apply this approach to our 3D case, as there are computational challenges (Section 3.2). Other related work, VoroMesh (Maruani u. a., 2023), also used Voronoi diagrams in point cloud reconstruction, but their formulation cannot represent open surfaces and is only confined to handle point clouds. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Probabilistic Approach to Mesh Connectivity ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To define a traditional, non-differentiable mesh, we specify the vertices and their connectivity. This connectivity is discrete, meaning for any given triplet of vertices, we check if they form a face in the mesh, returning 1 if they do and 0 otherwise. To overcome this discreteness, we propose a ", "page_idx": 2}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/27fdad39b81395a734bc7b9444db93c5293276b3098c0382f31a2fcb1f69d443.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 4: Illustration of our mesh representation for 2D and 3D cases. (a): Our representation in 2D for a letter \u201cA\u201d. (b): Our representation in 3D for a dragon model. Blue faces are \u201creal part\u201d and yellow ones are \u201cimaginary part\u201d. ", "page_idx": 3}, {"type": "text", "text": "probabilistic approach to create a fully differentiable mesh \u2013 given a triplet of vertices, we evaluate the probability of a face existing. This formulation enables differentiability not only of vertex positions but also of their connectivity. ", "page_idx": 3}, {"type": "text", "text": "Note that we need a procedure that tells us the existence probability of any given face to realize this probabilistic approach. This procedure must be 1) differentiable, 2) computationally efficient, and 3) maintain desirable mesh properties, such as avoiding non-manifoldness and self-intersections, when determining the face probabilities. ", "page_idx": 3}, {"type": "text", "text": "Among many possible options, we use Weighted Delaunay Triangulation (WDT) (Figure 6(a)) and a point-wise feature called the \"real\" value $(\\psi)$ to define our procedure. Each vertex in our framework is represented as a 5-dimensional2 vector including position (3), WDT weight (1), and real value (1) (Figure 3(a)). Given the precomputed WDT based on vertices\u2019 positions and weights, we check the face existence probability of each possible triplets. Specifically, 1) a face $F$ must exist in the WDT, and then 2) satisfy a condition on the real values of its vertices to exist on the actual surface. We describe the probability functions for these conditions as $\\Lambda_{w d t}$ and $\\Lambda_{r e a l}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Lambda_{w d t}(F)=P(F\\in\\operatorname{WDT}),\\quad\\Lambda_{r e a l}(F)=P(F\\in\\operatorname{Mesh}|F\\in\\operatorname{WDT}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Then we get the final existence probability function, which can be used in downstream applications (Figure 3), as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Lambda(F)=P(F\\in\\mathbf{Mesh})=\\Lambda_{w d t}(F)\\cdot\\Lambda_{r e a l}(F).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This formulation attains one nice property in determining the final mesh \u2013 that is, it prohibits self-intersections between faces. When it comes to the other two criteria about this procedure, $\\Lambda_{w d t}$ function\u2019s differentiability and efficiency is crucial, as we design $\\Lambda_{r e a l}$ to be a very efficient differentiable function based on real values (Section 4.2). Thus, we first introduce how we can evaluate $\\Lambda_{w d t}$ in a differentiable and efficient manner, which is one of our main contributions. ", "page_idx": 3}, {"type": "text", "text": "3.2 Basic Principles ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To begin with, we use $(d,k)$ pair to denote a $k$ -simplex $(\\Delta^{k})$ in $d$ -dimensional space. For a 3D mesh, we observe that our face $F$ corresponds to $(d=3,k=2)$ ) in Figure 5(b). To compute the probability $\\Lambda_{w d t}$ for the face, we use power diagram (PD), which is the dual structure of WDT (Figure 6(a)). While previously Rakotosaona et al. (2021) proposed a differentiable 2D triangulation method for the ( ${\\mathit{d}}={\\mathit{k}}=2$ ) case (Figure 5(c)), it suffers from quadratically increasing computational cost (e.g. it takes 4.3 seconds to process $10K$ points in 2D, Table 4) and unreliable estimation when $(k<d)$ . We will discuss later how our formulation conquer these computational challenges. Our setting for 3D meshes are similar to 2D meshes, the ${\\mathit{\\omega}}^{\\prime}d=2,k=1{\\mathit{\\omega}}$ ) case in Figure 5(d), where a triangular face reduces to a line. Therefore, we will mainly use this setting to describe and visualize basic concepts for simplicity. However, note that it can be generalized to any $(d,k)$ case without much problem. ", "page_idx": 3}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/2b4d31c59c8571e9b2a8a37ae0a9446592d5b02bd27bcd6e9183e728f1762b56.jpg", "img_caption": ["Figure 5: Renderings of $\\Delta^{k}\\mathbf{s}$ for different pairs of $(d,k)$ . Different $\\Delta^{k}\\mathrm{s}$ are rendered in different colors. "], "img_footnote": [], "page_idx": 3}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/260440f81330c2336a0e5b8e62981dd852298c07bcfdc6b8d42e3967faefabee.jpg", "img_caption": ["Figure 6: Basic concepts to compute existence probability of given 1-simplex $(\\Delta^{1})$ when $d=2$ . (a): WDT and PD of given set of weighted vertices are rendered in solid and dotted lines. The size of a vertex represents its weight. (b): Power cell of $p_{1}\\left(C_{p_{1}}\\right)$ is rendered in grey. Also, $\\Delta^{1}$ is rendered in black line, of which dual line $(D_{\\Delta^{1}})$ is rendered in red. (c), (d): For given $\\Delta^{1}$ , reduced power cell of $p_{1}$ for the $\\Delta^{1}$ $(R_{p_{1}|\\Delta^{1}})$ is rendered in blue, with the original power cell (grey). We can evaluate the existence of $\\Delta^{1}$ in WDT by computing the signed distance from $D_{\\Delta^{1}}$ to $R_{p_{1}|\\Delta^{1}}$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "We generalize the basic principles suggested by Rakotosaona u. a. (2021) to address our cases. For formal definitions of the concepts in this section, please refer to Appendix B. ", "page_idx": 4}, {"type": "text", "text": "Let $S$ be a finite set of points in $\\mathbb{R}^{d=2}$ with weights. For a given point $p\\in S$ , we denote its weight as $w_{p}$ . We call those weighted points in $S$ as \u201cvertices\u201d, to distinguish them from general unweighted points in $\\mathbb{R}^{2}$ . Then, we adopt power distance $\\pi(p,q)=d(p,q)^{2}-w_{p}-w_{q}$ as the distance measure between two vertices in $S$ . As depicted in Figure 6, $\\Delta^{k=1}$ is a 1-simplex, which is a line connecting two vertices $p_{i}$ and $p_{j}$ in $S$ . Its dual form $D_{\\Delta^{1}}$ (red line) is the set of unweighted points3 in $\\mathbb{R}^{2}$ that are located at the same power distance to $p_{i}$ and $p_{j}$ . In the power diagram, the power cell $C_{p}$ (gray cell) of a vertex $p$ is the set of unweighted points that are closer to $p$ than to any other vertices in $S$ . We can use $C_{p}$ and $D_{\\Delta^{1}}$ to measure the existence of $\\Delta^{1}$ . From Figure 6, we can see that when $\\Delta^{1}\\,=\\,\\{p_{i},p_{j}\\}$ exists in WDT, its dual line $D_{\\Delta^{1}}$ aligns exactly with $C_{p_{i}}$ \u2019s boundary, while when $\\Delta^{1}=\\{p_{i},p_{j}\\}$ doesn\u2019t exist in WDT, $D_{\\Delta^{1}}$ is outside $C_{p_{i}}$ . ", "page_idx": 4}, {"type": "text", "text": "To make this measurement less binary when $\\Delta^{1}$ exists, we use the expanded version of power cell called \"reduced\" power cell $(R_{p|\\Delta})$ , introduced by Rakotosaona u. a. (2021). The reduced power cell of $p_{i}\\in S$ for $\\Delta^{1}=\\{p_{i},p_{j}\\}$ is computed by excluding $p_{j}$ from $S$ when constructing the power cell 4. For example, when $\\Delta^{1}$ exists, $R_{p_{i}|\\Delta^{1}}$ will expand towards $p_{j}$ \u2019s direction (Figure 6(c)), and $D_{\\Delta^{1}}$ will \"go through\" $R_{p_{i}|\\Delta^{1}}$ . In contrast, when $\\Delta$ doesn\u2019t exists, even though we have removed $p_{j}$ , $R_{p_{i}|\\Delta^{1}}$ will not expand (Figure 6(d)), and thus $D_{\\Delta^{1}}$ stays outside of $R_{p_{i}|\\Delta^{1}}$ . ", "page_idx": 4}, {"type": "text", "text": "Now we can define a signed distance field $\\tau_{p t}(x,R)$ for a given reduced power cell $R$ , where the signed distance is measured as the distance from the point $\\boldsymbol{x}\\in\\mathbb{R}^{d}$ to the boundary of the reduced power cell (sign is positive when inside). Then, we can induce the signed distance between a dual form $D$ and a reduced power cell $R$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tau(D,R)=\\operatorname*{max}_{x\\in D}\\tau_{p t}(x,R).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As illustrate in Figure 6(c) and (d), $\\tau(D_{\\Delta^{1}},R_{p_{1}|\\Delta^{1}})$ is positive when $\\Delta^{1}$ exists, while negative when it does not exist in WDT. This observation can be generalized as follows: ", "page_idx": 4}, {"type": "text", "text": "Remark 3.1. $\\Delta^{k}$ exists in WDT if and only if $\\forall p_{i}\\in\\Delta^{k},\\tau(D_{\\Delta^{k}},R_{p_{i}|\\Delta^{k}})>0.$ ", "page_idx": 4}, {"type": "text", "text": "In fact, the sign of every $\\tau(D_{\\Delta^{k}},R_{p_{i}|\\Delta^{k}})$ is same for every $p_{i}\\,\\in\\,\\Delta^{k}$ . Therefore, we can use its average to measure the existence probability of $\\Delta_{k}$ , along with sigmoid function $\\sigma$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Lambda_{w d t}\\big(\\Delta^{k}\\big)=\\frac{1}{k+1}\\sum_{p\\in\\{\\Delta^{k}\\}}\\sigma\\big(\\tau(D_{\\Delta_{k}},R_{p|\\Delta^{k}})\\cdot\\alpha_{w d t}\\big),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\alpha_{w d t}$ is a constant value used for the sigmoid function. $\\Lambda_{w d t}(\\Delta^{k})$ is greater than 0.5 when $\\Delta^{k}$ exists, aligning with our probabilistic viewpoint and being differentiable. ", "page_idx": 4}, {"type": "text", "text": "Computational Challenges. As mentioned before, Rakotosaona et al. (2021) solved the problem for the case where ${\\mathit{\\omega}}^{\\prime}d\\,=\\,k\\,=\\,2$ ) where the dual $D_{\\Delta^{k}}$ is a single point. Na\u00efvely applying their approach for computing Eq. 3 to our cases poses two computational challenges: ", "page_idx": 5}, {"type": "text", "text": "\u2022 Precision: When $(d=3,k=2)$ or $(d=2,k=1)$ ), $D_{\\Delta_{k}}$ becomes a line, not a single point. Finding a point on the line that maximizes Eq. 3 is not straightforward. \u2022 Efficiency: When na\u00efvely estimating the reduced power cell in exhaustive manner, the computational cost increases with the number of points at a rate of $O(N^{2})$ , where $N$ is the number of points. ", "page_idx": 5}, {"type": "text", "text": "See Appendix B.2 for a detailed discussion of these limitations. ", "page_idx": 5}, {"type": "text", "text": "4 Formulation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Practical approach to compute $\\Lambda_{w d t}$ ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We introduce a practical approach to resolve the two aforementioned challenges. Specifically, we propose constructing the PD first and use it for computing lower bound of Eq. 3 in an efficient way. We also propose to handle the two cases separately: whether $\\Delta^{k}$ exists in the WDT or not. ", "page_idx": 5}, {"type": "text", "text": "First, when the simplex $\\Delta^{k}$ does not exist, we choose to use the negative distance between the dual form and the normal power cell, $-d(D_{\\Delta^{k}},C_{p})$ . This is the lower bound of Eq. 3: ", "page_idx": 5}, {"type": "equation", "text": "$$\n-d(D_{\\Delta^{k}},C_{p})\\leq\\tau(D_{\\Delta^{k}},R_{p|\\Delta^{k}})<0,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "as $C_{p}\\subset R_{p|\\Delta^{k}}$ . See Figure 6(d) for this case in ${\\mathit{\\omega}}^{\\prime}d=2,k=1{\\mathit{\\omega}}$ ) case. We can observe that computing this distance is computationally efficient, because the normal PD only needs to be computed once for all in advance. Moreover, $C_{p}$ is a convex polyhedron, and $D_{\\Delta^{k}}$ is a (convex) line, which allows us to find the distance between line segments on the boundary of $C_{p}{}^{5}$ and $D_{\\Delta^{k}}$ , and choose the minimum. ", "page_idx": 5}, {"type": "text", "text": "Second, we analyze the case when the simplex $\\Delta^{k}$ exists in WDT. In this case, we have to construct the reduced power cell $R_{p|\\Delta^{k}}$ for given $\\Delta^{\\hat{k}}$ , which requires much additional cost. Instead of doing it, we leverage pre-computed PD to approximate the reduced power cell. Then, we pick a point $v\\in D_{\\Delta^{k}}\\cap R_{p|\\Delta^{k}}$ , where $p\\in\\{\\Delta^{k}\\}$ , and the following holds: ", "page_idx": 5}, {"type": "equation", "text": "$$\n0\\leq\\tau_{p t}(v,R_{p|\\Delta^{k}})\\leq\\tau(D_{\\Delta^{k}},R_{p|\\Delta^{k}}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "because $v\\in R_{p|\\Delta^{k}}$ and by the definition at Eq. 3. In our case, since $D_{\\Delta^{k}}\\cap R_{p|\\Delta^{k}}$ is a line segment, we choose its middle point as $v$ to tighten this lower bound. See Figure 6(c) for the line segment in $(d=2,k=1)$ ) case. We use this bound when $\\Delta^{k}$ exists. Note that computing this lower bound is also computationally efficient, because we can simply project $v$ to the reduced power cell. ", "page_idx": 5}, {"type": "text", "text": "To sum up, we can rewrite Eq. 3 as follows. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tau(D_{\\Delta^{k}},R_{p|\\Delta^{k}})=\\left\\{\\begin{array}{l l}{\\tau_{p t}(v,R_{p|\\Delta^{k}})}&{\\mathrm{~if~}\\quad\\Delta^{k}\\in\\mathrm{WDT}}\\\\ {-d(D_{\\Delta^{k}},C_{p})}&{\\mathrm{else}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "By using this relaxation, we can get lower bound of Eq. 3, which is reliable because it always has the same sign. Also, we can reduce the computational cost from $O(N^{2})$ to nearly $O(N)$ , which is prerequisite for representing meshes that have more than $1K$ vertices in general. See Appendix B.2 for the computational speed and accuracy of our method, compared to the previous one. Finally, we implemented our algorithm for computing Eq. 7 in CUDA for further acceleration. ", "page_idx": 5}, {"type": "text", "text": "4.2 Definition of $\\Lambda_{r e a l}$ ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "$\\Lambda_{r e a l}$ evaluates the existence probability of a $k$ -simplex $\\Delta^{k}$ in our mesh when it exists in WDT. To define it, we leverage per-point value $\\psi\\,\\in\\,[0,1]$ . To be specific, we compute the minimum $\\psi$ of the points in $\\Delta^{k}$ in differentiable way: $\\begin{array}{r}{\\dot{\\Lambda_{r e a l}}\\!\\left(\\Delta^{k}\\right)\\,=\\,\\sum_{p\\in\\Delta^{k}}\\kappa(p)\\cdot\\Psi(p)}\\end{array}$ , where $\\kappa(p)\\,=$ $e^{-\\beta\\cdot\\Psi(p)}/\\sum_{q\\;\\in\\Delta^{k}}e^{-\\beta\\cdot\\Psi(q)}$ , and $\\Psi$ is function that maps a po int $p$ to its $\\psi$ value. We set $\\beta=100$ . ", "page_idx": 5}, {"type": "text", "text": "Along with $\\Lambda_{w d t}$ that we discussed before, now we can evaluate the final existence probability of faces in Eq. 2. We also note here, that when we extract the final mesh, we only select the faces of which $\\Lambda_{w d t}$ and $\\Lambda_{r e a l}$ are larger than 0.5. ", "page_idx": 5}, {"type": "text", "text": "4.3 Loss Functions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "DMesh can be reconstructed from various inputs, such as normal meshes, point clouds, and multiview images. With its per-vertex features and per-face existence probabilities $\\Lambda(F)$ , we can optimize it with various reconstruction losses and regularization terms. Please see details in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "4.3.1 Reconstruction Loss $(L_{r e c o n})$ ) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "First, if we have a normal mesh with vertices $\\mathbb{P}$ and faces $\\mathbb{F}$ , and we want to represent it with DMesh, we should compute the additional two per-vertex attributes, WDT weights and real values. We optimize them by maximizing $\\Lambda(\\mathbb{F})$ since these faces lies on the reference mesh. Conversely, for the remaining set of faces $\\bar{\\mathbb F}$ that can be defined on $\\mathbb{P}$ , we should minimize $\\Lambda(\\bar{\\mathbb{F}})$ . Together, they define the reconstruction loss for mesh input (Appendix C.1). ", "page_idx": 6}, {"type": "text", "text": "For reconstruction from point clouds or multi-view images, we need to optimize for all features including positions. For point clouds, we define our loss using Chamfer Distance (CD) and compute the expected CD using our face probabilities (Appendix C.2). For multi-view images, we define the loss as the $L_{1}$ loss between the given images and the rendering of DMesh, interpreting face probabilities as face opacities. We implemented efficient differentiable renderers to allow gradients to flow across face opacities (Appendix C.3). ", "page_idx": 6}, {"type": "text", "text": "4.3.2 Regularizations ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Being fully differentiable for both vertices and faces, DMesh allows us to develop various regularizations to improve the optimization process and enhance the final mesh quality. The first is weight regularization $(L_{w e i g h t})$ , applied to the dual Power Diagram of the WDT (Appendix C.4). This regularization reduces the structural complexity of the WDT and discards unnecessary points, controlling the final mesh ", "page_idx": 6}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/81e7b495c52e5b90410b05b0167f286458c1fa94efc07f81a8c9cae33b5d6003.jpg", "img_caption": ["Figure 7: Results with different $\\lambda_{w e i g h t}$ . "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "complexity (Figure 7). The next is real regularization $(L_{r e a l})$ , which enforces nearby points to have similar real values and increases the real values of points adjacent to high real value points (Appendix C.5). This helps remove holes or inner structures and makes faces near the current surface more likely to be considered (Appendix D). The final regularization, quality regularization $(L_{q u a l})$ , aims to improve the quality of triangle faces by minimizing the average expected aspect ratio of the faces, thus removing thin triangles (Appendix C.6). ", "page_idx": 6}, {"type": "text", "text": "To sum up, our final loss function can be written as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\nL=L_{r e c o n}+\\lambda_{w e i g h t}\\cdot L_{w e i g h t}+\\lambda_{r e a l}\\cdot L_{r e a l}+\\lambda_{q u a l}\\cdot L_{q u a l},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\lambda$ values are hyperparameters. In Appendix E, we provide values for these hyperparameters for every experiment. Also, in Appendix E.3, we present ablation studies for these regularizations. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments and Applications ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we provide experimental results to demonstrate the efficacy of our approach. First, we optimize vertex attributes to restore a given ground truth mesh, directly proving the differentiability of our design. Next, we conduct experiments on 3D reconstruction from point clouds and multi-view images, showcasing how our differentiable formulation can be used in downstream applications. ", "page_idx": 6}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/07f7d1d0e29dd6c428c960774d417bfa5cb83d4886725992a2293f6012773cae.jpg", "table_caption": ["Table 1: Mesh reconstruction results. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "For the mesh reconstruction problem, we used three models from the Stanford 3D Scanning Repository (Curless und Levoy, 1996). For point cloud and multi-view reconstruction tasks, we used four closed-surface models from the Thingi32 dataset, four open-surface models from the DeepFashion3D dataset, and three additional models with both closed and open surfaces from the Objaverse dataset and Adobe Stock. These models are categorized as \"closed,\" \"open,\" and \"mixed\" in this section. Additionally, we use nonconvex polyhedra of various Euler characteristics and non-orientable geometries to prove our method\u2019s versatility. ", "page_idx": 6}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/e8e8b5176ecb030bc698ff4b230c0ad819065d64a9b64d528e48383c521885ee.jpg", "img_caption": ["Figure 8: Point cloud and multi-view reconstruction results. (a): Ground truth mesh. (b), (f): Our method restores the original shape without losing much detail. (c), (d), (g), (h): PSR (Kazhdan und Hoppe, 2013), VoroMesh (Maruani u. a., 2023), FlexiCube (Shen u. a., 2023), and NIE (Mehta u. a., 2022) fail for open and mixed surfaces. (e): NDC (Chen u. a., 2022b) exhibits artifacts from grids. "], "img_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/77c9a4cd871508b0c96afb4469491f700c5bc709dfbfc7ea275da113472cb899.jpg", "table_caption": ["Table 2: Quantitative comparison for point cloud and multi-view reconstruction results. Best results are written in bold. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "We implemented our main algorithm for computing face existence probabilites and differentiable renderer used for multi-view image reconstruction in CUDA (Nickolls u. a., 2008). Since we need to compute WDT before running the CUDA algorithm, we used WDT implementation of CGAL (Jamin u. a., 2023). We implemented the rest of logic with Pytorch (Paszke u. a., 2017). All of the experiments were run on a system with AMD EPYC 7R32 CPU and Nvidia A10 GPU. ", "page_idx": 7}, {"type": "text", "text": "5.1 Mesh to DMesh ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this experiment, we demonstrate that we can preserve most of the faces in the original normal triangular mesh after converting it to DMesh using the mesh reconstruction loss introduced in 4.3. ", "page_idx": 7}, {"type": "text", "text": "In Table 1, we show the recovery ratio (RE) and false positive ratio (FP) of faces in our reconstructed mesh. Note that we could recover over $99\\%$ of faces in the original mesh, while only having under $1\\%$ of false faces. Please see Appendix E.1 for more details. This result successfully validates our differentiable formulation, but also reveals its limitation in reconstructing some abnormal triangles in the original mesh, such as long, thin triangles. ", "page_idx": 7}, {"type": "text", "text": "5.2 Point Cloud & Multi-View Reconstruction ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this experiment, we aim to reconstruct a mesh from partial geometric data, such as (oriented) point clouds or multi-view images. For point cloud reconstruction, we sampled 100K points from the ground truth mesh. We can additionally use point orientations, if they are available. For multi-view reconstruction, we rendered diffuse and depth images of the ground truth mesh from 64 view points. ", "page_idx": 7}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/296d7230ee1a6d3e4cabcdc538c7ea4c302648090c732e306386d5af3385559b.jpg", "img_caption": ["Figure 9: $(\\rightarrow)$ Shape interpolation using DMesh exhibiting topology change. After ftiting DMesh to a torus (upper left), we optimize it again to reconstruct a double torus (lower right), which has a different genus. We use multi-view images for the optimization. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "In Appendix E, we illustrated the example inputs for these experiments. Also, please see Appendix D to see the initialization and densification strategy we took in these experiments. ", "page_idx": 8}, {"type": "text", "text": "To validate our approach, we compare our results with various approaches. When it comes to point cloud reconstruction, we first compare our result with classical Screened Poisson Surface Reconstruction (PSR) method (Kazhdan und Hoppe, 2013) 6. Then, to compare our method with optimization based approach, we use recent VoroMesh (Maruani u. a., 2023) method. Note that these two methods are not tailored for open surfaces. To compare our method also for the open surfaces, we use Neural Dual Contouring (NDC) (Chen u. a., 2022b), even though it is learning-based approach. Finally, for multi-view reconstruction task, we compare our results with Flexicube (Shen u. a., 2023) and Neural Implicit Evolution (NIE) (Mehta u. a., 2022), which correspond to volumetric approaches that can directly produce meshes of varying geometric topology for given visual inputs. ", "page_idx": 8}, {"type": "text", "text": "In Figure 8, we visualize the reconstruction results along with the ground truth mesh for qualitative evaluation. For closed meshes, in general, volumetric approaches like PSR, VoroMesh, and Flexicube, capture fine details better than our methods. This is mainly because we currently have limitation in the mesh resolution that we can produce with our method. NIE, which is also based on volumetric principles, generates overly smoothed reconstruction results. However, when it comes to open or mixed mesh models, which are more ubiquitous in real applications, we can observe that these methods fail, usually with false internal structures or self-intersecting faces (Appendix E.2). Since NDC leverages unsigned information, it can handle these cases without much problem as ours. However, we can observe step-like visual artifacts coming from its usage of grid in the final output, which requires post-processing. Additionally, to show the versatility of our representation, we also visualize various shapes reconstructed from oriented point clouds in Figure 2. ", "page_idx": 8}, {"type": "text", "text": "Table 2 presents quantitative comparisons with other methods. We used following metrics from Chen u. a. (2022b) to measure reconstruction accuracy: Chamfer Distance (CD), F-Score (F1), Normal Consistency (NC), Edge Chamfer Distance (ECD), and Edge F-Score (EF1) to the ground truth mesh. Also, we report number of vertices and faces of the reconstructed mesh to compare mesh complexity, along with computational time. All values are average over 11 models that we used. In general, our method generates mesh of comparable, or better accuracy than the other methods. However, when it comes to ECD and EF1, which evaluate the edge quality of the reconstructed mesh, our results showed some weaknesses, because our method cannot prevent non-manifold edges yet. However, our method showed superior results in terms of mesh complexity \u2013 this is partially due to the use of weight regularization. Please see Appendix E.3 to see how the regularization works through ablation studies. Likewise, our method shows promising results in producing compact and accurate mesh. However, we also note that our method requires more computational cost than the other methods in the current implementation. ", "page_idx": 8}, {"type": "text", "text": "Before moving on, we present an experimental result about shape interpolation using DMesh in Figure 9. We used multi-view images to reconstruct a torus first, and then optimized the DMesh again to fit a double torus. The results show that DMesh effectively reconstructs the double torus, even when initialized from a converged single torus, highlighting the method\u2019s robustness to local minima. However, this also indicates that our representation lacks meaningful shape interpolation, as it does not assume any specific shape topology. ", "page_idx": 8}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/2fdc45a71a6c3bd1bf6d2907e9ad35302ab0ac41c1e3635ba195f9747a5996c7.jpg", "img_caption": ["Figure 10: Analysis of computational cost for computing face existence probabilities $(\\Lambda(F))$ . The computational cost rises sharply beyond 20K points, with most of the time spent on WDT construction (\u201cWDT\"), while the probability computation (\u201cProb\") requires significantly less time. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "6.1 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "As shown above, our method achieves a more effective and complete forms of differentiable meshes of various topology than existing methods, but still has several limitations to overcome. ", "page_idx": 9}, {"type": "text", "text": "Computational Cost. Currently, the resolution of DMesh is limited by computational cost. Although our theoretical relaxation and CUDA implementation reduce this burden, processing meshes with over 100K vertices remains challenging due to the computational bottleneck of constructing the WDT at each optimization step. In Figure 10, we analyze computational costs relative to the number of points. As shown, costs rise sharply beyond 20K points, with WDT construction consuming most of the time. This limits our method\u2019s ability to handle high resolution mesh. ", "page_idx": 9}, {"type": "text", "text": "Non-Manifoldness. As we have claimed so far, DMesh shows much better generalization than the other methods as it does not have any constraints on the shape topology and mesh connectivity. However, due to this relaxation of constraint, we can observe spurious non-manifold errors in the mesh, even though we adopted measures to minimize them (Appendix D.2.7). ", "page_idx": 9}, {"type": "text", "text": "Specifically, an edge must have at most two adjacent faces to be a \"manifold\" edge. Similarly, a \"manifold\" vertex should be adjacent to a set of faces that form a closed or open fan. We refer to edges or vertices that do not satisfy these definitions as \"non-manifold.\" In our results, we found that $5.50\\%$ of edges and $0.38\\%$ of vertices were non-manifold for point cloud reconstruction. For multi-view reconstruction, $6.62\\%$ of edges and $0.25\\%$ of vertices were non-manifold. Therefore, we conclude that non-manifold edges are more prevalent than non-manifold vertices in our approach. ", "page_idx": 9}, {"type": "text", "text": "6.2 Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "To address the computational cost issue, we can explore methods that reduce reliance on the WDT algorithm, as its cost increases significantly with the number of points. This is crucial since representing complex shapes with fine details often requires over 100K vertices. To tackle the non-manifold issue, we could integrate approaches based on (un)signed distance fields (Shen u. a., 2023; Liu u. a., 2023b) into our method, ensuring manifold mesh generation. Finally, future research could extend this work to solve other challenging problems, such as 3D reconstruction from real-world images, or applications like generative models for 3D shapes. This could involve encoding color or texture information within our framework, opening up exciting new directions for exploration. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements We thank Zhiqin Chen and Matthew Fisher for helpful advice. This research is a joint collaboration between Adobe and University of Maryland at College Park. This work has been supported in part by Adobe, IARPA, UMD-ARL Cooperate Agreement, and Dr. Barry Mersky and Capital One Endowed E-Nnovate Professorships. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[Amenta u. a. 1998a] AMENTA, Nina ; BERN, Marshall ; EPPSTEIN, David: The crust and the $\\beta$ -skeleton: Combinatorial curve reconstruction. In: Graphical models and image processing 60 (1998), Nr. 2, S. 125\u2013135   \n[Amenta u. a. 1998b] AMENTA, Nina ; BERN, Marshall ; KAMVYSSELIS, Manolis: A new Voronoi-based surface reconstruction algorithm. In: Proceedings of the 25th annual conference on Computer graphics and interactive techniques, 1998, S. 415\u2013421   \n[Aurenhammer u. a. 2013] AURENHAMMER, Franz ; KLEIN, Rolf ; LEE, Der-Tsai: Voronoi diagrams and Delaunay triangulations. World Scientific Publishing Company, 2013   \n[Brandt und Algazi 1992] BRANDT, Jonathan W. ; ALGAZI, V R.: Continuous skeleton computation by Voronoi diagram. In: CVGIP: Image understanding 55 (1992), Nr. 3, S. 329\u2013338   \n[Chen u. a. 2022a] CHEN, Anpei ; XU, Zexiang ; GEIGER, Andreas ; YU, Jingyi ; SU, Hao: TensoRF: Tensorial Radiance Fields. In: European Conference on Computer Vision (ECCV), 2022   \n[Chen u. a. 2023] CHEN, Anpei ; XU, Zexiang ; WEI, Xinyue ; TANG, Siyu ; SU, Hao ; GEIGER, Andreas: Dictionary Fields: Learning a Neural Basis Decomposition. In: ACM Trans. Graph. (2023)   \n[Chen u. a. 2019] CHEN, Wenzheng ; LING, Huan ; GAO, Jun ; SMITH, Edward ; LEHTINEN, Jaakko ; JACOBSON, Alec ; FIDLER, Sanja: Learning to predict 3d objects with an interpolationbased differentiable renderer. In: Advances in neural information processing systems 32 (2019)   \n[Chen u. a. 2022b] CHEN, Zhiqin ; TAGLIASACCHI, Andrea ; FUNKHOUSER, Thomas ; ZHANG, Hao: Neural dual contouring. In: ACM Transactions on Graphics (TOG) 41 (2022), Nr. 4, S. 1\u201313   \n[Chen u. a. 2020] CHEN, Zhiqin ; TAGLIASACCHI, Andrea ; ZHANG, Hao: Bsp-net: Generating compact meshes via binary space partitioning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, S. 45\u201354   \n[Cheng u. a. 2013] CHENG, Siu-Wing ; DEY, Tamal K. ; SHEWCHUK, Jonathan ; SAHNI, Sartaj: Delaunay mesh generation. CRC Press Boca Raton, 2013   \n[Cignoni u. a. 2008] CIGNONI, Paolo ; CALLIERI, Marco ; CORSINI, Massimiliano ; DELLEPIANE, Matteo ; GANOVELLI, Fabio ; RANZUGLIA, Guido u. a.: Meshlab: an open-source mesh processing tool. In: Eurographics Italian chapter conference Bd. 2008 Salerno, Italy (Veranst.), 2008, S. 129\u2013136   \n[Curless und Levoy 1996] CURLESS, Brian ; LEVOY, Marc: A volumetric method for building complex models from range images. In: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, 1996, S. 303\u2013312   \n[Guillard u. a. 2021] GUILLARD, Benoit ; REMELLI, Edoardo ; LUKOIANOV, Artem ; RICHTER, Stephan R. ; BAGAUTDINOV, Timur ; BAQUE, Pierre ; FUA, Pascal: DeepMesh: Differentiable iso-surface extraction. In: arXiv preprint arXiv:2106.11795 (2021)   \n[Hanocka u. a. 2019] HANOCKA, Rana ; HERTZ, Amir ; FISH, Noa ; GIRYES, Raja ; FLEISHMAN, Shachar ; COHEN-OR, Daniel: Meshcnn: a network with an edge. In: ACM Transactions on Graphics (ToG) 38 (2019), Nr. 4, S. 1\u201312   \n[Jamin u. a. 2023] JAMIN, Cl\u00e9ment ; PION, Sylvain ; TEILLAUD, Monique: 3D Triangulations. In: CGAL User and Reference Manual. 5.6. CGAL Editorial Board, 2023. \u2013 URL https: //doc.cgal.org/5.6/Manual/packages.html#PkgTriangulation3   \n[Ju u. a. 2002] JU, Tao ; LOSASSO, Frank ; SCHAEFER, Scott ; WARREN, Joe: Dual contouring of hermite data. In: Proceedings of the 29th annual conference on Computer graphics and interactive techniques, 2002, S. 339\u2013346   \n[Kazhdan und Hoppe 2013] KAZHDAN, Michael ; HOPPE, Hugues: Screened poisson surface reconstruction. In: ACM Transactions on Graphics (ToG) 32 (2013), Nr. 3, S. 1\u201313   \n[Kerbl u. a. 2023] KERBL, Bernhard ; KOPANAS, Georgios ; LEIMK\u00dcHLER, Thomas ; DRETTAKIS, George: 3D Gaussian Splatting for Real-Time Radiance Field Rendering. In: ACM Transactions on Graphics 42 (2023), Nr. 4   \n[Kingma und Ba 2014] KINGMA, Diederik P. ; BA, Jimmy: Adam: A method for stochastic optimization. In: arXiv preprint arXiv:1412.6980 (2014)   \n[Laine u. a. 2020] LAINE, Samuli ; HELLSTEN, Janne ; KARRAS, Tero ; SEOL, Yeongho ; LEHTINEN, Jaakko ; AILA, Timo: Modular primitives for high-performance differentiable rendering. In: ACM Transactions on Graphics (TOG) 39 (2020), Nr. 6, S. 1\u201314   \n[Lee 2010] LEE, John: Introduction to topological manifolds. Bd. 202. Springer Science & Business Media, 2010   \n[Liao u. a. 2018] LIAO, Yiyi ; DONNE, Simon ; GEIGER, Andreas: Deep marching cubes: Learning explicit surface representations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, S. 2916\u20132925   \n[Liu u. a. 2020] LIU, Lingjie ; GU, Jiatao ; LIN, Kyaw Z. ; CHUA, Tat-Seng ; THEOBALT, Christian: Neural Sparse Voxel Fields. In: NeurIPS (2020)   \n[Liu u. a. 2019] LIU, Shichen ; LI, Tianye ; CHEN, Weikai ; LI, Hao: Soft rasterizer: A differentiable renderer for image-based 3d reasoning. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, S. 7708\u20137717   \n[Liu u. a. 2023a] LIU, Yu-Tao ; WANG, Li ; YANG, Jie ; CHEN, Weikai ; MENG, Xiaoxu ; YANG, Bo ; GAO, Lin: Neudf: Leaning neural unsigned distance fields with volume rendering. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, S. 237\u2013247   \n[Liu u. a. 2023b] LIU, Zhen ; FENG, Yao ; XIU, Yuliang ; LIU, Weiyang ; PAULL, Liam ; BLACK, Michael J. ; SCH\u00d6LKOPF, Bernhard: Ghost on the Shell: An Expressive Representation of General 3D Shapes. In: arXiv preprint arXiv:2310.15168 (2023)   \n[Long u. a. 2023] LONG, Xiaoxiao ; LIN, Cheng ; LIU, Lingjie ; LIU, Yuan ; WANG, Peng ; THEOBALT, Christian ; KOMURA, Taku ; WANG, Wenping: Neuraludf: Learning unsigned distance fields for multi-view reconstruction of surfaces with arbitrary topologies. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, S. 20834\u201320843   \n[Lorensen und Cline 1998] LORENSEN, William E. ; CLINE, Harvey E.: Marching cubes: A high resolution 3D surface construction algorithm. In: Seminal graphics: pioneering efforts that shaped the field. 1998, S. 347\u2013353   \n[Maruani u. a. 2023] MARUANI, Nissim ; KLOKOV, Roman ; OVSJANIKOV, Maks ; ALLIEZ, Pierre ; DESBRUN, Mathieu: VoroMesh: Learning Watertight Surface Meshes with Voronoi Diagrams. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, S. 14565\u201314574   \n[Mehta u. a. 2022] MEHTA, Ishit ; CHANDRAKER, Manmohan ; RAMAMOORTHI, Ravi: A level set theory for neural implicit evolution under explicit flows. In: European Conference on Computer Vision Springer (Veranst.), 2022, S. 711\u2013729   \n[Mildenhall u. a. 2021] MILDENHALL, Ben ; SRINIVASAN, Pratul P. ; TANCIK, Matthew ; BARRON, Jonathan T. ; RAMAMOORTHI, Ravi ; NG, Ren: Nerf: Representing scenes as neural radiance fields for view synthesis. In: Communications of the ACM 65 (2021), Nr. 1, S. 99\u2013106   \n[Munkberg u. a. 2022] MUNKBERG, Jacob ; HASSELGREN, Jon ; SHEN, Tianchang ; GAO, Jun ; CHEN, Wenzheng ; EVANS, Alex ; M\u00dcLLER, Thomas ; FIDLER, Sanja: Extracting triangular 3d models, materials, and lighting from images. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, S. 8280\u20138290   \n[Nickolls u. a. 2008] NICKOLLS, John ; BUCK, Ian ; GARLAND, Michael ; SKADRON, Kevin: Scalable parallel programming with cuda: Is cuda the parallel programming model that application developers have been waiting for? In: Queue 6 (2008), Nr. 2, S. 40\u201353   \n[Nicolet u. a. 2021] NICOLET, Baptiste ; JACOBSON, Alec ; JAKOB, Wenzel: Large steps in inverse rendering of geometry. In: ACM Transactions on Graphics (TOG) 40 (2021), Nr. 6, S. 1\u201313   \n[Oechsle u. a. 2021] OECHSLE, Michael ; PENG, Songyou ; GEIGER, Andreas: UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction. In: International Conference on Computer Vision (ICCV), 2021   \n[Palfinger 2022] PALFINGER, Werner: Continuous remeshing for inverse rendering. In: Computer Animation and Virtual Worlds 33 (2022), Nr. 5, S. e2101   \n[Paszke u. a. 2017] PASZKE, Adam ; GROSS, Sam ; CHINTALA, Soumith ; CHANAN, Gregory ; YANG, Edward ; DEVITO, Zachary ; LIN, Zeming ; DESMAISON, Alban ; ANTIGA, Luca ; LERER, Adam: Automatic differentiation in pytorch. (2017)   \n[Rakotosaona u. a. 2021] RAKOTOSAONA, Marie-Julie ; AIGERMAN, Noam ; MITRA, Niloy J. ; OVSJANIKOV, Maks ; GUERRERO, Paul: Differentiable surface triangulation. In: ACM Transactions on Graphics (TOG) 40 (2021), Nr. 6, S. 1\u201313   \n[Shen u. a. 2021] SHEN, Tianchang ; GAO, Jun ; YIN, Kangxue ; LIU, Ming-Yu ; FIDLER, Sanja: Deep marching tetrahedra: a hybrid representation for high-resolution 3d shape synthesis. In: Advances in Neural Information Processing Systems 34 (2021), S. 6087\u20136101   \n[Shen u. a. 2023] SHEN, Tianchang ; MUNKBERG, Jacob ; HASSELGREN, Jon ; YIN, Kangxue ; WANG, Zian ; CHEN, Wenzheng ; GOJCIC, Zan ; FIDLER, Sanja ; SHARP, Nicholas ; GAO, Jun: Flexible isosurface extraction for gradient-based mesh optimization. In: ACM Transactions on Graphics (TOG) 42 (2023), Nr. 4, S. 1\u201316   \n[Wang u. a. 2021] WANG, Peng ; LIU, Lingjie ; LIU, Yuan ; THEOBALT, Christian ; KOMURA, Taku ; WANG, Wenping: Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. In: arXiv preprint arXiv:2106.10689 (2021)   \n[Wang u. a. 2023] WANG, Yiming ; HAN, Qin ; HABERMANN, Marc ; DANIILIDIS, Kostas ; THEOBALT, Christian ; LIU, Lingjie: NeuS2: Fast Learning of Neural Implicit Surfaces for Multiview Reconstruction. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023   \n[Wei u. a. 2023] WEI, Xinyue ; XIANG, Fanbo ; BI, Sai ; CHEN, Anpei ; SUNKAVALLI, Kalyan ; XU, Zexiang ; SU, Hao: NeuManifold: Neural Watertight Manifold Reconstruction with Efficient and High-Quality Rendering Support. In: arXiv preprint arXiv:2305.17134 (2023)   \n[Yariv u. a. 2021] YARIV, Lior ; GU, Jiatao ; KASTEN, Yoni ; LIPMAN, Yaron: Volume rendering of neural implicit surfaces. In: Thirty-Fifth Conference on Neural Information Processing Systems, 2021   \n[Yariv u. a. 2020] YARIV, Lior ; KASTEN, Yoni ; MORAN, Dror ; GALUN, Meirav ; ATZMON, Matan ; RONEN, Basri ; LIPMAN, Yaron: Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance. In: Advances in Neural Information Processing Systems 33 (2020)   \n[Zhang u. a. 2020] ZHANG, Kai ; RIEGLER, Gernot ; SNAVELY, Noah ; KOLTUN, Vladlen: NeRF $^{++}$ : Analyzing and Improving Neural Radiance Fields. In: arXiv:2010.07492 (2020)   \n[Zhou u. a. 2020] ZHOU, Yi ; WU, Chenglei ; LI, Zimo ; CAO, Chen ; YE, Yuting ; SARAGIH, Jason ; LI, Hao ; SHEIKH, Yaser: Fully convolutional mesh autoencoder using efficient spatially varying kernels. In: Advances in neural information processing systems 33 (2020), S. 9251\u20139262 ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Table 3: Traits of different optimization-based shape reconstruction methods. We compare methods based on template mesh (Palfinger, 2022; Nicolet u. a., 2021), neural SDF (Wang u. a., 2021, 2023), neural UDF (Long u. a., 2023; Liu u. a., 2023a), differentiable isosurface extraction techniques (Shen u. a., 2021; Munkberg u. a., 2022; Shen u. a., 2023; Liu u. a., 2023b) with ours. ", "page_idx": 13}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/e9daf086275a34a62030de6b1e34e9445efa6bc7eab7313ad7e048877e978de7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "A Comparison to Other Shape Reconstruction Methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Here we provide conceptual comparisons between our approach and the other optimization-based 3D reconstruction algorithms, which use different shape representations. To be specific, we compared our method with mesh optimization methods starting from template mesh (Palfinger, 2022; Nicolet u. a., 2021), methods based on neural signed distance fields (SDF) (Wang u. a., 2021, 2023), methods based on neural unsigned distance fields (UDF) (Liu u. a., 2023a; Long u. a., 2023), and methods based on differentiable isosurface extraction (Shen u. a., 2021; Munkberg u. a., 2022; Shen u. a., 2023; Liu u. a., 2023b). We used following criteria to compare these methods. ", "page_idx": 13}, {"type": "text", "text": "\u2022 Closed surface: Whether or not the given method can reconstruct, or represent closed surfaces.   \n\u2022 Open surface: Whether or not the given method can reconstruct, or represent open surfaces.   \n\u2022 Differentiable Meshing: Whether or not the given method can produce gradients from the loss computed on the final mesh.   \n\u2022 Differentiable Rendering: Whether or not the given method can produce gradients from the loss computed on the rendering results.   \n\u2022 Geometric topology: Whether or not the given method can change geometric topology of the shape. Here, geometric topology defines the continuous deformation of Euclidean subspaces (Lee, 2010). For instance, genus of the shape is one of the traits that describe geometric topology.   \n\u2022 Mesh topology: Whether or note the given method can produce gradients from the loss computed on the mesh topology, which denotes the structural configuration, or edge connectivity of a mesh. ", "page_idx": 13}, {"type": "text", "text": "\u2022 Manifoldness: Whether or not the given method guarantees manifold mesh. ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In Table 3, we present a comparative analysis of different methods. Note that our method meets all criteria, only except manifoldness. It is partially because our method does not assume volume, which is the same for methods based on neural UDF. However, because our method does not leverage smoothness prior of neural network like those methods, it could exhibit high frequency noises in the final mesh. Because of this reason, we gave $\\triangle$ to the neural UDF methods, while giving $\\boldsymbol{\\mathrm{X}}$ to our approach. When it comes to methods based on differentiable isosurface extraction algorithms, we gave $\\triangle$ to its ability to handle open surfaces, because of (Liu u. a., 2023b). They can represent open surfaces as subset of closed ones, but cannot handle non-orientable open surfaces. Finally, note that our method is currently the only method that can handle mesh topology. ", "page_idx": 13}, {"type": "text", "text": "Likewise, DMesh shows promise in addressing the shortcomings found in previous research. Nonetheless, it has its own set of limitations (Section 6). Identifying and addressing these limitations is crucial for unlocking the full potential of our method. ", "page_idx": 13}, {"type": "text", "text": "B Details about Section 3.2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Mathematical Definitions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Here, we provide formal mathematical definitions of the terms used in Section 3.2. We mainly use notations from Aurenhammer u. a. (2013) and Cheng u. a. (2013). ", "page_idx": 14}, {"type": "text", "text": "Generalizing the notations in Section 3.2, let $S[w]$ be a finite set of weighted points in $\\mathbb{R}^{d}$ , where $w$ is a weight assignment that maps each point $p\\in S$ to its weight $w_{p}$ . We denote a weighted point as $p[w_{p}]$ and define power distance to measure distance between two weighted points. ", "page_idx": 14}, {"type": "text", "text": "Definition B.1 (Power distance). Power distance between two weighted points $p[w_{p}]$ and $q[w_{q}]$ is measured as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\pi(p[w_{p}],q[w_{q}])=d(p,q)^{2}-w_{p}-w_{q},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $d(p,q)$ is the Euclidean distance. ", "page_idx": 14}, {"type": "text", "text": "Note that an unweighted point is regarded as carrying weight of 0. Based on this power distance, we can define the power cell $C_{p}$ of a point $p[w_{p}]$ as the set of unweighted points in $\\mathbb{R}^{d}$ that are closer to $p[w_{p}]$ than to any other weighted point in $\\bar{S}[w]$ . ", "page_idx": 14}, {"type": "text", "text": "Definition B.2 (Power cell). Power cell of a point $p[w_{p}]\\in S[w]$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nC_{p}=\\{x\\in\\mathbb{R}^{d}\\,|\\,\\forall q[w_{q}]\\in S[w],\\pi(x,p[w_{p}])\\leq\\pi(x,q[w_{q}])\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Note that some points may have empty power cells if their weights are relatively smaller than neighboring points. We call them \u201csubmerged\u201d points. As we will see later, weight regularization aims at submerging unnecessary points in mesh definition, which leads to mesh simplification. ", "page_idx": 14}, {"type": "text", "text": "To construct the power cell, we can use the concept of half space. A half space $H_{p<q}$ is the set of unweighted points in $\\mathbb{R}^{d}$ that are closer to $p[w_{p}]$ than $q[w_{q}]$ . ", "page_idx": 14}, {"type": "text", "text": "Definition B.3 (Half space). Half space $H_{p<q}$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nH_{p<q}=\\{x\\in\\mathbb{R}^{d}\\,|\\,\\pi(x,p[w_{p}])\\leq\\pi(x,q[w_{q}])\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Note that we can construct a power cell by intersecting half spaces, which proves the convexity of the power cell. Now we call $H(p,q)$ as a half plane that divides $\\mathbb{R}^{d}$ into two half spaces, $H_{p<q}$ and Hq<p. ", "page_idx": 14}, {"type": "text", "text": "Definition B.4 (Half plane). Half plane $H_{p,q}$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nH_{p,q}=\\{x\\in\\mathbb{R}^{d}\\,|\\,\\pi(x,p[w_{p}])=\\pi(x,q[w_{q}])\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then, for a given $k$ -simplex $\\Delta^{k}$ comprised of weighted points $\\begin{array}{r l r}{\\{\\Delta^{k}\\}}&{{}}&{=}\\end{array}$ $\\{p_{1}[w_{p_{1}}],\\ldots,p_{k+1}\\bar{[w_{p_{k+1}}]}\\}\\ \\subset\\ \\bar{S}[w]$ , the dual structure $D_{\\Delta^{k}}$ is the intersection of half planes between the points in $\\{\\Delta^{k}\\}$ , which is a convex set. ", "page_idx": 14}, {"type": "text", "text": "Definition B.5 (Dual form). Dual form $D_{\\Delta^{k}}$ of $\\Delta^{k}=\\{p_{1}[w_{p_{1}}],\\dots,p_{k+1}[w_{p_{k+1}}]\\}$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nD_{\\Delta^{k}}=\\bigcap_{i,j=1,\\ldots,k+1}H(p_{i},p_{j}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which is equivalent to: ", "page_idx": 14}, {"type": "equation", "text": "$$\nD_{\\Delta^{k}}=\\{x\\in\\mathbb{R}^{d}\\,|\\,\\forall p_{i}[w_{p_{i}}],p_{j}[w_{p_{j}}]\\in S[w],\\pi(x,p_{i}[w_{p_{i}}])=\\pi(x,p_{j}[w_{p_{j}}])\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Note than when $k\\,=\\,d$ , $D_{\\Delta^{k}}$ becomes a point, while it becomes a line when $k\\,=\\,d-1$ . As discussed in Section 3.2, we leverage the distance between this dual form $D_{\\Delta^{k}}$ and reduced power cell (Rakotosaona u. a., 2021) of the points in $D_{\\Delta^{k}}$ to query the existence of $\\Delta^{k}$ . The reduced power cell $R_{p|\\Delta^{k}}$ is a power cell of $p$ that does not concern the other points in $\\Delta^{k}$ in its construction. ", "page_idx": 14}, {"type": "text", "text": "Definition B.6 (Reduced power cell). Reduced power cell of a weighted point $p[w]\\in S[w]$ for given $\\Delta^{k}$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nR_{p|\\Delta^{k}}=\\{x\\in\\mathbb{R}^{d}\\,|\\,\\forall q[w_{q}]\\in S[w]-\\{\\Delta^{k}\\},\\pi(x,p[w_{p}])\\leq\\pi(x,q[w_{q}])\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Using these concepts, we can measure the existence probability of a $k$ -simplex, as provided in Section 3.2. ", "page_idx": 14}, {"type": "text", "text": "B.2 Analysis of previous approach ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.2.1 Theoretical Aspect ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As mentioned in Section 3.2, the previous approach of Rakotosaona u. a. (2021) has two computational challenges in computational efficiency and precision. These limitations are mainly rooted in not knowing the power diagram structure before evaluating Eq. 3. We summarize the overall procedure of the previous approach, and point out how our method is different from it. ", "page_idx": 15}, {"type": "text", "text": "Collecting simplexes to evaluate First, we need to collect simplexes that we want to compute probabilities for. Here we assume the number of simplexes increases linearly $(O(N))$ as the number of points $(N)$ increases. This is a plausible assumption, because we often search for $k$ -nearest neighbors for each point, and combine them to generate the query simplexes. ", "page_idx": 15}, {"type": "text", "text": "Sampling a point on the dual forms of the simplexes The previous method relies on point projections to evaluate Eq. 3. This did not incur any problem for their case ${\\dot{d}}=k=2$ ), because the dual form was a single point. However, when $(k<d)$ as in our cases, the dual form contains infinite number of points, which makes unclear how to apply this point-based approach. One possible solution is sampling the most \u201crepresentative\u201d point on the dual form, and leveraging the point to estimate Eq. 3. By definition, this estimation is lower bound of Eq. 3. However, the problem arises when this sample point does not give reliable result. For instance, we can consider the case shown in Figure 6(c). In the illustration, we can observe that $\\Delta^{1}$ exists in WDT, and thus $D_{\\Delta^{1}}$ goes thorugh $R_{p_{1}|D_{\\Delta^{1}}}.$ If we sample a point on $D_{\\Delta^{1}}$ that is included in $R_{p_{1}|D_{\\Delta^{1}}}$ , the signed distance from the sample point would have same sign as Eq. 3. However, if the sample point is selected outside $R_{p_{1}|D_{\\Delta^{1}}}$ , the sign would be different from the real value. In this case, even if $\\Delta^{k}$ exists, we can recognize it as not existing. Note that this false estimation produces false gradients, which could undermine optimization process. ", "page_idx": 15}, {"type": "text", "text": "In contrast, we do not have to concern about this precision issue, because we construct PD, which tells us good sample points that give reliable lower bounds of Eq. 3, when the given simplex exists in WDT. Otherwise, we explicitly compute minimum distance between the dual form and the reduced power cell, as discussed in Section 4.1. ", "page_idx": 15}, {"type": "text", "text": "Projecting sample points to reduced power cells The final step is point projection, where we project the sample points from dual forms to the reduced power cells to estimate Eq. 3. Based on the definitions in Appendix B, we can observe that a (reduced) power cell\u2019s boundaries are comprised of half planes. That is, the boundaries of $C_{p}$ is comprised of multiple half planes between $p$ and the other weighted points. However, when we do not know which half planes comprise the boundaries, we have to do exhaustive search to find the signed distance from the sample point to the boundaries of the reduced power cell. As the number of half planes that are associated with a point $p$ is $N$ , the computational cost to precisely compute the signed distance is $O(N)$ . ", "page_idx": 15}, {"type": "text", "text": "Note that it does not hold for our case, because by constructing WDT and PD, we know which half planes form the boundaries of each power cell. Also, note that even when the number of points increases, the average number of half planes that comprise the boundaries of power cells remains constant. Therefore, in our case, this step requires only $O(1)$ computational cost. ", "page_idx": 15}, {"type": "text", "text": "Summary To sum up, the computational cost of the previous approach amounts to $O(N^{2})$ , as the number of simplexes to evaluate increases linearly, and the cost for the projection step also increases linearly as the number of points increase. However, the cost for ours remains at $O(N)$ . Moreover, the previous approach does not guarantee satisfactory estimations of Eq. 3. ", "page_idx": 15}, {"type": "text", "text": "Before moving on, we point out that the original implementation limited the number of half planes to consider in evaluating Eq. 3 to reduce the computational cost to $O(N)$ . This relaxation is permissible to the case where the precision is not very important. However, the precision is important in our case, because we aim at representing mesh accurately. ", "page_idx": 15}, {"type": "text", "text": "B.2.2 Experimental Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To prove the aforementioned theoretical claim, we conducted experiments to measure the computational speed and accuracy of the probability estimation for $(d=2,k=2)$ and ${\\left(d=2,k=1\\right)}$ ) cases, for varying number of points. We randomly sampled points in a unit cube uniformly, and set the ", "page_idx": 15}, {"type": "text", "text": "Table 4: Comparison of computational speed and accuracy between the previous method (Rakotosaona u. a., 2021) and ours. For each number of points in 2D, we report the triplet of (computational speed (ms) / false positive ratio $(\\%)$ / false negative ratio $(\\%)$ ), along with the number of query simplexes that we give to the algorithm. ", "page_idx": 16}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/cc34b11f27657061f1aa37ca724b11a56d63c5b5fbc9e7202a29bb84f2429850.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "weights by random sampling from a normal distribution: $\\mathcal{N}(0,10^{-3})$ . For fair comparison, we did not use CUDA implementation that we mainly use in the paper. We implemented both algorithms in PyTorch, and ran 10 times for each setting to get fair values. In each experiment, we fed the query simplexes into the algorithm, and computed their existence probabilities. If the computed probability for a simplex was over 0.5, but did not exist, it is counted to false positive ratio. In contrast, if the computed probability for a simplex was below 0.5, but did exist, it is counted to false negative ratio. We measured the computational accuracy with these metrics. ", "page_idx": 16}, {"type": "text", "text": "In Table 4, we can see that as the number of points increases, the computational cost increases exponentially for the previous approach, while ours remain fairly stable up to 30K points. When the number of points reached 100K, the previous method failed because of excessive memory consumption. However, when the number of points is smaller than 1K, the previous method ran faster than ours, because we need to construct PD even for the small number of points, which consumes most of the time for all these cases. ", "page_idx": 16}, {"type": "text", "text": "In terms of accuracy, we can observe that the previous method and ours both give accurate estimations when $(d=2,k=1)$ ). However, when $(d=2,k=1)$ ), we can see that the false negative ratio is almost $50\\%$ \u2013 as we set the number of existing simplexes and non-existing simplexes in the query set as the same, it means that the previous method chose wrong sample points for most of the query simplexes, so that it predicted most of them as not existing. To select the most representative point, we found the intersection point between the dual form and the affine space created by the weighted points in the simplex. This could be another interesting direction to explore, but this approach found out to be not very accurate in this experiment. In contrast, our approach gave stable estimations for all the cases. This result demonstrates that our method is more scalable, and gives reliable probability estimations than the previous approach, which is necessary for accurate 3D mesh representation. ", "page_idx": 16}, {"type": "text", "text": "C Loss Functions ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Here we provide formal definitions for the loss functions that we use in the paper. ", "page_idx": 16}, {"type": "text", "text": "C.1 Mesh to DMesh ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we explore the loss function used to transform the ground truth mesh into our DMesh representation. As previously mentioned in Section 4.3, the explicit definition of ground truth connectivity in the provided mesh allows us to establish a loss function based on it. ", "page_idx": 16}, {"type": "text", "text": "Building on the explanation in Section 4.3, if the ground truth mesh consists of vertices $\\mathbb{P}$ and faces $\\mathbb{F}$ , we can construct an additional set of faces $\\bar{\\mathbb F}$ . These faces are formed from vertices in $\\mathbb{P}$ but do not intersect with faces in $\\mathbb{F}$ . ", "page_idx": 16}, {"type": "text", "text": "Then, we notice that we should maximize the existence probabilities of faces in $\\mathbb{F}$ , but minimize those of faces in $\\bar{\\mathbb F}$ . Therefore, we can define our reconstruction loss function as ", "page_idx": 16}, {"type": "equation", "text": "$$\nL_{r e c o n}=-\\sum_{F\\in\\mathbb{F}}\\Lambda(F)+\\sum_{F\\in\\mathbb{F}}\\Lambda(F).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If the first term of the loss function mentioned above is not fully optimized, it could lead to the omission of ground truth faces, resulting in a poorer recovery ratio (Section 5.1). Conversely, if the ", "page_idx": 16}, {"type": "text", "text": "second term is not fully optimized, the resulting DMesh might include faces absent in the ground truth mesh, leading to a higher false positive ratio (Section 5.1). Refer to Appendix D.1 for details on how this reconstruction loss is integrated into the overall optimization process. ", "page_idx": 17}, {"type": "text", "text": "C.2 Point Cloud Reconstruction ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In the task of point cloud reconstruction, we reconstruct the mesh by minimizing the $\\,L_{1}$ -norm based) expected Chamfer Distance (CD) between the given point cloud $(\\mathbb{P}_{g t})$ and the sample points $(\\mathbb{P}_{o u r s})$ from our reconstructed mesh. We denote the CD from $\\mathbb{P}_{g t}$ to $\\mathbb{P}_{o u r s}$ as $C D_{g t}$ , and the CD from $\\mathbb{P}_{o u r s}$ to $\\mathbb{P}_{g t}$ as $C D_{o u r s}$ . The final reconstruction loss is obtained by combining these two distances. ", "page_idx": 17}, {"type": "equation", "text": "$$\nL_{r e c o n}=C D_{g t}+C D_{o u r s}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "C.2.1 Sampling Pours ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "To compute these terms, we start by sampling $\\mathbb{P}_{o u r s}$ from our current mesh. First, we sample a set of faces that we will sample points from. We consider the areas of the triangular faces and their existence probabilities. To be specific, we define $\\eta(F)$ for a face $F$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\bar{\\eta}(F)=\\Lambda(F),\\quad\\eta(F)=F_{a r e a}\\cdot\\bar{\\eta}(F),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and define a probability to sample $F$ from the entires faces $\\mathbb{F}$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\nP_{s a m p l e}(F)=\\frac{\\eta(F)}{\\sum_{F^{\\prime}\\in\\mathbb{F}}\\eta(F^{\\prime})}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We sample $N$ faces from $\\mathbb{F}$ with replacement and then uniformly sample a single point from each selected face to define $\\mathbb{P}_{o u r s}$ . In our experiments, we set $N$ to $100K$ . ", "page_idx": 17}, {"type": "text", "text": "In this formulation, we sample more points from faces with a larger area and higher existence probability to improve sampling efficiency. However, we observed that despite these measures, the sampling efficiency remains low, leading to slow convergence. This issue arises because, during optimization, there is an excessive number of faces with very low existence probability. ", "page_idx": 17}, {"type": "text", "text": "To overcome this limitation, we decided to do stratified sampling based on point-wise real values and cull out faces with very low existence probabilities. To be specific, we define two different $\\eta$ functions: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\eta_{1}}(F)=\\Lambda_{w d t}(F)\\cdot\\operatorname*{min}(\\psi_{i},\\psi_{j},\\psi_{k}),\\quad\\eta_{1}(F)=F_{a r e a}\\cdot\\bar{\\eta_{1}}(F)}\\\\ &{\\bar{\\eta_{2}}(F)=\\Lambda_{w d t}(F)\\cdot\\operatorname*{max}(\\psi_{i},\\psi_{j},\\psi_{k}),\\quad\\eta_{2}(F)=F_{a r e a}\\cdot\\bar{\\eta_{2}}(F)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $(\\psi_{i},\\psi_{j},\\psi_{k})$ are the real values of the points that comprise $F$ . Note that $\\eta_{1}$ is the same as $\\eta^{\\ 7}$ ", "page_idx": 17}, {"type": "text", "text": "For the faces in $\\mathbb{F}$ , we first calculate the $\\bar{\\eta_{1}}$ and $\\bar{\\eta_{2}}$ values and eliminate faces with values lower than a predefined threshold $\\epsilon_{\\eta}$ . We denote the set of remaining faces as $\\mathbb{F}_{1}$ and $\\mathbb{F}_{2}$ . Subsequently, we sample $\\textstyle{\\frac{N}{2}}$ faces from $\\mathbb{F}_{1}$ and the other $\\textstyle{\\frac{N}{2}}$ faces from $\\mathbb{F}_{2}$ , using the following two sampling probabilities: ", "page_idx": 17}, {"type": "equation", "text": "$$\nP_{s a m p l e,1}(F)=\\frac{\\eta_{1}(F)}{\\sum_{F^{\\prime}\\in\\mathbb{F}_{1}}\\eta_{1}(F^{\\prime})},\\quad P_{s a m p l e,2}(F)=\\frac{\\eta_{2}(F)}{\\sum_{F^{\\prime}\\in\\mathbb{F}_{2}}\\eta_{2}(F^{\\prime})}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The rationale behind this sampling strategy is to prioritize (non-existing) faces closer to the current mesh over those further away. In the original $\\eta=\\eta_{1}$ function, we focus solely on the minimum real value, leading to a higher sampling rate for existing faces. However, to remove holes in the current mesh, it\u2019s beneficial to sample more points from potential faces\u2014those not yet existing but connected to existing ones. This approach, using $\\eta_{2}$ , enhances reconstruction results by removing holes more effectively. Yet, there\u2019s substantial potential to refine this importance sampling technique, as we haven\u2019t conducted a theoretical analysis in this study. ", "page_idx": 17}, {"type": "text", "text": "Moreover, when sampling a point from a face, we record the face\u2019s existence probability alongside the point. Additionally, if necessary, we obtain and store the face\u2019s normal. For a point $\\mathbf{p}\\in\\mathbb{P}_{o u r s}$ , we introduce functions $\\Lambda_{p t}(\\cdot)$ and $N o r m a l(\\cdot)$ to retrieve the face existence probability and normal, respectively: ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\Lambda_{p t}({\\bf p})=\\Lambda(F({\\bf p})),\\quad N o r m a l({\\bf p})=F({\\bf p})_{n o r m a l},}}\\\\ {{F({\\bf p})=\\mathrm{the~face~where~}{\\bf p}\\mathrm{~was~sampled~from}.\\hfill}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.2.2 $C D_{g t}$ ", "page_idx": 18}, {"type": "text", "text": "Now we introduce how we compute the $C D_{g t}$ , which is CD from $\\mathbb{P}_{g t}$ to $\\mathbb{P}_{o u r s}$ . For each point $\\textbf{p}\\in\\mathbb{P}_{g t}$ , we first find $k$ -nearest neighbors of $\\mathbf{p}$ in $\\mathbb{P}_{o u r s}$ , which we denote as $\\left(p_{1},p_{2},...,p_{k}\\right)$ . Then, we define a distance function between the point $\\mathbf{p}$ and the $k$ -nearest neighbors as follows, to accommodate the orientation information: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{D}(\\mathbf{p},p_{i})=||\\mathbf{p}-p_{i}||_{2}+\\lambda_{n o r m a l}\\cdot\\bar{D}_{n}(\\mathbf{p},p_{i}),}\\\\ {\\mathrm{ere}\\;\\bar{D}_{n}(\\mathbf{p},p_{i})=1-|<\\mathbf{p}_{n o r m a l},N o r m a l(p_{i})>|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\lambda_{n o r m a l}$ is a parameter than determines the importance of point orientation in reconstruction.   \nIf $\\lambda_{n o r m a l}=0$ , we only consider the positional information of the sampled points. ", "page_idx": 18}, {"type": "text", "text": "After we evaluate the above distance function values for the $k$ -nearest points, we reorder them in ascending order. Then, we compute the following expected minimum distance from $\\mathbf{p}$ to $\\mathbb{P}_{o u r s}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D(\\mathbf{p},\\mathbb{P}_{o u r s})=\\displaystyle\\sum_{i=1,\\dots,k}\\bar{D}(\\mathbf{p},p_{i})\\cdot P(p_{i})\\cdot\\bar{P}(p_{i}),}\\\\ &{\\qquad P(p_{i})=\\Lambda_{p t}(p_{i})\\cdot\\mathbb{I}_{p r e v}(F(p_{i}),}\\\\ &{\\qquad\\bar{P}(p_{i})=\\Pi_{i=1,\\dots,k-1}(1-P(p_{i})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\mathbb{I}_{p r e v}$ is an indicator function that returns 1 only when the given face has not appeared before in computing the above expected distance. For instance, if the face ids for the reordered points were $(1,2,3,2,3,4)$ , the $\\mathbb{I}_{p r e v}$ function evaluates to $(1,1,1,0,0,1)$ . This indicator function is needed, because if we select $p_{i}$ as the nearest point to $\\mathbf{p}$ with the probability $\\Lambda_{p t}(\\mathbf{p})$ , it means that we interpret that the face corresponding to $p_{i}$ already exists, and then we would select $p_{i}$ on the face as the nearest point to $\\mathbf{p}$ rather than the other points that were sampled from the same face, but have larger distance than $p_{i}$ and thus come after $p_{i}$ in the ordered points. ", "page_idx": 18}, {"type": "text", "text": "Note that we dynamically change $k$ during runtime to get a reliable estimation of $D(\\mathbf{p},\\mathbb{P}_{o u r s})$ . That is, for current $k$ , if most of $\\bar{P}(p_{k}^{-})\\mathrm{s}$ for the points in $\\mathbb{P}_{g t}$ are still large, it means that there is a chance that the estimation could change a lot if we find and consider more neighboring points. Therefore, in our experiments, if any point in $\\mathbb{P}_{g t}$ has $\\bar{P}(p_{k})$ larger than $10^{-4}$ , we increase $k$ by 1 for the next iteration. However, if there is no such point, we decrease $k$ by 1 to accelerate the optimization process. ", "page_idx": 18}, {"type": "text", "text": "Finally, we can compute $C D_{g t}$ by summing up the point-wise expected minimum distances. ", "page_idx": 18}, {"type": "equation", "text": "$$\nC D_{g t}=\\sum_{\\mathbf{p}\\in\\mathbb{P}_{g t}}D(\\mathbf{p},\\mathbb{P}_{o u r s}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.2.3 CDours ", "page_idx": 18}, {"type": "text", "text": "In computing $C D_{o u r s}$ , which is $C D$ from $\\mathbb{P}_{o u r s}$ to $\\mathbb{P}_{g t}$ , we also find $k$ -nearest neighbors for each point $\\mathbf{p}\\in\\mathbb{P}_{o u r s}$ , which we denote as $\\left(p_{1},p_{2},...,p_{k}\\right)$ . Then, for a point $\\mathbf{p}$ , we use the same distance function $\\bar{D}$ in Eq. 17 to find the distance between $\\mathbf{p}$ and $\\left(p_{1},p_{2},...,p_{k}\\right)$ . After that, we select the minimum one for each point, multiply the existence probability of each point, and then sum them up to compute $C D_{o u r s}$ . ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D(\\mathbf{p},\\mathbb{P}_{g t})=\\underset{i=1,\\ldots,k}{\\operatorname*{min}}\\,\\bar{D}(\\mathbf{p},p_{i}),}\\\\ &{\\quad C D_{o u r s}=\\underset{\\mathbf{p}\\in\\mathbb{P}_{o u r s}}{\\sum}\\Lambda_{p t}(\\mathbf{p})\\cdot D(\\mathbf{p},\\mathbb{P}_{g t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Finally, we can compute the final reconstruction loss for point clouds as shown in Eq. 16. ", "page_idx": 18}, {"type": "text", "text": "C.3 Multi-View Reconstruction ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "When we are given multi-view images, we reconstruct the mesh by minimizing the $L_{1}$ difference between our rendered images and the given images. In this work, we mainly use both diffuse and depth renderings to reconstruct the mesh. ", "page_idx": 19}, {"type": "text", "text": "If we denote the ${(N_{i m g})}$ ground truth images of $N_{p i x e l}$ number of pixels as $\\mathcal{T}_{i}^{g t}(i=1,...,N_{i m g})$ , and our rendered images as $\\mathcal{T}_{i}^{o u r s}$ , we can write the reconstruction loss function as ", "page_idx": 19}, {"type": "equation", "text": "$$\nL_{r e c o n}=\\frac{1}{N_{i m g}\\cdot N_{p i x e l}}\\sum_{i=1,...,N_{i m g}}||\\mathcal{Z}_{i}^{g t}-\\mathcal{Z}_{i}^{o u r s}||.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, we can define our rendered image as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\nI_{i}^{o u r s}=\\mathcal{F}(\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F}),\\mathbf{M}\\mathbf{V_{i}},\\mathbf{P_{i}}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mathcal{F}$ is a differentiable renderer that renders the scene for the given points $\\mathbb{P}$ , faces $\\mathbb{F}$ , face existence probabilities $\\Lambda(\\mathbb{F})$ , $i^{\\th}$ -th modelview matrix $\\mathbf{M}\\mathbf{V_{i}}\\,\\in\\,\\mathbb{R}^{4\\times\\overline{{4}}}$ , and $i$ -th projection matrix $\\mathbf{P_{i}}\\in\\mathbb{R}^{4\\times\\bar{4}}$ . The differentiable renderer $\\mathcal{F}$ has to backpropagate gradients along $\\mathbb{P},\\mathbb{F}.$ , and $\\Lambda(\\mathbb{F})$ to update our point attributes. Specifically, here we interpret $\\Lambda(\\mathbb{F})$ as opacity for faces to use in the rendering process. This is because opacity means the probability that a ray stops when it hits the face, which aligns with our face existence probability well. For this reason, we ignore faces with very low existence probability under some threshold to accelerate the reconstruction, as they are almost transparent and do not contribute to the rendering a lot. ", "page_idx": 19}, {"type": "text", "text": "To implement $\\mathcal{F}$ , we looked through previous works dedicated for differentiable rendering (Laine u. a., 2020; Liu u. a., 2019). However, we discovered that these methods incur substantial computational costs when rendering a large number of (potentially) semi-transparent triangles, as is the case in our scenario. Consequently, we developed two efficient, partially differentiable renderers that meet our specific requirements. These renderers fulfill distinct roles within our pipeline\u2014as detailed in Appendix D, our optimization process encompasses two phases within a single epoch. The first renderer is employed during the initial phase, while the second renderer is utilized in the subsequent phase. ", "page_idx": 19}, {"type": "text", "text": "If there are multiple semi-transparent faces in the scene, we have to sort the faces that covers a target pixel with their (view-space) depth values, and iterate through them until the accumulated transmittance is saturated to determine the color for the pixel. Conducting this process for each individual pixel is not only costly, but also requires a lot of memory to store information for backward pass. ", "page_idx": 19}, {"type": "text", "text": "Recently, 3D Gaussian Splatting (Kerbl u. a., 2023) overcame this issue with tile-based rasterizer. We adopted this approach, and modified their implementation to render triangular faces, instead of gaussian splats. To briefly introduce its pipeline, it first assigns face-wise depth value by computing the view-space depth of its center point. Then, after subdividing the entire screen into $16\\times16$ tiles, we assign faces to each tiles if they overlap. After that, by using the combination of tile ID and the face-wise depth as a key, we get the face list sorted by depth value in each tile. Finally, for each tile, we iterate through the sorted faces and determine color and depth for each pixel as follows. ", "page_idx": 19}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/e744916309c582b92a484a9e962bd283b446f70a0ee67782336f15a86b262866.jpg", "img_caption": ["Figure 11: ${\\mathcal{F}}_{B}$ uses tessellation structure to efficiently render overlapped faces in the correct order. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "equation", "text": "$$\nC=\\sum_{i=1,...,k}T_{i}\\cdot\\,\\alpha_{i}\\cdot C_{i},\\quad(T_{i}=\\Pi_{j=1,...,i-1}(1-\\alpha_{j})),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $T_{i}$ is the accumulated transmittance, $\\alpha_{i}$ is the opacity of the $i$ -th face, and $C_{i}$ is the color (or depth) of the $i$ -th face. Note that $\\alpha_{i}=\\Lambda(F_{i})$ , as mentioned above. ", "page_idx": 19}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/5c64336e347bd8a45613788fde74c313701adc7f27bcfead76af37eb47472d8a.jpg", "img_caption": ["Figure 12: Rendered images from two differentiable renderers, ${\\mathcal{F}}_{A}$ and ${\\mathcal{F}}_{A^{\\prime}}$ . Left and right image corresponds to diffuse and depth rendering, respectively. (a) ${\\mathcal{F}}_{A}$ is our (partially) differentiable renderer based on tile-based approach. (b) Since ${\\mathcal{F}}_{A}$ does not produce visibility-related gradients, we additionally use ${\\mathcal{F}}_{A^{\\prime}}$ (Laine u. a., 2020) to render images and integrate with ours. ", ""], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Even though this renderer admits an efficient rendering of large number of semi-transparent faces, there are still two large limitations in the current implementation. First, the current implementation does not produce visibility-related gradients (near face edges) to update point attributes. Therefore, we argue that this renderer is partially differentiable, rather than fully differentiable. Next, since it does not compute precise view-point depth for each pixel, its rendering result can be misleading for some cases, as pointed out in (Kerbl u. a., 2023). ", "page_idx": 20}, {"type": "text", "text": "To amend the first issue, we opt to use another differentiable renderer of Laine u. a. (2020), which produces the visibility-related gradients that we lack. Since this renderer cannot render (large number of) transparent faces as ours does, we only render the faces with opacity larger than 0.5. Also, we set the faces to be fully opaque. If we call this renderer as ${\\mathcal{F}}_{A^{\\prime}}$ , our final rendered image can be written as follows. ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{i}^{o u r s}=\\frac12(\\mathcal{F}_{A}(\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F}),\\mathbf{M}\\mathbf{V}_{i},\\mathbf{P}_{i})+\\mathcal{F}_{A^{\\prime}}(\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F}),\\mathbf{M}\\mathbf{V}_{i},\\mathbf{P}_{i})).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In Figure 12, we illustrate rendered images from ${\\mathcal{F}}_{A}$ and ${\\mathcal{F}}_{A^{\\prime}}$ . ", "page_idx": 20}, {"type": "text", "text": "Acknowledging that this formulation is not theoretically correct, we believe that it is an intriguing future work to implement a fully differentiable renderer that works for our case. However, we empirically found out that we can reconstruct a wide variety of meshes with current formulation without much difficulty. ", "page_idx": 20}, {"type": "text", "text": "As mentioned before, this renderer is used at the first phase of the optimization process, where all of the point attributes are updated. However, in the second phase, we fix the point positions and weights, and only update point-wise real values (Appendix D.2). In this case, we can leverage the tessellation structure to implement an efficient differentiable renderer. As the second renderer does a precise depth testing unlike the first one, it can be used to modify the errors incurred by the second limitation of the first renderer (Figure 13). ", "page_idx": 20}, {"type": "text", "text": "C.3.2 ${\\mathcal{F}}_{B}$ ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The second renderer performs precise depth ordering in an efficient way, based on the fixed tessellation structure that we have. In Figure 11, we illustrate a 2D diagram that explains our approach. When the green ray, which corresponds to a single ray to determine the color of a single pixel, goes through the tessellation, we can observe that it goes through a sequence of triangles (tetrahedron in 3D), which are denoted as $T_{1},T_{2}$ , and $T_{3}$ . When the ray enters a triangle $T_{i}$ through one of its three edges, we can see that it moves onto the other adjacent triangle $T_{i+1}$ only through one of the other edges of $T_{i}$ , because of compact tessellation. Therefore, when the ray hits one edge of $T_{i}$ , it can only examine the other two edges of $T_{i}$ to find the next edge it hits. Note that we do not have to do depth testing explicitly in this approach. Also, unlike the first approach, this renderer does not have to store all the possible faces that a ray collides for the backward pass, because it can iterate the same process in the opposite way in the backward pass to find the edge that it hit before the last edge. If we only store the last edge that each hits at the forward pass, we can start from the last edge and find the previous edges that it hit to compute gradients. Therefore, this second renderer requires much less memory than the first one, and also performs precise depth testing naturally. However, note that this renderer is also partilly differentiable, because it cannot update point positions and weights. ", "page_idx": 20}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/f08a7025700580d26946f961d6b21e8eb4ce4bfc85d92ed98fb4ee1dc39d3661.jpg", "img_caption": ["(a) Extracted Mesh after phase 1 "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/61bbca23bbb4bd0cedff8d2ad34700a94f8daadb9e27aa77e4d347b938f34253.jpg", "img_caption": ["Figure 13: Reconstructed mesh from multi-view images, rendered in MeshLab\u2019s (Cignoni u. a., 2008) x-ray mode to see inner structure. In multi-view reconstruction, we divide each epoch in two phases. (a) After the first phase ends, where we do inaccurate depth testing, lots of false inner faces are created. (b) To remove these inner faces, we require a renderer that does the exact depth testing, which we use in the second phase. Also see Appendix D.2 for details about post-processing step to remove the inner structure. ", "(b) Extracted Mesh after phase 2 "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "To sum up, we implemented two partially differentiable renderers to solve multi-view reconstruction problem with DMesh. They serve different objectives in our reconstruction process, and we empirically found out that they are powerful enough to reconstruct target meshes in our experiments. However, we expect that we can simplify the process and improve its stability, if we can implement a fully differentiable renderer that satisfy our needs. We leave it as a future work. ", "page_idx": 21}, {"type": "text", "text": "C.4 Weight Regularization ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Weight regularization aims at reducing the complexity of WDT, which supports our mesh. By using this regularization, we can discard unnecessary points that do not contribute to representing our mesh. Moreover, we can reduce the number of points on the mesh, if they are redundant, which ends up in the mesh simplification effect (Appendix E.3). ", "page_idx": 21}, {"type": "text", "text": "We formulate the complexity of WDT as the sum of edge lengths in its dual power diagram. Formally, we can write the regularization as follows, ", "page_idx": 21}, {"type": "equation", "text": "$$\nL_{w e i g h t}=\\sum_{i=1,...,N}L e n g t h(E_{i}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $E_{i}$ are the edges in the dual power diagram, and $N$ is the number of edges. ", "page_idx": 21}, {"type": "text", "text": "C.5 Real Regularization ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Real regularization is a regularization that is used for maintaining the real values of the connected points in WDT as similar as possible. Also, we leverage this regularization to make real values of points that are connected to the points with high real values to become higher, so that they can be considered in reconstruction more often than the points that are not connected to those points. To be specific, note that we ignore faces with very low existence probability in the reconstruction process. By using this regularization, it can remove holes more effectively. ", "page_idx": 21}, {"type": "text", "text": "This real regularzation can be described as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal L}_{r e a l}=\\frac{1}{\\sum_{i=1,\\dots,N}\\Lambda(F_{i})}\\sum_{i=1,\\dots,N}\\Lambda(F_{i})\\cdot(\\sigma_{1}(F_{i})+\\sigma_{2}(F_{i})),}}\\\\ {{\\displaystyle\\sigma_{1}(F_{i})=\\frac{1}{3}\\sum_{j=1,2,3}|\\psi_{j}-\\frac{(\\psi_{1}+\\psi_{2}+\\psi_{3})}{3}|,}}\\\\ {{\\displaystyle\\sigma_{1}(F_{i})=\\frac{1}{3}\\sum_{j=1,2,3}|1-\\psi_{j}|\\cdot\\mathbb{I}(\\operatorname*{max}_{j=1,2,3}(\\psi_{j})>\\delta_{h i g h}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Here $\\psi_{1,2,3}$ represent the real values of points that comprise $F_{i}$ , and $\\delta_{h i g h}$ is a threshold to determine \u201chigh\u201d real value, which is set as 0.8 in our experiments. Note that the faces with higher existence probabilities are prioritized over the others. ", "page_idx": 22}, {"type": "text", "text": "C.6 Quality Regularization ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "After reconstruction, we usually want to have a mesh that is comprised of triangles of good quality, rather than ill-formed triangles. We adopt the aspect ratio as a quality measure for the triangular faces, and minimize the sum of aspect ratios for all faces during optimization to get a mesh of good quality. Therefore, we can write the regularization as follows. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad L_{q u a l}=\\displaystyle\\frac{1}{\\sum_{i=1,\\dots,N}\\Lambda(F_{i})}\\sum_{i=1,\\dots,N}A R(F_{i})\\cdot E_{m a x}(F_{i})\\cdot\\Lambda(F_{i}),}\\\\ &{\\quad A R(F_{i})=\\displaystyle\\frac{E_{m a x}(F_{i})}{H_{m i n}(F_{i})}\\cdot\\frac{\\sqrt{3}}{2},}\\\\ &{E_{m a x}(F_{i})=\\mathrm{Maximum~edge~length~of~}F_{i},}\\\\ &{H_{m i n}(F_{i})=\\mathrm{Minimum~height~of~}F_{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that we prioritize faces with larger maximum edge length and higher existence probability than the others in this formulation. In Appendix E.3, we provide ablation studies for this regularization. ", "page_idx": 22}, {"type": "text", "text": "D Optimization Process ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we explain the optimization processes, or exact reconstruction algorithms, in detail. First, we discuss the optimization process for the experiment in Section 5.1, where we represent the ground truth mesh with DMesh. Then, we discuss the overall optimization process for point cloud or multi-view reconstruction tasks in Section 5.2, from initialization to post processing. ", "page_idx": 22}, {"type": "text", "text": "D.1 Mesh to DMesh ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Our overall algorithm to convert the ground truth mesh into DMesh is outlined in Algorithm 1. We explain each step in detail below. ", "page_idx": 22}, {"type": "text", "text": "D.1.1 Point Initialization ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "At the start of optimization, we initialize the point positions $\\left(\\mathbb{P}\\right)$ , weights (W), and real values $(\\psi)$ using the given ground truth information $(\\mathbb{P}_{g t},\\mathbb{F}_{g t})$ . To be specific, we initialize the point attributes as follows. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{P}=\\mathbb{P}_{g t},\\quad\\mathbb{W}=[1,...,1],\\quad\\psi=[1,...,1].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The length of vector $\\mathbb{W}$ and $\\psi$ is equal to the number of points. In Figure 14, we illustrate the initialized DMesh using these point attributes, which becomes the convex hull of the ground truth mesh. ", "page_idx": 22}, {"type": "text", "text": "$\\overline{{\\mathbb{P}_{g t},\\mathbb{F}_{g t}\\gets}}$ Ground truth mesh vertices and faces   \n$\\mathbb{P}$ , W, $\\psi\\leftarrow$ Initialize point attributes for DMesh   \n$\\bar{\\mathbb{F}}\\gets$ Empty set of faces   \nwhile Optimization not ended do $\\mathbb{P}$ , W, $\\psi\\leftarrow\\mathrm{Do}$ point insertion, with $\\mathbb{P}$ , F\u00af $W D T$ , $P D\\leftarrow\\mathrm{Run}$ WDT algorithm, with $\\mathbb{P}$ , W $\\bar{\\mathbb{F}}\\gets$ Update faces to exclude, with $W D T$ $\\Lambda(\\mathbb{F}_{g t})\\dot{,}\\Lambda(\\bar{\\mathbb{F}})\\gets\\mathfrak{$ Compute existence probability for faces, with $\\mathbb{P},\\psi,W D T,P D$ $L_{r e c o n}\\leftarrow\\mathrm{Cor}$ mpute reconstruction loss, with $\\Lambda(\\mathbb{F}_{g t}),\\Lambda(\\bar{\\mathbb{F}})$ Update $\\mathbb{P},\\mathbb{W},\\psi$ to minimize $L_{r e c o n}$ Bound $\\mathbb{P}$   \nend ", "page_idx": 23}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/426fc323a4e0431d1c6121f5cd737bd1e90dbf6c1d8d2713990ae0ad6daee841.jpg", "img_caption": ["Figure 14: Intermediate results in converting bunny model to DMesh. For given ground truth mesh in (a), we initialize our point attributes using the mesh vertices. (b) Then, the initial mesh becomes convex hull of the original mesh. (c) To remove undesirable faces that were not in the original mesh, we insert additional points on the undesirable faces. Then, some of them disappear because of the inserted points. (d) After optimizing 5000 steps, just before another point insertion, DMesh recovers most of the ground truth connectivity. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Note that during optimization, we allow only small perturbations to the positions of initial points, and fix weights and real values of them to 1. This is because we already know that these points correspond to the ground truth mesh vertices, and thus should be included in the final mesh without much positional difference. In our experiments, we set the perturbation bound as $1\\%$ of the model size. ", "page_idx": 23}, {"type": "text", "text": "However, we notice that we cannot restore the mesh connectivity with only small perturbations to the initial point positions, if there are no additional points that can aid the process. Therefore, we periodically perform point insertion to add additional points, which is described below. ", "page_idx": 23}, {"type": "text", "text": "D.1.2 Point Insertion ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The point insertion is a subroutine to add additional points to the current point configurations. It is performed periodically, at every fixed step. The additional points are placed at the random place on the faces in $\\bar{\\mathbb F}$ , which correspond to the faces that should not exist in the final mesh. Therefore, these additional points can aid removing these undesirable faces. ", "page_idx": 23}, {"type": "text", "text": "However, we found out that inserting a point for every face in $\\bar{\\mathbb F}$ can be quite expensive. Therefore, we use $k$ -means clustering algorithm to aggregate them into $0.1\\cdot N_{F}$ clusters, where $N_{F}$ is the number of faces in $\\bar{\\mathbb F}$ , to add the centroids of the clusters to our running point set. On top of that, we select 1000 random faces in $\\bar{\\mathbb F}$ to put additional points directly on them. This is because there are cases where centroids are not placed on the good positions where they can remove the undesirable faces. ", "page_idx": 23}, {"type": "text", "text": "In Figure 14, we render DMesh after point insertion to the initialized mesh. Note that some of the undesirable faces disappear because of the added points. ", "page_idx": 23}, {"type": "text", "text": "Algorithm 2 Point cloud & Multi-view Reconstruction ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "T \u2190Observation (Point cloud, Multi-view images)   \n$\\mathbb{P}$ , W, $\\psi\\leftarrow$ Initialize point attributes for DMesh (using T if possible)   \n$\\mathbb{F}\\gets$ Empty set of faces   \nwhile epoch not ended do $\\mathbb{P}$ , W, $\\psi\\leftarrow$ (If not first epoch) Initialize point attributes with sample points from current DMesh, for mesh refinement // Phase 1 while step not ended do $W D\\bar{T}$ , $P D\\leftarrow{\\bf R u n}$ WDT algorithm with $\\mathbb{P}$ , W $\\mathbb{F}\\gets$ Update faces to evaluate existence probability for, with $W D T$ $\\Lambda(\\mathbb{F})\\gets$ Compute existence probability for faces in $\\mathbb{F}$ , with $\\mathbb{P},\\psi,W D T,P D$ $L_{r e c o n}\\gets($ Compute reconstruction loss, with $\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F}),T$ $L_{w e i q h t}\\gets$ Compute weight regularization, with $P D$ $L_{r e a l}\\gets$ Compute real regularization, with $\\mathbb{P},\\psi,W D T$ $L_{q u a l}\\leftarrow$ Compute quality regularization, with $\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F})$ L \u2190Lrecon + \u03bbweight \u00b7 Lweight + \u03bbreal \u00b7 Lreal + \u03bbqual \u00b7 Lqual Update $\\mathbb{P}$ , W, $\\psi$ to minimize $\\bar{L}$ end // Phase 2 $W D T$ , $P D\\leftarrow{\\bf R u n}$ WDT algorithm with $\\mathbb{P}$ , W $\\mathbb{F}\\gets$ Faces in $W D T$ $\\Lambda_{w d t}(\\mathbb{F})\\gets1$ while step not ended do $\\Lambda(\\mathbb{F})\\gets$ Compute existence probability for $\\mathbb{F}$ , with $\\mathbb{P},\\psi,\\Lambda_{w d t}(\\mathbb{F})$ $L_{r e c o n}\\gets\\$ Compute reconstruction loss, with $\\mathbb{P},\\mathbb{F},\\Lambda(\\mathbb{F}),T$ $L_{r e a l}\\gets$ Compute real regularization, with $\\mathbb{P},\\psi,W D T$ $L\\leftarrow L_{r e c o n}+\\lambda_{r e a l}\\cdot L_{r e a l}$ Update $\\psi$ to minimize $L$ end   \nend   \n$M\\gets\\mathrm{Get}$ final mesh from DMesh, after post-processing ", "page_idx": 24}, {"type": "text", "text": "D.1.3 Maintaining F\u00af ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this problem, we minimize the reconstruction loss specified in Eq. 15 to restore the connectivity in the ground truth mesh, and remove faces that do not exist in it. In the formulation, we denoted the faces that are comprised of mesh vertices $\\mathbb{P}$ , but are not included in the original mesh as $\\bar{\\mathbb F}$ . Even though we can enumerate all of them, the total number of faces in $\\bar{\\mathbb F}$ mounts to $O(N^{3})$ , where $N$ is the number of mesh vertices. Therefore, rather than evaluating all of those cases, we maintain a set of faces $\\bar{\\mathbb F}$ that we should exclude in our mesh during optimization. ", "page_idx": 24}, {"type": "text", "text": "To be specific, at each iteration, we find faces in the current WDT that are comprised of points in $\\mathbb{P}$ , but do not exist in $\\mathbb{F}$ , and add them to the running set of faces $\\bar{\\mathbb F}$ . On top of that, at every pre-defined number of iterations, in our case 10 steps, we compute $k$ -nearest neighboring points for each point in $\\mathbb{P}$ . Then, we find faces that can be generated by combining each point with 2 of its $k$ -nearest points, following Rakotosaona u. a. (2021). Then, we add the face combinations that do not belong to $\\mathbb{F}$ to $\\bar{\\mathbb F}$ In our experiments, we set $k=8$ . ", "page_idx": 24}, {"type": "text", "text": "D.2 Point cloud & Multi-view Reconstruction ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In Algorithm 2, we describe the overall algorithm that is used for point cloud and multi-view reconstruction tasks. We explain each step in detail below. ", "page_idx": 24}, {"type": "text", "text": "D.2.1 Two Phase Optimization ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We divide each optimization epoch in two phases. In the first phase (phase 1), we optimize all of the point attributes \u2013 positions, weights, and real values. However, in the second phase (phase 2), we fix the point positions and weights, and only optimize the real values. ", "page_idx": 24}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/f62fd7a238fbd399cc814f37e51bff7398dff951cac847ff7e5dba187a86581e.jpg", "img_caption": ["(b) Initialized DMesh (Points, Extracted Mesh) "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure 15: Initialized DMesh using sample points from ground truth mesh. (a) From ground truth mesh, we uniformly sample $10K$ points to initialize DMesh. (b) In the left figure, sample points from the ground truth mesh $(\\mathbb{P}_{s a m p l e})$ are rendered in red. The points that correspond to $\\mathbb{P}_{v o r o n o i}$ are rendered in blue. In the right figure, we render the initial mesh we can get from the points, which has a lot of holes. ", "page_idx": 25}, {"type": "text", "text": "This design aims at removing ambiguity in our differentiable formulation. That is, even though we desire face existence probabilities to converge to either 0 and 1, those probabilities can converge to the values in between. To alleviate this ambiguity, after the first phase ends, we fix the tessellation to make $\\Lambda_{w d t}$ for each face in $\\mathbb{F}$ to either 0 or 1. Therefore, in the second phase, we only care about the faces that exist in current $W D T$ , which have $\\Lambda_{w d t}$ value of 1. Then, we can only care about real values. ", "page_idx": 25}, {"type": "text", "text": "Note that the two differentiable renderers that we introduced in Appendix C.3 are designed to serve for these two phases, respectively. ", "page_idx": 25}, {"type": "text", "text": "D.2.2 Point Initialization with Sample Points ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this work, we propose two point initialization methods. The first initialization method can be used when we have sample points near the target geometry in hand. ", "page_idx": 25}, {"type": "text", "text": "This initialization method is based on an observation that the vertices of Voronoi diagram of a point set tend to lie on the medial axis of the target geometry (Amenta u. a., 1998a,b). Therefore, for the given sample point set $\\mathbb{P}_{s a m p l e}$ , we first build Voronoi diagram of it, and find Voronoi vertices $\\mathbb{P}_{v o r o n o i}$ . Then, we merge them to initialize our point set $\\mathbb{P}$ : ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}=\\mathbb{P}_{s a m p l e}\\cup\\mathbb{P}_{v o r o n o i},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "all of which weights are initialized to 1. Then, we set the real values $(\\psi)$ of points in $\\mathbb{P}_{s a m p l e}$ as 1, while setting those of points in $\\mathbb{P}_{v o r o n o i}$ as 0. ", "page_idx": 25}, {"type": "text", "text": "In Figure 15, we render the mesh that we can get from this initialization method, when we use $10K$ sample points. Note that the initial mesh has a lot of holes, because there could be Voronoi vertices that are located near the mesh surface, as pointed out by (Amenta u. a., 1998b). However, we can converge to the target mesh faster than the initialization method that we discuss below, because most of the points that we need are already located near the target geometry. ", "page_idx": 25}, {"type": "text", "text": "D.2.3 Point Initialization without Sample Points ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "If there is no sample point that we can use to initialize our points, we initialize our points with $N^{3}$ points regularly distributed on a grid structure that encompasses the domain, all of which has weight 1 and $\\psi$ value of 1. We set $N=20$ for every experiment (Figure 16a). Then, we optimize the mesh to retrieve a coarse form of the target geometry (Figure 16b). Note that we need to refine this mesh in the subsequent epochs, as explained below. ", "page_idx": 25}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/4e892b3e101248d41ee8fd1b0610631fdb08b9f8581bbe2a72af71364ef0bbc4.jpg", "img_caption": ["Figure 16: Optimization process for multi-view reconstruction for Plant model. At each row, we present the initial state (left) and the last state (right) of each epoch. For each figure, the left rendering shows the point attributes color coded based on real values, while the right one shows the extracted mesh. (a), (b) In the first epoch, we initialize DMesh without sample points. At the end of each epoch, we sample points from the current mesh, and use them for initialization in the next epoch. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "D.2.4 Point Initialization for Different Inputs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Until now, we introduced two point initialization techniques. When the input is a point cloud, we sample subset of the point cloud to initialize our mesh (Figure 15). However, when the input is multi-view images, we start from initialization without sample points (Figure 16), because there is no sample point cloud that we can make use of. ", "page_idx": 26}, {"type": "text", "text": "D.2.5 Maintaining F ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We maintain the running set of faces to evaluate probability existence for in $\\mathbb{F}$ . At each iteration, after we get $W D T$ , we insert every face in $W D T$ to $\\mathbb{F}$ , as it has a high possibility to persist in the subsequent optimization steps. Also, as we did int mesh to DMesh conversion (Appendix D.1), at every 10 optimization step, we find $k$ -nearest neighbors for each point, and form face combinations based on them. Then, we add them to $\\mathbb{F}$ . ", "page_idx": 26}, {"type": "text", "text": "D.2.6 Mesh Refinement ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "At start of each epoch, if it is not the first epoch, we refine our mesh by increasing the number of points. To elaborate, we refine our mesh by sampling $N$ number of points on the current DMesh, and then initialize point attributes using those sample points as we explained above. We increase $N$ as number of epoch increases. For instance, in our multi-view reconstruction experiments, we set the number of epochs as 4, and set $N=(1K,3K,10K)$ for the epochs excluding the first one. In Figure 16, we render the initial and the last state of DMesh of each epoch. Note that the mesh complexity increases and becomes more accurate as epoch proceeds, because we use more points. Therefore, this approach can be regarded as a coarse-to-fine approach. ", "page_idx": 27}, {"type": "text", "text": "D.2.7 Post-Processing ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "When it comes to multi-view reconstruction, we found out that it is helpful to add one more constraint in defining the face existence. In our formulation, in general, a face $F$ has two tetrahedra $(T_{1},T_{2})$ that are adjacent to each other over the face. Then, we call the remaining point of $T_{1}$ and $T_{2}$ that is not included in $F$ as $P_{1}$ and $P_{2}$ . Our new constraint requires at least one of $P_{1}$ and $P_{2}$ to have $\\psi$ value of 0 to let $F$ exist. ", "page_idx": 27}, {"type": "text", "text": "This additional constraint was inspired by the fact that $F$ is not visible from outside if $F$ exists in our original formulation, and both of $P_{1}$ and $P_{2}$ have $\\psi$ value of 1. That is, if it is not visible from outside, we do not recognize its existence. This constraint was also adopted to accommodate our real regularization, which increases the real value of points near surface. If this regularization makes the real value of points inside the closed surface, they would end up in internal faces that are invisible from outside. Because of this invisibility, our loss function cannot generate a signal to remove them. In the end, we can expect all of the faces inside a closed surface will exist, because of the absence of signal to remove them. Therefore, we choose to remove those internal faces by applying this new constraint in the post-processing step. ", "page_idx": 27}, {"type": "text", "text": "Note that this discussion is based on the assumption that our renderer does a precise depth testing. If it does not do the accurate depth testing, internal faces can be regarded as visible from outside, and thus get false gradient signal. In Figure 13a, the final mesh after phase 1 is rendered, and we can see therer are lots of internal faces as the renderer used in phase 1 does not support precise depth testing. However, we can remove them with the other renderer in phase 2, as shown in Figure 13b, which justifies our implementation of two different renderers. ", "page_idx": 27}, {"type": "text", "text": "Finally, we note that this constraint is not necessary for point cloud reconstruction, because if we minimize $C D_{o u r s}$ in Appendix C.2, the internal faces will be removed automatically. ", "page_idx": 27}, {"type": "text", "text": "E Experimental Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we provide experimental details for the results in Section 5, and visual renderings of the our reconstructed mesh. Additionally, we provide the results of ablation studies about regularizations that we suggested in Section 4.3. ", "page_idx": 27}, {"type": "text", "text": "E.1 Mesh to DMesh ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "As shown in Table 1, we reconstruct the ground truth connectivity of Bunny, Dragon, and Buddha model from Stanford dataset (Curless und Levoy, 1996). For all these experiments, we optimized for $20K$ steps, and used an ADAM optimizer (Kingma und Ba, 2014) with learning rate of $10^{-4}$ . For Bunny model, we inserted additional points at every 5000 step. For the other models, we inserted them at every 2000 step. ", "page_idx": 27}, {"type": "text", "text": "In Figure 17, we provide the ground truth mesh and our reconstructed mesh. We can observe that most of the connectivity is preserved in our reconstruction, as suggested numerically in Table 1. However, note that the appearance of the reconstructed mesh can be slightly different from the ground truth mesh, because we allow $1\\%$ of positional perturbations to the mesh vertices. ", "page_idx": 27}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/0ebd1810ddc4d072c836fd56fd8287adc2fc242b8b47bdd8463adc04af6f69f5.jpg", "img_caption": ["(b) Reconstructed DMesh "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Figure 17: Reconstruction results for mesh to DMesh experiment. From Left: Bunny, Dragon, and Buddha. We can observe that most of the edge connectivity is perserved in the reconstruction, even though the appearance is slightly different from the ground truth mesh because of small perturbations of vertex positions. ", "page_idx": 28}, {"type": "text", "text": "E.2 Point Cloud & Multi-view Reconstruction ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "E.2.1 Hyperparameters for Point Cloud Reconstruction ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 Optimizer: ADAM Optimizer, Learning rate $=10^{-4}$ for open surface meshes and two mixed surface meshes (Bigvegas, Raspberry) $/\\,3\\cdot10^{-4}$ for closed surface meshes, and one mixed surface mesh (Plant).   \n\u2022 Regularization: $\\lambda_{w e i g h t}=10^{-8},\\lambda_{r e a l}=10^{-3},\\lambda_{q u a l}=10^{-3}$ for every mesh.   \n\u2022 Number of epochs: Single epoch for every mesh.   \n\u2022 Number of steps per epoch: 1000 steps for phase 1, 500 steps for phase 2 for every mesh. ", "page_idx": 28}, {"type": "text", "text": "E.2.2 Hyperparameters for Multi-view Reconstruction ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 Optimizer: ADAM Optimizer, Learning rate $=10^{-3}$ in the first epoch, and $3\\cdot10^{-4}$ in the other epochs for every mesh.   \n\u2022 Weight Regularization: $\\lambda_{w e i g h t}=10^{-8}$ for every mesh.   \n\u2022 Real Regularization: $\\lambda_{r e a l}=10^{-3}$ for the first 100 steps in every epoch for open surface meshes and one mixed surface mesh (Plant) $/\\,10^{-2}$ for the first 100 steps in every epoch for closed surface meshes and two mixed surface meshes (Bigvegas, Raspberry).   \n\u2022 Quality Regularization: $\\lambda_{q u a l}=10^{-3}$ for every mesh.   \n\u2022 Normal Coefficient: $\\lambda_{n o r m a l}=0$ for every mesh (Eq. 17).   \n\u2022 Number of epochs: 4 epochs for every mesh. In the first epoch, use $20^{-3}$ regularly distributed points for initialization. In the subsequent epochs, sample $1K,3K$ , and $10K$ points from the current mesh for initialization. \u2022 Number of steps per epoch: 500 steps for phase 1, 500 steps for phase 2 for every mesh.   \n\u2022 Batch size: 64 for open surface meshes, 16 for the other meshes. ", "page_idx": 28}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/95d01d49cf7587a412f30ba50e4a4d856db6d9936c7ffdc829d68d400e247af3.jpg", "img_caption": ["Figure 18: Reconstruction results for a closed surface model in Thingi32 dataset. Flexicube (Shen u. a., 2023) can generate internal structures, while our approach removes them through post-processing. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/ff5b32b9e415e2d30ec106dbba2861c2f09fd0ba9c00afecb864caff33c27119.jpg", "img_caption": ["Figure 19: Reconstruction results for the Plant model. Flexicube (Shen u. a., 2023) can generate redundant, self-intersecting faces for open surfaces, in this case, leaves. To better capture the redundant faces, we rendered the models from upper side, which is shown in the bottom right figures. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "E.2.3 Visual Renderings ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In Figure 22, 23, and 24, we provide visual renderings of our point cloud and multi-view reconstruction results with ground truth mesh. We also provide illustration of input point cloud and diffuse map. Note that we also used depth renderings for multi-view reconstruction experiments. ", "page_idx": 29}, {"type": "text", "text": "E.2.4 Additional Discussion ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Generally, we can observe that reconstruction results from both point cloud and multi-view images capture the overall topology well. However, we noticed that the multi-view reconstruction results are not as good as point cloud reconstruction results. In particular, we can observe small holes in the multi-view reconstruction results. We assume that these artifacts are coming from relatively weaker supervision of multi-view images than dense point clouds. Also, we believe that we can improve these multi-view reconstruction results with more advanced differentiable renderer, and better mesh refinement strategy. In the current implementation, we lose connectivity information at the start of each epoch, which is undesirable. We believe that we can improve this approach by inserting points near the regions of interest, rather than resampling over entire mesh. ", "page_idx": 29}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/666993f773ba30923d02fe85453cf65619bc2716b60fd5f7fcabc8dfecb35176.jpg", "img_caption": ["Figure 20: Point cloud reconstruction results with different $\\lambda_{w e i g h t}$ . From Left: $\\lambda_{w e i g h t}\\,=$ $10^{-6},10^{-5}$ , and $10^{-4}$ . "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "Also, regarding comparison to Flexicube (Shen u. a., 2023) in Table 2, we tried to found out the reason why ours give better results than Flexicube in terms of CD to the ground truth mesh for closed surfaces in thingi32 dataset. We could observe that Flexicube\u2019s reconstruction results capture fine geometric details on the surface mesh, but also observed that they have lots of false internal structure (Figure 18). Note that this observation not only applies to closed surfaces, but also to open surfaces, where it generates lots of false, self-intersecting faces (Figure 19). Our results do not suffer from these problems, as we do post-processing (Appendix D.2) to remove inner structure, and also our method can represent open surfaces better than the volumetric approaches without self-intersecting faces. ", "page_idx": 30}, {"type": "text", "text": "E.3 Ablation studies ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we provide ablation studies for the regularizations that we proposed in Section 4.3.   \nWe tested the effect of the regularizations on the point cloud reconstruction task. ", "page_idx": 30}, {"type": "text", "text": "E.3.1 Weight Regularization ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We tested the influence of weight regularzation in the final mesh, by choosing $\\lambda_{w e i g h t}$ in $(10^{-6},10^{-5},10^{-4})$ . Note that we set the other experimental settings as same as described in Section E.2, except $\\lambda_{q u a l i t y}$ , which is set as 0, to exclude it from optimization. ", "page_idx": 30}, {"type": "text", "text": "In Table 5, we provide the quantitative results for the experiments. For different $\\lambda_{w e i g h t}$ , we reconstructed mesh from point clouds, and computed average Chamfer Distance (CD) and average number of faces across every test data. We can observe that there exists a clear tradeoff between CD and mesh complexity. To be specific, when $\\lambda_{w e i g h t}=10^{-6}$ , the CD is not very different from the results in Table 2, where we use $\\lambda_{w e i g h t}=10^{-8}$ . However, when it increases to $10^{-5}$ and $10^{-4}$ , we can observe that the mesh complexity (in terms of number of faces) decreases, but CD increases quickly. ", "page_idx": 30}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/c5aaf1839575fb2195014f34f0c9cdb1a933f5c2129533f787161e6a31f6bdab.jpg", "img_caption": ["Figure 21: Point cloud reconstruction results with different $\\lambda_{q u a l i t y}$ . From Left: $\\lambda_{r e a l}\\;=$ $10^{-4},10^{-3}$ , and $10^{-2}$ . ", "(b) Plant "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "The renderings in Figure 20 support these quantitative results. When $\\bar{\\lambda}_{w e i g h t}=10^{-6}$ , we can observe good reconstruction quality. When $\\lambda_{w e i g h t}=10^{-5}$ , there are small artifacts in the reconstruction, but we can get meshes of generally good quality with fewer number of faces. However, when it becomes $10^{-4}$ , the reconstruction results deteriorate, making holes and bumpy faces on the smooth surface. Therefore, we can conclude that weight regularization contributes to reducing the mesh complexity. However, we need to choose $\\lambda_{w e i g h t}$ carefully, so that it does not harm the reconstruction quality. The experimental results tell us setting $\\lambda_{w e i g h t}$ to $10^{-6}$ could be a good choice to balance between these two contradictory objectives. ", "page_idx": 31}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/ddf664a35fd665712b2ed962a1e9dab58d00e81f36b57ccb49f9c45f020c63cb.jpg", "table_caption": ["Table 5: Ablation study for weight regularization, quantitative results. "], "table_footnote": [], "page_idx": 31}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "E.3.2 Quality Regularization ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "As we did in the previous section, we test the influence of quality regularization in the final mesh by selecting $\\lambda_{r e a l}$ among $(10^{-4},10^{-3},10^{-2})$ . We also set the other experimental settings as same as before, except $\\lambda_{w e i g h t}=0$ . ", "page_idx": 31}, {"type": "text", "text": "In Table 6 and Figure 21, we present quantitative and qualitative comparisons between the reconstruction results. We provide statistics about average CD, average number of faces, and average aspect ratio of faces. Interestingly, unlike weight regularization, we could not observe tradeoff between CD and aspect ratio. Rather than that, we could find that CD decreases as aspect ratio gets smaller, and thus the triangle quality gets better. ", "page_idx": 31}, {"type": "table", "img_path": "Io1qKqCVIK/tmp/b471dec3d572e1631ae1be73f2706d3b32800377f93826b32836c1bf3bc3aa09.jpg", "table_caption": ["Table 6: Ablation study for quality regularization, quantitative results. "], "table_footnote": [], "page_idx": 31}, {"type": "text", "text": "We find the reason for this phenomenon in the increase of smaller, good quality triangle faces. Note that there is no significant difference between the number of faces between $\\bar{\\lambda_{q u a l}}=\\bar{1}0^{-4}$ and $10^{-3}$ . Also, we cannot find big difference between visual renderings between them, even though the aspect ratio was clearly improved. However, when $\\lambda_{q u a l}$ becomes $10^{-2}$ , the number of faces increase fast, which can be observed in the renderings, too. We believe that this increase stems from our quality constraint, because it has to generate more triangles to represent the same area, if there is less degree of freedom to change the triangle shape. Since it has more triangle faces, we assume that they contribute to capturing fine details better, leading to the improved CD. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "However, at the same time, note that the number of holes increase as we increase $\\lambda_{q u a l}$ , which lead to visual artifacts. We assume that there are not enough points to remove these holes, by generating quality triangle faces that meet our needs. Therefore, as discussed before, if we can find a systematic way to prevent holes, or come up with a better optimization scheme to remove them, we expect that we would be able to get accurate mesh comprised of better quality triangles. ", "page_idx": 32}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/be37dcb691d26a5a759c479f4caa8199afbc36f8324cb5b2e2755c349810581d.jpg", "img_caption": ["(d) Mesh 448 "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Figure 22: Point cloud and Multi-view Reconstruction results for open surface models. From Left: Ground truth mesh, sample point cloud, point cloud reconstruction results, diffuse rendering, multi-view reconstruction results. ", "page_idx": 33}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/4ce684926ad9e0151400f058e8ab480514ed4e1e4ee9d6061da8950abb7436d8.jpg", "img_caption": ["(d) Mesh 527631 "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "Figure 23: Point cloud and Multi-view Reconstruction results for closed surface models. From Left: Ground truth mesh, sample point cloud, point cloud reconstruction results, diffuse rendering, multi-view reconstruction results. ", "page_idx": 34}, {"type": "image", "img_path": "Io1qKqCVIK/tmp/9398e310be6b93e4ddd93c82369d1b684c6404f241227a1b643b72f7ac43283e.jpg", "img_caption": ["(c) Mesh 313444 "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "Figure 24: Point cloud and Multi-view Reconstruction results for mixed surface models. From Left: Ground truth mesh, sample point cloud, point cloud reconstruction results, diffuse rendering, multi-view reconstruction results. ", "page_idx": 35}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: In abstract and introduction, we described that we are presenting a differentiable mesh, and we are going to explore various aspects of it (e.g. computational cost, reconstruction task, regularization). They are accurately discussed across the entire paper, including Appendix. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 36}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: We discussed the two limitations of our current approach in Section 6, which are about computational efficiency and manifoldness of the generated mesh. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 36}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [No] ", "page_idx": 37}, {"type": "text", "text": "Justification: Even though we tried our best to describe every theoretical detail in main paper, especially in Section 3.2, and Appendix B, our method assumes that the reader has some background knowledge about the geoemtrical concepts. However, we specified the sources that the readers can refer to learn details about the theoretical claims we made in the paper. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 37}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: In Appendix D and E, we provided the pseudocode of our optimization process, and detailed hyperparameters to reproduce the experimental results. Also, we included code in the supplementary material. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 37}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: Excluding 2 models that we obtained from Adobe Stock, every model that we used is publicly available. Also, we submitted our code. However, due to the size limitation of the supplementary material, we could not submit the entire version of the code, because it depends on many external libraries. But we believe readers can compare the code and the paper to learn details of our paper. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 38}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: We provide experimental details in Appendix E. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 38}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: For the nature of our optimization based experiments, random initialization has little affect in the results. In addition, our experiments exam the effect of resolution and topology varieties, it does not use large amount of testing data. Thus, error bars for showing statistical significance of the experiments are not suitable for our paper. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: We provided the machine that we used for running experiments in Section 5, and reported execution time in the experimental results. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 39}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: Our research conforms to the every guideline in the Code of Ethics. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 39}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Our research is mainly about geometry, especially about triangle mesh formulation. So we believe it does not possess societal impact. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 40}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Our research does not deliver any trained model, but suggest a method for formulating differentiable mesh. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 40}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 40}, {"type": "text", "text": "Answer: [No] ", "page_idx": 40}, {"type": "text", "text": "Justification: We cited the source of assets that we used in experiments in Section 5, but did not include license information about them. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 41}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: We used only existing assets. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 41}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: Our research does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 41}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: Our research does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]