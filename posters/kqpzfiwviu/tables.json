[{"figure_path": "kQPzFiwVIu/tables/tables_2_1.jpg", "caption": "Table 1: Eudoxus compared to baselines. We report the semantic score over all correctly parsed models. 1 is completely wrong; 5 is fully correct. Eudoxus is limited to five LLM calls per benchmark, and four benchmarks hit this limit.", "description": "This table compares the performance of Eudoxus, a prototype implementation of SPEAC, against several baseline methods for generating UCLID5 code from natural language descriptions.  The comparison focuses on two key metrics: the percentage of generated programs that pass compiler checks (syntactic correctness) and a semantic correctness score (ranging from 1 to 5, where 5 indicates fully correct).  The table shows that Eudoxus significantly outperforms the baselines in terms of syntactic correctness, while maintaining comparable semantic correctness. The limitation of five LLM calls per benchmark is also noted.", "section": "6 Evaluation"}, {"figure_path": "kQPzFiwVIu/tables/tables_7_1.jpg", "caption": "Table 1: Eudoxus compared to baselines. We report the semantic score over all correctly parsed models. 1 is completely wrong; 5 is fully correct. Eudoxus is limited to five LLM calls per benchmark, and four benchmarks hit this limit.", "description": "This table compares the performance of Eudoxus, a prototype implementation of SPEAC, against various LLM baselines on syntactic and semantic correctness for UCLID5 code generation.  It shows the percentage of outputs that successfully passed compiler checks (parse rate) and a semantic score (1-5, with 5 being fully correct) for each approach.  The baselines include different prompting techniques (few-shot, chain-of-thought, three-shot) and fine-tuning with both GPT3t and GPT4t LLMs.  The table highlights Eudoxus's superior performance in syntactic correctness, achieving a much higher parse rate than all baselines.  Note that Eudoxus's performance is limited by a maximum of five LLM calls per benchmark, and this limit was reached in four cases.", "section": "6 Evaluation"}, {"figure_path": "kQPzFiwVIu/tables/tables_8_1.jpg", "caption": "Table 1: Eudoxus compared to baselines. We report the semantic score over all correctly parsed models. 1 is completely wrong; 5 is fully correct. Eudoxus is limited to five LLM calls per benchmark, and four benchmarks hit this limit.", "description": "This table compares the performance of Eudoxus, a prototype implementation of the SPEAC approach for generating UCLID5 code, against several Large Language Model (LLM) baselines.  The metrics used are the percentage of generated programs that are syntactically correct (pass all compiler checks, \"Parse Rate\") and a semantic correctness score (1-5, where 5 is fully correct). The baselines include various prompting strategies (few-shot, three-shot, with and without Chain-of-Thought), self-repair, and fine-tuning. The table demonstrates that Eudoxus significantly outperforms the baselines in terms of generating syntactically correct code, with a smaller, but still positive impact on semantic accuracy.", "section": "6 Evaluation"}, {"figure_path": "kQPzFiwVIu/tables/tables_9_1.jpg", "caption": "Table 1: Eudoxus compared to baselines. We report the semantic score over all correctly parsed models. 1 is completely wrong; 5 is fully correct. Eudoxus is limited to five LLM calls per benchmark, and four benchmarks hit this limit.", "description": "This table compares the performance of Eudoxus, a prototype implementation of the SPEAC approach, against several LLM baselines on two metrics: syntactic correctness (passing compiler checks) and semantic correctness (manual assessment of the generated code).  It shows the number of benchmarks (out of 33) that passed compiler checks and the distribution of semantic scores (1-5) for each approach.  The table highlights that Eudoxus significantly outperforms the baselines in terms of syntactic correctness, while maintaining comparable semantic correctness. The limitation of Eudoxus to five LLM calls per benchmark is also noted.", "section": "6.1 Results"}]