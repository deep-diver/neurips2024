[{"figure_path": "RnQdRY1h5v/tables/tables_7_1.jpg", "caption": "Table 3: BMOJO demonstrates strong performance on a wide range of synthetic tasks, and both small and medium scale. We compare the performance of various models at the 2 layer and the 130M scale on 4 different synthetic tasks, (1) Selective Copying, a task involving recall of a specific sequence of tokens with random spacing (2) Induction Heads, the recall of a specific token amongst noisy tokens (3) Noisy MQAR, an associative recall task retrieving keys in a noisy environment and (4) Fuzzy Recall, an associative recall task involving keys and values that are multiple tokens each. We find that B'MOJO models consistently outperform or match all existing baselines.", "description": "This table compares the performance of B'MOJO against other state-of-the-art models on four different synthetic tasks assessing the models' ability to recall specific information from a sequence.  The results show that B'MOJO consistently achieves better or comparable performance across various model sizes and task difficulties.", "section": "4.1 Synthetic Tasks"}, {"figure_path": "RnQdRY1h5v/tables/tables_8_1.jpg", "caption": "Table 1: B'MOJO's performance on downstream tasks. We compare different architectures on several zero-shot downstream tasks used to test common-sense reasoning and question-answering on relatively small contexts. These tasks, however, do not require strong recall capabilities because the input text is typically very short (results on longer contexts are reported in Table 2). On pre-training perplexity B\u2019MOJO performs on par with our pre-trained Mistral model and outperforms our pre-trained Mamba models at the largest scale we test 1.4B. However, on accuracy metrics, while B'MOJO still outperforms Mamba, its gap with the Mistral model increases.", "description": "This table compares the performance of B'MOJO against several baseline models (Mistral, Mamba and Hybrid models) on several zero-shot downstream tasks. The results show that B'MOJO achieves comparable perplexity to Mistral and outperforms Mamba on accuracy metrics, especially on larger model sizes (1.4B).", "section": "4.3 Zero Shot Evaluation"}, {"figure_path": "RnQdRY1h5v/tables/tables_20_1.jpg", "caption": "Table 3: BMOJO demonstrates strong performance on a wide range of synthetic tasks, and both small and medium scale. We compare the performance of various models at the 2 layer and the 130M scale on 4 different synthetic tasks, (1) Selective Copying, a task involving recall of a specific sequence of tokens with random spacing (2) Induction Heads, the recall of a specific token amongst noisy tokens (3) Noisy MQAR, an associative recall task retrieving keys in a noisy environment and (4) Fuzzy Recall, an associative recall task involving keys and values that are multiple tokens each. We find that B'MOJO models consistently outperform or match all existing baselines.", "description": "This table presents the results of four different synthetic tasks performed on two different model sizes (2-layer and 130M) to evaluate the performance of B'MOJO against other models.  The tasks are designed to test different aspects of memory recall and accuracy under varying levels of noise and complexity.", "section": "4.1 Synthetic Tasks"}]