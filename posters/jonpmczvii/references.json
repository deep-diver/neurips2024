{"references": [{"fullname_first_author": "Y. Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-12-12", "reason": "This paper provides improved algorithms and analysis for linear stochastic bandits, which is foundational to the multi-task Bayesian linear bandit problem studied in this paper."}, {"fullname_first_author": "S. Basu", "paper_title": "No regrets for learning the prior in bandits", "publication_date": "2021-12-12", "reason": "This paper introduces a novel framework for hierarchical Bayesian bandits that directly learns the prior distribution, a key concept related to the hierarchical Bayesian bandit algorithms analyzed in the current paper."}, {"fullname_first_author": "E. Kaufmann", "paper_title": "On Bayesian upper confidence bounds for bandit problems", "publication_date": "2012-01-01", "reason": "This paper introduces the Bayesian upper confidence bound (BayesUCB) algorithm, which is extended and analyzed in this work within the hierarchical Bayesian setting."}, {"fullname_first_author": "B. Kveton", "paper_title": "Meta-Thompson sampling", "publication_date": "2021-07-01", "reason": "This paper proposes the meta-Thompson sampling algorithm, which is a significant predecessor and foundational algorithm for the hierarchical Thompson sampling methods discussed in this paper."}, {"fullname_first_author": "J. Hong", "paper_title": "Hierarchical Bayesian bandits", "publication_date": "2022-05-01", "reason": "This paper is the most directly related work, focusing on hierarchical Bayesian bandits and providing the most recent prior work to the theoretical improvements in Bayes regret bounds presented in the current paper."}]}