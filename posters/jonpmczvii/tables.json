[{"figure_path": "joNPMCzVIi/tables/tables_4_1.jpg", "caption": "Table 1: Different Bayes regret bounds for multi-task d-dimensional linear (or K-armed) bandit problem in the sequential setting. m is the number of tasks, n the number of iterations per task, A is the action set. Bayes Regret Bound =Bound I + Bound II + Negligible Terms, where Bound I is the regret bound for solving m tasks, Bound II the regret bound for learning hyper-parameter \u03bc*. ", "description": "This table compares different Bayes regret bounds for multi-task linear bandit problems in a sequential setting.  It shows the regret bounds (Bound I and Bound II) achieved by various algorithms from different papers, distinguishing between the regret for solving multiple tasks and the regret for learning hyperparameters. The action set (A) can be finite or infinite.", "section": "5 Bayes Regret Bounds"}, {"figure_path": "joNPMCzVIi/tables/tables_5_1.jpg", "caption": "Table 1: Different Bayes regret bounds for multi-task d-dimensional linear (or K-armed) bandit problem in the sequential setting. m is the number of tasks, n the number of iterations per task, A is the action set. Bayes Regret Bound =Bound I + Bound II + Negligible Terms, where Bound I is the regret bound for solving m tasks, Bound II the regret bound for learning hyper-parameter \u03bc*. ", "description": "This table compares different Bayes regret bounds for multi-task linear bandit problems in the sequential setting.  It shows the regret bounds (Bound I and Bound II) achieved by different algorithms ([25, Theorem 3], [7, Theorem 5], [17, Theorem 3], and the authors' Theorems 5.1 and 5.2), categorized by whether the action set is finite or infinite.  Bound I represents the regret for solving the m tasks, and Bound II represents the regret for learning the hyper-parameter \u03bc*. The table helps to illustrate the improvements in regret bounds achieved by the authors' algorithms.", "section": "5 Bayes Regret Bounds"}, {"figure_path": "joNPMCzVIi/tables/tables_7_1.jpg", "caption": "Table 1: Different Bayes regret bounds for multi-task d-dimensional linear (or K-armed) bandit problem in the sequential setting. m is the number of tasks, n the number of iterations per task, A is the action set. Bayes Regret Bound =Bound I + Bound II + Negligible Terms, where Bound I is the regret bound for solving m tasks, Bound II the regret bound for learning hyper-parameter \u03bc*. ", "description": "This table compares different Bayes regret bounds from existing research on multi-task linear bandit problems in a sequential setting (meaning each task is solved one at a time).  It shows the regret bounds broken down into two components: Bound I (regret from solving the individual tasks) and Bound II (regret from learning the hyperparameter).  The table helps illustrate the improvements achieved in the current paper.", "section": "5 Bayes Regret Bounds"}, {"figure_path": "joNPMCzVIi/tables/tables_21_1.jpg", "caption": "Table 3: Different Bayes regret bounds for multi-task d-dimensional linear bandit problem in the concurrent setting. m is the number of tasks, n is the number of iterations per task, A is the action set. Bayes Regret Bound =Bound I + Bound II + Negligible Terms, where Bound I is the regret bound for solving m tasks, Bound II the regret bound for learning hyper-parameter \u03bc*. ", "description": "This table compares different Bayes regret bounds for multi-task d-dimensional linear bandit problems in the concurrent setting.  It shows the regret bounds obtained from three different sources ([17, Theorem 4], Our Theorem 5.3, Our Theorem C.2), categorized by whether the action set |A| is finite or infinite.  For each source, the table is further divided into Bound I (regret bound for solving m tasks) and Bound II (regret bound for learning the hyper-parameter \u03bc*). This allows for a detailed comparison of different approaches to solving the multi-task concurrent linear bandit problem.", "section": "5 Bayes Regret Bounds"}, {"figure_path": "joNPMCzVIi/tables/tables_29_1.jpg", "caption": "Table 1: Different Bayes regret bounds for multi-task d-dimensional linear (or K-armed) bandit problem in the sequential setting. m is the number of tasks, n the number of iterations per task, A is the action set. Bayes Regret Bound =Bound I + Bound II + Negligible Terms, where Bound I is the regret bound for solving m tasks, Bound II the regret bound for learning hyper-parameter \u03bc*. ", "description": "This table compares different Bayes regret bounds for multi-task linear bandit problems in a sequential setting.  It shows the components of the Bayes regret bound (Bound I for solving m tasks, Bound II for learning the hyperparameter \u03bc*), highlighting the different results obtained by various studies ([25, Theorem 3], [7, Theorem 5], [17, Theorem 3]) and the improved bounds proposed by the authors (Our Theorem 5.1 and Our Theorem 5.2). The action set (A) is considered in both finite and infinite cases.", "section": "5 Bayes Regret Bounds"}]