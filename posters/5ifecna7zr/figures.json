[{"figure_path": "5IFeCNA7zR/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of our proposed DARG framework. We first use an LLM to construct internal reasoning graphs with rule-based supervision for label consistency. After that, we augment benchmarks through fine-grained graph interpolation based on different complexity dimensions. Finally, we decode the graph back into the original data format and use a code-augmented LLM agent to verify the label's correctness.", "description": "This figure illustrates the DARG framework, a dynamic evaluation method for LLMs.  It begins by constructing reasoning graphs from existing benchmarks using an LLM. These graphs are then perturbed to create new data points with varying complexity levels. A code-augmented LLM verifies the accuracy of the generated data. The process involves three main stages: reasoning graph construction, graph interpolation to increase complexity, and new data point verification.  The framework allows for the adaptive and dynamic evaluation of LLMs by continually creating new challenges.", "section": "Method: DARG"}, {"figure_path": "5IFeCNA7zR/figures/figures_4_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure displays the performance of fifteen different Large Language Models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graph increases along three dimensions: numerical complexity, graph width, and graph depth. Each dimension's complexity is increased incrementally, showing how the accuracy of each LLM changes as the complexity of the tasks increases. This illustrates the impact of increasing task complexity on the models\u2019 performance.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_5_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure shows how the accuracy of 15 different Large Language Models (LLMs) changes as the complexity of the GSM8K benchmark dataset increases.  The complexity is increased along three dimensions: numerical complexity (increased difficulty of the calculations), width (more parallel reasoning steps required), and depth (more sequential steps).  The graph demonstrates that in nearly all cases, accuracy decreases as the complexity increases across all three dimensions. The extent of the accuracy drop varies across different LLMs, highlighting the varying robustness of different models to increased complexity.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_6_1.jpg", "caption": "Figure 4: Comparison of different models' performances with CoT as the number of attribute pairs increases on the BBQ dataset when applying DARG. All models show a decreasing trend in overall accuracy (\u2191) and an increasing trend in bias scores (\u2193) in both ambiguous and disambiguous contexts. Except for Mistral 7B, GPT-4 Turbo and Gemini-1.5-Pro demonstrate the highest overall avoidance (\u2193), indicating their over-sensitivity to contents with protected groups.", "description": "This figure displays the performance of various LLMs on the Bias Benchmark for QA (BBQ) dataset as the number of attribute pairs increases, using Chain-of-Thought (CoT) prompting and the DARG framework.  The results demonstrate a consistent decrease in overall accuracy and an increase in bias scores across all models as complexity grows.  LLMs with higher overall avoidance rates (indicating a tendency to avoid answering when unsure) also show higher oversensitivity to content involving protected groups.", "section": "3.2 Social Reasoning: BBQ"}, {"figure_path": "5IFeCNA7zR/figures/figures_6_2.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure displays the performance changes of fifteen different Large Language Models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graph increases along three dimensions: numerical complexity, graph depth, and graph width.  Each bar represents the accuracy of a specific LLM on the GSM8K dataset under a specific complexity level.  The x-axis shows the increase in complexity level, while the y-axis shows the accuracy. The figure allows for a comparison of how different LLMs handle increasing complexity and the relative impact of each complexity dimension on model performance.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_7_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure shows the performance change of 15 different Large Language Models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graph increases.  The complexity is increased along three dimensions: numerical complexity, width increase, and depth increase.  The graph illustrates how the accuracy of each LLM changes as the complexity increases for each of the three dimensions. It helps to visualize the impact of increased complexity on the performance of various LLMs and allows for a comparison of their robustness to increasing complexity.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_7_2.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure displays the performance changes of fifteen Large Language Models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graph increases across three dimensions: numerical complexity, graph width, and graph depth.  Each bar represents an LLM's accuracy on the task. The x-axis shows the level of complexity increase (e.g., 'Original', '+2', '+4' etc. indicating an increase in the complexity parameter).  The y-axis shows the accuracy scores. The figure demonstrates how the performance of different LLMs varies with respect to increased complexity levels across different dimensions, highlighting LLMs' robustness to the growing complexity of reasoning tasks.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_17_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure displays the performance of fifteen different Large Language Models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graph increases.  The complexity is manipulated along three different dimensions: numerical complexity, graph depth, and graph width.  Each dimension is varied incrementally, allowing observation of how LLM performance changes as complexity rises.  The x-axis represents the increased complexity level for each dimension, and the y-axis shows the accuracy of the LLMs. The figure allows for a comparison of the performance of various LLMs across different complexity levels and dimensions, helping to understand the models' robustness and limitations under different types of reasoning challenges.", "section": "3.1 Mathematical Reasoning: GSM8K"}, {"figure_path": "5IFeCNA7zR/figures/figures_18_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure displays the performance of fifteen different large language models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graphs increases across three dimensions: numerical complexity, graph depth, and graph width. Each dimension's complexity is incrementally increased, allowing for observation of how the LLMs' accuracy changes. The graph provides insights into the robustness and limitations of various LLMs when confronted with increasingly complex reasoning tasks. It helps understand how different models perform in relation to the increasing complexity, shedding light on model capabilities and potential biases.", "section": "3.1 Mathematical Reasoning: GSM8K"}, {"figure_path": "5IFeCNA7zR/figures/figures_19_1.jpg", "caption": "Figure 4: Comparison of different models' performances with CoT as the number of attribute pairs increases on the BBQ dataset when applying DARG. All models show a decreasing trend in overall accuracy (\u2191) and an increasing trend in bias scores (\u2193) in both ambiguous and disambiguous contexts. Except for Mistral 7B, GPT-4 Turbo and Gemini-1.5-Pro demonstrate the highest overall avoidance (\u2193), indicating their over-sensitivity to contents with protected groups.", "description": "This figure shows the performance of several LLMs on the BBQ dataset under different complexity levels.  The x-axis represents the number of attribute pairs increased when applying the DARG method. The y-axis displays the overall accuracy, bias scores, and overall avoidance rates for both ambiguous and unambiguous contexts. The results indicate that most models show decreasing accuracy and increasing bias scores as complexity increases.  GPT-4 Turbo and Gemini-1.5-Pro exhibit a higher avoidance rate, suggesting potential oversensitivity to content involving protected groups.", "section": "3.2 Social Reasoning: BBQ"}, {"figure_path": "5IFeCNA7zR/figures/figures_22_1.jpg", "caption": "Figure 1: Overview of our proposed DARG framework. We first use an LLM to construct internal reasoning graphs with rule-based supervision for label consistency. After that, we augment benchmarks through fine-grained graph interpolation based on different complexity dimensions. Finally, we decode the graph back into the original data format and use a code-augmented LLM agent to verify the label's correctness.", "description": "This figure illustrates the DARG framework's workflow. It starts by constructing reasoning graphs from existing benchmark data using an LLM. These graphs are then perturbed to increase complexity (depth, width, numerical complexity) and transformed back into text format. A code-augmented LLM verifies the label correctness of the new data points, ensuring the accuracy of the newly generated, more complex data.", "section": "Method: DARG"}, {"figure_path": "5IFeCNA7zR/figures/figures_22_2.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure shows the performance change of 15 different LLMs on the GSM8K benchmark as the complexity of the reasoning graph increases.  The complexity is increased along three dimensions: numerical complexity, graph depth, and graph width.  Each bar in the chart represents the accuracy of a given LLM on the GSM8K dataset at a specific complexity level.  The figure demonstrates that, as complexity increases along any of these dimensions, almost all of the evaluated LLMs experience a performance decrease. This suggests that the current performance of LLMs on static benchmarks may not accurately reflect their capabilities in complex reasoning tasks.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_22_3.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure shows the performance change of fifteen large language models (LLMs) on the GSM8K benchmark dataset as the complexity of the reasoning graphs increases across three dimensions: numerical complexity, graph depth, and graph width.  Each bar represents the accuracy of a specific LLM on the GSM8K dataset for a given complexity level.  The x-axis represents the increase in complexity level for each dimension, while the y-axis represents the accuracy.  The figure helps to visualize how the performance of different LLMs varies with increasing complexity in different aspects of reasoning.", "section": "3.1 Mathematical Reasoning: GSM8K"}, {"figure_path": "5IFeCNA7zR/figures/figures_24_1.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure presents the performance changes of fifteen large language models (LLMs) on the GSM8K dataset as the complexity of the reasoning graph increases along three dimensions: numerical complexity, graph width, and graph depth.  Each dimension represents a different way of increasing the difficulty of the problem. The x-axis represents the level of complexity increase for each dimension, and the y-axis represents the accuracy of the LLMs.  The figure helps to illustrate how increases in complexity, across various dimensions, affect the performance of different LLMs, revealing varying degrees of robustness.", "section": "3.1 Mathematical Reasoning: GSM8K"}, {"figure_path": "5IFeCNA7zR/figures/figures_24_2.jpg", "caption": "Figure 2: Performance changes of 15 LLMs on GSM8K as the complexity level of the reasoning graph increases across three dimensions.", "description": "This figure shows how the performance of 15 different large language models (LLMs) changes on the GSM8K benchmark dataset as the complexity of the reasoning graph increases along three different dimensions: numerical complexity, graph depth, and graph width.  Each dimension's complexity is increased incrementally, showing the performance drop in each LLM as the task becomes more challenging. The figure provides insights into the robustness and limitations of various LLMs when faced with increasingly complex reasoning tasks.", "section": "3 Experiment"}, {"figure_path": "5IFeCNA7zR/figures/figures_25_1.jpg", "caption": "Figure 1: Overview of our proposed DARG framework. We first use an LLM to construct internal reasoning graphs with rule-based supervision for label consistency. After that, we augment benchmarks through fine-grained graph interpolation based on different complexity dimensions. Finally, we decode the graph back into the original data format and use a code-augmented LLM agent to verify the label's correctness.", "description": "This figure illustrates the DARG framework's three main stages.  First, it shows how an LLM constructs internal reasoning graphs for benchmark data points, using rule-based methods to ensure label consistency. Second, it details how these graphs are manipulated through fine-grained interpolation to introduce controlled complexity variations. Finally, it explains how the modified graphs are converted back into a usable format and then verified using a code-augmented LLM agent to guarantee label accuracy.", "section": "2 Method: DARG"}, {"figure_path": "5IFeCNA7zR/figures/figures_25_2.jpg", "caption": "Figure 1: Overview of our proposed DARG framework. We first use an LLM to construct internal reasoning graphs with rule-based supervision for label consistency. After that, we augment benchmarks through fine-grained graph interpolation based on different complexity dimensions. Finally, we decode the graph back into the original data format and use a code-augmented LLM agent to verify the label's correctness.", "description": "This figure illustrates the DARG framework's three main steps. First, it uses an LLM to generate internal reasoning graphs for the benchmark's data points.  Second, it perturbs these graphs to introduce controlled complexity variations. Finally, it uses a code-augmented LLM to validate the labels of the newly generated data points. This process dynamically extends the benchmark dataset with varied complexities while maintaining linguistic diversity.", "section": "2 Method: DARG"}, {"figure_path": "5IFeCNA7zR/figures/figures_26_1.jpg", "caption": "Figure 1: Overview of our proposed DARG framework. We first use an LLM to construct internal reasoning graphs with rule-based supervision for label consistency. After that, we augment benchmarks through fine-grained graph interpolation based on different complexity dimensions. Finally, we decode the graph back into the original data format and use a code-augmented LLM agent to verify the label's correctness.", "description": "This figure presents a schematic overview of the DARG framework, illustrating its three main stages: reasoning graph construction, graph interpolation, and new data point verification.  In the first stage, an LLM constructs an internal reasoning graph, which is checked for label consistency via rule-based verification. The second stage involves augmenting the benchmarks through graph interpolation, modifying the graph's structure to control complexity. The third stage decodes the modified graph back to the original format and uses a code-augmented LLM agent to verify its correctness. Each stage is visually represented, detailing the input, processing steps, and output.", "section": "2 Method: DARG"}]