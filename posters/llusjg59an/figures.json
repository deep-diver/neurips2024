[{"figure_path": "LLuSjg59an/figures/figures_3_1.jpg", "caption": "Figure 1: Graphical explanation of Masking the Attention over Instructions and Examples. The leftmost image has instructions and masks examples (Instr, Ex ), while the right image has both instructions and examples masked (Instr, ExMask). In the table, the overline corresponds to the yellow highlights. N and Y refer to absence and presence of either Instruction of Examples. Instr: Instructions and Ex: Examples.", "description": "This figure illustrates how the attention mechanism in transformer language models can be masked to study the effect of removing context (instructions or examples) from a certain layer in the network.  Three masking scenarios are shown: the first masks only examples, the second masks both instructions and examples, and the third masks only instructions. The yellow highlights in the diagrams correspond to the masked sections. The table summarizes the presence (Y) or absence (N) of instructions and examples in each masking scenario.", "section": "4.1 Analysis Methodology: Layer-from Context Masking"}, {"figure_path": "LLuSjg59an/figures/figures_4_1.jpg", "caption": "Figure 2: Layer-from context-masking experiments for GPTNeo2.7B, BLOOM3B, Llama7b, Llama7b-chat on en \u2194 fr. The graphs show translation performance when masking contexts from the jth layer onwards. Different lines indicate different treatments of the instruction, as described in Figure 1. The dashed black line is the performance when shown both examples and instructions without masking.", "description": "This figure presents the results of layer-wise context masking experiments conducted on four different large language models (GPTNeo2.7B, BLOOM3B, Llama7b, and Llama7b-chat) for machine translation between English and French.  The experiments mask out attention weights to the context (instructions or examples) from a specific layer onwards. Each graph shows the translation performance (BLEU score) as the masking layer changes. Different colored lines represent different conditions of including instructions and/or examples. The dashed black line serves as a baseline representing the performance without any masking.", "section": "4 Where does In-context MT happen?"}, {"figure_path": "LLuSjg59an/figures/figures_4_2.jpg", "caption": "Figure 3: Layer-from context-masking experiments for Starcoder2-3B, Starcoder2-7B, Llama7b, Llama7b-chat on a text to code generation task. The graphs show translation performance when masking contexts from the jth layer onwards. Different lines indicate different treatments of the instruction, as described in Figure 1. The dashed black line is the performance when shown both examples and instructions without masking.", "description": "This figure displays the results of layer-wise context masking experiments conducted on four different large language models (LLMs) for a code generation task.  The experiment masks out the attention weights to the context (instructions or examples) from a specific layer onwards to determine where in the model's layers the \"task recognition\" occurs. The graphs present the performance (PASS@1)  for each LLM when different parts of the context are masked, showing how the performance changes as more layers are masked. The different colored lines represent different combinations of instructions and examples in the context.  A black dashed line indicates the performance without masking.", "section": "4 Where does In-context MT happen?"}, {"figure_path": "LLuSjg59an/figures/figures_6_1.jpg", "caption": "Figure 2: Layer-from context-masking experiments for GPTNeo2.7B, BLOOM3B, Llama7b, Llama7b-chat on en \u2194 fr. The graphs show translation performance when masking contexts from the jth layer onwards. Different lines indicate different treatments of the instruction, as described in Figure 1. The dashed black line is the performance when shown both examples and instructions without masking.", "description": "This figure shows the results of layer-wise context masking experiments on four different language models (GPTNeo2.7B, BLOOM3B, Llama 7B, Llama 7B-chat) for English-to-French translation.  The x-axis represents the layer from which context masking begins (masking later layers). The y-axis represents BLEU score, a measure of translation quality. Different colored lines show the effect of masking with different combinations of instructions and examples (as defined in Figure 1 of the paper).  The black dashed line shows the baseline performance with no masking.", "section": "4 Where does In-context MT happen?"}, {"figure_path": "LLuSjg59an/figures/figures_7_1.jpg", "caption": "Figure 5: Layer-wise masking of self-attention heads for GPTNEO2.7B, BLOOM3B, LLAMA and LLAMA-CHAT on en \u2192 fr. The orange and blue dotted lines refer to the baselines (without masking) of 0 and 5 prompts with instructions. True/False refers to whether there are instructions provided (True) vs not provided (False). We observe critical layers near the middle and redundant layers towards the end of the model.", "description": "This figure displays the results of experiments where self-attention heads were masked layer by layer in four different language models (GPTNeo2.7B, BLOOM3B, LLAMA7B, and LLAMA7B-CHAT) during English-to-French translation.  The models were tested with and without instructions and with 0 or 5 examples.  The graph shows the BLEU score (translation quality) as the number of masked layers increases. The orange and blue lines represent experiments with and without instructions, respectively.  The key observation is the identification of \"critical layers\" (near the middle) where masking leads to a substantial drop in performance and \"redundant layers\" (towards the end) where masking has little impact on performance.  This supports the paper's claim that the task recognition happens in specific model layers.", "section": "6 Characterising Redundancy in Layers"}, {"figure_path": "LLuSjg59an/figures/figures_8_1.jpg", "caption": "Figure 6: Layer-from context-masking experiments for GPTNeo and BLOOM on en \u2192 fr investigating number of examples in the Ex ExMask mask setting. The dashed black line refers to no instructions and no examples.", "description": "The figure shows the results of layer-from context-masking experiments performed on GPTNeo and BLOOM models for English-to-French translation.  The experiments varied the number of examples provided in the context (1, 3, 7, and 9).  The y-axis represents the BLEU score (a metric for evaluating machine translation quality), and the x-axis represents the layer number in the model from which context masking was applied. The dashed black line indicates the baseline performance with no context masking and no instructions. The shaded regions represent the standard deviations across multiple runs. The graph illustrates how model performance changes depending on the layer at which context masking starts and the number of examples provided, providing insights into where the model begins to rely less on the examples for successful translation.", "section": "7 Further Analysis"}, {"figure_path": "LLuSjg59an/figures/figures_8_2.jpg", "caption": "Figure 7: Performance of no-instructions trained Lora layers for GPTNeo and BLOOM on en\u2194fr. The dashed black line refers to training of all layers together, while the orange (test without instructions) and blue (test with instructions) dashed lines refers to no training. The layers which are most amenable to lightweight fine-tuning occur in the earlier layers before the \"task recognition\" point.", "description": "This figure shows the performance of lightweight fine-tuning (using LoRA) on different layers of GPTNeo and BLOOM models for the English-French translation task. The dashed black line represents the performance when all layers are trained together. The orange and blue lines show performance with and without training instructions, respectively, when only some layers are fine-tuned using LoRA. The results indicate that the earlier layers (before the task recognition point) are more amenable to lightweight fine-tuning.", "section": "7.2 The Adaptability of Task Layers"}, {"figure_path": "LLuSjg59an/figures/figures_14_1.jpg", "caption": "Figure 8: Context-masking and Layer-masking results on the English \u2192 Portugese translation task. Critically, we see nearly identical trends to what we see in Figure 3 and Figure 5 on the English to French translation task, suggesting our results generalize across language pairs.", "description": "This figure shows the results of context-masking and layer-masking experiments performed on the English to Portuguese translation task.  The graphs illustrate how the translation performance changes when masking the attention weights to the context (instructions and examples) from a certain layer onward.  The results in this figure mirror those found in Figures 3 and 5, suggesting that the observed trends generalize across different language pairs.  This reinforces the paper's findings about where task recognition occurs within the language model.", "section": "4 Where does In-context MT happen?"}, {"figure_path": "LLuSjg59an/figures/figures_16_1.jpg", "caption": "Figure 9: Visualisation of attention head masks for GPTNeo and BLOOM, learned with L0 (\u03bb = 0.01) regularisation under a 0-prompt train scheme in en \u2192 fr. A value of 0 (in black) indicates that the attention head is effectively masked out by the trained attention gate. Around 10% of attention heads are masked out i.e., redundant, with a majority of them occuring at the later layers for GPTNeo and distributed across layers for BLOOM. fr \u2192 en is availble in Section A.5.1", "description": "This figure visualizes the attention head masks learned for GPTNeo and BLOOM using L0 regularization with a 0-prompt training scheme for English-to-French translation.  Black squares represent masked-out (redundant) attention heads.  Approximately 10% of attention heads were masked, showing redundancy primarily in later layers for GPTNeo, and more evenly distributed across layers for BLOOM. Results for French-to-English translation are available in Appendix section A.5.1.", "section": "A.7 Studying Redundancy via Compression"}]