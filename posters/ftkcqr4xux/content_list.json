[{"type": "text", "text": "Label Noise: Ignorance Is Bliss ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yilun Zhu   \nEECS   \nUniversity of Michigan   \nallanzhu@umich.edu   \nJianxin Zhang   \nEECS   \nUniversity of Michigan   \njianxinz@umich.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Aditya Gangrade ECE Boston University gangrade@bu.edu ", "page_idx": 0}, {"type": "text", "text": "Clayton Scott   \nEECS, Statistics   \nUniversity of Michigan   \nclayscot@umich.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We establish a new theoretical framework for learning under multi-class, instancedependent label noise. This framework casts learning with label noise as a form of domain adaptation, in particular, domain adaptation under posterior drift. We introduce the concept of relative signal strength (RSS), a pointwise measure that quantifies the transferability from noisy to clean posterior. Using RSS, we establish nearly matching upper and lower bounds on the excess risk. Our theoretical findings support the simple Noise Ignorant Empirical Risk Minimization (NI-ERM) principle, which minimizes empirical risk while ignoring label noise. Finally, we translate this theoretical insight into practice: by using NI-ERM to fit a linear classifier on top of a self-supervised feature extractor, we achieve state-of-the-art performance on the CIFAR-N data challenge. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The problem of classification with label noise can be stated in terms of random variables $X,Y$ , and $\\widetilde{Y}$ , where $X$ is the feature vector, $Y\\in\\{1,\\ldots,K\\}$ is the true label associated to $X$ , and $\\widetilde{Y}\\in\\{1,\\ldots,K\\}$ is a noisy version of $Y$ . The learner has access to i.i.d. realizations of $(X,{\\widetilde{Y}})$ , and t h e objective is to learn a classifier that optimizes the risk associated with $(X,Y)$ . ", "page_idx": 0}, {"type": "text", "text": "In recent years, there has been a surge of interest in the challenging setting of instance (i.e., feature) dependent label noise, in whichY can depend on both $Y$ and $X$ . While several algorithms have been developed, there remains relativ el y little theory regarding algorithm performance and the fundamental limits of this learning paradigm. ", "page_idx": 0}, {"type": "text", "text": "This work develops a theoretical framework for learning under multi-class, instance-dependent label noise. Our framework hinges on the concept of relative signal strength, which is a point-wise measure of \u201cnoisiness\u201d in a label noise problem. Using relative signal strength to charachterize the difficulty of a label noise problem, we establish nearly matching upper and lower bounds for excess risk. We further identify distributional assumptions that ensure that the lower and upper bounds tend to zero as the sample size $n$ grows, implying that consistent learning is possible. ", "page_idx": 0}, {"type": "text", "text": "Surprisingly, Noise Ignorant Empirical Risk Minimization (NI-ERM) principle, which conducts empirical risk minimization as if no label noise exists, is (nearly) minimax optimal. To translate this insight into practice, we use NI-ERM to fit a linear classifier on top of a self-supervised feature extractor, achieving state-of-the-art performance on the CIFAR-N data challenge. ", "page_idx": 0}, {"type": "text", "text": "2 Literature review ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Theory and algorithms for classification with label noise are often based on different probabilistic models. Such models may be categorized according on how $\\widetilde{Y}$ depends on $Y$ and $X$ . The simplest model is symmetric noise, where the distribution ofY is indep e ndent of $Y$ and $X$ [Angluin and Laird, 1988]. In this case, the probability thatY = k is  t he same for all $k\\neq Y$ , regardless of $Y$ and $X$ . In this setting, it is easy to show that mi n imizing the noisy excess risk (associated to the 0/1 loss) implies minimizing the clean excess risk, a property known as immunity. When immunity holds, there is no need to modify the learning algorithm on account of noisy labels. In other words, the learner may be ignorant of the label noise and still learn consistently. ", "page_idx": 1}, {"type": "text", "text": "A more general model is classification with label dependent noise, in which the distribution of $\\widetilde{Y}$ depends on $Y$ , but not $X$ . Many practical algorithms have been developed over the years, based  o n principles including data re-weighting [Liu and Tao, 2015], robust training [Han et al., 2018, Liu et al., 2020, Foret et al., 2021, Liu et al., 2022] and data cleaning [Brodley and Friedl, 1999, Northcutt et al., 2021]. Consistent learning algorithms still exist, such as those based on loss correction [Natarajan et al., 2013, Patrini et al., 2017, Van Rooyen and Williamson, 2018, Liu and Guo, 2020, Zhang et al., 2022]. These approaches assume knowledge of the noise transition probabilities, which can be estimated under some identifiability assumptions [Scott et al., 2013, Zhang et al., 2021b]. ", "page_idx": 1}, {"type": "text", "text": "In the most general setting, that of instance dependent label noise, the distribution ofY depends on both $Y$ and $X$ . While algorithms are emerging [Cheng et al., 2021, Zhu et al., 202 1 , Wang et al., 2022, Yang et al., 2023], theory has primarily focused on the binary setting. Scott [2019] establishes immunity for a Neyman-Pearson-like performance criterion under a posterior drift model, discussed in more detail below. Cannings et al. [2020] establish an upper bound for excess risk under the strong assumption that the optimal classifiers for the clean and noisy distributions are the same. ", "page_idx": 1}, {"type": "text", "text": "Closest to our work, Im and Grigas [2023] derive excess risk upper and lower bounds, and reach a similar conclusion, that noise-ignorant ERM attains the lower bound up to a constant factor. Our results, based on the new concept of relative signal strength, provide a more refined analysis. ", "page_idx": 1}, {"type": "text", "text": "Additional connections between our contributions and prior work are made throughout the paper. ", "page_idx": 1}, {"type": "text", "text": "3 Problem statement ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Notation. $\\mathcal{X}$ denotes the feature space and $\\mathcal{V}=\\{1,2,\\ldots,K\\}$ denotes the label space, with $K\\in\\mathbb N$ The $K$ -simplex is $\\Delta^{K}{\\,:=\\,}\\{p\\in\\bar{\\mathbb{R}}^{K}:\\forall i,p_{i}\\geq0,\\sum p_{i}=1\\}$ . A $K\\times K$ matrix is row stochastic if all of its rows are in $\\Delta^{K}$ . Denote the $i$ -th element  o f a vector $\\pmb{v}$ as $[{\\pmb v}]_{i}$ , and the $(i,j)$ -th element of a matrix $_M$ as $[M]_{i,j}$ . ", "page_idx": 1}, {"type": "text", "text": "In conventional multiclass classification, we observe training data $(X_{1},Y_{1}),\\ldots,(X_{n},Y_{n})$ drawn i.i.d. from a joint distribution $P_{X Y}$ . The marginal distribution of $X$ is denoted by $P_{X}$ , and the class posterior probabilities $P_{Y\\mid X=x}$ are captured by a $K$ -simplex-valued vector $\\pmb{\\eta}:\\mathcal{X}\\rightarrow\\Delta^{K}$ , where the $j$ -th component of the vector is $[\\pmb{\\eta}(x)]_{j}=\\mathbb{P}\\left(Y=j\\mid X=x\\right)$ . A classifier $f:\\mathcal X\\to\\mathcal Y$ maps an instance $x$ to a class $f(x)\\in\\mathcal{Y}$ . Denote the risk of a classifier $f$ with respect to distribution $P_{X Y}$ as $R(f)=\\mathbb{E}_{(X,Y)\\sim P_{X Y}}$ 1{f(X)\u0338=Y } . The Bayes optimal classifier for $P_{X Y}$ is $f^{*}(x)\\in\\arg\\operatorname*{max}{\\pmb{\\eta}}(x)$ The Bayes risk, which is the minimum achievable risk, is denoted as $R^{*}=R(f^{*})=\\operatorname*{inf}_{f}R(f)$ . ", "page_idx": 1}, {"type": "text", "text": "We consider the setting where, instead of the true class label $Y$ , a noisy labelY is observed. The training data $(X_{1},\\overleftarrow{\\tilde{Y}_{1}}),\\ldots,(X_{n},\\overleftarrow{Y}_{n})$ can be viewed as an i.i.d. sample drawn  f rom a \u201cnoisy\u201d distribution $P_{X\\tilde{Y}}$ . We d e fine $P_{\\widetilde{Y}|X=x},\\widetilde{\\eta},\\widetilde{R}$ and $\\tilde{f}^{*}$ analogously to the \u201cclean\u201d distribution $P_{X Y}$ . ", "page_idx": 1}, {"type": "text", "text": "The goal of learning from label noise is to find a classifier that is able to minimize the \u201cclean test error,\u201d that is, the risk $R$ defined w.r.t. $P_{X Y}$ , even though the learner has access to only corrupted training data $(X_{i},{\\widetilde{Y}}_{i})\\stackrel{\\mathrm{i.i.d.}}{\\sim}P_{X{\\widetilde{Y}}}$ . ", "page_idx": 1}, {"type": "text", "text": "Noise transition perspective. Traditionally, label noise is modeled through the joint distribution of $(X,Y,{\\widetilde{Y}})$ . This joint distribution is governed by $P_{X}$ , the clean class posterior $P_{Y\\mid X}$ , and a ", "page_idx": 1}, {"type": "text", "text": "matrix-valued function ", "page_idx": 2}, {"type": "equation", "text": "$$\nE:\\mathcal{X}\\to\\{M\\in\\mathbb{R}^{K\\times K}:M\\;\\mathrm{is~row~stochastic}\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "known as the noise transition matrix. The $(i,j)$ -th entry of the matrix is defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n[E(x)]_{i,j}=\\mathbb{P}\\left(\\widetilde{Y}=j\\mid Y=i,X=x\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This implies that the noisy and clean class posteriors are related by $\\widetilde{\\pmb{\\eta}}(x)=\\pmb{E}(x)^{\\top}\\pmb{\\eta}(x)$ , where \u22a4 denotes the matrix transpose. ", "page_idx": 2}, {"type": "text", "text": "Domain adaptation perspective. Alternatively, label noise learning can be framed as a domain adaptation problem. In this view, $P_{X\\tilde{Y}}$ represents the source domain, and $P_{X Y}$ represents the target domain. The relationship between the   two domains is characterized by \u201cposterior drift,\u201d meaning that while the source and target share the same $X$ -marginal, the class posteriors (i.e., the distribution of labels given $X$ ) may differ [Scott, 2019, Cai and Wei, 2021, Maity et al., 2023]. Thus, a label noise problem can also be described by a triple $(P_{X},\\eta,\\tilde{\\eta})$ . ", "page_idx": 2}, {"type": "text", "text": "The two perspectives are equivalent, as discussed  i n Appendix A.1. In this work, we emphasize the domain adaptation perspective for Sections 4 and 5, and the noise transition perspective for Section 6. ", "page_idx": 2}, {"type": "text", "text": "4 Relative signal strength ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To study label noise, we introduce the concept of relative signal strength (RSS). This is a pointwise measure of how much \u201csignal\u201d (certainty about the label) is contained in the noisy distribution relative to the clean distribution. Previous work [Cannings et al., 2020, Cai and Wei, 2021] has examined a related concept within the context of binary classification, under the restriction that clean and noisy Bayes classifiers are identical. Our definition incorporates multi-class classification and relaxes the requirement that the clean and noisy Bayes classifiers agree. ", "page_idx": 2}, {"type": "text", "text": "Definition 1 (Relative Signal Strength) For any class probability vectors $\\begin{array}{r}{\\eta,\\widetilde{\\eta},}\\end{array}$ , define the relative signal strength (RSS) at $x\\in\\mathscr{X}$ as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{min}_{j\\in\\mathcal{Y}}\\ \\frac{\\operatorname*{max}_{i}[\\widetilde{\\eta}(x)]_{i}-[\\widetilde{\\eta}(x)]_{j}}{\\operatorname*{max}_{i}[\\eta(x)]_{i}-[\\eta(x)]_{j}},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $0/0:=+\\infty$ . Furthermore, for $\\kappa\\in[0,\\infty)$ , denote the set of points whose RSS exceeds \u03ba as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{A}_{\\kappa}(\\eta,\\widetilde{\\eta})=\\left\\{x\\in\\mathcal{X}:\\mathcal{M}(x;\\eta,\\widetilde{\\eta})>\\kappa\\right\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "$\\mathcal{M}(x;\\eta,\\tilde{\\eta})$ is a point-wise measure of how much \u201csignal\u201d the noisy posterior contains about the clean pos t erior. To gain some intuition, first notice that if the noisy Bayes classifier predicts a different class than the clean Bayes classifier, the RSS is 0 by taking $j=\\arg\\operatorname*{max}\\widetilde{\\eta}$ (assuming for simplicity that the arg max is a singleton set). Now suppose the clean and noisy Ba y es classifiers $d o$ make the same prediction at $x$ , say $i^{*}$ , and consider a fixed $j$ . If ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\frac{[\\widetilde{\\pmb{\\eta}}(\\boldsymbol{x})]_{i^{*}}-[\\widetilde{\\pmb{\\eta}}(\\boldsymbol{x})]_{j}}{[\\pmb{\\eta}(\\boldsymbol{x})]_{i^{*}}-[\\pmb{\\eta}(\\boldsymbol{x})]_{j}}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "is small, it means that the clean Bayes classifier is relatively certain that $j$ is not the correct clean label, while the noisy Bayes classifier is less certain that $j$ is not the correct noisy label. Taking the minimum over $j$ gives the relative signal strength at $x$ . As we formalize in the next section, a large RSS at $x$ ensures that a small (pointwise) noisy excess risk at $x$ implies a small (pointwise) clean excess risk. To gain more intuition, consider the following examples. ", "page_idx": 2}, {"type": "text", "text": "Example 1 When $\\pmb{\\eta}(x)=[0\\,\\,1\\,\\,\\,0]^{\\top}$ and $\\begin{array}{r}{\\widetilde{\\pmb{\\eta}}(x)=[0.3\\;\\;0.6\\;\\;0.1]^{\\top},}\\end{array}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{min}_{j\\in\\mathcal{Y}}\\ \\frac{\\operatorname*{max}_{i}_{}[\\widetilde{\\eta}(x)]_{i}-[\\widetilde{\\eta}(x)]_{j}}{\\operatorname*{max}_{i}_{}[\\eta(x)]_{i}-[\\eta(x)]_{j}}=\\frac{[\\widetilde{\\eta}(x)]_{2}-[\\widetilde{\\eta}(x)]_{1}}{[\\eta(x)]_{2}-[\\eta(x)]_{1}}=\\frac{0.6-0.3}{1-0}=0.3.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here, first of all, arg max $\\pmb{\\eta}=\\arg\\operatorname*{max}\\widetilde{\\pmb{\\eta}}=2,$ , i.e., the clean and noisy Bayes classifier give the same prediction. What\u2019s more, $\\mathcal{M}(x;\\eta,\\tilde{\\eta})<1$ because the clean Bayes classifier is absolutely certain about its prediction, while the noisy   Bayes classifier is much less certain. ", "page_idx": 2}, {"type": "text", "text": "Example 2 When $\\pmb{\\eta}(x)=[0\\,\\,1\\,\\,\\,0]^{\\top}$ and $\\widetilde{\\pmb{\\eta}}(x)=[0\\,\\mathrm{~0~}\\,1]^{\\intercal}$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{min}_{j\\in\\mathcal{Y}}\\ \\:\\frac{\\operatorname*{max}_{i}[\\widetilde{\\eta}(x)]_{i}-[\\widetilde{\\eta}(x)]_{j}}{\\operatorname*{max}_{i}[\\eta(x)]_{i}-[\\eta(x)]_{j}}=\\frac{[\\widetilde{\\eta}(x)]_{3}-[\\widetilde{\\eta}(x)]_{3}}{[\\eta(x)]_{2}-[\\eta(x)]_{3}}=\\frac{1-1}{1-0}=0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The zero signal strength results from $\\widetilde{\\pmb{\\eta}}$ and $\\eta$ leading to different predictions about arg max. ", "page_idx": 3}, {"type": "text", "text": "Example 3 (Comparison to $\\mathbf{KL}$ divergence) When $\\pmb{\\eta}(x)\\;=\\;[0.05\\:\\:\\:0.7\\:\\:\\:0.25]^{\\top}$ , and $\\widetilde{\\pmb{\\eta}}^{(1)}(x)\\,=$ $[0.25\\;\\;0.7\\;\\;0.05]^{\\top}$ , $\\widetilde{\\pmb{\\eta}}^{(2)}(x)=[0.1\\;\\;0.6\\;\\;0.3]^{\\top}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{1}{\\mathcal{D}_{\\mathrm{KL}}\\left(\\eta\\left\\|\\tilde{\\eta}^{(1)}\\right)}<\\frac{1}{\\mathcal{D}_{\\mathrm{KL}}\\left(\\eta\\left\\|\\tilde{\\eta}^{(2)}\\right)}\\quad w h i l e\\quad\\mathcal{M}\\left(x;\\eta,\\widetilde{\\eta}^{(1)}\\right)>\\mathcal{M}\\left(x;\\eta,\\widetilde{\\eta}^{(2)}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, $\\widetilde{\\pmb{\\eta}}^{(2)}$ is \u201ccloser\u201d to \u03b7 in terms of $K L$ divergence, but $\\widetilde{\\pmb{\\eta}}^{(1)}$ provides more information in terms of predi ct ing the arg max of $\\eta$ . There is no conflict: $K L$ di v ergence considers the similarity between two (whole) distributions, while the task of classification only focuses on predicting the arg max. ", "page_idx": 3}, {"type": "text", "text": "This also illustrates why our notion of RSS is better suited for the label noise problem than other general-purpose distance measures between distributions. ", "page_idx": 3}, {"type": "text", "text": "A desirable learning scenario would be if $A_{\\kappa}(\\eta,\\widetilde{\\eta})=\\mathcal{X}$ for some large $\\kappa$ , indicating that the signal strength is big across the entire space. Unfortuna t ely, this ideal situation is generally not achievable. To gain some insight, consider the following result, proved in Appendix A.2.1. ", "page_idx": 3}, {"type": "text", "text": "Proposition 1 $\\mathcal{A}_{0}(\\eta,\\widetilde{\\eta})=\\big\\{x\\in\\mathcal{X}:\\arg\\operatorname*{max}\\widetilde{\\eta}(x)\\subseteq\\arg\\operatorname*{max}\\eta(x)\\big\\}.$ ", "page_idx": 3}, {"type": "text", "text": "If we assume that both arg max sets are singletons, this result indicates that $\\mathbf{\\mathcal{A}}_{0}$ , the region with positive RSS, is the region where the true and noisy Bayes classifiers agree. Accordingly, $\\mathcal{X}\\backslash\\mathcal{A}_{0}$ , the zero signal region, is the region where the clean and noisy Bayes decision rules differ. The \u201cregion of strong signal,\u201d $\\mathcal{A}_{\\kappa}$ , is a subset of $\\mathcal{A}_{\\mathrm{0}}$ . Since the clean and noisy Bayes classifiers will typically disagree for at least some $x$ , $A_{0}\\neq\\chi$ in general. We note that the strong assumption that $A_{0}=\\mathcal{X}$ has been made in prior studies [Cannings et al., 2020, Cai and Wei, 2021]. Our notion of RSS relaxes this assumption and provides a unified view. ", "page_idx": 3}, {"type": "text", "text": "4.1 RSS in binary classification ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We can express relative signal strength more explicitly in the binary setup. Let $\\eta(x):=[\\eta(x)]_{1}=$ $\\mathbb{P}\\left(Y=1\\mid X=x\\right)$ and $\\widetilde{\\eta}(x):=[\\widetilde{\\pmb{\\eta}}(x)]_{1}=\\mathbb{P}\\big(\\widetilde{Y}=1\\mid X=x\\big)$ . In standard binary classification, the margin [Tsybakov, 20  04, Massar t and N\u00e9d\u00e9lec , 2006], defined as $\\left|\\eta(x)-{\\textstyle{\\frac{1}{2}}}\\right|$ , serves as a pointwise measure of signal strength. Our notion of relative signal strength  (RSS) ca n be interpreted as an extension of this concept in the context of label noise learning. ", "page_idx": 3}, {"type": "text", "text": "Proposition 2 In the binary setting, for $\\kappa\\geq0$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{max}\\left\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},\\,0\\right\\},\\qquad a n d\\qquad\\mathcal{A}_{\\kappa}(\\eta,\\widetilde{\\eta})=\\left\\{x\\in\\mathcal{X}:\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}}>\\kappa\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In other words, RSS can be viewed as a \u201crelative\u201d margin. ", "page_idx": 3}, {"type": "text", "text": "Example 4 Illustration of relative signal strength in a binary classification setup (Figure 1). ", "page_idx": 3}, {"type": "text", "text": "4.2 Posterior Drift Model Class. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Now putting definitions together, we consider the posterior drift model $\\Pi$ defined over the triple $(P_{X},\\eta,\\tilde{\\eta})$ . Let $\\epsilon\\in[0,1],\\kappa\\in[0,+\\infty)$ , and define ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Pi(\\epsilon,\\kappa):=\\Big\\{\\left(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}}\\right):P_{X}\\Big(\\pmb{\\mathcal{A}}_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\pmb{\\eta}}\\right)\\Big)\\geq1-\\epsilon\\Big\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This is a set of triples (label noise problems) such that $\\mathcal{A}_{\\kappa}$ , the region with RSS at least $\\kappa$ , covers at least $1-\\epsilon$ of the probability mass. In the next section, we will demonstrate that the performance within $\\mathcal{A}_{\\kappa}$ can be guaranteed, whereas learning outside the region $\\mathcal{A}_{\\kappa}$ is provably challenging. ", "page_idx": 3}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/7f4ac752abf1e9bd19d4b3411ba8ed3d04b310dcfab62267a44c8c438c29413f.jpg", "img_caption": ["Figure 1: Illustration of relative signal strength for binary classification. Left: clean and noisy posteriors $[\\pmb{\\eta}(x)]_{1}=\\mathbb{P}\\left(Y=1|X=x\\right)$ and $[\\widetilde{\\pmb{\\eta}}(x)]_{1}=\\mathbb{P}\\big(\\widetilde{\\boldsymbol{Y}}=1|\\boldsymbol{X}=\\boldsymbol{x}\\big)$ . Right: relative signal strength corresponding to these posteriors. The  gray region, $x\\in(0,5)$ , is where the true and noisy Bayes classifiers differ, and is also the zero signal region $\\mathcal{X}\\setminus\\mathcal{A}_{0}$ . The red region is $\\mathcal{A}_{0.4}$ , where the RSS is $>0.4$ . Note that as $x\\uparrow0,\\mathcal{M}(x;\\eta,\\widetilde{\\eta})\\uparrow\\infty$ , which occurs since $[\\eta(x)]_{1}\\uparrow1/2$ , while $[\\widetilde{\\eta}]_{1}$ is far from $1/2$ . For $x=0^{+}$ , the predicted la b els under $\\eta$ and $\\widetilde{\\pmb{\\eta}}$ disagree, and the RSS crashes to  0. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "5 Upper and lower bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we establish both upper and lower bounds for excess risk under multi-class instancedependent label noise. ", "page_idx": 4}, {"type": "text", "text": "5.1 Minimax lower bound ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our first theorem reveals a fundamental limit: no classifier trained using noisy data can surpass the the following notation and terminology. Denote the noisy training data by $Z^{n}=\\left\\{(X_{i},\\widetilde{Y}_{i})\\right\\}_{i=1}^{n}\\overset{i.i.d}{\\sim}$ . $P_{X\\tilde{Y}}$ . A learning rule $\\hat{f}$ is an algorithm that takes $Z^{n}$ and outputs a classifier. The ri s k $R(\\hat{f})$ of a lear ning rule is a random variable, where the randomness is due to the draw $Z^{n}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 (Minimax Lower Bound) Let $\\epsilon\\in[0,1],\\kappa>0$ . Then ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{f}}\\operatorname*{sup}_{(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\frac{K-1}{K}\\epsilon+\\Omega\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{1}{n}}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the inf is over all learning rules. ", "page_idx": 4}, {"type": "text", "text": "The proof in Appendix A.2.3 offers insights into how label noise impacts the learning process: On the low RSS region $(\\mathcal{X}\\backslash A_{\\kappa})$ , learning is difficult if not impossible, and the learner incurs an irreducible error of $(1-1/K)\\epsilon$ . On the high RSS region $(\\mathcal{A}_{\\kappa})$ , the standard nonparametric rate [Devroye et al., 1996] is scaled by $1/\\kappa$ . These aspects determine fundamental limits that no classifier trained only on noisy data can overcome without additional assumptions. ", "page_idx": 4}, {"type": "text", "text": "5.2 Upper bound ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "This subsection establishes an upper bound for Noise Ignorant Empirical Risk Minimizer (NI-ERM), the empirical risk minimizer trained on noisy data. This result implies that NI-ERM is (nearly) minimax optimal, a potentially surprising result given that NI-ERM is arguably the simplest approach one might consider. We begin by presenting a general result on the excess risk of any classifier, which is proved in Appendix A.2.4. ", "page_idx": 4}, {"type": "text", "text": "Lemma 1 (Oracle Inequality) For any label noise problem $(P_{X},\\eta,\\tilde{\\eta})$ and any classifier $f$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\nR(f)-R(f^{*})\\leq\\operatorname*{inf}_{\\kappa>0}\\left\\{P_{X}\\Big(X\\setminus A_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\eta}\\right)\\Big)+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\widetilde{f}^{*}\\right)\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For $(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)$ , the first term is bounded by $\\epsilon$ . When $f$ is selected by ERM over the noisy training dat a,  conventional learning theory implies a bound on the second term. This leads to the following upper bound for NI-ERM, whose proof is in Appendix A.2.5. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2 (Excess Risk Upper Bound of NI-ERM) Let $\\epsilon\\;\\;\\in\\;\\;[0,1],\\kappa\\;\\;>\\;\\;0.$ . Consider any $(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)$ , assume function class $\\mathcal{F}$ has Natarajan dimension $V$ , and the noisy Bayes classifie r $\\tilde{f}^{*}$ belongs to $\\mathcal{F}$ . Let ${\\hat{f}}\\ \\in\\ {\\mathcal{F}}$ be the ERM trained on $Z^{n}~=~\\{(X_{i},{\\widetilde{Y}}_{i})\\}_{i=1}^{n},$ , i.e., $\\begin{array}{r}{\\hat{f}=\\underset{f\\in\\mathcal{F}}{\\arg\\operatorname*{min}}\\ \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{1}_{\\left\\{f(X_{i})\\neq\\widetilde{Y}_{i}\\right\\}}}\\end{array}$ . Then ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\leq\\epsilon+\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{V}{n}}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\tilde{\\mathcal{O}}$ denotes big- $\\scriptscriptstyle\\mathcal{O}$ notation ignoring logarithmic factors. The Natarajan dimension is a multiclass analogue of the VC dimension. The upper bound in Theorem 2 aligns with the minimax lower bound (Theorem 1) in both terms. For the irreducible error $\\epsilon$ , there is a small gap of $1/K$ . This gap arises because, in the lower bound construction, the low signal region ${\\mathcal{X}}\\setminus{\\mathcal{A}}_{\\kappa}$ is known to the learner, whereas knowledge of ${\\mathcal{X}}\\setminus A_{\\kappa}$ is not provided to NI-ERM. If $\\mathcal{A}_{\\kappa}$ were known to the learner (an unrealistic assumption), then a mixed strategy that preforms NI-ERM on $\\mathcal{A}_{\\kappa}$ and randomly guesses on $\\mathcal{X}\\setminus\\mathcal{A}_{\\kappa}$ would have an upper bound with first term of $(1-1/K)\\epsilon$ , exactly matching the lower bound. Regarding the second term, there is a universal constant and a logarithmic factor between the lower and upper bounds, which is a standard outcome in learning theory. ", "page_idx": 5}, {"type": "text", "text": "This result is surprising as it indicates that the simplest possible approach, which ignores the presence of noise, is nearly optimal. No learning rule could perform significantly better in this minimax sense. ", "page_idx": 5}, {"type": "text", "text": "5.3 A smooth margin-condition on the relative signal strength ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The previous sections have analyzed learning with label noise over the class $\\Pi(\\epsilon,\\kappa)=\\{(P_{X},\\eta,\\tilde{\\eta}):$ $P_{X}(\\bar{\\mathcal{A}}_{\\kappa})\\,\\geq\\,1\\,-\\,\\epsilon\\}$ . Now, the set ${\\mathcal{X}}\\setminus A_{\\kappa}$ equals $(\\mathcal{X}\\setminus\\mathcal{A}_{0})\\cup(\\mathcal{A}_{0}\\setminus\\mathcal{A}_{\\kappa})$ . The first part of this decomposition is the region where the Bayes classifiers under the noisy and clean distributions differ, while the second is a region where these match, but the RSS is small. Naturally, while $P_{X}(\\mathcal{X}\\backslash\\mathcal{A}_{0})$ must be incurred as an irreducible error, one may question why the class $\\Pi$ also limits the mass of $\\mathcal{A}_{0}\\setminus\\mathcal{A}_{\\kappa}$ . After all, with enough data, the optimal prediction in this region can be learned. ", "page_idx": 5}, {"type": "text", "text": "This issue would be resolved if there existed a $\\kappa_{0}~>~0$ such that $P_{X}(A_{0})\\,=\\,P_{X}(A_{\\kappa_{0}})$ , i.e., if $P_{X}(\\mathcal{A}_{0}\\backslash\\mathcal{A}_{\\kappa_{0}})=0$ . In fact, our lower bound from Theorem 1 uses precisely such a construction. An interesting point of comparison to this condition lies in Massart\u2019s hard-margin condition from standard supervised learning theory, which, for binary problems, demands that $\\bar{P}_{X}(|[\\pmb{\\eta}(x)]_{1}-[\\pmb{\\eta}(x)]_{2}|<$ $h)=0$ for some $h>0$ , under which one obtains minimax excess risk bounds of $O(V/n h)$ [Massart and N\u00e9d\u00e9lec, 2006]. With this lens, we can view the condition $P_{X}(\\mathcal{A}_{0}\\backslash\\mathcal{A}_{\\kappa_{0}})=\\overset{\\cdot}{0}$ as a type of hard-margin condition on the relative signal strength $\\mathcal{M}$ . This naturally motivates a smoothened version of this condition, inspired by Tsybakov\u2019s soft-margin condition [Tsybakov, 2004]. ", "page_idx": 5}, {"type": "text", "text": "Definition 2 A triple $(P_{X},\\eta,\\widetilde{\\eta})$ satisfies an $(\\epsilon,\\alpha,C_{\\alpha})$ -smooth relative signal margin condition with $\\epsilon\\in[0,1],\\alpha>0,C_{\\alpha}>0\\,i f$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\forall\\kappa>0,\\;P_{X}(\\mathcal{M}(x;\\eta,\\tilde{\\eta})\\leq\\kappa)\\leq C_{\\alpha}\\kappa^{\\alpha}+\\epsilon.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Further, we define $\\Pi^{\\prime}(\\epsilon,\\alpha,C_{\\alpha})$ as the set of triples $(P_{X},\\eta,\\widetilde{\\eta})$ that satisfy an $(\\epsilon,\\alpha,C_{\\alpha})$ -smooth relative signal margin condition. ", "page_idx": 5}, {"type": "text", "text": "We show in Appendix A.2.7 that the techniques of Section 5.2 yield the following result for $\\Pi^{\\prime}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3 Let $\\epsilon\\;\\in\\;[0,1],\\alpha\\;>\\;0,C_{\\alpha}\\;>\\;0.$ . Consider any $(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})\\;\\in\\;\\Pi^{\\prime}(\\epsilon,\\alpha,C_{\\alpha})$ , assume function class $\\mathcal{F}$ has Natarajan dimension $V$ , and the noisy Bayes cla s sifier $\\tilde{f}^{*}$ belongs to $\\mathcal{F}$ . Let ${\\hat{f}}\\in{\\mathcal{F}}$ be the ERM trained on $Z^{n}=\\left\\{(X_{i},{\\widetilde{Y}}_{i})\\right\\}_{i=1}^{n}$ . Then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z^{n}}\\left[R\\left(\\widehat{f}\\right)-R\\left(f^{*}\\right)\\right]\\leq\\epsilon+\\operatorname*{inf}_{\\kappa>0}\\left\\{C_{\\alpha}\\kappa^{\\alpha}+\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{V}{n}}\\right)\\right\\}=\\epsilon+\\tilde{\\mathcal{O}}\\left(n^{-\\alpha/(2+2\\alpha)}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Compared to Theorem 2, we see that the rate of the second term is slightly slower, which is consistent with standard learning theory where Massart\u2019s hard margin assumption leads to faster rates than Tsybakov\u2019s. The advantage of the smooth relative margin is that the irreducible term in the above theorem is exactly $P_{X}(\\mathcal{X}\\backslash\\mathcal{A}_{0})$ , which has a clearer meaning as it measures the mismatch between clean and noisy Bayes classifiers. Further, notice that the NI-ERM algorithm does not need information about $\\alpha$ , and thus the result is adaptive to both $\\alpha$ , and to the optimal $\\kappa$ for each value of $\\alpha$ , as a consequence of the oracle inequality of Lemma 1. ", "page_idx": 6}, {"type": "text", "text": "More broadly, Theorem 3 illustrates the flexibility of our conceptualization of label noise problems through RSS. The RSS $\\mathcal{M}$ characterizes the irreducible error in label noise learning, similar to how the regression function $\\eta$ characterizes excess risk in standard learning. Thus, standard theoretical frameworks can be adapted to the noisy label problem via the relative signal. ", "page_idx": 6}, {"type": "text", "text": "6 Conditions that ensure noise immunity ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The minimax lower bound in the previous section revealed a negative outcome, indicating that no method can do well in the low signal region. Nevertheless, numerous empirical successes have been observed even under significant label noise. This is not mere coincidence. In this section, we will illustrate that the high signal region $\\mathcal{A}_{\\kappa}$ can indeed cover the entire input space $\\mathcal{X}$ even under massive label noise, albeit with the constraint ${\\mathcal{A}}_{\\kappa}\\subseteq{\\mathcal{A}}_{0}$ as stated in Proposition 1. This not only explains past empirical successes, but also gives a rigorous condition on the consistency of NI-ERM. ", "page_idx": 6}, {"type": "text", "text": "This section will delve into the study of noise transition matrix $\\pmb{E}$ and establish precise conditions that lead to $A_{0}=\\mathcal{X}$ . These conditions are linear algebraic conditions on $\\pmb{E}$ that ensure arg max $\\widetilde{\\eta}(x)=$ arg max $\\eta(x)$ . As a result, we can infer that in a 10-class classification problem, even with up   to $90\\%$ of training labels being incorrect, the NI-ERM can still asymptotically achieve Bayes accuracy. In the upcoming definition, we introduce the concept of noise immunity, wherein the optimal classifiers remain unaffected by label noise [Menon et al., 2015, Scott, 2019]. ", "page_idx": 6}, {"type": "text", "text": "Definition 3 (Immunity) We say that a $K$ -class classification problem $(P_{X},\\eta,\\tilde{\\eta})$ is immune to label noise $i f\\forall x\\in\\mathcal{X}$ , arg max $\\widetilde{\\pmb{\\eta}}(x)=\\arg\\operatorname*{max}{\\pmb{\\eta}}(x)$ . ", "page_idx": 6}, {"type": "text", "text": "Notice that due to Proposition 1, if a problem is immune, then $A_{0}=\\mathcal{X}$ . We now provide necessary and sufficient conditions on noise transition matrix $\\boldsymbol{E}$ that ensure noise immunity. We begin by considering distribution $P_{X Y}$ with zero Bayes risk, that is, where $\\eta$ is one-hot almost surely. A matrix is defined as diagonally dominant if, for each row, the diagonal element is the unique maximum. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4 (Immunity for Zero-error Distribution) If $P_{X Y}$ has Bayes risk of zero, then immunity holds if and only if for all $x$ , the noise transition matrix $E(x)$ is diagonally dominant. ", "page_idx": 6}, {"type": "text", "text": "Remark For a zero-error distribution $P_{X Y}$ , even corrupted with instance-dependent label noise, achieving the Bayes risk is still feasible with a noise rate $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ up to $\\textstyle{\\frac{K-1}{K}}$ . This highlights that the task of classification itself is robust to label noise, specia lly when the clean $\\eta$ is well-separated. ", "page_idx": 6}, {"type": "text", "text": "The above result relies on strong assumptions about the distribution $P_{X Y}$ . Now, we present a result that applies to any distribution, which, as a trade-off, turns out to impose more requirements on $\\boldsymbol{E}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 5 (Universal Immunity) For any choice of $P_{X Y}$ , immunity holds ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\iff}&{{}\\exists\\,e(x)>0\\,s.t.\\;\\forall x\\in\\mathcal{X},\\;[E(x)]_{i,j}=\\left\\{\\begin{array}{l l}{\\frac{1}{K}+e(x)}&{i=j}\\\\ {\\frac{1}{K}-\\frac{e(x)}{K-1}}&{i\\neq j.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/a1fef540ce08498e617abea4d152d405d5a2ef6f5d167643fe265d5cb83236b8.jpg", "img_caption": ["(a) Logistic regression trained on 2D gaussian mixture data with different levels of symmetric noise "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/354cac1ecf657aa7c859f29a7cece04c4e6a1a7c91ac6b4d9103f6eeeacc9f3d.jpg", "img_caption": ["(b) 2-layer CNN trained on MNIST with different levels of symmetric noise "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 2: Data simulation that verifies noise immunity. For binary, the turning point is at noise rate $\\mathbb{P}\\big(\\tilde{Y}\\neq Y\\big)=0.5.$ For 10-class, the turning point is at $\\mathbb{P}\\big(\\widetilde{Y}\\neq Y\\big)=0.9$ . ", "page_idx": 7}, {"type": "text", "text": "Previous works [Ghosh and Kumar, 2017, Menon et al., 2018, Oyen et al., 2022] have established that symmetric label noise is sufficient for immunity. Our contribution advances this understanding by demonstrating that such noise conditions are not only sufficient but also necessary. Specifically, under symmetric label noise, learning towards the Bayes classifier is feasible as long as the proportion of wrong labels does not exceed $\\textstyle{\\frac{K-1}{K}}$ . Furthermore, this transition is abrupt: when $\\begin{array}{r}{\\mathbb{P}\\big(\\widetilde{Y}\\ne Y\\big)<\\frac{K-1}{K}}\\end{array}$ , $A_{0}=\\mathcal{X}$ , but when $\\begin{array}{r}{\\mathbb{P}(\\widetilde{Y}\\ne Y)\\ge\\frac{K-1}{K}}\\end{array}$ , $A_{0}=\\varnothing$ . Consequently, we expect to see a  sudden drop in performance when nois e rate passes the threshold. ", "page_idx": 7}, {"type": "text", "text": "The rationale behind the necessity of $E(x)$ taking this specific form is that it redistributes the probability mass of $\\eta$ in a \u201cuniform\u201d manner. This constraint arises because $E(x)$ cannot favor any classes besides the true class. For instance, consider $\\begin{array}{r}{\\pmb{\\eta}(x)=\\left[\\frac{1}{K}+\\delta\\;\\frac{1}{K}-\\delta\\;\\frac{1}{K}\\cdot\\cdot\\cdot\\frac{1}{K}\\right]^{\\intercal}}\\end{array}$ for some small $\\delta>0$ , a \u201cnon-uniform\u201d $E(x)$ would alter the arg max. ", "page_idx": 7}, {"type": "text", "text": "The above theorems demonstrate that signal strength at $x$ can still be high even under massive label noise $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ , and, in essence, it is the discrete nature of the classification problem that allows robustne ss to label noise. When immunity holds, the irreducible error in Theorem 2 vanishes, therefore NI-ERM becomes a consistent learning rule. We validate this through data simulations presented in Figure 2, where we systematically flip labels uniformly and observe the corresponding changes in the testing accuracy of NI-ERM. The simulation results align closely with the theoretical expectations: NI-ERM achieves near-Bayes risk performance until a certain noise threshold is reached, beyond which the testing performance sharply deteriorates. ", "page_idx": 7}, {"type": "text", "text": "7 Practical implication ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The modern practice of machine learning often involves training a deep neural network. In complex tasks involving noisy labels, the na\u00efve NI-ERM is often outperformed by state-of-the-art methods by a significant extent [Li et al., 2020, Xiao et al., 2023]. This is consistent with the finding that directly training a large neural network on noisy data frequently leads to overfitting [Zhang et al., 2021a]. ", "page_idx": 7}, {"type": "text", "text": "Yet this is not grounds for abandoning NI-ERM altogether as a practical strategy. Instead of using NI-ERM for end-to-end training of a deep neural network, we instead propose the following simple, two-step procedure, termed \u2018feature extraction $^+$ NI-ERM\u2019. ", "page_idx": 7}, {"type": "text", "text": "1. Perform feature extraction using any method (e.g., transfer learning or self-supervised learning) that does not require labels.   \n2. Learn a simple classifier (e.g., a linear classifier) on top of these extracted features, using the noisily labelled data, in a noise-ignorant way. ", "page_idx": 7}, {"type": "text", "text": "This approach has three advantages over full network training. First, it avoids the potentially negative impact of the noisy labels on the extracted features. Second, it enjoys the inherent robustness of ftiting a simple model (step 2) on noisy data, which we observed in Figure 2. Third, it avoids the need to tune hyperparameters of the feature extractor using noisy labels. We note that a \u201cself-supervised $^+$ simple approach\u201d to learning was previously studied by Bansal et al. [2021], although their focus was on generalisation properties without label noise. We also acknowledge that the practical idea of ignoring label noise is not new [Ghosh and Lan, 2021], but the full power of this approach has not been previously recognized. For example, prior works often combine this approach with additional steps or employ early stopping to mitigate the effects of noise [Zheltonozhskii et al., 2022, Xue et al., 2022]. ", "page_idx": 8}, {"type": "text", "text": "Remarkably, this two-step approach attains extremely strong performance. We conducted experiments 1 on the CIFAR image data under two scenarios: synthetic label flipping (symmetric noise) and realistic human label errors [Wei et al., 2022], as shown in Figure 3. We examine three different feature extractors: the DINOv2 foundation model [Oquab et al., 2023], ResNet-50 features extracted from training on ImageNet [He et al., 2016], and self-supervised ResNet-50 using contrastive loss [Chen et al., 2020]. We also compared to a simple linear model trained on the raw pixel intensities, and a ResNet-50 trained end-to-end. We observed that ResNet-50 exhibits degrading performance with increasing noise, consistent with previous findings [Zhang et al., 2021a, Mallinar et al., 2022]. The linear model demonstrates robustness to noise, but suffers from significant approximation error. ", "page_idx": 8}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/eff9a5e73c542f78364a6e52cdbb7c0aa01487f587747c9d9e9e1658536cc72b.jpg", "img_caption": ["(a) CIFAR-10 with synthetic label noise "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/2d9621939fc7177d74c4c485472f8d5a31eca40423e240621d068475d36f75fd.jpg", "img_caption": ["(b) CIFAR-10 with realistic label noise "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 3: A linear model trained on features obtained from either transfer learning (pretrained ResNet-50 on ImageNet [He et al., 2016] ), self-supervised learning (ResNet-50 trained on CIFAR-10 images with contrastive loss [Chen et al., 2020]), or a pretrained self-supervised foundation model DINOv2 [Oquab et al., 2023] significantly boosts the performance of the original linear model. In contrast, full training of a ResNet-50 leads to overfitting. ", "page_idx": 8}, {"type": "text", "text": "Conversely, the FE+NI-ERM approach enjoys the best of both worlds. Regardless of how the feature extraction is carried out, the resulting models exhibit robustness to label noise, while the overall accuracy depends entirely on the quality of the extracted features. This is illustrated in Figure 3, where the flatness of the accuracy curves as noise increases indicates the robustness, and the intercept at zero label noise is a measure of the feature quality. Importantly, this property holds true even under realistic label noise of CIFAR-N [Wei et al., 2022]. In fact, we find that using the DINOv2 [Oquab et al., 2023] extracted features in our FE+NI-ERM approach yields state of the art results on the CIFAR-10N and CIFAR-100N benchmarks, across the noise levels, as shown in Table 1. ", "page_idx": 8}, {"type": "text", "text": "We emphasize that the only hyperparameters of our model are the hyperparameters of the linear classifier, which are tuned automatically using standard cross-validation on the noisy labels. This contrasts to the implementation of many methods on the CIFAR-N leaderboard (http://noisylabels.com/) ", "page_idx": 8}, {"type": "text", "text": "2, where the hyperparameters are hard-coded. Furthermore, our approach does not rely on data augmentation. Additional experiments, detailed in Appendix A.4 , include comparisons with the \u2018linear probing, then fine-tuning\u2019 approach [Kumar et al., 2022], the application of different robust learning strategies on DINOv2 features, and results on synthetic instance-dependent label noise. ", "page_idx": 9}, {"type": "text", "text": "Overall, the strong performance, the simplicity of the approach and the lack of any untunable hyperparameters highlights the effectiveness of F $\\exists+\\Nu\\mathrm{I}$ -ERM, and indicates the value of further investigation into its properties. ", "page_idx": 9}, {"type": "text", "text": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \u201cAggre\u201d, \u201cRand1\u201d, . . . , \u201cNoisy\u201d denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python\u2019s sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible. ", "page_idx": 9}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/1da09d13242cf44f7c1f03931087bd45d80400efefd79d30131bc53523d9f30e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "RSS for realistic human label error. To ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "calculate the RSS under realistic human label error, we train two linear classifiers on DINOv2 features under clean and noisy labels and use the models\u2019 predictions as estimates for the class probabilities $\\eta$ and $\\widetilde{\\pmb{\\eta}}$ . Despite the high overall noise rate in C IFAR-10N \u201cWorst\u201d labels, with $\\mathbb{P}(Y\\neq$ $\\widetilde{Y})\\,=\\,40.21\\%$ , we conjecture that the reg ion where there is no signal, $\\mathcal{X}\\setminus\\mathcal{A}_{0}$ , covers only a small portion of the probability mass $(\\epsilon\\,\\leq\\,4\\%)$ ). Furthermore, the cumulative distribution of the estimated RSS can be upper-bounded by a polynomial $C_{\\alpha}\\kappa^{\\alpha}+\\epsilon$ , supporting the validity of the smooth relative signal margin condition introduced in Section 5.3. ", "page_idx": 9}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/40439c430883d9ae761c48d3ba25ddf89b68b230aa40a34b379aa7c6653c08d7.jpg", "img_caption": ["Figure 4: Empirical CDF of estimated RSS for CIFAR$10\\mathrm{N}$ , evaluated on test data. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "8 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work presents a rigorous theory for learning under multi-class, instance-dependent label noise. We establish nearly matching upper and lower bounds for excess risk and identify precise conditions for classifier consistency. Our theory reveals the (nearly) minimax optimality of Noise Ignorant Empirical Risk Minimizer (NI-ERM). To make this theory practical, we provide a simple modification leveraging a feature extractor with NI-ERM, demonstrating significant performance enhancements. A limitation of this work is that our methodology warrants more extensive experimental evaluation. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported in part by the National Science Foundation under award 2008074 and the Department of Defense, Defense Threat Reduction Agency under award HDTRA1-20-2-0002. The authors thank Zixuan Huang, Yihao Xue for helpful discussions and Raj Rao Nadakuditi for feedback during a course project in which some early experiments in this paper were conducted. We also thank the anonymous reviewers for their suggestions, especially the reviewer who provided Example 3. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Paul Albert, Eric Arazo, Tarun Krishna, Noel E O\u2019Connor, and Kevin McGuinness. Is your noise correction noisy? pls: Robustness to label noise with two stage detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 118\u2013127, 2023.   \nDana Angluin and Philip Laird. Learning from noisy examples. Machine learning, 2:343\u2013370, 1988.   \nYamini Bansal, Gal Kaplun, and Boaz Barak. For self-supervised learning, rationality implies generalization, provably. In International Conference on Learning Representations, 2021.   \nCarla E Brodley and Mark A Friedl. Identifying mislabeled training data. Journal of artificial intelligence research, 11:131\u2013167, 1999.   \nT Tony Cai and Hongji Wei. Transfer learning for nonparametric classification: Minimax rate and adaptive classifier. The Annals of Statistics, 49(1):100\u2013128, 2021.   \nTimothy I Cannings, Yingying Fan, and Richard J Samworth. Classification with imperfect training labels. Biometrika, 107(2):311\u2013330, 2020.   \nHao Chen, Ankit Shah, Jindong Wang, Ran Tao, Yidong Wang, Xing Xie, Masashi Sugiyama, Rita Singh, and Bhiksha Raj. Imprecise label learning: A unified framework for learning with various imprecise label configurations. arXiv preprint arXiv:2305.12715, 2023.   \nTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pages 1597\u20131607. PMLR, 2020.   \nHao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. Learning with instancedependent label noise: A sample sieve approach. In International Conference on Learning Representations, 2021.   \nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. IEEE, 2009.   \nLuc Devroye, L\u00e1szl\u00f3 Gy\u00f6rf,i and Gabor Lugosi. A Probabilistic Theory of Pattern Recognition, volume 31. Springer, 1996.   \nPierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id $\\cdot$ 6Tm1mposlrM.   \nAritra Ghosh and Himanshu Kumar. Robust loss functions under label noise for deep neural networks. In Proceedings of the AAAI conference on artificial intelligence, 2017.   \nAritra Ghosh and Andrew Lan. Contrastive learning improves model robustness under label noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2703\u20132708, 2021.   \nAritra Ghosh, Naresh Manwani, and PS Sastry. Making risk minimization tolerant to label noise. Neurocomputing, 160:93\u2013107, 2015.   \nBo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. Advances in neural information processing systems, 31, 2018.   \nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \nHyungki Im and Paul Grigas. Binary classification with instance and label dependent label noise. arXiv preprint arXiv:2306.03402, 2023.   \nAnanya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang. Fine-tuning can distort pretrained features and underperform out-of-distribution. In International Conference on Learning Representations, 2022.   \nJunnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as semisupervised learning. In International Conference on Learning Representations, 2020.   \nSheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Advances in neural information processing systems, 33:20331\u201320342, 2020.   \nSheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by overparameterization. In International Conference on Machine Learning, pages 14153\u201314172. PMLR, 2022.   \nTongliang Liu and Dacheng Tao. Classification with noisy labels by importance reweighting. IEEE Transactions on pattern analysis and machine intelligence, 38(3):447\u2013461, 2015.   \nYang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing noise rates. In International conference on machine learning, pages 6226\u20136236. PMLR, 2020.   \nJianhao Ma and Salar Fattahi. Blessing of depth in linear regression: Deeper models have flatter landscape around the true solution. Advances in Neural Information Processing Systems, 35: 34334\u201334346, 2022.   \nSubha Maity, Diptavo Dutta, Jonathan Terhorst, Yuekai Sun, and Moulinath Banerjee. A linear adjustment based approach to posterior drift in transfer learning. Biometrika, 2023. URL https: //doi.org/10.1093/biomet/asad029.   \nNeil Mallinar, James Simon, Amirhesam Abedsoltan, Parthe Pandit, Misha Belkin, and Preetum Nakkiran. Benign, tempered, or catastrophic: Toward a refined taxonomy of overftiting. Advances in Neural Information Processing Systems, 35:1182\u20131195, 2022.   \nPascal Massart and \u00c9lodie N\u00e9d\u00e9lec. Risk bounds for statistical learning. The Annals of Statistics, 34 (5):2326\u20132366, 2006.   \nAditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson. Learning from corrupted binary labels via class-probability estimation. In International conference on machine learning, pages 125\u2013134. PMLR, 2015.   \nAditya Krishna Menon, Brendan Van Rooyen, and Nagarajan Natarajan. Learning from binary labels with instance-dependent noise. Machine Learning, 107:1561\u20131595, 2018.   \nBalas K Natarajan. On learning sets and functions. Machine Learning, 4:67\u201397, 1989.   \nNagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. Advances in neural information processing systems, 26, 2013.   \nCurtis Northcutt, Lu Jiang, and Isaac Chuang. Confident learning: Estimating uncertainty in dataset labels. Journal of Artificial Intelligence Research, 70:1373\u20131411, 2021   \nMaxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy V Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel HAZIZA, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual features without supervision. Transactions on Machine Learning Research, 2023.   \nDiane Oyen, Michal Kucer, Nicolas Hengartner, and Har Simrat Singh. Robustness to label noise depends on the shape of the noise distribution. Advances in Neural Information Processing Systems, 35:35645\u201335656, 2022.   \nGiorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1944\u20131952, 2017.   \nClayton Scott. A generalized Neyman-Pearson criterion for optimal domain adaptation. In Algorithmic Learning Theory, pages 738\u2013761. PMLR, 2019.   \nClayton Scott, Gilles Blanchard, and Gregory Handy. Classification with asymmetric label noise: Consistency and maximal denoising. In Conference on learning theory, pages 489\u2013511. PMLR, 2013.   \nAlexander B Tsybakov. Optimal aggregation of classifiers in statistical learning. The Annals of Statistics, 32(1):135\u2013166, 2004.   \nBrendan Van Rooyen and Robert C Williamson. A theory of learning with corrupted labels. Journal of Machine Learning Research, 18(228):1\u201350, 2018.   \nV. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability & Its Applications, 16(2):264\u2013280, 1971. doi: 10.1137/1116025. URL https://doi.org/10.1137/1116025.   \nJialu Wang, Eric Xin Wang, and Yang Liu. Estimating instance-dependent label-noise transition matrix using a deep neural network. In International Conference on Machine Learning, 2022.   \nJiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning with noisy labels revisited: A study using real-world human annotations. In International Conference on Learning Representations, 2022.   \nXiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. Advances in Neural Information Processing Systems, 33:7597\u20137610, 2020.   \nRuixuan Xiao, Yiwen Dong, Haobo Wang, Lei Feng, Runze Wu, Gang Chen, and Junbo Zhao. Promix: Combating label noise via maximizing clean sample utility. In Edith Elkind, editor, Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI23, pages 4442\u20134450. International Joint Conferences on Artificial Intelligence Organization, 8 2023. doi: 10.24963/ijcai.2023/494. URL https://doi.org/10.24963/ijcai.2023/494. Main Track.   \nYihao Xue, Kyle Whitecross, and Baharan Mirzasoleiman. Investigating why contrastive learning benefits robustness against label noise. In International Conference on Machine Learning, pages 24851\u201324871. PMLR, 2022.   \nShuo Yang, Songhua Wu, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. A parametrical model for instance-dependent label noise. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.   \nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107\u2013115, 2021a.   \nJianxin Zhang, Yutong Wang, and Clayton Scott. Learning from label proportions by learning with label noise. Advances in Neural Information Processing Systems, 35:26933\u201326942, 2022.   \nMingyuan Zhang, Jane Lee, and Shivani Agarwal. Learning from noisy labels with no change to the training process. In International Conference on Machine Learning, pages 12468\u201312478. PMLR, 2021b.   \nEvgenii Zheltonozhskii, Chaim Baskin, Avi Mendelson, Alex M Bronstein, and Or Litany. Contrast to divide: Self-supervised pre-training for learning with noisy labels. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1657\u20131667, 2022.   \nZhaowei Zhu, Tongliang Liu, and Yang Liu. A second-order approach to learning with instancedependent label noise. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10113\u201310123, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Appendix / supplemental material ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Equivalence of noise transition and domain adaptation perspectives ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The noise transition perspective models the joint distribution of $(X,Y,{\\widetilde{Y}})$ , which can be characterized as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nP_{X,Y,\\widetilde{Y}}=P_{X}\\underbrace{P_{Y|X}}_{\\eta}\\underbrace{P_{\\widetilde{Y}|Y,X}}_{E}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, by specifying $P_{X},\\,\\eta$ , and $\\boldsymbol{E}$ , we obtain a triple $(P_{X},\\eta,\\tilde{\\eta})$ with $\\widetilde{\\pmb{\\eta}}(x)=\\pmb{E}(x)^{\\top}\\pmb{\\eta}(x)$ . ", "page_idx": 14}, {"type": "text", "text": "In contrast, the domain adaptation perspective views label   noise p r oblems directly as a triple $(P_{X},\\eta,\\tilde{\\eta})$ , bypassing the explicit modeling of the noise transition matrix $\\boldsymbol{E}$ . ", "page_idx": 14}, {"type": "text", "text": "If no ass u mptions are made about the form of $\\boldsymbol{E}$ , the domain adaptation view remains fully expressive. Given a triple $(P_{X},\\eta,\\widetilde{\\eta})$ , we can always define a noise transition matrix as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\pmb{E}(x)=\\mathbf{1}\\widetilde{\\eta}^{\\top},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\mathbf{1}=[1\\ldots1]^{\\top}$ . We can verify that $\\pmb{E}$ is row-stochastic, and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{\\eta}}=\\pmb{E}(\\boldsymbol{x})^{\\top}\\pmb{\\eta}=(\\widetilde{\\pmb{\\eta}}\\pmb{1}^{\\top})\\pmb{\\eta}=\\widetilde{\\pmb{\\eta}}(\\pmb{1}^{\\top}\\pmb{\\eta})=\\widetilde{\\pmb{\\eta}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, these two perspectives are equivalent. ", "page_idx": 14}, {"type": "text", "text": "A.2 Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.2.1 Proof of Proposition 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proposition ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{A}_{0}(\\eta,\\widetilde{\\eta})=\\big\\{x\\in\\mathcal{X}:\\arg\\operatorname*{max}\\widetilde{\\eta}(x)\\subseteq\\arg\\operatorname*{max}\\eta(x)\\big\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. Notice that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})=0\\quad\\Longleftrightarrow\\quad\\arg\\operatorname*{max}\\,\\widetilde{\\eta}(x)\\,\\mathcal{Z}\\,\\arg\\operatorname*{max}\\,\\eta(x).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This is because $\\mathcal{M}(x;\\pmb{\\eta},\\tilde{\\eta})=0$ when the numerator is zero and the denominator is non-zero, which happens when arg max $\\widetilde{\\eta}(\\boldsymbol{x})\\not\\subseteq$ arg max $\\eta(x)$ . ", "page_idx": 14}, {"type": "text", "text": "An equivalent statement of this is ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})>0\\quad\\Longleftrightarrow\\quad\\arg\\operatorname*{max}\\,\\widetilde{\\eta}(x)\\subseteq\\arg\\operatorname*{max}\\,\\eta(x).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.2.2 Proof of Proposition 2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proposition In the binary setting, for $\\kappa\\geq0$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{max}\\left\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},0\\right\\},\\qquad a n d\\qquad\\mathcal{A}_{\\kappa}(\\eta,\\widetilde{\\eta})=\\left\\{x\\in\\mathcal{X}:\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}}>\\kappa\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. In a brute-force way, we can examine the nine cases where $\\eta(x),\\widetilde{\\eta}(x)$ is greater, equal, or smaller than $1/2$ . ", "page_idx": 14}, {"type": "text", "text": "If $\\begin{array}{r}{\\widetilde{\\eta}(x)>\\frac{1}{2},\\eta(x)>\\frac{1}{2}}\\end{array}$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{min}_{j\\in\\mathcal{Y}}\\ \\frac{\\operatorname*{max}_{i}\\lvert\\widetilde{\\eta}(x)\\rvert_{i}-\\lvert\\widetilde{\\eta}(x)\\rvert_{j}}{\\operatorname*{max}_{i}\\lvert\\eta(x)\\rvert_{i}-[\\eta(x)]_{j}}}\\quad}&{}\\\\ &{=\\frac{\\widetilde{\\eta}(x)-(1-\\widetilde{\\eta}(x))}{\\eta(x)-(1-\\eta(x))}}\\\\ &{=\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}}}\\\\ &{=\\operatorname*{max}\\left\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "If $\\begin{array}{r}{\\widetilde{\\eta}(x)<\\frac{1}{2},\\eta(x)<\\frac{1}{2}}\\end{array}$ , the same argument holds. ", "page_idx": 15}, {"type": "text", "text": "If $\\begin{array}{r}{\\widetilde{\\eta}(x)>\\frac{1}{2},\\eta(x)<\\frac{1}{2}}\\end{array}$ or $\\begin{array}{r}{\\widetilde{\\eta}(x)<\\frac{1}{2},\\eta(x)>\\frac{1}{2}}\\end{array}$ , take $j=\\arg\\operatorname*{max}{\\widetilde{\\eta}}(x)$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{M}(x;\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})=\\underset{j\\in\\mathcal{Y}}{\\mathrm{min}}\\ \\ \\frac{\\mathrm{max}_{i}[\\widetilde{\\pmb{\\eta}}(x)]_{i}-[\\widetilde{\\pmb{\\eta}}(x)]_{j}}{\\operatorname*{max}_{i}[\\pmb{\\eta}(x)]_{i}-[\\pmb{\\eta}(x)]_{j}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=0}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\operatorname*{max}\\left\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},0\\right\\}\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "If $\\begin{array}{r}{\\widetilde{\\eta}(x)=\\frac{1}{2},\\eta(x)<\\frac{1}{2}}\\end{array}$ or $\\begin{array}{r}{\\widetilde{\\eta}(x)=\\frac{1}{2},\\eta(x)<\\frac{1}{2}}\\end{array}$ , take $j\\neq\\arg\\operatorname*{max}{\\eta(x)}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{M}(x;\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})=\\underset{j\\in\\mathcal{Y}}{\\mathrm{min}}\\ \\ \\frac{\\operatorname*{max}_{i}[\\widetilde{\\pmb{\\eta}}(x)]_{i}-[\\widetilde{\\pmb{\\eta}}(x)]_{j}}{\\operatorname*{max}_{i}[\\pmb{\\eta}(x)]_{i}-[\\pmb{\\eta}(x)]_{j}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=0}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\operatorname*{max}\\left\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},0\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "If $\\begin{array}{r}{\\eta(x)=\\frac{1}{2}}\\end{array}$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\underset{j\\in\\mathcal{Y}}{\\mathrm{min}}\\ \\ \\frac{\\operatorname*{max}_{i}\\lvert\\widetilde{\\eta}(x)\\rvert_{i}-[\\widetilde{\\eta}(x)]_{j}}{\\operatorname*{max}_{i}\\lvert\\eta(x)\\rvert_{i}-[\\eta(x)]_{j}}}\\\\ &{\\quad\\quad\\quad\\quad=\\frac{\\operatorname*{max}_{i}[\\widetilde{\\eta}(x)]_{i}-[\\widetilde{\\eta}(x)]_{j}}{0}}\\\\ &{\\quad\\quad\\quad\\quad=+\\infty}\\\\ &{\\quad\\quad\\quad=\\operatorname*{max}\\bigg\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},0\\bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Note that it makes sense for RSS to be $+\\infty$ when $\\begin{array}{r}{\\eta(x)=\\frac{1}{2}}\\end{array}$ , because in this case, clean excess risk $R(f)-R(f^{*})$ is 0 at point $x$ for any classifier. ", "page_idx": 15}, {"type": "text", "text": "Therefore, we can conclude that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{M}(x;\\eta,\\widetilde{\\eta})=\\operatorname*{max}\\bigg\\{\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}},0\\bigg\\},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "by definition, we have, for $\\kappa\\geq0$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}_{\\kappa}(\\eta,\\widetilde{\\eta})=\\{x\\in\\mathcal{X}:\\mathcal{M}(x;\\eta,\\widetilde{\\eta})>\\kappa\\}}\\\\ {=\\left\\{x\\in\\mathcal{X}:\\frac{\\widetilde{\\eta}(x)-\\frac{1}{2}}{\\eta(x)-\\frac{1}{2}}>\\kappa\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A.2.3 Proof of lower bound: Theorem 1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Now we provide a more formal statement of the minimax lower bound and its proof. We begin with the scenario where the noisy distribution $P_{X\\tilde{Y}}$ has zero Bayes risk as an introductory example. The proof for the general case follows a similar st rategy but involves more complex bounding techniques. We recommend that interested readers first review the proof of the zero-error version to build a solid understanding before tackling the general case. ", "page_idx": 16}, {"type": "text", "text": "Now consider a more restricted subset of $\\Pi(\\epsilon,\\kappa)$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Pi(\\epsilon,\\kappa,V,0):=\\left\\{\\,(P_{X},\\pmb{\\eta},\\widetilde{\\eta}):P_{X}\\Big(\\pmb{\\mathcal{A}}_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\eta}\\right)\\Big)\\geq1-\\epsilon,P_{X}\\:\\mathrm{su}_{\\kappa}\\,.\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Theorem (Minimax Lower Bound: when $\\tilde{R}^{*}=0,$ ) $L e t\\,\\epsilon\\in[0,1],\\kappa>0,V>1.$ . For any learning rule $\\hat{f}$ based upon $Z^{n}=\\left\\{(X_{i},{\\widetilde{Y}}_{i})\\right\\}_{i=1}^{n}$ , a n d $n>\\operatorname*{max}(V-1,2)$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\underset{(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa,V,0)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq\\frac{K-1}{K}\\epsilon+\\frac{1}{\\kappa}\\frac{\\left(V-1\\right)\\left(1-\\epsilon\\right)}{8e n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. ", "page_idx": 16}, {"type": "text", "text": "We will construct a triple $(P_{X},\\eta,\\tilde{\\eta})$ that is parameterized by $j,b:=\\left[b_{1}\\;b_{2}\\;\\cdot\\cdot\\cdot\\;b_{V-1}\\right]^{\\top}$ , and $\\delta$ . First, we define $P_{X}$ . Pick any $V+1$ distinct points $x_{0},x_{1},\\ldots,x_{V}$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\nP_{X}(x)=\\left\\{\\!\\!\\begin{array}{l l}{{\\epsilon}}&{{x=x_{0}}}\\\\ {{(1-\\epsilon)\\cdot\\frac{1}{n}}}&{{x=x_{1},\\ldots,x_{V-1}\\;,}}\\\\ {{(1-\\epsilon)\\cdot\\left(1-\\frac{V-1}{n}\\right)}}&{{x=x_{V}.}}\\end{array}\\!\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "this is where we need the condition that $n>V-1$ . ", "page_idx": 16}, {"type": "text", "text": "Then, define the clean and noisy class posteriors: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\textrm{f}x=x_{0},\\,\\mathrm{then}\\;\\;\\eta(x)=e_{j},\\;\\tilde{\\eta}(x)=e_{1},\\quad j\\in\\{1,2,\\ldots K\\}}\\\\ &{\\textrm{f}x=x_{t},\\,1\\le t\\le V-1,\\,\\mathrm{then}\\,\\eta(x)=\\left[\\frac{\\frac{1}{2}+\\frac{1}{2(\\kappa+\\delta)}\\cdot\\left(-1\\right)^{b_{t}+1}}{2(\\kappa+\\delta)}\\right],\\tilde{\\eta}(x)=e_{b_{t}},b_{t}\\in\\{1,2\\},\\delta>0,}\\\\ &{\\textrm{f}x=x_{t},\\,1\\le t\\le V-1,\\,\\mathrm{then}\\,\\eta(x)=\\left[\\begin{array}{c}{\\vdots}\\\\ {0}\\\\ {0}\\end{array}\\right],\\tilde{\\eta}(x)=e_{b_{t}},b_{t}\\in\\{1,2\\},\\delta>0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta(x)=\\left[\\begin{array}{c}{{\\frac{1}{2}+\\frac{1}{2(\\kappa+\\delta)}}}\\\\ {{\\frac{1}{2}-\\frac{1}{2(\\kappa+\\delta)}}}\\\\ {{0}}\\\\ {{\\vdots}}\\\\ {{0}}\\end{array}\\right],\\;\\widetilde{\\pmb{\\eta}}(x)=e_{1},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $e_{i}$ denotes the one-hot vector whose $i$ -th element is one. ", "page_idx": 16}, {"type": "text", "text": "The triple $(P_{X},\\eta,\\widetilde{\\eta})$ is thus parameterized by $j,b:=\\left[b_{1}\\;b_{2}\\;\\cdot\\cdot\\cdot\\;b_{V-1}\\right]^{\\top}$ , and $\\delta$ . ", "page_idx": 16}, {"type": "text", "text": "This construction e  nsures $(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})\\in\\Pi(\\epsilon,\\kappa,V,0)$ . In particular, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{A_{\\kappa}\\supseteq\\{x_{1},x_{2},\\ldots,x_{V}\\},\\qquad\\qquad\\qquad}&{P_{X}(\\mathcal{A}_{\\kappa})\\geq1-\\epsilon,}\\\\ &{\\mathcal{X}\\backslash\\mathcal{A}_{\\kappa}\\subseteq\\{x_{0}\\},\\qquad\\qquad\\qquad}&{P_{X}(\\mathcal{X}\\backslash\\mathcal{A}_{\\kappa})\\leq\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and $\\widetilde{R}^{*}=0$ because $\\widetilde{\\eta}(\\boldsymbol{x})$ is one-hot for all $x$ . ", "page_idx": 16}, {"type": "text", "text": "For any classifier $f$ , by definition, its risk equals ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{~}&{R\\left(f\\right)=\\mathbb{E}_{X,Y}\\left[\\mathbb{1}_{f\\left(X\\right)\\neq Y}\\right]}\\\\ {~}&{~~~~~=\\mathbb{E}_{X}\\mathbb{E}_{Y\\mid X}\\big[\\mathbb{1}_{f\\left(X\\right)\\neq Y}\\big]}\\\\ {~}&{~~~~=\\mathbb{E}_{X}\\mathbb{E}_{Y\\mid X}\\big[1-\\mathbb{1}_{f\\left(X\\right)=Y}\\big]}\\\\ {~}&{~~~=\\mathbb{E}_{X}\\left[1-\\left[\\eta(X)\\right]_{f\\left(X\\right)}\\right]}\\\\ {~}&{~~~=\\int_{\\mathcal{X}}\\left(1-\\left[\\eta(x)\\right]_{f\\left(x\\right)}\\right)d P_{X}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, the Bayes risk and excess risk equal ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\quad R(f^{*})=\\underset{f}{\\operatorname*{inf}}~\\mathbb{E}_{X,Y}\\left[\\mathbb{1}_{f(X)\\neq Y}\\right]}\\\\ &{\\quad\\quad\\quad\\quad=\\int_{\\mathcal{X}}\\left(1-\\operatorname*{max}\\eta(x)\\right)d P_{X}(x),}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad R(f)-R(f^{*})=\\int_{\\mathcal{X}}\\left(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\right)d P_{X}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Under our construction of $P_{X}$ , $R(f)$ can be decomposed into two parts ", "page_idx": 17}, {"type": "equation", "text": "$$\nR\\left(f\\right)=\\underbrace{\\int_{\\{x_{0}\\}}\\left(1-\\left[\\eta(x)\\right]_{f(x)}\\right)d P_{X}(x)}_{:=R_{0}(f)}+\\underbrace{\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\left(1-\\left[\\eta(x)\\right]_{f(x)}\\right)d P_{X}(x)}_{:=R_{V}(f)},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and so can the excess risk ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{R(f)-R(f^{*})=\\Big(R_{0}\\,(f)-R_{0}(f^{*})\\Big)+\\Big(R_{V}\\,(f)-R_{V}(f^{*})\\Big)}}\\\\ &{=\\displaystyle\\int_{\\{x_{0}\\}}\\Big(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\Big)\\,d P_{X}(x)}\\\\ &{\\qquad\\qquad+\\displaystyle\\int_{\\{x_{1},\\dots,x_{V}\\}}\\Big(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\Big)\\,d P_{X}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Recall that in our construction, $(P_{X},\\eta,\\widetilde{\\eta})$ is parameterized by $j,b$ , and $\\delta$ . Therefore ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\left(P_{X},\\eta,\\tilde{\\eta}\\right)\\in\\Pi\\left(\\epsilon,\\kappa,V,0\\right)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\underset{j,b,\\delta}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]}&{}\\\\ {=\\underset{j,b,\\delta}{\\operatorname*{sup}}\\left\\lbrace\\mathbb{E}_{Z^{n}}\\left[R_{0}\\left(\\hat{f}\\right)-R_{0}(f^{*})\\right]\\right.}&{}\\\\ {+\\left.\\mathbb{E}_{Z^{n}}\\left[R_{V}\\left(\\hat{f}\\right)-R_{V}(f^{*})\\right]\\right\\rbrace}&{}\\\\ {=\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[R_{0}\\left(\\hat{f}\\right)-R_{0}(f^{*})\\right]}&{}\\\\ {+\\underset{b,\\delta}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[R_{V}\\left(\\hat{f}\\right)-R_{V}(f^{*})\\right]}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last equality holds because region $\\{x_{0}\\}$ only depends on $j$ , while region $\\{x_{1},\\ldots,x_{V}\\}$ only depends on $b,\\delta$ . ", "page_idx": 17}, {"type": "text", "text": "In the remaining part of the proof, we will examine ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{j}\\,\\mathbb{E}_{Z^{n}}\\left[R_{0}\\left({\\hat{f}}\\right)-R_{0}(f^{*})\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{b,\\delta}\\,\\mathbb{E}_{Z^{n}}\\left[R_{V}\\left({\\hat{f}}\\right)-R_{V}(f^{*})\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "separately. ", "page_idx": 18}, {"type": "text", "text": "Let\u2019s start with the first term (5), which reflects the excess risk over the \u201clow signal strength\u201d region $\\{x_{0}\\}$ . Since $\\eta$ is one-hot on $\\{x_{0}\\}$ , its Bayes risk over that is zero ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[R_{0}\\left(\\widehat{f}\\right)-R_{0}(f^{*})\\right]=\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[R_{0}\\left(\\widehat{f}\\right)\\right]}&{}&\\\\ {=\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[\\displaystyle\\int_{\\{x_{0}\\}}\\mathbb{1}_{\\widehat{f}(x)\\neq j}d P_{X}(x)\\right].}&{}&\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "To deal with $\\operatorname{sup}_{j}$ , we use a technique called \u201cthe probabilistic method\u201d [Devroye et al., 1996]: replace $j$ with a random variable $J\\sim\\operatorname{Uniform}\\{1,2,\\ldots,K\\}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[\\int_{\\left\\{x_{0}\\right\\}}\\mathbb{1}_{\\hat{f}(x)\\neq j}d P_{X}(x)\\right]\\geq\\mathbb{E}_{J}\\left[\\mathbb{E}_{Z^{n}|J}\\left[\\int_{\\left\\{x_{0}\\right\\}}\\mathbb{1}_{\\hat{f}(x)\\neq J}d P_{X}(x)\\right]\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}_{J}\\,\\,\\underline{{z^{n}}}\\left[\\int_{\\left\\{x_{0}\\right\\}}\\mathbb{1}_{\\hat{f}(x)\\neq J}d P_{X}(x)\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}_{Z^{n}}\\left[\\mathbb{E}_{J|Z^{n}}\\left[\\int_{\\left\\{x_{0}\\right\\}}\\mathbb{1}_{\\hat{f}(x)\\neq J}d P_{X}(x)\\right]\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Again, notice that $J$ is an independent draw. Even if the point $x_{0}$ is observed in $Z^{n}$ , the associated noisy label $\\widetilde{Y}=1$ does not give any information about the clean label $Y=J$ . Thus ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Z^{n}}\\left[\\mathbb{E}_{J\\mid Z^{n}}\\left[\\int_{\\{x_{0}\\}}1_{\\hat{f}(x)\\neq J}d P_{X}(x)\\right]\\right]=\\mathbb{E}_{Z^{n}}\\left[\\mathbb{E}_{J}\\left[\\int_{\\{x_{0}\\}}1_{\\hat{f}(x)\\neq J}d P_{X}(x)\\right]\\right]}\\\\ &{\\phantom{=}=\\mathbb{E}_{Z^{n}}\\left[\\int_{\\{x_{0}\\}}\\mathbb{E}_{J}\\left[1_{\\hat{f}(x)\\neq J}\\right]d P_{X}(x)\\right]}\\\\ &{\\phantom{=}=\\mathbb{E}_{Z^{n}}\\left[\\int_{\\{x_{0}\\}}\\left(1-\\frac{1}{K}\\right)d P_{X}(x)\\right]}\\\\ &{\\phantom{=}=\\left(1-\\frac{1}{K}\\right)\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now we have the minimax lower bound for the first part (5): ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{j}\\,\\mathbb{E}_{Z^{n}}\\left[R_{\\{x_{0}\\}}\\left({\\hat{f}}\\right)-R_{\\{x_{0}\\}}(f^{*})\\right]\\geq\\left(1-{\\frac{1}{K}}\\right)\\epsilon.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For the second part (6), which is over $\\{x_{1},\\ldots,x_{V}\\}$ , due to the relative signal strength condition, and from our explicit construction in Eqn. (3) and (4), the excess risks w.r.t. true and noisy distribution are related by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathfrak{N}(f)-R_{V}(f^{*})=\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\left(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\right)d P_{X}(x)}}\\\\ &{=\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\frac{1}{\\kappa+\\delta}\\Big(\\operatorname*{max}\\tilde{\\eta}(x)-[\\tilde{\\eta}(x)]_{f(x)}\\Big)\\ d P_{X}(x)\\quad\\mathrm{by~construction~of~}\\eta,\\widetilde{\\eta}}\\\\ &{=\\frac{1}{\\kappa+\\delta}\\left(\\tilde{R}_{V}(f)-\\tilde{R}_{V}(\\tilde{f}^{*})\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{\\widetilde{R}_{V}(f):=\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\left(1-[\\widetilde{\\eta}(x)]_{f(x)}\\right)\\,d P_{X}(x)}\\end{array}$ . Also note that $f^{*}(x)\\,=\\,{\\tilde{f}}^{*}(x)$ for $x\\in$ $\\{x_{1},\\ldots,x_{V}\\}$ , which is a result of our  construction of $\\eta,\\widetilde{\\eta}$ . ", "page_idx": 18}, {"type": "text", "text": "Then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{b,\\delta}\\;\\mathbb{E}_{Z^{n}}\\left[R_{V}\\left(\\widehat{f}\\right)-R_{V}(f^{*})\\right]=\\operatorname*{sup}_{b,\\delta}\\;\\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(f)-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right)\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This allows us to reduce the label noise problem to a standard learning problem: we have an iid sample $Z^{n}$ from $P_{X\\tilde{Y}}$ and consider the risk evaluated on the same distribution $P_{X\\widetilde{Y}}$ . The remainder of the proof is simila  r to the proof of Devroye et al. [1996, Theorem 14.1]. ", "page_idx": 19}, {"type": "text", "text": "Notice that by our construction, $\\widetilde{Y}$ is a deterministic function of $X$ . To be specific, $\\widetilde{Y}\\,=\\,\\widetilde{f}^{*}(X)$ , where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tilde{f}^{*}(x)=\\left\\{\\!\\!\\begin{array}{l l}{1}&{x=x_{0},}\\\\ {b_{t}}&{x=x_{t},\\;1\\leq t\\leq V-1}\\\\ {1}&{x=x_{V}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "is the noisy Bayes classifier. ", "page_idx": 19}, {"type": "text", "text": "We use the shorthand $f_{b}:=\\tilde{f}^{*}$ to denote that the noisy Bayes classifier depends on $^{b}$ . Since the noisy Bayes risk is zero, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{b,\\delta}\\,\\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(\\hat{f})-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right)\\right]=\\operatorname*{sup}_{b,\\delta}\\,\\frac{1}{\\kappa+\\delta}\\,\\mathbb{E}_{Z^{n}}\\left[\\widetilde{R}_{V}(\\hat{f})\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Again, use the probabilistic method, replace $^{b}$ with $B\\sim\\mathrm{Uniform}\\{1,2\\}^{V-1}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{b,\\delta}{\\operatorname*{sup}}\\ \\frac{1}{\\kappa+\\delta}\\ \\mathbb{E}_{Z^{n}}\\left[\\widetilde{R}_{V}(\\hat{f})\\right]\\geq\\underset{\\delta}{\\operatorname*{sup}}\\ \\frac{1}{\\kappa+\\delta}\\ \\mathbb{E}_{B,Z^{n}}\\left[\\widetilde{R}_{V}(\\hat{f})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\underset{\\delta}{\\operatorname*{sup}}\\ \\frac{1}{\\kappa+\\delta}\\ \\mathbb{E}_{Z^{n}}\\left[\\mathbb{E}_{B|Z^{n}}\\left[\\int_{\\{x_{1},\\dots,x_{V}\\}}\\mathbb{1}_{\\hat{f}(x)\\neq f_{B}(x)}d P_{X}(x)\\right]\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since we have $B\\sim\\mathrm{Uniform}\\{1,2\\}^{V-1}$ and also $Z^{n}|B\\sim P_{X\\tilde{Y}}^{\\otimes n}$ , then by Bayes rule (or eye-balling, since $\\widetilde{\\pmb{\\eta}}$ is one-hot), we get the posterior distribution of $B|Z^{n}$ ,  to be specific: $\\forall x\\in\\{x_{1},\\cdot\\cdot\\cdot,x_{V}\\}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{If}\\,x=X_{i},i\\in\\{1,2,\\dots,n\\}\\,,\\ \\mathrm{~then}\\,\\ \\mathbb{P}\\left(f_{B}(x)=\\widetilde{Y}_{i}|Z^{n}\\right)=1,\\,\\mathbb{P}\\left(f_{B}(x)\\neq\\widetilde{Y}_{i}|Z^{n}\\right)=0}\\\\ &{\\qquad\\qquad\\qquad\\mathrm{~If}\\,x=x_{V},\\ \\mathrm{~then}\\ \\mathbb{P}\\left(f_{B}(x)=1|Z^{n}\\right)=1,\\,\\mathbb{P}\\left(f_{B}(x)=2|Z^{n}\\right)=0}\\\\ &{\\quad\\mathrm{~If}\\,x\\notin\\{X_{1},\\dots,X_{n},x_{V}\\},\\ \\mathrm{~then}\\ \\mathbb{P}\\left(f_{B}(x)=1|Z^{n}\\right)=\\frac{1}{2},\\,\\mathbb{P}\\left(f_{B}(x)=2|Z^{n}\\right)=\\frac{1}{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where we overload the notation $\\mathbb{P}$ to denote conditional probability of $B|Z^{n}$ . ", "page_idx": 19}, {"type": "text", "text": "Then the optimal decision rule for predicting $_B$ based on sample $Z^{n}$ is: ", "page_idx": 19}, {"type": "equation", "text": "$$\ng(x;Z^{n})=\\left\\{\\begin{array}{l l}{{\\widetilde{Y}}_{i}}&{x=X_{i},i\\in\\{1,2,\\ldots,n\\}}\\\\ {1}&{x=x_{V}}\\\\ {\\mathrm{random~guess~from~}\\{1,2\\}}&{x\\neq X_{1},\\ldots,x\\neq X_{n},x\\neq x_{V}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, the error comes from the probability of $X\\in\\{x_{1},\\ldots,x_{V}\\}$ not being one of the observed $X_{i}$ : for any $\\hat{f}$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\nabla_{\\theta,x}\\left\\{\\widetilde{\\mu}_{t}(f)\\right\\}=}&{\\mathbf{g}_{r}\\left(\\mathrm{b}_{\\theta,x}\\right)\\int_{0}^{\\infty}\\int_{\\mathbb R^{3}}{\\Big[\\int_{(\\theta,\\theta)}f\\Big(h_{t,t}\\Big)\\Big]\\times}\\theta\\Big[\\theta\\Big]}\\\\ &{\\geq\\mathbf{g}_{r}(\\mathrm{b}_{\\theta,x})\\Big(g_{r}(\\mathrm{b}_{\\theta,x})\\Big)\\times}\\\\ &{=\\Big(1-\\frac{1}{2}\\Big)^{p}\\nabla(\\mathcal{N})\\times\\theta_{1,x}\\Big(\\mathrm{b}_{\\theta,x})\\int_{0}^{\\infty}f\\Big(h_{t,x}\\Big)}\\\\ &{=\\Big(1-\\frac{1}{2}\\Big)^{p}\\nabla(\\mathcal{N})\\times\\theta_{1,x}\\Big(\\mathrm{b}_{\\theta,x})\\int_{0}^{\\infty}f\\Big(h_{t,x}\\Big)}\\\\ &{\\quad-\\frac{1}{2}\\underset{0}{\\overset{p}{\\sum}}\\Big(\\nabla(\\mathcal{N})\\times\\mathrm{b}_{\\theta_{1,x}}\\mathrm{b}_{\\theta,x}\\Big(\\mathrm{b}_{\\theta,x})\\Big)}\\\\ &{=\\frac{1}{2}\\underset{0}{\\overset{p}{\\sum}}\\Big[\\theta\\Big(\\mathcal{N})\\times\\mathrm{b}_{\\theta_{1,x}}\\Big(\\mathrm{b}_{\\theta,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big)\\Big)\\times\\mathrm{d}\\theta_{1,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big)}\\\\ &{=\\frac{1}{2}\\underset{0}{\\overset{p}{\\sum}}\\Big[\\theta\\Big(\\mathcal{N})\\times\\mathrm{f}_{0,\\theta}\\Big(\\mathrm{b}_{\\theta,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big)\\Big)\\times\\mathrm{d}\\theta_{1,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big)}\\\\ &{=\\frac{1}{2}\\underset{0}{\\overset{p}{\\sum}}\\Big[\\theta\\Big(\\mathcal{N})\\times\\mathrm{f}_{0,\\theta}\\Big(\\mathrm{b}_{\\theta,x}\\Big(\\mathrm{b}_{\\theta,x}\\Big)\\Big)\\Big]}\\\\ &{=\\frac{1}{2}\\underset{0}{\\overset{p}{\\sum}}\\Big[\\theta\\Big(\\mathcal{N})\\times\\mathrm{f}_{0,\\theta}\\Big(\\mathrm{b}_{\\theta,x}\\Big( \n$$$$\n{\\begin{array}{r l}&{{\\frac{1}{n}}\\sum_{i=1}^{n}\\left(X_{i}\\right)+\\varepsilon_{n+\\cdots}\\ldots+X_{n}\\varepsilon_{n}\\varepsilon_{n}X-x_{i}\\right)}\\\\ &{={\\frac{1}{2}}\\sum_{j=1}^{n}\\gamma\\left(X_{i}\\right)+\\varepsilon_{n+\\cdots}\\ldots\\sum_{\\varepsilon_{n}}\\varepsilon_{n}|X=x_{i}\\right)\\gamma\\left(X=x_{i}\\right)}\\\\ &{={\\frac{1}{2}}\\sum_{i=1}^{n}\\left(X_{i}\\right)+\\varepsilon_{n}\\ldots\\ldots\\sum_{\\varepsilon_{n}}\\varepsilon_{n}|X=x_{i}\\right)}\\\\ &{={\\frac{1}{2}}\\sum_{j=1}^{n}\\left(1-\\gamma\\left(X_{i}\\right)\\varepsilon_{n}\\varepsilon_{n+\\cdots}\\right)^{\\gamma}\\left(X=x_{i}\\right)}\\\\ &{={\\frac{1}{2}}(\\nu-1)\\left(1-\\gamma\\left(X_{i}-1\\right)^{\\varepsilon_{n}}\\right)}\\\\ &{=\\left({\\frac{\\nu-1}{2}}\\right)\\left(1-\\gamma\\left(1-\\gamma\\right)^{\\varepsilon_{n}}\\right)}\\\\ &{={\\frac{(\\nu-1)(1-\\varepsilon_{n})}{2}}\\left(1-\\left(1-{\\frac{1-\\varepsilon_{n})^{\\varepsilon_{n}}}{n}}\\right)^{\\nu}}\\\\ &{={\\frac{(\\nu-1)(1-\\varepsilon_{n})}{2n}}\\left(1-{\\frac{1-\\varepsilon_{n}}{n}}\\right)^{1/4}\\left(1-{\\frac{1-\\varepsilon_{n}}{n}}\\right)^{\\nu-1}}\\\\ &{\\geq{\\frac{(\\nu-1)(1-\\varepsilon_{n})}{2n}}\\left(1-{\\frac{1-\\varepsilon_{n})^{\\varepsilon_{n}}}{1-\\varepsilon_{n}}}\\right)^{1/4}e^{-1\\varepsilon_{n}}\\quad\\gamma\\left(1-{\\frac{1-\\varepsilon_{n}}{n}}\\right)^{n-1}\\varepsilon^{-1}}\\\\ &{\\geq{\\frac{(\\nu-1)(1-\\varepsilon_{n})}{2n}}\\left(1-{\\frac{1-\\varepsilon_{n}}{n}}\\right)^{2}e^{-1}}\\\\ &{\\geq{\\frac{(\\nu-1)(1-\\varepsilon_{n})}{2n}}\\left(1-{\\frac{1-\\varepsilon_{n})^{\\varepsilon_{n}}}{2n}}\\varepsilon^{-1}\\quad\\quad\\forall\\left( \n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now we get the minimax risk for the second part (6) ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{sup}_{b,\\delta}\\,\\mathbb{E}_{Z^{n}}\\left[R_{A_{\\kappa}}\\left(\\hat{f}\\right)-R_{A_{\\kappa}}(f^{*})\\right]\\geq\\displaystyle\\operatorname*{sup}_{\\delta}\\,\\frac{1}{\\kappa+\\delta}\\frac{(V-1)(1-\\epsilon)}{8e n}}&{}\\\\ {\\geq\\displaystyle\\frac{1}{\\kappa}\\frac{(V-1)(1-\\epsilon)}{8e n}}&{\\mathrm{let}\\,\\delta\\downarrow0}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Combine the two parts together, we get the final result, for $n>\\operatorname*{max}(V-1,2)$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa,V,0)}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\frac{K-1}{K}\\epsilon+\\frac{1}{\\kappa}\\frac{(V-1)(1-\\epsilon)}{8e n}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "As for the general version of the lower bound, now consider the set of triples: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Pi(\\epsilon,\\kappa,V,L):=\\left\\{\\,(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}}):\\!P_{X}\\!\\left(\\pmb{\\mathcal{A}}_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\pmb{\\eta}}\\right)\\right)\\geq1-\\epsilon,\\right.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\begin{array}{r}{\\widetilde{R}_{C}(f)=\\int_{C}\\left(1-[\\widetilde{\\eta}(x)]_{f(x)}\\right)d P_{X}(x).}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "Theorem (Minimax Lower Bound (General Version)) L $\\begin{array}{r}{\\begin{array}{r}{e t\\,\\epsilon\\in[0,1],\\kappa>0,V>1,L\\in(0,1/2).}\\end{array}}\\end{array}$ For any learning rule $\\hat{f}$ based upon $Z^{n}=\\left\\{(X_{i},\\widetilde{Y}_{i})\\right\\}_{i=1}^{n},$ , for $\\begin{array}{r}{n\\ge\\frac{V-1}{2L}\\operatorname*{max}\\left\\{16,\\frac{1}{(1-2L)^{2}}\\right\\}}\\end{array}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\left(P_{X},\\eta,\\tilde{\\eta}\\right)\\in\\Pi\\left(\\epsilon,\\kappa\\right)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R\\big(f^{*}\\big)\\right]\\geq\\underset{\\left(P_{X},\\eta,\\tilde{\\eta}\\right)\\in\\Pi\\left(\\epsilon,\\kappa,V,L\\right)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R\\big(f^{*}\\big)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\geq\\frac{K-1}{K}\\epsilon+\\frac{1-\\epsilon}{\\kappa}\\sqrt{\\frac{(V-1)L}{2n}}e^{-7}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\frac{K-1}{K}\\epsilon+\\Omega\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{1}{n}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. ", "page_idx": 21}, {"type": "text", "text": "Now we construct a triple $(P_{X},\\eta,\\tilde{\\eta})$ that is parameterized by $j,b:=\\left[b_{1}\\;b_{2}\\;\\cdot\\cdot\\cdot\\;b_{V-1}\\right]^{\\intercal}$ , $\\delta$ , $c$ and $p$ . First, we define $P_{X}$ . Pick any $V+1$ distinct points $x_{0},x_{1},\\ldots,x_{V}$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\nP_{X}(x)={\\binom{\\epsilon}{(1-\\epsilon)\\cdot p}}{\\begin{array}{l l}{P_{X}(x)=x_{0}}\\\\ {x=x_{1},\\ldots,x_{V-1}}\\\\ {(1-\\epsilon)\\cdot(1-(V-1)p)}&{x=x_{V}.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This imposes the constraint $(V-1)p\\,\\leq\\,1$ , which will be satisfied in the end. Notice the difference compared to the previous zero-error proof: we place probability mass $p$ , rather than $1/n$ , on $x_{1},\\dots,x_{V-1}$ . ", "page_idx": 21}, {"type": "text", "text": "As for the clean and noisy class probabilities, choose ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Bar{\\mathbf{\\Psi}}:x=x_{0},\\hbar\\mathbf{Re}\\,\\,\\eta(x)=e_{j},\\ \\ \\Bar{\\eta}(x)=e_{1},\\ \\ j\\in\\{1,2,...,k\\}}&{{}}\\\\ {\\Bar{\\mathbf{\\Psi}}}&{:=\\Bar{\\mathbf{\\Psi}}(x)=\\Bar{\\mathbf{\\Psi}}(x)=\\left[\\begin{array}{c}{\\left[\\frac{1}{2}+\\frac{e_{k}}{\\kappa+\\delta},\\ \\left(-1\\right)^{k+1}\\right]}\\\\ {\\frac{1}{2}-\\frac{e_{k}+\\delta}{\\kappa+\\delta},\\left(-1\\right)^{k+1}}\\\\ {\\vdots}\\\\ {\\left[\\begin{array}{c}{0}\\\\ {0}\\end{array}\\right]}\\end{array}\\right],\\ \\boldsymbol{\\Tilde{\\eta}}(x)=\\left[\\begin{array}{c}{\\left[\\frac{1}{2}+e_{x}\\cdot\\left(-1\\right)^{k+1}\\right]^{2}}\\\\ {\\frac{1}{2}-e_{x}\\cdot\\left(-1\\right)^{k+1}}\\\\ {0}\\end{array}\\right],}\\\\ {\\Bar{b}_{t}\\in\\{1,2\\},\\ \\delta>0,\\ c\\in\\left(0,\\frac{1}{2}\\right)}&{{}}\\\\ {\\boldsymbol{\\Psi}}&{:=\\Bar{\\mathbf{\\Psi}}(x),\\hbar\\mathbf{Re}\\,\\,\\eta(x)=\\left[\\begin{array}{c}{\\left[\\frac{1}{2}+\\frac{1}{2}\\frac{e_{k}}{\\kappa+\\delta}\\right]}\\\\ {\\vdots}\\\\ {0}\\end{array}\\right],}\\\\ {\\boldsymbol{\\Psi}}&{:=x_{V},\\hbar\\mathbf{Re}\\,\\,\\eta(x)=\\left[\\begin{array}{c}{\\left[\\begin{array}{c}{0}\\\\ {-1}\\\\ {0}\\end{array}\\right]}\\\\ {\\left[\\begin{array}{c}{\\left[\\begin{array}{c}{0}\\\\ {\\vdots}\\\\ {0}\\end{array}\\right]}\\end{array}\\right],\\ \\boldsymbol{\\Tilde{\\eta}}(x)=e_{1},\\ \\ 0\\leq e_{1},}\\\\ {\\vdots}\\end{array}\\right]}&{{}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $e_{i}$ denotes the one-hot vector whose $i$ -th element is one. ", "page_idx": 21}, {"type": "text", "text": "The construction for class posterior is also similar to the previous proof, except that for $x=$ $x_{t},t\\in\\{1,\\ldots,V-1\\}$ , $\\widetilde{\\pmb{\\eta}}$ is no longer a one-hot vector, rather has class probability separated by $2c$ : $\\left|\\left[\\widetilde{\\pmb{\\eta}}(x)\\right]_{1}-[\\widetilde{\\pmb{\\eta}}(x)]_{2}\\right|=2c.$ . ", "page_idx": 21}, {"type": "text", "text": "Therefore, the triple $(P_{X},\\eta,\\tilde{\\eta})$ can be parameterized by $j,b:=\\left[b_{1}\\;b_{2}\\;\\cdot\\cdot\\cdot\\;b_{V-1}\\right]^{\\top}$ , $\\delta,c$ and $p$ . Again, this construction ensu r es $(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)$ , to be specific: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{A_{\\kappa}\\supseteq\\{x_{1},x_{2},\\ldots,x_{V}\\},\\qquad\\qquad\\qquad}&{P_{X}(\\mathcal{A}_{\\kappa})\\geq1-\\epsilon,}\\\\ &{\\chi\\vee\\mathcal{A}_{\\kappa}\\subseteq\\{x_{0}\\},\\qquad\\qquad\\qquad}&{P_{X}(\\chi\\vee\\mathcal{A}_{\\kappa})\\leq\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For any classifier $f$ , its risk can be decomposed into two parts ", "page_idx": 22}, {"type": "equation", "text": "$$\nR\\left(f\\right)=\\underbrace{\\int_{\\{x_{0}\\}}\\left(1-\\left[\\eta(x)\\right]_{f(x)}\\right)d P_{X}(x)}_{:=R_{0}(f)}+\\underbrace{\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\left(1-\\left[\\eta(x)\\right]_{f(x)}\\right)d P_{X}(x)}_{:=R_{V}(f)},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "as can its excess risk ", "page_idx": 22}, {"type": "equation", "text": "$$\nR\\left(f\\right)-R(f^{*})=\\Big(R_{0}\\left(f\\right)-R_{0}(f^{*})\\Big)+\\Big(R_{V}\\Big(f\\Big)-R_{V}(f^{*})\\Big).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In our construction, $(P_{X},\\eta,\\widetilde{\\eta})$ is parameterized by $j,b:=\\left[b_{1}\\;b_{2}\\;\\cdot\\cdot\\cdot\\;b_{V-1}\\right]^{\\top}$ , \u03b4, $c$ and $p$ , therefore ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa,V,L)}{\\operatorname*{sup}}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\underset{j}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[R_{0}\\left(\\hat{f}\\right)-R_{0}(f^{*})\\right]}\\\\ &{\\phantom{\\exp x}+\\underset{b,\\delta,c,p}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(f)-\\widetilde{R}_{V}(\\tilde{f}^{*})\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that we have used the fact that ", "page_idx": 22}, {"type": "text", "text": "where ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{R_{V}(f)-R_{V}(f^{*})=\\displaystyle\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(f)-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right),}}\\\\ {{{}}}\\\\ {{\\displaystyle):=\\int_{\\{x_{1},\\dots,x_{V}\\}}\\left(1-[\\widetilde{\\eta}(x)]_{f(x)}\\right)d P_{X}(x).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The first part (10) is exactly the same as in the zero-error proof, and we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{j}\\,\\mathbb{E}_{Z^{n}}\\left[R_{0}\\left({\\hat{f}}\\right)-R_{0}(f^{*})\\right]\\geq\\left(1-{\\frac{1}{K}}\\right)\\epsilon.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "From this point forward, the procedure is similar to the proof of Devroye et al. [1996, Theorem 14.5]. For the second part (11), the noisy Bayes classifier is still ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tilde{f}^{*}(x)=\\left\\{\\!\\!\\begin{array}{l l}{{j}}&{{x=x_{0},}}\\\\ {{b_{t}}}&{{x=x_{t},\\;1\\leq t\\leq V}}\\\\ {{1}}&{{x=x_{V}.}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We also use the shorthand $f_{b}:=\\tilde{f}^{*}$ to denote that the noisy Bayes classifier depends on $^{b}$ . Now the noisy Bayes risk is no longer zero. In fact ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\widetilde{R}_{V}(\\widetilde{f}^{*})=\\int_{\\{x_{1},\\ldots,x_{V}\\}}\\left(1-[\\widetilde{\\eta}(x)]_{f(x)}\\right)d P_{X}(x)=(V-1)(1-\\epsilon)p\\left(\\frac{1}{2}-c\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "What\u2019s more, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{\\widetilde{R}_{A_{\\kappa}}\\left(\\widetilde{f}^{*}\\right)}{P_{X}\\left(A_{\\kappa}\\left(\\eta,\\widetilde{\\eta}\\right)\\right)}\\leq\\frac{\\widetilde{R}_{V}(\\widetilde{f}^{*})}{P_{X}\\Big(\\left\\{x_{1},\\ldots,x_{V}\\right\\}\\Big)}=(V-1)p\\left(\\frac{1}{2}-c\\right),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the inequality holds from $\\widetilde{R}_{A_{\\kappa}}(\\widetilde{f}^{*})\\;=\\;\\widetilde{R}_{V}(\\widetilde{f}^{*})$ (because $\\widetilde{\\pmb{\\eta}}$ is one-hot at point $x_{0}$ ) and $P_{X}\\Big(A_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\pmb{\\eta}}\\right)\\Big)\\geq P_{X}\\Big(\\left\\{x_{1},\\ldots,x_{V}\\right\\}\\Big)$ . ", "page_idx": 22}, {"type": "text", "text": "Notice that in order to ensure that our construction $(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})\\in\\Pi(\\epsilon,\\kappa,V,L)$ , by definition ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{\\widetilde{R}_{\\mathcal{A}_{\\kappa}}\\left(\\widetilde{f}^{*}\\right)}{P_{X}\\left(\\mathcal{A}_{\\kappa}\\left(\\eta,\\widetilde{\\eta}\\right)\\right)}\\leq L,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Due to the upper bound of (12), it suffices to require that ", "page_idx": 23}, {"type": "equation", "text": "$$\n(V-1)p\\left({\\frac{1}{2}}-c\\right)=L,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and this ensures that $(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})\\in\\Pi(\\epsilon,\\kappa,V,L)$ upon recalling that $(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)$ , and that $P_{X}$ is supported on $V+1$ po i nts. ", "page_idx": 23}, {"type": "text", "text": "It should be noted that since $(V-1)p\\leq1$ is required, and since $c>0$ , we have $L<1\\cdot1/2$ . This is the origin of our condition $L<1/2$ in the statement of the theorem. Naturally, the statement can be adjusted to $\\operatorname*{min}(L,1/2)$ instead. In any case, we are left with two nontrivial constraint on our parameters $(p,c)$ : (13) and $(V-1)p\\leq1$ , along with the boundary consraints $p\\in[0,1]$ and $c\\in[0,1/2]$ . ", "page_idx": 23}, {"type": "text", "text": "For fixed $^{b}$ , plugging in the definition of $\\widetilde{\\pmb{\\eta}}$ , the excess risk over region $\\{x_{1},\\ldots,x_{V}\\}$ becomes ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\widetilde{R}_{V}(\\hat{f})-\\widetilde{R}_{V}(\\tilde{f}^{*})=\\int_{\\{x_{1},\\ldots,x_{V}\\}}2c\\mathbb{1}_{\\hat{f}(x)\\neq f_{b}(x)}d P_{X}(x)}}\\\\ &{}&{\\ge2c\\sum_{t=1}^{V-1}(1-\\epsilon)p\\mathbb{1}_{\\hat{f}(x_{t})\\neq f_{b}(x_{t})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the inequality follows from the fact that we ignore the risk on point $x_{V}$ . ", "page_idx": 23}, {"type": "text", "text": "Using the probabilistic method, replace $^{b}$ with $B\\sim\\mathrm{Uniform}\\{1,2\\}^{V-1}.$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{sup}_{b,\\delta,c,p}\\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(\\hat{f})-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right)\\right]\\ge\\operatorname*{sup}_{\\delta,c,p}\\mathbb{E}_{B,Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{V}(\\hat{f})-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right)\\right]}&{}\\\\ {=\\displaystyle\\operatorname*{sup}_{\\delta,c,p}\\frac{1}{\\kappa+\\delta}\\mathbb{E}_{Z^{n}}\\left[\\mathbb{E}_{B|Z^{n}}\\left[\\left(\\widetilde{R}_{V}(\\hat{f})-\\widetilde{R}_{V}(\\widetilde{f}^{*})\\right)\\right]\\right]}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Now, we need to calculate $B|Z^{n}$ , which can be calculated using Bayes rule because we have $B\\sim\\mathrm{Uniform}\\{1,2\\}^{V-1}$ and also $Z^{n}|B\\sim P_{X\\tilde{Y}}^{\\otimes n}$ . ", "page_idx": 23}, {"type": "text", "text": "To be specific, for any $x\\in\\left\\{x_{0},x_{1},\\ldots,x_{V-1}\\right\\}$ , assume point $x_{t}$ is observed $k$ times in training sample $Z^{n}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(f_{B}(x)=1|Z^{n}\\right)=\\left\\{\\frac{1}{2}\\begin{array}{l l}{}&{x\\neq X_{1},\\ldots,x\\neq X_{n},x\\neq x_{V}}\\\\ {\\mathbb{P}\\left(B_{t}=1|Y_{t_{1}},\\ldots,Y_{t_{k}}\\right)}&{x=x_{t}=X_{t_{1}}=\\cdots=X_{t_{k}},\\;1\\leq t\\leq V-1,}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $B_{t}$ denotes the $t$ -th element of vector $_B$ (that associates with $x_{t}$ ). ", "page_idx": 23}, {"type": "text", "text": "Next we compute $\\mathbb{P}\\left(B_{t}=1|Y_{t_{1}}=y_{1},\\ldots,Y_{t_{k}}=y_{k}\\right)$ for $y_{1},\\ldots,y_{k}\\in\\{1,2\\}$ . Denote the numbers of ones and twos by $k_{1}=|\\{j\\leq k:y_{j}=1\\}|$ and $k_{2}=|\\{j\\leq k:y_{j}=2\\}|$ . Using Bayes rule, we get ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(B_{t}=1|Y_{t_{1}},\\ldots,Y_{t_{k}}\\right)=\\frac{\\mathbb{P}\\left(B_{t}=1\\cap Y_{t_{1}},\\ldots,Y_{t_{k}}\\right)}{\\mathbb{P}\\left(Y_{t_{1}},\\ldots,Y_{t_{k}}\\right)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\frac{\\mathbb{P}\\left(Y_{t_{1}},\\ldots,Y_{t_{k}}|B_{t}=1\\right)\\mathbb{P}\\left(B_{t}=1\\right)}{\\sum_{i=1}^{2}\\mathbb{P}\\left(Y_{t_{1}},\\ldots,Y_{t_{k}}|B_{t}=i\\right)\\mathbb{P}\\left(B_{t}=i\\right)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(1/2+c)^{k_{1}}(1/2-c)^{k_{2}}(1/2)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(1/2+c)^{k_{1}}(1/2)+(1/2+c)^{k_{2}}(1/2-c)^{k_{1}}(1/2)}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "After some calculation, following the proof of Devroye et al. [1996, Theorem 14.5], we get ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{b,\\delta,c,p}{\\operatorname*{sup}}\\ \\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{A_{\\kappa}}(f)-\\widetilde{R}_{A_{\\kappa}}(\\tilde{f}^{*})\\right)\\right]}\\\\ &{\\qquad\\qquad\\geq\\underset{\\delta,c,p}{\\operatorname*{sup}}\\ \\frac{1}{\\kappa+\\delta}c(V-1)(1-\\epsilon)p e^{-\\frac{8n(1-\\epsilon)p c^{2}}{1-2c}-\\frac{4c\\sqrt{n(1-\\epsilon)p}}{1-2c}}}\\\\ &{\\qquad\\geq\\frac{1-\\epsilon}{\\kappa}\\underset{c,p}{\\operatorname*{sup}}c(V-1)p e^{-\\frac{8n p c^{2}}{1-2c}-\\frac{4c\\sqrt{n p}}{1-2c}}\\quad\\because\\epsilon\\geq0,\\ \\mathrm{take}\\ \\delta\\downarrow0}\\\\ &{\\qquad=\\frac{1-\\epsilon}{\\kappa}\\underset{c,p}{\\operatorname*{sup}}c\\,\\frac{L}{1/2-c}e^{-\\frac{8n p c^{2}}{1-2c}-\\frac{4c\\sqrt{n p}}{1-2c}},\\qquad\\because\\left(13\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the supremum is over $(p,c)\\in[0,1]\\times[0,1/2]$ such that ", "page_idx": 24}, {"type": "text", "text": "Now, suppose $n$ is so large that ", "page_idx": 24}, {"type": "equation", "text": "$$\nn\\geq\\frac{(V-1)}{8L(1/2-L)^{2}}\\iff L\\leq\\frac{1}{2}-\\sqrt{\\frac{(V-1)}{8n L}},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and further that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sqrt{\\frac{(V-1)}{8n L}}\\leq\\frac{1}{8}\\iff n\\geq\\frac{8(V-1)}{L}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We choose ", "page_idx": 24}, {"type": "equation", "text": "$$\nc={\\sqrt{\\frac{(V-1)}{8n L}}},\\;\\mathrm{and}\\;p={\\frac{L}{(V-1)(1/2-c)}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By our choice of $c$ and the first condition on $n$ above, we can conclude that $L\\,\\leq\\,(1/2-c)$ , and therefore, ", "page_idx": 24}, {"type": "equation", "text": "$$\n(V-1)p=\\frac{L}{1/2-c}\\leq1,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "meaning that both the constraints required on $(p,c)$ are met by the above choice. ", "page_idx": 24}, {"type": "text", "text": "As a consequence of this choice of $c,p$ , we observe that ", "page_idx": 24}, {"type": "equation", "text": "$$\nn p c^{2}={\\frac{n L}{(V-1)(1/2-c)}}\\cdot c^{2}={\\frac{n L}{(V-1)(1/2-c)}}\\cdot{\\frac{(V-1)}{8n L}}={\\frac{1}{4-8c}}\\leq{\\frac{1}{3}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $c\\leq1/8$ further implies that $\\begin{array}{r}{\\frac{1}{1-2c}\\leq\\frac{4}{3}}\\end{array}$ , this implies that ", "page_idx": 24}, {"type": "equation", "text": "$$\n{\\frac{8n p c^{2}}{1-2c}}+{\\frac{4{\\sqrt{n p c^{2}}}}{1-2c}}\\leq{\\frac{8}{3}}\\cdot{\\frac{4}{3}}+4\\cdot{\\frac{4}{3}}\\cdot{\\sqrt{\\frac{1}{3}}}\\leq7.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, instantiating the bound (14), we conclude that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{sup}_{b,\\delta,c,p}\\mathbb{E}_{Z^{n}}\\left[\\frac{1}{\\kappa+\\delta}\\left(\\widetilde{R}_{A_{\\kappa}}(f)-\\widetilde{R}_{A_{\\kappa}}(\\tilde{f}^{*})\\right)\\right]\\ge\\frac{1-\\epsilon}{\\kappa}\\cdot\\sqrt{\\frac{V-1}{8n L}}\\cdot\\frac{L}{1/2-c}\\cdot e^{-7}}&{}\\\\ {\\ge\\frac{1-\\epsilon}{\\kappa}\\sqrt{\\frac{(V-1)L}{8n}}e^{-7}\\cdot2}&{}\\\\ {=\\displaystyle\\frac{1-\\epsilon}{\\kappa}\\sqrt{\\frac{(V-1)L}{2n}}e^{-7}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Putting the two parts together ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\left(P_{X},\\eta,\\tilde{\\eta}\\right)\\in\\Pi(\\epsilon,\\kappa)}\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\geq\\frac{K-1}{K}\\epsilon+\\frac{1-\\epsilon}{\\kappa}\\sqrt{\\frac{(V-1)L}{2n}}e^{-7},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "for $\\begin{array}{r}{n\\ge\\frac{V-1}{2L}\\operatorname*{max}\\left\\{16,\\frac{1}{(1-2L)^{2}}\\right\\}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "A.2.4 Proof of upper bound: Lemma 1 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Lemma (Oracle Inequality under Feature-dependent Label Noise) For any $(P_{X},\\eta,\\tilde{\\eta})$ and any classifier $f$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\nR(f)-R(f^{*})\\leq\\operatorname*{inf}_{\\kappa>0}\\left\\{P_{X}\\Big(X\\setminus A_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\eta}\\right)\\Big)+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\widetilde{f}^{*}\\right)\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. For any $\\kappa\\geq0$ , the input space $\\mathcal{X}$ can be divided into two regions: $\\mathcal{X}\\setminus\\mathcal{A}_{\\kappa}$ and $\\mathcal{A}_{\\kappa}$ . For any $f$ , its risk is ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{~}&{R\\left(f\\right)=\\mathbb{E}_{X,Y}\\left[\\mathbb{1}_{f\\left(X\\right)\\neq Y}\\right]}\\\\ {~}&{~~~~~=\\mathbb{E}_{X}\\mathbb{E}_{Y\\mid X}\\big[\\mathbb{1}_{f\\left(X\\right)\\neq Y}\\big]}\\\\ {~}&{~~~~=\\mathbb{E}_{X}\\mathbb{E}_{Y\\mid X}\\big[1-\\mathbb{1}_{f\\left(X\\right)=Y}\\big]}\\\\ {~}&{~~~~=\\mathbb{E}_{X}\\left[1-\\left[\\eta(X)\\right]_{f\\left(X\\right)}\\right]}\\\\ {~}&{~~~~=\\int_{\\mathcal{X}}\\left(1-\\left[\\eta(x)\\right]_{f\\left(x\\right)}\\right)d P_{X}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Therefore, its excess risk is ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(f)-R(f^{*})=\\int_{\\mathcal{X}}\\Big(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\Big)\\;d P_{X}(x)}\\\\ &{=\\underbrace{\\int_{\\mathcal{X}\\backslash\\mathcal{A}_{\\kappa}}\\Big(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\Big)\\;d P_{X}(x)}_{\\textcircled{4}}}\\\\ &{\\qquad\\qquad+\\underbrace{\\int_{\\mathcal{A}_{\\kappa}}\\Big(\\operatorname*{max}\\eta(x)-[\\eta(x)]_{f(x)}\\Big)\\;d P_{X}(x)}_{\\textcircled{6}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Now examine the two terms separately, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\circledast\\leq\\int_{\\mathcal{X}\\backslash A_{\\kappa}}1\\;d P_{X}(x)=P_{X}\\Big(\\mathcal{X}\\backslash A_{\\kappa}\\left(\\eta,\\widetilde{\\eta}\\right)\\Big),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{\\odot}<\\int_{A_{\\kappa}}\\frac{1}{\\kappa}\\Big(\\operatorname*{max}\\tilde{\\eta}(x)-[\\tilde{\\eta}(x)]_{f(x)}\\Big)\\ d P_{X}(x)}}&{\\ddots\\mathrm{by~definition~of~relative~signal~strength}}\\\\ &{\\le\\int_{x}\\frac{1}{\\kappa}\\Big(\\operatorname*{max}\\tilde{\\eta}(x)-[\\tilde{\\eta}(x)]_{f(x)}\\Big)\\ d P_{X}(x)}\\\\ &{=\\frac{1}{\\kappa}\\left(\\tilde{R}(f)-\\tilde{R}(\\tilde{f}^{*})\\right)\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\mathrm{by~definition~of~}\\tilde{R}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since this works for any $\\kappa>0$ , we then have ", "page_idx": 25}, {"type": "equation", "text": "$$\nR(f)-R(f^{*})\\leq\\operatorname*{inf}_{\\kappa>0}\\left\\{P_{X}\\Big(X\\setminus A_{\\kappa}\\left(\\pmb{\\eta},\\widetilde{\\eta}\\right)\\Big)+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\widetilde{f}^{*}\\right)\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "A.2.5 Proof of upper bound: Theorem 2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "To set the stage for the rate of convergence proof, we first introduce the concept of shattering in the multiclass setting and the Natarajan dimension [Natarajan, 1989], which serves as a multiclass counterpart to the VC dimension [Vapnik and Chervonenkis, 1971]. ", "page_idx": 25}, {"type": "text", "text": "Definition 4 (Multiclass Shattering) Let $\\mathcal{H}$ be a class of functions from $\\mathcal{X}$ to $\\mathcal{V}=\\{1,2,\\ldots,K\\}$ . For any set containing $n$ distinct elements $C_{n}=\\{x_{1},\\ldots,x_{n}\\}\\subset{\\mathcal{X}}$ , denote ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{H}_{C_{n}}=\\left\\{(h(x_{1}),\\dots,h(x_{n})):h\\in\\mathcal{H}\\right\\},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and therefore $\\left|\\mathcal{H}_{C_{n}}\\right|$ is the number of distinct vectors of length n that can be realized by functions in $\\mathcal{H}$ . ", "page_idx": 26}, {"type": "text", "text": "The $n^{t h}$ shatter coefficient is defined as ", "page_idx": 26}, {"type": "equation", "text": "$$\nS(\\mathcal{H},n):=\\operatorname*{max}_{C_{n}}\\left|\\mathcal{H}_{C_{n}}\\right|.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We say that a set $C_{n}$ is shattered by $\\mathcal{H}$ if there exists $f,g:C_{n}\\to\\mathcal{Y}$ such that for every $x\\in C_{n}$ , $f(x)\\neq g(x)$ , and ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{H}_{C}\\supseteq\\{f(x_{1}),g(x_{1})\\}\\times\\{f(x_{2}),g(x_{2})\\}\\times\\dots\\times\\{f(x_{n}),g(x_{n})\\}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "If $\\mathcal{D}=\\{1,2\\}$ , this definition reduces to the binary notion of shattering which says all labeling of points can be realized by some function in the hypothesis class $\\mathcal{H}$ , i.e., $\\mathcal{H}_{C}=\\{1,2\\}^{|C|}$ . Note that multiclass shattering does not mean being able to realize all $K$ possible labels for each point $x\\in C$ . Instead, multiclass shattering is more like \u201cembed the binary cube into multiclass\u201d, where every $x\\in C$ is allowed to pick from two of the $K$ labels. ", "page_idx": 26}, {"type": "text", "text": "Definition 5 (Natarajan Dimension) The Natarajan dimension of $\\mathcal{H}$ , denoted Ndim $\\mathcal{H})$ , is the maximal size of a shattered set $C\\in\\mathcal X$ . ", "page_idx": 26}, {"type": "text", "text": "Theorem (Excess Risk Upper Bound of NI-ERM) Let $\\epsilon\\in[0,1],\\kappa\\in(0,+\\infty)$ . Consider any $(P_{X},\\eta,\\widetilde{\\eta})\\in\\Pi(\\epsilon,\\kappa),$ , assume function class $\\mathcal{F}$ has Natarajan dimension $V$ , and the noisy Bayes classifie r $\\tilde{f}^{*}$ belongs to $\\mathcal{F}$ . Let ${\\hat{f}}\\in{\\mathcal{F}}$ be the ERM trained on $Z^{n}=\\left\\{(X_{i},{\\widetilde{Y}}_{i})\\right\\}_{i=1}^{n},$ , then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\leq\\epsilon+\\frac{1}{\\kappa}\\cdot16\\sqrt{\\frac{V\\log n+2V\\log k+4}{2n}}}\\\\ {=\\epsilon+\\mathcal{O}\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{V}{n}}\\right)\\quad u p\\:t o\\:l o g\\:f\\!a c t o r.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. Following directly from Lemma 1, with $(P_{X},\\eta,\\tilde{\\eta})\\in\\Pi(\\epsilon,\\kappa)$ , we already have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(f)-R(f^{*})\\leq P_{X}\\Big(X\\mathbin{\\vrule{\\chi\\vrule{\\chi}}}\\lvert\\mathcal{A}_{\\kappa}\\left(\\eta,\\widetilde{\\eta}\\right)\\Big)+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\widetilde{f}^{*}\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\epsilon+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\widetilde{f}^{*}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Now replace $f$ with $\\operatorname{NI-ERM}{\\hat{f}}$ . To bound the expected excess risk we employ a multiclass VC-style inequality. ", "page_idx": 26}, {"type": "text", "text": "Lemma 2 ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z^{n}}\\left[\\widetilde{R}\\left(\\hat{f}\\right)-\\widetilde{R}\\left(\\tilde{f}^{*}\\right)\\right]\\le16\\sqrt{\\frac{\\log(8e S(\\mathcal{H},n))}{2n}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The binary version of this lemma is Corollary 12.1 in Devroye et al. [1996]. We prove the multiclass version below in Section A.2.6. ", "page_idx": 26}, {"type": "text", "text": "Next, we bound the multiclass shattering coefficient with Natarajan dimension, using the following lemma, which can be viewed as a multiclass version of Sauer\u2019s lemma. ", "page_idx": 26}, {"type": "text", "text": "Lemma 3 (Natarajan [1989]) Let $C$ and $\\boldsymbol{\\wp}$ be two finite sets and let $\\mathcal{H}$ be a set of functions from $C$ to . Then ", "page_idx": 26}, {"type": "equation", "text": "$$\n|\\mathcal{H}|\\leq|C|^{N d i m(\\mathcal{H})}\\cdot|\\mathcal{V}|^{2N d i m(\\mathcal{H})}\\,.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Letting $V$ denote $\\operatorname{Ndim}({\\mathcal{H}})$ , we have that $S(\\mathcal{H},n)\\leq n^{V}K^{2V}$ , and therefore Lemma 2 can be upper bounded by ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{Z^{n}}\\left[\\widetilde{R}\\left(\\hat{f}\\right)-\\widetilde{R}\\left(\\tilde{f}^{*}\\right)\\right]\\le16\\sqrt{\\frac{\\log{\\left(8e(n)^{V}K^{2V}\\right)}}{2n}}}&{}\\\\ {=~16\\sqrt{\\frac{\\log{8e+\\log{\\left(n^{V}\\right)}+\\log{\\left(K^{2V}\\right)}}}{2n}}}\\\\ {\\le16\\sqrt{\\frac{V\\log{n}+2V\\log{K}+4}{2n}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Putting things together, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R(f^{*})\\right]\\leq\\epsilon+\\frac{1}{\\kappa}\\cdot16\\sqrt{\\frac{V\\log n+2V\\log K+4}{2n}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "A.2.6 Proof of Lemma 2 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Theorem 6 Consider any set of multiclass classifiers $\\mathcal{F}$ . Let $(X_{1},Y_{1}),\\ldots,(X_{n},Y_{n})$ be iid draws from $P_{X Y}$ . For any $n_{\\mathrm{:}}$ , and any $\\epsilon>0$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left\\{\\operatorname*{sup}_{f\\in\\mathcal{F}}\\left|R_{n}(f)-R(f)\\right|>\\epsilon\\right\\}\\leq8S(\\mathcal{F},n)e^{-n\\epsilon^{2}/32}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the probability is with respect to the draw of the data. ", "page_idx": 27}, {"type": "text", "text": "Proof. Apply Theorem 12.5 from Devroye et al. [1996], with the following identifications. In what follows, the left-hand side of each equation is a notation from Devroye et al. [1996], and the right-hand side is our notation. ", "page_idx": 27}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{\\nu=P_{X Y}}\\\\ &{Z=(X,Y)}\\\\ &{Z_{i}=(X_{i},Y_{i})}\\\\ &{A=\\{A_{f}\\mid f\\in{\\mathcal{F}}\\},{\\mathrm{~where~}}A_{f}:=\\{(x,y)\\mid f(x)=y\\}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "With these identifications, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\nu(A_{f})=1-R(f)}}\\\\ {{\\displaystyle\\nu_{n}(A_{f})=\\frac{1}{n}\\sum_{i}\\mathbb{1}_{\\{Z_{i}\\in A_{f}\\}}=\\frac{1}{n}\\sum_{i}\\mathbb{1}_{\\{f(X_{i})=Y_{i}\\}}=1-R_{n}(f)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By Theorem 12.5 we conclude ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left\\{\\operatorname*{sup}_{f\\in\\mathcal{F}}\\left|R_{n}(f)-R(f)\\right|>\\epsilon\\right\\}\\leq8s(\\mathcal{A},n)e^{-n\\epsilon^{2}/32},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $s(A,n)$ (note the lowercase \u201cs\u201d) is defined to be ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{z_{1},\\ldots,z_{n}}{\\mathcal{N}}_{A}(z_{1},\\ldots,z_{n})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the max is over points $z_{1},\\ldots,z_{n}$ , and ${\\mathcal{N}}_{A}(z_{1},\\ldots,z_{n})$ is the number of distinct subsets of the form ", "page_idx": 27}, {"type": "equation", "text": "$$\nA_{f}\\cap\\left\\{z_{1},\\ldots,z_{n}\\right\\}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "as $f$ ranges over $\\mathcal{F}$ . ", "page_idx": 27}, {"type": "text", "text": "To conclude the proof, it suffices to show that $s(\\mathcal{A},n)\\leq S(\\mathcal{F},n)$ , where the latter expression is the multiclass shatter coefficient defined above. We show this as follows. ", "page_idx": 27}, {"type": "text", "text": "Consider fixed pairs $z_{i}=(x_{i},y_{i})$ , $i=1,\\hdots,n$ . Supposed that there are $N$ distinct subsets of the form $A_{f}\\cap\\left\\{z_{1},\\ldots,z_{n}\\right\\}$ , and let $f_{1},\\ldots,f_{N}$ be the classifiers in $\\mathcal{F}$ that realize these distinct subsets. Consider the map that sends $f_{i}$ to the vector of its values at $x_{1},\\ldots,x_{n}$ : ", "page_idx": 28}, {"type": "equation", "text": "$$\nf_{i}\\mapsto(f_{i}(x_{1}),\\ldots,f_{i}(x_{n}))\\in\\mathcal{Y}^{n}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We will show that this map is injective, from which the claim follows. To see injectivity, consider classifiers $f_{i}$ and $f_{j}$ , where $i\\neq j$ . Since $f_{i}$ and $f_{j}$ yield different subsets, it means there is some pair $(x_{k},y_{k})$ such that one of $f_{i}$ and $f_{j}$ classifies the pair correctly, while the other does not. This implies that $f_{i}(x_{k})\\neq f_{j}(x_{k})$ , and therefore ", "page_idx": 28}, {"type": "equation", "text": "$$\n(f_{i}(x_{1}),\\dots,f_{i}(x_{n}))\\neq(f_{j}(x_{1}),\\dots,f_{j}(x_{n})).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 28}, {"type": "text", "text": "Now, Lemma 2 follows from the above theorem (stated in terms of the noisy data/distribution/risk) in precisely the same way that Corollary 12.1 in Devroye et al. [1996] follows from Theorem 12.6 in the same book. ", "page_idx": 28}, {"type": "text", "text": "A.2.7 Proof of upper bound: Theorem 3 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Theorem (Excess Risk Upper Bound of NI-ERM under smooth relative margin condition) Let $\\epsilon\\in[0,1],\\alpha>0,C_{\\alpha}>0$ . Consider any $(P_{X},\\pmb{\\eta},\\widetilde{\\pmb{\\eta}})\\in\\Pi^{\\prime}(\\epsilon,\\alpha,C_{\\alpha})$ , assume function class $\\mathcal{F}$ has Natarajan dimension $V$ , and the noisy Bayes cla s sifier $\\tilde{f}^{*}$ belongs to $\\mathcal{F}$ . Let $\\hat{f}\\in\\mathcal{F}$ be the ERM trained on $Z^{n}=\\left\\{(X_{i},{\\widetilde{Y}}_{i})\\right\\}_{i=1}^{n}$ . Then ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Z^{n}}\\left[R\\left(\\hat{f}\\right)-R\\left(f^{*}\\right)\\right]\\leq\\epsilon+\\operatorname*{inf}_{\\kappa>0}\\left\\{C_{\\alpha}\\kappa^{\\alpha}+\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\kappa}\\sqrt{\\frac{V}{n}}\\right)\\right\\}}\\\\ &{\\qquad\\qquad\\qquad=\\epsilon+\\tilde{\\mathcal{O}}\\left(n^{-\\alpha/(2+2\\alpha)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. Again, using Lemma 1, and Theorem 2, we can conclude the following, where $C$ is some large enough constant. ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Z^{n}}[R(\\hat{f})-R(f^{*})]}\\\\ &{\\quad\\quad\\leq\\underset{\\kappa>0}{\\operatorname*{inf}}\\left\\lbrace P_{X}\\Big(X\\wedge(\\eta,\\tilde{\\eta})\\Big)+\\frac{1}{\\kappa}\\left(\\widetilde{R}(f)-\\widetilde{R}\\left(\\tilde{f}^{*}\\right)\\right)\\right\\rbrace}\\\\ &{\\quad\\quad\\leq\\underset{\\kappa>0}{\\operatorname*{inf}}\\left\\lbrace P_{X}\\Big(X\\wedge(\\eta,\\tilde{\\eta})\\Big)+\\frac{1}{\\kappa}\\sqrt{\\frac{C V\\log(n K)}{n}}\\right\\rbrace.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Now, by definition of $\\Pi^{\\prime}(\\epsilon,\\alpha,C_{\\alpha})$ , it holds that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\forall\\kappa>0,\\;P_{X}(\\mathcal{M}(x;\\eta,\\tilde{\\eta})\\leq\\kappa)\\leq C_{\\alpha}\\kappa^{\\alpha}+\\epsilon.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Thus, we can further conclude that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z^{n}}[R(\\hat{f})-R(f^{*})]\\leq\\operatorname*{inf}_{\\kappa>0}\\left\\{\\epsilon+C_{\\alpha}\\kappa^{\\alpha}+\\frac{1}{\\kappa}\\sqrt{\\frac{C V\\log(n K)}{n}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The final statement now comes from optimizing the above bound, which is attained by taking the derivative w.r.t. $\\kappa$ and set to zero, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\kappa_{*}=\\left((\\alpha C_{\\alpha})^{-1}\\sqrt{C V\\log(n K)/n}\\right)^{1/(\\alpha+1)}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This yields the bound ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{Z^{n}}[R(\\hat{f})-R(f^{*})]\\leq\\epsilon+\\mathcal{O}\\left(\\left(\\sqrt{V\\log(n K)/n}\\right)^{\\alpha/(\\alpha+1)}\\right)=\\epsilon+\\tilde{\\mathcal{O}}(n^{-\\alpha/(2\\alpha+2)}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "A.2.8 Proof of immunity results: Theorem 4 and 5 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Here, we state the immunity theorems in an equivalent but different way, so that the proofs are easier to follow. ", "page_idx": 29}, {"type": "text", "text": "Theorem (Immunity for one-hot vector) Denote $\\boldsymbol{B}=\\{e_{1},\\ldots,e_{K}\\}$ to be the set of one-hot vectors. ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall\\,\\pmb{\\eta}(x)\\in\\mathcal{B},\\quad\\arg\\operatorname*{max}\\eta(x)=\\arg\\operatorname*{max}E(x)^{\\top}\\pmb{\\eta}(x)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. Let $\\pmb{\\eta}(x)=\\pmb{e}_{y}$ for some $y$ , then ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\boldsymbol{\\tilde{\\eta}}(x)=\\boldsymbol{E}^{\\top}\\boldsymbol{\\eta}(x)=\\left[\\begin{array}{c}{\\ln\\left(\\boldsymbol{\\tilde{Y}}=1\\mid\\boldsymbol{Y}=y,\\boldsymbol{X}=x\\right)}\\\\ {\\mathbb{P}\\left(\\boldsymbol{\\tilde{Y}}=2\\mid\\boldsymbol{Y}=y,\\boldsymbol{X}=x\\right)}\\\\ {\\vdots}\\\\ {\\mathbb{P}\\left(\\boldsymbol{\\tilde{Y}}=\\boldsymbol{K}\\mid\\boldsymbol{Y}=y,\\boldsymbol{X}=x\\right)}\\end{array}\\right]=\\left[\\boldsymbol{E}(x)\\right]_{y,\\boldsymbol{X}}^{\\top},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "To have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\arg\\operatorname*{max}\\left.\\widetilde{\\eta}(x)=\\arg\\operatorname*{max}\\left.[E(x)\\right]_{y,:}^{\\top}=\\arg\\operatorname*{max}\\left.\\eta(x)=y\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for any choice of $y$ , it is equivalent to say that the diagonal elements of $E(x)$ maximizes its row. ", "page_idx": 29}, {"type": "text", "text": "Theorem (Universal Immunity) Consider $K$ -class classification, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall\\,\\,\\pmb{\\eta}(x),\\quad\\arg\\operatorname*{max}\\eta(x)=\\arg\\operatorname*{max}E(x)^{\\top}\\eta(x)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\pmb{E}(x)=\\left[\\begin{array}{c c c c}{1-(K-1)e(x)}&{e(x)}&{\\cdots}&{e(x)}\\\\ {e(x)}&{1-(K-1)e(x)}&{\\cdots}&{e(x)}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {e(x)}&{e(x)}&{\\cdots}&{1-(K-1)e(x)}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. ", "page_idx": 29}, {"type": "text", "text": "$\\Longleftarrow$ : Plug $E(x)$ into the expression ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\boldsymbol{\\eta}}(x)=E^{\\top}\\boldsymbol{\\eta}(x)}\\\\ &{\\qquad=\\left[\\begin{array}{c c c c}{\\boldsymbol{1}-(K-1)e(x)}&{\\boldsymbol{e}(x)}&{\\cdots}&{\\boldsymbol{e}(x)}\\\\ {\\boldsymbol{e}(x)}&{1-(K-1)e(x)}&{\\cdots}&{\\boldsymbol{e}(x)}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {\\boldsymbol{e}(x)}&{\\boldsymbol{e}(x)}&{\\cdots}&{1-(K-1)e(x)}\\end{array}\\right]\\boldsymbol{\\eta}(x)}\\\\ &{\\qquad=\\left((1-K\\cdot e(x))\\cdot\\left[\\begin{array}{c c c c}{1}&{0}&{\\cdots}&{0}\\\\ {0}&{1}&{\\cdots}&{0}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {0}&{0}&{\\cdots}&{1}\\end{array}\\right]+\\boldsymbol{e}(x)\\cdot\\left[\\begin{array}{c c c c}{11}\\\\ {\\vdots}\\\\ {\\vdots}\\end{array}\\right]\\cdot\\left[\\begin{array}{c c c c}{1}&{\\cdots}&{1}\\\\ {\\cdots}&{1}\\\\ {\\vdots}\\end{array}\\right]\\boldsymbol{\\eta}(x)}\\\\ &{\\qquad=(1-K\\cdot e(x))\\cdot\\boldsymbol{\\eta}(x)+\\mathrm{constant\\;secon}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "When $\\begin{array}{r}{e(x)\\in[0,\\frac{1}{K})}\\end{array}$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall\\pmb{\\eta}(x),\\mathrm{~arg~max~}\\pmb{\\widetilde{\\eta}}(x)=\\arg\\operatorname*{max}\\pmb{\\eta}(x).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "$\\Longrightarrow$ : Denote $\\pmb{T}(x):=\\pmb{E}(x)^{\\top}$ , then ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\pmb T}({\\pmb x})=\\left[\\begin{array}{c c c c}{t_{11}({\\pmb x})}&{t_{12}({\\pmb x})}&{\\cdot\\cdot\\cdot}&{t_{1K}({\\pmb x})}\\\\ {t_{21}({\\pmb x})}&{t_{22}({\\pmb x})}&{\\cdot\\cdot\\cdot}&{t_{2K}({\\pmb x})}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {t_{K1}({\\pmb x})}&{t_{K2}({\\pmb x})}&{\\cdot\\cdot\\cdot}&{t_{K K}({\\pmb x})}\\end{array}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "has each column sum to 1. Let us consider several choices of $\\eta(x)$ , which pose conditions on matrix ${\\cal T}(x)$ . ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{\\eta}}(x)=\\pmb{T}(x)\\pmb{\\eta}(x)=\\frac{1}{K}\\left[\\begin{array}{c}{t_{11}(x)+t_{12}(x)+\\cdot\\cdot\\cdot+t_{1K}(x)}\\\\ {t_{21}(x)+t_{22}(x)+\\cdot\\cdot\\cdot+t_{2K}(x)}\\\\ {\\vdots}\\\\ {t_{K1}(x)+t_{K2}(x)+\\cdot\\cdot\\cdot+t_{K K}(x)}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "To have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\arg\\operatorname*{max}\\left.\\tilde{\\eta}(x)=\\arg\\operatorname*{max}\\eta(x)=\\{1,2,\\dots,k\\}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "all elements of $\\widetilde{\\pmb{\\eta}}(x)$ must be equal, i.e., each row of $\\pmb{T}(\\boldsymbol{x})$ should sum to the same value. The sum of all elements in $\\pmb{T}(\\boldsymbol{x})$ is $K$ , since all column sum to 1. Therefore, each row of $\\pmb{T}(\\boldsymbol{x})$ also sum to 1. ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\tilde{\\eta}(x)=T(x)\\eta(x)=\\frac{1}{K-1}\\left[\\begin{array}{c}{t_{11}(x)+t_{12}(x)+\\cdots+t_{1(K-1)}(x)}\\\\ {t_{21}(x)+t_{22}(x)+\\cdots+t_{2(K-1)}(x)}\\\\ {\\vdots}\\\\ {t_{(K-1)1}(x)+t_{(K-1)2}(x)+\\cdots+t_{(K-1)(K-1)}(x)}\\\\ {t_{K1}(x)+t_{K2}(x)+\\cdots+t_{K(K-1)}(x)}\\end{array}\\right]}\\\\ {=\\frac{1}{K-1}\\left[\\begin{array}{c}{1-t_{1K}(x)}\\\\ {1-t_{2K}(x)}\\\\ {\\vdots}\\\\ {1-t_{(K-1)k}(x)}\\\\ {1-t_{K K}(x)}\\end{array}\\right].}&{{}\\qquad:\\mathrm{each~row~of~}T(x)\\mathrm{~sum~t~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "To have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\arg\\operatorname*{max}\\left.\\widetilde{\\eta}(x)=\\arg\\operatorname*{max}\\left.\\eta(x)=\\left\\{1,2,\\dots,K-1\\right\\},\\right.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "the first $K-1$ elements of $\\widetilde{\\eta}(\\boldsymbol{x})$ must be equal (and larger than $t_{K K}(x))$ , then we have ", "page_idx": 30}, {"type": "equation", "text": "$$\nt_{1K}(x)=t_{2K}(x)=\\cdot\\cdot\\cdot=t_{(K-1)K}(x).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In other words, all elements of the $K$ -th column of $\\pmb{T}(\\boldsymbol{x})$ are the same (except for the $(K,K)$ -th element). Similarly, consider $\\eta(x)$ to be a vector that contains 0 in the $i$ -th position and K\u22121 in other positions, then the general condition for $\\pmb{T}(\\boldsymbol{x})$ is that: all elements of the $i$ -th column are equal, except the $i$ -th diagonal. Written explicitly, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\pmb T}({\\boldsymbol x})=\\left[\\begin{array}{c c c c c}{t_{11}({\\boldsymbol x})}&{t_{12}({\\boldsymbol x})}&{t_{13}({\\boldsymbol x})}&{\\cdot\\cdot\\cdot}&{t_{1K}({\\boldsymbol x})}\\\\ {t_{21}({\\boldsymbol x})}&{t_{22}({\\boldsymbol x})}&{t_{13}({\\boldsymbol x})}&{\\cdot\\cdot\\cdot}&{t_{1K}({\\boldsymbol x})}\\\\ {t_{21}({\\boldsymbol x})}&{t_{12}({\\boldsymbol x})}&{t_{33}({\\boldsymbol x})}&{\\cdot\\cdot\\cdot}&{t_{1K}({\\boldsymbol x})}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {t_{21}({\\boldsymbol x})}&{t_{12}({\\boldsymbol x})}&{t_{13}({\\boldsymbol x})}&{\\cdot\\cdot\\cdot}&{t_{K K}({\\boldsymbol x})}\\end{array}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Since each row and column of ${\\cal T}(x)$ sum to $1$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n{\\left\\{\\begin{array}{l l}{0+t_{12}(x)+t_{13}(x)+\\dots+t_{1K}(x)}&{=\\ (K-1)t_{21}(x)\\longleftarrow{\\mathrm{sum~of~first~row}}={\\mathrm{sum~of~first~col}}}\\\\ {t_{21}(x)+0+t_{13}(x)+\\dots+t_{1K}(x)}&{=\\ (K-1)t_{12}(x)}\\\\ {t_{21}(x)+t_{12}(x)+0+\\dots+t_{1K}(x)}&{=\\ (K-1)t_{13}(x)}\\\\ &{\\vdots}\\\\ {t_{21}(x)+t_{12}(x)+t_{13}(x)+\\dots+0}&{=\\ (K-1)t_{1K}(x)}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Subtracting the first equation from the second, we have $t_{12}(x)=t_{21}(x)$ . Repeating for all pairs of equations, we have $t_{21}(x)=t_{12}(x)=t_{13}(x)=\\cdots=t_{1K}(x)$ . What\u2019s more, all diagonal elements of ${\\cal T}(x)$ will be equal. Thus, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\pmb{T}(x)=\\left[\\begin{array}{c c c c}{1-(K-1)e(x)}&{e(x)}&{\\cdots}&{e(x)}\\\\ {e(x)}&{1-(K-1)e(x)}&{\\cdots}&{e(x)}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {e(x)}&{e(x)}&{\\cdots}&{1-(K-1)e(x)}\\end{array}\\right],\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "3) The final step is to determine what value $e(x)$ can take. Take $\\pmb{\\eta}(x)=e_{y}$ for some $y$ , then from Theorem 4, we know that the diagonal elements of $\\pmb{T}(\\boldsymbol{x})$ maximize their column, therefore ", "page_idx": 31}, {"type": "equation", "text": "$$\n1-(K-1)e(x)>e(x)\\quad\\Longrightarrow\\quad e(x)\\in[0,\\frac{1}{K}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Finally, take any $\\eta(x)$ , the arg max is preserved by multiplying this specific choice of $\\pmb{T}(\\boldsymbol{x})$ . This concludes the $\\Longleftarrow\\mathrm{part}$ . ", "page_idx": 31}, {"type": "text", "text": "A.3 Experimental details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "A.3.1 2D Gaussian with synthetic label noise ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "For 2D Gaussian mixture data, we draw from two Gaussian centered at $\\lbrack1\\,1\\rbrack^{\\intercal}$ and $[-1\\mathrm{~-~}1]^{\\intercal}$ , with covariance matrix being identity, 200 data points from each, with label $Y=1,2$ respectively. To generate noisy labels, we filp every label uniformly with some probability. We use Sklearn\u2019s logistic regression (with no $\\ell_{2}$ regularization). The experiment was conducted on AMD Ryzen 5 3600 CPU. The goal of the simulation is to experimentally verify noise immunity results in Section 6. Notice that different trial corresponds to different draw of both instances and noisy labels. ", "page_idx": 31}, {"type": "text", "text": "Table 2: Testing accuracy of logistic regression on gaussian mixture data with uniform label noise. \u201cNoise rate\u201d refers to $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ , the percentage of wrong labels in the training data. As theory in Section 6 predicts, when $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ reach $50\\%$ , there is a sharp decrease in performance. ", "page_idx": 31}, {"type": "image", "img_path": "fTKcqr4xuX/tmp/b98cafbf355979c41c28b04f454651922622d29748eb3de2d8a14d21f048dde6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "A.3.2 MNIST with synthetic label noise ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We flip the clean training label of MNIST (http://yann.lecun.com/exdb/mnist/) uniformly (to any of the wrong classes). We use a shallow neural network with two convolution layers and two fully connected layers. We train with stochastic gradient descent with learning rate 0.01 for 10 epochs, batch size equals 64. We use the same hyperparamters for all tests. The experiments were conducted on a single NVIDIA GTX 1660S GPU. The goal of the simulation is to experimentally verify noise immunity results in Section 6. Here randomness corresponds to different realization of noisy labels and stochastic gradient descent. ", "page_idx": 31}, {"type": "text", "text": "Table 3: Testing accuracy of a shallow CNN (2 conv layers with 2 fully connected layers) on MNIST with uniform label noise. \u201cNoise rate\u201d refers to $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ , the percentage of wrong labels in the training data. As theory in Section 6 predicts, when $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ reach $90\\%$ , there is a sharp decrease in performance. ", "page_idx": 32}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/30dedb9ab435eb0aeb57e647f0693c3879a9de393c7a9ce6fdb8f69d9b088a5c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "A.3.3 CIFAR with synthetic label noise ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We flip the clean training label of CIFAR-10 (https://www.cs.toronto.edu/\\~kriz/cifar. html) uniformly (to any of the wrong classes). To have a fair comparison between different methods, we fix the realization of noisy labels. Follow the 2-step procedure described in Section 7, we use different pre-trained neural networks as feature extractor: forward-passing the training image through the network and record the feature. Then use sklearn\u2019s (https://scikit-learn.org/stable/) logistic regression function to fit the (feature, noisy label) pair in a full batch manner. We prespecify a range of values for $\\ell_{2}$ regularization $(\\{0.0001,0.0\\dot{0}1,0.01,0.1,1,10,100\\}$ ) and number of iterations for lbfgs optimizer $(\\{10,20,50,100\\})$ ), then do cross-validation on noisy data to pick the best hyper-parameters. We use the same range of hyper-parameters in all tests. The experiments were conducted on a single NVIDIA Tesla V100 GPU. The result is deterministic. ", "page_idx": 32}, {"type": "text", "text": "Table 4: Peformance on CIFAR-10 with synthetic label noise. We apply linear model on top of different feature extractors: \u201cResNet-50 TL\u201d refers to using a pre-trained ResNet-50 on ImageNet [Deng et al., 2009] (available in Pytorch model library) in a transfer learning fashion, \u201cResNet-50 SSL\u201d refers to using a pre-trained ResNet-50 on unlabeled CIFAR data with self-supervised loss [Chen et al., 2020] (publicly downloadable weights https://github.com/ContrastToDivide/C2D? tab $=$ readme-ov-file) and \u201cDINOv2 SSL\u201d refers to using the self-supervised foundation model DINOv2 [Oquab et al., 2023] (available at https://github.com/facebookresearch/dinov2) as the feature extractor. \u201cNoise rate\u201d refers to $\\mathbb{P}(\\boldsymbol{\\widetilde{Y}}\\neq\\boldsymbol{Y})$ , the percentage of wrong labels in the training data. As theory in Section 6 predicts, when $\\mathbb{P}(\\widetilde{Y}\\neq Y)$ reach $90\\%$ , there is a sharp decrease in performance. We employed Python\u2019s sklearn logist ic regression and cross-validation functions without data augmentation. The results are deterministic. ", "page_idx": 32}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/73b9a329b6d091bbbfbcf0dab723cc1755e46c87c937e0d614942e3ae04c8c8e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "A.3.4 CIFAR with human label error ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We load the noisy human labels provided by http://noisylabels.com/, then follow exact the same procedure as above. ", "page_idx": 32}, {"type": "text", "text": "Table 5: Performance on CIFAR-N dataset (http://noisylabels.com/) in terms of testing accuracy. \u201cAggre\u201d, \u201cRand1\u201d, ..., \u201cNoisy\u201d denote various types of human label noise. We apply linear model on top of different feature extractors: \u201cResNet-50 TL\u201d refers to using a pre-trained ResNet-50 on ImageNet [Deng et al., 2009] in a transfer learning fashion, \u201cResNet-50 SSL\u201d refers to using a pre-trained ResNet-50 on unlabeled CIFAR data with self-supervised loss [Chen et al., 2020] and \u201cDINOv2 SSL\u201d refers to using the self-supervised foundation model DINOv2 [Oquab et al., 2023] as the feature extractor. We employed Python\u2019s sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible. ", "page_idx": 33}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/22319c26c159a0c627197be3c2bfab7180e610871fa1a7fe30dcd930d7804098.jpg", "table_caption": [], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "A.4 Additional experiments ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "A.4.1 Linear probing, then fine tuning (LP-FT) ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We study whether \u2018linear probing, then fine tuning\u2019 (LP-FT) [Kumar et al., 2022] works better than linear probing (LP) only, in label noise learning scenario. ", "page_idx": 33}, {"type": "text", "text": "Table 6: Performance on CIFAR-N dataset (http://noisylabels.com/) in terms of testing accuracy. \u201cClean\u201d refers to no label noise, \u201cAggre\u201d, \u201cRand1\u201d, ..., \u201cNoisy\u201d denote various types of human label noise. We compare the testing accuracy of LP-FT versus LP only, over different feature extractors: \u201cResNet-50 TL\u201d refers to using a pre-trained ResNet-50 on ImageNet [Deng et al., 2009] in a transfer learning fashion, \u201cResNet-50 SSL\u201d refers to using a pre-trained ResNet-50 on unlabeled CIFAR data with contrastive loss [Chen et al., 2020] and \u201cDINOv2 (small) SSL\u201d refers to using a light version of the self-supervised foundation model DINOv2 [Oquab et al., 2023] as the feature extractor. ", "page_idx": 33}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/50db6858407ef8b15233ee1ddb466945e947b3f14234b847fbd59a5affbcbb10.jpg", "table_caption": [], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "A.4.2 Robust learning strategy over DINOv2 feature ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "This section examines how different robust learning strategy works over DINOv2 feature, compared with only training with cross entropy. ", "page_idx": 33}, {"type": "text", "text": "Table 7: Comparison of different noise robust methods on DINOv2 features. Training a linear classifier with cross entropy (CE) loss is the baseline. We compare it with robust losses: mean absolute error (MAE) loss [Ghosh and Kumar, 2017, Ma and Fattahi, 2022], sigmoid loss [Ghosh et al., 2015], and regularized approaches: \u2018Early-Learning Regularization\u2019 (ELR) [Liu et al., 2020], \u2018Sharpness Aware Minimization\u2019 (SAM) [Foret et al., 2021]. ", "page_idx": 34}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/f6bc420e3bf46866fb61495a77316ee7f7d5da17376630cb951336180c7da667.jpg", "table_caption": [], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "A.4.3 Synthetic instance-dependent label noise ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Table 8: We synthetically corrupt labels of CIFAR-10 according to Xia et al. [2020], and compare our NI-ERM with the \u2018Part-dependent matrix estimation\u2019 (PTD) method proposed in that same paper. ", "page_idx": 34}, {"type": "table", "img_path": "fTKcqr4xuX/tmp/4f398717243b418bcbfc865178ad1532b6b120716a92e7423ac3ccd7466d26df.jpg", "table_caption": [], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The claims are either supported by theory statements or by reproducible experiment results. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 35}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: Limitations about our practical method is described. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 35}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Assumptions are stated in the theorem statement. Full proofs are included in the appendix. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 36}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Important information about the experiments are in main text. Details on the experimental setup is described in the appendix. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 36}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: Code is provided, common benchmark datase were used, instructions are given, the result is easily reproducible. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 37}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: See appendix and attached code. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 37}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: We have done repeated experiments for data simulation, e.g., different iid draw. For the result on CIFAR-N data challenge, our result is deterministic and thus no error bar. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 37}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 38}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: See appendix. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 38}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The authors have read the NeurIPS Code of Ethics and confirm that this research follows the code of ethics. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 38}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: This is a theory-oriented paper towards better understanding of label noise problem. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 39}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper poses no such risks ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 39}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: Citations and urls are included. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 40}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 40}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: The paper does not involve with this matter. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 40}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 41}]