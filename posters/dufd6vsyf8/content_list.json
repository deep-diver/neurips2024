[{"type": "text", "text": "Federated Natural Policy Gradient and Actor Critic Methods for Multi-task Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tong Yang\\* Shicong Cent Yuting Weit Yuxin Chens Yuejie Chi CMU CMU UPenn UPenn CMU ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods in the tabular setting under softmax parameterization, where gradient tracking is applied to estimate the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, where the rates are nearly independent of the size of the state-action space and illuminate the impacts of network size and connectivity, and further establish its robustness against inexact policy evaluation. We further propose a federated natural actor critic (NAC) method for multi-task RL with function approximation and stochastic policy evaluation, and establish its finitetime sample complexity taking the errors of function approximation into account. To the best of our knowledge, this is the first time that near dimension-free global convergence is established for federated multi-task RL using policy optimization. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated reinforcement learning (FRL) is an emerging paradigm that combines the advantages of federated learning (FL) and reinforcement learning (RL) [QZLZ21, $Z\\mathrm{FL}^{+}19]$ , allowing multiple agents to learn a shared policy from local experiences, without exposing their private data to a central server nor other agents. FRL is poised to enable collaborative and efficient decision making in scenarios where data is distributed, heterogeneous, and sensitive, which arise frequently in applications such as edge computing, smart cities, and healthcare $[\\mathrm{WHM}^{+}23$ ,WKNL20,ZFL $^+19]$ , to name just a few. As has been observed $[\\mathrm{L}Z Z^{+}17]$ , decentralized training can lead to performance improvements in FL by avoiding communication congestions at busy nodes such as the server, especially under high-latency scenarios. This motivates us to design algorithms for the fully decentralized setting, a scenario where the agents can only communicate with their local neighbors over a prescribed network topology.6 ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this work, we study the problem of federated multi-task RL [AR21, QZLZ21, $\\mathrm{YLS}^{+}20]$ ,where each agent collects its own reward \u2014\u2014- possibly unknown to other agents \u2014\u2014- corresponding to the local task at hand, while having access to the same dynamics (i.e., transition kernel) of the environment. The collective goal is to learn a shared policy that maximizes the total rewards accumulated from all the agents; in other words, one seeks a policy that performs well in terms of overall benefits, rather than biasing towards any individual task, achieving the Pareto frontier in a multi-objective context. There is no shortage of application scenarios where federated multi-task RL becomes highly relevant. For instance, in healthcare $[Z\\mathrm{BW}^{+}20]$ , different hospitals may be interested in finding an optimal treatment for all patients without disclosing private data, where the effectiveness of the treatment can vary across different hospitals due to demographical differences. See Appendix B.1 for more application scenarios of our setting. ", "page_idx": 1}, {"type": "text", "text": "Nonetheless, despite the promise, provably efficient algorithms for federated multi-task RL remain substantially under-explored, especially in the fully decentralized setting. The heterogeneity of local tasks leads to a higher degree of disagreements between the global value function and local value functions of individual agents. Due to the lack of global information sharing, care needs to be taken to judiciously balance the use of neighboring information (to facilitate consensus) and local data (to facilitate learning) when updating the policy. To the best of our knowledge, very few algorithms are currently available to find the global optimal policy with non-asymptotic convergence guarantees even for tabular infinite-horizon Markov decision processes. ", "page_idx": 1}, {"type": "text", "text": "Motivated by the connection with decentralized optimization, it is tempting to take a policy optimization perspective to tackle this challenge. Policy gradient (PG) methods, which seek to learn the policy of interest via first-order optimization methods, play an eminent role in RL due to their simplicity and scalability. In particular, natural policy gradient (NPG) methods [Ama98, Kak01] are among the most popular variants of PG methods, underpinning default methods used in practice such as trust region policy optimization (TRPO) $[\\mathrm{SLA}^{+}1\\bar{5}]$ and proximal policy optimization (PPO) $[\\mathrm{SWD}^{+}17]$ On the theoretical side, it has also been established recently that the NPG method enjoys fast global convergence to the optimal policy in an almost dimension-free manner [AKLM21, CWC21], where the iteration complexity is nearly independent of the size of the state-action space. These benefits can be translated to their sample-based counterparts such as the natural actor critic (NAC) method [BSGL09, XWL20, KDRM22], where the policies are evaluated via stochastic samples. It is natural to ask: ", "page_idx": 1}, {"type": "text", "text": "Can we develop federated NPG and NAC methods with non-asymptotic global convergence guarantees for multi-task RL in the fully decentralized setting? ", "page_idx": 1}, {"type": "text", "text": "1.1  Our contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Focusing on infinite-horizon Markov decision processes (MDPs), we provide an affirmative answer to the above question, by developing federated NPG (FedNPG) methods for solving both the vanilla and entropy-regularized multi-task RL problems with finite-time global convergence guarantees. While entropy regularization is often incorporated as an effective strategy to encourage exploration during policy learning, solving the entropy-regularized RL problem is of interest in its own right, as the optimal regularized policy possesses desirable robust properties with respect to reward perturbations [EL21, MP95]. Due to the multiplicative update nature of NPG methods under softmax parameterization, it is more convenient to work with the logarithms of local policies in the decentralized setting. In each iteration of the proposed FedNPG method, the logarithms of local policies are updated by a weighted linear combination of two terms (up to normalization): a gossip mixing [NO09] of the logarithms of neighboring local policies, and a local estimate of the global Q-function tracked via the technique of dynamic average consensus [ZM10], a prevalent idea in decentralized optimization that allows for the use of large constant learning rates [DLS16, NOS17, QL17] to accelerate convergence. We further develop sample-efficient federated NAC (FedNAC) methods that allow for both stochastic policy evaluation and function approximation. Our contributions are as follows. ", "page_idx": 1}, {"type": "text", "text": "\u00b7 We propose FedNPG methods for both the vanilla and entropy-regularized multi-task RL problems, where each agent only communicates with its neighbors and performs local computation using its own reward or task information. ", "page_idx": 1}, {"type": "table", "img_path": "DUFD6vsyF8/tmp/2f8fe00714502927f1c23a1848dc44169b3ad386ae51f6922d15e2bf4c79dad0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Table 1: Iteration complexities of NPG and FedNPG (ours) methods to reach $\\varepsilon$ -accuracy of the vanilla and entropy-regularized problems, where we assume exact gradient evaluation, and only keep the dominant terms w.r.t. $\\varepsilon$ . The policy estimates in the $t$ -iteration are $\\pi^{(t)}$ and $\\bar{\\pi}^{(t)}$ for NPG and FedNPG, respectively, where $T$ is the number of iterations. Here, $N$ is the number of agents, $\\tau\\leq1$ is the regularization parameter, $\\sigma\\in[0,1]$ is the spectral radius of the network, $\\gamma\\in[0,1)$ is the discount factor, $|{\\mathcal{A}}|$ is the size of the action space, and $\\eta>0$ is the learning rate. The iteration complexities of FedNPG reduce to their centralized counterparts when $\\sigma=0$ . For vanilla FedNPG, the learning rate is set as = n1 = 0 (1-)(1-g) log 1A1) 13 ; for entropy-regularized FedNPG, the learning rate satisfies 0 <n< no = 0 (1-)(-0)\u00b2) ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "\u00b7 Assuming access to exact policy evaluation, we establish that the average iterate of vanilla FedNPG converges globally at a rate of $\\mathcal{O}(1/T^{2/3})$ in terms of the sub-optimality gap for the multi-task RL problem, and that the last iterate of entropy-regularized FedNPG converges globally at a linear rate to the regularized optimal policy. Our convergence theory highlights the impacts of all salient problem parameters (see Table 1 for details), such as the size and connectivity of the communication network. In particular, the iteration complexities of FedNPG are again almost independent of the size of the state-action space, which recover prior results on the centralized NPG methods when the network is fully connected. ", "page_idx": 2}, {"type": "text", "text": "\u00b7 We further demonstrate the stability of the proposed FedNPG methods when policy evaluations are only available in an inexact manner. To be specific, we prove that their convergence rates remain unchanged as long as the approximation errors are sufficiently small in the $\\ell_{\\infty}$ sense. \u00b7 We go beyond the tabular setting and black-box policy evaluation by proposing FedNAC- a federated actor critic method for multi-task RL with function approximation and stochastic policy evaluation \u2014 and establish a finite-sample sample complexity on the order of $\\mathcal{O}(1/\\varepsilon^{7/2})$ for each agent in terms of the expected sub-optimality gap for the fully decentralized setting. ", "page_idx": 2}, {"type": "text", "text": "To the best of our knowledge, the proposed federated NPG and NAC methods are the first policy optimization methods for multi-task RL that achieve near dimension-free global convergence guarantees in terms of iteration and sample complexities, allowing for fully decentralized communication without any need to share local reward/task information. We conduct numerical experiments in a multi-task GridWorld environment to corroborate the efficacy of the proposed methods (see Appendix H). We defer the readers to Appendix A for more related work, and Appendix B.2 for additional discussions on our theoretical contributions. ", "page_idx": 2}, {"type": "text", "text": "Notation. Boldface small and capital letters denote vectors and matrices, respectively. Sets are denoted with curly capital letters, e.g., $S,A$ . We let $(\\mathbb{R}^{d},\\|\\cdot\\|)$ denote the $d$ -dimensional real coordinate space equipped with norm $\\lVert\\cdot\\rVert$ . The $\\ell_{p}$ -norm of $\\pmb{v}$ is denoted by $\\left\\|\\pmb{v}\\right\\|_{p}$ , where $1\\leq p\\leq\\infty$ , and the spectral norm and the Frobenius norm of a matrix $_M$ are denoted by $\\lVert M\\rVert_{2}$ and $\\Vert M\\Vert_{\\mathrm{F}}$ , resp. We let $[N]$ denote $\\{1,\\ldots,N\\}$ , use ${\\mathbf{1}}_{N}$ to represent the all-one vector of length $N$ , and denote by 0 a vector or a matrix consisting of all O's. We allow the application of functions such as $\\log(\\cdot)$ and $\\exp(\\cdot)$ to vectors or matrices, with the understanding that they are applied in an element-wise manner. ", "page_idx": 2}, {"type": "text", "text": "2   Model and backgrounds ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Markov decision processes. We consider an infinite-horizon discounted Markov decision process (MDP) denoted by. $\\mathcal{M}=(\\mathcal{S},\\mathcal{A},P,r,\\gamma)$ , where $\\boldsymbol{S}$ and $\\boldsymbol{\\mathcal{A}}$ denote the state space and the action space, respectively, $\\gamma\\in[0,1)$ indicates the discount factor, $P:S\\times A\\to\\Delta(S)$ is the transition kernel, and $r:S\\times A\\to[0,1]$ stands for the reward function. To be more specific, for each state-action pair $(s,a)\\in S\\times{\\dot{A}}$ and any state $s^{\\prime}\\in\\mathcal{S}$ , we denote by $P(s^{\\prime}|s,a)$ the transition probability from state $s$ to state $s^{\\prime}$ when action $a$ is taken, and $r(s,a)$ the instantaneous reward received in state $s$ when action $a$ is taken. Furthermore, a policy $\\pi:{\\mathcal{S}}\\rightarrow\\Delta(A)$ specifies an action selection rule, where $\\pi(a|s)$ specifies the probability of taking action $a$ in state $s$ for each $(s,a)\\in S\\times A$ ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "For any given policy $\\pi$ , we denoteby $V^{\\pi}:S\\mapsto\\mathbb{R}$ the corresponding value function, which is the expected discounted cumulative reward with an initial state $s_{0}=s$ givenby ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall s\\in{\\cal{S}}:\\quad V^{\\pi}(s):=\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s\\right],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the randomness is over the trajectory generated following the policy $a_{t}\\sim\\pi(\\cdot|s_{t})$ and the MDP dynamic $s_{t+1}\\sim P(\\cdot|s_{t},a_{t})$ .We also overload the notation $V^{\\pi}(\\rho)$ to indicate the expected value function of policy $\\pi$ when the initial state follows a distribution $\\rho$ over $\\boldsymbol{S}$ , namely, $\\bar{V^{\\pi}(\\rho)}:=$ $\\mathbb{E}_{s\\sim\\rho}\\left[V^{\\pi}(s)\\right]$ . Similarly, the Q-function $Q^{\\pi}:S\\times A\\mapsto\\mathbb{R}$ of policy $\\pi$ is defined by ", "page_idx": 3}, {"type": "equation", "text": "$$\nQ^{\\pi}(s,a):=\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for all $(s,a)\\in S\\times A$ , which measures the expected discounted cumulative reward with an initial state $s_{0}=s$ and an initial action $a_{0}=a$ , with expectation taken over the randomness of the trajectory. The optimalpolicy $\\pi^{\\star}$ refers to the policy that maximizes the value function $V^{\\pi}(s)$ for all states $s\\in S$ which is guaranteed to exist [Put14]. The corresponding optimal value function and Q-function are denoted as $V^{\\star}$ and $Q^{\\star}$ , respectively. ", "page_idx": 3}, {"type": "text", "text": "Entropy-regularized RL. Entropy regularization [WP91, ALRNS19] is a popular technique in practice that encourages stochasticity of the policy to promote exploration, as well as robustness against reward uncertainties. Mathematically, this can be viewed as adjusting the instantaneous reward based the current policy in use as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in{\\cal S}\\times{\\cal A}:\\ r_{\\tau}(s,a):=r(s,a)-\\tau\\log\\pi(a|s)\\,,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\tau\\geq0$ denotes the regularization parameter. Typically, $\\tau$ should not be too large to outweigh the actual rewards fo ease of presentation, we assume T \u2264 min 1. 1g AI [CCDX22]. Equivalently, this amounts to the entropy-regularized (also known as \u201csoft\") value function, defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall s\\in{\\mathcal{S}}:\\quad V_{\\tau}^{\\pi}(s):=V^{\\pi}(s)+\\tau{\\mathcal{H}}(s,\\pi),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{H}(s,\\pi):=\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}-\\gamma^{t}\\log\\pi(a_{t}|s_{t})\\big|s_{0}=s\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Analogously, for all $(s,a)\\in S\\times A$ , the regularized (or soft) Q-function $Q_{\\tau}^{\\pi}$ of policy $\\pi$ is related to the soft value function $V_{\\tau}^{\\pi}(s)$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{\\tau}^{\\pi}(s,a)=r(s,a)+\\gamma\\mathbb{E}_{s^{\\prime}\\in P(\\cdot|s,a)}\\left[V_{\\tau}^{\\pi}(s^{\\prime})\\right]\\,,\\;}\\\\ {V_{\\tau}^{\\pi}(s)=\\mathbb{E}_{a\\sim\\pi(\\cdot|s)}\\left[-\\tau\\pi(a|s)+Q_{\\tau}^{\\pi}(s,a)\\right]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The optimal regularized policy, the optimal regularized value function, and the Q-function are denoted by $\\pi_{\\tau}^{\\star}$ $V_{\\tau}^{\\star}$ ,and $Q_{\\tau}^{\\star}$ ,respectively. ", "page_idx": 3}, {"type": "text", "text": "Natural policy gradient methods. Natural policy gradient (NPG) methods lie at the heart of policy optimization, serving as the backbone of popular heuristics such as TRPO $[\\mathrm{SLA^{+}15}]$ andPPO $[\\bar{\\mathrm{SWD}}^{+}17]$ . Instead of directly optimizing the policy over the probability simplex, one often adopts the softmax parameterization, which parameterizes the policy as $\\pi_{\\theta}:=\\operatorname{softmax}(\\theta)$ Or ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi_{\\theta}(a|s):=\\frac{\\exp\\theta(s,a)}{\\sum_{a^{\\prime}\\in A}\\exp\\theta(s,a^{\\prime})}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for any $\\theta\\colon S\\times A\\rightarrow\\mathbb{R}$ and $(s,a)\\in S\\times A$ ", "page_idx": 3}, {"type": "text", "text": "In the tabular setting, the update rule of vanilla NPG at the $t$ -th iteration can be concisely represented as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi^{(t+1)}(a|s)\\propto\\pi^{(t)}(a|s)\\exp\\left(\\frac{\\eta Q^{(t)}(s,a)}{1-\\gamma}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Turning to the regularized problem, we note that the update rule of entropy-regularized NPG becomes ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pi^{(t+1)}(a|s)\\propto(\\pi^{(t)}(a|s))^{1-\\frac{\\eta\\tau}{1-\\gamma}}\\exp\\left(\\frac{\\eta Q_{\\tau}^{(t)}(s,a)}{1-\\gamma}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta\\in(0,\\frac{1-\\gamma}{\\tau}]$ is the learning rate, and $Q_{\\tau}^{(t)}=Q_{\\tau}^{\\pi^{(t)}}$ is the soft Q-function of policy $\\pi^{(t)}$ ", "page_idx": 4}, {"type": "text", "text": "3 Federated NPG methods for multi-task RL ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this paper, we consider the federated multi-task RL setting, where a set of agents learn collaboratively a single policy that maximizes its average performance over all the tasks using only local computation andcommunication. ", "page_idx": 4}, {"type": "text", "text": "Multi-task RL. Each agent $n\\in[N]$ has its own private reward function $r_{n}(s,a)$ \u2014 corresponding to different tasks \u2014 while sharing the same transition kernel of the environment. The goal is to collectively learn a single policy $\\pi$ that maximizes the global value function given by $V^{\\pi}(s)\\,=$ $\\textstyle{\\frac{1}{N}}\\sum_{n=1}^{N}V_{n}^{\\pi}(s)$ ,where $V_{n}^{\\pi}$ is the value function of agent $n\\in[N]$ , defined by ", "page_idx": 4}, {"type": "equation", "text": "$$\nV_{n}^{\\pi}(s):=\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r_{n}(s_{t},a_{t})|s_{0}=s\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Clearly, the global value function corresponds to using the average reward of all agents $\\begin{array}{r}{\\frac{1}{N}\\sum_{n=1}^{N}r_{n}(s,a)}\\end{array}$ TheglobalIOfuncion $Q^{\\pi}(s,a)$ $Q_{n}^{\\pi}(s,a)$ can be defined $r(s,a)=$ in a similar manner obeying $\\begin{array}{r}{Q^{\\pi}(s,a)=\\frac{1}{N}\\sum_{n=1}^{N}Q_{n}^{\\pi}(s,a).}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "In parallel, we are interested in the entropy-regularized setting, where each agent $n\\in[N]$ is equipped with a regularized reward function given by $r_{\\tau,n}(s,a):=\\bar{r}_{n}(s,a)-\\tau\\log\\pi(a|s)$ .And we define similarly the regularized value functions as ", "page_idx": 4}, {"type": "equation", "text": "$$\nV_{\\tau,n}^{\\pi}(s):=\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r_{\\tau,n}(s_{t},a_{t})|s_{0}=s\\right]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "for all $n\\in[N]$ and $\\begin{array}{r}{V_{\\tau}^{\\pi}(s)=\\frac{1}{N}\\sum_{n=1}^{N}V_{\\tau,n}^{\\pi}(s),\\forall s\\in S.}\\end{array}$ The soft Q-function of agent $n$ is given by ", "page_idx": 4}, {"type": "equation", "text": "$$\nQ_{\\tau,n}^{\\pi}(s,a)=r_{n}(s,a)+\\gamma\\mathbb{E}_{s^{\\prime}\\in P(\\cdot|s,a)}\\left[V_{\\tau,n}^{\\pi}(s^{\\prime})\\right]\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and the global soft Q-function is given by $\\begin{array}{r}{Q_{\\tau}^{\\pi}(s,a)=\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\pi}(s,a).}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Federated policy optimization in the fully decentralized setting. We consider a federated setting with fully decentralized communication, that is, all the agents are synchronized to perform information exchange over some prescribed network topology denoted by an undirected weighted graph $\\mathcal{G}([N],E)$ Here, $E$ stands for the edge set of the graph with $N$ nodes \u2014 each corresponding to an agent \u2014 and two agents can communicate with each other if and only if there is an edge connecting them. The information sharing over the graph is best described by a mixing matrix [NO09], denoted by $W=[w_{i j}]\\in[0,1]^{N\\times\\overline{{N}}}$ where $w_{i j}$ isa positiv umber if $(i,j)\\in\\bar{E}$ and O otherwise. We also make the following standard assumptions on the mixing matrix. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.1 (double stochasticity). The mixing matrix $W=[w_{i j}]\\in[0,1]^{N\\times N}$ is symmetric (i.e, $W^{\\top}=W$ ) and doubly stochastic (i.e., $W\\mathbf{1}_{N}=\\mathbf{1}_{N}$ \uff0c $\\mathbf{1}_{N}^{\\top}W=\\mathbf{1}_{N}^{\\top},$ ", "page_idx": 4}, {"type": "text", "text": "The following standard metric measures how fast information propagates over the graph. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.2 (spectral radius). The spectral radius of $W$ is given as $\\begin{array}{r}{\\sigma:=\\|\\pmb{W}-\\frac{1}{N}\\mathbf{1}_{N}\\mathbf{1}_{N}^{\\top}\\|_{2}\\in[0,1)}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "The spectral radius $\\sigma$ determines how fast information propagate over the network. For instance, in a fully-connected network, we can achieve $\\sigma=0$ by setting $\\begin{array}{r}{\\bar{\\pmb{W}}=\\frac{1}{N}\\mathbf{1}_{N}\\mathbf{1}_{N}^{\\top}}\\end{array}$ . For control of $1/(1-\\sigma)$ regarding different graphs, we refer the readers to [NOR18]. In an Erdos-Renyi random graph, as long as the graph is connected, one has with high probability $\\sigma\\asymp1$ . Another immediate consequence is that for any $\\mathbf{\\dot{x}}\\in\\mathbb{R}^{N}$ , letting $\\begin{array}{r}{\\overline{{\\boldsymbol{x}}}=\\frac{1}{N}\\mathbf{1}_{N}^{\\top}\\pmb{x}}\\end{array}$ be its average, we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left\\|{\\cal W}{\\pmb x}-\\overline{{{x}}}{\\bf1}_{N}\\right\\|_{2}\\leq\\sigma\\left\\|{\\pmb x}-\\overline{{{x}}}{\\bf1}_{N}\\right\\|_{2}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the consensus error contracts by a factor of $\\sigma$ ", "page_idx": 4}, {"type": "text", "text": "1: Input: learning rate $\\eta>0$ , iteration number $T\\in\\mathbb{N}_{+}$ , mixing matrix $W\\in\\mathbb{R}^{N\\times N}$   \n2: Initialize: $\\pi^{(0)}$ $\\pmb{T}^{(0)}=\\pmb{Q}^{(0)}$   \n3: for $t=0,1,\\cdot\\cdot\\cdot T-1$ do   \n4:  Update the policy for each $(s,a)\\in S\\times A$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\log\\pi^{(t+1)}(a|s)=W\\Bigl(\\log\\pi^{(t)}(a|s)+\\frac{\\eta}{1-\\gamma}T^{(t)}(s,a)\\Bigr)-\\log z^{(t)}(s)\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$\\begin{array}{r}{z^{(t)}(s)=\\sum_{a^{\\prime}\\in{\\cal A}}\\exp\\Big\\{W\\big(\\log\\pi^{(t)}(a^{\\prime}|s)+\\frac{\\eta}{1-\\gamma}T^{(t)}(s,a^{\\prime})\\big)\\Big\\}.}\\end{array}$ ", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "5: Evaluate $\\pmb{Q}^{(t+1)}$   \n6\uff1a Update the global Q-function estimate for each $(s,a)\\in S\\times A$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pmb{T}^{(t+1)}(s,a)=W\\Big(\\pmb{T}^{(t)}(s,a)+\\underbrace{\\pmb{Q}^{(t+1)}(s,a)-\\pmb{Q}^{(t)}(s,a)}_{\\mathrm{\\pmb{Q}.\\mathrm{tracking}}}\\Big)\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "7: end for ", "page_idx": 5}, {"type": "text", "text": "3.1   Proposed federated NPG algorithms ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Assuming softmax parameterization, the problem can be formulated as decentralized optimization, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{(unregularized)}}&{\\displaystyle\\operatorname*{max}_{\\theta}\\,V^{\\pi_{\\theta}}(s)=\\frac{1}{N}\\sum_{n=1}^{N}V_{n}^{\\pi_{\\theta}}(s),}\\\\ {\\mathrm{(regularized)}}&{\\displaystyle\\operatorname*{max}_{\\theta}\\,V_{\\tau}^{\\pi_{\\theta}}(s)=\\frac{1}{N}\\sum_{n=1}^{N}V_{\\tau,n}^{\\pi_{\\theta}}(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\pi_{\\theta}:=\\operatorname{softmax}(\\theta)$ subject to communication constraints. Motivated by the success of NPG methods, we aim to develop federated NPG methods to achieve our goal. For notational convenience, lete $\\pmb{\\pi}^{(t)}:=\\left(\\pi_{1}^{(t)},\\cdot\\cdot\\cdot\\,,\\pi_{N}^{(t)}\\right)^{\\top}$ e theoltonflyestmatea allaes int $t$ thiteration. Let ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\overline{{\\pi}}^{(t)}:=\\mathrm{softmax}\\left(\\frac{1}{N}\\sum_{n=1}^{N}\\log\\pi_{n}^{(t)}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which satisfies that $\\begin{array}{r}{\\overline{{\\pi}}^{(t)}(a|s)\\propto\\left(\\prod_{n=1}^{N}\\pi_{n}^{(t)}(a|s)\\right)^{1/N}}\\end{array}$ for each $(s,a)\\in{\\mathcal{S}}\\times{\\mathcal{A}}$ .Therefore, $\\overline{{\\pi}}^{(t)}$ $\\{\\pi_{n}^{(t)}\\}_{n\\in[N]}$ $\\pmb{Q}^{(t)}:=\\left(Q_{1}^{\\pi_{1}^{(t)}},\\cdot\\cdot\\cdot\\,,Q_{N}^{\\pi_{N}^{(t)}}\\right)^{\\top}$ $\\pmb{Q}_{\\tau}^{(t)}:=\\left(Q_{\\tau,1}^{\\bar{\\pi_{1}^{(t)}}},\\cdot\\cdot\\cdot\\,,Q_{\\tau,N}^{\\pi_{N}^{(t)}}\\right)^{\\top}$   \nthe notation and treat $\\pi^{(t)}$ \uff0c ${Q_{\\tau}^{(t)}}$ as matrices in $\\mathbb{R}^{N\\times|S||A|}$ , and treat $\\pi^{(t)}(a|s)$ $Q_{\\tau}^{(t)}(a|s)$ as vectors   \nin $\\mathbb{R}^{N}$ , for all $(s,a)\\in S\\times A$ ", "page_idx": 5}, {"type": "text", "text": "Vanilla federated NPG methods.  To motivate the algorithm development, observe that the NPG method (cf. (8) applied to (12) adopts the update rule $\\begin{array}{r l}{\\pi^{(t+1)}(a|s)}&{{}\\propto}\\end{array}$ $\\begin{array}{r}{\\pi^{(t)}(a|s)\\exp\\left(\\frac{\\eta\\sum_{n=1}^{N}Q_{n}^{\\pi^{(t)}}(s,a)}{N(1-\\gamma)}\\right)}\\end{array}$ for all $(s,a)\\,\\in\\,S\\,\\times\\,A$ . Two challenges arise when executing this update rule: the policy estimates are maintained locally without consensus, and the global Q-function are unavailable in the decentralized setting. To address these challenges, we apply the idea of dynamic average consensus [ZM10], where each agent maintains ts own estimate $T_{n}^{(t)}(s,a)$ of the global Q-function, which are collected as vector T(t) = (T(t), $\\mathbf{T}_{.}^{(t)}=\\left(T_{\\perp}^{(t)},\\cdot\\cdot\\cdot,T_{N_{.}}^{(t)}\\right)^{\\top}$ To..i ,T).At each iteration, each agent updates its policy estimates based on its neighbors' information via gossip mixing, in addition to a correction term that tracks the difference $Q_{n}^{\\pi_{n}^{(t+1)}}(s,a)-Q_{n}^{\\pi_{n}^{(t)}}(s,a)$ of the local Q-functions between consecutive policy updates. Note that the mixing is applied linearly to the logarithms of local policies, which translates into a multiplicative mixing of the local policies. Algorithm 1 summarizes the detailed procedure of the proposed algorithm written in a compact matrix form, which we dub as federated NPG (FedNPG). Note that the agents do not need to share their reward functions with others, and agent $n\\in[N]$ will only be responsible to evaluate the local policy $\\pi_{n}^{(t)}$ using the local reward $r_{n}$ ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Entropy-regularized federated NPG methods. Moving onto the entropy regularized case, we adopt similar algorithmic ideas to decentralize (9), and propose the federated NPG (FedNPG) method with entropy regularization, summarized in Algorithm 2 (see Appendix C.1). Clearly, the entropyregularized FedNPG method reduces to vanilla FedNPG in the absence of the regularization (i.e., when $\\tau=0$ ", "page_idx": 6}, {"type": "text", "text": "3.2  Theoretical guarantees ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Global convergence of FedNPG with exact policy evaluation. We begin with the global convergence of FedNPG (cf. Algorithm 1), stated in the following theorem. The formal statement and proof can be found in Appendix D.3, and see Appendix B.2 for discussions on the technical challenges. ", "page_idx": 6}, {"type": "text", "text": "ThoreGoba bnearenefxactFG(nfmal) $\\pi_{n}^{(0)},n\\in[N]$ are set as the uniform distribution. Then when T > 128o Al $\\begin{array}{r}{\\eta=\\left(\\frac{(1-\\gamma)^{9}(1-\\sigma)^{2}\\log{|A|}}{32T N\\sigma^{2}}\\right)^{1/3}}\\end{array}$ wehave ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{T}\\sum_{t=0}^{T-1}\\left(V^{\\star}(\\rho)-V^{\\overline{{\\pi}}^{(t)}}(\\rho)\\right)\\lesssim\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{(1-\\gamma)T}+\\frac{N^{1/3}\\sigma^{2/3}}{(1-\\gamma)^{3}(1-\\sigma)^{2/3}}\\left(\\frac{\\log|A|}{T}\\right)^{2/3}\\,.}\\\\ &{\\quad\\quad\\left\\|\\log\\pi_{n}^{(t)}-\\log\\bar{\\pi}^{(t)}\\right\\|_{\\infty}\\lesssim\\frac{N^{2/3}\\sigma^{1/3}}{(1-\\gamma)(1-\\sigma)^{1/3}}\\left(\\frac{\\log|A|}{T}\\right)^{1/3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3.3 characterizes the average-iterate convergence of the average policy $\\overline{{\\pi}}^{(t)}$ (cf. (14) across the agents, which depends logarithmically on the size of the action space, and independently on the size of the state space. Theorem 3.3 indicates that in the server-client setting with $\\sigma\\,=\\,0$ the convergence rate of FedNPG recovers the $\\mathcal{O}(1/T)$ rate, matching that of the centralized NPG established in [AKLM21]; on the other end, in the decentralized setting where $\\sigma>0$ , FedNPG slows down and eventually converges at the slower $\\mathcal{O}(1/T^{2/3})$ rate. ", "page_idx": 6}, {"type": "text", "text": "We state the iteration complexity in Corollary 3.4. ", "page_idx": 6}, {"type": "text", "text": "Corollary 3.4 (Iteration complexity of exact FedNPG). To reach $\\begin{array}{r l}{\\frac{1}{T}\\sum_{t=0}^{T-1}\\left(V^{\\star}(\\rho)\\,\\mathrm{~-~}\\,\\right.}&{{}}\\end{array}$ V\u03c0(t)(p)) E\uff0c the iteration complexity of FedNPG isat most $\\begin{array}{r}{\\mathcal{O}\\Big(\\Big(\\frac{\\sigma}{(1-\\gamma)^{9/2}(1-\\sigma)\\varepsilon^{3/2}}+\\frac{\\sigma^{2}}{(1-\\sigma)^{4}}\\Big)\\,\\sqrt{N}\\log|\\mathcal{A}|+\\frac{1}{\\varepsilon(1-\\gamma)^{2}}\\Big).}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "Global convergence of FedNPG with inexact policy evaluation. In practice, the policies need to be evaluated using samples collected by the agents, where the Q-functions are only estimated approximately. We are interested in gauging how the approximation error impacts the performance of FedNPG, as demonstrated in the following theorem. The formal statement, detailed discussions, and proof of this result is given in Appendix D.4. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5 (Global sublinear convergence of inexact FedNPG (informal). Suppose that an estimate $q_{n}^{\\pi_{n}^{(t)}}$ areused inreplaceof $Q_{n}^{\\pi_{n}^{(t)}}$ in Algorithm 1. Under the assumptions of Theorem 3.3, when $\\begin{array}{r}{T\\gtrsim\\frac{\\sqrt{N}\\log|\\mathcal{A}|\\sigma^{4}}{(1-\\sigma)^{4}}}\\end{array}$ and $\\begin{array}{r}{\\eta=\\left(\\frac{(1-\\gamma)^{9}(1-\\sigma)^{2}\\log{|A|}}{32T N\\sigma^{2}}\\right)^{1/3}}\\end{array}$ we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{T}\\displaystyle\\sum_{t=0}^{T-1}\\Big(V^{\\star}(\\rho)-V^{\\overline{{\\pi}}^{(t)}}(\\rho)\\Big)\\lesssim\\displaystyle\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{(1-\\gamma)T}+\\frac{N^{1/3}\\sigma^{2/3}}{(1-\\gamma)^{3}(1-\\sigma)^{2/3}}\\left(\\frac{\\log{|\\mathcal{A}|}}{T}\\right)^{2/3}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\frac{1}{(1-\\gamma)^{2}}\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\|Q_{n}^{\\pi_{n}^{(t)}}-q_{n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Equipped with existing sample complexity bounds on policy evaluation, e.g. using a simulator as in [LWCC23a], this immediate leads to the sample complexity per state-action pair at each agent to find an $\\varepsilon$ -optimal policy is at most ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{N}}{(1-\\gamma)^{11.5}(1-\\sigma)\\varepsilon^{3.5}}\\right)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "for sufficiently small $\\varepsilon$ ", "page_idx": 7}, {"type": "text", "text": "Global convergence of entropy-regularized FedNPG with exact policy evaluation. Next, we present our global convergence guarantee of entropy-regularized FedNPG with exact policy evaluation (cf. Algorithm 2). ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.6 (Global linear convergence of exact entropy-regularized FedNPG (informal). For anry $\\gamma\\,\\in\\,(0,1)$ and $0\\,<\\,\\tau\\,\\leq\\,1,$ there exists $\\begin{array}{r}{\\eta_{0}\\,=\\,\\operatorname*{min}\\left\\lbrace\\frac{1-\\bar{\\gamma}}{\\tau},\\mathcal{O}\\left(\\frac{(1-\\gamma)^{7}(1-\\sigma)^{2}\\tau}{\\sigma^{2}N}\\right)\\right\\rbrace}\\end{array}$ such that $i f$ $0<\\eta\\leq\\eta_{0}$ , then we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\|_{\\infty}\\leq2\\gamma C_{1}\\rho(\\eta)^{t}\\qquad\\left\\|\\log\\pi_{\\tau}^{\\star}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq\\frac{2C_{1}}{\\tau}\\rho(\\eta)^{t}\\,,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\overline{{Q}}_{\\tau}^{(t)}:=Q_{\\tau}^{\\overline{{\\pi}}^{(t)}}$ \uff0c $\\begin{array}{r}{\\rho(\\eta)\\le\\operatorname*{max}\\{1-\\frac{\\tau\\eta}{2},\\frac{3+\\sigma}{4}\\}<1}\\end{array}$ \", 3}<1, and C is some problem-dependent constant. Furthermore, the consensus error satisfies ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\big\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\big\\|_{\\infty}\\leq2C_{1}\\rho(\\eta)^{t}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The exact expressions of $C_{1}$ and $\\eta_{0}$ are specified in Appendix D.1. Theorem 3.6 confirms that entropy-regularized FedNPG converges at a linear rate to the optimal regularized policy, which is almost independent of the size of the state-action space, highlighting the positive role of entropy regularization in federated policy optimization. When the network is fully connected, i.e. $\\sigma=0$ the ieration complexity of entropy-reglaized FedNPG reduces to $\\begin{array}{r}{\\mathcal{O}\\Big(\\frac{1}{\\eta\\tau}\\log\\frac{1}{\\varepsilon}\\Big)}\\end{array}$ , matching that of the centralized entropy-regularized NPG established in [CWC21]. When the network is less connected, one needs to be more conservative in the choice of learning rates, leading to a higher iteration complexity, as described in the following corollary. ", "page_idx": 7}, {"type": "text", "text": "Corollary 3.7 (Iteration complexity of exact entropy-regularized FedNPG). To reach $\\left\\|\\log\\pi_{\\tau}^{\\star}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq\\varepsilon$ the iteration complexity of entropy-regularized FedNPG is at most ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{O}}\\left(\\operatorname*{max}\\left\\{\\frac{2}{\\tau\\eta},\\frac{4}{1-\\sigma}\\right\\}\\log\\frac{1}{\\varepsilon}\\right)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "up to logarithmic factors. Especially, when $\\eta~=~\\eta_{0}$ \uff0cthe best iteration complexity becomes $\\begin{array}{r}{\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{N\\sigma^{2}}{(1-\\gamma)^{7}(1-\\sigma)^{2}\\tau^{2}}+\\frac{1}{1-\\gamma}\\right)\\log\\frac{1}{\\tau\\varepsilon}\\right)}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "Global convergence of entropy-regularized FedNPG with inexact policy evaluation. Last but not the least, we present the informal convergence results of entropy-regularized FedNPG with inexact policy evaluation, whose formal version can be found in Appendix D.2. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.8 (Global linear convergence of inexact entropy-regularized FedNPG (informal). Suppose that an estimate qT,n are used in replace of $\\boldsymbol{Q}_{\\tau,n}^{\\pi_{n}^{(t)}}$ in Algorithm 2. Under the assumptions of Theorem 3.6, we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\|_{\\infty}\\leq2\\gamma\\Big(C_{1}\\rho(\\eta)^{t}+C_{2}\\varepsilon_{q}\\Big)\\,,\\quad\\left\\|\\log\\pi_{\\tau}^{\\star}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq\\frac{2}{\\tau}\\Big(C_{1}\\rho(\\eta)^{t}+C_{2}\\varepsilon_{q}\\Big)\\,,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "$\\overline{{Q}}_{\\tau}^{(t)}:=Q_{\\tau}^{\\overline{{\\pi}}^{(t)}}$ $\\begin{array}{r}{,\\varepsilon_{q}:=\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\|Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty},\\rho(\\eta)\\leq\\operatorname*{max}\\{1-\\frac{\\tau\\eta}{2},\\frac{3+\\sigma}{4}\\}<1\\,}\\end{array}$ ,and $C_{1}$ $C_{2}$ areproblem-dependentconstants. ", "page_idx": 7}, {"type": "text", "text": "4  Federated NAC with function approximation and stochastic evaluation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, motivated by the design and analysis of FedNPG, we go beyond the tabular setting and exact policy evaluation, by proposing a federated natural actor-critic (FedNAC) method with function approximation and stochastic policy evaluation. Specifically, we consider the policy with function approximation under softmax parameterization is of the following form: ", "page_idx": 7}, {"type": "equation", "text": "$$\nf_{\\xi}(a|s)=\\frac{\\exp(\\phi^{\\top}(s,a)\\pmb\\xi)}{\\sum_{a^{\\prime}\\in\\mathcal{A}}\\exp(\\phi^{\\top}(s,a^{\\prime})\\pmb\\xi)},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "for all $(s,a)\\in S\\times A$ and $\\xi\\in\\mathbb{R}^{p}$ , where $\\phi:S\\times A\\rightarrow\\mathbb{R}^{p}$ is a known feature map. We assume $\\phi$ is bounded over ${\\mathcal{S}}\\times{\\mathcal{A}}$ , i.e., there exists $C_{\\phi}>0$ such that $\\|\\phi(s,a)\\|_{2}\\leq C_{\\phi}$ holds for all $(s,a)\\in S\\times A$ ", "page_idx": 7}, {"type": "text", "text": "Following [AKLM21, $\\mathrm{YDG}^{+}22]$ , given any $\\pmb{w}\\in\\mathbb{R}^{p}$ \uff0c $Q:S\\times A\\rightarrow\\mathbb{R}$ and probability distribution $\\zeta\\in\\Delta(S\\times A)$ over the state-action space, we define the function approximation error $\\ell(w,Q,\\zeta)$ as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\ell({\\pmb w},Q,\\zeta):=\\mathbb{E}_{({\\pmb\\mathscr{s}},{\\pmb a})\\sim\\zeta}\\left[\\left({\\pmb w}^{\\top}\\phi({\\pmb s},{\\pmb a})-Q({\\pmb s},{\\pmb a})\\right)^{2}\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "By searching for $\\pmb{w}$ that minimizes $\\ell(w,Q,\\zeta)$ , it approximates $Q(s,a)$ using the feature map $\\phi$ with respect to the distribution $\\zeta$ ", "page_idx": 8}, {"type": "text", "text": "Algorithm design. Let us now discuss the high-level design of FedNAC, which is presented in Algorithm 3, with more details provided in Appendix C.2. At the $t$ -th iteration $(t=0,.\\,.\\,.\\,,T-1)$ \uff0c denote the ator conermning the plicies) parametes o allaents as $\\pmb{\\xi}^{(t)}\\,=\\,(\\pmb{\\xi}_{1}^{(t)},\\ldots,\\pmb{\\xi}_{N}^{(t)})^{\\top}\\,\\in$ $\\mathbb{R}^{N\\times p}$ andtheritpafall $\\pmb{w}^{(t)}=(\\pmb{w}_{1}^{(t)},\\dots,\\pmb{w}_{N}^{(t)})^{\\top}\\in\\mathbb{R}^{N\\times p}$ (concerning the local Q-values and $\\pmb{h}^{(t)}=(\\pmb{h}_{1}^{(t)},\\cdot\\cdot\\cdot\\cdot,\\pmb{h}_{N}^{(t)})^{\\top}\\in\\mathbb{R}^{N\\times p}$ (concerning the global Q-values). ", "page_idx": 8}, {"type": "text", "text": "\u00b7 First, the critic parameter ${\\pmb w}_{n}^{(t)}$ is locally updated at each agent by aiming to minimize $\\ell(\\pmb{w},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})$ (cf. (25) with gradient descent, where $Q_{n}^{(t)}$ is the local Q-function of the local policy $f_{\\xi_{n}^{(t)}}$ , and $\\tilde{d}_{n}^{(t)}$ is the state-actionvisitationdistribution induced by thelocal policy $f_{\\xi_{n}^{(t)}}$ and an initial state-action distribution $\\nu$ (determined from the data sampling mechanism, cf. (30)). However, since $Q_{n}^{(t)}$ is not direly availablit nes t estmatdfr slTf the critic update takes $K$ steps of stochastic gradient descent with critic learning rate $\\beta$ , given by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{w}}_{k+1}=\\widetilde{\\pmb{w}}_{k}-\\beta\\big(\\widetilde{\\pmb{w}}_{k}^{\\top}\\phi(s_{k},a_{k})-\\widehat{Q}_{\\xi}(s_{k},a_{k})\\big)\\phi(s_{k},a_{k}),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for $k=0,\\ldots,K-1$ , where $(s_{k},a_{k})$ is sampled on the local policy $f_{\\xi_{n}^{(t)}}$ , and $\\widehat{Q}_{\\xi}(s_{k},a_{k})$ is a careful estimate of the Q-value using a trajectory with expected length $1/(1\\!-\\!\\gamma)$ (see Algorithm 5 in Appendix C.2 adopted from $[\\mathrm{YDG^{+}}22]$ , Lemma 4]), and $\\widetilde{\\pmb w}_{0}={\\bf0}$ for simplicity. The final critic is updated as $\\begin{array}{r}{\\pmb{w}_{n}^{(t)}=\\frac{1}{K}\\sum_{k=1}^{K}\\widetilde{\\pmb{w}}_{k}}\\end{array}$ . The total sample complexity of the critic update per iteration is then on the order of $K^{\\prime}(\\bar{1}-\\gamma)$ ", "page_idx": 8}, {"type": "text", "text": "\u00b7 Next, the critic parameter $h_{n}^{(t)}$ for estimating the global Q-function can then be estimated by averaging with the neighbors with the Q-tracking term, given by $\\begin{array}{r l}{\\pmb{h}^{(t)}}&{{}=}\\end{array}$ $W\\left(h^{(t-1)}+w^{(\\check{t})}-w^{(t-1)}\\right)$   \n\u00b7 Finally, the actor parameter $\\xi_{n}^{(t)}$ can be updated via averaging with the neighbors along with the   \npolicy gradient informed by $h_{n}^{(t)}$ , given by $\\pmb{\\xi}^{(t+1)}=W\\left(\\pmb{\\xi}^{(t)}+\\alpha\\pmb{h}^{(t)}\\right)$ where $\\alpha$ is the learning rate of the actor. ", "page_idx": 8}, {"type": "text", "text": "Note that the sample complexity of FedNAC is on the order of $K T/(1-\\gamma)$ : An important aspect of the FedNAC method is that the policy is updated using trajectory data collected via executing the learned policy, which is closer to practice and more challenging to learn than using the generative model. ", "page_idx": 8}, {"type": "text", "text": "Theoretical guarantees. We first state the assumptions that are needed to guarantee the convergence of Algorithm 3, which are all commonly used in the literature, e.g., $[\\mathrm{YDG}^{\\bar{+}}22$ ,AKLM21]. To begin, we require the covariance matrix of the feature map induced by the initial state-action distribution $\\nu$ satisfies the following assumption to guarantee the convergence of the critic. ", "page_idx": 8}, {"type": "text", "text": "Assumption 4.1 (PsD of the covariance matrix of the feature map). There exists $\\mu>0$ such that $\\mathbb{E}_{(s,a)\\sim\\nu}\\left[\\phi(s,a)\\dot{\\phi}^{\\top}(s,a)\\right]=\\Sigma_{\\nu}\\geq\\mu I$ ", "page_idx": 8}, {"type": "text", "text": "We also need to ensure that the $\\mathrm{^Q}$ -values can be well approximated by the linear function approximation using feature map $\\phi(s,a)$ , which is captured next. ", "page_idx": 8}, {"type": "text", "text": "Assumption 42 (Bounded approximation error). For each $\\textit{n}\\in\\:[N]$ , there exists $\\varepsilon_{\\mathrm{approx}}^{n}~\\geq~0$ such that fo al $t~\\in~\\mathbb{N}$ . it hol s that $\\begin{array}{r l r}{\\mathbb{E}\\left[\\ell\\left(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)\\right]}&{\\leq}&{\\varepsilon_{\\mathrm{approx}}^{n}}\\end{array}$ where $w_{\\star,n}^{(t)}\\ :=$ $\\arg\\operatorname*{min}_{\\pmb{w}}\\ell\\left(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right).$ ", "page_idx": 8}, {"type": "text", "text": "We denote the average approximation error as $\\begin{array}{r}{\\bar{\\varepsilon}_{\\mathrm{approx}}=\\frac{1}{N}\\sum_{n=1}^{N}{\\varepsilon_{\\mathrm{approx}}^{n}}}\\end{array}$ Zn aprox-Similaras YDG+ 22l, wve need the following assumption that bounds the transfer errors due to distribution shifts. ", "page_idx": 8}, {"type": "text", "text": "Assumption 4.3 (Bounded transfer error). There exists $C_{\\nu}>0$ such that for all $n\\in[N]$ and $t\\in\\mathbb{N}$ it holds that E(s,a)\\~at) $\\begin{array}{r}{\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\frac{h^{\\pi}(s,a)}{\\tilde{d}_{n}^{(t)}(s,a)}\\right)^{2}\\right]\\le C_{\\nu}}\\end{array}$ , where $h^{\\pi}(s,a)$ is the state-action visitation distribution induced by any policy $\\pi$ from initial state distribution $\\rho$ ", "page_idx": 9}, {"type": "text", "text": "Note that if we choose $\\nu(s,a)>0$ for all $(s,a)\\in S\\times A$ , then Assumption 4.3 is guaranteed to hold true (see Lemma E.4 in Appendix $\\mathrm{E}$ ). We are now ready to state the convergence guarantee, whose formal version and proof could be found in Appendix $\\mathrm{E}$ ", "page_idx": 9}, {"type": "text", "text": "Theorem 4.4 (Convergence rate of Algorithm 3 (informal). Let $\\pmb{\\xi}_{1}^{(0)}\\,=\\,\\cdot\\,\\cdot\\,=\\,\\pmb{\\xi}_{N}^{(0)}$ in FedNAC. Denoting $\\begin{array}{r}{\\bar{\\pmb\\xi}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}\\pmb\\xi_{n}^{(t)}}\\end{array}$ and $\\bar{f}^{(t)}:=f_{\\bar{\\xi}^{(t)}}$ as the average policy. Then under Assumption 3.1, 4.1, 4.2 and 4.3, with appropriately chosen learning rates $\\alpha$ and $\\beta$ as long as the number of actor iterations satisfies ", "page_idx": 9}, {"type": "equation", "text": "$$\nT\\gtrsim\\operatorname*{max}\\left\\{\\frac{\\sigma}{\\varepsilon^{3/2}(1-\\gamma)^{17/4}(1-\\sigma)^{3/2}},\\frac{1}{\\varepsilon(1-\\gamma)},\\frac{\\sigma^{1/4}}{\\varepsilon^{3/4}(1-\\sigma)^{3/8}(1-\\gamma)^{7/8}N^{3/8}},\\frac{\\sigma^{4}}{(1-\\gamma)^{2}(1-\\sigma)^{6}}\\right\\}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "and the number of critic iterations satisfies $\\begin{array}{r}{K=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{6}\\varepsilon^{2}}\\right)}\\end{array}$ itholdsthat ", "page_idx": 9}, {"type": "equation", "text": "$$\nV^{\\star}(\\rho)-\\frac{1}{T}\\sum_{t=0}^{T-1}V^{\\bar{f}^{(t)}}(\\rho)\\lesssim\\varepsilon+\\frac{\\bar{\\varepsilon}_{a p p r o x}}{1-\\gamma}.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "In the server-client setting when $\\sigma=0$ , to reach (26), it suffices to choose $\\begin{array}{r}{T=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)\\varepsilon}\\right)}\\end{array}$ and $\\begin{array}{r}{K\\,=\\,\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{6}\\varepsilon^{2}}\\right)}\\end{array}$ leading to tota sampe omplexity of $\\begin{array}{r}{K T/(1-\\gamma)\\,=\\,\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{8}\\varepsilon^{3}}\\right)}\\end{array}$ per agent, and $\\begin{array}{r}{T=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)\\varepsilon}\\right)}\\end{array}$ rounds of communication. The sample complexity matches that of (centralized) Q-NPG established in $[\\mathrm{YDG}^{+}22]$ with a single agent. On the other end, in the fully decentralized setting when $\\sigma$ is not close to O, FedNAC requires $\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{45/4}\\varepsilon^{7/2}(1-\\sigma)^{3/2}}\\right)$ samples for each agent and $\\begin{array}{r}{{\\mathcal{O}}\\left(\\frac{1}{\\varepsilon^{3/2}(1-\\gamma)^{17/4}(1-\\sigma)^{3/2}}\\right)}\\end{array}$ rounds of communication to reach (26), for sufficiently small $\\varepsilon$ . Encouragingly, the dependency on the accuracy level $\\varepsilon$ \u2014 the dominating factor \u2014 in the sample complexity matches that of FedNPG given in (19) when assuming access to the generative model, which allows query of arbitrary state-action pairs. In contrast, FedNAC only collects on-policy samples, and therefore is much more challenging to guarantee its convergence. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work proposes the first provably efficient federated NPG (FedNPG) methods for solving vanilla and entropy-regularized multi-task RL problems in the fully decentralized setting. The established finite-time global convergence guarantees are almost independent of the size of the state-action space up to some logarithmic factor, and illuminate the impacts of the size and connectivity of the network. Furthermore, the proposed FedNPG methods are provably robust vis-a-vis inexactness of local policy evaluations. Last but not least, we also propose FedNAC, which can be viewed as an extension of FedNPG with function approximation and stochastic policy evaluation, and establish its finite-time sample complexity. Future directions include generalizing the framework of federated policy optimization to allow personalized policy learning in a shared environment. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The work of T. Yang, S. Cen and Y. Chi are supported in part by the grants ONR N00014-19-1-2404, NSF CCF-1901199, CCF-2106778, AFRL FA8750-20-2-0504, and a CMU Cylab seed grant. The work of Y. Wei is supported in part by the the NSF grants DMS-2147546/2015447, CAREER award DMS-2143215, CCF-2106778, and the Google Research Scholar Award. The work of Y. Chen is supported in part by the Alfred P. Sloan Research Fellowship, the Google Research Scholar Award, the AFOSR grant FA9550-22-1-0198, the ONR grant N00014-22-1-2354, and the NSF grants CCF2221009 and CCF-1907661. S. Cen is also gratefully supported by Wei Shen and Xuehong Zhang Presidential Fellowship, Boeing Scholarship, and JP Morgan Chase PhD Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[AKLM21] A. Agarwal, S. M. Kakade, J. D. Lee, and G. Mahajan. On the theory of policy gradient methods: Optimality, approximation, and distribution shift. The Journal of Machine Learning Research, 22(1):4431-4506, 2021.   \n[ALRNS19] Z. Ahmed, N. Le Roux, M. Norouzi, and D. Schuurmans. Understanding the impact of entropy on policy optimization. In International Conference on Machine Learning, pages 151-160, 2019. [Ama98] S.-I. Amari. Natural gradient works eficiently in learning. Neural computation, 10(2):251-276, 1998. [AR21] A. Anwar and A. Raychowdhury. Multi-task federated reinforcement learning with adversaries. arXiv preprint arXiv:2103.06473, 2021.   \n[ARB+19] M. Assran, J. Romoff, N. Ballas, J. Pineau, and M. Rabbat. Gossip-based actorlearner architectures for deep reinforcement learning. Advances in Neural Information Processing Systems, 32, 2019. [BM13] F. Bach and E. Moulines. Non-strongly-convex smooth stochastic approximation with convergence rate o (1/n). Advances in neural information processing systems, 26, 2013. [BR21] J. Bhandari and D. Russo. On the linear convergence of policy gradient methods for fniteMPsIIntational ConferenceonAtifcialInteligenceand Statisticpages 2386-2394. PMLR, 2021.   \n[BSGLO9] S. Bhatnagar, R. S. Sutton, M. Ghavamzadeh, and M. Lee. Natural actor-critic algorithms. Automatica, 45(11):2471-2482, 2009.   \n$[\\mathrm{CCC}^{+}22\\mathrm{a}$ ] S. Cen, C. Cheng, Y. Chen, Y. Wei, and Y. Chi. Fast global convergence of natural policy gradient methods with entropy regularization. Operations Research, 70(4):2563-2578, 2022.   \n[CCC+22b] S. Cen, C. Cheng, Y. Chen, Y. Wei, and Y. Chi. Fast global convergence of natural policy gradient methods with entropy regularization. Operations Research, 70(4):2563-2578, 2022.   \n[CCDX22] S. Cen, Y. Chi, S. S. Du, and L. Xiao. Faster last-iterate convergence of policy optimization in zero-sum Markov games. In The Eleventh International Conference on Learning Representations, 2022.   \n[CFGW22] J. Chen, J. Feng, W. Gao, and K. Wei. Decentralized natural policy gradient with variance reduction for collaborative multi-agent reinforcement learning. arXiv preprint arXiv:2209.02179, 2022. [CWC21] S. Cen, Y. Wei, and Y. Chi. Fast policy extragradient methods for competitive games with entropy regularization. Advances in Neural Information Processing Systems, 34:27952-27964, 2021. [CZC21] Z. Chen, Y. Zhou, and R. Chen. Multi-agent off-policy TDC with near-optimal sample and communication complexity In2021 55th Asilomar Conference on Signals, Systems, and Computers, pages 504-508. IEEE, 2021.   \n[CZGB21] T. Chen, K. Zhang, G. B. Giannakis, and T. Basar. Communication-effcient policy gradient methods for distributed reinforcement learning. IEEE Transactions on Control of Network Systems, 9(2):917-929, 2021. [DAW11] J. C. Duchi, A. Agarwal, and M. J. Wainwright. Dual averaging for distributed optimization: Convergence analysis and network scaling. IEEE Transactions on Automatic control, 57(3):592-606, 2011. [DLS16] P. Di Lorenzo and G. Scutari. Next: In-network nonconvex optimization. IEEE Transactions on Signal and Information Processing over Networks, 2(2):120-136, 2016. [EL21] B. Eysenbach and S. Levine. Maximum entropy RL (provably) solves some robust RL problems. In International Conference on Learning Representations, 2021. $[\\mathrm{ESM^{+}18}]$ 1L. Espeholt, H. Soyer, R. Munos, K. Simonyan, V. Mnih, T. Ward, Y. Doron, V. Firoiu, T. Harley, I. Dunning, et al. Impala: Scalable distributed deep-rl with importance weightedactor-learerarchitectures.InInternational conferenconmachinelearning, pages 1407-1416. PMLR, 2018. [HJ12] R. A. Horn and C. R. Johnson. Matrix analysis. Cambridge university press, 2012. [KakO1] S. M. Kakade. A natural policy gradient. Advances in neural information processing systems,14, 2001.   \n[KDRM22] S. Khodadadian, T. T. Doan, J. Romberg, and S. T. Maguluri. Finite sample analysis of two-time-scale natural actor-critic algorithm. IEEE Transactions on Automatic Control, 2022. [KJVM21] S. Khodadadian, P. R. Jhunjhunwala, S. M. Varma, and S. T. Maguluri. On the linear convergence of natural policy gradient algorithm. In 2021 60th IEEE Conference on Decision and Control (CDC), pages 3794-3799. IEEE, 2021. [KMP12] S. Kar, J. M. Moura, and H. V. Poor. Qd-learning: A collaborative distributed strategy for multi-agent reinforcement learning through consensus. arXiv preprint arXiv: 1205.0047, 2012. [KSJM22] S. Khodadadian, P. Sharma, G. Joshi, and S. T. Maguluri. Federated reinforcement learning: Linear speedup under Markovian sampling. In International Conference on Machine Learning, pages 10997-11057. PMLR, 2022. [Lan23] G. Lan. Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes. Mathematical programming, 198(1):1059-1106, 2023. [LCCC2O] B. Li, S. Cen, Y. Chen, and Y. Chi. Communication-efficient distributed optimization in networks with gradient tracking and variance reduction. The Journal of Machine Learning Research, 21(1):7331-7381, 2020. [LLZ23] G. Lan, Y. Li, and T. Zhao. Block policy mirror descent. SIAM Journal on Optimization, 33(3):2341-2378, 2023. [LO08] 1. Lobel and A. Ozdaglar. Convergence analysis of distributed subgradient methods over random networks. In 2008 46th Annual Allerton Conference on Communication, Control, and Computing, pages 353-360. IEEE, 2008. [LWA+23] G. Lan, H. Wang, J. Anderson, C. Brinton, and V. Aggarwal. Improved communication efficiency in federated natural policy gradient via admm-based gradient updates. arXiv preprint arXiv:2310.19807, 2023.   \n[LWCC23a] G. Li, Y. Wei, Y. Chi, and Y. Chen. Breaking the sample size barrier in model-based reinforcement learning with a generative model. Operations Research, 2023.   \n[LWCC23b] G. Li, Y. Wei, Y. Chi, and Y. Chen. Softmax policy gradient methods can take exponential time to converge. Mathematical Programming, pages 1-96, 2023. $[\\mathrm{L}Z Z^{+}17]$ X. Lian, C. Zhang, H. Zhang, C.-J. Hsieh, W. Zhang, and J. Liu. Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent. Advances in neural information processing systems, 30, 2017. [MA22] M. M Alshater. Exploring the role of artificial intelligence in enhancing academic performance: A case study of chatgpt. Available at SSRN, 2022.   \n$[\\mathrm{MBM}^{+}16]$ V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Lillicrap, T. Harley, D. Silver, and K. Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International conference on machine learning, pages 1928-1937, 2016. [MPy] K. D. McKelvey and I. K. Palrey. Quantal response equibria for normal form games. Games and economic behavior, 10(1):6-38, 1995.   \n[MXSS20] J. Mei, C. Xiao, C. Szepesvari, and D. Schuurmans. On the global convergence rates of softmaxpolicy gradient methods. In International Conference on Machine Learning, pages 6820-6829. PMLR, 2020.   \n[NNXS17] O. Nachum, M. Norouzi, K. Xu, and D. Schurmans. Bridging the gap between value and policy based reinforcement learning. InAdvances in Neural Information Processing Systems, pages 2775-2785, 2017. [NO09] A. Nedic and A. Ozdaglar. Distributed subgradient methods for multi-agent optimization. IEEE Transactions on Automatic Control, 54(1):48-61, 2009. [NOR18] A. Nedic, A. Olshevsky, and M. G. Rabbat. Network topology and communicationcomputation tradeoffs in decentralized optimization. Proceedings of the IEEE, 106(5):953-976, 2018. [NOS17] A. Nedic, A. Olshevsky, and W. Shi. Achieving geometric convergence for distributed optimization over time-varying graphs. SIAM Journal on Optimization, 27(4):2597- 2633, 2017.   \n[OPA+ 17] S. Omidshafiei, J. Pazis, C. Amato, J. P. How, and J. Vian. Deep decentralized multitask multi-agent reinforcement learning under partial observability. In International Conference on Machine Learning, pages 2681-2690. PMLR, 2017. [PN21] S. Pu and A. Nedic. Distributed stochastic gradient tracking methods. Mathematical Programming, 187:409-457, 2021. [PPO8] K. B. Petersen and M.S. Pedersen. The matrix cookbook. Technical University of Denmark, 7(15):510, 2008. [Put14] M. L. Puterman. Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons, 2014. [QL17] G. Qu and N. Li. Harnessing smoothness to accelerate distributed optimization. IEEE Transactions on Control of Network Systems, 5(3):1245-1260, 2017.   \n[QZLZ21] J. Qi, Q. Zhou, L. Lei, and K. Zheng. Federated reinforcement learning: Techniques, applications, and open challenges. arXiv preprint arXiv:2108.11887, 2021.   \n$[\\mathbf{R}\\mathbf{T}\\mathbf{R}^{+}23]$ 1M. M. Rahman, H. J. Terano, M. N. Rahman, A. Salamzadeh, and M. S. Rahaman. Chatgpt and academic research: a review and recommendations based on practical examples. Rahman, M., Terano, HJR, Rahman, N., Salamzadeh, A., Rahaman, S.(2023). ChatGPTandAcademicResearch:A Review and RecommendationsBasedonPractical Examples. Journal of Education, Management and Development Studies, 3(1):1-12, 2023. [SEM20] L. Shani, Y. Efroni, and S. Mannor. Adaptive trust region policy optimization: Global convergence and faster rates for regularized MDPs. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 5668-5675, 2020.   \n$[\\mathrm{SLA^{+}15}]$ J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz. Trust region policy optimization. In International conference on machine learning, pages 1889-1897, 2015.   \n$[\\mathrm{SWD}^{+}17]$ J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv: 1707.06347, 2017.   \nWCYW19] L. Wang, Q. Cai, Z. Yang, and Z. Wang. Neural policy gradient methods: Global optimality and rates of convergence. arXiv preprint arXiv: 1909.01150, 2019.   \n$[\\mathrm{WHM}^{+}23]$ 1 J. Wang, J. Hu, J. Mills, G. Min, M. Xia, and N. Georgalas. Federated ensemble model-based reinforcement learning in edge computing. IEEE Transactions on Parallel and Distributed Systems, 2023. [WJC23] J. Woo, G. Joshi, and Y. Chi. The blessing of heterogeneity in federated q-learning: Linear speedup and beyond. arXiv preprint arXiv:2305.10697, 2023.   \n[WKNL20] H. Wang, Z. Kaplan, D. Niu, and B. Li. Optimizing federated learning on non-id data with reinforcement learning. In IEEE INFOCOM 2020-IEEE Conference on Computer Communications, pages 1698-1707. IEEE, 2020. [WP91] R. J. Williams and J. Peng. Function optimization using connectionist reinforcement learning algorithms. Connection Science, 3(3):241-268, 1991.   \n[WSJC24] J. Woo, L. Shi, G. Joshi, and Y. Chi. Federated offline reinforcement learning: Collaborative single-policy coverage suffices. In Forty-first International Conference on Machine Learning, 2024. [Xia22] L. Xiao. On the convergence rates of policy gradient methods. The Journal of Machine Learning Research, 23(1):12887-12922, 2022.   \n[XWL20] T. Xu, Z. Wang, and Y. Liang. Improving sample complexity bounds for actor-critic algorithms. arXiv preprint arXiv:2004.12956, 2020.   \n$[\\mathbf{Y}\\mathbf{D}\\mathbf{G}^{+}22]$ R. Yuan, S. S. Du, R. M. Gower, A. Lazaric, and L. Xiao. Linear convergence of natural policy gradient methods with log-linear policies. arXiv preprint arXiv:2210.01400, 2022.   \n$[\\mathrm{YLS^{+}20}]$ T. Yu, T. Li, Y. Sun, S. Nanda, V. Smith, V. Sekar, and S. Seshan. Learning contextaware policies from multiple smart homes via federated multi-task learning. In 2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI), pages 104-115. IEEE, 2020.   \n$[Z\\mathrm{AD}^{+}21]$ S. Zeng, M. A. Anwar, T. T. Doan, A. Raychowdhury, and J. Romberg. A decentralized policy gradient approach to multi-task reinforcement learning. In Uncertainty in Artijficial Intelligence, pages 1002-1012. PMLR, 2021.   \n$[Z\\mathrm{BW}^{+}20]$ F. Zerka, S. Barakat, S. Walsh, M. Bogowicz, R. T. Leijenaar, A. Jochems, B. Miraglio, D. Townend, and P. Lambin. Systematic review of privacy-preserving distributed machine learning from federated databases in health care. JCO clinical cancer informatics, 4:184-200, 2020.   \n$\\mathrm{[ZCH^{+}23]}$ W. Zhan, S. Cen, B. Huang, Y. Chen, J. D. Lee, and Y. Chi. Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence. SIAM Journal on Optimization, 33(2):1061-1091, 2023.   \n$[Z\\mathrm{FL}^{+}19]$ H. H. Zhuo, W. Feng, Y. Lin, Q. Xu, and Q. Yang. Federated deep reinforcement learning. arXiv preprint arXiv:1901.08277, 2019.   \n$[Z\\mathrm{LK}^{+}22]$ R. Zhou, T. Liu, D. Kalathil, P. Kumar, and C. Tian. Anchor-changing regularized natural policy gradient for multi-objective reinforcement learning. Advances in Neural Information Processing Systems, 35:13584-13596, 2022. [ZM10] M. Zhu and S. Martinez. Discrete-time dynamic average consensus. Automatica, 46(2):322-329, 2010.   \n$[Z\\mathrm{RY}^{+}23]$ F. Zhao, X. Ren, S. Yang, P. Zhao, R. Zhang, and X. Xu. Federated multi-objective reinforcement learning. Information Sciences, 624:811-832, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Related work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Global convergence of NPG methods for tabular MDPs. [AKLM21] first establishes a $\\mathcal{O}(1/T)$ last-iterate convergence rate of the NPG method under softmax parameterization with constant step size, assuming access to exact policy evaluation. When entropy regularization is in place, [CWC21] establishes a global linear convergence to the optimal regularized policy for the entire range of admissible constant learning rates using softmax parameterization and exact policy evaluation, which is further shown to be stable in the presence of $\\ell_{\\infty}$ policy evaluation errors. The iteration complexity of NPG methods is nearly independent with the size of the state-action space, which is in sharp contrast to softmax policy gradient methods that may take exponential time to converge [LWCC23b, MXSS20]. [Lan23] proposed a more general framework through the lens of mirror descent for regularized RL with global linear convergence guarantees, which is further generalized in $[Z\\mathrm{CH}^{+}23$ , LLZ23]. Earlier analysis of regularized MDPs can be found in [SEM20]. Besides, [Xia22] proves that vanilla NPG also achieves linear convergence when geometrically increasing learning rates are used; see also [KJVM21, BR21]. $[Z\\mathrm{LK}^{+}22\\bar{]}$ developed an anchor-changing NPG method for multi-task RL under various optimality criteria in the centralized setting. ", "page_idx": 14}, {"type": "text", "text": "Convergence and sample complexity results of NAC. The convergence and sample complexity of a variety of natural actor-critic methods (NACs) are extensively studied in the literature [BSGL09, WCYW19, KDRM22, AKLM21, ${\\mathrm{YDG}}^{+}22]$ . More pertinent to our work, [AKLM21] introduced Q-NPG\u2014a sample version of the NPG method with function approximation under softmax parameterization \u2014and obtained a convergence rate of ${\\mathcal{O}}(1/{\\sqrt{T}})$ $[\\mathrm{YDG}^{+}22]$ weakens some of its assumptions and improves the convergence rate to $\\mathcal{O}(1/T)$ and gives the $\\widetilde{\\mathcal{O}}(1/\\varepsilon^{3})$ sample complexity using a constant actor learning rate. The FedNAC method we propose in this paper can be seen as a decentralized version of Q-NPG, and in the server-client setting where the network is fully connected, our convergence rate and sample complexity match those in $[\\mathbf{\\bar{Y}D G}^{+}22]$ ", "page_idx": 14}, {"type": "text", "text": "Distributed and federated RL. There have been a variety of settings being set forth for distributed and federated RL. $[\\mathrm{MBM^{+}}16$ ${\\mathrm{ESM}}^{+}18$ $\\mathrm{ARB^{+}19}$ , KSJM22, WJC23] focused on developing federated versions of RL algorithms to accelerate training, assuming all agents share the same transition kernel and reward function; in particular, [KSJM22, WJC23, WSJC24] established the provable benefits of federated learning in terms of linear speedup. More pertinent to our work, $[Z\\mathrm{R}\\bar{Y}^{+}23$ , AR21] considered the federated multi-task framework, allowing different agents having private reward functions. $[Z\\mathrm{RY}^{+}23]$ proposed an empirically probabilistic algorithm that can seek an optimal policy under the server-client setting, while [AR21] developed new attack methods in the presence of adversarial agents. Recently $[\\mathrm{LWA}^{+}23]$ discussed how to avoid transmitting the Hessian matrix during communication in the server-client setting where all agents share the same reward function. Different from the FRL framework, [CZGB21, CZC21, $\\mathrm{OPA^{+}17}$ , KMP12, CFGW22, $Z\\mathrm{AD}^{+}21]$ considered the distributed multi-agent RL setting where the agents interact with a dynamic environment through a multi-agent Markov decision process, where each agent can have their own state or action spaces. $[Z\\mathrm{AD}^{+}21]$ developed a decentralized policy gradient method where different agents have different MDPs, where a special case of their setting recovers ours. However, the convergence rate developed in $[Z\\mathrm{AD}^{+}21]$ has rather pessimistic dependencies with the size of the state-action space, together with other parameters, without leveraging natural policy gradients and gradient tracking techniques. ", "page_idx": 14}, {"type": "text", "text": "Decentralized first-order optimization algorithms. Early work of consensus-based first-order optimization algorithms for the fully decentralized setting include but are not limited to [LO08, NO09, DAW11]. Gradient tracking, which leverages the idea of dynamic average consensus [ZM10] to track the gradient of the global objective function, is a popular method to improve the convergence speed [QL17, NOS17, DLS16, PN21, LCCC20]. ", "page_idx": 14}, {"type": "text", "text": "B Additional Discussion ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Application Related to Federated Multi-task RL ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we elaborate more on our motivation and the application scenarios where federated multi-task RL becomes highly relevant. ", "page_idx": 14}, {"type": "text", "text": "We first provide some key motivations for our federated multi-task RL setting as follows. ", "page_idx": 14}, {"type": "text", "text": "\u00b7 Efficient knowledge transfer: multi-task RL enables agents to transfer knowledge across related tasks, accelerating learning and improving performance by leveraging experiences gained from one task to another. For instance, in our healthcare example in Section 1, by learning across hospitals with varying demographics, the agent can identify treatment strategies that are effective across diverse patient populations without directly accessing sensitive patient information. \u00b7 Generalization and adaptability: agents trained with multi-task RL can generalize their learned policies, adapt to new tasks, and handle diverse environments more effectively, enhancing their robustness and adaptability. In the healthcare example, an optimal treatment over different hospitals better adapts to variations in patient characteristics. \u00b7 Resource optimization: training a single policy for multiple tasks optimizes resource usage compared to training separate policies for each task, making it more efficient in scenarios with limited data or computational resources. In the healthcare example, the collaborative approach enhances learning efficiency and scalability while preserving data privacy, particularly in settings where each hospital has limited access to patient information. ", "page_idx": 15}, {"type": "text", "text": "Below we provide more application scenarios of our setting. ", "page_idx": 15}, {"type": "text", "text": ". To enhance ChatGPT's performance across different tasks or domains [MA22, $\\mathrm{RTR}^{+}23]$ one might consult domain experts to chat and rate ChatGPT's outputs for solving different tasks, and train ChatGPT in a federated manner without exposing private data or feedback ofeachexpert.   \n'. Our setting is especially suitable for the multi-task problems where each agent only have partial access of the \"global\" task. There are a lot of such problems. \u00b7 An example is the problem we consider in our experiments (see Appendix H), where we distributedly train the agents to learn a shared policy to follow a predetermined trajectory while each agent only has partial information of this trajectory. \u00b7 The above problem could be seen as a simplified version of the Unmanned Aerial Vehicle (UAV) Patrol Mission, each unmanned aerial vehicle (UAV) patrols only in a specific area, and they need to collectively train a strategy utilizing information from the entire patrol range. \u00b7 In the game setting, different agents aim to train a character to perform well in multiple tasks, and each agent trains on one task. ", "page_idx": 15}, {"type": "text", "text": "Despite the promise, provably efficient algorithms for federated multi-task RL remain substantially under-explored, especially in the fully decentralized setting. Our work is the first to provide efficient algorithms with global convergence guarantees for federated multi-task RL. ", "page_idx": 15}, {"type": "text", "text": "B.2  Theoretical Contribution ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we stress that while our work is built upon the algorithmic ideas in the distributed learning, reinforcement learning and optimization literature, it is not a strightforward combination and the theoretical analysis is by no means trivial. ", "page_idx": 15}, {"type": "text", "text": "One key difficulty is to estimate the global Q-functions using only neighboring information and local data. To address this issue, we invoke the \u201cQ-tracking\u201d step (see Algorithm 1, 2), which is inspired by the gradient tracking method in decentralized optimization. Note that this generalization is highly non-trivial: to the best of our knowledge, the utility of gradient tracking has not been exploited in policy optimization, and the intrinsic nonconcavity issue, together with the use of natural gradients, prevents us from directly using the results from decentralized optimization. It is thus of great value to study if the combination of NPG and gradient tracking could lead to fast globally convergent algorithms as in the standard decentralized optimization literature despite the nonconcavity. ", "page_idx": 15}, {"type": "text", "text": "Besides, due to the lack of global information sharing, care needs to be taken to judiciously balance the use of neighboring information (to facilitate consensus) and local data (to facilitate learning) when updating the policy. Compared to the centralized version of our proposed algorithms, a much more delicate theoretical analysis is required to prove our convergence results. For example, the key step to establish the convergence rate of the single-agent exact entropy-regularized NPG is to form the 2nd-order linear system in Eq. (46) in $[\\bar{\\mathrm{CCC}}^{+}\\bar{2^{2}}\\mathrm{a}]$ , while in our corresponding analysis, a 4th-order linear system in Eq. (49) is needed, where the inequality in each line is non-trivial and requires the introduction of some intricate and novel auxiliary lemmas, see Appendix D. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "C  Omitted Algorithms ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1 Federated NPG (FedNPG) with entropy regularization ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We record the entropy-regularized FedNPG method in Algorithm 2 here due to space limits. ", "page_idx": 16}, {"type": "text", "text": "Algorithm 2 Federated NPG (FedNPG) with entropy regularization ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1: Input: learning rate $\\eta>0$ iteration number $T\\in\\mathbb{N}_{+}$ , mixing matrix $W\\in\\mathbb{R}^{N\\times N}$ , regularization coefficient $\\tau>0$   \n2: Initialize: $\\pi^{(0)}$ \uff0c\uff0c $\\bar{\\pmb{T}}^{(0)}=\\pmb{Q}_{\\tau}^{(0)}$   \n3: for $t=0,1,\\cdot\\cdot\\cdot$ do   \n4: Update the policy for each $(s,a)\\in S\\times A$ $\\log\\pi^{(t+1)}(a|s)=W\\left(\\left(1-\\frac{\\eta\\tau}{1-\\gamma}\\right)\\log\\pi^{(t)}(a|s)+\\frac{\\eta}{1-\\gamma}T^{(t)}(s,a)\\right)-\\log z^{(t)}(s)\\,,$ where $\\begin{array}{r}{z^{(t)}(s)=\\sum_{a^{\\prime}\\in A}\\exp\\Big\\{W\\left(\\left(1-\\frac{\\eta\\tau}{1-\\gamma}\\right)\\log\\pi^{(t)}(a^{\\prime}|s)+\\frac{\\eta}{1-\\gamma}\\pmb{T}^{(t)}(s,a^{\\prime})\\right)\\Big\\}.}\\end{array}$   \n5\uff1a Evaluate Q(t+1)   \n6: Update the global Q-function estimate for each $(s,a)\\in S\\times A$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\pmb{T}^{(t+1)}(s,a)=W\\Big(\\pmb{T}^{(t)}(s,a)+\\underbrace{\\pmb{Q}_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)}_{\\mathrm{\\pmb{Q}.\\mathrm{tracking}}}\\Big)\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "7: end for ", "page_idx": 16}, {"type": "text", "text": "C.2 Development of FedNAC ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "For any policy $\\pi$ ,welet $d_{s_{0}}^{\\pi}$ denote the discounted state visitation distribution of $\\pi$ given an initial state $s_{0}\\in\\mathcal S$ i.e., ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\forall s\\in S:\\quad d_{s_{0}}^{\\pi}(s):=(1-\\gamma)\\sum_{t=0}^{\\infty}\\gamma^{t}\\mathbb{P}(s_{t}=s|s_{0})\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For a distribution $\\rho\\,\\in\\,\\Delta(S)$ , we define $d_{\\rho}^{\\pi}(s)\\,=\\,\\mathbb{E}_{s_{0}\\sim\\rho}[d_{s_{0}}^{\\pi}(s)]$ .We also define the state-action visitation distribution $\\bar{d}_{\\rho}^{\\pi}$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\bar{d}_{\\rho}^{\\pi}(s,a):=\\!d_{\\rho}^{\\pi}(s)\\pi(a|s)=(1-\\gamma)\\mathbb{E}_{s_{0}\\sim\\rho}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}\\mathbb{P}(s_{t}=s,a_{t}=a|s_{0})\\right]\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Furthermore, we extend the definition of $\\bar{d}_{\\rho}^{\\pi}$ by specifying the initial state-action distribution $\\nu\\in$ $\\Delta(S\\times A)$ and define ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\tilde{d}_{\\nu}^{\\pi}(s,a):=(1-\\gamma)_{(s_{0},a_{0})\\sim\\nu}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}\\mathbb{P}(s_{t}=s,a_{t}=a|s_{0},a_{0})\\right]\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Our proposed federated NAC method FedNAC could be seen as a decentralized version of Q-NPG method [AKLM21, $\\mathrm{YDG}^{+}22]$ , which we briefly review as follows. ", "page_idx": 16}, {"type": "text", "text": "Q-NPG method. Q-NPG is a sample version of NPG with function approximation which is suitable for thecasewhere $\\boldsymbol{S}$ Or $\\boldsymbol{\\mathcal{A}}$ is large or infinite. We consider the policy with function approximation under softmax parameterization (24). ", "page_idx": 16}, {"type": "text", "text": "Given an approximate solution $\\pmb{w}^{(t)}$ for  minimizing  the  function  approximation  error $\\ell\\big(\\pmb{w},Q^{f_{\\xi}(t)}\\,,\\tilde{d}_{\\nu}^{f_{\\xi}(t)}\\big)$ (se(25), the Q-NPG update rule $\\pmb{\\xi}^{(t+1)}\\,=\\,\\pmb{\\xi}^{(t)}\\,+\\,\\alpha\\pmb{w}^{(t)}$ when pluged in ", "page_idx": 16}, {"type": "text", "text": "parameterization (24), results in the following policy update rule when we set $\\alpha=\\eta/(1-\\gamma)$ ", "page_idx": 17}, {"type": "equation", "text": "$$\nf^{(t+1)}(a|s)\\propto f^{(t)}(a|s)\\exp\\left(\\frac{\\eta\\phi^{\\top}(s,a){\\pmb w}^{(t)}}{1-\\gamma}\\right)\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which could be seen as the function approximation version of the update rule (8) of vanilla NPG method. ", "page_idx": 17}, {"type": "text", "text": "Federated NAC method. FedNAC (describe in Section 4) is presented in Algorithm 3, whose subroutines are written in Algorithm 4, 5. In each iteration $t$ of FedNAC, each agent $n$ updates the criti parameter ${\\pmb w}_{n}^{(t)}$ locally using Algorithm 4, which aims to minimize $\\bar{\\ell}(\\pmb{w},Q_{n}^{(t)},\\tilde{d}_{n}^{[t)})$ by stochastic gradient descent. Note that since we don't know the Q-function $Q_{n}^{(t)}$ in the gradients, we need to invoke Algorithm 5 $\\bar{\\mathbf{\\Lambda}}[\\mathbf{Y}\\mathbf{D}\\mathbf{G}^{+}22\\mathbf{\\Lambda}$ , Algorithm 3] to give an unbiased estimate $\\widehat{Q}_{n}^{(t)}(s,a)$ , where $(s,a)$ is sampled from $\\tilde{d}_{n}^{(t)}$ (cf. Theorem E.1). As a consequence, in line 4 of Algorithm 4, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\widehat{\\nabla}_{w}\\ell(\\widetilde{\\pmb{w}}_{k},\\widehat{Q}^{\\pi},\\widetilde{d}^{f_{\\xi}})\\right]=\\nabla_{w}\\ell(\\widetilde{\\pmb{w}}_{k},\\widehat{Q}^{\\pi},\\widetilde{d}^{f_{\\xi}})\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In each actor iteration, agents share with their neighbors actor and critic parameters, where the tracking scheme is also used. ", "page_idx": 17}, {"type": "text", "text": "Algorithm 3 Federated Natural Actor-Critic (FedNAC) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1: Input: number of actor iterations $T$ , number of critic iterations $K$ , actor learning rate $\\alpha$ , critic learning rate $\\beta$ , discounted factor $\\gamma\\in[0,1)$   \n2: Initialiation initial tae-action isribution $\\nu$ actor parameter $\\pmb{\\xi}^{(0)}=(\\pmb{\\xi}_{1}^{(0)\\top},\\cdots,\\pmb{\\xi}_{N}^{(0)\\top})^{\\top}\\in$ $\\mathbb{R}^{N\\times p}$ $\\pmb{h}^{(-1)}=\\pmb{w}^{(-1)}=\\pmb{0}\\in\\mathbb{R}^{N\\times p}$   \n3: for $t=0,\\cdot\\cdot\\cdot,T-1$ do   \n4:  Critic update: $\\pmb{w}_{n}^{(t)}=\\mathrm{\\scriptsize~Critic}(K,\\nu,\\xi_{n}^{(t)},\\gamma,\\beta,r_{n}),$ $n\\in[N]$ (Algorithm 4)   \n5: Update the critic parameter for estimating the global Q-function: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\pmb{h}^{(t)}=W\\left(\\pmb{h}^{(t-1)}+\\pmb{w}^{(t)}-\\pmb{w}^{(t-1)}\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "6: Actor update: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\pmb{\\xi}^{(t+1)}=\\pmb{W}\\left(\\pmb{\\xi}^{(t)}+\\alpha\\pmb{h}^{(t)}\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "7: end for ", "page_idx": 17}, {"type": "text", "text": "A $\\mathbf{lgorithm\\,4\\,Critic}(K,\\nu,\\pmb{\\xi},\\gamma,\\beta,r)$ : sample-based regression solver to minimize $\\ell(\\pmb{w},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})$ ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1: Initialize: critic parameter $w_{0}\\in\\mathbb{R}^{p}$   \n2: for $k=0,\\cdot\\cdot\\cdot\\,,K-1$ do   \n3:  Sampling: $(s_{k},a_{k}),\\widehat{Q}^{\\pi}(s_{k},a_{k})=\\!\\mathrm{Q}\\!\\cdot\\!\\mathrm{Sampler}(\\nu,f_{\\xi},\\gamma,r)$ (Algorithm 5   \n4: Compute the stochastic gradient estimator of $L_{Q}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\widehat{\\nabla}_{w}\\ell(\\widetilde{\\boldsymbol{w}}_{k},\\widehat{Q}^{\\pi},\\widetilde{d}^{f_{\\xi}})=2\\left(\\widetilde{\\boldsymbol{w}}_{k}^{\\top}\\phi(s_{k},a_{k})-\\widehat{Q}^{\\pi}(s_{k},a_{k})\\right)\\phi(s_{k},a_{k})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "5: Critic Update: $\\widetilde{\\pmb{w}}_{k+1}=\\widetilde{\\pmb{w}}_{k}-\\beta\\widehat{\\nabla}_{w}\\ell(\\widetilde{\\pmb{w}}_{k},\\widehat{Q}^{\\pi},\\tilde{d}^{f_{\\xi}})$ ", "page_idx": 17}, {"type": "text", "text": "7: Output: $\\begin{array}{r}{{\\pmb w}_{\\mathrm{out}}=\\frac{1}{K}\\sum_{k=1}^{K}{\\widetilde{\\pmb w}_{k}}}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "D  Convergence analysis of FedNPG ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For technical convenience, we present first the analysis for entropy-regularized FedNPG and then for vanillaFedNPG. ", "page_idx": 17}, {"type": "text", "text": "1: Initialize: $(s_{0},a_{0})\\sim\\nu$ , time step $h,t=0$ , variable $X\\sim$ Bernoulli $(\\gamma)$   \n2: while $X=1$ do   \n3: Sample $s_{h+1}\\sim P(\\cdot|s_{h},a_{h})$   \n4: Sample $a_{h+1}\\sim\\pi(\\cdot|s_{h+1})$   \n5: $h\\leftarrow h+1$   \n6: X \uff5e Bernoulli $(\\gamma)$   \n7:end while   \n8: Set $x c(s_{h},a_{h})=r(s_{h},a_{h}),X\\sim\\operatorname{Bernoulli}(\\gamma),t=h$   \n9: while $X=1$ do   \n10: Sample $s_{t+1}\\sim P(\\cdot|s_{t},a_{t})$   \n11: Sample $a_{t+1}\\sim\\pi(\\cdot|s_{t+1})$   \n12: $\\widehat{Q}^{\\pi}(s_{h},a_{h})\\gets\\widehat{Q}^{\\pi}(s_{h},a_{h})+r(s_{t+1},a_{t+1})$   \n13: $t\\gets t+1$   \n14: $X\\sim\\mathrm{Bernoulli}(\\gamma)$   \n15: end while   \n16: Output: $(s_{h},a_{h})$ and $\\widehat{Q}^{\\pi}(s_{h},a_{h})$ ", "page_idx": 18}, {"type": "text", "text": "D.1 Analysis of entropy-regularized FedNPG with exact policy evaluation ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To facilitate analysis, we introduce several notation below. For all $t\\,\\geq\\,0$ ,werecall $\\overline{{\\pi}}^{(t)}$ as the normalizedgeometricmanof $\\{\\pi_{n}^{(t)}\\}_{n\\in[N]}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\overline{{\\pi}}^{(t)}:=\\mathrm{softmax}\\left(\\frac{1}{N}\\sum_{n=1}^{N}\\log\\pi_{n}^{(t)}\\right)\\,,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "from which we can easily see that for each $\\begin{array}{r}{(s,a)\\in\\mathcal{S}\\times\\mathcal{A},\\overline{{\\pi}}^{(t)}(a|s)\\propto\\left(\\prod_{n=1}^{N}\\pi_{n}^{(t)}(a|s)\\right)^{\\frac{1}{N}}}\\end{array}$ .We denote the soft $Q.$ -functions of $\\overline{{\\pi}}^{(t)}$ by $\\overline{{\\boldsymbol{Q}}}_{\\tau}^{(t)}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\overline{{{\\mathbf{Q}}}}_{\\tau}^{(t)}:=\\left(\\begin{array}{c}{Q_{\\tau,1}^{\\overline{{\\boldsymbol{\\pi}}}^{(t)}}}\\\\ {\\vdots}\\\\ {Q_{\\tau,N}^{\\overline{{\\boldsymbol{\\pi}}}^{(t)}}}\\end{array}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In addition, we define $\\widehat{Q}_{\\tau}^{(t)},\\overline{{Q}}_{\\tau}^{(t)}\\in\\mathbb{R}^{|S||A|}$ and $\\overline{{V}}_{\\tau}^{(t)}\\in\\mathbb{R}^{|S|}$ as follows ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\widehat{Q}_{\\tau}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\pi_{n}^{(t)}}\\,,}\\\\ {\\displaystyle\\overline{{Q}}_{\\tau}^{(t)}:=Q_{\\tau}^{\\overline{{\\pi}}^{(t)}}=\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\overline{{\\tau}}^{(t)}}\\,.}\\\\ {\\displaystyle\\overline{{V}}_{\\tau}^{(t)}:=V_{\\tau}^{\\overline{{\\pi}}^{(t)}}=\\frac{1}{N}\\sum_{n=1}^{N}V_{\\tau,n}^{\\overline{{\\tau}}^{(t)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For notational convenience, we also denote ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\alpha:=1-\\frac{\\eta\\tau}{1-\\gamma}\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "$[\\mathrm{CCC}^{+}22\\mathrm{b}]$ $\\{\\pmb{\\xi}^{(t)}=(\\xi_{1}^{(t)},\\cdot\\cdot\\cdot\\,,\\xi_{N}^{(t)})^{\\top}\\in$ $\\mathbb{R}^{N\\times|S||A|}\\}_{t=0,1,\\cdots}$ eachrecursively definedas ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\forall(s,a)\\in S\\times A:\\quad\\xi^{(0)}(s,a):=\\displaystyle\\frac{\\|\\exp\\left(Q_{\\tau}^{\\star}(s,\\cdot)/\\tau\\right)\\|_{1}}{\\left\\|\\exp\\left(\\frac{1}{N}\\sum_{n=1}^{N}\\log\\pi_{n}^{(0)}(\\cdot|s)\\right)\\right\\|_{1}}\\cdot\\pi^{(0)}(a|s)\\,,}\\\\ &{}&{\\log\\xi^{(t+1)}(s,a)=W\\left(\\alpha\\log\\xi^{(t)}(s,a)+(1-\\alpha)T^{(t)}(s,a)/\\tau\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\pmb{T}^{(t)}(s,a)$ is updated via (16). Similarly, we introduce an averaged auxiliary sequence $\\{\\overline{{\\xi}}^{(t)}\\in\\mathbf{\\Xi}$ IRISlIAl} given by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}:}&{\\ \\overline{\\xi}^{(0)}(s,a):=\\|\\mathrm{exp}\\left(Q_{\\tau}^{\\star}(s,\\cdot)/\\tau\\right)\\|_{1}\\cdot\\overline{\\pi}^{(0)}(a|s)\\,,}\\\\ {\\log\\overline{\\xi}^{(t+1)}(s,a)=\\alpha\\log\\overline{\\xi}^{(t)}(s,a)+(1-\\alpha)\\widehat Q_{\\tau}^{(t)}(s,a)/\\tau.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We introduces four error metrics defined as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Omega_{1}^{(t)}:=\\left\\lVert u^{(t)}\\right\\rVert_{\\infty},}\\\\ &{\\Omega_{2}^{(t)}:=\\left\\lVert v^{(t)}\\right\\rVert_{\\infty},}\\\\ &{\\Omega_{3}^{(t)}:=\\left\\lVert Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\right\\rVert_{\\infty},}\\\\ &{\\Omega_{4}^{(t)}:=\\operatorname*{max}\\left\\{0,-\\underset{s,a}{\\operatorname*{min}}\\left(\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t)}(s,a)\\right)\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $u^{(t)},v^{(t)}\\in\\mathbb{R}^{|S||A|}$ are defined as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u^{(t)}(s,a):=\\left\\|\\log\\pmb{\\xi}^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2},}\\\\ &{v^{(t)}(s,a):=\\left\\|T^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We collect the error metrics above in a vector $\\Omega^{(t)}\\in\\mathbb{R}^{4}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Omega^{(t)}:=\\left(\\Omega_{1}^{(t)},\\Omega_{2}^{(t)},\\Omega_{3}^{(t)},\\Omega_{4}^{(t)}\\right)^{\\top}\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "With the above preparation, we are ready to state the convergence guarantee of Algorithm 2 in Theorem D.1 below, which is the formal version of Theorem 3.6. ", "page_idx": 19}, {"type": "text", "text": "Theorem D.1. For any $N\\,\\in\\,\\mathbb{N}_{+},\\tau\\,>\\,0,\\gamma\\,\\in\\,(0,1),$ there exists $\\eta_{0}\\,>\\,0$ which depends only on $N,\\gamma,\\tau,\\sigma,|A|,$ such that $i f0<\\eta\\leq\\eta_{0}$ and $1-\\sigma>0$ then the updates of Algorithm 2 satisfy ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq2\\gamma\\rho(\\eta)^{t}\\left\\lVert\\mathbf{\\Omega}^{(0)}\\right\\rVert_{2},}\\\\ {\\left\\lVert\\log\\pi_{\\tau}^{\\star}-\\log\\overline{{\\pi}}^{(t)}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\rho(\\eta)^{t}\\left\\lVert\\mathbf{\\Omega}^{(0)}\\right\\rVert_{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\rho(\\eta)\\leq\\operatorname*{max}\\left\\lbrace1-\\frac{\\tau\\eta}{2},\\frac{3+\\sigma}{4}\\right\\rbrace<1\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Moreover, the consensus errors satisfy: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\left\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq2\\rho(\\eta)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thedependencyof $\\eta_{0}$ $N,\\gamma,\\tau,\\sigma,|A|$ is made clear in Lemma D.3 that will be presented momentarily in this section. The rest of this section is dedicated to the proof of Theorem D.1. We first state a key lemma that tracks the error recursion of Algorithm 2. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.2. The following linear system holds for all $t\\geq0$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Omega^{(t+1)}\\leq\\underbrace{\\left(\\begin{array}{c c c c}{\\sigma\\alpha}&{\\frac{\\eta\\sigma}{1-\\gamma}}&{0}&{0}\\\\ {S\\sigma}&{\\left(1+\\frac{\\eta M\\sqrt{N}}{1-\\gamma}\\sigma\\right)\\sigma}&{\\frac{(2+\\gamma)\\eta M N}{1-\\gamma}\\sigma}&{\\frac{\\gamma\\eta M N}{1-\\gamma}\\sigma}\\\\ {(1-\\alpha)M}&{0}&{(1-\\alpha)\\gamma+\\alpha}&{(1-\\alpha)\\gamma}\\\\ {\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}M}&{0}&{0}&{\\alpha}\\end{array}\\right)}_{=:A(\\eta)}\\Omega^{(t)}\\,,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where we let ", "page_idx": 19}, {"type": "equation", "text": "$$\nS:=M\\sqrt{N}\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}+\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}M\\right)\\,,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and ", "page_idx": 19}, {"type": "equation", "text": "$$\nM:=\\frac{1+\\gamma+2\\tau(1-\\gamma)\\log|\\mathcal{A}|}{(1-\\gamma)^{2}}\\cdot\\gamma\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In addition, it holds for all $t\\geq0$ that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq\\gamma\\Omega_{3}^{(t)}+\\gamma\\Omega_{4}^{(t)}\\,,}\\\\ &{\\left\\lVert\\log\\overline{{\\pi}}^{(t)}-\\log\\pi_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\Omega_{3}^{(t)}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. See Appendix F.1. ", "page_idx": 20}, {"type": "text", "text": "Let $\\rho(\\eta)$ denote the spectral norm of $A(\\eta)$ .As $\\Omega^{(t)}\\geq0$ , it is immediate from (49) that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left\\lVert\\Omega^{(t)}\\right\\rVert_{2}\\leq\\rho(\\eta)^{t}\\left\\lVert\\Omega^{(0)}\\right\\rVert_{2},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and therefore we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\|_{\\infty}\\leq2\\gamma\\|\\Omega^{(t)}\\|_{\\infty}\\leq2\\gamma\\rho(\\eta)^{t}\\|\\Omega^{(0)}\\|_{2}\\,,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left\\lVert\\log\\overline{{\\pi}}^{(t)}-\\log\\pi_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\left\\lVert\\Omega^{(t)}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\rho(\\eta)^{t}\\left\\lVert\\Omega^{(0)}\\right\\rVert_{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "It remains to bound the spectral radius $\\rho(\\eta)$ , which is achieved by the following lemma. Lemma D.3 (Bounding the spectral norm of $A(\\eta))$ .Let ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\zeta:=\\frac{(1-\\gamma)(1-\\sigma)^{2}\\tau}{8\\left(\\tau S_{0}\\sigma^{2}+10M c\\sigma^{2}/(1-\\gamma)+(1-\\sigma)^{2}\\tau^{2}/16\\right)}\\,,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n0<\\eta\\leq\\eta_{0}:=\\operatorname*{min}\\left\\lbrace\\frac{1-\\gamma}{\\tau},\\zeta\\right\\rbrace,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "then we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\rho(\\eta)\\leq\\operatorname*{max}\\Big\\{\\frac{3+\\sigma}{4},\\frac{1+(1-\\alpha)\\gamma+\\alpha}{2}\\Big\\}<1\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. See Appendix F.2. ", "page_idx": 20}, {"type": "text", "text": "D.2 Analysis of entropy-regularized FedNPG with inexact policy evaluation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We define the collection of inexact Q-function estimates as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\pmb{q}_{\\tau}^{(t)}:=\\left(q_{\\tau,1}^{\\pi_{1}^{(t)}},\\cdot\\cdot\\cdot\\ ,q_{\\tau,N}^{\\pi_{N}^{(t)}}\\right)^{\\top},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and then the update rule $(U_{T})$ should be understood as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\pmb{T}^{(t+1)}(s,a)=\\pmb{W}\\left(\\pmb{T}^{(t)}(s,a)+\\pmb{q}_{\\tau}^{(t+1)}(s,a)-\\pmb{q}_{\\tau}^{(t)}(s,a)\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "in the inexact setting. For notational simplicity, we define $e_{n}\\in\\mathbb{R}$ as ", "page_idx": 20}, {"type": "equation", "text": "$$\ne_{n}:=\\operatorname*{max}_{t\\in[T]}\\left\\|Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty}\\,,\\quad n\\in[N]\\,,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and let $\\boldsymbol{e}=(e_{1},\\cdot\\cdot\\cdot\\,,e_{n})^{\\intercal}$ . Define $\\widehat{q}_{\\tau}^{\\left(t\\right)}$ , the approximation of $\\widehat{Q}_{\\tau}^{(t)}$ as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\widehat{q}_{\\tau}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}q_{\\tau,n}^{\\pi_{n}^{(t)}}\\;.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "With slight abuse of notation, we adapt the auxiliary sequence $\\{\\overline{{\\xi}}^{(t)}\\}_{t=0,\\cdots}$ to the inexact updates as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\xi}^{(0)}(s,a):=\\|\\mathrm{exp}\\,(Q_{\\tau}^{\\star}(s,\\cdot)/\\tau)\\|_{1}\\cdot\\overline{{\\pi}}^{(0)}(a|s)\\,,}\\\\ &{\\overline{{\\xi}}^{(t+1)}(s,a):=\\left[\\overline{{\\xi}}^{(t)}(s,a)\\right]^{\\alpha}\\mathrm{exp}\\left((1-\\alpha)\\frac{\\widehat{q}_{\\tau}^{(t)}(s,a)}{\\tau}\\right)\\,,\\quad\\forall(s,a)\\in\\ensuremath{\\mathcal{S}}\\times\\ensuremath{\\mathcal{A}},\\;t\\geq0\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In addition, we define ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Omega_{1}^{(t)}:=\\left\\|u^{(t)}\\right\\|_{\\infty}\\,,}\\\\ &{\\Omega_{2}^{(t)}:=\\left\\|v^{(t)}\\right\\|_{\\infty}\\,,}\\\\ &{\\Omega_{3}^{(t)}:=\\left\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\right\\|_{\\infty}\\,,}\\\\ &{\\Omega_{4}^{(t)}:=\\operatorname*{max}\\left\\{0,-\\displaystyle\\operatorname*{min}_{s,a}\\left(\\overline{{q}}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t)}(s,a)\\right)\\right\\}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u^{(t)}(s,a):=\\left\\|\\log\\pmb{\\xi}^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}\\,,}\\\\ &{v^{(t)}(s,a):=\\left\\|T^{(t)}(s,a)-\\widehat{q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We let $\\Omega^{(t)}$ be ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Omega^{(t)}:=\\left(\\Omega_{1}^{(t)},\\Omega_{2}^{(t)},\\Omega_{3}^{(t)},\\Omega_{4}^{(t)}\\right)^{\\top}\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "With the above preparation, we are ready to state the inexact convergence guarantee of Algorithm 2 in Theorem D.4 below, which is the formal version of Theorem 3.8. ", "page_idx": 21}, {"type": "text", "text": "Theorem D.4. Suppose that $q_{\\tau,n}^{\\pi_{n}^{(t)}}$ are used in replace of $Q_{\\tau,n}^{\\pi_{n}^{(t)}}$ in Algorithm 2.Forany $N\\in\\mathbb{N}_{+},\\tau>$ $0,\\gamma\\in(0,1)$ ,there exists $\\eta_{0}>0$ whichdependsonlyon $N,\\gamma,\\tau,\\sigma,|A|$ such that $i f0<\\eta\\leq\\eta_{0}$ and $1-\\sigma>0$ ,we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq2\\gamma\\left(\\rho(\\eta)^{t}\\left\\lVert\\Omega^{(0)}\\right\\rVert_{2}+C_{2}\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\lVert Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\rVert_{\\infty}\\right)\\,,}\\\\ {\\left\\lVert\\log\\pi_{\\tau}^{\\star}-\\log\\overline{{\\pi}}^{(t)}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\left(\\rho(\\eta)^{t}\\left\\lVert\\Omega^{(0)}\\right\\rVert_{2}+C_{2}\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\lVert Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\rVert_{\\infty}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Moreover, the consensus errors satisfy: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\left\\lVert\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\rVert_{\\infty}\\leq2\\left(\\rho(\\eta)^{t}\\left\\lVert\\Omega^{(0)}\\right\\rVert_{2}+C_{2}\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\lVert Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\rVert_{\\infty}\\right),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\rho(\\eta)~~\\le~~\\operatorname*{max}\\{1~-~\\frac{\\tau\\eta}{2},\\frac{3+\\sigma}{4}\\}~~<~~1$ is the same as in Theorem D.1, and ${\\it C}_{2}\\;:=\\;\\;$ $\\begin{array}{r}{\\frac{\\sigma\\sqrt{N}(2(1-\\gamma)+M\\sqrt{N}\\eta)+2\\gamma^{2}+\\eta\\tau}{(1-\\gamma)(1-\\rho(\\eta))}}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "From Theorem D.4, we can conclude that if ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\|Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty}\\leq\\frac{(1-\\gamma)(1-\\rho(\\eta))\\varepsilon}{2\\gamma\\left(\\sigma\\sqrt{N}(2(1-\\gamma)+M\\sqrt{N}\\eta)+2\\gamma^{2}+\\eta\\tau\\right)}\\,,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "then inexact entropy-regularized FedNPG could stillachieve $2\\varepsilon$ accuracy(i.e. $\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq2\\varepsilon)$ within max $\\left\\{\\frac{2}{\\tau\\eta},\\frac{4}{1\\!-\\!\\sigma}\\right\\}\\log\\frac{2\\gamma\\left\\Vert\\Omega^{(0)}\\right\\Vert_{2}}{\\varepsilon}$ Remark D.5. When $\\eta=\\eta_{0}$ (cf. (54) and (53)) and $\\tau\\leq1$ , the RHS of (67) is of the order $\\mathcal{O}\\left(\\frac{(1-\\gamma)\\tau\\eta_{0}\\varepsilon}{\\gamma(\\gamma^{2}+\\sigma\\sqrt{N}(1-\\gamma))}\\right)=\\mathcal{O}\\left(\\frac{(1-\\gamma)^{8}\\tau^{2}(1-\\sigma)^{2}\\varepsilon}{\\gamma(\\gamma^{2}+\\sigma\\sqrt{N}(1-\\gamma))(\\gamma^{2}N\\sigma^{2}+(1-\\sigma)^{2}\\tau^{2}(1-\\gamma)^{6})}\\right)\\,,$ which can be translated into a crude sample complexity bound when using fresh samples to estimate the soft Q-functions in each iteration. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "The rest of this section outlines the proof of Theorem D.4. We first state a key lemma that tracks the error recursion of Algorithm 2 with inexact policy evaluation, which is a modified version of Lemma D.2. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.6. The following linear system holds for all $t\\geq0$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Omega^{(t+1)}\\leq A(\\eta)\\Omega^{(t)}+\\underbrace{\\left(\\sigma\\sqrt{N}\\left(2+\\frac{M\\sqrt{N}\\eta}{1-\\gamma}\\right)}_{\\frac{1-\\gamma}{1-\\gamma}}\\right)\\left\\Vert e\\right\\Vert_{\\infty},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $A(\\eta)$ is provided in Lemma $D.2$ . In addition, it holds for all $t\\geq0$ that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq\\gamma\\Omega_{3}^{(t)}+\\gamma\\Omega_{4}^{(t)}\\,,}\\\\ &{\\left\\lVert\\log\\overline{{\\pi}}^{(t)}-\\log\\pi_{\\tau}^{\\star}\\right\\rVert_{\\infty}\\leq\\frac{2}{\\tau}\\Omega_{3}^{(t)}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. See Appendix F.3. ", "page_idx": 22}, {"type": "text", "text": "By (68), we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\forall t\\in N_{+}:\\quad\\Omega^{(t)}\\leq A(\\eta)^{t}\\Omega^{(0)}+\\sum_{s=1}^{t}A(\\eta)^{t-s}b(\\eta)\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which gives ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\|\\Omega^{(t)}\\right\\|_{2}\\leq\\rho(\\eta)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\displaystyle\\sum_{s=1}^{t}\\rho(\\eta)^{t-s}\\left\\|b(\\eta)\\right\\|_{2}\\left\\|e\\right\\|_{\\infty}}\\\\ {\\leq\\rho(\\eta)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\displaystyle\\frac{\\sigma\\sqrt{N}(2(1-\\gamma)+M\\sqrt{N}\\eta)+2\\gamma^{2}+\\eta\\tau}{(1-\\gamma)(1-\\rho(\\eta))}\\left\\|e\\right\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Here, (71) follows from $\\begin{array}{r l r}{\\|b(\\eta)\\|_{2}}&{\\leq}&{\\|b(\\eta)\\|_{1}\\;\\;=\\;\\;\\frac{\\sigma\\sqrt{N}(2(1-\\gamma)+M\\sqrt{N}\\eta)+2\\gamma^{2}+\\eta\\tau}{1-\\gamma}\\left\\|e\\right\\|_{\\infty}}\\end{array}$ $\\begin{array}{r}{\\sum_{s=1}^{t}\\rho(\\eta)^{t-s}\\,\\le\\,1/(1-\\rho(\\eta))}\\end{array}$ Recall that the bound on $\\rho(\\eta)$ has already been established in Lemma D.3. Therefore we complete the proof of Theorem D.4 by combining the above inequality with (69) and (70) in a similar fashion as before. We omit further details for conciseness. ", "page_idx": 22}, {"type": "text", "text": "D.3  Analysis of FedNPG with exact policy evaluation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We state the formal version of Theorem 3.3 below. ", "page_idx": 22}, {"type": "text", "text": "Theorem D.7. Suppose all $\\pi_{n}^{(0)}$ in Algorithm $^{l}$ are initializedasuniform distribution.Whn ", "page_idx": 22}, {"type": "equation", "text": "$$\n0<\\eta\\leq\\eta_{1}:=\\frac{(1-\\sigma)^{2}(1-\\gamma)^{3}}{8(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=0}^{T-1}\\Big(V^{\\star}(\\rho)-V^{\\pi^{(t)}}(\\rho)\\Big)\\le\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{(1-\\gamma)T}+\\frac{\\log|{\\cal A}|}{\\eta T}+\\frac{8(1+\\gamma)^{2}\\gamma^{2}N\\sigma^{2}}{(1-\\gamma)^{9}(1-\\sigma)^{2}}\\eta^{2}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "for any fixed state distribution $\\rho$ Furthermore, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\left\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq\\frac{32N\\sigma}{3(1-\\gamma)^{4}(1-\\sigma)}\\eta\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The rest of this section is dedicated to prove Theorem D.7. Similar to (37), we denote the $Q$ -functions $\\overline{{\\pi}}^{(t)}$ by $\\overline{{\\boldsymbol{Q}}}^{(t)}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\overline{{{\\mathbf{Q}}}}^{(t)}:=\\left(\\begin{array}{c}{Q_{1}^{\\overline{{\\pi}}^{(t)}}}\\\\ {\\vdots}\\\\ {Q_{N}^{\\overline{{\\pi}}^{(t)}}}\\end{array}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In addition, similar to (38), we define $\\widehat{Q}^{(t)},\\overline{{Q}}^{(t)}\\in\\mathbb{R}^{|S||A|}$ and $\\overline{{V}}^{(t)}\\in\\mathbb{R}^{|S|}$ as follows ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\widehat Q}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}Q_{n}^{\\pi_{n}^{(t)}}\\,,}}\\\\ {{\\displaystyle{\\overline{{Q}}}^{(t)}:=Q^{\\overline{{\\pi}}^{(t)}}=\\frac{1}{N}\\sum_{n=1}^{N}Q_{n}^{\\overline{{\\pi}}^{(t)}}\\,.}}\\\\ {{\\displaystyle{\\overline{{V}}}^{(t)}:=V^{\\overline{{\\pi}}^{(t)}}=\\frac{1}{N}\\sum_{n=1}^{N}V_{n}^{\\overline{{\\pi}}^{(t)}}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Following the same strategy in the analysis of entropy-regularized FedNPG, we introduce the auxiliary sequence $\\{\\pmb{\\xi}^{(t)}=(\\xi_{1}^{(t)},\\cdots,\\xi_{N}^{(t)})^{\\top}\\in\\dot{\\mathbb{R}}^{N\\times|S||A|}\\}$ recursivelya ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\xi}^{(0)}(s,a):=\\frac{1}{\\left\\|\\exp\\left(\\frac{1}{N}\\sum_{n=1}^{N}\\log\\pi_{n}^{(0)}(\\cdot|s)\\right)\\right\\|_{1}}\\cdot\\pmb{\\pi}^{(0)}(a|s)\\,,}\\\\ {\\log\\pmb{\\xi}^{(t+1)}(s,a)=\\pmb{W}\\left(\\log\\pmb{\\xi}^{(t)}(s,a)+\\frac{\\eta}{1-\\gamma}\\pmb{T}^{(t)}(s,a)\\right),\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "as well as the averaged auxiliary sequence $\\{\\overline{{\\xi}}^{(t)}\\in\\mathbb{R}^{|S||A|}\\}$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\overline{{\\xi}}^{(0)}(s,a):=\\overline{{\\pi}}^{(0)}(a|s)\\,,}\\\\ &{\\log\\overline{{\\xi}}^{(t+1)}(s,a):=\\log\\overline{{\\xi}}^{(t)}(s,a)+\\displaystyle\\frac{\\eta}{1-\\gamma}\\widehat{Q}^{(t)}(s,a)\\,,\\quad\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A},\\ t\\geq0\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "As usual, wecollect theconsensus errors in avector $\\Omega^{(t)}=(\\left\\lVert u^{(t)}\\right\\rVert_{\\infty},\\left\\lVert v^{(t)}\\right\\rVert_{\\infty})^{\\top}$ where $u^{(t)},v^{(t)}\\in$ RISl-l are defined as: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u^{(t)}(s,a):=\\left\\|\\log\\pmb{\\xi}^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2},}\\\\ &{v^{(t)}(s,a):=\\left\\|T^{(t)}(s,a)-\\widehat{Q}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Step 1: establishing the error recursion. The next key lemma establishes the error recursion of Algorithm 1. ", "page_idx": 23}, {"type": "text", "text": "Lemma D.8. The updates of FedNPG satisfy ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Omega^{(t+1)}\\le\\underbrace{\\left(\\overset{\\sigma}{J}\\right.\\quad_{\\sigma}\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)}_{=:B(\\eta)}\\Omega^{(t)}+\\underbrace{\\left(\\frac{0}{(1+\\gamma)\\gamma N\\sigma}\\eta\\right)}_{=:d(\\eta)}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "for all $t\\geq0$ where ", "page_idx": 23}, {"type": "equation", "text": "$$\nJ:=\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N}\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In addition, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}(\\eta)\\leq\\phi^{(t)}(\\eta)+\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta\\|u^{(t)}\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\,,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi^{(t)}(\\eta):=\\mathbb{E}_{s\\sim d_{\\rho}^{\\pi^{\\star}}}\\left[\\mathsf{K L}\\big(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\overline{{\\pi}}^{(t)}(\\cdot|s)\\big)\\right]-\\frac{\\eta}{1-\\gamma}\\overline{{V}}^{(t)}(d_{\\rho}^{\\pi^{\\star}})\\,,\\quad\\forall t\\ge0\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Moreover, when $\\eta\\leq\\eta_{1}$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\left\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq2\\left(\\frac{3}{8}\\sigma+\\frac{5}{8}\\right)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\frac{32N\\sigma}{3(1-\\gamma)^{4}(1-\\sigma)}\\eta\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. See Appendix F.4. ", "page_idx": 23}, {"type": "text", "text": "Note that when al $\\pi_{n}^{(0)}$ inAlgorithm 1 are initialized as uniform distribton, $\\pmb{\\Omega}^{(0)}=\\mathbf{0}$ and(84) indicates (73) in Theorem D.7. ", "page_idx": 24}, {"type": "text", "text": "Step 2: bounding the value functions. Let $\\pmb{p}\\in\\mathbb{R}^{2}$ be defined as: ", "page_idx": 24}, {"type": "equation", "text": "$$\np(\\eta)=\\binom{p_{1}(\\eta)}{p_{2}(\\eta)}:=\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\left(\\frac{\\frac{\\sigma(1-\\gamma)\\left(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma\\eta/(1-\\gamma)^{3}\\right)\\eta}{(1-\\gamma)\\left(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}\\eta/(1-\\gamma)^{3}\\right)(1-\\sigma)-J\\sigma^{2}\\eta}}{\\frac{\\sigma\\eta^{2}}{(1-\\gamma)\\left(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}\\eta/(1-\\gamma)^{3}\\right)(1-\\sigma)-J\\sigma^{2}\\eta}}\\right);\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "the rationale for this choice will be made clear momentarily. We define the following Lyapunov function ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\Phi^{(t)}(\\eta)=\\phi^{(t)}(\\eta)+\\pmb{p}(\\eta)^{\\top}\\pmb{\\Omega}^{(t)}\\,,\\quad\\forall t\\geq0\\,,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "which satisfies ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathfrak{p}^{(t+1)}(\\eta)=\\phi^{(t+1)}(\\eta)+p(\\eta)^{\\top}\\Omega^{(t+1)}}}\\\\ &{}&{\\leq\\phi^{(t)}(\\eta)+\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta\\|u^{(t)}\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)+p(\\eta)^{\\top}\\left(B(\\eta)\\Omega^{(t)}+d(\\eta)\\right)}\\\\ &{}&{=\\Phi^{(t)}(\\eta)+\\left[p(\\eta)^{\\top}\\left(B(\\eta)-I\\right)+\\left(\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta,0\\right)\\right]\\Omega^{(t)}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)}\\\\ &{}&{+\\,p_{2}(\\eta)\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}\\eta\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, the second inequality follows from (82). One can verify that the second term vanishes due to thechoice of $\\pmb{p}(\\eta)$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\pmb{p}(\\eta)^{\\top}\\left(\\pmb{B}(\\eta)-\\pmb{I}\\right)+\\left(\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta,0\\right)=(0,0)\\,.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, we conclude that ", "page_idx": 24}, {"type": "equation", "text": "$$\nV^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\leq\\frac{\\Phi^{(t)}(\\eta)-\\Phi^{(t+1)}(\\eta)}{\\eta}+p_{2}(\\eta)\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}\\,.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Averaging over $t=0,\\cdot\\cdot\\cdot,T-1$ \uff0c ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{\\bar{T}}\\sum_{t=0}^{T-1}\\Big(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\Big)}\\\\ &{\\leq\\frac{\\Phi^{(0)}(\\eta)-\\Phi^{(T)}(\\eta)}{\\eta T}+\\frac{2(1+\\gamma)^{2}\\gamma^{2}}{(1-\\gamma)^{8}}\\cdot\\frac{N\\sigma^{2}\\eta^{2}}{(1-\\gamma)(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}\\eta/(1-\\gamma)^{3})(1-\\sigma)-\\sigma^{2}\\gamma^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Step 3: simplifying the expression. We first upper bound the first term in the RHS of (89). Assuming unifom itialization foral $\\pi_{n}^{(0)}$ in Algorithm I, we have $\\left\\|u^{(0)}\\right\\|_{\\infty}=\\left\\|v^{(0)}\\right\\|_{\\infty}=0$ and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{s\\sim d_{\\rho}^{\\pi^{\\star}}}\\left[\\mathsf{K L}\\big(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\overline{{\\pi}}^{(0)}(\\cdot|s)\\big)\\right]\\leq\\log|\\cal{A}|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, putting together relations (86) and (221) we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\Phi^{(0)}(\\eta)-\\Phi^{(T)}(\\eta)}{\\eta T}\\leq\\frac{\\log\\vert{\\cal A}\\vert}{T\\eta}+\\frac{1}{T}\\left(p(\\eta)^{\\top}\\Omega^{(0)}/\\eta+\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{1-\\gamma}\\right)=\\frac{\\log\\vert{\\cal A}\\vert}{T\\eta}+\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{T(1-\\gamma)}\\,,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "To continue, we upper bound the second term in the RHS of (89). Note that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\eta\\leq\\eta_{1}\\leq\\frac{(1-\\sigma)(1-\\gamma)^{3}}{2(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "which gives ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}}{(1-\\gamma)^{3}}\\eta\\leq\\frac{1-\\sigma}{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(1-\\gamma)(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}\\eta/(1-\\gamma)^{3})(1-\\sigma)-J\\sigma^{2}\\eta}\\\\ &{\\geq(1-\\gamma)(1-\\sigma)^{2}/2-J\\sigma^{2}\\eta_{1}}\\\\ &{\\geq(1-\\gamma)(1-\\sigma)^{2}/4\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality follows from (91) and the second inequality follows from the definition of $\\eta_{1}$ and $J$ .By (92),we deduce ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\frac{2(1+\\gamma)^{2}\\gamma^{2}}{(1-\\gamma)^{8}}\\cdot\\frac{N\\sigma^{2}\\eta^{2}}{(1-\\gamma)(1-\\sigma-(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}\\eta/(1-\\gamma)^{3})(1-\\sigma)-J\\sigma^{2}\\eta}\\leq\\frac{8(1+\\gamma)^{2}\\gamma^{2}N\\sigma^{2}}{(1-\\gamma)^{9}(1-\\sigma)^{2}}\\eta^{2}\\,,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and our advertised bound (72) thus follows from plugging (90) and (93) into (89). ", "page_idx": 25}, {"type": "text", "text": "D.4 Analysis of FedNPG with inexact policy evaluation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We state the formal version of Theorem 3.5 below. ", "page_idx": 25}, {"type": "text", "text": "Theorem D.9. Suppose that $q_{n}^{\\pi_{n}^{(t)}}$ are used in replace of $Q_{n}^{\\pi_{n}^{(t)}}$ in Algorithm 1. Suppose all $\\pi_{n}^{(0)}$ in Algorithm $^{l}$ set to uniform distribution. Let ", "page_idx": 25}, {"type": "equation", "text": "$$\n0<\\eta\\leq\\eta_{1}:=\\frac{(1-\\sigma)^{2}(1-\\gamma)^{3}}{8(1+\\gamma)\\gamma\\sqrt{N}\\sigma^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{T}\\sum_{t=0}^{T-1}\\left(V^{\\star}(\\rho)-V^{\\overline{{\\pi}}^{(t)}}(\\rho)\\right)}\\\\ &{\\leq\\displaystyle\\frac{V^{\\star}(d_{\\rho}^{\\pi^{\\star}})}{(1-\\gamma)T}+\\frac{\\log|A|}{\\eta T}+\\frac{8(1+\\gamma)^{2}\\gamma^{2}N\\sigma^{2}}{(1-\\gamma)^{9}(1-\\sigma)^{2}}\\eta^{2}}\\\\ &{\\quad\\quad+\\left[\\frac{8(1+\\gamma)\\gamma}{(1-\\gamma)^{5}(1-\\sigma)^{2}}\\sqrt{N}\\sigma\\eta\\left(\\frac{(1+\\gamma)\\gamma\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+2\\right)+\\frac{2}{(1-\\gamma)^{2}}\\right]\\operatorname*{max}_{n\\in[N],t\\in[T]}\\left\\|Q_{n}^{\\pi_{n}^{(t)}}-q_{n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "for any fixed state distribution $\\rho$ ", "page_idx": 25}, {"type": "text", "text": "Furthermore, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\langle n\\in[N]:\\quad\\left\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq\\frac{32}{3(1-\\sigma)}\\left(\\frac{N\\sigma}{(1-\\gamma)^{4}}\\eta+\\sqrt{N}\\sigma\\left(\\frac{\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+1\\right)\\operatorname*{max}_{n\\in[N],t\\in[T]}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We next outline the proof of Theorem D.9. With slight abuse of notation, we again define $e_{n}\\in\\mathbb{R}$ as ", "page_idx": 25}, {"type": "equation", "text": "$$\ne_{n}:=\\operatorname*{max}_{t\\in[T]}\\left\\|Q_{n}^{\\pi_{n}^{(t)}}-q_{n}^{\\pi_{n}^{(t)}}\\right\\|_{\\infty}\\,,\\quad n\\in[N]\\,,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and let $\\boldsymbol{e}=(e_{1},\\cdot\\cdot\\cdot\\,,e_{n})^{\\intercal}$ . We define the collection of inexact Q-function estimates as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\pmb q^{(t)}:=\\left(q_{1}^{\\pi_{1}^{(t)}},\\cdots,q_{N}^{\\pi_{N}^{(t)}}\\right)^{\\top},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and then the update rule (16) should be understood as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\pmb{T}^{(t+1)}(s,a)=\\pmb{W}\\left(\\pmb{T}^{(t)}(s,a)+\\pmb{q}^{(t+1)}(s,a)-\\pmb{q}^{(t)}(s,a)\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "in the inexact setting. Define $\\widehat{q}^{(t)}$ , the approximation of ${\\widehat Q}^{(t)}$ as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\widehat{q}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}q_{n}^{\\pi_{n}^{(t)}}\\,,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "we adapt the averaged auxiliary sequence $\\{\\overline{{\\xi}}^{(t)}\\in\\mathbb{R}^{|S||A|}\\}$ to the inexact updates as follows: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\overline{{\\xi}}^{(0)}(s,a):=\\overline{{\\pi}}^{(0)}(a|s)\\,,}\\\\ &{\\overline{{\\xi}}^{(t+1)}(s,a):=\\overline{{\\xi}}^{(t)}(s,a)\\exp\\left(\\displaystyle\\frac{\\eta}{1-\\gamma}\\widehat{q}^{(t)}(s,a)\\right)\\,,\\quad\\forall(s,a)\\in S\\times A,\\ t\\geq0\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "As usual, we defne the consensus eror vector as $\\Omega^{(t)}=(\\left\\|u^{(t)}\\right\\|_{\\infty},\\left\\|v^{(t)}\\right\\|_{\\infty})^{\\top}$ where $u^{(t)},v^{(t)}\\in$ IRISll-l are given by ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u^{(t)}(s,a):=\\left\\|\\log\\pmb{\\xi}^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}\\,,}\\\\ &{v^{(t)}(s,a):=\\left\\|\\pmb{T}^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The following lemma characterizes the dynamics of the error vector $\\Omega^{(t)}$ , perturbed by additional approximation error. ", "page_idx": 26}, {"type": "text", "text": "Lemma D.10. The updates of inexact FedNPG satisfy ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Omega^{(t+1)}\\leq B(\\eta)\\Omega^{(t)}+d(\\eta)+\\underbrace{\\left(\\sqrt{N}\\sigma\\left(\\frac{0}{(1-\\gamma)\\gamma\\eta\\sqrt{N}}+2\\right)\\right)\\left\\Vert e\\right\\Vert_{\\infty}}_{=:c(\\eta)}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In addition, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}(\\eta)\\leq\\phi^{(t)}(\\eta)+\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta\\left\\|u^{(t)}\\right\\|_{\\infty}+\\frac{2\\eta}{(1-\\gamma)^{2}}\\left\\|e\\right\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\,,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\phi^{(t)}(\\eta)$ is defined in (83). ", "page_idx": 26}, {"type": "text", "text": "Moreover, when $\\eta\\leq\\eta_{1}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\langle n\\in[N]:\\right\\rangle\\ \\ \\ \\left\\|\\log\\pi_{n}^{(t)}-\\log\\overline{{\\pi}}^{(t)}\\right\\|_{\\infty}\\leq2\\left(\\frac{3}{8}\\sigma+\\frac{5}{8}\\right)^{t}\\left\\|\\mathbf{\\Omega}^{(0)}\\right\\|_{2}+\\frac{32}{3(1-\\sigma)}\\left(\\frac{N\\sigma}{(1-\\gamma)^{4}}\\eta+\\sqrt{N}\\sigma\\left(\\frac{4\\pi^{2}}{(1-\\gamma)^{4}}\\eta\\right)\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. See Appendix F.5. ", "page_idx": 26}, {"type": "text", "text": "Similar to (87), we can recursively bound $\\Phi^{(t)}(\\eta)$ (defined in (86)) as ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{p}^{(t+1)}(\\eta)=\\phi^{(t+1)}(\\eta)+p(\\eta)^{\\top}\\mathfrak{D}^{(t+1)}}\\\\ &{\\qquad\\qquad\\overset{(10)}{\\leq}\\phi^{(t)}(\\eta)+\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta\\left\\|{\\boldsymbol u}^{(t)}\\right\\|_{\\infty}+\\frac{2\\eta}{(1-\\gamma)^{2}}\\left\\|{\\boldsymbol e}\\right\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)}\\\\ &{\\qquad\\qquad\\qquad+p(\\eta)^{\\top}\\left({\\boldsymbol B}(\\eta)\\Omega^{(t)}+d(\\eta)+c(\\eta)\\right)}\\\\ &{=\\Phi^{(t)}(\\eta)+\\underbrace{\\left[p(\\eta)^{\\top}\\left({\\boldsymbol B}(\\eta)-I\\right)+\\left(\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta,0\\right)\\right]}_{=(0,0)\\,\\forall\\,{\\mathfrak{a}}}\\Omega^{(t)}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)}\\\\ &{\\qquad\\qquad\\qquad+p_{2}(\\eta)\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}\\eta+\\left[p_{2}(\\eta)\\sqrt{N}\\sigma\\left(\\frac{(1+\\gamma)\\gamma\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+2\\right)+\\frac{2\\eta}{(1-\\gamma)^{2}}\\right]\\left\\|{\\boldsymbol e}\\right\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "From the above expression we know that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\rho)-\\overline{{V}}^{(t)}(\\rho)\\leq\\frac{\\Phi^{(t)}(\\eta)-\\Phi^{(t+1)}(\\eta)}{\\eta}+p_{2}(\\eta)\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}+\\left[p_{2}(\\eta)\\sqrt{N}\\sigma\\left(\\frac{(1+\\gamma)\\gamma\\sqrt{N}}{(1-\\gamma)^{3}}+\\frac{2}{\\eta}\\right)+\\frac{1-\\gamma}{(1-\\gamma)^{3}}\\right]p_{2}(\\eta),\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "which gives ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{T}\\sum_{t=0}^{T-1}\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\leq\\frac{\\Phi^{(0)}(\\eta)-\\Phi^{(T)}(\\eta)}{\\eta T}+p_{2}(\\eta)\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\left[p_{2}(\\eta)\\sqrt{N}\\sigma\\left(\\frac{(1+\\gamma)\\gamma\\sqrt{N}}{(1-\\gamma)^{3}}+\\frac{2}{\\eta}\\right)+\\frac{2}{(1-\\gamma)^{2}}\\right]\\|e\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "via telescoping. Combining the above expression with (90), (92) and (93), we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{T}\\sum_{t=0}^{T-1}\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\leq\\frac{\\log|A|}{T\\eta}+\\frac{V^{\\star}(d_{\\rho}^{\\star})}{T(1-\\gamma)}+\\frac{8(1+\\gamma)^{2}\\gamma^{2}N\\sigma}{(1-\\gamma)^{9}(1-\\sigma)^{2}}\\eta^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\left[\\frac{8(1+\\gamma)\\gamma}{(1-\\gamma)^{5}(1-\\sigma)^{2}}\\sqrt{N}\\sigma\\eta\\left(\\frac{(1+\\gamma)\\gamma\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+2\\right)+\\frac{2}{(1-\\gamma)^{2}}\\right]\\|{\\Phi}_{\\rho}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "which establishes (94). ", "page_idx": 27}, {"type": "text", "text": "E  Convergence analysis of FedNAC ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Let $\\pi^{\\star}$ be an optimal policy and does not need to belong to the log-linear policy class. Fix a state distribution $\\rho\\in\\Delta(S)$ and a state-action distribution $\\nu$ . To simplify the notation, we denote $d_{\\rho}^{\\pi^{\\star}}$ as $d_{\\star}$ $d^{f_{\\xi^{(t)}}}$ $d^{(t)},\\tilde{d}_{n}^{(t)}$ $\\tilde{d}_{\\nu}^{f}{\\varepsilon_{n}^{(t)}}$ and define $d_{n}^{(t)}$ and $\\bar{d}_{n}^{(t)}$ analogously. We alsolet $Q_{n}^{(t)}$ denote $Q_{n}^{\\xi_{n}^{(t)}}$ Define. ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\vartheta_{\\rho}:=\\frac{1}{1-\\gamma}\\left\\|\\frac{d_{\\star}}{\\rho}\\right\\|_{\\infty}\\geq\\frac{1}{1-\\gamma}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and assume $\\vartheta_{\\rho}<\\infty$ ", "page_idx": 27}, {"type": "text", "text": "We also introduce a weighted KL divergence given by ", "page_idx": 27}, {"type": "equation", "text": "$$\nD_{\\star}^{(t)}:=\\mathbb{E}_{s\\sim d_{\\star}}\\left[\\mathsf{K L}\\big(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\pi^{(t)}(\\cdot|s)\\big)\\right]\\,,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\mathsf{K L}\\big(\\cdot\\;\\|\\cdot\\big):\\mathbb{R}^{|A|}\\times\\mathbb{R}^{|A|}\\to\\mathbb{R}$ is the Kullback-Leibler (KL) divergence: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\forall f,g\\in\\mathbb{R}^{|A|}:\\quad\\mathsf{K L}\\big(f\\,\\|\\,g\\big):=\\sum_{a\\in A}f(a)\\log\\left(\\frac{f(a)}{g(a)}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Given a state distribution $\\rho$ and an optimal policy $\\pi^{\\star}$ , we define a state-action measure $\\tilde{d}^{\\star}$ as ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\tilde{d}^{\\star}(s,a):=d_{\\star}(s)\\cdot\\mathrm{Unif}_{A}(a)=\\frac{d_{\\star}(s)}{|A|}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "The following theorem guarantees that for any fixed policy $\\pi$ and state-action distribution $\\nu\\in$ $\\Delta(S\\times A)$ , the Q-Sampler algorithm (cf. Algorithm 5) samples $(s,a)$ from $\\tilde{d}_{\\nu}^{\\pi}$ and gives an unbiased estimate $\\widehat{Q}^{\\pi}(s,a)$ of $Q^{\\pi}(s,a)$ , whose proof can be found in $[\\mathrm{YDG^{+}}22]$ , Lemma 4]. ", "page_idx": 27}, {"type": "text", "text": "Lemma E.1 (Lemma 4 in $[\\mathrm{YDG}^{+}22]$ ). Consider the output $(s_{h},a_{h})$ and $\\widehat{Q}^{\\pi}(s_{h},a_{h})$ of Algorithm 5. It follows that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{E}[h+1]=\\frac{1}{1-\\gamma}\\,,}\\\\ {\\displaystyle P(s_{h}=s,a_{h}=a)=\\tilde{d}_{\\nu}^{\\pi}(s,a)\\,,}\\\\ {\\displaystyle\\mathbb{E}\\left[\\widehat{Q}^{\\pi}(s_{h},a_{h})|s_{h},a_{h}\\right]=Q^{\\pi}(s_{h},a_{h})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "To present the convergence results of FedNAC, we further introduce the following notation, where $t\\in\\mathbb{N}$ represents the iteration step in FedNAC: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\hat{w}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}w_{n}^{(t)},}\\\\ {\\displaystyle\\bar{\\xi}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}\\xi_{n}^{(t)},}\\\\ {\\displaystyle\\bar{f}^{(t)}:=f_{\\xi^{(t)}},}\\\\ {\\displaystyle\\bar{f}_{n}^{(t)}:=f_{\\xi^{(t)}},}\\\\ {\\displaystyle w_{\\star,n}^{(t)}\\in\\arg\\operatorname*{min}_{w}\\ell\\left(w,Q_{n}^{(t)},\\bar{d}_{n}^{(t)}\\right),}\\\\ {\\displaystyle\\hat{w}_{\\star}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}w_{\\star,n}^{(t)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "For convenience of narration, we introduce the following bounded statistical error assumption. ", "page_idx": 28}, {"type": "text", "text": "Assumption E.2 (Bounded statistical error). For al $n\\in[N]$ , there exists $\\varepsilon_{\\mathrm{stat}}^{n}>0$ such that for all $t\\in\\mathbb{N}$ in Algorithm 3, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\ell\\left(\\pmb{w}_{n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)-\\ell\\left(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)\\right]\\leq\\varepsilon_{\\mathrm{stat}}^{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Whensolinthreressionroblmithsamibadapprachweax $\\varepsilon_{\\mathrm{stat}}^{n}={\\mathcal{O}}(1/K)$ where $K$ is the iteration number of Algorithm 4. ", "page_idx": 28}, {"type": "text", "text": "Thorem3CoergnrtefCrtic (lgor)Aor $^{4}!$ $w_{0}=\\mathbf{0}$ and $\\begin{array}{r}{\\beta=\\frac{1}{2C_{\\phi}}}\\end{array}$ Then under Assumption 4.1, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\ell\\left(w_{o u t},Q_{\\xi},\\tilde{d}_{\\xi}\\right)\\right]-\\ell\\left({\\pmb w}^{\\star},Q_{\\xi},\\tilde{d}_{\\xi}\\right)\\leq\\frac{4}{K}\\left(\\frac{\\sqrt{2p}}{1-\\gamma}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)+\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)^{2}}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Where $\\pmb{w}^{\\star}\\in\\arg\\operatorname*{min}_{\\pmb{w}}\\ell\\left(\\pmb{w},Q^{\\xi},\\tilde{d}_{\\xi}\\right)$ ", "page_idx": 28}, {"type": "text", "text": "The proof of Theorem E.3 is postponed to Appendix G.5. ", "page_idx": 28}, {"type": "text", "text": "The following lemma provide a (very pessimistic) upper bound of $C_{\\nu}$ in Assumption 4.3. ", "page_idx": 28}, {"type": "text", "text": "Lemma E.4 (Upper bound of $C_{\\nu}$ ).If $\\nu(s,a)>0$ for all state-action pairs $(s,a)\\in S\\times A,$ then we have ", "page_idx": 28}, {"type": "equation", "text": "$$\nC_{\\nu}\\leq\\frac{1}{(1-\\gamma)^{2}\\nu_{\\mathrm{min}}^{2}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. We only need to note that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sqrt{\\mathbb{E}_{(s.a)\\sim\\tilde{d}^{(t)}}\\left[\\left(\\frac{h^{(t)}(s,a)}{\\tilde{d}_{n}^{(t)}(s,a)}\\right)^{2}\\right]}\\le\\operatorname*{max}_{(s,a)\\in\\mathcal{S}\\times\\mathcal{A}}\\frac{h^{(t)}(s,a)}{\\tilde{d}_{n}^{(t)}(s,a)}\\le\\frac{1}{(1-\\gamma)\\nu_{\\mathrm{min}}}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last inequality follows from (??). ", "page_idx": 28}, {"type": "text", "text": "We give some key lemmas which will be used in our proof of Theorem 4.4. ", "page_idx": 28}, {"type": "text", "text": "Lemma E.5 (consensus properties). For all $t\\in\\mathbb{N}$ wehave ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\overline{{\\xi}}^{(t+1)}=\\overline{{\\xi}}^{(t)}+\\alpha\\pmb{\\hat{w}}^{(t)},}\\\\ {\\displaystyle\\frac{1}{N}\\pmb{1}^{\\top}\\pmb{h}^{(t)}=\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\pmb{h}_{n}^{(t)}=\\pmb{\\hat{w}}^{(t)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. (115) could be obtained directly by using mathematical induction and update rule (33) (note that $\\begin{array}{r}{\\frac{1}{N}\\mathbf{1}^{\\top}h^{(-1)}=\\hat{\\pmb{w}}^{(-1)}=\\mathbf{0}}\\end{array}$ see line 2 of Algorithm 3), and 114) could be obtained by averaging both sides of (34) and using (115). ", "page_idx": 29}, {"type": "text", "text": "Lemma E.6 (Young's inequalities). Let $\\{x_{1},\\cdot\\cdot\\cdot,x_{m}\\}$ be a set of m vectors in $\\mathbb{R}^{l}$ .Thenfor any $\\zeta>0$ wehave ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|\\pmb{x}_{i}+\\pmb{x}_{j}\\|_{2}^{2}\\leq\\left(1+\\zeta\\right)\\|\\pmb{x}_{i}\\|_{2}^{2}+\\left(1+1/\\zeta\\right)\\|\\pmb{x}_{j}\\|_{2}^{2}\\,,}\\\\ {\\displaystyle\\left\\|\\sum_{i=1}^{m}\\pmb{x}_{i}\\right\\|_{2}^{2}\\leq m\\displaystyle\\sum_{i=1}^{m}\\|\\pmb{x}_{i}\\|_{2}^{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Lemma E.7 (Lipschitzness of $Q$ -function with function approximation). Assume that $r(s,a)\\in$ $[0,1],\\forall(s,a)\\in\\bar{S}\\times\\mathcal{A}$ Forany $\\pmb{\\xi},\\pmb{\\xi}^{\\prime}\\in\\mathbb{R}^{p}$ wehave ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in S\\times\\mathcal{A}:\\quad|Q^{f_{\\xi^{\\prime}}}(s,a)-Q^{f_{\\xi}}(s,a)|\\leq\\underbrace{\\frac{2C_{\\phi}\\gamma(1+\\gamma)}{(1-\\gamma)^{2}}}_{:=L_{Q}}\\|\\pmb{\\xi}^{\\prime}-\\pmb{\\xi}\\|_{2}~.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. See Appendix G.6. ", "page_idx": 29}, {"type": "text", "text": "For each teration step $t$ in Algorithm 3, we let $\\begin{array}{r}{{\\bar{\\pmb\\xi}}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}\\pmb{\\xi}_{n}^{(t)}=\\frac{1}{N}\\pmb{\\xi}^{(t)\\top}\\mathbf{1}_{N}}\\end{array}$ We define ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Omega_{1}^{(t)}:=\\mathbb{E}\\left\\|\\pmb{\\xi}^{(t)}-\\mathbf{1}_{N}\\pmb{\\bar{\\xi}}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2},}\\\\ &{\\Omega_{2}^{(t)}:=\\mathbb{E}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\pmb{\\hat{w}}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We let ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\varepsilon}_{\\mathrm{stat}}:=\\!\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\varepsilon_{\\mathrm{stat}}^{n}\\!\\mid,}\\\\ &{\\bar{\\varepsilon}_{\\mathrm{approx}}:=\\!\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\varepsilon_{\\mathrm{approx}}^{n}\\!\\mid,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and define $\\delta^{(t)}:=V^{\\star}-\\bar{V}^{(t)}(\\rho)$ where ${\\bar{V}}^{(t)}$ is shorthand for $V^{\\bar{f}^{(t)}}$ . We give the following performance improvement lemma. ", "page_idx": 29}, {"type": "text", "text": "Lemma E.8 (Performance improvement of FedNAC). Fix a state distribution $\\rho_{:}$ thenwehave ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\vartheta_{\\rho}\\delta^{(t+1)}+\\displaystyle\\frac{D_{\\star}^{(t+1)}}{(1-\\gamma)\\alpha}\\leq\\vartheta_{\\rho}\\delta^{(t)}+\\displaystyle\\frac{D_{\\star}^{(t)}}{(1-\\gamma)\\alpha}-\\delta^{(t)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\frac{2\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}\\left(\\sqrt{\\bar{\\varepsilon}_{s t a t}}+\\sqrt{2\\left(\\bar{\\varepsilon}_{a p p r o x}+\\displaystyle\\frac{L_{Q}^{2}}{N}\\left\\|\\xi^{(t)}-1_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}\\right)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. See Appendix G.7. ", "page_idx": 29}, {"type": "text", "text": "Lemma E.9 (linear system). For any $t\\in\\mathbb{N}$ welet $\\Omega^{(t)}=(\\Omega_{1}^{(t)},\\Omega_{2}^{(t)})^{\\top}$ . Then for any $\\zeta>0$ we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\boldsymbol{\\Omega}^{(t+1)}\\leq C\\boldsymbol{\\Omega}^{(t)}+\\boldsymbol{s},\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{C=(c_{i j})=\\left(\\!\\begin{array}{c c}{(1+\\zeta)\\sigma^{2}}&{\\alpha^{2}(1+1/\\zeta)\\sigma^{2}}\\\\ {(1+1/\\zeta)\\frac{96\\sigma^{2}L_{Q}^{2}}{(1-\\gamma)\\mu}}&{\\sigma^{2}\\left(1+\\zeta+(1+1/\\zeta)\\frac{24L_{Q}^{2}\\alpha^{2}}{(1-\\gamma)\\mu}\\right)}\\end{array}\\!\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{s=\\binom{s_{1}}{s_{2}}=\\left((1+1/\\zeta)\\frac{6\\sigma^{2}}{(1-\\gamma)\\mu}\\left(N(\\bar{\\varepsilon}_{s t a t}+C_{\\nu}\\bar{\\varepsilon}_{a p p o x})+4L_{Q}^{2}\\left(\\frac{\\alpha^{2}N\\bar{\\varepsilon}_{s t a t}}{(1-\\gamma)\\mu}+\\frac{\\alpha^{2}N C_{\\phi}^{2}}{\\mu^{2}(1-\\gamma)^{2}}\\right)\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Now we are ready to give the formal version of Theorem 4.4 and its proof. ", "page_idx": 30}, {"type": "text", "text": "Theorem E.10 (Convergence rate of FedNAC (formal). Let $\\pmb{\\xi}_{1}^{(0)}=\\cdot\\cdot\\cdot=\\pmb{\\xi}_{N}^{(0)}$ in FedNAC (Algorithm 3), let the $\\pmb{w}^{(0)}=\\mathbf{0}$ and the critic stepsize $\\begin{array}{r}{\\beta=\\frac{1}{2C_{\\phi}}}\\end{array}$ in Algorithm 4. Then under Assumptions 3.1, 4.1, 4.2 and 4.3, when the actor stepsize satisfies ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\alpha\\leq\\alpha_{1}:=\\frac{(1-\\sigma^{2})^{3}\\sqrt{(1-\\gamma)\\mu}}{768\\sqrt{6}\\sigma L_{Q}}\\,,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $L_{Q}$ is defined in Lemma $E.7$ we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\Gamma^{\\star}(\\rho)-\\frac{1}{T}\\frac{T-1}{\\Gamma}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]}}\\\\ &{\\leq\\frac{D_{\\star}^{(0)}+\\alpha\\delta\\rho}{T(1-\\gamma)\\alpha}+\\frac{1}{T}\\cdot\\frac{512\\sqrt{6}C_{\\phi}\\sqrt{C_{\\nu}}(\\theta_{\\rho}+1)\\sigma\\alpha}{(1-\\sigma^{2})^{3/2}(1-\\gamma)^{3}\\sqrt{N}}\\sqrt{\\Omega_{2}^{(0)}}}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{C_{\\nu}}(\\theta_{\\rho}+1)}{1-\\gamma}+\\sqrt{1+\\frac{64C_{\\phi}^{2}\\alpha^{2}}{(1-\\gamma)^{5}\\mu}}\\cdot\\frac{307\\sqrt{3}C_{\\phi}\\sqrt{C_{\\nu}}(\\theta_{\\rho}+1)\\sigma^{2}\\alpha}{(1-\\sigma^{2})^{3}(1-\\gamma)^{7/2}\\sqrt{\\mu}}\\right]}\\\\ &{\\quad\\cdot\\frac{2}{(1-\\gamma)^{2}\\sqrt{K}}\\left((\\sqrt{2p}+1)C_{\\phi}^{2}+\\sqrt{2p}\\mu(1-\\gamma)\\right)}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{2C_{\\nu}}(\\theta_{\\rho}+1)}{1-\\gamma}+\\frac{3072\\sqrt{3}C_{\\phi}C_{\\nu}(\\theta_{\\rho}+1)\\sigma^{2}\\alpha}{(1-\\sigma^{2})^{3}(1-\\gamma)^{7/2}\\sqrt{\\mu}}\\right]\\sqrt{\\varepsilon_{\\mathrm{apprac}}}+\\frac{6144\\sqrt{2}\\sigma^{2}C_{\\nu}(\\theta_{\\rho}+1)C_{\\phi}^{3}\\alpha^{2}}{(1-\\gamma)^{13/2}\\mu^{3/2}\\sqrt{\\mu^{3}\\gamma}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Moreover, the consensus errors could be upper bounded by ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|\\pmb{\\xi}^{(t)}-\\mathbf{1}_{N}\\overline{{\\pmb{\\xi}}}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}\\leq\\left(\\frac{49}{64}\\sigma^{2}+\\frac{15}{64}\\right)^{t}\\mathbb{E}\\left\\|h^{(0)}-\\mathbf{1}_{N}\\hat{w}^{(0)\\top}\\right\\|_{\\mathrm{F}}^{2}+\\frac{64\\delta(\\alpha,K)}{15(1-\\sigma^{2})}\\,,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathrm{:}(\\alpha,K):=\\frac{18\\sigma^{2}N}{(1-\\sigma^{2})(1-\\gamma)\\mu}\\left(\\bar{\\varepsilon}_{s t a t}+C_{\\nu}\\bar{\\varepsilon}_{a p p r o x}\\right)+\\frac{72\\sigma^{2}L_{Q}^{2}N}{(1-\\gamma)^{3}\\mu^{3}(1-\\sigma^{2})}\\left((1-\\gamma)\\mu\\bar{\\varepsilon}_{s t a t}+C_{\\phi}^{2}\\right)\\alpha^{2}\\,,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "and ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\bar{\\varepsilon}_{s t a t}\\leq\\frac{4}{(1-\\gamma)^{4}K}\\left((\\sqrt{2p}+1)C_{\\phi}^{2}+\\sqrt{2p}\\mu(1-\\gamma)\\right)^{2}\\,.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Remark E.11 (Sample and communication complexity). When $\\sigma>0$ and ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\alpha=\\frac{\\sqrt{\\mu}(D_{\\star}^{(0)})^{1/3}}{6144^{1/3}2^{1/6}C_{\\nu}^{1/3}(1+\\vartheta_{\\rho})^{1/3}C_{\\phi}}\\cdot\\frac{(1-\\gamma)^{11/6}(1-\\sigma^{2})}{T^{1/3}\\sigma^{2/3}},\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "it follows from Theorem E.10 that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{\\Gamma}^{*}(\\rho)-\\displaystyle\\frac{1}{T}\\sum_{t=0}^{T-1}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]}\\\\ &{\\leq\\frac{3^{1/3}\\cdot2^{9/6}(D_{\\epsilon}^{(0)})^{2/3}C^{1/3}(1+\\vartheta_{\\rho})^{1/3}C_{6}\\sigma^{2/3}}{T^{2/3}(1-\\gamma)^{17/6}(1-\\sigma^{2})\\sqrt{\\mu}}+\\frac{\\vartheta_{\\rho}}{(1-\\gamma)T}+\\frac{2^{17/3}3^{1/6}C_{\\nu}^{1/6}(1+\\vartheta_{\\rho})^{2/3}\\sigma^{1/3}\\sqrt{\\mu}}{T^{4/3}(1-\\sigma^{2})^{1/2}(1-\\gamma)^{7/6}}}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}+\\sqrt{1+\\frac{(D_{\\nu}^{(0)})^{2/3}(1-\\gamma)^{4/3}(1-\\sigma^{2})^{1/3}T^{2/3}\\sigma^{4/3}}{3^{3/2}\\cdot4C_{\\nu}^{2/3}(1-\\gamma)^{4/3}(1+\\vartheta_{\\rho})^{1/3}T^{2/3}\\sigma^{4/3}}}\\cdot\\frac{2^{37/6}\\cdot3^{7/6}C_{\\nu}^{1/6}(\\vartheta_{\\rho}+1)}{(1-\\sigma^{2})^{2}(1)}+\\right.}\\\\ &{\\quad\\left.\\cdot\\frac{2}{(1-\\gamma)^{2}\\sqrt{K}}\\left((\\sqrt{2p}+1)C_{\\phi}^{2}+\\sqrt{2p}\\mu(1-\\gamma)\\right)\\right.}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{2C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}+\\frac{2^{3/6}\\cdot3^{7/6}C_{\\nu}^{1/6}(\\vartheta_{\\rho}+1)^{2/3}\\sigma^{4/3}(D_{\\nu}^{(0)})^{1/3}}{(1-\\sigma^{2})^{2}(1-\\gamma)^{5/3}T^{2/3}}\\right]\\sqrt{\\varepsilon_{\\mathfrak{g}\\mathfrak{p e r e}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Consequently, we need ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\cap\\subsetneq\\left\\{\\frac{\\sigma}{\\varepsilon^{3/2}(1-\\gamma)^{17/4}(1-\\sigma^{2})^{3/2}},\\frac{1}{\\varepsilon(1-\\gamma)},\\frac{\\sigma^{1/4}}{\\varepsilon^{3/4}(1-\\sigma^{2})^{3/8}(1-\\gamma)^{7/8}N^{3/8}},\\frac{\\sigma^{4}}{(1-\\gamma)^{2}(1-\\gamma^{2})^{6}}\\right\\}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{6}\\varepsilon^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "such that $\\begin{array}{r}{V^{\\star}(\\rho)\\,-\\,\\frac{1}{T}\\sum_{t=0}^{T-1}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]\\,\\,\\lesssim\\,\\,\\varepsilon\\,+\\,\\frac{\\bar{\\varepsilon}_{\\mathrm{approx}}}{1-\\gamma}}\\end{array}$ In Algorithm 5, each trajectory has the expected length $1/(1-\\gamma)$ . Consider only the term where $\\varepsilon$ dominates, FedNAC requires $\\begin{array}{r}{\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{45/4}\\varepsilon^{7/2}(1-\\sigma^{2})^{3/2}}\\right)}\\end{array}$ samples for each agent and $\\begin{array}{r}{\\mathcal{O}\\left(\\frac{1}{\\varepsilon^{3/2}(1-\\gamma)^{17/4}(1-\\sigma^{2})^{3/2}}\\right)}\\end{array}$ rounds of communication. ", "page_idx": 31}, {"type": "text", "text": "On the other end, when $\\sigma=0$ , (128) becomes: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{\\displaystyle\\gamma^{\\star}(\\rho)-\\frac{1}{T}\\sum_{t=0}^{T-1}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]\\leq\\frac{D_{\\star}^{(0)}+\\alpha\\vartheta_{\\rho}}{T(1-\\gamma)\\alpha}+\\frac{4\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{(1-\\gamma)^{3}\\sqrt{K}}\\left((\\sqrt{2p}+1)C_{\\phi}^{2}+\\sqrt{2p}\\mu(1-\\gamma)\\right)}\\\\ {+\\,\\displaystyle\\frac{2\\sqrt{2C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}\\sqrt{\\bar{\\varepsilon}_{\\mathrm{appox}}},\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(132)}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Consequenty fr any ixed $\\alpha\\,>\\,0$ when $\\sigma\\,=\\,0$ or closeto 0 ithn $\\begin{array}{r}{T=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)\\varepsilon}\\right)}\\end{array}$ and $K=$ $\\begin{array}{r}{\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{6}\\varepsilon^{2}}\\right)}\\end{array}$ FedNAC requires $\\begin{array}{r}{K T/(1-\\gamma)=\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)^{8}\\varepsilon^{3}}\\right)}\\end{array}$ sample for cachagent andl $T=$ $\\begin{array}{r}{\\mathcal{O}\\left(\\frac{1}{(1-\\gamma)\\varepsilon}\\right)}\\end{array}$ rounds of communicationsuchthat $\\begin{array}{r}{V^{\\star}(\\rho)-\\frac{1}{T}\\sum_{t=0}^{T-1}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]\\lesssim\\varepsilon+\\frac{\\bar{\\varepsilon}_{\\mathrm{approx}}}{1-\\gamma}.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "E.1 Proof of Theorem E.10 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We suppose Assumptions 3.1, E.2, 4.1, 4.2 and 4.3 holds. By Lemma E.9 and nonnegativity of each entry of $_{C}$ $\\pmb{s}$ and $\\bar{\\Omega}^{(t)}$ where $t\\in\\mathbb{N}$ it's easy to see that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sqrt{\\Omega^{(t+1)}}\\leq\\sqrt{C}\\sqrt{\\Omega^{(t)}}+\\sqrt{s},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\sqrt{\\cdot}$ is exerted element-wise. ", "page_idx": 31}, {"type": "text", "text": "In addition, taking expectation on both sides of (123) and using the act that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sqrt{2\\left(\\bar{\\varepsilon}_{\\mathrm{approx}}+\\frac{L_{Q}^{2}}{N}\\left\\|\\pmb{\\xi}^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}\\right)}\\right]\\leq\\sqrt{2\\bar{\\varepsilon}_{\\mathrm{approx}}}+\\sqrt{\\frac{2L_{Q}^{2}}{N}\\Omega_{1}^{(t)}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\vartheta_{\\rho}\\mathbb{E}[\\delta^{(t+1)}]+\\displaystyle\\frac{\\mathbb{E}[D_{\\star}^{(t+1)}]}{(1-\\gamma)\\alpha}\\leq\\vartheta_{\\rho}\\mathbb{E}[\\delta^{(t)}]+\\displaystyle\\frac{\\mathbb{E}[D_{\\star}^{(t)}]}{(1-\\gamma)\\alpha}-\\mathbb{E}[\\delta^{(t)}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\displaystyle\\frac{2\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}\\left(\\sqrt{\\bar{\\varepsilon}_{\\mathrm{stat}}}+\\sqrt{2\\bar{\\varepsilon}_{\\mathrm{approx}}}+\\sqrt{\\displaystyle\\frac{2L_{Q}^{2}}{N}\\Omega_{1}^{(t)}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We define the Lyapunov function $\\Phi^{(t)}$ as follows: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\Phi^{(t)}:=\\vartheta_{\\rho}\\mathbb{E}[\\delta^{(t)}]+\\frac{\\mathbb{E}[D_{\\star}^{(t)}]}{(1-\\gamma)\\alpha}+\\pmb{q}^{\\top}\\sqrt{\\Omega^{(t)}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb q=\\binom{q_{1}}{q_{2}}=\\left(\\frac{\\frac{2L_{Q}\\sqrt{2C_{\\nu}}(\\vartheta_{\\rho}+1)}{(1-\\gamma)\\sqrt{N}}\\cdot\\frac{1}{1-\\sqrt{1+\\zeta}\\sigma-\\sqrt{(1+1/\\zeta)c_{21}}\\sigma\\alpha/(1-\\sqrt{c_{22}})}}{\\frac{2L_{Q}\\sqrt{2C_{\\nu}}(\\vartheta_{\\rho}+1)}{(1-\\gamma)\\sqrt{N}}\\cdot\\frac{\\sqrt{1+1/\\zeta}\\sigma\\alpha}{(1-\\sqrt{1+\\zeta}\\sigma)(1-\\sqrt{c_{22}})-\\sqrt{(1+1/\\zeta)c_{21}}\\sigma\\alpha}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "It's straightforward to verify that when $\\textstyle\\zeta={\\frac{1-\\sigma^{2}}{2}}$ , we have the entries in C (cf. (125) satisfies ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{c_{11}<\\frac{1+\\sigma^{2}}{2},}}\\\\ {\\displaystyle{c_{12}\\leq\\frac{3\\sigma^{2}\\alpha^{2}}{1-\\sigma^{2}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Moreover,from $\\begin{array}{r}{\\alpha\\leq\\frac{\\sqrt{(1-\\gamma)\\mu}(1-\\sigma^{2})}{12\\sqrt{2}\\sigma L_{Q}}}\\end{array}$ wededuce ", "page_idx": 32}, {"type": "equation", "text": "$$\nc_{22}\\leq{\\frac{3+\\sigma^{2}}{4}},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which gives ", "page_idx": 32}, {"type": "equation", "text": "$$\n1-{\\sqrt{c_{22}}}\\geq1-{\\sqrt{\\frac{3+\\sigma^{2}}{4}}}\\geq{\\frac{1-\\sigma^{2}}{8}},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Also note that $\\begin{array}{r}{\\alpha\\leq\\frac{(1-\\sigma^{2})^{3}\\sqrt{(1-\\gamma)\\mu}}{768\\sqrt{6}\\sigma^{2}L_{Q}}}\\end{array}$ yelds ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\sqrt{(1+1/\\zeta)c_{21}}\\sigma\\alpha\\leq\\frac{(1-\\sqrt{1+\\zeta}\\sigma)(1-\\sqrt{c_{22}})}{2}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which together with (140) and the fact $\\begin{array}{r}{1-\\sqrt{1+\\zeta}\\sigma\\geq\\frac{1-\\sigma^{2}}{4}}\\end{array}$ indicates $q_{1},q_{2}>0$ and that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l}{q_{1}\\leq\\frac{16\\sqrt{2}L_{Q}\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{(1-\\sigma^{2})(1-\\gamma)\\sqrt{N}},}\\\\ {q_{2}\\leq\\frac{128\\sqrt{6}L_{Q}\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)\\sigma\\alpha}{(1-\\sigma^{2})^{5/2}(1-\\gamma)\\sqrt{N}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Thus by (133) and (134) we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi^{(t+1)}=\\vartheta_{p}\\mathbb{E}[\\delta^{(t+1)}]+\\frac{\\mathbb{E}[D_{\\delta}^{(t+1)}]}{(1-\\gamma)\\alpha}+q^{\\top}\\sqrt{\\Omega^{(t+1)}}}\\\\ &{\\leq\\vartheta_{p}\\mathbb{E}[\\delta^{(t)}]+\\frac{\\mathbb{E}[D_{\\delta}^{(t+1)}]}{(1-\\gamma)\\alpha}-\\mathbb{E}[\\delta^{(t)}]+q^{\\top}\\left(\\sqrt{C}\\sqrt{\\Omega^{(t)}}+\\sqrt{\\vartheta}\\right)}\\\\ &{\\qquad+\\frac{2\\sqrt{C_{p}}(\\vartheta_{\\vartheta}+1)}{1-\\gamma}\\left(\\sqrt{\\ell_{\\Xi u}}+\\sqrt{2\\ell_{\\vartheta\\varphi\\infty}}+\\sqrt{\\frac{2L_{\\vartheta}^{2}}{N}}\\Omega_{1}^{(t)}\\right)}\\\\ &{=\\Phi^{(t)}+\\left(\\underbrace{q^{\\top}(\\sqrt{C}-I)+\\left(\\frac{2L_{\\vartheta}\\sqrt{2C_{\\nu}}(\\vartheta_{\\vartheta}+1)}{(1-\\gamma)\\sqrt{N}},0\\right)}_{=(0,0)}\\right)\\sqrt{\\Omega^{(t)}}}\\\\ &{\\qquad+\\frac{2\\sqrt{C_{p}}(\\vartheta_{\\vartheta}+1)}{1-\\gamma}\\left(\\sqrt{\\ell_{\\Xi u}}+\\sqrt{2\\xi_{\\Xi u\\varphi\\infty}}\\right)+q_{2}\\sqrt{\\vartheta_{2}}-\\mathbb{E}[\\delta^{(t)}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which gives ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\delta^{(t)}]\\leq\\Phi^{(t)}-\\Phi^{(t+1)}+\\frac{2\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}\\left(\\sqrt{\\bar{\\varepsilon}_{\\mathrm{stat}}}+\\sqrt{2\\bar{\\varepsilon}_{\\mathrm{approx}}}\\right)+q_{2}\\sqrt{s_{2}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Summing the above inequality over $t=0,1,\\cdot\\cdot\\cdot,T-1$ and divide both sides by $T$ wehave ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=0}^{T-1}\\mathbb{E}[\\delta^{(t)}]\\leq\\frac{\\Phi^{(0)}-\\Phi^{(t)}}{T}+\\frac{2\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{1-\\gamma}\\left(\\sqrt{\\bar{\\varepsilon}_{\\mathrm{stat}}}+\\sqrt{2\\bar{\\varepsilon}_{\\mathrm{appox}}}\\right)+q_{2}\\sqrt{s_{2}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Since ", "page_idx": 32}, {"type": "equation", "text": "$$\ns_{2}\\leq\\frac{18\\sigma^{2}N}{(1-\\sigma^{2})(1-\\gamma)\\mu}\\left(\\bar{\\varepsilon}_{\\mathrm{sut}}+C_{\\nu}\\bar{\\varepsilon}_{\\mathrm{appox}}\\right)+\\frac{72\\sigma^{2}L_{Q}^{2}N}{(1-\\gamma)^{3}\\mu^{3}(1-\\sigma^{2})}\\left((1-\\gamma)\\mu\\bar{\\varepsilon}_{\\mathrm{sut}}+C_{\\phi}^{2}\\right)\\alpha^{2},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathfrak{p}^{(0)}-\\Phi^{(t)}\\le\\Phi^{(0)}\\le\\frac{\\vartheta_{\\rho}}{1-\\gamma}+\\frac{\\mathbb{E}[D_{\\star}^{(0)}]}{(1-\\gamma)\\alpha}+\\frac{16\\sqrt{2}L_{Q}\\sqrt{C_{\\nu}}(\\vartheta_{\\rho}+1)}{(1-\\sigma^{2})(1-\\gamma)\\sqrt{N}}\\left(\\sqrt{\\Omega_{1}^{(0)}}+\\frac{8\\sqrt{3}\\sigma\\alpha}{\\sqrt{1-\\sigma^{2}}}\\sqrt{\\Omega_{2}^{(0)}}\\right),\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "we have (recall that $\\begin{array}{r}{L_{Q}=\\frac{2C_{\\phi}\\gamma(1+\\gamma)}{(1-\\gamma)^{2}}\\leq\\frac{4C_{\\phi}}{(1-\\gamma)^{2}})}\\end{array}$ ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r^{\\star}(\\rho)-\\displaystyle\\frac{1}{T}\\displaystyle\\sum_{t=0}^{T-1}\\mathbb{E}\\left[\\bar{V}^{(t)}(\\rho)\\right]}\\\\ &{\\leq\\displaystyle\\frac{D_{\\phi}^{(0)}}{T(1-\\gamma)\\alpha}+\\frac{1}{T}\\cdot\\frac{64\\sqrt{2}C_{\\phi}\\sqrt{C_{\\nu}}(\\rho_{\\rho}+1)}{(1-\\sigma^{2})(1-\\gamma)^{3}\\sqrt{N}}\\left(\\sqrt{\\Omega_{1}^{(0)}}+\\frac{8\\sqrt{3}\\sigma\\alpha}{\\sqrt{1-\\sigma^{2}}}\\sqrt{\\Omega_{2}^{(0)}}\\right)}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{C_{\\nu}}(\\rho_{\\rho}+1)}{1-\\gamma}+\\sqrt{\\frac{18\\sigma^{2}N}{(1-\\sigma^{2})(1-\\gamma)\\mu}}+\\frac{1152\\sigma^{2}C_{\\phi}^{2}N\\alpha^{2}}{(1-\\gamma)^{6}\\mu^{2}(1-\\sigma^{2})}\\cdot\\frac{512\\sqrt{6}C_{\\phi}\\sqrt{C_{\\nu}}(\\theta_{\\rho}+1)\\sigma\\alpha}{(1-\\sigma^{2})^{5/2}(1-\\gamma)^{3}\\sqrt{N}}\\right]}\\\\ &{\\quad+\\left[\\frac{2\\sqrt{2}C_{\\nu}(\\theta_{\\rho}+1)}{1-\\gamma}+\\sqrt{\\frac{18\\sigma^{2}N C_{\\nu}}{(1-\\sigma^{2})(1-\\gamma)\\mu}},\\frac{512\\sqrt{6}C_{\\phi}\\sqrt{C_{\\nu}}(\\theta_{\\rho}+1)\\sigma\\alpha}{(1-\\sigma^{2})^{5/2}(1-\\gamma)^{3}\\sqrt{N}}\\right]\\sqrt{\\varepsilon_{\\mathrm{qpro}}}}\\\\ &{\\quad+\\frac{614\\sqrt{2}\\sigma^{2}\\gamma(C_{\\nu}(\\theta_{\\rho}+1)C_{\\phi}^{2}\\alpha^{2}}{(1-\\gamma)^{1/3/2}\\mu^{3/2}(1-\\sigma^{2})^{3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By Theorem E.3 we know that $\\sqrt{\\bar{\\varepsilon}_{\\mathrm{stat}}}$ could be upper bounded as follows: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\sqrt{\\bar{\\varepsilon}_{s t a t}}\\leq\\frac{2}{(1-\\gamma)^{2}\\sqrt{K}}\\left((\\sqrt{2p}+1)C_{\\phi}^{2}+\\sqrt{2p}\\mu(1-\\gamma)\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "(128)follows from pluging(149) into(148) and noting that when $\\pmb{\\xi}_{1}^{(0)}=\\cdot\\cdot\\cdot=\\pmb{\\xi}_{N}^{(0)}$ \uff0c $\\Omega_{1}^{(0)}=0$ ", "page_idx": 33}, {"type": "text", "text": "Bounding the consensus errors. Similar to Step 4 in Appendix F.4, to bound the consensus eror $\\left\\|\\log f_{n}^{(t)}-\\log\\bar{f}^{(t)}\\right\\|_{\\infty}$ for all $n\\in[N]$ , we first upper bound the eigenvalue of $\\rho(C).$ -the spectral norm of $_{C}$ ", "page_idx": 33}, {"type": "text", "text": "The characteristic polynomial of $_{C}$ is ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{f(\\lambda)=(\\lambda-c_{11})(\\lambda-c_{22})-c_{12}c_{21}}}\\\\ {{\\qquad=\\lambda^{2}-(c_{11}+c_{22})\\lambda+c_{11}c_{22}-c_{12}c_{21}\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "which gives ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\rho(C)\\leq\\frac{c_{11}+c_{22}+\\sqrt{(c_{11}+c_{22})^{2}-4(c_{11}c_{12}-c_{11}c_{21})}}{2}}\\\\ &{\\qquad=\\frac{c_{11}+c_{22}+\\sqrt{(c_{22}-c_{11})^{2}+4c_{12}c_{21}}}{2}}\\\\ &{\\qquad\\leq\\frac{c_{11}+c_{22}+c_{22}-c_{11}+2\\sqrt{c_{12}c_{21}}}{2}}\\\\ &{\\qquad=c_{22}+\\sqrt{c_{12}c_{21}}}\\\\ &{\\qquad\\leq\\frac{3+\\sigma^{2}}{4}+\\sqrt{\\frac{3}{1-\\sigma^{2}}}\\cdot\\frac{12\\sqrt{2}L_{\\sigma^{\\sigma}}}{\\sqrt{1-\\sigma^{2}}(1-\\gamma)\\mu}}\\\\ &{\\qquad\\leq\\frac{3+\\sigma^{2}}{64}+\\frac{\\sigma(1-\\sigma^{2})^{2}}{64}}\\\\ &{\\qquad\\leq\\frac{49+15\\sigma^{2}}{64}<1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the third inequality uses (138), (139), and the fourth inequality uses (127) ", "page_idx": 33}, {"type": "text", "text": "Therefore, similar to (230), when $\\alpha\\leq\\alpha_{1}$ , we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\left\\Vert\\Omega^{(t)}\\right\\Vert_{2}\\leq\\left(\\frac{49}{64}\\sigma+\\frac{15}{64}\\right)^{t}\\left\\Vert\\Omega^{(0)}\\right\\Vert_{2}+\\frac{64s_{2}}{15(1-\\sigma^{2})}\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Combining the above inequality with (146), and (149), we obtain (129). ", "page_idx": 33}, {"type": "text", "text": "E.2Proof of Theorem E.3 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "The proof of Theorem E.3 could be found in Appendix C.5 in $[\\mathrm{YDG}^{+}22]$ .We present it for completeness. To prove Theorem E.3, we need the following Theorem G.2. ", "page_idx": 34}, {"type": "text", "text": "Theorem E.12 (Theorem 1 in [BM13]). Consider the following assumptions: ", "page_idx": 34}, {"type": "text", "text": "(i) The observations $(\\pmb{a}_{k},\\pmb{b}_{k})\\in\\mathbb{R}^{p}\\times\\mathbb{R}^{p}$ are independent and identically distributed.   \n(i) $\\mathbb{E}\\left[\\left\\Vert\\mathbf{a}_{k}\\right\\Vert^{2}\\right]^{\\intercal}$ and $\\mathbb{E}\\left[\\left\\Vert b_{k}\\right\\Vert^{2}\\right]$ are finite. The covariance E $\\left[\\mathbf{a}_{k}\\mathbf{a}_{k}^{\\top}\\right]$ is invertible.   \n(ii)The global minimum of $\\begin{array}{r}{g(w)=\\frac{1}{2}\\mathbb{E}\\left[\\langle w,\\pmb{a}_{k}\\rangle^{2}-2\\langle w,b_{k}\\rangle\\right]}\\end{array}$ is attained at a certain $\\pmb{w}^{\\star}\\in\\mathbb{R}^{p}$ Let $\\Delta_{k}=b_{k}-\\langle{\\pmb w}^{\\star},{\\pmb a}_{k}\\rangle{\\pmb a}_{k}$ denote the residual. We have $\\mathbb{E}[\\Delta_{k}]=0$   \n(iv) $\\exists R\\,>\\,0$ and $\\sigma~>~0$ such that $\\mathbb{E}\\left[\\Delta_{k}\\Delta_{k}^{\\top}\\right]\\ \\leq\\ \\sigma^{2}\\mathbb{E}\\left[a_{k}\\pmb{a}_{k}^{\\top}\\right]$ and $\\mathbb{E}\\left[\\left\\Vert\\mathbf{a}_{k}\\right\\Vert^{2}\\mathbf{a}_{k}\\mathbf{a}_{k}^{\\top}\\right]\\ \\leq$ $R^{2}\\mathbb{E}\\left[\\mathbf{a}_{k}\\mathbf{a}_{k}^{\\top}\\right]$ ", "page_idx": 34}, {"type": "text", "text": "Consider the stochastic gradient recursion ", "page_idx": 34}, {"type": "equation", "text": "$$\nw_{k+1}=w_{k}-\\eta\\left(\\langle w_{k},a_{k}\\rangle a_{k}-b_{k}\\right)\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "started from $w_{0}\\in\\mathbb{R}^{p}$ Let $\\begin{array}{r}{w_{o u t}=\\frac{1}{K}\\sum_{k=1}^{K}w_{k}}\\end{array}$ When $\\begin{array}{r}{\\eta=\\frac{1}{4R^{2}}}\\end{array}$ 4R2, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[g(w_{o u t})-g(w^{\\star})\\right]\\le\\frac{2}{K}(\\sigma\\sqrt{p}+R\\left\\|w_{0}-w^{\\star}\\right\\|)^{2}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "In the proof of Theorem E.3 we'll show that for Algorithm 4, the assumptions in Theorem G.2 are all satisfied and thus we can use the result (267). ", "page_idx": 34}, {"type": "text", "text": "Proof of Theorem E.3. We let $a_{k}$ and $b_{k}$ in Theorem G.2 be $\\phi(s,a)$ and $\\widehat{Q}_{\\xi}\\phi(s,a)$ in Algorithm 4, respectively. And we let $\\left\\|\\cdot\\right\\|\\ \\ =\\ \\ \\left\\|\\cdot\\right\\|_{2}$ in Theorem G.2. Since the observations $\\left(\\phi(s,a),\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right)\\in\\mathbb{R}^{p}\\times\\mathbb{R}^{p}$ are i.i.d., (i is satisfied. ", "page_idx": 34}, {"type": "text", "text": "As we assume $\\|\\phi(s,a)\\|_{2}\\,\\leq\\,C_{\\phi},\\,\\mathbb{E}\\left[\\|\\phi(s,a)\\|_{2}^{2}\\right]$ is finite. From Assumption 4.1 we know that $\\mathbb{E}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]$ is invertible. ", "page_idx": 34}, {"type": "text", "text": "Let $H$ be the length of rajectory for estimating $\\widehat{Q}_{\\xi}(s,a)$ . Then $\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}$ is bounded by ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}\\right]=\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[\\displaystyle\\sum_{\\tau=0}^{\\infty}P r(H=\\tau)\\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau}r(s_{t},a_{t})\\right)^{2}\\bigg|H=\\tau,s_{0}=s,a_{0}=a\\right]\\right]}\\\\ &{}&{=\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[(1-\\gamma)\\displaystyle\\sum_{\\tau=0}^{\\infty}\\gamma^{\\tau}\\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau}r(s_{t},a_{t})\\right)^{2}\\bigg|H=\\tau,s_{0}=s,a_{0}=a\\right]\\right]}\\\\ &{}&{\\leq\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[(1-\\gamma)\\displaystyle\\sum_{\\tau=0}^{\\infty}\\gamma^{\\tau}(\\tau+1)^{2}\\right]\\leq\\displaystyle\\frac{2}{(1-\\gamma)^{2}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "from which we deduce $\\mathbb{E}\\left[\\left\\lVert\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right\\rVert_{2}^{2}\\right]\\leq C_{\\phi}^{2}\\mathbb{E}\\left[\\widehat{Q}_{\\xi}(s,a)^{2}\\right]$ is bounded Thus i holds. Furthermore, we introduce the residual ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\Delta:=\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)\\phi(s,a)\\,,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "then from Lemma 7 in $[\\mathrm{YDG}^{+}22]$ we know that $\\begin{array}{r}{\\mathbb{E}[\\Delta]=\\frac{1}{2}\\nabla_{w}\\ell(w,\\widehat{Q}_{\\xi},d_{\\nu}^{\\pi_{\\xi}})=0}\\end{array}$ , which gives (ii). ", "page_idx": 34}, {"type": "text", "text": "To verify (iv), we let $\\mathrm{~\\textit~{~R~}~}=\\mathrm{~\\textit~{~C~}~}_{\\phi}$ in Theorem G.2, then $\\begin{array}{r l}{\\mathbb{E}\\left[\\left\\|\\phi(s,a)\\right\\|_{2}^{2}\\phi(s,a)\\phi(s,a)^{\\top}\\right]}&{\\leq}\\end{array}$ $C_{\\phi}^{2}\\mathbb{E}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]$ . Also note that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w^{\\star}=\\left(\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}^{\\varepsilon}}}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]\\right)^{\\dagger}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}^{\\varepsilon}}}\\left[\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right]}\\\\ &{\\quad\\leq\\displaystyle\\frac{1}{1-\\gamma}\\left(\\mathbb{E}_{(s,a)\\sim\\nu}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]\\right)^{\\dagger}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}^{\\varepsilon}}}\\left[\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "from which we deduce ", "page_idx": 35}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\|w^{\\star}\\|_{2}\\leq\\frac{B}{\\mu(1-\\gamma)^{2}}\\,.\n$$$$\n\\begin{array}{r l}&{\\begin{array}{r l}{\\|w^{*}\\|_{2}\\leq\\frac{\\gamma}{\\mu(1-\\gamma)^{2}}\\cdot}&{\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ &{}\\\\ {\\boldsymbol{\\mathfrak{z}}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{*}\\right)^{2}|s,a\\right]=\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}|s,a\\right]-2Q_{\\xi}(s,a)\\phi(s,a)^{\\top}w^{*}+(\\phi(s,a)^{\\top}w}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2}{(1-\\gamma)^{2}}+\\frac{2C_{\\phi}^{2}}{\\mu(1-\\gamma)^{3}}+\\frac{C_{\\phi}^{4}}{\\mu^{2}(1-\\gamma)^{4}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\frac{2}{(1-\\gamma)^{2}}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)^{2}.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The above expression implies ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\Delta\\Delta^{\\top}\\right]=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu^{\\varepsilon}}^{\\pi}}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)^{2}\\phi(s,a)\\phi(s,a)^{\\top}|s,a\\right]}\\\\ &{\\quad\\quad\\quad\\quad=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu^{\\varepsilon}}^{\\pi}}\\left[\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)^{2}|s,a\\right]\\phi(s,a)\\phi(s,a)^{\\top}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\leq\\left(\\underbrace{\\sqrt{2}}_{\\hphantom{(}\\displaystyle{\\frac{\\pi^{2}}{2}}\\gamma}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)\\right)\\mathbb{E}\\big[\\phi(s,a)\\phi(s,a)^{\\top}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Therefore, (iv) is verified. ", "page_idx": 35}, {"type": "text", "text": "Thus by (267), with stepsize $\\begin{array}{r}{\\beta=\\frac{1}{2C_{\\phi}^{2}}}\\end{array}$ initalizationw = OandK stes ofcritc updates, weave ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\ell\\left(w_{\\mathrm{out}},\\widehat{Q}_{\\xi},\\tilde{d}_{\\xi}\\right)\\right]-\\ell\\left(w^{\\star},\\widehat{Q}_{\\xi},\\tilde{d}_{\\xi}\\right)\\leq\\displaystyle\\frac{4}{K}\\left(\\sigma\\sqrt{p}+C_{\\phi}\\left\\lVert w^{\\star}\\right\\rVert_{2}\\right)^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{4}{K}\\left(\\frac{\\sqrt{2p}}{1-\\gamma}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)+\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)^{2}}\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "which gives (113). ", "page_idx": 35}, {"type": "text", "text": "F  Proof of key lemmas ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "F.1Proof of Lemma D.2 ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Before proceeding, we summarize several useful properties of the auxiliary sequences (cf. (40) and (41)), whose proof is postponed to Appendix G.1. ", "page_idx": 35}, {"type": "text", "text": "Lemma F.1 (Properties of auxiliary sequences $\\{\\overline{{\\xi}}^{(t)}\\}$ and $\\{\\pmb{\\xi}^{(t)}\\}).\\;\\;\\{\\overline{{{\\xi}}}^{(t)}\\}$ and $\\{\\pmb{\\xi}^{(t)}\\}$ have the following properties: ", "page_idx": 35}, {"type": "text", "text": "1. ${\\pmb\\xi}^{(t)}$ can be viewed as an unnormalized version of $\\pi^{(t)}$ ,i.e., ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\pi_{n}^{(t)}(\\cdot|s)=\\frac{\\xi_{n}^{(t)}(s,\\cdot)}{\\left\\|\\xi_{n}^{(t)}(s,\\cdot)\\right\\|_{1}}\\,,\\;\\forall n\\in[N],\\,s\\in\\mathcal{S}\\,.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "2. For any $t\\geq0$ $\\log\\overline{{\\xi}}^{(t)}$ keeps track of the average of $\\log\\pmb{\\xi}^{(t)}$ , i.e., ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\mathbf{1}_{N}^{\\top}\\log\\pmb{\\xi}^{(t)}=\\log\\overline{{\\xi}}^{(t)}\\,.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "It follows that ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\forall s\\in{\\cal S},\\,t\\geq0:\\quad\\overline{{\\pi}}^{(t)}(\\cdot|s)=\\frac{\\overline{{\\xi}}^{(t)}(s,\\cdot)}{\\left\\|\\overline{{\\xi}}^{(t)}(s,\\cdot)\\right\\|_{1}}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "LemmaF.2 $[\\mathrm{CCC}^{+}22\\mathrm{b}$ Appendix.A.2).For any vector $\\theta\\;=\\;[\\theta_{a}]_{a\\in\\mathcal{A}}\\;\\in\\;\\mathbb{R}^{|\\mathcal{A}|}$ wedenoteby $\\pi_{\\theta}\\in\\mathbb{R}^{|A|}$ the softmaxtransformof $\\theta$ Such that ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\pi_{\\theta}(a)=\\frac{\\exp(\\theta_{a})}{\\sum_{a^{\\prime}\\in\\mathcal{A}}\\exp(\\theta_{a^{\\prime}})}\\,,\\quad a\\in\\mathcal{A}\\,.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "For any $\\theta_{1},\\theta_{2}\\in\\mathbb{R}^{|A|}$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big|\\log(\\|\\mathrm{exp}(\\theta_{1})\\|_{1})-\\log(\\|\\mathrm{exp}(\\theta_{2})\\|_{1})\\big|\\le\\|\\theta_{1}-\\theta_{2}\\|_{\\infty}\\ ,\\ \\qquad}\\\\ {\\|\\!\\log\\pi_{\\theta_{1}}-\\log\\pi_{\\theta_{2}}\\|_{\\infty}\\le2\\,\\|\\theta_{1}-\\theta_{2}\\|_{\\infty}\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Step 1: bound $u^{(t+1)}(s,a)\\,=\\,\\bigl\\|\\log\\pmb{\\xi}^{(t+1)}(s,a)-\\log\\mp^{(t+1)}(s,a)\\mathbf{1}_{N}\\bigr\\|_{2}$ (t+1) (s,a)1l2 By (40b) and(41b) we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\iota^{(t+1)}(s,a)=\\big\\|\\log\\pmb{\\xi}^{(t+1)}(s,a)-\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}}\\\\ &{\\qquad\\qquad=\\Big\\|\\alpha\\Big(W\\log\\pmb{\\xi}^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\Big)+(1-\\alpha)\\Big(W\\pmb{T}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\Big)/}\\\\ &{\\qquad\\qquad\\leq\\sigma\\alpha\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}+\\frac{1-\\alpha}{\\tau}\\sigma\\big\\|\\pmb{T}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}}\\\\ &{\\qquad\\qquad\\leq\\sigma\\alpha\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{1-\\alpha}{\\tau}\\sigma\\|v^{(t)}\\|_{\\infty},}&{(166)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the penultimate step results from the averaging property of $W$ (property (11)). Taking maximum over $(s,a)\\in S\\times A$ establishes the bound on $\\Omega_{1}^{(t+1)}$ in (49). ", "page_idx": 36}, {"type": "text", "text": "Step 2: bound $v^{(t+1)}(s,a)=\\left\\|\\pmb{T}^{(t+1)}(s,a)-\\widehat{\\pmb{Q}}_{\\tau}^{(t+1)}(s,a)\\pmb{1}_{N}\\right\\|_{2}$ By $(U_{T})$ we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{[\\mathcal{I}^{\\iota\\lefteqn{(\\tau^{(t)}+\\iota)}(s,a)-Q_{\\tau}^{\\scriptscriptstyle{(t+\\tau^{+})}(s,a)}(s,a)\\mathbf{1}_{N}\\|_{2}}\\\\ &{=\\left\\|W\\left(\\pmb{T}^{(t)}(s,a)+Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{=\\left\\|\\left(\\pmb{W}\\pmb{T}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\right)+\\pmb{W}\\left(\\pmb{Q}_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)\\right)+\\left(\\widehat{Q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a)\\right)}\\\\ &{\\leq\\sigma\\|\\pmb{T}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\|_{2}+\\sigma\\left\\|\\left(\\pmb{Q}_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)\\right)+\\left(\\widehat{Q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a)\\right)}\\\\ &{\\leq\\sigma\\|\\pmb{T}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\|_{2}+\\sigma\\|Q_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)\\|_{2},}&{(167)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the penultimate step uses property (11), and the last step is due to ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\left(Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right)+\\left(\\widehat{Q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a)\\right)\\mathbf{1}_{N}\\right\\|_{2}^{2}}\\\\ &{=\\left\\|Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right\\|_{2}^{2}+N(\\widehat{Q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a))^{2}}\\\\ &{\\qquad-2\\displaystyle\\sum_{n=1}^{N}\\left(Q_{\\tau,n}^{\\pi_{n}^{(t+1)}}(s,a)-Q_{\\tau,n}^{\\pi_{n}^{(t)}}(s,a)\\right)\\left(\\widehat{Q}_{\\tau}^{(t+1)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\right)}\\\\ &{=\\left\\|Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right\\|_{2}^{2}-N(\\widehat{Q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t+1)}(s,a))^{2}}\\\\ &{\\leq\\left\\|Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Step 3: bound $\\left\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right\\|_{\\infty}.$ We decompose the term of interest as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}=Q_{\\tau}^{\\star}-\\tau\\alpha\\log\\overline{{\\xi}}^{(t)}-(1-\\alpha)\\widehat{Q}_{\\tau}^{(t)}}\\\\ &{\\qquad\\qquad\\qquad=\\alpha(Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)})+(1-\\alpha)(Q_{\\tau}^{\\star}-\\overline{{Q}}_{\\tau}^{(t)})+(1-\\alpha)(\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{Q}_{\\tau}^{(t)}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "which gives ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\big|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\big|\\big|_{\\infty}\\leq\\alpha\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)\\big\\|Q_{\\tau}^{\\star}-\\overline{{Q}}_{\\tau}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)\\big\\|\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{Q}_{\\tau}^{(t)}\\big\\|_{\\infty}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Note that we can upper bound $\\big|\\big|\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{Q}_{\\tau}^{(t)}\\big|\\big|_{\\infty}$ by ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{Q}_{\\tau}^{(t)}\\|_{\\infty}=\\left\\|\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\pi_{n}^{(t)}}-\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\pi^{(t)}}\\right\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\big\\|Q_{\\tau,n}^{\\pi_{n}^{(t)}}-Q_{\\tau,n}^{\\overline{{\\tau}}^{(t)}}\\big\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{M}{N}\\sum_{n=1}^{N}\\big\\|\\log\\xi_{n}^{(t)}-\\log\\bar{\\xi}^{(t)}\\big\\|_{\\infty}\\!\\leqslant\\!M\\big\\|u^{(t)}\\big\\|_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "The last step is due to $|\\log\\xi_{n}^{(t)}(s,a)-\\log\\overline{\\xi}^{(t)}(s,a)|\\leq u^{(t)}(s,a)$ , while the penultimate step results from writing ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\overline{{\\pi}}^{(t)}(\\cdot|s)=\\mathrm{softmax}\\left(\\log\\overline{{\\xi}}^{(t)}(s,\\cdot)\\right)\\,,}\\\\ {\\pi_{n}^{(t)}(\\cdot|s)=\\mathrm{softmax}\\left(\\log\\xi_{n}^{(t)}(s,\\cdot)\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "and applying the following lemma. ", "page_idx": 37}, {"type": "text", "text": "Lemma F.3 (Lipschitz constant of soft Q-function). Assume that $\\boldsymbol{r}(s,a)\\in[0,1],\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}$ and $\\tau\\geq0$ For any $\\theta$ $\\theta^{\\prime}\\in\\mathbb{R}^{|S||A|}$ wehave ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\|Q_{\\tau}^{\\pi_{\\theta^{\\prime}}}-Q_{\\tau}^{\\pi_{\\theta}}\\|_{\\infty}\\leq\\underbrace{\\frac{1+\\gamma+2\\tau(1-\\gamma)\\log|\\cal A|}{(1-\\gamma)^{2}}\\cdot\\gamma\\,\\|\\theta^{\\prime}-\\theta\\|_{\\infty}}_{=:M}\\;.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Plugging (169) into (168) gives ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\big\\|_{\\infty}\\leq\\alpha\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)\\big\\|Q_{\\tau}^{\\star}-\\overline{{Q}}_{\\tau}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)M\\big\\|u^{(t)}\\big\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Step 4: bound $\\left|\\left|Q_{\\tau}^{(t+1)}(s,a)-Q_{\\tau}^{(t)}(s,a)\\right|\\right|_{2}$ ", "page_idx": 37}, {"type": "text", "text": "Let $w^{(t)}:S\\times A\\rightarrow\\mathbb{R}$ be defined as ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}:\\quad w^{(t)}(s,a):=\\big\\|\\log\\xi^{(t+1)}(s,a)-\\log\\xi^{(t)}(s,a)-(1-\\alpha)V_{\\tau}^{\\star}(s)\\mathbf{1}_{N}/\\tau\\big\\|_{2}\\,.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Again, we treat $w^{(t)}$ as vectors in $\\mathbb{R}^{|S||A|}$ whenever it is clear from context. For any $(s,a)\\in S\\times A$ and $n\\in[N]$ , by Lemma F.3 it follows that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{Q_{\\tau,n}^{\\pi_{n}^{(t+1)}}(s,a)-Q_{\\tau,n}^{\\pi_{n}^{(t)}}(s,a)\\Big|\\le M\\displaystyle\\operatorname*{max}_{s\\in\\mathcal{S}}\\left\\|\\log\\xi_{n}^{(t+1)}(s,\\cdot)-\\log\\xi_{n}^{(t)}(s,\\cdot)-(1-\\alpha)V_{\\tau}^{\\star}(s)\\mathbf{1}_{|A|}/\\tau\\right\\|_{\\infty}}&{}&\\\\ {\\le M\\displaystyle\\operatorname*{max}_{s\\in\\mathcal{S}}\\displaystyle\\operatorname*{max}_{a\\in\\mathcal{A}}w^{(t)}(s,a)\\le M\\left\\|w^{(t)}\\right\\|_{\\infty},}&{}&{(173)}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "and consequently ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\left\\|\\pmb{Q}_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)\\right\\|_{2}\\leq M\\sqrt{N}\\|\\boldsymbol{w}^{(t)}\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "It boils down to control $\\left\\|w^{(t)}\\right\\|_{\\infty}$ . To do so, we first note that for each $(s,a)\\in S\\times A$ , we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v^{(t)}(s,a)}\\\\ &{=\\left\\|\\boldsymbol{W}\\left(\\alpha\\log\\xi^{(t)}(s,a)+(1-\\alpha)\\mathbf{T}^{(t)}(s,a)/\\tau\\right)-\\log\\xi^{(t)}(s,a)-(1-\\alpha)V_{\\tau}^{\\star}(s)\\mathbf{1}_{N}/\\tau\\right\\|_{2}}\\\\ &{\\overset{(a)}{=}\\left\\|\\alpha(\\boldsymbol{W}-\\boldsymbol{I}_{N})\\left(\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right)+(1-\\alpha)\\left(\\boldsymbol{W}T^{(t)}(s,a)/\\tau-\\log\\xi^{(t)}(s,a)-\\frac{1}{N}\\right)\\right\\|_{2}}\\\\ &{\\overset{(b)}{\\leq}2\\alpha\\left\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\frac{1-\\alpha}{\\tau}\\|\\boldsymbol{W}T^{(t)}(s,a)-\\tau\\log\\xi^{(t)}(s,a)-V_{\\tau}^{\\star}(s)\\mathbf{1}_{N}\\|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where (a) is due to the doubly stochasticity property of $W$ and (b) is from the fact $\\|\\b{W}-\\b{I}_{N}\\|_{2}\\leq2$ We further bound the second term as follows: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|W T^{(t)}(s,a)-\\tau\\log\\xi^{(t)}(s,a)-V_{\\tau}^{\\star}(s)\\mathbf{1}_{N}\\right|_{2}}\\\\ &{=\\left\\|W T^{(t)}(s,a)-\\tau\\log\\xi^{(t)}(s,a)-\\left(Q_{\\tau}^{\\star}(s,a)-\\tau\\log\\pi_{\\tau}^{\\star}(a|s)\\right)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{\\le\\left\\|W T^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\tau\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\pi_{\\tau}^{\\star}(a|s)\\mathbf{1}_{N}\\big\\|_{2}}\\\\ &{\\le\\left\\|W T^{(t)}(s,a)-\\hat{Q}_{\\tau}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\left\\|\\hat{Q}_{\\tau}(s,a)\\mathbf{1}_{N}-Q_{\\tau}^{\\star}(s,a)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{\\qquad+\\tau\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf{1}_{N}\\big\\|_{2}+\\tau\\big\\|\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf{1}_{N}-\\log\\pi_{\\tau}^{\\star}(a|s)\\mathbf{1}_{N}\\big\\|_{2}}\\\\ &{=\\sigma\\big\\|T^{(t)}(s,a)-\\hat{Q}_{\\tau}^{(t)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}+\\sqrt{N}\\big\\|\\hat{Q}_{\\tau}^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\big\\|}\\\\ &{\\qquad+\\tau\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\tau}}^{(t)}(a|s)\\mathbf{1}_{N}\\big\\|_{2}+\\tau\\sqrt{N}\\left\\|\\log\\overline{{\\pi}}^{(t)}(a|s)-\\log\\pi_{\\tau}^{\\star}(a|s)\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Here, the first step results from the following relation established in [NNXS17]: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in S\\times A:\\quad V_{\\tau}^{\\star}(s)=-\\tau\\log\\pi_{\\tau}^{\\star}(a|s)+Q_{\\tau}^{\\star}(s,a)\\,,\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "which also leads to ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\left\\|\\log\\overline{{\\pi}}^{(t)}-\\log\\pi_{\\tau}^{\\star}\\right\\|_{\\infty}\\leq\\frac{2}{\\tau}\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\big\\|_{\\infty}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "by Lemma F.2. For the remaining terms in (176), we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\left|\\widehat{Q}_{\\tau}^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\right|\\leq\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}+\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\|_{\\infty},\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "and ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf{1}_{N}\\Big\\|_{2}=\\sqrt{\\displaystyle\\sum_{n=1}^{N}\\left(\\log\\xi_{n}^{(t)}(s,a)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\right)^{2}}}\\\\ {\\displaystyle\\leq\\sqrt{\\displaystyle\\sum_{n=1}^{N}2\\|\\log\\xi_{n}^{(t)}-\\log\\overline{{\\xi}}^{(t)}\\|_{\\infty}^{2}}}\\\\ {\\displaystyle}&{\\leq\\sqrt{\\displaystyle\\sum_{n=1}^{N}2\\|u^{(t)}\\|_{\\infty}^{2}}=\\sqrt{2N}\\|u^{(t)}\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the first inequality again results from Lemma F.2. Plugging (178), (179), (180) into (176) and using the definition of $\\bar{u}^{(t)},v^{(t)}$ ,we arrive at ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{v^{(t)}(s,a)\\leq\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}\\right)\\left\\|u^{(t)}\\right\\|_{\\infty}+\\displaystyle\\frac{1-\\alpha}{\\tau}\\|v^{(t)}\\|_{\\infty}+\\displaystyle\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}\\left(\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\|_{\\infty}+\\right.}\\\\ {\\left.\\qquad\\qquad+\\displaystyle\\frac{1-\\alpha}{\\tau}\\cdot2\\sqrt{N}\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Using previous display, we can write (174) as ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\big\\|{Q}_{\\tau}^{(t+1)}(s,a)-{Q}_{\\tau}^{(t)}(s,a)\\big\\|_{2}}\\\\ {\\displaystyle\\leq M\\sqrt{N}\\bigg\\{\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}\\right)\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{1-\\alpha}{\\tau}\\sigma\\big\\|v^{(t)}\\big\\|_{\\infty}}\\\\ {\\displaystyle\\qquad+\\,\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}\\left(M\\big\\|u^{(t)}\\big\\|_{\\infty}+\\big\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\big\\|_{\\infty}\\right)+\\frac{1-\\alpha}{\\tau}\\cdot2\\sqrt{N}\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\big\\|_{\\infty}\\bigg\\}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Combining (167) with the above expression (181), we get ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\lvert v^{(t+1)}\\right\\rvert\\big\\rvert_{\\infty}\\leq\\sigma\\left(1+\\frac{\\eta M\\sqrt{N}}{1-\\gamma}\\sigma\\right)\\left\\lvert\\left\\lvert v^{(t)}\\right\\rvert\\right\\rvert_{\\infty}+\\sigma M\\sqrt{N}\\Bigg\\{\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}+\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}M\\right)}\\\\ {\\displaystyle~~~~~~~~~~~~~~~~~~+\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\rVert_{\\infty}+\\frac{1-\\alpha}{\\tau}\\cdot2\\sqrt{N}\\lVert Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\rVert_{\\infty}\\Bigg\\}\\,.\\qquad(182)}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Step 5: bound $\\left\\lVert\\overline{{Q}}_{\\tau}^{(t+1)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}$ . For any state-action pair $(s,a)\\in S\\times A$ , we observe that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{\\bar{\\partial}}_{\\tau}^{\\star}(s,a)-\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)}\\\\ &{=r(s,a)+\\gamma\\underbrace{\\mathbb{E}}_{s^{\\prime}\\sim P(\\cdot|s,a)}\\left[V_{\\tau}^{\\star}(s^{\\prime})\\right]-\\left(r(s,a)+\\gamma\\underbrace{\\mathbb{E}}_{s^{\\prime}\\sim P(\\cdot|s,a)}\\left[V_{\\tau}^{\\pi^{(t+1)}}(s^{\\prime})\\right]\\right)}\\\\ &{=\\gamma\\underbrace{\\mathbb{E}}_{s^{\\prime}\\sim P(\\cdot|s,a)}\\left[\\tau\\log\\left(\\left\\|\\exp\\left(\\frac{Q_{\\tau}^{\\star}(s^{\\prime},\\cdot)}{\\tau}\\right)\\right\\|_{1}\\right)\\right]-\\gamma\\underbrace{\\mathbb{E}}_{a^{\\prime}\\sim\\mathsf{N}^{\\prime}(\\cdot|s,a),}\\quad\\left[\\overline{{Q}}_{\\tau}^{(t+1)}(s^{\\prime},a^{\\prime})-\\tau\\log\\overline{{\\pi}}^{(t+1)}(a^{\\prime}|s)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the first step invokes the definition of $Q_{\\tau}$ (cf. (6a)), and the second step is due to the following expression of $V_{\\tau}^{\\star}$ established in [NNXS17]: ", "page_idx": 39}, {"type": "equation", "text": "$$\nV_{\\tau}^{\\star}(s)=\\tau\\log\\left(\\left\\|\\exp\\left(\\frac{Q_{\\tau}^{\\star}(s,\\cdot)}{\\tau}\\right)\\right\\|_{1}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "To continue, note that by (162) and (41b) we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\log\\overline{{\\pi}}^{(t+1)}(a|s)=\\log\\overline{{\\xi}}^{(t+1)}(s,a)-\\log\\left(\\left\\Vert\\overline{{\\xi}}^{(t+1)}(s,\\cdot)\\right\\Vert_{1}\\right)}\\\\ {=\\alpha\\log\\overline{{\\xi}}^{(t)}(s,a)+(1-\\alpha)\\frac{\\widehat Q_{\\tau}^{(t)}(s,a)}{\\tau}-\\log\\left(\\left\\Vert\\overline{{\\xi}}^{(t+1)}(s,\\cdot)\\right\\Vert_{1}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Plugging (185) into (183) and (181) establishes the bounds on ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{\\tau}^{\\star}(s,a)-\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)=\\gamma\\underset{s^{\\prime}\\sim P(\\cdot\\vert s,a)}{\\mathbb{E}}\\left[\\tau\\log\\left(\\left\\Vert\\exp\\left(\\frac{Q_{\\tau}^{\\star}(s^{\\prime},\\cdot)}{\\tau}\\right)\\right\\Vert_{1}\\right)-\\tau\\log\\left(\\left\\Vert\\overline{{\\xi}}^{(t+1)}(s^{\\prime},\\cdot)\\right\\Vert_{1}\\right)\\right]}\\\\ {-\\gamma\\underset{a^{\\prime}\\sim\\pi^{(t+1)}(\\cdot\\vert s^{\\prime})}{\\mathbb{E}}\\left[\\overline{{Q}}_{\\tau}^{(t+1)}(s^{\\prime},a^{\\prime})-\\tau\\underbrace{\\left(\\alpha\\log\\overline{{\\xi}}^{(t)}(s^{\\prime},a^{\\prime})+(1-\\alpha)\\frac{\\widehat{Q}_{\\tau}^{(t)}}{\\tau}\\right.}_{=\\log\\overline{{\\xi}}^{(t+1)}(s^{\\prime},a^{\\prime})}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "for any $(s,a)\\in S\\times A$ . In view of property (164), the first term on the right-hand side of (186) can bebounded by ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\tau\\log\\left(\\left\\lVert\\exp\\left(\\frac{Q_{\\tau}^{\\star}(s^{\\prime},\\cdot)}{\\tau}\\right)\\right\\rVert_{1}\\right)-\\tau\\log\\left(\\left\\lVert\\overline{{\\xi}}^{(t+1)}(s^{\\prime},\\cdot)\\right\\rVert_{1}\\right)\\le\\left\\lVert Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right\\rVert_{\\infty}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Plugging the above expression into (186), we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{\\Gamma}\\leq Q_{\\tau}^{\\star}(s,a)\\!-\\!\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)\\leq\\gamma\\|Q_{\\tau}^{\\star}\\!-\\!\\tau\\log\\overline{{\\xi}}^{(t+1)}\\|_{\\infty}\\!-\\!\\gamma\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "which gives ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|Q_{\\tau}^{\\star}\\!-\\!\\overline{{Q}}_{\\tau}^{(t+1)}\\right|\\right|_{\\infty}\\leq\\gamma\\!\\left\\|Q_{\\tau}^{\\star}\\!-\\!\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right\\|_{\\infty}\\!+\\!\\gamma\\operatorname*{max}\\left\\{0,-\\underset{s,a}{\\operatorname*{min}}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)\\right\\}\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "$\\Omega_{3}^{(t+1)}$ $\\Omega_{2}^{(t+1)}$ ", "page_idx": 39}, {"type": "text", "text": "in (49), respectivly. Step 6: bound $-\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)$ . We need the following lemma which is adapted from Lemma 1 in $[\\mathrm{CCC}^{+}22\\mathrm{b}]$ ", "page_idx": 39}, {"type": "text", "text": "Lemma F.4 (Performance improvement of FedNPG with entropy regularization). Suppose $0<\\eta\\leq$ $(1-\\gamma)/\\tau$ .For any state-action pair $(s_{0},a_{0})\\in\\mathcal S\\times\\mathcal A,$ onehas ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{V}}_{\\tau}^{(t+1)}(s_{0})-\\overline{{V}}_{\\tau}^{(t)}(s_{0})\\geq\\displaystyle\\frac{1}{\\eta}\\sum_{s\\sim d_{\\tau}^{\\infty}(t^{\\mathbb{I}+1})}\\left[\\alpha\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t+1)}(\\cdot|s_{0})\\parallel\\overline{{\\pi}}^{(t)}(\\cdot|s_{0})\\right)+\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t)}(\\cdot|s_{0})\\right)\\right]\\overline{{\\pi}}^{(t+1)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad-\\displaystyle\\frac{2}{1-\\gamma}\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\|_{\\infty}\\,,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\displaystyle\\frac{2}{2\\tau}\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Using (189), we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\left(\\alpha\\log\\overline{{\\xi}}^{(t)}(s,a)+(1-\\alpha)\\frac{\\widehat{Q}_{\\tau}^{(t)}(s,a)}{\\tau}\\right)}\\\\ &{\\geq\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\left(\\alpha\\log\\overline{{\\xi}}^{(t)}(s,a)+(1-\\alpha)\\frac{\\widehat{Q}_{\\tau}^{(t)}(s,a)}{\\tau}\\right)-\\frac{2\\gamma}{1-\\gamma}\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\|_{\\infty}}\\\\ &{\\geq\\alpha\\left(\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t)}(s,a)\\right)-\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "which gives ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\underset{s,a}{\\operatorname*{min}}\\left(\\overline{Q}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{\\xi}^{(t+1)}(s,a)\\right)}\\\\ &{\\leq-\\alpha\\underset{s,a}{\\operatorname*{min}}\\left(\\overline{Q}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{\\xi}^{(t)}(s,a)\\right)+\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}M\\|u^{(t)}\\|_{\\infty}}\\\\ &{\\leq\\alpha\\operatorname*{max}\\left\\{0,\\underset{s,a}{\\operatorname*{min}}\\left(\\overline{Q}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{\\xi}^{(t)}(s,a)\\right)\\right\\}+\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}M\\|u^{(t)}\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "This establishes the bounds on $\\Omega_{4}^{(t+1)}$ in(49). ", "page_idx": 40}, {"type": "text", "text": "F.2Proof of Lemma D.3 ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Let $f(\\lambda)$ denote the characteristic function. In view of some direct calculations, we obtain ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\lambda)=(\\lambda-\\alpha)\\bigg\\{\\underbrace{(\\lambda-\\sigma\\alpha)(\\lambda-\\sigma(1+\\sigma b\\eta))(\\lambda-(1-\\alpha)\\gamma-\\alpha)}_{=:f_{0}(\\lambda)}}\\\\ &{\\qquad\\quad-\\,\\displaystyle\\frac{\\eta\\sigma^{2}}{1-\\gamma}\\,\\Big[\\underline{{S(\\lambda-(1-\\alpha)\\gamma-\\alpha)+\\gamma c d M\\eta+(1-\\alpha)(2+\\gamma)M c\\eta}}\\Big]\\bigg\\}}\\\\ &{\\qquad\\quad-\\,\\displaystyle\\frac{\\tau\\eta^{3}\\gamma}{(1-\\gamma)^{2}}\\cdot2c d M\\sigma^{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where, for the notation simplicity, we let ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{l}{b:=\\displaystyle\\frac{M\\sqrt{N}}{1-\\gamma}\\,,}\\\\ {c:=\\displaystyle\\frac{M N}{1-\\gamma}=\\sqrt{N}b\\,,}\\\\ {d:=\\displaystyle\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Note that among all these new notation we introduce, $S,\\,d$ are dependent of $\\eta$ . To decouple the dependence, we give their upper bounds as follows ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle{d_{0}:=\\frac{1+\\gamma}{1-\\gamma}\\geq d\\,,}}\\\\ {\\displaystyle{S_{0}:=M\\sqrt{N}\\left(2+\\sqrt{2N}+\\frac{M\\sqrt{N}}{\\tau}\\right)\\geq S\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where (194) follows from $\\eta\\le(1-\\gamma)/\\tau$ , and (195) uses the fact that $\\alpha\\leq1$ and $1-\\alpha\\leq1$ ", "page_idx": 40}, {"type": "text", "text": "Let ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\lambda^{\\star}:=\\operatorname*{max}\\left\\{\\frac{3+\\sigma}{4},\\frac{1+(1-\\alpha)\\gamma+\\alpha}{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Since $A(\\rho)$ is a nonnegative matrix, by Perron-Frobenius Theorem (see [HJ12], Theorem 8.3.1), $\\rho(\\eta)$ is an eigenvalue of $A(\\rho)$ . So to verify (55), it suffices to show that $f(\\lambda)>0$ for any $\\lambda\\in[\\lambda^{\\star},\\infty)$ To do so, in the following we first show that $f(\\lambda^{\\star})>0$ , and then we prove that $f$ is non-decreasing on $\\left[\\lambda^{\\star},\\infty\\right)$ ", "page_idx": 40}, {"type": "text", "text": "\u00b7 Showing $f(\\lambda^{\\star})>0$ We fist lower bound $f_{0}(\\lambda^{\\star})$ . Since $\\lambda^{\\star}\\geq\\frac{3\\!+\\!\\sigma}{4}$ , we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\lambda^{\\star}-\\sigma(1+\\sigma b\\eta)\\geq\\frac{1-\\sigma}{4}\\,,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "and from 1+(1-a)+\u03b1 we deduce ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\lambda^{\\star}-(1-\\alpha)\\gamma-\\alpha\\geq\\frac{(1-\\gamma)(1-\\alpha)}{2}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "and ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\lambda^{\\star}>\\frac{1+\\alpha}{2}\\,,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "which gives ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\lambda^{\\star}-\\sigma\\alpha\\geq\\frac{1+\\alpha}{2}-\\sigma\\alpha\\,.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Combining (200), (197), (198), we have that ", "page_idx": 41}, {"type": "equation", "text": "$$\nf_{0}(\\lambda^{\\star})\\geq\\frac{1-\\sigma}{8}\\left(\\frac{1+\\alpha}{2}-\\sigma\\alpha\\right)\\eta\\tau\\,.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "To continue, we upper bound $f_{1}(\\lambda^{\\star})$ as follows. ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{1}(\\lambda^{\\star})\\leq S\\tau\\eta+\\gamma c d M\\eta+\\displaystyle\\frac{2+\\gamma}{1-\\gamma}c M\\tau\\eta^{2}}\\\\ &{\\qquad\\quad=\\eta\\left(\\tau\\left(S+\\displaystyle\\frac{2+\\gamma}{1-\\gamma}M c\\eta\\right)+\\gamma c d M\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Plugging (201),(202) into (192) and using (199), we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\lambda^{\\star}\\rangle>\\frac{1-\\alpha}{2}\\left(f_{0}(\\lambda^{\\star})-\\frac{\\eta\\sigma^{2}}{1-\\gamma}f_{1}(\\lambda^{\\star})\\right)-\\frac{\\tau\\eta^{3}\\gamma}{(1-\\gamma)^{2}}\\cdot2c d M\\sigma^{2}}\\\\ &{\\qquad\\ge\\frac{\\tau\\eta^{2}}{2(1-\\gamma)}\\left[\\frac{1-\\sigma}{8}\\tau\\left(1-\\sigma+(1-\\alpha)(\\sigma-\\frac12)\\right)-\\frac{\\eta\\sigma^{2}}{1-\\gamma}\\left(\\tau\\left(S+\\frac{2+\\gamma}{1-\\gamma}M c\\eta\\right)+5\\gamma c d M\\right)\\right.}\\\\ &{\\qquad=\\left.\\frac{\\tau\\eta^{2}}{2(1-\\gamma)}\\left[\\frac{(1-\\sigma)^{2}}{8}\\tau-\\frac{\\eta}{1-\\gamma}\\left(S\\tau\\sigma^{2}+\\frac{2+\\gamma}{1-\\gamma}M c\\sigma^{2}\\tau\\eta+\\tau^{2}\\left(\\frac12-\\sigma^{2}\\right)\\cdot\\frac{1-\\sigma}{8}+5\\gamma c d M\\right.\\right.}\\\\ &{\\qquad\\ge\\left.\\frac{\\tau\\eta^{2}}{2(1-\\gamma)}\\left[\\frac{(1-\\sigma)^{2}}{8}\\tau-\\frac{\\eta}{1-\\gamma}\\left(S_{0}\\tau\\sigma^{2}+\\frac{(1-\\sigma)^{2}}{16}\\tau^{2}+(2+\\gamma+5\\gamma d_{0})\\,c M\\sigma^{2}\\right)\\right]\\ge0\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where the penultimate inequality uses $\\textstyle{\\frac{1}{2}}-\\sigma\\leq{\\frac{1-\\sigma}{2}}$ , and the last inequality follows from the definition of $\\zeta$ (cf. (53). ", "page_idx": 41}, {"type": "text", "text": "\u00b7 Proving $f$ is non-decreasing on $\\left[\\lambda^{\\star},\\infty\\right)$ . Note that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\eta\\leq\\zeta\\leq\\frac{(1-\\gamma)(1-\\sigma)^{2}}{8S_{0}\\sigma^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "thus we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\forall\\lambda\\geq\\lambda^{\\star}:\\quad f_{0}^{\\prime}(\\lambda)-\\frac{\\eta\\sigma^{2}}{1-\\gamma}f_{1}^{\\prime}(\\lambda)\\geq(\\lambda-\\sigma\\alpha)(\\lambda-\\sigma(1+\\sigma b\\eta))-\\frac{\\eta}{1-\\gamma}S\\sigma^{2}\\geq0\\,,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "which indicates that $f_{0}-f_{1}$ is non-decreasing on $\\left[\\lambda^{\\star},\\infty\\right)$ . Therefore, $f$ is non-decreasing on $\\left[\\lambda^{\\star},\\infty\\right)$ ", "page_idx": 41}, {"type": "text", "text": "F.3Proof of Lemma D.6 ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Note that bounding $u^{(t+1)}(s,a)$ is identical to the proof in Appendix F. 1 and shall be omitted. The rest of the proof also follows closely that of Lemma D.2, and we only highlight the differences due to approximation error for simplicity. ", "page_idx": 41}, {"type": "text", "text": "Step 2: bound $v^{(t+1)}(s,a)=\\left\\|\\pmb{T}^{(t+1)}(s,a)-\\widehat{q}_{\\tau}^{(t+1)}(s,a)\\pmb{1}_{N}\\right\\|_{2}$ . Let $\\pmb q_{\\tau}^{(t)}:=\\left(q_{\\tau,1}^{\\pi_{1}^{(t)}},\\cdot\\cdot\\cdot\\,,q_{\\tau,N}^{\\pi_{N}^{(t)}}\\right)^{\\top}$ Similar to (167) we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|{\\cal T}^{(t+1)}(s,a)-\\widehat{q}_{\\tau}^{(t+1)}(s,a){\\bf1}_{N}\\right\\|_{2}}\\\\ &{\\leq\\sigma\\big\\|{\\cal T}^{(t)}(s,a)-\\widehat{q}_{\\tau}^{(t)}(s,a){\\bf1}_{N}\\big\\|_{2}+\\sigma\\big\\|{q}_{\\tau}^{(t+1)}(s,a)-{q}_{\\tau}^{(t)}(s,a)\\big\\|_{2}}\\\\ &{\\leq\\sigma\\big\\|{\\cal T}^{(t)}(s,a)-\\widehat{q}_{\\tau}^{(t)}(s,a){\\bf1}_{N}\\big\\|_{2}+\\sigma\\big\\|{Q}_{\\tau}^{(t+1)}(s,a)-{Q}_{\\tau}^{(t)}(s,a)\\big\\|_{2}+2\\sigma\\left\\|{e}\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Step 3: bound $\\left\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right\\|_{\\infty}\\!.$ In the context of inexact udates,(168)writes ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right|\\right|_{\\infty}\\leq\\alpha\\big\\|Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)\\big\\|Q_{\\tau}^{\\star}-\\overline{{Q}}_{\\tau}^{(t)}\\big\\|_{\\infty}+(1-\\alpha)\\big\\|\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{q}_{\\tau}^{(t)}\\big\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "For the last term, following a similar argument in (169) leads to ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-\\widehat{q}_{\\tau}^{(t)}\\right\\|_{\\infty}=\\left\\|\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\pi_{n}^{(t)}}-\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{\\tau,n}^{\\overline{{\\tau}}^{(t)}}\\right\\|_{\\infty}+\\left\\|\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\left(Q_{\\tau,n}^{\\pi_{n}^{(t)}}-q_{\\tau,n}^{\\pi_{n}^{(t)}}\\right)\\right\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\leq M\\cdot\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\left\\|\\log\\xi_{n}^{(t)}-\\log\\overline{{\\xi}}^{(t)}\\right\\|_{\\infty}+\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}e_{n}}\\\\ &{\\qquad\\qquad\\qquad\\leq M\\|u^{(t)}\\|_{\\infty}+\\|e\\|_{\\infty}~.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Combining the above two inequalities, we obtain ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|Q_{\\tau}^{\\star}\\!-\\!\\tau\\log\\overline{\\xi}^{(t+1)}\\right|\\!\\right|_{\\infty}\\leq\\alpha\\big\\|Q_{\\tau}^{\\star}\\!-\\!\\tau\\log\\overline{\\xi}^{(t)}\\big\\|_{\\infty}\\!+\\!(1\\!-\\!\\alpha)\\big\\|Q_{\\tau}^{\\star}\\!-\\!\\overline{Q}_{\\tau}^{(t)}\\big\\|_{\\infty}\\!+\\!(1\\!-\\!\\alpha)\\left(M\\big\\|u^{(t)}\\big\\|_{\\infty}+\\big\\|e\\big\\|_{\\infty}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Step 4: bound $\\left|\\left|\\boldsymbol{Q}_{\\tau}^{(t+1)}(s,a)-\\boldsymbol{Q}_{\\tau}^{(t)}(s,a)\\right|\\right|_{2}$ . We remark that the bound established in (174) still holds in the inexact setting, with the same definition for $w^{(t)}$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\left\\|\\pmb{Q}_{\\tau}^{(t+1)}(s,a)-\\pmb{Q}_{\\tau}^{(t)}(s,a)\\right\\|_{2}\\leq M\\sqrt{N}\\left\\|\\pmb{w}^{(t)}\\right\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "To deal with the approximation error, we rewrite (176) as ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|W T^{(t)}(s,a)-\\tau\\log\\xi^{(t)}(s,a)-V_{\\tau}^{\\star}(s)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{=\\left\\|W T^{(t)}(s,a)-\\tau\\log\\xi^{(t)}(s,a)-\\left(Q_{\\tau}^{\\star}(s,a)-\\tau\\log\\pi_{\\tau}^{\\star}(a|s)\\right)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{\\le\\left\\|W T^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\mathbf1_{N}\\right\\|_{2}+\\tau\\left\\|\\log\\xi^{(t)}(s,a)-\\log\\pi_{\\tau}^{\\star}(a|s)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{\\le\\left\\|W T^{(t)}(s,a)-\\widehat{q}_{\\tau}(s,a)\\mathbf1_{N}\\right\\|_{2}+\\left\\|\\widehat{q}_{\\tau}(s,a)\\mathbf1_{N}-Q_{\\tau}^{\\star}(s,a)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{\\qquad+\\tau\\left\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf1_{N}\\right\\|_{2}+\\tau\\left\\|\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf1_{N}-\\log\\pi_{\\tau}^{\\star}(a|s)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{\\le\\sigma\\left\\|T^{(t)}(s,a)-\\widehat{q}_{\\tau}^{(t)}(s,a)\\mathbf1_{N}\\right\\|_{2}+\\sqrt{N}\\left|\\widehat{q}_{\\tau}^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\right|}\\\\ &{\\qquad+\\tau\\left\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\mathbf1\\right\\|_{2}+\\tau\\sqrt{N}\\left|\\log\\overline{{\\pi}}^{(t)}(a|s)-\\log\\pi_{\\tau}^{\\star}(a|s)\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where the second term can be upper-bounded by ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\widehat{q}_{\\tau}^{(t)}(s,a)-Q_{\\tau}^{\\star}(s,a)\\right|\\leq\\left\\lVert\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\rVert_{\\infty}+\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}+\\left\\lVert\\widehat{q}_{\\tau}^{(t)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\right\\rVert_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\left\\lVert\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\rVert_{\\infty}+\\left\\lVert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}+\\left\\lVert e\\right\\rVert_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Combining (207), (206) and the established bounds in (175), (178), (180) leads to ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{l}{v^{(t)}(s,a)\\leq\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}\\right)\\left\\|u^{(t)}\\right\\|_{\\infty}+\\displaystyle\\frac{1-\\alpha}{\\tau}\\left\\|v^{(t)}\\right\\|_{\\infty}}\\\\ {\\qquad\\qquad+\\displaystyle\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}\\left(\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}+\\left\\|\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{*}\\right\\|_{\\infty}+\\left\\|e\\right\\|_{\\infty}\\right)+\\displaystyle\\frac{1-\\alpha}{\\tau}\\cdot2\\sqrt{N}\\left\\|Q_{\\tau}^{*}-\\tau\\right\\|_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Combining the above inequality with (205) and (203) gives ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{+1)\\Big\\Vert_{\\infty}\\leq\\sigma\\left(1+\\frac{\\eta M\\sqrt{N}}{1-\\gamma}\\sigma\\right)\\left\\Vert v^{(t)}\\right\\Vert_{\\infty}+\\sigma M\\sqrt{N}\\Bigg\\{\\left(2\\alpha+(1-\\alpha)\\cdot\\sqrt{2N}+\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}M\\right)\\left\\Vert u^{\\prime}\\right\\}}\\\\ {+\\left.\\frac{1-\\alpha}{\\tau}\\cdot\\sqrt{N}\\left(\\left\\Vert\\overline{{Q}}_{\\tau}^{(t)}-Q_{\\tau}^{\\star}\\right\\Vert_{\\infty}+\\left\\Vert e\\right\\Vert_{\\infty}\\right)+\\frac{1-\\alpha}{\\tau}\\cdot2\\sqrt{N}\\left\\Vert Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t)}\\right\\Vert_{\\infty}\\Bigg\\}+2\\sigma\\sqrt{N}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Step 5: bound $\\left\\lVert\\overline{{Q}}_{\\tau}^{(t+1)}-Q_{\\tau}^{\\star}\\right\\rVert_{\\infty}$ . It is straightforward to verify that (187) applies to the inexact updates as well: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|Q_{\\tau}^{\\star}-\\overline{{Q}}_{\\tau}^{(t+1)}\\right|\\right|_{\\infty}\\leq\\gamma\\left\\lVert Q_{\\tau}^{\\star}-\\tau\\log\\overline{{\\xi}}^{(t+1)}\\right\\rVert_{\\infty}+\\gamma\\left(-\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Plugging the above inequality into (204) and (208) establishes the bounds on $\\Omega_{3}^{(t+1)}$ and $\\Omega_{2}^{(t+1)}$ in (68), respectively. Step 6: bound - $\\cdot\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)\\!-\\!\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)$ . We obtain the following lemma by interpreting the approximation error $^e$ as part of the consensus error $\\left\\lVert\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\rVert_{\\circ}$ in Lemma F.4. ", "page_idx": 43}, {"type": "text", "text": "Lemma F.5 (inexact version of Lemma F.4). Suppose $0<\\eta\\leq(1-\\gamma)/\\tau$ .For any state-action pair $\\left(s_{0},a_{0}\\right)\\in\\mathcal S\\times\\mathcal A$ onehas ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\overline{{V}}_{\\tau}^{(t+1)}(s_{0})-\\overline{{V}}_{\\tau}^{(t)}(s_{0})\\geq\\displaystyle\\frac{1}{\\eta_{s\\times d_{0}^{\\tau}}(t+1)}\\left[\\alpha\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t+1)}(\\cdot|s_{0})\\right\\|\\,\\overline{{\\pi}}^{(t)}(\\cdot|s_{0})\\right)+\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t)}(\\cdot|s_{0})\\right)\\right.\\left.\\left.\\right.}\\\\ &{}&{\\qquad\\displaystyle\\qquad\\qquad\\qquad\\qquad\\left.-\\\\left.\\frac{2}{1-\\gamma}\\left(\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}+\\|e\\|_{\\infty}\\right)\\right.,}\\\\ &{}&{\\left.\\left.\\overline{{\\jmath}}^{(t+1)}(s_{0},a_{0})-\\overline{{Q}}_{\\tau}^{(t)}(s_{0},a_{0})\\geq-\\displaystyle\\frac{2\\gamma}{1-\\gamma}\\left(\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}+\\|e\\|_{\\infty}\\right)\\right.\\left.\\left.\\qquad\\qquad\\qquad\\quad\\left.(210)\\right.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Using (210), we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\left(\\alpha\\log\\overline{{\\xi}}^{(t)}(s,a)+(1-\\alpha)\\frac{\\widehat{Q}_{\\tau}^{(t)}(s,a)}{\\tau}\\right)}\\\\ &{\\geq\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\left(\\alpha\\log\\overline{{\\xi}}^{(t)}(s,a)+(1-\\alpha)\\frac{\\widehat{Q}_{\\tau}^{(t)}(s,a)}{\\tau}\\right)-\\frac{2\\gamma}{1-\\gamma}\\left(\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}+\\left\\|e\\right\\|_{\\infty}\\right)}\\\\ &{\\geq\\alpha\\left(\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t)}(s,a)\\right)-\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}\\left\\|\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\right\\|_{\\infty}-\\frac{2\\gamma}{1-\\gamma}\\left\\|e\\right\\|_{\\infty},\\qquad\\qquad(21\\eta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "which gives ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{l}{-\\displaystyle\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t+1)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\right)}\\\\ {\\displaystyle\\leq-\\alpha\\operatorname*{min}_{s,a}\\left(\\overline{{Q}}_{\\tau}^{(t)}(s,a)-\\tau\\log\\overline{{\\xi}}^{(t)}(s,a)\\right)+\\frac{2\\gamma+\\eta\\tau}{1-\\gamma}M\\left\\|u^{(t)}\\right\\|_{\\infty}+\\frac{2\\gamma}{1-\\gamma}\\left\\|e\\right\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "F.4Proof of Lemma D.8 ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Step 1: bound $u^{(t+1)}(s,a)=\\left\\|\\log\\xi^{(t+1)}(s,a)-\\log\\overline{{\\xi}}^{(t+1)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}$ . Fllowing the same strategy in establishing (166), we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\log\\xi^{(t+1)}(s,a)-\\log\\overline{\\xi}^{(t+1)}(s,a)\\mathbf1_{N}\\right\\|_{2}}\\\\ &{=\\left\\|\\left(W\\log\\xi^{(t)}(s,a)-\\log\\overline{\\xi}^{(t)}(s,a)\\mathbf1_{N}\\right)+\\frac{\\eta}{1-\\gamma}\\left(W T^{(t)}(s,a)-\\widehat Q^{(t)}(s,a)\\mathbf1_{N}\\right)\\right\\|_{2}}\\\\ &{\\leq\\sigma\\left\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{\\xi}^{(t)}(s,a)\\mathbf1_{N}\\right\\|_{2}+\\frac{\\eta}{1-\\gamma}\\sigma\\left\\|T^{(t)}(s,a)-\\widehat Q^{(t)}(s,a)\\mathbf1_{N}\\right\\|_{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "or equivalently ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\left\\|u^{(t+1)}\\right\\|_{\\infty}\\leq\\sigma\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{\\eta}{1-\\gamma}\\sigma\\big\\|v^{(t)}\\big\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Step 2: bound $v^{(t+1)}(s,a)=\\bigl\\|\\pmb{T}^{(t+1)}(s,a)-\\widehat{\\pmb{Q}}^{(t+1)}(s,a)\\pmb{1}_{N}\\bigr\\|_{2}.$ In the same vein of establishing (167), we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|{\\pmb{T}}^{(t+1)}(s,a)-\\widehat{Q}^{(t+1)}(s,a){\\mathbf{1}}_{N}\\right\\|_{2}}\\\\ &{\\leq\\sigma\\|{\\pmb{T}}^{(t)}(s,a)-\\widehat{Q}^{(t)}(s,a){\\mathbf{1}}_{N}\\|_{2}+\\sigma\\|{\\pmb{Q}}^{(t+1)}(s,a)-{\\pmb{Q}}^{(t)}(s,a)\\|_{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "The term $\\left|\\left|Q^{(t+1)}(s,a)-Q^{(t)}(s,a)\\right|\\right|_{2}$ can be bounded in a similar way in (174): ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\big\\|\\pmb{Q}^{(t+1)}(s,a)-\\pmb{Q}^{(t)}(s,a)\\big\\|_{2}\\leq\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N}\\big\\|w_{0}^{(t)}\\big\\|_{\\infty}\\,,\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where the coefficient $\\textstyle{\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}}$ comes from $M$ in Lemma F.3 when $\\tau=0$ and $w_{0}^{(t)}\\in\\mathbb{R}^{|S||A|}$ is defined as ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}:\\quad w_{0}^{(t)}(s,a):=\\left\\|\\log\\xi^{(t+1)}(s,a)-\\log\\xi^{(t)}(s,a)-\\frac{\\eta}{1-\\gamma}V^{\\star}(s)\\mathbf{1}_{N}\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "It remains to bound $\\left\\|w_{0}^{(t)}\\right\\|_{\\infty}$ . Towards this end, we rewrite (175) as ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w_{0}^{(t)}(s,a)}\\\\ &{\\!=\\!\\left\\|{W\\left(\\log\\xi^{(t)}(s,a)+\\frac{\\eta}{1-\\gamma}T^{(t)}(s,a)\\right)-\\log\\xi^{(t)}(s,a)-\\frac{\\eta}{1-\\gamma}V^{\\star}(s)\\mathbf1_{N}}\\right\\|_{2}}\\\\ &{\\!=\\!\\left\\|{(W-I)\\left(\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf1_{N}\\right)+\\frac{\\eta}{1-\\gamma}\\left(W T^{(t)}(s,a)-V^{\\star}(s)\\mathbf1_{N}\\right)}\\right\\|_{2}}\\\\ &{\\leq\\!2\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf1_{N}\\big\\|_{2}+\\frac{\\eta}{1-\\gamma}\\big\\|{W T^{(t)}(s,a)-V^{\\star}(s)\\mathbf1_{N}}\\big\\|_{2}}\\\\ &{\\leq\\!2\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf1_{N}\\big\\|_{2}+\\frac{\\eta}{1-\\gamma}\\big\\|{W T^{(t)}(s,a)-\\widehat{Q}^{(t)}(s,a)\\mathbf1_{N}}\\big\\|_{2}}\\\\ &{\\quad+\\frac{\\eta}{1-\\gamma}\\cdot\\sqrt{N}\\big|\\widehat{Q}^{(t)}(s,a)-V^{\\star}(s)\\big|\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Note that it holds for all $(s,a)\\in S\\times A$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\left|\\widehat{Q}^{(t)}(s,a)-V^{\\star}(s)\\right|\\leq\\frac{1}{1-\\gamma}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "since $\\widehat{Q}^{(t)}(s,a)$ and $V^{\\star}(s)$ are both in $\\left[0,1/(1-\\gamma)\\right]$ . This along with (218) gives ", "page_idx": 44}, {"type": "equation", "text": "$$\nw_{0}^{(t)}(s,a)\\leq2\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{\\eta}{1-\\gamma}\\big\\|v^{(t)}\\big\\|_{\\infty}+\\frac{\\eta\\sqrt{N}}{(1-\\gamma)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Combining the above inequality with (216) and (215), we arrive at ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\left|v^{(t+1)}\\right|\\right|_{\\infty}\\leq\\sigma\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)\\left\\|v^{(t)}\\right\\|_{\\infty}+\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N}\\sigma\\Bigg\\{2\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{\\eta}{(1-\\gamma)^{2}}\\cdot\\sqrt{N}\\Bigg\\}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Step 3: establish the descent equation. The following lemma characterizes the improvement in $\\bar{\\phi^{(t)}(\\eta)}$ for every iteration of Algorithm 1, with the proof postponed to Appendix G.4. ", "page_idx": 44}, {"type": "text", "text": "Lemma F.6 (Performance improvement of exact FedNPG). For all starting state distribution $\\rho\\in$ $\\Delta(S)$ we have the iterates of FedNPG satisfy ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}(\\eta)\\le\\phi^{(t)}(\\eta)+\\frac{2\\eta}{(1-\\gamma)^{2}}\\|\\widehat{Q}^{(t)}-\\overline{{Q}}^{(t)}\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\,,\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\phi^{(t)}(\\eta):=\\mathbb{E}_{s\\sim d_{\\rho}^{\\pi^{\\star}}}\\left[\\mathsf{K L}\\big(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\overline{{\\pi}}^{(t)}(\\cdot|s)\\big)\\right]-\\frac{\\eta}{1-\\gamma}\\overline{{V}}^{(t)}(d_{\\rho}^{\\pi^{\\star}})\\,,\\quad\\forall t\\ge0\\,.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "It remains to control the term $\\big|\\big|\\overline{{Q}}^{(t)}-\\widehat{Q}^{(t)}\\big|\\big|_{\\infty}$ . Similar to(169), for all $t\\geq0$ , we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\overline{{Q}}^{(t)}-\\widehat{Q}^{(t)}\\|_{\\infty}=\\left\\|\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{n}^{\\pi_{n}^{(t)}}-\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}Q_{n}^{\\pi^{(t)}}\\right\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\overset{(a)}{\\leq}\\displaystyle\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\cdot\\frac{1}{N}\\sum_{n=1}^{N}\\left\\|\\log\\xi_{n}^{(t)}-\\log\\overline{{\\xi}}^{(t)}\\right\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\overset{(b)}{\\leq}\\displaystyle\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\|u^{(t)}\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where (a) invokes Lemma F.3 with $\\tau=0$ and (b) stems from the definition of $\\boldsymbol{u}^{(t)}$ . This along with (220) gives ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}(\\eta)\\leq\\phi^{(t)}(\\eta)+\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{4}}\\eta\\|u^{(t)}\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\,.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Step 4: bound the consensus error. To bound the consensus error $\\left\\|\\log\\pi_{n}^{(t)}-\\log\\bar{\\pi}^{(t)}\\right\\|_{\\infty}$ for all $n\\in[N]$ , we first upper bound the spectral norm of $B(\\eta)$ which we denote as $\\rho(B(\\eta))$ .Since $B(\\eta)$ is a nonnegative matrix, by Perron-Frobenius Theorem, $\\rho(B(\\eta))$ is an eigenvalue of $B(\\eta)$ . So we only need to upper bound the eigenvalue of $\\rho(B(\\eta))$ ", "page_idx": 45}, {"type": "text", "text": "The characteristic polynomial of $B(\\eta)$ is ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{f(\\lambda)=\\left(\\lambda-\\sigma\\right)\\left(\\lambda-\\sigma\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)\\right)-\\frac{\\eta J}{1-\\gamma}\\sigma^{2}}}\\\\ {\\displaystyle{=\\lambda^{2}-\\left(2+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)\\sigma\\lambda+\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma-\\frac{\\eta J}{1-\\gamma}\\right)\\sigma^{2}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "which gives ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\iota(B(\\eta))\\le\\frac{\\sigma}{2}\\left[\\left(2+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)+\\sqrt{\\left(2+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)^{2}-4\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)^{2}}\\right.}}\\\\ &{}&{\\left.\\le\\frac{\\sigma}{2}\\left[\\left(2+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)+\\sqrt{\\left(\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)^{2}+4\\frac{\\eta J}{1-\\gamma}}\\right]\\right.}\\\\ &{}&{\\left.\\le\\sigma\\left[1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma+\\sqrt{\\frac{\\eta J}{1-\\gamma}}\\right]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Note that when $\\eta\\leq\\eta_{1}$ , we have (recall that $\\begin{array}{r}{J=\\frac{2(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N})}\\end{array}$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\leq\\frac{(1-\\sigma)^{2}}{8}\\,,\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "and ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\frac{\\eta J}{1-\\gamma}\\leq\\frac{(1-\\sigma)^{2}}{4\\sigma}\\,.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Plugging the above two expressions into (223) yields ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\rho(B(\\eta))\\leq\\sigma\\left(1+(1-\\sigma)^{2}/8+(1-\\sigma)/(2\\sqrt{\\sigma})\\right)}\\\\ &{\\qquad\\qquad\\leq\\sigma\\left(1+(1-\\sigma)/(8\\sigma)+(1-\\sigma)/(2\\sigma)\\right)=\\frac{3}{8}\\sigma+\\frac{5}{8}<1\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Therefore, when $\\eta\\leq\\eta_{1}$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\Omega^{(t)}\\right\\|_{2}\\leq\\rho(B(\\eta))\\left\\|\\Omega^{(t-1)}\\right\\|_{2}+d_{2}(\\eta)}\\\\ &{\\qquad\\qquad\\leq\\cdots\\leq\\rho^{t}(B(\\eta))\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\displaystyle\\sum_{i=0}^{t-1}\\rho^{i}(B(\\eta))\\displaystyle\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}\\eta}\\\\ &{\\qquad\\qquad\\leq\\rho^{t}(B(\\eta))\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\displaystyle\\frac{2N\\sigma}{(1-\\gamma)^{4}(1-\\rho(B(\\eta)))}\\eta}\\\\ &{\\qquad\\qquad\\leq\\left(\\frac{3}{8}\\sigma+\\frac{5}{8}\\right)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\displaystyle\\frac{16N\\sigma}{3(1-\\gamma)^{4}(1-\\sigma)}\\eta\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Combining the above inequality with the following fact: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\forall n\\in[N]:\\quad\\left\\lVert\\log\\pi_{n}^{(t)}-\\log\\bar{\\pi}^{(t)}\\right\\rVert_{\\infty}\\leq2\\left\\lVert\\log\\xi_{n}^{(t)}-\\log\\bar{\\xi}^{(t)}\\right\\rVert_{\\infty}\\leq\\Omega_{1}^{(t)}\\leq\\left\\lVert\\Omega^{(t)}\\right\\rVert_{2}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where the first inequality uses (165), we obtain (84). ", "page_idx": 46}, {"type": "text", "text": "F.5Proof of Lemma D.10 ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "The bound on $\\boldsymbol{u}^{(t+1)}(s,a)$ is already established in Step 1 in Appendix E 1 and shall be omitted. As usual we only highlight the key differences with the proof of Lemma D.8 due to approximation error. ", "page_idx": 46}, {"type": "text", "text": "Step 1: bound $\\begin{array}{r}{\\boldsymbol{v}^{(t+1)}(s,a)=\\big\\|\\boldsymbol{T}^{(t+1)}(s,a)-\\widehat{\\boldsymbol{q}}^{(t+1)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}\\cdot\\mathrm{Let}\\,\\boldsymbol{q}^{(t)}:=\\Big(q_{1}^{\\pi_{1}^{(t)}},\\cdots,q_{N}^{\\pi_{N}^{(t)}}\\Big)^{\\top}.}\\end{array}$ From (96), we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|T^{(t+1)}(s,a)-\\widehat{q}^{(t+1)}(s,a)\\mathbf{1}_{N}\\right|_{2}}\\\\ &{=\\left\\|W\\left(\\pmb{T}^{(t)}(s,a)+q^{(t+1)}(s,a)-q^{(t)}(s,a)\\right)-\\widehat{q}^{(t+1)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{=\\left\\|\\left(\\pmb{W}\\pmb{T}^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\right)+\\pmb{W}\\left(q^{(t+1)}(s,a)-q^{(t)}(s,a)\\right)+\\left(\\widehat{q}^{(t)}(s,a)-\\widehat{q}^{(t+1)}(s,a)\\right)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{\\leq\\sigma\\left\\|\\pmb{T}^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\sigma\\left\\|\\left(q^{(t+1)}(s,a)-q^{(t)}(s,a)\\right)+\\left(\\widehat{q}^{(t)}(s,a)-\\widehat{q}^{(t+1)}(s,a)\\right)\\mathbf{1}_{N}\\right\\|_{2}}\\\\ &{\\leq\\sigma\\left\\|\\pmb{T}^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\sigma\\left\\|q^{(t+1)}(s,a)-q^{(t)}(s,a)\\right\\|_{2}}\\\\ &{\\leq\\sigma\\left\\|\\pmb{T}^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\right\\|_{2}+\\sigma\\left\\|Q^{(t+1)}(s,a)-Q^{(t)}(s,a)\\right\\|_{2}+2\\sigma\\sqrt{N}\\left\\|e\\right\\|_{\\infty}.\\qquad\\qquad(225)}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "equation", "text": "$$\n\\left\\|\\pmb{Q}^{(t+1)}(s,a)-\\pmb{Q}^{(t)}(s,a)\\right\\|_{2}\\leq\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N}\\left\\|w_{0}^{(t)}\\right\\|_{\\infty},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $w_{0}^{(t)}$ isdefnedin 7)write 2,b $w_{0}^{(t)}(s,a)$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{l}{w_{0}^{(t)}(s,a)\\leq2\\big\\|\\log\\xi^{(t)}(s,a)-\\log\\overline{{\\xi}}^{(t)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}}\\\\ {\\quad\\qquad\\qquad+\\displaystyle\\frac{\\eta}{1-\\gamma}\\big\\|T^{(t)}(s,a)-\\widehat{q}^{(t)}(s,a)\\mathbf{1}_{N}\\big\\|_{2}+\\displaystyle\\frac{\\eta\\sigma}{1-\\gamma}\\cdot\\sqrt{N}\\big|\\widehat{q}^{(t)}(s,a)-V^{\\star}(s)\\big|\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "With the following bound ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}:\\quad\\left|\\widehat{q}^{(t)}(s,a)-V^{\\star}(s)\\right|\\leq\\left\\|\\widehat{q}^{(t)}-\\overline{{Q}}^{(t)}\\right\\|_{\\infty}+\\frac{1}{1-\\gamma}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "in mind, we write (218) as ", "page_idx": 46}, {"type": "equation", "text": "$$\nw_{0}^{(t)}(s,a)\\leq2\\|u^{(t)}\\|_{\\infty}+\\frac{\\eta\\sigma}{1-\\gamma}\\big\\|v^{(t)}\\big\\|_{\\infty}+\\frac{\\eta}{1-\\gamma}\\cdot\\sqrt{N}\\left(\\big\\|\\widehat{q}^{(t)}-\\overline{{q}}^{(t)}\\big\\|_{\\infty}+\\frac{1}{1-\\gamma}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Putting all pieces together, we obtain ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\|v^{(t+1)}\\right\\|_{\\infty}\\leq\\sigma\\left(1+\\frac{(1+\\gamma)\\gamma\\sqrt{N}\\eta}{(1-\\gamma)^{3}}\\sigma\\right)\\left\\|v^{(t)}\\right\\|_{\\infty}}\\\\ {\\displaystyle\\qquad\\qquad+\\left.\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\sqrt{N}\\sigma\\Bigg\\{2\\big\\|u^{(t)}\\big\\|_{\\infty}+\\frac{\\eta\\sqrt{N}}{(1-\\gamma)^{2}}+\\frac{\\eta\\sqrt{N}}{1-\\gamma}\\left\\|e\\right\\|_{\\infty}\\Bigg\\}}\\\\ {\\displaystyle\\qquad+\\left.2\\sigma\\sqrt{N}\\left\\|e\\right\\|_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Step 2: establish the descent equation. Note that Lemma F.6 directly applies by replacing ${\\widehat Q}^{(t)}$ With $\\widehat{q}^{(t)}$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}(\\eta)\\le\\phi^{(t)}(\\eta)+\\frac{2\\eta}{(1-\\gamma)^{2}}\\left\\|\\widehat{q}^{(t)}-\\overline{{Q}}^{(t)}\\right\\|_{\\infty}-\\eta\\left(V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\right)\\;.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "To bound the middle term, for all $t\\geq0$ ,wehave ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\overline{{Q}}^{(t)}-\\hat{q}^{(t)}\\right\\|_{\\infty}=\\left\\|\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}Q_{n}^{\\pi_{n}^{(t)}}-\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}Q_{n}^{\\overline{{\\pi}}^{(t)}}\\right\\|_{\\infty}+\\frac{1}{N}\\left\\|\\displaystyle\\sum_{n=0}^{N}\\left(q_{n}^{\\pi_{n}^{(t)}}-Q_{n}^{\\pi_{n}^{(t)}}\\right)\\right\\|_{\\infty}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\cdot\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\left\\|\\log\\xi_{n}^{(t)}-\\log\\overline{{\\xi}}^{(t)}\\right\\|_{\\infty}+\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}e_{n}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{(1+\\gamma)\\gamma}{(1-\\gamma)^{2}}\\left\\|u^{(t)}\\right\\|_{\\infty}+\\|e\\|_{\\infty}\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Hence, (102) is established by combining the above two inequalities. ", "page_idx": 47}, {"type": "text", "text": "Step 4: bound the consensus error. Similar as (224), here we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\vert\\Omega^{(t)}\\right\\vert\\right\\vert_{2}\\leq\\rho(B(\\eta))\\left\\|\\Omega^{(t-1)}\\right\\|_{2}+\\left(d_{2}(\\eta)+c_{2}(\\eta)\\right)}\\\\ {\\displaystyle\\leq\\cdots\\leq\\rho^{t}(B(\\eta))\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\sum_{i=0}^{t-1}\\rho^{i}(B(\\eta))\\left(\\frac{(1+\\gamma)\\gamma N\\sigma}{(1-\\gamma)^{4}}\\eta+\\sqrt{N}\\sigma\\left(\\frac{(1+\\gamma)\\gamma\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+2\\right)\\right.}\\\\ {\\displaystyle\\left.\\leq\\rho^{t}(B(\\eta))\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\frac{2}{1-\\rho(B(\\eta))}\\left(\\frac{N\\sigma}{(1-\\gamma)^{4}}\\eta+\\sqrt{N}\\sigma\\left(\\frac{\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+1\\right)\\|e\\|_{\\infty}\\right)}\\\\ {\\displaystyle\\leq\\left(\\frac{3}{8}\\sigma+\\frac{5}{8}\\right)^{t}\\left\\|\\Omega^{(0)}\\right\\|_{2}+\\frac{16}{3(1-\\sigma)}\\left(\\frac{N\\sigma}{(1-\\gamma)^{4}}\\eta+\\sqrt{N}\\sigma\\left(\\frac{\\eta\\sqrt{N}}{(1-\\gamma)^{3}}+1\\right)\\|e\\|_{\\infty}\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "which indicates 103. ", "page_idx": 47}, {"type": "text", "text": "G  Proof of auxiliary lemmas ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "G.1 Proof of Lemma F.1 ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The first claim is easily verified as $\\log\\xi_{n}^{(t)}(s,\\cdot)$ always deviate from $\\log\\pi_{n}^{(t)}(\\cdot|s)$ by a global constant shift, as long as it holds for $t=0$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathrm{og}\\,\\xi_{n}^{(t+1)}(s,\\cdot)=\\sum_{n^{\\prime}=1}^{N}[W]_{n,n^{\\prime}}\\left(\\alpha\\log\\xi_{n^{\\prime}}^{(t)}(s,\\cdot)+(1-\\alpha)T_{n}^{(t)}(s,\\cdot)/\\tau\\right)}\\\\ &{\\quad\\quad\\quad\\quad=\\alpha\\sum_{n^{\\prime}=1}^{N}[W]_{n,n^{\\prime}}\\left(\\alpha\\left(\\log\\pi_{n^{\\prime}}^{(t)}(s,\\cdot)+c_{n^{\\prime}}^{(t)}(s)\\mathbf{1}_{|A|}\\right)+(1-\\alpha)T_{n}^{(t)}(s,\\cdot)/\\tau\\right)}\\\\ &{\\quad\\quad\\quad=\\alpha\\displaystyle\\sum_{n^{\\prime}=1}^{N}[W]_{n,n^{\\prime}}\\left(\\alpha\\log\\pi_{n^{\\prime}}^{(t)}(s,\\cdot)+(1-\\alpha)T_{n}^{(t)}(s,\\cdot)/\\tau\\right)-\\log z_{n}^{(t)}(s)\\mathbf{1}_{|A|}+c_{n}^{(t+1)}(s)/\\tau\\right)}\\\\ &{\\quad\\quad\\quad=\\log\\pi_{n}^{(t+1)}(\\cdot|s)+c_{n}^{(t+1)}(s)\\mathbf{1}_{|A|},}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where $z_{n}^{(t)}$ isthnlr $\\{c_{n}^{(t)}(s)\\}$ are some constans To prove the second claim, $\\forall t\\geq0,\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}$ ,let ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\overline{{T}}^{(t)}(s,a):=\\frac{1}{N}\\mathbf{1}^{\\top}T^{(t)}(s,a)\\,.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Taking inner product with $\\scriptstyle{\\frac{1}{N}}\\mathbf{1}$ for both sides of $(U_{T})$ and using the double stochasticity property of $W$ ,weget ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\overline{{T}}^{(t+1)}(s,a)=\\overline{{T}}^{(t)}(s,a)+\\widehat{Q}_{\\tau}^{(t+1)}(s,a)-\\widehat{Q}_{\\tau}^{(t)}(s,a)\\,.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By the choice of ${\\pmb T}^{(0)}$ (line 2 of Algorithm 2), we have $\\overline{{T}}^{(0)}=\\widehat{Q}_{\\tau}^{(0)}$ and hence by induction ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\forall t\\geq0:\\quad\\overline{{T}}^{(t)}=\\widehat{Q}_{\\tau}^{(t)}\\,.\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "This implies ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\overline{\\xi}^{(t+1)}(s,a)-\\alpha\\log\\overline{\\xi}^{(t)}(s,a)=(1-\\alpha)\\widehat Q_{\\tau}^{(t)}(s,a)/\\tau}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad=(1-\\alpha)\\overline{T}^{(t)}(s,a)/\\tau}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad=\\cfrac{1}{N}\\mathbf1^{\\top}\\log\\xi^{(t+1)}(s,a)-\\alpha\\cfrac{1}{N}\\mathbf1^{\\top}\\log\\xi^{(t)}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Therefore, to prove (161), it suffices to verify the claim for $t=0$ ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{\\nabla}{\\bf1}^{\\top}\\log\\xi^{(0)}(s,a)=\\log\\|\\exp\\left(Q_{\\tau}^{\\star}(s,\\cdot)/\\tau\\right)\\|_{1}+\\frac{1}{N}{\\bf1}^{\\top}\\log\\pi^{(0)}(a|s)-\\log\\left\\|\\exp\\left(\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\log\\pi_{n}^{(0)}(\\cdot|s|)\\right)\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\log\\|\\exp\\left(Q_{\\tau}^{\\star}(s,\\cdot)/\\tau\\right)\\|_{1}+\\log\\overline{{\\pi}}^{(0)}(a|s)=\\log\\overline{{\\xi}}^{(0)}(s,a)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "By taking logarithm over both sides of the defnition of $\\overline{{\\pi}}^{(t+1)}$ (cf. (27), we get ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\log\\overline{{\\pi}}^{(t+1)}(a|s)=\\alpha\\log\\overline{{\\pi}}^{(t)}(a|s)+(1-\\alpha)\\widehat{Q}^{(t)}(s,a)/\\tau-z^{(t)}(s)\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "for some constant $z^{(t)}(s)$ , which deviate from the update rule of $\\log\\overline{{\\xi}}^{(t+1)}$ by a global constant shift and hence verifies (162). ", "page_idx": 48}, {"type": "text", "text": "G.2Proof of Lemma F.3 ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "For notational simplicity, we let ${Q}_{\\tau}^{\\theta^{\\prime}}$ and $Q_{\\tau}^{\\theta}$ denote $Q_{\\tau}^{\\pi_{\\theta^{\\prime}}}$ and $Q_{\\tau}^{\\pi_{\\theta}}$ , respectively. From (6a) we immediately know that to bound $\\left\\|Q_{\\tau}^{\\theta^{\\prime}}-Q_{\\tau}^{\\theta}\\right\\|_{\\infty}$ , it suffices to control $\\left|V_{\\tau}^{\\theta}(s)-V_{\\tau}^{\\theta^{\\prime}}(s)\\right|$ for each $s\\in S$ . By (4) we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|V_{\\tau}^{\\theta}(s)-V_{\\tau}^{\\theta^{\\prime}}(s)\\right|\\leq\\left|V^{\\theta}(s)-V^{\\theta^{\\prime}}(s)\\right|+\\tau\\big|\\mathcal{H}(s,\\pi_{\\theta})-\\mathcal{H}(s,\\pi_{\\theta^{\\prime}})\\big|\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "so in the following we bound both terms in the RHS of (235). ", "page_idx": 48}, {"type": "text", "text": "Step 1: bounding $\\begin{array}{r}{\\left|\\mathcal{H}(s,\\pi_{\\theta})-\\mathcal{H}(s,\\pi_{\\theta^{\\prime}})\\right|\\!.}\\end{array}$ We first bound $\\left|\\mathcal{H}(s,\\pi_{\\theta})-\\mathcal{H}(s,\\pi_{\\theta^{\\prime}})\\right|$ using the idea in the proof of Lemma 14 in [MXSS20]. We let ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\theta^{(t)}=\\theta+t(\\theta^{\\prime}-\\theta)\\,,\\quad\\forall t\\in\\mathbb{R}\\,,\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "and let $h^{(t)}\\in\\mathbb{R}^{|S|}$ be ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\forall s\\in S:\\quad h^{(t)}(s):=-\\sum_{a\\in\\mathcal{A}}\\pi_{\\theta^{(t)}}(a|s)\\log\\pi_{\\theta^{(t)}}(a|s)\\,.\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Note that $\\left\\|h^{(t)}\\right\\|_{\\infty}\\leq\\log|{\\mathcal{A}}|$ We also denote $H^{(t)}:S\\to\\mathbb{R}^{|\\mathcal{A}|\\times|\\mathcal{A}|}$ by: ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\forall s\\in\\mathcal{S}:\\quad H^{(t)}(s):=\\frac{\\partial\\pi_{\\theta}(\\cdot|s)}{\\partial\\theta}\\bigg\\vert_{\\theta=\\theta^{(t)}}=\\mathrm{diag}\\{\\pi_{\\theta^{(t)}}(\\cdot|s)\\}-\\pi_{\\theta^{(t)}}(\\cdot|s)\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}\\,,\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "then we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\forall s\\in S:\\ }&{\\left\\vert\\frac{d h^{(t)}(s)}{d t}\\right\\vert=\\left\\vert\\left\\langle\\frac{\\partial h^{(t)}(s)}{\\partial\\theta^{(t)}(\\cdot|s)},\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\rangle\\right\\vert}\\\\ &{\\qquad\\qquad\\quad=\\left\\vert\\left\\langle H^{(t)}(s)\\log\\pi_{\\theta^{(t)}}(\\cdot|s),\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\rangle\\right\\vert}\\\\ &{\\qquad\\qquad\\quad\\leq\\left\\Vert H^{(t)}(s)\\log\\pi_{\\theta^{(t)}}(\\cdot|s)\\right\\Vert_{1}\\left\\Vert\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\Vert_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where $\\frac{\\partial h^{\\left(t\\right)}\\left(s\\right)}{\\partial\\theta^{\\left(t\\right)}\\left(\\cdot|s\\right)}$ stands for l=0t) The frst tem in (239)is further upperbouded as ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\Big\\|H^{(t)}(s)\\log\\pi_{\\theta^{(t)}}(\\cdot|s)\\Big\\|_{1}=\\displaystyle\\sum_{a\\in A}\\pi_{\\theta^{(t)}}(a|s)\\left|\\log\\pi_{\\theta^{(t)}}(a|s)-\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}\\log\\pi_{\\theta^{(t)}}(\\cdot|s)\\right|}}\\\\ &{\\leq\\displaystyle\\sum_{a\\in A}\\pi_{\\theta^{(t)}}(a|s)\\left(\\left|\\log\\pi_{\\theta^{(t)}}(a|s)\\right|+\\left|\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}\\log\\pi_{\\theta^{(t)}}(\\cdot|s)\\right|\\right)}\\\\ &{=-2\\displaystyle\\sum_{a\\in A}\\pi_{\\theta^{(t)}}(a,s)\\log\\pi_{\\theta^{(t)}}(a|s)\\leq2\\log|A|\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "By Lagrange mean value theorem, there exists $t\\in(0,1)$ such that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\left|h_{1}(s)-h_{0}(s)\\right|=\\left|\\frac{d h^{(t)}(s)}{d t}\\right|\\leq2\\log|A|\\left\\|\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\|_{\\infty}\\,,\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where the inequality follows from (239) and the above inequality. Combining (5) with the above inequality, we arrive at ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\left\\vert\\mathcal{H}(s,\\pi_{\\theta})-\\mathcal{H}(s,\\pi_{\\theta^{\\prime}})\\right\\vert\\leq\\frac{2\\log|\\mathcal{A}|}{1-\\gamma}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Step 2: bounding $\\left|V^{\\theta}(s)-V^{\\theta^{\\prime}}(s)\\right|$ . Similar to the previous proof, we bound $\\left|V^{\\theta}(s)-V^{\\theta^{\\prime}}(s)\\right|$ by bounding $\\left|{\\frac{d V^{\\theta^{(t)}}}{d t}}\\!\\left(s\\right)\\right|$ ByBellman's consistencyquatio, the valefuctionf $\\pi_{\\theta^{(t)}}$ is given by ", "page_idx": 49}, {"type": "equation", "text": "$$\nV^{\\theta^{(t)}}(s)=\\sum_{a\\in A}\\pi_{\\theta^{(t)}}(a|s)r(s,a)+\\gamma\\sum_{a}\\pi_{\\theta_{\\alpha}}(a|s)\\sum_{s^{\\prime}\\in S}\\mathcal{P}(s^{\\prime}|s,a)V^{\\theta^{(t)}}(s^{\\prime})\\,,\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "which can be represented in a matrix-vector form as ", "page_idx": 49}, {"type": "equation", "text": "$$\nV^{\\theta_{\\star}^{(t)}}(s)=e_{s}^{\\top}M_{t}r_{t}\\,,\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $\\boldsymbol{e}_{s}\\in\\mathbb{R}^{|S|}$ is a one-hot vector whose $s$ -th entry is 1, ", "page_idx": 49}, {"type": "equation", "text": "$$\nM_{t}:=({\\pmb I}-\\gamma{\\pmb P}_{t})^{-1}\\,,\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Wwith $P_{t}\\in\\mathbb{R}^{|S|\\times|S|}$ denoting the induced state transition matrix by $\\pi_{\\theta}(t)$ ", "page_idx": 49}, {"type": "equation", "text": "$$\nP_{t}(s,s^{\\prime})=\\sum_{a\\in\\cal{A}}\\pi_{\\theta^{(t)}}(a|s)\\mathcal{P}(s^{\\prime}|s,a)\\,,\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "and $r_{t}\\in\\mathbb{R}^{|S|}$ is given by ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\forall s\\in{\\mathcal{S}}:\\quad r_{t}(s):=\\sum_{a\\in{\\mathcal{A}}}\\pi_{\\theta^{(t)}}(a|s)r(s,a)\\,.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Taking derivative w.r.t. $t$ in (241), we obtain [PP08] ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\frac{d V^{\\theta^{(t)}}(s)}{d t}=\\gamma\\cdot e_{s}^{\\top}M_{t}\\frac{d P_{t}}{d t}M_{t}r_{t}+e_{s}^{\\top}M_{t}\\frac{d r_{t}}{d t}\\,.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "We now calculate each term respectively. ", "page_idx": 49}, {"type": "text", "text": "\u00b7 For the first term, it follows that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\gamma\\cdot e_{s}^{\\top}M_{t}\\frac{d P_{t}}{d t}M_{t}r_{t}\\bigg|\\le\\gamma\\left\\|M_{t}\\frac{d P_{t}}{d t}M_{t}r_{t}\\right\\|_{\\infty}}&{}\\\\ {\\qquad\\le\\frac{\\gamma}{1-\\gamma}\\left\\|\\frac{d P_{t}}{d t}M_{t}r_{t}\\right\\|_{\\infty}}&{}\\\\ {\\qquad\\le\\frac{2\\gamma}{1-\\gamma}\\left\\|M_{t}r_{t}\\right\\|_{\\infty}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}}&{}\\\\ {\\qquad\\le\\frac{2\\gamma}{\\left(1-\\gamma\\right)^{2}}\\left\\|r_{t}\\right\\|_{\\infty}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}}&{}\\\\ {\\qquad\\le\\frac{2\\gamma}{\\left(1-\\gamma\\right)^{2}}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where the second and fourth lines use the fact $\\|M_{t}\\|_{1}\\leq1/(1-\\gamma)$ [LWCC23a, Lemma 10], and the last line follow from ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\left\\lVert r_{t}\\right\\rVert_{\\infty}=\\operatorname*{max}_{s\\in S}\\left\\lvert\\sum_{a\\in\\mathcal{A}}\\pi_{\\theta^{(t)}}(a|s)r(s,a)\\right\\rvert\\le1.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "We defer the proof of (246) to the end of proof. ", "page_idx": 49}, {"type": "text", "text": "\u00b7 For the second term, it follows that ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\left|e_{s}^{\\top}M_{t}\\frac{d r_{t}}{d t}\\right|\\leq\\frac{1}{1-\\gamma}\\left\\|\\frac{d r_{t}}{d t}\\right\\|_{\\infty}\\leq\\frac{1}{1-\\gamma}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where the first inequality follows again from $\\|M_{t}\\|_{1}\\leq1/(1-\\gamma)$ , and the second inequality follows from ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\frac{d r_{t}}{d t}\\right\\|_{\\infty}=\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\left|\\frac{d r_{t}(s)}{d t}\\right|=\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\left|\\left\\langle\\frac{\\partial\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}r(s,\\cdot)}{\\partial\\theta^{(t)}(s)},\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\rangle\\right|}\\\\ {\\leq\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\left\\|\\frac{\\partial\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}r}{\\partial\\theta^{(t)}(s,\\cdot)}r(s,\\cdot)\\right\\|_{1}\\left\\|\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\|_{\\infty}}\\\\ {=\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\left(\\sum_{\\alpha\\in\\mathcal{A}}\\pi_{\\theta^{(t)}}(a|s)\\left|r(s,a)-\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}r(s,\\cdot)\\right|\\right)\\left\\|\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right.}\\\\ {\\leq\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\frac{\\operatorname*{max}}{\\operatorname*{max}}\\left|r(s,a)-\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}r(s,\\cdot)\\right|\\left\\|\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\|_{\\infty}}\\\\ {\\leq\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\frac{\\operatorname*{max}}{\\operatorname*{max}}\\left|r(s,\\cdot)\\sin\\mathrm{er}\\left(s,a)\\right|}\\\\ {\\leq\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}}\\left\\|\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\|_{\\infty}=\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}\\,.\\qquad\\qquad\\qquad(249)}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Plugging the above two inequalities into (245) and using Lagrange mean value theorem, we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\left|V^{\\theta}(s)-V^{\\theta^{\\prime}}(s)\\right|\\le\\frac{1+\\gamma}{(1-\\gamma)^{2}}\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Step 3: sum up. Combining (250), (240) and (235), we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\forall s\\in\\mathcal{S}:\\quad\\left|V_{\\tau}^{\\theta}(s)-V_{\\tau}^{\\theta^{\\prime}}(s)\\right|\\leq\\frac{1+\\gamma+2\\tau(1-\\gamma)\\log|\\mathcal{A}|}{(1-\\gamma)^{2}}\\left\\|\\log\\pi-\\log\\pi^{\\prime}\\right\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Combining (251) and (6a), (170) immediately follows. ", "page_idx": 50}, {"type": "text", "text": "Proof of (246). For any vector $x\\in\\mathbb{R}^{|S|}$ ,wehave ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\left[\\frac{d{P}_{t}}{d t}x\\right]_{s}=\\sum_{s^{\\prime}\\in\\mathcal{S}}\\sum_{a\\in\\mathcal{A}}\\frac{d\\pi_{\\theta^{(t)}}(a|s)}{d t}\\mathcal{P}(s^{\\prime}|s,a)x(s^{\\prime})\\,,\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "from which we can bound the $l_{\\infty}$ norm as ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|\\frac{d\\boldsymbol{P}_{t}}{d t}\\boldsymbol{x}\\right\\|_{\\infty}\\leq\\operatorname*{max}_{s}\\sum_{\\stackrel{\\scriptstyle a\\in\\mathcal{A}}{s}}\\sum_{s^{\\prime}\\in\\mathcal{S}}\\mathcal{P}(s^{\\prime}|s,a)\\left|\\frac{d\\pi_{\\theta^{(t)}}(a|s)}{d t}\\right|\\|\\boldsymbol{x}\\|_{\\infty}}}\\\\ &{=\\displaystyle\\operatorname*{max}_{s}\\sum_{\\stackrel{\\scriptstyle a\\in\\mathcal{A}}{s}}\\left|\\frac{d\\pi_{\\theta^{(t)}}(a|s)}{d t}\\right|\\|\\boldsymbol{x}\\|_{\\infty}}\\\\ &{\\leq2\\left\\|\\theta^{\\prime}-\\theta\\right\\|_{\\infty}\\left\\|\\boldsymbol{x}\\right\\|_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "as desired, where the last line follows from the following fact: ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{a\\in A}\\left|\\frac{d\\pi_{\\theta^{(t)}}(a|s)}{d t}\\right|=\\displaystyle\\sum_{a\\in A}\\left|\\left\\langle\\frac{\\partial\\pi_{\\theta^{(t)}}(a|s)}{\\partial\\theta^{(t)}},\\theta^{\\prime}-\\theta\\right\\rangle\\right|}\\\\ &{\\quad=\\displaystyle\\sum_{a\\in A}\\left|\\left\\langle\\frac{\\partial\\pi_{\\theta^{(t)}}(a|s)}{\\partial\\theta^{(t)}(s,\\cdot)},\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right\\rangle\\right|}\\\\ &{\\quad=\\displaystyle\\sum_{a\\in A}\\pi_{\\theta^{(t)}}(a|s)\\left|\\left(\\theta^{\\prime}(s,a)-\\theta(s,a)\\right)-\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}\\left(\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right)\\right|}\\\\ &{\\quad\\leq\\displaystyle\\operatorname*{max}_{a}|\\theta^{\\prime}(s,a)-\\theta(s,a)|+\\left|\\pi_{\\theta^{(t)}}(\\cdot|s)^{\\top}\\left(\\theta^{\\prime}(s,\\cdot)-\\theta(s,\\cdot)\\right)\\right|}\\\\ &{\\quad\\leq2\\left\\lVert\\theta^{\\prime}-\\theta\\right\\rVert_{\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "G.3Proof of Lemma F.4 ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "To simplify the notation, we denote ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\delta^{(t)}:=\\widehat{Q}_{\\tau}^{(t)}-\\overline{{Q}}_{\\tau}^{(t)}\\,.\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "We first rearrange the terms of (234) and obtain ", "page_idx": 51}, {"type": "equation", "text": "$$\n-\\tau\\log\\overline{{\\pi}}^{(t)}(a|s)+\\left(\\overline{{Q}}_{\\tau}^{(t)}(s,a)+\\delta^{(t)}(s,a)\\right)=\\frac{1-\\gamma}{\\eta}\\left(\\log\\overline{{\\pi}}^{(t+1)}(a|s)-\\log\\overline{{\\pi}}^{(t)}(a|s)\\right)+\\frac{1-\\gamma}{\\eta}z^{(t)}(s,a).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "This in turn allows us to express $\\overline{{V}}_{\\tau}^{(t)}(s_{0})$ for any $s_{0}\\in\\mathcal S$ as follows ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(s_{0})=\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[-\\tau\\log\\overline{{\\pi}}^{(t)}(a_{0}\\vert s_{0})+\\overline{{Q}}_{\\tau}^{(t)}(s_{0},a_{0})\\right]}\\\\ &{\\quad\\quad=\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[\\frac{1-\\gamma}{\\eta}z^{(t)}(s_{0})\\right]+\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[\\frac{1-\\gamma}{\\eta}\\left(\\log\\overline{{\\pi}}^{(t+1)}(a_{0}\\vert s_{0})-\\log\\overline{{\\pi}}^{(t)}(a_{0}\\vert s_{0})\\right)-\\right.}\\\\ &{\\quad\\quad=\\frac{1-\\gamma}{\\eta}z^{(t)}(s_{0})-\\frac{1-\\gamma}{\\eta}\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})\\vert\\,\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{0})\\right)-\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[\\delta^{(t)}(s_{0},a_{0})\\right]}\\\\ &{\\quad\\quad=\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[\\frac{1-\\gamma}{\\eta}z^{(t)}(s_{0})\\right]-\\frac{1-\\gamma}{\\eta}\\mathsf{K L}\\left(\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})\\,\\Vert\\,\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{0})\\right)-\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\left[\\delta^{(t)}(s_{0})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where the first identity makes use of (6b), the second line follows from (254). Invoking (6b) again to rewritethe $z(s_{0})$ appearing in the first term of (255), we reach ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\gamma}_{\\tau}^{(t)}\\left(s_{0}\\right)}\\\\ &{=\\underset{a_{0}\\sim\\pi^{\\frac{\\mathbb{E}}{\\pi}\\left(\\tau^{\\!\\left(t+1\\right)}\\left(\\cdot\\vert s_{0}\\right)\\right)}}{=}\\left[-\\tau\\log\\overline{{\\pi}}^{\\left(t+1\\right)}(a_{0}\\vert s_{0})+\\overline{{Q}}_{\\tau}^{\\left(t\\right)}(s_{0},a_{0})+\\left(\\tau-\\frac{1-\\gamma}{\\eta}\\right)\\left(\\log\\overline{{\\pi}}^{\\left(t+1\\right)}(a_{0}\\vert s_{0})-\\log\\overline{{\\pi}}^{\\left(t\\right)}\\left(\\log\\overline{{\\pi}}\\right)\\right.\\right.}\\\\ &{\\qquad\\left.\\left.-\\frac{1-\\gamma}{\\eta}\\mathbb{K}\\!\\!\\!\\!\\!\\!}\\\\ &{=\\underset{a_{0}\\sim\\pi^{\\frac{\\mathbb{E}}{\\pi}\\left(t+1\\right)}\\left(\\cdot\\vert s_{0}\\right)}{=}\\left[-\\tau\\log\\overline{{\\pi}}^{\\left(t+1\\right)}(a_{0}\\vert s_{0})+r(s_{0})\\underset{a_{0}\\sim\\pi^{\\frac{\\mathbb{E}}{\\pi}\\left(t\\right)}\\left(\\cdot\\vert s_{0}\\right)}{=}\\left[\\delta^{\\left(t\\right)}(s_{0},a_{0})\\right]+\\underset{a_{0}\\sim\\pi^{\\frac{\\mathbb{E}}{\\pi}\\left(t+1\\right)}\\left(\\cdot\\vert s_{0}\\right)}{=}\\left[\\delta^{\\left(t\\right)}(s_{0},a_{0})\\right]}\\\\ &{=\\underset{a_{0}\\sim\\pi^{\\frac{\\mathbb{E}}{\\pi}\\left(t+1\\right)}\\left(\\cdot\\vert s_{0}\\right)}{=}\\left[-\\tau\\log\\overline{{\\pi}}^{\\left(t+1\\right)}(a_{0}\\vert s_{0})+r(s_{0},a_{0})+\\gamma\\overline{{V}}_{\\tau}^{\\left(t\\right)}(s_{0})\\right]}\\\\ &{\\qquad\\left.\\quad-\\left(\\frac{1-\\gamma}{\\eta}-\\tau\\right)\\mathbb{K}\\!\\!\\!\\!\\!\\left(\\overline{{\\pi}}^{\\left(t+1\\right)}(\\cdot\\vert s_{0}\\rangle\\left\\Vert\\ \\overline{{\\pi}}^{\\left(t\\right)}(\\cdot\\vert s_{0})\\right)-\\frac{1-\\gamma}{\\eta}\\mathbb{K}\\!\\!\\!\\left(\\overline{{\\pi}}^{\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Note that for any $\\left(s_{0},a_{0}\\right)\\in\\mathcal S\\times\\mathcal A$ , we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\Big[\\delta^{(t)}(s_{0},a_{0})\\Big]+\\underset{a_{0}\\sim\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{0})}{\\mathbb{E}}\\Big[\\delta^{(t)}(s_{0},a_{0})\\Big]}\\\\ &{=\\sum_{a_{0}\\in\\mathcal{A}}\\left(\\overline{{\\pi}}^{(t+1)}(a_{0}\\vert s_{0})-\\overline{{\\pi}}^{(t)}(a_{0}\\vert s_{0})\\right)\\delta^{(t)}(s_{0},a_{0})}\\\\ &{\\leq\\left\\Vert\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{0})-\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{0})\\right\\Vert_{1}\\left\\Vert\\delta^{(t)}\\right\\Vert_{\\infty}\\leq2\\left\\Vert\\delta^{(t)}\\right\\Vert_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "To fnish up,applying (256) recursively to expand $\\overline{{V}}_{\\tau}^{(t)}(s_{i})$ \uff0c $i\\geq1$ and making use of (257), we arrive at ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{\\overline{{\\tau}}}_{\\tau}^{(t)}(s_{0})}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{2}\\gamma^{i}\\cdot2\\left\\|\\delta^{(t)}\\right\\|_{\\infty}+\\operatorname*{max}_{s_{i+1}\\sim P(\\cdot+1)_{(\\cdot+\\vert s_{i}),\\cdot}}\\left[\\sum_{i=1}^{\\infty}\\gamma^{i}\\left\\{r(s_{i},a_{i})-\\tau\\log\\overline{{\\pi}}^{(t+1)}(a_{i}\\vert s_{i})\\right\\}\\right.}\\\\ &{\\qquad\\left.-\\displaystyle\\sum_{i=1}^{\\infty}\\gamma^{i}\\left\\{\\left(\\frac{1-\\gamma}{\\eta}-\\tau\\right)\\mathsf{K L}(\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{i})\\vert\\ \\|\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{i}))+\\frac{1-\\gamma}{\\eta}\\mathsf{K L}(\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{i})\\ \\|\\ \\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{i}))\\right\\}\\right]}\\\\ &{=\\displaystyle\\frac{2}{1-\\gamma}\\left\\|\\delta^{(t)}\\right\\|_{\\infty}+\\overline{{V}}_{\\tau}^{(t+1)}(s_{0})}\\\\ &{\\qquad-\\underbrace{\\mathbb{E}}_{s\\times\\overline{{\\kappa}}_{\\eta}^{(t+1)}}\\left[\\left(\\frac{1}{\\eta}-\\frac{\\tau}{1-\\gamma}\\right)\\mathsf{K L}(\\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{i})\\ \\|\\ \\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{i}))+\\frac{1}{\\eta}\\mathsf{K L}(\\overline{{\\pi}}^{(t)}(\\cdot\\vert s_{i})\\ \\|\\ \\overline{{\\pi}}^{(t+1)}(\\cdot\\vert s_{i}))\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where the thir line fllows since (t+1) can be viewed as the value function of $\\overline{{\\pi}}^{(t+1)}$ with adjusted rewards $\\overline{{r}}^{(t+1)}(s,a):=r(s,a)-\\tau\\log\\overline{{\\pi}}^{(t+1)}(s|a)$ And (18) follows immediatelyfrom the above inequality (258). By (6a) we can easily see that (189) is a consequence of (188). ", "page_idx": 52}, {"type": "text", "text": "G.4 Proof of Lemma F.6 ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "We first introduce the famous performance difference lemma which will be used in our proof. ", "page_idx": 52}, {"type": "text", "text": "Lemma G.1 (Performance difference lemma). For any policy $\\pi,\\pi^{\\prime}\\in\\Delta(\\mathcal{A})^{S}$ and $\\rho\\in\\Delta(S)$ we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle V^{\\pi}(\\rho)-V^{\\pi^{\\prime}}(\\rho)=\\frac{1}{1-\\gamma}\\mathbb{E}_{(s,a)\\sim\\bar{d}^{\\pi}}\\left[A^{\\pi^{\\prime}}(s,a)\\right]}}\\\\ {{\\displaystyle\\qquad\\qquad\\qquad=\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{\\pi}}\\left[\\langle Q^{\\pi^{\\prime}}(s),\\pi(s)-\\pi^{\\prime}(s)\\rangle\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Proof. See Lemma 3 in $[\\mathrm{YDG}^{+}22]$ ", "page_idx": 52}, {"type": "text", "text": "For all $t\\geq0$ we defne the advantage function ${\\overline{{A}}}^{(t)}$ as: ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in{\\mathcal{S}}\\times{\\mathcal{A}}:\\quad{\\overline{{A}}}^{(t)}(s,a):={\\overline{{Q}}}^{(t)}(s,a)-{\\overline{{V}}}^{(t)}(s)\\,.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Then for Alg. 1, the update rule of $\\overline{{\\pi}}$ (Eq. (234)) can be written as ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\log\\overline{{\\pi}}^{(t+1)}(a|s)=\\log\\overline{{\\pi}}^{(t)}(a|s)+\\frac{\\eta}{1-\\gamma}\\left(\\overline{{A}}^{(t)}(s,a)+\\delta^{(t)}(s,a)\\right)-\\log\\widehat{z}^{(t)}(s)\\,,\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where ${\\delta^{(t)}}$ is defined in (253) and ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\widehat{z}^{(t)}(s)=\\displaystyle\\log\\sum_{a^{\\prime}\\in A}\\overline{{\\pi}}^{(t)}(a^{\\prime}|s)\\exp\\left\\{\\frac{\\eta}{1-\\gamma}\\left(\\overline{{A}}^{(t)}(s,a^{\\prime})+\\delta^{(t)}(s,a^{\\prime})\\right)\\right\\}}\\\\ &{\\qquad\\qquad\\geq\\displaystyle\\sum_{a^{\\prime}\\in A}\\overline{{\\pi}}^{(t)}(a^{\\prime}|s)\\log\\exp\\left\\{\\frac{\\eta}{1-\\gamma}\\left(\\overline{{A}}^{(t)}(s,a^{\\prime})+\\delta^{(t)}(s,a^{\\prime})\\right)\\right\\}}\\\\ &{\\qquad=\\displaystyle\\frac{\\eta}{1-\\gamma}\\sum_{a^{\\prime}\\in A}\\overline{{\\pi}}^{(t)}(a^{\\prime}|s)\\left(\\overline{{A}}^{(t)}(s,a^{\\prime})+\\delta^{(t)}(s,a^{\\prime})\\right)}\\\\ &{\\qquad=\\displaystyle\\frac{\\eta}{1-\\gamma}\\sum_{a^{\\prime}\\in A}\\overline{{\\pi}}^{(t)}(a^{\\prime}|s)\\delta^{(t)}(s,a^{\\prime})\\geq-\\frac{\\eta}{1-\\gamma}\\left\\|\\delta^{(t)}\\right\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where the first inequality follows by Jensen's inequality on the concave function $\\log x$ and the last equality uses $\\begin{array}{r}{\\sum_{a^{\\prime}\\in\\mathcal{A}}\\overline{{\\pi}}^{(t)}(a^{\\prime}|s)\\overline{{A}}^{(t)}(s,a^{\\prime})=0}\\end{array}$ ", "page_idx": 52}, {"type": "text", "text": "Forallsani\u03bc , the performance difference lemma (Lemma G.1) implies: ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\gamma}}^{(t+1)}(\\mu)-\\overline{{V}}^{(t)}(\\mu)}\\\\ &{=\\displaystyle\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{(t+1)}}\\sum_{a\\in\\mathcal{A}}\\overline{{\\alpha}}^{(t+1)}(a|s)\\left(\\overline{{A}}^{(t)}(s,a)+\\delta^{(t)}(s,a)\\right)-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{(t+1)}}\\mathbb{E}_{a\\sim\\overline{{\\pi}}^{(t+1)}(\\cdot|s)}\\left[\\delta^{(t)}(s,a)\\right]}\\\\ &{=\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{(t+1)}}\\sum_{a\\in\\mathcal{A}}\\overline{{\\pi}}^{(t+1)}(a|s)\\log\\frac{\\overline{{\\pi}}^{(t+1)}(a|s)\\widehat{z}^{(t)}(s)}{\\overline{{\\pi}}^{(t)}(a|s)}-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{(t+1)}}\\mathbb{E}_{a\\sim\\overline{{\\pi}}^{(t+1)}(\\cdot|s)}\\left[\\delta^{(t)}(s,a)\\right]}\\\\ &{=\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{(t+1)}}\\mathbb{K}\\mathrm{L}(\\overline{{\\pi}}^{(t+1)}(\\cdot|s)\\left(\\overline{{\\pi}}^{(t)}(\\cdot|s)\\right)+\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{(t+1)}}\\log\\widehat{z}^{(t)}(s)-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{(t+1)}}\\mathbb{E}_{a\\sim\\overline{{\\pi}}^{(t+1)}(\\cdot|s)}\\left[\\frac{\\eta}{\\cdot|s)}\\right]}\\\\ &{\\geq\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{(t+1)}}\\left(\\log\\widehat{z}^{(t)}(s)+\\frac{\\eta}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\right)-\\frac{2}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "from which we can see that ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\overline{{V}}^{(t+1)}(\\mu)-\\overline{{V}}^{(t)}(\\mu)\\geq-\\frac{2}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\,,\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where we use (263), and that ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\overline{{V}}^{(t+1)}(\\mu)-\\overline{{V}}^{(t)}(\\mu)\\geq\\frac{1-\\gamma}{\\eta}\\mathbb{E}_{s\\sim\\mu}\\left(\\log\\widehat{z}^{(t)}(s)+\\frac{\\eta}{1-\\gamma}\\big\\|\\delta^{(t)}\\big\\|_{\\infty}\\right)-\\frac{2}{1-\\gamma}\\big\\|\\delta^{(t)}\\big\\|_{\\infty}\\,,\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "which follows from $d^{(t+1)}=d_{\\mu}^{\\overline{{{\\pi}}}^{(t+1)}}\\geq(1-\\gamma)\\mu$ and the fact that $\\begin{array}{r}{\\log\\widehat{z}^{(t)}(s)+\\frac{\\eta}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\geq0}\\end{array}$ (by (263)). ", "page_idx": 53}, {"type": "text", "text": "For any fixed $\\rho$ weuse $d^{\\star}$ as shorthand for $d_{\\rho}^{\\pi^{\\star}}$ . By the performance difference lemma (Lemma G.1), ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)}\\\\ &{=\\displaystyle\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{\\star}}\\sum_{a\\in\\mathcal{A}}\\pi^{\\star}(a|s)\\left(\\overline{{A}}^{(t)}(s,a)+\\delta^{(t)}(s,a)\\right)-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{\\star}}\\mathbb{E}_{a\\sim\\pi^{\\star}(\\cdot|s)}\\left[\\delta^{(t)}(s,a)\\right]}\\\\ &{=\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{\\star}}\\sum_{a\\in\\mathcal{A}}\\pi^{\\star}(a|s)\\log\\frac{\\overline{{\\pi}}^{(t+1)}(a|s)\\widehat{z}^{(t)}(s)}{\\overline{{\\pi}}^{(t)}(a|s)}-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{\\star}}\\mathbb{E}_{a\\sim\\pi^{\\star}(\\cdot|s)}\\left[\\delta^{(t)}(s,a)\\right]}\\\\ &{=\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{\\star}}\\left(\\mathsf{K L}(\\pi^{\\star}(\\cdot|s)\\|\\ \\overline{{\\pi}}^{(t)}(\\cdot|s))-\\mathsf{K L}(\\pi^{\\star}(\\cdot|s)\\|\\ \\overline{{\\pi}}^{(t+1)}(\\cdot|s))+\\log\\widehat{z}^{(t)}(s)\\right)-\\frac{1}{1-\\gamma}\\mathbb{E}_{s\\sim d^{\\star}}\\mathbb{E}_{a\\sim\\pi^{\\star}}}\\\\ &{\\leq\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{\\star}}\\left(\\mathsf{K L}\\left(\\pi^{\\star}(\\cdot|s)\\|\\ \\overline{{\\pi}}^{(t)}(\\cdot|s)\\right)-\\mathsf{K L}\\left(\\pi^{\\star}(\\cdot|s)\\|\\ \\overline{{\\pi}}^{(t+1)}(\\cdot|s)\\right)+\\left(\\log\\widehat{z}^{(t)}(s)+\\frac{\\eta}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where we use (262) in the second equality ", "page_idx": 53}, {"type": "text", "text": "By applying (265) with $\\mu=d^{\\star}$ as the initial state distribution, we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\frac{1}{\\eta}\\mathbb{E}_{s\\sim\\mu}\\Big(\\log\\widehat{z}^{(t)}(s)+\\frac{\\eta}{1-\\gamma}\\|\\delta^{(t)}\\|_{\\infty}\\Big)\\leq\\frac{1}{1-\\gamma}\\Big(\\overline{{V}}^{(t+1)}(d^{\\star})-\\overline{{V}}^{(t)}(d^{\\star})\\Big)+\\frac{2}{(1-\\gamma)^{2}}\\|\\delta^{(t)}\\|_{\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Plugging the above equation into (266), we obtain ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V^{\\star}(\\rho)-\\overline{{V}}^{(t)}(\\rho)\\leq\\displaystyle\\frac{1}{\\eta}\\mathbb{E}_{s\\sim d^{\\star}}\\left(\\mathsf{K L}\\left(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\overline{{\\pi}}^{(t)}(\\cdot|s)\\right)-\\mathsf{K L}\\big(\\pi^{\\star}(\\cdot|s)\\,\\|\\,\\overline{{\\pi}}^{(t+1)}(\\cdot|s)\\big)\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\displaystyle\\frac{1}{1-\\gamma}\\left(\\overline{{V}}^{(t+1)}(d^{\\star})-\\overline{{V}}^{(t)}(d^{\\star})\\right)+\\displaystyle\\frac{2}{(1-\\gamma)^{2}}\\|\\delta^{(t)}\\|_{\\infty}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "which gives Lemma F.6. ", "page_idx": 53}, {"type": "text", "text": "G.5 Proof of Theorem E.3 ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "The proof of Theorem E.3 could be found in Appendix C.5 in $[\\mathrm{YDG}^{+}22]$ .We present it for completeness. To prove Theorem E.3, we need the following Theorem G.2. ", "page_idx": 53}, {"type": "text", "text": "Theorem G.2 (Theorem 1 in [BM13]). Consider the following assaumptions: ", "page_idx": 54}, {"type": "text", "text": "(i) The observations $(\\pmb{a}_{k},\\pmb{b}_{k})\\in\\mathbb{R}^{p}\\times\\mathbb{R}^{p}$ are independent and identically distributed ", "page_idx": 54}, {"type": "text", "text": "$\\mid\\mathbb{E}\\left[\\left\\Vert\\mathbf{\\boldsymbol{a}}_{k}\\right\\Vert^{2}\\right]^{\\mathrm{s}}a n d\\operatorname{\\mathbb{E}}\\left[\\left\\Vert\\mathbf{\\boldsymbol{b}}_{k}\\right\\Vert^{2}\\right]$ are fnite. The covariance $\\mathbb{E}\\left[\\pmb{a}_{k}\\pmb{a}_{k}^{\\top}\\right]$ is invertible. ", "page_idx": 54}, {"type": "text", "text": "(ii\uff09 The global minimum of $\\begin{array}{r}{g(w)=\\frac{1}{2}\\mathbb{E}\\left[\\langle w,\\pmb{a}_{k}\\rangle^{2}-2\\langle w,b_{k}\\rangle\\right]}\\end{array}$ is attained at a certain $\\pmb{w}^{\\star}\\in\\mathbb{R}^{p}$ Let $\\Delta_{k}=b_{k}-\\langle{\\pmb w}^{\\star},{\\pmb a}_{k}\\rangle{\\pmb a}_{k}$ denote the residual. We have $\\mathbb{E}[\\Delta_{k}]=0$ ", "page_idx": 54}, {"type": "equation", "text": "$$\nR^{2}\\mathbb{E}\\left[\\mathbf{a}_{k}\\mathbf{a}_{k}^{\\top}\\right]\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "Consider the stochastic gradient recursion ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\pmb{w}_{k+1}=\\pmb{w}_{k}-\\eta\\left(\\langle\\pmb{w}_{k},\\pmb{a}_{k}\\rangle\\pmb{a}_{k}-\\pmb{b}_{k}\\right)\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "started from $\\pmb{w}_{0}\\in\\mathbb{R}^{p}$ . Let $\\begin{array}{r}{\\pmb{w}_{o u t}=\\frac{1}{K}\\sum_{k=1}^{K}\\pmb{w}_{k}}\\end{array}$ When $\\begin{array}{r}{\\eta=\\frac{1}{4R^{2}}}\\end{array}$ 4R2, we have ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[g(\\pmb{w}_{o u t})-g(\\pmb{w}^{\\star})\\right]\\leq\\frac{2}{K}(\\sigma\\sqrt{p}+R\\left\\|\\pmb{w}_{0}-\\pmb{w}^{\\star}\\right\\|)^{2}.\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "In the proof of Theorem E.3 we'll show that for Algorithm 4, the assumptions in Theorem G.2 are all satisfied and thus we can use the result (267). ", "page_idx": 54}, {"type": "text", "text": "Proof of Theorem E.3. We let $\\pmb{a}_{k}$ and $b_{k}$ in Theorem G.2 be $\\phi(s,a)$ and $\\widehat{Q}_{\\xi}\\phi(s,a)$ in Algorithm 4, respectively. And we let $\\|\\cdot\\|\\ \\ =\\ \\ \\|\\cdot\\|_{2}$ in Theorem G.2. Since the observations $\\Big(\\phi(s,a),\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\Big)\\in\\mathbb{R}^{p}\\times\\mathbb{R}^{p}$ are i.i.d, (i) is satisfed. ", "page_idx": 54}, {"type": "text", "text": "As we assume $\\|\\phi(s,a)\\|_{2}\\,\\leq\\,C_{\\phi},\\,\\mathbb{E}\\left[\\|\\phi(s,a)\\|_{2}^{2}\\right]$ is finite. From Assumption 4.1 we know that $\\mathbb{E}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]$ is invertible. ", "page_idx": 54}, {"type": "text", "text": "Let $H$ be the length of trajectory for estimating $\\widehat{Q}_{\\xi}(s,a)$ . Then $\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}$ is bounded by ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}\\right]=\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[\\displaystyle\\sum_{\\tau=0}^{\\infty}P r(H=\\tau)\\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau}r(s_{t},a_{t})\\right)^{2}\\bigg|H=\\tau,s_{0}=s,a_{0}=a\\right]\\right]}\\\\ &{}&{=\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[(1-\\gamma)\\displaystyle\\sum_{\\tau=0}^{\\infty}\\gamma^{\\tau}\\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau}r(s_{t},a_{t})\\right)^{2}\\bigg|H=\\tau,s_{0}=s,a_{0}=a\\right]\\right]}\\\\ &{}&{\\leq\\mathbb{E}_{(s,a)\\sim\\hat{d}_{\\nu}^{\\pi_{\\xi}^{\\pi}}}\\left[(1-\\gamma)\\displaystyle\\sum_{\\tau=0}^{\\infty}\\gamma^{\\tau}(\\tau+1)^{2}\\right]\\leq\\frac{2}{(1-\\gamma)^{2}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "from which we deduce $\\begin{array}{r}{\\mathbb{E}\\left[\\left\\|\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right\\|_{2}^{2}\\right]\\leq C_{\\phi}^{2}\\mathbb{E}\\left[\\widehat{Q}_{\\xi}(s,a)^{2}\\right]}\\end{array}$ is bounded. Thus i holds. ", "page_idx": 54}, {"type": "text", "text": "Furthermore, we introduce the residual ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\Delta:=\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)\\phi(s,a)\\,,\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "then from $[\\mathrm{YDG^{+}}22]$ , Lemma 7] we know that $\\begin{array}{r}{\\mathbb{E}[\\Delta]=\\frac{1}{2}\\nabla_{w}\\ell({\\pmb w}^{\\star},\\widehat{Q}_{\\xi},d_{\\nu}^{\\pi_{\\xi}})=0}\\end{array}$ , which gives (ii). ", "page_idx": 54}, {"type": "text", "text": "To verify (iv), we let $\\mathrm{~\\textit~{~R~}~}=\\mathrm{~\\textit~{~C~}~}_{\\phi}$ in Theorem G.2, then $\\begin{array}{r l}{\\mathbb{E}\\left[\\left\\|\\phi(s,a)\\right\\|_{2}^{2}\\phi(s,a)\\phi(s,a)^{\\top}\\right]}&{\\leq}\\end{array}$ $C_{\\phi}^{2}\\mathbb{E}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]$ . Also note that ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w^{\\star}=\\left(\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}}}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]\\right)^{\\dagger}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}}}\\left[\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right]}\\\\ &{\\quad\\quad\\leq\\displaystyle\\frac{1}{1-\\gamma}\\left(\\mathbb{E}_{(s,a)\\sim\\nu}\\left[\\phi(s,a)\\phi(s,a)^{\\top}\\right]\\right)^{\\dagger}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu}^{\\pi_{\\xi}}}\\left[\\widehat{Q}_{\\xi}(s,a)\\phi(s,a)\\right]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "\\*Here $\\lVert\\cdot\\rVert$ could be any norm in $\\mathbb{R}^{p}$ ", "page_idx": 54}, {"type": "text", "text": "from which we deduce ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\|\\pmb{w}^{\\star}\\|_{2}\\leq\\frac{B}{\\mu(1-\\gamma)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\boldsymbol{\\uptau}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)^{2}|s,a\\right]=\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)\\right)^{2}|s,a\\right]-2Q_{\\xi}(s,a)\\phi(s,a)^{\\top}w^{\\star}+(\\phi(s,a)^{\\top}u^{\\star})\\left(\\widehat{Q}_{\\xi}(s,a)-\\widehat{Q}_{\\xi}(s,a)\\right)^{2}}}\\\\ &{}&{\\stackrel{(272)}{\\leq}\\frac{2}{(1-\\gamma)^{2}}+\\frac{2C_{\\phi}^{2}}{\\mu(1-\\gamma)^{3}}+\\frac{C_{\\phi}^{4}}{\\mu^{2}(1-\\gamma)^{4}}}\\\\ &{}&{\\leq\\frac{2}{(1-\\gamma)^{2}}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "The above expression implies ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\Delta\\Delta^{\\top}\\right]=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu^{\\varepsilon}}^{\\pi}}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)^{2}\\phi(s,a)\\phi(s,a)^{\\top}|s,a\\right]}\\\\ &{\\quad\\quad\\quad\\quad=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{\\nu^{\\varepsilon}}^{\\pi}}\\left[\\mathbb{E}\\left[\\left(\\widehat{Q}_{\\xi}(s,a)-\\phi(s,a)^{\\top}w^{\\star}\\right)^{2}|s,a\\right]\\phi(s,a)\\phi(s,a)^{\\top}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\leq\\left(\\underbrace{\\sqrt{2}}_{\\textstyle{\\underbrace{1-\\gamma}}}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)\\right)\\mathbb{E}[\\phi(s,a)\\phi(s,a)^{\\top}]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Therefore, (iv) is verified. ", "page_idx": 55}, {"type": "text", "text": "Thus by (267), with stepsize $\\begin{array}{r}{\\beta=\\frac{1}{2C_{\\phi}^{2}}}\\end{array}$ , initialization $w_{0}=\\mathbf{0}$ and $K$ steps of critic updates, we have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\ell\\left(w_{\\mathrm{out}},Q_{\\xi},\\tilde{d}_{\\xi}\\right)\\right]-\\ell\\left(\\pmb{w}^{\\star},Q_{\\xi},\\tilde{d}_{\\xi}\\right)\\leq\\frac{4}{K}\\left(\\sigma\\sqrt{p}+C_{\\phi}\\left\\|\\pmb{w}^{\\star}\\right\\|_{2}\\right)^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\frac{4}{K}\\left(\\frac{\\sqrt{2p}}{1-\\gamma}\\left(\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)}+1\\right)+\\frac{C_{\\phi}^{2}}{\\mu(1-\\gamma)^{2}}\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "which gives (113). ", "page_idx": 55}, {"type": "text", "text": "G.6Proof of Lemma E.7 ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Proof of Lemma E.7. For notational simplicity we let $V^{\\xi},V^{\\xi^{\\prime}}$ denote $V^{f_{\\xi}},V^{f_{\\xi^{\\prime}}}$ , resp. Same as in Lemma F3, We define $\\xi^{(t)}=\\xi+t(\\xi^{\\prime}-\\bar{\\xi})$ and define $P_{t},M_{t},r_{t}$ by replacing $\\pi_{\\xi^{(t)}}$ with $f_{\\xi^{(t)}}$ in (243),(242) and (244), respectively. Define ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\bar{\\phi}_{\\xi}(s,a)=\\phi(s,a)-\\mathbb{E}_{a^{\\prime}\\sim f_{\\xi^{(t)}}}[\\phi(s,a^{\\prime})],\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "then we have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\frac{\\partial f_{\\xi}(a|s)}{\\partial\\xi}=f_{\\xi}(a|s)\\bar{\\phi}_{\\xi}(s,a)\\,.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Analogous to (252), we have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|\\frac{d P_{t}}{d t}x\\right\\|_{\\infty}\\leq\\operatorname*{max}_{s}\\sum_{a\\in\\mathcal{A}}\\sum_{s^{\\prime}\\in\\mathcal{S}}\\mathcal{P}(s^{\\prime}|s,a)\\left|\\frac{d\\pi_{\\xi^{(t)}}(a|s)}{d t}\\right|\\|x\\|_{\\infty}}}\\\\ &{=\\operatorname*{max}_{s}\\sum_{a\\in\\mathcal{A}}\\left|\\frac{d\\pi_{\\xi^{(t)}}(a|s)}{d t}\\right|\\|x\\|_{\\infty}}\\\\ &{\\leq2C_{\\phi}\\left\\|\\xi^{\\prime}-\\xi\\right\\|_{2}\\left\\|x\\right\\|_{\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where the last line follows is due to ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{a\\in A}\\left|\\frac{d f_{\\xi^{(t)}}(a|s)}{d t}\\right|=\\displaystyle\\sum_{a\\in A}\\left|\\left<\\frac{\\partial f_{\\xi^{(t)}}(a|s)}{\\partial\\xi^{(t)}},\\xi^{\\prime}-\\xi\\right>\\right|}\\\\ &{\\displaystyle=\\sum_{a\\in A}f_{\\xi^{(t)}}(a|s)\\left|\\left<\\bar{\\phi}_{\\xi}(s,a),\\xi^{\\prime}-\\xi\\right>\\right|}\\\\ &{\\displaystyle\\leq\\sum_{a\\in A}f_{\\xi^{(t)}}(a|s)\\left\\|\\bar{\\phi}_{\\xi}(s,a)\\right\\|_{2}\\left\\|\\xi^{\\prime}-\\xi\\right\\|_{2}}\\\\ &{\\leq2C_{\\phi}\\left\\|\\xi^{\\prime}-\\xi\\right\\|_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Same as (245) in Lemma F.3, we have ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\frac{d V^{\\xi^{(t)}}(s)}{d t}=\\gamma\\cdot e_{s}^{\\top}M_{t}\\frac{d P_{t}}{d t}M_{t}r_{t}+e_{s}^{\\top}M_{t}\\frac{d r_{t}}{d t}\\,.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "And similar to (249), we deduce ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left\\|\\frac{d r_{t}}{d t}\\right\\|_{\\infty}=\\operatorname*{max}_{s\\in\\mathcal{S}}\\left|\\frac{d r_{t}(s)}{d t}\\right|=\\operatorname*{max}_{s\\in\\mathcal{S}}\\left|\\left\\langle\\frac{\\partial f_{\\xi^{(t)}}(\\cdot|s)^{\\top}r(s,\\cdot)}{\\partial\\xi^{(t)}},\\xi^{\\prime}-\\xi\\right\\rangle\\right|}}\\\\ &{}&{=\\left|\\langle\\displaystyle\\sum_{a\\in\\mathcal{A}}f_{\\xi}(a|s)\\bar{\\phi}_{\\xi}(s,a)r(s,a),\\xi^{\\prime}-\\xi\\rangle\\right|}\\\\ &{}&{=\\displaystyle\\sum_{a\\in\\mathcal{A}}f_{\\xi}(a|s)r(s,a)\\left|\\langle\\bar{\\phi}_{\\xi}(s,a),\\xi^{\\prime}-\\xi\\rangle\\right|}\\\\ &{}&{\\le2C_{\\phi}\\left\\|\\xi^{\\prime}-\\xi\\right\\|_{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "which gives ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\left|e_{s}^{\\top}M_{t}\\frac{d r_{t}}{d t}\\right|\\leq\\frac{1}{1-\\gamma}\\left\\|\\frac{d r_{t}}{d t}\\right\\|_{\\infty}\\leq\\frac{2C_{\\phi}}{1-\\gamma}\\left\\|{\\pmb\\xi}^{\\prime}-{\\pmb\\xi}\\right\\|_{2}\\,.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Following the same steps in (247), we deduce ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\left|\\gamma\\cdot e_{s}^{\\top}M_{t}\\frac{d P_{t}}{d t}M_{t}r_{t}\\right|\\leq\\frac{2\\gamma C_{\\phi}}{(1-\\gamma)^{2}}\\left\\|{\\pmb\\xi}^{\\prime}-{\\pmb\\xi}\\right\\|_{2}\\,.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Combining the above two expressions (277) and (278) with (276), we deduce ", "page_idx": 56}, {"type": "equation", "text": "$$\n|V^{\\xi}(s)-V^{\\xi^{\\prime}}(s)|\\le\\frac{2C_{\\phi}(1+\\gamma)}{(1-\\gamma)^{2}}\\left\\|\\pmb{\\xi}^{\\prime}-\\pmb{\\xi}\\right\\|_{2}\\,,\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "which implies ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}:\\quad|Q^{\\xi}(s,a)-Q^{\\xi^{\\prime}}(s,a)|\\leq\\frac{2C_{\\phi}\\gamma(1+\\gamma)}{(1-\\gamma)^{2}}\\left\\|\\xi^{\\prime}-\\xi\\right\\|_{2}\\,.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "G.7 Proof of Lemma E.8 ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "This proof is inspired by the proof of $[\\mathrm{YDG^{+}}22]$ , Theorem 1]. To give the proof, we first introduce the following three-point descent lemma: ", "page_idx": 56}, {"type": "text", "text": "Lemma G.3 (Three-point descent lemma Lemma 6 in [Xia22]). Suppose that ${\\mathcal{C}}\\subset\\mathbb{R}^{m}$ is a closed convex set, $g:{\\mathcal{C}}\\to\\mathbb{R}$ is a proper, closed, convex function, $D_{h}(\\cdot,\\cdot)$ is the Bregman divergence generated by a function $h$ of Lengendretypeand rint domh $\\cap{\\mathcal{C}}\\neq\\emptyset$ .For any $x\\in$ rintdomh,let ", "page_idx": 56}, {"type": "equation", "text": "$$\nx^{+}\\in\\arg\\operatorname*{min}_{u\\in d o m h\\cap C}\\{f(u)+D_{h}(u,x)\\}\\,,\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "then $x^{+}\\in d o m h\\cap{\\mathcal{C}}$ and for any $u\\in d o m h\\cap{\\mathcal{C}}$ ,it holds that ", "page_idx": 56}, {"type": "equation", "text": "$$\nf(x^{+})+D_{h}(x^{+},x)\\leq f(u)+D_{h}(u,x)-D_{h}(u,x^{+})\\,.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Proof of Lemma $E.8.$ By the update rule (114) and the parameterization (24) we know know that ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\forall(s,a)\\in S\\times A:\\quad\\bar{f}^{(t+1)}(a|s)=\\frac{1}{Z^{(t)}(s)}f^{(t)}(a|s)\\exp\\left(\\alpha\\phi^{\\top}(s,a)\\hat{w}^{(t)}\\right),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where $Z^{(t)}(s)$ is a normaliation coefcient to ensure $\\textstyle\\sum_{a\\in A}f^{(t+1)}(s,a)=1$ for each $s\\in S$ Note that the above $\\pi^{(t+1)}$ could also be btained by a mirror descent update: ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\forall s\\in\\mathcal{S}:\\quad f^{(t+1)}(\\cdot|s)=\\arg\\operatorname*{min}_{g\\in\\Delta(\\mathcal{A})}\\left\\{-\\alpha\\langle\\Phi(s)\\hat{w}^{(t)},g\\rangle+D(g,f^{(t)}(\\cdot|s))\\right\\}\\,,\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where $\\Phi(s)\\in\\mathbb{R}^{|A|\\times p}$ is a matrix with rows $\\phi^{\\top}(s,a)\\in\\mathbb{R}^{p}$ for $a\\in A$ and $D(\\cdot,\\cdot)$ denotes the KL divergence defined in (109). ", "page_idx": 57}, {"type": "text", "text": "We apply the three-point descent lemma-Lemma G.3 with ${\\mathcal{C}}=\\Delta(A)$ \uff0c $f=-\\alpha\\langle\\Phi(s)\\hat{\\pmb w}^{(t)},\\cdot\\rangle$ and $h:\\bar{\\Delta}(\\bar{A})\\rightarrow\\mathbb{R}$ is the negative entropy with $\\begin{array}{r}{h(q)=\\sum_{a\\in\\mathcal{A}}q(a)\\log q(a)}\\end{array}$ and deduce that for any $q\\in\\Delta(A)$ , we have ", "page_idx": 57}, {"type": "equation", "text": "$$\n-\\alpha\\langle\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t+1)}(\\cdot|s)\\rangle+D\\left(\\bar{f}^{(t+1)}(\\cdot|s),\\bar{f}^{(t)}(\\cdot|s)\\right)\\leq-\\alpha\\langle\\Phi(s)\\hat{w}^{(t)},q\\rangle+D\\left(q,\\bar{f}^{(t)}(\\cdot|s)\\right)-D\\left(q,\\bar{f}^{(t)}(\\cdot|s)\\right),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Rearranging terms and dividing both sides by $-\\alpha$ we obtain ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t+1)}(\\cdot|s)-q\\rangle-\\frac{1}{\\alpha}D\\left(\\bar{f}^{(t+1)}(\\cdot|s),\\bar{f}^{(t)}(\\cdot|s)\\right)\\geq-\\frac{1}{\\alpha}D\\left(q,\\bar{f}^{(t)}(\\cdot|s)\\right)+\\frac{1}{\\alpha}D\\left(q,\\bar{f}^{(t+1)}(\\cdot|s)\\right)\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Let $q=\\bar{f}^{(t)}(\\cdot|s)$ and $\\pi^{\\star}(\\cdot|s)$ ,resp., we have the following two inequalities: ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t+1)}(\\cdot|s)-\\bar{f}^{(t)}(\\cdot|s)\\rangle\\geq\\frac{1}{\\alpha}D\\left(\\bar{f}^{(t+1)}(\\cdot|s),\\bar{f}^{(t)}(\\cdot|s)\\right)+\\frac{1}{\\alpha}D\\left(\\bar{f}^{(t)}(\\cdot|s),\\bar{f}^{(t+1)}(\\cdot|s)\\right)\\geq0\\,.\n$$", "text_format": "latex", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\langle\\Phi(s)\\hat{\\pmb w}^{(t)},\\bar{f}^{(t+1)}(\\cdot|s)-\\bar{f}^{(t)}(\\cdot|s)\\right\\rangle+\\left\\langle\\Phi(s)\\hat{\\pmb w}^{(t)},\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\right\\rangle}\\\\ {\\displaystyle\\geq-\\frac{1}{\\alpha}D\\left(\\pi^{\\star}(\\cdot|s),\\bar{f}^{(t)}(\\cdot|s)\\right)+\\frac{1}{\\alpha}D\\left(\\pi^{\\star}(\\cdot|s),\\bar{f}^{(t+1)}(\\cdot|s)\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Taking expectation w.r.t. distribution $d^{\\star}$ on both sides of (285), we arrive at ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\mathbb{\\bar{C}}_{s\\sim d^{\\star}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t+1)}(\\cdot|s)-\\bar{f}^{(t)}(\\cdot|s)\\rangle\\right]+\\mathbb{E}_{s\\sim d^{\\star}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]\\geq\\frac{1}{\\alpha}(D_{\\star}^{(t+1)}-D_{\\star}^{(t+1)}).\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "To simplify the notation we let $\\bar{Q}^{(t)}$ and ${\\bar{V}}^{(t)}$ denote $Q^{\\bar{f}^{(t)}}$ and $V^{\\bar{f}^{(t)}}$ , respectivly. Note that the fist expectation in the above expression (286) could be upper bounded as follows: ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\mathbb{E}_{s\\sim d^{\\delta}}\\left[\\langle\\Phi(s)\\dot{\\Phi}^{(t)},\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle\\right]}\\\\ &{=\\displaystyle\\sum_{s\\in\\mathcal{S}}d^{\\dagger^{*}}(s)\\langle\\Phi(s)\\dot{\\Phi}^{(t)},\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle}\\\\ &{\\quad\\displaystyle=\\sum_{s\\in\\mathcal{S}}\\frac{d^{\\dagger^{*}}(s)}{d^{(t+1)}(s)}d^{f^{(t+1)}}(s)\\langle\\Phi(s)\\dot{\\Phi}^{(t)},\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle}\\\\ &{\\quad\\displaystyle\\leq\\theta\\rho\\sum_{s\\in\\mathcal{S}}d^{\\bar{f}^{(t+1)}}(s)\\langle\\Phi(s)\\dot{\\Phi}^{(t)},\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle}\\\\ &{=\\displaystyle\\theta_{\\rho}\\sum_{s\\in\\mathcal{S}}d^{\\bar{f}^{(t+1)}}(s)\\langle\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle+\\theta\\rho\\sum_{s\\in\\mathcal{S}}d^{\\bar{f}^{(t+1)}}(s)\\langle\\bar{\\Phi}(s)\\dot{\\Phi}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle}\\\\ &{=\\displaystyle\\theta_{\\rho}(1-\\gamma)\\left(\\bar{V}^{(t+1)}(\\rho)-\\bar{V}^{(t)}(\\rho)\\right)+\\theta_{\\rho}\\sum_{s\\in\\mathcal{S}}d^{\\bar{f}^{(t+1)}}(s)\\langle\\bar{\\Phi}(s)\\dot{\\Phi}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where the first inequality uses (??) and the definition of $\\vartheta_{\\rho}$ (107) and the last line follows from (260) in Lemma G.1. We separate the second term of the last line into four terms as follows: ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in S}d^{\\tilde{f}^{(t+1)}}(s)\\langle\\bar{\\Phi}(s)\\hat{w}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t+1)}(\\cdot\\vert s)-\\bar{f}^{(t)}(\\cdot\\vert s)\\rangle}\\\\ &{=\\displaystyle\\sum_{\\underbrace{s\\in S}_{S}=\\epsilon,A}d^{\\tilde{f}^{(t+1)}}(s)\\bar{f}^{(t+1)}(a\\vert s)\\phi^{\\top}(s,a)(\\hat{w}^{(t)}-\\hat{w}_{\\star}^{(t)})+\\sum_{s\\in S}\\sum_{a\\in A}d^{\\tilde{f}^{(t+1)}}(s)\\bar{f}^{(t+1)}(a\\vert s)\\left(\\hat{\\phi}^{\\top}(s,a)\\hat{w}^{(t)}-\\hat{\\phi}^{(t)}(s)\\right)}\\\\ &{\\quad+\\displaystyle\\sum_{\\underbrace{s\\in S}_{S}=\\epsilon,A}d^{\\tilde{f}^{(t+1)}}(s)\\bar{f}^{(t)}(a\\vert s)\\phi^{\\top}(s,a)(\\hat{w}_{\\star}^{(t)}-\\hat{w}^{(t)})+\\sum_{s\\in S}\\sum_{a\\in A}d^{\\tilde{f}^{(t+1)}}(s)\\bar{f}^{(t)}(a\\vert s)\\left(\\bar{Q}^{(t)}(s,a)-\\hat{w}^{(t)}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "Applying again Lemma G.1, we deduce the equivalent form of the second expectation in (286) as follows: ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~\\mathbb{E}_{s\\sim d^{*}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)},\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]}\\\\ &{=\\mathbb{E}_{s\\sim d^{*}}\\left[\\langle\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]+\\mathbb{E}_{s\\sim d^{*}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]}\\\\ &{=(1-\\gamma)\\left(\\bar{V}^{(t)}(\\rho)-V^{\\pi^{\\star}}(\\rho)\\right)+\\mathbb{E}_{s\\sim d^{*}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]\\;,\\;\\;(289)}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where the second term of the last line could be decomposed into the following terms: ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underbrace{\\mathbb{E}_{s\\sim d^{*}}\\left[\\langle\\Phi(s)\\hat{w}^{(t)}-\\bar{Q}^{(t)}(s,\\cdot),\\bar{f}^{(t)}(\\cdot|s)-\\pi^{\\star}(\\cdot|s)\\rangle\\right]}_{\\underbrace{s\\in S}_{a\\in A}}}\\\\ &{\\underbrace{=\\displaystyle\\sum_{s\\ll S}\\sum_{a\\in A}d^{\\star}(s)\\bar{f}^{(t)}(a|s)\\phi^{\\top}(s,a)(\\hat{w}^{(t)}-\\hat{w}_{\\star}^{(t)})}_{(A)}+\\underbrace{\\sum_{s\\in S}\\sum_{a\\in A}d^{\\star}(s)\\bar{f}^{(t)}(a|s)\\left(\\phi^{\\top}(s,a)\\hat{w}_{\\star}^{(t)}-\\bar{Q}^{(t)}(s,a)\\hat{w}_{\\star}^{(t)}-\\hat{w}_{\\star}^{(t)}\\right)}_{(B)}}\\\\ &{\\quad+\\displaystyle\\sum_{s\\in S}\\sum_{a\\in A}d^{\\star}(s)\\pi^{\\star}(a|s)\\phi^{\\top}(s,a)(\\hat{w}_{\\star}^{(t)}-\\hat{w}^{(t)})+\\displaystyle\\sum_{s\\in S}\\sum_{a\\in A}d^{\\star}(s)\\pi^{\\star}(a|s)\\left(\\bar{Q}^{(t)}(s,a)-\\phi^{\\top}(s,a)\\hat{w}_{\\star}^{(t)}-\\bar{Q}^{(t)}(s,a)\\hat{w}_{\\star}^{(t)}\\right)}_{\\displaystyle\\sum_{s\\in S}s\\in A},}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "Plugging (288), (290) into (287) and (289), resp., and making use of (286), we have ", "page_idx": 58}, {"type": "text", "text": "$\\begin{array}{r l}&{\\partial_{\\rho}(1-\\gamma)\\left(V^{(t+1)}(\\rho)-V^{(t+1)}(\\rho)\\right)+(1-\\gamma)\\left(V^{(t)}(\\rho)-V^{\\ast}(\\rho)\\right)}\\\\ &{+\\rho_{\\gamma}\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon,\\varepsilon}(J^{(t+1)}(\\alpha)\\beta)^{\\varepsilon(t+1)}(\\alpha)\\beta^{\\varepsilon}(s,\\alpha)(w^{(t)}-\\omega_{\\gamma}^{(t)})+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon}\\displaystyle\\sum_{\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime\\prime}+1}(s)\\beta^{\\gamma(t+1)}(\\alpha)s\\left(\\rho^{\\gamma}\\right.}\\\\ &{\\left.+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime\\prime}+1}(s)\\beta^{\\gamma(t)}(\\alpha)s)\\overline{{\\gamma}}(s,\\alpha)(w^{(t)}-w^{(t)})+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime\\prime}+1}(s)\\beta^{\\gamma(t)}(\\alpha)s\\left(\\beta^{\\gamma(t)}(s,\\alpha)-\\alpha\\right)}\\\\ &{+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon}d^{t^{\\prime\\prime}+1}(s)\\beta^{\\gamma(t)}(\\alpha)s)\\overline{{\\gamma}}(s,\\alpha)(w^{(t)}-w^{(t)})+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}\\displaystyle\\sum_{\\varepsilon\\leq\\varepsilon}d^{t^{\\prime\\prime}+1}(s)\\beta^{\\gamma(t)}(\\alpha)s\\left(\\beta^{\\gamma}(s,\\alpha)\\right)\\overline{{\\gamma}}(s,\\alpha)(w^{(t)}-\\beta^{(t)})}\\\\ &{+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime}}(s)\\beta^{\\gamma(t)}(\\alpha)s\\overline{{\\gamma}}(s,\\alpha)(w^{(t)}-w^{(t)})+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime}}(s)\\beta^{\\gamma(t)}(\\alpha)s\\left(\\beta^{\\gamma}(s,\\alpha)_{\\gamma}^{(t)}-\\beta^{\\gamma(t)}(s,\\alpha)\\right)}\\\\ &{+\\displaystyle\\sum_{\\leq\\varepsilon\\leq\\varepsilon+\\varepsilon}d^{t^{\\prime}}(s)\\beta^{\\gamma(t)}(s,\\alpha)(w_{\\gamma}^{(t)}-w^{(t)})+\\displaystyle\\sum_{\\leq $ (s,a)\u7684 -@()(s,a) s, a) () ", "page_idx": 58}, {"type": "text", "text": "Below we upper bound $|(I)|-|(I V)|$ and $|(A)|{-}|(D)|$ ", "page_idx": 59}, {"type": "text", "text": "For any $t\\in\\mathbb{N}$ and $n\\in[N]$ , we define matrix $\\Sigma_{\\tilde{d}_{n}^{(t)}}\\in\\mathbb{R}^{p\\times p}$ as ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\Sigma_{\\tilde{d}_{n}^{(t)}}:=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\phi(s,a)\\phi^{\\top}(s,a)\\right]\\,,\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "and we define ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\varepsilon_{\\mathrm{stat},n}^{(t)}:=\\ell\\left(\\pmb{w}_{n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)-\\ell\\left(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)\\,,}\\\\ &{\\varepsilon_{\\mathrm{approx},n}^{(t)}:=\\ell\\left(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "then for all $n\\in[N]$ , by Assumption E.2 and Assumption 4.2 we have ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\varepsilon_{\\mathrm{stat},n}^{(t)}\\right]\\leq\\varepsilon_{\\mathrm{stat}}^{n}\\,,\\quad\\mathrm{and}\\quad\\mathbb{E}\\left[\\varepsilon_{\\mathrm{approx},n}^{(t)}\\right]\\leq\\varepsilon_{\\mathrm{approx}}^{n}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "We let we have $\\begin{array}{r}{\\bar{\\varepsilon}_{\\mathrm{stat}}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}{\\varepsilon}_{\\mathrm{stat},n}^{(t)}}\\end{array}$ and $\\begin{array}{r}{\\bar{\\varepsilon}_{\\mathrm{approx}}^{(t)}:=\\frac{1}{N}\\sum_{n=1}^{N}{\\varepsilon_{\\mathrm{approx},n}^{(t)}}}\\end{array}$ By Cauchy-Shwartz's inequalty ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle(I)\\big|}&{\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\sum_{(s,a)\\in S\\times A}d^{f^{(t+1)}}(s)\\bar{f}^{(t+1)}(a|s)|\\phi^{\\top}(s,a)(w_{n}^{(t)}-w_{\\cdot,n}^{(t)})|}\\\\ &{\\displaystyle~~\\leq\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\sqrt{\\sum_{(s,a)\\in S\\times A}\\frac{(d^{f^{(t+1)}}(s))^{2}\\left(\\bar{f}^{(t+1)}(a|s)\\right)^{2}}{\\bar{d}_{n}^{\\top}\\{s,a\\}}\\cdot\\sum_{(s,a)\\in S\\times A}\\bar{d}_{n}^{(t)}(s,a)\\left(\\phi^{\\top}(s,a)(w_{n}^{(t)}-w_{n-1}^{(t)})\\right)}}\\\\ &{\\displaystyle~~=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\sqrt{\\mathbb{E}_{(s,a)\\sim d_{n}^{(t)}}\\left[\\left(\\frac{(d^{f^{(t+1)}}(s))\\left(\\bar{f}^{(t+1)}(a|s)\\right)}{\\bar{d}_{n}^{\\top}\\{s,a\\}}\\right)^{2}\\right]\\left\\Vert w_{n}^{(t)}-w_{\\cdot,n}^{(t)}\\right\\Vert_{\\Sigma_{d_{0}^{(t)}}}^{2}}}\\\\ &{\\displaystyle~\\leq\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\sqrt{C_{\\nu}\\left\\|w_{n}^{(t)}-w_{\\cdot,n}^{(t)}\\right\\|_{\\Sigma_{d_{0}^{(t)}}}^{2}}}\\\\ &{\\displaystyle~\\leq\\frac{1}{N}\\displaystyle\\sum_{m=1}^{N}\\sqrt{C_{\\nu}\\varepsilon_{\\mathrm{s},a}^{(t)}}\\leq\\sqrt{C_{\\nu}\\varepsilon_{\\mathrm{s},a}^{(t)}},}\\end{array}\\right.\\quad\\mathrm{(296)}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "where the third inequality follows from Assumption 4.3, the last inequality uses Jensen's inequality, and the penultimate inequality by Assumption E.2 and by noticing that for all $\\pmb{w}\\in\\mathbb{R}^{p}$ ,wehave ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\ell\\left(w,Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)-\\ell\\left(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)}\\\\ &{=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w-\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}+\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}(s,a)\\right)^{2}\\right]-\\ell\\left(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)}\\\\ &{=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w-\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}\\right)^{2}\\right]+2\\left(w-w_{\\star,n}^{(t)}\\right)^{\\top}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}\\right)\\right]}\\\\ &{=\\left\\Vert w-w_{\\star,n}^{(t)}\\right\\Vert_{\\Sigma_{\\tilde{d}_{n}^{(t)}}}+\\left(w-w_{\\star,n}^{(t)}\\right)^{\\top}\\nabla_{w}\\ell\\left(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)}\\\\ &{\\geq\\left\\Vert w-w_{\\star,n}^{(t)}\\right\\Vert_{\\Sigma_{\\tilde{d}_{n}^{(t)}}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "where the last line follws from the first-order optimality condition for the minimum point $w_{\\star,n}^{(t)}\\in$ $\\arg\\operatorname*{min}_{w}\\ell\\left(\\pmb{w},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)$ ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\forall w\\in\\mathbb{R}^{p}:\\quad\\left(w-w_{\\star,n}^{(t)}\\right)^{\\top}\\nabla_{w}\\ell\\left(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)}\\right)\\geq0.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "$|(I)|$ $\\bar{f}^{(t+1)}$ ${\\bar{f}}^{(t)}$ $\\pi^{\\star}$ $d^{\\bar{f}^{(t+1)}}$ into $d^{\\star}$ , we obtain the same upper bound for $|(I I I)|,|(A)|$ and $|(C)|$ ,i.e., ", "page_idx": 59}, {"type": "equation", "text": "$$\n|(I I I)|,|(A)|,|(C)|\\leq\\sqrt{C_{\\nu}\\bar{\\varepsilon}_{\\mathrm{stat}}^{(t)}}\\,.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Now we upper bound $|(I I)|$ as follows: ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle[I I]\\big|}&{\\leq\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{(s_{i})\\in\\mathcal{S}\\times\\mathcal{A}}\\displaystyle\\int_{0}^{t(\\tau+1)}(s)\\bar{f}^{(t+1)}(a|s)\\left(\\big|\\bar{\\rho}^{\\top}(s,a)w_{s,n}^{(t)}-Q_{n}^{(t)}(s,a)\\big|+|Q_{n}^{(t)}(s,a)-\\bar{Q}^{(t)}(s,a)|\\right.}\\\\ &{\\leq\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\sqrt{\\sum_{(s_{i})\\in\\mathcal{S}\\times\\mathcal{A}}\\displaystyle\\frac{(d\\bar{f}^{(t+1)}(s))^{2}\\left(\\bar{f}^{(t+1)}(a|s)\\right)^{2}}{\\bar{d}_{n}^{(t)}(s,a)}}.}\\\\ &{\\qquad\\cdot\\sqrt{\\sum_{(s,a)\\in\\mathcal{S}\\times\\mathcal{A}}\\displaystyle\\frac{\\bar{d}^{(t)}(s,a)}{\\bar{d}_{n}(s,a)}\\left(\\left(\\bar{\\rho}^{\\top}(s,a)w_{s,n}^{(t)}-Q_{n}^{(t)}(s,a)\\right)^{2}+\\left(Q_{n}^{(t)}(s,a)-\\bar{Q}^{(t)}(s,a)\\right)^{2}\\right)}}\\\\ &{=\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\sqrt{\\mathbb{E}_{(s,a)\\sim\\mathcal{A}_{n}^{(t)}}\\left[\\left(\\frac{(d\\bar{f}^{(t+1)}(s))}{\\bar{d}_{n}^{(t)}(s,a)}\\|\\bar{f}^{(t+1)}(a|s)\\right)\\right]^{2}}\\left[\\cdot2\\left(\\varepsilon_{\\sf m m,n}^{(t)}+L_{Q}^{2}\\right\\|\\xi_{n}^{(t)}-\\bar{\\xi}^{(t)}\\right\\|_{2,2}^{2}\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\leq\\sqrt{2C_{p}\\left(\\frac{\\varepsilon(0)}{\\bar{\\varepsilon}^{(t)}\\oplus\\mathcal{A}}-\\frac{L_{Q}^{2}}{N}\\|\\xi^{(t)}-1(\\bar{\\xi}^{(t)})\\|^{2}\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where $L_{Q}$ is defined in Lemma E.7, the second line uses Cauchy-Schwartz's inequality and Young's inequality (117) and the last inequality uses Assumption 4.3 and Jensen's inequality. ", "page_idx": 60}, {"type": "text", "text": "Aal into , we obtain the same upper bound for $|(I V)|,|(B)|$ and $|(D)|$ ,i.e, ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\left|(I V)|,|(B)|,|(D)|\\right|\\leq\\sqrt{2C_{\\nu}\\left(\\bar{\\varepsilon}_{\\mathrm{approx}}^{(t)}+\\frac{L_{Q}^{2}}{N}\\left\\|\\pmb{\\xi}^{(t)}-\\mathbf{1}(\\bar{\\xi}^{(t)})^{\\top}\\right\\|_{\\mathrm{F}}^{2}\\right)}\\,.\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Plugging (296),(298),(299),(300) into (291) and dividing both sides by $(1-\\gamma)$ yield ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\diamond\\left(\\delta^{(t+1)}-\\delta^{(t)}\\right)+\\delta^{(t)}\\leq\\frac{D_{\\star}^{(t)}}{(1-\\gamma)\\alpha}-\\frac{D_{\\star}^{(t+1)}}{(1-\\gamma)\\alpha}+\\frac{2\\sqrt{C_{\\nu}}(\\vartheta+1)}{1-\\gamma}\\left(\\sqrt{\\tilde{\\varepsilon}_{\\mathrm{sat}}^{(t)}}+\\sqrt{2\\left(\\tilde{\\varepsilon}_{\\mathrm{sprox}}^{(t)}+\\frac{L_{Q}^{2}}{N}\\left\\|\\xi^{(t)}-\\tilde{\\varepsilon}_{\\mathrm{sbit}}^{(t)}\\right\\|\\right)}\\right).\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Taking expectation on both sides of the above expression and making use of the simple fact that ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[{\\sqrt{x}}\\right]\\leq{\\sqrt{\\mathbb{E}[x]}}\\,,\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "we reach the conclusion (123). ", "page_idx": 60}, {"type": "text", "text": "G.8Proof of Lemma E.9 ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Proof of Lemma $E.9.$ For any $\\zeta>0$ , by the actor update rule (34) and (114) we have that ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\xi^{(t+1)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t+1)\\top}\\right|\\right|_{\\mathrm{F}}^{2}=\\left\\|\\boldsymbol{W}(\\xi^{(t)}+\\alpha\\boldsymbol{h}^{(t)})-\\mathbf{1}_{N}(\\bar{\\xi}^{(t)}+\\alpha\\hat{\\boldsymbol{w}}^{(t)})^{\\top}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq(1+\\zeta)\\sigma^{2}\\left\\|\\xi^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+\\alpha^{2}(1+1/\\zeta)\\sigma^{2}\\left\\|\\boldsymbol{h}^{(t)}-\\mathbf{1}_{N}\\hat{\\boldsymbol{w}}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where the last line follows from Young's inequality (116) and (11). By the gradient tracking step (33) , Young's inequality (116) and (11), we have ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|h^{(t+1)}-\\mathbf{1}\\hat{w}^{(t+1)\\top}\\right|\\biggr\\|_{\\mathrm{F}}^{2}=\\left\\|\\mathbf{W}(h^{(t)}+w^{(t+1)}-w^{(t)})-\\mathbf{1}\\hat{w}^{(t)\\top}+\\mathbf{1}(\\hat{w}^{(t)\\top}-\\hat{w}^{(t+1)\\top})\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\left\\|\\mathbf{W}h^{(t)}-\\mathbf{1}\\hat{w}^{(t)\\top}+\\mathbf{W}(w^{(t+1)}-w^{(t)})-\\mathbf{1}(\\hat{w}^{(t+1)\\top}-\\hat{w}^{(t)\\top})\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq(1+\\zeta)\\sigma^{2}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\hat{w}^{(t)\\top}\\right\\|+(1+1/\\zeta)\\sigma^{2}\\left\\|w^{(t+1)}-w^{(t)}-\\mathbf{1}(\\hat{w}^{(t+1)}}\\\\ &{\\qquad\\qquad\\leq(1+\\zeta)\\sigma^{2}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\hat{w}^{(t)\\top}\\right\\|+(1+1/\\zeta)\\sigma^{2}\\left\\|w^{(t+1)}-w^{(t)}\\right\\|_{\\mathrm{F}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where the last inequality follows from the fact ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|w^{(t+1)}-w^{(t)}-\\mathbf{1}(\\hat{w}^{(t+1)\\top}-\\hat{w}^{(t)\\top})\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{=\\left\\|w^{(t+1)}-w^{(t)}\\right\\|_{\\mathrm{F}}^{2}+N\\left\\|\\hat{w}^{(t+1)}-\\hat{w}^{(t)}\\right\\|_{2}^{2}-2\\displaystyle\\sum_{n=1}^{N}\\langle w_{n}^{(t+1)}-w_{n}^{(t)},\\hat{w}^{(t+1)}-\\hat{w}^{(t)}\\rangle}\\\\ &{=\\left\\|w^{(t+1)}-w^{(t)}\\right\\|_{\\mathrm{F}}^{2}-N\\left\\|\\hat{w}^{(t+1)}-\\hat{w}^{(t)}\\right\\|_{2}^{2}}\\\\ &{\\leq\\left\\|w^{(t+1)}-w^{(t)}\\right\\|_{\\mathrm{F}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Then for any $n\\in[N]$ $t\\in\\mathbb{N}$ and $\\pmb{w}\\in\\mathbb{R}^{p}$ , we have ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ell(w,Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})-\\ell(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})}\\\\ &{=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w-\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}+\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}(s,a)\\right)^{2}\\right]-\\ell(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})}\\\\ &{=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w-\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}\\right)^{2}\\right]+2(w-w_{\\star,n}^{(t)})^{\\top}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}\\left[\\left(\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}\\right)^{2}\\right]}\\\\ &{=\\left\\|w-w_{\\star,n}^{(t)}\\right\\|_{\\Sigma_{\\tilde{d}_{n}^{(t)}}}^{2}+(w-w_{\\star,n}^{(t)})^{\\top}\\nabla_{w}\\ell(w_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})}\\\\ &{\\geq\\left\\|w-w_{\\star,n}^{(t)}\\right\\|_{\\Sigma_{\\tilde{d}_{n}^{(t)}}}^{2}}\\\\ &{\\geq(1-\\gamma)\\mu\\left\\|w-w_{\\star,n}^{(t)}\\right\\|_{\\Sigma_{\\tilde{d}_{n}^{(t)}}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where the penultmate lne folws fromthefrst-orderptimality conditions for the ptma $\\mathbf{\\boldsymbol{w}}_{\\star,n}^{(t)}$ ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\forall\\pmb{w}\\in\\mathbb{R}^{p}:\\quad(\\pmb{w}-\\pmb{w}_{\\star,n}^{(t)})^{\\top}\\nabla_{w}\\ell(\\pmb{w}_{\\star,n}^{(t)},Q_{n}^{(t)},\\tilde{d}_{n}^{(t)})\\geq0\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "and the last line is by Assumption 4.1 and (??). ", "page_idx": 61}, {"type": "text", "text": "Note that ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ \\ell(w_{\\star,n}^{(t)},Q_{n}^{(t+1)},\\tilde{d}_{n}^{(t+1)})}\\\\ &{=\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t+1)}}\\left[(\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t+1)}(s,a))^{2}\\right]}\\\\ &{\\le2\\displaystyle\\sum_{(s,a)\\in S\\times A}\\tilde{d}_{n}^{(t)}(s,a)\\displaystyle\\frac{\\tilde{d}_{n}^{(t+1)}(s,a)}{\\tilde{d}_{n}^{(t)}(s,a)}(\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}(s,a))^{2}+2\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t+1)}}(Q_{n}^{(t+1)}(s,a)-Q_{n}^{(t)}(s,a))}\\\\ &{\\le2C_{\\nu}\\mathbb{E}_{(s,a)\\sim\\tilde{d}_{n}^{(t)}}(\\phi^{\\top}(s,a)w_{\\star,n}^{(t)}-Q_{n}^{(t)}(s,a))^{2}+2L_{Q}\\left\\lVert\\xi_{n}^{(t+1)}-\\xi_{n}^{(t)}\\right\\rVert_{2}^{2}}\\\\ &{\\le2C_{\\nu}\\varepsilon_{\\mathrm{appon}}^{n}+2L_{Q}^{2}\\left\\lVert\\xi_{n}^{(t+1)}-\\xi_{n}^{(t)}\\right\\rVert_{2}^{2},}&{\\quad{\\scriptstyle(306)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where the second inequality uses Assumption 4.3 and Lemma E.7, and the last line uses Assumption 4.2. ", "page_idx": 61}, {"type": "text", "text": "The above equation (306) together with (304) gives ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|w_{\\star}^{(t+1)}-w_{\\star}^{(t)}\\right\\|_{\\mathrm{F}}^{2}=\\displaystyle\\sum_{n=1}^{N}\\left\\|w_{\\star,n}^{(t+1)}-w_{\\star,n}^{(t)}\\right\\|_{2}^{2}}\\\\ &{\\leq\\displaystyle\\frac{1}{(1-\\gamma)\\mu}\\sum_{n=1}^{N}\\left(\\ell(w_{\\star,n}^{(t)},Q_{n}^{(t+1)},\\tilde{d}_{n}^{(t+1)})-\\ell(w_{\\star,n}^{(t+1)},Q_{n}^{(t+1)},\\tilde{d}_{n}^{(t+1)})\\right)}\\\\ &{\\leq\\displaystyle\\frac{2}{(1-\\gamma)\\mu}\\left(C_{\\nu}\\sum_{n=1}^{N}\\varepsilon_{\\mathrm{approx}}^{n}+L_{Q}^{2}\\left\\|\\xi^{(t+1)}-\\xi^{(t)}\\right\\|_{\\mathrm{F}}^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where $\\pmb{w}_{\\star}^{(t)}:=(\\pmb{w}_{1}^{(t)},\\cdot\\cdot\\cdot\\,,\\pmb{w}_{N}^{(t)})^{\\top},\\forall t.$ ", "page_idx": 61}, {"type": "text", "text": "Also note that by Assumption E.2 and (304) we have ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\forall t\\in\\mathbb{N}:\\quad\\left\\|w^{(t)}-w_{\\star}^{(t)}\\right\\|_{\\mathrm{F}}^{2}\\leq\\frac{\\sum_{n=1}^{N}\\varepsilon_{\\mathrm{stat}}^{n}}{(1-\\gamma)\\mu}.\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Therefore, by (306) and (308) we have ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|w^{(t+1)}-w^{(t)}\\right\\|_{\\mathrm{F}}^{2}\\leq3\\left(\\left\\|w^{(t+1)}-w_{\\star}^{(t+1)}\\right\\|_{\\mathrm{F}}^{2}+\\left\\|w_{\\star}^{(t+1)}-w_{\\star}^{(t)}\\right\\|_{\\mathrm{F}}^{2}+\\left\\|w^{(t)}-w_{\\star}^{(t)}\\right\\|_{\\mathrm{F}}^{2}\\right)}\\\\ {\\leq\\frac{6}{(1-\\gamma)\\mu}\\left(N(C_{\\nu}\\bar{\\varepsilon}_{\\mathrm{appox}}+\\bar{\\varepsilon}_{\\mathrm{stal}})+L_{Q}^{2}\\left\\|\\xi^{(t+1)}-\\xi^{(t)}\\right\\|_{\\mathrm{F}}^{2}\\right).\\qquad\\qquad(1-\\gamma)\\mu\\leq N,}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "where the first inequality uses Young's inequality (117) ", "page_idx": 62}, {"type": "text", "text": "Note that by the update rule (34), the double stochasticity of the mixing matrix $W$ and the consensus property (11) we have ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\xi^{(t+1)}-\\xi^{(t)}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{=\\left\\|W(\\xi^{(t)}+\\alpha h^{(t)})-\\xi^{(t)}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{=\\left\\|(W-I)(\\xi^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top})+\\alpha(W h^{(t)}-\\mathbf{1}_{N}\\bar{w}^{(t)\\top})+\\alpha\\mathbf{1}(\\hat{w}^{(t)}-\\hat{w}_{\\star}^{(t)\\top})^{\\top}+\\mathbf{1}(\\hat{w}_{\\star}^{(t)})^{\\top}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\leq16\\left\\|\\xi^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+4\\alpha^{2}\\sigma^{2}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\hat{w}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+4\\alpha^{2}N\\left\\|\\hat{w}^{(t)}-\\hat{w}_{\\star}^{(t)}\\right\\|_{2}^{2}+4\\alpha^{2}N\\left\\|\\hat{w}_{\\star}^{(t)}\\right\\|_{2}^{2}}\\\\ &{\\leq16\\left\\|\\xi^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+4\\alpha^{2}\\sigma^{2}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\hat{w}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+4\\alpha^{2}\\displaystyle\\sum_{n=1}^{N}\\left\\|w_{n}^{(t)}-w_{\\star,n}^{(t)}\\right\\|_{2}^{2}+4\\alpha^{2}\\displaystyle\\sum_{n=1}^{N}\\left\\|w_{\\star,n}^{(t)}\\right\\|_{n}^{2}}\\\\ &{\\leq16\\left\\|\\xi^{(t)}-\\mathbf{1}_{N}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+4\\alpha^{2}\\sigma^{2}\\left\\|h^{(t)}-\\mathbf{1}_{N}\\hat{w}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+\\frac{4\\alpha^{2}N\\bar{\\xi}_{\\mathrm{M}}}{(1-\\gamma\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "where the penultimate line uses Jensen's inequality and the last line follows from (304), Assumption E.2 and (271). ", "page_idx": 62}, {"type": "text", "text": "Combining (310) and (309) with (302), we deduce ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|h^{(t+1)}-\\mathbf{1}\\hat{w}^{(t+1)\\top}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\leq(1+1/\\zeta)\\frac{96\\sigma^{2}L_{Q}^{2}}{(1-\\gamma)\\mu}\\left\\|\\xi^{(t)}-\\mathbf{1}\\bar{\\xi}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}+\\sigma^{2}\\left(1+\\zeta+(1+1/\\zeta)\\frac{24L_{Q}^{2}\\alpha^{2}}{(1-\\gamma)\\mu}\\right)\\left\\|h^{(t)}-\\mathbf{1}\\hat{w}^{(t)\\top}\\right\\|_{\\mathrm{F}}^{2}}\\\\ &{\\quad+\\,(1+1/\\zeta)\\frac{6\\sigma^{2}}{(1-\\gamma)\\mu}\\left(N(\\bar{\\varepsilon}_{\\mathrm{sut}}+C_{\\nu}\\bar{\\varepsilon}_{\\mathrm{appox}})+4L_{Q}^{2}\\left(\\frac{\\alpha^{2}N\\bar{\\varepsilon}_{\\mathrm{sut}}}{(1-\\gamma)\\mu}+\\frac{\\alpha^{2}N C_{\\phi}^{2}}{\\mu^{2}(1-\\gamma)^{2}}\\right)\\right).\\qquad(311)}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Finally, (124) follows from taking expectations on both sides of (301) and (311). ", "page_idx": 62}, {"type": "text", "text": "H  Numerical experiments ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Experimental setup. We study the empirical performance of FedNPG (Algorithm 1) and entropyregularized FedNPG (Algorithm 2) on a $K\\times K$ GridWorld problem. To be specific, the collective goal of $N$ agents is to learn a global optimal policy to follow a predetermined path which starts at the top left corner and ends at the bottom right corner. However, each agent only has access to partial information about the whole map: in figure 1 (where we take $N=3$ and $K=9$ as an example), agent $n$ explores on map $n$ \uff0c $n\\in[N]$ . After taking an action, only when the agent is at the shaded positions can it get reward 1, otherwise it gets O. We stipulate the action space of all agents to be $\\bar{\\mathcal{A}}=\\{\\mathrm{right},\\mathrm{down}\\}$ , i.e. movement is allowed only to the right or down. If an agent takes an action that will lead it out of the boarder of the map, we stipulate the agent's state doesn't change and receive reward O. Each agent starts at the top left corner. To learn a shared policy to follow the path, we aim to maximize the average value function of all agents. ", "page_idx": 62}, {"type": "text", "text": "Results. In the following we discuss the empirical results of our algorithms. In all the experiments, we fix the discounted factor $\\gamma=0.99$ . In our experiments, we also don't require the mixing matrix to strictly adhere to Assumption 3.1. In Figure 2, we validate the effectiveness of vanilla FedNPG and entropy-regularized FedNPG across different map size $K$ , where we set $\\tau=0$ ,0.005,0.05, $\\eta=0.1$ $N=10$ , and use a standard ring graph where agent $n$ receives information from agent $n+1$ for $n\\in[N-1]$ , and agent $N$ receives information from agent 1, and we set all the weights on each edge of the communication graph to be 0.5. The corresponding mixing matrix of the standard ring graph is as follows: ", "page_idx": 62}, {"type": "image", "img_path": "DUFD6vsyF8/tmp/4060803e731298ee8333332851a7c69065f2bbad070303584eabcb89ec5e76a3.jpg", "img_caption": ["Figure 1: Gridworld experiement. $N$ agents $N=3$ here) aim to learn a shared policy to follow a predetermined path, which is the red dashed line in the complete map. Each agent only has access to partial information about the path and gets reward 1 only at the shaded positions and O at other positions. Each agent starts at the top left corner. "], "img_footnote": [], "page_idx": 63}, {"type": "text", "text": "", "page_idx": 63}, {"type": "equation", "text": "$$\nW=\\left(\\begin{array}{c c c c c c c}{{0.5}}&{{0.5}}&{{0}}&{{0}}&{{\\cdots}}&{{0}}&{{0}}\\\\ {{0}}&{{0.5}}&{{0.5}}&{{0}}&{{\\cdots}}&{{0}}&{{0}}\\\\ {{0}}&{{0}}&{{0.5}}&{{0.5}}&{{\\cdots}}&{{0}}&{{0}}\\\\ {{\\vdots}}&{{\\vdots}}&{{\\vdots}}&{{\\vdots}}&{{}}&{{\\vdots}}&{{\\vdots}}\\\\ {{0}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}&{{0.5}}&{{0.5}}\\\\ {{0.5}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}&{{0}}&{{0.5}}\\end{array}\\right)\\ .\n$$", "text_format": "latex", "page_idx": 63}, {"type": "image", "img_path": "DUFD6vsyF8/tmp/032e7309fc199ed4eb5cf4571885a03367288fb08aaf6ee282bd3196d69c7f15.jpg", "img_caption": ["Here, $W$ in (312) satisfies the double stochasticity assumption but is not symmetric. ", "Figure 2: Changing map size $K$ . we let $\\tau=0,0.005$ and change $K$ for each $\\tau$ . We plot the curves f $(V_{\\tau}^{\\star}-\\overline{{V}}_{\\tau}^{(t)})/V_{\\tau}^{\\star}$ changing withthe iteraion number. We can seethat both vaniland enropyregularized NPG converges to the optimal value function in a few iterations, and the convergence speed is almost the same across different $K$ "], "img_footnote": [], "page_idx": 63}, {"type": "text", "text": "Figure 2illustrates the normalized sub-optimality gap $(V_{\\tau}^{\\star}-\\overline{{V}}_{\\tau}^{(t)})/V_{\\tau}^{\\star}$ with respect to the itertion number. It can be seen that both vanilla and entropy-regularized NPG converge to the optimal value function in a few iterations, and the convergence speed is almost the same across different $K$ ,i.e. the impactof $K$ on the convergence speed is minimal. ", "page_idx": 64}, {"type": "image", "img_path": "DUFD6vsyF8/tmp/3efd25bde2bcf0350b25d11648e8080d6478934a7fff3de755522986b4e38730.jpg", "img_caption": ["Figure 3: Changing number of agents $N$ . we let $K\\,=\\,10,20,30$ and change $N$ for each $K$ We plot the curves of value functions changing with the iteration number. The green dashed line represents the optimal value. We can see that the convergence speed decreases as $N$ increases. Same as before, the convergence speed is insensitive to the change of $K$ "], "img_footnote": [], "page_idx": 64}, {"type": "text", "text": "In Figure 3, we study the performance of our algorithms when the number of agents $N$ varies. We set $K=10$ ,20,30, $\\tau=0.005$ $\\eta=0.1$ and the communication graph to be the standard ring graph. We can see that the convergence speed decreases as $N$ increases. Same as before, the convergence speed is insensitive to the change of $K$ ", "page_idx": 64}, {"type": "text", "text": "In Figure 4, we illustrate the effect of the communication network topology to our algorithms. To be specific, we change the number of neighbors of each agent (i.e., the number of non-zero entries in each row of $W$ ) and (i) randomly generalize the weights of the graph such that each row of $W$ sum up.to 1, i.e., $W\\mathbf{1}=\\mathbf{1}$ , see Figure 4(a); (i) set the non-zero entries in each row of $W$ all tobe puberfbseeFigure4(b\uff09Wefix=0.1,K=10, =0.005.We plot thecurves of val functions changing with the iteration number. The green dashed line represents the optimal value. For both 4(a) and 4(b),the convergence speed increase as number of neighbors of each agent increases. FedNPG performs better when using equal weights. ", "page_idx": 64}, {"type": "image", "img_path": "DUFD6vsyF8/tmp/2d6c3169663fdaf1ea72833a13e4b66f5f323f89275f13ca6f1a2f39bcf4642d.jpg", "img_caption": ["Figure 4: Changing communication network topology. We change the number of neighbors of each agent. (i) In Figure 4(a), we randomly generalize the weights of the graph such that each rowof $W$ sum up to 1; (i) In Figure 4(b), we set the non-zero entries in each row of $W$ alltobe dube  eighbsWe lothecurves of value functionschanging with the iteratonnumbr The green dashed line represents the optimal value. For both 4(a) and 4(b), the convergence speed increase as number of neighbors increases. FedNPG performs better when using equal weights. "], "img_footnote": [], "page_idx": 64}, {"type": "text", "text": "H.1   Discussion on the Experiments ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "Note that even though there are many existing works in federated RL, none of the existing works, to the best of our knowledge, studies federated multi-tasks RL in the decentralized setting. Therefore, we are not able to compare our work with existing works. However, here we include a comparison between FedNPG and a naive baseline without the Q-tracking technique (line 6 in Algorithm 1). ", "page_idx": 64}, {"type": "text", "text": "", "page_idx": 65}, {"type": "image", "img_path": "DUFD6vsyF8/tmp/33b45331518bd5b9443b833693fe63548404cbc391cb29b8fa2b019842f6991c.jpg", "img_caption": ["Figure 5: Comparison between FedNPG and a naive baseline without the Q-tracking technique. The plot shows that while FedNPG converges within a few iterates, the algorithm without Q-tracking diverges, confirming the positive role of Q-tracking in ensuring convergence. "], "img_footnote": [], "page_idx": 65}, {"type": "text", "text": "For this plot, we use the standard ring graph (Eq. 312). We fix the size of the maze $K=30$ learning rate $\\eta=0.1$ , and regularity coefficient $\\tau=0.005$ .We experiment on different number of agents $N$ and plot the curves of value function changing with the iteration number. The plot shows that while FedNPG converges within a few iterates, the algorithm without Q-tracking diverges, confirming the positive role of Q-tracking in ensuring convergence. ", "page_idx": 65}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 66}, {"type": "text", "text": "Justification: we clearly state in the abstract and introduction the claims we made, including the contributions made in the paper and important assumptions and limitations. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 66}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Justification: we clearly state our assumptions. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational effciency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 66}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 66}, {"type": "text", "text": "Justification: we provide the full set of assumptions and a complete (and correct) proof. Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 67}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 67}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 67}, {"type": "text", "text": "Justification: see Appendix H. ", "page_idx": 67}, {"type": "text", "text": "Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 67}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 67}, {"type": "text", "text": "Answer: [No] ", "page_idx": 68}, {"type": "text", "text": "Justification: The experiments are simple and can be easily reproduced by following the instructions in the paper. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 68}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 68}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 68}, {"type": "text", "text": "Justification: Experiment details are included in Section H. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 68}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 68}, {"type": "text", "text": "Answer: [No] ", "page_idx": 68}, {"type": "text", "text": "Justification: stochasticity is not critical in our experiments. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 68}, {"type": "text", "text": "", "page_idx": 69}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 69}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 69}, {"type": "text", "text": "Justification: the results are irrelevant to the compute resources. ", "page_idx": 69}, {"type": "text", "text": "Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 69}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 69}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 69}, {"type": "text", "text": "Justification: the research conducted in the paper conforms with the NeurIPs Code of Ethics. Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 69}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 69}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 69}, {"type": "text", "text": "Justification: this is a theoretical paper and it has no societal impact. ", "page_idx": 69}, {"type": "text", "text": "Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 69}, {"type": "text", "text": "", "page_idx": 70}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 70}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 70}, {"type": "text", "text": "Justification: the paper aims to provide a better understanding on existing algorithms and thus poses no such risks. ", "page_idx": 70}, {"type": "text", "text": "Guidelines: ", "page_idx": 70}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 70}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 70}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 70}, {"type": "text", "text": "Justification: the paper does not use existing assets. ", "page_idx": 70}, {"type": "text", "text": "Guidelines: ", "page_idx": 70}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 70}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 71}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 71}, {"type": "text", "text": "Justification: the paper does not release new assets. ", "page_idx": 71}, {"type": "text", "text": "Guidelines: ", "page_idx": 71}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 71}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 71}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 71}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 71}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 71}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 71}]