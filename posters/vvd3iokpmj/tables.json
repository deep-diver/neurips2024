[{"figure_path": "VVd3iOKPMJ/tables/tables_4_1.jpg", "caption": "Table 1: Main results. We train models on features extracted by DINOv2 [35] ViT-B and ViT-G models. We report the results using LOFF (no augmentations) and LOFF-TA (with tensor augmentations). We consider features extracted from 256 \u00d7 256 and 512 \u00d7 512 images (using pooling as described in 3.1). Frozen + linear and Unfrozen + linear are points of comparison consisting of a frozen/unfrozen foundation model with a linear layer trained on images directly, with image augmentations.", "description": "This table presents the main results of the experiments comparing the performance of LOFF and LOFF-TA against baselines (Frozen + linear and Unfrozen + linear). It shows the performance metrics (APTOS, AID, DDSM, ISIC, NABirds) for different model sizes (256 and 512) and with/without pooling and tensor augmentations.  The baselines represent training a linear layer or a full linear classifier directly on images with standard augmentations, with the foundation model either frozen or unfrozen.", "section": "3 Results"}, {"figure_path": "VVd3iOKPMJ/tables/tables_5_1.jpg", "caption": "Table 1: Main results. We train models on features extracted by DINOv2 [35] ViT-B and ViT-G models. We report the results using LOFF (no augmentations) and LOFF-TA (with tensor augmentations). We consider features extracted from 256 \u00d7 256 and 512 \u00d7 512 images (using pooling as described in 3.1). Frozen + linear and Unfrozen + linear are points of comparison consisting of a frozen/unfrozen foundation model with a linear layer trained on images directly, with image augmentations.", "description": "The table presents the main results of the experiments comparing different methods for training classifiers on features extracted from foundation models. It compares LOFF and LOFF-TA against baselines (Frozen+linear and Unfrozen+linear), considering different image sizes (256x256 and 512x512) and pooling strategies.  Performance metrics (such as APTOS, AID, etc.) and computational resources (memory and training/inference speed) are reported for each method.", "section": "3 Results"}, {"figure_path": "VVd3iOKPMJ/tables/tables_6_1.jpg", "caption": "Table 3: Ablations. We systematically remove components of LOFF-TA to investigate the impact of each contribution. Results are reported with DINOv2 [35] as the foundation model, adding trivial augment [33] as an augmentation strategy.", "description": "This table presents the ablation study results, showing the impact of each component of the LOFF-TA method on the performance.  It systematically removes components (CLS, layer norm, Gaussian noise, spatial augmentation, trivial augmentation) to isolate their individual effects.  Results are reported using DINOv2 as the foundation model and include a comparison with adding trivial augmentations. The experiment is conducted on Oxford-III Pet and Caltech-101 datasets.", "section": "5.4 Ablation study"}, {"figure_path": "VVd3iOKPMJ/tables/tables_8_1.jpg", "caption": "Table 4: LOFF-TA can be used alongside foundation adaptation methods. Below we report results using ViT-B. Standalone LOFF-TA performs comparable with other foundation adaptation methods and can easily be combined with them to further enhance performance.", "description": "This table compares the performance of LOFF-TA with other foundation adaptation methods (VPT, SSF, AdaptFormer).  It shows that LOFF-TA achieves competitive results on its own and that combining LOFF-TA with these other methods leads to further performance improvements across multiple datasets.", "section": "5.5 LOFF-TA vs. foundation adaptation methods"}, {"figure_path": "VVd3iOKPMJ/tables/tables_12_1.jpg", "caption": "Table 2: Expanded results on seven standard datasets. We compare LOFF (no augmentations) and LOFF-TA (with tensor augmentations) against baselines Frozen + linear, Unfrozen + linear and Frozen + DEIT-S consisting of a frozen/unfrozen foundation model with a linear layer/DEIT-S classifier trained on images directly (with image augmentations). Results are reported for features extracted from OPENCLIP [19] and DINOv2 [35] using 256 \u00d7 256 images.", "description": "This table presents a detailed comparison of the performance of LOFF and LOFF-TA against several baseline models across seven standard image classification datasets.  The results are broken down by method (LOFF, LOFF-TA, Frozen + linear, Unfrozen + linear, Frozen + DeiT-S), using features extracted from both OPENCLIP and DINOv2 models with 256x256 images.  It shows performance metrics for each dataset and model, allowing for a comprehensive evaluation of the proposed methods.", "section": "5.2 Further evidence"}, {"figure_path": "VVd3iOKPMJ/tables/tables_13_1.jpg", "caption": "Table 1: Main results. We train models on features extracted by DINOv2 [35] ViT-B and ViT-G models. We report the results using LOFF (no augmentations) and LOFF-TA (with tensor augmentations). We consider features extracted from 256 \u00d7 256 and 512 \u00d7 512 images (using pooling as described in 3.1). Frozen + linear and Unfrozen + linear are points of comparison consisting of a frozen/unfrozen foundation model with a linear layer trained on images directly, with image augmentations.", "description": "This table presents the main results of the LOFF and LOFF-TA methods, comparing them against baselines using DINOv2 ViT-B and ViT-G models.  It shows the performance (using various metrics depending on the dataset), training speed (images per second), and GPU memory usage for different configurations: LOFF (no augmentations), LOFF-TA (with tensor augmentations), and two baselines (Frozen + linear and Unfrozen + linear). The table also explores the impact of pooling on features extracted from images of different resolutions (256x256 and 512x512).", "section": "Results"}]