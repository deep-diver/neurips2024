[{"figure_path": "vjsd8Bcipv/figures/figures_5_1.jpg", "caption": "Figure 1: Test accuracies on CIFAR-10 under symmetric noise with different m, where the red box represents the zoomed-in accuracies of the last 20 epochs. (a) and (b) illustrate CE with 0 (clean) and 0.8 noise rates, respectively. (c) and (d) illustrate CE+MAE (\u03b1 = 0.01, \u03b2 = 5) similarly.", "description": "This figure compares the test accuracy of using cross-entropy loss (CE) and CE combined with mean absolute error (MAE) loss on the CIFAR-10 dataset under different symmetric noise rates.  The parameter 'm' in e-softmax is varied, showing its effect on model performance. The zoomed-in section highlights the performance in the later epochs of training.  The results illustrate how the proposed methods (CE and CE+MAE) handle different noise levels and the impact of the 'm' parameter on model robustness and accuracy.", "section": "3.3 Gradient Analysis of e-Softmax"}, {"figure_path": "vjsd8Bcipv/figures/figures_7_1.jpg", "caption": "Figure 2: Visualizations of learned representations on CIFAR-10 with symmetric label noise. The x-axis and y-axis represent the first and second dimensions of the 2D embeddings, respectively.", "description": "This figure visualizes the learned representations of CIFAR-10 data using t-SNE, comparing the standard Cross-Entropy (CE) loss and the proposed CE+MAE loss under different symmetric noise levels (0.2 and 0.4). The visualizations show that CE overfits to noisy labels and clusters are mixed, while CE+MAE generates well-separated clusters, indicating robustness to label noise.", "section": "3.4 Better Trade-off between Robustness and Effective Learning"}, {"figure_path": "vjsd8Bcipv/figures/figures_19_1.jpg", "caption": "Figure 1: Test accuracies on CIFAR-10 under symmetric noise with different m, where the red box represents the zoomed-in accuracies of the last 20 epochs. (a) and (b) illustrate CE with 0 (clean) and 0.8 noise rates, respectively. (c) and (d) illustrate CE+MAE (\u03b1 = 0.01, \u03b2 = 5) similarly.", "description": "This figure shows the test accuracy of the CE and CE+MAE loss functions with different values of the hyperparameter 'm' under symmetric noise conditions on the CIFAR-10 dataset. The plots show that CE+MAE is more robust to noise than CE and is less prone to overfitting, especially at high noise levels. The zoomed-in sections highlight the performance in the last 20 epochs.", "section": "3.1 Robustness"}]