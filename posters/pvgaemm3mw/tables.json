[{"figure_path": "PVgAeMm3MW/tables/tables_5_1.jpg", "caption": "Table 1: Comparison Results. We compare our method against SVD [13], AnimateLCM [21], UFOGen [25], and LADD [28] using different numbers of sampling steps. AnimateLCM* indicates the usage of the officially provided 25-frame model, with only the first 14 frames considered for FVD calculation. \u2020 indicates our implementations. We also report the latency of the denoising process for each setting, measured on a single NVIDIA A100 GPU.", "description": "This table compares the performance of the proposed single-step video generation model against existing state-of-the-art methods.  It shows the Fr\u00e9chet Video Distance (FVD), number of sampling steps, and inference latency (on a single NVIDIA A100 GPU) for each model.  The comparison includes the proposed model and other models using different numbers of sampling steps for a fair comparison.", "section": "4.2 Comparisons Results"}, {"figure_path": "PVgAeMm3MW/tables/tables_9_1.jpg", "caption": "Table 1: Comparison Results. We compare our method against SVD [13], AnimateLCM [21], UFOGen [25], and LADD [28] using different numbers of sampling steps. AnimateLCM* indicates the usage of the officially provided 25-frame model, with only the first 14 frames considered for FVD calculation. \u2020 indicates our implementations. We also report the latency of the denoising process for each setting, measured on a single NVIDIA A100 GPU.", "description": "This table compares the performance of the proposed single-step video generation model against existing state-of-the-art models using different numbers of sampling steps.  It evaluates the models based on Fr\u00e9chet Video Distance (FVD), the number of sampling steps required, and the inference latency (time taken to process a single video batch). The results demonstrate the significant speedup achieved by the proposed method without compromising video generation quality.", "section": "4.2 Comparisons Results"}]