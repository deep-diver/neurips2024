{"references": [{"fullname_first_author": "Franco Scarselli", "paper_title": "The graph neural network model", "publication_date": "2009-01-01", "reason": "This paper is foundational to the field of graph neural networks, introducing the basic model used in many subsequent works."}, {"fullname_first_author": "Tailin Wu", "paper_title": "Graph information bottleneck", "publication_date": "2020-01-01", "reason": "This paper introduces the Graph Information Bottleneck (GIB) principle, which is central to the explanation method proposed in the current paper."}, {"fullname_first_author": "Zhitao Ying", "paper_title": "Gnnexplainer: Generating explanations for graph neural networks", "publication_date": "2019-01-01", "reason": "This paper introduces GNNExplainer, a widely used method for explaining graph neural networks that is directly compared to and improved upon in the current paper."}, {"fullname_first_author": "Naftali Tishby", "paper_title": "The information bottleneck method", "publication_date": "2000-01-01", "reason": "This paper introduces the Information Bottleneck (IB) principle, which underlies the GIB method used in this paper."}, {"fullname_first_author": "Jiaxing Zhang", "paper_title": "Mixupexplainer: Generalizing explanations for graph neural networks with data augmentation", "publication_date": "2023-01-01", "reason": "This paper introduces the MixupExplainer method, which addresses issues of distribution shift, and this method is used as a basis for the current paper's approach."}]}