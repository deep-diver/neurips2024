[{"type": "text", "text": "Plant-and-Steal: Truthful Fair Allocations via Predictions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ilan Reuven Cohen Bar-Ilan University ilan-reuven.cohen@biu.ac.il ", "page_idx": 0}, {"type": "text", "text": "Alon Eden The Hebrew University alon.eden@mail.huji.ac.il ", "page_idx": 0}, {"type": "text", "text": "Talya Eden Bar-Ilan University talyaa01@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Arsen Vasilyan UC Berkeley arsen@berkeley.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study truthful mechanisms for approximating the Maximin-Share (MMS) value of agents with additive valuations for indivisible goods. Algorithmically, constant factor approximations exist for the problem for any number of agents. When adding incentives to the mix, a jarring result by Amanatidis, Birmpas, Christodoulou, and Markakis [EC 2017] shows that the best possible approximation for two agents and $m$ items is $\\textstyle\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor$ . We adopt a learning-augmented framework to investigate what is possible when a prediction on the input is given. For two agents, we give a truthful mechanism that takes agents\u2019 ordering over items as prediction. When the prediction is accurate, our mechanism gives a 2-approximation to the MMS (consistency), and when the prediction is off, our mechanism still obtains an $\\textstyle\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ - approximation to the MMS (robustness). We further show that the mechanism\u2019s performance degrades gracefully in the number of \u201cmistakes\u201d in the prediction; i.e., we interpolate between the two extremes: when there are no mistakes, and when there is a maximum number of mistakes. We also show an impossibility result on the obtainable consistency for mechanisms with finite robustness. For the general case of $n\\geq2$ agents, we give a 2-approximation mechanism for accurate predictions, with relaxed fallback guarantees. Finally, we give experimental results which illustrate when different components of our framework, made to ensure consistency and robustness, come into play. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Allocating items among self interested agents in a \u201cfair\" way is an age-old problem, with many applications such as splitting inheritance and allocating courses to students. As a starting point, consider the case of two agents. When the items are divisible, the famous cut-and-choose procedure achieves fairness in two senses. Firstly, no agent wants to switch their allocation with the other; i.e., there is no envy among the agents. Secondly, each agent gets a bundle of items which they value at least as much as their value for all the items divided by 2; that is, each one gets their \u201cfair share\". When moving to the case of indivisible goods, which is relevant to scenarios such as splitting inheritance and allocating courses, things get trickier. For instance, if there\u2019s a single item, the agent that does not receive that item does not get an envy-free allocation, nor do they get their \u201cfair share\" according to the previous definitions. Therefore, it is clear that some fairness needs to be sacrificed in this case. ", "page_idx": 0}, {"type": "text", "text": "The study of fair allocations with indivisible goods has been a fruitful research direction, with many meaningful notions of fairness studied (see survey by Amanatidis et al. [10]). In this paper, we focus on the notion of the Maximin Share, or MMS, introduced by Budish [18]. For two agents, this notion captures the value an agent will ensure if we implement the cut-and-choose procedure. That is, assume Alice splits the items into two bundles, and then Bob takes one of them (adversarially), and Alice gets the second one. The MMS captures exactly how much value Alice can guarantee for herself. Generalizing the notion for $n$ agents is pretty straightforward \u2014 the MMS is the minimum value Alice can guarantee for herself when she partitions the items into $n$ bundles, assuming $n-1$ bundles are taken adversarially. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We study the case where agents have additive valuations over goods.1 For the case of two agents, the allocation produced by the cut-and-choose procedure guarantees each of the agents their MMS value. For more than two agents, the existence of such an allocation is not longer guaranteed. Kurokawa et al. [30] show an instance of three agents, where in every allocation, at least one of the agents does not get their MMS value. Since allocating all the agents their MMS value is not always feasible, various papers studied the existence of approximately optimal allocation. An allocation is an $\\alpha$ -approximate MMS allocation for $\\alpha>1$ if every agents gets at least an $1/\\alpha$ fraction of their MMS value. Feige et al. [22] introduce an instance where one cannot find an $\\alpha$ -approximate allocation for $\\begin{array}{r}{\\alpha<\\frac{\\widecheck{40}}{39}}\\end{array}$ . On the other hand, [30] show there always exists $\\frac{3}{2}$ -approximation. The $\\frac{3}{2}$ factor was gradually improved [16, 24, 23, 8, 4, 3, 5], where the state-of-the-art algorithm achieves an approximation of $959/720<4/3$ [3]. Adding incentives to the mix further complicates matters. ", "page_idx": 1}, {"type": "text", "text": "Amanatidis et al. [7] study the case of two additive agents, and $m$ items, where the algorithm (or mechanism) does not know the values of the agents. Thus, the algorithm\u2019s designer is faced with the task of devising an allocation rule such that $(i)$ agents will maximize their allocated value by bidding truthfully, and $(i i)$ the resulting allocation is an $\\alpha$ -approximate MMS allocation for an $\\alpha$ close to 1 as possible. [7] show that no incentive-compatible algorithm can approximate the MMS to a factor better than $\\textstyle\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor$ , and this is matched by the following trivial mechanism \u2014 the first agent picks their favorite item, and the second agent gets the rest. ", "page_idx": 1}, {"type": "text", "text": "For $2<n<m$ ,2 a trivial truthful algorithm that lets the first $n-1$ agents pick a single item in some order and gives the last agent the rest achieves an $\\textstyle{\\lfloor{\\frac{m-n+2}{2}}\\rfloor}$ -approximation, and no better mechanism is known. It is conjectured that one cannot drop the dependence in $m$ for $n>2$ . We are left with a stark disparity. On the one hand, assuming agents\u2019 values are public information, approximate solutions are known to exist. On the other hand, when considering private values, it seems that only trivial approximations are possible. The goal of this paper is to bridge these two regimes using predictions. ", "page_idx": 1}, {"type": "text", "text": "We study the problem of truthful allocations that approximate the MMS, taking a learning-augmented point of view. In the learning-augmented framework, the algorithm designer aims to tackle some intrinsic hardness of the problem at hand, which might arise due to computational constraints, space constraints, input arriving piecemeal online, or incentive constraints, among others. To help the designer overcome these constraints, the algorithm is given some side information which is a function of the input, or a prediction, in order to improve the algorithm\u2019s performance. The hope is that if the prediction is accurate, then the performance is greatly improved over the performance without the prediction (termed consistency). On the other end, if the prediction is inaccurate then the performance of the algorithm is comparable to the performance of the best algorithm that is not given access to predictions (termed robustness). The learning-augmented framework has proven useful in bypassing impossibilities that arise due to incentive issues [14, 1, 25, 15, 40, 33, 13]. ", "page_idx": 1}, {"type": "text", "text": "When designing a learning-augmented mechanism, one should think of realistic predictions. For instance, predicting the entire valuation profile of all agents seems to be a strong assumption. A more plausible assumption is to have some ordinal ranking over the items of the agents. Indeed, it seems unlikely that the algorithm can accurately predict Alice\u2019s value for a car, but it is plausible that the algorithm can guess that Alice values the car more than she values the table. Ideally, the algorithm\u2019s performance should remain robust if the predicted ordering is almost perfect, with only a few pairs of items whose real ordering is swapped in the prediction. Another desired property is to make the prediction as space-efficient as possible, as previous results [20, 31, 32] show that succinct predictions are crucial for learning parameters from few samples and for incorporating a PAC-learnable component in the learning-augmented framework. ", "page_idx": 1}, {"type": "text", "text": "In this paper we devise learning-augmented truthful mechanisms for the problem of approximateMMS allocations, while taking into considerations the concerns mentioned above. ", "page_idx": 2}, {"type": "text", "text": "Our Results. We start by studying the two agent case. We aim at getting: (a) Constant consistency: when the predictions are accurate, we want to get a constant approximation to the MMS. (b) Nearoptimal robustness: when the predictions are off, we want to get as close as possible to the optimal $\\textstyle\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor$ -approximation we can obtain by truthful mechanisms [7]. ", "page_idx": 2}, {"type": "text", "text": "Plant-and-Steal Framework. In Section 3 we present a framework for devising learningaugmented mechanisms for approximating the MMS with two agents. As using only predictions does not guarantee any robustness, we use reports to ensure each agent gets at least one valuable item. This is done while maintaining a near-optimal allocation according to predictions. Our framework, which we term Plant-and-Steal, is modular. Along with the set of goods and the agents\u2019 reports, it also receives a prediction and an allocation procedure. Different combinations of predictions and allocation procedures yields different consistency-robustness tradeoffs. It is worth noting that, although privacy is not the primary focus of this paper, the Plant-and-Steal framework uses agents\u2019 reports in a minimal way, as they are only required to select (i.e. \u201csteal back\u201d) a single item from a predefined set of options, where this set is determined by the predictions, and not the actual reports. ", "page_idx": 2}, {"type": "text", "text": "Ordering Predictions. In Section 4, we study learning-augmented mechanisms when the predictions given are preference orders over items of the agents, rather than the values. We instantiate the Plant-and-Steal framework with a Round-Robin-based allocation procedure. We observe that in the case of two agents, Round-Robin obtains 2-approximation to the MMS. The 2-consistency of using Plant-and-Steal with Round-Robin as the allocation procedure almost immediately follows. The $\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ robustness follows two facts: $(a)$ Round-Robin produces allocations that are balanced in the number of items allocated to each agent; and $(b)$ The Plant-and-Steal framework ensures each agent gets one of their 2 favorite items according to reports. In Appendix E, we show how to get an improved $\\frac{3}{2}$ consistency, while maintaining $O(m)$ robustness when using a modified Round-Robin allocation procedure. ", "page_idx": 2}, {"type": "text", "text": "In Sec 5, we then study the performance of the Plant-and-Steal framework when using the Round-Robin procedure, when the prediction given is not fully accurate, but accurate to some degree. To quantify the prediction\u2019s accuracy, we adopt the Kendall tau distance measure. The Kendall tau distance counts the number of pairs of elements swapped in the predicted preference order and the order induced by the true valuations. We show that com\u221abining the Plant-and-Steal framework with a Round-Robin allocation procedure obtains $O({\\sqrt{d}})$ -approximation to the MMS when the Kendall tau distance is $d$ . Since $d$ goes from 0 to ${\\binom{m}{2}}=\\Theta(m^{2})$ , we recover the constant consistency when there are no errors, and the $O(m)$ robustness when the number of errors is maximal. ", "page_idx": 2}, {"type": "text", "text": "General Predictions. In Appendix G, we study the two-agent case where the mechanism is given access to predictions which are not necessarily the preference order of the agents. We first show that for any prediction given to the learning-augmented mechanism, no mechanism can simultaneously be $\\alpha$ -consistent while maintaining finite robustness for $\\alpha\\,<\\,6/5$ . For the proof, we leverage the characterization of two-agent truthful mechanisms by [7]. ", "page_idx": 2}, {"type": "text", "text": "We then study small-space predictions. The Round-Robin-based mechanisms described above require an $\\Omega(m)$ -bit prediction (to describe an arbitrary allocation of items). We first notice that we can implement a bag-filling type allocation procedure using $O(\\log m)$ -bit predictions. This already achieves a constant consistency along with $O(m)$ robustness. We then devise a more refined allocation procedure, which requires $O(\\log m/\\epsilon)$ -bit predictions, and achieves $2+\\epsilon$ consistency along with $\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ robustness. ", "page_idx": 2}, {"type": "text", "text": "General number of agents n. In Appendix H, we devise a learning-augmented truthful mechanism for $n\\,\\geq\\,2$ additive agents. We obtain a 2-consistent mechanism, while relaxing the robustness guarantees of the mechanism. We take a similar approach to the work of [18, 27, 28, 2, 5], who compete against a relaxed benchmark of the MMS value for $\\hat{n}>n$ agents, and try to minimize $\\hat{\\boldsymbol{n}}$ . We obtain an $\\operatorname*{max}\\{m-\\hat{n}-1,1\\}$ -approximation to the MMS for $\\begin{array}{r}{\\hat{n}=\\bar{\\lceil\\frac{3n}{2}\\rceil}}\\end{array}$ agents when the predictions are off. Our mechanism uses the modified Round-Robin procedure from [8] to determine the initial allocation using the predictions. It then applies a recursive plant-and-steal procedure to determine the final allocation. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Experiments. Finally, In Section 6, we demonstrate how several components in our design come into play when experimenting with synthetic data. We run different variants of mechanism on two player instances, and show that when predictions are accurate, then only using predictions is nearly optimal, if predictions are noisy, then the stealing component ensures robustness, and our Plant-and-Steal framework achieves best-of-both-worlds guarantees. ", "page_idx": 3}, {"type": "table", "img_path": "aFB97F8QSF/tmp/b6a1f196a0e8642d1ff0eb431f34a68f58d096b9911a3fef4d5c5181b9d79a22.jpg", "table_caption": ["We summarize the bounds we obtain in Table 1. "], "table_footnote": ["Table 1: Known bounds for truthful learning-augmented MMS mechanisms. "], "page_idx": 3}, {"type": "text", "text": "Further Related Work. In addition to the the studies mentioned above, we give a comprehensive review of further related work in Appendix B. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the setting we study, there is a set $N$ of $n$ agents and a set $M$ of $m$ indivisible items. Each agent has a private additive valuation over the items, unknown to the mechanism designer, where the value of agent $i$ for item $j$ is $v_{i j}$ (also denoted as $v_{i}(j)\\rrangle$ ). For a bundle $S\\subseteq M$ of items, $\\begin{array}{r}{v_{i}(S)=\\sum_{j\\in S}v_{i j}}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "The fairness notion we focus on is the following. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.1 (Maximin Share). The Maximin Share (MMS) of agent $i$ with valuation $v_{i}$ and $n$ agents is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mu_{i}^{n}=\\operatorname*{max}_{S_{1}\\bigcup\\ldots\\bigcup S_{n}=M}\\operatorname*{min}_{j\\in[n]}v_{i}(S_{j});\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "that is, if i were to partition the items into n bundles, and then $n-1$ of those bundles are taken adversarially, what is the value i can guarantee for themselves. When clear from the context, we omit $n$ and use $\\mu_{i}$ to denote the MMS of $i$ with n agents. ", "page_idx": 3}, {"type": "text", "text": "We are interested in mechanisms that produce approximately optimal allocations, as defined next. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.2 $(\\gamma,k)$ -approximate MMS Allocation). An allocation $\\boldsymbol{X}=(X_{1},\\ldots,X_{n})$ is $(\\gamma,k)$ - approximate MMS allocation for $\\gamma>1$ and a natural number $k$ if for every agent $i$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nv_{i}(X_{i})\\geq\\mu_{i}^{k}/\\gamma.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "When $k=n$ , we say the allocation is a $\\gamma$ -approximate MMS allocation. ", "page_idx": 3}, {"type": "text", "text": "We study mechanism that get some prediction on the input. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.3 (Learning-Augmented Mechanism). A learning-augmented mechanism takes agents\u2019 reports $\\mathbf{r}=(r_{1},\\ldots,r_{n})$ and predictions $\\mathbf{p}$ in some prediction space $\\mathcal{P}$ , and outputs a partition of the items ", "page_idx": 3}, {"type": "equation", "text": "$$\nX(\\mathbf{r},\\mathbf{p})=(X_{1}(\\mathbf{r},\\mathbf{p}),X_{2}(\\mathbf{r},\\mathbf{p}),\\dots,X_{n}(\\mathbf{r},\\mathbf{p})),\\quad X_{1}(\\mathbf{r},\\mathbf{p})\\bigcup\\Sigma_{2}(\\mathbf{r},\\mathbf{p})\\bigcup\\ldots\\bigcup X_{n}(\\mathbf{r},\\mathbf{p})=M,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where agent $i$ gets $X_{i}(\\mathbf{r},\\mathbf{p})$ . ", "page_idx": 3}, {"type": "text", "text": "For learning-augmented mechanisms, truthfulness should hold for any possible prediction p. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.4. A learning-augmented mechanism is truthful if for every agent i and every possible report of other agents $\\mathbf{r}_{-i}$ and every possible prediction $\\mathbf{p}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\nv_{i}(X_{i}(v_{i},\\mathbf{r}_{-i},\\mathbf{p}))\\geq v_{i}(X_{i}(r_{i},\\mathbf{r}_{-i},\\mathbf{p}))\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "for every $r_{i}$ ", "page_idx": 4}, {"type": "text", "text": "We next define the consistency and robustness measures according to which we measure the performance of our mechanisms. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.5 $\\alpha$ -consistency). Consider a prediction function $f_{\\mathcal{P}}$ which takes a valuation profile and outputs a prediction in prediction space $\\mathcal{P}$ . A learning-augmented mechanism is $\\alpha$ -consistent for $\\alpha>1$ and prediction function $f_{\\mathcal{P}}$ if for every valuation profile v and every prediction $\\mathbf{p}=f_{\\mathcal{P}}(\\mathbf{v})$ , $X({\\bf v},{\\bf p})$ is an $\\alpha$ -approximate MMS allocation. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.6 $\\mathit{\\check{\\Psi}}(\\beta,k)$ -robust). A learning-augmented mechanism is $(\\beta,k)$ -robust for $\\beta>1$ and natural number $k$ if for every valuation profile v and every prediction $\\mathbf{p}$ , $X({\\bf v},{\\bf p})$ is an $(\\beta,k)$ - approximate MMS allocation. If $k=n$ , we say the mechanism is $\\beta$ -robust. ", "page_idx": 4}, {"type": "text", "text": "For ease of presentation, for valuation $v_{i}$ , report $r_{i}$ and prediction $p_{i}$ , we use $v_{i}^{\\ell},r_{i}^{\\ell},p_{i}^{\\ell}$ to denote both the $\\ell^{\\mathrm{th}}$ highest good according to the valuation/report/prediction and its value. Note that, we may use $v_{i}^{\\ell}$ for $\\ell>m$ , in this case, $v_{i}^{\\bar{\\ell}}\\,{=}\\,0$ . For $\\ell=1$ , i.e., the highest good we use $v_{i}^{*},r_{i}^{*},p_{i}^{*}$ . ", "page_idx": 4}, {"type": "text", "text": "Ordering Predictions and Kendall tau Distance. Most of our mechanisms use predictions which take the form of an ordering over agents\u2019 items. That is, $f_{\\mathcal{P}}(\\mathbf{v})$ outputs a vector of orderings $\\mathbf{p}=(p_{1},\\ldots,p_{n})$ , where $p_{i}^{\\ell}$ is the $\\ell^{\\mathrm{th}}$ highest valued item of $i$ in $M$ according to p. Accordingly, for agent $i$ , let $v_{i}^{\\ell}$ be the $\\ell^{\\mathrm{th}}$ highest valued item according to $\\mathbf{v}$ . For two items $j\\neq j^{\\prime}$ , We use $j\\succ_{p_{i}}j^{\\prime}$ to denote that $j$ is higher ranked than $j^{\\prime}$ according to $\\mathbf{p}$ . ", "page_idx": 4}, {"type": "text", "text": "When studying imprecise predictions, we want to quantify the degree to which the prediction is inaccurate. For this, we use the following measure. For an agent $i$ , we define our noise level with respect to the Kendall tau distance (also known as bubble-sort distance) between $\\mathbf{v}$ and $\\mathbf{p}$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2.7 (Kendall tau distance). The Kendall tau distance counts the number of pairwise disagreements between two orders. For i\u2019s valuation $v_{i}$ and predicted preference order $p_{i}$ , we define ", "page_idx": 4}, {"type": "equation", "text": "$$\nK_{d}(v_{i},p_{i})=|\\{j\\succ_{p_{i}}j^{\\prime}\\,:\\,v_{i}(j)<v_{i}(j^{\\prime})\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "That is, the number of pairs of items where the prediction got their relative ordering wrong. We also denote $K_{d}(\\mathbf{v},\\mathbf{p})=\\operatorname*{max}\\{K_{d}(v_{1},p_{1}),K_{d}(v_{2},p_{2})\\}$ . ", "page_idx": 4}, {"type": "text", "text": "We note that the Kendall tau distance between $v_{i}$ and $p_{i}$ , $K_{d}(v_{i},p_{i})$ , can go from 0 to $\\binom{m}{2}$ . ", "page_idx": 4}, {"type": "text", "text": "3 Plant-and-Steal Framework ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we present the framework which is used to devise learning-augmented mechanisms for two agents. The ideas presented here also inspire the more complex learning-augmented mechanism for $n>2$ agents. Missing proofs of this section appear in Appendix C. Our framework, which we term Plant-and-Steal is given the set of goods, an allocation procedure $\\boldsymbol{\\mathcal{A}}$ , the prediction $\\mathbf{p}$ and reports $\\mathbf{v}$ . The framework operates as follows: ", "page_idx": 4}, {"type": "text", "text": "1. It first applies $\\boldsymbol{\\mathcal{A}}$ on the predictions $\\mathbf{p}$ to divide the set of goods into two bundles $A_{1},A_{2}$ . The procedure $\\boldsymbol{\\mathcal{A}}$ should be an allocation procedure with good MMS guarantees. We use different allocation procedures depending on the type of prediction given and on the consistency-robustness tradeoffs we are aiming for.   \n2. Planting phase: For each agent $i$ , it picks $i$ \u2019s favorite item in set $A_{i}$ according to prediction, and \u201cplants\u201d this item in the bundle $A_{j}$ of the other agent $j\\neq i$ . Let $T_{1},T_{2}$ denote the sets that result in this planting phase.   \n3. Stealing phase: To obtain the final allocation, each agent $i$ now \u201csteals\u201d back their favorite item from set $T_{j}$ of agent $j\\neq i$ according to reports. Notice this is the first and only place where we use agents\u2019 reports. ", "page_idx": 4}, {"type": "text", "text": "This procedure is trivially truthful because the only step where we use agents\u2019 reports is the one where they pick exactly one item to steal back from $T_{j}$ , and this $T_{j}$ only depends on predictions, and not reports (Lemma 3.1). To obtain robustness, we notice that each agent gets one of their two favorite items according to their true valuations (Lemma 3.2). This implies a robustness of $m-1$ . We show that for balanced allocations, we get improved robustness guarantees (Lemma 3.4). ", "page_idx": 5}, {"type": "text", "text": "For $S\\subseteq M$ , and agent $i$ , let $v_{i}^{*}(S)\\left(p_{i}^{*}(S),r_{i}^{*}(S)\\right)$ be the max valued item in $S$ according to $v_{i}\\left(p_{i},r_{i}\\right)$ . for $g\\in M$ and $S\\subseteq M$ , denote $S+g:=S\\cup\\{g\\}$ and $S-g=S\\setminus\\{g\\}$ . The Plant-and-Steal framework is presented in Mechanism 1. ", "page_idx": 5}, {"type": "text", "text": "MECHANISM 1: Two agent Plant-and-Steal Framework ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Input :Allocation Procedure $\\boldsymbol{\\mathcal{A}}$ , set of items $M$ , predictions p and reports r   \nOutput :Allocations $X_{1}\\left[\\cdot\\right]X_{2}=M$ $/*$ Find an initial allocation by applying $\\mathcal{A}$ on the predictions $\\ast/$   \n$(A_{1},A_{2}):=\\mathcal{A}(M,N,{\\bf p})$ /\\* Plant favorite items according to predictions \\*/   \n$\\begin{array}{r l}&{\\hat{j}_{1}\\leftarrow p_{1}^{*}(A_{1})}\\\\ &{\\hat{j}_{2}\\leftarrow p_{2}^{*}(A_{2})}\\\\ &{T_{1}\\leftarrow A_{1}+\\hat{j}_{2}-\\hat{j}_{1}}\\\\ &{T_{2}\\leftarrow A_{2}+\\hat{j}_{1}-\\hat{j}_{2}}\\end{array}$ /\\* Steal according to report \\*/   \nj\u02dc1 \u2190r1\u2217(T2)   \nj\u02dc2 \u2190r2\u2217(T1)   \nX1 \u2190T1 + j\u02dc1 \u2212j\u02dc2   \nX2 \u2190T2 + j\u02dc2 \u2212j\u02dc1 ", "page_idx": 5}, {"type": "text", "text": "We show that for any allocation function $\\boldsymbol{\\mathcal{A}}$ and predictions $\\mathbf{p}$ given to the framework, the resulting mechanism is truthful. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.1 (Truthfulness Lemma). For any allocation procedure $\\boldsymbol{\\mathcal{A}}$ , Plant-and-Steal mechanism using $\\boldsymbol{\\mathcal{A}}$ is truthful. ", "page_idx": 5}, {"type": "text", "text": "Since the framework is truthful, from now on, we assume that $\\textbf{r}=\\textbf{v}$ . Next, we show that the Plant-and-Steal mechanism ensures that for each agent, an item is allocated with a value that is at least as good as their second-best option according to their value. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.2. Consider the allocation $(X_{1},X_{2})$ returned by Plant-and-Steal with some allocation procedure $\\boldsymbol{\\mathcal{A}}$ . For any agent $i$ , then $v_{i}^{1}\\in X_{i}$ or $v_{i}^{2}\\in X_{i}$ . ", "page_idx": 5}, {"type": "text", "text": "We next claim that if $i$ gets one of their two favorite items and any $k-1$ additional items, $i$ \u2019s value is an $m-k$ -approximation to $\\mu_{i}$ . ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.3. For any agent $i$ , let $S\\subseteq M$ be a subset of the items of size $|S|=k$ and $v_{i}^{1}\\in S$ or $v_{i}^{2}\\in S$ then ", "page_idx": 5}, {"type": "equation", "text": "$$\nv_{i}(S)\\geq\\mu_{i}/(m-k).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We immediately get the following. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.4 (Robustness Lemma). Let $\\boldsymbol{\\mathcal{A}}$ be an allocation rule guaranteeing ${\\mathrm{min}}\\{|A_{1}|,|A_{2}|\\}\\geq k,$ , then when Plant-and-Steal uses $\\boldsymbol{\\mathcal{A}}$ , the resulting mechanism is $(m-k)$ -robust. ", "page_idx": 5}, {"type": "text", "text": "Proof. By Lemma 3.2, we are guaranteed that each agent gets one of their two favorite items according to their report. Combining with the condition on $\\boldsymbol{\\mathcal{A}}$ and Lemma 3.3, the proof is finished. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "4 Ordering Predictions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we consider the case of two agents, where the predictions (and in fact, also the reports) given to the mechanism are preference orders of agents over items. Our mechanisms makes use of the Plant-and-Steal framework instantiated by Round-Robin based allocation procedures. We first present the round-robin allocation procedures we\u2019ll use, and give their approximation guarantees when the input is accurate. Next, we prove the robustness and consistency guarantees. Finally, we quantify the accuracy of the predictions using the Kendall tau distance, and obtain fine-grained approximation results, where the approximation smoothly degrades in the accuracy. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Amanatidis et al. [6] studied mechanisms where the preference orders of the agents over items are public (while valuations are private). They showed that no truthful mechanism can achieve a better approximation than $5/4$ in this setting. This implies that when the predictions are preference orders, no learning-augmented mechanism can obtain consistency better than $5/4$ , no matter if the robustness is bounded or not. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.1 (Corollary of Amanatidis et al. [6]). For any $\\epsilon>0$ , no mechanism that is given preference orders as predictions can obtain consistency $5/4-\\epsilon$ . ", "page_idx": 6}, {"type": "text", "text": "Round-Robin Allocation Procedures. The two allocation procedures we use to instantiate the Plant-and-Steal framework take as input preference orders of agents over items: ", "page_idx": 6}, {"type": "text", "text": "\u2022 Balanced-Round-Robin: the agents take turns, and at each turn, an agent takes their highest ranked remaining item. This results in a balanced allocation. \u2022 1-2-Round-Robin: the agents take turns, where we compensate the second agent, who might not get their favorite item, to take two items each turn. ", "page_idx": 6}, {"type": "text", "text": "In this section, we only prove consistency-robustness guarantees when Balanced-Round-Robin is used as the allocation procedure. In Appendix $\\mathrm{E}$ we show different tradeoffs when 1-2-Round-Robin is used. ", "page_idx": 6}, {"type": "table", "img_path": "aFB97F8QSF/tmp/630083e0105ecf3c337231e74fc74fc8f49c256cc102ab810df7aed496400201.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Consider the allocation procedure depicted in Algorithm 2. In order to implement the two allocation procedures, we only needs to receive preference orders over items. Let $A_{i}=(a_{i}^{1},\\ldots,a_{i}^{|A_{i}|})$ a|iAi|) be agent $i$ \u2019s allocation by the algorithm, where $a_{i}^{k}$ is the $k$ \u2019th choice of agent $i$ . We observe the following. ", "page_idx": 6}, {"type": "text", "text": "Observation 4.1. The output $(A_{1},A_{2})$ of the Balanced-Round-Robin procedure, satisfies: ", "page_idx": 6}, {"type": "text", "text": "1. $\\left|A_{1}\\right|=\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ , $|A_{2}|=\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor$ .   \n2. For each agent $i$ and round $k$ , $a_{i}^{k}\\in\\{v_{i}^{\\ell}\\}_{\\ell\\in[2k]}$ ; that is, in round $k$ an agent gets one of their top $2k$ items. ", "page_idx": 6}, {"type": "text", "text": "Amanatidis et al. [8] show that first allocating large items to agents, and then using a Round-Robin to allocate the remaining items to the remaining agents, gives a 2-approximation to the MMS. We observe that for two agents, Round-Robin as is, without the initial step, achieves this approximation guarantee. The proof of the following Lemma is deferred to Appendix D. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. Let $(A_{1},A_{2})$ be the allocation of Balanced-Round-Robin. For every agent i, $v_{i}(A_{i})\\geq\\mu_{i}/2$ . ", "page_idx": 6}, {"type": "text", "text": "We next use the allocation procedure to instantiate the Plant-and-Steal framework. ", "page_idx": 6}, {"type": "text", "text": "Round-Robin-Based Mechanism. The mechanism we analyze, B-RR-Plant-and-Steal, results from instantiating Plant-and-Steal with Balanced-Round-Robin as $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 6}, {"type": "text", "text": "We first show that if the predictions correspond to the preference orders of the real valuations, then B-RR-Plant-and-Steal outputs the same allocation as Balanced-Round-Robin. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.2. When predictions correspond to actual values, B-RR-Plant-and-Steal outputs the same allocation as Balanced-Round-Robin. ", "page_idx": 6}, {"type": "text", "text": "We are now ready to prove the performance guarantees of our mechanisms. ", "page_idx": 6}, {"type": "text", "text": "Proof. By Lemma 3.1, the mechanism is truthful. By Observation 4.1, each agent receives at least $\\lfloor m/2\\rfloor$ items; combining with Lemma 3.4, we get that the mechanism is $\\textstyle\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ -robust. Finally, if predictions correspond to valuations, by Lemma 4.1 and Lemma 4.2, the allocation is a 2-approximation to the MMS. Thus, the mechanism is 2-consistent. \u53e3 ", "page_idx": 7}, {"type": "text", "text": "We note that by Amanatidis et al. [7], our robustness guarantee matches the optimal obtainable approximation by any truthful mechanism (up to the rounding). ", "page_idx": 7}, {"type": "text", "text": "5 Noisy Predictions ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now analyze Mechanism B-RR-Plant-and-Steal\u2019s performance under varying levels of noise. Consider the case where the Kendall tau distance between v and $\\mathbf{p}$ is at most $d$ . Our main theorem in this section shows that \u221acombining the Plant-and-Steal framework with a Round-Robin allocation procedure obtains $O({\\sqrt{d}})$ -approximation to the MMS when the Kendall tau distance is $d$ . Missing proofs of this section appear in Appendix F. ", "page_idx": 7}, {"type": "text", "text": "To prove the approximation ratio, we relate the value that agent $i$ obtains from the allocation, $v_{i}(X_{i})$ , to their maximin share, $\\mu_{i}$ , by considering the worst possible set of items that agent $i$ might receive under the Round-Robin procedure when acting on their true preferences. Specifically, we define this Twhoersrte-fcoarsee,  soebt taais $R_{i}=\\{v_{i}^{2j}\\}_{j\\in\\{1,\\dots,\\lfloor m/2\\rfloor\\}}.$ .  fIanc tEoqr.  o(f2) otfi mLeesm , ewnse uprreos vae  ftahcatt $v_{i}(R_{i})\\geq\\mu_{i}/2$ $c$ $v_{i}(R_{i})$ $c/2$ MMS value. ", "page_idx": 7}, {"type": "text", "text": "We further simplify the analysis by applying the zero-one principle3. The zero-one principle basically let\u2019s us reduce the analysis to instances where the values are either 0\u2019s or 1\u2019s. For threshold $\\tau\\geq0$ , let $h_{\\tau}(q)=1$ if $q\\geq\\tau$ and 0 otherwise, and let $\\begin{array}{r}{v_{i}^{\\tau}(S)=\\sum_{j\\in S}h_{\\tau}(v_{i}(j))}\\end{array}$ . ", "page_idx": 7}, {"type": "text", "text": "By the zero-one principle, for two sets $S,T\\subseteq M$ , in order to show that ${v}_{i}(S)$ approximates $v_{i}(T)$ , it is enough to show that $v_{i}^{\\tau}(S)$ approximates $v_{i}^{\\tau}(T)$ for every threshold $\\tau\\geq0$ . ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.1. For $c>1$ and for any two sets $S,T\\subseteq M_{:}$ , if for every threshold $\\tau\\geq0$ , $v_{i}^{\\tau}(S)\\geq$ $v_{i}^{\\tau}(T)/c_{;}$ , then $v_{i}(S)\\geq v_{i}(T)/c$ . ", "page_idx": 7}, {"type": "text", "text": "Thus, we will show that when the Kendall tau distance is $d$ , for every threshold $\\tau\\geq0$ , $v_{i}^{\\tau}(X_{i})\\geq$ $v_{i}^{\\tau}(R_{i})/c$ for some $c=O({\\sqrt{d}})$ . Recall that $A_{i}$ is the set of items assigned to $i$ after running the Round-Robin procedure on the predictions $\\mathbf{p}$ . We first show that for Kendall tau distance $d$ , the additive approximation $v_{i}^{\\tau}(A_{i})$ gives to $v_{i}^{\\tau}(R_{i})$ is $\\sqrt{d}$ . ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.2. If the Kendall tau dist\u221aance between $\\mathbf{p}$ and $\\mathbf{v}$ is at most d, then for any threshold $\\tau\\geq0$ , we have that $v_{i}^{\\tau}(A_{i})\\geq v_{i}^{\\tau}(R_{i})-{\\sqrt{d}}.$ . ", "page_idx": 7}, {"type": "text", "text": "We note that although $v_{i}^{\\tau}(A_{i})$ gives an additive approximation to $v_{i}^{\\tau}(R_{i})$ , it can still be the case that the Kendall tau distance is constant, yet $v_{i}(A_{i})$ does not give any multiplicative approximation to $\\mu_{i}$ .4 Therefore, we must use the fact that agent $i$ gets to \u201csteal\u201d an item according to their true valuation in the Plant-and-Steal procedure in order to get our approximation guarantee. By combining these results, we prove the following theorem concerning the approximation ratio of B-RR-Plant-and-Steal\u2019s performance under varying levels of noise, $d$ . 5 ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.1. Consider a prediction \u221ap and valuations v such that $K_{d}(\\mathbf{v},\\mathbf{p})=d,$ , then Mechanism B-RR-Plant-and-Steal gives a $(2\\sqrt{d}+6)$ -approximation to the MMS. ", "page_idx": 7}, {"type": "text", "text": "6 Experimental Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section6, we give experiments which illustrate the role of different components of our framework for two players under various noise levels of the predictions. The predictions we use for our experiments are the predicted values of the items. The noise we introduce permutes the vectors of values to match the instance\u2019s Kendall tau distance, and uses the permuted vector as prediction. We show that our framework is almost optimal for small amounts of noise while still showing resilience for higher noise levels. Moreover, we study the performance of variants which only use specific components of our framework. ", "page_idx": 8}, {"type": "text", "text": "When using predictions, our initial allocation procedure is a cut-and-choose procedure, implemented as follows: ", "page_idx": 8}, {"type": "text", "text": "\u2022 We use the first player\u2019s prediction to implement a bag-filling algorithm which sorts the items by values, and then partitions the items into two sets using a greedy procedure that assigns each item to the set with current lowest value.   \n\u2022 We use the second player\u2019s prediction to allocate the agent the set with the higher predicted value of the two. ", "page_idx": 8}, {"type": "text", "text": "This allocation ensures that the second agent obtains their MMS value according to the prediction. In the data we generates, we observe that in a sampled valuation, the two sets chosen by the bag-fliling algorithm gives the two sets the same value, up to $0.5\\%$ , which ensures that the lowest valued set obtains a 1.026-approximation to the MMS. ", "page_idx": 8}, {"type": "text", "text": "We inspect the following mechanisms: ", "page_idx": 8}, {"type": "text", "text": "1. Random: a mechanism that ignores reports and predictions and randomly partitions the items into two sets of size $m/2$ .   \n2. Random-Steal: a mechanism that ignores predictions, randomly partitions the items into two sets of size $m/2$ , and then implements the stealing phase where each player takes their favorite item from the other player\u2019s set according to reports.   \n3. Partition: a mechanism that ignores reports, and partitions the items according to predictions, using the cut-and-choose procedure described above.   \n4. Partition-Steal: a mechanism that partitions the items according to predictions, using the cut-and-choose procedure described above, and then implements the stealing phase where each player takes their favorite item from the other player\u2019s set according to reports.   \n5. Partition-Plant-Steal: a mechanism that implements the Plant-and-Steal framework. partitions the items according to predictions, using the cut-and-choose procedure described above, \u201cplants\u201d each player\u2019s favorite item according to predictions, and then \u201csteals\u201d each player\u2019s favorite item from the other player\u2019s set according to reports. ", "page_idx": 8}, {"type": "text", "text": "Experiments. We consider two-player scenarios with $m=100$ items. For each distance measure, we generate 1000 valuation profiles. For each pair of valuation profiles and corresponding Kendall tau distance, we generate 100 predictions based on the distance. We then assess the performance of the mechanisms described earlier on these instances. We examine two distinct cases regarding the relationship between the players\u2019 preference orders: the Correlated case, where both players have identical preference orders, although their valuation magnitudes differ, and the Uncorrelated case, where the preference orders of the players are generated independently and chosen uniformly at random. Further details on the procedures used to generate the valuations and predictions are provided in Appendix A. ", "page_idx": 8}, {"type": "text", "text": "Benchmark. We plot the percentage of these instances where both players get at least $(1-\\epsilon)$ of their MMS value for $\\epsilon=0.1,0.05,0.02$ . ", "page_idx": 8}, {"type": "text", "text": "Results. The results are shown in Figure 1. We first examine the performance of the two mechanisms that do not use predictions, Random and Random-Steal. Scenarios with correlated values perform significantly worse, as there is a non-negligible probability of an unbalanced partition of the relatively few high and medium valued items in a random partition. For $\\epsilon$ values of 0.02, 0.05, 0.1, the Random strategy success rate is $11\\%$ , $25\\%$ , and $43\\%$ , respectively, under correlated preferences, compared to $33\\%$ , $43\\%$ , and $60\\%$ under uncorrelated preferences. Moreover, adding the stealing component significantly improves the success rate only in the uncorrelated case, as Random-Steal achieves success rates of $66\\%$ , $75\\%$ , and $87\\%$ . In the correlated case, as each player has a highly valuable item stolen, their obtained value is not expected to increase. ", "page_idx": 8}, {"type": "image", "img_path": "aFB97F8QSF/tmp/8a2afb6bb5df72c3a4662fbde3b91daeba838f3c57a52c8922ee0612a5c27b1d.jpg", "img_caption": ["Figure 1: Mechanisms: Random (yellow), Random-Steal (cyan), Partition (red), Partition-Steal (green), Partition-Plant-Steal (blue). Data generation: correlated (first row) and uncorrelated (second row). Success rate: the percentage of instances where both players receive at least $(1-\\epsilon)$ -fraction of their MMS values for different values of $\\epsilon\\colon0.02$ (first column), 0.05 (second column), and 0.1 (third column). "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "In the mechanisms that use predictions, Partition, Partition-Steal and Partition-Plant-Steal, the performance degrades as a function of noise, as expected. When comparing the performance of Partition, which only relies on the prediction component of our framework, and Random-Steal, which only relies on the stealing component of our framework, we notice that in the uncorrelated case, for small amount of noise guarantee a higher success rate, while as the noise increases, the stealing component becomes more instrumental to the performance. This is in tact with the theoretical results, where using the prediction is crucial to achieve the consistency guarantees, which take place when the prediction is accurate, while stealing is important to achieve robustness guarantees in case the prediction is inaccurate. As described above, in the case where the valuations are correlated, stealing is not expected to help. Interestingly, on fully noisy input, even Random outperforms Partition as Partition might partition the items into unequally-sized sets, which performs worse than the equally-sized sets Random outputs. ", "page_idx": 9}, {"type": "text", "text": "Our experiments show that Partition-Plant-Steal performs as well as the Partition strategy for small amounts of noise and outperforms it on uncorrelated instances for large amounts of noise. Moreover, for any amount of noise, it outperforms Random-Steal and converges to it for a fully noisy input. This illustrates the \u201cbest of both worlds\u201d tradeoff obtained by our framework. ", "page_idx": 9}, {"type": "text", "text": "Finally, when comparing the Partition-Plant-Steal strategy to the Partition-Steal strategy, we observe that Partition-Plant-Steal outperforms Partition-Steal in the correlated case with a small amount of noise (worst-case scenario) for $\\epsilon=0.02$ , as planting guarantees your favorite items would not be taken. In other scenarios, Partition-Steal outperforms Partition-Plant-Steal because \u201cplanting\u201d removes a valuable item from the player\u2019s set that might be taken otherwise, especially in the uncorrelated case. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Arsen Vasilyan was supported in part by NSF awards CCF-2006664, DMS-2022448, CCF-1565235, CCF-1955217, CCF-2310818, Big George Fellowship and Fintech@CSAIL. The work of A. Vasilyan was partially done while visiting Bar-Ilan university as a part of the MISTI-Israel program, supported by the Zuckerman Institute. Part of this work was conducted while Arsen Vasilyan was visiting the Simons Institute for the Theory of Computing. ", "page_idx": 10}, {"type": "text", "text": "The work of I.R. Cohen was supported in part by ISF grant 1737/21. The work of A. Eden was supported by the Israel Science Foundation (grant No. 533/23). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Priyank Agrawal, Eric Balkanski, Vasilis Gkatzelis, Tingting Ou, and Xizhi Tan. Learningaugmented mechanism design: Leveraging predictions for facility location. In David M. Pennock, Ilya Segal, and Sven Seuken, editors, EC \u201922: The 23rd ACM Conference on Economics and Computation, Boulder, CO, USA, July 11 - 15, 2022, pages 497\u2013528. ACM, 2022. doi: 10.1145/3490486.3538306. URL https://doi.org/10.1145/3490486.3538306.   \n[2] Elad Aigner-Horev and Erel Segal-Halevi. Envy-free matchings in bipartite graphs and their applications to fair division. Inf. Sci., 587:164\u2013187, 2022. doi: 10.1016/J.INS.2021.11.059. URL https://doi.org/10.1016/j.ins.2021.11.059.   \n[3] Hannaneh Akrami and Jugal Garg. Breaking the 3/4 barrier for approximate maximin share. CoRR, abs/2307.07304, 2023. doi: 10.48550/ARXIV.2307.07304. URL https://doi.org/ 10.48550/arXiv.2307.07304.   \n[4] Hannaneh Akrami, Jugal Garg, Eklavya Sharma, and Setareh Taki. Simplification and improvement of MMS approximation. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, China, pages 2485\u20132493. ijcai.org, 2023. doi: 10.24963/IJCAI.2023/276. URL https://doi.org/10.24963/ijcai.2023/276.   \n[5] Hannaneh Akrami, Jugal Garg, and Setareh Taki. Improving approximation guarantees for maximin share. CoRR, abs/2307.12916, 2023. doi: 10.48550/ARXIV.2307.12916. URL https://doi.org/10.48550/arXiv.2307.12916.   \n[6] Georgios Amanatidis, Georgios Birmpas, and Evangelos Markakis. On truthful mechanisms for maximin share allocations. In Subbarao Kambhampati, editor, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, pages 31\u201337. IJCAI/AAAI Press, 2016. URL http://www.ijcai.org/ Abstract/16/012.   \n[7] Georgios Amanatidis, Georgios Birmpas, George Christodoulou, and Evangelos Markakis. Truthful allocation mechanisms without payments: Characterization and implications on fairness. In Constantinos Daskalakis, Moshe Babaioff, and Herv\u00e9 Moulin, editors, Proceedings of the 2017 ACM Conference on Economics and Computation, EC \u201917, Cambridge, MA, USA, June 26-30, 2017, pages 545\u2013562. ACM, 2017. doi: 10.1145/3033274.3085147. URL https: //doi.org/10.1145/3033274.3085147.   \n[8] Georgios Amanatidis, Evangelos Markakis, Afshin Nikzad, and Amin Saberi. Approximation algorithms for computing maximin share allocations. ACM Trans. Algorithms, 13(4):52:1\u201352:28, 2017. doi: 10.1145/3147173. URL https://doi.org/10.1145/3147173.   \n[9] Georgios Amanatidis, Georgios Birmpas, Federico Fusco, Philip Lazos, Stefano Leonardi, and Rebecca Reiffenh\u00e4user. Allocating indivisible goods to strategic agents: Pure nash equilibria and fairness. In Michal Feldman, Hu Fu, and Inbal Talgam-Cohen, editors, Web and Internet Economics - 17th International Conference, WINE 2021, Potsdam, Germany, December 14-17, 2021, Proceedings, volume 13112 of Lecture Notes in Computer Science, pages 149\u2013166. Springer, 2021. doi: 10.1007/978-3-030-94676-0\\_9. URL https://doi.org/10.1007/ 978-3-030-94676-0_9.   \n[10] Georgios Amanatidis, Haris Aziz, Georgios Birmpas, Aris Filos-Ratsikas, Bo Li, Herv\u00e9 Moulin, Alexandros A. Voudouris, and Xiaowei Wu. Fair division of indivisible goods: Recent progress and open questions. Artif. Intell., 322:103965, 2023. doi: 10.1016/J.ARTINT.2023.103965. URL https://doi.org/10.1016/j.artint.2023.103965.   \n[11] Yossi Azar and Yossi Richter. The zero-one principle for switching networks. In L\u00e1szl\u00f3 Babai, editor, Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, June 13-16, 2004, pages 64\u201371. ACM, 2004. doi: 10.1145/1007352.1007369. URL https://doi.org/10.1145/1007352.1007369.   \n[12] Moshe Babaioff, Tomer Ezra, and Uriel Feige. Fair and truthful mechanisms for dichotomous valuations. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, pages 5119\u20135126. AAAI Press, 2021. doi: 10.1609/AAAI.V35I6.16647. URL https://doi.org/10.1609/aaai.v35i6.16647.   \n[13] Maria-Florina Balcan, Siddharth Prasad, and Tuomas Sandholm. Bicriteria multidimensional mechanism design with side information. CoRR, abs/2302.14234, 2023. doi: 10.48550/ARXIV. 2302.14234. URL https://doi.org/10.48550/arXiv.2302.14234.   \n[14] Eric Balkanski, Vasilis Gkatzelis, and Xizhi Tan. Strategyproof scheduling with predictions. In Yael Tauman Kalai, editor, 14th Innovations in Theoretical Computer Science Conference, ITCS 2023, January 10-13, 2023, MIT, Cambridge, Massachusetts, USA, volume 251 of LIPIcs, pages 11:1\u201311:22. Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, 2023. doi: 10.4230/ LIPICS.ITCS.2023.11. URL https://doi.org/10.4230/LIPIcs.ITCS.2023.11.   \n[15] Eric Balkanski, Vasilis Gkatzelis, Xizhi Tan, and Cherlin Zhu. Online mechanism design with predictions. CoRR, abs/2310.02879, 2023. doi: 10.48550/ARXIV.2310.02879. URL https://doi.org/10.48550/arXiv.2310.02879.   \n[16] Siddharth Barman and Sanath Kumar Krishnamurthy. Approximation algorithms for maximin fair division. ACM Trans. Economics and Comput., 8(1):5:1\u20135:28, 2020. doi: 10.1145/3381525. URL https://doi.org/10.1145/3381525.   \n[17] Sylvain Bouveret and Michel Lema\u00eetre. Characterizing conflicts in fair division of indivisible goods using a scale of criteria. Auton. Agents Multi Agent Syst., 30(2):259\u2013290, 2016. doi: 10.1007/S10458-015-9287-3. URL https://doi.org/10.1007/s10458-015-9287-3.   \n[18] Eric Budish. The combinatorial assignment problem: Approximate competitive equilibrium from equal incomes. Journal of Political Economy, 119(6):1061\u20131103, 2011.   \n[19] Ioannis Caragiannis and Georgios Kalantzis. Randomized learning-augmented auctions with revenue guarantees. CoRR, abs/2401.13384, 2024. doi: 10.48550/ARXIV.2401.13384. URL https://doi.org/10.48550/arXiv.2401.13384.   \n[20] Ilan Reuven Cohen and Debmalya Panigrahi. A General Framework for Learning-Augmented Online Allocation. In 50th International Colloquium on Automata, Languages, and Programming (ICALP 2023), volume 261 of Leibniz International Proceedings in Informatics (LIPIcs), pages 43:1\u201343:21, 2023. ISBN 978-3-95977-278-5. doi: 10.4230/LIPIcs.ICALP.2023.43.   \n[21] Nikhil R. Devanur and Thomas P. Hayes. The adwords problem: online keyword matching with budgeted bidders under random permutations. In John Chuang, Lance Fortnow, and Pearl Pu, editors, Proceedings 10th ACM Conference on Electronic Commerce (EC-2009), Stanford, California, USA, July 6\u201310, 2009, pages 71\u201378. ACM, 2009. doi: 10.1145/1566374.1566384. URL https://doi.org/10.1145/1566374.1566384.   \n[22] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for MMS fair allocations. In Michal Feldman, Hu Fu, and Inbal Talgam-Cohen, editors, Web and Internet Economics - 17th International Conference, WINE 2021, Potsdam, Germany, December 14-17, 2021, Proceedings, volume 13112 of Lecture Notes in Computer Science, pages 355\u2013372. Springer, 2021. doi: 10. 1007/978-3-030-94676-0\\_20. URL https://doi.org/10.1007/978-3-030-94676-0_ 20.   \n[23] Jugal Garg, Peter McGlaughlin, and Setareh Taki. Approximating maximin share allocations. In Jeremy T. Fineman and Michael Mitzenmacher, editors, 2nd Symposium on Simplicity in Algorithms, SOSA 2019, January 8-9, 2019, San Diego, CA, USA, volume 69 of OASIcs, pages 20:1\u201320:11. Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, 2019. doi: 10.4230/OASICS. SOSA.2019.20. URL https://doi.org/10.4230/OASIcs.SOSA.2019.20.   \n[24] Mohammad Ghodsi, Mohammad Taghi Hajiaghayi, Masoud Seddighin, Saeed Seddighin, and Hadi Yami. Fair allocation of indivisible goods: Improvements and generalizations. In \u00c9va Tardos, Edith Elkind, and Rakesh Vohra, editors, Proceedings of the 2018 ACM Conference on Economics and Computation, Ithaca, NY, USA, June 18-22, 2018, pages 539\u2013556. ACM, 2018. doi: 10.1145/3219166.3219238. URL https://doi.org/10.1145/3219166.3219238.   \n[25] Vasilis Gkatzelis, Kostas Kollias, Alkmini Sgouritsa, and Xizhi Tan. Improved price of anarchy via predictions. In David M. Pennock, Ilya Segal, and Sven Seuken, editors, EC \u201922: The 23rd ACM Conference on Economics and Computation, pages 529\u2013557. ACM, 2022. doi: 10.1145/3490486.3538296. URL https://doi.org/10.1145/3490486.3538296.   \n[26] Vasilis Gkatzelis, Alexandros Psomas, Xizhi Tan, and Paritosh Verma. Getting more by knowing less: Bayesian incentive compatible mechanisms for fair division. CoRR, abs/2306.02040, 2023. doi: 10.48550/ARXIV.2306.02040. URL https://doi.org/10.48550/arXiv.2306. 02040.   \n[27] Hadi Hosseini and Andrew Searns. Guaranteeing maximin shares: Some agents left behind. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, pages 238\u2013244. ijcai.org, 2021. doi: 10.24963/IJCAI.2021/34. URL https://doi.org/10.24963/ijcai. 2021/34.   \n[28] Hadi Hosseini, Andrew Searns, and Erel Segal-Halevi. Ordinal maximin share approximation for goods (extended abstract). In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, China, pages 6894\u20136899. ijcai.org, 2023. doi: 10.24963/IJCAI.2023/778. URL https://doi.org/10. 24963/ijcai.2023/778.   \n[29] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index structures. In Gautam Das, Christopher M. Jermaine, and Philip A. Bernstein, editors, Proceedings of the 2018 International Conference on Management of Data, SIGMOD Conference 2018, Houston, TX, USA, June 10-15, 2018, pages 489\u2013504. ACM, 2018. doi: 10.1145/3183713.3196909. URL https://doi.org/10.1145/3183713.3196909.   \n[30] David Kurokawa, Ariel D. Procaccia, and Junxing Wang. Fair enough: Guaranteeing approximate maximin shares. J. ACM, 65(2):8:1\u20138:27, 2018. doi: 10.1145/3140756. URL https://doi.org/10.1145/3140756.   \n[31] T Lavastida, B Moseley, R Ravi, and C Xu. Learnable and instance-robust predictions for online matching, flows and load balancing. In European Symposium on Algorithms, 2021.   \n[32] Shi Li and Jiayi Xian. Online unrelated machine load balancing with predictions revisited. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 6523\u20136532. PMLR, 2021. URL http://proceedings. mlr.press/v139/li21w.html.   \n[33] Pinyan Lu, Zongqi Wan, and Jialin Zhang. Competitive auctions with imperfect predictions. CoRR, abs/2309.15414, 2023. doi: 10.48550/ARXIV.2309.15414. URL https://doi.org/ 10.48550/arXiv.2309.15414.   \n[34] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. J. ACM, 68(4):24:1\u201324:25, 2021. doi: 10.1145/3447579. URL https://doi.org/10.1145/ 3447579.   \n[35] Michael Mitzenmacher. How useful is old information? IEEE Trans. Parallel Distributed Syst., 11(1):6\u201320, 2000. doi: 10.1109/71.824633. URL https://doi.org/10.1109/71.824633. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "[36] Benjamin Plaut and Tim Roughgarden. Almost envy-freeness with general valuations. SIAM J. Discret. Math., 34(2):1039\u20131068, 2020. doi: 10.1137/19M124397X. URL https://doi. org/10.1137/19M124397X. ", "page_idx": 13}, {"type": "text", "text": "[37] Biaoshuai Tao. On existence of truthful fair cake cutting mechanisms. In David M. Pennock, Ilya Segal, and Sven Seuken, editors, EC \u201922: The 23rd ACM Conference on Economics and Computation, Boulder, CO, USA, July 11 - 15, 2022, pages 404\u2013434. ACM, 2022. doi: 10.1145/3490486.3538321. URL https://doi.org/10.1145/3490486.3538321. ", "page_idx": 13}, {"type": "text", "text": "[38] Erik Vee, Sergei Vassilvitskii, and Jayavel Shanmugasundaram. Optimal online assignment with forecasts. In David C. Parkes, Chrysanthos Dellarocas, and Moshe Tennenholtz, editors, Proceedings 11th ACM Conference on Electronic Commerce (EC-2010), Cambridge, Massachusetts, USA, June 7-11, 2010, pages 109\u2013118. ACM, 2010. doi: 10.1145/1807342.1807360. URL https://doi.org/10.1145/1807342.1807360. ", "page_idx": 13}, {"type": "text", "text": "[39] Adam Wierman and Misja Nuyens. Scheduling despite inexact job-size information. In Zhen Liu, Vishal Misra, and Prashant J. Shenoy, editors, Proceedings of the 2008 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, SIGMETRICS 2008, pages 25\u201336. ACM, 2008. doi: 10.1145/1375457.1375461. URL https://doi.org/ 10.1145/1375457.1375461. ", "page_idx": 13}, {"type": "text", "text": "[40] Chenyang Xu and Pinyan Lu. Mechanism design with predictions. In Luc De Raedt, editor, Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, pages 571\u2013577. ijcai.org, 2022. doi: 10.24963/IJCAI.2022/81. URL https://doi. org/10.24963/ijcai.2022/81. ", "page_idx": 13}, {"type": "text", "text": "A Experimental Supplement ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Generating valuations. To generate interesting valuations for the players, we use a multi-step function to generate item values, since if the values are close together, any balanced partition obtains good MMS guarantees, without considering reports and predictions. Specifically, we consider a four-step (High/Med/Low/Extra-Low) random valuation function, where an item has a High valuation with probability $8/m$ , a Medium valuation with probability $1/4$ , a Low valuation with probability $1/2$ and an Extra-Low valuation with the remaining probability. A High valuation is drawn from $\\dot{U}[1000,2000]$ , a Medium valuation is drawn from $U[400,800]$ , a Low valuations is drawn from $U[100,200]$ and an Extra-Low valuation is sampled from $U[1,2]$ . Figure 2 shows the value distribution generated by this process for two players. We generate values for $m=100$ items. ", "page_idx": 13}, {"type": "text", "text": "We generate valuations satisfying one of the two types of relations between players\u2019 preferences: ", "page_idx": 13}, {"type": "text", "text": "\u2022 Correlated: the two preference orders are identical (but not the values).   \n\u2022 Uncorrelated: Both preference orders are chosen independently and uniformly at random. ", "page_idx": 13}, {"type": "text", "text": "Generating predictions. To generate predictions, we take valuations and permute elements randomly to create noise. We generate predictions under varying noise levels according to the Kendall tau distance between the valuations and the predictions. We very the Kendall tau distance between 1 to 2560, where 2560 corresponds to the expected noise level of a random permutation of 100 items. To randomly choose a permutation of a certain noise level, we start with the ordered permutation and then choose two indices $j<k$ u.a.r. and swap items $r$ and $r+1$ for $r\\in\\{j,\\ldots,k-1\\}$ if it increases the Kendall Tau distance by one. We repeat this process until the distance of the resulting permutation equals the desired value. ", "page_idx": 13}, {"type": "text", "text": "B Related Work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The notion of the maximin share allocation was introduced by Budish [18] as an ordinal notion, and extended to the notion we adopt by Bouveret and Lema\u00eetre [17]. Using machine learning advice in algorithm design was used in theory [21, 38] and practice [29]. The learning-augmented framework of studying consistency-robustness tradeoffs was introduced by Lykouris and Vassilvitskii [34]. [35, 39] studied the performance of algorithms using imprecise predictions. ", "page_idx": 13}, {"type": "image", "img_path": "aFB97F8QSF/tmp/f1b383ba13fe004cb141b2226306506207184e1bd014a59a8a04e89828ebd151.jpg", "img_caption": ["Figure 2: Plotting randomly sampled valuations for two players, where the values are sorted such that lower indexed items have higher values. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Fair division with incentives. The two closest papers to ours are Amanatidis et al. [6, 7]. In [6], they initiate the study of truthful mechanisms for approximating the MMS value for agents with additive valuations. They show that no truthful mechanism can get an approximation better than $1/2$ for the MMS in the case of 2 agents and 4 items. They give the best known approximation guarantee for $n$ agents and $m$ items of $\\textstyle{\\frac{\\bar{m}-n+2}{2}}\\rfloor$ . Finally they consider the public ranking model, where the ranking over items is public information. Using this, they are able to obtain a n2+ 1-approximation algorithm. One can view this as an algorithm that is given a prediction over the input, but does not provide robustness guarantees. [7] Fully characterize truthful mechanism for 2 agents with additive valuations. They use this characterization to provide a strong lower bound of $\\textstyle\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor$ for any truthful mechanism. ", "page_idx": 14}, {"type": "text", "text": "[12] design truthful mechanisms for dichotomous submodular valuations that maximize welfare, along with desirable fairness properties such as EFX and NSW. For additive binary valuations, they also maximize the MMS in a truthful manner. [26] bypass the impossibilities imposed by [7, 37] for truthful fair allocations with indivisible and divisible goods by considering Bayesian Incentive Compatible mechanisms with symmetric priors. They are able to obtain EF-1 allocations for indivisible goods and proportional allocations for indivisible goods. ", "page_idx": 14}, {"type": "text", "text": "Finally, [9] study the Nash equilibrium for simple mechanisms for agents with additive valuations. They show that for every number of agents, the Pure Nash equilibrium of the Round-Robin procedure produces an EF-1 allocation. For two agents, they show that the Pure Nash equilibrium of Plaut and Roughgarden [36] cut-and-choose procedure produces an EFX and MMS allocation. ", "page_idx": 14}, {"type": "text", "text": "1-out-of- $k$ . As stated above, the MMS value of an agent is defined by the highest value an agent can guarantee for themselves when partitioning the items into $n$ different bundles, where $n$ is the number of agents, and then getting the lowest valued bundle. Thus, an agent get a value larger than the worst one-out-of- ${\\mathbf{\\nabla}}n$ bundles that define the MMS. ", "page_idx": 14}, {"type": "text", "text": "Noticing that finding an allocation that satisfies the MMS value of each agent is a demanding task (which was shown to be infeasible in some cases by Kurokawa et al. [30]), Budish [18] relaxed the notion and defined the 1-out-of- ${\\cdot n+1}$ MMS to be the worst bundle out of the bundles that define the MMS when partitioning the items using an additional bundle. [18] showed it is possible to achieve this benchmark when adding a small number of access goods. There has been an effort to find the smallest $k$ for which an allocation that guarantees a 1-out-of- $k$ MMS for each agent exists. [2] were able to show the existence for $k=2n-2$ , [27, 28] achieved $\\begin{array}{r}{k=\\left\\lceil\\frac{3n}{2}\\right\\rceil}\\end{array}$ , and recently, [5] showed the smallest up-to-date $\\textstyle k=\\left\\lceil{\\frac{4n}{3}}\\right\\rceil$ . In our $n$ -agent mechanism, our robustness guarantee approximates this relaxed benchmark for $\\textstyle k=\\left\\lceil{\\frac{3n}{2}}\\right\\rceil$ . ", "page_idx": 14}, {"type": "text", "text": "Learning-Augmented Mechanisms. Agrawal et al. [1] and $\\mathrm{Xu}$ and Lu [40] first explored the learning-augmented framework in a mechanism design setting, where [1] studied the facility location problem while [40] applied the framework to several settings such as revenue-maximization, path auctions, scheduling and two-facility games. [14] give nearly optimal consistency-robustness tradeoffs to the strategyproof scheduling with unrelated machines. [25] use predictions to design mechanisms with improved Price of Anarchy bounds. [33, 19] study revenue maximization auctions with predictions, and [13] devise bicriteria mechanisms. ", "page_idx": 15}, {"type": "text", "text": "C Deferred proofs from Section 3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 3.1. We show that agent 1 is better off reporting their true valuation, a symmetric argument holds for agent 2. First, notice that sets $T_{1}$ and $T_{2}$ are determined using predictions, ignoring the reports. Next, notice that the item $\\tilde{j}_{2}$ is chosen only using agent 2\u2019s report. Therefore, the only way agent 1 can affect their allocation is by choosing which item in $T_{2}$ is allocated to them. agent 1 gets their favorite item in $T_{2}$ according to their report. Therefore, it is clear that the agent maximize their utility by reporting their true value. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 3.2. Consider some agent $i$ . We claim for every partition of the items into two non-empty sets, $T_{1},T_{2}$ , $i$ is always guaranteed to have one of their two favorite items according to their true valuation $v_{i}$ in $X_{i}$ . This is because either $(I)\\textsl{i}$ has one of their two favorite items in $T_{\\ell}$ , $\\ell\\neq i$ , and $i$ gets their favorite item from $T_{\\ell}$ ; or (2) $i$ \u2019s two favorite items are in $T_{i}$ , and in this case, $i$ gets all items from $T_{i}$ but one, so $i$ is guaranteed one of them. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 3.3. Let $g\\in S\\cap\\{v_{i}^{1},v_{i}^{2}\\}$ , by the definition of $S$ such $g$ exists. Let $S^{\\prime}=S\\setminus\\{g\\}$ , by the definition of $S$ , we have $|S^{\\prime}|=k-1$ and $v_{i}(S)\\geq v_{i}^{2}+v_{i}(S^{\\prime})$ . Consider a partition ", "page_idx": 15}, {"type": "equation", "text": "$$\n(S_{1},S_{2})\\in\\arg\\operatorname*{max}_{(T_{1},T_{2})}:T_{1}\\cup T_{2}{=}M\\operatorname*{min}_{j\\in\\{1,2\\}}v_{i}(T_{j}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By definition, $\\begin{array}{r}{\\mu_{i}=\\operatorname*{min}_{j\\in\\{1,2\\}}v_{i}(S_{j})}\\end{array}$ . We have, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\frac{\\mu_{i}}{v_{i}(S)}}&{\\leq}&{\\frac{\\mu_{i}}{v_{i}^{2}+v_{i}(S^{\\prime})}}\\\\ &{=}&{\\frac{\\operatorname*{min}_{j\\in\\{1,2\\}}v_{i}(S_{j})}{v_{i}^{2}+v_{i}(S^{\\prime})}}\\\\ &{\\leq}&{\\frac{\\operatorname*{min}_{j\\in\\{1,2\\}}v_{i}(S_{j})-v_{i}(S^{\\prime})}{v_{i}^{2}}}\\\\ &{\\leq}&{\\frac{\\operatorname*{min}_{j\\in\\{1,2\\}}v_{i}(S_{j})\\,\\langle S_{j}\\rangle}{v_{i}^{2}}}\\\\ &{\\leq}&{\\frac{\\operatorname*{min}_{j\\in\\{1,2\\}}\\{|S_{j}\\rangle\\,\\langle S^{\\prime}|\\,\\operatorname*{max}\\{v_{i}(\\ell):\\ell\\in S_{j}\\}\\,S^{\\prime}\\rangle\\}}{v_{i}^{2}}}\\\\ &{\\leq}&{\\frac{(m-k)\\cdot\\operatorname*{min}_{j\\in\\{1,2\\}}\\operatorname*{max}\\{v_{i}(\\ell):\\ell\\in S_{j}\\}}{v_{i}^{2}}}\\\\ &{\\leq}&{m-k.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the before last inequality is since if $S_{j}\\subseteq S^{\\prime}$ for some $j$ , then $v_{i}^{2}+v_{i}(S^{\\prime})\\geq\\mu_{i}$ ; therefore $S_{1}\\setminus S^{\\prime}$ and $S_{2}\\setminus S^{\\prime}$ are two disjoint non empty subsets and $|S_{1}\\setminus S^{\\prime}|+|\\dot{S_{2}}\\setminus S^{\\prime}|=m-k+1$ , hence the maximum number of elements in one of these subsets is $m-k$ . \u53e3 ", "page_idx": 15}, {"type": "text", "text": "D Deferred proofs from Section 4 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 4.1. By Observation 4.1, we have $v_{i}(a_{i}^{k})\\geq v_{i}^{2k}$ , therefore ", "page_idx": 15}, {"type": "equation", "text": "$$\nv_{i}(A_{i})=\\sum_{k=1}^{|A_{i}|}a_{i}^{k}\\geq\\sum_{k=1}^{\\lfloor m/2\\rfloor}v_{i}^{2k}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $i$ \u2019s favorite item must be absent from some set of the sets defining the MMS value, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{k=2}^{m}v_{i}^{k}\\geq\\mu_{i}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since the $v_{i}^{k}$ are ordered, $v_{i}^{2k}\\geq v_{i}^{2k+1}$ , hence $\\begin{array}{r}{\\sum_{k=1}^{\\lfloor m/2\\rfloor}v_{i}^{2k}\\ge\\sum_{k=1}^{\\lfloor m/2\\rfloor}v_{i}^{2k+1}}\\end{array}$ . Therefore, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\lfloor m/2\\rfloor}v_{i}^{2k}\\geq\\mu_{i}/2\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Equations (1),(2), we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\nv_{i}(A_{i})\\geq\\sum_{k=1}^{\\lfloor m/2\\rfloor}v_{i}^{2k}\\geq\\mu_{i}/2.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma 4.2. Let $j_{1}$ be the first item assigned in Balanced-Round-Robin to agent 1. By definition, $j_{1}$ is agent 1\u2019s favorite item in $M$ according to $p_{1}$ . Clearly, in Plant-and-Steal, $j_{1}$ is also agent 1\u2019s favorite item in $A_{1}\\subseteq M$ according to $p_{1}$ . Hence, $\\hat{j}_{1}=j_{1}$ . By the definition of Plant-and-Steal, $j_{1}\\in T_{2}$ . Since we assume the prediction corresponds to agent 1\u2019s actual value, $j_{1}$ is also agent 1\u2019s favorite item in $T_{2}\\subseteq M$ , which implies $\\tilde{j}_{1}=j_{1}$ . ", "page_idx": 16}, {"type": "text", "text": "Similarly Let $j_{2}$ be the first item assigned in Balanced-Round-Robin to agent 2. By definition, $j_{2}$ is agent 2\u2019s favorite item in $M\\setminus\\{j_{1}\\}$ according to $p_{2}$ . Since $j_{1}\\in A_{1}$ , $A_{2}\\subseteq M\\setminus\\{\\dot{j}_{1}\\}$ . Therefore, $j_{2}$ is also agent 2\u2019s favorite item in $A_{2}$ according to $p_{2}$ . Hence, $\\hat{j}_{2}=j_{2}$ . Since we established that $\\hat{j}_{1}=j_{1}$ , we have that $T_{1}\\subseteq M\\setminus\\{j_{1}\\}$ and $j_{2}\\in T_{1}$ . Since we assume the prediction corresponds to agent 1\u2019s actual value, $j_{2}$ is also agent 1\u2019s favorite item in $T_{1}$ , implying $\\tilde{j}_{2}=j_{2}$ . We get that $X_{1}=A_{1}$ and $X_{2}=A_{2}$ as required. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "E 1-2-RR-Plant-and-Steal Mechanism: $\\mathbf{A}\\,3/2$ -consistent, $\\lfloor{^{2m}}/{3}\\rfloor$ -robust Mechanism ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we show that using a modified round-robin allocation procedure to instantiate the Plant-and-Steal framework give an improved $3/2$ consistency guarantee, while maintaining $O(m)$ robustness. Consider the Balanced-Round-Robinallocation procedure depicted in Algorithm 2. One can show that the agent that picks first actually gets a value at least as large as their MMS, while for the second agent this analysis is indeed tight.7 In order to compensate agent 2, 1-2-Round-Robin lets this agent pick two items each round. See Algorithm 3 for details. ", "page_idx": 16}, {"type": "table", "img_path": "aFB97F8QSF/tmp/6ed1223aff0119df4023f4d2041b34c2568b9afc30e48c64cf70328ada4c7f53.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "Let $a_{i}^{k}$ be agent $i$ \u2019s $k$ th choice in 1-2-Round-Robin, we observe the following. ", "page_idx": 16}, {"type": "text", "text": "Observation E.1. The output $(A_{1},A_{2})$ of the 1-2-Round-Robin procedure, satisfies: ", "page_idx": 16}, {"type": "text", "text": "7Consider the case where the agents\u2019 valuations are $(m\\!-\\!1,1,\\ldots,1)$ . According to Round-Robing allocation, the first item will be assigned to agent 1, and agent 2 will have $m/2$ items of value 1, while $\\mu_{2}=m-1$ . ", "page_idx": 16}, {"type": "text", "text": "Amanatidis et al. [6] show that 1-2-Round-Robin guarantees each agent $2/3$ of their MMS. We provide the proof for completeness. ", "page_idx": 17}, {"type": "text", "text": "Lemma E.1 (Amanatidis et al. [6]). Let $(A_{1},A_{2})$ be the allocation of 1-2-Round-Robin. For every agent $i$ , $v_{i}(A_{i})\\geq2\\mu_{i}/3$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. We first prove the approximation for player 1 (the first player to be allocated). First, observe that $v_{1}(M)\\geq2\\mu_{1}$ . Let $I_{1}{\\stackrel{\\rightharpoonup}{=}}\\{v_{1}^{3k-2}\\,:\\,k=1,\\dot{\\ldots}\\,,[m/3]\\}$ be the worst possible allocation agent 1 might get in the 1-2-Round-Robin allocation. Notice that $v_{1}(I_{1})\\,\\geq\\,^{-}\\!v_{1}(M)/3\\,\\geq\\,2\\mu_{1}/3$ . By Observation E.1, $v_{1}(a_{1}^{k})\\geq v_{1}^{3k-2}$ . Therefore, $v_{1}(A_{1})\\geq v_{1}(I_{1})\\geq2\\mu_{1}/3$ . ", "page_idx": 17}, {"type": "text", "text": "Now consider player 2. As stated in the proof of Lemma 4.1, $v_{2}(M\\setminus v_{2}^{1})\\geq\\mu_{2}$ . Let ", "page_idx": 17}, {"type": "equation", "text": "$I_{2}^{a}=\\{v_{2}^{3k-1}\\,:\\,k\\in\\mathbb{N}_{>0}\\,\\wedge\\,3k-1\\leq m\\}$ ", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "First, notice that ", "page_idx": 17}, {"type": "equation", "text": "$$\nv_{2}(I_{2}^{a}\\cup I_{2}^{b})\\ \\geq\\ 2v_{2}(M\\setminus v_{2}^{1})/3\\ \\geq\\ 2\\mu_{2}/3.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Moreover, by Observation E.1, we have, $v_{2}(a_{2}^{2k-1})\\ \\geq\\ v_{2}^{3k-1}$ , and $v_{2}(a_{2}^{2k})~\\geq~v_{2}^{3k}$ . Therefore, $v_{2}(A_{2})\\geq v_{2}(I_{2}^{a}\\cup I_{2}^{b})\\geq2\\mu_{2}/3$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "The mechanism we consider in this section, 1-2-RR-Plant-and-Steal, results from instantiating Plant-and-Steal with 1-2-Round-Robin as $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 17}, {"type": "text", "text": "The next lemma states that if the predictions correspond to the preference orders of the real valuations, then 1-2-RR-Plant-and-Steal outputs the same allocation as 1-2-Round-Robin. The proof is omitted as it is identical to the proof of 4.2. ", "page_idx": 17}, {"type": "text", "text": "Lemma E.2. When predictions correspond to actual values, 1-2-RR-Plant-and-Stealoutputs the same allocation as 1-2-Round-Robin. ", "page_idx": 17}, {"type": "text", "text": "We next show that in 1-2-RR-Plant-and-Steal we are able to achieve a better consistency, while slightly weakening the robustness guarantee. ", "page_idx": 17}, {"type": "text", "text": "Theorem E.1. Mechanism 1-2-RR-Plant-and-Steal is truthful, 3/2-consistent and $\\lfloor{\\frac{2m}{3}}\\rfloor$ -robust. ", "page_idx": 17}, {"type": "text", "text": "Proof. By Lemma 3.1, the mechanism is truthful. By Observation E.1, each agent receives at least $\\lceil m/3\\rceil$ items; combining with Lemma 3.4, we get that the mechanism is $\\lfloor\\frac{\\overline{{2}}m}{3}\\rfloor$ -robust. Finally, if predictions correspond to valuations, by Lemma E.1 and Lemma E.2, the allocation is $3/2\\cdot$ approximation to the MMS. Thus, the mechanism is $2/3$ -consistent. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "F Deferred proofs from Section 5 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof of Lemma 5.1. Let $S=\\{s_{1},\\ldots,s_{k}\\}$ ( $|S|=k;$ ) and $T=\\left\\{t_{1},\\dots,t_{\\ell}\\right\\}\\left(|T|=\\ell\\right)$ . We have the following. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{v_{i}(S)}&{=}&{\\displaystyle\\sum_{j=1}^{k}v_{i}(s_{j})=\\sum_{j=1}^{k}\\int_{0}^{\\infty}h_{\\tau}(v_{i}(s_{j}))d\\tau=\\int_{0}^{\\infty}\\sum_{j=1}^{k}h_{\\tau}(v_{i}(s_{j}))d\\tau=\\int_{0}^{\\infty}v_{i}^{\\tau}(S)d\\tau}\\\\ &{\\ge}&{\\displaystyle\\int_{0}^{\\infty}v_{i}^{\\tau}(T)/c\\,d\\tau=\\frac{1}{c}\\int_{0}^{\\infty}\\sum_{j=1}^{\\ell}h_{\\tau}(t_{j})d\\tau=\\frac{1}{c}\\sum_{j=1}^{\\ell}\\int_{0}^{\\infty}h_{\\tau}(t_{j})d\\tau=\\frac{1}{c}\\sum_{j=1}^{\\ell}v_{i}(t_{j})}\\\\ &{=}&{v_{i}(T)/c,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where we use the identity $\\begin{array}{r}{\\int_{0}^{\\infty}h_{\\tau}(q)d\\tau=q}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "Proof of Lemma 5.2. Let $\\left\\lfloor{\\frac{m}{2}}\\right\\rfloor\\,\\leq\\,m_{i}\\,\\leq\\,\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ be the number of items agent $i$ gets by Mechanism B-RR-Plant-and-Steal. Let $A_{i}\\,=\\,\\{a_{i}^{1},a_{i}^{2},\\ldots,a_{i}^{m_{i}}\\}$ be the items assigned to agent $i$ in the ", "page_idx": 17}, {"type": "text", "text": "Round-Robin according to the predicted orderings $\\mathbf{p}$ , where $a_{i}^{\\ell}$ is the item allocated to $i$ in the $\\ell^{\\mathrm{th}}$ round of Round-Robin. First, by Observation 4.1, we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\na_{i}^{\\ell}\\in\\{p_{i}^{j}\\}_{j\\in\\{1,\\dots,2\\ell\\}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For a fixed $\\tau\\geq0$ , let $L_{\\tau}=v_{i}^{\\tau}(R_{i})$ be the number of values larger than threshold $\\tau$ in $R_{i}$ . We show that if the Kendall tau distance is at most $d$ , then it must be the case that ", "page_idx": 18}, {"type": "equation", "text": "$$\nv_{i}^{\\tau}(A_{i})\\geq L_{\\tau}-{\\sqrt{d}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that $h_{\\tau}(v_{i}^{k})=1$ for $k\\leq2\\cdot L_{\\tau}$ since $R_{i}$ gets every second item by the sorted values of agent $i$ . This implies that if $h_{\\tau}(v_{1}(a_{i}^{\\ell}))=0$ then $a_{i}^{\\ell}=v_{i}^{k}$ for $k>2\\cdot L_{\\tau}$ . Moreover, if $\\ell\\leq L_{\\tau}$ then $a_{i}^{\\ell}=p_{i}^{k}$ for $k\\leq2\\cdot L_{\\tau}$ by Eq. (3). Thus, if $\\begin{array}{r}{\\sum_{k=1}^{L_{\\tau}}h_{\\tau}(v_{1}(a_{i}^{k}))<L_{\\tau}-\\sqrt{d}}\\end{array}$ there are strictly more than $\\lceil\\sqrt{d}\\rceil$ items whose rank according to th e true valuation is at most $2\\cdot L_{\\tau}$ , and their rank according to the prediction is at least $2\\cdot L_{\\tau}+1$ . We show that this implies that the Kendall tau distance is larger than $d$ , yielding a contradiction. Formally, let ", "page_idx": 18}, {"type": "equation", "text": "$$\nG_{1}=\\{v_{1}^{k}\\}_{k\\in\\{1,\\dots,2\\cdot L_{\\tau}\\}}\\setminus\\{p_{1}^{k}\\}_{k\\in\\{1,\\dots,2\\cdot L_{\\tau}\\}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "be the set of items whose rank is at most $2\\cdot L_{\\tau}$ according to the real values but not according to the predictions, and let ", "page_idx": 18}, {"type": "equation", "text": "$$\nG_{2}=\\{v_{1}^{k}\\}_{k\\in\\{2:L_{\\tau}+1,\\dots,m\\}}\\setminus\\{p_{1}^{k}\\}_{k\\in\\{2:L_{\\tau}+1,\\dots,m\\}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "be the set of items whose rank is strictly larger than $2\\cdot L_{\\tau}$ according to the real values but not according to the predictions. By the above, $\\left|G_{1}\\right|=\\left|G_{2}\\right|>\\left\\lceil{\\sqrt{d}}\\right\\rceil$ , and for each pair $j\\in G_{1},j^{\\prime}\\in G_{2}$ , ", "page_idx": 18}, {"type": "text", "text": "1. $j$ rank according to $v_{i}$ is at most $2\\cdot L_{\\tau}$ and $j^{\\prime}$ rank according to $v_{i}$ is at least $2\\cdot L_{\\tau}+1$ ; ", "page_idx": 18}, {"type": "text", "text": "That is, $j$ and $j^{\\prime}$ are ordered oppositely in the ordering according to $p_{i}$ and $v_{i}$ . Since there are $|G_{1}|\\ .$ $|G_{2}|>d$ such pairs, we get that the Kendall tau distance is strictly greater than $d$ , a contradiction. ", "page_idx": 18}, {"type": "text", "text": "Proof of Theorem 5.1. Recall that, in Eq. (2) of Lemma 4.1, we establish that: ", "page_idx": 18}, {"type": "equation", "text": "$$\nv_{i}(R_{i})\\geq\\mu_{i}/2\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In additio\u221an, we apply the zero-one principle to show that Lemma 5.1 holds for the sets $X_{i}$ and $R_{i}$ with $c=\\sqrt{d}+3$ . The proof follows by combining these two results. ", "page_idx": 18}, {"type": "text", "text": "Notice that $\\vert A_{i}\\setminus X_{i}\\vert\\le2$ , because in the \u201cstealing\u201d phase, agent $i$ might not take the \u201cplanted\u201d item from $A_{i}$ back, and the other agent might take one item from $A_{i}$ .8 Moreover, by Lemma 3.2, either $v_{i}^{1}$ or $v_{i}^{2}$ are in $X_{i}$ . Therefore, for every threshold $\\tau\\geq0$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{v_{i}^{\\tau}(X_{i})}&{\\geq}&{\\operatorname*{max}\\{h_{\\tau}(v_{i}^{2}),v_{i}^{\\tau}(A_{i})-2\\}}\\\\ &{\\geq}&{\\operatorname*{max}\\{h_{\\tau}(v_{i}^{2}),v_{i}^{\\tau}(R_{i})-\\sqrt{d}-2\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the inequality follows Lemma 5.2. ", "page_idx": 18}, {"type": "text", "text": "If $h_{\\tau}(v_{i}^{2})=0$ , then $v_{i}^{\\tau}(R_{i})\\leq|R_{i}|\\cdot h_{\\tau}(v_{i}^{2})=0$ , and Lemma 5.1 holds with $c=0$ . Therefore, the interesting case is when h\u03c4(vi2 ) = 1. Consider the ratio vvi\u03c4\u03c4 ((XRii)) which we want to bound. Since $v_{i}^{\\tau}(X_{i})\\geq h_{\\tau}(v_{i}^{2})=1$ , $v_{i}^{\\tau}(R_{i})\\in[1,\\sqrt{d}+3]$ implies that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{v_{i}^{\\tau}(R_{i})}{v_{i}^{\\tau}(X_{i})}\\leq v_{i}^{\\tau}(R_{i})\\leq\\sqrt{d}+3.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "On the oth\u221aer hand, by Eq. (6), setting $v_{i}^{\\tau}(R_{i})\\,=\\,\\sqrt{d}+3+\\delta$ for $\\delta\\,>\\,0$ implies that $v_{i}^{\\tau}(X_{i})\\geq$ $v_{i}^{\\tau}(R_{i})-\\sqrt{d}-2\\geq1+\\delta$ , which yields ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{v_{i}^{\\tau}(R_{i})}{v_{i}^{\\tau}(X_{i})}\\:\\leq\\:\\frac{\\sqrt{d}+3+\\delta}{1+\\delta}\\:\\leq\\:\\sqrt{d}+3.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We get that Lemma 5.1 holds for $X_{i}$ and $R_{i}$ with $c=\\sqrt{d}+3$ . Thus, ", "page_idx": 18}, {"type": "equation", "text": "$$\nv_{i}(X_{i})\\geq v_{i}(R_{i})/({\\sqrt{d}}+3)\\geq\\mu_{i}/(2{\\sqrt{d}}+6),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last inequality follows Eq. (5). ", "page_idx": 18}, {"type": "text", "text": "8In fact, this holds for any noise in the valuations of the other agent. ", "page_idx": 18}, {"type": "text", "text": "G Non-ordering Predictions ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this Section, we consider the case where predictions are not necessarily preference orders over items. In Section G.1, we show that for any prediction the mechanism might get, consistency is bounded away from 1. Sections G.2, G.3, we study succinct predictions, i.e. predictions about general structure of the preferences of two agents. Section G.2 presents a 4-consistent and $\\lceil m/2\\rceil$ -robust mechanism, whose consistency relies on the correctness of only a $\\log{m}$ -bit prediction about the preferences of the two agents. In Section G.3, we show that a $2+\\epsilon$ -consistent and $\\lceil m/2\\rceil$ -robust mechanism exists, whose consistency relies on correctly predicting only $O(\\log m/\\epsilon)$ bit about the preferences of the two agents. ", "page_idx": 19}, {"type": "text", "text": "G.1 No Mechanism with $<6/5$ Consistency and Bounded Robustness ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In [7] they define the following family of mechanisms. ", "page_idx": 19}, {"type": "text", "text": "Definition G.1 (Singleton Picking-Exchange Mechanisms [7]). A mechanism $X$ is a singleton picking-exchange mechanism if for each $i\\in\\{1,2\\}$ , there is exactly one of two sets: either $N_{i}\\subseteq M$ , or $E_{i}=\\{\\ell_{i}\\}$ for a single item $\\ell_{i}\\in M$ . If $N_{i}$ is non-empty, then the mechanism lets player $j\\neq i$ pick item $\\ell\\in N_{i}$ that maximizes $v_{j}(\\ell)$ , and $i$ gets $N_{i}\\setminus\\{\\ell\\}$ . If both $E_{1},E_{2}$ are non-empty, then the agents exchange the two items $\\ell_{1}\\in E_{1}$ and $\\ell_{2}\\in E_{2}$ if $v_{1}(\\bar{\\ell}_{2})>v_{1}(\\ell_{1})$ and $v_{2}(\\ell_{1})>v_{1}(\\ell_{2})$ . Notice that $i f$ $m>2$ , either $E_{1}$ or $E_{2}$ is empty and there will be no exchange. ", "page_idx": 19}, {"type": "text", "text": "[7] showed the following. ", "page_idx": 19}, {"type": "text", "text": "Lemma G.1. In order for a mechanism to be truthful and have a bounded approximation, it has to be a singleton picking-exchange mechanism ", "page_idx": 19}, {"type": "text", "text": "We make use of this characterization in our impossibility. ", "page_idx": 19}, {"type": "text", "text": "Theorem G.1. For any $\\epsilon>0$ , there is no truthful a mechanism with consistency $6/5-\\epsilon$ and bounded robustness. ", "page_idx": 19}, {"type": "text", "text": "Proof. Consider the case where $p_{1}=p_{2}=(1/2,1/2,1/3,1/3,1/3)$ . Notice that for the predictions, $\\mu_{1}\\,=\\,\\mu_{2}\\,=\\,1$ . We show that for any singleton-picking-exchange mechanism, no agent obtains both large items (of value $1/2$ ). Consider agent 1 (the argument is symmetric for agent 2). If $N_{1}$ is non-empty, then if both large items are in $N_{1}$ , surely 1 will only get one of them. If both large items are in $N_{2}$ , then agent 2 will surely pick one of them, and agent 1 will only get one of them. If one large item is in $N_{1}$ and the other is in $N_{2}$ , each agent $i$ will pick the large item in $N_{i}$ . If agent 2 has a large item in $E_{2}$ , then since $N_{1}$ is non-empty, $E_{1}$ is empty and agent 2 will keep the large item. Now consider the case where $E_{1}$ is non-empty. In this case, $E_{1}$ contains one item, and $N_{1}$ is empty. Since $E_{2}$ can contain at most one item, and there are more than 2 items, in this case, $E_{2}=\\emptyset$ , and $|\\dot{N}_{2}|=4$ . Therefore, $N_{2}$ contains at least one large item. Since agent 2 will always pick the large item, agent one only gets one large item. We conclude that for any singleton picking-exchange mechanism, the large items are split among the agents. Since there are 3 small items, there must be an agent that gets at most one small item, and this agent has an overall value of at most $1/2+1/3=5/6$ , while the MMS is 1. Thus the claim follows. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "G.2 4-Consistent, $(m-1)$ -Robust Mechanism Using a $3\\log m+1$ -Space Prediction ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Let us formally define a mechanism that uses a space-s prediction ", "page_idx": 19}, {"type": "text", "text": "Definition G.2. A learning-augmented mechanism is a space-s mechanism if the prediction space $\\mathcal{P}$ can be represented by the elements of $\\{0,1\\}^{s}$ . ", "page_idx": 19}, {"type": "text", "text": "We first give a simple mechanism that only requires $3\\log m+1$ bits of information about the valuations $v_{1}$ and $v_{2}$ . It will only need to know an index $j_{0}$ in $[m]$ together with a bit $b$ to produce an approximately-optimal allocation, and an additional $2\\log n$ bits to implement the planting phase. The mechanism will utilize the Plant-and-Steal framework in conjunction with the well-known bag-filling allocation procedure: ", "page_idx": 19}, {"type": "text", "text": "We see that, in order to predict the behaviour of the mechanism above, one only needs to predict accurately the index $j_{0}$ on which the mechanism terminates, as well as a bit $b\\in\\{1,2\\}$ that encodes ", "page_idx": 19}, {"type": "text", "text": "Input :Preference orders of agents over items ${\\bf v}=(v_{1},v_{2})$ on a set of items $M=[m]$ Output :Allocations $A_{1}\\upharpoonup A_{2}=M$ ", "page_idx": 20}, {"type": "text", "text": "for $j=1,\\dots,m$ : do $\\begin{array}{r}{\\frac{v_{1}([j])}{v_{1}([m])}\\geq\\frac{1}{2}}\\end{array}$ then Output $(A_{1},A_{2})\\gets([j],[m]\\setminus[j])$ and terminate if v2([j]) $\\begin{array}{r}{\\frac{v_{2}([j])}{v_{2}([m])}\\geq\\frac{1}{2}}\\end{array}$ then Output $(A_{1},A_{2})\\gets([m]\\setminus[j],[j])$ and terminate whether the algorithm terminates due to the condition vv1(([[jm]])) $\\frac{v_{1}([j])}{v_{1}([m])}~\\geq~\\frac12$ being satisfied or due to the condition v2([j]) $\\begin{array}{r}{\\frac{v_{2}([j])}{v_{2}([m])}\\geq\\frac{1}{2}}\\end{array}$ being satisfied. This can be encoded using $\\log m+1$ bits. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "We also see that the The Plant-and-Steal framework when used with the Bag-Filling allocation procedure gives a truthful 4-consistent and a $m-1$ -robust9 allocation mechanism. The truthfulness and robustness follow immediately from Lemmas 3.1 and 3.4 respectively. ", "page_idx": 20}, {"type": "text", "text": "The 4-consistency holds for the following reason. It is a well-known fact (see i.e. [10]) that the partition $(A_{1},A_{2})$ given by the bag-filling algorithm satisfies $v_{1}(A_{1})\\geq\\mu_{1}/2$ and $v_{2}(A_{2})\\geq\\mu_{2}/2$ . By inspecting the Plant-and-Steal framework (Algorithm 1), we see that both agent 1 and agent 2 will either (i) retain their most preferred item in $A_{1}$ and $A_{2}$ respectively or (ii) Lose this item, but obtain an item that they prefer even more. Overall, this implies that in the worst case the difference $v_{1}(A_{1})-v_{1}(X_{1})$ will equal to the value of the second-most favorite item of Agent 1 in $A_{1}$ . This implies that $\\begin{array}{r}{\\dot{v_{1}}(\\bar{X}_{1})\\geq\\frac{1}{2}\\dot{v}_{1}(A_{1})\\geq\\frac{\\mu_{1}}{4}}\\end{array}$ . Analogously, we see that $\\begin{array}{r}{v_{1}(X_{2})\\geq\\frac{1}{2}v_{1}\\tilde{(A_{2})}\\geq\\frac{\\mu_{2}}{4}}\\end{array}$ . ", "page_idx": 20}, {"type": "text", "text": "G.3 $2+\\epsilon$ -Consistent, $\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ -Robust Mechanism Using a $O(\\log m/\\epsilon)$ -Space Prediction ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We now show that a better consistency of $2+\\epsilon$ can be achieved at the cost predicting $O(\\log m/\\epsilon)$ bits of information about the valuations $v_{1}$ and $v_{2}$ . We will also obtain a better robustness of $\\textstyle\\left\\lceil{\\frac{m}{2}}\\right\\rceil$ . To do this, we will use the Plant-and-Steal framework in conjunction with the Cut-and-Balance allocation procedure. We first explain how the mechanisms above can be implemented by only ", "page_idx": 20}, {"type": "text", "text": "ALGORITHM 5: Cut-and-Balance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Output :Allocations $A_{1}\\bigcup A_{2}=M$   \nConsider a partition $S_{1}\\bigcup S_{2}=M$ satisfying $|S_{1}|\\geq|S_{2}|$ and $\\operatorname*{min}_{j\\in\\{1,2\\}}v_{1}(S_{j})\\geq(1-\\epsilon)\\mathrm{max}_{T_{1}\\bigcup\\tau_{2}=M}\\operatorname*{min}_{j\\in\\{1,2\\}}v_{1}(T_{j})=(1-\\epsilon)\\mu_{1}$   \nLet $S^{\\prime}\\subset S_{1}$ be a set of $\\lfloor m/2\\rfloor-\\lvert S_{2}\\rvert$ items satisfying \u2022 $v_{1}(S^{\\prime})\\leq v_{1}(S_{1})/2$ \u2022 if $|S_{2}|>1$ additionally satisfying $v_{1}(S^{\\prime})\\leq v_{1}(S_{1}\\setminus\\{\\hat{j},\\hat{j}^{\\prime}\\})/2$ , for some $\\hat{j}\\in\\arg\\operatorname*{max}_{j\\in S_{1}}v_{1}(j)$ and $\\hat{j}^{\\prime}\\in\\arg\\operatorname*{max}_{\\ell\\in S_{1}\\backslash\\hat{j}}v_{1}(\\hat{j})$   \nSet $\\tilde{S}_{1}\\leftarrow S_{1}\\setminus S^{\\prime}$ and $\\tilde{S}_{2}\\gets S_{2}\\cup S^{\\prime}$   \nLet $i_{2}\\gets\\arg\\operatorname*{max}_{i\\in\\{1,2\\}}p_{2}(\\tilde{S}_{i})$ and let $i_{1}$ be the index of the other bundle   \nSet $A_{1}\\leftarrow S_{i_{1}}$ and $A_{2}\\leftarrow S_{i_{2}}$ , and output the allocation $\\left(A_{1},A_{2}\\right)$ ", "page_idx": 20}, {"type": "text", "text": "obtaining $O(\\log m/\\epsilon)$ bits of information about the valuations $v_{1}$ and $v_{2}$ . This follows from the following proposition, the proof of which is given in Appendix G.4. ", "page_idx": 20}, {"type": "text", "text": "Proposition G.1. Suppose $M\\ =\\ [m]$ . There is a partition $M\\ =\\ L_{1}\\Lt L_{2}\\Lt S$ and indices $\\alpha_{1},\\beta_{1},\\alpha_{2}$ and $\\beta_{2}$ with $\\begin{array}{r l r}{|L_{1}|\\!\\!\\!}&{{}+\\!\\!\\!}&{\\!\\!\\!|L_{2}|\\!\\!\\!}&{\\leq}&{{\\cal O}\\left(\\frac{1}{\\epsilon}\\right)}\\end{array}$ , such that the partition $M~=~S_{1}\\bigcup S_{2}$ defined as $S_{1}~=~L_{1}\\bigcup(S\\bigcap[\\alpha_{1},\\beta_{1}])$ and ${\\cal S}_{2}~\\stackrel{\\cdot}{=}~{\\cal L}_{2}\\bigcup({\\cal S}\\bigcap[\\alpha_{2},\\beta_{2}])$ satisfies $|S_{1}|\\ \\geq\\ |S_{2}|$ and $\\operatorname*{min}(v_{1}(S_{1}),v_{1}(S_{2}))\\geq(1-\\epsilon/4)\\mu_{1}$ . ", "page_idx": 20}, {"type": "text", "text": "Additionally, there exist integers $\\alpha_{3}$ $\\,_{3},\\beta_{3},\\alpha_{4}$ and $\\beta_{4}$ such that the set $S^{\\prime}=S\\bigcap\\left(\\left[\\alpha_{3},\\beta_{3}\\right]\\bigcup\\left[\\alpha_{4},\\beta_{4}\\right]\\right)$ satisfies $|S^{\\prime}|=\\left\\lfloor m/2\\right\\rfloor-|S_{2}|$ , $S^{\\prime}\\subset S_{1}$ , $v_{1}(S^{\\prime})\\leq v_{1}(S_{1})/2$ and i $f|S_{2}|>1$ then $S^{\\prime}$ al so satisfies $v_{1}(S^{\\prime})\\leq v_{1}(S_{1}\\setminus\\{\\hat{j},\\hat{j}^{\\prime}\\})/2$ , where $\\hat{j}\\in\\arg\\operatorname*{max}_{j\\in S_{1}}v_{1}(j)$ and $\\hat{\\boldsymbol j}^{\\prime}\\in\\arg\\operatorname*{max}_{\\boldsymbol j\\in S_{1}\\backslash\\hat{\\boldsymbol j}}v_{1}(\\boldsymbol j)$ . ", "page_idx": 20}, {"type": "text", "text": "9Note that $\\operatorname*{min}(|A_{1}|,|A_{2}|)\\leq m-1$ which implies that the algorithm is $(m-1)$ -robust. ", "page_idx": 20}, {"type": "text", "text": "The main ideas for proving Proposition G.1 are: (i) using the sets $L_{1}$ and $L_{2}$ to handle elements $x$ whose value $v(x)$ is large, and separate the remaining items into the set $S$ (ii) Showing that the remaining items can be separated into well-behaved subsets of the form $S\\bigcap[\\alpha_{i},\\beta_{i}]$ . ", "page_idx": 21}, {"type": "text", "text": "The proposition above implies that the sets $S_{1},S_{2}$ and $S^{\\prime}$ can be represented exactly via sets $L_{1}$ and $L_{2}$ , together with the indices $\\{\\alpha_{1},\\cdot\\cdot\\cdot,\\alpha_{4},\\beta_{1},\\cdot\\cdot\\cdot\\beta_{4}\\}$ . We will also need to know the index $i_{2}~\\in~\\{1,2\\}$ . Since the sets $L_{1}$ and $L_{2}$ have a size of $\\dot{O}(1/\\epsilon)$ , all this information amounts to $O(\\log m/\\epsilon)$ bits as claimed. ", "page_idx": 21}, {"type": "text", "text": "The following proposition implies the truthfulness, the robustness and the consistency of the mechanism that combines the Cut-and-Balance allocation procedure with the Plant-and-Steal framework. ", "page_idx": 21}, {"type": "text", "text": "Theorem G.2. The Plant-and-Steal framework, when used with Cut-and-Balance allocation procedure, gives a truthful, $2+\\epsilon$ -consistent and a $\\lceil m/2\\rceil$ -robust allocation mechanism. ", "page_idx": 21}, {"type": "text", "text": "Proof. Truthfulness follows from Lemma 3.1. Since the sets $A_{1}$ and $A_{2}$ both have size at most $\\lceil m/2\\rceil$ , the robustness follows via Lemma 3.4. ", "page_idx": 21}, {"type": "text", "text": "The proof of $\\left(2+\\epsilon\\right)$ -consistency is deferred to Appendix G.5. The main challenge for showing the bound on consistency is the fact that both the Cut-and-Balance allocation procedure and the Plant-and-Steal framework can reduce the consistency by a factor of 2. Naively, one would expect the overall consistency to be close to 4, given that each stage can lose a factor of 2 in consistency. However, our insight is that for the instances, on which the Cut-and-Balance allocation procedure loses a factor of 2 in consistency, the Plant-and-Steal framework will have consistency close to 1, and vice versa. This allows us to prove a tighter bound of $2+\\epsilon$ on the consistency of our overall algorithm. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "G.4 Proof of Proposition G.1 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We first show the following, which implies the first half of Proposition G.1. ", "page_idx": 21}, {"type": "text", "text": "Proposition G.2. There exists a partition $M=L_{1}\\bigcup L_{2}\\bigcup S$ and and indices $\\alpha_{1},\\alpha_{2},\\beta_{1},\\beta_{2}$ in $[m]$ such that $M=[\\alpha_{1},\\beta_{1}]\\,\\lfloor\\cdot\\rfloor[\\alpha_{2},\\beta_{2}],$ , for the sets $S_{1}=\\bar{L}_{1}\\cup(\\bar{S}\\cap[\\alpha_{1},\\beta_{1}])$ and $S_{2}=L_{2}\\cup(S\\cap[\\alpha_{2},\\beta_{2}])$ we have ", "page_idx": 21}, {"type": "text", "text": "$\\begin{array}{r l}&{\\bullet\\ \\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}\\geq(1-\\epsilon/8)\\mu_{1}}\\\\ &{\\bullet\\ |L_{1}|+|L_{2}|\\leq\\lceil\\frac{8}{\\epsilon}\\rceil+2}\\\\ &{\\bullet\\ |S_{1}|\\geq|S_{2}|.}\\end{array}$   \n\u2022 For every $x$ in $L_{1}$ and $y$ in $S_{1}$ we have $v_{1}(x)>v_{1}(y)$ . Analogously, for every $x$ in $L_{2}$ and $y$ in $S_{2}$ we have $v_{1}(x)>v_{1}(y)$   \n\u2022 There are $\\hat{j},\\hat{j}^{\\prime}\\in L_{1}$ satisfying $\\begin{array}{r}{\\hat{j}\\in\\arg\\operatorname*{max}_{\\ell\\in S_{1}}v_{1}(\\ell)\\,a n d\\,\\hat{j}^{\\prime}\\in\\arg\\operatorname*{max}_{\\ell\\in S_{1}\\backslash\\hat{j}}v_{1}(\\ell),}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "We do this by inspecting two types of items, large items, with value greater than $\\epsilon\\mu_{1}/4$ , and small items items with value at most $\\epsilon\\mu_{1}/4$ . We first show that there are ${\\cal O}(1/\\epsilon)$ large items, therefore, separating these items into two bundles require at most ${\\cal O}(1/\\epsilon)$ intervals. Moreover, we can find a separation of the larges items into two sets, $L_{1},L_{2}$ , and a single index $j\\in[m]$ such that all small items to the left of $j$ (including) together with $L_{1}$ form $S_{1}$ , and all items to the right of $j$ (excluding) together with $L_{2}$ form $S_{2}$ , such that $S_{1},S_{2}$ satisfy the approximation requirement. It is easy to see that this increases the number of intervals by at most 1. ", "page_idx": 21}, {"type": "text", "text": "We start by showing there are not too many large items. ", "page_idx": 21}, {"type": "text", "text": "Lemma G.2. There are at most $\\lceil\\frac{8}{\\epsilon}\\rceil$ items with value strictly greater than $\\epsilon\\mu_{1}$ for agent $^{\\,I}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Let items with value greater than $\\epsilon\\mu_{1}/4$ be the large items. Suppose there are at least $\\lceil\\frac{8}{\\epsilon}\\rceil+1$ large items. If $\\lceil\\frac{8}{\\epsilon}\\rceil$ is even, consider a partition $(S_{1},S_{2})$ such that each $S_{i}$ gets at least $\\lceil\\frac{8}{\\epsilon}\\rceil/2$ large items and the rest are allocated arbitrarily. If $\\lceil\\frac{8}{\\epsilon}\\rceil$ is odd, consider the allocation in which each $S_{i}$ gets $(\\lceil\\frac{8}{\\epsilon}\\rceil+1)/2$ large items and the rest are allocated arbitrarily. In either case, each $S_{i}$ gets at least $\\lceil\\frac{8}{\\epsilon}\\rceil/2\\geq\\frac{4}{\\epsilon}$ large items. Thus, $\\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}>\\epsilon\\mu_{1}/4\\cdot\\frac{4}{\\epsilon}=\\mu_{1}$ , a contradiction. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "We are now ready to prove Proposition G.2. ", "page_idx": 22}, {"type": "text", "text": "Proof of Proposition G.2. Consider the set of large items, $L=\\{j\\in[m]\\,:\\,v_{1}(j)>\\epsilon\\mu_{1}/4\\}$ , and let $S=M\\setminus L$ be the set of small items. ", "page_idx": 22}, {"type": "text", "text": "We give a constructive proof which finds both sets $L_{1},L_{2}$ and an index $j$ satisfying the condition stated in the lemma. Let ", "page_idx": 22}, {"type": "equation", "text": "$$\n(L_{1},L_{2})\\in\\arg\\operatorname*{max}_{(T_{1},T_{2})}:T_{1}\\sqcup T_{2}=L\\operatorname*{min}_{j\\in\\{1,2\\}}v_{1}(S_{j}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We use the following procedure to find $j$ . ", "page_idx": 22}, {"type": "equation", "text": "$$\nj_{r}:=j_{r}-1.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We consider two cases: ", "page_idx": 22}, {"type": "text", "text": "Case 1: $j\\,=\\,0$ (or symmetrically, $j\\,=\\,m)$ ). Without loss of generality, suppose that $j\\,=\\,m$ . We first show that if $v_{1}(S_{1})\\,<\\,v_{1}(S_{2})$ then $\\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}=\\mu_{1}$ . Notice that since $S_{1}$ gets all the small items, it must be the case that $v_{1}(L_{1})\\,<\\,v_{1}(L_{2})$ . Suppose there\u2019s a different partition $T_{1}\\left\\lvert\\cdot\\right\\rvert T_{2}$ such that $\\operatorname*{min}\\{v_{1}(T_{1}),v_{1}(T_{2})\\}\\;>\\;\\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}.$ Without loss of generality, let $v_{1}(\\bar{T}_{1}\\cap L)\\leq v_{1}(T_{2}\\cap\\bar{L})$ (otherwise, we can rename both bundles). By the definition of $L_{1},L_{2}$ , it must be the case that $v_{1}(L_{1})\\geq v_{1}(T_{1}\\cap L)$ . Thus, Since $T_{1}\\setminus(T_{1}\\cap L)\\subseteq S$ , it must be that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v_{1}(S_{1})\\,=\\,v_{1}(L_{1})+v_{1}(S)\\,\\geq\\,v_{1}(T_{1}\\cap L)+v_{1}(T_{1}\\setminus(T_{1}\\cap L))\\,=\\,v_{1}(T_{1})\\,\\geq\\,\\operatorname*{min}\\{v_{1}(T_{1}),v_{1}(T_{2})\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "a contradiction. ", "page_idx": 22}, {"type": "text", "text": "On the other hand, if $v_{1}(S_{1})\\geq v_{1}(S_{2})=v_{1}(L_{2})$ , by condition 2b of the above procedure, it must be the case that when $j_{\\ell}$ was equal $m-1$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\nv_{1}(S_{\\ell})\\;<\\;v_{1}(S_{r})\\;=\\;v_{1}(L_{2})\\;=\\;v_{1}(S_{2}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, ", "page_idx": 22}, {"type": "equation", "text": "$$\nv_{1}(S_{1})\\;=\\;v_{1}(S_{\\ell})+v_{1}(m)\\;<\\;v_{1}(S_{2})+\\epsilon\\mu_{1}/4.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We get that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v_{1}(S_{2})\\;\\geq\\;v_{1}(S_{1})-\\epsilon\\mu_{1}/4\\;\\geq\\;2\\mu_{1}-v_{1}(S_{2})-\\epsilon\\mu_{1}/4\\;\\Rightarrow}\\\\ &{\\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}\\;=\\;v_{1}(S_{2})\\;\\geq\\;(1-\\epsilon/8)\\mu_{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second inequality follows since $2\\mu_{1}\\leq v_{1}(S_{1})+v_{1}(S_{2})$ . ", "page_idx": 22}, {"type": "text", "text": "Case 2: $0<j<m$ . In this case, since both $j_{\\ell}$ and $j_{r}$ were moved, there were some values of $j_{\\ell}$ and $j_{r}$ such that $v_{1}(S_{\\ell})\\leq v_{1}(S_{r})$ and some values such that $v_{1}(S_{\\ell})>v_{1}(S_{r})$ . Assume initially that $v_{1}(S_{\\ell})\\leq v_{1}(S_{r})$ . Since at each step of the procedure, the the lower-valued bundle can increase by at most $\\epsilon\\mu_{1}/4$ , when the first item is added to $S_{\\ell}$ such that $v_{1}(S_{\\ell})>v_{1}(S_{r})$ , it must be the case that $v_{1}(S_{\\ell})\\leq v_{(}S_{r})+\\epsilon\\mu_{1}/4$ . It is easy to see that the invariant where $|v_{1}(\\dot{S_{\\ell}})-v_{1}(S_{r})|\\le\\epsilon\\mu_{1}/4$ is kept throughout the run of the procedure. Therefore, this also holds for the final $S_{1}$ and $S_{2}$ . Thus, we can use the same reasoning of Eq. (7) to conclude that $\\operatorname*{min}\\{v_{1}(S_{1}),v_{1}(S_{2})\\}\\geq(1-\\epsilon/8)\\mu_{1}$ . ", "page_idx": 22}, {"type": "text", "text": "Thus, the sets $S_{1}$ and $S_{2}$ have a form $S_{1}=L_{1}\\cup(S\\cap[1,j])$ and $S_{2}=L_{2}\\cup(S\\cap[j+1,m])$ and have the form required. If $|S_{1}|<|S_{2}|$ we can swap our definitions for the sets $S_{1}$ and $S_{2}$ , thus ensuring that $|S_{1}|>|S_{2}|$ . Due to our definitions of $L_{1}$ and $L_{2}$ we have for every $x$ in $L_{1}$ and $y$ in $S_{1}$ we have $v_{1}(x)>v_{1}(y)$ . Analogously, for every $x$ in $L_{2}$ and $y$ in $S_{2}$ we have $v_{1}(x)>v_{1}(y)$ . ", "page_idx": 22}, {"type": "text", "text": "We can ensure that There are $\\hat{j},\\hat{j}^{\\prime}\\in L_{1}$ satisfying ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\hat{j}\\in\\arg\\operatorname*{max}_{\\ell\\in S_{1}}v_{1}(\\ell)\\mathrm{~and~}\\hat{j}^{\\prime}\\in\\arg\\operatorname*{max}_{\\ell\\in S_{1}\\backslash\\hat{j}}v_{1}(\\ell),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "by adding such values from $S\\cap[\\alpha_{1},\\beta_{1}]$ to $L_{1}$ (we see that after this all other properties still hold). Overall, we see that $\\begin{array}{r}{|L_{1}|+|L_{2}|\\stackrel{.}{\\leq}\\lceil\\frac8\\epsilon\\rceil\\stackrel{.}{+}2}\\end{array}$ , as required. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Now, we proceed to proving the second half of Proposition G.1. We will need the following lemma. Lemma G.3. Let $k_{1}$ and $k_{2}$ be positive integers satisfying $k_{1}>k_{2}$ , and let $f$ be a function mapping $[k_{1}]$ to non-negative real numbers. Then, there exist a pair of integers $\\alpha,\\beta,\\alpha^{\\prime}$ and $\\beta^{\\prime}$ in $[k_{1}]$ such that $|[\\alpha,\\beta]\\cup[\\dot{\\alpha}^{\\prime},\\beta^{\\prime}]|=k_{2}$ and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{\\sum_{i\\in[\\alpha,\\beta]\\cup[\\alpha^{\\prime},\\beta^{\\prime}]}f(i)}{k_{2}}\\leq\\frac{\\sum_{i\\in[k_{1}]}f(i)}{k_{1}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. We prove the lemma using the probabilistic method. Let $j$ be a uniformly random integer in $[k_{1}]$ , and choose $\\alpha,\\beta,\\alpha^{\\prime}$ and $\\beta^{\\prime}$ such that ", "page_idx": 23}, {"type": "equation", "text": "$$\n[\\alpha,\\beta]\\cup[\\alpha^{\\prime},\\beta^{\\prime}]=\\{j,j+1\\mod k_{1},\\cdots,j+k_{2}-1\\mod k_{1}\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We see that indeed a set chosen as above can be represented as a union of two intervals. Now, since $j$ is chosen uniformly at random form $[k_{1}]$ , we see that for every element $i$ in $\\left[k_{1}\\right]$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{j\\sim[k_{1}]}[i\\in\\{j,j+1\\mod k_{1},\\cdots,j+k_{2}-1\\mod k_{1}\\}]={\\frac{k_{2}}{k_{1}}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus via linearity of expectation we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}_{j\\sim[k_{1}]}\\left[\\frac{1}{k_{2}}\\sum_{\\substack{i\\in\\{j,j+1\\mod k_{1},\\cdots,j+k_{2}-1\\mod k_{1}\\}\\}}f(i)\\}\\right]=\\frac{1}{k_{1}}\\sum_{\\substack{i\\in[k_{1}]}}f(i).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, since $f(i)$ is non-negative for all values of $i$ , we see that for some specific choice of $j$ it has to be the case that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{1}{k_{2}}\\sum_{i\\in\\{j,j+1\\mod k_{1},\\cdots,j+k_{2}-1\\mod k_{1}\\}}f(i)\\}\\leq\\frac{1}{k_{1}}\\sum_{i\\in[k_{1}]}f(i),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which finishes the proof. ", "page_idx": 23}, {"type": "text", "text": "Now, we apply the lemma above. If $m<4\\lceil\\frac{t}{\\epsilon}\\rceil+2$ we can satisfy Proposition G.2 by: ", "page_idx": 23}, {"type": "text", "text": "1. First choosing a partition $M=S_{1}\\left\\lfloor.\\right\\rfloor S_{2}$ such that $\\operatorname*{min}(v_{1}(S_{1}),v_{1}(S_{2}))\\geq\\mu_{1}$ and $|R_{1}|\\geq$ $|R_{2}|$ .   \n2. Define $L_{2}:=S_{2}$ , put the smallest $\\lfloor m/2\\rfloor-\\vert S_{2}$ elements of $S_{1}$ into $S$ , and define $L_{1}$ to contain the rest of elements in $S_{1}$ .   \n3. Define $\\alpha_{1}=\\alpha_{3}=1$ $,\\beta_{1}=\\beta_{3}=m,\\alpha_{2}=\\beta_{2}=\\alpha_{4}=\\beta_{4}=m+1.$ ", "page_idx": 23}, {"type": "text", "text": "Overall, this allocates $S^{\\prime}$ to be the bottom $\\lfloor m/2\\rfloor$ elements of $S_{1}$ . We see that this suffices to guarantee the properties that $S^{\\prime}$ needs to satisfy in Proposition G.1. ", "page_idx": 23}, {"type": "text", "text": "Therefore, henceforth we can assume that $m>4\\lceil\\frac{t}{\\epsilon}\\rceil+2$ . Since $|S_{1}|\\ge m/2$ and $\\begin{array}{r}{|L_{1}|\\leq\\frac{8}{\\epsilon}+2}\\end{array}$ , and $S_{1}=L_{1}\\cup(S\\cap[\\alpha_{1},\\beta_{1}])$ this implies that $|S\\cap[\\alpha_{1},\\beta_{1}])|>3\\;\\lceil\\frac{t}{\\epsilon}\\rceil>m/2$ Thus, we can ensure that $|S^{\\prime}|=\\left\\lfloor m/2\\right\\rfloor-\\left\\lvert S_{2}\\right\\rvert$ using a subset $S^{\\prime}\\subset S\\cap[\\alpha_{1},\\beta_{1}])$ . ", "page_idx": 23}, {"type": "text", "text": "If $|S_{2}|=1$ we only need choose $S^{\\prime}$ to satisfy $|S^{\\prime}|=\\left\\lfloor m/2\\right\\rfloor-\\left\\lvert S_{2}\\right\\rvert$ and $v_{1}(S^{\\prime})\\leq v_{1}(S_{1}\\setminus\\{\\hat{j},\\hat{j}^{\\prime}\\})/2$ . First of all, since every element in $L_{1}$ is larger than any element in $S\\cap\\left[\\alpha_{1},\\beta_{1}\\right])$ , we see that this is also true in average ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{\\sum_{\\ell\\in S_{1}}v_{1}(\\ell)}{|S_{1}|}\\leq\\frac{\\sum_{\\ell\\in S\\cap[\\alpha_{1},\\beta_{1}])}v_{1}(\\ell)}{|S\\cap[\\alpha_{1},\\beta_{1}])|}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then, applying Lemma G.3 to the set $S\\cap\\left[\\alpha_{1},\\beta_{1}\\right])$ we see that there exist disjoint subsets $[\\alpha_{3},\\beta_{3}]$ and $[\\alpha_{4},\\beta_{4}]$ of $[\\alpha_{1},\\beta_{1}]$ such that $|S\\cap([\\alpha_{3},\\dot{\\beta}_{3}]\\bigcup[\\dot{\\alpha}_{4},\\beta_{4}]))|=\\lfloor m/2\\rfloor-|S_{2}|$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\sum_{\\ell\\in S\\cap[\\alpha_{1},\\beta_{1}])}v_{1}(\\ell)}{|S\\cap[\\alpha_{1},\\beta_{1}])|}\\leq\\frac{\\sum_{\\ell\\in S\\cap([\\alpha_{3},\\beta_{3}]\\bigcup[\\alpha_{4},\\beta_{4}]))}v_{1}(\\ell)}{|S\\cap([\\alpha_{3},\\beta_{3}]\\bigcup[\\alpha_{4},\\beta_{4}]))|}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combing Equations 8 and 9, we see that taking $S^{\\prime}=S\\cap\\left(\\left[\\alpha_{3},\\beta_{3}\\right]\\bigcup\\left[\\alpha_{4},\\beta_{4}\\right]\\right)$ satisfies $v_{1}(S^{\\prime})\\leq$ $v_{1}(S_{1})/{\\bar{2}}$ and the other requirements of Proposition G.1. ", "page_idx": 24}, {"type": "text", "text": "Now, suppose $|S_{2}|>1$ . Since by Proposition G.2, the set $S$ does not contain the two largest elements $\\hat{j}$ and $\\Hat{j}^{\\prime}$ of $S_{1}$ , as well as the fact that every element in $L_{1}$ is at least as large as any element in $S\\cap\\left[\\alpha_{1},\\beta_{1}\\right])$ , we see that every every element in $S_{1}\\setminus\\{\\hat{j},\\hat{j}^{\\prime}\\}$ is either in $S\\cap\\left[\\alpha_{1},\\beta_{1}\\right])$ or greater than every element in $S\\cap[\\alpha_{1},\\beta_{1}]\\rangle$ . this implies that: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\sum_{\\ell\\in S_{1}\\backslash\\{\\hat{j},\\hat{j}^{\\prime}\\}}v_{1}(\\ell)}{|S_{1}|-2}\\leq\\frac{\\sum_{\\ell\\in S\\cap[\\alpha_{1},\\beta_{1}])}v_{1}(\\ell)}{|S\\cap[\\alpha_{1},\\beta_{1}])|}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then, we can again apply applying Lemma G.3 to the set $S\\cap[\\alpha_{1},\\beta_{1}])$ we see that there exist disjoint subsets $[\\alpha_{3},\\beta_{3}]$ and $[\\alpha_{4},\\beta_{4}]$ of $[\\alpha_{1},\\beta_{1}]$ such that $|S\\cap\\left(\\left[\\alpha_{3},\\bar{\\beta}_{3}\\right]\\bigcup\\lbrack\\bar{\\alpha_{4}},\\beta_{4}\\rbrack\\right)\\rangle|=\\lfloor m/2\\rfloor-\\vert S_{2}\\vert$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\sum_{\\ell\\in S\\cap[\\alpha_{1},\\beta_{1}])}v_{1}(\\ell)}{|S\\cap[\\alpha_{1},\\beta_{1}])|}\\leq\\frac{\\sum_{\\ell\\in S\\cap([\\alpha_{3},\\beta_{3}]\\bigcup[\\alpha_{4},\\beta_{4}]))}v_{1}(\\ell)}{|S\\cap([\\alpha_{3},\\beta_{3}]\\bigcup[\\alpha_{4},\\beta_{4}]))|}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combing Equations 10 and 11, we see that taking $S^{\\prime}=S\\cap\\left(\\left[\\alpha_{3},\\beta_{3}\\right]\\cup\\left[\\alpha_{4},\\beta_{4}\\right]\\right)$ satisfies $v_{1}(S^{\\prime})\\leq$ $v_{1}(S_{1}\\backslash\\{\\hat{j},\\hat{j}^{\\prime}\\})/2$ as required in Proposition G.1. Note that this also implies that $v_{1}(S^{\\prime})\\leq v_{1}(S_{1}\\})/2$ since ${\\hat{j}},{\\hat{j}}^{\\prime}$ have the top two largest values of $v_{1}$ in $S_{1}$ . Overall, this finishes the proof of Proposition G.1. ", "page_idx": 24}, {"type": "text", "text": "G.5 Proof of $\\left(2+\\epsilon\\right)$ -consistency. ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "It remains to show that the algorithm is $2+\\epsilon$ -consistent. We will be referencing the variables $\\hat{j}_{1},\\hat{j}_{2},\\tilde{j}_{1},\\tilde{j}_{2},T_{1}$ and $T_{2}$ within the Plant-And-Steal framework (Algorithm 1). ", "page_idx": 24}, {"type": "text", "text": "We first reason about agent 2. First, notice that since agent 2 has a higher value for $\\tilde{S}_{i_{2}}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\nv_{2}(\\tilde{S}_{i_{2}})\\geq\\mu_{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since the mechanism had a chance to pick item $\\hat{j}_{2}$ from $T_{1}$ as $\\tilde{j}_{2}$ , it must be the case that $v_{2}(\\tilde{j}_{2})\\geq$ $v_{2}(\\hat{j}_{2})$ (and possibly $\\tilde{j}_{2}=\\hat{j}_{2}{'}$ ). If $\\tilde{j}_{1}=\\hat{j}_{1}$ , then $T_{2}\\setminus\\tilde{j}_{1}=\\tilde{S}_{i_{2}}\\setminus\\hat{j}_{2}$ , and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mu_{2}\\;\\leq\\;v_{2}\\bigl(\\tilde{S}_{i_{2}}\\bigr)\\;=\\;v_{2}\\bigl(\\tilde{S}_{i_{2}}\\setminus\\hat{j}_{2}\\bigr)+v_{2}\\bigl(\\hat{j}_{2}\\bigr)\\;\\leq\\;v_{2}\\bigl(T_{2}\\setminus\\tilde{j}_{1}\\bigr)+v_{2}\\bigl(\\tilde{j}_{2}\\bigr)\\;=\\;v_{2}\\bigl(X_{2}\\bigr).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Otherwise, $\\tilde{j}_{1}\\in\\tilde{S}_{i_{2}}$ , and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\tilde{S}_{i_{2}}\\setminus\\hat{j}_{2}\\setminus\\tilde{j}_{1}\\subset T_{2}\\setminus\\tilde{j}_{1}\\;\\Rightarrow\\;v_{2}(\\tilde{S}_{i_{2}}\\setminus\\hat{j}_{2}\\setminus\\tilde{j}_{1})\\leq v_{2}(T_{2}\\setminus\\tilde{j}_{1}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $\\hat{j}_{2}$ is the item with the highest value for agent 2 in $\\tilde{S}_{i_{2}},v_{2}(\\tilde{j}_{2})\\;\\geq\\;v_{2}(\\hat{j}_{2})\\;\\geq\\;v_{2}(k_{1})$ . Combining with Eq. (12), we get that ", "page_idx": 24}, {"type": "text", "text": "Moreover, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v_{2}(T_{2}\\setminus\\tilde{j}_{1}\\cup\\{\\tilde{j}_{2}\\})\\ \\geq\\ v_{2}(\\tilde{S}_{i_{2}}\\setminus\\{\\hat{j}_{2}\\}.}\\\\ {v_{2}(T_{2}\\setminus\\tilde{j}_{1}\\cup\\{\\tilde{j}_{2}\\})\\ \\geq\\ v_{2}(\\tilde{j}_{2})\\ \\geq\\ v_{2}(\\hat{j}_{2}).\\ \\ \\ \\ }\\\\ {v_{2}(X_{2})\\ =\\ v_{2}(T_{2}\\setminus\\tilde{j}_{1}\\cup\\{\\tilde{j}_{2}\\})\\ \\geq\\ v_{2}(\\tilde{S}_{i_{2}})/2\\ =\\ \\mu_{2}/2,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, ", "page_idx": 24}, {"type": "text", "text": "as desired. ", "page_idx": 24}, {"type": "text", "text": "It is left to show that $v_{1}(X_{1})\\geq\\mu_{1}/(2+\\epsilon)$ . If $i_{1}=2$ , then ", "page_idx": 24}, {"type": "equation", "text": "$$\nv_{1}(\\tilde{S}_{i_{1}})\\;=\\;v_{1}(\\tilde{S}_{2})\\;\\geq\\;v_{1}(S_{2})\\;\\geq\\;(1-\\epsilon/4)\\mu_{1}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In this case, the same exact arguments used for agent 2 can be harnessed to show that $v_{1}(X_{1})\\geq$ $(1-\\epsilon/4)\\mu_{1}/2\\ge\\mu_{1}/(2+\\epsilon)$ . Thus, it is left to consider the case where $i_{1}=1$ . ", "page_idx": 25}, {"type": "text", "text": "Consider the $(S_{1},S_{2})$ partition that is set in the first step of Cut-and-Balance-and-Choose. Since $v_{1}(S^{\\prime})\\leq v_{1}(\\dot{S}_{1})/2$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\nv_{1}(\\tilde{S}_{1})\\;\\geq\\;v_{1}(S_{1})/2\\;\\geq\\;(1-\\epsilon/4)\\mu_{1}/2\\geq\\frac{\\mu_{1}}{2+\\epsilon}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "If $\\tilde{j}_{2}=\\hat{j}_{2}$ , we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\nv_{1}(X_{1})=v_{1}(\\tilde{S}_{1}\\cup\\{\\tilde{j}_{1}\\}\\setminus\\{\\hat{j}_{1}\\})\\geq v_{1}(\\tilde{S}_{1})\\geq\\frac{\\mu_{1}}{2+\\epsilon},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality follows since $v_{1}(\\tilde{j}_{1})\\geq v_{1}(\\hat{j}_{1})$ . ", "page_idx": 25}, {"type": "text", "text": "Note also that if $|S_{2}|=1$ i.e., $S_{2}=\\{a\\}$ , if $\\hat{j}_{2}\\neq a$ then $v_{1}(X_{1})\\geq v_{1}(S_{2})$ since $a\\in T_{2}$ , similarly if $\\tilde{j}_{2}\\neq a$ then $v_{1}(X_{1})\\geq v_{1}(S_{2})$ , finally we have $\\hat{j}_{2}=k_{2}=a$ and $v_{1}(X_{1})\\geq\\mu_{1}/(2+\\epsilon)$ an in the first case. ", "page_idx": 25}, {"type": "text", "text": "Therefore, we assume $\\tilde{j}_{2}\\neq\\hat{j}_{2}$ and $|S_{2}|>1$ , and let $\\hat{j}_{1}^{\\prime}\\in\\arg\\operatorname*{max}_{j\\in\\tilde{S}_{1}\\backslash\\{\\hat{j}_{1}\\}}v_{1}(j)$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{v_{1}(X_{1})}&{=}&{v_{1}(T_{1}\\cup\\{\\hat{j}_{1}\\}\\setminus\\{\\hat{j}_{2}\\})}\\\\ &{=}&{v_{1}(T_{1})+v_{1}(\\tilde{j}_{1})-v_{1}(k_{2})}\\\\ &{\\geq}&{v_{1}(\\tilde{S}_{1}\\cup\\{\\hat{j}_{2}\\}\\setminus\\{\\hat{j}_{1}\\})+v_{1}(\\hat{j}_{1})-v_{1}(\\tilde{j}_{2})}\\\\ &{\\geq}&{v_{1}(\\tilde{S}_{1}\\setminus\\{\\hat{j}_{1}\\})+v_{1}(\\hat{j}_{1})-v_{1}(\\tilde{j}_{2})}\\\\ &{=}&{v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1}\\})+v_{1}(\\hat{j}_{1})-v_{1}(\\tilde{j}_{2})}\\\\ &{\\geq}&{v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1}\\})+v_{1}(\\hat{j}_{1})-v_{1}(\\hat{j}_{1}^{\\prime})}\\\\ &{=}&{v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\})+v_{1}(\\hat{j}_{1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality is since, $v_{1\\tilde{j}_{1}}\\,=\\,\\mathrm{max}_{j\\in T_{2}}\\,v_{1j}\\,\\geq\\,v_{1\\tilde{j}_{1}}$ . The second inequality is since $v_{1}(\\hat{j}_{2})\\geq0$ , the third inequality is by $\\hat{j}_{1}^{\\prime}$ definition since $\\tilde{\\boldsymbol{j}}_{2}\\in\\tilde{S}_{1}\\setminus\\hat{\\boldsymbol{j}}_{1}$ by our assumption that $k_{2}\\neq\\hat{j}_{2}$ . Finally, we have have $|S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\}|\\geq|S^{\\prime}|$ since ", "page_idx": 25}, {"type": "equation", "text": "$$\nS_{1}|-2-|S^{\\prime}|=|S_{1}|-2-(m/2-|S_{2}|)=|S_{1}|-2-(m/2-(m-|S_{1}|))=m/2-2\\geq|S^{\\prime}|,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the last inequality is since $|S_{2}|\\,>\\,1$ . Since we handles the case $|S_{2}|\\,=1$ earlier, we can here assume $|S_{2}|>1$ in which case the set $S^{\\prime}$ is required to satisfy $v_{1}(S^{\\prime})\\leq v_{1}(S_{1}\\setminus\\{\\hat{j},\\hat{j}^{\\prime}\\})/2$ . Therefore, we have $v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\}\\geq v_{1}(S^{\\prime})$ . ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{(1-\\epsilon/4)\\mu_{1}\\leq v_{1}(S_{1})}&{=}&{v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\})+v_{1}(\\hat{j}_{1})+v_{1}(\\hat{j}_{1}^{\\prime})+v_{1}(S^{\\prime})}\\\\ &{\\leq}&{v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\})+2\\cdot v_{1}(\\hat{j}_{1})+v_{1}(S^{\\prime})}\\\\ &{\\leq}&{2\\cdot v_{1}(S_{1}\\setminus S^{\\prime}\\setminus\\{\\hat{j}_{1},\\hat{j}_{1}^{\\prime}\\})+2\\cdot v_{1}(\\hat{j}_{1})}\\\\ &{\\leq}&{2\\cdot v_{1}(X_{1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "which implies that $\\begin{array}{r}{v_{1}(X_{1})\\geq\\frac{\\mu_{1}}{2+\\epsilon}}\\end{array}$ , finishing the proof. ", "page_idx": 25}, {"type": "text", "text": "H Mechanisms for $n$ agents ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section we provide a learning-augmented mechanism for $n~>~2$ agents, LearningAugmented-MMS-for- $\\cdot n$ -Agents. The mechanism we devise ensures that if the predictions are accurate, then each agent gets an allocation with value at least $\\mu_{i}^{n}/2$ (2 consistency). On the other hand, we show that for any prediction, every agent gets at least $\\mu_{i}^{\\hat{n}}/\\alpha$ for $\\hat{n}=\\lceil3n/2\\rceil$ and $\\alpha=\\operatorname*{max}\\{m-\\hat{n}-1,1\\}$ (robustness). ", "page_idx": 25}, {"type": "text", "text": "Theorem H.1. The Learning-Augmented-MMS-for-n-Agents Mechanism (Mechanism 6) is truthful, 2-consistent and $(\\mu_{i}^{\\hat{n}}/\\bar{\\alpha})$ -robust for $\\hat{n}=\\lceil3n/2\\rceil$ and $\\alpha=\\operatorname*{max}\\{m-\\hat{n}-1,1\\}$ . ", "page_idx": 25}, {"type": "text", "text": "H.1 An Overview ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The Mechanism. The mechanism works in three phases. In the first phase, it uses the predictions in order to obtain a partial allocation to agents with high predicted items (which are then removed from the set of active agents, so that we can now that for all agents, all predicted values are small). Then, in the second stage, the mechanism uses the predictions in order to obtain a tentative allocation, by running a Round-Robin procedure, where items are tentatively allocated to agents according to their predictions. In the third and final phase, the tentative allocation is used to implement a recursive plant and steal procedure, where the \u201cplanting\u201d is done from the tentative allocations according to predictions, but the \u201cstealing\u201d is done according to the agents\u2019 reports and results in a final allocation. ", "page_idx": 26}, {"type": "text", "text": "MECHANISM 6: Learning-Augmented-MMS-for-n-Agents ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Input :Set of agents $N$ , set of items $M$ , reports $\\mathbf{r}_{N}$ , predictions $\\mathbf{p}_{N}$   \nOutput : A partition of the items $\\ \\{\\cdot\\rfloor_{i\\in N}\\ X_{i}$   \nInvoke Algorithm 7, $X\\leftarrow$ Allocate-Large(N, M, rN, pN)   \nInvoke Algorithm 9, $A\\leftarrow$ Tentative-Allocation-Round-Robin(N, M, pN)   \nInvoke Algorithm 10, $X\\leftarrow$ Split-Plant-Steal-Recurse(N, A,first-level-flag = True, X, rN, pN) ", "page_idx": 26}, {"type": "image", "img_path": "aFB97F8QSF/tmp/370a225cebb1a213512933c7de1da9ec4fc1296c19fe0d693adea4e1f7ba6116.jpg", "img_caption": ["Figure 3: Illustration of a single round of the recursive planting and stealing phase (Algorithm 10), for the case where predictions are accurate (so that each agent steals back their planted item). Note that the stealing is done from the union of items of agents in the opposite set (and not just from the corresponding agent). "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Consistency. In the case the predictions are accurate, the initial allocation phase will take care of agents with high valued items (of value larger than $\\mu_{i}^{n}/2)$ . Then, in the second phase, the tentative allocation will be exactly identical to a Round-Robin allocation (made according to true valuations). Finally, in the third phase, since agents steal in the same order they were allocated the items in the Round-Robin allocation, and since the predictions are accurate, the agents \u201csteal\u201d back the same item the mechanism plants. Since a Round-Robin allocation achieves $\\mu_{i}^{n}/2$ when there are no agents with high valued items [8], correctness follows. ", "page_idx": 26}, {"type": "text", "text": "Robustness. In the case the predictions are inaccurate, we show that every agent still gets at least $\\mu_{i}^{\\hat{n}}/\\alpha$ . Here we rely on the plant-and-steal phase to ensure that each agent gets at least their $\\left\\lceil3n/2\\right\\rceil$ highest-valued item according to their true valuation. This property provides our robustness guarantee. We notice that reversing the order between the first and subsequent rounds of the Round-Robin procedure (and thus, the stealing phases) gives an enhanced robustness guarantee. ", "page_idx": 27}, {"type": "text", "text": "Prediction. In the description of the mechanism, we assume the mechanism is given a prediction of agents valuations. We note that in order to implement the mechanism it is enough to be given access to agents\u2019 preference order over items, and an additional information indicating which items are worth more than $\\mu_{i}^{n}/2$ for each agent $i$ . ", "page_idx": 27}, {"type": "text", "text": "Due to space constraints the proof of Theorem H.1 is deferred to Appendix H.3, and we now provide a detailed description of the different phases. ", "page_idx": 27}, {"type": "text", "text": "H.2 Implementation Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "As discussed, in order to utilize the Round-Robin mechanism, we first allocate a single item to each agent with a high predicted value. ", "page_idx": 27}, {"type": "table", "img_path": "aFB97F8QSF/tmp/9e2a993d815bf0f3ae0e60bd718ef212ed6716720e15be21a20d0343a3745c58.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Before describing the tentative allocation mechanism, we first give a procedure, Allocate-Best, which performs a single round of Round-Robin according to a specific order, and preferences (either predictions or reports), denote o. ", "page_idx": 27}, {"type": "table", "img_path": "aFB97F8QSF/tmp/dafe619097536885acab218ef3c6c3b95e67fc2bb7100661080a5ac4cc2f6412.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "The tentative allocation mechanism repeatedly invokes Allocate-Best according to given predictions, until all items are tentatively allocated. As previously mentioned, the first round of the tentative allocation is performed according to the given order, and in all subsequent rounds, the order is reversed (recall that reversing the order enhances the robustness guarantees). ", "page_idx": 27}, {"type": "table", "img_path": "aFB97F8QSF/tmp/6011cc65fda48e1133b9d3cb67de88b6c3178cc9fea49592365d294082ee83af.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "The final phase in the mechanism is a recursive plant and steal algorithm. The input to this algorithm is an ordered set of agents $N$ , along with their predictions, reports, and a tentative allocation for each agent. At each recursive invocation, the algorithm splits the set of agents into two (almost) equal-size ordered sets $N_{0}$ and $N_{1}$ . Then the mechanism \u201cplants\u201d for the $i^{\\mathrm{th}}$ agent in each set $N_{b}$ their highest (according to predictions) valued item in their tentative allocation in the tentative set of the $i^{\\mathrm{th}}$ agent in $N_{\\neg b}$ . Then we perform one round of Round-Robin, where the items available to the agents of set $N_{b}$ are those tentatively allocated to the agents of $N_{\\neg b}$ (after the planting phase), and the allocations are determined according to agents reports. See Figure 3 for an illustration of a single round of plant and steal. The algorithm then recurses on each of the sets $N_{0}$ and $N_{1}$ , until all sets are of size 1. At this point, the single agent in the set is further allocated its remaining tentatively allocated items, and the process terminates. ", "page_idx": 28}, {"type": "text", "text": "ALGORITHM 10: Split-Plant-Steal-Recurse ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Input :Ordered set of agents $N=(i_{1},\\ldots,i_{|N|})$ , tentative allocations $A$ , partial allocations $X_{N}$ , first-level-flag indicating if this is the first level of the recursion, reports $\\mathbf{r}_{N}$ , predictions $\\mathbf{p}_{N}$ $/*$ Halting condition - Allocate all remaining items \\*/   \nif $N=\\{i\\}$ then set $X_{i}=X_{i}\\cup A_{i}$ and halt $/*$ Split the agents into two almost-equal parts \\*/   \n$p a r=|N|$ mod 2   \n$N_{0}\\gets(i_{1},i_{3},\\ldots,i_{|N|-1+p a r})$   \n$N_{1}\\gets(i_{2},i_{4},\\cdot\\cdot\\cdot,i_{|N|-p a r}^{\\cdot})$ $/*$ Plant according to predictions \\*/   \nfor $i=l,\\ldots,\\,\\lfloor\\lvert N\\lvert/2\\rfloor$ do Let $i^{0},i^{1}$ denote the $i^{\\mathrm{th}}$ agent in $N_{0},N_{1}$ respectively. $\\begin{array}{l}{{j_{0}^{*}=p_{i^{0}}^{*}(A_{i_{0}})}}\\\\ {{j_{1}^{*}=p_{i^{1}}^{*}(A_{i_{1}})}}\\\\ {{A_{i^{0}}=A_{i^{0}}+j_{1}^{*}-j_{0}^{*}}}\\\\ {{A_{i^{1}}=A_{i^{1}}+j_{0}^{*}-j_{1}^{*}}}\\end{array}$ $/*$ Plant $i_{n}\\,^{\\bullet}\\,{\\bf s}$ favorite item in a tentative set \\*/   \nif $p a r=1$ then $\\begin{array}{l}{{i^{0}=i_{n},i^{1}=i_{2}}}\\\\ {{j_{0}^{*}=p_{i^{0}}^{*}(A_{i^{0}})}}\\\\ {{A_{i^{1}}=A_{i^{1}}+j_{0}^{*},A_{i^{0}}=A_{i^{0}}-j_{0}^{*}}}\\end{array}$ $/*$ Steal from the opposite set according to reports \\*/   \nforeach $b\\in\\{0,1\\}$ do   \nfor $\\begin{array}{r l}&{\\hat{X}\\!\\!=\\!\\!\\mathtt{A l l o c a t e-B e s t}(N_{b},A_{N_{-b}},\\mathbf{r})}\\\\ &{\\mathbf{each}\\;i\\in N\\;\\mathbf{do}}\\\\ &{\\;X_{i}\\gets X_{i}\\cup\\hat{X}_{i}}\\end{array}$ $/*$ Reverse the order after the first level of recursion \\*/   \nif first-level-flag then $\\begin{array}{l}{N_{0}\\gets\\bar{(i_{|N|-1+p a r},\\dots,i_{3},i_{1})}}\\\\ {N_{1}\\gets\\bar{(i_{|N|-p a r},\\dots,i_{4},i_{2})}}\\end{array}$ $/*$ Recursively invoke Split-Plant-Steal-Recurse on each set \\*/   \nforeach $b\\in\\{0,1\\}$ do Split-Plant-Steal-Recurs $\\mathfrak{z}(N_{b},A_{N_{b}},X_{N_{b}}$ ,first-level-flag $=$ False) ", "page_idx": 28}, {"type": "text", "text": "Given the above implementation details, it remains to prove Theorem H.1 regarding truthfulness, consistency and robustness of the mechanism. The proof is given in Appendix H.3. ", "page_idx": 28}, {"type": "text", "text": "H.3 Missing Details from Section H ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In this section we prove Theorem H.1, which we now recall. ", "page_idx": 28}, {"type": "text", "text": "Theorem H.1. The Learning-Augmented-MMS-for- $^{n}$ -Agents Mechanism (Mechanism 6) is truthful, 2-consistent and $(\\mu_{i}^{\\hat{n}}/\\bar{\\alpha})$ -robust for $\\hat{n}=\\lceil3n/2\\rceil$ and $\\alpha=\\operatorname*{max}\\{m-\\hat{n}-1,1\\}$ . ", "page_idx": 28}, {"type": "text", "text": "First, we give a simple observation regarding Algorithm 7. ", "page_idx": 28}, {"type": "text", "text": "1. If the reports equal the true valuations, and agent i is allocated an item $j$ , then $v_{i}(j)\\geq v_{i}^{n}/2$ . 2. After the algorithm completes its run, there are no remaining agents in $N$ with large predicted values for the remaining items in M. ", "page_idx": 29}, {"type": "text", "text": "We continue to prove each of the properties specified in Theorem H.1 separately, starting with truthfulness. ", "page_idx": 29}, {"type": "text", "text": "Lemma H.1 (Truthfulness). Mechanism Learning-Augmented-MMS-for-n-agents (Mechanism 6) is truthful. ", "page_idx": 29}, {"type": "text", "text": "Proof. Algorithm Tentative-Allocation-Round-Robin (Algorithm 9) only depends on agents predictions and not their reports. Hence, we only need to consider the use of the reports in Algorithms 9 and 10. ", "page_idx": 29}, {"type": "text", "text": "For every agent $i$ , either they are allocated a single item in Algorithms 9, or $i$ participates in the recursive plant ant steal, and this is determined according to the predictions, so in particular $r_{i}$ has no affect on this. Thus, we can consider the two independent events separately. In the first case, where $i$ is allocated a single item, it is the item that maximizes their report over remaining items at that point, so that $i$ has no incentive to lie. ", "page_idx": 29}, {"type": "text", "text": "In the second case, $i$ participates in the plant and steal phase. Observe that in this case, whenever $i$ chooses an item from some set $A^{\\prime}$ , it will have no future interaction with this set. That is, fix a recursive call and assume without loss of generality that $i\\in N_{0}$ . Then after the planting step, $i$ is allocated the item in $A_{N_{1}}$ that maximizes their reports. Then, in following recursive steps, $i$ only continues to interact with items in $A_{N_{0}}$ , so $i$ \u2019s choice does not affect the identity of the items from which $i$ will be able to choose from in future rounds. Hence, $i$ \u2019s only incentive is to maximize the value of its allocated value in each round, implying truthfulness. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "Due to the above lemma, from now on we assume agents report truthfully, i.e., that for every agent $i$ , $r_{i}=v_{i}$ . We turn to show the mechanism is consistent, we rely on the following theorem. ", "page_idx": 29}, {"type": "text", "text": "Theorem H.2 (Lemma 2 in [10] (based on Theorem 3.5 in [8])). If for every $i\\in N$ and $j\\in M$ , $\\begin{array}{r}{v_{i}(j)\\le\\frac{1}{2}\\mu_{i}^{n}}\\end{array}$ , then the Round-Robin algorithm returns an allocation that is a 2-approximation to the MMS. ", "page_idx": 29}, {"type": "text", "text": "Furthermore, their analysis holds when changing the order of allocation between the different rounds of the Round-Robin. ", "page_idx": 29}, {"type": "text", "text": "We are now ready to prove the mechanism is consistent. ", "page_idx": 29}, {"type": "text", "text": "Lemma H.2 (Consistency). If the set of predictions is accurate, then for every i, $v_{i}(X_{i})\\geq\\mu_{i}^{n}/2$ . ", "page_idx": 29}, {"type": "text", "text": "Proof. First consider agents that were allocated an item in Algorithm Allocate-Large (Algorithm 7). If the predictions are accurate, then each such agent $i$ is allocated an item $j$ such that $v_{i}(j)\\geq\\mu_{i}^{n}/2$ and so the statement holds. Moreover, at the end of this step, there are no remaining agents with large predicted values, hence, no agents with large values remain. ", "page_idx": 29}, {"type": "text", "text": "If the set of predictions is accurate, then the tentative allocation determined according to agents\u2019 predictions in Algorithm Tentative-Allocation-Round-Robin ( Algorithm 9) is identical to a Round-Robin mechanism according to valuations, with reversing the order between the first and all subsequent rounds. Furthermore, by the above, there are no agents with large values when the Round-Robin is invoked. Therefore, by Theorem H.2, it holds that for every $i$ , $v_{i}(A_{i})\\,\\geq\\,\\mu_{i}^{n}/2$ . We shall prove that for every agent $i$ , its final allocation equals its tentative allocation, $X_{i}=A_{i}$ , concluding the proof. ", "page_idx": 29}, {"type": "text", "text": "We prove that in depth $k$ of the recursion, every agent $i$ is allocated the $k^{\\mathrm{th}}$ item in $A_{i}$ . We prove the claim by induction on the depth $k$ of the recursion, and the $\\ell^{\\mathrm{th}}$ agent in that round that is allocated some value. ", "page_idx": 29}, {"type": "text", "text": "We first prove for $k=1,\\ell=1$ . In the plant phase, $\\ell^{0}(=1)$ plants $j=p_{\\ell^{0}}^{*}(A_{\\ell^{0}})$ in $A_{\\ell^{1}}$ . Then, in the stealing phase, during the invocation of Algorithm 8, agent $\\ell^{0}$ is the first to choose an item from $A_{N_{1}}$ , which in particular contains $j$ . Hence, the first item in $A_{1}$ is allocated into $X_{1}$ . We now assume the claim holds for $k=1$ and $\\ell-1$ and prove it for $\\ell$ . Assume without loss of generality that $\\ell$ is odd so that $i_{\\ell}\\in N_{0}$ . ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "In step $\\ell$ of the planting phase, the mechanism plants $\\ell^{0}$ \u2019s (the proof for $\\ell^{1}$ is identical) first (according to value $p_{\\ell^{0}}$ ) item in $A_{\\ell^{0}}$ . Then, during the tentative allocation phase, agent $\\ell^{0}$ is the $\\ell^{\\mathrm{th}}$ to choose among the items in $A_{N_{1}}$ minus the items that were allocated to the $\\ell-1$ agents that were before her in the tentative Round-Robin. By the induction hypothesis, every agent preceding her chose the item the mechanism planted for them previously in that round. Therefore, the item $j$ that the mechanism planted for agent $\\ell^{0}$ is still available. Moreover, let $M^{\\ell-1}$ denote the set of items after $\\ell-1$ rounds of the tentative Round-Robin in Algorithm 9. Further let $A_{N_{1}}^{\\ell-1}$ denote the set of items after $\\ell-1$ rounds of the Allocate-Best algorithm invoked in the stealing phase with the set $N_{0}$ , ir.oeu.,n $A_{N_{1}}^{\\ell-1}=A_{N_{1}}\\setminus\\bigcup_{j\\in N_{0},j<\\ell}\\{X_{j}\\}$ .t hSei norcdee tr hien  owrhdiecrh i tnh ew choircrhe stphoe nadgineng ttse nptlaatnitv ea naldl osctaetailo inn r oeuacnhd was performed, it holds that $A_{N_{1}}^{\\ell-1}\\subset M^{\\ell-1}$ . Since $j\\,=\\,p_{\\ell^{0}}^{*}(M^{\\ell-1})$ , and $p_{\\ell^{0}}=r_{\\ell^{0}}$ , it holds that $r_{\\ell^{0}}^{*}(A_{N_{1}}^{\\ell-1})$ equals $j$ . Therefore $\\ell^{0}$ will choose $j$ to $X_{\\ell^{0}}$ as claimed. ", "page_idx": 30}, {"type": "text", "text": "Proving the claim for a general $k$ is almost identical. At the planting phase of the $k^{\\mathrm{th}}$ round, the mechanism plants for every agent $\\ell^{0}\\in N_{0}^{k}$ their $k^{\\mathrm{th}}$ item of $A_{i}$ in $A_{N_{1}^{k}}$ and vice versa. A similar argument to the one above, shows that this item will remain available until its their turn to choose an item for allocation, as by the recursion hypothesis, all agents preceding $i$ in the Round-Robin will select the items the mechanism planted for them. Hence, the $k^{\\mathrm{th}}$ item in $A_{\\ell^{0}}$ will be allocated to $X_{\\ell^{0}}$ . ", "page_idx": 30}, {"type": "text", "text": "Finally, once the set agent $i$ belongs to becomes a singleton, by our halting condition, $X_{i}\\leftarrow X_{i}\\cup A_{i}$ , so together with the previous argument, we get that for every $\\ell$ , $X_{i}=A_{i}$ as needed. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "We continue to prove that the mechanism is robust. Since when $m<\\hat{n}$ , $\\mu_{i}^{\\hat{n}}=0$ for every agent $i$ , and each agent trivially gets their MMS value, we assume from now on that $m\\geq\\hat{n}$ and show the mechanism achieves $(m-\\hat{n}-1)$ -robustness for $\\mu_{i}^{\\hat{n}}$ . We first prove in Lemma H.3 that for each agent $i$ , $v_{i}(X_{i})\\geq v_{i}^{\\lceil3n/2\\rceil}$ , and then prove in Lemma H.5 that the value of this item is not too small compared to $\\mu_{i}^{\\lceil3n/2\\rceil}$ . ", "page_idx": 30}, {"type": "text", "text": "Lemma H.3. For every agent i, $v_{i}(X_{i})\\geq v_{i}^{\\lceil3n/2\\rceil}$ . ", "page_idx": 30}, {"type": "text", "text": "Proof. We first prove the claim for agents that were allocated a value during the invocation of Algorithm 7. By the definition of the algorithm and its truthfulness when agent $i$ is allocated an item, at most $n-1$ items were previously allocated to other agents. Hence, she can always choose her $n^{\\mathrm{th}}$ highest valued item. Therefore, we have $v_{i}(X_{i})\\geq v_{i}^{n}\\geq v_{i}^{\\lceil3n/2\\rceil}$ , as claimed. ", "page_idx": 30}, {"type": "text", "text": "We continue to prove the claim for the set of agents with no large predicted values. Consider the $\\ell^{\\mathrm{th}}$ agent in $N,i_{\\ell}$ , and consider the following coloring process. Initially, color all items in $M$ black. We will then color all items $i_{\\ell}$ was able to choose from green, and items allocated before she had the chance to choose from gray (note that these colors are unrelated to the ones in the figure). Note that an item turns green when it belongs to the tentative allocation of opposite set to $i_{\\ell}$ \u2019s and has not been taken by agents preceding her in the allocation order. We claim that by the time no black items remain, at most $\\left\\lceil3n/2\\right\\rceil-1$ have turned gray, implying that at some point during the recursion, $i_{\\ell}$ could have chosen their $\\lceil{\\frac{3n}{2}}\\rceil^{\\mathrm{th}}$ highest valued item (according to $r_{i_{\\ell}}$ ). ", "page_idx": 30}, {"type": "text", "text": "We let $N^{k}$ denote the set of agents to which $i_{\\ell}$ belongs to at depth $k$ of the recursion, starting with $N^{1}=N$ . At each recursive call, $N^{k}$ is partitioned into $N_{0}^{k},N_{1}^{\\tilde{k}}$ . We further let $b^{k}\\in\\{0,1\\}$ denote tthure niendd egxr aoyf  dthuee  stoe t atgo enwthsi icnh $i_{\\ell}$ ealnond $i_{\\ell}\\in N_{b^{k}}^{k}$ . We will separately bound the number of items $N_{b_{k}}^{k}$ $N_{\\neg b_{k}}^{k}$ ", "page_idx": 30}, {"type": "text", "text": "In the first iteration, for $k=1$ , let $A_{N_{b^{0}}^{1}}^{1},A_{N_{-b^{0}}^{1}}^{1}$ denote the tentative sets allocated to the agents of $N_{0}^{1}$ and $N_{1}^{1}$ after the planting phase (i.e., at the beginning of the stealing phase). ", "page_idx": 30}, {"type": "text", "text": "The number of items that turn gray due to agents in $N_{b^{1}}^{1}$ is $G_{b^{1}}^{1}=\\left\\lceil\\ell/2\\right\\rceil-1$ , since $i_{\\ell}$ has access to all items in $A_{N_{-b^{1}}}^{1}$ excluding the $\\lceil\\ell/2\\rceil-1$ items that were allocated to the agents in her set preceding her in the or\u00acdbering. (The rest of the items in $A_{N_{\\rightarrow b^{1}}}^{1}$ turn green.) ", "page_idx": 30}, {"type": "text", "text": "Turning to $G_{\\rightarrow b^{1}}^{1}$ , each agent in the opposite set to hers, $N_{\\neg b^{1}}^{1}$ , is allocated a single item (from $A_{N_{b^{1}}^{1}}^{1})$ before continuing to the next round of the recursion. Therefore, $G_{\\rightarrow b^{1}}^{1}=|N_{\\rightarrow b^{1}}^{1}|$ (and no item turns green). ", "page_idx": 31}, {"type": "text", "text": "The recursion then continues with $N^{2}=N_{b^{1}}^{1}$ and in reversed order (due to the order being reversed). Therefore, at the beginning of the second iteration, $i_{\\ell}$ is in location $\\left|N_{b^{1}}^{1}\\right|-\\left\\lceil\\ell/2\\right\\rceil$ in $N^{2}$ . After the partition phase, $i_{\\ell}$ is in set $N_{b^{2}}^{2}$ and in location $\\lceil\\frac{|N_{b^{1}}^{1}|-\\lceil\\frac{\\ell}{2}\\rceil}{2}\\rceil$ . Hence, $\\begin{array}{r}{G_{b^{1}}^{\\bar{1}}=\\lceil\\frac{|N_{b_{1}}^{1}|-\\lceil\\frac{\\ell}{2}\\rceil}{2}\\rceil-1}\\end{array}$ due to agents in her set preceding here in the ordering. Also, $G_{\\rightarrow b^{1}}^{1}=|N_{\\rightarrow b^{1}}^{1}|$ due to allocations to agents in the opposite set to hers. ", "page_idx": 31}, {"type": "text", "text": "From now on, the order is preserved, so for every $k\\geq3$ , $G_{b^{k}}^{k}=|N_{b^{k}}^{k}|$ and $\\begin{array}{r}{G_{-b^{k}}^{k}=\\lceil\\frac{|N_{b^{1}}^{1}|-\\lceil\\ell/2\\rceil}{2^{k-1}}\\rceil-1}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "We continue by bounding \u2308kl=og1 n $\\begin{array}{r}{\\sum_{k=1}^{\\lceil\\log n\\rceil}G_{\\neg b^{k}}^{k}\\;=\\;\\sum_{k=1}^{\\lceil\\log n\\rceil}|N_{\\neg b^{k}}^{k}|}\\end{array}$ . Observe that if $N^{k}$ is even then $N_{b^{k}}^{k}=N_{\\neg b^{k}}^{k}=N^{k}/2$ , and  if $N^{k}$ is odd, then e ither $N_{b^{k}}^{k}$ is odd and $N_{\\neg b^{k}}^{k}$ is even or vice versa. In the first case, $\\bar{G}_{\\rightarrow b^{k}}^{k}=\\lceil N^{k}/2\\rceil$ and we recurse with $N_{b^{k}}^{k}$ which is of size $\\left\\lfloor N^{K}/2\\right\\rfloor$ . In the second case, $G_{\\rightarrow b^{k}}^{k}=\\lfloor N^{K}/2\\rfloor$ and we recurse with $N_{b^{k}}^{k}$ of size $\\left\\lceil N^{k}/2\\right\\rceil$ . Hence, we have the following recursion formula. For even $\\ell$ , $T(\\ell)=\\ell/2+T(\\ell/2),$ , and for odd $\\ell$ , either (a) $T(\\ell)=\\lceil\\ell/2\\rceil+\\bar{T}(\\lfloor\\ell/2\\rfloor)$ or (b) $T(\\ell)=\\lfloor\\ell/2\\rfloor+T(\\lceil\\ell/2\\rceil)$ . In Claim H.4 below, we prove that for such a function, if it also holds that $T(1)=0$ and $T(2)=1$ , then $T(\\ell)\\leq\\ell-1$ . Therefore, we get that \u2308kl=og1 n\u2309Gk\u00acbk \u2264n \u22121. ", "page_idx": 31}, {"type": "text", "text": "We continue to bound $\\begin{array}{r}{\\sum_{k=2}^{\\lceil\\log n\\rceil}G_{\\rightarrow b^{k}}^{k}=\\sum_{k=2}^{\\lceil\\log n\\rceil}\\lceil\\frac{|N_{b^{1}}^{1}|-\\lceil\\ell/2\\rceil}{2^{k-1}}\\rceil-1}\\end{array}$ . The sum $\\sum_{k=1}^{\\lceil\\log X\\rceil}\\left\\lceil{\\frac{X}{2^{k}}}\\right\\rceil$ can be bounded by $\\begin{array}{r}{\\left(\\sum_{k=1}^{\\lceil\\log X\\rceil}\\frac{X}{2^{k}}\\right)+L}\\end{array}$ , where $L$ is the number of indices $k$ for whic h the fraction $X/2^{k}$ is rounded up. Observe that for every $X$ , $L$ can be bounded above by $\\lceil\\log X\\rceil$ as $L$ exactly equals the number of 1 bits in the binary representation of $X$ . Hence, the overall number of items that turn gray can be bounded as follows: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{G^{\\lceil\\log n\\rceil}=\\sum_{k=1}^{\\lceil\\log n\\rceil}\\big(G_{-b^{k}}^{k}+G_{b^{k}}^{k}\\big)}}\\\\ &{\\le n-1+\\lceil\\ell/2\\rceil-1+\\sum_{k=2}^{\\lceil\\log n\\rceil}\\left(\\left\\lceil\\frac{\\lceil n/2\\rceil-\\lceil\\ell/2\\rceil}{2^{k-1}}\\right\\rceil-1\\right)}\\\\ &{\\le n-1+\\lceil\\ell/2\\rceil-1+\\lceil n/2\\rceil-\\lceil\\ell/2\\rceil+\\lceil\\log n\\rceil-\\lceil\\log n\\rceil+1}\\\\ &{\\le\\lceil3n/2\\rceil-1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Therefore, the number of items that turn gray by the end of the recursion is at most $\\left\\lceil3n/2\\right\\rceil-1$ , and so i\u2113get their \u23083n/2\u2309highest valued item vi\u2308\u21133 $v_{i_{\\ell}}^{\\lceil3n/2\\rceil}$ \u53e3 ", "page_idx": 31}, {"type": "text", "text": "We now prove the claim regarding the cost of the recursion that was used in the previous lemma. ", "page_idx": 31}, {"type": "text", "text": "Lemma H.4. Let $T(n)$ be such that $T(n)\\,=\\,n/2+T(n/2)$ if $n$ is even and either (a) $T(n)\\,=$ $\\lceil n/2\\rceil+T(\\lfloor n/2\\rfloor)\\,o r\\,(b)\\,T(n)=\\lfloor n/2\\rfloor+T(\\lceil n/2\\rceil)$ for odd $n$ . Also assume $T(1)=0,T(2)=1$ Then $T(n)\\leq n-1$ . ", "page_idx": 31}, {"type": "text", "text": "Proof. We prove the claim by induction on $n$ . By $T(1)=0$ and $T(2)=1$ so the induction basis holds. We now assume correctness for all values smaller than $n$ and prove for $n$ . ", "page_idx": 31}, {"type": "text", "text": "If $n$ is even then $T(n)=n/2+T(n/2)\\le n/2+n/2-1=n-1.$ , so the claim holds. ", "page_idx": 31}, {"type": "text", "text": "If $n$ is odd, then in case (a), $T(n)=\\lceil n/2\\rceil+T(\\lfloor n/2\\rfloor)\\le\\lceil n/2\\rceil+\\lfloor n/2\\rfloor-1=n-1$ , and in case (b), T(n) = \u230an/2\u230b+ T $^7(\\lceil n/2\\rceil)-1\\leq\\lfloor n/2\\rfloor+\\lceil n/2\\rceil-1=n-1.$ . \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Finally, we prove that the highest valued item allocated to each agent $i$ is not too small compared to their MMS. ", "page_idx": 31}, {"type": "text", "text": "Lemma H.5. Consider an MMS for agent $i$ , and let $j^{*}$ be the highest valued item of i in her allocation. Then ", "page_idx": 31}, {"type": "equation", "text": "$$\nv_{i}(j^{\\ast})\\geq\\mu_{i}^{\\left[3n/2\\right]}/\\alpha\\quad f o r\\quad\\alpha=m-\\left[3n/2\\right]-1.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Consider an MMS allocation of $M$ for $k=\\lceil3n/2\\rceil$ , and let $A_{i}$ be the set such that $v_{i}(A_{i})=$ $\\mu_{i}^{k}$ . By the assumption on $j^{*}$ , its value is higher then the highest valued item in $A_{i}$ , $v_{i}(j^{*})\\geq$ $v_{i}^{1}(A_{i})$ . Therefore, $v_{i}(A_{i})\\;\\leq\\;|A_{i}|\\cdot v_{i}(j^{*})$ , implying $v_{i}(j^{*})\\;\\geq\\;v_{i}(A_{i})/|A_{i}|\\;=\\;\\mu_{i}^{k}/|A_{i}|$ . Since $|A_{i}|\\leq m-k-1$ (as at least $k-1$ items must be allocated to the $k-1$ additional agents, it holds that $v_{i}(j^{*})\\geq\\mu_{i}^{3n/2}/(m-\\lceil3n/2\\rceil-1).$ . \u53e3 ", "page_idx": 32}, {"type": "text", "text": "Proof of Theorem H.1. The theorem follows by Lemmas H.1, H.2, H.3, and H.5. ", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 33}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 33}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 33}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 33}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 33}, {"type": "text", "text": "IMPORTANT, please: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The abstract is a high-level description of the results of the paper. The intro introduces a more detailed dive into the results, with a \u201cour results and techniques\" section, where we try to give a detailed overview of our technical contributions. Moreover, Table 1 is given to provide an easy-to-understand summary of our theoretical results. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [No] ", "page_idx": 34}, {"type": "text", "text": "Justification: This is mainly a theoretical paper, and all the assumptions are clearly stated. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 34}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper contains a detailed preliminary section where the model is fully described. The theorems and complete, and the ones not appearing in the body appear in the appendix. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Using the code provided, it is possible to reproduce the main experimental results. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 35}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: The code can be accessed via the link: https://tinyurl.com/PlantStealExperiments. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We describe how the data is generated and provide the code. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 36}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper experiments with Bernoulli variables (indicating either success or failure) with non-negligible $p$ values, which are known to be very highly concentrated. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The experiments were done on a standard PC (Intel i9, 32GB memory), and it took approximately 30 minutes. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 37}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The paper studies a mechanism design problem with the objective of outputting a fair allocation, which is a highly desirable goal. We study a generalization of the widely studied proportionality objective for discrete settings. We note that this objective is well motivated in settings like course-allocation [18], but might be inappropriate in other settings. The techniques in this paper should be used with appropriate care. Moreover, over paper suggests that using past data might increase fairness, but every usage of data should be taken with extra precautions, as these might introduce implicit biases, as shown in the past. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 37}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: Introducing a learning-augmented framework is shown to obtain stronger theoretical fairness guarantees than other mechanisms studied in the literature. Elements in the design might improve the performance of fair allocation mechanisms in settings such as course allocation, which is of course a positive societal impact. On the other hand, using past data can also result in introducing biases to the allocation, thus, using data should be done with awareness to such potential biases. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 37}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: No third-party packages are used, and the data used for experiments is synthetic. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: Experimental details are described and documented code is provided. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 39}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 39}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 39}]