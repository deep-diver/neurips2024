[{"figure_path": "PmLty7tODm/tables/tables_3_1.jpg", "caption": "Table 1: Accuracy of local hyperplanes for neighboring points.", "description": "This table shows the accuracy of the local hyperplanes generated by the IMN model for different numbers of neighboring points.  The accuracy is calculated by using the hyperplane generated for a single data point to classify its neighbors.  The table demonstrates that the IMN model generates hyperplanes that maintain reasonable accuracy even when classifying points further away from the data point for which the hyperplane was originally trained.", "section": "2 Proposed Method"}, {"figure_path": "PmLty7tODm/tables/tables_6_1.jpg", "caption": "Table 2: Aggregated training and inference times for all methods.", "description": "This table presents the median training and inference times for various machine learning models used in the paper's experiments.  The models are categorized as either interpretable white-box models, strong black-box classifiers, or interpretable deep learning architectures. Training times reflect the time taken to train the models, while inference times reflect the time taken to generate predictions for a single data instance. The GPU usage for some of the models is also specified. This table provides a comparative analysis of the computational efficiency of different methods for both training and inference.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_7_1.jpg", "caption": "Table 3: Investigating the interpretability of IMNs against state-of-the-art interpretability methods. The results are generated from the XAI Benchmark (Liu et al., 2021) datasets (with p = 0).", "description": "This table presents a comparison of the proposed IMN method against eight state-of-the-art explainability methods across three datasets from the XAI Benchmark.  The comparison uses five interpretability metrics: Faithfulness, Faithfulness (ROAR), Infidelity, Monotonicity (ROAR), and Shapley Correlation. Higher values are better for Faithfulness and Monotonicity, while lower values are better for Infidelity.  The table shows the performance of each method on each metric for each dataset, allowing for a comprehensive evaluation of the IMN's interpretability compared to existing techniques.", "section": "4.2 Explainability Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_7_2.jpg", "caption": "Table 4: Interpretable method inference times. All the methods are run on the GPU and the time is reported in seconds.", "description": "This table presents the median inference time in seconds for various interpretable methods including IMN, TabNet, and SHAP using different backbones (TabResNet and CatBoost) on three benchmark datasets: Credit-g, Adult, and Christine. The results demonstrate IMN's significantly faster inference compared to other methods.", "section": "4.2 Explainability Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_8_1.jpg", "caption": "Table 5: The feature rank importances for the Census dataset. A lower rank is associated with a higher feature importance.", "description": "This table shows the feature ranking based on importance for the Census dataset, using several explainable methods (SHAP, Decision Tree, TabNet, CatBoost, and IMN).  A lower rank indicates a higher importance for that feature in predicting the target variable.  This allows a comparison of how these different methods assess the relative importance of features.", "section": "4.2 Explainability Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_16_1.jpg", "caption": "Table 6: Statistics regarding the AutoML benchmark datasets.", "description": "This table provides a statistical overview of the 35 datasets used in the AutoML benchmark experiments. For each dataset, it lists the dataset ID, dataset name, number of instances, number of features, number of classes, majority class percentage, and minority class percentage.  The table offers a comprehensive summary of the characteristics of the datasets used in the study's predictive accuracy experiments. This information is crucial for understanding the context and generalizability of the experimental results.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_16_2.jpg", "caption": "Table 8: The per-dataset test AUROC performance for all methods in the accuracy experiments with default hyperparameter configurations. The test performance is the mean value from 10 runs with different seeds. A dashed line '-' represents a failure of running on that particular dataset.", "description": "This table shows the test AUROC (Area Under the Receiver Operating Characteristic curve) for multiple classification models on various datasets.  The models compared include Decision Tree, Logistic Regression, NAM, Random Forest, TabNet, TabResNet, CatBoost, and IMN. The AUROC values represent the average performance over 10 runs with different random seeds, offering a robust comparison of model performance. A dash indicates that a specific model failed to produce a result for a particular dataset. This table is part of the analysis comparing different models' predictive accuracy on multiple datasets using default hyperparameters.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_17_1.jpg", "caption": "Table 8: The per-dataset test AUROC performance for all methods in the accuracy experiments with default hyperparameter configurations. The test performance is the mean value from 10 runs with different seeds. A dashed line '-' represents a failure of running on that particular dataset.", "description": "This table presents the test AUROC (Area Under the Receiver Operating Characteristic curve) performance for different classification models on various datasets.  The results are averaged over 10 runs with different random seeds, to provide a measure of robustness.  A dash indicates that the model failed to run on that specific dataset.  The models compared include Decision Tree, Logistic Regression, NAM, Random Forest, TabNet, TabResNet, CatBoost, and IMN (Interpretable Mesomorphic Network). The table helps to evaluate the predictive accuracy of different methods on a diverse range of datasets, using a standard performance metric.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_18_1.jpg", "caption": "Table 8: The per-dataset test AUROC performance for all methods in the accuracy experiments with default hyperparameter configurations. The test performance is the mean value from 10 runs with different seeds. A dashed line '-' represents a failure of running on that particular dataset.", "description": "This table presents the test AUROC (Area Under the Receiver Operating Characteristic curve) performance of several classification methods on 35 different datasets from the AutoML benchmark.  Each method's AUROC is the average across 10 runs with different random seeds.  The results show the predictive accuracy of different models, including Decision Tree, Logistic Regression, Random Forest, TabNet, TabResNet, CatBoost, and the proposed IMN (Interpretable Mesomorphic Network) model.  A '-' indicates that a specific method failed to run on a particular dataset.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_19_1.jpg", "caption": "Table 8: The per-dataset test AUROC performance for all methods in the accuracy experiments with default hyperparameter configurations. The test performance is the mean value from 10 runs with different seeds. A dashed line '-' represents a failure of running on that particular dataset.", "description": "This table presents the test AUROC (Area Under the Receiver Operating Characteristic curve) performance of different machine learning methods on 35 diverse datasets.  The methods compared include Decision Tree, Logistic Regression, NAM, Random Forest, TabNet, TabResNet, CatBoost, and IMN (Interpretable Mesomorphic Network).  The AUROC scores represent the average performance across ten runs with varying random seeds, providing a measure of model robustness. A dash indicates that a particular method failed to complete the experiment for that specific dataset.", "section": "4.1 Predictive Accuracy Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_20_1.jpg", "caption": "Table 3: Investigating the interpretability of IMNs against state-of-the-art interpretability methods. The results are generated from the XAI Benchmark (Liu et al., 2021) datasets (with p = 0).", "description": "This table compares the performance of IMN against other state-of-the-art methods on multiple interpretability metrics. The metrics used are faithfulness, faithfulness (ROAR), infidelity, monotonicity (ROAR), and Shapley Correlation. The results are generated from three datasets within the XAI Benchmark.", "section": "4.2 Explainability Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_20_2.jpg", "caption": "Table 1: Accuracy of local hyperplanes for neighboring points.", "description": "This table presents the accuracy of local hyperplanes generated by the IMN model for varying numbers of neighboring points.  It shows how well the linear model generated for a single data point generalizes to its neighbors.  The results demonstrate the local accuracy of the learned linear models.", "section": "2 Proposed Method"}, {"figure_path": "PmLty7tODm/tables/tables_20_3.jpg", "caption": "Table 3: Investigating the interpretability of IMNs against state-of-the-art interpretability methods. The results are generated from the XAI Benchmark (Liu et al., 2021) datasets (with p = 0).", "description": "This table compares the performance of the proposed IMN model against eight state-of-the-art explainability methods across three datasets from the XAI Benchmark.  The comparison uses five interpretability metrics: Faithfulness, Monotonicity, Infidelity, and Shapley Correlation.  The table shows the numerical results for each method and metric on each dataset, allowing for a direct comparison of the IMN's interpretability against existing techniques.", "section": "4.2 Explainability Experiments"}, {"figure_path": "PmLty7tODm/tables/tables_21_1.jpg", "caption": "Table 1: Accuracy of local hyperplanes for neighboring points.", "description": "This table presents the accuracy of local hyperplanes generated by the IMN model for varying numbers of neighboring points.  It demonstrates the model's ability to generate accurate linear classifiers not only for a specific data point but also for its neighboring points, showcasing its local accuracy and interpretability.", "section": "2 Proposed Method"}, {"figure_path": "PmLty7tODm/tables/tables_21_2.jpg", "caption": "Table 1: Accuracy of local hyperplanes for neighboring points.", "description": "This table shows the accuracy of the local hyperplanes generated by the IMN model for different numbers of neighboring points. The accuracy is evaluated by classifying the neighborhood of each point using the hyperplane generated for that point. The results indicate that the IMN model generates accurate local hyperplanes for the neighborhood of points, with an accuracy of 0.84 for 10 neighbors and 0.77 for 200 neighbors.", "section": "2 Proposed Method"}, {"figure_path": "PmLty7tODm/tables/tables_21_3.jpg", "caption": "Table 16: Hyperparameter search space for the TabNet model.", "description": "This table presents the hyperparameter search space used for tuning the TabNet model during the experiments.  Each hyperparameter is listed along with its data type (categorical or continuous) and the range of values considered.  Note that the `log_scale` column indicates whether the logarithmic scale was used for the hyperparameter's range. This information is crucial for understanding the hyperparameter optimization process and how the TabNet model was tuned for optimal performance.", "section": "4.1 Predictive Accuracy Experiments"}]