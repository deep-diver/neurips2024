[{"figure_path": "QgMC8ftbNd/figures/figures_1_1.jpg", "caption": "Figure 1: A depiction of the generality of our proposed models. POSTs and POSGs capture MDPS, POMDPs, Dec-POMDPs, and POMGs as special cases.", "description": "This figure shows a Venn diagram illustrating the relationships between different reinforcement learning models.  The most general models are POSTs (partially-observable sequential teams) and POSGs (partially-observable sequential games).  These encompass several other, more specialized models as subsets: MDPS (Markov Decision Processes), POMDPs (Partially Observable Markov Decision Processes), Dec-POMDPs (Decentralized Partially Observable Markov Decision Processes), and POMGs (Partially Observable Markov Games). The figure visually represents the hierarchical inclusion of these models, showing that POSTs and POSGs are the most comprehensive.", "section": "Summary of Contributions"}, {"figure_path": "QgMC8ftbNd/figures/figures_6_1.jpg", "caption": "Figure 4: An illustrative example of the information-structural state for POMDPs. Left. The DAG representation of the information structure G. Right. The DAG G\u2020 is depicted by drawing the edges corresponding to the information sets of the action variables with dotted lines. The information-structural state coincides with the Markovian state st, and is depicted in red. Future observables are drawn in green, and past observables are drawn in blue.", "description": "This figure illustrates the concept of information-structural state in the context of POMDPs. It shows two DAGs. The left DAG (G) represents the full information structure of the POMDP, indicating causal relationships between variables (states, observations, actions). The right DAG (G\u2020) is a modified version of G where edges pointing to action variables are removed. The information-structural state (depicted in red) is the minimal set of past variables that renders past and future observations conditionally independent, effectively serving as a sufficient statistic for predicting future observations. This concept generalizes the notion of a Markovian state.", "section": "3.3 Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_6_2.jpg", "caption": "Figure 2: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent Z. To find I\u2020, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows the DAG representation of five different information structures. Each node represents a variable, and edges indicate causal relationships between variables.  Different node colors represent different variable types (e.g., system variables, action variables, observable variables).  The figure illustrates how the information structural state, a crucial concept in the paper, can be identified from the DAGs. The information structural state is the minimal set of past variables (observable and unobservable) that separates past and future observations, determining the complexity of the system's dynamics.", "section": "Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_7_1.jpg", "caption": "Figure 3: A depiction of the construction of a generalized generalized predictive state representation for POST/POSG models.", "description": "This figure shows a schematic representation of how to construct a generalized predictive state representation for partially observable sequential teams (POST) and partially observable sequential games (POSG).  It highlights the key components including the information structural state (I\u2020h), which is a sufficient statistic for predicting future observations given the past; m-step future observable trajectories that serve as core test sets (Qm); and the transition operator Mh(xt(h)) that updates the representation based on the current observable and information structural state.", "section": "Constructing a PSR Parameterization for POSTs and POSGs"}, {"figure_path": "QgMC8ftbNd/figures/figures_21_1.jpg", "caption": "Figure 2: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent the information structural state I\u2020. To find I\u2020, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows five examples of DAG representation of information structures of different types of sequential decision-making problems. The nodes represent variables and the edges represent the causal relationships between them. The color of the nodes indicate whether the variable is observable (blue, green) or unobservable (grey) and whether the variable belongs to the past (blue) or future (green).  The red nodes represent the information-structural state, which according to Theorem 1 is a sufficient statistic of the past to predict the future observations.", "section": "Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_22_1.jpg", "caption": "Figure 5: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent the information structural state I. To find I, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows five different DAG representations of various information structures. Each DAG visually represents causal dependencies between variables, illustrating different levels of complexity. The nodes represent variables (observable or unobservable, past or future, action or system) and the edges represent causal dependencies between them. The red node represents the information-structural state which is crucial for determining the complexity of the problem.  The figure aids in understanding Theorem 1 and the effects of various information structures on the complexity of sequential decision-making problems.", "section": "3.3 Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_22_2.jpg", "caption": "Figure 5: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent the information structural state I\u2020. To find I\u2020, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows different DAG representations of various information structures in sequential decision making problems, including decentralized POMDP/POMG, mean-field, point-to-point real-time communication with feedback, limited-memory, and fully-connected structures. Each node represents a variable, solid edges represent causal dependencies between system variables, and light edges represent information sets of action variables.  Grey, blue, green, and red nodes represent unobservable, past observable, future observable, and information structural state variables, respectively. The figure illustrates how the complexity of observable system dynamics changes across different information structures by using the concept of d-separation to identify the minimal set of past variables that d-separate past observations from future observations. This minimal set is the information structural state, I\u2020, which is shown in red.", "section": "Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_22_3.jpg", "caption": "Figure 2: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent the information structural state I. To find I, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows different DAG representations of information structures. Each DAG represents a different sequential decision-making problem. The nodes represent the variables in the problem, which can be observable or unobservable, action or state. The edges represent the dependencies between the variables.  Each row represents the sequence of variables at a specific time step.  The red node shows the information structural state, which is a sufficient statistic to predict the future given the past.  The figure illustrates how the information structure can significantly affect the complexity of a sequential decision-making problem.", "section": "Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_22_4.jpg", "caption": "Figure 2: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent Z. To find I\u2020, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows several examples of information structures represented as directed acyclic graphs (DAGs). Each DAG visually depicts the causal relationships between variables in a sequential decision-making problem. Different colors are used to represent different types of variables (unobservable, past observable, future observable, action variables).  The red nodes highlight the information-structural states, which are minimal sets of past variables that make the past and future observations conditionally independent. This visualization helps to understand how the information structure influences the complexity of the system dynamics, which is crucial for reinforcement learning.", "section": "Examples of Information Structures and their Rank"}, {"figure_path": "QgMC8ftbNd/figures/figures_41_1.jpg", "caption": "Figure 2: DAG representation of various information structures. Solid edges indicate the edges in E\u2020 and light edges indicate the information sets of action variables. Grey nodes represent unobservable variables, blue nodes represent past observable variables, green nodes represent future observable variables, and red nodes represent the information structural state I. To find I, as per Theorem 1, we first remove the incoming edges into the action variables, then we find the minimal set among all past variables (both observable and unobservable) which d-separates the past observations from the future observations.", "description": "This figure shows the directed acyclic graph (DAG) representation of five different information structures.  Each DAG represents the causal relationships between variables in a sequential decision-making problem. The nodes represent variables, and the edges represent causal dependencies. Grey nodes are unobservable, blue are past observables, green are future observables, and red is the information-structural state (I). Theorem 1 of the paper uses the DAG to determine an upper bound on the rank of the observable system dynamics, a key factor in determining the complexity of the problem.  The five examples illustrate variations in complexity ranging from simple (decentralized POMDPs/POMGs) to complex (fully connected).", "section": "3.3 Examples of Information Structures and their Rank"}]