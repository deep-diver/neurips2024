[{"figure_path": "FbUSCraXEB/tables/tables_3_1.jpg", "caption": "Table 1: Alignment gap, uniformity gap, and test accuracy(%) of poisoned SimCLR [5] models. Attacks are grouped according to whether they are based on contrastive error minimization. Bold fonts emphasize prominent contrastive unlearnability values.", "description": "This table presents the results of various availability attacks against the SimCLR algorithm on the CIFAR-10 dataset.  For each attack, it shows the alignment gap, uniformity gap, and test accuracy. The alignment and uniformity gaps measure the difference in feature distributions between the clean and poisoned datasets. The table is organized to highlight the differences in effectiveness between attacks based on contrastive error minimization and other methods.  Bold values highlight significant contrastive unlearnability.", "section": "3.2 Existing Attacks against Contrastive Learning"}, {"figure_path": "FbUSCraXEB/tables/tables_5_1.jpg", "caption": "Table 2: Accuracy drop(%) of SimCLR caused by basic attacks and our methods.", "description": "This table presents the performance comparison of different attacks against the SimCLR algorithm on CIFAR-10 and CIFAR-100 datasets. It shows the percentage drop in accuracy achieved by different attacks, including the basic UE and AP attacks and the proposed AUE and AAP attacks.  The negative values indicate a decrease in accuracy, representing the success of the attacks in making the models less accurate.  The table highlights the improved performance of the proposed AUE and AAP attacks compared to the baseline methods.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_6_1.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the results of various availability attacks on CIFAR-10 and CIFAR-100 datasets, evaluating their effectiveness against both supervised learning (SL) and contrastive learning (CL) algorithms.  The lower the accuracy percentage, the better the performance of the attack in rendering the model unusable. It compares several attack methods, including the authors' proposed AUE and AAP, against baselines.  It shows the worst-case unlearnability across different algorithms for each attack, highlighting the effectiveness of the methods in achieving both supervised and contrastive unlearnability simultaneously.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_7_1.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of different availability attacks (None, AP, SEP, CP, TUE, TP, AAP, AUE) against supervised learning (SL) and contrastive learning algorithms (SimCLR, MoCo, BYOL, SimSiam) on CIFAR-10 and CIFAR-100 datasets. The 'Worst' column indicates the worst performance across all algorithms for each attack. Lower values in each column indicate better unlearnability, meaning that the attack is more effective at making the model unusable. The table highlights the superior performance of the proposed AUE and AAP attacks.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_7_2.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of various availability attacks on CIFAR-10 and CIFAR-100 datasets.  It shows the accuracy achieved by supervised learning (SL) and four contrastive learning algorithms (SimCLR, MoCo, BYOL, SimSiam) after training on data poisoned by different attacks (None, AP, SEP, CP, TUE, TP, AAP, AUE).  The lower the accuracy, the better the attack's performance in rendering the data unusable for training.  The \"Worst\" column shows the worst-case accuracy across all five learning algorithms for each attack.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_8_1.jpg", "caption": "Table 7: SimCLR accuracy(%) of attacks generated with decoupled strength parameters on CIFAR-10. For example, 0-0-s means that ResizedCrop strength is 0, ColorJitter strength is 0, and Grayscale strength is s.", "description": "This table shows the SimCLR accuracy (%) resulting from attacks generated with different combinations of ResizedCrop, ColorJitter, and Grayscale augmentation strength. Each combination is represented by a three-number code (e.g., 0-0-s, where 0 indicates no augmentation and s indicates full augmentation strength). The table helps analyze the individual impact of each augmentation type on the effectiveness of the AUE and AAP attacks.", "section": "5.6 Ablation Study of Decoupling Augmentations"}, {"figure_path": "FbUSCraXEB/tables/tables_15_1.jpg", "caption": "Table 8: Details of supervised and contrastive evaluations.", "description": "This table presents the hyperparameters used for training the supervised and contrastive learning models in the experiments.  It shows the batch size, number of epochs, loss function, optimizer, learning rate, weight decay, momentum, scheduler, warmup period, and temperature (for contrastive learning models).  These settings are crucial for reproducibility and understanding the experimental setup.  The table provides the details of different settings used for supervised learning and contrastive learning algorithms.", "section": "C.5 Evaluation Algorithms"}, {"figure_path": "FbUSCraXEB/tables/tables_16_1.jpg", "caption": "Table 9: Alignment and uniformity gaps of AUE with different strengths.", "description": "This table shows the impact of varying augmentation strength (s) on the performance of the Augmented Unlearnable Examples (AUE) attack.  It demonstrates how increasing the strength affects the alignment gap (AG), uniformity gap (UG), and the resulting SimCLR accuracy.  Higher gaps generally correlate with lower accuracy, indicating a more successful attack.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_17_1.jpg", "caption": "Table 10: Targeted and untargeted AP and AAP attacks on CIFAR-10.", "description": "This table presents the performance of both targeted and untargeted adversarial poisoning (AP) and augmented adversarial poisoning (AAP) attacks on the CIFAR-10 dataset.  It shows the accuracy drop (%) achieved by these attacks against various algorithms, including supervised learning (SL), SimCLR, MoCo, BYOL, and SimSiam. The \"Worst\" column indicates the worst-case unlearnability across all the algorithms considered, providing a comprehensive evaluation of the attacks' effectiveness.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_17_2.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of different availability attacks against supervised learning (SL) and contrastive learning (CL) algorithms on CIFAR-10 and CIFAR-100 datasets.  The attacks are compared using the worst-case unlearnability metric, which is calculated as the maximum of the accuracy of supervised and contrastive algorithms. Lower values indicate a more effective attack that leads to lower accuracy of the trained models, thus higher unlearnability. The table shows the effectiveness of various attacks including AP, SEP, CP, TUE, TP, AUE and AAP.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_17_3.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of different attacks on CIFAR-10 and CIFAR-100 datasets.  The attacks are evaluated using two metrics:  SL (Supervised Learning) accuracy and SimCLR (a Contrastive Learning method) accuracy. Lower values indicate better unlearnability, meaning the attacks are more successful in preventing the model from learning effectively. The table allows for a comparison of the effectiveness of various attack methods against both supervised and contrastive learning approaches.", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_17_4.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of different availability attacks against supervised learning (SL) and contrastive learning (SimCLR, MoCo, BYOL, SimSiam) algorithms on CIFAR-10 and CIFAR-100 datasets.  The \"None\" row indicates the accuracy of clean data.  Lower values indicate better attack performance in terms of worst-case unlearnability (meaning the model is less usable). The table shows that the proposed AUE and AAP attacks achieve the best performance compared to other methods (AP, SEP, CP, TUE, TP).", "section": "5.2 Attack Performance"}, {"figure_path": "FbUSCraXEB/tables/tables_18_1.jpg", "caption": "Table 3: Attack Performance (%) on CIFAR-10 and CIFAR-100. The lower the value, the better the unlearnability.", "description": "This table presents the performance of different availability attacks (including the proposed AUE and AAP attacks) against supervised learning (SL) and contrastive learning (CL) algorithms on CIFAR-10 and CIFAR-100 datasets.  The lower the percentage, the better the attack's ability to render the model unusable (i.e., achieve higher unlearnability). The table compares the proposed methods with several existing attacks.  It is a key result illustrating the effectiveness of AUE and AAP in achieving state-of-the-art worst-case unlearnability.", "section": "5.2 Attack Performance"}]