[{"figure_path": "LUIXdWn6Z5/figures/figures_1_1.jpg", "caption": "Figure 1: Relations of control problems.", "description": "This figure summarizes the relationships between several control problems discussed in the paper.  It shows the equivalence between Control as Inference (CaI) with KL divergence and MaxEnt control.  It illustrates how CaI with R\u00e9nyi divergence (RCaI) extends CaI and connects to LP regularized risk-sensitive control. As the risk-sensitivity parameter (\u03b7) approaches 0, RCaI converges to MaxEnt control.  As \u03b7 approaches -1, the policy converges.  A parallel risk-sensitive generalization using R\u00e9nyi entropy regularization is also shown, demonstrating the same structure as the LP regularized approach.", "section": "Related work"}, {"figure_path": "LUIXdWn6Z5/figures/figures_2_1.jpg", "caption": "Figure 2: Graphical model for CaI.", "description": "This figure shows a graphical model representation of Control as Inference (CaI).  It illustrates the relationships between the states (x), control inputs (u), and optimality variables (O) over a time horizon T.  Each time step t has a state variable xt, a control input ut, and an optimality variable Ot. The optimality variable Ot indicates whether (xt, ut) is optimal or not.  The arrows represent the conditional dependencies: the next state xt+1 depends on the current state xt and the control input ut; and the optimality variable Ot depends on the current state xt and control input ut.", "section": "2 Brief introduction to control as inference"}, {"figure_path": "LUIXdWn6Z5/figures/figures_8_1.jpg", "caption": "Figure 3: Average episode cost for RSAC with some \u03b7 and standard SAC.", "description": "This figure shows the average episode cost for the risk-sensitive soft actor-critic (RSAC) algorithm with different values of the risk-sensitivity parameter \u03b7, compared to the standard soft actor-critic (SAC) algorithm.  The experiment was conducted using the Pendulum-v1 environment from OpenAI Gym. The results demonstrate the impact of the risk-sensitivity parameter on the average episode cost and highlight the robustness of RSAC against perturbations in the environment (changes in pendulum length).", "section": "5 Experiment"}, {"figure_path": "LUIXdWn6Z5/figures/figures_9_1.jpg", "caption": "Figure 4: Empirical distributions of the costs for different risk-sensitivity parameters \u03b7.", "description": "This figure shows the empirical distributions of episode costs for different risk-sensitivity parameters (\u03b7) in the Pendulum-v1 environment.  Three subplots represent different pendulum lengths (l): the original length (l=1.0) used during training, and perturbed lengths (l=1.25 and l=1.5). Each subplot displays distributions for various \u03b7 values (including \u03b7=0 for standard SAC), illustrating the impact of risk sensitivity on cost distribution under system perturbations. The distributions are obtained from 20 independent training runs, each with 100 sampling paths for cost calculation.", "section": "5 Experiment"}, {"figure_path": "LUIXdWn6Z5/figures/figures_26_1.jpg", "caption": "Figure 5: Training process of RSAC (with different \u03b7) and SAC in terms of average episode cost.", "description": "This figure shows the training curves for the risk-sensitive soft actor-critic (RSAC) algorithm with different values of the risk-sensitivity parameter \u03b7, along with a standard soft actor-critic (SAC) algorithm. The x-axis represents the number of learning steps, and the y-axis represents the average episode cost. The shaded regions represent the standard deviation of the results.  The plot demonstrates how the choice of risk-sensitivity affects the learning process and the final performance of the algorithm.", "section": "5 Experiment"}]