[{"figure_path": "yWSxjlFsmX/figures/figures_4_1.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three different variants of the Decision Mamba (DeMa) model used in trajectory optimization. The left side illustrates the RNN-like and Transformer-like versions, highlighting the differences in their input processing and data flow. The right side details the two residual structures (pre and post up-projection) that can be incorporated into either DeMa architecture.  The figure also specifies the input data structure variations (B3LD and BL3D) for the different DeMa versions.", "section": "4 The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_5_1.jpg", "caption": "Figure 2: The impact of sequence length on single-step forward computation time, single-step training time, and GPU memory usage. The sequence length of RNN-like DeMa is 1000.", "description": "This figure shows the impact of sequence length on the computational cost of different models (RNN-like DeMa, Transformer-like DeMa, and DT).  It displays three subplots: forward computation time, training time, and GPU memory usage.  The x-axis in each subplot represents sequence length, while the y-axis represents the corresponding metric (time in milliseconds or memory usage in MB). The results reveal that Transformer-like DeMa is faster and more memory-efficient for short sequence lengths, but the RNN-like DeMa becomes relatively more efficient only when processing exceptionally long sequences. This highlights the trade-off between performance and efficiency depending on the sequence length used.", "section": "4.1 Input Data Structures"}, {"figure_path": "yWSxjlFsmX/figures/figures_5_2.jpg", "caption": "Figure 2: The impact of sequence length on single-step forward computation time, single-step training time, and GPU memory usage. The sequence length of RNN-like DeMa is 1000.", "description": "This figure analyzes the effect of sequence length on the computational cost and performance of different models: RNN-like DeMa, Transformer-like DeMa, and DT.  It shows three plots illustrating the forward computation time (ms), training time (ms), and GPU memory usage (MB) for varying sequence lengths.  The results highlight that the Transformer-like DeMa outperforms the RNN-like DeMa in terms of speed and memory efficiency for shorter sequence lengths, while the RNN-like DeMa becomes more competitive with extremely long sequences.", "section": "4.1 Input Data Structures"}, {"figure_path": "yWSxjlFsmX/figures/figures_6_1.jpg", "caption": "Figure 7: Hidden attention scores of DeMa from the 300th to the 600th timestep, trained on the Walker2d-medium dataset.", "description": "This figure visualizes the hidden attention scores of the Decision Mamba (DeMa) model over a sequence of 300 to 600 timesteps.  The data used to train this model was from the Walker2d-medium dataset.  The visualization is a 3D representation, showing how the attention mechanism focuses on different parts of the input sequence at each decision step. The x-axis represents the decision timestep, the y-axis represents the input sequence (past K tokens), and the z-axis represents the attention scores.  The colors in the heatmap represent the magnitude of the attention scores, with warmer colors indicating stronger attention.", "section": "4 The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_7_1.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three variants of the Decision Mamba (DeMa) model used in trajectory optimization. The left side shows the architectural differences between the RNN-like DeMa and the Transformer-like DeMa, highlighting the use of hidden state inputs in the RNN-like version.  The right side illustrates how both types of DeMa can incorporate post and pre up-projection residual blocks.  The figure clarifies the design choices made in adapting Mamba for trajectory optimization, emphasizing the selection between recurrent and transformer-like approaches and the use of different residual structures.", "section": "The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_20_1.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three different variants of the Decision Mamba (DeMa) model used for trajectory optimization.  The left side illustrates the RNN-like and Transformer-like architectures of DeMa, highlighting differences in their input processing (hidden state vs. full sequence). The right side shows that both architectures can incorporate post-projection and pre-projection residual blocks for improved performance.", "section": "4 The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_21_1.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three different designs of Decision Mamba (DeMa) used in trajectory optimization.  The left side illustrates the RNN-like DeMa (I) which uses hidden state inputs at every step, and two variations of the Transformer-like DeMa (II and III) which differ in how input data is concatenated.  The right side shows that both RNN-like and Transformer-like DeMas can incorporate post and pre up-projection residual blocks. The figure visually represents the architectural differences in DeMa implementations.", "section": "The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_21_2.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure illustrates three different variants of the Decision Mamba (DeMa) model used in trajectory optimization.  The left side shows the RNN-like DeMa and the Transformer-like DeMa, highlighting the difference in their input data handling (B3LD vs. BL3D). The RNN-like version requires hidden state inputs at each step, while the Transformer-like version doesn't.  The right side shows how both types of DeMa can use two different residual structures (pre- and post-projection) within their architecture.", "section": "The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_22_1.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three different variants of the Decision Mamba (DeMa) model used in trajectory optimization.  The left side illustrates the architectural differences between the RNN-like and Transformer-like versions of DeMa, highlighting the input requirements and the use of recurrent connections in the RNN-like version. The right side focuses on the residual structures incorporated within both RNN-like and Transformer-like DeMa, comparing post and pre up-projection residual blocks.  These design choices affect the efficiency and effectiveness of the model for sequential decision-making tasks.", "section": "The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_22_2.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure shows three different variants of the Decision Mamba (DeMa) model used in trajectory optimization.  The left side illustrates the RNN-like and Transformer-like versions of DeMa, highlighting the difference in how they process sequences (recursive vs. parallel). The right side shows the two residual structures that can be incorporated into either DeMa variant.", "section": "The Analysis of DeMa"}, {"figure_path": "yWSxjlFsmX/figures/figures_22_3.jpg", "caption": "Figure 1: Variant design of the DeMa in trajectory optimization. In the left portion, (I) represents the RNN-like DeMa (B3LD), which requires hidden state inputs at each decision step; (II) indicates the transformer-like DeMa (B3LD); and (III) refers to the transformer-like DeMa (BL3D). The right portion illustrates that both types of these DeMa can incorporate two distinct residual structures, i.e. the post up-projection residual block and the pre up-projection residual block.", "description": "This figure illustrates three different variants of the Decision Mamba (DeMa) model used in trajectory optimization.  The left side shows the architectural differences between the RNN-like and Transformer-like versions of DeMa, highlighting the use of hidden state inputs in the RNN-like model. The right side shows that both RNN-like and Transformer-like DeMa can use either a \"post up-projection\" or \"pre up-projection\" residual block structure.  The different versions reflect different approaches to handling sequence information and residual connections in the model.", "section": "4 The Analysis of DeMa"}]