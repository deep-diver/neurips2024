[{"figure_path": "X1QeUYBXke/figures/figures_1_1.jpg", "caption": "Figure 1: Gradient-guided diffusion model for generative optimization, with or without adaptive fine-tuning. A pre-trained diffusion model is guided with an additional gradient signal from an external objectives function towards generating near-optimal solutions.", "description": "This figure illustrates the architecture of a gradient-guided diffusion model for generative optimization.  It shows how a pre-trained diffusion model is adapted to optimize a user-specified objective function by incorporating gradient guidance. The model can optionally include an adaptive fine-tuning step, where the pre-trained score function is updated using newly generated samples. The gradient guidance is computed based on a forward prediction loss that leverages information from the pre-trained score functions, ensuring that the generated samples maintain the latent structure learned from pre-training data.  The figure highlights the key components: pre-trained diffusion model, gradient guidance computation, guided diffusion process, optional weighted fine-tuning, and the generation of adapted samples.", "section": "Scope and Contribution"}, {"figure_path": "X1QeUYBXke/figures/figures_4_1.jpg", "caption": "Figure 2: Directly adding the gradient of the objective function to the backward process sabotages the subspace structure. Left: Directly adding gradients that point out of the data subspace causes samples to leave the subspace. Right: Numerical experiments show that naive gradients lead to substantially larger off-subspace error compared to our gradient guidance Gloss (Definition 1); see Section 7 for experiment details.", "description": "This figure shows that simply applying the gradient of the objective function to the backward process (naive gradient guidance) fails to maintain the data's latent structure, which is essential for generating high-quality samples.  The left panel illustrates how naive gradient guidance can pull samples away from the data's low-dimensional subspace, while the right panel provides numerical evidence demonstrating that a modified approach (Gloss) significantly reduces the error incurred outside of this subspace.", "section": "4. Structural Data Distribution with Subspace"}, {"figure_path": "X1QeUYBXke/figures/figures_6_1.jpg", "caption": "Figure 3: Computing Gloss.", "description": "This figure illustrates the computation of the gradient guidance Gloss.  It shows the process of taking a noisy sample x\u209c, using a pre-trained score network s\u03b8 to estimate E[x\u2080|x\u209c], combining this with the gradient g and other parameters via a weighted square loss to compute the gradient w.r.t. x\u209c. This gradient is then used as the guidance in the generative optimization process.", "section": "4.4 Estimation and Implementation of Gloss"}, {"figure_path": "X1QeUYBXke/figures/figures_8_1.jpg", "caption": "Figure 8: Comparison between two types of gradient guidance G and Gloss. We plot the off/on support ratio of the generated samples, denoted by r_off. The objective function is f_1(x), with \u03b8 having an off/on-support ratio of 9.", "description": "This figure compares two gradient guidance methods, G and Gloss, in terms of their ability to preserve the subspace structure of the generated samples. The off/on-support ratio (r_off) is used to measure the proximity of generated samples to the data subspace.  The results show that Gloss significantly outperforms G in maintaining the subspace structure, particularly as the number of iterations increases.  Subplots (a) and (b) demonstrate this for Algorithm 1 (without adaptive score fine-tuning) and Algorithm 2 (with adaptive fine-tuning), respectively.  Subplots (c) and (d) provide zoomed-in views of specific iterations to highlight the differences.", "section": "7.1 Simulation"}, {"figure_path": "X1QeUYBXke/figures/figures_9_1.jpg", "caption": "Figure 5: Convergence of Algorithms 1 and 2. (a) and (b) are under different \u03b8 for the objective function. (d) visualizes the distribution of the generated samples of Alg. 2 (red) and Alg. 1 (blue) across the iterations.", "description": "This figure presents the convergence results of Algorithm 1 and Algorithm 2. Panels (a) and (b) demonstrate the convergence behavior of Algorithm 1 under different objective functions, showing that it converges to a sub-optimal value. Panel (c) shows that Algorithm 2 successfully converges to the maximal value of the objective function, indicating its ability to achieve global optima. Finally, panel (d) visualizes the distribution of generated samples for both algorithms, highlighting the differences in their sampling characteristics. Algorithm 2's samples move beyond the initial data distribution, suggesting its capacity to generate novel samples.", "section": "7.1 Simulation"}, {"figure_path": "X1QeUYBXke/figures/figures_9_2.jpg", "caption": "Figure 6: Reward increase and effect on images across iterations. Left: Reward increases and converges across iterations. Larger guidance strength \u03b3 (smaller regularizer strength) results in higher convergent reward value. Right: Images become more abstract, shifting from photo-realistic with detailed backgrounds to more virtual, stylized ones.", "description": "The left panel shows how the reward increases and converges as the number of iterations increases, with larger guidance strength leading to higher rewards. The right panel shows generated images across iterations for different guidance strengths.  The generated images transition from photorealistic to more abstract and stylized as the reward (and guidance strength) increases.", "section": "7.2 Image Generation"}, {"figure_path": "X1QeUYBXke/figures/figures_18_1.jpg", "caption": "Figure 7: Plot of f(t), a(t), h(t) for t\u2208 [0, 10] when \u2211 = I.", "description": "This figure shows the plot of the functions f(t), a(t), and h(t) for t ranging from 0 to 10, given that the covariance matrix \u2211 is equal to the identity matrix I.  These functions are related to the forward diffusion process in the paper.  Specifically:\n\n* **f(t)** Represents the noise scheduling function used in the forward process (Ornstein-Uhlenbeck process) to progressively add noise to the data.\n* **a(t)** Represents the scaling factor that determines how much of the original signal remains at time t in the forward process. \n* **h(t)** Represents the variance of the noise added at time t in the forward process.", "section": "D Additional Materials for Section 4"}, {"figure_path": "X1QeUYBXke/figures/figures_26_1.jpg", "caption": "Figure 8: Comparison between two types of gradient guidance G and Gloss. We plot the off/on support ratio of the generated samples, denoted by r<sub>off</sub>. The objective function is f<sub>1</sub>(x), with \u03b8 having an off/on-support ratio of 9.", "description": "This figure compares the performance of two gradient guidance methods, G and Gloss, in preserving the subspace structure learned from a pre-trained model.  The off/on-support ratio (r<sub>off</sub>) is used to measure how well the generated samples adhere to the subspace.  The left two panels show that Gloss significantly outperforms G in this respect, maintaining samples much closer to the subspace over many iterations, for both Algorithm 1 and Algorithm 2. The right two panels provide 3D visualizations of the sample distributions, clearly showing that Gloss's samples remain concentrated in the subspace compared to G's samples which stray significantly outside of it.", "section": "7.1 Simulation"}, {"figure_path": "X1QeUYBXke/figures/figures_26_2.jpg", "caption": "Figure 9: Convergence of Algorithm 1 under different objectives. Objectives are f1(x) for (a) and (b), and f2(x) for (c) and (d). Parameters \u03b8 and b are specified as (a) \u03b8 = A\u03b2* with \u03b2* being sampled from the unit ball in Rd; (b) the off/on-support ratio of \u03b8 being 9 (same as Figure 8); (c) and (d) choosing b as a homogeneous vector or randomly from a Gaussian distribution. All the experiments adopt the gradient guidance Gloss.", "description": "This figure displays the convergence results of Algorithm 1 under various objective functions and parameter settings.  Panels (a) and (b) show results for the quadratic objective function f1(x), with different choices for the parameter \u03b8. Panels (c) and (d) show results for the linear objective function f2(x), with different choices for the parameter b.  Across all experiments, the gradient guidance Gloss is used.", "section": "7.1 Simulation"}, {"figure_path": "X1QeUYBXke/figures/figures_27_1.jpg", "caption": "Figure 10: Convergence of Algorithm 2. Panel (a) plots the objective values achieved by Algorithm 2 as a function of iterations. Here 0 is chosen the same as in Figure 9 (b) with off/on-support ratio 0 = 9. Panel (b) visualizes the distribution of the generated samples of Algorithm 2 (red) across the iterations. For comparison, we also visualize the distribution of generated samples of Algorithm 1 (blue).", "description": "This figure shows the convergence results and the generated sample distributions of Algorithm 2 (adaptive fine-tuning) and Algorithm 1 (no adaptive fine-tuning). Panel (a) shows that Algorithm 2 successfully converges to the global optimal objective value, whereas Algorithm 1 only converges to a sub-optimal value due to regularization imposed by the pre-trained diffusion model. Panel (b) visualizes the sample distributions. As Algorithm 2 iterates, the samples spread out beyond the pre-trained data distribution, while the samples generated by Algorithm 1 stay concentrated around the data distribution.", "section": "7.1 Simulation"}, {"figure_path": "X1QeUYBXke/figures/figures_27_2.jpg", "caption": "Figure 8: Comparison between two types of gradient guidance G and Gloss. We plot the off/on support ratio of the generated samples, denoted by roff = ||x||off/||x||. The objective function is f1(x), with \u03b8 having an off/on-support ratio of 9.", "description": "This figure compares the performance of two gradient guidance methods, G (naive gradient) and Gloss (proposed gradient guidance), in terms of maintaining the latent structure of generated samples. The left panel shows the reward (objective function value) over training iterations for both methods, demonstrating Gloss's superior convergence to the optimal reward. The right panel shows the off-support ratio (a measure of how much the generated samples deviate from the subspace) versus the reward.  It illustrates that Gloss significantly outperforms G in preserving the subspace structure throughout the optimization process. The pre-trained model's baseline off-support ratio is also shown for reference.", "section": "7.1 Simulation"}]