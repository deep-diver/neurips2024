[{"figure_path": "fx6aSBMu6z/figures/figures_3_1.jpg", "caption": "Figure 1: The architecture of our proposed HC-GAE model.", "description": "This figure illustrates the overall architecture of the Hierarchical Cluster-based Graph Auto-Encoder (HC-GAE) model. The HC-GAE model consists of two main stages: encoding and decoding.  During the encoding stage, an input graph is compressed by the encoder into a coarsened graph which represents the graph-level representation of the input. This coarsened graph is then processed by the decoder to reconstruct the original input graph, thus producing a node-level representation. The encoding stage involves a series of compressing operations performed layer-wise, and the decoding stage involves an expansion procedure. The model is designed to learn effective structural characteristics for graph data analysis, using both graph-level and node-level representations.", "section": "3 The Methodology"}, {"figure_path": "fx6aSBMu6z/figures/figures_4_1.jpg", "caption": "Figure 2: The computational architecture for our proposed layer in the GNN encoder.", "description": "This figure illustrates the two main steps in the encoding process of the proposed HC-GAE model: hard node assignment and coarsening. First, the hard assignment step divides the input graph into several subgraphs. Then, the coarsening step compresses each subgraph into a single node, resulting in a smaller coarsened graph. This process is repeated layer-wise in the encoder to generate a sequence of progressively smaller graphs, extracting hierarchical structural features in the process.", "section": "3.1 The GNN Encoder associated with the Hard Node Assignment"}, {"figure_path": "fx6aSBMu6z/figures/figures_5_1.jpg", "caption": "Figure 3: The illustration of our proposed layer in the GNN decoder.", "description": "This figure illustrates a single layer within the decoder of the proposed HC-GAE model.  The decoder takes a retrieved graph (left) as input and aims to reconstruct the original graph structure by probabilistically expanding each coarsened node. The solid black lines represent the edges in the reconstructed graph, while the dotted pink and light blue lines represent the probabilistic expansion of nodes from the retrieved graph into the reconstructed graph. The process demonstrates the soft node assignment used in the HC-GAE decoder to probabilistically reconstruct the original graph structure.", "section": "3.2 The GNN Decoder associated with the Soft Node Assignment"}, {"figure_path": "fx6aSBMu6z/figures/figures_8_1.jpg", "caption": "Figure 4: The ablation experiments on graph classification task.", "description": "This figure shows the ablation study comparing the performance of the proposed HC-GAE model against a variant, HC-GAE-SE, which uses soft node assignment instead of hard node assignment in the encoder. The results across five graph classification datasets (IMDB-B, IMDB-M, PROTEINS, COLLAB, MUTAG) demonstrate that HC-GAE significantly outperforms HC-GAE-SE, highlighting the importance of hard node assignment for effective graph representation learning.", "section": "4 Experiments"}]