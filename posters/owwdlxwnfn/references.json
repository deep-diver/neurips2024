{"references": [{"fullname_first_author": "Shinji Nishimoto", "paper_title": "Reconstructing visual experiences from brain activity evoked by natural movies", "publication_date": "2011-00-00", "reason": "This paper is foundational for using brain activity to reconstruct visual experiences, a core methodology of the current paper."}, {"fullname_first_author": "Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk", "paper_title": "Reconstructing perceived faces from brain activations with deep adversarial neural decoding", "publication_date": "2017-00-00", "reason": "This paper demonstrates the effectiveness of adversarial neural decoding for reconstructing complex visual stimuli, which is highly relevant to the current paper's methodology."}, {"fullname_first_author": "Katja Seeliger", "paper_title": "Generative adversarial networks for reconstructing natural images from brain activity", "publication_date": "2018-00-00", "reason": "This paper directly addresses using GANs for reconstructing images from brain data, a crucial technique used and improved upon in the current research."}, {"fullname_first_author": "Guohua Shen", "paper_title": "End-to-end deep image reconstruction from human brain activity", "publication_date": "2019-00-00", "reason": "This paper advanced end-to-end image reconstruction from brain activity, providing a direct comparison point for the current paper's novel approach."}, {"fullname_first_author": "Lynn Le", "paper_title": "Brain2pix: Fully convolutional naturalistic video frame reconstruction from brain activity", "publication_date": "2022-00-00", "reason": "This paper, also by the current paper's authors, provides a direct precursor study with similar goals, enabling a clear demonstration of progress."}]}