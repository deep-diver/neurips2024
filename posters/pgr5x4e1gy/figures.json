[{"figure_path": "pGR5X4e1gy/figures/figures_1_1.jpg", "caption": "Figure 1: Top: adjacency matrix of a simple graph. Bottom: approximating 5 community ICG.", "description": "This figure shows a visual comparison between the adjacency matrix of a simple graph and its approximation using an Intersecting Community Graph (ICG) with 5 communities. The top panel displays the adjacency matrix of the original graph, highlighting its inherent structure with dense and sparse regions. The bottom panel illustrates the ICG approximation, capturing the overall statistics of edge densities and community structure. The ICG significantly simplifies the original graph by representing it as a combination of overlapping communities (cliques), resulting in a lower-rank representation that requires less memory and computation to process.", "section": "Challenges and techniques"}, {"figure_path": "pGR5X4e1gy/figures/figures_7_1.jpg", "caption": "Figure 2: Runtime of K-ICGu-NN (for K=100) as a function of GCN forward pass duration on graphs G ~ ER(n, p(n) = 0.5).", "description": "This figure empirically validates the theoretical advantage of using ICGs over standard GNNs (GCN in this case) by comparing their runtimes. The plot shows a strong square root relationship between the runtime of ICGu-NN and GCN, confirming that ICGu-NN's runtime complexity is indeed O(N) while GCN's is O(E), where N is the number of nodes and E is the number of edges.  The square root relationship arises from the fact that the denser the graph, the closer E is to N\u00b2, making the difference between O(N) and O(E) less apparent in extremely dense graphs, but still holding true.", "section": "6.1 How does the runtime compare to standard GNNs?"}, {"figure_path": "pGR5X4e1gy/figures/figures_7_2.jpg", "caption": "Figure 3: ROC AUC of ICG-NN and an MLP as a function of the % nodes removed from the graph.", "description": "This figure compares the performance of ICG-NN and a Multilayer Perceptron (MLP) on the tolokers dataset when different percentages of nodes are removed from the graph.  The y-axis shows the ROC AUC score, indicating the model's performance in classifying nodes. The x-axis displays the ratio of nodes removed from the graph. The shaded area around the ICG-NN line represents the standard deviation across multiple trials.  The plot shows a relatively small degradation in performance for ICG-NN as more nodes are removed, suggesting robustness to node removal.", "section": "Node classification using Subgraph SGD"}, {"figure_path": "pGR5X4e1gy/figures/figures_27_1.jpg", "caption": "Figure 4: Test ROC AUC of tolokers (left) and test accuracy of squirrel (right) as a function of the number of communities.", "description": "This figure shows the performance of two models, ICGu-NN and ICG-NN, on the tolokers and squirrel datasets for node classification. The x-axis represents the number of communities used in the model, and the y-axis represents the ROC AUC (for tolokers) and accuracy (for squirrel).  The plot demonstrates how the model performance varies with the number of communities used. Error bars are included to show the variability of the results.", "section": "F.4 Ablation study over the number of communities"}, {"figure_path": "pGR5X4e1gy/figures/figures_28_1.jpg", "caption": "Figure 1: Top: adjacency matrix of a simple graph. Bottom: approximating 5 community ICG.", "description": "This figure shows a visual comparison of a simple graph's adjacency matrix and its approximation using an Intersecting Community Graph (ICG). The top panel displays the adjacency matrix of a simple graph, illustrating the presence of dense and sparse regions. The bottom panel shows the ICG approximation, demonstrating how intersecting communities (cliques) can represent the graph's underlying structure effectively. The approximation captures the edge density statistics while simplifying the graph's fine-grained granularity.", "section": "Challenges and techniques"}, {"figure_path": "pGR5X4e1gy/figures/figures_29_1.jpg", "caption": "Figure 6: Empirical runtimes: K-ICG approximation process as a function of GCN forward pass duration on the dense (left) and sparse (right) Erd\u0151s-R\u00e9nyi distribution ER(n, p(n) = 0.5) and ER(n,p(n) = 50) for K=10, 100.", "description": "This figure shows the empirical runtime comparison between the ICG approximation process and GCN forward pass on both dense and sparse graphs.  It demonstrates a strong linear relationship between the runtimes for both types of graphs.  This highlights the computational advantage of using ICGs over standard GCN methods.", "section": "Run-time analysis"}, {"figure_path": "pGR5X4e1gy/figures/figures_29_2.jpg", "caption": "Figure 2: Runtime of K-ICGu-NN (for K=100) as a function of GCN forward pass duration on graphs G ~ ER(n, p(n) = 0.5).", "description": "This figure empirically validates the theoretical advantage of ICGu-NN over GCN by comparing their runtimes on Erd\u0151s-R\u00e9nyi graphs. The plot shows a strong square-root relationship between the runtime of ICGu-NN and that of GCN, aligning with the theoretical complexities O(N) and O(E), respectively. The result highlights that ICGu-NN is more efficient for large graphs, demonstrating a clear advantage of using ICGs for graph learning.", "section": "6.1 How does the runtime compare to standard GNNs?"}, {"figure_path": "pGR5X4e1gy/figures/figures_30_1.jpg", "caption": "Figure 8: Memory allocated for K-ICG approximation (K=10,100) as a function of the memory allocated for GCN on graphs G ~ ER(n, p(n) = 0.5).", "description": "This figure shows the memory usage comparison between the proposed ICG approximation method and the standard GCN method. The x-axis represents the memory used by GCN, and the y-axis represents the memory used by the ICG approximation for K=10 and K=100. The figure demonstrates a linear relationship between the memory used by both methods, highlighting the memory efficiency of the ICG approach, especially for larger values of K.", "section": "F.9 Memory allocation analysis"}]