{"references": [{"fullname_first_author": "Danfei Xu", "paper_title": "Scene graph generation by iterative message passing", "publication_date": "2017-00-00", "reason": "This paper is foundational for scene graph generation (SGG), introducing the iterative message passing framework and setting the stage for subsequent advancements."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is a key vision-language model used as a foundational element for the method proposed in the target paper."}, {"fullname_first_author": "Junnan Li", "paper_title": "BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-00-00", "reason": "BLIP, another key vision-language model, is used in the target paper and is directly relevant to their approach."}, {"fullname_first_author": "Tao He", "paper_title": "Towards open-vocabulary scene graph generation with prompt-based finetuning", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it directly addresses open-vocabulary scene graph generation (OVSGG), a central topic of the target paper."}, {"fullname_first_author": "Qifan Yu", "paper_title": "Visually-prompted language model for fine-grained scene graph generation in an open world", "publication_date": "2023-00-00", "reason": "This paper is a state-of-the-art work in OVSGG, providing a strong benchmark against which the proposed method is compared."}]}