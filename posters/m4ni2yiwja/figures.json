[{"figure_path": "m4NI2yIwJA/figures/figures_6_1.jpg", "caption": "Figure 1: Comparison of Dirichlet energies between pre-trained parent GNNs and the corresponding child from PMC.", "description": "This figure shows the Dirichlet energy of pre-trained parent GNNs (A and B) and the child GNN produced by the Parent Message Coordination (PMC) scheme.  Each point represents a pair of parent GNNs trained on different data splits. The x-axis represents the Dirichlet energy of parent GNN A, the y-axis represents the Dirichlet energy of parent GNN B, and the color represents the Dirichlet energy of the child GNN produced by PMC. The figure demonstrates the over-smoothing effect of PMC, where the child GNN's Dirichlet energy is lower than those of the parents, indicating a loss of node feature variance.", "section": "5.3 Child Message Calibration Scheme"}, {"figure_path": "m4NI2yIwJA/figures/figures_8_1.jpg", "caption": "Figure 2: The t-SNE visualisations of various methods on a subset comprising the first 10 classes of ogbn-arxiv. Additional visualisations for the remaining classes are available in Appendix E.", "description": "This figure compares the feature space visualizations generated by different methods for node classification on the ogbn-arxiv dataset.  t-SNE is used to reduce the dimensionality of the feature vectors to 2D for visualization.  Each point represents a node, and its color represents its class label. The figure shows that the proposed DuMCC method, with and without child message calibration (CMC), achieves better separation of classes compared to other baselines, such as Knowledge Amalgamation (KA), Vanilla Parameter Interpolation (VPI), and Vanilla Alignment Prior to Interpolation (VAPI).", "section": "5.3 Child Message Calibration Scheme"}, {"figure_path": "m4NI2yIwJA/figures/figures_8_2.jpg", "caption": "Figure 3: Visualisations of feature space structures, depicted by the distances between the red point and all other points.", "description": "This figure shows t-SNE visualizations of feature space structures for different methods (KA, VPI, VAPI, and the proposed method) on the ModelNet40 dataset.  The color gradient represents the distance from a reference point (red dot) to other points, illustrating how different methods group similar features and the overall structure of the learned feature space.  The visualization helps demonstrate the impact of different approaches on the organization and discriminative power of node features.", "section": "Experiments"}]