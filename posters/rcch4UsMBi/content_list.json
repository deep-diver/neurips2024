[{"type": "text", "text": "Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 We introduce Generalized Instruction Tuning (called GLAN), a general and scal  \n2 able method for instruction tuning of Large Language Models (LLMs). Unlike prior   \n3 work that relies on seed examples or existing datasets to construct instruction-tuning   \n4 data, GLAN exclusively utilizes a pre-curated taxonomy of human knowledge and   \n5 capabilities as input and generates large-scale synthetic instruction data across all   \n6 disciplines. Specifically, inspired by the systematic structure in human education   \n7 system, we build the taxonomy by decomposing human knowledge and capabilities   \n8 to various fields, sub-fields and ultimately, distinct disciplines semi-automatically,   \n9 facilitated by LLMs. Subsequently, we generate a comprehensive list of subjects   \n0 for every discipline and proceed to design a syllabus tailored to each subject, again   \n11 utilizing LLMs. With the fine-grained key concepts detailed in every class session   \n12 of the syllabus, we are able to generate diverse instructions with a broad coverage   \n13 across the entire spectrum of human knowledge and skills. Extensive experiments   \n14 on large language models (e.g., Mistral) demonstrate that GLAN excels in mul  \n15 tiple dimensions from mathematical reasoning, coding, academic exams, logical   \n16 reasoning to general instruction following without using task-specific training data   \n17 of these tasks. In addition, GLAN allows for easy customization and new fields or   \n18 skills can be added by simply incorporating a new node into our taxonomy. ", "page_idx": 0}, {"type": "text", "text": "19 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "20 Large Language Models (LLMs) have enabled unprecedented capabilities to understand and generate   \n21 text like humans. By scaling up model size and data size [17, 13], LLMs are better at predicting   \n22 next tokens and prompting to perform certain tasks with a few demonstrations [2]. However, these   \n23 capabilities do not directly translate to better human instruction following [25]. Instruction tuning   \n24 [34] bridges this gap by fine-tuning LLMs on instructions paired with human-preferred responses.   \n25 Prior work constructs instruction tuning data from seed examples or existing datasets. Initially, natural   \n26 language processing (NLP) datasets described via instructions are used to fine-tune LLMs and the   \n27 resulting LLMs can generalize on unseen (NLP) tasks [34]. However, there are only thousands of   \n28 NLP tasks [33, 19] available, which limits the tuned LLMs to generalize in real-world scenarios [39].   \n29 Self-instruct [32] is a cost-effective method for creating synthetic instruction tuning datasets, which   \n30 starts from a small pool of human-written seed instructions and generates new instructions by few  \n31 shot prompting an LLM (e.g., text-davinci-002) with randomly selected instructions from the   \n32 pool. Unfortunately, the diversity of generated instructions is still an issue, since few-shot prompting   \n33 tends to generate new instructions similar to its demonstrations. In addition, the process of creating   \n34 high-quality seed instructions requires considerable human effort and expertise. Evolve-Instruct [39]   \n35 improves self-instruct by augmenting existing instruction tuning datasets with different rewriting   \n36 operations using LLMs, which is essentially data argumentation. Consequently, the scope of domains   \n37 or tasks that these augmented datasets can cover is limited by the original input datasets. See Figure 1   \n38 for illustrations of these methods described above. There are also studies concentrated on developing   \n39 instruction-tuning datasets tailored to particular domains or tasks. For instance, [20] creates datasets   \n40 targeting mathematical reasoning. In contrast, [3] and [21] focus on coding-related tasks. All of the   \n41 above methods cannot produce instruction datasets that are generally applicable to a wide range of   \n42 domains.   \n43 How to create a general instruction tuning dataset? We draw inspiration from the systematic structure   \n44 in human education system. The structure of human education includes several levels, starting   \n45 from early childhood education up to higher education and beyond [37]. Within each level, a   \n46 student acquires knowledge, skills, and values in a systematic process. The courses a student learns   \nfrom primary school to college cover a broad range of knowledge and skills, which facilitates the   \n48 development of a diverse array of abilities. We believe that the systemic framework of the human   \n49 education system has the potential to help the generation of high-quality and general instruction data,   \n50 which spans a diverse range of disciplinary areas.   \n51 In this paper, we introduce a generalized instruction tuning paradigm GLAN (shorthand for   \n52 Generalized Instruction-Tuning for Large LANguage Models) to generate synthetic instruction   \n53 tuning data almost from scratch. Unlike existing work [39, 21, 20, 24], GLAN exclusively utilizes   \n54 a pre-curated taxonomy of human knowledge and capabilities as input and generates large-scale   \n55 instruction data systematically and automatically across all disciplines. Specifically, inspired by   \n56 the structure of the human education system, the input taxonomy is constructed by decomposing   \n57 human knowledge and capabilities to various fields, sub-fields, and, ultimately, distinct disciplines   \n58 semi-automatically, facilitated by LLMs and human verification. The cost of human verification   \n59 process is low due to the limited number of disciplines in the taxonomy. As shown in Figure 1,   \n60 we then further break down these disciplines into even smaller units. We continue to generate a   \n61 comprehensive list of subjects for every discipline and proceed to design a syllabus tailored to each   \n62 subject, again utilizing LLMs. With the fine-grained key concepts detailed in every class session   \n63 of the syllabus, we can first sample from them and then generate diverse instructions with broad   \n64 coverage across the entire spectrum of human knowledge and skills. The process described above   \n65 mirrors the human educational system, where educators in each discipline craft a series of subjects   \n66 for student learning. Instructors then develop a syllabus for each subject, breaking down the content   \n67 into specific class sessions. These sessions are then further divided into core concepts that students   \n68 must comprehend and internalize. Based on these detailed core concepts outlined in the syllabus,   \n69 teaching materials and exercises are subsequently created, which are our instruction tuning data.   \n70 GLAN is general, scalable and customizable. GLAN is a general method, which is task-agnostic   \n71 and is capable of covering a wide range of domains. GLAN is scalable. Similar to [32, 39], GLAN   \n72 generates instructions using LLMs, which can produce instructions on a massive scale. Moreover, the   \n73 input of GLAN is a taxonomy, which is generated by prompting an LLM and human verification,   \n74 requiring minimal human effort. GLAN allows for easy customization. New fields or skills can be   \n75 added by simply incorporating a new node into our taxonomy. Note that each node of the taxonomy   \n76 can be expanded independently, which means that we only need to apply our method to the newly   \n7 added nodes without re-generating the entire dataset. Extensive experiments on large language   \n78 models (e.g., Mistral) demonstrate that GLAN excels in multiple dimensions from mathematical   \n79 reasoning, coding, academic exams, and logical reasoning to general instruction following without   \n80 using task-specific training data of these tasks. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "image", "img_path": "rcch4UsMBi/tmp/a7441ec0e0fc9ec1cb22bc9bc897dadd66db340977f11656729871aa63a1c2b5.jpg", "img_caption": ["Figure 1: Comparing GLAN with FLAN, Self-Instruct and Evolve-Instruct. The inputs of FLAN, Self-Instrct and Eovlve-Instruct are either seed examples or existing datasets, which limits the scope of domains of instructions that these methods can generate. GLAN takes the taxonomy of human knowledge & capabilities as input to ensure the broad coverage of generated instructions in various domains. This taxonomy is then broken down into smaller pieces and recombined to generate diverse instruction data. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "81 2 GLAN: Generalized Instruction-Tuned Language Models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "82 GLAN aims to create synthetic instruction data covering various domains of human knowledge   \n83 and capabilities on a large scale. As shown in Algorithm 1, we first build a taxonomy of human   \n84 knowledge and capabilities using frontier LLMs (i.e., GPT-4) and human verification. The taxonomy   \n85 naturally breaks down human knowledge and capabilities to fields, sub-fields, and ultimately different   \n86 disciplines (see Section 2.1). The following steps are fully autonomously facilitated by GPT-4 (or   \n87 GPT-3.5). Then for each discipline, we again instruct GPT-4 to further decompose it into a list of   \n88 subjects within this discipline (Section 2.2). Similar to an instructor, GPT-4 continues to design   \n89 a syllabus for each subject, which inherently breaks a subject into various class sessions with key   \n90 concepts students need to master (Section 2.3). With obtained class sessions and key concepts, we   \n9 are ready to construct synthetic instructions. We prompt GPT-4 to generate homework questions   \n92 based on randomly sampled class sessions and key concepts as well as the syllabus (Section 2.4).   \n93 We recursively decompose human knowledge and capabilities into smaller units until atomic-level   \n94 components (i.e., class sessions and key concepts). We expect to randomly combine these class   \n95 sessions and key concepts to ensure the coverage and diversity of synthetic instructions. ", "page_idx": 2}, {"type": "table", "img_path": "rcch4UsMBi/tmp/0fd5c24e802f41a28e5b157ff68579a1df4bbb64feee91eeeedf4d22b7862496.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "96 2.1 Taxonomy of Human Knowledge and Capabilities ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "97 We build a taxonomy of human knowledge and capabilities to guide the generation of synthetic   \n98 instructions. Therefore, its coverage is important. On the other hand, it is also essential to make   \n99 the taxonomy highly extensible, since the preferred capabilities of LLMs may change over time.   \n100 In the first step, we propose to generate the taxonomy by prompting GPT-4 with a set of different   \n101 instructions (e.g., list all fields of human knowledge and capabilities). Then, we do   \n102 human post-editing to ensure its correctness and completeness. Due to the limited number of fields,   \n103 sub-fields, and disciplines in our taxonomy, the cost of human verification is reasonably low. Another   \n104 advantage of human post-editing is that we can easily add new fields or disciplines to the taxonomy   \n105 as needed.   \n106 Our taxonomy currently covers a diverse range of knowledge and capabilities in both academic   \n107 education and vocational training. The top level of the taxonomy contains fields such as Natural   \n108 Sciences, Humanities, or Services (vocational training). These fields branch out to various sub-fields   \n109 and/or disciplines such as Chemistry, Sociology or Retailing. We keep breaking down nodes of the   \n110 taxonomy until disciplines, and we leave the breaking down of disciplines to automatic methods   \n111 described in the following sections. By collecting the leaf nodes of the taxonomy, we obtain a list of   \n112 disciplines $\\mathbb{D}=\\{d_{1},d_{2},\\dots,d_{M}\\}$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "113 2.2 Subject Generator ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "114 As in Algorithm 1, for each discipline $d$ , we aim to extract the list of subjects in it through prompt   \n115 engineering. Specifically, we instruct GPT-4 to act as an education expert of discipline   \n116 $d$ and design a list of subjects a student should learn. The completion of GPT-4   \n117 contains a comprehensive list of subjects and their meta data (e.g., level, introduction and subtopics   \n118 of the subject) in unstructured text format, which can not be directly used in subsequent steps. We   \n119 therefore used another round of prompting to convert the completion to JSONL format:   \n120 Awesome! Transform the above to JSONL format so that it is easier for   \n121 a computer to understand. Enclose the JSONL output between two sets of   \n122 triple backticks. For each JSONL object, use the keys \u201csubject_name\u201d,   \n123 \u201clevel\u201d and \u201csubtopics\u201d.   \n124 It is worth noting that generating a subject list in JSONL format using a single prompt is feasible.   \n125 However, we refrain to do so, because we observe that incorporating additional formatting instructions   \n126 directly into the prompt can compromise the quality of the resulting subject list. These extracted   \n127 subjects (as well as their meta data) $\\mathbb{S}=\\{s_{1},s_{2},\\dots,s_{N}\\}$ can be subsequently used in next steps.   \n128 For each $s\\in\\mathbb S$ , let s.name, s.level and s.subtopics denote the name, grade level and subtopics   \n129 of subject $s$ , respectively. We can apply the above prompts multiple times to ensure better coverage   \n130 of subjects within this discipline. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "131 2.3 Syllabus Generator ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "132 For each subject $s$ , we have already extracted its name (s.name), grade level (s.level), and a   \n133 small set of included sub-topics (s.subtopics) in a structured format. In this section, we aim to   \n134 further segment each subject into smaller units, making them more suitable for creating homework   \n135 assignments. We consult GPT-4 to design a syllabus for this subject. We opt for syllabus generation   \n136 for the following reasons. Firstly, a syllabus essentially breaks down the main topic of a subject   \n137 into smaller segments in a hierarchical manner. Specifically, each subject comprises several class   \n138 sessions, and each session covers a variety of sub-topics and key concepts. Secondly, a syllabus   \n139 provides an introduction, objectives, and expected outcomes of a subject, which are inherently useful   \n140 for formulating homework questions. We instruct GPT-4 to 1) design a syllabus based on its meta   \n141 data (s.level, s.name and s.subtopics); 2) break the subject into different class sessions; 3)   \n142 provide details for each class session with a description and detailed key concepts students need to   \n143 master.   \n144 Let $\\boldsymbol{\\mathcal{A}}$ denote the generated syllabus. The resulting syllabus $\\boldsymbol{\\mathcal{A}}$ is in unstructured text format. However,   \n145 class session names and key concepts of each class are required in the instruction generation step (see   \n146 Algorithm 1). Similar to the process of subject list extraction in Section 2.2, we again extract these   \n147 meta data of each class session by prompting GPT-4. As a result, we obtain a list of class sessions   \n148 $\\mathbb{C}=\\{c_{1},c_{2},\\ldots,c_{|\\mathbb{C}|}\\}$ and their corresponding key concepts $\\mathbb{K}=\\left\\{\\mathbf{k}_{1},\\mathbf{k}_{2},\\ldots,\\mathbf{k}_{|\\mathbb{C}|}\\right\\}$ . The detailed   \n149 prompt for syllabus generation is in Appendix A.3. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "150 2.4 Instruction Generator ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "151 Given a syllabus $\\boldsymbol{\\mathcal{A}}$ as well as a list of its class sessions $\\mathbb{C}$ and their associated key concepts $\\mathbb{K}$ ,   \n152 we are ready to generate homework questions and their answers. To generate diverse homework   \n153 questions, we first sample one or two class session names from $\\mathbb{C}$ and one to five key concepts under   \n154 these selected class sessions. Let $\\hat{\\mathbb C}$ denote the selected class session names and $\\hat{\\mathbb K}$ the selected key   \n155 concepts. Then we prompt GPT-4 (or GPT-3.5) to generate a homework question given the selected   \n156 class sessions $\\hat{\\mathbb C}$ and key concepts $\\hat{\\mathbb K}$ as well as the syllabus $\\boldsymbol{\\mathcal{A}}$ . We intend to give GPT-4/3.5 more   \n157 context (e.g., what students have already learned in previous sessions) when creating assignments.   \n158 Therefore, we additionally instruct GPT to consider that students have learned up to class sessions $\\hat{\\mathbb C}$   \n159 when crafting homework and try to leverage multiple key concepts across different class sessions.   \n160 See details of our prompt for instruction generation in Appendix A.4.   \n161 Sampling Class Sessions and Key Concepts In a single syllabus, there are numerous class sessions   \n162 and key concepts. We have two strategies to sample from them. In the first strategy, we generate   \n163 assignments from a single class session. Therefore, we have only one class session name. Suppose   \n164 twhee  hma vkeey c koenyc ecpotsn,c ewphtisc ihn  mtoetaanl si nw teh ihsa svees tsoitoanl.l y $\\textstyle\\sum_{i=1}^{5}{\\binom{m}{i}}$ lcy osmabmipnlaet ioonnes .t Io n ftivhei s ksetrya tceognyc, ewptes  fforcoums   \n166 on creating basic homework questions. To make  the resulting questions more challenging (combine   \n167 knowledge from multiple class sessions), we propose a second strategy to combine key concepts   \n168 from two class sessions in the second strategy. We intend to generate questions leverage knowledge   \n169 from two different class sessions. Suppose we have $m_{1}$ and $m_{2}$ key concepts in the first and second   \n170 class sessions, respectively. We can have i5=2 $\\begin{array}{r}{\\sum_{i=2}^{5}\\binom{m_{1}+m_{2}}{i}-\\sum_{i=2}^{5}\\binom{m_{1}}{i}-\\sum_{i=2}^{5}\\binom{m_{2}}{i}}\\end{array}$ different   \n171 combinations, which is significantly more than that of the first strategy. We use both strategies to   \n172 ensure our created questions are diverse in difficulty levels.   \n173 Answer Generation After we generate questions in previous steps, we simply send these questions   \n174 to GPT-3.5 and collect answers. We use GPT-3.5 for answer generation, because we find the quality   \n175 of generated answers from GPT-3.5 is sufficiently good and using GPT-3.5 is significantly faster   \n176 than GPT-4. The resulting question-answer pairs are our instruction tuning data. With a huge amount   \n177 of question-answer pairs ranging from different disciplines with various difficulty levels, we expect   \n178 the resulting LLM can excel in a wide range of tasks. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "179 3 Experiments ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "180 3.1 Data Generation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "181 Taxonomy Creation By asking GPT-4 to create a taxonomy of human knowledge and capabilities,   \n182 we end up with a set of fields, sub-fields, and disciplines that cover a broad range of domains in human   \n183 knowledge and capabilities. Next, we ask human annotators to decide whether these elements in the   \n184 taxonomy should be kept or not in order to reduce the redundancy of the taxonomy while maintaining   \n185 its correctness. Note that if a field or sub-field is marked as remove, we remove its descendant as   \n186 well. We kept 126 disciplines after majority voting (provided in supplementary materials). Note that   \n187 it is feasible to manually add extra disciplines, sub-fields, or fields whenever necessary.   \n188 Subject and Syllabus Generation During the subject list and syllabus generation, we prompt   \n189 GPT-4 and employ nucleus sampling [14] with temperature $T=1.0$ and top- $\\cdot p=0.95$ to encourage   \n190 diversity. We do not use GPT-3.5-turbo since some subjects belong to the long-tail distribution   \n191 which may not be effectively modeled by GPT-3.5-turbo. To ensure diversity and completeness of   \n192 the generated subjects, we query GPT-4 10 times for each discipline (Section 2.2). There are 100 to   \n193 200 subjects for each discipline on average. It is worth noting that the same subjects may appear in   \n194 different disciplines. For instance, the subject calculus is both in physics and mathematics. We do   \n195 not de-duplicate those subjects, since it may reflect their importance in human knowledge. Given a   \n196 subject in a specified discipline, we query GPT-4 for only one time to design a syllabus (see details in   \n197 section 2.3). The temperature and top- $p$ are still set to 1.0 and 0.95, respectively. The number of class   \n198 sessions contained in each syllabus varies from 10 to 30 and each class session contains around five   \n199 key concepts.   \n200 Instruction Generation Each instruction data consists of a question and its answer. We choose to   \n201 generate questions and answers separately since we observed that separate generations lead to better   \n202 quality. After question generation with GPT-4, each question is then answered by GPT-3.5-turbo   \n203 with temperature $T\\,=\\,0.7$ , top- $\\textit{p}=\\ 0.95$ (we use a lower temperature in order to make the re  \n204 sulting answers more accurate). We use GPT-3.5-turbo instead of GPT-4 for answer generation,   \n205 because GPT-3.5-turbo is significantly faster with reasonably good results. We generate 10 million   \n206 instruction-response pairs in total and then we do training data decontamination. Specifically, the   \n207 training instruction-response pairs are decontaminated by removing pairs that contain questions or   \n208 input prompts from the test and training (if any) sets of benchmarks we evaluate. We exclude the   \n209 training set of benchmarks we evaluate to verify the generalization capability of our synthetic data. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "table", "img_path": "rcch4UsMBi/tmp/8f604b26cdfa70bc7b4fa561ee45c31061b6a9aa61212d81dec9d06a2cf596d3.jpg", "table_caption": ["Table 1: Main results on Mathematical Reasoning, Coding, Logical Reasoning, and Academic Exam benchmarks. Best results are in boldface, while the second best results are underscored. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "210 3.2 Model Training ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "211 We employ Mistral 7B [16] as our base model. During training, we concatenate each instruction and   \n212 response pair to a single sequence and only compute loss on response tokens. We train our model for   \n213 3 epochs with a learning rate of 3e-6. The batch size is set to approximately 512 instruction-response   \n214 pairs. We employ a dynamic batch size to ensure a constant total number of tokens per batch. We   \n215 use a cosine learning rate schedule and we start with a linear warm-up of 1000 steps and the final   \n216 learning rate is reduced to 0. The training requires approximately 8 days using 32 A100 GPUs. ", "page_idx": 5}, {"type": "text", "text": "217 3.3 Benchmark Evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "218 The instruction data GLAN generated spans a wide range of subjects. We evaluate its effectiveness   \n219 in mathematical reasoning, coding, logical reasoning, and academic exams.   \n220 Mathematical Reasoning: Mathematics is a common subject in many different disciplines. Hence, it   \n221 is necessary to test the math reasoning ability of GLAN. We choose the two popular benchmarks for   \n222 evaluation (i.e., GSM8K [7] and MATH [12]). GSM8K [7] is a high-quality math problem dataset   \n223 that measures the basic multi-step mathematical reasoning ability. It contains around 7k problems for   \n224 training and 1K problems for test. MATH [12] is a challenging math dataset that contains mathematics   \n225 competition-level problems from AMC, AIME, etc. The $7.5\\mathrm{k}$ training and 5K test problems cover   \n226 seven math subjects, i.e., Prealgebra, Precalculus, Algebra, Intermediate Algebra, Number Theory,   \n227 Counting and Probability, and Geometry. Note that GLAN does not use any examples in the training   \n228 set of GSM8K or MATH. Following [20], we report 0-shot setting results for GLAN. Coding: To   \n229 evaluate the coding capability of GLAN, we opt for two coding benchmarks HumanEval [4] and   \n230 MBPP [1]. We employ 0-shot setting for HumanEval and 3-shot setting for MBPP following prior art   \n231 [4, 21]. BBH: The instruction dataset we generated covers many disciplines, which can potentially   \n232 enhance the reasoning ability of GLAN. Therefore, we evaluate GLAN on the BIG-Bench Hard   \n233 dataset (BBH [29]), which contains 23 challenging tasks from Big-Bench [28]. We employ the   \n234 standard 3-shot setting with chain-of-thought demonstrations. Academic Exams: We also evaluate   \n235 GLAN on different academic benchmarks to verify whether GLAN is capable of solving exam   \n236 questions. We choose two benchmarks (i.e., ARC [6] and MMLU [11]). Both benchmarks are   \n237 composed of multi-choice questions. AI2 Reasoning Challenge (ARC [6]) contains grade-school   \n238 level, multi-choice science questions. It contains two sub-sets, which are ARC-Challenge (ARC-C)   \n239 and ARC-Easy (ARC-E). Massive Multitask Language Understanding (MMLU [11]) consists of a   \n240 set of multiple-choice questions about 57 subjects ranging in difficulty from elementary levels to   \n241 professional levels. It covers various of domains of knowledge, including humanities, STEM and   \n242 social sciences. Note that there is a training set for ARC. However, we have excluded it from our   \n243 training set during the decontamination process described in Section 3.1. Previous models mostly   \n244 leverage probability-based methods on ARC and MMLU, which returns the best option based on the   \n245 probabilities of the four options conditioned on the corresponding multi-choice question. We observe   \n246 that after training on 10 million instructions, GLAN is able to generate its predicted options and   \n247 analysis of multi-choice questions in plain text as GPT-3.5 does. We therefore opt for 0-shot setting   \n248 for GLAN and extract predictions using rules based on its completions as in [22].   \n249 Results Our main results are shown in Table 1. We compare GLAN against general domain models   \n250 (Orca 2 [22], Mistral Instruct [16] and WizardLM [39]), math optimized models (MetaMath [40]   \n251 and WizardMath [20]) and coding optimized models (CodeAlpaca [3]). We also report results of   \n252 base LLMs (i.e., LLaMA2 [31] and Mistral [16]) as references. GLAN either obtains the best results   \n253 or results close to the best across all benchmarks. We observe that capabilities of math or coding   \n254 optimized models increase on math or coding benchmarks while usually not others. After instruction   \n255 tuning, GLAN excels on multiple dimensions from mathematical reasoning, coding, reasoning, and   \n256 academic exams with a systematical data generation approach. Also note that our method does not   \n257 use any task-specific training data such as training sets of GSM8K, MATH, or ARC as in Orca 2,   \n258 MetaMath, and WizardMath, which indicates the general applicability of GLAN.   \n259 A Closer Look at Academic Exams ARC and MMLU are all multi-choice based benchmarks on   \n260 academic exams. However, we observe that improvements of GLAN over Mistral on ARC are much   \n261 larger than these on MMLU (see Table 1). By grouping the 57 subjects in MMLU into four categories   \n262 (i.e., STEM, Humanities, Social Sciences, and Other (business, health, misc.)), we observe GLAN   \n263 wildly improves on STEM in MMLU while not in other categories (Table 2). Also note that ARC   \n264 is composed of high school science problems, which are also STEM questions. GLAN is good at   \n265 STEM subjects may be because responses of our dataset are from GPT-3.5-turbo, which by default   \n266 generates responses with Chain-of-Thoughts (CoT) reasoning. Indeed, we observe that GLAN   \n267 generates solutions with CoT for multi-choice questions. CoT may help the multi-step reasoning in   \n268 STEM multi-choice questions [35], while humanities and social sciences questions involve more   \n269 memorization and single-step reasoning, where CoT may introduce additional errors. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "table", "img_path": "rcch4UsMBi/tmp/e088c1226ebc028b554586c348d253dfbc4334f3493c9305c05606a341aa848d.jpg", "table_caption": ["Table 2: Detailed Results on Academic Exam benchmarks. "], "table_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "rcch4UsMBi/tmp/a2c984d33e67ca2bdfcbff47886a9cc0e5622dc279104a5299c3c2b66ed53ef4.jpg", "img_caption": ["Figure 2: The scaling curve of GLAN on downstream tasks. The $x$ -axis denotes GLAN data size (in $\\log_{10}$ scale following [17]), and the $y$ -axis denotes the task performance. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "270 3.4 Scaling Property of GLAN ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "271 We investigate the scaling property of GLAN by training Mistral on different numbers of examples   \n272 (i.e., 50K, 200K, 500K, 1M, and 10M) we generated. The results on downstream tasks are shown in   \n273 Figure 2. It can be observed that overall task performance tends to increase as we increase the data size.   \n274 Notably, the curve has not reached a plateau, indicating the potential for further improvement through   \n275 the continued scaling of the data size of GLAN. However, we defer further scaling experiments to   \n276 future work. ", "page_idx": 6}, {"type": "table", "img_path": "rcch4UsMBi/tmp/903e77148778d849cfe1b3d6be863355fcaeae4c18362db3b787e8f39e1d6a63.jpg", "table_caption": ["Table 3: The evaluation of loss values between the test data and training data. Large positive $\\Delta$ (or $\\Delta(\\%))$ indicates task-specific in-domain training data might be exposed to the model during training. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "277 3.5 Task-specific Training Data ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "278 GLAN is a generalized method to create synthetic data for instruction tuning. In order to evaluate   \n279 the generalization capabilities of this synthetic data, we deliberately exclude task-specific training   \n280 sets from all benchmarks on which we conduct our assessments. Similar to [36], we explore whether   \n281 models have been trained on task-specific in-domain data. We compute the training loss $L_{t r a i n}$ and   \n282 test loss $L_{t e s t}$ on ARC Challenge (ARC-C), GSM8K, and MATH for GLAN and other models in   \n283 comparison. We choose these datasets because among all benchmarks evaluated in Section 3.3, these   \n284 benchmarks contain training sets. Intuitively, the larger $\\Delta=L_{t e s t}-L_{t r a i n}$ is, the more likely the   \n285 training set is exposed. To make $\\Delta$ easier to interpret, we additionally compute the relative difference   \n286 $\\Delta(\\%)\\stackrel{-}{=}(L_{t e s t}-L_{t r a i n})/L_{t e s t}$ . Table 3 shows the losses of the training and test splits for GLAN   \n287 are nearly identical (or $\\Delta$ is negative). This suggests that GLAN has not been exposed to in-domain   \n88 data during training and tuning procedures. Please refer detailed $L_{t r a i n}$ and $L_{t e s t}$ losses in Table 8 (in   \n289 Appendix). Additionally, as shown in Table 8, we observe that GLAN obtains higher losses on both   \n290 test and training splits on GSM8K, MATH, and ARC compared to other models, while performances   \n291 of GLAN on these datasets are high (see Table 1). This might imply that synthetic data generated by   \n292 GLAN is diverse and our resulting model avoids convergence to any specific domain or style present   \n293 in existing benchmarks. ", "page_idx": 7}, {"type": "text", "text": "294 3.6 Instruction Following Evaluation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "295 IFEval We assess the instruction-following capabilities of GLAN utilizing the Instruction Fol  \n296 lowing Evaluation dataset (IFEval [42]). IFEval consists of a collection of \u201cverifiable instructions\u201d,   \n297 encompassing 25 distinct types of instructions (around 500 prompts in total). Each prompt comprises   \n298 one or more verifiable instructions. The evaluation involves four types of metrics at both prompt   \n299 level and instruction level, evaluating strict and loose accuracies. As shown in Table 4, GLAN   \n300 demonstrates superior instruction-following capabilities in both prompt-level and instruction-level   \n301 evaluations. However, there is still a considerable gap compared to GPT-3.5-turbo and GPT-4.   \n302 Evol-Instruct Test Evol-Instruct testset [39] contains real-world human instructions from diverse   \n303 sources, and it consists of 218 instances with 29 distinct skills. Each instruction is associated with   \n304 a difficulty level from 1 to 10. The responses are often open-ended descriptions, and we believe   \n305 this benchmark is a necessary supplement to IFEval (answers to their instructions are \u201cverifiable\u201d).   \n306 Following [39] and [5], we adopt a GPT-4-based automatic evaluation method to conduct a pairwise   \n307 comparison between GLAN and other models. Specifically, GPT-4 is instructed to assign a score   \n308 between 1 and 10 overall score w.r.t. the helpfulness, relevance, accuracy, and level of detail of   \n309 responses generated by two different models for a given input question. A higher score indicates   \n310 better overall performance. To mitigate potential order bias, we perform bidirectional comparisons   \n311 for each response pair and determine their average score. The average score difference to GLAN   \n312 (i.e., avg_score(GLAN) \u2212avg_score $(x)$ ) serves as the final metric. Table 5 presents the results   \n313 of pairwise comparisons across various levels of instruction difficulty. GLAN showcases superior   \n314 performance compared to LLaMA-2, Orca 2, Mistral Instruct, and even WizardLM-13B (note that   \n315 GLAN contains only 7B parameters) on most difficulty levels and overall scores. This suggests that   \n316 GLAN demonstrates improved ability to process diverse instructions, regardless of their difficulty   \n317 or complexity. Also, note that GLAN falls behind GPT-3.5-turbo as other models in comparison.   \n318 Additionally, we group Evol-Instruct test according to the 29 skills and observe the same trends.   \n319 Detailed results are listed in Appendix (Table 9 and 10). GLAN demonstrates strong performance on   \n320 most skills, especially in Math, Coding, and Reasoning. However, it slightly falls short in common  \n321 sense related tasks. We also created GLAN-Test, similar to the Evol-Instruct Test but much larger in   \n322 size, where GLAN outperforms other models as well (see Appendix A.8). ", "page_idx": 7}, {"type": "table", "img_path": "rcch4UsMBi/tmp/cf541336c76c5cf76d6c63a7fdb9dd9d2b47b6f52d648ca7c70279315f0dc68e.jpg", "table_caption": ["Table 4: Instruction following capability evaluation on IFEval. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "table", "img_path": "rcch4UsMBi/tmp/dd303c456492863c50f0ad4bd1f5047761a42a7acc15151350715eab2a831079.jpg", "table_caption": ["Table 5: Pairwise comparison on various difficulty levels between GLAN and other models on Evol-Instruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as avg_score(GLAN) \u2212avg_score $(x)$ . "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "323 4 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "324 Recent literature has extensively explored the collection of various human-made resources for   \n325 instruction tuning. An intuitive direction is to collect existing NLP datasets and corresponding   \n326 task descriptions [26, 33, 41], typical LLMs such as BLOOMZ [23] and FLAN [34] are trained   \n327 on this type of instruction tuning data. However, with only tens to thousands of existing datasets   \n328 available, the scope and diversity of instruction tuning are inevitably limited. Another common   \n329 practice is to implement instruction tuning with real-world human user prompts. For instance,   \n330 InstructGPT [25] was trained on high-quality human prompts submitted by real-world users to   \n331 OpenAI GPT APIs. Vicuna [5] leverages user-shared prompts along with ChatGPT responses for   \n332 instruction tuning, and Dolly[8] was trained on simulated human-user interactions written by over   \n333 5k employees. Nevertheless, acquiring instructional data from human users typically involves high   \n334 costs and involves privacy concerns. As LLM capabilities improve, instruction tuning with LLM  \n335 generated data exhibits better scalability and potential in addressing the super-alignment problem [27].   \n336 Leveraging the in-context learning ability of LLMs, Unnatural instructions [15] and Self-instruct [32]   \n337 sampled seed instructions as examples to elicit LLMs to generate new instructions. Taking advantage   \n338 of the rephrasing ability of LLMs, WizardLM [39] and WizardMath [20] were trained using Evol  \n339 Instruct. Evol-Instruct iteratively employs ChatGPT to rewrite seed instructions into increasingly   \n340 complex instructions. Similar to generation from seed instructions, carefully selected seed topics   \n341 are used for generating textbook-like synthetic data [18] or self-chat multi-turn dialogues [38, 9]   \n342 for instruction tuning. However, models trained on these LLM-generated data only work well in   \n343 specific domains such as math [20, 40], dialogue [38, 9] or open-ended question answering [30, 39].   \n344 These methods encounter challenges in generalization [10], as the data diversity is restricted by seed   \n345 instructions or seed topics. ", "page_idx": 8}, {"type": "text", "text": "346 5 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "347 We propose GLAN, a general and scalable method for synthesizing instruction data. Experiments   \n348 show that GLAN can help large language models improve their capabilities in multiple dimensions,   \n349 from mathematical reasoning, coding, academic exams, and logical reasoning to general instruction   \n350 following. Currently, our synthetic data are based on the taxonomy of human knowledge and   \n351 capabilities, and there are other types of useful data that have not been covered. We are interested in   \n352 designing methods with border coverage. Our current instruction data are mostly question-answer   \n353 pairs, and in the next step, we plan to generate synthetic data of multi-turn conversations and long   \n354 documents. ", "page_idx": 8}, {"type": "text", "text": "355 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "356 [1] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry,   \n357 Q. Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732,   \n358 2021.   \n359 [2] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,   \n360 G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural   \n361 information processing systems, 2020.   \n362 [3] S. Chaudhary. Code alpaca: An instruction-following llama model for code generation. https:   \n363 //github.com/sahil280114/codealpaca, 2023.   \n364 [4] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda,   \n365 N. Joseph, G. Brockman, et al. Evaluating large language models trained on code. arXiv   \n366 preprint arXiv:2107.03374, 2021.   \n367 [5] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E.   \n368 Gonzalez, I. Stoica, and E. P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with   \n369 $90\\%^{*}$ chatgpt quality, March 2023.   \n370 [6] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think   \n371 you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint   \n372 arXiv:1803.05457, 2018.   \n373 [7] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek,   \n374 J. Hilton, R. Nakano, C. Hesse, and J. Schulman. Training verifiers to solve math word   \n375 problems. arXiv preprint arXiv:2110.14168, 2021.   \n376 [8] M. Conover, M. Hayes, A. Mathur, J. Xie, J. Wan, S. Shah, A. Ghodsi, P. Wendell, M. Zaharia,   \n377 and R. Xin. Free dolly: Introducing the world\u2019s first truly open instruction-tuned llm, 2023.   \n378 [9] N. Ding, Y. Chen, B. Xu, Y. Qin, Z. Zheng, S. Hu, Z. Liu, M. Sun, and B. Zhou. Enhancing   \n379 chat language models by scaling high-quality instructional conversations. arXiv preprint   \n380 arXiv:2305.14233, 2023.   \n381 [10] A. Gudibande, E. Wallace, C. V. Snell, X. Geng, H. Liu, P. Abbeel, S. Levine, and D. Song.   \n382 The false promise of imitating proprietary language models. In International Conference on   \n383 Learning Representations, 2024.   \n384 [11] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea  \n385 suring massive multitask language understanding. In International Conference on Learning   \n386 Representations, 2021.   \n387 [12] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt.   \n388 Measuring mathematical problem solving with the math dataset. In Advances in Neural   \n389 Information Processing Systems, 2021.   \n390 [13] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de Las Casas,   \n391 L. A. Hendricks, J. Welbl, A. Clark, T. Hennigan, E. Noland, K. Millican, G. van den Driessche,   \n392 B. Damoc, A. Guy, S. Osindero, K. Simonyan, E. Elsen, O. Vinyals, J. Rae, and L. Sifre. Training   \n393 compute-optimal large language models. In Advances in Neural Information Processing Systems,   \n394 2022.   \n395 [14] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi. The curious case of neural text   \n396 degeneration. In International Conference on Learning Representations, 2020.   \n397 [15] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language   \n398 models with (almost) no human labor. In Proceedings of the 61st Annual Meeting of the   \n399 Association for Computational Linguistics (Volume 1: Long Papers), 2023.   \n400 [16] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand,   \n401 G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.   \n402 [17] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Rad  \n403 ford, J. Wu, and D. Amodei. Scaling laws for neural language models. arXiv preprint   \n404 arXiv:2001.08361, 2020.   \n405 [18] Y. Li, S. Bubeck, R. Eldan, A. Del Giorno, S. Gunasekar, and Y. T. Lee. Textbooks are all you   \n406 need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463, 2023.   \n407 [19] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei,   \n408 and A. Roberts. The flan collection: Designing data and methods for effective instruction tuning.   \n409 In International Conference on Machine Learning, 2023.   \n410 [20] H. Luo, Q. Sun, C. Xu, P. Zhao, J. Lou, C. Tao, X. Geng, Q. Lin, S. Chen, and D. Zhang.   \n411 Wizardmath: Empowering mathematical reasoning for large language models via reinforced   \n412 evol-instruct. arXiv preprint arXiv:2308.09583, 2023.   \n413 [21] Z. Luo, C. Xu, P. Zhao, Q. Sun, X. Geng, W. Hu, C. Tao, J. Ma, Q. Lin, and D. Jiang.   \n414 Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint   \n415 arXiv:2306.08568, 2023.   \n416 [22] A. Mitra, L. Del Corro, S. Mahajan, A. Codas, C. Simoes, S. Agarwal, X. Chen, A. Razdaibied  \n417 ina, E. Jones, K. Aggarwal, et al. Orca 2: Teaching small language models how to reason. arXiv   \n418 preprint arXiv:2311.11045, 2023.   \n419 [23] N. Muennighoff, T. Wang, L. Sutawika, A. Roberts, S. Biderman, T. Le Scao, M. S. Bari,   \n420 S. Shen, Z. X. Yong, H. Schoelkopf, X. Tang, D. Radev, A. F. Aji, K. Almubarak, S. Albanie,   \n421 Z. Alyafeai, A. Webson, E. Raff, and C. Raffel. Crosslingual generalization through multitask   \n422 finetuning. In Proceedings of the 61st Annual Meeting of the Association for Computational   \n423 Linguistics (Volume 1: Long Papers), 2023.   \n424 [24] S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, and A. Awadallah. Orca: Pro  \n425 gressive learning from complex explanation traces of gpt-4. arXiv preprint arXiv:2306.02707,   \n426 2023.   \n427 [25] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,   \n428 K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.   \n429 In Advances in Neural Information Processing Systems, 2022.   \n430 [26] V. Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,   \n431 A. Raja, M. Dey, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chh  \n432 ablani, N. V. Nayak, D. Datta, J. Chang, M. T. Jiang, H. Wang, M. Manica, S. Shen, Z. X.   \n433 Yong, H. Pandey, R. Bawden, T. Wang, T. Neeraj, J. Rozen, A. Sharma, A. Santilli, T. F\u00e9vry,   \n434 J. A. Fries, R. Teehan, T. L. Scao, S. Biderman, L. Gao, T. Wolf, and A. M. Rush. Multi  \n435 task prompted training enables zero-shot task generalization. In International Conference on   \n436 Learning Representations, 2022.   \n437 [27] T. Shen, R. Jin, Y. Huang, C. Liu, W. Dong, Z. Guo, X. Wu, Y. Liu, and D. Xiong. Large   \n438 language model alignment: A survey. arXiv preprint arXiv:2309.15025, 2023.   \n439 [28] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro,   \n440 A. Gupta, A. Garriga-Alonso, A. Kluska, A. Lewkowycz, A. Agarwal, A. Power, A. Ray,   \n441 A. Warstadt, A. W. Kocurek, A. Safaya, A. Tazarv, A. Xiang, A. Parrish, A. Nie, A. Hussain,   \n442 A. Askell, A. Dsouza, et al. Beyond the imitation game: Quantifying and extrapolating the   \n443 capabilities of language models. Transactions on Machine Learning Research, 2023.   \n444 [29] M. Suzgun, N. Scales, N. Sch\u00e4rli, S. Gehrmann, Y. Tay, H. W. Chung, A. Chowdhery, Q. Le,   \n445 E. Chi, D. Zhou, and J. Wei. Challenging BIG-bench tasks and whether chain-of-thought can   \n446 solve them. In Findings of the Association for Computational Linguistics: ACL 2023, 2023.   \n447 [30] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.   \n448 Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/   \n449 stanford_alpaca, 2023.   \n450 [31] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra,   \n451 P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv   \n452 preprint arXiv:2307.09288, 2023.   \n453 [32] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct:   \n454 Aligning language models with self-generated instructions. In Proceedings of the 61st Annual   \n455 Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association   \n456 for Computational Linguistics, 2023.   \n457 [33] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S.   \n458 Dhanasekaran, A. Arunkumar, D. Stap, E. Pathak, G. Karamanolakis, H. Lai, I. Purohit, I. Mon  \n459 dal, J. Anderson, K. Kuznia, K. Doshi, K. K. Pal, M. Patel, M. Moradshahi, M. Parmar,   \n460 M. Purohit, N. Varshney, P. R. Kaza, P. Verma, R. S. Puri, R. Karia, S. Doshi, S. K. Sampat,   \n461 S. Mishra, S. Reddy A, S. Patro, T. Dixit, and X. Shen. Super-NaturalInstructions: Generaliza  \n462 tion via declarative instructions on $1600+$ NLP tasks. In Proceedings of the 2022 Conference   \n463 on Empirical Methods in Natural Language Processing, 2022.   \n464 [34] J. Wei, M. Bosma, V. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le.   \n465 Finetuned language models are zero-shot learners. In International Conference on Learning   \n466 Representations, 2022.   \n467 [35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. Chain  \n468 of-thought prompting elicits reasoning in large language models. In Advances in Neural   \n469 Information Processing Systems, 2022.   \n470 [36] T. Wei, L. Zhao, L. Zhang, B. Zhu, L. Wang, H. Yang, B. Li, C. Cheng, W. L\u00fc, R. Hu, C. Li,   \n471 L. Yang, X. Luo, X. Wu, L. Liu, W. Cheng, P. Cheng, J. Zhang, X. Zhang, L. Lin, X. Wang,   \n472 Y. Ma, C. Dong, Y. Sun, Y. Chen, Y. Peng, X. Liang, S. Yan, H. Fang, and Y. Zhou. Skywork:   \n473 A more open bilingual foundation model, 2023.   \n474 [37] Wikipedia contributors. Education, 2023. Last edited on 24 March 2023.   \n475 [38] C. Xu, D. Guo, N. Duan, and J. McAuley. Baize: An open-source chat model with parameter  \n476 efficient tuning on self-chat data. In Proceedings of the 2023 Conference on Empirical Methods   \n477 in Natural Language Processing, 2023.   \n478 [39] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, and D. Jiang. Wizardlm: Empow  \n479 ering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244,   \n480 2023.   \n481 [40] L. Yu, W. Jiang, H. Shi, J. YU, Z. Liu, Y. Zhang, J. Kwok, Z. Li, A. Weller, and W. Liu. Meta  \n482 math: Bootstrap your own mathematical questions for large language models. In International   \n483 Conference on Learning Representations, 2024.   \n484 [41] C. Zhou, P. Liu, P. Xu, S. Iyer, J. Sun, Y. Mao, X. Ma, A. Efrat, P. Yu, L. YU, S. Zhang,   \n485 G. Ghosh, M. Lewis, L. Zettlemoyer, and O. Levy. LIMA: Less is more for alignment. In   \n486 Advances in Neural Information Processing Systems, 2023.   \n487 [42] J. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y. Luan, D. Zhou, and L. Hou. Instruction  \n488 following evaluation for large language models. arXiv preprint arXiv:2311.07911, 2023. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "489 A Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "490 A.1 Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "491 While GLAN presents significant advancements in academic benchmarks. However, there may   \n492 still have several limitations in real world deployment. The resulting LLMs train on generated data   \n493 using GLAN may occasionally produce factual incorrect (or even toxic) responses. Further training   \n494 for refusal, hallucination reduction as well as toxic content reduction should be performed before   \n495 deployment. ", "page_idx": 12}, {"type": "text", "text": "496 A.2 Broader Impacts ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "497 Data synthesizing is crucial for the continual scaling of large language models, especially as we   \n498 exhaust available human data. GLAN demonstrates the potential to generate vast amounts of synthetic   \n499 data from scratch, paving the way for even larger-scale data synthesis efforts. While GLAN has   \n500 shown the effectiveness of synthetic data, we must point out that synthetic data may inherit and even   \n501 amplify social biases present in the frontier LLMs for generation. Future research should focus on   \n502 developing techniques to identify and correct biases in the generated datasets and models trained on   \n503 them. ", "page_idx": 12}, {"type": "text", "text": "504 A.3 Prompt for Syllabus Generator ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "505 The prompt template for syllabus generation is in Table 6. ", "page_idx": 12}, {"type": "text", "text": "Table 6: Prompt template for Syllabus Generator. ", "page_idx": 12}, {"type": "image", "img_path": "rcch4UsMBi/tmp/64a3c728a9f84f00921a7facd1b8c3e8a43a38a781c5a04c8c03b2e934e653ea.jpg", "img_caption": [], "img_footnote": [], "page_idx": 12}, {"type": "text", "text": "506 A.4 Prompt for Instruction Generator ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "507 The prompt template for instruction generator is in Table 7. ", "page_idx": 12}, {"type": "text", "text": "508 A.5 Task-specific Training Data ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "509 We provide the specific train/test values of different models on different benchmarks in Table 8. ", "page_idx": 12}, {"type": "text", "text": "510 A.6 Evol-Instruct Test Results on Different Difficulty Levels ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "511 The concrete Evol-Instruct test results on different difficulty levels are shown in Table 9. ", "page_idx": 12}, {"type": "image", "img_path": "rcch4UsMBi/tmp/1cd526054090120c49dc0e9b9b617c826fb2a704c4e1e6932bcf9362c1398d4c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "table", "img_path": "rcch4UsMBi/tmp/cf97c7ccc015dbed778ddb63d15bbcfd9a05f795884494ea9b6351f0df95dede.jpg", "table_caption": ["Table 8: The evaluation of loss values between the test data and training data. Large positive $\\Delta$ (or $\\Delta(\\%))$ indicate task specific in-domain training data may be exposed to the model during training. "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "512 A.7 Evol-Instruct Test Results on Different Skills ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "513 The concrete Evol-Instruct test results on different skills are shown in Table 10. ", "page_idx": 13}, {"type": "text", "text": "514 A.8 GLAN-Test Overall Results ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "515 GLAN-Test There are only hundreds of instructions in In IFEval and Evol-Instruct Test and   \n516 we believe the domains or skills they can cover are rather limited. Therefore, we propose a held  \n517 out test set using GLAN data and we call it GLAN-Test. It contains 6,300 instructions on 126   \n518 disciplines (50 instructions for each discipline). We further categorize the 126 disciplines to 8   \n519 distinct fields (i.e., Academic-Humanities, Academic-Social Science, Academic-Natural Science,   \n520 Academic-Applied Science, Academic-Formal Science, Industry-Manufacturing, Industry-Services   \n521 and Industry-Agriculture). We believe that the extensive domain coverage of GLAN-Test renders   \n522 it an effective test bed for the assessment of generalization capabilities in LLMs. We adopt the   \n523 same GPT-4 based evaluation protocol as in Evol-Instruct Test (previous paragraph). We prompt   \n524 GPT-4 to do a pairwise ranking of GLAN and other models in comparison. The overall results and   \n525 results across the 8 fields are presented in Table 11, where GLAN obtains higher GPT-4 scores than   \n526 Orca2-7B, Mistral-7B Instruct and WizardLM-13B, despite using only 7B parameters. GLAN still ", "page_idx": 13}, {"type": "text", "text": "Table 9: Pairwise comparison on various difficulty levels between GLAN and other models on Evol-Instruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as avg_score(GLAN) \u2212avg_score $(x)$ . ", "page_idx": 14}, {"type": "table", "img_path": "rcch4UsMBi/tmp/ffd66dc5246df1b5d10c45c45b89598f47c51cd037565b83cb9370c3ed40240b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "rcch4UsMBi/tmp/909b486e55db3e330f520cb8e1825e2f8c0db0a96677037b8298fb5bdbc685aa.jpg", "table_caption": ["Table 10: Pairwise comparison on various skills between GLAN and other models on EvolInstruct testset. The scores are the average gap of scores assigned by GPT-4, calculated as avg_score(GLAN) \u2212avg_score $(x)$ . "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "527 lag behind GPT-4. Detailed results for the 126 fine-grained disciplines can be found in Appendix   \n528 A.9 (see Table 12 for more details). GLAN demonstrates its effectiveness on multiple domains (or   \n529 disciplines) such as Mathematics, Physics, Chemistry, Computer science, Electrical, Mechanical, etc.,   \n530 indicating that smaller models may yield general improvements on various domains through strategic   \n531 fine-tuning. Furthermore, it is noted that GLAN demonstrates less-than-ideal performance across   \n532 distinct disciplines such as American history, Divinity, or Radiology. This observation underscores   \n533 the potential for further refinement and development of our methodology within these domains. ", "page_idx": 14}, {"type": "text", "text": "Table 11: Pairwise comparison between GLAN and other models on GLAN-Test (the 126 disciplines are categorized into 8 fields for clarity of the illustration). The scores are the average gap of scores assigned by GPT-4, calculated as avg_score(GLAN) \u2212avg_score(x). ", "page_idx": 15}, {"type": "table", "img_path": "rcch4UsMBi/tmp/e66aa06c0948e94f20fb3c134ab3897f13665b341aa3760e7894b8af3ba1a7a8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "rcch4UsMBi/tmp/a1c549b8cd208c8b0e8efe4555736d7d6a2d3ac48f6d79bf15d8fafef752cde6.jpg", "table_caption": ["Table 12: Pairwise comparison across 126 disciplines (or domains) on GLAN-Test. The scores are generated from the average gap between GLAN and other model $x$ in assessment scores assigned by GPT-4, calculated as avg_score(GLAN) \u2212avg_score(x). "], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "rcch4UsMBi/tmp/63950e535dfcb85f77f822257a369addf4cefdf072759d247d30b671b0df9992.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "535 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "537 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n538 paper\u2019s contributions and scope?   \n539 Answer: [Yes]   \n540 Justification: See Abstract and Section 1.   \n541 Guidelines:   \n542 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n543 made in the paper.   \n544 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n545 contributions made in the paper and important assumptions and limitations. A No or   \n546 NA answer to this question will not be perceived well by the reviewers.   \n547 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n548 much the results can be expected to generalize to other settings.   \n549 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n550 are not attained by the paper.   \n551 2. Limitations   \n552 Question: Does the paper discuss the limitations of the work performed by the authors?   \n553 Answer: [Yes]   \n554 Justification: See Section 5 and Appendix A.1   \n555 Guidelines:   \n556 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n557 the paper has limitations, but those are not discussed in the paper.   \n558 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n559 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n560 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n561 model well-specification, asymptotic approximations only holding locally). The authors   \n562 should reflect on how these assumptions might be violated in practice and what the   \n563 implications would be.   \n564 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n565 only tested on a few datasets or with a few runs. In general, empirical results often   \n566 depend on implicit assumptions, which should be articulated.   \n567 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n568 For example, a facial recognition algorithm may perform poorly when image resolution   \n569 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n570 used reliably to provide closed captions for online lectures because it fails to handle   \n571 technical jargon.   \n572 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n573 and how they scale with dataset size.   \n574 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n575 address problems of privacy and fairness.   \n576 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n577 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n578 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n579 judgment and recognize that individual actions in favor of transparency play an impor  \n580 tant role in developing norms that preserve the integrity of the community. Reviewers   \n581 will be specifically instructed to not penalize honesty concerning limitations.   \n582 3. Theory Assumptions and Proofs   \n83 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n84 a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "598 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "599 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n600 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n601 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: In Section 2 and 3.1, we provide a detailed description of the data generation process. Although we haven\u2019t shared the original prompts yet, they are quite simple and customizable. Besides, we are actively working to gain authorization to release them as soon as possible. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "639 5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "40 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n41 tions to faithfully reproduce the main experimental results, as described in supplemental   \n42 material?   \n43 Answer: [No]   \n44 Justification: While we are temporarily unable to provide open access to the data and code,   \n45 we are actively working to gain the necessary authorization to release these resources. Once   \n46 obtained, we will ensure that all data and code, along with detailed instructions, are made   \n47 available to faithfully reproduce the main experimental results.   \n48 Guidelines:   \n49 \u2022 The answer NA means that paper does not include experiments requiring code.   \n50 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n51 public/guides/CodeSubmissionPolicy) for more details.   \n52 \u2022 While we encourage the release of code and data, we understand that this might not be   \n53 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n54 including code, unless this is central to the contribution (e.g., for a new open-source   \n55 benchmark).   \n56 \u2022 The instructions should contain the exact command and environment needed to run to   \n57 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n58 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n59 \u2022 The authors should provide instructions on data access and preparation, including how   \n60 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n61 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n62 proposed method and baselines. If only a subset of experiments are reproducible, they   \n63 should state which ones are omitted from the script and why.   \n64 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n65 versions (if applicable).   \n66 \u2022 Providing as much information as possible in supplemental material (appended to the   \n67 paper) is recommended, but including URLs to data and code is permitted.   \n6. Experimental Setting/Details ", "page_idx": 20}, {"type": "text", "text": "", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: See Section 3.2, 3.3 Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "680 7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "681 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n682 information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [No] ", "page_idx": 20}, {"type": "text", "text": "691 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n692 example, train/test split, initialization, random drawing of some parameter, or overall   \n693 run with given experimental conditions).   \n694 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n695 call to a library function, bootstrap, etc.)   \n696 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n697 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n698 of the mean.   \n699 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n700 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n701 of Normality of errors is not verified.   \n702 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n703 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n704 error rates).   \n705 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n706 they were calculated and reference the corresponding figures or tables in the text.   \n707 8. Experiments Compute Resources   \n708 Question: For each experiment, does the paper provide sufficient information on the com  \n709 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n710 the experiments?   \n711 Answer: [Yes]   \n712 Justification: We included compute resources in Section 3.2.   \n713 Guidelines:   \n714 \u2022 The answer NA means that the paper does not include experiments.   \n715 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n716 or cloud provider, including relevant memory and storage.   \n717 \u2022 The paper should provide the amount of compute required for each of the individual   \n718 experimental runs as well as estimate the total compute.   \n719 \u2022 The paper should disclose whether the full research project required more compute   \n720 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n721 didn\u2019t make it into the paper).   \n722 9. Code Of Ethics   \n723 Question: Does the research conducted in the paper conform, in every respect, with the   \n724 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n725 Answer: [Yes]   \n726 Justification: This study strictly adheres to the NeurIPS Code of Ethics.   \n727 Guidelines:   \n728 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n729 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n730 deviation from the Code of Ethics.   \n731 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n732 eration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "733 10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "736 Answer: [Yes]   \n737 Justification: See Appendix A.2   \n738 Guidelines:   \n739 \u2022 The answer NA means that there is no societal impact of the work performed.   \n740 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n741 impact or why the paper does not address societal impact.   \n742 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n743 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n744 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n745 groups), privacy considerations, and security considerations.   \n746 \u2022 The conference expects that many papers will be foundational research and not tied   \n747 to particular applications, let alone deployments. However, if there is a direct path to   \n748 any negative applications, the authors should point it out. For example, it is legitimate   \n749 to point out that an improvement in the quality of generative models could be used to   \n750 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n751 that a generic algorithm for optimizing neural networks could enable people to train   \n752 models that generate Deepfakes faster.   \n753 \u2022 The authors should consider possible harms that could arise when the technology is   \n754 being used as intended and functioning correctly, harms that could arise when the   \n755 technology is being used as intended but gives incorrect results, and harms following   \n756 from (intentional or unintentional) misuse of the technology.   \n757 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n758 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n759 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n760 feedback over time, improving the efficiency and accessibility of ML).   \n761 11. Safeguards   \n762 Question: Does the paper describe safeguards that have been put in place for responsible   \n763 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n764 image generators, or scraped datasets)?   \n765 Answer: [No]   \n766 Justification: To ensure future responsible release, we are still in the process of implementing   \n767 comprehensive safeguards.   \n768 Guidelines:   \n769 \u2022 The answer NA means that the paper poses no such risks.   \n770 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n771 necessary safeguards to allow for controlled use of the model, for example by requiring   \n772 that users adhere to usage guidelines or restrictions to access the model or implementing   \n773 safety filters.   \n774 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n775 should describe how they avoided releasing unsafe images.   \n776 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n777 not require this, but we encourage authors to take this into account and make a best   \n778 faith effort.   \n779 12. Licenses for existing assets   \n780 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n781 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n782 properly respected?   \n783 Answer: [Yes]   \n784 Justification: All existing assets used in this paper are properly credited. The license and   \n785 terms of use are properly respected.   \n786 Guidelines:   \n787 \u2022 The answer NA means that the paper does not use existing assets.   \n788 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n789 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n790 URL.   \n791 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n792 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n793 service of that source should be provided. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Justification: Once authorization is obtained, we will ensure that comprehensive documentation is provided alongside the assets to facilitate their proper use and understanding. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 23}, {"type": "text", "text": "834 Question: Does the paper describe potential risks incurred by study participants, whether   \n835 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n36 approvals (or an equivalent approval/review based on the requirements of your country or   \n837 institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}]