[{"figure_path": "wWguwYhpAY/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration comparing between INR architectures for (a) traditional INR, (b) Vanilla MoE INR and (c) Our Neural Experts. Two key elements of our approach include the conditioning and pretraining of the manager that improve signal reconstruction with fewer parameters.", "description": "This figure compares three different architectures for implicit neural representations (INRs): a traditional INR using a single MLP, a vanilla MoE INR that naively applies the MoE approach, and the proposed Neural Experts architecture.  The key difference in the proposed method is the addition of conditioning and pretraining for the manager network, which significantly improves performance and reduces the number of parameters needed for accurate signal reconstruction. The figure clearly illustrates the flow of information in each architecture.", "section": "3 Mixture of Experts for Implicit Neural Representations"}, {"figure_path": "wWguwYhpAY/figures/figures_4_1.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure shows a comparison of image reconstruction results using different methods: ground truth (GT), SoftPlus, SoftPlus Wider, SoftPlus MoE (proposed method), SIREN, SIREN Wider, Naive MoE, and SIREN MoE.  The left side displays qualitative results showing the reconstructed image, its gradient, and its Laplacian. The right side provides quantitative results showing the Peak Signal-to-Noise Ratio (PSNR) over training epochs.  The results demonstrate the superiority of the proposed Neural Experts architecture.", "section": "4 Neural Experts Experimental Results"}, {"figure_path": "wWguwYhpAY/figures/figures_6_1.jpg", "caption": "Figure 3: Audio reconstruction visualization. Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visualization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.", "description": "This figure compares audio reconstruction results using three different methods: SIREN, SIREN Wider, and the proposed Neural Experts method.  Each method's reconstruction is displayed alongside the ground truth audio signal for two-speaker audio. The error between the reconstruction and the ground truth is also shown. The Neural Experts method uses color-coding to visually represent different \"experts\" that contribute to the final reconstruction.", "section": "4.2 Audio signal reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_6_2.jpg", "caption": "Figure 3: Audio reconstruction visualization. Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visualization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.", "description": "This figure visualizes the audio reconstruction results for three different methods: SIREN, SIREN Wider, and the proposed Neural Experts model.  Each section shows a waveform block with three rows: the ground truth audio, the reconstructed audio, and the error between the two. The Neural Experts approach uses color-coding to highlight which expert was responsible for reconstructing which parts of the waveform, demonstrating its ability to divide the task among specialized subnetworks.", "section": "4.2 Audio signal reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_6_3.jpg", "caption": "Figure 3: Audio reconstruction visualization. Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visualization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.", "description": "This figure compares the audio reconstruction results from three different methods: SIREN, SIREN Wider, and the proposed Neural Experts model. Each row in the figure shows the ground truth, the reconstruction, and the reconstruction error for a specific audio segment. The color-coding in the Neural Experts reconstruction highlights which expert was responsible for each part of the reconstruction.", "section": "4.2 Audio signal reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_6_4.jpg", "caption": "Figure 3: Audio reconstruction visualization. Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visualization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.", "description": "This figure visualizes the audio reconstruction results for three different methods: SIREN, SIREN Wider, and the proposed Neural Experts model. Each row in each waveform block represents a different stage: ground truth, reconstruction, and reconstruction error.  The Neural Experts model uses different colored lines to represent individual experts in the reconstruction, highlighting the method's ability to partition the signal and reconstruct the components separately.", "section": "4.2 Audio signal reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_6_5.jpg", "caption": "Figure 3: Audio reconstruction visualization. Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visualization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.", "description": "This figure visualizes the audio reconstruction results for three different methods: SIREN, SIREN Wider, and the proposed Neural Experts method.  Each section shows three waveforms: ground truth, reconstruction, and error.  The Neural Experts section highlights the contribution of individual experts by color-coding their respective parts of the reconstruction. This demonstrates the method's ability to divide the audio signal into meaningful sub-regions and process each sub-region independently.", "section": "4.2 Audio signal reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_7_1.jpg", "caption": "Figure 5: 3D surface reconstruction. Results on the Thai Statue shape. Our method noticeably captures more detail in the toes, nostrils, and eye. The error colormap shows that our method produces a mesh with far less large errors (lighter indicates higher distance to the ground truth surface), and the expert segmentation shows our method provides a subdivision of the space.", "description": "This figure shows a comparison of 3D surface reconstruction results between the proposed Neural Experts method and a SIREN baseline on the Thai Statue shape.  Three visualizations are provided: the output mesh (reconstructed surface), an error colormap highlighting reconstruction errors, and a final expert segmentation illustrating how different parts of the shape were handled by different experts in the MoE architecture. The Neural Experts method is shown to reconstruct finer details and exhibit fewer large errors compared to the SIREN model, showcasing the effectiveness of the proposed approach in capturing complex geometric structures. The colormap visually demonstrates the distribution of errors, and the expert segmentation highlights the spatial division of labor among experts, indicating localized modeling of the shape.", "section": "4.3 Surface reconstruction results"}, {"figure_path": "wWguwYhpAY/figures/figures_8_1.jpg", "caption": "Figure 6: Manager pretraining. Visualizing the experts selected by the manager after the pretraining stage (top row) and after the full network training (bottom row) for different pretraining ablations.", "description": "This figure visualizes the expert selection process during pretraining and after full training for different pretraining methods. Each column represents a different pretraining method: None, SAM, Kmeans, Grid, and Random. The top row shows the expert selection before any training on the reconstruction task, while the bottom row shows the final expert selection after training. Each color represents the region assigned to a specific expert.  The figure demonstrates how different pretraining strategies lead to different initial expert assignments and how these assignments evolve during the training process. The differences highlight the influence of pretraining on the final segmentation of the input space and potentially the performance of the reconstruction.", "section": "4.4 Ablation study"}, {"figure_path": "wWguwYhpAY/figures/figures_14_1.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure shows a comparison of image reconstruction results using different methods. The left side displays qualitative results, showing the reconstructed image, its gradient, and its Laplacian for each method. The right side shows a quantitative comparison based on PSNR (Peak Signal-to-Noise Ratio) over training epochs. The results demonstrate that the proposed \"Neural Experts\" approach, particularly with Sine activations, significantly outperforms existing baselines in image reconstruction.", "section": "4.1 Image reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_15_1.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure presents a comparison of image reconstruction results using different methods: ground truth (GT), SoftPlus, SoftPlus Wider, SoftPlus Mixture of Experts (MoE), SIREN, SIREN Wider, Naive MoE, and SIREN MoE.  Both qualitative (image, gradients, Laplacian) and quantitative (PSNR over training epochs) results are shown.  The quantitative results demonstrate the superior performance of the proposed Neural Experts approach, particularly when using Sine activations.", "section": "4 Neural Experts Experimental Results"}, {"figure_path": "wWguwYhpAY/figures/figures_15_2.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure shows a comparison of image reconstruction results between different methods: ground truth (GT), SoftPlus, SoftPlus Wider, SoftPlus MoE (Mixture of Experts), SIREN, SIREN Wider, Naive MoE, and SIREN MoE.  Qualitative results (left) display the reconstructed images, their gradients, and Laplacian matrices for each method. Quantitative results (right) show the Peak Signal-to-Noise Ratio (PSNR) over training epochs.  The results demonstrate that the Neural Experts architecture using Sine activations achieves superior performance.", "section": "4.1 Image reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_15_3.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure compares image reconstruction results of different methods, including the proposed Neural Experts. Qualitative results in the left panel show reconstructed images, their gradients, and Laplacians (a measure of image sharpness). The right panel shows the quantitative comparison using PSNR (Peak Signal-to-Noise Ratio) for several models with different activation functions. The proposed method achieves the highest PSNR, demonstrating its superior performance in image reconstruction.", "section": "4.1 Image reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_16_1.jpg", "caption": "Figure 2: Image reconstruction. Qualitative (left) and quantitative (right) results. Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE, (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN MoE. The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.", "description": "This figure shows a comparison of image reconstruction results using different methods: ground truth (GT), SoftPlus, SoftPlus Wider, SoftPlus Mixture of Experts (MoE), SIREN, SIREN Wider, Naive MoE, and SIREN MoE.  The left side displays qualitative results showing the reconstructed image, its gradients, and its Laplacian. The right side shows quantitative results, specifically the Peak Signal-to-Noise Ratio (PSNR) over training epochs.  The results demonstrate that the proposed Neural Experts architecture, particularly with Sine activations, achieves superior performance.", "section": "4.1 Image reconstruction"}, {"figure_path": "wWguwYhpAY/figures/figures_17_1.jpg", "caption": "Figure 1: Illustration comparing between INR architectures for (a) traditional INR, (b) Vanilla MoE INR and (c) Our Neural Experts. Two key elements of our approach include the conditioning and pretraining of the manager that improve signal reconstruction with fewer parameters.", "description": "This figure compares three different architectures for implicit neural representations (INRs).  (a) shows a traditional INR using a single multi-layer perceptron (MLP). (b) illustrates a naive mixture-of-experts (MoE) approach, where multiple experts are used but without the crucial conditioning and pretraining of the manager network proposed in the paper. (c) presents the authors' proposed \"Neural Experts\" architecture, which incorporates a conditioned and pretrained manager network to significantly improve performance. The key improvements in (c) are highlighted as key elements of their approach.", "section": "3 Mixture of Experts for Implicit Neural Representations"}, {"figure_path": "wWguwYhpAY/figures/figures_19_1.jpg", "caption": "Figure 5: 3D surface reconstruction. Results on the Thai Statue shape. Our method noticeably captures more detail in the toes, nostrils, and eye. The error colormap shows that our method produces a mesh with far less large errors (lighter indicates higher distance to the ground truth surface), and the expert segmentation shows our method provides a subdivision of the space.", "description": "This figure shows the results of 3D surface reconstruction on the Thai Statue shape using the proposed Neural Experts method and compares it to the SIREN method. The figure includes three parts: the output mesh, the error colormap, and the expert segmentation. The output mesh visually demonstrates the reconstruction of the Thai statue shape. The error colormap shows the difference between the reconstructed surface and the ground truth surface. Warmer colors indicate larger errors, and cooler colors indicate smaller errors. Expert segmentation shows which expert in the model was responsible for reconstructing each part of the shape.", "section": "4.3 Surface reconstruction results"}, {"figure_path": "wWguwYhpAY/figures/figures_20_1.jpg", "caption": "Figure 5: 3D surface reconstruction. Results on the Thai Statue shape. Our method noticeably captures more detail in the toes, nostrils, and eye. The error colormap shows that our method produces a mesh with far less large errors (lighter indicates higher distance to the ground truth surface), and the expert segmentation shows our method provides a subdivision of the space.", "description": "This figure compares the 3D surface reconstruction results between the proposed Neural Experts method and the SIREN baseline method on the Thai Statue shape.  The figure shows three aspects for each method: the output mesh, the error colormap (showing the distance to the ground truth surface, with lighter colors indicating smaller errors), and the expert segmentation (showing how the input space was divided among different expert networks in the Neural Experts method). The results demonstrate the ability of the Neural Experts model to capture finer details, resulting in a mesh with significantly fewer large errors compared to SIREN.", "section": "4.3 Surface reconstruction results"}, {"figure_path": "wWguwYhpAY/figures/figures_21_1.jpg", "caption": "Figure 15: Surface reconstruction results on the Lucy shape. Our method performs overall better but in particular at the torch region where there are high levels of detail.", "description": "This figure compares the results of surface reconstruction on the Lucy shape using three different methods: SIREN Large, Our Neural Experts Large (the proposed method), and Our Neural Experts Large.  Each method's output mesh, error colormap, and expert segmentation are shown. The colormaps visualize the difference between the reconstructed surface and the ground truth. The expert segmentation shows how different subnetworks (experts) contribute to the overall reconstruction. The results demonstrate that the proposed method, Our Neural Experts Large, achieves better overall reconstruction quality, especially in high-detail areas such as the torch.", "section": "4.3 Surface reconstruction results"}, {"figure_path": "wWguwYhpAY/figures/figures_22_1.jpg", "caption": "Figure 1: Illustration comparing between INR architectures for (a) traditional INR, (b) Vanilla MoE INR and (c) Our Neural Experts. Two key elements of our approach include the conditioning and pretraining of the manager that improve signal reconstruction with fewer parameters.", "description": "This figure compares three different architectures for Implicit Neural Representations (INRs): a traditional INR using a single MLP, a vanilla MoE INR, and the proposed Neural Experts architecture.  The key difference is the introduction of a manager network in the MoE and Neural Experts models, which routes the input to different expert networks. The Neural Experts method further enhances this by incorporating conditioning and pretraining techniques for the manager network, improving signal reconstruction and reducing the number of parameters needed.", "section": "3 Mixture of Experts for Implicit Neural Representations"}]