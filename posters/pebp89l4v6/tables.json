[{"figure_path": "pebP89l4v6/tables/tables_5_1.jpg", "caption": "Table 1: GPU memory footprint of different Table 2: Single-image motion deblurring results. Go- implementations (i.e., Triton, Torch-Gather, Pro [62] dataset is used for training. and Torch-Mask) of our key-graph attention block. N is the number of tokens and k is the number of nearest neighbors. OOM denotes \"out of memory\".", "description": "This table compares the GPU memory usage of three different implementations (Triton, Torch-Gather, and Torch-Mask) for the key-semantic attention block in the SemanIR model. The comparison is made for different numbers of tokens (N) and nearest neighbors (k). The results show that Triton uses significantly less memory than the other two methods, but it has some limitations in terms of speed and back-propagation complexity. The Torch-Gather method uses more memory than Torch-Mask, but also faces issues with large numbers of tokens.  The Torch-Mask offers a good balance between efficiency and practicality.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/tables/tables_5_2.jpg", "caption": "Table 2: Single-image motion deblurring results. GoPro [62] dataset is used for training.", "description": "This table presents the results of single-image motion deblurring experiments.  The GoPro dataset was used for training the models. The table compares various methods by their performance on the GoPro and HIDE datasets, measured using PSNR and SSIM metrics.  Higher PSNR and SSIM values indicate better deblurring performance.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/tables/tables_6_1.jpg", "caption": "Table 2: Single-image motion deblurring results. GoPro [62] dataset is used for training.", "description": "This table presents the quantitative results of single-image motion deblurring experiments.  The GoPro dataset was used for training the models. The results are compared against several state-of-the-art methods, showing the PSNR and SSIM values achieved on the GoPro and HIDE test datasets.  Higher PSNR and SSIM values generally indicate better image quality.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/tables/tables_6_2.jpg", "caption": "Table 3: The efficiency comparisons results on Urban100 dataset.", "description": "This table compares the efficiency of SemanIR with other state-of-the-art image restoration methods on the Urban100 dataset.  The metrics used for comparison include the number of parameters (Params), floating point operations (FLOPs), runtime, and peak signal-to-noise ratio (PSNR).  The results show that SemanIR achieves competitive PSNR performance while being faster and using fewer parameters than some comparable methods, highlighting its efficiency.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/tables/tables_7_1.jpg", "caption": "Table 2: Single-image motion deblurring results. GoPro [62] dataset is used for training.", "description": "This table presents the results of single-image motion deblurring experiments.  The GoPro dataset was used for training the models. The table shows the performance (PSNR and SSIM) of various methods on the GoPro and HIDE datasets, indicating how well each method can deblur images.  Higher PSNR and SSIM values suggest better deblurring performance.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/tables/tables_7_2.jpg", "caption": "Table 5: Gray image denoising PSNR.", "description": "This table presents the Peak Signal-to-Noise Ratio (PSNR) values for gray image denoising.  The PSNR is a metric used to evaluate the quality of reconstructed images compared to the ground truth, with higher values indicating better quality. The table shows the PSNR values for three different datasets (Set12, BSD68, Urban100) and three different window sizes (8, 16, 32).", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/tables/tables_7_3.jpg", "caption": "Table 6: Color image denoising PSNR.", "description": "This table presents the Peak Signal-to-Noise Ratio (PSNR) results for color image denoising on four datasets (Mcmaster, CBSD68, Kodak24, Urban100) using three different window sizes (8, 16, 32).  It demonstrates the impact of window size on denoising performance.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/tables/tables_8_1.jpg", "caption": "Table 2: Single-image motion deblurring results. GoPro [62] dataset is used for training.", "description": "This table presents the quantitative results of single image motion deblurring experiments using the GoPro dataset for training.  It compares the performance of SemanIR against other state-of-the-art methods on two standard metrics, PSNR and SSIM, across different datasets (GoPro and HIDE). The table shows the PSNR and SSIM scores achieved by each method, allowing for a direct comparison of their performance in deblurring images.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/tables/tables_8_2.jpg", "caption": "Table 8: IR in adverse weather conditions.", "description": "This table presents the quantitative results for image restoration in adverse weather conditions.  Specifically, it compares the performance of several different methods (pix2pix, HRGAN, SwinIR, MPRNet, All-in-One, TransWea, and SemanIR) on three different datasets representing various adverse weather conditions: Test1 (rain+fog), SnowTest100k-L (snow), and RainDrop (raindrops). The primary metric used for comparison is PSNR (Peak Signal-to-Noise Ratio), which measures the quality of the restored image.", "section": "4.2 Evaluation of SemanIR on Various IR Tasks"}, {"figure_path": "pebP89l4v6/tables/tables_8_3.jpg", "caption": "Table 8: IR in adverse weather conditions.", "description": "This table presents the quantitative results for image restoration in adverse weather conditions. The results are reported for three different datasets: Test1 (rain+fog), SnowTest100k-L, and RainDrop.  The metrics used are PSNR. The comparison methods include pix2pix [31], DesnowNet [52], AttGAN [66], MMNet [38], DDR [88], HRGAN [45], JSTASR [12], Quan [68], DeepJoint [26], SwinIR [50], MPRNet [94], RLDDR [29], DRUNet [99], All-in-One [46], RNAN [109], TransWea. [83], GRL [48], and SemanIR (Ours).", "section": "4.2 Evaluation of SemanIR on Various IR Tasks"}, {"figure_path": "pebP89l4v6/tables/tables_9_1.jpg", "caption": "Table 10: Classical image SR results. Both lightweight and accurate models are summarized.", "description": "This table presents the performance of various classical image super-resolution (SR) models on four benchmark datasets (Set5, Set14, BSD100, and Urban100), along with the Manga109 dataset.  The results are categorized by model, upscaling factor (2x or 4x), number of parameters, and Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores for each dataset.  The table distinguishes between lightweight and accurate models, providing a comprehensive comparison of different SR approaches.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/tables/tables_17_1.jpg", "caption": "Table 11: The details of the transformer stages and layers per stage of SemanIR for both architectures.", "description": "This table shows the number of SemanIR stages and the number of SemanIR layers within each stage for two different architectures: Archi-V1 (columnar shape) and Archi-V2 (U-shape).  Archi-V1 is used for image super-resolution, while Archi-V2 is used for other image restoration tasks.  The table provides details for two SemanIR variations: SemanIR-small and SemanIR-base, along with a breakdown of down stages, up stages, and a final stage for the U-shaped architecture.", "section": "A.2 Model Architecture"}, {"figure_path": "pebP89l4v6/tables/tables_18_1.jpg", "caption": "Table 1: GPU memory footprint of different Table 2: Single-image motion deblurring results. Go-implementations (i.e., Triton, Torch-Gather, Pro [62] dataset is used for training.and Torch-Mask) of our key-graph attentionblock. N is the number of tokens and k isthe number of nearest neighbors. OOMdenotes \"out of memory\".", "description": "This table compares the GPU memory usage of three different implementations (Triton, Torch-Gather, Torch-Mask) of the key-graph attention block in the SemanIR model.  It shows how memory consumption varies with different numbers of tokens (N) and nearest neighbors (k). The results demonstrate that the Triton implementation has a smaller memory footprint than the other two, although it sacrifices some performance. This section provides insights into the efficiency of various attention mechanisms.", "section": "4.1 Ablation Study"}]