[{"figure_path": "pebP89l4v6/figures/figures_1_1.jpg", "caption": "Figure 1: (a) The CNN filter captures information only within a local region. (b) The standard MLP/Transformer architectures take full input in a long-sequence manner. (c) The window-size multi-head self-attention (MSA) mechanism builds a full connection within each window. (d) Position-fixed sparse connection. (e) The proposed Key-Semantic connection.", "description": "This figure compares different methods of processing image information in image restoration tasks. (a) shows the local receptive field of a CNN, which limits its ability to capture long-range dependencies. (b) shows a standard MLP/Transformer that processes the entire image as a long sequence, which can be computationally expensive. (c) shows a window-based MSA that focuses on local regions but still builds a full connection within each window. (d) demonstrates a position-fixed sparse connection, which reduces computation but might miss important long-range relationships. Finally, (e) illustrates the proposed Key-Semantic connection, which aims to find and connect semantically similar patches, regardless of their relative location, making it efficient and effective.", "section": "1 Introduction"}, {"figure_path": "pebP89l4v6/figures/figures_3_1.jpg", "caption": "Figure 2: The proposed SemanIR mainly consists of a convolutional feature extractor, the main body of SemanIR for representation learning, and an image reconstructor. The main body in columnar shape shown here is for image SR, while the U-shaped structure (shown in Appx. A.2) is used for other IR tasks. (b) The transformer layer of our SemanIR. The toy example of k=3 for (c) the Key-semantic dictionary construction and (d) the attention of each Layer.", "description": "This figure illustrates the overall architecture of the proposed SemanIR model for image restoration. It showcases the main components: a convolutional feature extractor, the core SemanIR module (which can be either columnar or U-shaped, depending on the task), and an image reconstructor.  The figure also zooms into the key-semantic transformer layer, detailing the key-semantic dictionary construction and the key-semantic attention mechanism.  The example (c) and (d) demonstrate how the sparse key-semantic dictionary is constructed using KNN for a limited set of semantically related patches instead of a full connectivity and how this dictionary is used for the attention mechanism to reduce computational cost.", "section": "3 Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_6_1.jpg", "caption": "Figure 4: The impact of k with different inference k value.", "description": "This figure shows the impact of the k parameter (number of nearest neighbors) on the attention mechanism's performance in SemanIR. It displays activation maps for different k values, illustrating how the model focuses on semantically related regions as k increases.  The results demonstrate a balance, where increasing k beyond a certain point includes less relevant regions, highlighting the effectiveness of the key-semantic dictionary in focusing attention on semantically meaningful components.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/figures/figures_9_1.jpg", "caption": "Figure 6: Visual comparison of classical image SR (4\u00d7) on Urban100. Best viewed by zooming.", "description": "This figure compares the visual results of different super-resolution (SR) methods on the Urban100 dataset, specifically at a 4x upscaling factor.  It showcases the input low-resolution (LR) images and the results produced by SwinIR, ART, CAT-A, EDT, and the proposed SemanIR method. The ground truth high-resolution (HR) images are also included for comparison. The images are displayed in a way that allows for a direct visual comparison of the different methods. Zooming in on the image is recommended for better analysis.", "section": "4.2 Evaluation of SemanIR on Various IR Tasks"}, {"figure_path": "pebP89l4v6/figures/figures_17_1.jpg", "caption": "Figure 7: The U-shaped hierarchical architecture (Archi-V2) of the proposed SemanIR for Image Restoration. Note that this U-shaped one is used for image JPEG CAR, image denoising, image demosaicking, IR in AWC, and image deblurring. Symbols and denote the element-wise addition and channel-wise concatenation. The downsample and upsample operations are denoted by red and green arrows.", "description": "This figure shows the U-shaped architecture of SemanIR used for image restoration tasks except for image super-resolution. It consists of a feature extractor, multiple SemanIR stages at different scales (downsampling and upsampling), and an image reconstructor. Each SemanIR stage contains several key-semantic transformer layers to extract and share key semantic information for efficient image restoration. The U-shape design allows the model to capture both local and global features, leading to improved performance. ", "section": "3 Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_19_1.jpg", "caption": "Figure 3: The impact of k with different inference k value. Circle size represents FLOPs.", "description": "This figure shows the impact of the parameter 'k' (number of nearest neighbors) on the performance of the SemanIR model for four different image restoration tasks: color image denoising, gray image denoising, color image JPEG compression artifact removal, and gray image JPEG compression artifact removal.  Each subplot displays the PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index) scores achieved by SemanIR using different 'k' values (64, 128, 192, 256, 384, 512) during inference. The size of each circle in the plot corresponds to the number of FLOPs (floating-point operations) used. This helps visualize the tradeoff between performance and computational cost.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/figures/figures_20_1.jpg", "caption": "Figure 3: The impact of k with different inference k value. Circle size represents FLOPs.", "description": "This figure displays the impact of the k parameter (number of nearest neighbors) on the performance of the SemanIR model for four different image restoration tasks: color image denoising, grayscale image denoising, color image JPEG compression artifact removal, and grayscale image JPEG compression artifact removal.  Each subfigure shows a plot of PSNR (Peak Signal-to-Noise Ratio) against different values of k during inference. Two training strategies, fixed top-k and random top-k, are compared.  The size of the circles in the plot represents the FLOPs (floating point operations), illustrating the computational cost associated with each k value.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/figures/figures_20_2.jpg", "caption": "Figure 7: The U-shaped hierarchical architecture (Archi-V2) of the proposed SemanIR for Image Restoration. Note that this U-shaped one is used for image JPEG CAR, image denoising, image demosaicking, IR in AWC, and image deblurring. Symbols and denote the element-wise addition and channel-wise concatenation. The downsample and upsample operations are denoted by red and green arrows.", "description": "This figure shows the U-shaped architecture used in SemanIR for image restoration tasks other than image super-resolution. It illustrates the flow of data through different stages, including feature extraction, multiple SemanIR stages (with downsampling and upsampling), and final image reconstruction.  The use of U-shape structure enables the network to capture multi-scale features and contextual information for more accurate restoration.", "section": "3 Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_21_1.jpg", "caption": "Figure 3: The impact of k with different inference k value. Circle size represents FLOPs.", "description": "This figure shows the impact of the hyperparameter k (number of nearest neighbors) on the performance of the SemanIR model across different inference k values.  Four subfigures represent results for different image restoration tasks (color image denoising, gray image denoising, color image JPEG compression artifact removal, and gray image JPEG compression artifact removal). Each subfigure shows PSNR and SSIM scores as a function of k for both fixed top-k and random top-k training strategies.  The size of the circles in the graphs corresponds to the number of FLOPs (floating-point operations) required for each k value, visually representing the computational cost.", "section": "4.1 Ablation Study"}, {"figure_path": "pebP89l4v6/figures/figures_22_1.jpg", "caption": "Figure 2: The proposed SemanIR mainly consists of a convolutional feature extractor, the main body of SemanIR for representation learning, and an image reconstructor. The main body in columnar shape shown here is for image SR, while the U-shaped structure (shown in Appx. A.2) is used for other IR tasks. (b) The transformer layer of our SemanIR. The toy example of k=3 for (c) the Key-semantic dictionary construction and (d) the attention of each Layer.", "description": "This figure shows the overall architecture of SemanIR, a novel image restoration method using key-semantic information sharing in transformers.  It highlights the main components: a convolutional feature extractor, the key-semantic transformer layers (with a detailed view of a single layer showing key-semantic dictionary construction and attention mechanism), and an image reconstructor.  The figure illustrates the columnar architecture used for image super-resolution (SR) and mentions a U-shaped architecture used for other image restoration (IR) tasks (detailed in Appendix A.2).", "section": "Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_23_1.jpg", "caption": "Figure 13: Visual comparison for restoring images in AWC. Best viewed by zooming.", "description": "This figure shows a visual comparison of image restoration results for images degraded by adverse weather conditions (AWC). The comparison includes the input image (Raining Input), results from three state-of-the-art methods (RESCAN, All-in-One, TransWeather), and the results from the proposed SemanIR method.  The green boxes highlight specific regions of interest, demonstrating how each method handles different aspects of AWC degradation.  Zooming in is recommended to fully appreciate the detail.", "section": "4.2 Evaluation of SemanIR on Various IR Tasks"}, {"figure_path": "pebP89l4v6/figures/figures_24_1.jpg", "caption": "Figure 2: The proposed SemanIR mainly consists of a convolutional feature extractor, the main body of SemanIR for representation learning, and an image reconstructor. The main body in columnar shape shown here is for image SR, while the U-shaped structure (shown in Appx. A.2) is used for other IR tasks. (b) The transformer layer of our SemanIR. The toy example of k=3 for (c) the Key-semantic dictionary construction and (d) the attention of each Layer.", "description": "This figure shows the architecture of the proposed SemanIR model for image restoration.  It consists of three main parts: a convolutional feature extractor, the main body (SemanIR) for learning representations, and an image reconstructor.  The main body can be columnar (for super-resolution) or U-shaped (for other tasks, shown in Appendix A.2). Part (b) details a SemanIR transformer layer, showing how key-semantic dictionaries are constructed (c) and used in attention calculations (d) to focus on only semantically related image patches.", "section": "Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_25_1.jpg", "caption": "Figure 15: Visual comparison of color JPEG CAR on Urban100 dataset. Best viewed by zooming.", "description": "This figure compares the performance of different methods (DRUNet, SwinIR, GRL, and SemanIR) on the task of JPEG compression artifact removal.  The results are shown for six different images from the Urban100 dataset.  Each row represents a different image, and the columns show the original image, results from each method, and the ground truth. The figure highlights the effectiveness of SemanIR in restoring image quality and reducing compression artifacts.", "section": "4 Experiments"}, {"figure_path": "pebP89l4v6/figures/figures_26_1.jpg", "caption": "Figure 2: The proposed SemanIR mainly consists of a convolutional feature extractor, the main body of SemanIR for representation learning, and an image reconstructor. The main body in columnar shape shown here is for image SR, while the U-shaped structure (shown in Appx. A.2) is used for other IR tasks. (b) The transformer layer of our SemanIR. The toy example of k=3 for (c) the Key-semantic dictionary construction and (d) the attention of each Layer.", "description": "This figure illustrates the architecture of the proposed SemanIR model for image restoration. It consists of three main components: a convolutional feature extractor, the main body of SemanIR (which can be either columnar or U-shaped depending on the task), and an image reconstructor. The columnar architecture is used for image super-resolution, while the U-shaped architecture is used for other image restoration tasks such as deblurring and denoising.  The figure also shows a detailed view of the key-semantic transformer layer, highlighting the key-semantic dictionary construction and the attention mechanism.", "section": "Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_27_1.jpg", "caption": "Figure 7: The U-shaped hierarchical architecture (Archi-V2) of the proposed SemanIR for Image Restoration. Note that this U-shaped one is used for image JPEG CAR, image denoising, image demosaicking, IR in AWC, and image deblurring. Symbols and denote the element-wise addition and channel-wise concatenation. The downsample and upsample operations are denoted by red and green arrows.", "description": "This figure shows the U-shaped architecture used in SemanIR for image restoration tasks.  It illustrates the flow of image features through convolutional layers, multiple SemanIR stages at different scales (downsampled and upsampled), and the final image reconstruction stage.  This architecture is specifically used for JPEG CAR, image denoising, image demosaicking, IR in adverse weather conditions (AWC), and image deblurring. The arrows depict downsampling and upsampling operations, while symbols represent element-wise addition and concatenation.", "section": "3 Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_28_1.jpg", "caption": "Figure 2: The proposed SemanIR mainly consists of a convolutional feature extractor, the main body of SemanIR for representation learning, and an image reconstructor. The main body in columnar shape shown here is for image SR, while the U-shaped structure (shown in Appx. A.2) is used for other IR tasks. (b) The transformer layer of our SemanIR. The toy example of k=3 for (c) the Key-semantic dictionary construction and (d) the attention of each Layer.", "description": "This figure illustrates the architecture of the proposed SemanIR model for image restoration. It consists of three main components: a convolutional feature extractor, the main body (SemanIR) for representation learning which uses a columnar architecture for image super-resolution (SR) and a U-shaped architecture for other image restoration tasks, and an image reconstructor.  The figure also shows details of the key-semantic transformer layer, including the key-semantic dictionary construction and the attention mechanism.", "section": "Methodology"}, {"figure_path": "pebP89l4v6/figures/figures_29_1.jpg", "caption": "Figure 6: Visual comparison of classical image SR (4\u00d7) on Urban100. Best viewed by zooming.", "description": "This figure shows a visual comparison of different image super-resolution (SR) methods on the Urban100 dataset at a scaling factor of 4x. It compares the results of SwinIR, ART, CAT-A, EDT, and SemanIR, highlighting the visual differences in terms of detail and structural preservation.  It demonstrates the effectiveness of SemanIR in achieving a high-quality SR result.", "section": "Evaluation on SR"}]