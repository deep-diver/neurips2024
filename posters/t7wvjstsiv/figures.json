[{"figure_path": "t7wvJstsiV/figures/figures_0_1.jpg", "caption": "Figure 1: Factuality decoding overview.", "description": "This figure illustrates the overview of factuality decoding.  The left side shows implicit learning where the LLM acquires latent knowledge (what the LLM knows) from training data. This latent knowledge is then leveraged during inference through factuality decoding, which aims to align the LLM's output distribution (what the LLM tells) with the real-world factuality distribution. The right side highlights the explicit training process where the LLM is explicitly trained on real-world factuality, resulting in an output distribution optimized to reflect factual correctness.  The dotted lines show that the real-world distribution is only indirectly incorporated through the LLM's implicit learning.", "section": "1 Introduction"}, {"figure_path": "t7wvJstsiV/figures/figures_1_1.jpg", "caption": "Figure 2: Illustration of our Self Logits-Evolution Decoding (SLED) workflow.", "description": "This figure illustrates the Self Logits Evolution Decoding (SLED) workflow.  The process starts by contrasting the output logits from the final layer of an LLM with those from earlier layers (8th, 16th, and 24th layers shown). This comparison helps uncover the latent knowledge within the LLM.  A latent knowledge distribution (Platent) is then estimated, which represents the model's implicit understanding of the real-world factuality distribution. Finally, this latent knowledge is used to refine the final layer's logits through a self-evolution process, aiming to align the model's output distribution more closely with real-world facts, resulting in improved factual accuracy.", "section": "2 Self Logits Evolution Decoding"}, {"figure_path": "t7wvJstsiV/figures/figures_2_1.jpg", "caption": "Figure 3: We analyze the next-token predictions of three LLaMA-2-base models using the logits from each layer individually. This analysis is performed on 200 true claims from the FACTOR dataset. The results verify that the logits distribution at the final layer is closer to the real-world distribution than all the early layers in terms of KL divergence.", "description": "This figure shows the KL divergence between the logits distribution of each layer and the real-world factuality distribution for three different sizes of LLaMA-2 base models.  The x-axis represents the layer index, and the y-axis represents the KL divergence.  The results show that the KL divergence decreases as the layer index increases, indicating that the final layer's logits distribution is closer to the real-world distribution than those of the early layers.", "section": "2 Self Logits Evolution Decoding"}, {"figure_path": "t7wvJstsiV/figures/figures_4_1.jpg", "caption": "Figure 4: An example from GSM8K demonstrating SLED\u2019s mechanism. SLED derives the estimations P(n)latent by contrasting final layer\u2019s logits logitsN with early layers\u2019 logits {logitsn}. We list the token with the highest probability value from the P(n)latent for different early layers. As shown, SLED downplays incorrect tokens by assigning lower weights s(n) to the corresponding P(n)latent. Conversely, if the estimation is correct, the weights are relatively larger. The parameter evaluation scale is set to 2.", "description": "This figure shows an example of how SLED works using the GSM8K dataset.  It illustrates the core concept of SLED: contrasting the logits (predicted probabilities) from the final layer of the LLM with those from earlier layers to identify and correct factual errors.  The figure highlights how SLED assigns weights to the probability distributions from each layer, giving higher weights to layers where the prediction is more accurate (closer to the ground truth) and lower weights to layers with inaccurate predictions, effectively guiding the model towards a more factual output.  The example shows how this process leads to the correct answer.", "section": "2.3 Achieving the Self Logits Evolution in Three Phases"}, {"figure_path": "t7wvJstsiV/figures/figures_9_1.jpg", "caption": "Figure 3: We analyze the next-token predictions of three LLaMA-2-base models using the logits from each layer individually. This analysis is performed on 200 true claims from the FACTOR dataset. The results verify that the logits distribution at the final layer is closer to the real-world distribution than all the early layers in terms of KL divergence.", "description": "This figure displays the KL divergence between the logits distribution of each layer and the real-world distribution for three different sized LLAMA-2 models.  The results show that the KL divergence is consistently lower for the final layer than for any of the earlier layers, indicating that the final layer's logits distribution is a better approximation of the real-world distribution.", "section": "2 Self Logits Evolution Decoding"}, {"figure_path": "t7wvJstsiV/figures/figures_9_2.jpg", "caption": "Figure 3: We analyze the next-token predictions of three LLaMA-2-base models using the logits from each layer individually. This analysis is performed on 200 true claims from the FACTOR dataset. The results verify that the logits distribution at the final layer is closer to the real-world distribution than all the early layers in terms of KL divergence.", "description": "This figure shows the KL divergence between the logits distribution of each layer in three different sized LLAMA-2 base models and the real-world distribution.  The x-axis represents the layer index, and the y-axis shows the KL divergence.  The results demonstrate that as the model processes through more layers (moving towards the final layer), the output logits distribution increasingly aligns with the real-world factuality distribution. This suggests the model progressively incorporates factual knowledge stored within its layers during decoding.", "section": "2 Self Logits Evolution Decoding"}, {"figure_path": "t7wvJstsiV/figures/figures_15_1.jpg", "caption": "Figure 7: We collect 10k pairs of (logitsn -logitsN, \u2207logitsnKL(Preal, Plogitsn)) on different tokens in FACTOR and different early layers. We calculate their cosine similarity values and draw the density function for each LLM. Most of the pairs have positive Cosine similarity values.", "description": "This figure shows the distribution of cosine similarity between the difference of early layer logits and final layer logits (logitsn - logitsN) and the gradient of KL divergence between the real-world distribution and the output distribution at early layer logits (\u2207logitsnKL(Preal, Plogitsn)).  A positive cosine similarity indicates that the direction of logitsn - logitsN approximates the gradient, supporting the paper's claim that this difference can be used to estimate the gradient during the self-logits evolution process.", "section": "A Additional Analysis and Ablation Studies"}]