[{"figure_path": "F7tGQ7b10q/figures/figures_1_1.jpg", "caption": "Figure 1: (a) The PCA [16] visualization of honesty-related (top) and harm-related (bottom) hidden state of top layer embeddings extracted from the final token in Llama2-7b's outputs. The harm-related queries come from the previous study [15]. (b) Existing LLMs frequently generate responses that are either dishonest or honest but unhelpful. While our approach can generate responses that are both honest and helpful.", "description": "This figure shows two visualizations. The first (a) uses Principal Component Analysis (PCA) to show how embeddings of honest and harmful queries differ in Llama2-7b.  The second (b) is a diagram that illustrates the potential response types of LLMs in handling a query and how the proposed method aims to improve honesty and helpfulness.  It highlights the difference between dishonest answers, honest but unhelpful responses, and the desired honest and helpful response.", "section": "1 Introduction"}, {"figure_path": "F7tGQ7b10q/figures/figures_3_1.jpg", "caption": "Figure 2: Different categories in HONESET.", "description": "This figure shows a pie chart that visually represents the distribution of queries across six different categories within the HONESET dataset. Each slice of the pie chart corresponds to one category: Latest Information with External Services, User Input Not Enough Or With Wrong Information, Modality Mismatch, Interactivity Sensory Processing, Professional Capability in Specific Domains, and Self-identity Cognition.  The size of each slice is proportional to the number of queries in that category.  The numerical values for the number of queries in each category are also provided.", "section": "3 HONESET: A New Dataset"}, {"figure_path": "F7tGQ7b10q/figures/figures_4_1.jpg", "caption": "Figure 1: (a) The PCA [16] visualization of honesty-related (top) and harm-related (bottom) hidden state of top layer embeddings extracted from the final token in Llama2-7b's outputs. The harm-related queries come from the previous study [15]. (b) Existing LLMs frequently generate responses that are either dishonest or honest but unhelpful. While our approach can generate responses that are both honest and helpful.", "description": "This figure shows the visualization of honesty and harm related queries using PCA on Llama2-7b's output embeddings.  Panel (a) shows how honesty and harm are represented in the model's embedding space, based on the final token of the model's output for each query. Panel (b) illustrates the difference between existing LLMs and the proposed HonestLLM framework. Existing LLMs often produce dishonest answers or honest but unhelpful answers. In contrast, the proposed framework aims to generate responses that are both honest and helpful.", "section": "1 Introduction"}, {"figure_path": "F7tGQ7b10q/figures/figures_6_1.jpg", "caption": "Figure 4: Comprehensive evaluation results of the training-free method.", "description": "This figure presents a comprehensive evaluation of the training-free method using three different assessment metrics. Subfigure (a) shows the honesty rate across nine LLMs before and after applying the training-free method. Subfigure (b) displays a pairwise comparison of the H\u00b2 assessment (honest and helpful) scores before and after applying the method.  Finally, subfigure (c) presents the H\u00b2 scores broken down into three dimensions (Explanation, Solution, Guidance) and shows the improvement achieved using the training-free method.", "section": "5.2 Main Results"}, {"figure_path": "F7tGQ7b10q/figures/figures_6_2.jpg", "caption": "Figure 4: Comprehensive evaluation results of the training-free method.", "description": "This figure presents a comprehensive evaluation of the training-free method, showcasing its impact on honesty rates and helpfulness across various LLMs.  Panel (a) displays the honesty rate for each model before and after applying the training-free method. Panel (b) shows the pairwise comparison results of the H\u00b2 (honest and helpful) assessment, indicating the preference between original and optimized responses. Finally, panel (c) provides a detailed score breakdown for the three dimensions of H\u00b2 assessment: Explanation, Solution, and Guidance.", "section": "5.2 Main Results"}, {"figure_path": "F7tGQ7b10q/figures/figures_18_1.jpg", "caption": "Figure 6: Distributions of data in HONESET", "description": "The figure shows the distribution of data lengths and self-BLEU scores in the HONESET dataset. The length distribution shows that most queries are between 10 and 20 words long, with some variation across categories. The self-BLEU scores show that HONESET has relatively high diversity, indicating that the queries are not all similar to each other. This is important because it means that HONESET can be used to evaluate a wide range of LLMs, and that the results will be more generalizable.", "section": "B Dataset Analysis"}, {"figure_path": "F7tGQ7b10q/figures/figures_18_2.jpg", "caption": "Figure 6: Distributions of data in HONESET", "description": "This figure visualizes the length distribution and self-BLEU score of the HONESET dataset across six categories. The length distribution shows that most queries fall within the 10-20 word range. The self-BLEU score indicates the diversity of the queries; a lower score implies higher diversity, and HONESET shows relatively high diversity across categories.", "section": "Dataset Analysis"}, {"figure_path": "F7tGQ7b10q/figures/figures_21_1.jpg", "caption": "Figure 1: (a) The PCA [16] visualization of honesty-related (top) and harm-related (bottom) hidden state of top layer embeddings extracted from the final token in Llama2-7b's outputs. The harm-related queries come from the previous study [15]. (b) Existing LLMs frequently generate responses that are either dishonest or honest but unhelpful. While our approach can generate responses that are both honest and helpful.", "description": "This figure shows the results of Principal Component Analysis (PCA) on the hidden states of Llama2-7b model's outputs for honesty and harm-related queries.  The PCA visualization in (a) helps to understand the relationship between honesty and harm in the model's responses. Panel (b) illustrates a framework summarizing the differences between existing LLMs, which often produce dishonest or unhelpful responses, and the proposed approach, which aims for both honest and helpful responses.", "section": "1 Introduction"}, {"figure_path": "F7tGQ7b10q/figures/figures_22_1.jpg", "caption": "Figure 1: (a) The PCA [16] visualization of honesty-related (top) and harm-related (bottom) hidden state of top layer embeddings extracted from the final token in Llama2-7b's outputs. The harm-related queries come from the previous study [15]. (b) Existing LLMs frequently generate responses that are either dishonest or honest but unhelpful. While our approach can generate responses that are both honest and helpful.", "description": "This figure visualizes the results of Principal Component Analysis (PCA) on the hidden states of Llama2-7b's outputs for honesty-related and harm-related queries.  The top panel (a) shows the PCA for honesty-related queries, demonstrating how different queries cluster based on their honesty-related embedding features. The bottom panel (a) presents similar PCA results for harm-related queries. Panel (b) illustrates the different response patterns of existing LLMs vs. the proposed method. Existing LLMs often produce responses that are either dishonest or honest but unhelpful.  The authors' approach aims to generate responses that are both honest and helpful.", "section": "1 Introduction"}, {"figure_path": "F7tGQ7b10q/figures/figures_22_2.jpg", "caption": "Figure 3: The overall pipeline incorporates both training-free and fine-tuning methods to ensure honesty and enhance helpfulness simultaneously.", "description": "This figure illustrates the overall workflow of the proposed approach, which combines training-free and fine-tuning methods to enhance the honesty and helpfulness of LLMs. The training-free method uses curiosity-driven prompting to optimize LLM responses, while the fine-tuning method employs a two-stage process inspired by curriculum learning. The first stage focuses on teaching LLMs to differentiate between honest and dishonest responses, while the second stage focuses on improving the overall quality and helpfulness of responses. The pipeline shows the flow of data through each stage and the methods used in each stage to achieve the desired results. ", "section": "4 Methodology"}, {"figure_path": "F7tGQ7b10q/figures/figures_23_1.jpg", "caption": "Figure 1: (a) The PCA [16] visualization of honesty-related (top) and harm-related (bottom) hidden state of top layer embeddings extracted from the final token in Llama2-7b's outputs. The harm-related queries come from the previous study [15]. (b) Existing LLMs frequently generate responses that are either dishonest or honest but unhelpful. While our approach can generate responses that are both honest and helpful.", "description": "This figure shows two visualizations. (a) uses Principal Component Analysis (PCA) to show the relationship between honesty and harm in the responses generated by the Llama2-7b language model.  The PCA is applied to the hidden state embeddings of the final tokens in the model's responses.  (b) illustrates a framework that compares the responses of existing Large Language Models (LLMs) with the responses of the proposed model.  Existing LLMs often produce responses that are either dishonest or honest but unhelpful, while the proposed model aims to generate responses that are both honest and helpful.", "section": "1 Introduction"}]