[{"figure_path": "fOLNl52Q5U/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with some SOTA methods. RN101 refers to ResNet101 [16], DN53 denotes DarkNet53 [52], ViT-B/32 means ViT-Base [11] with stride of 32 in visual embedding. * denotes testing with a NVIDIA RTX 3090 GPU, while other entries are tested with a GTX 1080Ti GPU. SimVG-TB and SimVG-DB refer to the SimVG model using only the token and decoder branch for inference, respectively.", "description": "This table compares the performance of SimVG against other state-of-the-art (SOTA) visual grounding models on six widely used datasets (RefCOCO, RefCOCO+, RefCOCOg, ReferIt, Flickr30k, and GRefCOCO).  The results are presented in terms of Precision@0.5 (for RefCOCO, RefCOCO+, RefCOCOg, ReferIt, and Flickr30K) and Precision@(F1=1, IoU\u22650.5) and N-acc (for GRefCOCO).  The table also indicates the visual encoder used (ResNet101, DarkNet53, VGG16, or ViT-Base), inference time (in milliseconds), and whether an RTX 3090 or GTX 1080Ti GPU was used for testing.  It also shows results for SimVG using only the token branch (SimVG-TB) and only the decoder branch (SimVG-DB) for comparison.", "section": "4.3 Comparison with The State-of-the-art"}, {"figure_path": "fOLNl52Q5U/tables/tables_7_1.jpg", "caption": "Table 2: GREC benchmark results on GRefCOCO dataset. Threshold is set to 0.7 for all the methods.", "description": "This table presents a comparison of different methods' performance on the GRefCOCO dataset for the GREC (general referring expression comprehension) task.  The performance is measured using Precision@(F1@0.5) and N-acc (no-target accuracy), with an IoU threshold of 0.7. The table shows the visual and textual encoders used by each method along with its performance on the validation set and test sets (testA and testB).  SimVG-TB and SimVG-DB represent different variations of the proposed SimVG model.", "section": "4.3 Comparison with The State-of-the-art"}, {"figure_path": "fOLNl52Q5U/tables/tables_7_2.jpg", "caption": "Table 1: Comparison with some SOTA methods. RN101 refers to ResNet101 [16], DN53 denotes DarkNet53 [52], ViT-B/32 means ViT-Base [11] with stride of 32 in visual embedding. * denotes testing with a NVIDIA RTX 3090 GPU, while other entries are tested with a GTX 1080Ti GPU. SimVG-TB and SimVG-DB refer to the SimVG model using only the token and decoder branch for inference, respectively.", "description": "This table compares the performance of SimVG with other state-of-the-art (SOTA) visual grounding models on several benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, ReferIt, Flickr30K).  It shows the results for different model architectures (two-stage, one-stage, transformer-based), visual encoders (ResNet, DarkNet, ViT), and measures performance using various metrics (val, testA, testB, etc.).  The table also indicates the inference time and the GPU used for testing, clarifying differences in computational efficiency.", "section": "4.3 Comparison with The State-of-the-art"}, {"figure_path": "fOLNl52Q5U/tables/tables_7_3.jpg", "caption": "Table 1: Comparison with some SOTA methods. RN101 refers to ResNet101 [16], DN53 denotes DarkNet53 [52], ViT-B/32 means ViT-Base [11] with stride of 32 in visual embedding. * denotes testing with a NVIDIA RTX 3090 GPU, while other entries are tested with a GTX 1080Ti GPU. SimVG-TB and SimVG-DB refer to the SimVG model using only the token and decoder branch for inference, respectively.", "description": "This table compares the performance of SimVG with other state-of-the-art (SOTA) visual grounding methods across several benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, ReferIt, Flickr30K).  It shows the performance (val, testA, testB) for each method, specifying the backbone used (ResNet, DarkNet, ViT), and the inference time. The table also highlights the improvements achieved by using only the token branch (SimVG-TB) or decoder branch (SimVG-DB) of the SimVG model.", "section": "4.3 Comparison with The State-of-the-art"}, {"figure_path": "fOLNl52Q5U/tables/tables_8_1.jpg", "caption": "Table 5: Ablation studies related to TQG module in the token and decoder branches.", "description": "This table presents the ablation study results focusing on the Text-guided Query Generation (TQG) module. It compares the performance of the token branch and decoder branch with and without the TQG module, and with different variations of the TQG module (Baseline, TQG, Mask Max Pool, TQG) to show how the performance improves by incorporating textual information into queries.", "section": "4.4.2 Text-guided Query Generation"}, {"figure_path": "fOLNl52Q5U/tables/tables_8_2.jpg", "caption": "Table 6: Ablation studies related to DWBD module, including one/two stage distillation results.", "description": "This table presents the ablation study results focusing on the Dynamic Weight-Balance Distillation (DWBD) module. It compares different distillation methods, including one-stage and two-stage approaches.  The methods are compared based on their performance on the RefCOCO validation set, testA and testB splits. The numbers in parentheses indicate the absolute improvement over the baseline.", "section": "4.4 Ablation Studies"}, {"figure_path": "fOLNl52Q5U/tables/tables_18_1.jpg", "caption": "Table 1: Comparison with some SOTA methods. RN101 refers to ResNet101 [16], DN53 denotes DarkNet53 [52], ViT-B/32 means ViT-Base [11] with stride of 32 in visual embedding. * denotes testing with a NVIDIA RTX 3090 GPU, while other entries are tested with a GTX 1080Ti GPU. SimVG-TB and SimVG-DB refer to the SimVG model using only the token and decoder branch for inference, respectively.", "description": "This table compares the performance of SimVG with other state-of-the-art (SOTA) visual grounding models on four benchmark datasets: RefCOCO, RefCOCO+, RefCOCOg, and ReferIt.  The table shows the performance (in terms of validation and test accuracy) of each model, categorized by whether it is a two-stage, one-stage, or transformer-based approach.  It also lists the backbone network used for the visual encoder (e.g., RN101, DN53, VGG16, ViT-B/16, ViT-B/32), the inference time in milliseconds, and whether the model was tested on a NVIDIA RTX 3090 GPU or a GTX 1080Ti GPU.  The SimVG-TB and SimVG-DB columns show the performance of SimVG using only the token branch and only the decoder branch, respectively.", "section": "4.3 Comparison with The State-of-the-art"}, {"figure_path": "fOLNl52Q5U/tables/tables_18_2.jpg", "caption": "Table 1: Comparison with some SOTA methods. RN101 refers to ResNet101 [16], DN53 denotes DarkNet53 [52], ViT-B/32 means ViT-Base [11] with stride of 32 in visual embedding. * denotes testing with a NVIDIA RTX 3090 GPU, while other entries are tested with a GTX 1080Ti GPU. SimVG-TB and SimVG-DB refer to the SimVG model using only the token and decoder branch for inference, respectively.", "description": "This table compares the performance of SimVG with other state-of-the-art (SOTA) visual grounding methods on several benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, ReferIt, Flickr30k).  It shows precision scores (val, testA, testB) for different models, along with the type of visual encoder used (RN101, DN53, ViT-B/16, ViT-B/32, ViT-L/32) and the inference time. The table highlights SimVG's improved performance and efficiency compared to two-stage, one-stage, and transformer-based methods.  SimVG-TB and SimVG-DB results show the performance of using either the token or decoder branch independently. The GPU used for testing is also indicated.", "section": "4.3 Comparison with The State-of-the-art"}]