[{"figure_path": "7v0UyO0B6q/figures/figures_7_1.jpg", "caption": "Figure 2: Evaluation of DiffTS on three synthetic problems. The first row shows samples from the true (blue) and diffusion model (red) priors. The second row shows the regret of DiffTS and the baselines as a function of round n.", "description": "This figure presents a comparison of the performance of the proposed DiffTS algorithm against several baseline algorithms on three different synthetic contextual bandit problems.  The top row displays scatter plots visualizing samples drawn from the true prior distribution (blue dots) and the learned diffusion model prior (red dots) for each problem. The bottom row shows line graphs illustrating the cumulative regret (y-axis) over rounds (x-axis). The regret, a measure of the algorithm's performance, is plotted for DiffTS and the baseline algorithms (TS, TunedTS, MixTS, DPS). This allows for a visual comparison of DiffTS's performance against different approaches in terms of regret, illustrating its efficacy in handling various complex prior distributions.", "section": "6 Experiments"}, {"figure_path": "7v0UyO0B6q/figures/figures_8_1.jpg", "caption": "Figure 3: Evaluation of DiffTS on the MovieLens dataset.", "description": "This figure shows the results of the MovieLens experiment, comparing DiffTS with other Thompson sampling baselines (TS, TunedTS, MixTS, and DPS). Subfigure (a) visualizes the learned diffusion prior against the original prior, showing their similarity. Subfigures (b) and (c) present the regret curves for linear and logistic bandit settings, respectively. DiffTS consistently outperforms the baselines, demonstrating its effectiveness in handling high-dimensional data.", "section": "6 Experiments"}, {"figure_path": "7v0UyO0B6q/figures/figures_17_1.jpg", "caption": "Figure 4: Evaluation of DiffTS on another three synthetic problems. The first row shows samples from the true (blue) and diffusion model (red) priors. The second row shows the regret of DiffTS and the baselines as a function of round n.", "description": "This figure presents the results of the DiffTS algorithm on three different synthetic problems, each showing a unique prior distribution.  The top row displays the true and learned diffusion model priors visually, illustrating the similarity between the two. The bottom row presents a graph comparing the cumulative regret of DiffTS against several baseline algorithms (TS, TunedTS, MixTS, and DPS) over a range of rounds (n). This allows for a direct comparison of DiffTS's performance against established methods in handling different prior distributions.", "section": "6.2 Synthetic Experiment"}, {"figure_path": "7v0UyO0B6q/figures/figures_17_2.jpg", "caption": "Figure 5: Evaluation of DiffTS on the MNIST dataset.", "description": "The figure shows the results of an experiment on the MNIST dataset, comparing the performance of DiffTS against other methods.  Subfigure (a) displays a visualization comparing the learned diffusion prior and the original prior using UMAP projection. Subfigures (b) and (c) show the regret curves for linear and logistic bandit settings, respectively, comparing DiffTS to TS, TunedTS, MixTS baselines. DiffTS demonstrates lower regret than the others.", "section": "6 Experiments"}, {"figure_path": "7v0UyO0B6q/figures/figures_18_1.jpg", "caption": "Figure 6: An ablation study of DiffTS on the cross problem: (a) regret with a varying number of samples for training the diffusion prior, (b) regret with a varying number of diffusion stages T, and (c) computation time with a varying number of diffusion stages T.", "description": "This figure presents an ablation study evaluating the performance of the DiffTS algorithm across three different aspects: the number of training samples used for the diffusion prior, the number of diffusion stages (T), and the computational time required per run.  The results are visualized in three separate subplots. (a) shows how the regret changes with different training sample sizes; (b) illustrates the relationship between regret and the number of diffusion steps; and (c) displays the computational cost (time) as a function of the number of diffusion steps.", "section": "C.3 Ablation Studies"}, {"figure_path": "7v0UyO0B6q/figures/figures_18_2.jpg", "caption": "Figure 7: Evaluation on Gaussian mixture variants of the synthetic problems in Figure 2. The first row shows samples from the true (blue) and diffusion model (red) priors. The second row shows the earth mover's distance of DiffTS and baseline posterior distributions from the true posterior as a function of sample size n.", "description": "This figure presents a comparison of different Thompson Sampling algorithms on three synthetic bandit problems with Gaussian mixture priors. The top row visualizes samples from the true and learned diffusion priors for each problem, showcasing the similarity between them. The bottom row displays the Earth Mover's Distance (EMD) between the posterior distributions obtained using various methods (including DiffTS, the proposed approach) and the true posterior distribution, plotted as a function of the sample size (n).  This demonstrates the accuracy and stability of the proposed method, showing that its posterior approximation converges to the true posterior as the sample size increases, outperforming other methods in terms of accuracy.", "section": "6 Experiments"}]