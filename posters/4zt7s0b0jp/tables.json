[{"figure_path": "4Zt7S0B0Jp/tables/tables_3_1.jpg", "caption": "Table 2: CoT-decoding reliably extracts the CoT-paths compared to other methods (on PaLM-2 L).", "description": "This table compares the performance of different methods for extracting chain-of-thought (CoT) paths from the top 10 decoded paths of a language model.  The methods compared are greedy decoding, ranking by the model's highest log-probability, ranking by the model's highest length-normalized log-probability, and CoT-decoding (ranking by the model's answer confidence). The results are shown for two datasets: GSM8K (top 100) and Year Parity.  CoT-decoding demonstrates significantly better performance in identifying CoT paths compared to the other methods.", "section": "2.2 CoT-Decoding for Extracting CoT Paths"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_3_2.jpg", "caption": "Table 3: CoT-decoding and self-consistency w/o prompts on GSM8K.", "description": "This table compares the performance of greedy decoding, self-consistency without CoT prompting, and CoT-decoding on the GSM8K dataset.  It highlights the superior performance of CoT-decoding in eliciting chain-of-thought reasoning without relying on explicit prompting techniques. The results demonstrate that CoT-decoding significantly improves accuracy compared to the other methods.", "section": "2.2 CoT-Decoding for Extracting CoT Paths"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_5_1.jpg", "caption": "Table 4: CoT-decoding is the only decoding strategy that can effectively elicit language models' reasoning.", "description": "This table compares the performance of various decoding strategies on the GSM8K benchmark.  The strategies include several sampling methods (Top-k, Top-p/Nucleus, Temperature), beam search, greedy decoding, and self-consistency (without CoT prompting).  The key finding is that CoT-decoding significantly outperforms all other methods, demonstrating its effectiveness in eliciting reasoning capabilities from language models.", "section": "3.1 CoT-Decoding Effectively Elicits Reasoning from Language Models"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_6_1.jpg", "caption": "Table 5: CoT-decoding improves both pre-trained and instruction-tuned Mistral-7B models.", "description": "This table presents the accuracy results of different decoding methods on three reasoning tasks: GSM8K, MultiArith, and Year Parity. It compares the performance of greedy decoding and CoT-decoding on both pre-trained and instruction-tuned Mistral-7B models. The results show that CoT-decoding significantly improves the accuracy of both types of models on all three tasks, highlighting the effectiveness of the proposed method in eliciting reasoning capabilities from language models.", "section": "3.2 CoT-decoding Enables a Better Understanding of Model's Intrinsic Reasoning Abilities"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_7_1.jpg", "caption": "Table 6: The model's intrinsic reasoning ability varies depending on the task difficulty levels.", "description": "This table shows the accuracy of the greedy decoding method and the CoT-decoding method on various reasoning tasks with different difficulty levels.  The tasks are categorized into Coin Flip (with varying rounds of flips), Web of Lies (with varying numbers of statements), Multi-step Arithmetic (with varying depth and length), Sports Understanding, and Object Count.  The results demonstrate that CoT-decoding generally improves accuracy compared to greedy decoding, but the degree of improvement varies depending on the complexity of the task.", "section": "3.2 CoT-decoding Enables a Better Understanding of Model's Intrinsic Reasoning Abilities"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_7_2.jpg", "caption": "Table 7: Adding CoT-decoding on top of zero-shot CoT-prompting can further boost the reasoning performance on both models. The accuracy number here is computed over the GSM8K test set.", "description": "This table compares the performance of different decoding methods on the GSM8K dataset, both with and without zero-shot CoT prompting.  It shows that combining CoT-decoding (either max or aggregated path) with zero-shot CoT prompting significantly improves accuracy compared to using either method alone.  The computational complexity of each method is also indicated.", "section": "3.3 Combining CoT-decoding with CoT-Prompting"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_15_1.jpg", "caption": "Table 4: CoT-decoding is the only decoding strategy that can effectively elicit language models' reasoning.", "description": "This table compares the effectiveness of different decoding strategies (greedy decoding, top-k sampling, top-p sampling, beam search, temperature sampling, self-consistency without CoT prompting, and CoT-decoding) on the GSM8K accuracy.  It highlights that CoT-decoding is the only method that substantially improves the reasoning capabilities of language models, while other strategies either yield minimal gains or even hurt performance compared to greedy decoding. ", "section": "3.1 CoT-Decoding Effectively Elicits Reasoning from Language Models"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_16_1.jpg", "caption": "Table 1: Examples of greedy decoded paths and alternative top-k paths over the PaLM-2 Large model. The model's confidence over the answers (bolded) are highlighted in blue (See \u00a72.2 for details).", "description": "This table shows examples of greedy decoding paths and alternative top-k paths for two reasoning tasks: GSM8K (math reasoning) and Year Parity (commonsense reasoning).  The model's confidence in each answer is shown in parentheses; higher confidence is represented by a bolder font.  The table highlights that simply altering the decoding process (from greedy to top-k) can reveal inherent chain-of-thought (CoT) reasoning paths, which are often absent in the greedy approach.", "section": "2.1 Pre-trained Language Models Can Reason without Prompting"}, {"figure_path": "4Zt7S0B0Jp/tables/tables_17_1.jpg", "caption": "Table 4: CoT-decoding is the only decoding strategy that can effectively elicit language models' reasoning.", "description": "This table compares the effectiveness of different decoding strategies in eliciting reasoning capabilities from language models.  It shows that only CoT-decoding consistently achieves high accuracy, while other methods like top-k sampling, nucleus sampling, beam search, and temperature sampling yield lower accuracy or even hurt the model's performance.  This highlights the unique ability of CoT-decoding to extract the inherent reasoning abilities of LLMs.", "section": "3.1 CoT-Decoding Effectively Elicits Reasoning from Language Models"}]