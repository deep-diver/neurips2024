[{"figure_path": "aCaspFfAhG/figures/figures_33_1.jpg", "caption": "Figure 1: Instance with  Amin = 0.03 and all the gaps small.", "description": "The figure shows the cumulative regret of different algorithms (EC, DREE with different delta values, and RLPE) over time.  The instance used has a minimum gap (Amin) of 0.03 between the expected rewards of the arms, and all gaps are relatively small. The shaded areas represent the 95% confidence intervals over 50 runs.  The plot demonstrates the performance of these algorithms in a scenario with small reward differences.", "section": "D Numerical evaluation"}, {"figure_path": "aCaspFfAhG/figures/figures_33_2.jpg", "caption": "Figure 1: Instance with Amin = 0.03 and all the gaps small.", "description": "The figure shows the cumulative regret of different algorithms (EC, DREE with different delta values, and RLPE) over time for a bandit problem instance with a minimum gap (Amin) of 0.03 and all other gaps being small.  The shaded area around each line represents the 95% confidence interval across 50 runs. The graph illustrates how the different algorithms perform in terms of cumulative regret.", "section": "D Numerical evaluation"}, {"figure_path": "aCaspFfAhG/figures/figures_34_1.jpg", "caption": "Figure 1: Instance with Amin = 0.03 and all the gaps small.", "description": "The figure shows the cumulative regret of different algorithms (EC, DREE with different delta values, and RLPE) for a bandit problem instance with a small minimum gap (Amin = 0.03) between the expected rewards of the arms. The x-axis represents the time horizon (T), and the y-axis shows the cumulative regret.  The shaded regions represent the 95% confidence interval over 50 independent runs. This plot illustrates how the algorithms perform when all the gaps between the arms' expected rewards are relatively small.", "section": "D Numerical evaluation"}, {"figure_path": "aCaspFfAhG/figures/figures_34_2.jpg", "caption": "Figure 1: Instance with  Amin = 0.03 and all the gaps small.", "description": "The figure shows the cumulative regret for different bandit algorithms over time.  The algorithms include EC, DREE with different delta parameters (1, 1.5, 2), and RLPE. The instance used has a minimum gap (Amin) of 0.03, meaning that the difference between the expected rewards of the best and second-best arms is relatively small. This is a stochastic setting with Gaussian noise. The shaded regions represent the 95% confidence intervals. ", "section": "D Numerical evaluation"}]