{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a groundbreaking model that significantly advanced the field of vision-language alignment, serving as a foundational model for many subsequent works, including the current paper."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2023-04-01", "reason": "DINOv2 is used as the visual backbone for LexVLA due to its ability to learn local-inclined features, a key element in the improved performance of LexVLA."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-01", "reason": "Llama 2 is leveraged in LexVLA for its in-context lexical prediction capabilities, enhancing the model's interpretability and performance."}, {"fullname_first_author": "Aaron van den Oord", "paper_title": "Representation learning with contrastive predictive coding", "publication_date": "2018-07-01", "reason": "The InfoNCE loss function, based on contrastive predictive coding, is employed as the main objective in LexVLA's training process."}, {"fullname_first_author": "Tsung-Yi Lin", "paper_title": "Microsoft COCO: Common Objects in Context", "publication_date": "2014-09-01", "reason": "The MS COCO dataset is used for evaluating LexVLA's patch-level interpretability, a key aspect of the model's performance and contribution."}]}