[{"figure_path": "xoCFd1WKpf/figures/figures_1_1.jpg", "caption": "Figure 1: LexVLA can generate a lexical representation of the input image (the first word cloud figure), or to pick some patches of the image for local lexical information representation (the second word cloud figure, with the seleted patches boxed in red), and to select the most relevant patches of the image given the text content (the rightmost figure, with caption 'horse', with the second-to-last figure is the ground-truth mask).", "description": "This figure illustrates LexVLA's ability to generate lexical representations in three different ways.  The first shows a word cloud representing the entire image's lexical representation. The second shows a word cloud for specific image patches, highlighted in red. The third demonstrates how LexVLA selects the most relevant image patches given a text caption, comparing the selected patches to a ground truth mask.", "section": "1 Introduction"}, {"figure_path": "xoCFd1WKpf/figures/figures_2_1.jpg", "caption": "Figure 2: Framework of LexVLA. We learn a unified lexical representation with distinct codebooks for text and visual modalities. For the image, we adopt the frozen DINOv2, learn an adapter and a mapper to get visual lexical representation. For the text, we use LoRA to fine-tune the Llama 2 on in-context lexical prediction task, followed with a mapper to get the text lexical representation. We initialize codebooks as Llama 2's codebook, freeze the text codebook while fine-tuning the visual codebook. We train LexVLA with the standard contrastive objectives along with the proposed overuse penalty to encourage sparsity while preventing meaningless activation.", "description": "This figure illustrates the architecture of the LexVLA model.  It shows how two pre-trained models (DINOv2 for vision and Llama 2 for text) are integrated and fine-tuned.  The visual branch uses a frozen DINOv2 backbone with an added adapter and mapper to project into the shared lexical space.  The text branch fine-tunes Llama 2 using LoRA, and also employs a mapper. Both branches use distinct codebooks, initialized by Llama 2's codebook, but the text codebook is frozen during training. The training process involves standard contrastive objectives to align visual and textual lexical representations, along with an overuse penalty to promote sparsity and avoid activating meaningless words.", "section": "3 LexVLA"}, {"figure_path": "xoCFd1WKpf/figures/figures_7_1.jpg", "caption": "Figure 3: PatchDis visualization. The same color indicates the same category. LexVLA correctly predicts the corresponding region, even for the small-scale objects, like the bottle in the first image.", "description": "This figure visualizes the PatchDis metric, which evaluates the patch-level interpretability of the LexVLA model.  It shows three example images, each with its ground truth segmentation mask and the mask predicted by the LexVLA model. The results show that LexVLA accurately predicts the locations of various objects, including small objects, demonstrating its effectiveness at patch-level image understanding.", "section": "3.4 PatchDis: interpretability metric"}, {"figure_path": "xoCFd1WKpf/figures/figures_7_2.jpg", "caption": "Figure 4: Visualization of the image lexical representation obtained by LexVLA. Larger word indicates larger lexical value. The first row represents the complete image, and the second row represent local patches (boxed in red). LexVLA learns a well-aligned lexical representation for both image and patches without local supervision.", "description": "This figure visualizes the image lexical representations generated by LexVLA. The top row shows word clouds representing the complete image, while the bottom row displays word clouds for specific image patches (highlighted in red boxes).  The size of each word in the word clouds is proportional to its lexical value, indicating the importance of the corresponding word to the image or patch. Notably, LexVLA achieves this alignment without relying on local supervision.", "section": "4.2 Lexical representation analysis"}, {"figure_path": "xoCFd1WKpf/figures/figures_8_1.jpg", "caption": "Figure 5: Retrieval in different sparse levels. We compare LexVLA with VDR in the same sparse levels and with CLIP as a proxy of dense latent alignment. The first row is results in the Flickr30K dataset, and the second in the MSCOCO dataset. The first to the third columns show the settings of Recall@1, Recall@5, and Recall@10, respectively. Purple symbols represent CLIP.", "description": "This figure compares the performance of LexVLA and VDR at various sparsity levels on Flickr30K and MSCOCO datasets.  It shows how recall@1, recall@5, and recall@10 change as the average sparsity (quadratic measure) increases. CLIP is included as a baseline representing a dense model. The results demonstrate LexVLA's robustness to increasing sparsity, maintaining high performance even with a significant reduction in non-zero elements in the lexical representation.", "section": "4.3 Further analysis"}, {"figure_path": "xoCFd1WKpf/figures/figures_9_1.jpg", "caption": "Figure 6: Visualization of lexical representations of LexVLA w/ FLOPs loss and w/ our proposed overuse penalty, respectively. The first row represents images while the second is caption. LexVLA w/ FLOPs loss usually falsely activates similar meaningless tokens frequently as a shortcut (see '@' and 'contemporary' outlined by green boxes as examples). LexVLA w/ overuse penalty significantly mitigate this false activation issue.", "description": "This figure visualizes the lexical representations generated by LexVLA using two different penalty methods: FLOPs loss and the proposed overuse penalty.  The comparison highlights how the overuse penalty effectively reduces the activation of irrelevant tokens, improving the quality and interpretability of the lexical representations.  The word clouds show the most prominent words activated by each method for different image-caption pairs. The images are shown in the first row, and their corresponding captions are in the second. Green boxes indicate examples of falsely activated tokens that the overuse penalty helps to mitigate.", "section": "4.3 Further analysis"}]