[{"type": "text", "text": "RoPINN: Region Optimized Physics-Informed Neural Networks ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Haixu Wu, Huakun Luo, Yuezhou Ma, Jianmin Wang, Mingsheng Long ", "page_idx": 0}, {"type": "text", "text": "School of Software, BNRist, Tsinghua University, China {wuhx23,luohk19,mayz20}@mails.tsinghua.edu.cn, {jimwang,mingsheng}@tsinghua.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Physics-informed neural networks (PINNs) have been widely applied to solve partial differential equations (PDEs) by enforcing outputs and gradients of deep models to satisfy target equations. Due to the limitation of numerical computation, PINNs are conventionally optimized on finite selected points. However, since PDEs are usually defined on continuous domains, solely optimizing models on scattered points may be insufficient to obtain an accurate solution for the whole domain. To mitigate this inherent deficiency of the default scatter-point optimization, this paper proposes and theoretically studies a new training paradigm as region optimization. Concretely, we propose to extend the optimization process of PINNs from isolated points to their continuous neighborhood regions, which can theoretically decrease the generalization error, especially for hidden high-order constraints of PDEs. A practical training algorithm, Region Optimized PINN (RoPINN), is seamlessly derived from this new paradigm, which is implemented by a straightforward but effective Monte Carlo sampling method. By calibrating the sampling process into trust regions, RoPINN finely balances optimization and generalization error. Experimentally, RoPINN consistently boosts the performance of diverse PINNs on a wide range of PDEs without extra backpropagation or gradient calculation. Code is available at this repository: https://github.com/thuml/RoPINN. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Solving partial differential equations (PDEs) is the key problem in extensive areas, covering both engineering and scientific research [38, 40, 49]. Due to the inherent complexity of PDEs, they usually cannot be solved analytically [10]. Thus, a series of numerical methods have been widely explored, such as spectral methods [22, 40] or finite element methods [5, 7]. However, these numerical methods usually suffer from huge computational costs and can only obtain an approximate solution on discretized meshes [26, 43]. Given the impressive nonlinear modeling capability of deep models [4, 14], they have also been applied to solve PDEs, where physics-informed neural networks (PINNs) are proposed and have emerged as a promising and effective surrogate tool for numerical methods [44, 36, 35]. By formalizing PDE constraints (i.e. equations, initial and boundary conditions) as objective functions, the outputs and gradients of PINNs will be optimized to satisfy a certain PDE during training [36], which successfully instantiates the PDE solution as a deep model. ", "page_idx": 0}, {"type": "text", "text": "Although deep models have been proven to enjoy the universal approximation capability, the actual optimization process of PINNs still faces thorny challenges [8, 24, 35]. As a basic topic of PINNs, the optimization problem has been widely explored from various aspects [17, 44]. Previous methods attempt to mitigate this problem by using novel architectures to enhance model capacity [58, 3, 50], reweighting multiple loss functions for more balanced convergence [47], resampling data to improve important areas [51] or developing new optimizers to tackle the rough loss landscape [55, 37], etc. ", "page_idx": 0}, {"type": "table", "img_path": "wZigMVFURk/tmp/70691315ecbccd8ac06de3e8b294369f683fad8f26f3e9482b03d6cba5853828.jpg", "table_caption": [], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Orthogonal to the above-mentioned methods, this paper focuses on a foundational problem, which is the objective function of PINNs. We notice that, due to the limitation of numerical calculation, it is almost impossible to optimize the loss function in the complete continuous domain. Thus, the conventional PINN loss is only defined on a series of selected points [36] (Figure 1). However, the scatter-point loss function obviously mismatches the PDE-solving objective, which is approximating the solution on a continuous domain. This mismatch may fundamentally limit the performance of PINNs. Several prior works also try to improve the canonical PINN loss function, which can be roughly categorized into the following two paradigms. One paradigm enhances the optimization by adding high-order derivatives of PDEs as a regularization term to the loss function [55]. However, calculating high-order gradients is numerically unstable and time-consuming, even with automatic differentiation in well-established deep learning frameworks [2, 34]. The other paradigm attempts to bypass the high-order derivative calculation in the PINN loss function with variational formulations [18, 19, 20]. Nevertheless, these variational methods still face difficulties in calculating the integral of deep models and will bring extra computations, thereby mainly limited to very shallow models or relying on massive sampled quadrature points and elaborative test functions [11, 57]. ", "page_idx": 1}, {"type": "text", "text": "This paper proposes and studies a new training paradigm for PINNs as region optimization. As shown in Figure 1, we extend the optimization process from selected scatter points into their neighborhood regions, which can theoretically decrease the generalization error on the whole domain, especially for hidden high-order constraints of PDEs. In practice, we seamlessly transform this paradigm into a practical training algorithm, named Region Optimized PINN (RoPINN), which is implemented through simple but effective Monte Carlo sampling. In addition, to control the estimation error, we adaptively adjust the sampling region size according to the gradient variance among successive training iterations, which can constrain the sampling-based optimization into a neighborhood with low-variance loss gradients, namely trust region. In experiments, RoPINN demonstrates consistent and sharp improvement for diverse PINN backbones on extensive PDEs (19 different tasks) without any extra gradient calculation. Our contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 To mitigate the inherent deficiency of conventional PINN optimization, we propose the region optimization paradigm, which extends the scatter-point optimization to neighborhood regions that theoretically beneftis both generalization and high-order constraints satisfaction. \u2022 We present RoPINN for PINN training based on Monte Carlo sampling, which can effectively accomplish the region optimization. A trust region calibration strategy is proposed to reduce the gradient estimation error caused by sampling for more trustworthy optimization. \u2022 RoPINN can consistently improve the performance of various PINN backbones (i.e. canonical and Transformer-based) on a wide range of PDEs without extra gradient calculation. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "A PDE with equation constraints, initial (ICs) and boundary conditions (BCs) can be formalized as ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathcal{F}(u)({\\pmb x})=0,{\\pmb x}\\in\\Omega;\\,\\mathcal{Z}(u)({\\pmb x})=0,{\\pmb x}\\in\\Omega_{0};\\,\\mathcal{B}(u)({\\pmb x})=0,{\\pmb x}\\in\\partial\\Omega,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\mathcal{F},\\mathcal{T},\\mathcal{B}$ denote the PDE equations, ICs and BCs respectively [6]. $u:\\mathbb{R}^{d+1}\\rightarrow\\mathbb{R}^{m}$ is the target PDE solution. $\\pmb{x}\\in\\Omega\\subseteq\\mathbb{R}^{d+1}$ represents the input coordinate, which is usually a composition of spatial and temporal positions, namely $\\pmb{x}=(x_{1},\\cdots,x_{d},t)$ . $\\Omega_{0}$ corresponds to the $t=0$ situation. ", "page_idx": 1}, {"type": "text", "text": "Correspondingly, the PINN loss function (point optimization) is typically defined as follows [17, 36]: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}(u_{\\theta})=\\frac{\\lambda_{\\Omega}}{N_{\\Omega}}\\sum_{i=1}^{N_{\\Omega}}\\|\\mathcal{F}(u_{\\theta})(\\boldsymbol{x}_{i})\\|^{2}+\\frac{\\lambda_{\\Omega_{0}}}{N_{\\Omega_{0}}}\\sum_{i=1}^{N_{\\Omega_{0}}}\\|\\mathcal{Z}(u_{\\theta})(\\boldsymbol{x}_{i})\\|^{2}+\\frac{\\lambda_{\\partial\\Omega}}{N_{\\partial\\Omega}}\\sum_{i=1}^{N_{\\partial\\Omega}}\\|\\mathcal{B}(u_{\\theta})(\\boldsymbol{x}_{i})\\|^{2},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $u_{\\theta}$ represents the neural network parameterized by $\\theta$ . $N_{\\Omega},N_{\\Omega_{0}},N_{\\partial\\Omega}$ are the numbers of sampled points in $\\Omega,\\Omega_{0},\\partial\\Omega$ respectively. $\\lambda_{*}$ is the corresponding loss weight. Note that there is an additional data loss term in Eq. (2) when we can access the ground truth of some points [36]. Since we mainly focus on PDE constraints throughout this paper, we omit the data loss term in the above formalization, which is still maintained in our experiments. In this paper, we try to improve PINN solving by defining a new surrogate loss in place of the canonical definition of PINN loss in Eq. (2). In contrast, the relevant literature mainly improves the objective function in two different directions as follows. Appendix F provides a more comprehensive discussion on other relative topics. ", "page_idx": 2}, {"type": "text", "text": "High-order regularization The first direction is to add the high-order constraints of PDEs as regularization terms to the loss function [55]. Specifically, since PDEs are sets of identical relations, suppose that the solution $u$ is a $K$ -order differential function, Eq. (1) can naturally derive a branch of high-order equations, where the $k$ -th derivative for the $j$ -th dimension is \u2202\u2202xkk F(u)(x) = 0, $\\pmb{x}\\in\\Omega,1\\leq j\\leq(d+1),1\\leq k\\leq K$ , corresponding to the following regularization: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{k,j}^{\\mathrm{reg}}(u_{\\theta})=\\frac{\\lambda_{k,j}}{N_{k,j}}\\sum_{i=1}^{N_{k,j}}\\left\\|\\frac{\\partial^{k}}{\\partial x_{j}^{k}}\\mathcal{F}(u_{\\theta})({\\pmb x}_{i})\\right\\|^{2},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $N_{k,j}$ denotes the number of sampled points with weight $\\lambda_{k,j}$ . Although this design can explicitly enhance the model performance in satisfying high-order constraints, the calculation of highorder derivatives can be extremely time-consuming and unstable [39]. Thus, in practice, the previous methods [55, 31] only consider a small value of $K$ . In the next sections, we will prove that RoPINN can naturally incorporate high-order constraints. Besides, as presented in Eq. 3, this paradigm still optimizes PINNs on scattered points, while this paper extends optimization to neighborhood regions. ", "page_idx": 2}, {"type": "text", "text": "Variational formulation As a classical tool in traditional PDE solvers, the variational formulation is widely used to reduce the smoothness requirements of the approximate solution [42]. Concretely, the target PDEs are multiplied with a set of predefined test functions $\\{v_{1},\\cdot\\cdot\\cdot,v_{M}\\}$ and then the PDE equation term of the loss function is transformed as follows [18, 19, 20]: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}^{\\mathrm{equ}}(u_{\\theta})=\\frac{1}{M}\\sum_{k=1}^{M}\\left\\|\\left<\\mathcal{F}^{(x_{j})}(u_{\\theta})(\\mathbf{x}),v_{k}(\\mathbf{x})\\right>\\right|_{\\partial_{(x_{j})}\\Omega}-\\int_{\\Omega}\\left<\\mathcal{F}^{(x_{j})}(u_{\\theta})(\\mathbf{x}),\\frac{\\partial}{\\partial x_{j}}v_{k}(\\mathbf{x})\\right>\\mathrm{d}\\mathbf{x}\\right\\|^{2},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where ${\\mathcal{F}}^{(x_{j})}$ defines the antiderivative of $\\mathcal{F}$ on the $j$ -th dimension. Using integrals by parts, the derivative operation in $\\mathcal{F}$ is transferred to test functions $\\{v_{k}\\}_{k=1}^{M}$ , thereby able to bypass high-order derivatives. However, the integral on is still hard to compute, which requires massive quadrature points for approximation [18]. Besides, test function selection requires extra manual effort and will bring $M$ times computation costs [57]. In contrast, RoPINN does not require test functions and will not bring extra gradient calculations. Also, RoPINN employs a trust region calibration strategy to limit the optimization in low-variance regions, which can control the estimation error of sampling. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As aforementioned, we propose the region optimization paradigm to extend the optimization from scatter points to a series of corresponding neighborhood regions. This section will first present the region optimization and its theoretical benefits in both reducing generalization error and satisfying high-order PDE constraints. Then, we implement RoPINN in a simple but effective sampling-based way, along with a trust region calibration strategy to control the sampling estimation error. ", "page_idx": 2}, {"type": "text", "text": "3.1 Region Optimization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For clarity, we record the point optimization loss defined in Eq. (2) at $\\textbf{\\em x}$ as $\\textstyle{\\mathcal{L}}(u_{\\theta},\\mathbf{\\boldsymbol{x}})$ , where $\\pmb{x}\\in\\Omega\\cup$ $\\Omega_{0}\\cup\\partial\\Omega$ denotes the point selected from inner domain, initial state or boundaries. We adopt $\\boldsymbol{S}$ to denote the finite set of selected points. Then Eq. (2) can be simplified as $\\begin{array}{r}{\\mathcal{L}(u_{\\theta},S)=\\frac{1}{|S|}\\sum_{\\pmb{x}\\in S}\\mathcal{L}(u_{\\theta},\\pmb{x})}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "Correspondingly, we define the objective function of our region optimization innovatively as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\boldsymbol{S})=\\frac{1}{\\left|S\\right|}\\sum_{x\\in\\mathcal{S}}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\boldsymbol{x})=\\frac{1}{\\left|\\Omega_{r}\\right|\\times\\left|S\\right|}\\sum_{x\\in\\mathcal{S}}\\int_{\\Omega_{r}}\\mathcal{L}(u_{\\theta},\\boldsymbol{x}+\\boldsymbol{\\xi})\\mathrm{d}\\boldsymbol{\\xi},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\Omega_{r}\\,=\\,[0,r]^{(d+1)}$ represents the extended neighborhood region with hyperparameter $r$ . Although this definition seems to require more sampling points than point optimization, we can develop an efficient algorithm to implement it without adding sampling points (see next section). Besides, this formalization also provides us with a convenient theoretical analysis framework. Next, we will discuss the theoretical properties of the two optimization paradigms. All proofs are in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "Generalization bound Here we discuss the generalization error in expectation [13], which is independent of the point selection, thereby quantifying the error of PINN optimization more rigorously. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1. The generalization error in expectation of model trained on dataset $\\boldsymbol{S}$ is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}=\\left|\\mathbb{E}_{S,A}\\left[\\mathcal{L}\\left(u_{A(S)},\\Omega\\right)-\\mathcal{L}\\left(u_{A(S)},S\\right)\\right]\\right|,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\boldsymbol{\\mathcal{A}}$ denotes the training algorithm and ${\\mathcal{A}}(S)$ represents the optimized model parameters. ", "page_idx": 3}, {"type": "text", "text": "Assumption 3.2. The loss function $\\mathcal{L}$ is $L$ -Lipschitz and $\\beta$ -smooth with respect to model parameters, which means that $\\forall{\\pmb x}\\in\\Omega$ the following inequalities hold: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathcal{L}(u_{\\theta_{1}},x)-\\mathcal{L}(u_{\\theta_{2}},x)\\|\\leq L\\|\\theta_{1}-\\theta_{2}\\|,\\ \\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{1}},x)-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{2}},x)\\|\\leq\\beta\\|\\theta_{1}-\\theta_{2}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Theorem 3.3 (Point optimization). Suppose that the loss function $\\mathcal{L}$ is $L$ -Lipschitz- $\\beta$ -smooth for $\\theta$ . If we run stochastic gradient descent with step size $\\alpha_{t}$ at the $t$ -th step for $T$ iterations, we have that: ", "page_idx": 3}, {"type": "text", "text": "incre $\\mathcal{L}$ ing step sizes $\\begin{array}{r}{\\alpha_{t}\\le\\frac{1}{\\beta t}}\\end{array}$ , the $C$ $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{gen}}\\leq\\frac{C}{|S|}+\\frac{2L^{2}(T-1)}{\\beta(|S|-1)}}\\end{array}$ $\\theta,x$ (tighter boun $\\theta$ than [13, 52]). ", "page_idx": 3}, {"type": "text", "text": "Lemma 3.4. If $\\mathcal{L}$ is bounded for all $\\theta,x$ and is convex, $L$ -Lipschitz- $\\beta$ -smooth with respect to model parameters $\\theta_{i}$ , then $\\mathcal{L}_{r}^{\\mathrm{region}}$ is also bounded for all $\\theta,x$ and convex, $L$ -Lipschitz- $\\beta$ -smooth for $\\theta$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.5 (Region optimization). Suppose that the point optimization loss function $\\mathcal{L}$ is $L$ - Lipschitz and $\\beta$ -smooth for $\\theta$ . If we run stochastic gradient descent with step size $\\alpha_{t}$ for $T$ iterations based on region optimization loss $\\mathcal{L}_{r}^{\\mathrm{region}}$ in Eq. (5), the generalization error in expectation satisfies: ", "page_idx": 3}, {"type": "text", "text": "(2) If $\\mathcal{L}$ is bounded by a constant $C$ for all $\\theta,x$ and is non-convex for $\\theta$ with monotonically nonincreasing step sizes \u03b1t \u2264\u03b21t, then Egen \u2264 |SC| + 2\u03b2L(2|S(T| \u2212\u221211)) \u2212JL( ||\u2126\u2126r|| )2, where J is a finite number that depends on the training property at the several beginning iterations. ", "page_idx": 3}, {"type": "text", "text": "Proof. Based on the Lipschitz assumption, $\\mathcal{E}_{\\mathrm{gen}}$ can be bounded by a term relating to the expectation of distance between parameter $\\theta$ optimized from different training sets. The region optimization paradigm brings a more \u201cconsistent\u201d gradient optimization direction than point optimization at each iteration, thereby benefiting the generalization property. See Appendix A.3 for complete proof. ", "page_idx": 3}, {"type": "text", "text": "From Theorems 3.3 and 3.5, we can observe that region optimization can reduce the generalization error ${\\mathcal{E}}_{\\mathrm{gen}}$ . Furthermore, the region optimization theorem also provides a more general theoretical framework. For example, the conventional point optimization is equivalent to the case of $\\Omega_{r}=0$ , where only one single point is selected for each region. For another extreme case, enlarging the region size to the whole domain (i.e. $\\Omega_{r}=\\Omega$ ), Eq. (5) is equivalent to directly optimizing the loss defined on $\\Omega$ , where the generalization error will be reduced to zero. Unfortunately, this ideal situation cannot be satisfied in practice, since Eq. (5) requires precise calculation of the integral over the whole domain. More discussions of practical implementation are deferred to the next section. ", "page_idx": 3}, {"type": "text", "text": "High-order PDE constraints In our proposed region optimization (Eq. (5)), the integral operation on the input domain can also relax the smoothness requirements of the loss function $\\mathcal{L}$ . For example, without any additional assumption of the smoothness of $\\mathcal{L}(u_{\\theta},\\mathbf{\\boldsymbol{x}})$ on $\\textbf{\\em x}$ , we can directly derive the generalization error for the first-order loss $\\begin{array}{r}{\\frac{\\partial}{\\partial x_{j}}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\pmb{x})}\\end{array}$ on the $j$ -th dimension as follows. ", "page_idx": 3}, {"type": "text", "text": "Input: number of iterations $T$ , number of past iterations $T_{0}$ retained to estimate the trust region,   \ndefault region size $r$ , trust region calibration value $\\sigma_{0}=1$ , and initial PINN parameters $\\theta_{0}$ .   \nOutput: optimized PINN parameters $\\theta_{T}$ .   \nInitialize an empty buffer to record gradients as $\\mathbf{g}$ .   \nfor $t=0$ to $T$ do // Region Optimization with Monte Carlo Approximation Sample points from neighborhood regions: $\\begin{array}{r}{\\bar{S}^{\\prime}=\\{\\pmb{x}_{i}+\\pmb{\\xi}_{i}\\}_{i=1}^{|S|},\\pmb{x}_{i}\\in S,\\pmb{\\xi}_{i}\\sim U[0,\\frac{r}{\\sigma_{t}}]^{(d+1)}}\\end{array}$ Calculate loss function $\\mathcal{L}_{t}=\\mathcal{L}\\left(u_{\\theta_{t}},S^{\\prime}\\right)$ Update $\\theta_{t}$ to $\\theta_{t+1}$ with optimizer (Adam [21], L-BFGS [27], etc) to minimize loss function $\\mathcal{L}_{t}$ // Trust Region Calibration Record the gradient of parameters $g_{t}$ throughout optimization Update gradient buffer $\\mathbf{g}$ by adding $g_{t}$ and keeping the latest $T_{0}$ elements Trust region calibration with $\\sigma_{t+1}=\\lVert\\sigma(\\mathbf{g})\\rVert$   \nend for ", "page_idx": 4}, {"type": "text", "text": "", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Corollary 3.6 (Region optimization for first-order constraints). Suppose that $\\mathcal{L}$ is bounded by $C$ for all $\\theta,x$ and is $L$ -Lipschitz and $\\beta$ -smooth for $\\theta$ . If we run stochastic gradient method based on first-order j-th dimension loss function\u2202\u2202xj Lrreg for $T$ iterations, the generalization error in Theorem 3.5(2) still holds when we adopt the monotonically non-increasing step size \u03b1t \u226421\u03b2t. ", "page_idx": 4}, {"type": "text", "text": "Corollary 3.6 implies that the integral on the input domain in region optimization can help training PINNs with high-order constraints, which is valuable for high-order PDEs, such as wave equations. In contrast, this valuable property cannot be achieved by the classic point optimization. See Example 3.7. ", "page_idx": 4}, {"type": "text", "text": "Example 3.7 (Point optimization fails in optimizing with first-order constraints). Under the same assumption with Corollary 3.6, we cannot obtain t\u221ahe Lipschitz and smoothness property of $\\frac{\\partial}{\\partial x_{j}}\\mathcal{L}(u_{\\theta},\\pmb{x})$ . For example, suppose that $\\mathcal{L}(u_{\\theta},\\mathbf{x})=|\\theta^{\\mathsf{T}}\\sqrt{\\mathbf{x}}|,\\dot{\\mathbf{x}}\\in[0,1]^{(d+1)}$ , which is $^{\\,l}$ -Lipschitz$^{\\,I}$ -smooth. However, $\\nabla_{\\boldsymbol{\\theta}}\\frac{\\partial}{\\partial x_{j}}\\mathcal{L}(u_{\\boldsymbol{\\theta}},\\mathbf{x})$ is unbounded when ${\\boldsymbol x}\\to{\\bf0}$ , thereby not Lipschitz constant. ", "page_idx": 4}, {"type": "text", "text": "3.2 Practical Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Derived from our theoretical insights of region optimization, we implement RoPINN as a practical training algorithm. As elaborated in Algorithm 1, RoPINN involves the following two iterative steps: Monte Carlo approximation and trust region calibration, where the former can efficiently approximate the optimization objective and the latter can effectively control the estimation error. Next, we will discuss the details and convergence properties of RoPINN. All proofs can be found in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "Monte Carlo approximation Note that the region integral in Eq. (5) cannot be directly calculated, so we adopt a straightforward implementation based on the Monte Carlo approximation. Concretely, to approximate the gradient descent on the region loss $\\mathcal{L}_{r}^{\\mathrm{region}}$ , we uniformly sample one point within the region $\\Omega_{r}$ for the gradient descent at each iteration, whose expectation is equal to the gradient descent of the original region optimization in Eq. (5): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pmb{\\xi}\\sim U(\\Omega_{r})}\\left[\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi})\\right]=\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\pmb{x}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In addition to efficiently approximating region optimization without adding sampling points, our proposed sampling-based strategy is also equivalent to a high-order loss function, especially for the first-order term, which is essential in practice [55]. Concretely, with Taylor expansion, we have that: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\xi\\sim U(\\Omega_{r})}\\big(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},{\\pmb x}+\\xi)\\big)=\\mathbb{E}_{\\xi\\sim U(\\Omega_{r})}\\big(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},{\\pmb x})+\\nabla_{\\theta}(\\pmb{\\xi}^{\\top}\\mathcal{L}_{1}(u_{\\theta},{\\pmb x}))+\\mathcal{O}(\\|\\xi\\|^{2})\\big),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Omega_{r}=[0,r]^{d+1}$ , and ${\\mathcal{L}}_{1}$ represents the first order of loss function, namely $\\begin{array}{r}{\\frac{\\partial}{\\partial\\mathbf{x}}\\mathcal{L}(u_{\\theta},\\pmb{x})}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.8 (Convergence rate). Suppose that there exists a constant $H$ , s.t. $\\forall v$ and $\\forall{\\pmb x}\\in\\Omega$ , $|v^{\\mathsf{T}}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},x)v|^{\\mathsf{\\Tilde{\\phi}}}\\leq H\\|v\\|^{2}$ . If the step size $\\begin{array}{r}{\\alpha_{t}=\\frac{1}{\\sqrt{t+1}}}\\end{array}$ decreases over time for $T$ iterations, the region optimization based on Monte Carlo approximation will converge at the speed of ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\pmb{x})\\right\\Vert^{2}\\right]\\leq\\mathcal{O}\\left(\\frac{1}{\\sqrt{T}}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Theorem 3.9 (Gradient estimation error). The estimation error of gradient descent between Monte Carlo approximation and the original region optimization satisfies: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\xi\\sim U(\\Omega_{r})}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},x+\\xi)-\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},x)\\right\\|^{2}\\right]^{\\frac{1}{2}}=\\left\\|\\sigma_{\\xi\\sim U(\\Omega_{r})}\\left(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},x+\\xi)\\right)\\right\\|,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\sigma$ represents the standard deviation of gradients in region $\\Omega_{r}$ . ", "page_idx": 5}, {"type": "text", "text": "Trust region calibration Although the expectation of the Monte Carlo sampling is equal to region optimization as shown in Eq. (8), this design will also bring estimation error in practice (Theorem 3.9). A large estimation error will cause unstable training and further affect convergence. To ensure a reliable gradient descent, we propose to control the sampling region size $r$ towards a trustworthy value, namely trust region calibration. Unlike the notion in optimization [56], here trust region is used to define the area of input domain where the variance of loss gradients for different points is relatively small. Formally, we adjust the region size in inverse proportion to gradient variance: ", "page_idx": 5}, {"type": "equation", "text": "$$\nr\\propto\\frac{1}{\\left\\|\\sigma_{\\pmb{\\xi}\\sim U(\\Omega_{r})}\\left(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi})\\right)\\right\\|}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In practice, we initialize the trust region size as a default value $r$ and calculate the gradient estimation error during the training process for calibration (Algorithm 1). However, the calculation of the standard deviation of gradients usually requires multiple samples, which will bring times of computation overload. In pursuit of a practical algorithm, we propose to adopt the gradient variance among several successive iterations as an approximation. Similar ideas are widely used in deep learning optimizers, such as Adam [21] and AdaGrad [48], which adopt multi-iteration statistics as the momentum of gradient descent. The approximation process is guaranteed by the following theoretical results. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.10 (Trust region one-iteration approximation). Suppose that loss function $\\mathcal{L}$ is $L$ - Lipschitz and $\\beta$ -smooth for $\\theta$ and the $t$ -th step parameter is $\\theta_{t}$ . Two gradient difference sequences between successive iterations, $\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\|$ and $\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta_{t}},z_{2}\\big)\\|$ , share the same limit, as the difference of the two sequences is dominated by the following inequality: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big|\\left\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\right\\|-\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{2})\\|\\big|\\leq\\beta L\\alpha_{t-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\alpha_{t-1}$ represents the step size at the $(t-1)$ - $^{t h}$ iteration, which approaches $\\boldsymbol{O}$ as $t$ tends to $\\infty$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.11 (Trust region multi-iteration approximation). Suppose that loss function $\\mathcal{L}$ is L-Lipschitz and \u03b2-smooth for \u03b8 and the learning rate \u03b1t \u2264\u03b21L converges to zero over time $t$ , then the estimation error can be approximated by the variance of optimization gradients in multiple successive iterations. Given hyperparameter $T_{0}$ , our multi-iteration approximation is guaranteed by ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{t\\to\\infty}\\sigma\\left(\\left\\{\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})\\right\\}_{i=1}^{T_{0}}\\right)=\\sigma\\left(\\{\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})\\}_{i=1}^{T_{0}}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "It is worth noting that, as presented in Algorithm 1, since the gradient of each iteration has already been on the shelf, our design will not bring any extra gradient or backpropagation calculation in comparison with point optimization. Besides, our algorithm is not limited to a certain optimizer, and in general, we can effectively obtain the gradients of parameters by retrieving the computation graph. ", "page_idx": 5}, {"type": "text", "text": "Balance between generalization and optimization Recall that in Theorem 3.5, we observe that a larger region size will benefti the generalization error, while Theorem 3.9 demonstrates that too large region size will also cause unstable training because it will result in excessive gradient estimation error of Monte Carlo sampling in our implementation. The above analysis reveals the underlying trade-off between generalization and optimization of PINN models, which is formally stated below. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.12 (Region Optimization with gradient estimation error). Based on the same assumptions in Theorem 3.5 but optimizing the PINN model with the approximate region optimization loss $\\begin{array}{r}{\\mathcal{L}_{r}^{\\mathrm{approx}}(u_{\\theta},\\pmb{x})=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi}),\\pmb{\\xi}\\sim U(\\Omega_{r}),}\\end{array}$ for $T$ iterations, we further denote the upper bound of gradient estimation error as $\\begin{array}{r}{\\mathcal{E}_{r,\\mathrm{grad}}=\\operatorname*{max}_{t\\leq T}\\|\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{approx}}-\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}\\|}\\end{array}$ , then $\\mathcal{E}_{\\mathrm{gen}}$ satisfies: $(I)$ If $\\mathcal{L}$ is convex for $\\theta$ and $\\begin{array}{r}{\\alpha_{t}\\le\\frac{2}{\\beta}}\\end{array}$ , $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{gen}}\\leq\\big(\\underbrace{(1-|\\Omega_{r}|/|\\Omega|)L}_{i n v e r s e l y\\,p r o p o r t i o n a l\\,t o\\;|\\Omega_{r}|}+\\underbrace{\\mathcal{E}_{r,\\mathrm{grad}}}_{g e n e r a l l y\\,\\propto\\;|\\Omega_{r}|}\\big)\\frac{2L}{|S|}\\sum_{t=1}^{T}\\alpha_{t}.}\\end{array}$ (2) If $\\mathcal{L}$ is bounded by a constant $C$ and is non-convex for $\\theta$ with monotonically non-increasing step sizes \u03b1t \u2264\u03b21t, then Egen \u2264|SC| + 2\u03b2L(|S(T| \u2212\u221211)) $\\begin{array}{r l}{\\mathcal{E}_{\\mathrm{gen}}\\leq\\frac{C}{|\\mathcal{S}|}+\\frac{2L^{2}(T-1)}{\\beta(|\\mathcal{S}|-1)}}&{\\underbracket{-J^{\\prime}L(|\\Omega_{r}|/|\\Omega|)^{2}}_{i n v e r s e l y\\,p r o p o r t i o n a l\\,t o\\;|\\Omega_{r}|}+\\;\\underbracket{J^{\\prime}\\mathcal{E}_{r,\\mathrm{grad}}(1+|\\Omega_{r}|/|\\Omega|)}_{g e n e r a l l y\\,\\propto\\;|\\Omega_{r}|},}\\end{array}$ where $J^{\\prime}$ is a finite number that depends on the training property at the several beginning iterations. ", "page_idx": 5}, {"type": "text", "text": "Proof. In contrast to Theorem 3.5, here the gradient estimation error will bring extra optimization discrepancy between different training sets. See Appendix B.4 for complete proof. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "Based on Theorem 3.12, we have pinpointed that classical point optimization $\\Omega_{r}=0$ ) and sampling points globally $\\left(\\Omega_{r}=\\Omega\\right)$ discussed in Theorem 3.5 correspond to two extreme cases. The former makes $\\mathcal{E}_{r,\\mathrm{grad}}=0$ but cannot reduce the generalization error, while the latter holds a large gradient estimation error. Thus, neither case can yield perfect generalization for PINNs . In contrast, the design for calibrating trust regions in RoPINN provides an adaptive strategy to better balance generalization and optimization, which can adjust the region size according to multi-iteration training stability. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To verify the effectiveness and generalizability of our proposed RoPINN, we experiment with a wide range of PDEs, covering diverse physics processes and a series of advanced PINN models. ", "page_idx": 6}, {"type": "text", "text": "Benchmarks For a comprehensive evaluation, we experiment with four benchmarks: 1D-Reaction, 1D-Wave, Convection and PINNacle [12]. The first three benchmarks are widely acknowledged in investigating the optimization property of PINNs [47, 37]. Especially, 1D-Reaction and Convection are highly challenging and have ", "page_idx": 6}, {"type": "table", "img_path": "wZigMVFURk/tmp/3bad6b648f324f4c0a0334f91ebbd8a68f042f39985d4a907fa1486979420e86.jpg", "table_caption": ["Table 1: Summary of benchmarks. Dimension means the input space and Derivative is the highest derivative order. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "been used to demonstrate \u201cPINNs failure modes\u201d [24, 33]. As for PINNacle [12], it is a comprehensive family of 20 tasks, including diverse PDEs, e.g. Burgers, Poisson, Heat, Navier-Stokes, Wave and Gray-Scott equations in 1D to 5D space and on complex geometries. In this paper, to avoid meaningless comparisons, we remove the tasks that all the methods fail and leave 16 tasks. ", "page_idx": 6}, {"type": "text", "text": "Base models To verify the generalizability of RoPINN among different PINN models, we experiment with five base models, including canonical PINN [36], activation function enhanced models: QRes [3] and FLS [50], Transformer-based model PINNsFormer [58] and advanced physics-informed backbone KAN [28]. PINNsFormer [58] and KAN [28] are the most advanced PINN models. ", "page_idx": 6}, {"type": "text", "text": "Baselines As stated before, this paper mainly focuses on the objective function of PINNs. Thus, we only include the gradient-enhanced method gPINN [55] and variational-based method vPINN [18] as baselines. Notably, there are diverse training strategies for PINNs focusing on other aspects than objective function, such as sampling-based RAR [51] or neural tangent kernel (NTK) approaches [47]. We also experimented with them and demonstrated that they contribute orthogonally to RoPINN. ", "page_idx": 6}, {"type": "text", "text": "Implementations In RoPINN (Algorithm 1), we select the multi-iteration hyperparameter $T_{0}$ from $\\lbrace5,10\\rbrace$ and set the initial region size $r\\,=\\,10^{-4}$ for all datasets, where the trust region size will be adaptively adjusted to fit the PDE property during training. For 1D-Reaction, 1D-Wave and Convection, we follow [58] and train the model with L-BFGS optimizer [27] for 1,000 iterations. As for PINNacle, we strictly follow their official configuration [12] and train the model with Adam [21] for 20,000 iterations. Besides, for simplicity and fair comparison, we set the weights of PINN loss as equal, that is $\\lambda_{*}=1$ in Eq. (2). Canonical loss formalized in Eq. (2), relative L1 error (rMAE) and relative L2 error (rMSE) are recorded. All experiments are implemented in PyTorch [34] and trained on a single NVIDIA A100 GPU. See Appendix C for more implementation details. ", "page_idx": 6}, {"type": "text", "text": "4.1 Main Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Results As shown in Table 2, we investigate the effectiveness of RoPINN on diverse tasks and base models and compare it with two well-acknowledged PINN objectives. Here are two key observations. ", "page_idx": 6}, {"type": "text", "text": "RoPINN can consistently boost performance on all benchmarks, justifying its generality on PDEs and base models. Notably, since the PDEs under evaluation are quite diverse, especially for PINNacle (Table 1), it is extremely challenging to obtain such a consistent improvement. We can find that the previous high-order regularization and variational-based methods could yield negative effects in many cases. For example, gPINN [55] performs badly on 1D-Wave, which may be due to second-order derivatives in the wave equation. Besides, vPINN [18] also fails in 1D-Reaction and QRes. ", "page_idx": 6}, {"type": "table", "img_path": "wZigMVFURk/tmp/5709acd2baead2b29d3c6990d0755890e24fe7a7f98f2ee9e592eb25d0154b7b.jpg", "table_caption": ["Table 2: Comparison between RoPINN and other objective functions (gPINN [55] and vPINN [18]) under different base models. Metrics for PINNacle [12] are the proportions of improved tasks over 16 tasks, where full results can be found in Appendix E. A lower loss, rMAE or rMSE indicates better performance. For clarity, we highlight the value with blue if it surpasses the vanilla PINN and the best is in bold. Promotion refers to the relative promotion of RoPINN over the vanilla version. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "As we stated in Table 1, 1D-Reaction and Convection are hard to optimize, so-called \u201cPINNs failure modes\u201d [24, 33]. In contrast, empowered by RoPINN, PINNs can mitigate this thorny challenge to some extent. Specifically, with RoPINN, canonical PINN [36], QRes [3] and FLS [50] achieve more than $90\\%$ improvements in 1D-Reaction. Besides, RoPINN can further enhance the performance of PINNsFormer [58] and KAN [28], which have already performed well in 1D-Recation or Convection, further verifying its effectiveness in helping PINN optimization. ", "page_idx": 7}, {"type": "text", "text": "Combining with other strategies Since RoPINN mainly focuses on the objective function design, it can be integrated seamlessly and directly with other strategies. As shown in Table 3, we experiment with the widely-used loss-reweighting method NTK [47] and data-sampling strategy RAR [51]. Although NTK can consistently improve the performance, it will take extra computation costs due to the calculation of neural tangent kernels [15]. Based on NTK, our RoPINN can obtain better results with slightly more ", "page_idx": 7}, {"type": "table", "img_path": "wZigMVFURk/tmp/c2be44fccac0829d29dec2b47667ab131aa2ab8b9774388bc3b99a5a56ca677e.jpg", "table_caption": ["Table 3: Adding RoPINN to other strategies based on PINN. Time is for every $10^{2}$ training iterations on 1D-Reaction. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "time cost. As for RAR, it performs unstable in different tasks, while RoPINN can also boost it. These results verify the orthogonal contribution and favorable efficiency of RoPINN w.r.t. other methods. ", "page_idx": 7}, {"type": "text", "text": "4.2 Algorithm Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Initial region size in Algorithm 1 To provide an intuitive understanding of RoPINN, we plot the curves of training statistics in Figure 2, including temporally adjusted region size $\\log\\!\\left({\\frac{r}{\\sigma_{t}}}\\right)$ , train loss, and test performance. From Figure 2(a), we can find that even though we initialize the region size as distinct values, RoPINN will progressively adjust the trust region size to similar values during training. This indicates that our algorithm can capture a potential \u201cbalance point\u201d between training stability and generalization error, where the fluctuation of trust region size reveals the balancing process. Further, as shown in Figure 2(b-c), if $r$ is initialized as a value closer to the balance point (e.g. 1e-4 and 1e-5 in this case), then the training process will converge faster. And too large a region size (e.g. 1e-3) will decrease the convergence speed due to the optimization noise (Theorem 3.9). ", "page_idx": 8}, {"type": "image", "img_path": "wZigMVFURk/tmp/a3076f8209e238328003e4bf1e8c4e75e79f613c65e1a418a904ff7fdb94e12a.jpg", "img_caption": ["Figure 2: Optimization of canonical PINN [36] on the 1D-Reaction under different region sizes. To highlight the region size change, we adopt the moving average over time and mark the temporal standard deviation with shadow. The steep training loss is caused by the learning difficulty of PDE. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Number of sampling points in Eq. (8) For efficiency, RoPINN only samples one point within the trust region to approximate the region gradient descent. However, it is worth noticing that sampling more points will make the approximation in Eq. (8) more accurate, leading to a lower gradient estimation error. Further, since RoPINN employs an adaptive strategy to adjust region $\\Omega_{r}$ , a lower gradient estimation error will also make the optimization process adapt to a larger region size $r$ . Therefore, we observe in Figure 3(a-b) that sampling more points will also increase the finally learned region size $r$ and speed up the convergence. In addition, Figure 3(c) shows that adding sampled points can also improve the final performance, which has also been theoretically justified in Theorem 3.12 that the upper bound of generalization error is inversely proportion to gradient estimation error. ", "page_idx": 8}, {"type": "image", "img_path": "wZigMVFURk/tmp/8713121f24547432f63ec3402d526c0e79e69ea9dfdc9b4c1794ff383525f52a.jpg", "img_caption": ["Figure 3: Optimization of canonical PINN [36] on the 1D-Reaction under different sample points. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Efficiency analysis As we discussed above, sampling more points can benefti the final performance, while we choose only sample one point as the default setting of RoPINN in the spirit of boosting PINNs without extra backpropagation or gradient calculation, which has already achieved significant promotion w.r.t. original PINNs (Table 2). To provide a more comprehensive understanding of algorithm property, we plot the efficiency-performance curve in Figure 4, where we can obtain the following observations. Firstly, computation costs will grow linearly when adding points. Secondly, more points will bring better performance but will saturate around 10 points, where the performance fluctuations of 9, 13, and 30 points are within three times the standard deviations (Appendix D.3). ", "page_idx": 8}, {"type": "text", "text": "Ablations To verify the effectiveness of our design in RoPINN, we present ablations in Figure 5. It is observed that although we only sample one point, even fixed-size region optimization can also boost the performance of PINNs in most cases, demonstrating the effectiveness of introducing \u201cregion\u201d to PINN optimization. However, as illustrated in Theorem 3.9, the sampling process may also cause gradient estimation error, so the relative promotion is inconsistent and unstable among different PDEs and base models. With our proposed trust region calibration, we can obtain a more significant and consistent improvement, indicating that achieving a better balance between optimization and generalization (formally stated in Theorem 3.12) performs an essential role in training PINN models. ", "page_idx": 8}, {"type": "image", "img_path": "wZigMVFURk/tmp/561b5f17c481f2b0c6344c7f17367a779f9a1a4db68c5831f173bf3f8143d426.jpg", "img_caption": ["Figure 4: Efficiency and model performance w.r.t. number of samples. Note that the default setting of RoPINN is just sampling one point, which will not bring extra gradient calculation costs. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "wZigMVFURk/tmp/76c47a36ff180d726a45bfa5868f4bbd15337a5591d66f4ee0f538f4611f5525.jpg", "img_caption": ["Figure 5: Ablation study of RoPINN on different PDEs and diverse base models. rMSE is recorded. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Loss landscape Previous research [24] has studied why PINN cannot solve the Convection equation and found that it is not caused by the limited model capacity but by the hard-to-optimize loss landscape. Here we also provide a loss landscape visualization in Figure 6, which is obtained by perturbing the trained model along the directions of the first two dominant Hessian eigenvectors [24, 25, 54]. We can find that vanilla PINN optimized by PINN loss in Eq. (2) presents sharp cones. In contrast, empowered by RoPINN, the loss landscape is significantly smoothed. This visualization intuitively interprets why RoPINN can mitigate \u201cPINN failure modes\u201d. See Appendix D for more results. ", "page_idx": 9}, {"type": "image", "img_path": "wZigMVFURk/tmp/c8c50fe63777c9c3951e8e12709174815a9765e2038be8e9de899f34e22cd3e0.jpg", "img_caption": ["Figure 6: Loss landscape of RoPINN and vanilla PINNs on the Convection equation. Error Map refers to the distance between model prediction and the accurate solution, i.e. $\\left(u_{\\theta}-u\\right)$ . "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper presents and analyzes a new PINN optimization paradigm: region optimization. Going beyond previous scatter-point optimization, we extend the optimization from selected points to their neighborhood regions. Based on this idea, RoPINN is implemented as a simple but effective training algorithm, where an efficient Monte Carlo approximation process is used along with a trust region calibration strategy to control the gradient estimation error caused by sampling, theoretically manifesting a better balance of generalization and optimization. In addition to theoretical advantages, RoPINN can consistently boost the performance of various PINN models without extra backpropagation or gradient calculation, demonstrating favorable efficiency, training stability and general capability. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported by the National Natural Science Foundation of China (U2342217 and 62022050), the BNRist Project, and the National Engineering Research Center for Big Data Software. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Michael Francis Atiyah, Raoul Bott, and Lars G\u00e5rding. Lacunas for hyperbolic differential operators with constant coefficients i. 1970.   \n[2] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python $^{+}$ NumPy programs, 2018.   \n[3] Jie Bu and Anuj Karpatne. Quadratic residual networks: A new class of neural networks for solving forward and inverse problems in physics involving pdes. In SIAM, 2021.   \n[4] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL, 2019.   \n[5] Gouri Dhatt, Emmanuel Lefran\u00e7ois, and Gilbert Touzot. Finite element method. John Wiley & Sons, 2012.   \n[6] Lawrence C Evans. Partial differential equations. American Mathematical Soc., 2010.   \n[7] Bengt Fornberg. A practical guide to pseudospectral methods. Cambridge university press, 1998.   \n[8] Olga Fuks and Hamdi A Tchelepi. Limitations of physics informed machine learning for nonlinear two-phase transport in porous media. Journal of Machine Learning for Modeling and Computing, 2020.   \n[9] Han Gao, Luning Sun, and Jian-Xun Wang. Phygeonet: Physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state pdes on irregular domain. Journal of Computational Physics, 2021.   \n[10] Christian Grossmann, Hans-G\u00f6rg Roos, and Martin Stynes. Numerical treatment of partial differential equations. Springer, 2007.   \n[11] Zhongkai Hao, Songming Liu, Yichi Zhang, Chengyang Ying, Yao Feng, Hang Su, and Jun Zhu. Physics-informed machine learning: A survey on problems, methods and applications. arXiv preprint arXiv:2211.08064, 2022.   \n[12] Zhongkai Hao, Jiachen Yao, Chang Su, Hang Su, Ziao Wang, Fanzhi Lu, Zeyu Xia, Yichi Zhang, Songming Liu, Lu Lu, et al. Pinnacle: A comprehensive benchmark of physics-informed neural networks for solving pdes. arXiv preprint arXiv:2306.08827, 2023.   \n[13] Moritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. In ICML, 2016.   \n[14] Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CVPR, 2016.   \n[15] Arthur Jacot, Franck Gabriel, and Cl\u00e9ment Hongler. Neural tangent kernel: Convergence and generalization in neural networks. NeurIPS, 2018.   \n[16] Alan Jeffrey and Hui Hui Dai. Handbook of mathematical formulas and integrals. Elsevier, 2008.   \n[17] George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning. Nat. Rev. Phys., 2021.   \n[18] Ehsan Kharazmi, Zhongqiang Zhang, and George Em Karniadakis. Variational physics-informed neural networks for solving partial differential equations. arXiv preprint arXiv:1912.00873, 2019.   \n[19] Ehsan Kharazmi, Zhongqiang Zhang, and George Em Karniadakis. hp-vpinns: Variational physicsinformed neural networks with domain decomposition. Computer Methods in Applied Mechanics and Engineering, 2021.   \n[20] Reza Khodayi-Mehr and Michael Zavlanos. Varnet: Variational neural networks for the solution of partial differential equations. In Learning for Dynamics and Control, 2020. ", "page_idx": 10}, {"type": "text", "text": "[21] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. ", "page_idx": 11}, {"type": "text", "text": "[22] David A Kopriva. Implementing spectral methods for partial differential equations: Algorithms for scientists and engineers. Springer Science & Business Media, 2009.   \n[23] Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett. Mitigating propagation failures in physics-informed neural networks using retain-resample-release (R3) sampling. In ICML, 2023.   \n[24] Aditi Krishnapriyan, Amir Gholami, Shandian Zhe, Robert Kirby, and Michael W Mahoney. Characterizing possible failure modes in physics-informed neural networks. NeurIPS, 2021.   \n[25] Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. Visualizing the loss landscape of neural nets. NeurIPS, 2018.   \n[26] Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. In ICLR, 2021.   \n[27] Dong C Liu and Jorge Nocedal. On the limited memory bfgs method for large scale optimization. Mathematical programming, 1989.   \n[28] Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Solja\u02c7ci\u00b4c, Thomas Y Hou, and Max Tegmark. Kan: Kolmogorov-arnold networks. arXiv preprint arXiv:2404.19756, 2024.   \n[29] ES Lobanova and FI Ataullakhanov. Running pulses of complex shape in a reaction-diffusion model. Physical review letters, 2004.   \n[30] Lu Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. DeepXDE: A deep learning library for solving differential equations. SIAM Review, 2021.   \n[31] Suryanarayana Maddu, Dominik Sturm, Christian L M\u00fcller, and Ivo F Sbalzarini. Inverse dirichlet weighting enables reliable training of physics informed neural networks. Machine Learning: Science and Technology, 2022.   \n[32] Siddhartha Mishra and Roberto Molinaro. Estimates on the generalization error of physics-informed neural networks for approximating pdes. IMA Journal of Numerical Analysis, 2023.   \n[33] Rambod Mojgani, Maciej Balajewicz, and Pedram Hassanzadeh. Lagrangian pinns: A causalityconforming solution to failure modes of physics-informed neural networks. arXiv preprint arXiv:2205.02902, 2022.   \n[34] Adam Paszke, S. Gross, Francisco Massa, A. Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Z. Lin, N. Gimelshein, L. Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, 2019.   \n[35] Maziar Raissi. Deep hidden physics models: Deep learning of nonlinear partial differential equations. JMLR, 2018.   \n[36] Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. J. Comput. Phys., 2019.   \n[37] Pratik Rathore, Weimu Lei, Zachary Frangella, Lu Lu, and Madeleine Udell. Challenges in training pinns: A loss landscape perspective. arXiv preprint arXiv:2402.01868, 2024.   \n[38] Tom\u00e1\u0161 Roub\u00edc\u02c7ek. Nonlinear partial differential equations with applications. Springer Science & Business Media, 2013.   \n[39] Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential equations. Journal of computational physics, 2018.   \n[40] Pavel \u02c6Sol\u00edn. Partial differential equations and the finite element method. John Wiley & Sons, 2005.   \n[41] Thomas Stocker. Introduction to climate modelling. Springer Science & Business Media, 2011.   \n[42] ENZO Tonti. Variational formulation for every nonlinear problem. International Journal of Engineering Science, 1984.   \n[43] Nobuyuki Umetani and Bernd Bickel. Learning three-dimensional flow for interactive aerodynamic design. ACM Transactions on Graphics (TOG), 2018.   \n[44] Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, et al. Scientific discovery in the age of artificial intelligence. Nature, 2023.   \n[45] Sifan Wang, Shyam Sankaran, and Paris Perdikaris. Respecting causality for training physics-informed neural networks. Computer Methods in Applied Mechanics and Engineering, 2024.   \n[46] Sifan Wang, Shyam Sankaran, Hanwen Wang, and Paris Perdikaris. An expert\u2019s guide to training physicsinformed neural networks. arXiv preprint arXiv:2308.08468, 2023.   \n[47] Sifan Wang, Xinling Yu, and Paris Perdikaris. When and why pinns fail to train: A neural tangent kernel perspective. Journal of Computational Physics, 2022.   \n[48] Rachel Ward, Xiaoxia Wu, and Leon Bottou. Adagrad stepsizes: Sharp convergence over nonconvex landscapes. JMLR, 2020.   \n[49] Abdul Majid Wazwaz. Partial differential equations: methods and applications. 2002.   \n[50] Jian Cheng Wong, Chin Chun Ooi, Abhishek Gupta, and Yew-Soon Ong. Learning in sinusoidal spaces with physics-informed neural networks. IEEE Transactions on Artificial Intelligence, 2022.   \n[51] Chenxi Wu, Min Zhu, Qinyang Tan, Yadhu Kartha, and Lu Lu. A comprehensive study of non-adaptive and residual-based adaptive sampling for physics-informed neural networks. Computer Methods in Applied Mechanics and Engineering, 2023.   \n[52] Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Jue Wang, and Zhi-Quan Luo. Stability analysis and generalization bounds of adversarial training. NeurIPS, 2022.   \n[53] Jiachen Yao, Chang Su, Zhongkai Hao, Songming Liu, Hang Su, and Jun Zhu. Multiadam: Parameter-wise scale-invariant optimizer for multiscale training of physics-informed neural networks. In ICML, 2023.   \n[54] Zhewei Yao, Amir Gholami, Kurt Keutzer, and Michael W Mahoney. Pyhessian: Neural networks through the lens of the hessian. In 2020 IEEE international conference on big data (Big data), 2020.   \n[55] Jeremy Yu, Lu Lu, Xuhui Meng, and George Em Karniadakis. Gradient-enhanced physics-informed neural networks for forward and inverse pde problems. Computer Methods in Applied Mechanics and Engineering, 2022.   \n[56] Ya-xiang Yuan. A review of trust region algorithms for optimization. In Iciam, 2000.   \n[57] Yaohua Zang, Gang Bao, Xiaojing Ye, and Haomin Zhou. Weak adversarial networks for high-dimensional partial differential equations. Journal of Computational Physics, 2020.   \n[58] Leo Zhiyuan Zhao, Xueying Ding, and B Aditya Prakash. Pinnsformer: A transformer-based framework for physics-informed neural networks. ICLR, 2024. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Generalization Analysis in Section 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "This section will present the proofs for the theorems in Section 3.1. ", "page_idx": 13}, {"type": "text", "text": "A.1 Proof for Point Optimization Generalization Error (Theorem 3.3) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The proof for the convex case is derived from previous papers [13, 52] under the Assumption 3.2. We derive a more compact upper bound for generalization error in expectation for the non-convex setting. ", "page_idx": 13}, {"type": "text", "text": "Lemma A.1. Given two finite sets of selected points $S=(x_{1},\\cdot\\cdot\\cdot,x_{N})$ and $S^{\\prime}=({\\pmb x}_{1}^{\\prime},\\cdot\\cdot\\cdot\\,,{\\pmb x}_{N}^{\\prime}),$ , let ${\\cal S}^{(i)}=({\\pmb x}_{1},\\cdot\\cdot\\cdot\\;,{\\pmb x}_{i-1},{\\pmb x}_{i}^{\\prime},{\\pmb x}_{i+1},\\cdot\\cdot\\cdot\\;,{\\pmb x}_{N})$ be the set that is identical to $\\boldsymbol{S}$ except the $i$ -th element, the generalization error in expectation is equal to the expectation of the error difference between these two sets, which can be formalized as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}=\\left|\\mathbb{E}_{S,S^{\\prime},A}\\left[\\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{L}(A(S^{(i)}),\\boldsymbol{x}_{i}^{\\prime})-\\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{L}(\\boldsymbol{A}(S),\\boldsymbol{x}_{i}^{\\prime})\\right]\\right|.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Directly deriving from the in-domain loss, we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{E}_{{\\boldsymbol{S}},{\\boldsymbol{A}}}\\left[{\\boldsymbol{Z}}({\\boldsymbol{A}}({\\boldsymbol{S}}),{\\boldsymbol{S}})\\right]=\\mathbb{E}_{{\\boldsymbol{S}},{\\boldsymbol{A}}}\\left[\\frac{1}{N}\\sum_{i=1}^{N}{\\boldsymbol{Z}}({\\boldsymbol{A}}({\\boldsymbol{S}}),\\mathbf{r}_{i})\\right]}\\\\ &{\\displaystyle=\\mathbb{E}_{{\\boldsymbol{S}},{\\boldsymbol{S}}^{\\prime},{\\boldsymbol{A}}}\\left[\\frac{1}{N}\\sum_{i=1}^{N}{\\boldsymbol{Z}}({\\boldsymbol{A}}({\\boldsymbol{S}}^{(i)}),\\mathbf{r}_{i}^{\\prime})\\right]}\\\\ &{\\displaystyle=\\mathbb{E}_{{\\boldsymbol{S}},{\\boldsymbol{S}}^{\\prime},{\\boldsymbol{A}}}\\left[\\frac{1}{N}\\sum_{i=1}^{N}{\\boldsymbol{Z}}({\\boldsymbol{A}}({\\boldsymbol{S}}),\\mathbf{r}_{i}^{\\prime})\\right]+\\delta}\\\\ &{\\displaystyle=\\mathbb{E}_{{\\boldsymbol{S}},{\\boldsymbol{A}}}\\left[{\\boldsymbol{Z}}({\\boldsymbol{A}}({\\boldsymbol{S}}),{\\boldsymbol{\\Omega}})\\right]+\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Then, according to Definition 3.1, we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}=\\delta=\\mathbb{E}_{S,S^{\\prime},A}\\left[\\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{L}(\\boldsymbol{A}(\\boldsymbol{S}^{(i)}),\\boldsymbol{x}_{i}^{\\prime})-\\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{L}(\\boldsymbol{A}(\\boldsymbol{S}),\\boldsymbol{x}_{i}^{\\prime})\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Lemma A.2 (Convex case). Given the stochastic gradient method with an update rule as $G_{\\alpha,\\pmb{x}}(\\theta)=$ $\\theta\\!-\\!\\alpha\\nabla_{\\theta}\\mathcal{L}(\\theta,\\pmb{x})$ and $\\mathcal{L}$ is convex in $\\theta$ , then for $\\begin{array}{r}{\\alpha\\le{\\frac{2}{\\beta}}}\\end{array}$ , we have $\\lVert G_{\\alpha,\\mathbf{x}}(\\theta_{1})-G_{\\alpha,\\mathbf{x}}(\\theta_{2})\\rVert\\leq\\lVert\\theta_{1}-\\theta_{2}\\rVert$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. For clarity, we denote $g=\\|\\nabla_{\\theta}\\mathcal{L}(\\theta_{1},\\pmb{x})-\\nabla_{\\theta}\\mathcal{L}(\\theta_{2},\\pmb{x})\\|$ . Then we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|G_{\\alpha,x}(\\theta_{1})-G_{\\alpha,x}(\\theta_{2})\\|^{2}=\\|\\theta_{1}-\\theta_{2}-\\alpha(\\nabla_{\\theta}\\mathcal{L}(\\theta_{1},x)-\\nabla_{\\theta}\\mathcal{L}(\\theta_{2},x))\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\|\\theta_{1}-\\theta_{2}\\|^{2}-2\\alpha\\left(\\nabla_{\\theta}\\mathcal{L}(\\theta_{1},x)-\\nabla_{\\theta}\\mathcal{L}(\\theta_{2},x)\\right)^{\\mathsf{T}}(\\theta_{1}-\\theta_{2})+\\alpha^{2}g^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\|\\theta_{1}-\\theta_{2}\\|^{2}-\\displaystyle\\frac{2\\alpha}{\\beta}g^{2}+\\alpha^{2}g^{2}\\qquad\\qquad\\qquad(\\mathrm{Convexity\\and\\Assumption\\A})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\|\\theta_{1}-\\theta_{2}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Convex setting Next, we will give the proof for the convex case of Theorem 3.3(1). ", "page_idx": 13}, {"type": "text", "text": "Proof. According to Lemma A.1, we attempt to bound the generalization error in expectation $\\mathcal{E}_{\\mathrm{gen}}$ by analyzing the error difference between two selected sample sets. Denote $\\boldsymbol{S}$ and $S^{\\prime}$ as two identical sample sets of size $|{\\cal S}|$ except for one sample. Suppose that with the stochastic gradient method ", "page_idx": 13}, {"type": "text", "text": "on these two sets, we can obtain two optimization trajectories $\\{\\theta_{t}\\}_{t=1}^{T}$ and $\\{\\theta_{t}^{\\prime}\\}_{t=1}^{T}$ respectively. According to Assumption 3.2, we have the following inequality: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{t}},\\pmb{x})-\\mathcal{L}(u_{\\theta_{t}^{\\prime}},\\pmb{x})|\\right]\\leq L\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We assume two optimization trajectories, both obtained under the same random update rule and random permutation rule. Note that at the $t$ -th step, with probability $\\textstyle{\\bigl(}1-{\\frac{1}{|S|}}{\\bigr)}$ , the example selected by the stochastic gradient method is the same in both $\\boldsymbol{S}$ and $S^{\\prime}$ . As for the other $\\textstyle{\\frac{1}{|S|}}$ probability, we have to deal with different selected samples. Thus, according to Lemma A.2, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{\\xi}\\left[\\|\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\|\\right]=(1-\\frac{1}{|{\\cal S}|})\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}(\\theta_{t})-G_{\\alpha_{t},x}(\\theta_{t}^{\\prime})\\|\\right]+\\frac{1}{|{\\cal S}|}\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}(\\theta_{t}^{\\prime})\\|\\right]}\\\\ {\\displaystyle\\le(1-\\frac{1}{|{\\cal S}|})\\mathbb{E}[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|]+\\frac{1}{|{\\cal S}|}\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|+\\|\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},x)-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta},x^{\\prime})\\|\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Due to the $L$ -Lipschitz assumption of $\\mathcal{L}$ , the gradient $\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(u_{\\boldsymbol{\\theta}},\\mathbf{\\boldsymbol{x}})$ is uniformly smaller than $L$ , then: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Vert\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\Vert\\right]\\leq\\mathbb{E}\\left[\\Vert\\theta_{t}-\\theta_{t}^{\\prime}\\Vert\\right]+{\\frac{2\\alpha_{t}L}{|S|}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In summary, since both optimization trajectories start from the same initialization, namely $\\theta_{0}=\\theta_{0}^{\\prime}$ , the following inequality holds: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\pmb{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\pmb{x})|\\right]\\leq\\frac{2L^{2}}{|\\mathcal{S}|}\\sum_{t=1}^{T}\\alpha_{t}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "From Lemma A.1, we have $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{gen}}\\leq\\frac{2L^{2}}{|S|}\\sum_{t=1}^{T}\\alpha_{t}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma A.3 (Non-convex case). Given the stochastic gradient method with an update rule as $G_{\\alpha,\\pmb{x}}(\\theta)=\\theta-\\alpha\\nabla_{\\theta}\\mathcal{L}(\\theta,\\pmb{x}),$ , then we have $\\begin{array}{r}{\\|G_{\\alpha,x}(\\theta_{1})-\\bar{G}_{\\alpha,x}(\\theta_{2})\\|\\leq(1+\\alpha\\beta)\\|\\theta_{1}\\stackrel{*}{-}\\theta_{2}\\|}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. This inequality can be easily obtained from the following: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|G_{\\alpha,x}(\\theta_{1})-G_{\\alpha,x}(\\theta_{2})\\|=\\|\\theta_{1}-\\theta_{2}-\\alpha(\\nabla_{\\theta}\\mathcal{L}(\\theta_{1},x)-\\nabla_{\\theta}\\mathcal{L}(\\theta_{2},x))\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\|\\theta_{1}-\\theta_{2}\\|+\\alpha\\|\\nabla_{\\theta}\\mathcal{L}(\\theta_{1},x)-\\nabla_{\\theta}\\mathcal{L}(\\theta_{2},x)\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq(1+\\alpha\\beta)\\|\\theta_{1}-\\theta_{2}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Non-convex setting Finally, we will give the proof for the non-convex case in Theorem 3.3(2). ", "page_idx": 14}, {"type": "text", "text": "Proof. We also consider the optimization trajectory $\\{\\theta_{t}\\}_{t=1}^{T}$ and $\\{\\theta_{t}^{\\prime}\\}_{t=1}^{T}$ from $\\boldsymbol{S}$ and $S^{\\prime}$ , which are identical except for one element. We assume two optimization trajectories, both obtained under the same random update rule and random permutation rule. Let $\\delta_{t}=\\lVert{\\boldsymbol{\\theta}}_{t}-{\\boldsymbol{\\theta}}_{t}^{\\prime}\\rVert$ and $t_{0}\\in\\{1,\\cdots,|S|\\}$ be a considered iteration. Here, $t\\leq|S|$ because for $t>|S|$ , we must have $\\delta_{t_{0}}\\neq0$ . Then we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\boldsymbol{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\boldsymbol{x})|\\right]=\\mathbb{P}(\\delta_{t_{0}}=0)\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\boldsymbol{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\boldsymbol{x})||\\delta_{t_{0}}=0\\right]}&{}\\\\ {+\\,\\mathbb{P}(\\delta_{t_{0}}\\neq0)\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\boldsymbol{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\boldsymbol{x})||\\delta_{t_{0}}\\neq0\\right]}&{}\\\\ {\\le L\\mathbb{E}\\left[||\\theta_{T}-\\theta_{T}^{\\prime}|||\\delta_{t_{0}}=0\\right]+\\mathbb{P}(\\delta_{t_{0}}\\neq0)C\\quad}&{\\mathrm{(Upper~bound~of~)}}\\\\ {=\\frac{C t_{0}}{|S|}+L\\mathbb{E}\\left[||\\theta_{T}-\\theta_{T}^{\\prime}|||\\delta_{t_{0}}=0\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Similar to the convex case, we analyze the expectation of parameter difference in the $(t+1)$ -th iteration as follows. Since $\\begin{array}{r}{\\alpha\\leq\\frac{1}{\\beta t}}\\end{array}$ , then we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\left[\\|\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\|\\|\\delta_{t_{0}}=0\\right]\\leq(1-\\frac{1}{|\\mathcal{S}|})(1+\\frac{1}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{1}{|\\mathcal{S}|}\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{2L}{\\beta t|\\mathcal{S}|}}}\\\\ &{}&{\\leq(1+\\frac{1}{t}-\\frac{1}{t|\\mathcal{S}|})\\mathbb{E}[\\delta_{t}]+\\frac{2L}{\\beta t|\\mathcal{S}|}}\\\\ &{}&{\\leq\\exp(\\frac{1}{t}-\\frac{1}{t|\\mathcal{S}|})\\mathbb{E}[\\delta_{t}]+\\frac{2L}{\\beta t|\\mathcal{S}|}.}&{(1+x\\leq\\exp(x))}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Accumulating the above in equations recursively, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\big[\\|\\theta_{T}-\\theta_{T}^{\\prime}\\|\\big\\|\\delta_{0}=0\\big]\\leq\\underset{t=t_{0}+1}{\\overset{T}{\\sum}}\\Bigg\\{\\Pi_{k=t+1}^{T}\\mathrm{exp}\\left(\\frac{1}{t}-\\frac{1}{t|S|}\\right)\\Bigg\\}\\frac{2L}{\\beta t|S|}}}\\\\ &{\\leq\\underset{t=t_{0}+1}{\\overset{T}{\\sum}}\\mathrm{exp}\\left((1-\\frac{1}{|S|})\\mathrm{log}\\frac{T}{t}\\right)\\frac{2L}{\\beta t|S|}}&{\\quad{\\scriptstyle(\\underset{k=t+1}{\\overset{T}{\\sum}}\\frac{1}{k}\\leq\\log\\frac{T}{t})}}\\\\ &{=\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\underset{t=t_{0}+1}{\\overset{T}{\\sum}}t^{-(1-\\frac{1}{|S|})-1}}\\\\ &{\\leq\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\frac{1}{1-\\frac{1}{|S|}}\\left(t_{0}^{-(1-\\frac{1}{|S|})}-T^{-(1-\\frac{1}{|S|})}\\right).}&{\\mathrm{(Integral~approximation)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Organizing the above inequalities, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\|\\theta_{T}-\\theta_{T}^{\\prime}\\||\\delta_{t_{0}}=0\\right]\\leq\\frac{2L}{\\beta(|S|-1)}\\left(\\frac{T}{t_{0}}\\right)^{1-\\frac{1}{|S|}}-\\frac{2L}{\\beta(|S|-1)}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2L}{\\beta(|S|-1)}\\left(\\frac{T}{t_{0}}\\right)-\\frac{2L}{\\beta(|S|-1)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "According to Eq. (24), for arbitrary $T\\geq1$ , we just choose $t_{0}=1$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\pmb{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\pmb{x})|\\right]\\leq\\frac{C}{|S|}+\\frac{2L^{2}(T-1)}{\\beta(|S|-1)}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This boundary is tighter than [13, 52], where the latter omits the $\\frac{2L}{\\beta(|S|-1)}$ term in Eq. (27). ", "page_idx": 15}, {"type": "text", "text": "A.2 Proof for Properties of Region Optimization (Lemma 3.4) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Since $\\mathcal{L}_{r}^{\\mathrm{region}}$ is defined as a region integral of $\\mathcal{L}$ , Lemma 3.4 can be easily obtained by: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{C_{r}^{\\mathrm{region}}(u_{\\theta},x)=\\displaystyle\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{r}}C(u_{\\theta},x+\\xi)\\mathrm{d}\\xi\\leq\\operatorname*{max}_{\\theta,x}\\mathcal{L}(u_{\\theta},x)}\\\\ &{\\big(\\nabla_{\\theta}C_{r}^{\\mathrm{region}}(u_{\\theta_{1}},x)-\\nabla_{\\theta}C_{r}^{\\mathrm{region}}(u_{\\theta_{2}},x)\\big)^{\\top}(\\theta_{1}-\\theta_{2})}\\\\ &{=\\displaystyle\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{r}}\\big(\\nabla_{\\theta}C(u_{\\theta_{1}},x+\\xi)-\\nabla_{\\theta}C(u_{\\theta_{2}},x+\\xi)\\big)^{\\top}\\left(\\theta_{1}-\\theta_{2}\\right)\\mathrm{d}\\xi\\geq0}\\\\ &{\\|C_{r}^{\\mathrm{region}}(u_{\\theta_{1}},x)-C_{r}^{\\mathrm{region}}(u_{\\theta_{2}},x)\\|}\\\\ &{\\leq\\displaystyle\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{r}}\\|C(u_{\\theta_{1}},x+\\xi)-\\mathcal{L}(u_{\\theta_{2}},x+\\xi)\\|\\,\\mathrm{d}\\xi\\leq L\\|\\theta_{1}-\\theta_{2}\\|}\\\\ &{\\|\\nabla_{\\theta}C_{r}^{\\mathrm{region}}(u_{\\theta_{1}},x)-\\nabla_{\\theta}C_{r}^{\\mathrm{region}}(u_{\\theta_{2}},x)\\|}\\\\ &{\\leq\\displaystyle\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{r}}\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{1}},x+\\xi)-\\nabla_{\\theta}C(u_{\\theta_{2}},x+\\xi)\\|\\,\\mathrm{d}\\xi\\leq\\beta\\|\\theta_{1}-\\theta_{2}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lipschitz: ", "page_idx": 15}, {"type": "text", "text": "Smoothness: ", "page_idx": 15}, {"type": "text", "text": "A.3 Proof for Region Optimization Generalization Error (Theorem 3.5) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Similar to the proof in Appendix A.1, we will discuss the generalization error on region optimization. ", "page_idx": 16}, {"type": "text", "text": "Convex setting Firstly, we would like to prove the convex case. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. According to Lemma 3.4, the region loss also holds the convexity, Lipschitz and smoothness properties, which ensures that Lemma A.2 and A.3 still work for $\\mathcal{L}_{r}^{\\mathrm{region}}$ . We also focus on the selected sample sets $\\boldsymbol{S}$ and $S^{\\prime}$ , which are identical except for one element. Thus, at $t$ -step, the following equation is satisfied: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\boldsymbol{\\uptau}}\\left[\\left\\Vert\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\right\\Vert\\right]=(1-\\frac{1}{|\\mathcal{S}|})\\mathbb{E}\\left[\\left\\Vert G_{\\alpha_{t},x}^{\\mathrm{region}}(\\theta_{t})-G_{\\alpha_{t},x}^{\\mathrm{region}}(\\theta_{t}^{\\prime})\\right\\Vert\\right]+\\frac{1}{|\\mathcal{S}|}\\mathbb{E}\\left[\\left\\Vert G_{\\alpha_{t},x}^{\\mathrm{region}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{region}}(\\theta_{t}^{\\prime})\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq(1-\\frac{1}{|\\mathcal{S}|})\\mathbb{E}\\left[\\left\\Vert\\theta_{t}-\\theta_{t}^{\\prime}\\right\\Vert\\right]+\\frac{1}{|\\mathcal{S}|}\\mathbb{E}\\left[\\left\\Vert G_{\\alpha_{t},x}^{\\mathrm{region}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{region}}(\\theta_{t}^{\\prime})\\right\\Vert\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $G_{\\alpha,\\pmb{x}}^{\\mathrm{region}}(\\theta)=\\theta-\\alpha\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(\\theta,\\pmb{x})$ . As for the second item on the right part, we also consider the upper bound of $\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\mathbf{x})$ . However, different from point-wise optimization, $\\pmb{x}+\\Omega_{r}$ could overlap with $\\pmb{x}^{\\prime}+\\Omega_{r}$ . For clarity, we define the overlapped area as $\\Omega_{\\mathrm{in}}$ , whose size is larger than zero when $\\mathbf{\\nabla}x^{\\prime}$ fall into the area centered at $\\textbf{\\em x}$ with size $2^{(d+1)}|\\Omega_{r}|$ . Actually, due to the boundary of $\\Omega$ , we cannot always ensure $(\\pmb{x}^{\\prime}+\\Omega_{r})\\subset\\Omega$ . Thus, for simplification, we assume that the domain $\\Omega$ can be projected to a torus, where the out-of-domain samples will be re-included to $\\Omega$ . ", "page_idx": 16}, {"type": "text", "text": "Further, $\\mathbb{E}_{\\mathbf{x},\\mathbf{x}^{\\prime}\\in\\Omega}$ , s.t. $|\\Omega_{\\mathrm{in}}|{=}0$ is simplified as $\\mathbb{E}_{\\Omega_{\\mathrm{in}}=0}$ and $\\mathbb{E}_{\\mathbf{x},\\mathbf{x}^{\\prime}\\in\\Omega}$ , s.t. $|\\Omega_{\\mathrm{in}}|\\!>\\!0$ is shorted as $\\mathbb{E}_{\\Omega_{\\mathrm{in}}>0}$ And the operator $\\mathbb{I}$ is defined as $\\mathbb{I}(x)=\\operatorname*{max}\\left(0,\\operatorname*{min}(1,x)\\right)$ Thus, we can obtain the estimation for the difference between the updated model parameters through the following derivations: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\{\\left|\\bar{Q}_{t}^{T}\\bar{Q}_{t}^{T}(\\theta_{t})\\right|\\leq C_{\\theta_{1}}\\alpha^{T}(\\theta_{1})\\}}\\\\ &{=\\prod_{t=1}^{(B)-2\\theta_{1}}\\frac{1}{\\alpha}\\Bigg\\{Q_{t}\\alpha_{t-1}\\Bigg\\}[\\prod_{t=1}^{B}\\alpha_{t}\\Big(\\prod_{t=1}^{B}\\theta_{t}\\Big)-C_{\\theta_{1},t}^{T}(\\theta_{1})\\Big]}\\\\ &{+\\prod_{t=1}^{(B)-1}\\frac{\\alpha_{t}^{T}}{\\alpha_{t}^{T}}\\Bigg\\{Q_{t}\\alpha_{t-1}\\Bigg[Q_{t}^{T}\\Big(Q_{t}^{T}\\Big(\\theta_{1}\\Big)-C_{\\theta_{1},t}^{T}(\\theta_{1})\\Big)}\\\\ &{\\leq1\\Bigg[\\frac{(B)-2\\alpha_{t}^{T}(1+1)\\alpha_{t}}{\\alpha_{t}^{T}}\\Bigg]Q_{t}\\alpha_{t-1}\\Bigg\\}[Q_{t}-\\theta_{1}\\Bigg]+\\mathcal{Q}_{t}\\alpha_{t}\\Bigg\\}}\\\\ &{+\\prod_{t=1}^{(B)-2\\theta_{1}}\\Bigg\\}\\sum_{k_{t=1}^{(B)-2\\theta_{1}}}\\Bigg\\{\\prod_{t=1}^{B}\\alpha_{t}\\Big(\\prod_{t=1}^{B}\\alpha_{t}+k\\Theta-\\alpha_{t}\\frac{1}{\\alpha_{t-1}^{T}}\\Big)\\int_{\\mathbb{R}_{0}}^{T}\\nabla_{t}G(\\theta_{1})}\\\\ &{\\leq1\\Bigg(\\frac{(B)-2\\alpha_{t}^{T}(1+1)\\alpha_{t}}{\\alpha_{t}^{T}}\\Big)\\int_{\\mathbb{R}_{0}}\\log\\frac{1}{\\alpha_{t-1}}[1+\\alpha_{t}\\Big(\\prod_{t=1}^{B}\\alpha_{t}\\Big(\\prod_{t=1}^{B}\\alpha_{t}+k\\Theta-\\alpha_{t}\\frac{1}{\\alpha_{t-1}^{T}}\\Big)\\int_{\\mathbb{R}_{0}}^{T}C_{\\theta}(\\theta_{1})}\\\\ &{+\\prod_{t=1}^{(B)-2\\theta_{1}}\\Big)\\int_{\\mathbb{R}_{0}\\to\\infty}\\left[\\left[\\frac{\\alpha_{t}^{T \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In the above inequalities, the third inequality is based on the following derivations. Firstly, denote $g=$ ", "page_idx": 16}, {"type": "text", "text": "$\\begin{array}{r}{\\|\\left(\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{\\mathrm{in}}}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},x+\\xi)\\mathrm{d}\\xi-\\frac{1}{|\\Omega_{r}|}\\int_{\\Omega_{\\mathrm{in}}}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}^{\\prime}},x+\\xi)\\mathrm{d}\\xi\\right)\\|.}\\end{array}$ According to Assumption 3.2, ", "page_idx": 16}, {"type": "text", "text": "we have $\\begin{array}{r}{g\\leq\\frac{|\\Omega_{\\mathrm{in}}|}{|\\Omega_{r}|}\\beta\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\leq\\beta\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|}\\end{array}$ . Thus, the following inequality holds: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\theta_{t}-\\theta_{t}^{\\prime}-\\left(\\alpha_{t}\\frac{1}{|\\Omega_{r}|}\\displaystyle\\int_{\\Omega_{\\mathrm{in}}}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},\\boldsymbol{x}+\\xi)\\mathrm{d}\\boldsymbol{\\xi}-\\alpha_{t}\\frac{1}{|\\Omega_{r}|}\\displaystyle\\int_{\\Omega_{\\mathrm{in}}}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}^{\\prime}},\\boldsymbol{x}+\\xi)\\mathrm{d}\\boldsymbol{\\xi}\\right)\\right\\|^{2}}\\\\ &{=\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|^{2}-2\\alpha_{t}g^{\\mathsf{T}}(\\theta_{t}-\\theta_{t}^{\\prime})+\\alpha_{t}^{2}g^{2}}\\\\ &{\\leq\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|^{2}-2\\frac{\\alpha_{t}}{\\beta}g^{2}+\\alpha_{t}^{2}g^{2}\\qquad\\qquad\\qquad\\qquad\\qquad(\\mathrm{Convexity\\and}\\ g\\leq\\beta\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|)}\\\\ &{\\leq\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, recursively accumulating the residual at the $t$ -th step, we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}\\leq\\big(1-\\frac{\\left|\\Omega_{r}\\right|}{\\left|\\Omega\\right|}\\big)\\frac{2L^{2}}{\\left|S\\right|}\\sum_{t=1}^{T}\\alpha_{t}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For the more general case, we no longer assume that the domain $\\Omega$ can be projected to a torus, resulting in a non-symmetric scenario when $|\\Omega_{\\mathrm{in}}|>0$ . This asymmetry arises due to the presence of boundaries, since points that could potentially intersect with the set $\\pmb{x}+\\Omega_{r}$ may be truncated by the boundary. Specifically, we consider $\\Omega=[0,\\dot{l}]^{(d+1)}$ and $\\Omega_{r}=[0,r]^{(d+1)}$ . The concrete probability $\\mathbb{P}(|\\Omega_{\\mathrm{in}}|>0)$ and the expectation $\\mathbb{E}_{|\\Omega_{\\mathrm{in}}|>0}(|\\Omega_{\\mathrm{in}}|)$ can be calculated as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}(|\\Omega_{\\mathrm{in}}|>0)=(\\frac{r(2l-3r)}{(l-r)^{2}})^{(d+1)},\\;\\mathbb{E}_{|\\Omega_{\\mathrm{in}}|>0}(|\\Omega_{\\mathrm{in}}|)=(\\frac{r^{2}(3l-4r)}{3(l-r)^{2}})^{(d+1)}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, the general case of Eq. 31 can be reformulated using the identities above. We assume $\\textstyle{\\frac{r}{l}}<0.5$ , as when $\\begin{array}{r}{\\frac{r}{l}\\geq0.5}\\end{array}$ , it follows that $\\mathbb{P}(|\\Omega_{\\mathrm{in}}|>0)=1$ . Specifically, Eq. (31) can be rewrite as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left\\{\\|\\mathcal{X}_{m_{k}}^{\\top,m_{k}}(\\theta_{t})-\\mathcal{X}_{m_{k}}^{\\top,m_{k}}(\\theta)\\right\\|\\right\\}}\\\\ &{=\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|=0\\}\\mathbb{E}_{m_{k}}\\left[\\left\\|\\mathcal{X}_{m_{k}}^{\\top,m_{k}}(\\theta)-\\mathcal{X}_{m_{k}}^{\\top,m_{k}}(\\theta^{*})\\right\\|\\right]+\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|>0\\}\\mathbb{E}_{m_{k}>0}\\left[\\big|\\mathcal{X}_{m_{k}}^{\\top,m_{k};m}(\\theta)-\\mathcal{X}_{m_{k}}^{\\top}(\\theta)\\big|\\right]}\\\\ &{\\le\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|=0\\}\\mathbb{E}_{m_{k}>0}\\left[\\|\\mathcal{H}_{m_{k}}-\\mathcal{H}_{l}\\|\\right]+\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|=0\\}\\mathbb{E}_{m_{k}>0}\\left[\\big|\\mathcal{X}_{m_{k}}^{\\top}\\big|-\\mathcal{X}_{m_{k}}^{\\top}\\big|\\right]}\\\\ &{+\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|>0\\}\\mathbb{E}_{m_{k}>0}\\left[\\big\\|\\mathcal{H}_{m_{k}}-\\mathcal{H}_{l}\\big|-\\Big(\\alpha_{m_{k}}^{*}\\big)\\Big|\\int_{m_{k}}\\mathbb{E}_{m}\\mathcal{L}(\\theta,\\theta_{t,k},\\theta^{*})+\\mathbb{E}\\|\\mathcal{X}_{m_{k}}^{\\top}-\\alpha_{m_{k}}^{*}\\|\\sum_{i_{1}=0}^{l}\\mathbb{E}_{m_{k}>0}\\right]}\\\\ &{\\le\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|=0\\}\\mathbb{E}_{m_{k}>0}\\left[\\|\\mathcal{H}_{m_{k}}-\\mathcal{H}_{l}\\|+\\mathbb{P}\\{\\|\\mathcal{X}_{m_{k}}\\|>0\\}\\mathbb{E}_{m_{k}>0}\\left[\\big|\\mathcal{X}_{m_{l}}^{\\top,1}\\|\\mathcal{X}_{m_{l}}\\right]\\right]}\\\\ &{+\\mathbb{P}\\{\\|\\mathcal{X}_{m \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, recursively accumulating the residual at the $t$ -th step, we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}\\leq\\left[1-(\\frac{r^{2}(2l-3r)(3l-4r)}{3(l-r)^{4}})^{(d+1)}\\right]\\frac{2L^{2}}{|\\mathcal{S}|}\\sum_{t=1}^{T}\\alpha_{t}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Although the specific forms differ and the general case is much more complex, these two inequalities both share the same intuitive meaning: region optimization beneftis from the overlap between $\\pmb{x}+\\Omega_{r}$ and $x^{\\prime}+\\Omega_{r}$ . Moreover, within a certain range, the benefti increases as the value of $r$ becomes larger. ", "page_idx": 17}, {"type": "text", "text": "Thus, to keep the bound simple and easy to understand, the main text theorems are under the assumption that \u2126can be projected to a torus. Otherwise, ||\u2126\u2126r|| should be replaced by $\\scriptstyle\\Big(\\frac{r^{2}(2l-3r)(3l-4r)}{3(l-r)^{4}}\\Big)^{(d+1)}$ ", "page_idx": 18}, {"type": "text", "text": "Non-convex setting Next, we will prove the non-convex setting. Similarly, we assume $\\Omega$ can be projected to a torus. Otherwise, the $\\frac{|\\Omega_{r}|}{|\\Omega|}$ in the final bound should be replaced by $\\textstyle\\big(\\frac{r^{2}(2l-3r)(3l-4r)}{3(l-r)^{4}}\\big)^{(\\stackrel{\\cdot}{d}+1)}$ ", "page_idx": 18}, {"type": "text", "text": "Proof. For clarity, let $\\begin{array}{r}{M=\\frac{|\\Omega_{r}|}{|\\Omega|}}\\end{array}$ . Then, we can rewrite the Eq. (25) as follows. ", "page_idx": 18}, {"type": "text", "text": "If $\\begin{array}{r}{\\mathbb{E}(\\delta_{t})\\leq\\frac{2L}{\\beta}}\\end{array}$ , we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\xi}\\left[\\|\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\||\\delta_{t_{0}}=0\\right]\\leq(1-\\displaystyle\\frac{1}{|\\mathcal{S}|})(1+\\displaystyle\\frac{1}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\displaystyle\\frac{1}{|\\mathcal{S}|}\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}^{\\mathrm{region}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{region}}(\\theta_{t}^{\\prime})\\|\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq(1-\\displaystyle\\frac{1}{|\\mathcal{S}|})(1+\\displaystyle\\frac{1}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\displaystyle\\frac{1}{|\\mathcal{S}|}\\left((1+\\displaystyle\\frac{M}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\displaystyle\\frac{2L}{\\beta t}(1+\\displaystyle\\frac{2L}{\\beta t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]\\right)}\\\\ &{\\qquad\\qquad\\leq(1+\\displaystyle\\frac{1}{t}-\\displaystyle\\frac{1-M}{t|\\mathcal{S}|})\\mathbb{E}[\\delta_{t}]+\\displaystyle\\frac{2L}{\\beta t|\\mathcal{S}|}(1-M)}\\\\ &{\\qquad\\qquad\\leq\\exp\\left(\\displaystyle\\frac{1}{t}-\\displaystyle\\frac{1-M}{t|\\mathcal{S}|}\\right)\\mathbb{E}[\\delta_{t}]+\\displaystyle\\frac{2L}{\\beta t|\\mathcal{S}|}(1-M),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the second inequality is based on the following derivations: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{1}\\left(\\frac{\\displaystyle\\frac{2}{\\displaystyle\\frac{3}{\\displaystyle\\nu}}\\left(1\\!-\\!\\frac{\\nu}{2}\\right)\\!\\frac{\\displaystyle\\nu}{\\displaystyle\\nu}\\right)_{2,\\ldots,n}\\left\\{\\left|\\frac{\\displaystyle\\left(\\nu\\!-\\!\\nu\\right)\\!-\\!\\nu\\right|_{{\\Omega}}}{\\displaystyle n\\!\\right\\}_{\\mathcal{A}_{n}\\to1}\\!\\right\\}}\\\\ &{\\leq_{1}\\left(\\frac{\\displaystyle\\frac{1}{\\displaystyle n}\\!-\\!\\frac{\\nu+\\nu\\left(1\\!+\\!\\frac{\\nu}{2}\\right)}{\\displaystyle n\\!-\\!\\nu\\right|n}}{\\displaystyle n\\!+\\!\\frac{\\nu}{2}\\left(1\\!-\\!\\frac{\\nu}{2}\\right)\\!\\frac{\\displaystyle\\nu}{\\displaystyle n}}\\right)_{\\Omega_{n}\\to1}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Notably, $\\mathbb{E}\\left[\\|G_{\\alpha_{t},\\pmb{x}}^{\\mathrm{region}}(\\theta_{t})-G_{\\alpha_{t},\\pmb{x}^{\\prime}}^{\\mathrm{region}}(\\theta_{t}^{\\prime})\\|\\right]$ has an obvious upper bound, i.e. $\\begin{array}{r}{\\left(\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{2L}{\\beta t}\\right)}\\end{array}$ . And only when $\\begin{array}{r}{\\mathbb{E}(\\delta_{t})\\leq\\frac{2L}{\\beta}}\\end{array}$ , the bound derived by Eq. (38) is tighter. Furthermore, the condition that $\\begin{array}{r}{\\mathbb{E}(\\delta_{t})\\leq\\frac{2L}{\\beta}}\\end{array}$ can be easily satisfied at the beginning several iterations since $\\mathbb{E}(\\delta_{0})=0$ . Otherwise, we still take the following equation: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Vert{\\theta}_{t+1}-\\theta_{t+1}^{\\prime}\\Vert|\\delta_{t_{0}}=0\\right]\\leq\\exp\\left(\\frac{1}{t}-\\frac{1}{t|S|}\\right)\\mathbb{E}[\\delta_{t}]+\\frac{2L}{\\beta t|S|},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where we do not consider the benefits brought by the overlap area of $\\pmb{x}+\\Omega_{r}$ and $x^{\\prime}+\\Omega_{r}$ . Suppose that at the first $K$ steps $\\begin{array}{r}{\\mathbb{E}[\\delta_{t_{0}+K}]\\leq\\frac{2L}{\\beta}}\\end{array}$ , Accumulating the above in equations recursively, we have the generalization error bound accumulated to the first $K$ steps as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta=\\underset{t=t_{\\mathrm{sup}}}{\\sum}\\Bigg\\{\\underset{u\\in\\mathbb{R}_{+}}{\\prod}\\Bigg(\\mathrm{I}_{\\mathbf{t}_{k+1}\\setminus\\mathbb{R}(\\mathbf{y})}\\bigg(\\frac{1}{t}-\\frac{1}{t}|\\mathbf{J}|\\Bigg)\\Pi_{k\\in\\mathbb{R}(\\mathbb{R}^{n})}^{T}\\Bigg(\\frac{1}{t}-\\frac{1}{t|\\mathbf{J}|}\\Bigg)\\Bigg\\}\\frac{2L}{\\beta|U|\\mathcal{S}|}\\Bigg(1-M\\Bigg)}\\\\ &{\\quad\\leq\\underset{t=t_{\\mathrm{sup}}}{\\sum}+\\mathrm{vep}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t_{\\mathrm{sup}}}+(1-\\frac{1-M}{|\\mathbf{J}|})\\log\\frac{t_{\\mathrm{sup}}(1+K)}{t}\\right)\\frac{2L}{\\beta|U|\\mathcal{S}|}(1-M)}\\\\ &{\\quad=\\underset{t=t_{\\mathrm{sup}}}{\\sum}+\\mathrm{vep}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t}+\\frac{M}{|\\mathbf{J}|}\\log\\frac{t_{\\mathrm{sup}}(1+K)}{t}\\right)\\frac{2L}{\\beta|U|\\mathcal{S}|}(1-M)}\\\\ &{\\quad\\overset{v\\in\\mathbb{R}^{n}}{\\sum}\\mathrm{tand}}\\\\ &{\\quad\\leq\\underset{t=t_{\\mathrm{sup}}}{\\sum}+\\mathrm{vep}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t}\\right)\\frac{2L}{\\beta|U|\\mathcal{S}|}(1-M)(\\frac{t_{\\mathrm{sup}}(1+K)}{t})^{\\frac{2}{3|\\mathbf{J}|}}}\\\\ &{\\quad\\leq\\underset{t=t_{\\mathrm{sup}}}{\\sum}+\\mathrm{vep}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t}\\right)\\frac{2L}{\\beta|U|\\mathcal{S}|}\\underset{t=t_{\\mathrm{sup}}}{\\sum}\\mathrm{trand}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t}\\right)\\frac{2L}{\\beta|U|\\mathcal{S}|}(1-M)}\\\\ &{\\quad\\overset{t\\in\\mathbb{R}^{n}}{\\sum}\\mathrm{tep}\\left((1-\\frac{1}{|\\mathbf{J}|})\\log\\frac{T}{t}\\right)\\frac{ \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $J$ is a finite value that depends on the training property of beginning iterations, namely $K$ and $t_{0}$ . The last inequality is from $\\begin{array}{r}{\\bar{({\\frac{t_{0}+K}{t}})}^{\\frac{M}{|S|}}\\le(1+\\bar{M})}\\end{array}$ , when $|{\\cal S}|$ is sufficient enough. Then, considering the all $T$ steps, we have ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\xi\\left[\\left\\lVert\\theta_{T}-\\theta_{T}^{\\prime}\\right\\rVert\\right\\rVert\\delta_{t_{0}}=0\\right]\\le\\Delta+\\displaystyle\\sum_{t=t_{0}+K+1}^{T}\\left\\{\\Pi_{k=t+1}^{T}\\mathrm{exp}\\left(\\frac{1}{t}-\\frac{1}{t|S|}\\right)\\right\\}\\frac{2L}{\\beta t|S|}}&\\\\ {\\le\\displaystyle\\sum_{t=t_{0}+1}^{T}\\mathrm{exp}\\left((1-\\frac{1}{|S|})\\log\\frac{T}{t}\\right)\\frac{2L}{\\beta t|S|}-J M^{2}~~}&{(\\displaystyle\\sum_{k=t+1}^{T}\\frac{1}{k}\\le\\log\\frac{T}{t})}\\\\ {=\\displaystyle\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\displaystyle\\sum_{t=t_{0}+1}^{T}t^{-(1-\\frac{1}{|S|})-1}-J M^{2}}\\\\ {\\le\\displaystyle\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\displaystyle\\frac{1}{1-\\frac{1}{|S|}}\\left(t_{0}^{-(1-\\frac{1}{|S|})}-T^{-(1-\\frac{1}{|S|})}\\right)-J M^{2},}&{(\\mathrm{Integral~appro})}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}&{...}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "ximation) ", "page_idx": 19}, {"type": "text", "text": "Thus, following a similar proof process as Theorem 3.3(2), we can obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Vert{\\theta}_{T}-\\theta_{T}^{\\prime}\\Vert\\vert\\delta_{t_{0}}=0\\right]\\le\\frac{2L}{\\beta(\\vert S\\vert-1)}(\\frac{T}{t_{0}})-\\frac{2L}{\\beta(\\vert S\\vert-1)}-J M^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "With $t_{0}=1$ , we have the generalization error under the non-convex case satisfies: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\pmb{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\pmb{x})|\\right]\\leq\\frac{C}{|S|}+\\frac{2L^{2}(T-1)}{\\beta(|S|-1)}-J L M^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A.4 Proof for High-order Constraint Optimization (Corollary 3.6) ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "First, we would like to prove the following Lemma. ", "page_idx": 20}, {"type": "text", "text": "Lemma A.4. Suppose that $\\mathcal{L}$ is bounded by $C$ for all $\\theta,x$ and is $L$ -Lipschitz and $\\beta$ -smooth for $\\theta$ , then the first-order j-th dimension loss function\u2202\u2202xj Lrregionis also bounded by C for all \u03b8, x and is $2L$ -Lipschitz and $2\\beta$ -smooth for $\\theta$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. For the bounded property, with the non-negative property of loss function, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{\\partial}{\\partial x_{j}}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta},\\pmb{x})=\\frac{\\partial}{\\partial x_{j}}\\int_{\\Omega_{r}}\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi})\\mathrm{d}\\boldsymbol{\\xi}=\\int_{\\Omega_{r}\\backslash x_{j}}\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi}_{r})-\\mathcal{L}(u_{\\theta},\\pmb{x}+\\pmb{\\xi}_{0})\\mathrm{d}\\boldsymbol{\\xi}\\leq C,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where ${\\pmb\\xi}_{r}=(\\cdots\\,,r,\\cdot\\,\\cdot\\,\\cdot\\,)\\in\\Omega_{t}\\backslash x_{j}$ and ${\\pmb\\xi}_{0}=(\\cdots\\,,0,\\cdots)\\in\\Omega_{t}\\backslash x_{j}$ . ", "page_idx": 20}, {"type": "text", "text": "As for the Lipschitz and smoothness, we can obtain the following inequalities: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Lipssitic}\\ \\ \\ |\\frac{\\partial}{\\partial x_{2}}\\mathcal{L}_{x}^{r,s+\\varepsilon=\\varepsilon}(u_{0},x)-\\frac{\\partial}{\\partial x_{2}}\\mathcal{L}_{x}^{r,s+\\varepsilon=\\varepsilon}(u_{0},x)||}\\\\ &{=1\\int_{\\Omega_{\\varepsilon,x_{1}}}\\mathcal{L}(u_{0},x+\\varepsilon,-\\varepsilon)-\\mathcal{L}(u_{0},x+\\varepsilon_{0})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})||}\\\\ &{\\leq\\int_{\\Omega_{\\varepsilon,x_{1}}}|\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})||+|E|(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})||}\\\\ &{\\leq2|\\mathcal{L}||\\mu_{1}-\\mathcal{L}_{x}||}\\\\ {\\mathrm{moodness.}\\ \\ |\\nabla_{\\sigma}\\frac{\\partial}{\\partial x_{2}}\\mathcal{L}_{x}^{r,s+\\varepsilon=\\varepsilon}(u_{0},x)-\\nabla_{\\sigma}\\frac{\\partial}{\\partial x_{2}}\\mathcal{L}_{x}^{r,s+\\varepsilon=\\varepsilon}(u_{0},x)||}\\\\ &{=\\|\\nabla_{\\sigma}\\int_{\\Omega_{\\varepsilon,x_{1}}}\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\mathcal{L}(u_{0},x+\\varepsilon_{*})}\\\\ &{\\leq\\int_{\\Omega_{\\varepsilon,x_{1}}}|\\nabla_{\\sigma}\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\nabla_{\\sigma}\\mathcal{L}(u_{0},x+\\varepsilon_{*})||\\mathcal{L}|}\\\\ &{\\ +\\int_{\\Omega_{\\varepsilon,x_{1}}}|\\nabla_{\\sigma}\\mathcal{L}(u_{0},x+\\varepsilon_{*})-\\nabla_{\\sigma}\\mathcal{L}(u_{0},x+\\varepsilon_{*})||\\mathcal{L}|}\\\\ &{\\leq2\\beta|\\mu_{1}-\\mathcal{L}_{x}||.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus,\u2202x $\\scriptstyle{\\frac{\\partial}{\\partial x_{j}}}{\\mathcal{L}}_{r}^{\\mathrm{region}}$ is also bounded by $C$ for all $\\theta,x$ and is $2L$ -Lipschitz and $2\\beta$ -smooth for $\\theta$ . ", "page_idx": 20}, {"type": "text", "text": "Next, we will give the proof for Corollary 3.6. ", "page_idx": 20}, {"type": "text", "text": "Proof. According to Lemma A.3, we have the gradient update operator region,xj for $\\scriptstyle{\\frac{\\partial}{\\partial x_{j}}}{\\mathcal{L}}_{r}^{\\mathrm{region}}$ satisfies the following inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|G_{\\alpha_{t},x}^{\\mathrm{region},x_{j}}(\\theta_{1})-G_{\\alpha_{t},x}^{\\mathrm{region},x_{j}}(\\theta_{2})\\|\\leq(1+2\\alpha_{t}\\beta)\\|\\theta_{1}-\\theta_{2}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let $\\begin{array}{r}{M=\\frac{|\\Omega_{r}|}{|\\Omega|}}\\end{array}$ , since $\\begin{array}{r}{\\alpha_{t}\\leq\\frac{1}{2\\beta t}}\\end{array}$ , we can rewrite the Eq. (37) as follows: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[\\|\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\||\\delta_{t_{0}}=0\\right]}\\\\ {\\displaystyle\\leq(1-\\frac{1}{|\\mathcal{S}|})(1+\\frac{1}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{1}{|\\mathcal{S}|}\\left((1+\\frac{M}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{2L}{\\beta}(1-M)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second term is derived from Eq. (38) by substituting $L$ to $2L$ and $\\beta$ to $2\\beta$ , which is: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}^{\\mathrm{region},x_{j}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{region},x_{j}}(\\theta_{t}^{\\prime})\\|\\right]\\leq(1+\\frac{2\\alpha_{t}\\beta|\\Omega_{r}|}{|\\Omega|})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+4\\alpha_{t}L(1-\\frac{|\\Omega_{r}|}{|\\Omega|})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=(1+\\frac{M}{t})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{2L}{\\beta t}(1-M).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus, following the same derivation as Theorem 3.5, we have Corollary 3.6 holds. ", "page_idx": 20}, {"type": "text", "text": "B Algorithm Analysis in Section 3.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "This section contains the proof for the theoretical analysis of our proposed algorithm in Section 3.2. ", "page_idx": 21}, {"type": "text", "text": "B.1 Proof for Convergence Rate of RoPINN (Theorem 3.8) ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The crux of proof is to take expectation for Monte Carlo sampling. ", "page_idx": 21}, {"type": "text", "text": "Proof. From Taylor expansion, there exist $\\pmb{x}^{\\prime}$ such that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t+1}},x)=\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}}-\\alpha_{t}\\nabla_{\\theta}\\mathcal L(u_{\\theta_{t}},x+\\xi),x)}\\\\ &{\\qquad\\qquad\\qquad=\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}},{x})-\\alpha_{t}\\nabla_{\\theta}\\mathcal L(u_{\\theta_{t}},{x}+\\xi)^{\\mathsf T}\\nabla_{\\theta}\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}},{x})}\\\\ &{\\qquad\\qquad\\qquad+\\,\\frac12(\\alpha_{t}\\nabla_{\\theta}\\mathcal L(u_{\\theta_{t}},{x}))^{\\mathsf T}\\nabla_{\\theta}^{2}\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}},{x}^{\\prime})(\\alpha_{t}\\nabla_{\\theta}\\mathcal L(u_{\\theta_{t}},{x}))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}},{x})-\\alpha_{t}\\nabla_{\\theta}\\mathcal L(u_{\\theta_{t}},{x}+\\xi)^{\\mathsf T}\\nabla_{\\theta}\\mathcal L_{r}^{\\mathrm{region}}(u_{\\theta_{t}},{x})+\\frac{\\alpha_{t}^{2}L^{2}H}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Taking expectations to $\\xi$ on both sides, since $\\mathbb{E}[\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},\\pmb{x}+\\pmb{\\xi})]=\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\pmb{x}+\\pmb{\\xi})$ , we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi\\left[\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t+1}},\\boldsymbol{x})\\right]\\leq\\mathbb{E}\\left[\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\boldsymbol{x})-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},\\boldsymbol{x}+\\xi)^{\\mathsf{T}}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\boldsymbol{x})+\\frac{\\alpha_{t}^{2}L^{2}H}{2}\\right]}\\\\ &{\\phantom{\\leq}=\\mathbb{E}\\left[\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\boldsymbol{x})\\right]-\\alpha_{t}\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\boldsymbol{x})\\right\\|^{2}\\right]+\\frac{\\alpha_{t}^{2}L^{2}H}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Rearranging the terms and accumulating over $T$ iterations, we have the following sum: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{=0}^{r-1}\\alpha_{t}\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},x)\\right\\|^{2}\\right]\\leq\\displaystyle\\sum_{t=0}^{T-1}\\left(\\mathbb{E}\\left[\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},x)\\right]-\\mathbb{E}\\left[\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t+1}},x)\\right]\\right)+\\displaystyle\\sum_{t=0}^{T-1}\\frac{\\alpha_{t}^{2}L^{2}I}{2}}\\\\ &{\\leq\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{0}},x)-\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{T}},x)+\\displaystyle\\frac{L^{2}H}{2}\\displaystyle\\sum_{t=0}^{T-1}\\alpha_{t}^{2}}\\\\ &{\\leq\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{0}},x)-\\mathcal{L}_{r}^{\\mathrm{region}}(u_{*},x)+\\displaystyle\\frac{L^{2}H}{2}\\displaystyle\\sum_{t=0}^{T-1}\\alpha_{t}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $u_{*}$ represents the global optimum. Here we run the gradient descent for a random number of iterations $\\tau$ . For $\\tau=t$ iterations with probability: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\tau=t)=\\frac{\\alpha_{t}}{\\sum_{k=0}^{T-1}\\alpha_{k}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, with $\\begin{array}{r}{\\alpha_{t}=\\frac{1}{\\sqrt{t+1}}}\\end{array}$ , we have the gradient norm is bounded by: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{\\tau}},\\boldsymbol{x})\\right\\|^{2}\\right]=\\left(\\displaystyle\\sum_{t=0}^{T-1}\\alpha_{t}\\right)^{-1}\\sum_{t=0}^{T-1}\\alpha_{t}\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{t}},\\boldsymbol{x})\\right\\|^{2}\\right]}\\\\ {\\displaystyle\\leq\\left(\\displaystyle\\sum_{t=0}^{T-1}\\alpha_{t}\\right)^{-1}\\left(\\angle_{r}^{\\mathrm{region}}(u_{\\theta_{0}},\\boldsymbol{x})-\\angle_{r}^{\\mathrm{region}}(u_{*},\\boldsymbol{x})+\\frac{L^{2}H}{2}\\sum_{t=0}^{T-1}\\alpha_{t}^{2}\\right)}\\\\ {\\displaystyle\\lesssim(2\\sqrt{T})^{-1}\\left(\\mathcal{L}_{r}^{\\mathrm{region}}(u_{\\theta_{0}},\\boldsymbol{x})-\\mathcal{L}_{r}^{\\mathrm{region}}(u_{*},\\boldsymbol{x})+\\frac{L^{2}H}{2}\\log(T+1)\\right)}\\\\ {\\displaystyle=\\mathcal{O}(\\frac{1}{\\sqrt{T}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "B.2 Proof for Estimation of RoPINN (Theorem 3.9) ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "As presented in Eq. (8) and (50), we approximate the region optimization with the Monte Carlo sampling method. For better efficiency, we propose only to sample one point at each iteration. However, this will cause an estimation error formalized in Theorem 3.9, which can be directly derived by the definition of standard deviation as follows: ", "page_idx": 22}, {"type": "text", "text": "Proof. According to the definition of $\\mathcal{L}_{r}^{\\mathrm{region}}$ in Eq. (5), we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\pmb{\\xi}\\sim U(\\Omega_{r})}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta},\\pmb{x}+\\pmb{\\xi}\\big)-\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{region}}\\big(u_{\\theta},\\pmb{x}\\big)\\right\\|^{2}\\right]^{\\frac{1}{2}}}\\\\ &{=\\mathbb{E}_{\\pmb{\\xi}\\sim U(\\Omega_{r})}\\left[\\left\\|\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta},\\pmb{x}+\\pmb{\\xi}\\big)-\\nabla_{\\theta}\\frac{1}{\\left|\\Omega_{r}\\right|}\\int_{\\Omega_{r}}\\mathcal{L}\\big(u_{\\theta},\\pmb{x}+\\pmb{\\xi}\\big)\\mathrm{d}\\boldsymbol{\\xi}\\right\\|^{2}\\right]^{\\frac{1}{2}}}\\\\ &{=\\left\\|\\sigma_{\\pmb{\\xi}\\sim U(\\Omega_{r})}\\left(\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta},\\pmb{x}+\\pmb{\\xi}\\big)\\right)\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "B.3 Proof for Estimation of Trust Region (Lemma 3.10 and Theorem 3.11) ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "First, we give the proof for Lemma 3.10. ", "page_idx": 22}, {"type": "text", "text": "Proof. According to Assumption 3.2, there exist $\\mathbf{\\nabla}x^{\\prime}$ , such that the following equation holds: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})}\\\\ &{=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}+\\alpha_{t-1}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})},z_{2})}\\\\ &{=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{2})+\\alpha_{t-1}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\nabla_{\\theta}^{2}\\mathcal{L}(u_{\\theta_{t-1}},x^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, the following inequality holds: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\left\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\right\\|-\\left\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{2})\\right\\||}\\\\ &{\\leq\\left\\|\\left(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\right)-\\left(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{1})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{2})\\right)\\right\\|}\\\\ &{=\\left\\|\\alpha_{t-1}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-1}},z_{2})\\nabla_{\\theta}^{2}\\mathcal{L}(u_{\\theta_{t-1}},x^{\\prime})\\right\\|}\\\\ &{\\leq\\beta L\\alpha_{t-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next, we will prove Theorem 3.11. ", "page_idx": 22}, {"type": "text", "text": "Proof. This theorem can be proved by demonstrating that: for all $i,j\\in\\{1,\\cdot\\cdot\\cdot,T_{0}\\}$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\operatorname*{lim}_{t\\to\\infty}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})}\\\\ {\\displaystyle}\\\\ {\\displaystyle\\operatorname*{lim}_{t\\to\\infty}\\big(\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-j+1}},z_{j})\\big)=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{j}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For the first equation, since $\\alpha_{t}\\,\\to\\,0$ , given $\\forall\\epsilon$ , there exists a constant $M$ such that any $t\\,>\\,M$ $\\begin{array}{r}{\\alpha_{t}\\le\\frac{\\epsilon}{T_{0}L\\beta}}\\end{array}$ . Thus, for any $t>M$ and any $i,j\\in\\{1,\\cdot\\cdot\\cdot,T_{0}\\}$ , the following equation is satisfied: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})\\|\\leq\\displaystyle\\sum_{k=1}^{i-1}\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+k}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+k+1}},z_{i})\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\displaystyle\\sum_{k=1}^{i-1}\\alpha_{t-i+k}L\\beta\\le\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, $\\begin{array}{r}{\\operatorname*{lim}_{t\\rightarrow\\infty}\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})=\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i}).}\\end{array}$ . Therefore, given $\\forall\\epsilon^{\\prime}$ , there exist a constant $M^{\\prime}$ , $\\forall t>M^{\\prime}$ , $\\begin{array}{r}{\\|\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta_{t-i+1}},z_{i}\\big)-\\nabla_{\\theta}\\mathcal{L}\\big(u_{\\theta_{t}},z_{i}\\big)\\|\\leq\\frac{\\epsilon}{2}}\\end{array}$ . ", "page_idx": 22}, {"type": "text", "text": "As for the second equation, for any $t>M^{\\prime}$ , the following equation is satisfied: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-j+1}},z_{j})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{j})\\|}\\\\ &{\\leq\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-i+1}},z_{i})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{i})\\|+\\|\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t-j+1}},z_{j})-\\nabla_{\\theta}\\mathcal{L}(u_{\\theta_{t}},z_{j})\\|\\leq\\epsilon^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, Theorem 3.11 can be proved by replacing the gradient of past iterations with their limitations. ", "page_idx": 22}, {"type": "text", "text": "B.4 Proof for Region Optimization with Gradient Estimation Error (Theorem 3.12) ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Convex setting Firstly, we would like to prove the convex case as follows. ", "page_idx": 23}, {"type": "text", "text": "Proof. Similar to the proof of region optimization in Appendix A.3, at the $t$ -th step, we can obtain the following equation: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{Z}\\left[\\left\\|\\theta_{t+1}-\\theta_{t+1}^{\\prime}\\right\\|\\right]=(1-\\frac{1}{|{\\cal S}|})\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}^{\\mathrm{approx}}(\\theta_{t})-G_{\\alpha_{t},x}^{\\mathrm{approx}}(\\theta_{t}^{\\prime})\\|\\right]+\\frac{1}{|{\\cal S}|}\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}^{\\mathrm{approx}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{approx}}(\\theta_{t}^{\\prime})\\|\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq(1-\\frac{1}{|{\\cal S}|})\\mathbb{E}\\left[\\|\\theta_{t}-\\theta_{t}^{\\prime}\\|\\right]+\\frac{1}{|{\\cal S}|}\\mathbb{E}\\left[\\|G_{\\alpha_{t},x}^{\\mathrm{approx}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{approx}}(\\theta_{t}^{\\prime})\\|\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $G_{\\alpha,x}^{\\mathrm{approx}}(\\theta)=\\theta-\\alpha\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{approx}}(\\theta,x)=\\theta-\\alpha\\nabla_{\\theta}\\mathcal{L}(\\theta,x+\\xi),\\boldsymbol{\\xi}\\sim U(\\Omega_{r})$ . Suppose that we have sampled $\\xi,\\xi^{\\prime}\\in\\Omega_{r}$ , the second term on the right part can be bounded as follows: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\Vert G_{\\alpha_{t},x}^{\\mathrm{approx}}(\\theta_{t})-G_{\\alpha_{t},x^{\\prime}}^{\\mathrm{approx}}(\\theta_{t}^{\\prime})\\Vert\\right]}\\\\ &{\\leq\\mathbb{E}\\left[\\Vert\\theta_{t}-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(\\theta_{t},x+\\xi)-\\theta_{t}^{\\prime}-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(\\theta_{t}^{\\prime},x^{\\prime}+\\xi^{\\prime})\\Vert\\right]}\\\\ &{\\leq\\mathbb{E}\\left[\\Vert\\theta_{t}-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{epion}}(\\theta_{t},x)-\\theta_{t}^{\\prime}-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{epion}}(\\theta_{t}^{\\prime},x^{\\prime})\\Vert\\right]}\\\\ &{+\\mathbb{E}\\left[\\Vert\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(\\theta_{t},x+\\xi)-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{epion}}(\\theta_{t},x)\\Vert\\right]}\\\\ &{+\\mathbb{E}\\left[\\Vert\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}(\\theta_{t},x^{\\prime}+\\xi^{\\prime})-\\alpha_{t}\\nabla_{\\theta}\\mathcal{L}_{r}^{\\mathrm{epion}}(\\theta_{t}^{\\prime},x^{\\prime})\\Vert\\right]}\\\\ &{\\leq\\mathbb{E}\\left[\\Vert\\theta_{t}-\\theta_{t}^{\\prime}\\Vert\\right]+2\\alpha_{t}L(1-\\frac{\\vert\\Omega_{r}\\vert}{\\vert\\Omega\\vert})+2\\alpha_{t}\\xi_{r,\\mathrm{grad}}}\\\\ &{=\\mathbb{E}\\left[\\Vert\\theta_{t}-\\theta_{t}^{\\prime}\\Vert\\right]+2\\alpha_{t}\\left(L(1-\\frac{\\vert\\Omega_{r}\\vert}{\\vert\\Omega\\vert})+\\mathcal{E}_{r,\\mathrm{grad}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, recursively accumulating the residual at the $t$ -th step, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}\\leq\\left(L(1-\\frac{|\\Omega_{r}|}{|\\Omega|})+\\mathcal{E}_{r,\\mathrm{grad}}\\right)\\frac{2L}{|S|}\\sum_{t=1}^{T}\\alpha_{t}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Non-convex setting Similarly, we can prove the non-convex setting as follows. ", "page_idx": 23}, {"type": "text", "text": "Proof. It is easy to prove that $\\mathcal{L}_{r}^{\\mathrm{approx}}(\\theta,\\pmb{x})$ is still $L$ -Lipchitz- $\\beta$ -smoothness for $\\theta$ . For clarity, we define that $\\begin{array}{r}{M=\\frac{|\\Omega_{r}|}{|\\Omega|}}\\end{array}$ . Thus, based on Eq. (38), we have the following derivations. ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\|\\bar{\\mu}_{t+1}-\\theta_{t+1}^{*}\\right\\|\\bar{\\delta}_{t}\\right]=0}\\\\ &{\\leq(1-\\frac{1}{|{\\mathcal E}|})(1+\\frac{1}{t})\\mathbb{E}\\left\\|\\bar{\\mu}_{t}-\\bar{\\theta}_{t}\\right\\|+\\frac{1}{|{\\mathcal E}|}\\mathbb{E}\\left[\\left\\|\\bar{G}_{\\alpha_{t,x}}^{\\mathrm{GPE}\\alpha\\alpha}(\\theta_{t})-G_{\\alpha_{t,x}}^{\\mathrm{sgrec}}(\\theta_{t}^{*})\\right\\|\\right]}\\\\ &{\\leq(1-\\frac{1}{|{\\mathcal E}|})(1+\\frac{1}{t})\\mathbb{E}\\left\\|\\bar{\\mu}_{t}-\\bar{\\theta}_{t}\\right\\|}\\\\ &{+\\frac{1}{|{\\mathcal E}|}\\left(\\mathbb{E}\\left[\\mathbb{E}|G_{\\alpha_{t,x}}^{\\mathrm{cosinr}}(\\theta_{t})-G_{\\alpha_{t,x}}^{\\mathrm{sgrec}}(\\theta_{t}^{*})\\right]\\right)}\\\\ &{+\\frac{1}{|{\\mathcal E}|}\\left(\\mathbb{E}\\left[|\\alpha_{t}\\nabla_{G}G(\\theta_{t},x+\\xi)-G_{\\alpha_{t}}\\nabla_{G}G_{\\alpha_{t,x}}^{\\mathrm{cosin}}(\\theta_{t},x)|\\right]\\right)}\\\\ &{+\\frac{1}{|{\\mathcal E}|}\\left(\\mathbb{E}\\left[|\\alpha_{t}\\nabla_{G}G(\\theta_{t},x^{+}\\xi)-G_{\\alpha_{t}}^{\\star}\\nabla_{G}G_{\\alpha_{t,x}}^{\\mathrm{cosin}}(\\theta_{t}^{*},x^{*})|\\right]\\right)}\\\\ &{\\leq(1+\\frac{1}{|{\\mathcal E}|}-\\frac{1}{t})\\mathbb{E}\\|\\bar{\\mu}_{t}\\|_{L^{1}}\\frac{2\\alpha_{t}^{2}}{|{\\mathcal E}|}\\left(L(1-M)+E_{\\alpha_{t,x}}^{2}\\mathrm{cosin}\\right)}\\\\ &{\\leq\\exp\\left(\\frac{1}{t}-\\frac{1}{t-M}\\right)\\mathbb{E}\\|\\bar{\\mu}_{t}\\|_{H}+\\frac{2}{\\beta_{t}^{2}M/3}~[{\\mathcal E}(1-M)+E_{\\alpha_{t,x}}^{2}\\mathrm{cosin}].}\\end{array\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Otherwise, we still consider the following inequality: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Vert{\\theta}_{t+1}-\\theta_{t+1}^{\\prime}\\Vert|\\delta_{t_{0}}=0\\right]\\leq\\exp\\left(\\frac{1}{t}-\\frac{1}{t|S|}\\right)\\mathbb{E}[\\delta_{t}]+\\frac{2L}{\\beta t|S|},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Suppose that at the first $K^{\\prime}$ steps $\\begin{array}{r}{\\mathbb{E}[\\delta_{t_{0}+K^{\\prime}}]\\leq\\frac{2L}{\\beta}-\\frac{2}{\\beta M}\\mathcal{E}_{r,\\mathrm{grad}}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Accumulating the above in equations recursively, we have the generalization error bound accumulated to the first $K^{\\prime}$ steps as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{a}:=\\frac{\\mu_{0}^{\\mathbb{E}}}{r_{0}\\to\\infty}\\left\\{\\begin{array}{l l}{\\mathfrak{R}_{t+\\varepsilon}^{(n,\\mathbb{E}^{\\prime})}\\cap\\mathbb{P}\\left(\\frac{1}{t},\\frac{1}{t(S)}\\right)\\mathbb{I}_{t=n+\\varepsilon^{\\mathbb{E}^{\\prime}}+\\exp{\\left(\\frac{1}{t},\\frac{1}{t(S)}\\right)}}^{\\mathbb{E}}\\frac{2}{\\mu_{|\\widetilde{S}|,\\widehat{S}|}}\\right\\}\\frac{2}{\\widehat{\\mu}_{|\\widetilde{S}|,\\widehat{S}|}^{2}}\\left(L(1-M)+\\mathcal{E}_{x,x x}\\right)}\\\\ &{\\mathfrak{c}:=\\frac{\\mu_{0}^{\\mathbb{E}+\\varepsilon^{\\mathbb{E}^{\\prime}}}}{r_{0}\\to\\infty}\\exp{\\left((1-\\frac{1}{|\\widetilde{S}|})\\log\\frac{T}{t}\\right)}\\frac{T}{\\mu_{0}+K^{\\prime}}+(1-\\frac{1-M}{|\\widetilde{S}|})\\log\\frac{t_{+}K^{\\prime}}{t}\\right\\}\\frac{2}{\\widehat{\\mu}_{|\\widetilde{S}|,\\widehat{S}|}^{2}}\\left(L(1-M)+\\mathcal{E}_{x,x x}\\right)}\\\\ &{\\mathfrak{w}_{t+\\varepsilon^{\\mathbb{E}^{\\prime}}}^{(\\mathbb{E},\\mathbb{E}^{\\prime})}\\exp{\\left((1-\\frac{1}{|\\widetilde{S}|})\\log\\frac{T}{t}+\\frac{M}{|\\widetilde{S}|}\\log\\frac{t_{+}K^{\\prime}}{t}\\right)}\\frac{2}{\\widehat{\\mu}_{|\\widetilde{S}|,\\widehat{S}|}}\\left(L(1-M)+\\mathcal{E}_{x,x x}\\right)}\\\\ &{\\mathfrak{w}_{t-\\widehat{\\mu}_{0}}^{(\\mathbb{E},\\mathbb{E}^{\\prime})}\\exp{\\left((1-\\frac{1}{|\\widetilde{S}|})\\log\\frac{T}{t}\\right)}\\frac{2}{\\widehat{\\mu}_{|\\widetilde{S}|,\\widehat{S}|}}\\left(L(1-M)+\\mathcal{E}_{x,x x}\\right)\\frac{t_{+}(K-\\varepsilon^{\\mathbb{E}^{\\prime}})}{\\widehat{\\mu}_{0}(1-M)}}\\\\ &{\\mathfrak{w}_{t-\\widehat{\\mu}_{0}}^{(\\mathbb{E},\\mathbb{E}^{\\prime \n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $J^{\\prime}$ is a finite value that depends on the training property of beginning iterations, namely $K^{\\prime}$ and $t_{0}$ . The last inequality is from $\\begin{array}{r}{\\big(\\frac{t_{0}+K^{\\prime}}{t}\\big)^{\\frac{M}{|S|}}\\leq\\big(1+\\overline{{M}}\\big)}\\end{array}$ , when $|{\\mathcal{S}}|$ is sufficient enough. ", "page_idx": 24}, {"type": "text", "text": "Then, considering the all $T$ steps, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|\\theta_{T}-\\theta_{T}^{\\mathcal{T}}\\||\\delta_{0}=0]}\\\\ &{\\le\\Delta+\\displaystyle\\sum_{t=t_{0}+K+1}^{T}\\left\\{\\prod_{k=t+1}^{T}\\exp\\left(\\frac{1}{t}-\\frac{1}{t|S|}\\right)\\right\\}\\frac{2L}{\\beta t|S|}}\\\\ &{\\le\\displaystyle\\sum_{t=t_{0}+1}^{T}\\exp\\left((1-\\frac{1}{|S|})\\log\\frac{T}{t}\\right)\\frac{2L}{\\beta t|S|}-J^{\\prime}M^{2}+J^{\\prime}E_{\\mathrm{r,grad}}(1+M)\\quad\\quad\\quad(\\sum_{k=t+1}^{T}\\frac{1}{k}\\le\\log\\frac{T}{t})}\\\\ &{=\\displaystyle\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\sum_{t=t_{0}+1}^{T}t^{-(1-\\frac{1}{|S|})-1}-J^{\\prime}M^{2}+J^{\\prime}E_{\\mathrm{s,grad}}(1+M)}\\\\ &{\\le\\frac{2L}{\\beta|S|}T^{1-\\frac{1}{|S|}}\\frac{1}{1-\\frac{1}{|S|}}\\left(t_{0}^{-(1-\\frac{1}{|S|})}-T^{-(1-\\frac{1}{|S|})}\\right)-J^{\\prime}M^{2}+J^{\\prime}E_{\\mathrm{r,grad}}(1+M).\\quad\\mathrm{(Inegrad~appre)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Next, following the proof in Appendix A.3, we can obtain the generalization bound as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[|\\mathcal{L}(u_{\\theta_{T}},\\boldsymbol{x})-\\mathcal{L}(u_{\\theta_{T}^{\\prime}},\\boldsymbol{x})|\\right]\\le\\frac{C}{|S|}+\\frac{2L^{2}(T-1)}{\\beta(|S|-1)}-J^{\\prime}L M^{2}+J^{\\prime}\\mathcal{E}_{r,\\mathrm{grad}}(1+M).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that $K^{\\prime}$ does not exist when $\\begin{array}{r}{\\frac{2L}{\\beta}<\\frac{2}{\\beta M}\\mathcal{E}_{r,\\mathrm{grad}}}\\end{array}$ , then $J^{\\prime}=0$ , which corresponds to the situation that the region size is too large and brings serious gradient estimation error. Introducing \u201cregion\u201d cannot bring a better generalization bound in this case. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "C Implementation Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "This section provides experiment details, including benchmarks, metrics and implementations. ", "page_idx": 25}, {"type": "text", "text": "C.1 Benchmarks ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "To comprehensively test our algorithm, we include the following four benchmarks. The first three benchmarks cover three typical PDEs (plotted in Figure 7), which are widely used in exploring the PINN optimization [24, 37]. The last one is an advanced comprehensive benchmark with 20 different PDEs. Here are the details. ", "page_idx": 25}, {"type": "image", "img_path": "wZigMVFURk/tmp/3ff5de361e3a7e71a786337a3c296be817b22b91acbc04d699951b16a921a601.jpg", "img_caption": ["Figure 7: Visualization of the solution $u$ for the first three benchmarks. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "1D-Reaction This problem is a one-dimensional non-linear ODE, which describes the chemical reactions. The concrete equation that we studied here can be formalized as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac{\\partial u}{\\partial t}-\\rho u(1-u)=0,\\,x\\in(0,2\\pi),t\\in(0,1),}\\\\ {u(x,0)=\\exp{\\left(-\\frac{(x-\\pi)^{2}}{2(\\pi/4)^{2}}\\right)},\\,x\\in[0,2\\pi],}\\\\ {u(0,t)=u(2\\pi,t),\\,t\\in[0,1].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The analytical solution to this problem is $\\begin{array}{r}{u(x,t)=\\frac{h(x)e^{\\rho t}}{h(x)e^{\\rho t}+1-h(x)}}\\end{array}$ and $\\begin{array}{r}{h(x)=\\exp\\left(-\\frac{(x-\\pi)}{2(\\pi/4)^{2}}\\right)}\\end{array}$ . In our experiments, we set $\\rho=5$ . This problem is previously studied as \u201cPINN failure mode\u201d [24], which is because of the non-linear term of the equation [29]. Besides, as shown in Figure 7(a), it contains sharp boundaries for the center high-value area, which is also hard to learn for deep models. ", "page_idx": 25}, {"type": "text", "text": "Following experiments in PINNsFormer [58], we uniformly sampled 101 points for initial state $\\Omega_{0}$ and boundary $\\partial\\Omega$ and a uniform grid of $101\\!\\times\\!101$ mesh points for the residual domain $\\Omega$ . For evaluation, we employed a $101\\!\\times\\!101$ mesh within the residual domain $\\Omega$ . This strategy is also adopted for 1D-Wave and Convection experiments. ", "page_idx": 25}, {"type": "text", "text": "1D-Wave This problem presents a hyperbolic PDE that is widely studied in acoustics, electromagnetism, and fluid dynamics [1]. Concretely, the PDE can be formalized as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\frac{\\partial^{2}u}{\\partial t^{2}}-4\\frac{\\partial^{2}u}{\\partial x^{2}}=0,\\,x\\in(0,1),t\\in(0,1),}\\\\ &{}&{u(x,0)=\\sin(\\pi x)+\\frac{1}{2}\\sin(\\beta\\pi x),\\,x\\in[0,1],\\,\\ \\ \\ }\\\\ &{}&{\\displaystyle\\frac{\\partial u(x,0)}{\\partial t}=0,\\,x\\in[0,1],\\,\\ \\ }\\\\ &{}&{u(0,t)=u(1,t)=0,\\,t\\in[0,1].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The analytic solution for this PDE is $\\begin{array}{r}{u(x,t)=\\sin(\\pi x)\\cos(2\\pi t)+\\frac{1}{2}\\sin(\\beta\\pi x)\\cos(2\\beta\\pi t)}\\end{array}$ . We set $\\beta=3$ for our experiments. As presented in Figure 7(b), the solution is smoother than the other two datasets, thereby easier for deep models to solve in some aspects. However, the equation contains second-order derivative terms, which also brings challenges in automatic differentiation. That is why gPINN [55] fails in this task (Table 2). ", "page_idx": 25}, {"type": "table", "img_path": "wZigMVFURk/tmp/a742b1aecc17375fabc29fa213246aed81ebace4fa02c7b5d18208f6214028e7.jpg", "table_caption": ["Table 4: Details of datasets in PINNacle [12] (16 different PDEs included in our experiments), including the dimension of inputs, highest order of PDEs, number of train/test points and concrete equations. Here we only present the simplified PDE formalizations for intuitive understanding. More detailed descriptions of PDE type and coefficient meanings can be found in their paper [12]. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Convection This problem is also a hyperbolic PDE that can be used to model fluid, atmosphere, heat transfer and biological processes [41]. The concrete PDE that we studied in this paper is: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac{\\partial u}{\\partial t}+\\beta\\frac{\\partial u}{\\partial t}=0,\\,x\\in(0,2\\pi),t\\in(0,1),}\\\\ {\\displaystyle u(x,0)=\\sin(x),\\,x\\in[0,2\\pi],}\\\\ {\\displaystyle u(0,t)=u(2\\pi,t),t\\in[0,1].}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The analytic solution for this PDE is $u(x,t)=\\sin(x-\\beta t)$ , where $\\beta$ is set as 50 in our experiments. Note that although the final solution seems to be quite simple, it is difficult for PINNs in practice due to the highly complex and high-frequency patterns. And the previous research [24] has shown that the loss landscape of the Convection equation contains many hard-to-optimize sharp cones. ", "page_idx": 26}, {"type": "text", "text": "PINNacle This benchmark [12] is built upon the DeepXDE [30], consisting of a wide range of PDEs and baselines. In their paper, the authors included 20 different PDE-solving tasks, covering diverse phenomena in fluid dynamics, heat conduction, etc and including PDEs with high dimensions, complex geometrics, nonlinearity and multiscale interactions. To ensure a comprehensive evaluation, we also benchmark RoPINN with PINNacle. ", "page_idx": 26}, {"type": "text", "text": "During our experiments, we found that there are several subtasks that none of the previous methods can solve, such as the 2D Heat equation with long time (Heat 2d-LT), 2D Navier-Stokes equation with long time (NS 2d-LT), 2D Wave equation with long time (Wave 2d-MS) and Kuramoto-Sivashinsky equation (KS). In addition to the challenges of high dimensionality and complex geometry mentioned by PINNacle, we discover unique challenges in these tasks caused by long periods and high-order derivatives of governed PDEs, making them extremely challenging for current PINNs. To solve these problems, we might need more powerful PINN backbones. Since we mainly focus on the PINN training paradigm, we omit the abovementioned 4 tasks to avoid the meaningless comparison and experiment with the left 16 tasks. Our datasets are summarized in Table 4. ", "page_idx": 26}, {"type": "text", "text": "C.2 Metrics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In our experiments, we adopt the following three metrics. Training loss, rMAE and rMSE. And the training loss has been defined in Eq. (2). Here are the calculations for rMSE and rMAE: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{rMAE:}\\ \\sqrt{\\frac{\\sum_{x\\in S}\\left|u_{\\theta}(\\pmb{x})-u_{*}(\\pmb{x})\\right|}{\\sum_{x\\in S}\\left|u_{*}(\\pmb{x})\\right|}}\\quad\\mathrm{rMSE:}\\ \\sqrt{\\frac{\\sum_{x\\in S}\\left(u_{\\theta}(\\pmb{x})-u_{*}(\\pmb{x})\\right)^{2}}{\\sum_{x\\in S}\\left(u_{*}(\\pmb{x})\\right)^{2}}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $u_{*}$ denotes the ground truth solution. Note that the model output and ground truth can be negative and positive, respectively. Thus, these two metrics could be larger than 1. ", "page_idx": 27}, {"type": "text", "text": "C.3 Implementations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "For classical base models PINN [36], QRes [3] and FLS [50], we adopt the conventional configuration from previous papers [58]. As for the latest model PINNsFormer [58] and KAN [28], we use their official code. Next, we will detail the implementations of optimization algorithms. ", "page_idx": 27}, {"type": "text", "text": "RoPINN As we described in the main text, we set the initial region size $r=10^{-4}$ , past iteration number $T_{0}\\;\\in\\;\\{5,10\\}$ and only sample 1 point for each region at each iteration for all datasets. The corresponding analyses have been included in Figure 2 for $r$ , Figure 3 for sampling points and Appendix D.1 for $T_{0}$ to demonstrate the algorithm property under different hyperparameter settings. ", "page_idx": 27}, {"type": "text", "text": "In addition, our formalization for region optimization in Eq. (8) only involves the equation, initial and boundary conditions, where we can still calculate their loss values after random sampling in the extended region. This definition perfectly matches the setting of 1D-Reaction, 1D-Wave and Convection. However, in PINNacle [12], some tasks also involve the data loss term, such as the inverse problem (Appendix D.2), which means we can only obtain the correct values for several observed or pre-calculated points. Since these points are pre-selected, we cannot obtain their new values after sampling. Thus, we do not apply region sampling to these points in our experiments. Actually, the data loss term only involves the forward process of deep models, which is a pure data-driven paradigm and is distinct from the other PDE-derived terms in PINNs. Therefore, the previous methods, gPINN and vPINN, also do not consider the data loss term in their algorithms. ", "page_idx": 27}, {"type": "text", "text": "gPINN For the first three benchmarks, we add the first-order derivatives for spatial and temporal dimensions as the regularization term. We also search the weights of regularization terms in $\\left\\lbrace1,0.1,0.01\\right\\rbrace$ and report the best results. As for the PINNacle, we report the results of canonical PINN following their paper [12] and experiment with other base models by only replacing the model. ", "page_idx": 27}, {"type": "text", "text": "vPINN We follow the code base in PINNacle, and implement it to the first three benchmarks. The test functions are set as Legendre polynomials and the test function number is set as 5. The number of points used to compute the integral within domain $\\Omega$ is set as 10, and the number of grids is set differently for each subtask, with values of {4, 8, 16, 32} for PINNacle and the same to other baselines for the first three benchmarks. ", "page_idx": 27}, {"type": "text", "text": "Other baselines In Table 3 of the main text, we also experiment with the loss-reweighting method NTK [47] and data-resampling method RAR [51]. For NTK, we follow their official code and recalculate the neural tangent kernel to update loss weights every 10 iterations. And the kernel size is set as 300. As for RAR, we use the residual-based adaptive refinement with distribution algorithm. ", "page_idx": 27}, {"type": "text", "text": "D Additional Results ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we provide more results as a supplement to the main text, including additional hyperparameter analysis, new experiments and more showcases. ", "page_idx": 27}, {"type": "text", "text": "D.1 Hyperparameter Sensitivity on $T_{0}$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "As we stated in Algorithm 1, we adopt the gradient variance of past $T_{0}$ iterations to approximate the sampling error defined in Theorem 3.9. In our experiments, we choose $T_{0}$ from $\\lbrace5,10\\rbrace$ , which can achieve consistently good and stable performance among different benchmarks and PDEs. To analyze the effect of this hyperparameter, we further add experiments with different choices in Figure 8. ", "page_idx": 27}, {"type": "image", "img_path": "wZigMVFURk/tmp/c820bf2621db3514135a4dcb2a1ece76033fae880e607a628c9f3414ca79403f.jpg", "img_caption": ["Figure 8: Hyperparameter analyses for $T_{0}$ in RoPINN based on PINN [36] and PINNsFormer [58] on different benchmarks. We change $T_{0}$ in $\\{1,5,10,15,20,25,30\\}$ and record the rMSE. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "As shown in Figure 8, we can find that under all the choices in $\\{1,5,10,15,20,25,30\\}$ , RoPINN performs better than the vanilla PINN. Specifically, in both 1D-Reaction and 1D-Wave (Figure 8(a-b)), the model performs quite stable under different choices of $T_{0}$ . As for Convection in Figure 8(c-d), the influence of $T_{0}$ is relatively significant in PINN. This may caused by the deficiency of PINN in solving Convection, where all the PINN-based experiments fail to generate an accurate solution for Convection $(\\mathrm{rMSE}{>}0.5$ , Table 2). If we adopt a more powerful base model, such as PINNsFormer [58], this sensitivity will be alleviated. Also, it is worth noticing that, even though in Convection, RoPINN surpasses the vanilla PINN under all hyperparameter settings of $T_{0}$ . ", "page_idx": 28}, {"type": "text", "text": "Besides, we can observe that the model performance slightly decreases when we set $T_{0}$ with a relatively large value. This may come from the difference between parameters $\\theta_{t}$ and $\\theta_{t+29}$ , which will make the gradient variance approximation less reliable (Eq. (58) in the Theorem 3.11 proof). ", "page_idx": 28}, {"type": "text", "text": "D.2 Experiments with Data Loss (Inverse Problem) ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "As we stated in the implementations (Appendix C.3), RoPINN can also be applied to tasks with data loss. Here we also include an inverse problem in PINNacle to testify to the performance of RoPINN in this case, which requires the model to reconstruct the diffusion coefficients of the Poisson equation from observations on 2500 uniform grids with additional Gaussian noise. ", "page_idx": 28}, {"type": "text", "text": "As presented in Table 5, in this task, RoPINN can also boost the performance of PINN with over $10\\%$ in the rMSE metric and outperform the other baselines (gPINN and vPINN) that cannot bring improvements. Note that in this experiment, we failed to reproduce the performance of vPINN reported by PINNacle. Thus, we report the results of vPINN by directly running the official code in PINNacle. ", "page_idx": 28}, {"type": "table", "img_path": "wZigMVFURk/tmp/c82ec55b7e89b403257b24460822015e7d28106b5fb5c81f58a23323e24bbeaf.jpg", "table_caption": ["Table 5: Experiments on the Possion inverse problem (PInv) of PINNacle. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "D.3 Standard Deviations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Considering the limited resources, we repeat all the experiments on the first three typical benchmarks and our method on the PINNacle three times and other experiments one time. The official paper of PINNacle has provided the standard deviations for PINN, gPINN and vPINN on all benchmarks. ", "page_idx": 28}, {"type": "text", "text": "We summarize the standard deviations of PINN in Table 6. As for other base models, the standard deviations of FLS, QRes and KAN are within 0.005 on 1D-Wave and Convection, and within 0.001 for 1D-Reaction. PINNsFormer\u2019s standard deviations are smaller than 0.001 for all three benchmarks. ", "page_idx": 28}, {"type": "text", "text": "Table 6: Standard deviations for canonical PINN on three typical benchmarks. The confidence for RoPINN achieving the best performance is over $99\\%$ in all three benchmarks. ", "page_idx": 28}, {"type": "table", "img_path": "wZigMVFURk/tmp/4e54647871c8799665ab8aaa7679650ba41d94e53af49daf4a618a2962a2b03e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "D.4 More Showcases ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "As a supplement to the main text, we provide the showcases of RoPINN in Figure 9. From these showcases, we can observe that RoPINN can consistently boost the model performance and benefit the solving process of boundaries, discontinuous phases and periodic patterns. ", "page_idx": 29}, {"type": "image", "img_path": "wZigMVFURk/tmp/e8033ac45fe69bbd35f217b278142ab3e05bbd632842bb07e49302352c3136c1.jpg", "img_caption": ["Figure 9: Showcases of RoPINN on the first three datasets based on PINN and PINNsFormer. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "D.5 Experiments with Advanced Quadrature Methods ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In our implementation, RoPINN employs a simple Monte Carlo sampling to approximate integral. Obviously, we can adopt more advanced quadrature methods, such as Gaussian quadrature [16]. Thus, we also experiment with 2D space Gaussian quadrature, which requires square number points and the one-point-sampling situation will degenerate to the center value. As shown in Table 7, we can find that under our official setting (only sampling one point), Monte Carlo is better, while Gaussian quadrature is better in more points. Note that although Gaussian quadrature has the potential to achieve better performance, sampling more points may contradict our motivation of boosting PINNs without extra backpropagation or gradient calculation. Thus, we choose the Monte Carlo method, which works better under high-efficiency settings. ", "page_idx": 29}, {"type": "table", "img_path": "wZigMVFURk/tmp/c8c2f64ad3392817933d2d1a2cfe6d5360488aecbab43e629192d7a6c2753b01.jpg", "table_caption": ["Table 7: Comparison between Monte Carlo approximation (Monte Carlo) and Gaussian quadrature (Gaussian) on 1D Reaction. rMSE is recorded. "], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "E Full Results on PINNacle ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In Table 2 of the main text, due to the context limitation, we only present the proportion of improved tasks over the total tasks. Here we provide the complete results for 5 based models for PINNacle (16 different tasks) in Table 8 and Table 9, where we can have the following observations: ", "page_idx": 29}, {"type": "text", "text": "\u2022 RoPINN presents favorable generality in varied PDEs and base models. As we described in Table 4, this benchmark contains of extensive physics phenomena. It is impressive that our proposed RoPINN can boost the performance of such extensive base models on a wide scope of PDEs, highlighting the generalizability of our algorithm.   \n\u2022 RoPINN is numerically stable and efficient for computation. As a training paradigm, RoPINN does not require extra gradient calculation and also does not add sampled points, which makes the algorithm computation efficient. In contrast, other baselines may generate poor results or encounter NaN or OOM problems in some PDEs. ", "page_idx": 29}, {"type": "table", "img_path": "wZigMVFURk/tmp/92dbe0be50d028577ffe228ceaebcba02bc95961cecfd69bdd485c04e12d7500.jpg", "table_caption": ["Table 8: Full results of gPINN [55], vPINN [18] and RoPINN under different base models on PINNacle [12] (16 different PDEs). A lower rMAE or rMSE with higher relative promotion indicates better performance. The promotion over vanilla is recorded in parentheses. For clarity, we highlight the value with blue if it surpasses the vanilla PINN, gray if it fails (over 10 times worse than the vanilla PINN), or is numerically unstable (NaN) or out-of-memory (OOM). "], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table 9: Full results of gPINN [55], vPINN [18] and RoPINN under different base models on PINNacle [12] (16 different PDEs). A lower rMAE or rMSE with higher relative promotion indicates better performance. The promotion over vanilla is recorded in parentheses. For clarity, we highlight the value with blue if it surpasses the vanilla PINN, gray if it fails (over 10 times worse than the vanilla PINN), or is numerically unstable (NaN) or out-of-memory (OOM). For PINNsFormer, it fails in most of the tasks due to the OOM problem. We omit these tasks in calculating proportion. ", "page_idx": 31}, {"type": "table", "img_path": "wZigMVFURk/tmp/aead5b7291b6d3b491e17ef231e4f033259c34f2d9fe419a861ea07067e6a391.jpg", "table_caption": [], "table_footnote": [], "page_idx": 31}, {"type": "text", "text": "F Related Work ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "This section will discuss some related works as a supplement to Section 2. We will first discuss some PINN research and then we will also clarify some looking similar but completely distinct topics. ", "page_idx": 31}, {"type": "text", "text": "PINN optimizers As we mentioned in the second paragraph of the introduction, many previous works focus on developing efficient and effective deep-model optimizers for PINNs [55, 37], which may help the optimization process tackle the ill-conditioned Hessian matrix or naturally balance multiple loss terms [53]. As we formalized in Algorithm 1, RoPINN is not restricted to a certain optimizer. The researchers can easily replace the Adam [21] or L-BFGS [27] with other advanced optimizers. Since we mainly focus on the objective function, these works are orthogonal to us. ", "page_idx": 31}, {"type": "text", "text": "Numerical differentiation for objective functions In addition to the regularization or variationalbased methods, some researchers attempt to replace the automatic differentiation with numerical approximations [39, 9], which can tackle the expensive computation cost caused by calculating high-order derivatives. However, this paradigm does not attempt to change the objection function definition, just focuses on the calculation of point optimization PINN loss, which is distinct from our proposed region optimization paradigm. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "Sampling-based methods Strategies for sampling collocation points perform an important role in training PINN models [46]. Previous sampling-based methods mainly focus on accumulating collocation points to high-residual areas [51, 23] or considering the temporal causality [45], whose theoretical analyses are usually based on the quadrature theorem [32]. Distinct from these methods, RoPINN is motivated by the optimization deficiency of PINN models and can be seamlessly integrated with sampling-based methods with significant promotion (Table 3), indicating that RoPINN works orthogonally to sampling methods. Besides, the theoretical analysis of RoPINN also starts from the optimization perspective, which reveals that one key advancement of RoPINN is a better balance between optimization error and generalization error (Theorem 3.12). ", "page_idx": 32}, {"type": "text", "text": "In addition, RoPINN is also distinct from data augmentation or adversarial training techniques in the following aspects: (1) Theorem difference: although our proposed practical algorithm is based on Monte Carlo sampling in a region, the underlying theoretical support and insights are a region-based objective function (Theorem 3.5). (2) Implementation difference: In our algorithm, not only is the input changed, but the objective is also correspondingly changed. Thus, this paper is foundationally different from augmentation and adversarial training in that the ground truth label is fixed. Our design is tailored to the physics-informed loss function of PINNs, where we can accurately calculate the equation residual at any point within the input domain. ", "page_idx": 32}, {"type": "text", "text": "G Limitations ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "This paper presents region optimization as a new PINN training paradigm and provides both theoretical analysis and practical algorithms, supported by extensive experiments. However, there are still several limitations. In the theoretical analysis, we assume that the canonical loss function is $L$ -Lipschitz- $\\cdot\\beta\\cdot$ -smooth, which may not be guaranteed in practice. Besides, RoPINN involves several hyperparameters, such as initial region size $r$ , and number of past iterations $T_{0}$ . Although we have studied the sensitivity w.r.t. them in Figures 2 and Appendix D.1 and demonstrate that they are easy to tune in most cases, we still need to adjust them for better performance in practice. ", "page_idx": 32}, {"type": "text", "text": "According to our experiments and theorems, we provide some recipes for hyperparameter tuning in the following, which may be helpful to the usage of RoPINN: ", "page_idx": 32}, {"type": "text", "text": "\u2022 As shown in Figure 2, region size $r$ will be progressively adjusted by RoPINN. Setting $r$ in $[10^{-6},10^{-4}]$ can work well. According to Theorem 3.12, the choice of $r$ should balance optimization and generalization, which may be inherently decided by the PDE smoothness. \u2022 As analyzed in Figures 3 and 4, sampling 1-30 points can gain consistent promotion but will linearly increase the computation costs. Following our default setting (sampling one point) can already achieve a competitive performance in a wide range of PDEs. \u2022 As presented in Figure 8, number of past iterations $T_{0}$ is easy to tune in [1, 20]. Setting $T_{0}\\bar{\\in}\\{5,10\\}$ can be a good choice, which has been widely verified in our paper. \u2022 Some hyperparameter tuning tools, such as Weights and Bias (Wandb1), may mitigate this limitation to some extent, which has already been used in previous related work [37]. ", "page_idx": 32}, {"type": "text", "text": "H Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "In this paper, we develop a new region optimization training paradigm for PINNs and provide both theorem analyses and practical algorithms. This new perspective may inspire the subsequent research of PINNs, especially rethinking the canonical objective function. In addition, our proposed RoPINN shows favorable efficiency and generalizes well in different base models and PDEs, which can be used to boost the precision of PINNs and generally benefit the downstream tasks, such as physics phenomenon simulation, biological property analysis, etc. Since we purely focus on the training algorithm of PINNs, there are no potential negative social impacts or ethical risks. ", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: This paper proposes a new training paradigm for PINNs along with a practical algorithm. Theoretical analyses (Theorems 3.3-3.12), extensive experiments (Tables 2, 8 and 9) and detailed discussions of related work (Section 2 and Appendix F) are provided to verify the effectiveness of our design and clarify the scope of our paper. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have discussed our limitations in Appendix G. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have provided complete and detailed proofs for all the lemmas, theorems and corollaries in Appendixes A and B. The previous works have also been properly cited. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have clearly formalized our method in Algorithm 1, which is easy to reproduce. We have also included every detail of datasets, baselines and hyperparameters of our algorithm in both the main text and Appendix C. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Code is available at this repository: https://github.com/thuml/RoPINN. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have included all the details in Appendix C. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have included the statistical significance in Appendix D.3. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We have included these details in the main text (Section 4) and Table 3. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: We have strictly followed the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: We have included the discussion in Appendix H. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: All the data and code are used with proper citation and license. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 37}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA]   \nJustification: Not applicable. Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] Justification: Not applicable. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] Justification: Not applicable. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]