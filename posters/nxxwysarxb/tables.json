[{"figure_path": "nXXwYsARXB/tables/tables_2_1.jpg", "caption": "Table 1: Comparison of HDPD to prior works that decompose ML performance gaps. The distinguishing contribution of this work is that it unifies aggregate and detailed decompositions under a nonparametric framework with uncertainty quantification.", "description": "This table compares the proposed Hierarchical Decomposition of Performance Differences (HDPD) framework with existing methods for decomposing machine learning performance gaps.  It highlights key differences across several aspects: whether the methods perform aggregate decomposition, detailed decomposition for covariate shift and conditional outcome shift, whether causal graph knowledge is required, whether confidence intervals are provided, and whether the approach is nonparametric. The table shows that HDPD uniquely combines all these desirable features, providing a more complete and robust framework for understanding ML performance discrepancies.", "section": "Introduction"}, {"figure_path": "nXXwYsARXB/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of HDPD to prior works that decompose ML performance gaps. The distinguishing contribution of this work is that it unifies aggregate and detailed decompositions under a nonparametric framework with uncertainty quantification.", "description": "This table compares the proposed Hierarchical Decomposition of Performance Differences (HDPD) framework with existing methods for decomposing ML performance gaps.  It highlights that HDPD uniquely combines aggregate and detailed decompositions in a nonparametric way, providing confidence intervals and not requiring causal graph knowledge.  Prior methods only address parts of this hierarchical decomposition, often making parametric assumptions or requiring knowledge of the causal graph,  limiting their applicability and interpretability.", "section": "1 Introduction"}, {"figure_path": "nXXwYsARXB/tables/tables_31_1.jpg", "caption": "Table 1: Comparison of HDPD to prior works that decompose ML performance gaps. The distinguishing contribution of this work is that it unifies aggregate and detailed decompositions under a nonparametric framework with uncertainty quantification.", "description": "This table compares the proposed Hierarchical Decomposition of Performance Differences (HDPD) framework with existing methods for decomposing machine learning performance gaps.  It highlights that HDPD uniquely combines aggregate and detailed decompositions in a nonparametric way, offering confidence intervals and not requiring causal graph knowledge, unlike many previous approaches. ", "section": "1 Introduction"}, {"figure_path": "nXXwYsARXB/tables/tables_32_1.jpg", "caption": "Table 1: Comparison of HDPD to prior works that decompose ML performance gaps. The distinguishing contribution of this work is that it unifies aggregate and detailed decompositions under a nonparametric framework with uncertainty quantification.", "description": "This table compares the proposed Hierarchical Decomposition of Performance Differences (HDPD) method with existing methods for decomposing machine learning (ML) performance gaps.  It highlights HDPD's unique ability to provide both aggregate and detailed decompositions in a nonparametric way, offering confidence intervals and not requiring knowledge of the causal graph.", "section": "1 Introduction"}]