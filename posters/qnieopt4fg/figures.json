[{"figure_path": "QNieOPt4fg/figures/figures_0_1.jpg", "caption": "Figure 1: Existing advanced data selection strategies rely heavily on external models or data; however, SelectIT effectively overcomes this limitation.", "description": "This figure is a comparison of different methods for instruction tuning (IT) of large language models (LLMs).  It highlights that existing advanced methods like LIMA, AlpaGasus, and Instruction Mining rely on either external models or additional data for selecting high-quality instruction data. In contrast, SelectIT leverages the LLM's intrinsic capabilities and doesn't require extra resources, making it a more efficient and accessible approach.", "section": "1 Introduction"}, {"figure_path": "QNieOPt4fg/figures/figures_2_1.jpg", "caption": "Figure 2: Overall framework of SelectIT. In Token-level Self-Reflection, we employ the foundation model to rate the IT data from 1 to K. In Sentence-level Self-Reflection, we leverage the uncertainty of varied prompts on LLMs to enhance the rating process. In Model-level Self-Reflection, we harness uncertainty among different LLMs to facilitate a collaborative decision-making process in selecting IT data. Finally, different levels of self-reflection are reasonably combined into SelectIT, which can effectively select high-quality IT data without relying on additional resources.", "description": "This figure illustrates the overall framework of the SelectIT method.  It shows three main levels of self-reflection: token-level, sentence-level, and model-level.  Each level uses the inherent uncertainty within LLMs to score the quality of instruction tuning (IT) data. The token-level focuses on the next-token prediction probability, sentence-level incorporates variations in prompt phrasing, and model-level considers the discrepancies between different LLMs' evaluations.  These individual scores are then combined to produce a final quality score for each data point, enabling effective selection of high-quality data without requiring external resources.", "section": "3 Our SelectIT Method"}, {"figure_path": "QNieOPt4fg/figures/figures_5_1.jpg", "caption": "Figure 3: Comparison of LLM abilities with varying Alpaca proportions.", "description": "This figure shows the results of an ablation study on the impact of the size of the instruction tuning dataset on the performance of LLMs.  The x-axis represents the proportion of the Alpaca dataset used for training, ranging from 10% to 100%. The y-axis shows the change in LLM ability (\u0394), likely measured by some benchmark score, reflecting the improvement achieved by fine-tuning with different proportions of data. Two lines are plotted, representing the performance of LLaMA-2-7B and LLaMA-2-13B models.  The graph illustrates an optimal range (marked as \"Best Size\") where using a smaller subset of the data (around 20-40%) yields better results than using the full dataset. This highlights the importance of data quality over quantity in instruction tuning.", "section": "5.1 Abalation Study of SelectIT"}, {"figure_path": "QNieOPt4fg/figures/figures_9_1.jpg", "caption": "Figure 2: Overall framework of SelectIT. In Token-level Self-Reflection, we employ the foundation model to rate the IT data from 1 to K. In Sentence-level Self-Reflection, we leverage the uncertainty of varied prompts on LLMs to enhance the rating process. In Model-level Self-Reflection, we harness uncertainty among different LLMs to facilitate a collaborative decision-making process in selecting IT data. Finally, different levels of self-reflection are reasonably combined into SelectIT, which can effectively select high-quality IT data without relying on additional resources.", "description": "This figure illustrates the overall framework of the SelectIT method for selective instruction tuning. It shows three main levels of self-reflection: token-level, sentence-level, and model-level. Each level leverages the intrinsic uncertainty of LLMs to improve the accuracy of IT data selection. The token-level uses next-token prediction probabilities, the sentence-level considers the variance in scores from multiple prompts, and the model-level integrates the ratings from multiple LLMs. Finally, these three levels are combined to generate a final score for each data point, allowing SelectIT to effectively select high-quality data without external resources.", "section": "3 Our SelectIT Method"}, {"figure_path": "QNieOPt4fg/figures/figures_9_2.jpg", "caption": "Figure 5: Left: The average length of samples. Right: The proportion of calculation type.", "description": "This figure shows two bar charts comparing the characteristics of instructions in three datasets: Full Alpaca, AlpaGasus, and Selective Alpaca.  The left chart displays the average length of instructions in each dataset, showing that Selective Alpaca has the longest average instruction length (241.85), followed by AlpaGasus (208.27), and Full Alpaca (176.09).  The right chart shows the percentage of instructions that involve calculations in each dataset.  Selective Alpaca has the highest percentage (8.55%), indicating a higher proportion of computationally intensive instructions compared to AlpaGasus (1.83%) and Full Alpaca (4.34%). This suggests that SelectIT preferentially selects instructions with a higher computational complexity.", "section": "5 Analysis"}, {"figure_path": "QNieOPt4fg/figures/figures_9_3.jpg", "caption": "Figure 6: Changing trends of the calculation and sample length with different data sizes.", "description": "This figure shows the trends of the proportion of calculation and the average length of samples in Alpaca-GPT4 dataset with different proportions after sorting by SelectIT.  It illustrates how these characteristics change as more data is included. The key observation is that as the proportion of Alpaca-GPT4 data increases beyond 50%, the proportion of calculation-based instruction tuning data drops significantly (below 6%), leading to a noticeable decline in the overall capabilities of the LLMs.  This suggests that longer, more computationally intensive instruction tuning data might be more effective for improving LLMs' abilities.", "section": "5 Analysis"}, {"figure_path": "QNieOPt4fg/figures/figures_18_1.jpg", "caption": "Figure 2: Overall framework of SelectIT. In Token-level Self-Reflection, we employ the foundation model to rate the IT data from 1 to K. In Sentence-level Self-Reflection, we leverage the uncertainty of varied prompts on LLMs to enhance the rating process. In Model-level Self-Reflection, we harness uncertainty among different LLMs to facilitate a collaborative decision-making process in selecting IT data. Finally, different levels of self-reflection are reasonably combined into SelectIT, which can effectively select high-quality IT data without relying on additional resources.", "description": "This figure illustrates the overall framework of the SelectIT method, which leverages the uncertainty inherent in LLMs at three levels: token, sentence, and model.  Each level contributes to a score for each piece of instruction tuning (IT) data, ultimately leading to a ranked list of data suitable for fine-tuning. This process eliminates the need for additional models or data.", "section": "3 Our SelectIT Method"}]