[{"figure_path": "Q8yfhrBBD8/tables/tables_6_1.jpg", "caption": "Table 1: Results comparison on the CATH dataset. Benchmarked results are quoted from Hsu et al. [22], Zheng et al. [64], Yi et al. [58], Gao et al. [14]. \u2020: \u201cSingle-chain\u201d in Hsu et al. [22] is defined differently. The best and suboptimal results are labeled with bold and underline.", "description": "This table compares the performance of Bridge-IF with other state-of-the-art methods on the CATH dataset for inverse protein folding.  It shows the perplexity (lower is better) and recovery rate (higher is better) for three protein categories: short proteins, single-chain proteins, and all proteins.  Results are broken down by the language model used (ESM-1b or ESM-2) and whether or not pre-trained language models were used.  The table highlights Bridge-IF's superior performance, especially when using larger language models and improved training techniques.  The '+' symbol denotes different definitions of single-chain proteins among various models.", "section": "5.2 Inverse folding"}, {"figure_path": "Q8yfhrBBD8/tables/tables_7_1.jpg", "caption": "Table 2: Numerical comparison on foldability and recovery rate. Benchmarked results are quoted from Wang et al. [53]. The best and suboptimal results are labeled with bold and underline.", "description": "This table compares the performance of different inverse folding methods in terms of TM-score and recovery rate.  The TM-score measures the similarity between the predicted and native protein structures, while the recovery rate reflects the accuracy of sequence recovery.  The methods are compared against a baseline of native sequences, and also against simpler approaches using uniform or natural frequencies of amino acids.  The table highlights that Bridge-IF achieves the best performance in terms of both TM-score and recovery rate.", "section": "5.3 Foldability"}, {"figure_path": "Q8yfhrBBD8/tables/tables_8_1.jpg", "caption": "Table 3: Ablation studies of key design choices on CATH v4.2. \"w/ AdaLN-Bias\" replaces the vanilla AdaLN with AdaLN-Bias. \"w/ SCE\" replaces the variational lower bound loss with simplified cross-entropy loss.", "description": "This table presents the results of ablation studies conducted to evaluate the impact of key design choices in the Bridge-IF model.  The studies focus on three aspects: the use of pre-training, AdaLN-Bias (a modified adaptive layer normalization), and the simplified cross-entropy loss (SCE). By comparing the performance metrics (perplexity and recovery rate) across different combinations of these design choices, the table helps to understand their individual contributions and the overall effectiveness of the Bridge-IF model.", "section": "5.5 Ablation Studies"}, {"figure_path": "Q8yfhrBBD8/tables/tables_14_1.jpg", "caption": "Table 4: Performance on multi-chain protein complex dataset (in median recovery). Results of the original ProteinMPNN and GVP-Transformer were obtained using publicly available checkpoints.", "description": "This table presents the performance of different models on a multi-chain protein complex dataset.  The median recovery rate is used as the evaluation metric.  The models compared include ProteinMPNN, ProteinMPNN with CMLM, LM-Design with different combinations of pre-trained models (ProtMPNN-CMLM and ESM-1b or ESM-2), and Bridge-IF with a pre-trained PiFold model and ESM-2. The results show that Bridge-IF achieves the best performance, demonstrating its effectiveness in designing multi-chain protein complexes.", "section": "B.1 Multi-chain protein complex design"}]