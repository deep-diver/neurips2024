[{"figure_path": "1l9cEyFmxg/figures/figures_0_1.jpg", "caption": "Figure 1: Comparison of sampled images using 18-step MaskGIT [4] without (top) and with the proposed self-guidance (bottom) on ImageNet 512\u00d7512 (left) and 256\u00d7256 (right) resolutions. Each paired image is sampled using the same random seed and sampling hyperparameters. The proposed self-guidance effectively improves the capabilities of the masked generative models.", "description": "This figure shows a comparison of image samples generated by MaskGIT with and without the proposed self-guidance method.  The top row displays samples generated without self-guidance, while the bottom row shows samples generated with it.  Each pair of images uses the same random seed and hyperparameters, demonstrating the improvement in image quality achieved by the self-guidance technique. The images are from the ImageNet dataset at two different resolutions (512x512 and 256x256).", "section": "Abstract"}, {"figure_path": "1l9cEyFmxg/figures/figures_2_1.jpg", "caption": "Figure 2: Visualization of the effect of guidance using spatial smoothing (SAG) [22] and the proposed semantic smoothing. We tokenize the input image using VQGAN [11] encoder, mask the 90% of VQ tokens, and predict x0,t using MaskGIT [4]. With the proposed self-guidance leveraging semantic smoothing, generated sample quality is improved by enhancing fine-scale details.", "description": "This figure compares image generation results using different guidance methods.  The input image is tokenized, and 90% of the tokens are masked.  Three different approaches are shown: a single prediction step from the masked image; self-guidance with spatial smoothing (SAG), which uses a spatial smoothing technique to guide the generation process; and the proposed self-guidance with semantic smoothing, which leverages an auxiliary task to smooth the VQ tokens before guiding the generation.  The results demonstrate that the proposed method significantly improves the fine-scale details and quality of the generated images compared to the other methods.", "section": "Methods"}, {"figure_path": "1l9cEyFmxg/figures/figures_5_1.jpg", "caption": "Figure 3: (a) Fine-tuning the feature selection module H\u2084 (TOAST [49]). With the auxiliary objective in Eq. (7), H\u2084 implicitly learns to smooth erroneous input zt to address semantic outliers (Section 3.2). (b) During the sampling steps, self-guidance can be efficiently implemented by leveraging the feature map from the generative process. H\u2084 performs semantic smoothing on the input xt, guiding the sampling process toward enhancing fine-scale details in the generated sample.", "description": "This figure illustrates the architecture and workflow of the proposed self-guidance method. Panel (a) shows the training process for the feature selection module (H\u2084), a crucial component for semantic smoothing in the VQ token space.  The module is fine-tuned using an auxiliary objective (Laux) to learn to correct errors in the input (zt), effectively smoothing the input before feeding it into the pretrained masked generator. Panel (b) details how self-guidance is applied during sampling. The pretrained masked generator produces initial predictions, which are then processed by the fine-tuned feature selection module (H\u2084) to generate semantically smoothed output.  This smoothed output guides the sampling process, improving the quality of the final generated samples by focusing on finer-scale details.", "section": "3 Methods"}, {"figure_path": "1l9cEyFmxg/figures/figures_7_1.jpg", "caption": "Figure 4: IS vs. FID curves of various sampling methods for MGMs on ImageNet 256\u00d7256 and 512\u00d7512. The curve positioned towards the bottom right indicates a better trade-off between sample quality and diversity. We plot the curve by varying the sampling temperature (T), and the curves of MaskGIT [4] and Token-Critic [35] are taken from Token-Critic [35].", "description": "This figure shows the trade-off between Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) for different sampling methods applied to Masked Generative Models (MGMs) on ImageNet datasets with resolutions 256x256 and 512x512.  The curves are generated by varying the sampling temperature. A curve towards the lower-right corner represents better sample quality (higher IS) and diversity (lower FID).  The figure compares the proposed method's performance to existing methods like MaskGIT and Token-Critic.", "section": "5 Experiments"}, {"figure_path": "1l9cEyFmxg/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of sampled images using 18-step MaskGIT [4] without (top) and with the proposed self-guidance (bottom) on ImageNet 512\u00d7512 (left) and 256\u00d7256 (right) resolutions. Each paired image is sampled using the same random seed and sampling hyperparameters. The proposed self-guidance effectively improves the capabilities of the masked generative models.", "description": "This figure compares image samples generated by MaskGIT with and without the proposed self-guidance method.  The top row shows samples generated without self-guidance, while the bottom row shows samples generated with it.  The images are from the ImageNet dataset at two resolutions (512x512 and 256x256). Each pair of images uses the same random seed and parameters to highlight the impact of the self-guidance.  The results demonstrate that self-guidance significantly improves image quality.", "section": "Abstract"}, {"figure_path": "1l9cEyFmxg/figures/figures_9_1.jpg", "caption": "Figure 6: Exploring the sampling hyperparameters by varying (a) guidance scale, (b) sampling temperature, (c) sampling timesteps, and (d) fine-tuning epochs.", "description": "This figure shows the impact of four different hyperparameters on the performance of the proposed self-guidance method.  The plots show FID and IS scores (metrics for image generation quality and diversity) as a function of each hyperparameter, revealing the optimal range for each parameter to achieve a balance between quality and diversity. (a) Guidance scale: Shows that a moderate guidance scale is optimal.  (b) Temperature: Shows that higher temperatures lead to higher diversity but lower quality; a lower temperature provides better quality but reduced diversity. (c) Timesteps: Reveals the optimal number of timesteps for sampling. (d) Fine-tuning epochs: Illustrates that the model converges quickly; further fine-tuning does not significantly improve the results.", "section": "5.2 Ablation Studies and Analysis"}, {"figure_path": "1l9cEyFmxg/figures/figures_14_1.jpg", "caption": "Figure 7: Sampled images on ImageNet 256\u00d7256 class conditional generation using (a) our default config, (b) large guidance scale (s = 5), and (c) high sampling temperature (\u03c4 = 50).", "description": "This figure shows the effect of varying guidance scale and sampling temperature on the quality of generated images using the proposed self-guidance method.  (a) shows images generated with default settings. (b) shows images generated with a higher guidance scale (s=5), which leads to higher-quality images but possibly reduced diversity. (c) shows images generated with higher temperature (\u03c4=50), resulting in more diverse but potentially lower-quality samples.", "section": "B Effect of High Sample Temperature and Guidance Scale"}, {"figure_path": "1l9cEyFmxg/figures/figures_15_1.jpg", "caption": "Figure 5: Sampled images on ImageNet 256\u00d7256 class conditional generation using selected classes (105: Koala, 661: model T, and 933: Cheeseburger). left: LDM [44] + CFG (s=1.5, NFE=250\u00d72), middle: MaskGIT (NFE=18), right: Ours (s=1.0, NFE=18\u00d72).", "description": "This figure compares the image generation quality of three different methods: LDM with classifier-free guidance, MaskGIT, and the proposed method.  Each column shows generated images for the same three classes (Koala, model T, Cheeseburger) using each method.  The number of function evaluations (NFE) is also given, indicating the computational cost of each method.", "section": "5.1 Comparison with Various Generative Models"}]