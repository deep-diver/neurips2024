[{"figure_path": "FtzLbGoHW2/tables/tables_7_1.jpg", "caption": "Table 1: Comparative analysis of representation density and performance on the PHOENIX-2014T dataset. \"+SignCL\" indicates the inclusion of the proposed contrastive learning strategy during VLP (Video Language Processing) feature extraction or SLT (Sign Language Translation) training processes. WERs (Word Error Rates) in the gloss-free set are derived from an independent SLR (Sign Language Recognition) task, used specifically for probing the quality of sign features. These WERs do not participate in the SLT training process.", "description": "This table presents a comparative analysis of representation density and performance on the PHOENIX-2014T dataset.  It shows the impact of integrating the SignCL method on both gloss-based and gloss-free feature extraction techniques, using different metrics like SDR (Sign Density Ratio), WER (Word Error Rate), and BLEU-4 score (B@4).  The results highlight the improvement in performance achieved by SignCL in reducing representation density and enhancing the accuracy of sign language recognition and translation.", "section": "5.1 Experiments on Sign Language Transformer"}, {"figure_path": "FtzLbGoHW2/tables/tables_8_1.jpg", "caption": "Table 2: Improvement in the GFSLT-VLP framework by reducing representation density on PHOENIX-2014T test set. \"+SignCL into Pretraining\" indicates applying the proposed contrastive learning strategy during the pretraining stage, while \"+SignCL into Finetuning\" indicates the inclusion of the SignCL during the finetuning stage. \"+SignCL into Two State\" means plus SignCL both in pertaining and finetuning states.", "description": "This table shows the performance improvement of GFSLT-VLP model by applying SignCL in different training stages (pretraining, finetuning, or both).  The results are evaluated on the PHOENIX-2014T test set, using metrics such as Recall@1 (R@1), BLEU scores at different levels (B@1, B@2, B@3, B@4), and Sign Density Ratio (SDR).  The table demonstrates that incorporating SignCL leads to significant improvements in translation performance, especially when applied during both pretraining and finetuning.", "section": "5.2 Experiments on Gloss-free Sign Language Translation"}, {"figure_path": "FtzLbGoHW2/tables/tables_8_2.jpg", "caption": "Table 3: Enhancing GFSLT-VLP by reducing representation density on CSL-Daily test set.", "description": "This table presents a comparative analysis of representation density and performance on the CSL-Daily test set.  It shows the results for the baseline GFSLT-VLP model and three variants incorporating the SignCL contrastive learning strategy at different stages (pretraining, finetuning, or both).  The metrics include the Sign Density Ratio (SDR), Recall at 1 (R@1), and BLEU scores at different levels (B@1, B@2, B@3, B@4). The improvement achieved by SignCL in each metric is also displayed, highlighting its positive impact on performance.", "section": "5.2 Experiments on Gloss-free Sign Language Translation"}, {"figure_path": "FtzLbGoHW2/tables/tables_13_1.jpg", "caption": "Table 4: Hyperparameters of Sign Language Transformer models.", "description": "This table lists the hyperparameters used for training the Sign Language Transformer models on the PHOENIX-2014T and CSL-Daily datasets.  The hyperparameters control various aspects of the model's architecture and training process, including the number of encoder and decoder layers, attention heads, hidden size, activation function, learning rate, Adam beta parameters, label smoothing, maximum output length, dropout rate, and batch size.  These settings were optimized for each dataset to achieve the best performance.", "section": "A.1 Hyper-parameters of Baselines"}, {"figure_path": "FtzLbGoHW2/tables/tables_13_2.jpg", "caption": "Table 5: Detailed Gloss-Free SLT (GFSLT) Framework. B represents batch size, T denotes the length of the longest input sign video in the batch, and U is the length of the longest input text in the batch. It is copied from GFSLT-VLP [52].", "description": "This table details the architecture of the Gloss-Free Sign Language Translation (GFSLT) model used in the paper. It breaks down the different modules involved, their strides and kernel sizes, and the resulting output sizes at each stage of processing.  It shows how the model processes both sign language input (video) and text input, ultimately leading to a final output.  The table uses B for batch size, T for the length of the longest video, and U for the length of the longest text input. The values are copied from a previously published work, GFSLT-VLP [52].", "section": "A.1 Hyper-parameters of Baselines"}, {"figure_path": "FtzLbGoHW2/tables/tables_14_1.jpg", "caption": "Table 1: Comparative analysis of representation density and performance on the PHOENIX-2014T dataset. \"+SignCL\" indicates the inclusion of the proposed contrastive learning strategy during VLP (Video Language Processing) feature extraction or SLT (Sign Language Translation) training processes. WERs (Word Error Rates) in the gloss-free set are derived from an independent SLR (Sign Language Recognition) task, used specifically for probing the quality of sign features. These WERS do not participate in the SLT training process.", "description": "This table compares the performance of different sign language translation models on the PHOENIX-2014T dataset. It shows that the proposed SignCL method significantly improves performance by reducing the representation density.  The table compares gloss-based and gloss-free methods, with and without SignCL.  Performance is evaluated using SDR (Sign Density Ratio), WER (Word Error Rate), and BLEU score (B@4).", "section": "5.1 Experiments on Sign Language Transformer"}, {"figure_path": "FtzLbGoHW2/tables/tables_14_2.jpg", "caption": "Table 7: Sensitivity to Zipf's factor.", "description": "This table presents the results of an ablation study on the sensitivity of the SignCL model to different values of the Zipf's factor.  The Zipf's factor is used to dynamically estimate the margin for negative sampling in the contrastive learning process. The table shows the BLEU-4 scores obtained using five different Zipf's factor values (1, GT, 2.3, 3, and 4).  The GT (Ground Truth) value represents the actual average margin calculated from the data.  The experiment results shows that SignCL model is relatively insensitive to the choice of Zipf's factor within this range.", "section": "A.2 Parameter Sensitivity Analysis of SignCL"}, {"figure_path": "FtzLbGoHW2/tables/tables_15_1.jpg", "caption": "Table 8: Ablation study on the impact of different loss components in the +SignCL approach.", "description": "This ablation study investigates the individual effects of VLP Loss, SignCL Loss, SLT Loss, and SignCL Loss on the performance of the Sign Language Transformer model.  The table shows that the inclusion of both SignCL loss components (during both pre-training and fine-tuning) significantly improves performance, as indicated by lower SDR (Sign Density Ratio) and higher R@L and B@4 metrics. The study highlights the importance of SignCL in enhancing performance.", "section": "A.3 Ablation Studies"}, {"figure_path": "FtzLbGoHW2/tables/tables_15_2.jpg", "caption": "Table 1: Comparative analysis of representation density and performance on the PHOENIX-2014T dataset. \"+SignCL\" indicates the inclusion of the proposed contrastive learning strategy during VLP (Video Language Processing) feature extraction or SLT (Sign Language Translation) training processes. WERs (Word Error Rates) in the gloss-free set are derived from an independent SLR (Sign Language Recognition) task, used specifically for probing the quality of sign features. These WERs do not participate in the SLT training process.", "description": "This table compares the performance of different models on the PHOENIX-2014T dataset, focusing on the impact of representation density. It shows the sign density ratio (SDR), word error rate (WER), and BLEU score (B@4) for various models with and without the proposed SignCL method. The results demonstrate that SignCL significantly reduces the representation density, leading to improved performance in both sign language recognition and translation.", "section": "5.1 Experiments on Sign Language Transformer"}, {"figure_path": "FtzLbGoHW2/tables/tables_16_1.jpg", "caption": "Table 10: Correlation analysis between sign recognition performance and density metrics.", "description": "This table presents the results of a correlation analysis between sign recognition performance (accuracy) and density metrics (Inter-Gloss Distance, Intra-Gloss Distance, and Sign Density Ratio) for both PHOENIX-2014T and CSL-Daily datasets.  It shows the Pearson and Spearman correlation coefficients, along with their corresponding p-values, indicating the strength and significance of the relationships.  Negative correlation between SDR and accuracy suggests that higher representation density correlates with poorer recognition performance.  Conversely, a positive correlation between Inter-Gloss Distance and accuracy shows that greater distances between different glosses correlate with better recognition performance.", "section": "A.4.2 Correlation Coefficient"}, {"figure_path": "FtzLbGoHW2/tables/tables_16_2.jpg", "caption": "Table 11: Comparative analysis of representation density and performance on the PHOENIX-2014T dataset. \"+SignCL (ours)\" indicates the inclusion of the proposed contrastive learning strategy during VLP feature extraction or NSLT training processing.", "description": "This table presents a comparative analysis of representation density and performance on the PHOENIX-2014T dataset for different feature extraction methods: Self-Mutual KD, Sign Recognition, I3D Pretrained, and VLP Pretrained.  It shows the Sign Density Ratio (SDR), Word Error Rate (WER) for Sign Language Recognition (SLR), and BLEU scores (B@4) for Sign Language Translation (SLT) using the Joint-SLT and NSLT models.  The table also includes results when the proposed contrastive learning strategy, SignCL, is integrated into either feature extraction or the SLT training process.", "section": "5.1 Experiments on Sign Language Transformer"}, {"figure_path": "FtzLbGoHW2/tables/tables_16_3.jpg", "caption": "Table 11: Comparative analysis of representation density and performance on the PHOENIX-2014T dataset. \"+SignCL (ours)\" indicates the inclusion of the proposed contrastive learning strategy during VLP feature extraction or NSLT training processing.", "description": "This table compares different feature extraction methods (gloss-based and gloss-free) for their representation density and performance on the PHOENIX-2014T dataset.  The performance metrics are evaluated using Word Error Rate (WER) for Sign Language Recognition (SLR) and BLEU score (B@4) for Sign Language Translation (SLT), using both the standard Sign Language Transformer and a version enhanced with SignCL (the proposed contrastive learning method). It shows that reducing representation density using SignCL leads to improved performance on both SLR and SLT tasks.", "section": "5.1 Experiments on Sign Language Transformer"}]