[{"figure_path": "FtzLbGoHW2/figures/figures_1_1.jpg", "caption": "Figure 1: An example of the representation density problem in sign language translation. The two images show the sign gestures for \u201cRECIPROCATE\u201d (blue dot) and \u201cREVENGE\u201d (orange dot). Although the two have opposite meanings, their visual representations are densely clustered together, as shown in the t-SNE visualization. The various colors in the visualization indicate sign gestures with different meanings.", "description": "This figure illustrates the representation density problem in sign language translation.  It shows a t-SNE visualization of feature vectors representing different sign gestures.  Notice that the vectors for \"RECIPROCATE\" and \"REVENGE\", which have opposite meanings, are clustered very closely together in the feature space.  This proximity makes it difficult for a model to distinguish between them, highlighting the challenge posed by representation density in gloss-free sign language translation.", "section": "3 Representation Density Problem"}, {"figure_path": "FtzLbGoHW2/figures/figures_4_1.jpg", "caption": "Figure 2: The t-SNE visualization of sign features across existing extraction techniques. SRP, SMKD, and I3D are downloaded from their official websites, while VLP is reproduced with official code. The addition of +SignCL denotes our proposed method that integrates a contrastive learning strategy into the VLP method (see Section 4). Different colors represent sign gestures with distinct semantics. Points in gray represent other sign categories not listed. Better viewed by zooming in.", "description": "This figure visualizes the feature distributions of different sign gesture extraction methods using t-SNE.  It shows how densely clustered the representations are for different methods, with gloss-free methods (VLP, I3D) exhibiting higher density than gloss-based methods (SRP, SMKD). The addition of SignCL to the VLP method significantly reduces the density, illustrating the effectiveness of the proposed contrastive learning approach.", "section": "3.2 Demonstrating Representation Density Problem"}, {"figure_path": "FtzLbGoHW2/figures/figures_4_2.jpg", "caption": "Figure 3: Comparative analysis of representation density and its impact on sign language recognition (SLR) and translation (SLT). The left panel (a) shows the correlation between representation density and SLR accuracy across different sign feature types and sign gesture groups. Binning in this context is based on sorting by gloss density within a group, where higher bins indicate higher density. The right panel (b) illustrates the performance drops in SLT caused by the representation density problem. This figure assesses both the recognition and translation accuracies, reflecting how denser representations impact these metrics.", "description": "This figure shows a comparative analysis of how representation density affects sign language recognition (SLR) and translation (SLT) performance.  The left panel (a) displays the relationship between representation density and SLR accuracy for different feature types and sign gesture groups.  The groups are ranked by their density. The right panel (b) shows how different SLT models' performance decreases as representation density increases. It compares models using gloss-based and gloss-free features and highlights that those using gloss-free features consistently suffer performance drops due to representation density.", "section": "3.2 Demonstrating Representation Density Problem"}, {"figure_path": "FtzLbGoHW2/figures/figures_6_1.jpg", "caption": "Figure 4: Overview of the SignCL in gloss-free sign language translation: (a) Sign contrastive learning sampling strategy, (b) Showcases the integration of SignCL in the pretraining stage, and (c)) Displays the application of SignCL during the finetuning stage.", "description": "This figure illustrates how the Sign contrastive learning (SignCL) strategy is integrated into a gloss-free sign language translation framework.  Panel (a) shows the contrastive learning sampling strategy, where adjacent frames are considered positive samples and distant frames are negative samples. Panel (b) demonstrates how SignCL is incorporated during the model's pretraining phase, enhancing visual-text alignment. Finally, panel (c) shows the integration of SignCL into the fine-tuning phase, improving the translation performance. The overall goal is to reduce the representation density problem by learning more discriminative feature representations.", "section": "4 Contrastive Learning for Gloss-free Sign Langauge Translation"}, {"figure_path": "FtzLbGoHW2/figures/figures_9_1.jpg", "caption": "Figure 5: Qualitative comparison of translation results on CSL-Daily test set. The red background denotes model misinterpretations about the sign gestures, while green one means accurate recognition. Content in (...) is English translation for non-Chinese readers.", "description": "This figure shows a qualitative comparison of translation results obtained using GFSLT-VLP and GFSLT-VLP with SignCL on the CSL-Daily dataset. The left side presents the results of GFSLT-VLP which misinterprets the sign for \"piano\" as \"laptop\".  The t-SNE visualization shows the close proximity of the two signs in the feature space leading to this error. The right side demonstrates the results of GFSLT-VLP with SignCL which correctly translates \"piano\". The t-SNE visualization now shows that the signs are more separated in the feature space. The improved separation reflects the effectiveness of SignCL in mitigating representation density issues.", "section": "5 Experiments"}, {"figure_path": "FtzLbGoHW2/figures/figures_14_1.jpg", "caption": "Figure 6: The distribution of the estimated margin during training on the PHOENIX-2014T dataset. The green distribution represents our current paper's method (factor = 2.3), while the orange distribution shows the ground truth calculated based on gloss annotations.", "description": "This figure shows the distribution of dynamically estimated margins used in the SignCL method during training on the PHOENIX-2014T dataset.  The margin is a key parameter in contrastive learning, determining how far apart positive and negative samples should be in the feature space. The green bars represent the distribution of margins calculated using the proposed method, which uses a Zipf's factor of 2.3 to estimate the average duration of sign gestures. The orange bars show the ground truth distribution, calculated using gloss annotations, providing a comparison point to assess the accuracy of the proposed method's margin estimation.", "section": "A.2 Parameter Sensitivity Analysis of the SignCL"}, {"figure_path": "FtzLbGoHW2/figures/figures_15_1.jpg", "caption": "Figure 7: The effect of the hyperparameter \u03bb on BLEU scores. the grey dashed line indicates the baseline performance of GFSLT-VLP, while the red solid line represents the performance with SignCL integrated.", "description": "This figure shows the impact of the hyperparameter lambda (\u03bb) on the BLEU scores of a sign language translation model.  The x-axis represents different values of \u03bb, and the y-axis shows the corresponding BLEU scores. The grey dashed line represents the baseline performance of the GFSLT-VLP model without SignCL. The red solid line shows the performance of the model when SignCL (the proposed contrastive learning strategy) is integrated.  It demonstrates that a specific range of \u03bb values achieves the best balance between reducing representation density and improving translation performance.  Selecting an inappropriate \u03bb value can negatively affect the model's performance.", "section": "5.2 Experiments on Gloss-free Sign Language Translation"}]