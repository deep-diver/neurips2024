[{"figure_path": "jHh804fZ5l/figures/figures_8_1.jpg", "caption": "Figure 1: Plots of objective ratios (upper) and Gurobi's running times (lower, semi-log) for Full, ColRand, PCA, and SGA averaged over 100 test instances. The error band of ColRand indicates the standard deviation over 10 independent trials. The results of Full are shown for every k for reference, although it always solves n-dimensional LPs and hence is independent of k.", "description": "This figure presents the results of comparing four different methods for solving linear programming problems: Full, ColRand, PCA, and SGA.  The top row shows the objective ratios (quality of solution) for each method across different datasets (Packing, MaxFlow, MinCostFlow, GROW7, ISRAEL, SC205, SCAGR25, STAIR) as the reduced dimensionality (k) varies. The bottom row shows the corresponding running times using Gurobi solver. The error bars for ColRand represent the standard deviation across 10 independent runs, highlighting the variability inherent in this randomized approach.  Full serves as a baseline, always solving the full-dimensional problem, allowing for comparison of solution quality and speed improvements offered by dimensionality reduction techniques.", "section": "6 Experiments"}, {"figure_path": "jHh804fZ5l/figures/figures_14_1.jpg", "caption": "Figure 2: Running times of PCA and SGA for learning projection matrices on 200 training instances.", "description": "This figure shows the training times taken by PCA and SGA for learning projection matrices on training datasets of 200 instances.  The training time for solving original LPs was not included. The figure demonstrates that SGA generally takes much longer than PCA because it iteratively solves LPs for computing gradients and quadratic programs for projection, whereas PCA only requires computing the top-(k-1) right-singular vectors of X - 1.  The x-axis represents the reduced dimensionality (k) and the y-axis represents the training time in seconds.  Different lines represent different datasets. ", "section": "5 Learning methods"}, {"figure_path": "jHh804fZ5l/figures/figures_15_1.jpg", "caption": "Figure 1: Plots of objective ratios (upper) and Gurobi's running times (lower, semi-log) for Full, ColRand, PCA, and SGA averaged over 100 test instances. The error band of ColRand indicates the standard deviation over 10 independent trials. The results of Full are shown for every k for reference, although it always solves n-dimensional LPs and hence is independent of k.", "description": "This figure presents a comparison of four different methods for solving linear programming (LP) problems: Full, ColRand, PCA, and SGA.  The upper plots show the objective ratios (the objective value obtained by each method divided by the optimal objective value) for each method across eight different datasets (Packing, MaxFlow, MinCostFlow, GROW7, ISRAEL, SC205, SCAGR25, and STAIR). The lower plots show the corresponding running times of Gurobi, a commercial LP solver, for each method. The x-axis represents the reduced dimensionality (k) of the LP problem, obtained by applying a projection matrix to the original, higher-dimensional problem.  The figure demonstrates that data-driven projection methods (PCA and SGA) generally achieve much higher objective ratios (closer to optimal) and significantly faster solution times than the baseline random projection method (ColRand), although there is some variation across different datasets.", "section": "6 Experiments"}, {"figure_path": "jHh804fZ5l/figures/figures_15_2.jpg", "caption": "Figure 1: Plots of objective ratios (upper) and Gurobi's running times (lower, semi-log) for Full, ColRand, PCA, and SGA averaged over 100 test instances. The error band of ColRand indicates the standard deviation over 10 independent trials. The results of Full are shown for every k for reference, although it always solves n-dimensional LPs and hence is independent of k.", "description": "This figure presents a comparison of four different methods for solving linear programming (LP) problems: Full, ColRand, PCA, and SGA.  The top row shows the objective ratios (the objective value obtained by each method divided by the optimal objective value obtained by the Full method) for eight different datasets. The bottom row shows the running times of Gurobi (a commercial LP solver) for each method.  The figure demonstrates that data-driven projection methods (PCA and SGA) can achieve significantly higher solution quality and faster solving times than random projection methods (ColRand), while still being comparable in performance to the Full method. The error bands for ColRand show the standard deviation across 10 independent trials, highlighting the variability inherent in random projection techniques.", "section": "6 Experiments"}]