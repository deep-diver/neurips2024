[{"figure_path": "SFCZdXDyNs/tables/tables_4_1.jpg", "caption": "Figure 2: Utility and d\u00e9j\u00e0 vu memorization of ViT-B-32 CLIP models with varying training set sizes. Model utility is quantified in terms of ImageNet zero-shot accuracy. Population-level memorization of models is measured using the metrics defined in Section 3.2 over various public sets (a): training set sampled from filtered LAION and ImageNet is used as public set. (b): training set sampled from filtered LAION and a holdout filtered LAION-50M set is used as public set. (c): training set sampled from Shutterstock and a holdout SS-20M set is used as public set. For the memorization metrics, we report the mean \u00b1 std values (std \u2264 0.003) over 100 repetitions of randomly sampling 10% of records with replacement.", "description": "This figure shows the relationship between the size of the training dataset used for training ViT-B-32 CLIP models and both their utility (measured by ImageNet zero-shot accuracy) and the degree of memorization.  Three different scenarios are presented, each using a different combination of training and testing datasets. The memorization is evaluated using population-level metrics (PPG, PRG, AUCG), showing the mean and standard deviation of these metrics over 100 random samplings of the training data.", "section": "4 Evaluating D\u00e9j\u00e0 vu Memorization"}]