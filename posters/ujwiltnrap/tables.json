[{"figure_path": "ujwIlTNrAP/tables/tables_7_1.jpg", "caption": "Table 1: 3D object detection performance comparison with the state-of-the-art pruning methods on the nuScenes validation dataset. We list the mAP and NDS of models pruned by different approaches within 80%, 85%, and 90% pruning ratios. The two baseline models are trained with SwinT and VoxelNet backbone.", "description": "This table presents a comparison of 3D object detection performance using different pruning methods on the nuScenes validation dataset.  It shows the mean Average Precision (mAP) and NuScenes Detection Score (NDS) for models pruned at 80%, 85%, and 90% sparsity levels.  Two baseline models (BEVfusion-mit and BEVfusion-pku) are included, each trained with different backbones (SwinT and VoxelNet). The table allows for a comparison of AlterMOMA's performance against other state-of-the-art pruning techniques (IMP, SynFlow, SNIP, ProsPr).", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_7_2.jpg", "caption": "Table 2: 3D object detection performance comparison with the state-of-the-art pruning methods on the KITTI Validation dataset on car class. We list the models pruned by different approaches within 80%, and 90% pruning ratios. The baseline model is AVOD-FPN architecture.", "description": "This table compares the performance of different pruning methods on the KITTI dataset for 3D object detection of cars. It shows the AP-3D and AP-BEV (average precision in 3D and bird's eye view) for different pruning ratios (80% and 90%) and difficulty levels (easy, moderate, hard).  The baseline model used is AVOD-FPN.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_8_1.jpg", "caption": "Table 3: BEV segmentation performance comparison on the nuScenes validation dataset.", "description": "This table presents a comparison of the BEV segmentation performance (mIoU) achieved by different pruning methods on the nuScenes validation dataset.  It shows the mIoU scores for three different sparsity levels (80%, 85%, and 90%) for each method, including a baseline model with no pruning and several other state-of-the-art pruning techniques (IMP, SynFlow, SNIP, ProsPr). The table highlights the performance of the proposed AlterMOMA method relative to these baselines.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_8_2.jpg", "caption": "Table 4: 3D object detection performance with various backbones on the nuScenes validation dataset.", "description": "This table compares the performance of different pruning methods (IMP, SynFlow, SNIP, ProsPr, and AlterMOMA) on 3D object detection task using various backbones (ResNet and PointPillars) on the nuScenes validation dataset.  The table shows the mean Average Precision (mAP) achieved at different sparsity levels (80%, 85%, and 90%).  It demonstrates the effectiveness of AlterMOMA compared to other methods in maintaining high accuracy even with significant parameter reduction.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_8_3.jpg", "caption": "Table 5: 3D object detection performance of structure pruning on the nuScenes validation dataset.", "description": "This table presents the results of structure pruning experiments conducted on the nuScenes validation dataset using the 3D object detection task.  It compares the performance of different pruning methods (IMP, ProsPr, and AlterMOMA) at two different sparsity levels (30% and 50%).  The performance metrics reported include mean Average Precision (mAP), NuScenes Detection Score (NDS), and the reduction in GFLOPs (giga floating-point operations). The table shows that AlterMOMA achieves better performance compared to other methods at both sparsity levels while simultaneously offering significant computational savings.", "section": "4.4 Structure Pruning Results on 3D object Detection"}, {"figure_path": "ujwIlTNrAP/tables/tables_16_1.jpg", "caption": "Table 1: 3D object detection performance comparison with the state-of-the-art pruning methods on the nuScenes validation dataset. We list the mAP and NDS of models pruned by different approaches within 80%, 85%, and 90% pruning ratios. The two baseline models are trained with SwinT and VoxelNet backbone.", "description": "This table compares the performance of different pruning methods on the nuScenes dataset for 3D object detection.  It shows the mean Average Precision (mAP) and NuScenes Detection Score (NDS) for models pruned at 80%, 85%, and 90% sparsity levels. Two baseline models (trained with Swin Transformer and VoxelNet backbones) are included for comparison.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_16_2.jpg", "caption": "Table 2: 3D object detection performance comparison with the state-of-the-art pruning methods on the KITTI Validation dataset on car class. We list the models pruned by different approaches within 80%, and 90% pruning ratios. The baseline model is AVOD-FPN architecture.", "description": "This table compares the performance of different pruning methods (IMP, SynFlow, SNIP, ProsPr, and AlterMOMA) on the KITTI dataset for 3D object detection, specifically focusing on the 'car' class.  It shows the Average Precision (AP) in 3D, BEV, and across different difficulty levels (Easy, Moderate, Hard) for 80% and 90% sparsity levels. The baseline results (without pruning) are also provided for comparison.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_17_1.jpg", "caption": "Table 7: 3D object detection performance comparison with camera-radar fusion models on the nuScenes validation dataset. The baseline model is trained with ResNet and PointPillars backbone.", "description": "This table compares the performance of different pruning methods on a camera-radar fusion model for 3D object detection using the nuScenes validation dataset.  The baseline model uses ResNet and PointPillars backbones.  The table shows the mean Average Precision (mAP) and NuScenes Detection Score (NDS) for models pruned at 80% and 90% sparsity levels, comparing the performance of AlterMOMA against the ProPr baseline method.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_17_2.jpg", "caption": "Table 8: 3D multi-object tracking (MOT) task performance comparison by performing tracking-by-detection on the nuScenes validation dataset. We list the AMOTA of models pruned within 80% and 90% pruning ratios. The baseline model is trained with SwinT and VoxelNet backbone.", "description": "This table compares the performance of different pruning methods on the task of 3D multi-object tracking using the nuScenes dataset.  It shows the AMOTA (Average Multi-Object Tracking Accuracy) scores for models pruned at 80% and 90% sparsity levels.  The baseline model uses SwinT and VoxelNet backbones.  The table helps to demonstrate the effectiveness of AlterMOMA in maintaining high tracking accuracy even with significant model compression.", "section": "4.3 Experimental Results on Unstructured Pruning"}, {"figure_path": "ujwIlTNrAP/tables/tables_18_1.jpg", "caption": "Table 9: 3D object detection performance and inference speed comparison with the structure pruning methods on the nuScenes validation dataset. Note that baseline model is BEVfusion-mit with ResNet101 and SECOND as backbone and inference is tested on the RTX3090.", "description": "This table presents a comparison of 3D object detection performance and inference speed for different pruning methods on the nuScenes validation dataset.  The baseline model used is BEVfusion-mit, with ResNet101 and SECOND backbones.  The results show the mAP, NDS, GFLOPs (with percentage reduction), and inference time (in milliseconds) for the baseline model and two versions of the AlterMOMA method (with 30% and 50% pruning).  The table highlights the trade-off between accuracy and efficiency achieved by the AlterMOMA approach.", "section": "4.4 Structure Pruning Results on 3D object Detection"}]