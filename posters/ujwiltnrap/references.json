{"references": [{"fullname_first_author": "Yingwei Li", "paper_title": "Deepfusion: Lidar-camera deep fusion for multi-modal 3d object detection", "publication_date": "2022-00-00", "reason": "This paper introduces a state-of-the-art camera-LiDAR fusion model for 3D object detection, directly relevant to the core topic of the current paper."}, {"fullname_first_author": "Tingting Liang", "paper_title": "Bevfusion: A simple and robust lidar-camera fusion framework", "publication_date": "2022-00-00", "reason": "This paper presents a highly efficient and robust camera-LiDAR fusion method, which is directly relevant to the efficiency and performance comparison in the current paper."}, {"fullname_first_author": "Jason Ku", "paper_title": "Joint 3d proposal generation and object detection from view aggregation", "publication_date": "2018-00-00", "reason": "This paper provides a fundamental two-stage camera-LiDAR fusion model, serving as a baseline for comparison in the experimental section."}, {"fullname_first_author": "Zhijian Liu", "paper_title": "Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation", "publication_date": "2023-00-00", "reason": "This paper is another state-of-the-art camera-LiDAR fusion model using a unified bird's-eye view representation, relevant to the comparative analysis in the current paper."}, {"fullname_first_author": "Holger Caesar", "paper_title": "nuScenes: A multimodal dataset for autonomous driving", "publication_date": "2020-00-00", "reason": "This paper introduces the nuScenes dataset, a crucial dataset for evaluating camera-LiDAR fusion models and directly used in the experiments of the current paper."}]}