[{"figure_path": "fPmScVB1Td/tables/tables_6_1.jpg", "caption": "Table 1: Comparsion results on ZeroSCROLLS [34] benchmarks. The evaluation metrics for various tasks are tailored as follows: GovReport, SummScreenFD, QMSum, and SQUALITY utilize the geometric mean of Rouge-1/2/L scores. Qasper and NarrativeQA are assessed through the F1 score, while BookSumSort employs the concordance index.", "description": "This table presents a comparison of the performance of several Large Language Models (LLMs) on various tasks from the ZeroSCROLLS benchmark.  The models are tested both with and without the proposed Ms-PoE method.  Different evaluation metrics are used depending on the specific task, including ROUGE scores, F1 score, and concordance index.  The results show the accuracy for each model on each task, with the improvement provided by Ms-PoE shown in parentheses.", "section": "4.1 Enhanced Generation Quality"}, {"figure_path": "fPmScVB1Td/tables/tables_7_1.jpg", "caption": "Table 2: Comparsion results with other competitive methods on MDQA and Key-Value Retrival. Results are reported in accuracy.", "description": "This table compares the performance of Ms-PoE against baseline methods (PI and Self-Extend) and other competitive methods on two tasks: Multi-Document Question Answering (MDQA) and Key-Value Retrieval.  The accuracy is reported for different positions of the key document or key-value pair within the input context (1, 3, 5, 7, 10 for MDQA; 1, 15, 30, 40, 50 for Key-Value Retrieval).  The average accuracy across all positions is also provided for each method.  The results highlight Ms-PoE's superior performance in handling long contexts.", "section": "4.2 Superior Context Utilization"}, {"figure_path": "fPmScVB1Td/tables/tables_8_1.jpg", "caption": "Table 3: Ablation results of different ordering metrics. Experiments are conducted on Multi-Documents Question Answering task with the Vicuna-7B model.", "description": "This table presents the ablation study results on the Multi-Documents Question Answering task using the Vicuna-7B model. It compares the performance of different head ordering strategies for assigning scaling ratios in the Ms-PoE method. The strategies include: Baseline (original method), Random, Sequential, Entropy, and Position-Awareness. The results are shown in terms of accuracy for the beginning, middle, and end positions of the key document, as well as the average accuracy across all positions. The Position-Awareness strategy, which leverages the position-awareness score of each attention head, demonstrates the best performance.", "section": "4.3 Ablation Study and More Investigation"}, {"figure_path": "fPmScVB1Td/tables/tables_8_2.jpg", "caption": "Table 3: Ablation results of different ordering metrics. Experiments are conducted on Multi-Documents Question Answering task with the Vicuna-7B model.", "description": "This table presents the ablation study results focusing on different ordering metrics for assigning scaling ratios to attention heads in the Ms-PoE method.  It compares the average accuracy across various strategies (Random, Sequential, Entropy, Position-Awareness) for assigning scaling ratios when the crucial information is located at the beginning, middle, or end of the input text. The results demonstrate the effectiveness of the position-awareness strategy in improving the model's ability to utilize long-context information.", "section": "4.3 Ablation Study and More Investigation"}]