[{"figure_path": "uikhNa4wam/figures/figures_0_1.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated using FIFO-Diffusion. Each example demonstrates the model's ability to maintain video quality and semantic consistency over a long sequence of frames, even though the model was only trained on short video clips (16 frames).  The number on the top-left corner of each frame represents the frame index.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of diagonal denoising with f = 4. The frames surrounded by solid lines are model inputs while frames surrounded by dotted line are their denoised version. After denoising, the fully denoised instance at the top-right corner is dequeued while random noise is enqueued.", "description": "This figure illustrates the FIFO-Diffusion process.  A queue of frames is maintained, each with a different level of noise (timesteps). At each step, a frame is denoised, starting with the least noisy (top-right), removed from the queue, and a new, fully noisy frame is added to the queue (bottom-left). This diagonal processing allows the model to generate a continuous video sequence.", "section": "3 FIFO-Diffusion"}, {"figure_path": "uikhNa4wam/figures/figures_3_1.jpg", "caption": "Figure 3: Comparison between the chunked autoregressive methods and FIFO-Diffusion proposed for long video generation. The random noises (black) are iteratively denoised to image latents (white) by the models. The red boxes indicate the denoising network in the pretrained base model while the green boxes denote the prediction network obtained by additional training.", "description": "This figure compares the chunked autoregressive methods and FIFO-Diffusion methods.  The chunked autoregressive approach processes small chunks of frames at a time, requiring additional training for each chunk to maintain consistency.  In contrast, FIFO-Diffusion processes frames in a queue, allowing each frame to refer to preceding frames with lower noise levels.  This results in an ability to generate arbitrarily long videos without requiring additional training for each frame.", "section": "3 FIFO-Diffusion"}, {"figure_path": "uikhNa4wam/figures/figures_4_1.jpg", "caption": "Figure 4: Illustration of latent partitioning and lookahead denoising where f = 4 and n = 2. (a) Latent partitioning divides the diffusion process into n parts to reduce the maximum noise level difference. (b) Lookahead denoising on (a) enables all frames to be denoised with an adequate number of former frames at the expense of two times more computation than (a).", "description": "This figure illustrates the concepts of latent partitioning and lookahead denoising. Latent partitioning divides the frames into blocks to reduce the noise level difference between frames. Lookahead denoising leverages cleaner frames to improve denoising accuracy, but increases computational cost.", "section": "3. FIFO-Diffusion"}, {"figure_path": "uikhNa4wam/figures/figures_5_1.jpg", "caption": "Figure 5: The relative MSE losses of the noise prediction of z (see Equation (7)) when n = 4. 'VDM' indicates the original denoising strategy as a reference line. 'LP' and 'LD' denote latent partitioning and lookahead denoising, respectively.", "description": "This figure shows the relative mean squared error (MSE) loss in noise prediction for different methods.  The x-axis represents the timestep during the denoising process, and the y-axis shows the relative MSE loss. Three lines are plotted: VDM (original denoising), LP (latent partitioning), and LP+LD (latent partitioning with lookahead denoising).  The plot demonstrates the effectiveness of latent partitioning and lookahead denoising in reducing the MSE loss compared to the baseline VDM method. Dashed vertical lines separate the different latent partitions.", "section": "3.2 Latent partitioning"}, {"figure_path": "uikhNa4wam/figures/figures_6_1.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three example videos generated by the FIFO-Diffusion method. Each video is 10,000 frames long and based on a single text prompt. The top-left corner of each frame displays the frame index. The results demonstrate FIFO-Diffusion's ability to generate long, high-quality videos from a model trained on much shorter video clips.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_6_2.jpg", "caption": "Figure 7: Sample videos generated by (first) FIFO-DIffusion on VideoCrafter2, (second) FreeNoise on VideoCrafter2, (third) Gen-L-Video on VideoCrafter2, and (last) LaVie + SEINE. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure compares the video generation quality of four different methods: FIFO-Diffusion, FreeNoise, Gen-L-Video, and LaVie+SEINE, all using the VideoCrafter2 model.  It showcases a sample video generated by each method using the same prompt, illustrating differences in visual quality, motion smoothness, and overall coherence.", "section": "4.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_7_1.jpg", "caption": "Figure 8: The results of user study between FIFO-Diffusion and FreeNoise for five criteria.", "description": "The figure shows the results of a user study comparing FIFO-Diffusion and FreeNoise across five criteria: Overall Preference, Plausibility of Motion, Magnitude of Motion, Fidelity to Text, and Aesthetic Quality.  FIFO-Diffusion significantly outperforms FreeNoise in all criteria, demonstrating its superior performance in generating long videos.", "section": "4.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_8_1.jpg", "caption": "Figure 21: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure presents an ablation study comparing three versions of FIFO-Diffusion: one using only diagonal denoising (DD), another adding latent partitioning (DD+LP), and a third version incorporating both latent partitioning and lookahead denoising (DD+LP+LD).  The goal is to show the impact of these components on the visual quality of the generated videos.  Each row shows a different video generated using the same prompt but with a different version of the FIFO-Diffusion method. The number in the upper-left corner of each frame indicates the frame index.", "section": "H Ablation study"}, {"figure_path": "uikhNa4wam/figures/figures_16_1.jpg", "caption": "Figure 10: Videos generated by FIFO-Diffusion with VideoCrafter2. The number on the top left of each frame indicates the frame index.", "description": "This figure shows six video examples generated by FIFO-Diffusion using the VideoCrafter2 model. Each example is a 80-frame video clip, showcasing a different scene, and the caption provides a textual description of each video.", "section": "D.1 VideoCrafter2"}, {"figure_path": "uikhNa4wam/figures/figures_17_1.jpg", "caption": "Figure 11: Videos generated by FIFO-Diffusion with VideoCrafter2. The number on the top left of each frame indicates the frame index.", "description": "This figure shows several video frames generated using the FIFO-Diffusion method with the VideoCrafter2 model.  Each row represents a different video, generated from a corresponding text prompt. The numbers in the top left corner of each frame indicate the frame index, demonstrating the ability of FIFO-Diffusion to generate long videos (over 80 frames shown per video).", "section": "4.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_18_1.jpg", "caption": "Figure 12: Videos generated by FIFO-Diffusion with VideoCrafter2. The number on the top left of each frame indicates the frame index.", "description": "This figure shows seven video examples generated using the FIFO-Diffusion method with the VideoCrafter2 model. Each example showcases a different scene, demonstrating the model's ability to generate diverse and detailed videos based on text prompts.  The numbers in the top left corner of each frame indicate the frame index, allowing for tracking of video progression.", "section": "4 Experiment"}, {"figure_path": "uikhNa4wam/figures/figures_19_1.jpg", "caption": "Figure 13: Videos generated by FIFO-Diffusion with VideoCrafter1. The number on the top left of each frame indicates the frame index.", "description": "This figure shows eight example videos generated using the FIFO-Diffusion method with the VideoCrafter1 model.  Each video is accompanied by a text prompt describing its content (e.g., \"A kayaker navigating through rapids, photorealistic, 4K, high quality.\").  The numbered frames illustrate the temporal progression within each generated video sequence. The figure demonstrates the model's ability to produce visually appealing and semantically coherent long videos.", "section": "D.2 VideoCrafter1"}, {"figure_path": "uikhNa4wam/figures/figures_20_1.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated by the FIFO-Diffusion method.  Each video is based on a different text prompt, and the top-left corner of each frame displays its index in the sequence. The results demonstrate FIFO-Diffusion's ability to produce long videos from a model initially trained only on much shorter (16-frame) video clips, maintaining high quality and consistent visual dynamics.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_21_1.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated by the FIFO-Diffusion method.  Each video is based on a text prompt, and the top-left corner of each frame shows the frame number.  The examples demonstrate the method's ability to generate very long videos from a model trained on much shorter videos (16 frames) without loss of quality or coherence.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_22_1.jpg", "caption": "Figure 16: Videos generated by FIFO-Diffusion with three prompts. The number on the top left of each frame indicates the frame index.", "description": "This figure shows three examples of videos generated using FIFO-Diffusion with three different prompts sequentially given to the model. Each row represents a different video, where the prompts change during generation.  The first video shows Ironman changing his actions in order of running, standing, and flying. The second is of a tiger walking, standing, and resting. The final video is a teddy bear walking, standing and dancing. The numbers in the top left corner show the frame index.", "section": "E.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_23_1.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated using the FIFO-Diffusion method.  Each video is generated from a text prompt, and the top-left corner of each frame displays its index number. The results demonstrate that the FIFO-Diffusion method produces high-quality, long videos without any noticeable degradation, even though it uses a model trained only on short videos of 16 frames.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_23_2.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated using the FIFO-Diffusion method.  Each video is generated from a text prompt describing a scene (fireworks over Sydney Harbour, an astronaut on the moon, penguins on Antarctic ice). The top-left corner of each frame shows its index. The figure demonstrates the method's ability to generate very long videos from a model trained on much shorter video clips (16 frames), without losing visual quality or the semantic meaning of the scene.", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_23_3.jpg", "caption": "Figure 1: Illustration of 10K-frame long videos generated by FIFO-Diffusion based on a pretrained text-conditional video generation model, VideoCrafter2 [3]. The number at the top-left corner of each image indicates the frame index. The results clearly show that FIFO-Diffusion can generate extremely long videos effectively based on the model trained on short clips (16 frames) without quality degradation while preserving the dynamics and semantics of scenes.", "description": "This figure shows three examples of 10,000-frame videos generated using FIFO-Diffusion.  Each video is based on a different text prompt and uses a pretrained VideoCrafter2 model. The top-left corner of each frame displays its frame index, illustrating the long video generation capability.  The results demonstrate that FIFO-Diffusion maintains high quality over the 10,000 frames, despite being trained on much shorter videos (only 16 frames).", "section": "Abstract"}, {"figure_path": "uikhNa4wam/figures/figures_23_4.jpg", "caption": "Figure 17: Videos generated by FIFO-Diffusion with two prompts. The number on the top left of each frame indicates the frame index.", "description": "This figure shows four examples of videos generated using FIFO-Diffusion with two prompts. Each row represents a different video, with the caption describing the content.  The numbers at the top left of each frame indicate the frame index, providing a visual representation of the temporal progression of the video. The videos showcase the method's ability to smoothly transition between different actions or scenes as specified in the prompts.", "section": "E.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_24_1.jpg", "caption": "Figure 18: Qualitative comparisons with other long video generation techniques, Gen-L-Video, FreeNoise, and LaVie + SEINE. The number in the top-left corner of each frame indicates the frame index.", "description": "This figure compares the video generation quality of FIFO-Diffusion against other methods such as FreeNoise, Gen-L-Video, and LaVie+SEINE.  The comparison uses two example video prompts: a vibrant underwater scene and a panoramic view of a peaceful Zen garden. The results show that FIFO-Diffusion produces videos with better visual quality and coherence than the other methods.", "section": "F Qualitative comparisons with other long video generation methods"}, {"figure_path": "uikhNa4wam/figures/figures_25_1.jpg", "caption": "Figure 7: Sample videos generated by (first) FIFO-DIffusion on VideoCrafter2, (second) FreeNoise on VideoCrafter2, (third) Gen-L-Video on VideoCrafter2, and (last) LaVie + SEINE. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure compares the video generation results of four different methods: FIFO-Diffusion, FreeNoise, Gen-L-Video, and LaVie+SEINE, all using the VideoCrafter2 model.  Each method generates a video based on the prompt \"An astronaut floating in space, high quality, 4K resolution.\" The figure allows for a visual comparison of the video quality, motion smoothness, and overall fidelity to the prompt across the different methods.", "section": "4.2 Qualitative results"}, {"figure_path": "uikhNa4wam/figures/figures_25_2.jpg", "caption": "Figure 18: Qualitative comparisons with other long video generation techniques, Gen-L-Video, FreeNoise, and LaVie + SEINE. The number in the top-left corner of each frame indicates the frame index.", "description": "This figure compares the video generation results of FIFO-Diffusion with three other methods: FreeNoise, Gen-L-Video, and LaVie+SEINE.  Two example video clips are shown, each generated from the same prompt by all four methods. The comparison highlights the differences in video quality, motion smoothness, and overall fidelity to the text prompt.", "section": "F Qualitative comparisons with other long video generation methods"}, {"figure_path": "uikhNa4wam/figures/figures_26_1.jpg", "caption": "Figure 20: Comparison of optical flow magnitudes between FIFO-Diffusion and FreeNoise.", "description": "This histogram compares the average optical flow magnitudes for videos generated by FIFO-Diffusion and FreeNoise.  The x-axis represents the average optical flow magnitude, indicating the amount of motion in the video. The y-axis shows the frequency of videos with that particular average optical flow magnitude. The graph shows that FIFO-Diffusion generates videos with a much broader range of motion compared to FreeNoise, which tends to produce videos with significantly less movement.", "section": "G Motion evaluation"}, {"figure_path": "uikhNa4wam/figures/figures_27_1.jpg", "caption": "Figure 21: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure shows the ablation study of FIFO-Diffusion. Three versions of the model are compared: only diagonal denoising (DD), diagonal denoising + latent partitioning (DD+LP), and diagonal denoising + latent partitioning + lookahead denoising (DD+LP+LD). The results show that latent partitioning and lookahead denoising significantly improve the quality and temporal consistency of the generated videos.", "section": "H Ablation study"}, {"figure_path": "uikhNa4wam/figures/figures_27_2.jpg", "caption": "Figure 21: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure shows the ablation study of the FIFO-Diffusion method. It compares the results of FIFO-Diffusion with only diagonal denoising (DD), with the addition of latent partitioning with n=4 (DD+LP), and with lookahead denoising (DD+LP+LD). Three different prompts were used to generate videos. The top row shows the results with diagonal denoising only, the middle row shows the results with diagonal denoising and latent partitioning, and the bottom row shows the results with all three components of the FIFO-Diffusion method. The number on the top-left corner of each frame indicates the frame index.", "section": "4.5 Ablation study"}, {"figure_path": "uikhNa4wam/figures/figures_27_3.jpg", "caption": "Figure 21: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure shows the ablation study of the FIFO-Diffusion model.  Three different versions of the model are compared: one using only diagonal denoising (DD), one with diagonal denoising and latent partitioning (DD+LP), and one with diagonal denoising, latent partitioning, and lookahead denoising (DD+LP+LD). The results for each model are displayed for the same video, and show the impact of latent partitioning and lookahead denoising on the quality of generated video frames.", "section": "4.5 Ablation study"}, {"figure_path": "uikhNa4wam/figures/figures_28_1.jpg", "caption": "Figure 22: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure shows the results of an ablation study on the FIFO-Diffusion model, comparing the effects of diagonal denoising (DD), latent partitioning (LP), and lookahead denoising (LD).  The top row shows the results using only diagonal denoising, the middle row shows the results with the addition of latent partitioning, and the bottom row shows the results with all three techniques. The image shows a close-up of a blooming rose and a tarantula for each ablation setting. The numbers on the top-left corners indicate the frame indices within each generated sequence. The figure helps to visually demonstrate the impact of each technique on the quality and temporal consistency of the generated videos.", "section": "H Ablation study"}, {"figure_path": "uikhNa4wam/figures/figures_28_2.jpg", "caption": "Figure 22: Ablation study. DD, LP, and LD signifies diagonal denoising, latent partitioning, and lookahead denoising, respectively. The number on the top-left corner of each frame indicates the frame index.", "description": "This figure shows the ablation study results comparing three versions of FIFO-Diffusion: only diagonal denoising (DD), diagonal denoising + latent partitioning (DD+LP), and diagonal denoising + latent partitioning + lookahead denoising (DD+LP+LD).  The results are visually presented for two different video prompts:  a close-up of a tarantula walking and a detailed macro shot of a blooming rose. Each frame shows a different timestep of the diffusion process. The goal is to show how each component affects the final generated video quality and temporal consistency.", "section": "H Ablation study"}]