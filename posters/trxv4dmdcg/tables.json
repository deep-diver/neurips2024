[{"figure_path": "TrXV4dMDcG/tables/tables_2_1.jpg", "caption": "Table 1: For a mixture of Gaussian components N(\u00b5i, Id), we show upper and lower bounds for the error of the i-component given a output list L (of the respective algorithm) min\u00fb\u2208L ||\u00fb \u2013 \u03bci||. When the error doesn't depend on i, all means have the same error guarantee irrespective of their weight. Note that depending on the type of inlier mixture, different methods in [3] are used as the 'best prior work': robust mixture learning for the first row and list-decodable mean estimation for the rest.", "description": "The table presents a comparison of upper and lower bounds on the error of different algorithms for estimating the mean of Gaussian mixture components. The comparison is performed for three types of inlier mixtures: large well-separated groups, small well-separated groups, and non-separated groups. For each type of mixture, the table shows the best prior work, the authors' proposed algorithm, and an information-theoretic lower bound on the error.", "section": "Main results"}]