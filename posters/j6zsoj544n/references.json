{"references": [{"fullname_first_author": "Kwangjun Ahn", "paper_title": "SGD with shuffling: optimal rates without component convexity and large epoch requirements", "publication_date": "2020-MM-DD", "reason": "This paper provides optimal convergence rates for SGD with shuffling, a crucial technique used in the paper's analysis of UD-SGD, which relaxes strong convexity assumptions."}, {"fullname_first_author": "Noga Alon", "paper_title": "Non-backtracking random walks mix faster", "publication_date": "2007-MM-DD", "reason": "This paper introduces non-backtracking random walks, a sampling technique that improves the convergence speed of Markov chains and is relevant to the Markovian sampling strategies analyzed in the paper."}, {"fullname_first_author": "Albert Benveniste", "paper_title": "Adaptive algorithms and stochastic approximations", "publication_date": "2012-MM-DD", "reason": "This book provides foundational knowledge on stochastic approximation methods, which are essential for analyzing the asymptotic convergence properties of UD-SGD."}, {"fullname_first_author": "Pascal Bianchi", "paper_title": "Performance of a distributed stochastic approximation algorithm", "publication_date": "2013-MM-DD", "reason": "This paper analyzes the convergence behavior of a distributed stochastic approximation algorithm, which is relevant to the paper's analysis of UD-SGD in decentralized settings."}, {"fullname_first_author": "Stephen Boyd", "paper_title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "publication_date": "2011-MM-DD", "reason": "This paper provides foundational knowledge on distributed optimization techniques, which are used extensively in the paper's investigation of unified distributed SGD and its variants."}]}