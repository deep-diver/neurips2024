[{"figure_path": "2vhkjOdlc8/tables/tables_7_1.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the Dinomaly model's performance against other state-of-the-art (SOTA) models for multi-class unsupervised anomaly detection (MUAD).  It shows the image-level and pixel-level performance metrics (AUROC, AP, F1-max, AUPRO) achieved by various MUAD and class-separated UAD methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The table highlights Dinomaly's superior performance across all datasets and metrics compared to its predecessors.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_7_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the Dinomaly model's performance against other state-of-the-art (SOTA) models for multi-class unsupervised anomaly detection (MUAD).  The comparison is made across three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  Metrics used include image-level AUROC, Average Precision (AP), and F1-max, as well as pixel-level AUROC, AP, F1-max, and Average Precision under the Per-Region-Overlap curve (AUPRO). The \u2020 symbol indicates that a specific model was designed specifically for the MUAD task.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_8_1.jpg", "caption": "Table 3: Ablations of Dinomaly elements on MVTec-AD (%). NB: Noisy Bottleneck. LA: Linear Attention. LC: Loose Constraint (2 groups). LL: Loose Loss. Results on VisA see Table A1.", "description": "This ablation study analyzes the impact of each component of the Dinomaly model on the performance of multi-class unsupervised anomaly detection.  It shows the Area Under the Receiver Operating Characteristic (AUROC), Average Precision (AP), F1-max, and Average Precision under the Per-Region Overlap (AUPRO) scores for image-level and pixel-level anomaly detection on the MVTec-AD dataset for different combinations of the model's components (Noisy Bottleneck, Linear Attention, Loose Constraint, and Loose Loss).", "section": "3.4 Ablation Study"}, {"figure_path": "2vhkjOdlc8/tables/tables_8_2.jpg", "caption": "Table 4: Ablations of Dropout rates in Noisy Bottleneck, conducted on MVTec-AD (%). \u2020: default.", "description": "This table presents the ablation study results of varying dropout rates within the Noisy Bottleneck component of the Dinomaly model.  The impact on both image-level and pixel-level anomaly detection performance is assessed using AUROC, AP, F1-max, and AUPRO metrics on the MVTec-AD dataset. The default dropout rate (0.2) is indicated with a \u2020 symbol.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_8_3.jpg", "caption": "Table 5: Ablations of reconstruction constraint, conduected on MVTec-AD (%). \u2020: default.", "description": "This table presents the ablation study results on the MVTec-AD dataset focusing on different reconstruction constraints. It compares the performance metrics (AUROC, AP, F1-max, and AUPRO) achieved using various reconstruction schemes: layer-to-layer (dense, sparse), layer-to-cat-layer, and group-to-group (1 and 2 groups). The results demonstrate the impact of the reconstruction constraint on both image-level and pixel-level anomaly detection.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_14_1.jpg", "caption": "Table 3: Ablations of Dinomaly elements on MVTec-AD (%). NB: Noisy Bottleneck. LA: Linear Attention. LC: Loose Constraint (2 groups). LL: Loose Loss. Results on VisA see Table A1.", "description": "This table presents the ablation study results on the MVTec-AD dataset. It shows the impact of each component of the Dinomaly framework (Noisy Bottleneck, Linear Attention, Loose Constraint, and Loose Loss) on the performance.  The table displays the AUROC, AP, and F1-max metrics for both image-level and pixel-level evaluation. Results using all four components are shown as well as results achieved when one or more are omitted.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_14_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of different multi-class unsupervised anomaly detection (MUAD) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The metrics used include image-level AUROC, AP, F1-max, and pixel-level AUROC, AP, F1-max, and AUPRO.  The results highlight the superior performance of Dinomaly compared to existing SoTA MUAD and even class-separated UAD methods.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_15_1.jpg", "caption": "Table 3: Ablations of Dinomaly elements on MVTec-AD (%). NB: Noisy Bottleneck. LA: Linear Attention. LC: Loose Constraint (2 groups). LL: Loose Loss. Results on VisA see Table A1.", "description": "This ablation study analyzes the impact of each component of the Dinomaly model on the MVTec-AD dataset.  It shows the Area Under the Receiver Operating Characteristic (AUROC), Average Precision (AP), and F1-max scores for both image-level and pixel-level anomaly detection. The table highlights the individual and combined effects of the Noisy Bottleneck (NB), Linear Attention (LA), Loose Constraint (LC), and Loose Loss (LL) components.  Results for the VisA dataset are in a separate table (Table A1).", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_15_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of different multi-class unsupervised anomaly detection (MUAD) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The metrics used for evaluation include image-level AUROC, AP, F\u2081-max, and pixel-level AUROC, AP, F\u2081-max, and AUPRO.  The table allows readers to directly compare the performance of Dinomaly against other state-of-the-art (SOTA) methods in the field, highlighting its superior performance across all datasets and metrics.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_16_1.jpg", "caption": "Table 3: Ablations of Dinomaly elements on MVTec-AD (%). NB: Noisy Bottleneck. LA: Linear Attention. LC: Loose Constraint (2 groups). LL: Loose Loss. Results on VisA see Table A1.", "description": "This table presents the ablation study of Dinomaly's components on the MVTec-AD dataset. It shows the impact of removing or including the Noisy Bottleneck (NB), Linear Attention (LA), Loose Constraint (LC), and Loose Loss (LL) components on the model's performance.  The results are evaluated using AUROC, AP, and F1-max for both image-level and pixel-level evaluations.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_17_1.jpg", "caption": "Table 3: Ablations of Dinomaly elements on MVTec-AD (%). NB: Noisy Bottleneck. LA: Linear Attention. LC: Loose Constraint (2 groups). LL: Loose Loss. Results on VisA see Table A1.", "description": "This table presents the ablation study results of Dinomaly on the MVTec-AD dataset.  It shows the impact of individual components (Noisy Bottleneck, Linear Attention, Loose Constraint, and Loose Loss) on the model's performance. Each row represents a different combination of these components, and the columns show the AUROC, AP, and F1-max metrics for both image-level and pixel-level evaluation.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_17_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of Dinomaly's performance against other state-of-the-art (SOTA) methods for multi-class unsupervised anomaly detection (MUAD). It shows the image-level and pixel-level performance metrics (AUROC, AP, F1-max, AUPRO) achieved by Dinomaly and various other methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The results highlight Dinomaly's superior performance compared to existing MUAD and even class-separated UAD approaches.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_18_1.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the proposed Dinomaly model with several state-of-the-art (SOTA) multi-class unsupervised anomaly detection (MUAD) methods, and also some SoTA class-separated UAD methods, across three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  For each dataset and method, the table reports image-level AUROC, AP, and F1-max scores, as well as pixel-level AUROC, AP, F1-max, and AUPRO scores. The results show that Dinomaly outperforms all other methods on all metrics and datasets.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_18_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents the performance comparison of Dinomaly against other state-of-the-art (SOTA) methods on three benchmark datasets for multi-class unsupervised anomaly detection (MUAD).  It shows image-level metrics (AUROC, AP, F1-max) and pixel-level metrics (AUROC, AP, F1-max, AUPRO) across the MVTec-AD, VisA, and Real-IAD datasets.  The \u2020 symbol indicates methods specifically designed for MUAD.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_18_3.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of different multi-class unsupervised anomaly detection (MUAD) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  For each dataset and method, the table shows the image-level performance (AUROC, AP, F1-max) and pixel-level performance (AUROC, AP, F1-max, AUPRO).  The results highlight the superior performance of the proposed Dinomaly method compared to state-of-the-art (SOTA) methods.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_18_4.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the performance of different multi-class unsupervised anomaly detection (MUAD) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The metrics used for evaluation include image-level (AUROC, AP, F1-max) and pixel-level (AUROC, AP, F1-max, AUPRO) performance.  The table highlights the superior performance of the proposed Dinomaly method compared to other state-of-the-art (SOTA) MUAD and class-separated UAD methods.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_19_1.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the Dinomaly model's performance against other state-of-the-art (SOTA) models on three popular multi-class unsupervised anomaly detection (MUAD) benchmarks: MVTec-AD, VisA, and Real-IAD.  The table shows image-level and pixel-level metrics (AUROC, AP, F1-max, AUPRO) for each dataset.  The \u2020 symbol indicates methods specifically designed for the multi-class setting. Dinomaly's superior performance across all datasets and metrics is highlighted.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}, {"figure_path": "2vhkjOdlc8/tables/tables_19_2.jpg", "caption": "Table 1: Performance under multi-class UAD setting (%). \u2020: method designed for MUAD.", "description": "This table presents a comparison of the proposed Dinomaly model's performance against other state-of-the-art (SOTA) multi-class unsupervised anomaly detection (MUAD) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The comparison includes both image-level and pixel-level metrics (AUROC, AP, F1-max, AUPRO) to assess both the overall detection accuracy and the precision of anomaly localization. The \u2020 symbol indicates methods specifically designed for the multi-class setting.", "section": "3.2 Comparison to Multi-Class UAD SOTAs"}]