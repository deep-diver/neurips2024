[{"figure_path": "TuCQdBo4NC/tables/tables_7_1.jpg", "caption": "Table 1: Performance of the proposed FE and FEEL with different training strategies. The perturbation  = 8/255 for all attacks, and iterative step k = 7, step size  = 0.01 for PGD, BIM. The dataset is CIFAR100 with T = 8, the network is VGG11. The improvement brought by our method is shown in parentheses.", "description": "This table presents the performance of the Frequency Encoding (FE) and Evolutionary Leak Factor (FEEL) methods in improving the robustness of Spiking Neural Networks (SNNs) against various attacks.  Different training strategies (vanilla, adversarial training (AT), regularized adversarial training (RAT), and stochastic gating (StoG)) are used to evaluate the effectiveness of the proposed methods.  The table shows the accuracy on the CIFAR-100 dataset using the VGG11 network with various attack methods (Gaussian noise (GN), Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Carlini & Wagner (CW) attacks). The improvements achieved by adding FE and FEEL to the various training strategies are shown in parentheses.", "section": "5.2 Overall performance for various attack types"}, {"figure_path": "TuCQdBo4NC/tables/tables_8_1.jpg", "caption": "Table 2: Performance (%) of the proposed Frequency Encoding (FE) and the alternative strategy Inverse-FE (IFE). The perturbation  = 4/255 for all attacks, and iterative step k = 4, step size a = 0.01 for PGD. The dataset is CIFAR10 with time step T = 4, the network is VGG11.", "description": "This table compares the performance of the proposed Frequency Encoding (FE) method against a baseline method (Inverse FE) and the vanilla method across various attack types. The results demonstrate FE's effectiveness in improving robustness while preserving accuracy, unlike Inverse-FE.", "section": "5.3 Ablation study"}, {"figure_path": "TuCQdBo4NC/tables/tables_9_1.jpg", "caption": "Table 3: Effect of frequency masking radius r on robustness. The attack is PGD with perturbation \\(\\epsilon = 4/255\\), iterative step \\(\\alpha = 0.01\\), and iterative step \\(k = 4\\). The dataset is CIFAR10 with \\(T = 4\\), the network is VGG11.", "description": "This table shows the impact of different frequency masking radius r values on the robustness of the FEEL-SNN model against PGD attacks.  It compares three different encoding strategies: a direct encoding approach using a fixed radius, a frequency encoding approach with a uniform radius across all time steps, and the proposed frequency encoding approach with a variable radius that changes across time steps. The results show that the proposed approach consistently outperforms the other two methods across different radius values.", "section": "5.3 Ablation study"}, {"figure_path": "TuCQdBo4NC/tables/tables_13_1.jpg", "caption": "Table 1: Performance of the proposed FE and FEEL with different training strategies. The perturbation  = 8/255 for all attacks, and iterative step k = 7, step size a = 0.01 for PGD, BIM. The dataset is CIFAR100 with T = 8, the network is VGG11. The improvement brought by our method is shown in parentheses.", "description": "This table presents a quantitative comparison of the proposed Frequency Encoding (FE) and FEEL methods against various state-of-the-art training strategies. It assesses the model's performance under different attacks (clean, GN, FGSM, PGD, BIM, CW) on the CIFAR100 dataset. The results showcase the improvements achieved by integrating FE and FEEL, especially in enhancing robustness against adversarial attacks.", "section": "5.2 Overall performance for various attack types"}, {"figure_path": "TuCQdBo4NC/tables/tables_14_1.jpg", "caption": "Table 1: Performance of the proposed FE and FEEL with different training strategies. The perturbation\n\u20ac = 8/255 for all attacks, and iterative step k = 7, step size a = 0.01 for PGD, BIM. The dataset is CIFAR100\nwith T = 8, the network is VGG11. The improvement brought by our method is shown in parentheses.", "description": "This table presents the performance of the FEEL-SNN model against various attacks under different training strategies.  It shows the clean accuracy and accuracy under different attacks (Gaussian Noise, FGSM, PGD, BIM, CW) for various SNN training methods (Vanilla, Vanilla+FE, Vanilla+FEEL, AT, AT+FE, AT+FEEL, RAT, RAT+FE, RAT+FEEL, StoG, StoG+FE, StoG+FEEL, AT+StoG, AT+StoG+FE, AT+StoG+FEEL, RAT+StoG, RAT+StoG+FE, RAT+StoG+FEEL). The results highlight the improvements achieved by incorporating the Frequency Encoding (FE) and Evolutionary Leak Factor (EL) methods, both individually and in combination with other training strategies, demonstrating enhanced robustness against adversarial attacks.", "section": "5.2 Overall performance for various attack types"}, {"figure_path": "TuCQdBo4NC/tables/tables_14_2.jpg", "caption": "Table 6: Performance (%) of the proposed evolutionary leak factor \u03bb (EL) with other strategies, where 'FEEL, (||||2)' represents EL with L2 norm regularization, 'GP' represents gradient penalty, which adds L2 norm constraint to the model gradient. The perturbation \u03b5 = 4/255 for all attacks, and iterative step k = 4, step size \u03b1 = 0.01 for PGD. The dataset is CIFAR10 with T = 4, the network is VGG11.", "description": "This table compares the performance of different methods for enhancing the robustness of Spiking Neural Networks (SNNs) against adversarial attacks.  It contrasts the performance of the proposed Evolutionary Leak Factor (EL) with various other techniques (Vanilla, FEEL with different fixed \u03bb, FEEL with L2 regularization, and FEEL with learnable \u03bb) and shows that EL consistently improves both clean accuracy and robustness under various attacks.", "section": "5.3 Ablation study"}]