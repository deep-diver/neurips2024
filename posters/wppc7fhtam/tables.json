[{"figure_path": "WPPC7FHtaM/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It uses occlusion sensitivity analysis to determine the importance of individual words or phrases within the prompts by removing them one by one and measuring the impact on classification accuracy.  The results highlight differences in the prompts learned by gradient descent methods (CoOP, CoCoOP) compared to the human-interpretable prompts generated by IPO, demonstrating the advantages of IPO's approach.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_6_2.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table presents a comparison of different prompt engineering methods (CLIP, COOP, COCOOP, and IPO) on the Flower102 dataset, focusing on the impact of specific words on performance.  Occlusion sensitivity analysis is performed, where words are progressively removed from prompts to assess their importance. The results highlight the differences in interpretability and generalization capabilities of different methods. The table shows the performance on base and novel classes, with IPO demonstrating better performance and interpretability.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_6_3.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt optimization methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset. It shows the impact of using different prompts and removing individual words from the prompts on the accuracy of the models. The results highlight the strengths and weaknesses of different methods in terms of interpretability and overfitting, and the superior performance of the proposed method.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_6_4.jpg", "caption": "Table 2: Effect of LLM and LMM choice. We obtain best results with GPT-3.5-turbo as the LLM optimizer, and MiniCPM-V-2.0 for generating image descriptions for the Prompt Optimization Prompt.", "description": "This table presents the results of experiments conducted to evaluate the impact of different Large Language Models (LLMs) and Large Multimodal Models (LMMs) on the performance of the proposed IPO method.  The table shows that using GPT-3.5-turbo as the LLM optimizer and MiniCPM-V-2.0 for generating image descriptions yields the best performance.  The results highlight the importance of the choice of LLM and LMM for achieving optimal results with the IPO method.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_6_5.jpg", "caption": "Table 2: Effect of LLM and LMM choice. We obtain best results with GPT-3.5-turbo as the LLM optimizer, and MiniCPM-V-2.0 for generating image descriptions for the Prompt Optimization Prompt.", "description": "This table presents the results of experiments conducted to evaluate the impact of different Large Language Models (LLMs) and Large Multimodal Models (LMMs) on the performance of the proposed IPO method.  The table shows that using GPT-3.5-turbo as the LLM optimizer and MiniCPM-V-2.0 for generating image descriptions yielded the best overall performance (H-score) on the benchmark.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table presents a comparison of different prompt variations across various vision-language models on the Flower102 dataset. It highlights the impact of specific words and phrases on model performance, particularly demonstrating that the original CLIP model is sensitive to the word 'photo'.  The table also illustrates the overfitting behavior of methods such as CoOP and CoCoOP, showing improvements in novel class performance when learned tokens are removed. Finally, it showcases how the interpretable prompt optimization method (IPO) ensures that all tokens contribute to the overall performance, both in base and novel classes.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_7_2.jpg", "caption": "Table 4: Benefit of image description.", "description": "This table compares the performance of the model with and without image descriptions included in the Prompt Optimization Prompt.  The results show that including image descriptions significantly improves the model's accuracy, particularly on novel classes. This highlights the importance of incorporating multimodal information into the prompt optimization process.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_7_3.jpg", "caption": "Table 4: Benefit of image description.", "description": "This table compares the performance of the CLIP model with and without the inclusion of image descriptions generated by a Large Multimodal Model (LMM) in the Prompt Optimization Prompt.  It demonstrates the improvement in the model's performance when image information is integrated into the prompt optimization process. The results highlight the importance of multimodal inputs for enhancing prompt optimization in vision-language models.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_8_1.jpg", "caption": "Table 6: Comparison with existing state-of-the-art methods for base-to-novel generalization using 1-shot learning. Except for CLIP, the results for other methods are based on our reimplementation of their official code. Our proposed IPO exhibits robust generalization capability and achieves significant improvements on novel classes across 11 datasets.", "description": "This table compares the performance of the proposed IPO method against several existing state-of-the-art methods on eleven image classification datasets.  The comparison is done using a 1-shot learning setting (meaning each model is only shown one example from each class during training).  The table shows the performance (harmonic mean of base and novel accuracy) of each method on each dataset, highlighting IPO's improved performance on novel classes (classes not seen during training).  Note that results for methods other than CLIP are from the authors' re-implementation, ensuring consistent evaluation.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_15_1.jpg", "caption": "Table 10: Impact of large language model.", "description": "This table presents the results of experiments conducted to evaluate the impact of using different large language models (LLMs) on the performance of the proposed interpretable prompt optimizer (IPO).  The table shows that using larger and more advanced LLMs generally leads to improved performance in both base and novel classes, as measured by harmonic mean (H). The results suggest that increasing LLM capacity enhances the model's ability to generate effective and generalizable prompts.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_15_2.jpg", "caption": "Table 10: Impact of large language model.", "description": "This table shows the impact of using different LLMs (large language models) on the performance of the IPO method.  The results demonstrate that using more advanced LLMs, like GPT-4 and GPT-40, leads to improved performance in both base and novel classes, particularly with the H-score (harmonic mean).", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_16_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods on the Flower102 dataset, evaluating their performance on both base and novel classes.  It highlights the impact of specific words in the prompts and demonstrates that the proposed method (IPO) is more robust to word removal compared to existing techniques. The table includes occlusion sensitivity analysis, highlighting the importance of different words for various methods and illustrating how IPO improves the performance and interpretability of prompts compared to gradient-based methods. ", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_16_2.jpg", "caption": "Table 13: Experiments on segmentation tasks.", "description": "This table presents the results of experiments conducted on semantic segmentation tasks.  Several methods, including SPNet, ZS3, CaGNet, SIGN, Joint, Zegformer, Zsseg, and ZegCLIP are compared against two variations that incorporate the proposed IPO method (Zsseg + IPO and ZegCLIP + IPO). The table shows performance metrics for each method, including pAcc (pixel accuracy), mIoU (S) (mean Intersection over Union for the source domain), mIoU (U) (mean Intersection over Union for the unseen domain), and hIoU (harmonic mean of mIoU (S) and mIoU (U)).  The results demonstrate the performance improvements achieved by integrating the proposed IPO method into existing semantic segmentation models. ", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_16_3.jpg", "caption": "Table 14: Effect of batch size.", "description": "This table presents the results of experiments conducted to evaluate the impact of different batch sizes on the performance of the IPO model when using either GPT-3.5 Turbo or GPT-40 as the large language model (LLM).  The table shows that while GPT-40 maintains strong performance even with larger batch sizes, the performance of GPT-3.5 Turbo begins to decline when the batch size increases beyond a certain point. This is because GPT-3.5 Turbo has a limited capacity for effectively processing longer input texts.  The results highlight the trade-off between cost-effectiveness and performance when choosing a batch size.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_17_1.jpg", "caption": "Table 15: Impact of prompt history length.", "description": "This table shows the impact of varying prompt history lengths on the model's performance, evaluated on the base and novel classes as well as the harmonic mean.  It demonstrates that including a history of previous prompts leads to improved performance, with optimal performance at 20 past prompts. While including more past prompts improves the harmonic mean, it significantly increases the computational cost, which is why 20 was chosen as the optimal balance between performance and cost.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_17_2.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt methods (CLIP, COOP, COCOOP, and IPO) on the Flower102 dataset. It shows the accuracy for base and novel classes using different prompts, including prompts with certain words removed. The results highlight the overfitting issue of some methods and the interpretability advantage of the proposed IPO method.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_23_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table presents a comparison of different prompt strategies on the Flower102 dataset. It shows the performance of CLIP, CoOP, and CoCoOP models using various prompts, with and without specific words or tokens removed.  The results highlight the impact of specific keywords on model performance and show that the proposed interpretable prompt optimization method (IPO) offers improvements in novel classes while addressing overfitting issues observed in other methods.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_24_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table presents a comparison of different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It uses occlusion sensitivity analysis to show the impact of removing words from the prompts on the accuracy of classification for both base and novel classes. The results highlight the differences in how these methods learn and generalize, with IPO demonstrating the importance of each word in its human-interpretable prompts.  The shaded sections represent the original performance of each model.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_25_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset. It shows the impact of removing words from prompts on classification accuracy for both base and novel classes.  The results highlight the different strengths and weaknesses of each method, specifically showing how IPO produces more robust and interpretable prompts.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_26_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt optimization methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It uses occlusion sensitivity analysis to evaluate the importance of individual words in the prompts.  The results show that CLIP is sensitive to specific words, while CoOP and CoCoOP exhibit overfitting.  In contrast, IPO generates more interpretable prompts where each word contributes to performance.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_27_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by COOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt optimization methods (CLIP, COOP, CoCoOP, and IPO) on the Flower102 dataset. It shows the accuracy of each method using different prompts, including the original prompt and prompts with words removed.  The results highlight the impact of specific keywords and the overfitting issues with gradient-based methods.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_28_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods on the Flower102 dataset, analyzing their performance on base and novel classes.  It highlights the impact of removing individual words from prompts on model accuracy, revealing that traditional gradient-based methods (CoOP, CoCoOP) suffer from overfitting. In contrast, the proposed interpretable prompt optimization (IPO) demonstrates that all words in the generated prompts significantly contribute to improved performance on both base and novel classes.  The results are presented using the harmonic mean (H) of base and novel class accuracies.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_29_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It evaluates the performance of various prompts, including the standard prompt and prompts generated by each method.  Occlusion sensitivity analysis is applied by removing individual words to determine their importance.  The results highlight differences in performance and overfitting between the methods, showcasing IPO's superior interpretability and generalization.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_30_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It shows the accuracy on base and novel classes using various prompts, including prompts with words removed to assess their individual importance.  The results highlight the different strengths of each method. CLIP is sensitive to specific words, CoOP and CoCoOP overfit to base classes, while IPO generates more interpretable and generalizable prompts.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_31_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt optimization methods on the Flower102 dataset. It shows the impact of removing individual words from prompts on accuracy, highlighting the importance of specific words for different models.  The table contrasts traditional gradient-based methods with the proposed interpretable prompt optimizer (IPO), demonstrating IPO's ability to generate human-understandable prompts that improve both base and novel class performance without overfitting.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_32_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It shows the accuracy of different prompts on base and novel classes. Occlusion sensitivity analysis is performed to understand which words/tokens in the prompts are most impactful on performance. The results highlight the differences in how different methods handle base class overfitting and how IPO produces interpretable prompts. ", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_33_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares different prompt engineering methods (CLIP, COOP, COCOOP, and IPO) on the Flower102 dataset.  It shows the accuracy on base and novel classes for various prompts, including prompts with words removed to assess their importance.  The results highlight the overfitting issues with gradient-based methods and demonstrate IPO's improved interpretability and performance.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_34_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt engineering methods (CLIP, CoOP, CoCoOP, and IPO) on the Flower102 dataset.  It uses occlusion sensitivity analysis to evaluate the importance of individual words within prompts. The results highlight the overfitting issues of gradient-descent based methods (CoOP and CoCoOP) and the improved performance and interpretability of the proposed IPO method.", "section": "5.2 Results"}, {"figure_path": "WPPC7FHtaM/tables/tables_35_1.jpg", "caption": "Table 1: Comparison of various prompts with occlusion sensitivity analysis across different models on the Flower102 dataset [52]. The shaded areas in the table indicate the original performance of each method. Bold blue refers to the result of the best prompt for each model. The original CLIP model shows particular sensitivity to the word photo. In contrast, the tokens learned by CoOP and CoCoOP affect especially base class performance, while removing these learned tokens improves novel class performance. By contrast, with our interpretable prompt optimization, every word makes a meaningful contribution to both base and new classes. We provide results for more datasets in the appendix.", "description": "This table compares the performance of different prompt optimization methods on the Flower102 dataset. It shows how different prompts (including those generated by the proposed IPO method) affect the model's performance on both base and novel classes. Occlusion sensitivity analysis is used to determine the importance of each word in the prompts.  The results highlight the strengths and weaknesses of different approaches and illustrate the interpretability of the IPO method.", "section": "5.2 Results"}]