[{"figure_path": "yfQwyxiSJ7/figures/figures_1_1.jpg", "caption": "Figure 1: The overview of the proposed AutoPalette framework. Initialization: We compare the information gain of quantized images to select the images used in the initialization stage. Training: We forward the synthetic data to the palette network to obtain the color-reduced images. The objective functions of palette network include La, Lb, Lm and Ltask. The synthetic dataset is updated by solely optimizes Ltask.", "description": "This figure illustrates the AutoPalette framework, which consists of two main stages: initialization and training. In the initialization stage, the information gain of quantized images is used to select representative images for the synthetic dataset. The training stage involves a palette network that dynamically allocates colors to pixels, aiming to reduce color redundancy while preserving essential image features.  The palette network is trained using the Ltask loss, as well as auxiliary losses La, Lb, and Lm to ensure color utility and balance.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_2_1.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure visualizes the effect of color condensation on images.  (a) shows original images at different bit depths (8, 6, 3, 1-bit), demonstrating the reduction in color information. (b) and (c) display color-condensed synthetic images generated by the proposed AutoPalette model. (b) uses the full model, including the palette loss, while (c) omits the palette loss. The color palettes accompanying each set of images show how the model allocates colors, with a larger variation in color usage indicating more efficient color utilization.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison between the performance of submodular color diversity initialization and random real images initialization.", "description": "This figure shows a comparison of the performance of two different initialization methods:  one using a submodular color diversity approach (GraphCut) and the other using randomly selected real images (Baseline). The x-axis represents the number of colors used in the quantized images, while the y-axis shows the accuracy achieved.  The graph illustrates how the submodular color diversity initialization generally outperforms random initialization, especially when using a lower number of colors. This highlights the effectiveness of the proposed color-guided initialization in improving model performance by selecting more diverse images during the initialization stage.", "section": "4.3 Ablation Study"}, {"figure_path": "yfQwyxiSJ7/figures/figures_13_1.jpg", "caption": "Figure 1: The overview of the proposed AutoPalette framework. Initialization: We compare the information gain of quantized images to select the images used in the initialization stage. Training: We forward the synthetic data to the palette network to obtain the color-reduced images. The objective functions of palette network include La, Lb, Lm and Ltask. The synthetic dataset is updated by solely optimizes Ltask.", "description": "This figure provides a high-level overview of the AutoPalette framework, which consists of two main stages: initialization and training.  The initialization stage uses information gain to select representative images with low color redundancy from the dataset. These images are then used to train a palette network. The training stage involves passing synthetic data through the palette network to obtain color-reduced images. The network's objective function includes several components to balance color utility and minimize dataset redundancy.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_15_1.jpg", "caption": "Figure 4: CIFAR10 color condensed synthetic images with ZCA whitening.", "description": "This figure shows a visualization of the color-condensed synthetic images generated by the AutoPalette framework for the CIFAR-10 dataset.  ZCA whitening, a dimensionality reduction technique, has been applied to the images. Each small square represents a single image from the synthetic dataset, showcasing the visual characteristics after color reduction and data augmentation. The overall image provides a sense of the diversity and quality of the distilled dataset created by the proposed method.", "section": "A.7 Visualization of Distilled Images"}, {"figure_path": "yfQwyxiSJ7/figures/figures_15_2.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure shows the effect of the proposed AutoPalette method on color reduction. Subfigure (a) displays the same image with different bit depths (8, 6, 3, and 1), representing different levels of color quantization. Subfigures (b) and (c) show the synthetic images generated by AutoPalette with and without the palette loss, respectively. The color palettes for each image are also shown, with larger differences between palette rows indicating more efficient color utilization.", "section": "3. Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_15_3.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure shows a comparison of images at different bit depths (8, 6, 3, and 1-bit), demonstrating the effect of color condensation.  Subfigures (b) and (c) present examples of synthetic images generated by the AutoPalette model, with (b) using the full model and (c) excluding the palette loss. The color palettes for each image are also displayed, illustrating that a wider range of colors in the palette corresponds to better color utilization.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_16_1.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure shows the effect of the proposed AutoPalette model on color reduction. (a) shows images at different bit depths (8,6,3,1), demonstrating the progressive reduction in color information.  (b) displays color-condensed synthetic images generated by the full AutoPalette model, showcasing the preserved key features despite fewer colors.  (c) shows results when the palette loss is removed, highlighting the importance of this component for efficient color utilization.  The variation in color palette row heights visually represents the model's efficiency in distributing colors.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_16_2.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure visualizes the effect of reducing the number of bits used to represent colors in images.  (a) shows images with 8, 6, 3, and 1-bit color depth, demonstrating the significant loss of detail as the color depth decreases. (b) and (c) show the color-condensed synthetic images produced by the AutoPalette model with and without a palette loss, respectively, along with their associated color palettes. A larger difference between the colors in a palette signifies a more efficient use of the color space.", "section": "3 Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_16_3.jpg", "caption": "Figure 9: Color condensed synthetic images for ImageFruit", "description": "This figure shows a set of color-condensed synthetic images generated for the ImageFruit subset of the ImageNet dataset using the AutoPalette method. The images have a reduced color palette, aiming for efficient storage while preserving essential visual features.  The reduced color palette is a key aspect of the AutoPalette approach, which seeks to minimize redundancy in the color space for improved efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "yfQwyxiSJ7/figures/figures_17_1.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure visualizes the effect of reducing the number of bits used to represent color in images.  Subfigure (a) shows example images with 8, 6, 3, and 1 bits per color channel. Subfigures (b) and (c) display the color-condensed synthetic images generated by the AutoPalette model, with and without the palette loss respectively. The color palettes are shown alongside their corresponding images.  A larger difference in color values within a palette suggests more effective color utilization by the model.", "section": "3. Methodology"}, {"figure_path": "yfQwyxiSJ7/figures/figures_17_2.jpg", "caption": "Figure 8: Color condensed synthetic images for ImageWoof", "description": "This figure shows a collection of 64 synthetic images generated for the ImageWoof dataset using the AutoPalette method.  The images have been condensed to a reduced color palette, which aims to reduce storage space while preserving essential image features.  Each image represents a different class within the ImageWoof dataset, and the overall visual quality demonstrates the effectiveness of the color reduction technique in preserving relevant details despite the reduced color information.", "section": "4.2 Experimental Results"}, {"figure_path": "yfQwyxiSJ7/figures/figures_17_3.jpg", "caption": "Figure 2: The visualization of (a) images under 8, 6, 3, 1-bit color depths (b-c) color condensed synthetic images and their color palette. (b) our full model (c) our full model without palette loss. The larger difference among rows of a color palette indicates better color utilization.", "description": "This figure visualizes the effect of reducing the number of bits used to represent color in images.  Panel (a) shows example images at different bit depths (8, 6, 3, and 1). Panels (b) and (c) show the color-condensed synthetic images generated by the proposed method (AutoPalette). Panel (b) shows the results with the full model (including the palette loss), and panel (c) shows the results when the palette loss is removed. The color palettes show that using the palette loss results in a better distribution of colors across the palette (larger differences among rows). This indicates a more effective use of the limited color space.", "section": "3 Methodology"}]