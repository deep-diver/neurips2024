[{"figure_path": "5d2eScRiRC/tables/tables_7_1.jpg", "caption": "Table 1: Algorithm profiling with computation in milliseconds. 'Sampling' refers to generating a number of sequences equivalent to batch size and often uses equal or more time than updates. These times depend on hardware, implementation and code optimization.", "description": "This table compares the computational cost of different algorithms for training language models, measured in milliseconds.  It shows the time taken for model updates (MLE, GAIL, IQLearn) and the additional time required for sampling (which applies to online IRL). The results are shown for three different sizes of T5 models (base, large, and XL).", "section": "3.3.1 Computational efficiency and accuracy for online & offline inverse RL"}, {"figure_path": "5d2eScRiRC/tables/tables_15_1.jpg", "caption": "Table 3: IQLearn and MLE hyperparameters", "description": "This table lists the hyperparameter settings used for both the IQLearn and MLE algorithms in the experiments described in the paper.  It specifies the learning rate for both T5 and PaLM2 models, the number of warmup steps, the batch sizes used for different sizes of T5 models and the PaLM2 model, and the number of random seeds used per experiment.", "section": "3.3.1 Computational efficiency and accuracy for online & offline inverse RL"}, {"figure_path": "5d2eScRiRC/tables/tables_16_1.jpg", "caption": "Table 4: GAIL hyperparameters", "description": "This table lists the hyperparameters used for the Generative Adversarial Imitation Learning (GAIL) algorithm in the paper's experiments.  It specifies values for batch size, learning rate, warmup steps, KL strength (for the KL penalty in the policy optimization), and the number of random seeds used per experiment, for different sizes of the T5 language model (T5-base, T5-large, T5-xl). These settings were used to control the training process of the GAIL algorithm during the study.", "section": "A.1.3 GAIL"}, {"figure_path": "5d2eScRiRC/tables/tables_19_1.jpg", "caption": "Table 5: WMT22 results for offline IQLearn initialised with a PaLM2 checkpoint. Italic \u2013 best dev BLEU in group (i.e. same mix value), bold \u2013 best overall.", "description": "This table presents the results of offline IQLearn on the WMT22 dataset, comparing different regularization strengths (lambda) and the ratio of online data used (mixin). The table shows the dev-BLEU and test-BLEU scores for various combinations of these hyperparameters.  Italicized entries represent the best dev-BLEU scores within each mixin group, while bolded entries indicate the overall best performance across all tested configurations.", "section": "3.3 Analysis and ablations"}]