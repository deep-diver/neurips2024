[{"type": "text", "text": "IWBVT: Instance Weighting-based Bias-Variance Trade-off for Crowdsourcing ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Wenjun Zhang ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Liangxiao Jiang\u2217 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "School of Computer Science China University of Geosciences Wuhan 430074, China wjzhang@cug.edu.cn ", "page_idx": 0}, {"type": "text", "text": "School of Computer Science China University of Geosciences Wuhan 430074, China ljiang@cug.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Chaoqun Li School of Mathematics and Physics China University of Geosciences Wuhan 430074, China chqli@cug.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent years, a large number of algorithms for label integration and noise correction have been proposed to infer the unknown true labels of instances in crowdsourcing. They have made great advances in improving the label quality of crowdsourced datasets. However, due to the presence of intractable instances, these algorithms are usually not as significant in improving the model quality as they are in improving the label quality. To improve the model quality, this paper proposes an instance weighting-based bias-variance trade-off (IWBVT) approach. IWBVT at first proposes a novel instance weighting method based on the complementary set and entropy, which mitigates the impact of intractable instances and thus makes the bias and variance of trained models closer to the unknown true results. Then, IWBVT performs probabilistic loss regressions based on the bias-variance decomposition, which achieves the bias-variance trade-off and thus reduces the generalization error of trained models. Experimental results indicate that IWBVT can serve as a universal post-processing approach to significantly improving the model quality of existing state-of-the-art label integration algorithms and noise correction algorithms. Our codes and datasets are available at https://github.com/jiangliangxiao/IWBVT. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Crowdsourcing eases the difficulty of obtaining training datasets for supervised learning [8]. In crowdsourcing scenarios, instances are annotated not by domain experts but by crowd workers from crowdsourcing platforms [1,12]. While crowd workers are more cost-effective compared to domain experts, they typically possess inferior expertise and are thus more prone to assigning noisy labels [2,13]. To mitigate the impact of noisy labels, a common practice in crowdsourcing is repeated annotating, where each instance is annotated by multiple workers to obtain multiple noisy labels [21]. Subsequently, a multitude of algorithms have been proposed to infer the unknown true label of an instance from its multiple noisy labels [3,11,15]. ", "page_idx": 0}, {"type": "text", "text": "Specifically, these proposed algorithms can be roughly classified into two categories, namely label integration algorithms and noise correction algorithms. Label integration algorithms aim to integrate multiple noisy labels of each instance to infer an integrated label that is as close as possible to its unknown true label [16, 30]. Noise correction algorithms focus on identifying and correcting noise in integrated labels obtained from label integration algorithms [19,32]. Therefore, both label integration algorithms and noise correction algorithms inevitably pay more attention to the label quality of crowdsourced datasets, i.e., the proportion of instances in crowdsourced datasets whose integrated labels are equal to the unknown true labels. Indeed, these proposed algorithms have achieved empirical success in improving the label quality of crowdsourced datasets. ", "page_idx": 1}, {"type": "text", "text": "However, due to the presence of intractable instances, these algorithms often fall short of achieving anticipated improvements in the model quality. Here, the model quality is the proportion of instances whose predicted labels are equal to the unknown true labels when models classify test instances. On the one hand, the proportion of intractable instances in datasets tends to be low, which makes them have less impact on the label quality. For this reason, the above algorithms pay little attention to intractable instances in improving the label quality. On the other hand, the reason why intractable instances are hard to label and infer is that their attributes are ambiguous. Ambiguous attributes affect the effectiveness of models in learning classification rules from crowdsourced datasets. Therefore, intractable instances have a greater impact on the model quality compared to the label quality. Considering the fact that collecting high-quality integrated labels is ultimately aimed at training highquality models, improving the model quality should be paid more attention compared to improving the label quality in crowdsourcing. ", "page_idx": 1}, {"type": "text", "text": "To improve the model quality, this paper proposes an instance weighting-based bias-variance trade-off (IWBVT) approach for crowdsourcing. IWBVT at first proposes a novel instance weighting method based on the idea of complementary set and entropy, which mitigates the impact of intractable instances and thus makes the bias and variance of trained models closer to the unknown true results. Subsequently, IWBVT performs probabilistic loss regressions based on the bias-variance decomposition, which achieves the bias-variance trade-off and thus reduces the generalization error of trained models. In general, the contributions of this paper can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We focus on the performance of existing algorithms in terms of the model quality and reveal that existing algorithms are not as significant in improving the model quality as they are in improving the label quality.   \n\u2022 We propose a novel instance weighting method based on the complementary set and entropy. This new instance weighting method is more robust and can be applied to more complex crowdsourced scenarios.   \n\u2022 We propose IWBVT to improve the model quality. IWBVT mitigates the impact of intractable instances by instance weighting and achieves the bias-variance trade-off by probabilistic loss regressions.   \n\u2022 We demonstrate that IWBVT can serve as a universal post-processing approach to significantly improving the model quality of existing state-of-the-art label integration algorithms and noise correction algorithms. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "With repeated annotating, crowdsourcing collects multiple noisy labels for each instance in datasets. Subsequently, label integration is usually used to integrate multiple noisy labels to infer the unknown true label for each instance. Initiating the area of label integration, [4] leveraged an expectationmaximization (EM) algorithm to estimate a confusion matrix, which models workers and class priors in clinical diagnostics. In contrast, [20] performed majority voting based on multiple noisy labels of instances, and the class receiving the highest number of votes was determined as the integrated label. Enhancing this concept by incorporating worker reliability, [10] performed weighted majority voting by iteratively estimating worker weights and integrated labels. [23] further proposed max-margin majority voting, which integrates labels by maximizing the margin between classes. Recently, [3] augmented the label space for an instance by considering the labels of its neighbors, which distinguishes the impact of different neighbors by instance weighting. Inspired by label distribution learning [6,17,26], [8] proposed multiple noisy label distribution propagation, which absorbs label distributions of neighboring instances into the label distribution of the focal instance. ", "page_idx": 1}, {"type": "text", "text": "No matter how powerful the label integration algorithms are, a certain degree of noise is always present in integrated labels. Subsequently, noise correction has been proposed to identify and correct these noises. Initiating the area of noise correction, [19] introduced three distinct algorithms: polishing labels (PL), self-training correction (STC), and cluster-based correction (CC). PL divides datasets into subsets to train multiple models and then performs majority voting based on the models\u2019 predictions to correct the original integrated labels. STC fliters the dataset into a clean set and a noise set, iteratively training models on the clean set to predict and correct instances in the noise set. CC estimates the probability of each instance belonging to each class through repeated clustering and performs weighted majority voting to correct original integrated labels. Forgoing the above three algorithms, [32] adaptively estimated the proportion of noise in datasets based on multiple noisy labels to fliter out a clean set and a noise set. Recently, drawing from multi-view learning [31], [15] used multi-view learning for correcting noise instances. They trained dual models on the attribute and multiple noisy label views of the clean set to correct instances in the noise set. [11] focused on the effect of neighboring instances on noise flitering before noise correction, utilizing multiple noisy label distributions of neighbors to identify noise instances more accurately. ", "page_idx": 2}, {"type": "text", "text": "In essence, both label integration algorithms and noise correction algorithms aim to improve the model quality by improving the label quality. Unfortunately, due to the presence of intractable instances, these algorithms are usually not as significant in improving the model quality as they are in improving the label quality. Currently, although there exist several supervised or semi-supervised approaches focused on improving the model quality from noisy training datasets [7,14,28], they are not perfectly applicable to crowdsourcing. On the one hand, they cannot utilize the multiple noisy labels specific to crowdsourcing. On the other hand, semi-supervised approaches typically assume that true labels of a few instances are known, which cannot be satisfied in crowdsourcing. In this context, we propose IWBVT, as the first universal post-processing approach to improve the model quality of both label integration algorithms and noise correction algorithms in crowdsourcing. ", "page_idx": 2}, {"type": "text", "text": "3 Notations and preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $D$ denote a crowdsourced dataset $\\{(\\pmb{x}_{i},\\pmb{L}_{i})\\}_{i=1}^{N}$ , where $N$ represents the number of instances, and $\\pmb{x}_{i}$ is the $i$ -th instance, represented as $\\{x_{i1},\\dots,x_{i m},\\dots,x_{i M}\\}$ . Here, $M$ signifies the dimension of attributes and $x_{i m}$ denotes the attribute value of $\\pmb{x}_{i}$ on the $m$ -th attribute $A_{m}$ . $\\pmb{L}_{i}$ denotes multiple noisy labels of $\\pmb{x}_{i}$ , which can be represented as $\\{l_{i r}\\}_{r=1}^{R}$ . $R$ denotes the number of workers, $l_{i r}$ denotes the label of $\\pmb{x}_{i}$ annotated by the $r$ -th worker $u_{r}$ . $l_{i r}$ takes a value from $\\{-1,c_{1},\\ldots,c_{q},\\ldots,c_{Q}\\}$ , where $Q$ denotes the number of classes, $c_{q}$ denotes the $q$ -th class and $-1$ denotes that $u_{r}$ does not annotate $\\pmb{x}_{i}$ . The purpose of label integration and noise correction is to infer an integrated label $\\hat{y}_{i}$ for $\\pmb{x}_{i}$ and to minimize the error between $\\hat{y}_{i}$ and the unknown true label $y_{i}$ . ", "page_idx": 2}, {"type": "text", "text": "3.1 Instance weighting for crowdsourcing ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given $(\\pmb{x}_{i},\\pmb{L}_{i})$ , the weight of $\\pmb{x}_{i}$ is denoted by $w_{i}$ . Intuitively, the smaller the value of $w_{i}$ , the more likely that $\\pmb{x}_{i}$ is an intractable instance. To estimate $w_{i}$ , $\\pmb{L}_{i}$ is first transformed into a multiple noisy llaabbeell s diins tuhtiaot nt $P_{i}=\\{P(c_{q}|L_{i})\\}_{q=1}^{Q}$ e, qwuheenrtley ,t hsee vperroabl arebiplriteys $P(c_{q}|L_{i})$ srteafnlecce tsw tehige hptirnogp omrteitohno dosf $L_{i}$ $c_{q}$ have been proposed based on $P_{i}$ . First, [21] proposed estimating $w_{i}$ by $P(\\hat{y}_{i}|L_{i})$ , i.e., $\\bar{w_{i}}\\propto\\bar{P}(\\hat{y}_{i}|L_{i})$ . Take MV as an example, the probability $P(\\hat{y}_{i}|L_{i})$ consistently equals the maximum value in $P_{i}$ . This method is usually effective when $Q=2$ . However, when $Q>2$ , $P(\\hat{y}_{i}|L_{i})$ is not sufficient to distinguish different distributions, such as $\\lbrace0.5,0.3,0.2\\rbrace$ and $\\{0.5,0.4,0.1\\}$ . ", "page_idx": 2}, {"type": "text", "text": "Subsequently, [27] proposed estimating $w_{i}$ by the entropy of $P_{i}$ , i.e., $\\begin{array}{r}{w_{i}\\propto\\frac{1}{E n t(P_{i})}}\\end{array}$ Ent(Pi), where ", "page_idx": 2}, {"type": "equation", "text": "$$\nE n t(P_{i})=-\\sum_{q=1}^{Q}P(c_{q}|L_{i})\\log P(c_{q}|L_{i}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Based on the maximum entropy principle, when $P_{i}$ conforms more closely to the uniform distribution, the entropy $E n t(P_{i})$ increases, leading to a decrease in the corresponding weight $w_{i}$ . Though entropybased methods can weight instances in multi-class datasets, they still fail to distinguish some complex distributions, such as $\\left\\lbrace\\bar{0}.4,0.3,0.3\\right\\rbrace$ and $\\{0.4,0.4,0.2\\}$ . Recently, [3] proposed estimating $w_{i}$ by the ", "page_idx": 2}, {"type": "image", "img_path": "aJDGfynRw7/tmp/1ed268f867e4ffa56510cc1e9b614e48d2f0ce8699a7db4419f1f227770f6fcd.jpg", "img_caption": ["Figure 1: The illustration of our new instance weighting method. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "class margin as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nw_{i}\\propto\\operatorname*{max}(P_{i})-\\sec(P_{i}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\operatorname*{max}(P_{i})$ and $\\sec(P_{i})$ denote the largest and second largest values in $P_{i}$ , respectively. This method focuses on the confusing classes in crowdsourced datasets. Nevertheless, it still struggles to distinguish some complex distributions, such as $\\{0.5,0.3,0.1,0.1\\}$ and $\\{0.4,0.2,0.2,0.2\\}$ . ", "page_idx": 3}, {"type": "text", "text": "In addition to these methods, there are also a few methods that estimate $w_{i}$ with classification models or evolutionary algorithms [22,29]. However, these methods have not been discussed here as their performance is affected by the selected models, loss functions, parameter settings, etc. ", "page_idx": 3}, {"type": "text", "text": "3.2 Bias-variance decomposition ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The bias-variance decomposition is an effective way to analyze the generalization error of models. Referring to [9], given a model $f$ , its generalization error $\\mathbb{E}_{f}$ can be denoted as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{E}_{f}=\\sum_{i=1}^{N}P(\\pmb{x}_{i})\\left(b i a s_{i}^{2}+v a r_{i}+\\sigma_{i}^{2}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $P(x_{i})$ denotes the probability of selecting $\\pmb{x}_{i}$ from $D.\\ b i a s_{i}^{2}$ and $v a r_{i}$ denote the bias term and the variance term, respectively. They are estimated as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nb i a s_{i}^{2}=\\frac{1}{2}\\sum_{q=1}^{Q}\\Big[P(c_{q}|\\pmb{x}_{i})-P(c_{q}|\\pmb{f},\\pmb{x}_{i})\\Big]^{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "equation", "text": "$$\nv a r_{i}=\\frac{1}{2}\\Big[1-\\sum_{q=1}^{Q}P(c_{q}|f,\\pmb{x}_{i})^{2}\\Big],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $P(c_{q}|\\pmb{x}_{i})$ denotes the true probability that $\\pmb{x}_{i}$ belongs to $c_{q}$ , $P(c_{q}|f,\\pmb{x}_{i})$ denotes the probability that $f$ classifies $\\pmb{x}_{i}$ into $c_{q}$ in multiple results generated by cross-validation. Therefore, $\\bar{P}(c_{q}|\\pmb{x}_{i})$ is independent of $f$ and is only related to $D$ . $\\sigma_{i}^{2}$ denotes the noise term, which is also only related to $D$ . ", "page_idx": 3}, {"type": "text", "text": "4 Approach ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The primary objective of IWBVT is to improve the model quality through bias-variance trade-off. However, in crowdsourcing scenarios, $P(c_{q}|\\pmb{x}_{i})$ can only be roughly estimated because $y_{i}$ is unknown and $\\hat{y}_{i}$ is inaccurate. To estimate the bias and variance of $f$ as accurately as possible, IWBVT first mitigates the impact of intractable instances by instance weighting. Subsequently, to achieve the bias-variance trade-off, IWBVT learns probabilistic loss by probabilistic loss regressions. ", "page_idx": 3}, {"type": "text", "text": "4.1 Instance weighting ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "As previously mentioned, existing instance weighting methods struggle to distinguish certain complex distributions effectively. In response, IWBVT introduces a novel instance weighting method that leverages the complementary set and entropy to overcome this limitation. The innovative aspects of this method are depicted in Figure 1. As shown in the figure, $P(\\hat{y}_{i}|L_{i})$ reflects the proportion of the integrated label in $\\pmb{L}_{i}$ . A higher $P(\\hat{y}_{i}|L_{i})$ suggests more workers reach a consensus on $\\pmb{x}_{i}$ , thereby indicating a decreased likelihood of $\\pmb{x}_{i}$ being an intractable instance. To extend our method to multi-class datasets, we also focus on the entropy of $\\bar{P}_{i}$ , i.e., $E n t(\\bar{P}_{i})$ . Here, $\\bar{P_{i}}$ is the complementary set of $\\{P(\\hat{y}_{i}|L_{i})\\}$ in $P_{i}$ $(\\{P(c_{q}|L_{i})\\}_{q=1}^{Q})$ . Intuitively, workers tend to reach a consensus on a special class on tractable instances, so they should be more randomized on other classes. The entropy of $\\bar{P_{i}}$ reflects the degree of randomization. Accordingly, our instance weighting method considers four cases, shown to the right side of the arrow in Figure 1. Among them, the case in the upper left corner indicates that when $\\bar{E n t}(\\bar{\\pmb{P}_{i}})$ is fixed, a lower $P(\\hat{y}_{i}|L_{i})$ results in a lower $w_{i}$ . Conversely, the case in the upper right corner indicates that a higher $P(\\hat{y}_{i}|L_{i})$ results in a higher $w_{i}$ . The case in the lower left corner indicates that when $P(\\hat{y}_{i}|L_{i})$ is fixed, a lower $E n t(\\bar{P}_{i})$ results in a lower $w_{i}$ . The case in the lower right corner indicates that the higher $E n t(\\bar{P}_{i})$ results in a higher $w_{i}$ . To cover these cases, specifically, we estimate $w_{i}$ as follows: ", "page_idx": 3}, {"type": "table", "img_path": "aJDGfynRw7/tmp/8b43912241a9ad7229e659f314139c019b42df5d9c1d5453f594d83bf0eb9440.jpg", "table_caption": ["Table 1: The comparison results of instance weighting methods on complex distributions. "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nw_{i}=P(\\hat{y}_{i}|L_{i})\\frac{E n t(\\bar{P}_{i})}{\\log(Q-1)},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\log(Q-1)$ is the normalization factor. When $Q=2$ , we set $\\frac{E n t(\\bar{P}_{i})}{\\log(Q-1)}$ to 1. ", "page_idx": 4}, {"type": "text", "text": "To demonstrate the superiority of our weighting method over existing methods, we calculate instance weights with each method on all the complex distributions mentioned in Section 3.1. Table 1 reports the detailed comparison results. Here, $\"\\checkmark\"$ and $\"\\times\"$ indicate whether the weighting method is effective in distinguishing the corresponding complex distribution, respectively. Empirically, the weight corresponding to the front distribution in each example should be higher than the latter. The results show that only our method can distinguish all these types of complex distributions, while existing methods cannot. By Eq. (6), we calculate weights of all instances as $W=\\{w_{i}\\}_{i=1}^{N}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 1. When $E n t(\\bar{P}_{i})$ remains constant, Eq. (6) covers $w_{i}\\propto P(\\hat{y}_{i}|L_{i})$ . When $Q>2$ and $P(\\hat{y}_{i}|L_{i})$ is the maximum value in $P_{i}$ , Eq. (6) covers $w_{i}\\propto\\mathrm{max}(P_{i})-\\mathrm{sec}(P_{i})$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. When $Q\\,=\\,2$ , we set $E n t(\\Bar{P}_{i})/\\mathrm{log}(Q-1)$ to 1, so Eq. (6) simplifies to $w_{i}\\,\\propto\\,P(\\hat{y}_{i}|L_{i})$ . $w_{i}\\propto P(\\hat{y}_{i}|L_{i})$ still holds in Eq. (6) when $Q>2$ and $E n t(\\bar{P}_{i})$ remains constant. When $Q>2$ and $P(\\hat{y}_{i}|L_{i})$ remains constant, $\\bar{w_{i}}\\propto E n t(\\bar{P_{i}})$ holds. According to the maximum entropy principle, $E n t(\\bar{P}_{i})$ takes its maximum value when any element of $\\bar{P_{i}}$ is equal to $\\textstyle{\\frac{1-P\\left({\\hat{y}}_{i}|L_{i}\\right)}{Q-1}}$ . At this point, if $P(\\hat{y}_{i}|L_{i})$ is the maximum value in $P_{i}$ , $\\operatorname*{max}(P_{i})-\\sec(P_{i})$ takes its maximum value. Conversely, when $E n t(\\bar{P}_{i})$ takes its minimum value, $\\operatorname*{max}(P_{i})\\,{-}\\sec(P_{i})$ also takes its minimum value. Therefore, $w_{i}\\propto\\operatorname*{max}(P_{i})-\\sec(P_{i})$ holds when $Q>2$ and $P(\\hat{y}_{i}|L_{i})$ is the maximum value in $P_{i}$ . Due to the limited pages, more detailed proof of Theorem 1 is provided in Appendix A. \u53e3 ", "page_idx": 4}, {"type": "text", "text": "4.2 Bias-variance trade-off ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "After instance weighting, the impact of intractable instances is mitigated. Therefore, $P(c_{q}|\\pmb{x}_{i})$ can be calculated more accurately, and then bias and variance can be estimated more accurately. Based on this result, the bias-variance trade-off will be more effective. After instance weighting, we train a classification model $f$ on $D$ with $W$ . Let $C$ denote the label space $\\{c_{1},\\ldots,c_{q},\\ldots,c_{Q}\\}$ , in this paper, $f$ classifies the test instance $\\textbf{\\em x}$ with the bias-variance trade-off as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nc(\\pmb{x})=\\underset{c_{q}\\in C}{\\arg\\operatorname*{max}}\\big(f\\big(c_{q}|\\pmb{x}\\big)+h_{q}(\\pmb{x})\\big),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $f(c_{q}|\\pmb{x})$ denotes the probability that $\\textbf{\\em x}$ belongs to $c_{q}$ predicted by $f.\\ h_{q}(x)$ is the prediction of the regression model $h_{q}$ trained on the following probabilistic loss regression task: ", "page_idx": 4}, {"type": "equation", "text": "$$\nT_{q}=({\\pmb{\\mathscr{X}}};{\\pmb{W}};{\\pmb{\\mathscr{L}}}_{q}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $_{x}$ is the attribute matrix consisting of all training instances. $\\pmb{{\\mathcal{L}}}_{q}$ is the probabilistic loss vector for $c_{q}$ , which can be represented as $\\{\\mathcal{L}_{1q},...\\,,\\mathcal{L}_{i q},...\\,,\\mathcal{L}_{N q}\\}^{T}.~\\mathcal{L}_{i}$ is calculated as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}_{i q}=\\left\\{1-f(c_{q}|\\pmb{x}_{i})\\ \\ \\ c_{q}=\\hat{y}_{i}\\right.}\\\\ {0-f(c_{q}|\\pmb{x}_{i})\\ \\ \\ c_{q}\\neq\\hat{y}_{i}}\\end{array}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Theorem 2. When the probabilistic loss is defined as in Eq. (9), performing probabilistic loss regressions constructed by $E q$ . (8) ensures that Eq. (7) asymptotically achieves the bias-variance trade-off. ", "page_idx": 5}, {"type": "text", "text": "Proof. When $f$ is adjusted, $P(c_{q}|f,x_{i})$ changes with $f$ , and this change is denoted as $\\Delta_{i q}$ . Let $b\\tilde{i a}s_{i}^{2}$ and $v\\tilde{a}r_{i}$ denote the changed bias term and variance term, they can be calculated as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\nb\\tilde{i}a s_{i}^{2}=b i a s_{i}^{2}+\\sum_{q=1}^{Q}\\Delta_{i q}P(c_{q}|f,x_{i})+\\frac{1}{2}\\sum_{q=1}^{Q}\\Delta_{i q}^{2}-\\sum_{q=1}^{Q}\\Delta_{i q}P\\left(c_{q}|x_{i}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\nv\\tilde{a}r_{i}=v a r_{i}-\\sum_{q=1}^{Q}\\Delta_{i q}P(c_{q}|f,\\pmb{x}_{i})-\\frac{1}{2}\\sum_{q=1}^{Q}\\Delta_{i q}^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Due to the limited pages, more detailed derivation of Eqs. (10) - (11) is provided in Appendix B. Comparing Eq. (10) and Eq. (11) shows that the common terms $\\textstyle\\sum_{q=1}^{Q}\\Delta_{i q}P(c_{q}|f,\\mathbf{x}_{i})$ and $\\textstyle{\\frac{1}{2}}\\sum_{q=1}^{Q}\\Delta_{i q}^{2}$ in $b\\tilde{a}{{{s}_{i}}^{2}}$ and $v\\tilde{a}r_{i}$ have opposite signs. Therefore, when improving $\\mathbb{E}_{f}$ , the bias and variance tend to change in opposite trends, which is known as the bias-variance dilemma. Improving $\\mathbb{E}_{f}$ by synergistically considering changes in both bias and variance is known as the bias-variance trade-off. According to Eqs. (3), (10), and (11), we can get the changed $\\tilde{\\mathbb{E}_{f}}$ as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{\\mathbb{E}_{f}}=\\mathbb{E}_{f}-\\sum_{i=1}^{N}P(\\pmb{x}_{i})\\sum_{q=1}^{Q}\\Delta_{i q}P\\left(c_{q}|\\pmb{x}_{i}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In general, when $c_{q}$ is the true label of $\\pmb{x}_{i}$ , $P\\left(c_{q}|\\mathbf{x}_{i}\\right)$ tends to 1, otherwise it tends to 0. However, the true label $y_{i}$ is unknown in crowdsourcing scenarios. After instance weighting, the impact of intractable instances is mitigated, so we assume that $\\hat{y}_{i}$ is equal to $y_{i}$ . Therefore, when $c_{q}\\neq\\hat{y}_{i}$ , $\\Delta_{i q}P(c_{q}|\\pmb{x}_{i})$ tends to 0. When $c_{q}=\\hat{y}_{i}$ , since the probability terms $P(x_{i})$ and $P(c_{q}|\\pmb{x}_{i})$ in Eq. (12) are non-negative, $\\tilde{\\mathbb{E}_{f}}$ is guaranteed to be less than $\\mathbb{E}_{f}$ as long as $\\Delta_{i q}$ is greater than 0. In summary, the key factor of the bias-variance trade-off is $\\Delta_{i q}\\left(\\dot{c}_{q}=\\hat{y}_{i}\\right)$ . To make $\\Delta_{i q}$ $(c_{q}=\\hat{y}_{i})$ greater than 0, the following optimization task can be constructed: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m a x i m i z e\\quad f(\\hat{y}_{i}|\\pmb{x}_{i})}\\\\ &{s.t.\\quad f(\\hat{y}_{i}|\\pmb{x}_{i})-\\underset{c_{q}\\in C\\land c_{q}\\neq\\hat{y}_{i}}{\\operatorname*{max}}f(c_{q}|\\pmb{x}_{i})\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, maximizing $f(\\hat{y}_{i}|\\pmb{x}_{i})$ ensures that $\\Delta_{i q}$ ( $\\chi_{q}=\\hat{y}_{i})$ is greater than 0, while the constraint ensures that the prediction of $f$ will be $\\hat{y}_{i}$ . Then, according to the Lagrange multiplier, the Lagrange function can be constructed as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\nL(\\pmb{x}_{i})=f(\\hat{y}_{i}|\\pmb{x}_{i})+\\lambda\\big[f(\\hat{y}_{i}|\\pmb{x}_{i})-\\operatorname*{max}_{c_{q}\\in C\\land c_{q}\\neq\\hat{y}_{i}}f(c_{q}|\\pmb{x}_{i})\\big],\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\lambda\\geq0$ . For simplicity, $L^{\\prime}(\\pmb{x}_{i})$ can be further constructed as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L^{\\prime}(\\pmb{x}_{i})=L(\\pmb{x}_{i})-\\underset{\\substack{c_{q}\\in C\\land c_{q}\\neq\\hat{y}_{i}}}{\\operatorname*{max}}f(c_{q}|\\pmb{x}_{i})}\\\\ &{\\qquad\\quad=(1+\\lambda)\\big[f(\\hat{y}_{i}|\\pmb{x}_{i})-\\underset{\\substack{c_{q}\\in C\\land c_{q}\\neq\\hat{y}_{i}}}{\\operatorname*{max}}f(c_{q}|\\pmb{x}_{i})\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Since the probability $\\operatorname*{max}_{c_{q}\\in C\\land c_{q}\\neq\\hat{y}_{i}}f(c_{q}|{\\pmb x}_{i})\\geq0$ , so $L(\\pmb{x}_{i})\\geq L^{\\prime}(\\pmb{x}_{i})$ . Ultimately, Eq. (13) can be optimized to achieve a better result by maximizing $L^{\\prime}(\\pmb{x}_{i})$ . At the same time, since $\\lambda\\geq0$ , the value of $L^{\\prime}(\\pmb{x}_{i})$ is positively correlated with the following difference: ", "page_idx": 5}, {"type": "equation", "text": "$$\nf({\\hat{y}}_{i}|\\pmb{x}_{i})-\\operatorname*{max}_{c_{q}\\in C\\land c_{q}\\neq{\\hat{y}}_{i}}f(c_{q}|\\pmb{x}_{i}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "According to Eq. (9), through probabilistic loss regressions, when $c_{q}=\\hat{y}_{i}$ , $f(c_{q}|{\\pmb x})+h_{q}({\\pmb x})$ in Eq. (7) tends to 1. Conversely, when $c_{q}\\neq\\hat{y}_{i}$ , $f(c_{q}|{\\pmb x})+h_{q}({\\pmb x})$ tends to 0. Therefore, Eq. (7) is effective in maximizing the difference Eq. (16). Ultimately, Theorem 2 is proved. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "The whole learning process of IWBVT is shown in Algorithm 1. In Algorithm 1, lines 1-3 learn a weight for each instance and their time complexity is $O(N R Q)$ . Line 4 trains a classification model $f$ whose training time complexity is denoted as $O(t_{1})$ . Lines 5-11 learn a probabilistic loss regression model $h_{q}$ for each class $c_{q}$ and their time complexity is $O(Q(N t_{2}+t_{3}))$ . Here, $t_{2}$ denotes the prediction time complexity of $f$ on each class and $t_{3}$ denotes the training time complexity of $h_{q}$ In this paper, we select NB as the classification model and linear regression as the regression model. Therefore, $t_{1},\\,t_{2}$ , $t_{3}$ are equal to $O(N M)$ , $O(M)$ , and $O(N M^{2}\\,\\bar{+}\\,M^{3})$ , respectively. If only the highest order terms are taken, the time complexity of IWBVT is $O(N R\\dot{Q}+\\bar{N}Q M^{2}+Q M^{3})$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 The learning process of IWBVT ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Require: $\\hat{D}=\\{(\\pmb{x}_{i},\\pmb{L}_{i},\\hat{y}_{i})\\}_{i=1}^{N}$ - a crowdsourced dataset with integrated labels.   \nEnsure: classification model $f$ , regression model set $\\pmb{H}$ .   \n1: for $i=1$ to $N$ do   \n2: Calculate the weight $w_{i}$ of $\\pmb{x}_{i}$ by Eq. (6);   \n3: end for   \n4: Train the classification model $f$ on $\\hat{D}$ with $W=\\{w_{i}\\}_{i=1}^{N}$ ;   \n5: for $q=1$ to $Q$ do   \n6: for $i=1$ to $N$ do   \n7: Calculate the probabilistic loss $\\mathcal{L}_{i q}$ by Eq. (9);   \n8: end for   \n9: Construct the regression task $T_{q}$ by Eq. (8);   \n10: Learn the regression model hq on Tq;   \n11: end for   \n12: return classification model $f,H=\\{h_{1},h_{2},\\ldots,h_{Q}\\}$ . ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To validate the effectiveness of IWBVT, we conduct a series of experiments on the whole 34 simulated and 2 real-world crowdsourced datasets published on the Crowd Environment and its Knowledge Analysis (CEKA) [33] platform. First, we illustrate the setup of our experiments, including comparison algorithms and their parameter settings. Next, we describe the simulation process and present the simulated experimental results in terms of the model quality. Finally, to further validate the strength of IWBVT, we analyze the experimental results of comparative experiments and ablation experiments on real-world crowdsourced datasets. ", "page_idx": 6}, {"type": "text", "text": "5.1 Experimental setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We select seven state-of-the-art algorithms for experiments, including: majority voting (MV) [20], iterative weighted majority voting (IWMV) [10], label augmented and weighted majority voting (LAWMV) [3], multiple noisy label distribution propagationg (MNLDP) [8], adaptive voting noise correction (AVNC) [32], multi-view-based noise correction (MVNC) [15], and neighborhood weighted voting-based noise correction (NWVNC) [11]. Among them, MV is the simplest label integration algorithm and is used as a baseline for all algorithms. IWMV, LAWMV and MNLDP are three state-of-the-art label integration algorithms. AVNC, MVNC and NWVNC are three state-ofthe-art noise correction algorithms. They are used to validate the effectiveness of IWBVT for label integration and noise correction. All these algorithms are implemented based on the CEKA platform and their parameter settings are consistent with the corresponding published papers. AVNC, MVNC and NWVNC are all performed based on integrated labels inferred by MV. Besides, we use linear regression as $h_{q}$ in IWBVT. All experiments are conducted on a Windows 10 machine with an AMD Athlon(tm) X4 860K Quad Core Processor $\\ @\\ 3.70\\,\\mathrm{GHz}$ and 16 GB of RAM. ", "page_idx": 6}, {"type": "text", "text": "5.2 Experiments on simulated datasets ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets and simulation process. We conduct our simulated experiments on all simulated datasets published on the CEKA platform. These datasets come from a wide variety of application domains and represent plentiful crowdsourcing scenarios. Considering that the selected label integration algorithms and noise correction algorithms handle the missing values of datasets differently, we use the unsupervised attribute filter ReplaceMissingValues in the Waikato Environment and Knowledge Analysis (WEKA) [25] platform to replace all missing values. Specifically, ReplaceMissingValues uses the mean of numerical attribute values or the modes of the nominal attribute values from the available data to replace missing values. Subsequently, to generate multiple noisy labels for each instance, we simulate the crowdsourcing process for these datasets. First, we randomly generate five workers whose label quality follows a normal distribution with $\\Nu(0.65,0.05^{2})$ . The label quality of a worker reflects the probability that the noisy label annotated by this worker to an instance is the same as this instance\u2019s unknown true label. Then, we hide true labels and use these simulated workers to annotate datasets. Finally, we use the selected algorithms to infer integrated labels for these datasets. For each simulation, we evaluate the original model quality and the corresponding model quality improved using IWBVT through stratified 10-fold cross-validation. Here, we use Naive Bayes (NB) [5] as the target model. The above processes are repeated ten times independently for each algorithm on each dataset. ", "page_idx": 6}, {"type": "table", "img_path": "aJDGfynRw7/tmp/797a2650722eef4cbde615091e7a0a9afa13dbefe3e6eea32497b99891be0b0f.jpg", "table_caption": ["Table 2: The model quality $(\\%)$ comparisons of MV, IWMV, LAWMV, MNLDP, AVNC, MVNC and NWVNC before and after using IWBVT on 34 simulated datasets. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Experimental results. Table 2 shows the detailed model quality $(\\%)$ comparisons of each algorithm on each dataset, respectively. The columns ORI and IWBVT correspond to the original model quality and the model quality using IWBVT, respectively. The symbols $\\bullet$ and $\\circ$ in the table denote the model quality has a statistically significant improvement or degradation using our proposed IWBVT with a corrected paired two-tailed t-test with the significance level $\\alpha=0.05$ [18], respectively. Besides, the averages and the Win/Tie/Lose $(W/T/L)$ values are summarized at the bottom of Table 2. The $W/T/L$ implies that when improving the original model quality, IWBVT wins on $W$ datasets, ties on $T$ datasets, and loses on $L$ datasets. These experimental results validate the effectiveness of IWBVT, and we can summarize the following highlights: ", "page_idx": 7}, {"type": "text", "text": "\u2022 The average model quality of MV using IWBVT on 34 datasets is $79.03\\%$ , which is higher than the original model quality of all selected algorithms. This demonstrates both the limitations of label integration algorithms or noise correction algorithms and the effectiveness of IWBVT in improving the model quality. ", "page_idx": 7}, {"type": "image", "img_path": "aJDGfynRw7/tmp/0687718b4071df9864078fbce9e7297ddd841c55c7e735e4d7a93987afe570bc.jpg", "img_caption": ["Figure 2: The model quality $(\\%)$ comparisons of MV, IWMV, LAWMV, MNLDP, AVNC, MVNC and NWVNC before and after using IWBVT on Leaves and Income. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "\u2022 The average model quality of IWMV $(78.94\\%)$ , LAWMV $(80.22\\%)$ , and MNLDP $(80.24\\%)$ using IWBVT are higher than the original results of these state-of-the-art label integration algorithms. This demonstrates that IWBVT is still effective for more sophisticated label integration algorithms in improving the model quality.   \n\u2022 The average model quality of AVNC $(80.77\\%)$ , MVNC $(80.44\\%)$ , and NWVNC $(80.54\\%)$ using IWBVT are also higher than the original results of these state-of-the-art noise correction algorithms. This demonstrates that IWBVT can serve as a universal post-processing approach to significantly improving the model quality.   \n\u2022 Based on the t-test results, the number of datasets in which IWBVT wins significantly $(W)$ is always much higher than the number of datasets in which it loses significantly $(L)$ for all algorithms. This strongly demonstrates the effectiveness and robustness of IWBVT. ", "page_idx": 8}, {"type": "text", "text": "5.3 Experiments on real-world datasets ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Datasets. To demonstrate the robustness of IWBVT, the above simulation process pays more attention to common factors of crowdsourcing. However, training models on real-world datasets may also be affected by other factors, such as sparsity and annotating bias. To verify the effectiveness of IWBVT in real-world crowdsourced scenarios, we also construct our experiments on two widely used real-world crowdsourced datasets, Leaves and Income, published on the CEKA platform [34]. Here, Leaves and Income are selected through the online platform Amazon Mechanical Turk (AMT). Leaves is annotated by 83 workers and each instance is annotated by 10 workers. There are 6 classes, 384 instances, 3840 labels, 64 numeric attributes, and 0 missing values in Leaves. Income is annotated by 67 workers and each instance is also annotated by 10 workers. There are 2 classes, 600 instances, 6000 labels, 10 nominal attributes, and 0 missing values in Income. We only evaluate the original model quality and the corresponding model quality using IWBVT by stratified 10-fold cross-validation one time because real-world datasets do not have a random simulation process. ", "page_idx": 8}, {"type": "text", "text": "Experimental results. Figure 2 shows the model quality $(\\%)$ comparisons of MV, IWMV, LAWMV, MNLDP, AVNC, MVNC and NWVNC before and after using IWBVT on Leaves and Income. With Figures 2a and 2b, we can find that IWBVT can also serve as a universal post-processing approach to significantly improving the model quality in real-world crowdsourced scenarios. Besides, we can also find the original model quality of several state-of-the-art algorithms is even lower than the original model quality of MV. These results once again demonstrate the limitation of label integration and noise correction in improving the model quality. ", "page_idx": 8}, {"type": "text", "text": "Ablation experiment. The above results only demonstrate the effectiveness of IWBVT as a whole, yet they do not delineate the contributions of its two key components: instance weighting and bias-variance trade-off. In IWBVT, instance weighting is used to mitigate the impact of intractable instances to make the bias and variance of trained models closer to the unknown true results. Therefore, to independently verify the effectiveness of instance weighting, we first observe the bias and variance of trained models before and after instance weighting. To estimate the bias and variance, referring to [24], NB is tested on Leaves and Income by ten runs of three-fold cross-validation. Figure 3a shows the bias and variance comparisons before and after using instance weighting on Leaves and Income. ", "page_idx": 8}, {"type": "image", "img_path": "aJDGfynRw7/tmp/5c5c89e97d4d48ab899d73d90caae58076873d3a314f6e6cba81f1c8ac17c05a.jpg", "img_caption": ["Figure 3: The ablation experiment comparisons of IWBVT and its components on Leaves and Income. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "In Figure 3a, object1 denotes the estimation results of NB trained directly with true labels. object2 denotes the estimation results of NB trained with integrated labels inferred by MV. The conditions for $o b j e c t_{3}$ and $o b j e c t_{2}$ are the same, besides considering instance weighting. As can be seen in Figure 3a, the bias and variance of models trained only with integrated labels are usually higher than unknown true results. When instance weighting is introduced, both the bias and variance of models tend to be closer to unknown true results. These results demonstrate that instance weighting successfully corrects the bias and variance of trained models by mitigating the impact of intractable instances. Therefore, IWBVT performs the instance weighting before the bias-variance trade-off, which is more effective in improving the generalization performance of trained models. ", "page_idx": 9}, {"type": "text", "text": "Additionally, we also analyze the effectiveness of another component, the bias-variance trade-off, in improving model quality. Similarly, we still fix the label integration algorithm to be MV, and then introduce the instance weighting and bias-variance trade-off individually to observe their influence in improving model quality. Figure 3b shows the model quality $(\\%)$ comparisons of MV using IWBVT or its components on Leaves and Income. In Figure 3b, objec $\\mathrm{\\nabla\\cdot}\\mathrm{1}$ denotes the model quality of MV, $o b j e c t_{2}$ denotes the model quality of MV using the bias-variance trade-off, $o b j e c t_{3}$ denotes the model quality of MV using the instance weighting, and $o b j e c t_{4}$ denotes the model quality of MV using the whole IWBVT. As can be seen in Figure 3b, both the instance weighting and the bias-variance trade-off effectively improve the model quality of MV. This demonstrates that the two components of the IWBVT are both effective. Moreover, the model quality of MV using the whole IWBVT is the highest on both Leaves and Income, which suggests that it is reasonable for IWBVT to utilize both components at the same time. In addition, in Figure 3b, we can also find that the instance weighting is more effective on Leaves, while the bias-variance trade-off is more effective on Income. This is because the average label quality of Leaves is low. Instance weighting helps to identify rare instances that are inferred correctly, and therefore has a greater impact on Leaves. However, the average label quality of Income is high, and more instances can be correctly inferred than in Leaves. Therefore, the bias and variance are estimated closer to the unknown true values, so the bias-variance trade-off is more effective on Income. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "To improve the model quality of models trained on crowdsourced datasets, we propose a universal post-processing approach called IWBVT. IWBVT first mitigates the impact of intractable instances by instance weighting to make the bias and variance of trained models closer to the unknown true results. Then, IWBVT reduces the generalization error of trained models by the bias-variance trade-off. Experimental results suggest that IWBVT can significantly improve the model quality of existing state-of-the-art label integration algorithms and noise correction algorithms. ", "page_idx": 9}, {"type": "text", "text": "Though the above experimental results sufficiently demonstrate the effectiveness of IWBVT, some anomalies are found in experiments. Table 2 shows that IWBVT degrades the model quality on a few datasets such as labor and lymph. The datasets such as labor and lymph contain some numerical attributes that are significantly higher in magnitude than other attributes. However, the linear regression chosen for IWBVT in experiments is not robust to regression tasks constructed for these datasets. Therefore, in the future, we will further improve the robustness of IWBVT to make trained models insensitive to anomalous attributes. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgment ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The work was partially supported by National Natural Science Foundation of China (62276241), Foundation of Key Laboratory of Artificial Intelligence, Ministry of Education, P.R. China (AI2022004), and Science and Technology Project of Hubei Province-Unveiling System (2021BEC007). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] P. Chen, Y. Yang, D. Yang, H. Sun, Z. Chen, and P. Lin, \u201cBlack-box data poisoning attacks on crowdsourcing,\u201d in Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, China. ijcai.org, 2023, pp. 2975\u20132983.   \n[2] Z. Chen, H. Sun, H. He, and P. Chen, \u201cLearning from noisy crowd labels with logics,\u201d in 39th IEEE International Conference on Data Engineering, ICDE 2023, Anaheim, CA, USA, April 3-7, 2023. IEEE, 2023, pp. 41\u201352.   \n[3] Z. Chen, L. Jiang, and C. Li, \u201cLabel augmented and weighted majority voting for crowdsourcing,\u201d Inf. Sci., vol. 606, pp. 397\u2013409, 2022.   \n[4] A. P. Dawid and A. M. Skene, \u201cMaximum likelihood estimation of observer error-rates using the em algorithm,\u201d Journal of the Royal Statistical Society: Series C (Applied Statistics), vol. 28, no. 1, pp. 20\u201328, 1979.   \n[5] N. Friedman, D. Geiger, and M. Goldszmidt, \u201cBayesian network classifiers,\u201d Mach. Learn., vol. 29, no. 2-3, pp. 131\u2013163, 1997.   \n[6] L. He, Y. Lu, W. Li, and X. Jia, \u201cGenerative calibration of inaccurate annotation for label distribution learning,\u201d in Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada, M. J. Wooldridge, J. G. Dy, and S. Natarajan, Eds. AAAI Press, 2024, pp. 12 394\u201312 401.   \n[7] Z. Huang, L. Shen, J. Yu, B. Han, and T. Liu, \u201cFlatmatch: Bridging labeled data and unlabeled data with cross-sharpness for semi-supervised learning,\u201d in Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.   \n[8] L. Jiang, H. Zhang, F. Tao, and C. Li, \u201cLearning from crowds with multiple noisy label distribution propagation,\u201d IEEE Trans. Neural Networks Learn. Syst., vol. 33, no. 11, pp. 6558\u20136568, 2022.   \n[9] R. Kohavi and D. H. Wolpert, \u201cBias plus variance decomposition for zero-one loss functions,\u201d in Machine Learning, Proceedings of the Thirteenth International Conference (ICML \u201996), Bari, Italy, July 3-6, 1996, L. Saitta, Ed. Morgan Kaufmann, 1996, pp. 275\u2013283.   \n[10] H. Li and B. Yu, \u201cError rate bounds and iterative weighted majority voting for crowdsourcing,\u201d CoRR, vol. abs/1411.4086, 2014.   \n[11] H. Li, L. Jiang, and S. Xue, \u201cNeighborhood weighted voting-based noise correction for crowdsourcing,\u201d ACM Trans. Knowl. Discov. Data, vol. 17, no. 7, pp. 96:1\u201396:18, 2023.   \n[12] J. Li, H. Sun, and J. Li, \u201cBeyond confusion matrix: learning from multiple annotators with awareness of instance features,\u201d Mach. Learn., vol. 112, no. 3, pp. 1053\u20131075, 2023.   \n[13] J. Li, Y. Kawase, Y. Baba, and H. Kashima, \u201cPerformance as a constraint: An improved wisdom of crowds using performance regularization,\u201d in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, C. Bessiere, Ed. ijcai.org, 2020, pp. 1534\u20131541.   \n[14] M. Li, R. Wu, H. Liu, J. Yu, X. Yang, B. Han, and T. Liu, \u201cInstant: Semi-supervised learning with instancedependent thresholds,\u201d in Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.   \n[15] X. Li, C. Li, and L. Jiang, \u201cA multi-view-based noise correction algorithm for crowdsourcing learning,\u201d Inf. Fusion, vol. 91, pp. 529\u2013541, 2023.   \n[16] Y. Li, B. I. P. Rubinstein, and T. Cohn, \u201cExploiting worker correlation for label aggregation in crowdsourcing,\u201d in Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, ser. Proceedings of Machine Learning Research, K. Chaudhuri and R. Salakhutdinov, Eds., vol. 97. PMLR, 2019, pp. 3886\u20133895.   \n[17] Y. Lu and X. Jia, \u201cPredicting label distribution from multi-label ranking,\u201d in Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., 2022.   \n[18] C. Nadeau and Y. Bengio, \u201cInference for the generalization error,\u201d Mach. Learn., vol. 52, no. 3, pp. 239\u2013281, 2003.   \n[19] B. Nicholson, V. S. Sheng, and J. Zhang, \u201cLabel noise correction and application in crowdsourcing,\u201d Expert Syst. Appl., vol. 66, pp. 149\u2013162, 2016.   \n[20] V. S. Sheng, F. J. Provost, and P. G. Ipeirotis, \u201cGet another label? improving data quality and data mining using multiple, noisy labelers,\u201d in Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Las Vegas, Nevada, USA, August 24-27, 2008, Y. Li, B. Liu, and S. Sarawagi, Eds. ACM, 2008, pp. 614\u2013622.   \n[21] V. S. Sheng, J. Zhang, B. Gu, and X. Wu, \u201cMajority voting and pairing with multiple noisy labeling,\u201d IEEE Trans. Knowl. Data Eng., vol. 31, no. 7, pp. 1355\u20131368, 2019.   \n[22] F. Tao, L. Jiang, and C. Li, \u201cDifferential evolution-based weighted soft majority voting for crowdsourcing,\u201d Eng. Appl. Artif. Intell., vol. 106, p. 104474, 2021.   \n[23] T. Tian, J. Zhu, and Y. Qiaoben, \u201cMax-margin majority voting for learning from crowds,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 10, pp. 2480\u20132494, 2019.   \n[24] G. I. Webb, \u201cMultiboosting: A technique for combining boosting and wagging,\u201d Mach. Learn., vol. 40, no. 2, pp. 159\u2013196, 2000.   \n[25] I. H. Witten, E. Frank, and M. A. Hall, Data mining: practical machine learning tools and techniques, 3rd Edition. Morgan Kaufmann, Elsevier, 2011.   \n[26] C. Xu and X. Geng, \u201cHierarchical classification based on label distribution learning,\u201d in The ThirtyThird AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019. AAAI Press, 2019, pp. 5533\u20135540.   \n[27] W. Xu, L. Jiang, and C. Li, \u201cImproving data and model quality in crowdsourcing using cross-entropy-based noise correction,\u201d Inf. Sci., vol. 546, pp. 803\u2013814, 2021.   \n[28] S. Yang, S. Wu, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and T. Liu, \u201cA parametrical model for instancedependent label noise,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 45, no. 12, pp. 14 055\u201314 068, 2023.   \n[29] W. Yang, C. Li, and L. Jiang, \u201cLearning from crowds with decision trees,\u201d Knowl. Inf. Syst., vol. 64, no. 8, pp. 2123\u20132140, 2022.   \n[30] L. Yin, J. Han, W. Zhang, and Y. Yu, \u201cAggregating crowd wisdoms with label-aware autoencoders,\u201d in Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017, C. Sierra, Ed. ijcai.org, 2017, pp. 1325\u20131331.   \n[31] C. Zhang, X. Jia, Z. Li, C. Chen, and H. Li, \u201cLearning cluster-wise anchors for multi-view clustering,\u201d in Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada, M. J. Wooldridge, J. G. Dy, and S. Natarajan, Eds. AAAI Press, 2024, pp. 16 696\u201316 704.   \n[32] J. Zhang, V. S. Sheng, T. Li, and X. Wu, \u201cImproving crowdsourced label quality using noise correction,\u201d IEEE Trans. Neural Networks Learn. Syst., vol. 29, no. 5, pp. 1675\u20131688, 2018.   \n[33] J. Zhang, V. S. Sheng, B. Nicholson, and X. Wu, \u201cCEKA: a tool for mining the wisdom of crowds,\u201d J. Mach. Learn. Res., vol. 16, pp. 2853\u20132858, 2015.   \n[34] J. Zhang, X. Wu, and V. S. Sheng, \u201cLearning from crowdsourced labeled data: a survey,\u201d Artif. Intell. Rev., vol. 46, no. 4, pp. 543\u2013576, 2016. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Appendix A Additions to the proof of Theorem 1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In the proof of Theorem 1, according to the maximum entropy principle, we get that $E n t(\\bar{P}_{i})$ tdaektaeisl eitds  demraivxaitmioun.m  Fvirasltu, eb yw thheen d aenfiyn iteiloenm oef $\\bar{P_{i}}$ siism eplqiufya li tt too $\\textstyle{\\frac{1-P\\left(\\hat{y}_{i}|L_{i}\\right)}{Q-1}}$ rew,i twh $\\bar{P_{i}}$ $\\bar{P}_{i}=\\{P_{q}\\}_{q=1}^{Q-1}$ $\\textstyle\\sum_{q=1}^{Q-1}P_{q}=$ $1-P(\\hat{y}_{i}|L_{i})$ . Then, we can find the maximum value of $E n t(\\bar{P}_{i})$ as follows: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{q}}{\\arg\\operatorname*{max}}\\,E n t(\\bar{P_{i}})=\\underset{P_{q}}{\\arg\\operatorname*{max}}-\\displaystyle\\sum_{q=1}^{Q-1}\\Big[P_{q}*\\log P_{q}\\Big]}\\\\ &{s.t.\\displaystyle\\sum_{q=1}^{Q-1}P_{q}=1-P(\\hat{y}_{i}|L_{i}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Then, according to the Lagrange multiplier, the Lagrange function $L(\\bar{P_{i}})$ can be constructed as follows: ", "page_idx": 12}, {"type": "equation", "text": "$$\nL(\\bar{\\cal P}_{i})=-\\sum_{q=1}^{Q-1}\\Big[{\\cal P}_{q}*\\log{\\cal P}_{q}\\Big]+\\lambda(\\sum_{q=1}^{Q-1}{\\cal P}_{q}-1+{\\cal P}(\\hat{y}_{i}|{\\cal L}_{i})).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Now, to obtain the maximum value of $L(\\bar{P_{i}})$ , we can take the partial derivative of $L(\\bar{P_{i}})$ concerning $P_{q}$ , and set this derivative equal to zero as follows: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\frac{\\partial{\\cal L}(\\bar{\\cal P}_{i})}{\\partial P_{q}}=-(\\log P_{q}+1)+\\lambda=0.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "According to Eq. (19), we can obtain $P_{q}=2^{\\lambda-1}$ . Bringing this result into the constraints, we can oFibntaailnl $\\begin{array}{r}{\\sum_{q=1}^{Q-1}P_{q}=(Q{-}1)2^{\\lambda-1}=1{-}\\bar{P}(\\hat{y}_{i}|L_{i})}\\end{array}$ $\\begin{array}{r}{P_{q}=\\frac{1-P(\\hat{y}_{i}|L_{i})}{Q-1}}\\end{array}$ .,  Twhee creafno rcea,l ict uilsa ctlee tahr et hmat $\\begin{array}{r}{P_{q}=2^{\\lambda-1}=\\frac{1-P(\\hat{y}_{i}|\\mathbf{L}_{i})}{Q-1}}\\end{array}$ $E n t(\\bar{P}_{i})$ as (1 \u2212P(y\u02c6i|Li)) log1\u2212PQ (y\u02c6i1|Li). ", "page_idx": 12}, {"type": "text", "text": "Appendix B Derivation of Eqs. (10) - (11) ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Due to the limited pages, Eqs. (10) - (12) in the main text only give the derived results. Here, we provide their detailed derivation. First, when $f$ is adjusted, $\\bar{P}(\\bar{c}_{q}|f,\\pmb{x}_{i})$ changes with $f$ , and this change is denoted as $\\Delta_{i q}$ . Then, we bring $\\Delta_{i q}$ into Eq. (4) and Eq. (5), respectively. The following derivation can be obtained: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\hat{w}\\dot{\\omega}_{s}^{2}=\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[P(c_{*}|x_{t})-(P(c_{*}|f,x_{t})+\\Delta_{i})\\Big]^{2}}\\\\ &{\\displaystyle\\qquad=\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[P(c_{*}|x_{t})^{2}+(P(c_{*}|f,x_{t})+\\Delta_{i})^{2}-2P(c_{*}|x_{t})\\big(P(c_{*}|f,x_{t})+\\Delta_{i})\\Big]}\\\\ &{\\displaystyle\\qquad=\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[P(c_{*}|x_{t})^{2}+P(c_{*}|f,x_{t})^{2}+\\Delta_{i}^{2}+2\\Delta_{i}\\mu_{i}P(c_{*}|f,x_{t})-2P(c_{*}|x_{t})P(c_{*}|f,x_{t})-\\lambda}\\\\ &{\\displaystyle\\qquad=\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[P(c_{*}|x_{t})^{2}+P(c_{*}|f,x_{t})^{2}-2P(c_{*}|x_{t})P(c_{*}|f,x_{t})\\Big]+\\displaystyle\\sum_{j=1}^{1}\\displaystyle\\sum_{k=1}^{9}\\Big[\\Delta_{i}^{2}+2\\Delta_{i k}P(c_{*}|f)}\\\\ &{\\displaystyle\\qquad=\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[P(c_{*}|x_{t})-P(c_{*}|f,x_{t})\\Big]^{2}+\\displaystyle\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Big[\\Delta_{i}^{2}+2\\Delta_{i j}P(c_{*}|f,x_{t})-2\\Delta_{i k}P(c_{*}|x_{t})\\Big]}\\\\ &{\\displaystyle\\qquad=b\\,\\mathrm{as}_{\\delta}^{2}+\\displaystyle\\sum_{n=1}^{9}\\Delta_{i k}P(c_{*}|f,x_{t})+\\frac{1}{2}\\displaystyle\\sum_{n=1}^{9}\\Delta_{i k}^{2}-\\displaystyle\\sum_{n=1}^{9}\\Delta_{i k}P(c_{*}|x_{t}),}\\\\ &{\\displaystyle\\qquad=b\\,\\mathrm{as}_{\\delta}^{2}+\\displaystyle\\sum\n$$", "text_format": "latex", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v\\tilde{\\alpha}r_{i}=\\displaystyle\\frac{1}{2}\\Big[1-\\displaystyle\\sum_{q=1}^{Q}\\big(P(c_{q}|f,x_{i})+\\Delta_{i q}\\big)^{2}\\Big]}\\\\ &{\\qquad=\\displaystyle\\frac{1}{2}\\Big[1-\\displaystyle\\sum_{q=1}^{Q}\\big(P(c_{q}|f,x_{i})^{2}+\\Delta_{i q}^{2}+2\\Delta_{i q}P(c_{q}|f,x_{i})\\big)\\Big]}\\\\ &{\\displaystyle=\\frac{1}{2}\\Big[1-\\displaystyle\\sum_{q=1}^{Q}P(c_{q}|f,x_{i})^{2}\\Big]-\\displaystyle\\frac{1}{2}\\sum_{q=1}^{Q}\\Big[\\Delta_{i q}^{2}+2\\Delta_{i q}P(c_{q}|f,x_{i})\\Big]}\\\\ &{\\displaystyle=v a r_{i}-\\sum_{q=1}^{Q}\\Delta_{i q}P(c_{q}|f,x_{i})-\\displaystyle\\frac{1}{2}\\sum_{q=1}^{Q}\\Delta_{i q}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We clearly claim in the abstract and introduction section that the approach proposed in our paper is mainly used to improve the model quality in crowdsourcing. The contributions of our paper are also highlighted in the introduction. ", "page_idx": 13}, {"type": "text", "text": "Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 13}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We mentioned the limitations of our IWBVT in the Conclusion and future work section. IWBVT is not robust on datasets containing anomalous attributes. ", "page_idx": 13}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: We give proofs to theorems that appear in the paper. Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 14}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Justification: This paper fully discloses all the information needed to reproduce the main experimental results of the paper. ", "page_idx": 14}, {"type": "text", "text": "Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: This paper provides open access to the data and code, and provides a document to guide readers in reproducing all experimental results in supplemental material. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 15}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: This paper specifies all the training and test details necessary to understand the results. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 15}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We explain in detail the experimental metrics in the paper and provide the results of the significance tests. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 16}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We describe in detail the experimental setting on the computer resources in this paper. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 16}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: The research conducted in this paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. ", "page_idx": 16}, {"type": "text", "text": "\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 17}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: The new approach proposed in this paper helps to train models more efficiently from crowdsourced datasets. There are no negative societal impacts. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 17}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 17}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We used the datasets and algorithmic implementations published by the CEKA platform, which is described in detail in the paper. The license and terms of use explicitly are properly respected in this paper. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 18}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper provides open access to the data and code, and provides a document to guide readers in reproducing all experimental results in supplemental material. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 18}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper did not select new crowdsourced datasets. The datasets used for experiments are publicly available and their information is described in detail in the paper. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 18}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not involve the research with human subjects. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 19}]