{"references": [{"fullname_first_author": "Rishi Bommasani", "paper_title": "On the opportunities and risks of foundation models", "publication_date": "2021-08-07", "reason": "This paper is foundational to the field of foundation models, providing a comprehensive overview of opportunities and risks, which directly informs the current paper's focus on responsible and effective LLM usage."}, {"fullname_first_author": "Alexander Ratner", "paper_title": "Snorkel: rapid training data creation with weak supervision", "publication_date": "2017-11-01", "reason": "This paper introduces the concept of weak supervision, which the current research builds upon for its label-free LLM routing approach."}, {"fullname_first_author": "Daniel Fu", "paper_title": "Fast and three-rious: Speeding up weak supervision with triplet methods", "publication_date": "2020-07-13", "reason": "This work provides the theoretical framework for the quality estimation method used in the current paper."}, {"fullname_first_author": "Simran Arora", "paper_title": "Simple linear attention language models balance the recall-throughput tradeoff", "publication_date": "2024-01-01", "reason": "This paper explores the trade-offs in different language models, which is directly relevant to the current paper's efforts to optimize LLM selection for specific tasks."}, {"fullname_first_author": "Mayee F. Chen", "paper_title": "Shoring up the foundations: fusing model embeddings and weak supervision", "publication_date": "2022-08-01", "reason": "This paper combines model embeddings with weak supervision, a methodology that is central to the current paper's unsupervised LLM routing technique."}]}