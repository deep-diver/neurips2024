[{"figure_path": "4I2aEav51N/figures/figures_8_1.jpg", "caption": "Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "The figure compares three differentially private variance estimation methods: Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and the proposed Asymmetric Sensitivity Mechanism.  For several datasets (diamonds, abalone, bike, adult - age and hours worked), the average absolute error of each method is plotted against different privacy parameters (epsilon). Error bars representing 0.9 confidence intervals are included to show the variability of the estimates.  The plot demonstrates that the Asymmetric Sensitivity Mechanism consistently outperforms the other two methods across various datasets and privacy levels.", "section": "5 Private Variance Estimation"}, {"figure_path": "4I2aEav51N/figures/figures_9_1.jpg", "caption": "Figure 2: Plots comparing each method for estimating cross entropy loss. For each privacy parameter we both sample 1,000 datapoints from the test set and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "The figure compares three different differentially private methods for estimating cross-entropy loss: Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and Asymmetric Sensitivity Mechanism.  The plots show the average absolute error for each method across four different datasets (Adult, Diabetes, MNIST, CIFAR) at various privacy parameters (epsilon). Error bars representing 0.9 confidence intervals are included. The results demonstrate the superior accuracy of the Asymmetric Sensitivity Mechanism, especially at higher privacy parameters (smaller epsilon values).", "section": "6 Private Machine Learning Model Evaluation"}, {"figure_path": "4I2aEav51N/figures/figures_9_2.jpg", "caption": "Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "The figure compares three differentially private variance estimation methods (Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and Asymmetric Sensitivity Mechanism) across various privacy parameters (epsilon). For each privacy setting, 1000 data points were sampled, and each mechanism was run 100 times. The plots show the average absolute error, along with 90% confidence intervals, for each method across four different datasets: diamonds, abalone, bike, and adult (age and hours). The results demonstrate that the Asymmetric Sensitivity Mechanism consistently outperforms the other two methods in terms of accuracy, especially at higher privacy levels.", "section": "5 Private Variance Estimation"}, {"figure_path": "4I2aEav51N/figures/figures_9_3.jpg", "caption": "Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "This figure compares three methods for estimating variance with differential privacy: Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and Asymmetric Sensitivity Mechanism.  The plots show the average absolute estimation error for each method across a range of privacy parameters (\u03b5).  For each privacy parameter, 1000 data points were sampled from a dataset, and each method was run 100 times. Error bars represent 0.9 confidence intervals. The Asymmetric Sensitivity Mechanism consistently demonstrates lower error compared to the other methods.", "section": "5 Private Variance Estimation"}, {"figure_path": "4I2aEav51N/figures/figures_15_1.jpg", "caption": "Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "The figure compares three different methods (Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and Asymmetric Sensitivity Mechanism) for estimating variance under differential privacy.  For various privacy parameters (epsilon), the average absolute error of each method is shown, based on 100 trials with 1000 datapoints sampled from the dataset for each trial. The plots visualize the performance of the methods for estimating variance, showing how the error varies with different privacy levels and comparing the effectiveness of each method.", "section": "5 Private Variance Estimation"}, {"figure_path": "4I2aEav51N/figures/figures_16_1.jpg", "caption": "Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals.", "description": "The figure compares three methods for estimating variance under differential privacy: Smooth Sensitivity Mechanism, Inverse Sensitivity Mechanism, and Asymmetric Sensitivity Mechanism.  For each privacy parameter (epsilon), 1000 data points were sampled from five different datasets (diamonds, abalone, bike, adult (hours), adult (age)). Each mechanism was run 100 times for each sample, and the average absolute error was plotted with 90% confidence intervals.  The plot shows that the Asymmetric Sensitivity Mechanism consistently outperforms the other two methods across all datasets and privacy parameters.", "section": "5 Private Variance Estimation"}, {"figure_path": "4I2aEav51N/figures/figures_17_1.jpg", "caption": "Figure 5: We provide here an informal visualization of the inverse sensitivity and reflective inverse sensitivity. For most functions of interest we can just plot these as step functions using the upper and lower output bounds from Definition 3.4. In the plot, we denote Lf(x) and Uf(x) with Lk and Uk, respectively. We will go into further detail in the next section but note that the sensitivities are perfectly symmetric in this example.", "description": "This figure provides a visualization of the inverse sensitivity and reflective inverse sensitivity, which are key concepts in the paper's proposed asymmetric sensitivity mechanism.  It uses step functions based on upper and lower output bounds to illustrate these sensitivities for a scenario with perfectly symmetric sensitivities. The figure serves as a visual aid to help readers grasp the concepts before a more detailed mathematical explanation in a later section.", "section": "C.1 Visualization of both methods"}, {"figure_path": "4I2aEav51N/figures/figures_17_2.jpg", "caption": "Figure 6: We provide here an informal visualization of the approximate PDFs for inverse sensitivity mechanism (ISM) and our asymmetric sensitivity mechanism (ASM) when the sensitivities are perfectly symmetric. We slightly alter our mechanism M.3 to uniformly draw an output in [tk\u22121, tk] for easier visualization, which implies our PDF will be a step function between the potential outputs.", "description": "This figure compares the probability density functions (PDFs) of the Inverse Sensitivity Mechanism (ISM) and the Asymmetric Sensitivity Mechanism (ASM) under the condition of perfectly symmetric sensitivities.  It shows how the ASM, through its iterative nature, introduces a slight bias resulting in a more concentrated distribution around the true output (f(x)).  The difference is subtle in this symmetric case, but highlights a key difference between the two methods.", "section": "C Intuition and Asymmetric Advantage"}, {"figure_path": "4I2aEav51N/figures/figures_18_1.jpg", "caption": "Figure 7: We provide here an informal visualization of the approximate PDFs but with asymmetric sensitivities. We remove the labels for L}(x), L}(x), and L3(x) as they become too condensed around f(x) but we keep their tick marks on the x-axis. We again slightly alter our mechanism M.3 to uniformly draw an output in [tk\u22121, tk] for easier visualization, which implies our PDF will be a step function between the potential outputs.", "description": "This figure compares the probability density functions (PDFs) of the inverse sensitivity mechanism (ISM) and the asymmetric sensitivity mechanism (ASM) when the sensitivities are asymmetric.  The ASM's PDF shows a higher concentration of probability mass around the true output (f(x)) compared to the ISM, indicating that it better handles asymmetric sensitivities.", "section": "C Intuition and Asymmetric Advantage"}, {"figure_path": "4I2aEav51N/figures/figures_19_1.jpg", "caption": "Figure 8: We consider a range of randomly sampled output bounds and privacy parameters and compute the absolute error of our asymmetric sensitivity mechanism (ASM) and the inverse sensitivity mechanism (ISM) over a small number of random draws. We plot the (error ISM) / (error ASM) corresponding to the asymmetry of the sensitivities for the given output bounds and privacy parameter.", "description": "This figure shows the relationship between the relative error of the inverse sensitivity mechanism and the asymmetric sensitivity mechanism and the asymmetry of sensitivities.  The x-axis represents the asymmetry of sensitivities (a metric defined in the paper), and the y-axis shows the ratio of the absolute errors of the two methods. The plot indicates that as the asymmetry of sensitivities increases, the relative error of the asymmetric sensitivity mechanism decreases compared to the inverse sensitivity mechanism, suggesting that the proposed method is more advantageous when sensitivities are asymmetric.", "section": "C.3 Formalizing asymmetry of sensitivities"}]