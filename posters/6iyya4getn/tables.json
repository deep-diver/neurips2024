[{"figure_path": "6IyYa4gETN/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model with several state-of-the-art models on three different datasets: DeepFashion (256x176), DeepFashion (512x352), and Market-1501 (128x64).  The comparison is based on three metrics: Structural SIMilarity Index Measure (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Fr\u00e9chet Inception Distance (FID). Higher SSIM values indicate better structural similarity, lower LPIPS values indicate better perceptual similarity, and lower FID values indicate better overall image quality. The results show that IMAGPose outperforms other models on all three metrics across all datasets.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model against several other state-of-the-art models on the DeepFashion and Market-1501 datasets.  The comparison uses three metrics: Structural Similarity Index Measure (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Fr\u00e9chet Inception Distance (FID). Higher SSIM values indicate better image quality, while lower LPIPS and FID values suggest better perceptual similarity and better overall image quality, respectively.  The results show that IMAGPose outperforms other models across all three metrics on both datasets.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_8_2.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model with several state-of-the-art models on two benchmark datasets: DeepFashion and Market-1501.  The comparison uses three metrics: SSIM (Structural Similarity Index), LPIPS (Learned Perceptual Image Patch Similarity), and FID (Fr\u00e9chet Inception Distance). Higher SSIM values indicate better structural similarity, while lower LPIPS and FID values suggest better perceptual similarity and better overall image quality, respectively. The table shows that IMAGPose outperforms other methods across both datasets and metrics, demonstrating its improved performance in pose-guided person image generation.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_8_3.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model with several state-of-the-art models on the DeepFashion and Market-1501 datasets.  The comparison is based on three metrics: Structural Similarity Index Measure (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Fr\u00e9chet Inception Distance (FID). Higher SSIM values indicate better image quality, lower LPIPS values indicate better perceptual similarity, and lower FID values indicate better model performance.  The table allows for a direct comparison of IMAGPose against existing methods and highlights its performance advantages.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_13_1.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model against several state-of-the-art models on three different datasets: DeepFashion (256x176 and 512x352 resolutions), and Market-1501 (128x64 resolution).  The comparison uses three standard metrics for evaluating image generation quality: Structural Similarity Index Measure (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Fr\u00e9chet Inception Distance (FID).  Higher SSIM values indicate better structural similarity, lower LPIPS values indicate better perceptual similarity, and lower FID values indicate better overall image quality.  The table allows for a direct comparison of IMAGPose's performance relative to other existing methods on these datasets.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_13_2.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model against several state-of-the-art models on different datasets.  The comparison uses three metrics: SSIM (Structural Similarity Index Measure), LPIPS (Learned Perceptual Image Patch Similarity), and FID (Fr\u00e9chet Inception Distance). Higher SSIM values indicate better structural similarity, while lower LPIPS and FID values indicate better perceptual similarity and better overall image quality.  The results show IMAGPose's superior performance compared to existing methods.", "section": "4 Experiments"}, {"figure_path": "6IyYa4gETN/tables/tables_15_1.jpg", "caption": "Table 1: Quantitative comparison of the proposed IMAGPose with several state-of-the-art models.", "description": "This table presents a quantitative comparison of the proposed IMAGPose model against several state-of-the-art models on the DeepFashion and Market-1501 datasets.  The comparison uses three metrics: SSIM (structural similarity index), LPIPS (learned perceptual image patch similarity), and FID (Fr\u00e9chet inception distance). Higher SSIM values indicate better image quality, while lower LPIPS and FID values represent better perceptual similarity and better overall image generation, respectively.  The results show that IMAGPose outperforms other models across various metrics and datasets.", "section": "4 Experiments"}]