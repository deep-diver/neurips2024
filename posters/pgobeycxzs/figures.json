[{"figure_path": "pGOBEYcXzs/figures/figures_1_1.jpg", "caption": "Figure 1: A brief overview of various LLM binarization methods. PB-LLM involves both a binary weight matrix and a high-precision, sparse weight matrix, and BiLLM stores four types of binary weight matrices. OneBit simplifies the layer structure by introducing scaling factors for input and output dimensions respectively. BinaryMoS introduces multiple scaling experts to enhance the capacity of binarized models.", "description": "This figure provides a visual comparison of four different LLM binarization methods: PB-LLM, BiLLM, OneBit, and BinaryMoS.  Each method is illustrated with a diagram showing its approach to handling binary and high-precision weights. PB-LLM uses a combination of both, BiLLM uses multiple types of binary matrices, OneBit uses scaling factors on both input and output, and BinaryMoS uses multiple scaling experts. The diagrams highlight the differences in architectural complexity and the strategies used to improve the accuracy of binarized models.", "section": "Background"}, {"figure_path": "pGOBEYcXzs/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the proposed BinaryMoS scheme. The proposed BinaryMoS introduces mixture of scale approach to generate token-adaptive scaling factors. LLMs without the extensive memory overhead associated with traditional MoE configurations. In the following section, we will delve deeper into how BinaryMoS operates and its benefits over conventional techniques.", "description": "This figure illustrates the architecture of BinaryMoS, a novel binarization technique for LLMs.  It shows how multiple scaling experts are used to generate token-adaptive scaling factors, which are then used to improve the representational power of binarized LLMs. The figure highlights the key components of BinaryMoS, including the router, which dynamically combines the scaling experts, and the matrix multiplication and linear weighted sum operations, which are used to generate the final output. The figure also shows how BinaryMoS maintains compression efficiency while achieving better accuracy than traditional static binarization methods.", "section": "3 Proposed BinaryMoS"}, {"figure_path": "pGOBEYcXzs/figures/figures_6_1.jpg", "caption": "Figure 3: (a) Gating scores of 4 scaling experts in 18th layer of LLaMA-1-7B model for each token in the input sequence. (b) Distribution of values of token-adaptive scaling factors. The boxplot visually presents the distribution of token-adaptive scaling factors among processed tokens. The box spans the interquartile range, indicating the middle 50% of the scaling factors. Extending from the box are whiskers that reach the furthest data points within 1.5 times the interquartile range, providing insight into the overall range of the data.", "description": "This figure shows the gating scores for four scaling experts and resulting token-adaptive scaling factors for the output projection of the 18th layer in the LLaMA-1-7B model.  The top panel (a) shows a heatmap visualizing how the gating scores vary across tokens in a sequence, indicating how the model dynamically weights the influence of different scaling experts for each token. The bottom panel (b) presents boxplots illustrating the distribution of token-adaptive scaling factors for both input and output dimensions, comparing them against the use of a single scaling factor.  The boxplots highlight the increased variability and range of values achieved with the token-adaptive approach, demonstrating its effectiveness in capturing contextual information.", "section": "4.3 Analysis on the Token-Adaptive Scaling Factors"}]