{"references": [{"fullname_first_author": "P-A Absil", "paper_title": "Optimization algorithms on matrix manifolds", "publication_date": "2008-01-01", "reason": "This paper provides the foundational mathematical background for optimization on matrix manifolds, which is crucial for understanding and developing the amortized eigendecomposition approach."}, {"fullname_first_author": "Roger W Brockett", "paper_title": "Dynamical systems that sort lists, diagonalize matrices, and solve linear programming problems", "publication_date": "1991-01-01", "reason": "This seminal work introduces Brockett's cost function, a key element in the proposed differentiable optimization framework for efficient eigendecomposition."}, {"fullname_first_author": "Emmanuel J Cand\u00e8s", "paper_title": "The power of convex relaxation: Near-optimal matrix completion", "publication_date": "2010-01-01", "reason": "This paper's contribution to the theory of matrix completion is relevant to the nuclear norm regularization task, where low-rank matrix recovery is a key objective."}, {"fullname_first_author": "Tsung-Han Chan", "paper_title": "Pcanet: A simple deep learning baseline for image classification?", "publication_date": "2015-01-01", "reason": "This paper demonstrates the effectiveness of PCA in deep learning, providing context for the latent-space PCA application of the amortized eigendecomposition approach."}, {"fullname_first_author": "Guillaume Desjardins", "paper_title": "Natural neural networks", "publication_date": "2015-01-01", "reason": "This work explores natural neural networks, which helps in understanding the general framework of integrating eigendecomposition into neural network training, as discussed in the amortized eigendecomposition approach."}]}