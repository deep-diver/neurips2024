[{"figure_path": "bNVvcgfEwD/figures/figures_7_1.jpg", "caption": "Figure 1: Average test accuracy and standard deviation (shallow blue region) under different decay rate parameters c.", "description": "This figure displays the average test accuracy and its standard deviation for three different ResNet models (ResNet-20 on CIFAR-10, ResNet-20 on CIFAR-100, and ResNet-110 on CIFAR-100) trained using Adafactor without update clipping.  The x-axis represents the decay rate parameter 'c' which varies from 0.5 to 1.0. The y-axis shows the test accuracy. The shaded blue region represents the standard deviation around the average accuracy.  The purpose is to demonstrate the effect of different decay rate parameters (c) on the final performance of Adafactor, indicating how the convergence rate and performance are affected by varying c.", "section": "8 Experiments"}, {"figure_path": "bNVvcgfEwD/figures/figures_7_2.jpg", "caption": "Figure 2: Training loss vs. steps using Adafactor without update clipping under different \u20ac1. The step-size \u03b7k, decay rate \u03b22,k, and learning rate warm-up are set by default.", "description": "This figure shows the training loss curves for Adafactor without update clipping, using different values of the hyperparameter \u03f51.  The x-axis represents the training step, and the y-axis shows the training loss.  The various curves correspond to different values of \u03f51, ranging from 10\u207b\u00b3\u2070 to 10\u207b\u00b9. The default settings for step size, decay rate, and learning rate warm-up were used.", "section": "8 Experiments"}, {"figure_path": "bNVvcgfEwD/figures/figures_8_1.jpg", "caption": "Figure 3: Training loss vs. steps on different models and datasets. We use step-size without warm-up technique and test under different \u03b1.", "description": "This figure displays the training loss curves for ResNet-20 on CIFAR-10, ResNet-20 on CIFAR-100, and ResNet-110 on CIFAR-100 datasets.  Each curve represents a different value of the hyperparameter \u03b1 (4.0, 6.0, 7.0, 8.0, 9.0) in the Adafactor algorithm with a time-increasing update clipping threshold.  The 'Baseline' curve shows the performance with the original constant clipping threshold setting.  The x-axis represents the training step, and the y-axis represents the training loss. The figure aims to demonstrate the effect of varying the hyperparameter \u03b1 on the convergence speed and stability of Adafactor.", "section": "8 Experiments"}, {"figure_path": "bNVvcgfEwD/figures/figures_8_2.jpg", "caption": "Figure 3: Training loss vs. steps on different models and datasets. We use step-size without warm-up technique and test under different \u03b1.", "description": "This figure shows the training loss curves for ResNet-20 on CIFAR-10, ResNet-20 on CIFAR-100, and ResNet-110 on CIFAR-100 datasets.  Each curve represents a different value of the hyperparameter \u03b1 (4.0, 6.0, 7.0, 8.0, 9.0), with the 'Baseline' representing the standard Adafactor setting (\u03b1=1).  The experiment uses a step-size without a warm-up technique. The figure aims to illustrate the impact of the time-varying clipping threshold parameter \u03b1 on the training stability and convergence speed of Adafactor.", "section": "8 Experiments"}]