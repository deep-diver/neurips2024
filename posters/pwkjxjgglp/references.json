{"references": [{"fullname_first_author": "Chen, Y.C.", "paper_title": "Uniter: Learning universal image-text representations", "publication_date": "2020-00-00", "reason": "This paper is foundational for the field of multimodal learning and is directly relevant to the current work's use of MLLMs for document understanding."}, {"fullname_first_author": "Li, J.", "paper_title": "BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-00-00", "reason": "BLIP is a highly influential model that directly inspired the current work's approach to unifying visual and language modalities."}, {"fullname_first_author": "Li, J.", "paper_title": "BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models", "publication_date": "2023-00-00", "reason": "BLIP-2 builds upon BLIP and is the most directly relevant model used in the experiments of the current work."}, {"fullname_first_author": "Ye, J.", "paper_title": "UReader: universal ocr-free visually-situated language understanding with multimodal large language model", "publication_date": "2023-00-00", "reason": "UReader is a key comparative model which the current work directly improves upon and builds upon for OCR-free document understanding."}, {"fullname_first_author": "Xu, Y.", "paper_title": "LayoutLM: Pre-training of text and layout for document image understanding", "publication_date": "2020-00-00", "reason": "LayoutLM is an important foundational model for OCR-based document understanding which demonstrates the need for the proposed OCR-free methods."}]}