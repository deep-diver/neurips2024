[{"type": "text", "text": "Optimal Hypothesis Selection in (Almost) Linear Time ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Maryam Aliakbarpour   \nDepartment of Computer Science   \nRice University   \nHouston, TX 77005   \nmaryama@rice.edu ", "page_idx": 0}, {"type": "text", "text": "Mark Bun Department of Computer Science Boston University Boston, MA 02215 mbun@bu.edu ", "page_idx": 0}, {"type": "text", "text": "Adam Smith Department of Computer Science Boston University Boston, MA 02215 ads22@bu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hypothesis selection, also known as density estimation, is a fundamental problem in statistics and learning theory. Given a sample set from an unknown distribution $P$ and a finite class of candidate distributions (hypotheses) $\\mathcal{H}:=H_{1},H_{2},...,H_{n}$ , the goal is to design an algorithm that selects a distribution $\\hat{H}$ from $\\mathcal{H}$ that best describes $P$ . The accuracy of the algorithm is measured by the distance between $\\hat{H}$ and $P$ , compared to the distance between the closest distribution in $\\mathcal{H}$ and $P$ (denoted by OPT). Specifically, we aim for $\\|\\hat{H}-P\\|_{\\mathrm{TV}}$ to be at most $\\alpha\\cdot{\\mathsf{O P T}}+\\epsilon$ for some small $\\epsilon$ and $\\alpha$ . ", "page_idx": 0}, {"type": "text", "text": "While the value of $\\epsilon$ can be reduced with an increasing number of samples, $\\alpha$ is an inherent characteristic of the algorithm. Achieving $\\alpha<3$ is impossible, even with only two candidate hypotheses, unless the number of samples is proportional to the domain size of $P$ [Bousquet, Kane, Moran \u201919]. Finding a computationally efficient algorithm that achieves the optimal $\\alpha$ has been a primary focus of research since the early work of [Devroye, Lugosi $\\mathrm{\\nabla01}^{\\circ}$ ]. Before our work, the algorithms achieving $\\alpha<5$ required time $\\dot{\\Omega}(n^{2})$ . We present the first algorithm that operates in almost linear time $(\\tilde{O}(n/\\epsilon^{3}))$ and achieves $\\alpha=3$ . This result improves upon a long line of hypothesis selection research. Previously known algorithms had either worse time complexity, a larger $\\alpha$ factor, or additional assumptions about the problem setting. Additionally, we provide another (almost) linear-time algorithm with better dependency on the additive accuracy parameter $\\epsilon$ , albeit with a slightly worse accuracy parameter of $\\alpha=4$ . ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hypothesis selection, also known as density estimation, is a fundamental problem in statistics and learning theory. This problem involves identifying a density function that accurately represents the distribution of a given dataset. Suppose we are given a dataset of samples drawn from an unknown distribution $P$ and a finite class of known distributions, representing different hypotheses: $\\mathcal{H}:=\\{H_{1},H_{2},...,H_{n}\\}$ . The goal is to select a distribution in $\\mathcal{H}$ that is close to $P$ in total variation (TV) distance. ", "page_idx": 0}, {"type": "text", "text": "Typically, learning a distribution over a domain $\\mathcal{X}$ with an $\\epsilon$ error in TV distance requires $\\Omega(|\\boldsymbol{\\mathcal{X}}|/\\epsilon^{2})$ samples, which presents a substantial lower bound in sample complexity for distributions over large domains. Surprisingly, the findings of Yatracos, Devroye, and Lugosi revealed that for hypothesis selection, this sample complexity can be independent of the domain size and only logarithmic in the number of hypotheses [Yat85, DL96, DL97]. With just $s:=\\Theta(\\log n/\\epsilon^{2})$ samples from $P$ , it is possible to learn $P$ within error $\\alpha\\cdot{\\mathsf{O P T}}+\\epsilon$ , where OPT denotes the distance of the nearest distribution in $\\mathcal{H}$ to $P$ . Specifically, Devroye and Lugosi introduced two algorithms for this problem: the Scheff\u00e9 tournament, which operates in $O(n^{2}\\cdot\\bar{s})\\;\\mathrm{time}^{1}$ and achieves $\\alpha=9$ ; and the minimum distance estimate, which runs in $O(n^{3}\\cdot s)$ time and achieves $\\alpha=3$ [DL01, Chapter 6]. In these results, although $\\epsilon$ can be decreased as the number of samples increases, $\\alpha$ remains an inherent parameter of the algorithm. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Significant effort has been directed towards finding computationally efficient algorithms for this problem while maintaining sample efficiency. The trade-off between the accuracy parameter $\\alpha$ and computational efficiency has been a focal point. Mahalanabis and Stefankovic in [MS08] enhanced the minimum distance estimate, improving the time complexity to $O(n^{2}\\cdot s)$ . They also introduced a nearly linear-time algorithm that achieves $\\alpha=3$ , but requires exponential time in $n$ for preprocessing the class $\\mathcal{H}$ . Other nearly linear-time algorithms were developed achieving $\\alpha=9$ in [AJOS14, $\\mathrm{AF}\\bar{\\mathrm{J}}^{+}18.$ , $\\mathrm{AAC}^{+}23]^{2}$ and $\\alpha=5$ in [ABS23]. Furthermore, linear-time algorithms have been presented under the assumption that the algorithm receives the value of OPT (or its upper bound) as input [DK14, ABS23]. However, achieving $\\alpha<3$ is not possible unless the number of samples becomes $\\mathrm{poly}(|\\mathcal{X}|)$ , as indicated in [BKM19]. ", "page_idx": 1}, {"type": "text", "text": "Despite the long-standing history of this problem, the following question remained open: ", "page_idx": 1}, {"type": "text", "text": "Is there an algorithm for hypothesis selection with the optimal number of samples $s=O(\\log(n)/\\epsilon^{2})$ and optimal accuracy parameter $\\alpha=3$ that runs in $O(n\\cdot s)$ time? ", "page_idx": 1}, {"type": "text", "text": "We present the first almost linear-time algorithm that uses the optimal number of samples and achieves the optimal accuracy parameter $\\alpha=3$ . Our algorithm runs in $\\tilde{O}(n\\cdot s\\mid\\epsilon)$ time (see Theorem 2). Additionally, we introduce another algorithm with improved dependency on $\\epsilon$ , running in $\\tilde{O}(n\\cdot s)$ time while obtaining a slightly higher accuracy parameter, $\\alpha\\,=\\,4$ (see Theorem 3). Our results represent a significant step forward, as they are the first in decades to achieve time complexity linear in $n$ for any $\\alpha<5$ . See Table 1. ", "page_idx": 1}, {"type": "text", "text": "Applications of Hypothesis Selection The primary application of hypothesis selection is to identify the best distribution from a set of known models that represent potential underlying data distributions we can effectively manage. For example, this set might include Poisson, gamma, and binomial distributions with various parameters used to model the number of arrivals per time unit. This makes hypothesis selection applicable to tasks like interpretable distribution selection and strategy optimization, where the objective is to choose the most suitable model from available options. ", "page_idx": 1}, {"type": "text", "text": "Another key strength of hypothesis selection is its agnostic nature, allowing it to adapt even when the true distribution lies outside the considered class. This robustness makes it effective in noisy data settings, with applications in denoising and anomaly detection. From a theoretical standpoint, hypothesis selection is fundamental in learning structured distributions, particularly when combined with the cover method, as seen in learning mixtures of Gaussians [DK14, SOAJ14]. For additional references, see Section 1.3. ", "page_idx": 1}, {"type": "text", "text": "Importance of improving $\\pmb{\\alpha}$ by a constant factor In most learning algorithms, the error guarantee decreases polynomially as the number of samples increases, so constant factors may not be as crucial. However, this is not the case in hypothesis selection. The output hypothesis is guaranteed to be $(\\alpha\\cdot{\\mathsf{O P T}}+\\epsilon)$ -close to $P$ in total variation distance. While increasing the number of samples can reduce $\\epsilon$ to negligible levels, it does not improve the term $\\alpha\\cdot\\mathsf{O P T}$ . Hence, $\\alpha$ is an inherent property of the algorithm and directly impacts the best achievable error guarantee. Therefore, even a constant improvement in $\\alpha$ is significant. ", "page_idx": 1}, {"type": "text", "text": "One might argue that, alternatively, OPT could be reduced by carefully curating the class $\\mathcal{H}$ . However, beyond the practical challenges of finding a better $\\mathcal{H}$ , it is unclear whether this can be achieved without significantly increasing the size of the hypothesis class $\\mathcal{H}$ . For example, in the cover method, when aiming to learn a distribution within a class $\\mathcal{C}$ , we set $\\mathcal{H}$ to be a $\\gamma.$ -net that serves as a cover for $\\mathcal{C}$ , ensuring that $\\mathsf{O P T}<\\gamma$ . While using a finer $\\gamma$ -net can reduce OPT, it may also drastically increase the size of $\\mathcal{H}$ , thereby increasing the algorithm\u2019s running time, since the size of the net can grow super-polynomially with respect to $\\gamma$ . For instance, in the case of mixtures of $k$ Gaussians, the size of the net depends on $\\gamma$ as roughly ${\\mathcal{O}}(\\gamma^{-3\\cdot k})$ (see [SOAJ14]). Thus, reducing $\\gamma$ by a factor of three could exponentially increase the size of $\\mathcal{H}$ in terms of $k$ , thereby increasing both the running time and sample complexity, ultimately resulting in an inefficient algorithm. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "table", "img_path": "Skv26JteFz/tmp/e968223f2b2d4131d5c953e61bd5fe2911f4fbf488d50b93627b2822fb709f2d.jpg", "table_caption": ["Table 1: Summary of Past Results in Hypothesis Selection. All algorithms use $s\\,=\\,\\Theta(\\log n/\\epsilon^{2})$ samples. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "1.1 Problem Setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Suppose we have an unknown distribution $P$ over a domain $\\mathcal{X}$ and a set of $n$ known distributions $\\mathcal{H}:=\\{H_{1},H_{2},...,H_{n}\\}$ . Let OPT denote the distance between $P$ and the closest distribution to it in $\\mathcal{H}^{\\,3}$ $\\begin{array}{r}{\\dot{\\colon}\\mathsf{O P T}(\\mathcal{H},P):=\\operatorname*{min}_{H\\in\\mathcal{H}}\\|H-P\\|_{\\mathrm{TV}}}\\end{array}$ . We use the standard access model for this problem as introduced in [DL01]. The algorithm accesses the distributions through the following types of queries: ", "page_idx": 2}, {"type": "text", "text": "1. The algorithm can request a sample from the unknown distribution $P$ . ", "page_idx": 2}, {"type": "text", "text": "2. The algorithm can compare the PDF of two known distributions: For every domain element $x\\in\\mathscr{X}$ and every pair of indices $i$ and $j$ , it can ask if $H_{j}(x)<H_{i}(x)$ . This is equivalent to asking if $x$ is in the Scheff\u00e9 set of $H_{i}$ and $H_{j}$ (defined in Equation (2)).   \n3. The algorithm can query the probability mass of the Scheff\u00e9 sets according to all the known distributions. ", "page_idx": 2}, {"type": "text", "text": "Remark 1. The last requirement of our model can be relaxed. Only estimates of the probability masses of the Scheff\u00e9 sets are needed for our algorithms. Thus, one can alternatively assume sample access to $H_{i}\\,^{,}s_{;}$ , and estimate these values via samples. ", "page_idx": 2}, {"type": "text", "text": "Definition 1.1 (Proper learner for hypothesis selection). Suppose algorithm $\\boldsymbol{\\mathcal{A}}$ is given parameters $\\epsilon,\\delta\\,\\in\\,(0,1)$ , $\\alpha\\,\\in\\,\\mathbb{R}_{>0}$ and has access to an unknown distribution $P$ and a class of $n$ known distributions $\\mathcal{H}$ (as described above). We say $\\boldsymbol{\\mathcal{A}}$ is an $(\\alpha,\\epsilon,\\delta)$ -proper learner for the hypothesis selection problem if for every $P$ and $\\mathcal{H},\\,\\mathcal{A}$ outputs $\\hat{H}\\in\\mathcal H$ for which, with probability at least $1-\\delta$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\|\\hat{H}-P\\|_{T V}\\leq\\alpha\\cdot\\mathsf{O P T}(\\mathcal{H},P)+\\epsilon\\,.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "We refer to \u03b1 as the accuracy parameter, \u03f5 as the error (or proximity) parameter, and \u03b4 as the confidence parameter of the algorithm. ", "page_idx": 3}, {"type": "text", "text": "1.2 Main theorems ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Below, we provide informal versions of our theorems. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2. For every $\\epsilon,\\delta\\in(0,1)$ , Algorithm $^{l}$ is an $(\\alpha=3,\\epsilon,\\delta)$ -proper learner for hypothesis selection that uses $s=O(\\log(n/\\delta)/\\epsilon^{2})$ samples and time $\\tilde{O}(n\\cdot s\\,/\\,(\\delta^{3}\\epsilon))=\\tilde{O}(n/(\\delta^{3}\\epsilon^{3}))$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 3. For every $\\epsilon,\\delta\\in(0,1)$ , Algorithm $^{4}$ is an $(\\alpha=4,\\epsilon,\\delta)$ -proper learner for hypothesis selection that uses $s=O(\\log(n/\\delta)/\\epsilon^{2})$ samples and time $\\tilde{O}(n\\!\\cdot\\!s\\!\\cdot\\!\\log(1/\\delta))=\\tilde{O}(n\\!\\cdot\\!\\log^{2}(1/\\delta)/\\epsilon^{2}))$ ). ", "page_idx": 3}, {"type": "text", "text": "For formal statements, see Theorem 5 (Appendix A) and Corollary B.1 (Appendix B). ", "page_idx": 3}, {"type": "text", "text": "Our results are the first to achieve time complexity linear in $n$ for any $\\alpha<5$ . To achieve this, we introduce novel algorithmic techniques that will hopefully be broadly useful\u2014see Section 3 for an overview. Both algorithms use the optimal number of samples. The first algorithm obtains optimal accuracy parameter $\\alpha=3$ with a time complexity of $\\tilde{O}(n/(\\delta^{3}\\,\\epsilon)\\cdot s)$ , which is off by an $O(1/(\\delta^{3}\\,\\epsilon))$ factor. Our second algorithm achieves the optimal time complexity up to logarithmic factors while achieving a slightly higher $\\alpha=4$ . Our results leave a fascinating open question: Can one combine the best aspects of both algorithms, maintaining $\\alpha=3$ , achieving $O(n\\cdot s)$ time (or even lower), and sample complexity $s=\\bar{O^{\\left(\\log\\left(n/\\delta\\right)/\\epsilon^{2}\\right)\\?}}$ ", "page_idx": 3}, {"type": "text", "text": "Remark 4. Readers may be surprised by the polynomial dependence on $1/\\delta$ in Theorem 2. In many settings, the success probability of a learning algorithm can be amplified from a constant, say 2/3, to at least $1-\\delta$ at a cost of at most $\\log(1/\\delta)$ in running time and sample complexity. However, in hypothesis selection, there is no (known) general technique for boosting the confidence parameter while keeping \u03b1 the same. The issue is that choosing the best output from several runs of a given algorithm requires executing a second hypothesis selection algorithm, which introduces another factor of $\\alpha$ in the approximation\u2014leading to a total factor of at least 9. As a result, these kinds of two-phase algorithms are not sufficient in the low $\\alpha$ regime. Some previous results, such as [ABS23], also suffer from a polynomial dependency on $\\delta$ . ", "page_idx": 3}, {"type": "text", "text": "1.3 Other related work ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Hypothesis selection has been studied in various settings including improper setting. In [BKM19], the authors consider the improper version of the problem where the output hypothesis $\\hat{H}$ may not necessarily be in $\\mathcal{H}$ . They presented an improper learner with accuracy guarantee $\\alpha\\,=\\,2$ . The sample complexity of their algorithm was improved by $[\\mathrm{BBK}^{+}21]$ , who gave an algorithm with nearly optimal sample complexity and the same accuracy parameter $\\alpha=2$ . It is worth noting that our algorithms are proper learners and solve this problem with a slightly better sample complexity. In addition, like other proper learners, our algorithms select their output from a predefined set, which can facilitate choosing a distribution with specific structural property (e.g., mixture of Gaussians). In certain applications, this selection ensures consistency with the problem\u2019s underlying assumptions, which enhances interpretability and robustness. ", "page_idx": 3}, {"type": "text", "text": "The problem of hypothesis selection in sublinear time was studied for distributions on discrete domains $[\\mathrm{AAC}^{+}2\\dot{3}]$ . Among other results, the authors developed a data structure that upon receiving samples from a unknown distribution $P$ returns a hypothesis $\\hat{H}$ in $o(n)$ time. While their algorithm runs in sublinear time, their sample complexity depends on the domain size of the distribution, and their setting allows pre-processing of the class $\\mathcal{H}$ in polynomial time. Another interesting variation for hypothesis selection is designing differentially private learners for the problem which has received attention over the past few years [BKSW19, $\\mathrm{CKM}^{+}19$ , $\\mathrm{GKK}^{+}20]$ . ", "page_idx": 3}, {"type": "text", "text": "An important application of hypothesis selection arises when there is a structural assumption on the underlying distributions. One approach for learning these classes is to selectively choose a cover for the class. One can then use the learners for the standard hypothesis selection problem (which we study in the paper) and use the cover as the class $\\mathcal{H}$ . Examples of such structural assumptions include Poisson binomial distributions [DDS12], mixtures of Gaussians [KMV12, DK14, SOAJ14, DKS17, KSS18, ABM18, $\\mathrm{ABH^{+}20}]$ , distributions with piecewise polynomial PDFs [ADLS17], and histograms [Pea95, CDSS14, CDKL22]. See Diakonikolas [Dia16] for a survey of results. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Notation: We use the following notation throughout this article. We use $[n]$ to indicate the set $\\{1,2,\\ldots,n\\}$ . For a distribution $Q$ over $\\mathcal{X}$ , $Q(x)$ denotes the PDF of $Q$ at the domain element $x\\in\\mathscr{X}$ . For any measurable subset of the domain $S\\subseteq\\mathcal{X}$ , $Q(S)$ indicates the probability mass of the set $S$ according to $Q$ . We use $\\|Q_{1}-Q_{2}\\|_{\\mathrm{TV}}:=\\operatorname*{sup}_{S\\subseteq\\mathcal{X}}\\left|Q_{1}(S)-Q_{2}(S)\\right|$ to denote the total variation distance between $Q_{1}$ and $Q_{2}$ . We say $Q_{1}$ is $\\epsilon$ -close to $Q_{2}$ if $\\lVert Q_{1}-Q_{2}\\rVert_{\\mathrm{TV}}$ is at most $\\epsilon$ . Conversely, we say $Q_{1}$ is $\\epsilon_{}$ -far from $Q_{2}$ if $\\lVert Q_{1}-Q_{2}\\rVert_{\\mathrm{TV}}$ is greater than $\\epsilon$ . We use the standard $O,\\Omega,\\Theta$ notation for asymptotic functions. Additionally, we use $\\Tilde{O},\\Tilde{\\Omega}$ , and $\\Tilde{\\Theta}$ to hide polylog factors. ", "page_idx": 4}, {"type": "text", "text": "Scheff\u00e9 sets: For every pair of hypotheses $H_{i}$ and $H_{j}$ in $\\mathcal{H}$ , we define the Scheff\u00e9 set of $H_{i}$ and $H_{j}$ as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nS_{i,j}:={\\left\\{\\begin{array}{l l}{\\{x\\in{\\mathcal{X}}\\mid H_{i}(x)<H_{j}(x)\\}\\quad}&{{\\mathrm{if~}}i\\leq j}\\\\ {S_{j,i}\\quad}&{{\\mathrm{if~}}i>j}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "It is known that the Scheff\u00e9 set maximizes the probability discrepancy between $H_{i}$ and $H_{j}$ , thus fully characterizing the total variation distance between the two distributions: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|H_{i}-H_{j}\\|_{\\mathrm{TV}}=\\operatorname*{sup}_{S\\subseteq\\mathcal{X}}\\left|H_{i}(S)-H_{j}(S)\\right|=\\left|H_{i}\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)\\right|\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The optimal hypothesis: Recall that we assume the algorithm is given samples drawn from an unknown distribution $P$ . Let $H_{i^{*}}$ denote the closest hypothesis in $\\mathcal{H}$ to $P$ . That is, $H_{i^{*}}$ is the hypothesis for which $\\|H_{i^{*}}-P\\|_{\\mathrm{TV}}={\\mathsf{O P T}}$ . When there is more than one hypothesis with this property, we pick one arbitrarily as $H_{i^{*}}$ . ", "page_idx": 4}, {"type": "text", "text": "Semi-distances: For every pair $i,j$ in $[n]$ , we define $w_{j}(H_{i})$ to be $\\lvert H_{i}\\left(S_{i,j}\\right)-P\\left(S_{i,j}\\right)\\rvert$ . In words, $w_{j}(H_{i})$ is the distance of $H_{i}$ to $P$ observed on the Scheff\u00e9 set of $H_{i}$ and $H_{j}$ . For every pair $i,j\\,\\in\\,[n]$ , we use $\\hat{w}_{j}(H_{i})$ to denote an estimate of $w_{j}(H_{i})$ based on the observed sample. For the sake of consistency, we define $w_{i}(H_{i})$ to be zero. In addition, we define the score function $\\begin{array}{r}{W(H_{i}):=\\operatorname*{max}_{j\\in[n]}w_{j}(H_{i})}\\end{array}$ . Similarly, $\\hat{W}(H_{i})$ is defined to be $\\operatorname*{max}_{j\\in[n]}\\hat{w}_{j}(H_{i})$ . ", "page_idx": 4}, {"type": "text", "text": "Refined access model: Similar to previous work [DL01, MS08], we use estimates of the semidistances. One can easily estimate these quantities, denoted by $\\hat{w}_{j}(H_{i})$ , via the access model we have described earlier by letting $\\hat{w}_{j}(H_{i})$ be the empirical ratio of the samples that are in $\\mathscr{S}_{i,j}$ . Throughout this paper, we assume that there are two universal parameters $\\delta^{\\prime}=\\Theta(\\delta)$ and $\\epsilon^{\\prime}=\\Theta(\\epsilon)$ , for which with probability $1-\\delta^{\\prime}$ every $\\hat{w}_{j}(H_{i})$ is within $\\epsilon^{\\prime}$ of $w_{j}(H_{i})$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\forall i,j\\in[n]:\\quad|\\hat{w}_{j}(H_{i})-w_{j}(H_{i})|\\leq\\epsilon^{\\prime}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "A simple application of the Hoeffding bound and the union bound shows that one can compute all of the estimates via $s=O(\\log(n/\\delta^{\\prime})/\\bar{\\epsilon^{\\prime}}^{2})$ samples, and each estimate can be computed in $O(s)$ time. ", "page_idx": 4}, {"type": "text", "text": "Our algorithms access the distributions in $\\mathcal{H}\\cup\\{P\\}$ only via querying $\\hat{w}_{j}(H_{i})$ . This fact brings the sample complexity of our algorithms to $s=O(\\log(n/\\delta^{\\prime})/\\epsilon^{\\prime2})$ samples. The time complexity of our algorithms is determined by the number of queries they make to the $\\hat{w}_{j}(H_{i})$ \u2019s, multiplied by time that we spend on each query, $O(s)$ . Moreover, in the proofs of our theorems, we assume without loss of generality that all the $\\hat{w}_{j}(H_{i})$ \u2019s are accurate. Conditioning on the accuracy will not decrease the probability of correctness of any of our algorithms by more than $\\delta^{\\prime}$ due to Fact C.1. ", "page_idx": 4}, {"type": "text", "text": "3 Overview of our techniques ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we provide a high-level discussion of our algorithm. The important notations and definitions used here are provided in Section 2. For the high-level discussions in this section, we assume we have access to the exact values of the semi-distances $w_{j}(H_{i})$ . In the formal proofs presented in subsequent sections, we will substitute each $w_{j}(H_{i})$ with an estimated value $\\hat{w}_{j}(H_{i})$ . ", "page_idx": 4}, {"type": "text", "text": "If the error of these estimates is below $\\epsilon^{\\prime}=\\Theta(\\epsilon)$ , it can be shown that the overall impact of this substitution on our final distance guarantee (Equation 1) is at most $\\Theta(\\epsilon)$ . See the \u201cRefined access model\u201d in Section 2 for further details. ", "page_idx": 5}, {"type": "text", "text": "3.1 Background: Semi-distances and the minimum distance estimate ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To solve the hypothesis selection problem, we seek a certificate that ensures we output a hypothesis $\\hat{H}$ such that $\\|\\hat{H}-P\\|_{\\mathrm{TV}}$ is at most 3 OPT. Similar to previous work, our algorithms operate based on the probability masses of the Scheff\u00e9 sets (Equation (2)) of pairs of hypotheses in $\\mathcal{H}$ . The semi-distance $w_{j}(H_{i})$ , defined as $\\vert H_{i}\\left(S_{i,j}\\right)-P\\left(S_{i,j}\\right)\\vert$ , captures the \u201cdistance\u201d between $H_{i}$ and $P$ as measured on this particular set $S_{i,j}$ . One suggestion for readers to internalize the semi-distances is to view them as a distance between $H_{i}$ and $P$ that is measured from the perspective of $H_{j}$ . By definition, $w_{j}(H_{i})$ is always a lower bound for $\\|H_{i}-P\\|_{\\mathrm{TV}}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nw_{j}(H_{i}):=|H_{i}\\left(S_{i,j}\\right)-P\\left(S_{i,j}\\right)|\\leq\\operatorname*{sup}_{S\\subseteq\\mathcal{X}}\\left|H_{i}(S)-P(S)\\right|=\\|H_{i}-P\\|_{\\mathrm{TV}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "However, it is possible for $w_{j}(H_{i})$ to be much lower, making it difficult for an algorithm to estimate the TV distance between $H_{i}$ and $P$ just using semi-distances. ", "page_idx": 5}, {"type": "text", "text": "Nevertheless, for each hypothesis $H_{i}$ , a specific semi-distance $w_{i^{*}}(H_{i})$ , associated with the optimal hypothesis $H_{i^{*}}$ , determines its quality. As shown in the following proof, if $w_{i^{*}}(H_{i})\\leq\\mathsf{O P T}$ , then $H_{i}$ is 3, OPT-close to $P$ , with the total variation distance between $H_{i}$ and $P$ bounded by $w_{i^{*}}(H_{i})$ and OPT via the triangle inequality: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|H_{i}-P\\|_{\\mathrm{TV}}\\leq\\|H_{i}-H_{i^{*}}\\|_{\\mathrm{TV}}+\\|H_{i^{*}}-P\\|_{\\mathrm{TV}}=|H_{i}\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)|+{\\sf O P T}}\\\\ &{\\qquad\\qquad\\leq w_{i^{*}}(H_{i})+w_{i}(H_{i^{*}})+{\\sf O P T}\\leq w_{i^{*}}(H_{i})+2\\,{\\sf O P T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This observation implies that if we assert that $w_{i^{*}}(H_{i})$ is bounded by $\\mathsf{O P T}$ , we can output $H_{i}$ as our final solution to the problem and be done. The challenge is that we neither know $i^{*}$ nor OPT. ", "page_idx": 5}, {"type": "text", "text": "This issue is addressed by the minimum distance estimate presented in [DL01, MS08] using a score function $W(H_{i})$ , as defined earlier: $\\begin{array}{r}{W(H_{i}):=\\operatorname*{max}_{j\\in[n]}\\Bar{w}_{j}(H_{i})}\\end{array}$ . The minimum distance estimate outputs a hypothesis H\u02c6 that minimizes $W(H_{i})$ . We can assert that, for the output of this algorithm, $\\hat{H}$ $,\\,w_{i^{*}}(\\hat{H})$ is at most OPT. This approach simultaneously bypasses the issues of not knowing $i^{*}$ and $\\mathsf{O P T}$ . ", "page_idx": 5}, {"type": "text", "text": "Note that $W(H_{i})$ serves as a proxy for the quality of $H_{i}$ since $W(H_{i})$ is an upper bound for $w_{i^{*}}(H_{i})$ . Using $W(H_{i})$ , we can address the issue of not knowing $i^{*}$ . On the other hand, although OPT is not known, we have a good lower bound for OPT, which is $W(H_{i^{*}})$ . Putting these observations together, we obtain: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\hat{H}-P\\|_{\\operatorname{TV}}\\leq w_{i^{*}}(\\hat{H})+2\\,0\\mathsf{P T}\\leq W(\\hat{H})+2\\,0\\mathsf{P T}\\leq W(H_{i^{*}})+2\\,0\\mathsf{P T}\\leq3\\,0\\mathsf{P T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "These inequalities are derived using the triangle inequality and the fact that $\\hat{H}$ was chosen to be the arg $\\mathrm{min}_{i\\in[n]}\\,W(H_{i})$ . See Figure 1 for an illustration of the above inequality. ", "page_idx": 5}, {"type": "text", "text": "The primary hurdle with the minimum distance estimate is that it is costly to compute. Computing each $W(H_{i})$ takes $O(n\\cdot s)$ time, bringing the total time complexity of the algorithm to $O(\\bar{n}^{2}\\cdot s)$ . One might naturally conjecture that sampling may help to compute an estimate of $W(H_{i})$ . Instead of using $\\begin{array}{r}{W(H_{i}):=\\operatorname*{max}_{j\\in[n]}w_{j}(H_{i})}\\end{array}$ , we can use $\\tilde{W}(H_{i}):=\\operatorname*{max}_{j\\in R}w_{j}(H_{i})$ where $R$ is a set of random indices in $[n]$ . The issue with this approach is that there is no guarantee of $i^{*}$ being selected in $R$ , making $\\tilde{W}(H_{i})$ too low while $H_{i}$ may be far from $P$ . Hence sampling, if used in a trivial manner, is not beneficial. ", "page_idx": 5}, {"type": "text", "text": "3.2 The algorithm with $\\alpha=3$ ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present an overview of Algorithm 1 that attains $\\alpha=3$ . The details of this algorithm and its related theorems are provided in Section A. At a high level, similar to the minimum distance estimate, we work towards finding a hypothesis that minimizes $W(H_{i})$ . To increase efficiency, we work with estimates of $W(H_{i})$ \u2019s, denoted by $\\tilde{W}(H_{i})$ . The general structure of our algorithm is as follows: Initially, all $\\tilde{W}(H_{i})$ are set to zero. At every step, we come up with several pairs of hypotheses $H_{i}$ and $H_{j}$ and update our estimates by setting $\\tilde{W}(H_{j})$ to $\\operatorname*{max}(\\tilde{W}(H_{j}),w_{i}(H_{j}))$ . Our approach ensures that at every step, $\\tilde{W}(H_{i})$ is equal to $\\operatorname*{max}_{j\\in R}w_{j}(H_{i})$ for a small, carefully chosen set $R$ . Eventually, we output a hypothesis with roughly the smallest $\\tilde{W}(H_{i})$ . ", "page_idx": 5}, {"type": "image", "img_path": "Skv26JteFz/tmp/d4f1ab957941437a1a56634e05115c9f25b95398603a842a737c9857c5375ef3.jpg", "img_caption": ["Figure 1: A description of bounding $\\|H_{i}-P\\|_{\\mathrm{TV}}$ via $W(H_{i})$ and OPT "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Focusing on small $\\tilde{W}$ : Our first idea is to focus on updating the $\\Tilde{W}$ for hypotheses whose $\\tilde{W}(H_{i})$ values are around the current minimum $\\Tilde{W}$ . The rationale for this action comes from a simple fact: $\\tilde{W}(H_{j})$ always underestimates the value of $W(H_{j})$ . Hence, if we observe that $\\tilde{W}(H_{i})$ is substantially larger than the current minimum, then $W(H_{i})$ is also substantially larger than the current minimum. This implies that $H_{i}$ is not a suitable candidate for the minimum at this stage of the algorithm, and it can be ignored for now. ", "page_idx": 6}, {"type": "text", "text": "Bucketing hypotheses based on $\\tilde{W}$ : To implement this idea, we partition the hypotheses into $k\\,=\\,\\Theta(1/\\epsilon^{\\prime})$ buckets $\\boldsymbol{B}\\,:=\\,\\{B_{1},B_{2},\\ldots,B_{k}\\}$ based on $\\tilde{W}(H_{i})$ . The bucket $\\ell$ contains all the hypotheses $H_{i}$ such that $\\tilde{W}(H_{i})\\,\\in\\,[(\\ell-1)\\epsilon^{\\prime},\\ell\\,\\epsilon^{\\prime})$ . At every step, we focus on the smallest nonempty bucket $B_{\\ell}$ (the smallest $\\ell$ for which $|B_{\\ell}|\\neq0|$ ). $B_{\\ell}$ contains all the hypotheses whose $\\tilde{W}(H_{j})$ is around the minimum $\\Tilde{W}$ . We pick pairs of hypotheses, $H_{i}\\in{\\mathcal{H}}$ and $H_{j}\\in B_{\\ell}$ , and update $\\tilde{W}(H_{j})$ . Note that our updates may increase $\\tilde{W}(H_{j})$ , and we may remove $H_{j}$ from $B_{\\ell}$ and put it into a larger bucket (a bucket with a larger index $\\ell$ ). Also, observe that we never move a hypothesis into a smaller bucket since $\\tilde{W}(H_{j})$ never decreases. We continue our updates to reach one of the following outcomes: ", "page_idx": 6}, {"type": "text", "text": "\u2022 $B_{\\ell}$ becomes empty. That is, our updates made all $\\tilde{W}(H_{i})$ fall out of the range of these buckets $[0,\\ell\\,\\epsilon^{\\prime})$ . Thus, every $\\tilde{W}(H_{i})$ (and consequently every $W(H_{i}))$ is at least $\\ell\\cdot\\epsilon^{\\prime}$ . Every time that we empty out a bucket, we have increased our threshold for minimum $W(H_{i})$ by $\\epsilon^{\\prime}$ . Hence, we are getting closer to a bucket with the true minimum, which we hope to reach in ${\\cal O}(1/\\epsilon^{\\prime})$ steps. \u2022 $B_{\\ell}$ is not empty, but we can confidently confirm most of the hypotheses in $B_{\\ell}$ are an acceptable output for the algorithm. Although we cannot ensure that $H_{i^{*}}$ is indeed in $B_{\\ell}$ , we can find an acceptable final answer by selecting a random hypothesis in $B_{\\ell}$ . ", "page_idx": 6}, {"type": "text", "text": "Which pairs to update? Next, we outline our update scheme to implement the above ideas in linear time. To enhance time efficiency, our aim is to optimize the updating process to ensure both quality and quantity in the chosen updates. Quality, in this context, relates to the extent of change in $\\mathring{W}(H_{j})$ following an update: We consider $H_{i}$ to have made a substantial update to $H_{j}$ if $\\tilde{W}(H_{j})+\\epsilon^{\\prime}<\\hat{w}_{j}(H_{i})$ . Such updates cause a significant shift, increasing the value of $\\tilde{W}(H_{j})$ by more than $\\epsilon^{\\prime}$ and subsequently moving $H_{j}$ to a different bucket with a higher index $\\ell$ . We refer to this event as $H_{i}$ removing $H_{j}$ from its bucket. The quantity, on the other hand, relates to the number of $H_{j}$ instances that a given $H_{i}$ can remove from $B_{\\ell}$ . An ideal $H_{i}$ eliminates a substantial portion of hypotheses from $B_{\\ell}$ (say a constant fraction). We call such an $H_{i}$ a prompting hypothesis. Now, if for $O(\\log|B_{\\ell}|)$ rounds we find a prompting hypothesis and update all the $\\tilde{W}(H_{j})$ for $H_{j}\\in B_{\\ell}$ , we will empty out the bucket $B_{\\ell}$ , and we can move forward. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Finding a prompting hypothesis: To find a prompting hypothesis quickly, we iterate over all $H_{i}$ in $\\mathcal{H}$ , sample a few $H_{j}$ , and check if $H_{i}$ substantially updates $\\tilde{W}(H_{j})$ . If $H_{i}$ substantially improves a large fraction of the sampled hypotheses, then we declare that $H_{i}$ is a prompting hypothesis. See Section A.1.1 for further details. In addition to that, we provide a more advanced version of this procedure in Section A.1.2 that allows us to shave off an ${\\cal O}(\\log n)$ factor. ", "page_idx": 7}, {"type": "text", "text": "Getting stuck? Here is your way out: What happens when $B_{\\ell}$ is not empty, and we cannot find a prompting hypothesis? We show that if we do not find a prompting hypothesis, then a random hypothesis in $B_{\\ell}$ is an acceptable answer. ", "page_idx": 7}, {"type": "text", "text": "The surprising part about this statement is that it holds regardless of the size of the bucket $B_{\\ell}$ due to hypothesis sampling procedure we have to find a prompting hypothesis. In search for a prompting hypothesis, we iterate over all $H_{i}$ and sample roughly $O(\\log n/\\delta)$ many hypotheses $H_{j}$ \u2019s in $B_{\\ell}$ . We check, if $H_{i}$ can remove them from the bucket. Note that if $H_{i}$ was not found to be prompting, it implies that $H_{i^{*}}$ cannot substantially update most of the hypotheses in $B_{\\ell}$ . Thus, We have that with high probability for $1-\\delta$ fraction of the hypotheses in $B_{\\ell}$ , $w_{i}(H_{j})\\leq\\epsilon^{\\prime}\\cdot\\ell$ . ", "page_idx": 7}, {"type": "text", "text": "The clever hack here is an observation about $H_{i^{*}}$ . Earlier, we discussed that we are looking for a hypothesis $H_{i}$ with $w_{i^{*}}(H_{i})\\leq\\mathsf{O P T}$ . We claim that a random hypothesis in the last $B_{\\ell}$ (almost) has this property. On one hand, given that $H_{i^{*}}$ was not found to be a prompting hypothesis, for $1-\\delta$ fraction of $H_{i}$ in $B_{\\ell}$ , $w_{i^{*}}(H_{i})$ must be at most $\\ell\\cdot\\epsilon^{\\prime}$ . On the other hand, the fact that all the previous buckets, $B_{1},\\ldots,B_{\\ell-1}$ , are empty indicates $H_{i^{*}}$ has shown a semi-distance of at least $\\left(\\bar{\\ell}-1\\right)\\epsilon^{\\prime}$ . Hence, OPT, which is at least as large as all $H_{i^{*}}$ semi-distances, is at least $\\left(\\ell-1\\right)\\epsilon^{\\prime}$ . Therefore, $w_{i^{*}}(H_{i})\\leq\\epsilon^{\\prime}+0\\mathsf{P T}$ . Therefore, for $1-\\delta$ fraction of the hypotheses in $B_{\\ell}$ , they are $3\\,0\\mathsf{P T}+\\Theta(\\epsilon)$ close to $P$ . For a formal argument, see Lemma A.1. ", "page_idx": 7}, {"type": "text", "text": "Now, assume the search for the prompting hypothesis fails. Recall that during the search, we have checked every single hypothesis in $\\mathcal{H}$ . During the search, at some point, we must have stumbled upon $H_{i^{*}}$ and did not declare it as a prompting hypothesis. In this case, either our sampling for substantial updates failed (which happens with small probability), or we can infer that there are not too many far hypotheses in $B_{\\ell}$ . Either way, we can output a random hypothesis from $B_{\\ell}$ as the final sample without increasing the error probability by too much. ", "page_idx": 7}, {"type": "text", "text": "Dependency on $\\delta$ : It is worth noting that this last step results in a polynomial dependency on $\\delta$ (as opposed to a more desirable dependency of $\\log(1/\\delta),$ ). This is mainly due to the fact that to ensure that a random hypothesis in $B_{\\ell}$ is not too far, with a probability of $1-\\delta$ in a single round, we have to try $O(\\log(n){\\bar{/}}\\delta)$ hypotheses in $B_{\\ell}$ and check if $H_{i^{*}}$ is prompting them. Hence, relying on this structural property of $H_{i^{*}}$ makes a polynomial dependency on $\\delta$ inevitable. Improving the dependency on $\\delta$ for this algorithm would require new algorithmic ideas. ", "page_idx": 7}, {"type": "text", "text": "3.3 The algorithm with $\\alpha=4$ ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We introduce another (almost) linear-time algorithm for the hypothesis selection problem, where the time complexity shows improved dependency on $\\epsilon$ . However, this algorithm has a slightly worse accuracy parameter compared to our previous algorithm: $\\alpha=4$ . This algorithm and the subsequent theorems are provided in Section B. ", "page_idx": 7}, {"type": "text", "text": "Algorithm with a guessed upper bound of OOOPPPTTT: As mentioned earlier, unlike previous work, our algorithm does not receive any prior information about the value of $\\mathsf{O P T}$ . It might be speculated that there exists an easy reduction between our problem and another version of hypothesis selection, where an auxiliary parameter $\\sigma$ is provided to the algorithm such that ${\\mathsf{O P T}}\\leq\\sigma$ . A learner without the knowledge of $\\sigma$ can make a guess about $\\sigma$ and run one of the existing algorithms that works with the knowledge of an upper bound of OPT (e.g., [ABS23]) and check if it finds a good hypothesis or not. With this procedure in mind, we can run a binary search to find the smallest $\\sigma$ for which we find a hypothesis.4 However, a challenge with this approach is that the algorithm might yield a hypothesis even when $\\sigma<\\mathsf{O P T}$ , making it difficult for us to refute the hypothesis that is found. Even if the output $\\hat{H}$ satisfies $W({\\hat{H}})>\\sigma$ , it does not necessarily invalidate our guessed value $\\sigma$ . ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "To overcome this challenge, we design an algorithm, namely $\\boldsymbol{\\mathcal{A}}$ , with enhanced accuracy guarantees for the output hypothesis. We provide $\\boldsymbol{\\mathcal{A}}$ with the value $\\sigma$ . We treat $\\sigma$ as a \"guess\" for which we hope that ${\\mathsf{O P T}}\\leq\\sigma$ . We require the algorithm to either refute our guess and declare $\\mathsf{O P T}>\\sigma$ , or output a hypothesis $\\hat{H}$ with a reasonable distance to $P$ , irrespective of the relationship between OPT and $\\sigma$ . More precisely, the distance of the output hypothesis should be bounded by: $\\|\\hat{H}-P\\|_{\\mathrm{TV}}\\leq$ $\\alpha\\cdot\\operatorname*{max}(mathsf{O P T},\\sigma)+\\epsilon$ . With these revised guarantees, it is permissible to run a binary search over different values of $\\sigma$ in $\\{\\epsilon,2\\,\\epsilon,\\dots,\\lceil1/\\epsilon\\rceil\\ \\epsilon\\}$ , and output the hypothesis that $\\boldsymbol{\\mathcal{A}}$ returns on the smallest $\\sigma$ . For the rest of this discussion, we focus on designing $\\boldsymbol{\\mathcal{A}}$ and a provided parameter $\\sigma$ . ", "page_idx": 8}, {"type": "text", "text": "Seeds and finding an acceptable hypothesis via seeds: In this algorithm, we introduce a new concept called a seed for hypotheses. A seed provides us with a structural property that enables us to identify an acceptable hypothesis, regardless of the relationship between $H_{i^{*}}$ and the seed. More formally, for a hypothesis $H_{i}$ , we define $\\mathcal{M}_{a,b}(H_{i})$ as the set of hypotheses $H_{j}$ such that $w_{j}(H_{i})$ is between $a$ and $b$ : ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathcal{M}_{a,b}(H_{i}):=\\{H_{j}\\in\\mathcal{H}\\mid a<\\hat{w}_{j}(H_{i})\\leq b\\}\\;.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We may omit the subscript of $\\mathcal{M}$ when it is clear from the context. We say a hypothesis $H_{i}$ is a seed if almost all of its $\\hat{w}_{j}(H_{i})$ are low and its $W(H_{i})$ is not too large. The quality of a seed is determined by three parameters: $a,b$ , and $m$ . ", "page_idx": 8}, {"type": "text", "text": "Definition 3.1 (Seed). Given parameters $a,b\\,\\in\\,\\mathbb{R}_{\\geq0}$ , and a non-negative integer $m$ , we say $a$ hypothesis is an $(a,b,m)$ -seed if the following hold: $^{\\,l}$ ) $\\hat{W}(H_{i})\\leq b_{i}$ , and 2) $|\\mathcal{M}_{a,b}(H_{i})|\\leq m$ . ", "page_idx": 8}, {"type": "text", "text": "A seed with a small-sized set $\\mathcal{M}$ and a small $b$ exhibits an interesting property: Suppose we have a seed $H_{i}$ with a constant-sized set $\\mathcal{M}$ . In this case, in $O(n)$ time, we can compute $W(H_{j})$ of every hypothesis $H_{j}$ in $\\mathcal{M}$ . Now, let $H_{\\ell}\\,\\in\\,\\mathcal{M}$ be one of the hypotheses that minimize $\\dot{W}(\\dot{H}_{j})$ : $\\begin{array}{r}{H_{\\ell}:=\\arg\\operatorname*{min}_{H_{j}\\in\\mathring{\\mathcal{M}}}W(H_{j})}\\end{array}$ . We claim either $H_{i}$ or $H_{\\ell}$ is acceptable output in this case. ", "page_idx": 8}, {"type": "text", "text": "When $H_{i^{*}}$ is in $\\mathcal{H}\\backslash\\mathcal{M}$ , we can infer that $w_{i^{*}}(H_{i})$ is at most $b$ (or, more precisely, $b+\\epsilon^{\\prime})$ . From our earlier discussion, if $b$ is sufficiently small (compared to $\\sigma$ ), we can show that $H_{i}$ is close to $P$ . In cases where $H_{i^{*}}$ is in $\\mathcal{M}$ , although we do not have strong guarantees for $H_{i}$ itself, we have a very good answer already: $H_{\\ell}$ is essentially a minimum distance estimate for the set $\\mathcal{M}$ which includes $H_{i^{*}}$ . Thus, we can conclude: First, $H_{\\ell}$ is an acceptable output because it is 3 OPT-close; second, $W(H_{\\ell})$ is a lower bound for OPT. ", "page_idx": 8}, {"type": "text", "text": "Now, as we described, we have two acceptable outputs for two cases of the problem. For $H_{i^{*}}\\in\\mathcal{H}\\backslash\\mathcal{M}$ , $H_{i}$ is an acceptable answer. For $H_{i^{*}}\\in\\mathcal{M}$ , $H_{\\ell}$ is an acceptable answer. The only problem is that we do not know which case we are in. Our strategy is to pick a hypothesis that is still reasonably close to $P$ even if we are in the other case. Let us fix a threshold value $T$ . We compare $W(H_{\\ell})$ with $T\\sigma$ : 1) If $W(H_{\\ell})\\leq T\\cdot\\sigma$ , as we have discussed earlier, $H_{\\ell}$ is $(T\\cdot\\sigma+20\\mathsf{P T})$ -close to $P$ . This bound holds regardless of where $H_{i^{*}}$ is. 2) Next, if $W(H_{\\ell})>T\\cdot\\sigma$ , we cannot say $H_{\\ell}$ is a good choice for us. However, we can conclude that $H_{i}$ is a close hypothesis to $P$ even when $H_{i^{*}}$ happens to be in $\\mathcal{M}$ . In this case, we know that $\\mathsf{O P T}\\geq W(H_{\\ell})>T\\cdot\\sigma$ . We take advantage of this knowledge and obtain the following bound: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Vert H_{i^{*}}-P\\Vert_{\\mathrm{TV}}=b\\,\\sigma+2\\,0\\mathsf{P T}\\leq\\left(\\frac{b}{T}+2\\right)0\\mathsf{P T}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Thus, regardless of where $H_{i^{*}}$ is, $H_{i}$ is $(\\operatorname*{max}(a,b/T)+2)\\cdot\\operatorname*{max}\\left(\\sigma,0\\mathsf{P T}\\right)$ . Now, the algorithm is fairly straightforward. If $W(H_{\\ell})$ is small, output $H_{\\ell}$ ; otherwise, output $H_{i}$ . We summarize these four cases in the following table. Depending on $a$ and $b$ , we set $T$ to minimize the maximum distance we endure in these cases. It is worth noting that in this argument, we did not rely on any prior knowledge concerning the relationship between $\\sigma$ and OPT. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "table", "img_path": "Skv26JteFz/tmp/908429b40ce4598649dcd3820abb43a36b75f009623f1a5fceeb008aeafa462e.jpg", "table_caption": ["Table 2: Four cases when we process a good seed. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "How to find the first seed? Here, we provide an overview of our approach for identifying an initial seed. For a detailed explanation of the algorithm and its performance, refer to Section B.1. ", "page_idx": 9}, {"type": "text", "text": "To start, fix two parameters, $a=\\sigma$ and $b=3\\sigma$ . To identify a seed hypothesis, we iterate over all hypotheses $H_{1},...,H_{n}$ , checking whether each hypothesis $H_{i}$ is a strong seed (i.e., a seed with a small $|{\\mathcal{M}}|)$ by sampling several $H_{j}$ \u2019s and verifying if $w_{j}(H_{i})$ is at most $a$ . Roughly speaking, for an integer $m\\in[n]$ , if we sample approximately ${\\tilde{O}}(n/{\\bar{m}})$ $H_{j}$ \u2019s and find that no $w_{j}(H_{i})>a$ , we can, with high probability, confirm that the size of $\\mathcal{M}$ does not exceed $m$ . This approach requires $O(n^{2}/m)$ time. ", "page_idx": 9}, {"type": "text", "text": "There are, however, a few caveats with this method. First, if a seed is identified using the above approach, it may have a large $W(H_{i})>b$ . In this case, we can infer that $H_{i}$ is likely far from $P$ . Given the time invested in identifying $H_{i}$ , we aim to leverage this information. Broadly, observing that $w_{j}(H_{i})\\leq a$ implies that many hypotheses are close to $H_{i}$ (assuming that $w_{i}(H_{j})$ values are also small). Knowing that $H_{i}$ is far from $P$ , we can mark all hypotheses close to $H_{i}$ as also far, allowing us to proceed with the search. While this may seem counterproductive, marking a significant number of hypotheses as \u201cfar\u201d constitutes progress for our algorithm. Specifically, if, at some point, all hypotheses are marked, we can declare that $\\sigma<\\mathsf{O P T}$ . ", "page_idx": 9}, {"type": "text", "text": "The second caveat is more challenging. Ideally, we seek a seed with a constant $m$ , but finding such a seed would require $\\tilde{O}(n^{2}/m)=\\bar{\\tilde{O}}(n^{\\frac{2}{2}})$ time. Consequently, for a linear-time algorithm, we can only afford to find seeds where $m=\\Theta(n)$ . In other words, the quality of the seed we can initially identify is much lower than the quality required for a producing solution. This leads to our next idea: boosting a seed, which is an approach to incrementally improve the seed\u2019s quality in roughly $O(\\log n)$ steps. ", "page_idx": 9}, {"type": "text", "text": "Boosting a Seed: In this process, we use an initial seed to iteratively find a stronger seed with a reduced value of $|{\\mathcal{M}}|$ . For a formal argument, see Section B.2. Assume a rate parameter $\\eta\\in(0,1)$ . As discussed earlier, by spending $\\bar{O(\\bar{n}/\\eta)}$ time, we can identify a seed with $m\\approx\\eta\\cdot n$ . Initially, $m=|\\mathcal{M}|$ might be $O(n)$ . Hence, rather than calculating $W({\\cal H}_{j})$ exactly for all $H j\\,\\in\\,{\\mathcal{M}}$ , we compute an approximate maximum semi-distance $\\tilde{W}(H_{j})$ by sampling $t$ hypotheses. Specifically, for each $H j\\in M$ , we set $\\tilde{W}(H_{j}):=\\operatorname*{max}_{H_{k}}\\hat{w}_{k}(H_{j})$ , where $H_{k}$ \u2019s are sample hypotheses. Using these approximate values $\\Tilde{W}$ , we process the seed as follows. Let $H_{\\ell}$ denote the hypothesis minimizing $\\tilde{W}(H_{j})$ , with the following possible outcomes: ", "page_idx": 9}, {"type": "text", "text": "1. High $\\tilde{W}(H_{\\ell})$ : If $\\tilde{W}(H_{\\ell})$ is high, all $\\tilde{W}(H_{j})$ (and thus $W(H_{j}))$ values are likely large, making $H_{i}$ an acceptable final solution.   \n2. Low $\\tilde{W}(H_{\\ell})$ : While this does not guarantee a low $W(H_{\\ell})$ , it suggests that most $w_{i}(H_{\\ell})$ values are small. Based on the value of $W(H_{\\ell})$ , we consider two cases: 2.1 $W(H_{\\ell})\\gg\\tilde{W}(H_{\\ell});$ $H_{\\ell}$ is likely far from $P$ but has many close hypotheses, allowing us to mark these nearby hypotheses as far. 2.2 Moderate $W(H_{\\ell})$ : In this case, $H_{\\ell}$ can serve as our new seed, as it yields a smaller set $\\mathcal{M}(H_{\\ell})$ than $H_{i}$ . ", "page_idx": 9}, {"type": "text", "text": "Note that when we select $H_{\\ell}$ as our new seed, $\\mathcal{M}(H_{\\ell})$ is roughly $O(n/t)$ . However, we compute $\\tilde{W}(H_{j})$ \u2019s for only $|\\mathcal{M}(H_{i})|\\;\\approx\\;\\eta\\cdot\\,n$ many hypotheses. Hence, with an increased sample size $t=O(1/\\eta^{2})$ , this approach yields a smaller $|\\mathcal{M}(H_{\\ell})|\\approx\\eta^{2}\\cdot n$ . The step of the process requires $O(|\\mathcal{M}|\\cdot\\dot{t})=m/\\eta^{2}\\dot{=}O(n/\\eta)$ , paralleling the initial search. By repeating, we progressively reduce $m=|\\mathcal{M}|$ , and for a constant $\\eta,m$ decreases by a fixed factor until reaching a constant $m$ seed, as desired. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "M.A. was supported by NSF awards CNS-2120667, CNS-2120603, CCF-1934846, and BU\u2019s Hariri Institute for Computing. This work was initiated while M.A. was affiliated with Boston University and Northeastern University and was done in part while M.A. was a research fellow at the Simons Institute for the Theory of Computing. M.B. was supported in part by NSF award CNS-2046425 and a Sloan Research Fellowship. A.S. was supported in part by NSF awards CCF-1763786 and CNS-2120667 as well as Faculty Awards from Google and Apple. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "$[\\mathrm{AAC}^{+}23]$ Anders Aamand, Alexandr Andoni, Justin Y. Chen, Piotr Indyk, Shyam Narayanan, and Sandeep Silwal. Data structures for density estimation. In Proceedings of the 40th International Conference on Machine Learning. PMLR, 2023.   \n$[\\mathrm{ABH^{+}}20]$ Hassan Ashtiani, Shai Ben-David, Nicholas J. A. Harvey, Christopher Liaw, Abbas Mehrabian, and Yaniv Plan. Near-optimal sample complexity bounds for robust learning of gaussian mixtures via compression schemes. J. ACM, 67(6):32:1\u201332:42, 2020.   \n[ABM18] Hassan Ashtiani, Shai Ben-David, and Abbas Mehrabian. Sample-efficient learning of mixtures. In Sheila A. McIlraith and Kilian Q. Weinberger, editors, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, pages 2679\u20132686. AAAI Press, 2018.   \n[ABS23] Maryam Aliakbarpour, Mark Bun, and Adam Smith. Hypothesis selection with memory constraints. To appear in NeurIPS 2023, 2023.   \n[ADLS17] Jayadev Acharya, Ilias Diakonikolas, Jerry Li, and Ludwig Schmidt. Sample-optimal density estimation in nearly-linear time. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA, pages 1278\u20131289. SIAM, 2017.   \n$[\\mathrm{AFJ^{+}}18]$ Jayadev Acharya, Moein Falahatgar, Ashkan Jafarpour, Alon Orlitsky, and Ananda Theertha Suresh. Maximum selection and sorting with adversarial comparators. The Journal of Machine Learning Research, 19:59:1\u201359:31, 2018.   \n[AJOS14] Jayadev Acharya, Ashkan Jafarpour, Alon Orlitsky, and Ananda Theertha Suresh. Sorting with adversarial comparators and application to density estimation. In 2014 IEEE International Symposium on Information Theory, pages 1682\u20131686, 2014.   \n$[\\mathbf{BBK}^{+}21]$ Olivier Bousquet, Mark Braverman, Gillat Kol, Klim Efremenko, and Shay Moran. Statistically near-optimal hypothesis selection. In 62nd IEEE Annual Symposium on Foundations of Computer Science, FOCS 2021, Denver, CO, USA, February 7-10, 2022, pages 909\u2013919. IEEE, 2021.   \n[BKM19] Olivier Bousquet, Daniel Kane, and Shay Moran. The optimal approximation factor in density estimation. In Alina Beygelzimer and Daniel Hsu, editors, Proceedings of the Thirty-Second Conference on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pages 318\u2013341. PMLR, 25\u201328 Jun 2019.   \n[BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d\u2019Alch\u00e9- Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 156\u2013167, 2019.   \n[CDKL22] Cl\u00e9ment L. Canonne, Ilias Diakonikolas, Daniel Kane, and Sihan Liu. Nearly-tight bounds for testing histogram distributions. In Advances in Neural Information Processing Systems 35 (NeurIPS), 2022. To appear.   \n[CDSS14] Siu-on Chan, Ilias Diakonikolas, Rocco A. Servedio, and Xiaorui Sun. Near-optimal density estimation in near-linear time using variable-width histograms. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages 1844\u20131852, 2014.   \n[CKM+19] Cl\u00e9ment L. Canonne, Gautam Kamath, Audra McMillan, Adam D. Smith, and Jonathan R. Ullman. The structure of optimal private tests for simple hypotheses. In Moses Charikar and Edith Cohen, editors, Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, June 23-26, 2019, pages 310\u2013321. ACM, 2019.   \n[DDS12] Constantinos Daskalakis, Ilias Diakonikolas, and Rocco A. Servedio. Learning poisson binomial distributions. In Howard J. Karloff and Toniann Pitassi, editors, Proceedings of the 44th Symposium on Theory of Computing Conference, STOC 2012, New York, NY, USA, May 19 - 22, 2012, pages 709\u2013728. ACM, 2012. [Dia16] Ilias Diakonikolas. Learning structured distributions. In CRC Handbook of Big Data, pages 267\u2013283. 2016. [DK14] Constantinos Daskalakis and Gautam Kamath. Faster and sample near-optimal algorithms for proper learning mixtures of gaussians. In Conference on Learning Theory, pages 1183\u20131213. PMLR, 2014.   \n[DKS17] Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. Statistical query lower bounds for robust estimation of high-dimensional gaussians and gaussian mixtures. In Chris Umans, editor, 58th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2017, Berkeley, CA, USA, October 15-17, 2017, pages 73\u201384. IEEE Computer Society, 2017. [DL96] Luc Devroye and G\u00e1bor Lugosi. A universally acceptable smoothing factor for kernel density estimates. The Annals of Statistics, 24(6):2499 \u2013 2512, 1996. [DL97] Luc Devroye and G\u00e1bor Lugosi. Nonasymptotic universal smoothing factors, kernel complexity and Yatracos classes. The Annals of Statistics, 25(6):2626 \u2013 2637, 1997. [DL01] Luc Devroye and G\u00e1bor Lugosi. Combinatorial methods in density estimation. Springer, 2001.   \n$[{\\bf G K K}^{+}20]$ Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov, Zhiwei Steven Wu, and Huanyu Zhang. Locally private hypothesis selection. In Jacob D. Abernethy and Shivani Agarwal, editors, Conference on Learning Theory, COLT 2020, 9-12 July 2020, Virtual Event [Graz, Austria], volume 125 of Proceedings of Machine Learning Research, pages 1785\u20131816. PMLR, 2020.   \n[KMV12] Adam Tauman Kalai, Ankur Moitra, and Gregory Valiant. Disentangling gaussians. Commun. ACM, 55(2):113\u2013120, 2012. [KSS18] Pravesh K. Kothari, Jacob Steinhardt, and David Steurer. Robust moment estimation and improved clustering via sum of squares. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2018, Los Angeles, CA, USA, June 25-29, 2018, pages 1035\u20131046. ACM, 2018. [MS08] Satyaki Mahalanabis and Daniel Stefankovic. Density estimation in linear time. In 21st Annual Conference on Learning Theory - COLT, pages 503\u2013512, 2008. [Pea95] Karl Pearson. Mathematical contributions to the theory of evolution. ii. skew variation in homogeneous material. [abstract]. Proceedings of the Royal Society of London, 57:257\u2013260, 1895.   \n[SOAJ14] Ananda Theertha Suresh, Alon Orlitsky, Jayadev Acharya, and Ashkan Jafarpour. Near-optimal-sample estimators for spherical gaussian mixtures. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 27, 2014. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "[Yat85] Yannis G. Yatracos. Rates of convergence of minimum distance estimators and kolmogorov\u2019s entropy. The Annals of Statistics, 13(2):768 \u2013 774, 1985. ", "page_idx": 12}, {"type": "image", "img_path": "Skv26JteFz/tmp/96fc8f4640ba1480902f7bea424f97f903536fc21d0a41bcb42b692974e68503.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "A Almost linear time algorithm with $\\alpha=3$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we focus on our first result, the algorithm with $\\alpha\\,=\\,3$ . The pseudocode of our approach is presented in Algorithm 1. We prove the performance of this algorithm in Theorem 5. An overview of our approach is described in Section 3.2. ", "page_idx": 13}, {"type": "text", "text": "At a high level, our algorithm begins with all $\\tilde{W}(H_{i})$ set to zero, and all hypotheses placed in $B_{1}$ . We then iterate over all buckets. In round $\\ell$ , we check if there is a prompting hypothesis $H_{i}\\in{\\mathcal{H}}$ that can move a significant fraction of hypotheses from $B_{\\ell}$ . Specifically, we look for an $H_{i}$ that moves a $\\gamma$ -fraction of hypotheses from $B_{\\ell}$ by updating them, where $\\gamma=\\Theta(\\delta)$ . If we find such a hypothesis $H_{i}$ , we update all the hypotheses in $B_{\\ell}$ and move as many as possible out of $B_{\\ell}$ . During this process, we count the number of hypotheses that $H_{i}$ removes from $B_{\\ell}$ , which is tracked by $C_{\\ell\\,i}$ in the algorithm. If the actual fraction of hypotheses removed from $B_{\\ell}$ is less than $\\gamma/2$ , we infer that IS-PROMPTING falsely declared $H_{i}$ as a prompting hypothesis (false positive). Thus, the algorithm returns $\\bot$ . Otherwise, we restart the search by setting $i=1$ and iterate over all $H_{i}$ to find the next prompting hypothesis. We continue this process until no prompting hypothesis is found or the bucket is emptied. If we completely empty a bucket, we move on to the next one. If not, we select a random hypothesis in $B_{\\ell}$ as the final output and halt. ", "page_idx": 13}, {"type": "text", "text": "Theorem 5. Suppose $\\mathcal{H}$ is a class of n known hypotheses and $P$ is an unknown hypothesis. Assume the algorithm has access to accurate estimates of $\\hat{w}_{j}(H_{i})\\,\\rangle_{s}$ that have an error of at most $\\epsilon^{\\prime}$ . Let $\\epsilon$ and $\\delta$ be two parameters in $(0,1)$ . If $3\\,\\epsilon^{\\prime}\\le\\epsilon,$ , then Algorithm $^{l}$ is an $(\\alpha=3,\\epsilon,\\delta)$ -proper learner for $P$ in $\\mathcal{H}$ . The running time of our algorithm is $\\tilde{O}((n/(\\delta^{3}\\epsilon))\\cdot T_{q})$ , where $T_{q}$ is the time to obtain each $\\hat{w}_{j}(H_{i})$ . ", "page_idx": 13}, {"type": "text", "text": "1. If the algorithm returns $\\hat{H}$ , with high probability, $\\hat{H}$ is not too far from $P$ . ", "page_idx": 14}, {"type": "text", "text": "2. While the algorithm may not produce a hypothesis all the time, the overall failure probability of the algorithm is low. 3. The running time of the algorithm meets the desired bounds in the theorem. ", "page_idx": 14}, {"type": "text", "text": "The output $\\hat{H}$ is close with high probability. Suppose we output ${\\hat{H}}\\in B_{\\ell}$ at step $\\ell$ . Our goal is to show that $\\hat{H}$ is $(3\\,0\\mathsf{P T}+\\epsilon)$ -close to $P$ with probability $1-\\delta^{\\prime}$ . We define two events $\\mathscr{E}_{\\ell}$ and $\\overline{{\\mathcal{E}_{\\ell}}}$ for each $\\ell\\in[k]$ based on the fraction of far hypotheses in $B_{\\ell}$ in Line 25:5 ", "page_idx": 14}, {"type": "text", "text": "$\\mathcal{E}_{\\ell}:=$ the event that a non-empty $B_{\\ell}$ in Line 25 contains at least $\\lceil\\gamma\\cdot|B_{\\ell}|\\rceil$ hypotheses that are $(3\\,0\\mathsf{P T}+\\epsilon)$ -far from $P$ .   \n$\\overline{{\\mathcal{E}_{\\ell}}}:=$ the event that a non-empty $B_{\\ell}$ in Line 25 contains fewer than $\\lceil\\gamma\\cdot\\lvert B_{\\ell}\\rvert\\rceil$ hypotheses that are $(3\\,0\\mathsf{P T}+\\epsilon)$ -far from $P$ . ", "page_idx": 14}, {"type": "text", "text": "Conditioning on the event $\\overline{{\\mathcal{E}_{\\ell}}}$ , fewer than a $\\gamma$ fraction of the hypotheses in $B_{\\ell}$ are far. Since $\\hat{H}$ is a randomly selected hypothesis in $B_{\\ell}$ , the probability of $\\hat{H}$ being far is less than $\\gamma$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbf{Pr}\\Big[\\|\\hat{H}-P\\|_{\\mathrm{TV}}>3\\,0\\mathsf{P T}+\\epsilon\\;\\|\\;\\overline{{\\mathcal{E}_{\\ell}}}\\Big]<\\gamma\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Next, we focus on the case where $\\mathscr{E}_{\\ell}$ holds: at least a $\\gamma$ fraction of the hypotheses in $B_{\\ell}$ are $(3\\,0\\mathsf{P T}+\\epsilon)$ -far from $P$ . In the following lemma, we show that $H_{i^{*}}$ is a prompting hypothesis for such a $B_{\\ell}$ . The proof of this lemma is available in Section A.2. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.1. Suppose $B_{\\ell}\\subseteq{\\mathcal{H}}$ is the smallest non-empty bucket for which at least a $\\gamma$ fraction of its hypotheses are $(3\\,0\\mathsf{P T}+\\epsilon)$ -far from $P$ . Then $H_{i^{*}}$ is a prompting hypothesis that can remove $a\\gamma$ fraction of the hypotheses in $B_{\\ell}$ . ", "page_idx": 14}, {"type": "text", "text": "If we output a hypothesis in $B_{\\ell}$ , clearly, the prompting hypotheses had failed to empty out the bucket. Therefore, the last time the algorithm was iterating over all $i$ \u2019s in $[n]$ , the IS-PROMPTING procedure returned false for every single $H_{i}$ , and no \u201crestart\u201d happened. However, during those iterations, at some point, $i$ reached $i^{*}$ , implying that the IS-PROMPTING procedure did not catch that $H_{i^{*}}$ is a prompting hypothesis. This event happens with probability at most $\\delta_{f n}$ . ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{Pr}[\\mathcal{E}_{\\ell}]\\leq\\mathbf{Pr}\\big[\\mathrm{Is\\mathrm{-}P R O M P T I N G\\ r e t u r n s~f a1s e\\ f o r\\ }H_{i^{*}}\\mathrm{~and\\}H_{i^{*}}\\mathrm{~is~a~prompting~hypothesis}\\big]}\\\\ &{\\qquad\\qquad\\leq\\mathbf{Pr}\\big[\\mathrm{Is\\mathrm{-}P R O M P T I N G\\ r e t u r n s~f a1s e\\ f o r\\ }H_{i^{*}}\\mathrm{~is~a~prompting~hypothesis}\\big]\\leq\\delta_{f n}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Given Equation (4) and Equation (5), we bound the probability of outputting a far $\\hat{H}$ as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{Pr}\\Big[\\mathrm{Ouputing~}\\hat{H}\\mathrm{~and~}\\|\\hat{H}-P\\|_{\\mathrm{T}}>3\\,0\\mathrm{PT}+\\epsilon\\Big]}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{\\ell=1}^{k}\\mathbf{Pr}\\Big[\\|\\hat{H}-P\\|_{\\mathrm{T}}>3\\,0\\mathrm{PT}+\\epsilon\\,\\big|\\,\\mathcal{E}_{\\ell}\\Big]\\cdot\\mathbf{Pr}\\big[\\mathcal{E}_{\\ell}\\big]}\\\\ &{\\qquad\\qquad+\\displaystyle\\sum_{\\ell=1}^{k}\\mathbf{Pr}\\Big[\\|\\hat{H}-P\\|_{\\mathrm{T}}>3\\,0\\mathrm{PT}+\\epsilon\\,\\big|\\,\\mathcal{E}_{\\ell}\\Big]\\cdot\\mathbf{Pr}\\big[\\mathcal{E}_{\\ell}\\big]}\\\\ &{\\qquad\\leq\\displaystyle\\sum_{\\ell=1}^{k}\\mathbf{Pr}\\big[\\mathcal{E}_{\\ell}\\big]+\\displaystyle\\sum_{\\ell=1}^{k}\\gamma\\cdot\\mathbf{Pr}\\big[\\mathcal{E}_{\\ell}\\big]}\\\\ &{\\qquad\\leq k\\cdot\\mathcal{S}\\rho_{n}+\\gamma\\leq2\\delta^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Bounding the overall error probability: We have shown that if we output H\u02c6, it is an acceptable answer with high probability. Now, we need to show that the overall error probability of the algorithm is not too high as well. ", "page_idx": 15}, {"type": "text", "text": "Our first claim is that the algorithm always ends, meaning that we do not restart the \u201cfor\u201d loop infinitely many times in Line 24. Note that the restart happens only after we check that at least $\\gamma/2$ of the hypotheses are removed from $B_{\\ell}$ in Line 22. Therefore, the total number of restarts for any given bucket is at most $\\log_{1/(1-\\gamma/2)}(|B_{\\ell}|)+1\\leq4\\log(n)/\\gamma$ times. ", "page_idx": 15}, {"type": "text", "text": "In addition, we claim the algorithm does not end without outputting $\\hat{H}$ or $\\perp$ . Every $H_{i}$ belongs to some bucket at every step of the algorithm. This is due to the assumption that $\\hat{w}_{j}(H_{i})$ is in $[0,1]$ . Thus, $\\tilde{W}(H_{i})$ is always between $0\\le\\tilde{W}(H_{i})\\le1<k\\epsilon^{\\prime}$ . Thus, it is not possible to reach $|B_{\\ell}|=0$ for all $\\ell\\in[k]$ in Line 25. For the bucket that cannot be emptied out, the algorithm outputs either $\\bot$ or $\\hat{H}$ . ", "page_idx": 15}, {"type": "text", "text": "Next, we show that the probability of outputting $\\bot$ is at most $\\delta^{\\prime}$ . Note that the algorithm outputs $\\bot$ when $H_{i}$ was not able to remove at least $\\gamma/2$ of the hypotheses in $B_{\\ell}$ . As we have established earlier, the restart happens only $4\\log(n)/\\gamma$ times for every bucket. Therefore, the IS-PROMPTING procedure is invoked at most $4k n\\log(n)/\\gamma$ times overall. Each time we have a chance of $\\delta_{f p}$ of declaring a hypothesis prompting erroneously. The algorithm in Line 22 checks if the error has happened, and it outputs $\\bot$ when it does. Hence, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{Pr}[\\mathrm{Outputting~}\\bot]\\leq\\frac{4k n\\log(n)}{\\gamma}\\cdot\\delta_{f p}\\leq\\delta^{\\prime}\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The final inequality follows from setting $\\delta_{f p}=\\gamma\\cdot\\delta^{\\prime}/(4\\,k\\,n\\,\\log(n))$ . Thus, we can bound the overall error probability as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{Pr}[\\mathrm{Wrong~answer}]=\\mathbf{Pr}[\\mathrm{Outputting~}\\bot]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\mathbf{Pr}\\Big[\\mathrm{Outputing~}\\hat{H}\\mathrm{~s.t.~}\\lVert\\hat{H}-P\\rVert_{\\mathrm{TV}}>3\\,0\\mathbf{PT}+\\epsilon\\Big]\\le3\\,\\delta^{\\prime}\\le\\delta\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The last inequality holds since $\\delta^{\\prime}=\\delta/3$ . ", "page_idx": 15}, {"type": "text", "text": "Running time: The initialization takes $O(n\\!+\\!k)$ time. The algorithm runs over $k$ buckets. For each bucket, we may restart the \u201cfor\u201d loop $O(\\log(n)/\\gamma)$ times. Within each \u201cfor\u201d loop before restarting, we invoke the IS-PROMPTING procedure $O(n)$ times where, with the exception of one of them, all return false. Let $T_{\\mathtt{f a l s e}}^{(i)}$ indicate the time that the procedure spends on $H_{i}$ in the false case. Also, set this quantity be $T_{\\mathrm{true}}$ if the procedure returns true (which happens at most once before restarting). If we find a prompting hypothesis, we query the $\\hat{w}_{i}(H_{j})$ \u2019s $O(n)$ times, and spend $O(n\\cdot T_{q})$ for this step. Hence, the total time complexity is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{Total\\time\\complexity}\\ ={\\cal O}\\left(k\\cdot\\frac{\\log(n)}{\\gamma}\\cdot\\left(\\sum_{i}^{n}T_{\\mathrm{false}}^{(i)}+T_{\\mathrm{true}}+n\\cdot T_{q}\\right)\\right)\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Advanced version of IS-PROMPTING: We described the guarantees of the advanced version of the IS-PROMPTING procedure in Lemma A.3. In that lemma, we have shown that the running time of the false case is proportionate to the number of hypotheses we remove from $B_{\\ell}$ during the procedure of IS-PROMPTING. We denote this quantity in the $r$ -th search for the prompting hypothesis $H_{i}$ in bucket $b_{\\ell}$ via n(r\u2113,i). Since the total number of hypotheses that we can remove is at most O(n), we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i}^{n}T_{\\mathrm{false}}^{(i)}=\\sum_{i}^{n}O\\left(\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\Big(\\delta_{f p}^{-1}\\Big)\\right)\\cdot T_{q}/\\gamma^{2}+n_{r}^{(\\ell,i)}\\cdot T_{q}/\\gamma\\right)}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ =O\\left(n\\cdot\\left(\\log\\Big(\\delta_{f n}^{-1}\\Big)+\\log\\log\\Big(\\delta_{f p}^{-1}\\Big)\\right)\\cdot T_{q}/\\gamma^{2}+n\\cdot T_{q}/\\gamma\\right)}\\\\ &{=O\\left(n\\cdot\\left(\\log\\Big(\\delta_{f n}^{-1}\\Big)+\\log\\log\\Big(\\delta_{f p}^{-1}\\Big)\\right)\\cdot T_{q}/\\gamma^{2}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using the setting of our parameters, $\\delta_{f p}\\,=\\,\\gamma\\cdot\\delta^{\\prime}/(4\\,k\\,n\\,\\log(n))\\,=\\,O(n\\,\\log n/(\\delta\\,\\epsilon))$ and $\\delta_{f n}\\,=$ $\\delta^{\\prime}/k\\stackrel{\\triangledown}{=}O(1/(\\delta\\,\\overline{{\\epsilon}}))$ . ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\sum_{i}^{n}T_{\\mathrm{false}}^{(i)}=O\\left(\\frac{n}{\\delta^{2}}\\cdot\\left(\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)+\\log\\log\\left(\\frac{n}{\\delta\\,\\epsilon}\\right)\\right)\\cdot T_{q}\\right)}\\\\ {\\displaystyle=O\\left(\\frac{n}{\\delta^{2}}\\cdot\\left(\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)+\\log\\log\\left(n\\right)\\right)\\cdot T_{q}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, for the case that a prompting hypothesis is found: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{T_{\\mathrm{true}}=O\\left(\\log\\left(\\delta_{f p}^{-1}\\right)\\cdot\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\left(\\delta_{f p}^{-1}\\right)\\right)\\cdot T_{q}/\\gamma^{2}\\right)}\\\\ &{\\qquad=O\\left(\\frac{1}{\\delta^{2}}\\cdot\\log\\left(\\frac{n}{\\delta\\,\\epsilon}\\right)\\cdot\\left(\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)+\\log\\log\\left(\\frac{n}{\\delta\\,\\epsilon}\\right)\\right)\\cdot T_{q}\\right)}\\\\ &{\\qquad=O\\left(\\frac{1}{\\delta^{2}}\\cdot\\log\\left(\\frac{n}{\\delta\\,\\epsilon}\\right)\\cdot\\left(\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)+\\log\\log\\left(n\\right)\\right)\\cdot T_{q}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence, the total time complexity is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Total~time~complexity}\\:=\\:O\\left(k\\cdot\\frac{\\log(n)}{\\gamma}\\cdot\\left(\\sum_{i}^{n}T_{\\mathrm{false}}^{(i)}+T_{\\mathrm{true}}+n\\cdot T_{q}\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=O\\left(\\frac{\\log(n)}{\\delta^{3}\\,\\epsilon}\\cdot\\left(n\\cdot\\log\\log n+n\\cdot\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)+\\left(\\log\\left(\\frac{1}{\\delta\\,\\epsilon}\\right)\\right)^{2}\\right)\\cdot T_{q}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\tilde{O}\\left(\\frac{n}{\\delta^{3}\\,\\epsilon}\\cdot T_{q}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Simple version of IS-PROMPTING: In this version, we only have one possible confidence parameter, which is $\\operatorname*{min}(\\delta_{f n},\\delta_{f p})$ . Hence, using Lemma A.2, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\nT_{\\mathbf{false}}^{(i)}=T_{\\mathbf{true}}=O\\left(\\log\\left((\\operatorname*{min}(\\delta_{f n},\\delta_{f p}))^{-1}\\right)\\cdot T_{q}/\\gamma^{2}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Total\\time\\complexity\\}=O\\left(k\\cdot\\frac{\\log(n)}{\\gamma}\\cdot\\left(\\displaystyle\\sum_{i}^{n}T_{\\sf f a l s e}^{(i)}+T_{\\sf t r u e}+n\\cdot T_{q}\\right)\\right)}\\\\ &{\\hphantom{T_{\\rho}}=O\\left(n\\cdot\\frac{\\log(n)}{\\delta^{3}\\,\\epsilon}\\cdot\\left(\\log\\left(\\frac{n}{\\delta\\,\\epsilon}\\right)\\right)\\cdot T_{q}\\right)}\\\\ &{\\hphantom{T_{\\rho}}=\\tilde{O}\\left(\\frac{n}{\\delta^{3}\\epsilon}\\cdot T_{q}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, the proof is complete. ", "page_idx": 16}, {"type": "text", "text": "A.1 Identifying prompting hypothesis ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we provide two algorithms for identifying a prompting hypothesis. The simple algorithm, presented in Section A.1.1, involves sampling the hypotheses in a bucket to estimate the fraction of the hypotheses that $H_{i}$ can move, using a standard application of the Hoeffding bound. The advanced algorithm, presented in Section A.1.2, is based on the fact that we require different confidence parameters for false negative and false positive errors, given our analysis for Algorithm 1. We also show that the time complexity of this algorithm, in the case it returns false, is proportional to the number of hypotheses we can remove from the bucket during this procedure, which later helps us to use an amortized argument for the overall time spent on false returns. ", "page_idx": 17}, {"type": "text", "text": "A.1.1 Simple version of IS-PROMPTING ", "text_level": 1, "page_idx": 17}, {"type": "table", "img_path": "Skv26JteFz/tmp/a415678e0b77ca5e6e9e2aea0e291f8dacce655574b647c61d7fb1d5cf83e969.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Lemma A.2. Suppose we are given two parameters $\\delta,\\epsilon^{\\prime}\\ \\in\\ (0,1)$ , and three positive integers $n,\\ k,$ , and $\\ell\\,\\in\\,[k]$ . Assume we are given a class of hypotheses $\\mathcal{H}$ , its partition into $k$ buckets $\\boldsymbol{B}\\,=\\,\\{B_{1},B_{2},\\ldots,B_{k}\\},$ , and a hypothesis $H_{i}\\,\\in\\,{\\mathcal{H}}$ . The IS-PROMPTING-SIMPLE procedure in Algorithm 2 receives $\\mathcal{H},\\mathcal{B},\\mathcal{l},H_{i},\\delta_{f p},\\delta_{f n}$ , and $\\epsilon^{\\prime}$ as its input and returns true or false with the following guarantees: ", "page_idx": 17}, {"type": "text", "text": "\u2022 If $H_{i}$ substantially updates at least $a\\,\\gamma$ -fraction of the hypotheses in $B_{\\ell}$ , then IS-PROMPTINGSIMPLE returns true with probability at least $1-\\delta$ .   \n\u2022 If $H_{i}$ substantially updates less than a $\\gamma/2$ -fraction of the hypotheses in $B_{\\ell}$ , then ISPROMPTING-SIMPLE returns false with probability at least $1-\\delta$ .   \n\u2022 We have the following guarantees for the algorithm: Number of queries to $\\hat{w}_{i}(H_{j})^{\\prime}s\\colon O\\left(\\log(\\delta^{-1})/\\gamma^{2}\\right)$ , Running time: $O\\left(\\log(\\delta^{-1})\\cdot T_{q}/\\gamma^{2}\\right)$ , where $T_{q}$ is the time to obtain each $\\hat{w}_{j}(H_{i})$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. This is a simple application of the Hoeffding bound: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{Pr}\\Big[\\left|\\frac{u}{t}-\\mathbf{E}\\Big[\\frac{u}{t}\\Big]\\right|\\geq\\frac{\\gamma}{4}\\right]\\leq2\\exp\\left(-2\\,t\\,\\gamma^{2}\\right)\\leq\\delta\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "A.1.2 Advanced version of IS-PROMPTING ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We present an overview of the algorithm for the advanced version of IS-PROMPTING. Suppose we are given a parameter $\\gamma$ , and our goal is to design an algorithm that does the following with high probability: it returns true when $H_{i}$ can substantially update a $\\gamma$ -fraction of the hypotheses in $B_{\\ell}$ , and it returns false when $H_{i}$ can substantially update less than a $\\gamma/2$ fraction of the hypotheses in $B_{\\ell}$ . ", "page_idx": 17}, {"type": "text", "text": "For this new procedure, we take advantage of an asymmetry that exists between returning false and true. This asymmetry arises mainly from the analysis of Algorithm 1. Roughly speaking, for every bucket $\\ell$ , to find a single prompting hypothesis, we check $O(n)$ (potentially non-prompting) hypotheses. On the other hand, we only need $\\log_{1/\\gamma}(B_{\\ell})$ prompting hypotheses to empty out the whole bucket. Hence, we expect that the procedure returns mostly false rather than true. ", "page_idx": 18}, {"type": "text", "text": "Another difference here is the cost we pay for mistakenly declaring true or false. When we declare a hypothesis prompting, we iterate over all hypotheses in $B_{\\ell}$ and check if we can remove them from the bucket. If the hypothesis was not actually prompting, we have paid a substantial cost (in time) without making progress. Thus, we cannot have too many hypotheses that the algorithm declares prompting while they are not (false positives). However, the probability of mistakenly missing a prompting hypothesis does not have to be this small (false negatives). ", "page_idx": 18}, {"type": "text", "text": "Below is a more precise definition of these errors: ", "page_idx": 18}, {"type": "text", "text": "\u03b4fp := Pr[[[Returning true | $H_{i}$ substantially updates less than a $\\gamma/2$ fraction]]] $\\delta_{f n}:=\\mathbf{Pr}[\\$ Returning false | $H_{i}$ substantially updates at least a $\\gamma$ fraction]]] ", "page_idx": 18}, {"type": "text", "text": "Given the analysis of our algorithm, we can show that the probability of false positives must be around $\\tilde{O}(1/\\,|\\bar{B}_{\\ell}|)=\\tilde{O}(1/n)$ . On the other hand, our analysis is robust as long as the probability of false negatives is roughly $O(\\delta)$ , where $\\delta$ is the overall confidence of our algorithm. (The reason for this choice of parameter may not be obvious from this high-level discussion; however, it is a direct artifact of our analysis.) This gap is particularly large when $\\delta$ is a small constant, as is common in the literature. ", "page_idx": 18}, {"type": "text", "text": "The IS-PROMPTING procedure (Algorithm 3) is designed in a way that has different time complexities depending on its output being true or false. The procedure uses more than ${\\cal O}(\\log n)$ (more like $O(\\log n\\cdot\\mathrm{{log}}(1/\\delta)/\\dot{\\gamma^{2}}))$ time if it returns true. However, the main advantage is that it uses much less time when the output is false. In fact, instead of paying ${\\cal O}(\\log n)$ , we only spend $O(\\log(1/\\delta))$ time plus an amortized cost of $O(1/\\gamma)$ for the $O(B_{\\ell})$ calls to the procedure. ", "page_idx": 18}, {"type": "text", "text": "The algorithm runs in roughly $O(\\log n)$ rounds. In each round, it draws a few random hypotheses from $B_{\\ell}$ (roughly $O(\\log(1/\\delta)/\\gamma^{2});$ ). In each round, we check if the fraction of hypotheses $H_{i}$ can substantially update is close to $\\gamma$ . At any round, if we see that the fraction is not close to $\\gamma$ , we return false. The hope is that for a non-prompting hypothesis, we either stop very quickly or the hypothesis passes too many rounds without us noticing that it is not prompting. Therefore, we must have seen an inflated number of substantial updates in these rounds. Before returning false, we perform those substantial updates among the sampled hypotheses that we have observed to remove those movable hypotheses from $B_{\\ell}$ . ", "page_idx": 18}, {"type": "text", "text": "We can capitalize on this fact in our cost analysis. In fact, we can show that in the false case, if the procedure takes roughly $O(t/\\gamma)$ time, it must have removed $t$ hypotheses from the bucket. Thus, one can show that the amortized cost of these elongated rounds is only $O(1/\\gamma)$ .6 ", "page_idx": 18}, {"type": "text", "text": "Lemma A.3. Suppose we are given three parameters $\\delta_{f p},\\delta_{f n},\\epsilon^{\\prime}\\in(0,1)$ , and three positive integers $n,\\ k_{\\mathrm{~\\,~}}$ , and $\\ell\\,\\in\\,[k]$ . Assume we are given a classes of hypotheses $\\mathcal{H}$ , its partition into $k$ buckets $\\boldsymbol{\\mathcal{B}}=\\{B_{1},B_{2},\\ldots,B_{k}\\}$ and a hypothesis $H_{i}\\in{\\mathcal{H}}$ . The IS-PROMPTING procedure in Algorithm 3 receives $\\mathcal{H},\\mathcal{B},\\ell,H_{i},\\delta_{f p},\\delta_{f n}$ , and $\\epsilon^{\\prime}$ as its input and returns true or false with the following guarantees: ", "page_idx": 18}, {"type": "text", "text": "\u2022 If $H_{i}$ substantially updates at least $\\gamma$ fraction of the hypotheses in $B_{\\ell}$ , then IS-PROMPTING returns true with probability at least $1-\\delta_{f n}$ . ", "page_idx": 18}, {"type": "text", "text": "\u2022 If $H_{i}$ substantially updates less than $\\gamma/2$ fraction of the hypotheses in $B_{\\ell}$ , then ISPROMPTING returns false with probability at least $1-\\delta_{f p}$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 3 An algorithm to identify a prompting hypothesis. ", "page_idx": 19}, {"type": "text", "text": "1: procedure IS-PROMPTING(B, \u2113, Hi, \u03b3, \u03f5\u2032, $\\delta_{f n}$ , $\\delta_{f p}$ , and query access to $\\hat{w}_{j}(H_{i})$ \u2019s)   \n2: R \u2190 log3/2   \n3: S0 \u2190\u2205 \u25b7 $S$ is a set of hypotheses that $H_{i}$ can update substantially.   \n4: for $r=1,\\ldots,R$ do   \n5: if |SrB\u22121|\u2265\u03b32 then   \n6: return true   \n7: $\\begin{array}{r l}&{S_{r}\\gets S_{r-1}}\\\\ &{u_{r}\\gets0}\\\\ &{\\mathbf{repeat}\\ t:=\\left\\lceil\\frac{48\\log(2R/\\delta_{f n})}{\\gamma^{2}}\\right\\rceil\\ \\mathbf{times}}\\\\ &{\\qquad G_{j}^{(r)}\\gets\\mathbf{a}\\,\\mathrm{random}\\ \\mathbf{hypothesis}\\ \\mathbf{in}\\ B_{\\ell}}\\\\ &{\\qquad\\mathbf{if}\\ \\hat{w}_{i}\\left(G_{j}^{(r)}\\right)>\\tilde{W}\\left(G_{j}^{(r)}\\right)+\\epsilon^{\\prime}\\ \\mathbf{then}}\\\\ &{\\qquad u_{r}\\gets u_{r}+1}\\\\ &{\\qquad S_{r}\\gets S_{r}\\cup\\{G_{j}^{(r)}\\}}\\end{array}$   \n8: $\\textsf{D}u_{r}$ indicates # hypotheses $H_{i}$ updates   \n9:   \n10:   \n11:   \n12:   \n13:   \n14:   \n15: if $\\begin{array}{r}{|S_{r}|-|S_{r-1}|<\\frac{\\gamma\\cdot t}{8}}\\end{array}$ then   \n16: 17: for $\\begin{array}{r l}&{\\mathop{\\\"}H_{j}\\in S_{r}\\:\\mathbf{do}}\\\\ &{\\quad\\tilde{W}(H_{j})\\gets\\operatorname*{max}\\left(\\tilde{W}(H_{j}),\\hat{w}_{i}(H_{j})\\right)}\\\\ &{\\mathrm{Move}\\:H_{j}\\mathrm{~to~}B_{\\left[\\tilde{W}(H_{j})/\\epsilon^{\\prime}\\right]}}\\end{array}$   \n18:   \n19: return false   \n20: if utr < 3 4\u03b3 then   \n21: for $\\bar{H_{j}^{'}}\\in S_{r}$ do   \n22: $\\begin{array}{r l}&{\\tilde{\\hat{W}}(H_{j})\\gets\\operatorname*{max}\\Big(\\tilde{W}(H_{j}),\\hat{w}_{i}(H_{j})\\Big)}\\\\ &{\\mathrm{Move}\\;H_{j}\\;\\mathrm{to}\\;B_{\\left\\lceil\\tilde{W}(H_{j})/\\epsilon^{\\prime}\\right\\rceil}}\\end{array}$   \n23:   \n24: return false   \n25: return true ", "page_idx": 19}, {"type": "text", "text": "\u2022 If the algorithm returns true, we have the following guarantees for the algorithm: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r i e s\\;t o\\;\\hat{w}_{i}(H_{j})^{*}s\\colon O\\left(\\log\\left(\\delta_{f p}^{-1}\\right)\\cdot\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\left(\\delta_{f p}^{-1}\\right)\\right)/\\gamma^{2}\\right)\\,,}\\\\ &{O\\left(\\log\\left(\\delta_{f p}^{-1}\\right)\\cdot\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\left(\\delta_{f p}^{-1}\\right)\\right)\\cdot T_{q}/\\gamma^{2}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "\u2022 Suppose the algorithm returns false. Assume (r\u2113,i)indicates the number of hypotheses that the algorithm removes from $B_{\\ell}$ . Then, we have the following guarantees for the algorithm: Number of qu $\\begin{array}{r l}&{e r i e s\\;t o\\;\\hat{w}_{i}(H_{j})^{*}s\\colon O\\left(\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\left(\\delta_{f p}^{-1}\\right)\\right)/\\gamma^{2}+n_{r}^{(\\ell,i)}/\\gamma\\right)\\,,}\\\\ &{\\ O\\left(\\left(\\log\\left(\\delta_{f n}^{-1}\\right)+\\log\\log\\left(\\delta_{f p}^{-1}\\right)\\right)\\cdot T_{q}/\\gamma^{2}+n_{r}^{(\\ell,i)}\\cdot T_{q}/\\gamma\\right)\\,.\\,f}\\end{array}$ Running time: ", "page_idx": 19}, {"type": "text", "text": "In above bounds, where $T_{q}$ denotes the time complexity to obtain each $\\hat{w}_{j}(H_{i})$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. The probabilities in this proof are taken over the random choices of $G_{j}^{(r)}$ \u2019s. Note that $S$ contains at the hypotheses for which we can change. ", "page_idx": 19}, {"type": "text", "text": "Probability of false positive: First, we show that probability of outputting true, while $H_{i}$ can substantially update less $\\gamma/2$ fraction of hypotheses in $B_{\\ell}$ , is at most $\\delta_{f p}$ . The algorithm return true in two places. First, at the beginning of each round, we check whether $S_{r-1}$ contains at least $\\gamma/2$ -fraction of hypotheses. This answer is always correct with probability one. Since the algorithm has an evidence that $H_{i}$ can certainly update at least $\\gamma/2$ of hypotheses in $B_{\\ell}$ . Thus, this case does not affect our false positive rate $\\delta_{f p}$ . ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Second, the algorithm returns true after all rounds end. This case only happens when $u_{r}/t$ is at least $3\\gamma/4$ in every round in Line 20. It is not hard to see that $u_{r}$ is a binomial random variable with $t$ trials. The success probability of each trial is the ratio of the hypotheses in $B_{\\ell}$ that $H_{i}$ can update substantially. Thus, in the case where $H_{i}$ substantially updates less than $\\gamma$ fraction of hypotheses, by Markov\u2019s inequality, we have: ", "page_idx": 20}, {"type": "text", "text": "Pr[[[Returning true $\\mid H_{i}$ substantially updates less than $\\gamma/2$ -fraction]]] ", "page_idx": 20}, {"type": "equation", "text": "$$\n=\\mathbf{Pr}\\left[\\forall r\\in[R]:\\frac{u_{r}}{t}\\geq\\frac{3\\gamma}{4}\\right]\\left(\\mathbf{Pr}\\left[\\frac{u_{r}}{t}\\geq\\frac{3\\gamma}{4}\\right]\\right)^{R}\\leq(2/3)^{R}\\leq\\delta_{f p}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Probability of false negative: Suppose that $H_{i}$ substantially updates at least $\\gamma$ -fraction of the hypotheses in $B_{\\ell}$ . That is, $H_{i}$ can update each $G_{j}^{(r)}$ with probability at least $\\gamma$ . Fix a round $r$ . We bound the probability of returning false in Line 19 and Line 24. ", "page_idx": 20}, {"type": "text", "text": "In Line 19, we return false when $\\begin{array}{r}{|S_{r}|-|S_{r-1}|<\\frac{\\gamma\\cdot t}{8}}\\end{array}$ . That is, the number of new hypotheses we added to $S_{r}$ is not too large. Consider the random hypotheses we draw at round $r$ . Our claim is that most of these random hypotheses are not in $S_{r-1}$ . The probability that one G(jr)be selected from $S_{r-1}$ is $|S_{r-1}|\\,/\\,|B_{\\ell}|$ . However, this expectation is less than $\\gamma/2$ . Otherwise, the algorithm would have returned true earlier in Line 5. With this information in mind, we can use the Hoeffding bound and get: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\left[\\mathrm{number~of~}G_{j}^{(r)}\\in S_{r-1}\\geq\\frac{5\\,\\gamma\\,\\cdot\\,t}{8}\\right]=\\operatorname*{Pr}\\left[\\frac{\\mathrm{number~of~}G_{j}^{(r)}\\in S_{r-1}}{t}\\geq\\frac{5\\,\\gamma}{8}=\\frac{\\gamma}{2}\\cdot\\left(1+\\frac{1}{4}\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\operatorname*{Pr}\\left[\\frac{\\mathrm{number~of~}G_{j}^{(r)}\\in S_{r-1}}{t}>\\frac{|S_{r-1}|}{|B_{\\ell}|}+\\frac{\\gamma}{4}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\exp\\left(-2\\,t\\,(\\gamma/4)^{2}\\right)\\leq\\frac{\\delta_{f n}}{2\\,R}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In Line 24, we return false if $u_{r}/t$ is less than $3\\,\\gamma/4$ . By Chernoff bound, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{Pr}\\left[\\frac{u_{r}}{t}<\\gamma\\cdot\\left(1-\\frac{1}{4}\\right)\\right]\\le\\exp\\left(-\\frac{t\\,\\gamma}{3\\cdot4^{2}}\\right)=\\frac{\\delta_{f n}}{2\\,R}\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Taking the union bound over all rounds, we obtain: ", "page_idx": 20}, {"type": "text", "text": "Pr[[[Returning false $\\mid H_{i}$ substantially updates at least $\\gamma$ -fraction]]] $\\leq\\delta_{f n}$ . ", "page_idx": 20}, {"type": "text", "text": "Running time: In the case the algorithm return true, the algorithm makes $O(R\\cdot t)$ queries to $\\hat{w}_{i}\\left(G_{j}^{(r)}\\right)$ \u2019s. And, it runs in the ${\\cal O}(R\\cdot t\\cdot T_{q})\\,.$ If algorithm returns false in round $r$ , similarly it makes $O(r\\cdot t)$ queries to $\\hat{w}_{i}\\left(G_{j}^{(r)}\\right)$ \u2019s. And, it runs in the ${\\cal O}(r\\cdot t\\cdot T_{q})$ . Note that with the exception of the last round in every round $r^{\\prime}\\in[r-1]$ . At least $(\\gamma\\cdot t)/8$ new hypotheses are added to $S_{r^{\\prime}}$ . Therefore, the size of $S_{r}$ is at least $(\\boldsymbol{\\gamma}\\cdot\\boldsymbol{t}\\cdot(\\dot{\\boldsymbol{r}}-1))/8$ . We remove all of these hypotheses before we output false which cause the size of $B_{\\ell}$ to drop by $n_{r}^{(\\ell,i)}\\,:=\\,|S_{r}|$ . In this case, the algorithm makes $O(t+n_{r}^{(\\ell,i)}/\\gamma)$ queries to $\\hat{w}_{i}\\left(G_{j}^{(r)}\\right)$ \u2019s. And, it runs in the $O\\left(\\left(t+n_{r}^{(\\ell,i)}/\\gamma\\right)\\cdot T_{q}\\right)$ . Thus, the proof is complete by setting $R:=\\left\\lceil\\log_{3/2}(1/\\delta_{f p})\\right\\rceil$ and $t:=\\lceil48\\log(2R/\\delta_{f n})/\\gamma^{2}\\rceil$ . \u53e3 ", "page_idx": 20}, {"type": "text", "text": "A.2 Proof of Lemma A.1 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Lemma A.1. Suppose $B_{\\ell}\\subseteq{\\mathcal{H}}$ is the smallest non-empty bucket for which at least a $\\gamma$ fraction of its hypotheses are $(3\\,0\\mathsf{P T}+\\epsilon)$ -far from $P$ . Then $H_{i^{*}}$ is a prompting hypothesis that can remove $a\\gamma$ fraction of the hypotheses in $B_{\\ell}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. We show that $H_{i^{*}}$ can substantially update $\\Tilde{W}$ of any far hypothesis in $B_{\\ell}$ . Let $H_{f}$ denote a $(3\\,0\\mathsf{P T}+\\epsilon)$ -far hypothesis. First, observe that $\\hat{w}_{i^{*}}$ $\\left(H_{f}\\right)$ must be large compared to ${\\mathsf{O P T}}$ : ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{w}_{i^{*}}\\left(H_{f}\\right)\\geq w_{i^{*}}\\left(H_{f}\\right)-\\epsilon^{\\prime}=\\left|H_{f}\\left(S_{f\\,i^{*}}\\right)-P\\left(S_{f\\,i^{*}}\\right)\\right|-\\epsilon^{\\prime}}\\\\ &{\\qquad\\qquad\\geq\\left|H_{f}\\left(S_{f\\,i^{*}}\\right)-H_{i^{*}}\\left(S_{f\\,i^{*}}\\right)\\right|-\\left|H_{i^{*}}\\left(S_{f\\,i^{*}}\\right)-P\\left(S_{f\\,i^{*}}\\right)\\right|-\\epsilon^{\\prime}}\\\\ &{\\qquad\\qquad\\geq\\left\\|H_{f}-H_{i^{*}}\\right\\|_{\\mathrm{TV}}-\\left\\|H_{i^{*}}-P\\right\\|_{\\mathrm{TV}}-\\epsilon^{\\prime}}\\\\ &{\\qquad\\qquad\\geq\\left\\|H_{f}-P\\right\\|_{\\mathrm{TV}}-2\\left\\|H_{i^{*}}-P\\right\\|_{\\mathrm{TV}}-\\epsilon^{\\prime}}\\\\ &{\\qquad\\qquad>3\\,0\\mathsf{P T}+\\epsilon-2\\,0\\mathsf{P T}-\\epsilon^{\\prime}\\geq0\\mathsf{P T}+2\\,\\epsilon^{\\prime}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "In addition, OPT cannot be much smaller than $\\ell\\,\\epsilon^{\\prime}$ . The main reason is that all the buckets before $B_{\\ell}$ are empty. Hence, $H_{i^{*}}$ belongs to a bucket $B_{\\ell^{\\prime}}$ where $\\ell^{\\prime}$ is at least $\\ell$ . By our definition of bucketing: $\\tilde{W}\\left(H_{i^{*}}\\right)$ must be at least $\\left(\\ell-1\\right)\\epsilon^{\\prime}$ . Hence we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left(\\ell-1\\right)\\epsilon^{\\prime}\\leq\\tilde{W}\\left(H_{i^{*}}\\right)\\leq\\hat{W}(H_{i^{*}})\\leq W(H_{i^{*}})\\leq\\mathsf{O P T}\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Note that we assume $H_{f}$ belongs to $B_{\\ell}$ , so $\\tilde{W}_{f}$ is less than $\\ell{\\epsilon}^{\\prime}$ . Putting all these observation together, we achieve: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\tilde{W}_{f}+\\epsilon^{\\prime}<\\ell\\,\\epsilon^{\\prime}+\\epsilon^{\\prime}\\leq0\\mathsf{P T}+2\\epsilon^{\\prime}<\\hat{w}_{i^{*}}\\left(H_{f}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, if we update $\\tilde{W}_{f}$ via $\\hat{w}_{i^{*}}\\left(H_{f}\\right)$ , then $H_{i^{*}}$ can significantly improve $\\tilde{W}_{f}$ . This fact implies that $H_{i^{*}}$ can removes all the bad hypothesis from $B_{\\ell}$ which concludes the proof of the lemma. ", "page_idx": 21}, {"type": "text", "text": "B Linear time algorithm with $\\alpha=4$ ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we present our second algorithm whose sample complexity has a better dependency on the accuracy parameter $\\epsilon$ . An overview of our approach is presented in Section 3.3. The pseudocode of our approach is presented in Algorithm 4. We prove the performance of this algorithm in Theorem 6. ", "page_idx": 21}, {"type": "text", "text": "Apart from improving the accuracy parameters, we also provide modifications to our algorithm that can achieve low rounds of adaptivity (roughly speaking, it means the number of times the algorithm needs to look at the sample set). More formally, in our access model, we define one round of adaptivity as follows: The algorithm selects a set of $t\\\"=O(n^{2})$ pairs of indices $\\{(i_{\\ell},j_{\\ell})\\}_{\\ell\\in[t]}$ and query all $\\hat{w}_{j\\ell}\\left(H_{i_{\\ell}}\\right)$ at once. The number of adaptivity rounds represents the total count of times the algorithm needs to repeat this process in order to produce its final output. This is particularly interesting when considering a federated learning setting in which the rounds of interactivity are important. The modification of our algorithm runs in time $O(n^{1+\\lambda})$ runs in $O(1/\\lambda)$ rounds of adaptivity. ", "page_idx": 21}, {"type": "text", "text": "Theorem 6. Suppose Algorithm $^{4}$ receives these parameters as input: $\\sigma_{\\mathrm{~\\scriptsize~\\textc~}}\\in\\mathrm{~\\scriptsize~[0,1]~}$ , $\\eta\\ \\in$ $(0,1/4)$ , \u03f5, $\\delta~\\in~(0,1)$ . Also, assume the algorithm has access to a class of $n$ hypotheses $\\mathcal{H}$ , and a set of unmarked hypotheses in $\\mathcal{Q}\\subseteq\\mathcal{H}$ where initially $\\mathcal{Q}=\\mathcal{H}$ . Suppose the algorithm can query $\\hat{w}_{j}(H_{i})$ \u2019s with error at most $\\epsilon^{\\prime}\\leq\\epsilon/6$ . The algorithm has one of the two possible outcomes: either it declares that $\\sigma<\\mathsf{O P T}$ ; or it outputs a hypothesis $H_{i}$ such that: with probability at least $1-\\delta$ we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\hat{H}-P\\|_{T V}\\leq4\\mathrm{~max}\\left(\\sigma,0\\mathsf{P T}\\right)+\\epsilon\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The algorithm runs in ${\\cal O}(n/\\eta\\cdot T_{q})$ time and $O\\left(\\log_{1/\\eta}^{2}(n)\\right)$ rounds of adaptivity. Here $T_{q}$ is the time required to obtain each $\\hat{w}_{j}(H_{i})$ . ", "page_idx": 21}, {"type": "text", "text": "1: procedure SELECT-HYPOTHESIS(H, Q, \u03c3, \u03f5, \u03b4, $\\eta_{\\cdot}$ , , and query access to $\\hat{w}_{j}(H_{i})^{\\circ}\\mathrm{s})$   \n2: if $|\\mathcal{Q}|=0$ then   \n3: return $\\begin{array}{r}{{^{\\star}\\sigma}<\\mathsf{O P T}^{\\bullet}}\\end{array}$ .   \n4: if $|\\mathcal{Q}|=1$ then   \n5: $H_{i}\\leftarrow$ the only unmarked hypothesis left.   \n6: if $\\hat{W}(H_{i})>\\sigma+\\epsilon^{\\prime}$ then   \n7: return $\\begin{array}{r}{{^{\\star}\\sigma}<\\mathsf{O P T}^{\\,,}}\\end{array}$ .   \n8: else   \n9: return $H_{i}$ .   \n10: $\\begin{array}{r l}&{\\epsilon^{\\prime}\\leftarrow\\epsilon/6}\\\\ &{\\delta^{\\prime\\prime}\\leftarrow\\delta/\\left(100\\cdot\\left(\\log_{1/(2\\eta)}(n)\\cdot\\log_{1/(\\eta)}(n)\\right)\\right)}\\\\ &{m\\leftarrow\\lfloor\\eta\\cdot n\\rfloor}\\\\ &{\\mathrm{Run~FIND-SEED}(\\mathcal{H},\\,\\,\\mathcal{Q},\\,\\sigma,\\,\\epsilon^{\\prime},\\,\\delta^{\\prime\\prime},\\,\\eta)}\\end{array}$   \n11:   \n12:   \n13:   \n14: if FIND-SEED declares \u201c $\\prime\\sigma<\\mathsf{O P}7$ \u201d then   \n15: return \u201c $\\begin{array}{r}{\\dot{\\boldsymbol{\\sigma}}<\\mathsf{O P T}^{*}}\\end{array}$ .   \n16: else if FIND-SEED returns \u201cstart over\u201d then   \n17: return SELECT-HYPOTHESIS $(\\mathcal{H},\\,\\mathcal{Q},\\,\\sigma,\\,\\epsilon,\\,\\delta,\\,\\eta)$   \n18: $H_{i}\\gets$ the seed that FIND-SEED found.   \n19: while $\\begin{array}{r}{m>\\frac{1}{\\eta}}\\end{array}$ do   \n20: Run BOOST- $\\cdot\\mathrm{SEED}(\\mathcal{H},\\,\\,\\mathcal{Q},\\,\\,H_{i},\\,\\,\\sigma,\\,\\,\\kappa=2,\\,\\kappa^{\\prime}=2,\\,\\,\\epsilon^{\\prime},\\,\\,\\eta)$   \n21: if BOOST-SEED finds the final answer. then   \n22: return $H_{i}$ found by BOOST-SEED.   \n23: else if BOOST-SEED finds a new seed then   \n24: $H_{i}\\gets$ the seed that BOOST-SEED returns   \n25: $m\\leftarrow\\lfloor\\eta\\cdot m\\rfloor$   \n26: else if BOOST-SEED returns \u201cstart over\u201d then   \n27: return SELECT-HYPOTHESIS $(\\mathcal{H},\\,\\,\\mathcal{Q},\\,\\,s,\\,\\,\\sigma,\\,\\epsilon,\\,\\,\\delta)$   \n28: $H_{\\ell}\\gets\\arg\\operatorname*{min}_{H_{j}\\in\\mathcal{M}}\\hat{W}(H_{j})$ \u25b7M denotes $\\mathcal{M}_{2\\,\\sigma+\\epsilon^{\\prime}}$ , $4\\,\\sigma{+}5\\,\\epsilon^{\\prime}\\bigl(H_{i}\\bigr)$ .   \n29: if $\\hat{W}(H_{\\ell})\\le2\\,\\sigma+\\,\\epsilon^{\\prime}$ then   \n30: Output $H_{\\ell}$ .   \n31: else   \n32: Output $H_{i}$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. For the sake of argument, assume each of the sub-routines in the algorithm works as guaranteed with probability one (as oppose to the case where they work as expected with probability $1-\\delta^{\\prime\\prime})$ . Later on, we discuss the overall confidence of the algorithm to remove this assumption. ", "page_idx": 22}, {"type": "text", "text": "Accuracy of seeds: the procedure to find the initial seeds provides us with a $(\\sigma+\\epsilon^{\\prime},3\\,\\sigma+3\\epsilon^{\\prime},m)\\/$ - seed with high probability. Using Fact C.4, this seed is also a $(2\\,\\sigma\\!+\\!\\epsilon^{\\prime},4\\,\\sigma\\!+\\!5\\epsilon^{\\prime},m)$ . In boosting seeds, we start with $(\\bar{2}\\,\\sigma+\\epsilon^{\\prime},\\bar{4}\\,\\sigma+5\\bar{\\epsilon^{\\prime}},m)$ and we get $(2\\,\\sigma+\\epsilon^{\\prime},4\\,\\sigma+5\\epsilon^{\\prime},m^{\\prime})$ where $m^{\\prime}=\\lfloor\\eta\\cdot m\\rfloor$ . This statement is justified by Theorem 9, setting $\\kappa=\\kappa^{\\prime}=2$ , and using the same values for $\\bar{a}=2,\\bar{\\sigma}+\\epsilon^{\\prime}$ and $b=4,\\sigma+5\\epsilon^{\\prime}$ for our seeds. It is worth noting that the only parameter that changes while we boost is $m$ . ", "page_idx": 22}, {"type": "text", "text": "Accuracy of the output Consider the case where we produce output when $|\\mathcal{Q}|$ is zero. That implies that our algorithm marked all the hypotheses. Throughout the course of algorithms, we never mark a hypothesis $H_{i}$ unless we have found an evidence that $\\|H_{i}-P\\|_{\\mathrm{TV}}>\\sigma$ . This was established by observing $\\hat{w}_{j}(H_{i})>\\sigma+\\epsilon^{\\prime}$ , which implies $\\|H_{i}-P\\|_{\\mathrm{TV}}$ must be greater than $\\sigma$ ; Or, showing a close-by hypotheses to $H_{i}$ is far from $P$ and apply triangle inequality. See our argument for Case 3.2 in the proof of Theorem 9 for example. Thus, if all hypotheses are marked, it must be the case that for every $H_{i}$ , $\\|H_{i}-P\\|_{\\mathrm{TV}}$ is greater than $\\sigma$ . Hence, when the size of $\\mathcal{Q}$ is zero we can truly assert that \u201c $\\begin{array}{r}{{\\mathsf{\\Sigma}}\\sigma<0{\\mathsf{P}}{\\mathsf{T}}^{\\bullet}}\\end{array}$ . ", "page_idx": 22}, {"type": "text", "text": "For the case that $|\\mathcal{Q}|=1$ , the algorithm focuses on $H_{i}$ , the only unmarked hypothesis left. If we found $\\hat{W}(H_{i})$ is greater than $\\sigma+\\epsilon^{\\prime}$ , we can simply conclude that for every $H_{i}$ , $\\|H_{i}-P\\|_{\\mathrm{TV}}$ is greater than $\\sigma$ , and ${\\begin{array}{r}{\\overleftarrow{\\boldsymbol{\\sigma}}}<0P\\top^{\\ast}}\\end{array}}$ . Otherwise, using Fact C.3, the $H_{i}$ is a valid answer: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|H_{i}-P\\|_{\\operatorname{TV}}\\leq W(H_{i})+20\\mathsf{P T}\\leq\\hat{W}(H_{i})+\\epsilon^{\\prime}+20\\mathsf{P T}\\leq3\\,\\operatorname*{max}\\left(\\sigma,0\\mathsf{P T}\\right)+2\\epsilon^{\\prime}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In addition, the accuracy of the $H_{i}$ that is returned in Line 22 is guaranteed by the Theorem 9, and setting $\\kappa=\\kappa^{\\prime}=2$ . Next, lets focus on the hypotheses we output after the \u201cif\u201d condition in Line 29. When $\\hat{W}(H_{\\ell})$ is small, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{\\ell}{-}P\\|_{\\operatorname{TV}}\\leq W(H_{\\ell}){+}20\\mathsf{P T}\\leq\\hat{W}(H_{\\ell}){+}\\epsilon^{\\prime}{+}20\\mathsf{P T}\\leq2\\,\\sigma{+}2\\epsilon^{\\prime}{+}20\\mathsf{P T}\\leq4\\operatorname*{max}{(\\sigma,0\\mathsf{P T})}{+}2\\epsilon^{\\prime}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "When $\\hat{W}(H_{\\ell})$ is large, the analysis is very similar to Case 1 in the proof of Theorem 9. Again, by setting $\\kappa=\\kappa^{\\prime}=2$ , and using the facts that $\\hat{W}(H_{\\ell})-\\epsilon^{\\prime}\\geq\\kappa^{\\prime}\\sigma$ and $\\hat{W}(H_{i})\\le(\\kappa+2)\\,\\sigma+5\\,\\epsilon^{\\prime}$ , we obtain: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|H_{i}-P\\|_{\\mathrm{TV}}\\leq4\\,\\operatorname*{max}\\left(\\sigma,0\\mathrm{PT}\\right)+6\\epsilon^{\\prime}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Number of recursions: Given Theorem 8 and Theorem 9, we only see \u201cstart over\u201d when $(1-2\\eta)$ fraction of unmarked hypotheses in $\\mathcal{Q}$ have been marked. Since we have $n$ hypotheses, we do not start over more than $O(\\bar{\\log_{1/\\eta}}(n))$ times. ", "page_idx": 23}, {"type": "text", "text": "Running time: In the while loop, $m$ decreases with a factor of $\\eta$ every time we find a new seed. Hence, the total number of iterations is bounded by $O(\\log_{1/\\eta}(n))$ . Using Theorem 8 and Theorem 9, invoking the procedures for finding a seed and boosting a seed each takes $O(n\\log(n/\\delta^{\\prime\\prime})/\\eta\\cdot T_{q})$ time. Thus, the total time complexity is: ", "page_idx": 23}, {"type": "equation", "text": "$$\nO\\left(\\frac{n}{\\eta}\\cdot\\left(\\log(n/\\delta)+\\log\\log_{1/\\eta}(n)\\right)\\cdot\\log_{1/\\eta}^{2}(n)\\cdot T_{q}\\right)=\\tilde{O}\\left(\\frac{n\\cdot\\log(1/\\delta)\\cdot T_{q}}{\\eta}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Overall confidence parameter: The total number of subroutines we call here is at most $O(\\log_{1/\\eta}^{2}(n))$ . Thus, by setting $\\delta^{\\prime\\prime}$ to $O(\\delta/\\log_{1/\\eta}^{2}(n))$ and using the union bound, we can show the overall error probability is bounded by $\\delta$ . ", "page_idx": 23}, {"type": "text", "text": "Rounds of adaptivity: Using Theorem 8 and Theorem 9, invoking the procedures for finding a seed and boosting a seed each takes $O(1)$ rounds of adaptivity. Hence, the overall rounds of adaptivity is $O\\left(\\log_{1/\\eta}^{2}(n)\\right)$ rounds. ", "page_idx": 23}, {"type": "text", "text": "Remark 7. One could argue that we have demonstrated the algorithm operates in $\\tilde{O}(n/\\eta\\cdot T_{q})$ time with a probability of $1-\\delta$ . However, this fact does not inherently guarantee that the algorithm consistently maintains the desired time complexity. Fortunately, a straightforward solution exists to address this concern. ", "page_idx": 23}, {"type": "text", "text": "Our algorithm may fail for two primary reasons: either too few hypotheses were marked, or the identified seed had a larger m value than anticipated. In either scenario, the algorithm can verify the occurrence of this undesirable, but improbable event. In these situations, we can output $\\bot$ to indicate the algorithm\u2019s failure to produce a valid answer. With this adjustment, the time complexity remains low as desired. ", "page_idx": 23}, {"type": "text", "text": "Corollary B.1. Suppose $\\mathcal{H}$ is a class of n known hypotheses and $P$ is an unknown hypothesis. Let $\\epsilon$ and \u03b4 be two parameters in $(0,1)$ . Assume the algorithm has access to accurate estimates of $\\hat{w}_{j}(H_{i})\\,\\gamma_{s}$ that have error at most $\\epsilon^{\\prime}$ . If $3\\,\\epsilon^{\\prime}\\,\\le\\,\\epsilon$ , then for every $\\eta\\in(1/n,1/4)$ there exists an $(\\alpha=4,\\epsilon,\\delta)$ )- proper learner for $P$ in $\\mathcal{H}$ . The running time of our algorithm is $\\tilde{O}((n/\\eta)\\cdot\\log(1/\\delta)\\cdot\\log(1/\\epsilon)\\cdot T_{q})$ , and it can be implemented in $O\\left(\\log_{1/\\eta}^{2}(n)\\cdot\\log(1/\\epsilon)\\right)$ rounds of adaptivity. ", "page_idx": 23}, {"type": "text", "text": "Proof. This is a direct corollary of Theorem 6 combined with a binary search over values of $\\sigma\\in$ $\\{\\epsilon^{\\prime},\\bar{\\epsilon^{\\prime}}\\}$ where $\\epsilon^{\\prime}:=\\epsilon/100$ . Note that for every $\\sigma\\geq0\\mathsf{P T}$ , the algorithm has to produce a hypothesis, since it cannot declare $\\mathsf{O P T}<\\sigma$ with high probability. Outputting the hypothesis associated with the smallest $\\sigma$ would give us the desired guaranteed. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "B.1 Finding initial seed ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we describe an algorithm that receives parameter $\\sigma$ as input and finds a $(\\sigma+\\epsilon^{\\prime},\\,3\\,\\sigma+$ $2\\epsilon^{\\prime}$ , $\\lfloor\\eta\\cdot n\\rfloor$ )-seed in roughly $\\bar{O}(\\bar{n}/\\eta\\cdot T_{q})$ time with high probability or declares \u201c $\\begin{array}{r}{\\mathcal{\\sigma}<\\mathsf{O P T}\"}\\end{array}$ . ", "page_idx": 24}, {"type": "table", "img_path": "Skv26JteFz/tmp/63c0a8d6670bde63c1f9329802304a7441ac7c16e22e5256429be62887bbc540.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Theorem 8. Suppose that we are given a class of $n$ hypotheses, $\\mathcal{H}$ , a rate parameter $\\eta\\in(0,1/4)$ , two parameters $\\sigma,\\delta\\in(0,1)$ , and we have access to $\\hat{w}_{j}(H_{i})$ with error at most $\\epsilon^{\\prime}$ for every $i,j\\in[n]$ . Algorithm 5 queries $O\\left(n\\log(n/\\delta)/\\eta\\right))$ many $w_{i}(\\hat{H}_{j})$ and runs in $O\\left((n\\log(n/\\delta)/\\eta)\\cdot T_{q}\\right)$ time. Also, it can be implemented in $O(1)$ rounds of adaptivity. This algorithm returns a hypothesis $H_{\\ell}$ , declares $\\sigma<\\mathsf{O P T}$ , or returns \u201cstart over\u201d for which the following guarantees hold with probability $1-\\delta$ : ", "page_idx": 24}, {"type": "text", "text": "\u2022 $I f\\sigma\\geq\\mathsf{O P T}$ , then the algorithm does not declare that $\\sigma$ is less than OPT.   \n\u2022 If the algorithm returns a hypotheses $H_{\\ell}$ , then $H_{\\ell}$ is $\\iota\\left(\\sigma+\\epsilon^{\\prime},\\,3\\,\\sigma+3\\,\\epsilon^{\\prime},\\,m\\right)$ -seed where $m:=\\lfloor\\eta\\cdot n\\rfloor$ .   \n\u2022 If the algorithm returns \u201cstart over.\u201d with probability $1-\\delta$ , it marks $(1-2\\eta)$ fraction of the hypotheses in $\\mathcal{Q}$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. Our first claim is that if $\\sigma$ is at least OPT, then we do not declare otherwise. This is due to the fact that the discrepancy between $H_{i^{*}}$ and $P$ on any subset of the domain, including the Scheff\u00e9 sets, will not exceed OPT. Hence, $\\hat{w}_{j}(H_{i^{*}})$ is at most $\\partial\\mathsf{P T}+\\epsilon^{\\prime}\\leq\\sigma+\\epsilon^{\\prime}$ , and we will not mark $H_{i^{*}}$ in Line 7, Line 10, nor Line 15. That is, for at least one hypothesis, i.e., $H_{i^{*}}$ , the \u201cif\u201d statement in Line 16 holds. And, we return a seed or \u201cstart over.\u201d (And, we will never reach Line 25.) ", "page_idx": 24}, {"type": "text", "text": "Next, we show that if the algorithm outputs $H_{i}$ , then it is a $(\\sigma+\\epsilon^{\\prime},\\,3\\,\\sigma+3\\,\\epsilon^{\\prime},\\,m)$ -seed with high probability. First, observe that $\\hat{W}(H_{i})$ must be at most $3\\,\\sigma+3\\,\\epsilon^{\\prime}$ due to the \u201cif\u201d condition in Line 18, satisfying one of the two conditions we need for our desired seed in Definition 3.1. ", "page_idx": 25}, {"type": "text", "text": "Now, we show the next required condition for $H_{i}$ to be a good seed holds as well: $\\left|\\mathcal{M}_{\\sigma+\\epsilon^{\\prime},3\\,\\sigma+3\\,\\epsilon^{\\prime}}(H_{i})\\right|\\leq m$ . This condition requires that the number of $H_{j}$ \u2019s in $\\mathcal{H}$ for which $\\hat{w}_{j}(H_{i})$ is in $(\\sigma+\\epsilon^{\\prime},3\\,\\sigma+3\\,\\epsilon^{\\prime}]$ is bounded by $m$ . We have already established that $\\hat{w}_{j}(H_{i})$ for every $j\\in[n]$ is bounded by $3\\,\\sigma+3\\,\\epsilon^{\\prime}$ since $\\hat{W}(H_{i})$ is at most $3\\,\\sigma+3\\,\\epsilon^{\\prime}$ . Hence, we only need to show that there are at most $m$ hypotheses $H_{j}$ such that $w_{j}(H_{i})$ is larger than $\\sigma+\\epsilon^{\\prime}$ . ", "page_idx": 25}, {"type": "text", "text": "Now, if there are more than $m$ hypothesis $H_{j}$ in $\\mathcal{H}$ such that $\\hat{w}_{j}(H_{i})>\\sigma+\\epsilon^{\\prime}$ . Now, if we sample $t:=\\left\\lceil8\\,n\\log\\left(2n/\\delta\\right)/m\\right\\rceil$ hypotheses, we should observe at least one $H_{j}$ for which $\\hat{w}_{j}(H_{i})$ is larger than $\\sigma+\\epsilon^{\\prime}$ , with probability at least $1-\\delta/(2n)$ . However, we know that such a hypothesis was never observed because we did not mark $H_{i}$ earlier. By the union bound, with a probability of at least $1\\!-\\!\\delta/2$ , no such $H_{i}$ exists. Hence, with probability at least $1\\!-\\!\\delta/2$ , $H_{i}$ is an $(\\sigma\\!+\\!\\bar{\\epsilon^{\\prime}},3\\,\\sigma\\!+\\!3\\dot{\\epsilon^{\\prime}},m^{\\prime})$ -seed as promised in the statement of the lemma. ", "page_idx": 25}, {"type": "text", "text": "Next, assume we output \u201cstart over.\u201d after finding an unmarked hypothesis $H_{i}$ . In this case, we know that $H_{i}$ is not marked and $\\hat{W}(H_{i})>2\\sigma+3\\epsilon^{\\prime}$ . Note that we have sampled $t$ edges of $H_{i}$ , and we never see $w_{j}(H_{i})>\\sigma+\\epsilon^{\\prime}$ . Using a very similar argument as we have above: one can show there cannot be more than $m^{\\prime}=\\lceil\\eta\\cdot\\lvert Q\\rvert\\rceil$ for which $w_{j}(\\bar{H_{i}})>\\sigma+\\epsilon^{\\prime}$ with probability $1-\\delta/2$ (for every $H_{i}$ ). That means, we will mark $|\\boldsymbol{\\mathcal{Q}}|-\\boldsymbol{m}^{\\prime}$ many hypothesis in $\\mathcal{Q}$ . If $|\\boldsymbol{\\mathcal{Q}}|>t\\geq1/\\eta$ , this implies that $(1-2\\eta)$ fraction of the hypothesis in $\\mathcal{Q}$ are removed. If $|\\mathcal{Q}|\\le t$ , then we know all the hypothesis in $\\mathcal{Q}$ have $w_{j}(H_{i})\\leq\\sigma+\\epsilon^{\\prime}$ and all of them will be marked. ", "page_idx": 25}, {"type": "text", "text": "Furthermore, we show that we did not wrongfully mark a hypothesis that was $\\sigma$ -close to $P$ . Observe that the condition in Line 22 holds in two cases: ", "page_idx": 25}, {"type": "text", "text": "Case 1: $\\hat{w}_{i}(H_{j})>\\sigma+\\epsilon^{\\prime}$ . It is straightforward to show that $H_{j}$ is not $\\sigma$ -close to $P$ since we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\|H_{j}-P\\|_{\\mathrm{TV}}\\geq w_{i}(H_{j})\\geq\\hat{w}_{i}(H_{j})-\\epsilon^{\\prime}>\\sigma\\,.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Case 2: $\\hat{w}_{i}(H_{j})\\le\\sigma+\\epsilon^{\\prime}$ and $\\hat{w}_{j}(H_{i})\\le\\sigma+\\epsilon^{\\prime}$ . Even though $\\hat{w}_{\\ell}(H_{j})$ is small in this case, we can indirectly deduce that $H_{j}$ is not $\\sigma$ -close to $P$ . By the definition of $\\hat{w}_{j}(H_{i})$ and $\\hat{w}_{i}(H_{j})$ , we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|H_{i}-H_{j}\\|_{\\mathrm{TV}}=|H_{i}\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)|\\leq|H_{i}\\left(S_{i,j}\\right)-P\\left(S_{i,j}\\right)|-|P\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)|}\\\\ &{\\qquad\\qquad=w_{i}(H_{j})+w_{j}(H_{i})\\leq\\hat{w}_{i}(H_{j})+\\hat{w}_{j}(H_{i})+2\\,\\epsilon^{\\prime}\\leq2\\sigma+2\\,\\epsilon^{\\prime}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "On the other hand, by the triangle inequality, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|P-H_{j}\\|_{\\mathrm{TV}}\\geq\\|P-H_{i}\\|_{\\mathrm{TV}}-\\|H_{i}-H_{j}\\|_{\\mathrm{TV}}\\geq W(H_{i})-\\|H_{j}-H_{i}\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\hat{W}(H_{i})-\\epsilon^{\\prime}-\\|H_{i}-H_{j}\\|_{\\mathrm{TV}}>3\\,\\sigma+3\\,\\epsilon^{\\prime}-\\epsilon^{\\prime}-(2\\,\\sigma+2\\,\\epsilon^{\\prime})=\\sigma\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Therefore, in both of the cases above, we do not mark an $\\sigma$ -close distribution to $P$ . ", "page_idx": 25}, {"type": "text", "text": "By the union bound over all the steps, our guarantees hold with probability $1-\\delta$ . In addition, it is not hard to see that the running time of the algorithm is $O\\left((n\\cdot t\\,\\Bar{+}\\,n)\\cdot T_{q}\\right)\\stackrel{}{=}O(n\\cdot(\\log(n/\\delta))\\cdot T_{q}/\\eta)$ time. ", "page_idx": 25}, {"type": "text", "text": "Rounds of adaptivity: It is straight forward to show that this algorithm can be implemented with a constant round of adaptivity. Let $\\mathcal{Q}_{0}$ denote the initial state of unmarked hypotheses at the algorithm\u2019s outset. Since hypotheses are marked in sequence, in round $i$ , the set of unmarked hypotheses is $\\mathcal{Q}_{i}:=\\mathcal{Q}_{0}\\cap H_{i},H_{i+1},...\\,,H_{n}$ . As a result, we can agree on the set of random $H_{j}$ \u2019s in $\\mathcal{Q}$ and $\\mathcal{H}$ and request $\\hat{w}_{j}(H_{i})$ within a single round. If the size of $|\\mathcal{Q}_{i}|$ is at most $t$ , then we include all $\\hat{w}_{j}(H_{i})$ for every $i\\in n$ and $H_{j}\\in\\mathcal{Q}$ . Next, upon discovering an unmarked $H_{i}$ , we initiate another round of adaptivity to request all $\\hat{w}_{j}(H_{i})$ and $\\hat{w}_{j}(H_{i})$ for all $j\\in[n]$ . This enables the implementation of the rest of the algorithm. ", "page_idx": 25}, {"type": "text", "text": "B.2 Boosting a seed ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we provide an algorithm that receives a $(\\kappa\\,\\sigma+\\epsilon^{\\prime},(\\kappa+2)\\sigma+5\\,\\epsilon^{\\prime},m)$ -seed and aims to find a $(\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime},(\\kappa^{\\prime}+2)\\sigma+5\\,\\epsilon^{\\prime},m^{\\prime})$ -seed with smaller $m^{\\prime}$ . That means, the size of $\\mathcal{M}$ for this new seed is smaller which brings us closer to have enough time to fully investigate the set $\\mathcal{M}$ for a future seed. Our algorithm runs in $\\tilde{O}(n\\cdot T_{q}/\\eta)$ time where $\\eta\\approx m^{\\prime}/m$ is our rate parameter. This running time is adaptive to our budget. If we are aiming for ${\\tilde{O}}(n)$ algorithm, we find a seed such that $m^{\\prime}$ is only smaller than $m$ by a constant factor (constant $\\eta$ ); Alternatively, if we have more time, we can decrease $m^{\\prime}$ with a faster rate (smaller $\\eta$ ). ", "page_idx": 26}, {"type": "text", "text": "While our main goal is to find a better seed, our algorithm may not always be able to do so; However, it makes progress towards the end goal of the algorithm one way or the other. There are three possible outcomes for our algorithm: ", "page_idx": 26}, {"type": "text", "text": "1. The algorithm finds an accurate enough $\\hat{H}$ as the final output of the algorithm.   \n2. The algorithm finds a better seed as we aimed for.   \n3. The algorithm marks $(1-2\\eta)$ fraction of the unmarked hypotheses; And after that, we start over the procedure. ", "page_idx": 26}, {"type": "text", "text": "Although we may have regressed in last case above, it does not happen too often. Since we have only $n$ unmarked hypotheses to begin with, and we marked a large fraction of them every time, we do not start more than $O(\\log_{1/2\\eta}(n))$ times over the course of the algorithm. Our approach is presented in Algorithm 6, and we prove its performance in Theorem 9. ", "page_idx": 26}, {"type": "table", "img_path": "Skv26JteFz/tmp/259bf7bc9578a1bee1fcab23e68295e5746d51c10c959321a0a863a903261a89.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Theorem 9. Suppose Algorithm 6 receives these parameters as input: $\\sigma\\in\\mathbb{R}_{\\ge0},\\;\\kappa,\\;\\kappa^{\\prime}\\ge1,\\;\\eta\\in$ $(0,1/4)$ , $\\epsilon^{\\prime}$ , $\\delta\\in(0,1)$ , and two non-negative integers $n$ , m. Also, assume the algorithm has access to a class of $n$ hypotheses $\\mathcal{H}$ , and a set of unmarked hypotheses in $\\mathcal{Q}\\subseteq\\mathcal{H}$ . It also receives $a$ hypothesis $H_{i}\\in{\\mathcal{H}}$ . The algorithm has one of the three possible outcomes listed below. Now, for any setting of such input parameters, if $H_{i}$ is a $(\\kappa\\,\\sigma+\\epsilon^{\\prime},\\bar{(\\kappa+2)}\\sigma+5\\,\\epsilon^{\\prime},m)$ seed, then the following guarantees hold for the outcome of Algorithm $^ \u1e0a 6 \u1e0c$ with a probability of at least $1-\\delta$ : ", "page_idx": 26}, {"type": "text", "text": "1. If the algorithm outputs a hypothesis $\\hat{H}$ as the final answer, then we have for every $\\epsilon\\geq6\\,\\epsilon^{\\prime}$ : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\|\\hat{H}-P\\|_{T V}\\le\\operatorname*{max}\\left(\\kappa+2,\\frac{\\kappa+2}{\\kappa^{\\prime}}+2\\right)\\cdot\\operatorname*{max}\\left(\\sigma,{\\mathsf{O P T}}\\right)+\\epsilon\\,.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "2. If the algorithm outputs a hypothesis $H_{\\ell}$ as a new seed, then $H_{\\ell}$ is a $(\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime},(\\kappa^{\\prime}+2)\\sigma+$ $5\\,\\epsilon^{\\prime},m^{\\prime})$ -seed where $m^{\\prime}:=\\lfloor\\eta\\,m\\rfloor$ . ", "page_idx": 26}, {"type": "text", "text": "1: procedure COMPUTE- $\\tilde{W}(\\mathcal{H},\\mathcal{Q},H_{i},t,$ , and query access to $\\hat{w}_{j}(H_{i})$ \u2019s)   \n2: W\u02dc \u21900   \n3: repeat $t$ times   \n4: $H_{j}\\leftarrow\\mathbf{a}$ uniformly random sample drawn from $\\mathcal{H}$   \n5: $\\tilde{W}\\gets\\operatorname*{max}\\Big(\\tilde{W},\\;\\hat{w}_{j}(H_{i})\\Big)$   \n6: Hj \u2190a uniformly random sample drawn from $\\mathcal{Q}$   \n7: W\u02dc \u2190max W\u02dc, w\u02c6j(Hi)   \n8:   \n9: if $|\\mathcal{Q}|\\leq t$ then   \n10: for all $H_{j}\\in\\mathcal{Q}$ do   \n11: $\\tilde{W}\\gets\\operatorname*{max}\\Big(\\tilde{W},\\;\\hat{w}_{j}(H_{i})\\Big)$   \n12: Return W\u02dc. ", "page_idx": 27}, {"type": "text", "text": "3. If the algorithm requires us to start over, then we have marked at least $(1-2\\eta)$ of the unmarked hypotheses. ", "page_idx": 27}, {"type": "text", "text": "The algorithm runs in $O(n\\cdot(\\log(n/\\delta))\\cdot T_{q}/\\eta)$ time and can be implemented in $O(1)$ rounds of adaptivity. ", "page_idx": 27}, {"type": "text", "text": "Proof. Let $\\mathcal{M}$ denote the set ${\\mathcal{M}}_{\\kappa\\,\\sigma+\\epsilon^{\\prime},(\\kappa+2)\\sigma+5\\,\\epsilon^{\\prime}}(H_{i})$ . We consider the three possible outcomes of the algorithm, and prove the algorithm satisfied the desired guarantee in each of the three cases. ", "page_idx": 27}, {"type": "text", "text": "Case 1: $\\tilde{W}(H_{\\ell})>\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ . In this case, the algorithm will return $H_{i}$ as the final answer. We show that the total variation distance between $H_{i}$ and $P$ is as desired. There are two possibilities depending on whether $H_{i^{*}}$ is in $\\mathcal{M}$ or not. ", "page_idx": 27}, {"type": "text", "text": "Case 1.1: $H_{i^{*}}\\in\\mathcal{M}$ . Using that $H_{\\ell}$ has the minimum $\\tilde{W}(H_{\\ell})$ among all the hypotheses in $\\mathcal{M}$ , we can bound OPT as follows: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathsf{O P T}\\geq W(H_{i^{\\ast}})\\geq\\hat{W}(H_{i^{\\ast}})-\\epsilon^{\\prime}\\geq\\hat{W}(H_{\\ell})-\\epsilon^{\\prime}\\geq\\tilde{W}(H_{\\ell})-\\epsilon^{\\prime}\\geq\\kappa^{\\prime}\\,\\sigma\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We prove that $H_{i}$ is not too far from $P$ . Note that since $H_{i}$ was an $\\left(\\kappa\\,\\sigma+\\epsilon^{\\prime},\\,\\left(\\kappa+2\\right)\\sigma+\\right.$ $5\\,\\epsilon^{\\prime},\\,m)$ -seed, we are guaranteed that $\\hat{W}(H_{i})$ is bounded by $\\left(\\kappa+2\\right)\\sigma+5\\,\\epsilon^{\\prime}$ . Using the above bound for OPT and Fact C.3, we get: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|H_{i}-P\\|_{\\mathrm{TV}}\\leq W(H_{i})+2\\,{\\sf O P T}\\leq\\hat{W}(H_{i})+\\epsilon^{\\prime}+2\\,{\\sf O P T}\\leq\\left(\\kappa+2\\right)\\sigma+6\\,\\epsilon^{\\prime}+2\\,{\\sf O P T}}\\\\ &{\\qquad\\qquad\\leq\\left(\\frac{\\kappa+2}{\\kappa^{\\prime}}+2\\right)\\cdot{\\sf O P T}+6\\,\\epsilon^{\\prime}\\leq\\left(\\frac{\\kappa+2}{\\kappa^{\\prime}}+2\\right)\\cdot\\operatorname*{max}(\\sigma,{\\sf O P T})+\\epsilon\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Case 1.2: $H_{i^{*}}\\notin\\cal M$ . Since $H_{i}$ is a $(\\kappa\\,\\sigma+\\epsilon^{\\prime},(\\kappa+2)\\sigma+5\\,\\epsilon^{\\prime},m)$ -seed, $\\hat{w}_{i^{*}}(H_{i})$ is bounded by $\\hat{W}(H_{i})\\,\\le\\,(\\kappa+2)\\sigma+5\\,\\epsilon^{\\prime}$ . Now that $H_{i^{*}}$ is not in $\\mathcal{M}$ , it must be the case that $\\hat{w}_{i^{*}}(H_{i})$ is bounded by $\\kappa\\,\\sigma+\\epsilon^{\\prime}$ . In this case, we have the following bound for the total variation distance between $H_{i}$ and $P$ via Fact C.3: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|H_{i}-P\\|_{\\mathrm{TV}}\\leq w_{i^{*}}(H_{i})+2\\,0\\mathsf{P T}\\leq\\hat{w}_{i^{*}}(H_{i})+\\epsilon^{\\prime}+2\\,0\\mathsf{P T}\\leq\\kappa\\,\\sigma+2\\,\\epsilon^{\\prime}+2\\,0\\mathsf{P T}}\\\\ &{\\qquad\\qquad\\leq(\\kappa+2)\\operatorname*{max}(\\sigma,0\\mathsf{P T})+\\epsilon\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Case 2: $\\tilde{W}(H_{\\ell})\\le\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ and $\\hat{W}(H_{\\ell})\\le(\\kappa^{\\prime}+2)\\,\\sigma+5\\,\\epsilon^{\\prime}$ . In this case, we output $H_{\\ell}$ as a new seed. Given the assumptions of this case, we show that $H_{\\ell}$ is a $(\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime},(\\kappa^{\\prime}+\\bar{2})\\sigma+5\\,\\epsilon^{\\prime},m^{\\prime}).$ - seed. First, $\\hat{W}(H_{\\ell})$ is at most $\\left(\\kappa^{\\prime}+2\\right)\\sigma+5\\,\\epsilon^{\\prime}$ implying the first desired property for being an $(\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime},(\\kappa^{\\prime}+2)\\sigma+5\\,\\epsilon^{\\prime},m^{\\prime})$ -seed holds for $H_{\\ell}$ . Next, we show the second desired property for $H_{\\ell}$ : the size of $\\mathcal{M}_{\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}}$ , $(\\kappa^{\\prime}{+}2)\\sigma{+}5\\,\\epsilon^{\\prime}\\big(H\\ell\\big)$ is bounded by $m^{\\prime}$ . At a high level, we expect the size of this set to be small; Otherwise, we would have observed one of these large $\\hat{w}_{\\ell}(H_{j})$ when we have sampled $t$ hypotheses to compute $\\tilde{W}(H_{\\ell})$ . ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "Suppose $H_{\\ell}$ has more than $m^{\\prime}$ edges with $\\hat{w}_{j}(H_{\\ell})\\ >\\ \\kappa^{\\prime}\\,\\sigma\\,+\\,\\epsilon^{\\prime}$ . Now, if we sample $t\\ :=$ $\\left[8\\,n\\log\\left(2n/\\delta\\right)/m^{\\prime}\\right]$ hypotheses, we should observe at least one $H_{j}$ for which $\\hat{w}_{j}(H_{\\ell})$ is larger than $\\kappa^{\\prime}\\,\\sigma+\\dot{\\epsilon}^{\\prime}$ , with probability at least $1-\\delta/(2n)$ . However, we know that such a hypothesis was never observed because $\\tilde{W}(H_{\\ell})$ , which is the maximum of $\\hat{w}_{j}(H_{\\ell})$ \u2019s, is bounded from above by $\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ . By the union bound, with a probability of at least $\\mathrm{i}-\\delta/2$ , no such $H_{\\ell}$ exists. Hence, with probability at least $1-\\delta/2$ , $H_{\\ell}$ is an $(\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime},(\\kappa^{\\prime}+2)\\,\\sigma+5\\dot{\\epsilon}^{\\prime},m^{\\prime})$ -seed as promised in the statement of the lemma. ", "page_idx": 28}, {"type": "text", "text": "Case 3: $\\tilde{W}(H_{\\ell})\\le\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ and $\\hat{W}(H_{\\ell})>(\\kappa^{\\prime}+2)\\,\\sigma+5\\,\\epsilon^{\\prime}$ . In this case the algorithm marks any unmarked hypothesis $H_{j}$ for which $\\hat{w}_{\\ell}(H_{j})\\,>\\,\\sigma\\,+\\,\\epsilon^{\\prime}$ or $\\hat{w}_{j}(H_{\\ell})\\,\\le\\,\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ , and we start over. First, we show that we did not wrongfully mark a hypothesis that was $\\sigma$ -close to $P$ . Observe that the condition in Line 15 holds in two cases: ", "page_idx": 28}, {"type": "text", "text": "Case 3.1: $\\hat{w}_{\\ell}(H_{j})>\\sigma+\\epsilon^{\\prime}$ . It is straightforward to show that $H_{j}$ is not $\\sigma$ -close to $P$ since we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|H_{j}-P\\|_{\\mathrm{TV}}\\geq w_{\\ell}(H_{j})\\geq\\hat{w}_{\\ell}(H_{j})-\\epsilon^{\\prime}>\\sigma\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Case 3.2: $\\hat{w}_{\\ell}(H_{j})\\le\\sigma+\\epsilon^{\\prime}$ and $\\hat{w}_{j}(H_{\\ell})\\le\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ . Even though $\\hat{w}_{\\ell}(H_{j})$ is small in this case, we can indirectly deduce that $H_{j}$ is not $\\sigma$ -close to $P$ . By the definition of $\\hat{w}_{j}(H_{\\ell})$ and $\\hat{w}_{\\ell}(H_{j})$ , we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}&{\\|H_{\\ell}-H_{j}\\|_{\\mathrm{TV}}=|H_{\\ell}\\left({\\cal S}_{\\ell,j}\\right)-H_{j}\\left({\\cal S}_{\\ell,j}\\right)|\\leq|H_{\\ell}\\left({\\cal S}_{\\ell,j}\\right)-P\\left({\\cal S}_{\\ell,j}\\right)|-|P\\left({\\cal S}_{\\ell,j}\\right)-H_{j}\\left({\\cal S}_{\\ell,j}\\right)|}\\\\ &{\\qquad\\qquad=w_{\\ell}(H_{j})+w_{j}(H_{\\ell})\\leq\\hat{w}_{\\ell}(H_{j})+\\hat{w}_{j}(H_{\\ell})+2\\,\\epsilon^{\\prime}\\leq\\kappa^{\\prime}\\sigma+\\sigma+4\\,\\epsilon^{\\prime}\\,.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "On the other hand, by the triangle inequality, we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|P-H_{j}\\|_{\\mathrm{TV}}\\ge\\|P-H_{\\ell}\\|_{\\mathrm{TV}}-\\|H_{\\ell}-H_{j}\\|_{\\mathrm{TV}}\\ge W(H_{\\ell})-\\|H_{j}-H_{\\ell}\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad\\ge\\hat{W}(H_{\\ell})-\\epsilon^{\\prime}-\\|H_{\\ell}-H_{j}\\|_{\\mathrm{TV}}>\\left(\\kappa^{\\prime}+2\\right)\\sigma+4\\,\\epsilon^{\\prime}-\\left(\\left(\\kappa^{\\prime}+1\\right)\\sigma+4\\,\\epsilon^{\\prime}\\right)=\\sigma\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Therefore, in both of the cases above, we do not mark an $\\sigma$ -close distribution to $P$ . ", "page_idx": 28}, {"type": "text", "text": "Second, we claim that we mark at least $(1-2\\,\\eta)$ fraction of the unmarked hypotheses in $\\mathcal{Q}$ . Recall that when we compute $\\tilde{W}(H_{\\ell})$ we also sample $t$ hypotheses from the set of unmarked hypotheses, and we did not observe any edge $\\hat{w}_{j}(H_{\\ell})$ that is larger than $\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ . With a very similar argument we had above, with probability $1-\\delta/(2n)$ , we do not have more than $m^{\\prime\\prime}:=\\lceil\\dot{\\eta}\\cdot\\lvert\\boldsymbol{\\mathcal{Q}}\\rvert\\cdot m/\\bar{n}\\rceil\\leq\\lceil\\eta\\cdot\\lvert\\boldsymbol{Q}\\rvert\\rceil$ hypotheses in $\\mathcal{Q}$ such that $\\hat{w}_{j}(\\dot{H}_{\\ell})>\\kappa^{\\prime}\\,\\sigma+\\epsilon^{\\prime}$ . Otherwise, we would have seen one of these edges, and $\\tilde{W}(H_{\\ell})$ would have been larger. By the union bound, this fact holds for every $H_{\\ell}$ . Hence, the \u201cif\u201d condition in Line 15 holds for over $|\\mathcal{Q}|-\\lceil\\eta\\cdot|\\mathcal{Q}|\\rceil$ of the unmarked hypotheses in $\\mathcal{Q}$ , and the algorithm mark them. If $|\\mathcal{Q}|\\ge1/\\eta$ , it is easy to show that $|\\mathcal{Q}|-\\lceil\\eta\\cdot|\\mathcal{Q}|\\rceil$ is at least $\\left(1-2\\,\\eta\\right)\\cdot\\left|\\boldsymbol{\\mathcal{Q}}\\right|$ . Thus, we mark at least $(1-2\\,\\eta)$ fraction of the hypotheses in $\\mathcal{Q}$ as we have claimed. Now, if $|Q|\\leq1/\\eta$ , it is easy to show that $|Q|<t$ . Hence, the algorithm involves all the $H_{j}$ \u2019s in $\\mathcal{Q}$ to compute $\\hat{W}(H_{\\ell})$ . Therefore, every single $\\hat{w}_{j}(H_{\\ell})$ is at most $\\kappa^{\\prime}\\sigma+\\epsilon^{\\prime}$ and we mark all the hypotheses in $\\mathcal{Q}$ . ", "page_idx": 28}, {"type": "text", "text": "By the union bound over all the steps, our guarantees hold with probability $1-\\delta$ . In addition, it is not hard to see that the running time of the algorithm is $O\\left((m\\cdot t+n)\\cdot T_{q}\\right)=O(n\\cdot(\\log(n/\\delta))\\cdot T_{q}/\\eta)$ time. ", "page_idx": 28}, {"type": "text", "text": "Rounds of adaptivity: Our algorithm can be implemented in constant rounds of adaptivity. To compute $\\Tilde{W}$ \u2019s, we can preselect the random $H_{j}$ \u2019s. If $\\mathcal{Q}$ contains fewer than $t+1$ hypotheses, we include every $\\hat{w}_{j}(H_{i})$ for each $H_{j}\\in\\mathcal{Q}$ and $i\\in[n]$ . Upon discovering $H_{\\ell}$ , another round of adaptivity allows us to query every $\\hat{w}_{j}(H_{\\ell})$ and $\\hat{w}_{\\ell}(H_{j})$ to calculate $\\hat{W}(H_{\\ell})$ and mark the hypotheses in $\\mathcal{Q}$ . ", "page_idx": 28}, {"type": "text", "text": "C Preliminary facts and lemmas ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Fact C.1. For all distribution $P$ and for all probability event $\\mathcal{E}$ defined under $P$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\|P-P_{|\\varepsilon}\\|_{T V}=1-P(\\mathcal{E})\\,,\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $P_{|\\mathcal{E}}$ denotes the probability distribution $P$ when conditioned on the event $\\mathcal{E}$ . ", "page_idx": 29}, {"type": "text", "text": "Fact C.2. For every pair of distributions $H_{i}$ and $H_{j}$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Vert H_{i}-H_{j}\\Vert_{T V}=|H_{i}\\left(S_{i j}\\right)-H_{j}\\left(S_{i j}\\right)|\\ .\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The following fact is adapted from [DL01, MS08, ABS23]. ", "page_idx": 29}, {"type": "text", "text": "Fact C.3. Suppose $H_{i^{*}}$ is the closest hypothesis to $P$ in $\\mathcal{H}(i.e.,\\,\\|H_{i^{*}}-P\\|_{T V})$ . For every pair of hypotheses $H_{i}$ and $H_{j}$ , the following holds: ", "page_idx": 29}, {"type": "equation", "text": "$$\nI.\\ \\ \\|H_{i}-P\\|_{T V}\\leq w_{j}(H_{i})+2\\|H_{j}-P\\|_{T V}\\,,\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. The proof is based on triangle inequality, and the definitions of $w_{j}(H_{i})$ \u2019s and OPT. For every $H_{j}$ in $\\mathcal{H}$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}&{\\|H_{i}-P\\|_{\\mathrm{TV}}\\leq\\|H_{i}-H_{j}\\|_{\\mathrm{TV}}+\\|H_{j}-P\\|_{\\mathrm{TV}}=|H_{i}\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)|+\\|H_{j}-P\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad\\leq|H_{i}\\left(S_{i,j}\\right)-P\\left(S_{i,j}\\right)|+|P\\left(S_{i,j}\\right)-H_{j}\\left(S_{i,j}\\right)|+\\|H_{j}-P\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad=w_{j}(H_{i})+w_{i}(H_{j})+\\|H_{j}-P\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad\\leq w_{j}(H_{i})+2\\|H_{j}-P\\|_{\\mathrm{TV}}\\,.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Hence, Item 1 is proved. Now, if we set $H_{j}$ to be $H_{i^{*}}$ , then $\\|H_{i^{*}}-P\\|_{\\mathrm{TV}}$ is equal to OPT implying Item 2. Item 3 is concluded from Item 2 and the fact that $w_{i^{*}}(H_{i})$ is upper bounded by $W(H_{i})$ . ", "page_idx": 29}, {"type": "text", "text": "Fact C.4. Suppose we are given six parameters $a,b,a^{\\prime},b^{\\prime}\\in\\mathbb{R}_{\\ge0}$ , and $m,m^{\\prime}\\in\\mathbb{Z}_{\\geq0}$ . If $a\\le a^{\\prime}$ , $b\\leq b^{\\prime}$ , and $m\\le m^{\\prime}$ , every $(a,b,m)$ -seed is also an $(a^{\\prime},b^{\\prime},m^{\\prime})$ -seed. ", "page_idx": 29}, {"type": "text", "text": "Fact C.5. Suppose we have a set of $n$ hypotheses $\\mathcal{H}$ , and a predicate, $R(H):{\\mathcal{H}}\\to\\{0,1\\}$ , that maps the hypotheses in $\\mathcal{H}$ to zero or one. Assume $\\mathcal{H}$ contains more than m hypotheses with $R(H)=1$ for an arbitrary integer parameter $0\\leq m<n.$ . If we draw $s\\geq8\\,n\\,\\log(\\delta^{-1})/m$ hypotheses from $\\mathcal{H}$ uniformly at random, we will observe at least one hypothesis with $R(H)=1$ with probability at least $1-\\delta$ . ", "page_idx": 29}, {"type": "text", "text": "Proof. Let $p$ denote the fraction of such hypothesis in $\\mathcal{H}$ with $R(H)=1$ . Observe that $p>0$ since there are at least $m+1$ such hypothesis in $\\mathcal{H}$ . Then, using the Chernoff bound, we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbf{Pr}[r=0]\\leq\\mathbf{Pr}\\Big[r<\\frac{s\\,p}{2}\\Big]=\\mathbf{Pr}\\Big[\\frac{r}{s}<\\Big(1-\\frac{1}{2}\\Big)\\cdot p\\Big]}\\\\ {\\leq\\exp\\left(-\\frac{s\\,p}{8}\\right)<\\exp\\left(-\\frac{s\\,m}{8\\,n}\\right)\\leq\\delta\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "D Data structure for marked and unmarked hypotheses ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Here, we describe a simple data structure that allows us to efficiently keep track of marked and unmarked hypotheses. Our data structure consists of two integers, n and t, and two arrays of size n: index[] and list[]. Here, n represents the number of hypotheses that the data structure supports. The list array is an arbitrary ordering of integers from 1 to n. Throughout the operations of this data structure, we preserve the following guarantee: the value of index[i] indicates where to find element i in the list. In other words, list[index[i]] is always i. The integer t serves as a threshold quantity. The first t numbers in the list correspond to unmarked hypotheses, while the remaining numbers represent marked hypotheses. Initially, list is a list of integers from 1 to n in ascending order. And, for every hypothesis $H_{i}$ , index[i] is set to i. This data structure supports the following operations: ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "\u2022 Initialization ds(size): To initialize the data structure, we set n and t to size. Next, we set list to be a list of integers from 1 to $\\mathbf{n}$ in ascending order. To ensure consistency with the list, each index[i] is set to i.   \n\u2022 mark(i): To mark hypothesis $H_{i}$ , we swap the element at index i with the element at index t in the list array, and then decrement t by 1.   \n\u2022 is_marked(i): Given our definition, if index[i] is less than or equal to $\\mathtt{t}$ , then $H_{i}$ is unmarked; otherwise, it is marked.   \n\u2022 is_all_marked(): If $\\mathtt{t}$ is equal to zero, then it means all the hypotheses are marked.   \n\u2022 random_unmarked(): To select a random unmarked hypothesis, we generate a random integer r between 1 and t, and output the hypothesis at list[r].   \n\u2022 random_marked(): To select a random marked hypothesis, we follow the same process as for an unmarked hypothesis, except that $\\mathbf{r}$ is generated between $\\pm+1$ and $\\mathfrak{n}$ . ", "page_idx": 30}, {"type": "text", "text": "It is easy to see that the initialization takes $O(n)$ time, and the rest of the operations only take $O(1)$ time. ", "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our results are a theoretical contribution to the field of learning theory. The paper, including the appendix, contains all the algorithms, theorem statements, and their proofs. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Please see the discussion in Section 1.2 regarding potential improvements and future directions. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We have clearly stated our model and our assumptions. All the proofs are included in the appendix. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: We do not have any experimental results. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 4.1 If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 4.2 If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 4.3 If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4.4 We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We do not have any experimental results. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We do not have any experimental results. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We do not have any experimental results. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: We do not have any experimental results. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Our results are a theoretical formulation of a fundamental problem in statistics and learning theory. They can be viewed as a computationally efficient version of existing results. Given the theoretical nature of our findings, we do not anticipate any harm to society. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: Given the theoretical nature of our findings, we do not anticipate broader societal impact for this paper. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 34}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 35}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: We do not have any experimental results. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: We did not use any existing assets, other than the publicly available articles that we have cited. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The contributions of this paper are theoretical. As is standard in the field, we will make our results publicly accessible and do not anticipate generating revenue from them. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: We do not have any crowdsourcing experiments nor human subjects. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: We do not have any experiments involving crowdsourcing nor research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 37}]