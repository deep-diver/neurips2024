[{"figure_path": "GqrWhROxrG/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison with NeRF-Det [22]. The 3D voxel centers (grey dots) are overlaid with the reference scene. The red dots denotes the erroneous backprojection pixel features to the points in the free space. Compared to NeRF-Det, we show much less inaccurate backprojections.", "description": "This figure compares the proposed MVSDet method with the NeRF-Det method in terms of 3D voxel center backprojections.  It visualizes the accuracy of projecting 2D image features into 3D space.  The grey dots represent the voxel centers, while the red dots highlight erroneous projections into free space.  MVSDet demonstrates significantly fewer incorrect projections compared to NeRF-Det, indicating improved accuracy in geometry estimation.", "section": "Abstract"}, {"figure_path": "GqrWhROxrG/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our MVSDet. The upper branch shows the detection pipeline with our proposed probabilistic sampling and soft weighting. The backprojected ray intersects at 3 points (shown as dots), but only the green point receives the pixel feature based on the selected depth proposals. The red points are denoted as invalid backprojection location and thus the pixel feature is not assigned to them. \"GT Location\" is the ground truth 3D location of the pixel. The lower branch shows the pixel-aligned Gaussian Splatting (PAGS). We select nearby views for the novel image from the images input to the detection branch and predict Gaussian maps on them. Note that PAGS is removed during testing.", "description": "This figure illustrates the MVSDet architecture.  The upper branch details the detection pipeline using probabilistic sampling and soft weighting to efficiently place pixel features on the 3D volume based on depth probability. The lower branch demonstrates the use of Pixel-aligned Gaussian Splatting (PAGS) for novel view synthesis, improving depth prediction, but only used during training.  The figure highlights the selection of depth proposals and shows how pixel features are assigned to valid and invalid 3D locations, comparing to the ground truth.", "section": "3 Our Method"}, {"figure_path": "GqrWhROxrG/figures/figures_4_1.jpg", "caption": "Figure 3: Comparison of different feature backprojection methods. The pixel ray intersects at 4 voxel centers with the blue box denoting the ground truth 3D location of the pixel. Our method computes the placement of the pixel features based on the depth probability distribution (purple) and thus able to suppress incorrect intersections.", "description": "This figure compares different feature backprojection methods in 3D volume-based object detection.  The left shows the method used in ImVoxelNet, which projects pixel features to all voxels intersected by the ray.  The right demonstrates the proposed method (MVSDet). MVSDet uses depth probability distribution to guide feature placement, assigning features only to voxels with high probability, thus reducing errors. The blue box represents the ground truth 3D location, green dots represent valid feature placements, and red dots represent invalid feature placements.", "section": "3.2 Efficient Plane Sweep"}, {"figure_path": "GqrWhROxrG/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative comparison on ScanNet dataset. Note that the mesh is not the input to the model and is only for visualization purpose.", "description": "This figure compares the qualitative results of three different methods on the ScanNet dataset for indoor 3D object detection.  The first row shows the ground truth bounding boxes, illustrating the actual locations and sizes of the objects. The second row displays the results of the NeRF-Det method which uses NeRF for geometric reasoning.  The third row shows the results obtained using the proposed method (Ours), MVSDet, which leverages a more efficient plane sweep technique. A visual comparison highlights the differences in accuracy and precision between the different approaches, demonstrating the improved performance of the proposed method over NeRF-Det.", "section": "4 Experiments"}, {"figure_path": "GqrWhROxrG/figures/figures_8_1.jpg", "caption": "Figure 5: Depth map visualization. \u201cGT Depth\u201d denotes ground truth depth map. Both \u201cw/ Gaussian\u201d and \u201cw/o Gaussian\u201d use M = 12 depth planes.", "description": "This figure visualizes the depth maps predicted by the probability volume.  It compares the ground truth depth map with the depth maps predicted with and without using Gaussian Splatting.  Both versions use 12 depth planes. The visualization helps to show the impact of incorporating Gaussian Splatting on depth map quality.", "section": "4.4 Ablation Study"}, {"figure_path": "GqrWhROxrG/figures/figures_8_2.jpg", "caption": "Figure 6: Comparison of different depth prediction methods on 3D object detection on ScanNet.", "description": "This figure compares the performance of different depth prediction methods on 3D object detection using the ScanNet dataset.  The x-axis represents the number of depth planes used in the methods, while the y-axis shows the mAP@0.25 (mean Average Precision at IoU threshold of 0.25).  The results show that the proposed method (Ours) achieves comparable performance to using ground truth depth with significantly fewer depth planes than other methods like MVSNet and BEVStereo.  MVSNet performs poorly despite using many depth planes, while BEVStereo's performance is limited even with ground truth depth information.", "section": "4.3 Comparison with Baselines"}, {"figure_path": "GqrWhROxrG/figures/figures_11_1.jpg", "caption": "Figure 4: Qualitative comparison on ScanNet dataset. Note that the mesh is not the input to the model and is only for visualization purpose.", "description": "This figure shows a qualitative comparison of the proposed MVSDet method against the NeRF-Det method on the ScanNet dataset.  It visually demonstrates the improved accuracy of object detection using MVSDet.  The images display the ground truth bounding boxes in the scene, followed by the bounding boxes produced by the NeRF-Det method, and lastly the bounding boxes predicted by the MVSDet method.  The improved accuracy in locating the object bounding boxes in the MVSDet results is clearly apparent from the visual comparison.  Note that the mesh is added for visualization purposes and is not an input to the model.", "section": "4 Experiments"}, {"figure_path": "GqrWhROxrG/figures/figures_11_2.jpg", "caption": "Figure 8: Novel view synthesis results on ScanNet dataset. \"Rendering\" denotes the rendered image / depth from our Gaussian Splatting module. \"GT\" denotes the ground-truth image /depth of the novel view.", "description": "This figure shows the results of novel view synthesis on the ScanNet dataset.  It compares the rendered images and depth maps produced by the model's Gaussian Splatting module against the ground truth images and depth maps for several novel viewpoints. The comparison demonstrates the model's ability to generate realistic and accurate novel views.", "section": "A.2 Novel View Synthesis Results"}]