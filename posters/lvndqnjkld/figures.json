[{"figure_path": "LvNDqNJKlD/figures/figures_7_1.jpg", "caption": "Figure 1: Figures (a) & (b) show the plot of objective of the upper-level problem (Upper Objective) for different strategies. HINV and CG strategies have fastest convergence, followed by NS and AD. The corresponding estimation errors are shown in (c). Figure (d) specifically shows the robustness of approximation error obtained by NS across different \u03b3 and T values.", "description": "This figure presents the results of a synthetic experiment comparing different hypergradient estimation strategies for Riemannian bilevel optimization.  Subfigure (a) shows the upper-level objective function over epochs for the different methods (Hessian inverse (HINV), conjugate gradient (CG), truncated Neumann series (NS), and automatic differentiation (AD)). Subfigure (b) displays the same objective but plots it against time. Subfigure (c) shows the hypergradient estimation error for these methods across epochs.  Finally, subfigure (d) investigates the robustness of the NS method to changes in hyperparameters \u03b3 (damping factor) and T (number of iterations).", "section": "Experiments"}, {"figure_path": "LvNDqNJKlD/figures/figures_8_1.jpg", "caption": "Figure 2: Figures (a), (b), and (c) show the performance of RHGD on the hyper-representation problems on SPD networks. Figure (d) shows the good generalization performance of our proposed RHGD algorithms over the projected gradient PHGD baselines on the MiniImageNet dataset.", "description": "This figure presents the results of experiments on hyper-representation problems using SPD networks and the MiniImageNet dataset.  Figures (a), (b), and (c) compare the performance of the proposed Riemannian Hypergradient Descent (RHGD) algorithm with different hypergradient estimation strategies (Hessian Inverse, Conjugate Gradient, Truncated Neumann Series, and Automatic Differentiation) for shallow and deep hyper-representation tasks on SPD manifolds. Figure (d) shows a comparison of RHGD and Projected Hypergradient Descent (PHGD) for meta-learning on the MiniImageNet dataset, demonstrating RHGD's superior generalization performance.", "section": "4 Experiments"}]