[{"figure_path": "LvNDqNJKlD/tables/tables_2_1.jpg", "caption": "Table 1: Comparison of first-order and second-order complexities for reaching e-stationarity. For stochastic algorithms, including HGD-NS, RSHGD-HINV, the complexities are measured with respect to the component functions fi, gi. Here, Gf, Gg are the gradient complexities of function f, g, respectively, to reach an e-stationary point of (1). Also, we denote JVg, HVg as the complexity of computing the second-order cross derivative and Hessian-vector product of function g.", "description": "This table compares the computational complexities of different first-order and second-order methods for achieving \\( \\epsilon \\)-stationarity in bilevel optimization problems.  It shows the complexities in terms of gradient computations for the upper-level function (Gf), the lower-level function (Gg), the second-order cross derivative (JVg), and the Hessian-vector product (HVg).  The table distinguishes between deterministic and stochastic algorithms.", "section": "3.2 Theoretical analysis"}, {"figure_path": "LvNDqNJKlD/tables/tables_5_1.jpg", "caption": "Table 1: Comparison of first-order and second-order complexities for reaching \u03b5-stationarity. For stochastic algorithms, including HGD-NS, RSHGD-HINV, the complexities are measured with respect to the component functions fi, gi. Here, Gf, Gg are the gradient complexities of function f, g, respectively, to reach an \u03b5-stationary point of (1). Also, we denote JVg, HVg as the complexity of computing the second-order cross derivative and Hessian-vector product of function g.", "description": "This table compares the computational complexity of different first-order and second-order methods for solving bilevel optimization problems, specifically focusing on the number of gradient and Hessian computations needed to achieve an \u03b5-stationary point.  It breaks down the complexities for deterministic and stochastic algorithms, considering the complexities of gradient calculations for both upper and lower level functions, as well as the complexities of computing second-order cross derivatives and Hessian-vector products.", "section": "3.2 Theoretical analysis"}, {"figure_path": "LvNDqNJKlD/tables/tables_8_1.jpg", "caption": "Table 2: Classification accuracy on the Caltech-Office dataset.", "description": "This table presents the classification accuracy results achieved using three different methods: Optimal Transport with Earth Mover's Distance (OT-EMD), Optimal Transport with Sinkhorn Divergence (OT-SKH), and the proposed Riemannian bilevel optimization approach.  The results are shown for various domain adaptation tasks, represented by source and target domains (e.g., A\u2192C means Amazon to Caltech).  The proposed method demonstrates improved classification accuracy compared to the baseline optimal transport methods across all twelve adaptation tasks.", "section": "4.3 Riemannian meta learning"}, {"figure_path": "LvNDqNJKlD/tables/tables_35_1.jpg", "caption": "Table 1: Comparison of first-order and second-order complexities for reaching \u03b5-stationarity. For stochastic algorithms, including HGD-NS, RSHGD-HINV, the complexities are measured with respect to the component functions fi, gi. Here, Gf, Gg are the gradient complexities of function f, g, respectively, to reach an \u03b5-stationary point of (1). Also, we denote JVg, HVg as the complexity of computing the second-order cross derivative and Hessian-vector product of function g.", "description": "This table compares the computational complexities of different hypergradient descent methods for reaching an \u03b5-stationary point in bilevel optimization problems.  It shows the first-order and second-order complexities for both deterministic and stochastic algorithms. The complexities are broken down by the method used (Hessian Inverse, Conjugate Gradient, Neumann Series, Automatic Differentiation) and indicate gradient complexities for functions f and g, as well as complexities for computing second-order cross derivatives and Hessian-vector products.", "section": "3.2 Theoretical analysis"}, {"figure_path": "LvNDqNJKlD/tables/tables_36_1.jpg", "caption": "Table 1: Comparison of first-order and second-order complexities for reaching \u03b5-stationarity. For stochastic algorithms, including HGD-NS, RSHGD-HINV, the complexities are measured with respect to the component functions fi, gi. Here, Gf, Gg are the gradient complexities of function f, g, respectively, to reach an \u03b5-stationary point of (1). Also, we denote JVg, HVg as the complexity of computing the second-order cross derivative and Hessian-vector product of function g.", "description": "This table compares the computational complexities of different bilevel optimization algorithms in reaching an \u03b5-stationary point.  It breaks down the complexities into first-order and second-order terms for both deterministic and stochastic methods, considering the complexities of gradient computations for both upper and lower level functions (Gf, Gg), as well as the complexities of computing second-order cross derivatives (JVg) and Hessian-vector products (HVg).  The algorithms compared include several variants of Riemannian Hypergradient Descent (RHGD), along with their stochastic counterparts and a comparison against existing Euclidean algorithms.", "section": "3.2 Theoretical analysis"}]