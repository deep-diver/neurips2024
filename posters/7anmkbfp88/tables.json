[{"figure_path": "7ANmKBfP88/tables/tables_8_1.jpg", "caption": "Table 1: Model's performance with different settings. F1 and ACC denote the F1 score and accuracy score, respectively. ACC(F) refers to the accuracy of reframing directions, excluding the categories 'Leave it unchanged' and 'None of the other options.'N/A indicates not applicable experiments due to limitations on the model's accessibility or incompatibility with the experiment design.", "description": "This table presents the performance of different vision-language models (VLMs) under various settings.  The settings involve two different perturbation ranges (0.3-0.7 and 0.1-0.9) and whether the option choices were shuffled during training or not. The models' performance is evaluated using three metrics: F1-score (F1), overall accuracy (ACC), and accuracy specifically on reframing directions (ACC(F)). The baseline performance of each model without fine-tuning is also included.  The table shows how different training strategies and model architectures affect the ability of the models to provide directional guidance for improving image framing in Visual Question Answering (VQA) tasks.", "section": "5 Results"}, {"figure_path": "7ANmKBfP88/tables/tables_9_1.jpg", "caption": "Table 2: Model's performance under different perturbation ranges with LLaVA-1.5 7b.", "description": "This table presents the performance of the LLaVA-1.5 7b model under different perturbation ranges. The perturbation range determines the cropping ratios used to generate the training samples. It shows the overall F1 score, overall accuracy and accuracy on reframing cases (ACC(F)) for each perturbation range. The results demonstrate the impact of the perturbation range on model performance.", "section": "5.2 Model's performance after fine-tuning"}, {"figure_path": "7ANmKBfP88/tables/tables_15_1.jpg", "caption": "Table 1: Model's performance with different settings. F1 and ACC denote the F1 score and accuracy score, respectively. ACC(F) refers to the accuracy of reframing directions, excluding the categories 'Leave it unchanged' and 'None of the other options'.N/A indicates not applicable experiments due to limitations on the model's accessibility or incompatibility with the experiment design.", "description": "This table presents the performance of four different vision-language models (LLaVA-1.5 7B, LLaVA-1.5 13B, InstructBlip 7B, and GPT-4) under various settings.  The metrics used are F1 score, overall accuracy (ACC), and accuracy specifically on reframing directions (ACC(F)).  The settings compared include the use of shuffled options during training and different perturbation ranges for data augmentation.  'N/A' indicates where a model could not be tested under a particular setting.", "section": "5 Results"}]