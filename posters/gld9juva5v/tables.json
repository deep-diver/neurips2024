[{"figure_path": "GlD9Juva5V/tables/tables_1_1.jpg", "caption": "Table 1: A comparison of song generation with related tasks in the literature. We use Composition to denote whether the model can complete vocal composition, Arrangement to denote whether the model can arrange the instrumental accompaniment, and Harmony to denote whether vocals and accompaniment sound harmonious and pleasant together.", "description": "This table compares song generation with related tasks like singing voice synthesis, accompaniment generation, and text-to-music generation.  It shows the inputs and outputs for each task and indicates whether each model exhibits vocal composition, instrumental arrangement, and harmonious combination of vocals and accompaniment.", "section": "1 Introduction"}, {"figure_path": "GlD9Juva5V/tables/tables_5_1.jpg", "caption": "Table 2: Specific attention mask strategy of all tasks supported by SongCreator. [\u00b7] indicates that the condition is optional. * indicates that our proposed model achieves significant improvements in this task.", "description": "This table lists the eight tasks supported by the SongCreator model, showing the input conditions, output types, and the attention mask strategies (self-attention and bidirectional cross-attention) used for each task.  The * indicates tasks where SongCreator shows significant improvement over previous state-of-the-art methods.  Square brackets around conditions indicate optional inputs.", "section": "3 Method"}, {"figure_path": "GlD9Juva5V/tables/tables_7_1.jpg", "caption": "Table 3: Lyrics-to-song evaluation without audio prompt.", "description": "This table presents the results of the lyrics-to-song task without using any audio prompts. It compares the performance of SongCreator with several baseline models across three metrics: FAD (Fr\u00e9chet Audio Distance), Musicality (MOS score), and Quality (MOS score). Lower FAD indicates better generation fidelity, while higher Musicality and Quality scores represent better subjective evaluations. The results show that SongCreator outperforms the baseline models in both musicality and quality.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_7_2.jpg", "caption": "Table 4: Lyrics-to-vocals evaluation without audio prompt.", "description": "This table presents the results of the lyrics-to-vocals task without using any audio prompts. It compares the performance of SongCreator and several baselines, including MusicLM and VALL-E, across three evaluation metrics: Musicality, Quality, and Similarity.  SongCreator demonstrates superior performance across all three metrics compared to the baselines.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_7_3.jpg", "caption": "Table 6: Prompt-based lyrics-to-vocals. We sample the prompt at random from a held-out set.", "description": "This table presents the results of a prompt-based lyrics-to-vocals experiment.  The model generated vocals using prompts randomly selected from a held-out set. The results are evaluated using SECS (Speaker Embedding Cosine Similarity), Musicality (MOS score), and Similarity (MOS score).  The metrics assess the quality of the generated vocals in terms of speaker similarity, musicality, and overall similarity to reference vocals.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_7_4.jpg", "caption": "Table 5: Prompt-based lyrics-to-song. We sample the prompt at random from a held-out set.", "description": "This table presents the results of a prompt-based lyrics-to-song generation task.  The model was evaluated using FAD (Fr\u00e9chet Audio Distance), MCD (Mel-Cepstral Distortion), Musicality (MOS), and Similarity (MOS) metrics.  The prompt was randomly selected from a held-out set to assess the model's ability to generate songs with varied acoustic conditions based on the provided prompt.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_7_5.jpg", "caption": "Table 7: Vocals-to-song evaluation.", "description": "This table presents the results of the Vocals-to-song task, comparing SongCreator against several baselines.  Metrics include FAD (Fr\u00e9chet Audio Distance), Musicality (MOS score), and Harmony (MOS score).  The table helps demonstrate SongCreator's performance compared to existing methods when generating a song from an input vocal track.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_8_1.jpg", "caption": "Table 9: Music continuation evaluation.", "description": "This table presents the results of the music continuation evaluation. Three models, AudioLM, GPT, and SongCreator, are evaluated using three metrics: FAD (Fr\u00e9chet Audio Distance), Musicality (MOS score), and Similarity (MOS score).  Lower FAD indicates better fidelity, while higher Musicality and Similarity scores indicate better performance.  The results show that SongCreator achieves competitive performance with state-of-the-art models in music continuation.", "section": "4 Experiments"}, {"figure_path": "GlD9Juva5V/tables/tables_8_2.jpg", "caption": "Table 1: A comparison of song generation with related tasks in the literature. We use Composition to denote whether the model can complete vocal composition, Arrangement to denote whether the model can arrange the instrumental accompaniment, and Harmony to denote whether vocals and accompaniment sound harmonious and pleasant together.", "description": "This table compares different music generation tasks based on their inputs and outputs, focusing on whether each task involves vocal composition, instrumental arrangement, and the harmonious integration of vocals and accompaniment.  It helps to illustrate the unique contribution of the SongCreator model, which aims to achieve all three aspects simultaneously.", "section": "1 Introduction"}, {"figure_path": "GlD9Juva5V/tables/tables_15_1.jpg", "caption": "Table 1: A comparison of song generation with related tasks in the literature. We use Composition to denote whether the model can complete vocal composition, Arrangement to denote whether the model can arrange the instrumental accompaniment, and Harmony to denote whether vocals and accompaniment sound harmonious and pleasant together.", "description": "This table compares the capabilities of different song generation approaches and related tasks, focusing on whether they can perform vocal composition, instrumental arrangement, and harmonious vocal and accompaniment generation.  It highlights the unique challenge of generating songs with both vocals and accompaniment given only lyrics as input.", "section": "1 Introduction"}, {"figure_path": "GlD9Juva5V/tables/tables_16_1.jpg", "caption": "Table 13: Reconstructed music performance results for different semantic tokenizers.", "description": "This table presents a comparison of the performance of various semantic tokenizers in reconstructing music.  The models used were HuBERT, MERT, MusicFM, and BEST-RQ.  The evaluation metric used was ViSQOL, which measures the quality of the reconstructed audio.  BEST-RQ shows the best performance, suggesting it is a better choice for music reconstruction.", "section": "A.2 BEST-RQ with vector quantization"}, {"figure_path": "GlD9Juva5V/tables/tables_19_1.jpg", "caption": "Table 1: A comparison of song generation with related tasks in the literature. We use Composition to denote whether the model can complete vocal composition, Arrangement to denote whether the model can arrange the instrumental accompaniment, and Harmony to denote whether vocals and accompaniment sound harmonious and pleasant together.", "description": "This table compares different music generation tasks, including singing voice synthesis, song composition, text-to-music, accompaniment generation, and the complete song generation task. For each task, it lists the input, output, and whether the model can complete vocal composition, instrumental arrangement, and achieve harmonious vocals and accompaniment.  The table highlights that while previous work has tackled aspects of song generation, the complete generation of songs with both vocals and accompaniment from lyrics remained a significant challenge before SongCreator.", "section": "1 Introduction"}, {"figure_path": "GlD9Juva5V/tables/tables_19_2.jpg", "caption": "Table 15: Results of the AB preference test between SongCreator and Jukebox in lyrics-to-song. N/P denotes \u201cno preference\u201d.", "description": "This table presents the results of an A/B preference test comparing the song generation quality of SongCreator and Jukebox. Participants were asked to choose their preferred song based on overall quality. The results show that SongCreator was preferred in 60% of comparisons, while Jukebox was preferred in 38.5%, and 1.5% showed no preference.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_19_3.jpg", "caption": "Table 16: Results of the AB preference test between SongCreator and Singsong in vocals-to-song. N/P denotes \"no preference\".", "description": "This table presents the results of an A/B preference test comparing the quality of vocal generation between SongCreator and Singsong. Participants were asked to choose their preferred song based on overall quality.  The results show that Singsong was preferred by a significant margin (54.1%) compared to SongCreator (30%), with only a small percentage (15.9%) indicating no preference.", "section": "4.2 The results of tasks"}, {"figure_path": "GlD9Juva5V/tables/tables_20_1.jpg", "caption": "Table 2: Specific attention mask strategy of all tasks supported by SongCreator. [\u00b7] indicates that the condition is optional. * indicates that our proposed model achieves significant improvements in this task.", "description": "This table shows the specific attention mask strategies used for each of the eight tasks supported by SongCreator.  It details the attention masking approach used for both self-attention (SA) and bidirectional cross-attention (BCA) layers within the model for vocals and accompaniment generation.  The table clarifies which masking strategy (causal, non-causal, bidirectional, accompaniment-to-vocal (A2V), or vocal-to-accompaniment (V2A)) is employed for each layer in each task, highlighting tasks where SongCreator shows significant improvement over previous works.", "section": "3.3 Attention mask strategies for universal song generation"}, {"figure_path": "GlD9Juva5V/tables/tables_20_2.jpg", "caption": "Table 2: Specific attention mask strategy of all tasks supported by SongCreator. [\u00b7] indicates that the condition is optional. * indicates that our proposed model achieves significant improvements in this task.", "description": "This table shows the different attention mask strategies used by SongCreator for eight different song generation tasks.  For each task, it specifies the input conditions (lyrics, vocal prompt, accompaniment prompt, etc.), the output (song, vocals, etc.), and the attention mask strategies used in the self-attention (SA) and bidirectional cross-attention (BCA) layers of the model.  The SA mask can be either causal (only attending to previous tokens) or non-causal (attending to all tokens). The BCA mask options include Bidirectional (BR), Accompaniment-to-Vocals (A2V), Vocals-to-Accompaniment (V2A), and None (no cross-attention). The table highlights the tasks where SongCreator achieved state-of-the-art or significantly improved results.", "section": "3.3 Attention mask strategies for universal song generation"}, {"figure_path": "GlD9Juva5V/tables/tables_20_3.jpg", "caption": "Table 19: Results of the AB preference test for using different attention mask strategies in BAC on the Accompaniment-to-song task.", "description": "This table presents the results of an A/B preference test comparing different attention mask strategies used in the bidirectional cross-attention (BCA) layer of the SongCreator model for the accompaniment-to-song generation task.  The test shows the percentage of participants who preferred each strategy (BR, A2V) or had no preference (N/P). The A2V strategy, allowing the vocal decoder to attend to the entire accompaniment sequence, was significantly preferred.", "section": "4.3 Ablation Studies"}, {"figure_path": "GlD9Juva5V/tables/tables_20_4.jpg", "caption": "Table 2: Specific attention mask strategy of all tasks supported by SongCreator. [\u00b7] indicates that the condition is optional. * indicates that our proposed model achieves significant improvements in this task.", "description": "This table shows the attention mask strategies used by SongCreator for various song generation tasks, including lyrics-to-song, lyrics-to-vocals, accompaniment-to-song, vocals-to-song, music continuation, song editing, vocals editing, and vocals editing in song.  It details the specific mask strategies (SA mask and BCA mask) employed for each task, indicating whether a causal, non-causal, bidirectional, or no mask is used for self-attention (SA) and bidirectional cross-attention (BCA) layers.  The optional conditions for each task are also listed, along with an indication of significant performance improvements achieved by the model (*).", "section": "3.3 Attention mask strategies for universal song generation"}]