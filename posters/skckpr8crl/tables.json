[{"figure_path": "sKCKPr8cRL/tables/tables_7_1.jpg", "caption": "Table 1: We report the predicted optimal vocabulary parameters Nv and the vocabulary size V by the proposed three approaches given Nnv. We assume the training FLOPs are optimally allocated i.e. that the non-vocabulary parameters and training data are scaled equally. \"App\" denotes the approach.", "description": "This table presents the predicted optimal vocabulary parameters (Nv) and vocabulary sizes (V) for different model sizes (Nnv) based on three different approaches (App1, App2, App3).  The predictions are made under the assumption that the training FLOPs are optimally allocated and that the non-vocabulary parameters and training data are scaled equally.  The table shows the optimal vocabulary size according to each approach and the corresponding FLOPs budget.", "section": "Discussion"}, {"figure_path": "sKCKPr8cRL/tables/tables_8_1.jpg", "caption": "Table 2: Zero-shot performance of models with Nnv = 2.87B comparing the commonly used V = 32K with our predicted optimal vocabulary Vopt. We consider the scenario where the number of training data is equally scaled with the non-vocabulary parameters. We report accuracy and standard deviation in percentages. Accuracy is normalized: The predicted likelihoods are divided by the length of each choice for multiple choices to eliminate the effect of text length on predictions.", "description": "This table presents the zero-shot performance results of language models with 2.87 billion non-vocabulary parameters (Nnv).  It compares the performance using a commonly used vocabulary size of 32K against the predicted optimal vocabulary size (Vopt) determined by the authors' method. The models were trained with an optimal amount of training data, meaning the data size scaled equally with the number of non-vocabulary parameters.  The results show accuracy and standard deviation across several downstream tasks (ARC-C, ARC-E, Hellaswag, OBQA, WG, PIQA, BoolQ), and an average score across all tasks.", "section": "5 Discussion"}, {"figure_path": "sKCKPr8cRL/tables/tables_8_2.jpg", "caption": "Table 3: Zero-shot performance of models with Nnv = 2.87B comparing the commonly used V = 32K with our predicted optimal vocabulary Vopt when undertraining or overtraining.", "description": "This table presents the zero-shot performance results on eight downstream tasks (ARC-C, ARC-E, Hellaswag, OBQA, WG, PIQA, BoolQ, and Average) for two different vocabulary sizes (V=32K and Vopt) under two training data conditions (insufficient and overly sufficient).  The non-vocabulary parameters (Nnv) are kept constant at 2.87B across all experiments.  The results show the impact of using the predicted optimal vocabulary size (Vopt) compared to a commonly used size (32K) under different data conditions. The optimal vocabulary size varies depending on whether the model is undertrained or overtrained.", "section": "5 Discussion"}, {"figure_path": "sKCKPr8cRL/tables/tables_20_1.jpg", "caption": "Table 4: The architectures of the models and the corresponding number of training characters adopted in our experiments.", "description": "This table lists the architecture details for the language models used in the experiments.  For each model, it shows the non-vocabulary parameters (in millions), sequence length, number of layers, number of heads, embedding dimension, intermediate size, and the total number of training characters (in billions). The table provides a clear overview of the model configurations employed throughout the study, enabling reproducibility and facilitating a better understanding of the results presented.", "section": "A.7.1 Setting of model architecture, vocabulary size and training characters"}, {"figure_path": "sKCKPr8cRL/tables/tables_21_1.jpg", "caption": "Table 1: We report the predicted optimal vocabulary parameters Nv and the vocabulary size V by the proposed three approaches given Nnv. We assume the training FLOPs are optimally allocated i.e. that the non-vocabulary parameters and training data are scaled equally. \"App\" denotes the approach.", "description": "This table shows the predicted optimal vocabulary parameters (Nv) and vocabulary size (V) for different non-vocabulary parameter (Nnv) values using three different approaches (App1, App2, App3). The prediction is based on the assumption that training FLOPs are optimally allocated, meaning the non-vocabulary parameters and training data are scaled equally.  The table helps illustrate how the optimal vocabulary size increases with larger models.", "section": "5 Discussion"}]