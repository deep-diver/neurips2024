{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is heavily used and adapted throughout the research presented in the target paper."}, {"fullname_first_author": "Devansh Arpit", "paper_title": "A closer look at memorization in deep networks", "publication_date": "2017-07-01", "reason": "This paper provides crucial background on the memorization effect of deep neural networks, which is central to understanding the challenges of learning with noisy labels addressed by the target paper."}, {"fullname_first_author": "Bo Han", "paper_title": "Co-teaching: Robust training of deep neural networks with extremely noisy labels", "publication_date": "2018-12-01", "reason": "This paper introduces the Co-teaching algorithm for handling noisy labels, serving as a key antecedent to the proposed DEFT framework and influencing its sample selection strategies."}, {"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-07-01", "reason": "This paper introduces ResNet, a widely-used convolutional neural network architecture that serves as a backbone for many vision tasks, including those addressed in the target paper."}, {"fullname_first_author": "Alex Krizhevsky", "paper_title": "Learning multiple layers of feature from tiny images", "publication_date": "2009-01-01", "reason": "This paper introduces the CIFAR-100 dataset which is used as a benchmark for evaluating DEFT's performance on image classification tasks"}]}