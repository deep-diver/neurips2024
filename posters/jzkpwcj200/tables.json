[{"figure_path": "jzkpwcj200/tables/tables_22_1.jpg", "caption": "Table 1: Kendall's W per LLM", "description": "This table presents the Kendall's W values for each of the 15 LLMs evaluated in the paper. Kendall's W is a measure of agreement among rankings, ranging from 0 (no agreement) to 1 (perfect agreement).  In this context, it measures the consistency of each model's performance across different prompt templates within the MMLU benchmark. Higher Kendall's W values suggest greater consistency in a model's ranking across different prompts.", "section": "Details MMLU spread analysis"}, {"figure_path": "jzkpwcj200/tables/tables_23_1.jpg", "caption": "Table 2: Overview of Discrete Features", "description": "This table lists the discrete features used to represent prompt templates in the BBH and LMentry benchmarks.  It categorizes features into casing, formatting, special characters, and length features, providing a description of each feature and how it is counted.", "section": "M Heuristics for discrete features"}]