[{"figure_path": "lzfzjYuWgY/tables/tables_4_1.jpg", "caption": "Table 5: Probing performance (recovery rate) of all predicates on GRIPPER.", "description": "This table presents the results of probing experiments conducted on the GRIPPER dataset. It shows the recovery rate (a measure of how well the model's internal representations capture the predicates) for various predicates categorized by their abstraction level (raw, world-irrelevant, Q*-irrelevant, \u03c0*-irrelevant).  Different LLMs (Llama2, Mistral, Llama3, Pythia, Phi3, and a Transformer baseline) are evaluated, allowing for a comparison of their ability to maintain different abstraction levels.  The percentages reflect the accuracy of recovering each predicate from the LLM's representations.", "section": "6.2 Probing Results and Analysis"}, {"figure_path": "lzfzjYuWgY/tables/tables_6_1.jpg", "caption": "Table 1: Planning performance of Llama2-13b and Mistral on GRIPPER and COOK.", "description": "This table presents the performance of Llama2-13b and Mistral language models on two datasets, GRIPPER and COOK,  in terms of the percentage of legal actions, successful task completions, and optimal solutions (achieving the goal with the minimum number of steps).  It shows the models' performance before and after fine-tuning (FT) and demonstrates the improvement in planning abilities after fine-tuning.", "section": "6 Experiments"}, {"figure_path": "lzfzjYuWgY/tables/tables_9_1.jpg", "caption": "Table 2: Recovery rate with different encoding methods of label candidates.", "description": "This table presents the results of probing experiments using different encoding methods for label candidates in the context of LLM representations.  Specifically, it compares the recovery rate of various predicates using two methods: one incorporating the hidden states (ht) from the LLM and the contextualized embedding (Ctxt(e)) of the label candidate, and another using only the contextualized embedding (Ctxt(e)). The table shows that for some predicates, incorporating the hidden states improves performance, while for others it does not. This highlights the nuances of probing LLM representations, and the importance of selecting an appropriate approach depending on the specific predicate.", "section": "6.2 Probing Results and Analysis"}, {"figure_path": "lzfzjYuWgY/tables/tables_14_1.jpg", "caption": "Table 3: Textual templates used in GRIPPER and COOK.", "description": "This table lists the different textual templates used for the predicates in the GRIPPER and COOK datasets.  The templates provide variations in how the same predicate is expressed, adding to the realism and diversity of the datasets.  For example, the 'store' predicate has multiple variations like 'container contains object', 'container holds object', etc., for both datasets.  The 'boxName', 'grab', 'put', and 'move' predicates also have several variations, reflecting different ways of describing container names and actions.", "section": "4.2 Datasets"}, {"figure_path": "lzfzjYuWgY/tables/tables_18_1.jpg", "caption": "Table 1: Planning performance of Llama2-13b and Mistral on GRIPPER and COOK.", "description": "This table presents the performance of Llama2-13b and Mistral language models on two different datasets, GRIPPER and COOK.  The performance is measured using three metrics:  \\\"%Legal\\\" (the percentage of actions that comply with the task constraints), \\\"%Succ\\\" (the percentage of trials that successfully achieve the target state), and \\\"%Optim\\\" (the percentage of successful trials that achieve the target state using the minimum number of actions). The table shows that fine-tuning (SFT) significantly improves the performance of both models on both datasets, compared to using in-context learning (ICL).", "section": "6 Experiments"}, {"figure_path": "lzfzjYuWgY/tables/tables_18_2.jpg", "caption": "Table 5: Probing performance (recovery rate) of all predicates on GRIPPER.", "description": "This table presents the results of probing experiments conducted on the GRIPPER dataset. It shows the recovery rate, which is a normalized F1-score, for various predicates across different LLMs. Each predicate is categorized by its corresponding abstraction type (Raw, World-irrelevant, Q*-irrelevant, \u03c0*-irrelevant) which reflects the level of abstraction that a predicate maintains within an LLM\u2019s representation. The table offers insights into how well the different types of world abstractions are preserved within various LLMs' internal representations during decoding, indicating whether LLMs prioritize maintaining the complete world state, goal-oriented information or task-related details only.", "section": "6.2 Probing Results and Analysis"}, {"figure_path": "lzfzjYuWgY/tables/tables_18_3.jpg", "caption": "Table 5: Probing performance (recovery rate) of all predicates on GRIPPER.", "description": "This table presents the performance of probing different predicates across various LLMs on the GRIPPER dataset.  The recovery rate, a measure of how well the predicates could be recovered from the LLM's representations, is shown.  The table breaks down the results by abstraction type (Raw, World-irrelevant, Q*-irrelevant, \u03c0*-irrelevant) to analyze how different types of abstractions affect the ability to recover the predicates from the LLMs.  It compares the performance of different models (Llama2, Llama2-13b, Mistral, Llama3, Phi3-17b, Pythia-70m, Transformer).", "section": "6.2 Probing Results and Analysis"}, {"figure_path": "lzfzjYuWgY/tables/tables_19_1.jpg", "caption": "Table 7: Comparative experiments of probing color information under GRIPPER and COLORGRIPPER.", "description": "This table presents a comparison of the results from probing experiments conducted on two different datasets: GRIPPER and COLORGRIPPER.  The experiments involved assessing the ability of language models to identify specific color information.  The table shows that the recovery rate for color information is low when the color is irrelevant to the task (GRIPPER), but the recovery rate is significantly improved (37.70) when the color information becomes relevant to the task (COLORGRIPPER). This highlights that the model's ability to recover information is linked to task relevance, supporting the idea of goal-oriented abstraction.", "section": "6.2 Probing Results and Analysis"}, {"figure_path": "lzfzjYuWgY/tables/tables_19_2.jpg", "caption": "Table 8: Comparative probing experiments with Llama3-8b fine-tuned on original and suboptimal actions on GRIPPER.", "description": "This table presents a comparison of probing experiment results using Llama3-8b, fine-tuned on two different versions of the GRIPPER dataset: one with original, optimal action sequences and another with suboptimal sequences.  The goal is to assess how the use of suboptimal actions influences the recovery rates of different types of world abstractions (Raw, World-irrelevant, Q*-irrelevant, and \u03c0*-irrelevant).  Recovery rate represents the success of probing, indicating how well different levels of abstraction are maintained in the LLM's representations.", "section": "L Probing from LLMs Fine-tuned with Suboptimal Action Sequences"}, {"figure_path": "lzfzjYuWgY/tables/tables_19_3.jpg", "caption": "Table 4: Planning performance of LLMs on GRIPPER and COOK.", "description": "This table shows the performance of different LLMs on two datasets, GRIPPER and COOK.  The performance is measured using three metrics: the percentage of legal actions (following the task constraints), the success rate (achieving the target state), and the optimality rate (achieving the target state with the minimum number of actions).  The table compares the performance of different LLMs (Llama2, Mistral, Llama3, Phi3) using in-context learning (ICL) and supervised fine-tuning (SFT).", "section": "6 Experiments"}]