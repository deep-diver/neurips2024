[{"figure_path": "aDQlAz09dS/figures/figures_0_1.jpg", "caption": "Figure 1: TREACLE chooses LLMs to achieve high accuracy and ~85% cost reduction, compared to individual LLMs.", "description": "This figure shows the accuracy vs. total cost ($) for different LLMs and prompting methods on a specific task (likely mathematical reasoning problems based on the paper).  Each point represents a different combination of LLM (Llama-2-7b, Llama-2-13b, GPT-3.5-turbo, GPT-4) and prompt style (Chain-of-Thought, domain expert). The blue line represents the performance of TREACLE, a reinforcement learning policy that dynamically selects the optimal LLM and prompt combination to maximize accuracy while respecting a cost budget.  The figure demonstrates that TREACLE achieves significantly higher accuracy than individual LLMs at a much lower cost, highlighting its efficiency in selecting LLMs.", "section": "1 Introduction"}, {"figure_path": "aDQlAz09dS/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of TREACLE framework. TREACLE decides on the next (LLM, prompt) to query in a context-aware fashion, summarized in the state variable. It can adapt to unseen tasks by projecting the new queries into the text embedding space.", "description": "This figure illustrates the TREACLE framework's workflow.  It shows how TREACLE takes in a sequence of questions and a budget, and uses a reinforcement learning (RL) policy to select the optimal large language model (LLM) and prompt for each question. The selection is based on the current state, which includes response consistency, input/output lengths, the remaining budget, the current LLM and prompt, and a text embedding of the question.  The framework also demonstrates its ability to handle new, unseen question types by projecting these into the existing text embedding space.", "section": "4 Proposed Framework: TREACLE"}, {"figure_path": "aDQlAz09dS/figures/figures_6_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baselines across different cost functions (pure monetary price and price-latency tradeoffs) and budget constraints.  It showcases how TREACLE adapts to various cost structures and budgets while maintaining high accuracy. The dashed lines represent methods with unrealistic perfect knowledge of which models are best for which question, serving as upper bounds for comparison.  The plot shows accuracy on the y-axis and total budget on the x-axis, illustrating the accuracy-cost tradeoff for each method.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_7_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baselines across different cost functions and budget constraints.  The x-axis represents the total budget, and the y-axis represents the accuracy achieved.  Multiple lines show the performance for each method (TREACLE, Majority vote, Knapsack (online), Knapsack (offline), Single model, FrugalGPT, Calibrated cascade) under varying budgets and cost functions (pure monetary and monetary price-latency combination). The dashed lines represent theoretical upper bounds that assume perfect knowledge of question difficulty and cost which is not feasible in real-world scenarios. The figure demonstrates that TREACLE outperforms the baselines in most scenarios, approaching the theoretical optimum with higher budgets.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_7_2.jpg", "caption": "Figure 5: With and without re-querying.", "description": "This figure compares the performance of TREACLE with and without the ability to re-query.  The dashed lines represent model variants that permit re-querying, while the solid lines show models that do not allow re-querying. The figure shows that without re-querying, accuracy is significantly lower, especially at lower budgets.  Only with significantly larger budgets do models without re-querying achieve comparable accuracy to those with re-querying, highlighting the importance of the re-querying mechanism for maintaining high accuracy while saving cost.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_7_3.jpg", "caption": "Figure 6: Performance with new LLMs and lowered prices. Lines and dots in light (dark) colors are results with old (new) prices and LLMs. \u03b1 = 1/20.", "description": "This figure shows the performance of various models (including TREACLE and FrugalGPT) before and after fine-tuning with new LLMs (MetaMath and GPT-4-turbo) and adjusted pricing. The x-axis represents the total cost, and the y-axis represents the accuracy.  It demonstrates TREACLE's adaptability to new models and price changes, showing that after fine-tuning, it achieves higher accuracy with a lower budget compared to both its previous version and FrugalGPT.  Light colors represent the performance before the update, while dark colors represent the performance after updating with the new models and prices.", "section": "5.2.1 Addition of new LLMs"}, {"figure_path": "aDQlAz09dS/figures/figures_8_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baseline methods across various cost functions and budget levels.  The x-axis represents the total budget, while the y-axis shows the accuracy achieved.  Different lines represent different methods: TREACLE, FrugalGPT, a calibrated cascade approach, an offline and online knapsack algorithm, and a single model. The dashed lines represent methods that have perfect knowledge of the optimal cost-accuracy tradeoff (offline knapsack), showcasing the upper bound for performance. The results demonstrate that TREACLE consistently outperforms the other methods, approaching the performance of the offline knapsack, which is not feasible in a real-world setting.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_8_2.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baseline methods under various budget constraints and cost functions.  The x-axis represents the total budget, and the y-axis represents the accuracy.  Different lines represent different methods: TREACLE, FrugalGPT, a calibrated cascade, an online knapsack, an offline knapsack, and a single model.  The dashed lines show the performance of methods with perfect (offline) knowledge of the ideal model and prompt choices for each question, which is not feasible in reality but provides an upper bound on performance. The figure shows that TREACLE consistently outperforms the baselines in most scenarios, achieving accuracy close to the theoretical optimum (offline knapsack), especially when budgets are more constrained.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_9_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baseline methods across three different datasets (GSM8K, CSQA, and LLC) under various budget constraints and cost functions.  The cost functions consider pure monetary cost (with different scaling factors \u03b1) and a combination of monetary and latency cost (with different tradeoff coefficients \u03b2). The x-axis shows the total budget, and the y-axis represents the accuracy achieved. The figure highlights that TREACLE consistently outperforms the baselines and approaches the performance of the offline knapsack method (which has access to perfect knowledge of question difficulty and costs, making it impractical in real-world scenarios).", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_11_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure displays the performance of different methods for various cost functions and budget constraints.  The x-axis represents the total budget, and the y-axis represents the accuracy achieved. Several methods are compared: Majority Vote, Knapsack (online and offline), Single model, FrugalGPT, Calibrated Cascade, and TREACLE. The dashed lines represent methods with perfect knowledge (ground truth) of the best model to use, which provides a theoretical upper bound for performance.  The plot shows that TREACLE consistently outperforms the other baselines and approaches the performance of the impractical ground-truth methods.  The plot is shown across multiple cost functions (\u03b1=1/50, 1/20, 1/10, and \u03b2=50k, 500k, 1M).  Each of these represents different trade-offs between accuracy and monetary cost, showing the robustness of TREACLE.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_14_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of different methods for answering questions under various cost functions and budget constraints.  The x-axis represents the total budget, while the y-axis shows the accuracy.  Several methods are compared, including TREACLE, FrugalGPT, and various baseline methods. The dashed lines represent methods that have access to perfect knowledge (ground truth), which is not practical but serves as an upper bound on performance.  The plot shows how TREACLE achieves high accuracy while saving on cost, outperforming other methods, especially under tighter budgets. The results are shown for different cost functions, demonstrating TREACLE's robustness and adaptability.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_16_1.jpg", "caption": "Figure 1: TREACLE chooses LLMs to achieve high accuracy and ~85% cost reduction, compared to individual LLMs.", "description": "This figure shows the accuracy vs. cost trade-offs of various Llama and GPT LLMs on grade school math word problems.  The x-axis represents the total cost in dollars, and the y-axis represents the accuracy of the models. The different colored lines represent different LLMs and prompting schemes. The TREACLE line shows that the proposed approach achieves high accuracy at a significantly lower cost compared to the individual LLMs and prompting schemes.  It essentially finds the Pareto optimal frontier between cost and accuracy.", "section": "1 Introduction"}, {"figure_path": "aDQlAz09dS/figures/figures_17_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of different methods for solving reasoning problems under various budget constraints and cost functions.  The x-axis represents the total budget, and the y-axis represents the accuracy achieved.  Multiple lines represent different methods: TREACLE (the proposed method), Majority Voting, Offline and Online Knapsack (theoretical optimal methods with complete knowledge of all costs and benefits), FrugalGPT, and Calibrated Cascade.  The dashed lines represent theoretical upper bounds using offline methods that have access to perfect knowledge. The plot shows that TREACLE consistently outperforms other methods, approaching the performance of offline knapsack methods (which are impractical in real settings).  The performance is shown for GSM8K across different cost parameterizations (\u03b1 and \u03b2).", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_19_1.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of different methods for solving reasoning problems under various cost constraints and functions.  The x-axis represents the total budget allocated, and the y-axis represents the accuracy achieved.  The methods compared include TREACLE, FrugalGPT, a calibrated cascade, majority voting, and both online and offline knapsack approaches (the latter two having perfect knowledge of optimal costs). For each method, multiple lines are shown, each corresponding to a different cost function (pure monetary cost with varying coefficients, and combinations of monetary cost and latency). The dashed lines represent upper bounds on performance achievable if one had perfect knowledge of optimal costs which is generally not realistic.", "section": "5.2 Results"}, {"figure_path": "aDQlAz09dS/figures/figures_21_1.jpg", "caption": "Figure 1: TREACLE chooses LLMs to achieve high accuracy and ~85% cost reduction, compared to individual LLMs.", "description": "This figure shows the accuracy vs. total cost of various LLMs (Llama-2-7b, Llama-2-13b, GPT-3.5-turbo, GPT-4) using different prompting strategies (Chain-of-Thought (CoT), domain expert) on a specific task (grade-school math problems).  It highlights that TREACLE, the proposed method, significantly reduces cost while maintaining high accuracy by intelligently selecting the most cost-effective LLM and prompting scheme for each question. The Pareto front formed by TREACLE demonstrates its superior performance compared to using individual LLMs alone.", "section": "1 Introduction"}, {"figure_path": "aDQlAz09dS/figures/figures_21_2.jpg", "caption": "Figure 3: The performance of various methods for different cost functions and budget constraints. The dashed lines are methods that have ground knowledge, which is impractical but illustrates the best achievable performance.", "description": "This figure compares the performance of TREACLE against several baseline methods across various cost functions and budget constraints.  The x-axis represents the total budget, and the y-axis represents the accuracy achieved.  Different lines represent different methods, including TREACLE, a simple single model approach, FrugalGPT, and a calibrated cascade method.  The dashed lines represent theoretical optimal methods (offline and online knapsack) that have access to perfect information about the accuracy and cost of each model.  The figure shows that TREACLE consistently outperforms other methods across different budgets and cost functions.", "section": "5.2 Results"}]