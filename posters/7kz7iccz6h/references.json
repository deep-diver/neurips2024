{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the concept of prompt engineering and in-context learning, which are key techniques used and discussed in the CALVIN model."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is the vision encoder used in CALVIN, demonstrating the importance of large, multi-modal models for visual understanding."}, {"fullname_first_author": "Tengda Han", "paper_title": "AutoAD: Movie description in context", "publication_date": "2023-06-01", "reason": "AutoAD is a direct precursor to CALVIN, establishing the contextual video captioning task and providing a baseline model for comparison."}, {"fullname_first_author": "Mattia Soldan", "paper_title": "MAD: A scalable dataset for language grounding in videos from movie audio descriptions", "publication_date": "2022-06-01", "reason": "The MAD dataset is the primary dataset used in training CALVIN, highlighting its importance in providing contextual annotations for movies"}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "Flamingo is a key model in the evolution of VLMs, showing the feasibility of few-shot learning in visual language tasks, directly relevant to CALVIN's approach."}]}