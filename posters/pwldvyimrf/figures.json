[{"figure_path": "pwLdvYIMrF/figures/figures_0_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between standard causal language models and the proposed Train-Attention model. (a) shows how a causal language model processes text by decomposing it into multiple token sequences, each with varying importance but assigned uniform weights. This can lead to inefficiencies and increased forgetting in continual knowledge learning. (b) introduces the Train-Attention model, which uses meta-learning to predict token weights that approximate importance. This enables targeted knowledge updates and minimizes forgetting.", "section": "Introduction"}, {"figure_path": "pwLdvYIMrF/figures/figures_3_1.jpg", "caption": "Figure 2: (a) depicts the architecture of Train-Attention, which shares the structure of causal LM, while the decoder layer (LM head) of causal LM is replaced from a linear layer of [hidden size \u00d7 vocab size] dimension to [hidden size \u00d7 1] dimension, which is TA (Train-Attention) head. (b) depicts the TAALM, where the Train-Attention (\u03c6) is augmented to the base model (\u03b8).", "description": "This figure shows the architecture of Train-Attention and Train-Attention-Augmented Language Model (TAALM). Train-Attention is a model that predicts the optimal token weights to improve the efficiency of continual knowledge learning.  The left panel (a) shows the architecture of Train-Attention, highlighting how it replaces the standard LM head with a Train-Attention head that outputs a single weight for each token. The right panel (b) illustrates how Train-Attention is integrated with a causal language model (the base model) to create TAALM, where token weights are used during training to focus learning efforts on the most important tokens.", "section": "3 Train-Attention-Augmented Language Model (TAALM)"}, {"figure_path": "pwLdvYIMrF/figures/figures_3_2.jpg", "caption": "Figure 3: Optimal W leads \u03b8 closer to \u03b8*. ", "description": "This figure illustrates the meta-learning process of Train-Attention. The model \u03b8 is updated using token weights W predicted by Train-Attention \u03c6. The goal is to find the optimal weights W* that bring \u03b8 as close as possible to \u03b8*, which represents the ideal model capable of performing the task T<sub>D</sub>. The process is iterative, with \u03c6 being optimized to minimize the distance between \u03b8' (the updated model) and \u03b8*.  The figure visually represents the steps involved in this iterative optimization, showing the movement of \u03b8 towards \u03b8* with each update of the token weights.", "section": "3 Train-Attention-Augmented Language Model (TAALM)"}, {"figure_path": "pwLdvYIMrF/figures/figures_3_3.jpg", "caption": "Figure 4: One step update of $\n$.", "description": "This figure shows a detailed breakdown of a single step within the Train-Attention model's training process. It illustrates how the base model (\u03b8) and the Train-Attention model ($\n$) interact and update their respective parameters.  The process involves predicting token weights (W) using the Train-Attention model, using these weights to update the base model, and then using the updated base model to evaluate task performance and update the Train-Attention model accordingly. The green and pink shading represents gradient tracking for \u03b8 and $\n$, respectively, emphasizing the meta-learning aspect of the model.", "section": "3 Train-Attention-Augmented Language Model"}, {"figure_path": "pwLdvYIMrF/figures/figures_4_1.jpg", "caption": "Figure 5: Evaluation procedure of the LAMA-CKL benchmark.", "description": "This figure illustrates the evaluation procedure for the LAMA-CKL benchmark.  The process involves two phases: a training phase using the 'To-Learn' dataset (500 units from LAMA's T-Rex, focusing on time-variant relations and zero accuracy in baseline models), and a testing phase assessing both 'To-Learn' and 'Not-To-Forget' tasks. The 'To-Learn' task evaluates plasticity (ability to learn new knowledge) while the 'Not-To-Forget' task assesses stability (retention of prior knowledge).  This is repeated over 30 epochs.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_5_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between a standard causal language model and the proposed Train-Attention model. (a) shows how a standard causal language model processes text by uniformly weighting all tokens, which can lead to inefficiencies in continual knowledge learning. (b) shows how the Train-Attention model addresses this by dynamically predicting and applying weights to tokens based on their importance. This allows for more targeted knowledge updates and minimizes forgetting.", "section": "Introduction"}, {"figure_path": "pwLdvYIMrF/figures/figures_6_1.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of various baseline models on the LAMA-CKL benchmark using the Llama2-7B model.  The left graph displays the \"TO-LEARN\" accuracy (how well the model learns new knowledge), while the right graph shows the \"NOT-TO-FORGET\" accuracy (how well the model retains previously learned knowledge).  Both graphs plot accuracy against the number of training epochs, illustrating the trade-off between learning new information and forgetting old information for each model.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_7_1.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of various baseline models on the LAMA-CKL benchmark.  The left graph displays the \"To-Learn\" accuracy (ability to learn new knowledge) over 30 epochs, while the right graph shows the \"Not-To-Forget\" accuracy (ability to retain previously learned knowledge).  It compares the performance of standard fine-tuning (Finetune) against other continual knowledge learning (CKL) approaches (K-Adapter, Mix-review, RecAdam, RHO-1) and the proposed TAALM model.  The x-axis represents the training epoch, and the y-axis represents the accuracy.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_12_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between traditional causal language models and the proposed Train-Attention model. (a) shows that standard causal language models uniformly weight all tokens during training, which can be inefficient. (b) introduces the Train-Attention model, which uses a meta-learning approach to dynamically predict token weights based on their importance, leading to more efficient continual knowledge updates and minimizing catastrophic forgetting.", "section": "Introduction"}, {"figure_path": "pwLdvYIMrF/figures/figures_15_1.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of different continual knowledge learning (CKL) methods on the LAMA-CKL benchmark using the Llama2-7B language model. The left graph displays the accuracy of the \"To-Learn\" task (learning new knowledge), while the right graph shows the accuracy of the \"Not-To-Forget\" task (retaining previously learned knowledge).  The x-axis represents the number of training epochs, and the y-axis shows the accuracy.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_16_1.jpg", "caption": "Figure 11: Comparison of each baseline alone and combined with our method. Each title on the plot represents the baseline method. The gray line represents the baseline alone, and the red line represents the combination with TAALM. Solid line for TO-LEARN, dashed line for NOT-TO-FORGET. All are based on Llama2-7B, and tested on LAMA-CKL.", "description": "This figure compares the performance of several continual knowledge learning (CKL) baselines both individually and when combined with the proposed TAALM method.  It shows the TO-LEARN (plasticity) and NOT-TO-FORGET (stability) accuracy over 30 epochs for each model. The solid lines represent TO-LEARN accuracy, and the dashed lines represent NOT-TO-FORGET accuracy.  The results demonstrate that incorporating TAALM consistently improves both the plasticity and stability of the various CKL approaches.", "section": "A.4.2 Combination of ours (TAALM) and other baselines"}, {"figure_path": "pwLdvYIMrF/figures/figures_16_2.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of various baseline models on the LAMA-CKL benchmark using the Llama2-7B language model.  The left graph displays the TO-LEARN accuracy (how well the model learns new knowledge) and the right graph shows the NOT-TO-FORGET accuracy (how well the model retains previously learned knowledge) over 30 epochs.  The x-axis represents the training epoch, and the y-axis represents the accuracy.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_17_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between standard causal language models and the proposed Train-Attention model. (a) shows how standard models uniformly weight all tokens, leading to inefficiency, while (b) shows the Train-Attention model dynamically predicting weights based on token importance, improving learning efficiency and reducing catastrophic forgetting.", "section": "Introduction"}, {"figure_path": "pwLdvYIMrF/figures/figures_17_2.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of different continual knowledge learning baselines on the LAMA-CKL benchmark using the Llama2-7B language model.  The left graph displays the To-Learn accuracy (plasticity), showing how well the models learn new knowledge. The right graph illustrates the Not-To-Forget accuracy (stability), indicating how well the models retain previously learned knowledge.  The x-axis represents the training epoch, while the y-axis represents the accuracy.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_18_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between the standard causal language model training and the proposed Train-Attention method. (a) shows how a standard causal language model processes text by uniformly weighting all tokens regardless of their importance. This leads to inefficiencies and unnecessary parameter updates. (b) introduces the Train-Attention model, which dynamically predicts token importance and applies weights accordingly. This targeted approach improves learning efficiency and minimizes forgetting in continual knowledge learning (CKL).", "section": "Introduction"}, {"figure_path": "pwLdvYIMrF/figures/figures_20_1.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of different large language models on the LAMA-CKL benchmark.  The left graph displays the accuracy of the models in learning new knowledge (TO-LEARN), while the right graph illustrates their ability to retain previously learned knowledge (NOT-TO-FORGET) over 30 epochs. It highlights the trade-off between learning new information and forgetting old information in continual knowledge learning.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_21_1.jpg", "caption": "Figure 7: LAMA-CKL performance of large (Llama2-7B) baseline models. The graph on the left represents TO-LEARN task, and the graph on the right represents NOT-TO-FORGET task performance. The x-axis is the learning epoch, and the y-axis is accuracy.", "description": "This figure shows the performance of different large language models (LLMs) on the LAMA-CKL benchmark.  The left graph displays the \"To-Learn\" accuracy, measuring the model's ability to learn new knowledge. The right graph shows the \"Not-To-Forget\" accuracy, representing the model's ability to retain previously learned knowledge.  Both graphs plot accuracy against the number of training epochs.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/figures/figures_22_1.jpg", "caption": "Figure 1: (a) Learning of Causal LM: The document is decomposed into multiple token sequences Sixi x<i\u00b3, which aligns with different importance, but uniformly weighted. (b) Train-Attention: Our proposed Train-Attention learns to predict weights that approximate importance, to enable targeted continual knowledge updates through label-free meta-learning method.", "description": "This figure illustrates the difference between traditional causal language models and the proposed Train-Attention model. (a) shows how a standard causal language model processes text by uniformly weighting all tokens, which can lead to inefficiencies in continual knowledge learning. (b) introduces the Train-Attention model, which dynamically predicts and applies weights to tokens based on their importance, leading to more efficient knowledge updates and reduced forgetting.", "section": "Introduction"}]