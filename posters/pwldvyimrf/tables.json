[{"figure_path": "pwLdvYIMrF/tables/tables_6_1.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the quantitative results of different continual knowledge learning (CKL) methods on the LAMA-CKL benchmark using the Llama2-7B language model.  The metrics evaluated are Top Accuracy (Top Acc), the epoch at which the highest accuracy was achieved, Not-To-Forget Accuracy (NF Acc), and Total Knowledge (sum of Top Acc and NF Acc).  The table highlights the superior performance of TAALM (Train-Attention-Augmented Language Model) compared to existing baselines, demonstrating its effectiveness in balancing learning new knowledge and retaining old knowledge.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_8_1.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the results of several continual knowledge learning (CKL) methods on the LAMA-CKL benchmark using the Llama2-7B language model.  It compares the performance of different approaches including fine-tuning, K-Adapter, Mix-review, RecAdam, RHO-1, and the proposed TAALM method. The metrics used for comparison are Top Accuracy (Top Acc), the epoch at which Top Acc was achieved (Epoch), Not-To-Forget Accuracy (NF Acc), and Total Knowledge (sum of Top Acc and NF Acc).  The table highlights the superior performance of TAALM in terms of both learning speed and overall knowledge retention.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_12_1.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the performance of different baselines on the LAMA-CKL benchmark using the Llama2-7B language model.  The metrics used to evaluate the performance are Top Accuracy (Top Acc), the epoch at which the top accuracy was achieved, Not-To-Forget Accuracy (NF Acc), and Total Knowledge (sum of Top Acc and NF Acc). The best performing model for each metric is highlighted in bold, and the second-best model is underlined.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_13_1.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the results of several continual knowledge learning (CKL) baselines on the LAMA-CKL benchmark using the Llama2-7B language model.  The metrics used to evaluate the performance are Top Accuracy (Top Acc), the epoch at which this top accuracy is reached (Epoch), Not-To-Forget Accuracy (NF Acc), and Total Knowledge (a sum of Top Acc and NF Acc).  The table highlights the best performing model in bold and the second-best in italics, providing a comparison of various CKL approaches.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_13_2.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the results of different continual knowledge learning (CKL) methods on the LAMA-CKL benchmark using the Llama2-7B language model.  The metrics evaluated include Top Accuracy (the highest accuracy achieved during the 30 epochs of training), Epoch (the epoch at which the Top Accuracy was achieved), Not-To-Forget Accuracy (accuracy on the tasks not meant to be forgotten), and Total Knowledge (sum of Top and Not-To-Forget Accuracies). The table allows for comparison of the performance of various CKL methods, highlighting the best and second-best performers.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_15_1.jpg", "caption": "Table 5: LAMA-CKL performance of small (TinyLlama-1B) baselines.", "description": "This table presents the results of the LAMA-CKL experiment using the smaller TinyLlama-1B language model.  It shows the Top Accuracy (Top Acc) achieved by each method, the epoch at which this top accuracy was reached, the Not-To-Forget Accuracy (NF Acc), which measures the model's ability to retain previously learned knowledge, and the Total Knowledge, which is the sum of Top Acc and NF Acc.  This allows for comparison of different continual knowledge learning methods in terms of both learning new knowledge and retaining old knowledge when using a smaller model.", "section": "A.4.1 LAMA-CKL Experiment on small (1B) baselines"}, {"figure_path": "pwLdvYIMrF/tables/tables_16_1.jpg", "caption": "Table 6: Combination of ours (TAALM) and other baselines. Based on Llama2-7B, tested on LAMA-CKL.", "description": "This table presents the results of experiments combining the proposed Train-Attention (TAALM) method with other continual knowledge learning (CKL) baselines on the LAMA-CKL benchmark.  It shows the Top Accuracy (Top Acc), the epoch at which the top accuracy was achieved (Epoch), the Not-to-Forget Accuracy (NF Acc), and the total knowledge (sum of Top Acc and NF Acc) for each combination. The goal is to evaluate the synergistic effect of combining TAALM with existing CKL approaches and to determine if this improves performance on both learning new information (plasticity) and retaining old information (stability).", "section": "A.4.2 Combination of ours (TAALM) and other baselines"}, {"figure_path": "pwLdvYIMrF/tables/tables_19_1.jpg", "caption": "Table 2: TEMPORALWIKI performacne of small (TinyLlama-1B) baselines. Un refers UNCHANGED, C refers CHANGED, Avg refers the average of the two. TAALM is our method.", "description": "This table shows the performance of different continual knowledge learning (CKL) methods on the TEMPORALWIKI benchmark using a small language model (TinyLlama-1B).  The benchmark consists of four periods (0809, 0910, 1011, 1112).  For each period, the results are presented separately for unchanged (Un) and changed (C) knowledge. The average performance is also calculated. The table compares several baselines against the proposed TAALM method. The results are presented in terms of perplexity, demonstrating the ability of each method to retain previously learned knowledge while learning new knowledge.", "section": "4.2 TEMPORALWIKI"}, {"figure_path": "pwLdvYIMrF/tables/tables_20_1.jpg", "caption": "Table 1: LAMA-CKL performance of Llama2-7B based baselines. The evaluation indicator of each column is explained on \u00a74.1. The best performance is marked as bold while the second best is underlined.", "description": "This table presents the results of the LAMA-CKL experiment using the Llama2-7B language model. It compares the performance of different continual knowledge learning (CKL) methods.  The metrics used for comparison are Top Accuracy (Top Acc), the epoch at which the top accuracy was achieved (Epoch), Not-Forgotten Accuracy (NF Acc), and the total knowledge retained (Total Knowledge).  The table highlights the best-performing method by bolding its results and the second-best by underlining them.", "section": "4.1 LAMA-CKL"}, {"figure_path": "pwLdvYIMrF/tables/tables_21_1.jpg", "caption": "Table 9: LAMA-CKL performance of Llama2-7B based baselines.", "description": "This table presents the results of the LAMA-CKL experiment using Llama2-7B baselines.  It compares the performance of the proposed TAALM model with several variants (different token weighting strategies) against a standard finetune baseline. The metrics reported include Top Acc (the highest TO-LEARN accuracy), Epoch (the epoch where the Top Acc occurs), NF Acc (NOT-TO-FORGET accuracy), and Total Knowledge (sum of Top Acc and NF Acc), allowing for a comprehensive evaluation of the continual knowledge learning performance.", "section": "E Ablation"}]