[{"figure_path": "Ao0FiZqrXa/figures/figures_0_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares different diffusion model acceleration methods based on their FID (Fr\u00e9chet Inception Distance) scores and fine-tuning time (in A100 GPU hours).  It highlights that the proposed SFD method (Simple and Fast Distillation) achieves state-of-the-art performance with significantly less fine-tuning time compared to existing methods. The x-axis represents the fine-tuning time, and the y-axis represents the FID score. Lower FID values indicate better image generation quality, and shorter fine-tuning times indicate higher efficiency. The chart is divided into solver-based and distillation-based methods, with SFD falling into the latter and outperforming other distillation methods.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares different diffusion model acceleration methods based on their FID score (a measure of image quality) and fine-tuning time.  The x-axis represents the fine-tuning time on a single NVIDIA A100 GPU, and the y-axis represents the FID score achieved by the method at a specified number of function evaluations (NFEs). The figure demonstrates that the proposed method (SFD) achieves state-of-the-art performance with significantly reduced fine-tuning time compared to other methods.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_3_1.jpg", "caption": "Figure 3: MODEL(\u03c8n) is trained to match the teacher's sampling trajectory at tn but can enhance the matching at untrained timestamps. The time schedule follows the polynomial schedule with p = 7, to = 0.002, t4 = 80.", "description": "This figure shows the results of an ablation study to validate the strategy of fine-tuning only a few timestamps that will be used in sampling. Four different student models are initialized from a pre-trained teacher model and fine-tuned only on a certain timestamp. The L2 distance between the teacher and student model sampling trajectory is calculated and visualized for all timestamps. The results demonstrate that fine-tuning at a specific timestamp can positively impact the gradient direction at other timestamps, even though they are far apart, which means that fine-tuning on a fine-grained time schedule is unnecessary.", "section": "3 Method"}, {"figure_path": "Ao0FiZqrXa/figures/figures_4_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares different diffusion model acceleration methods based on their FID score (a measure of image quality) and fine-tuning time.  It highlights that the proposed SFD method (marked with a star) achieves state-of-the-art FID scores while requiring significantly less fine-tuning time than other methods. The x-axis is the fine-tuning time on a single NVIDIA A100 GPU (in hours), and the y-axis is the FID score.  The chart distinguishes between solver-based and distillation-based methods, illustrating the superior efficiency of the proposed SFD approach.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_5_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares various diffusion model acceleration methods based on their FID score (a measure of image generation quality) and fine-tuning time on a single NVIDIA A100 GPU.  It shows that the proposed SFD method achieves state-of-the-art performance with significantly reduced fine-tuning time compared to other methods. The x-axis is a log scale representing the fine-tuning time in hours, while the y-axis represents the FID score. The different markers represent different acceleration methods, categorized as solver-based or distillation-based methods. The figure highlights the superior performance and efficiency of the SFD approach.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_5_2.jpg", "caption": "Figure 8: Ablation study on the type of condition.", "description": "This ablation study compares the performance of two different conditioning methods used in the SFD-v model for variable-NFE distillation.  The graph shows the FID scores over training iterations for both the 'tnext-cond' (next time step condition) and 'step-cond' (step condition) approaches, each tested at different numbers of function evaluations (NFEs). The results indicate that the 'step-cond' approach generally performs better than 'tnext-cond' in achieving lower FID scores across various NFEs, demonstrating its superior effectiveness for variable-step sampling.", "section": "3.3 Towards Variable-NFE Distillation"}, {"figure_path": "Ao0FiZqrXa/figures/figures_6_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares various acceleration methods for diffusion models based on their FID score and fine-tuning time on a single NVIDIA A100 GPU.  It highlights the trade-off between achieving a low FID (indicating high-quality image generation) and the time required for fine-tuning a model.  The authors' method (SFD) is shown to achieve state-of-the-art FID scores with significantly reduced fine-tuning times compared to other methods, emphasizing its efficiency.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_8_1.jpg", "caption": "Figure 10: Ablation study on one-NFE distillation.", "description": "This ablation study compares different loss functions (L1, L1 + LPIPS) and training approaches (single-stage SFD, two-stage SFD) for one-NFE distillation. The y-axis represents the FID score, a measure of image quality, and the x-axis shows the number of training iterations.  The results illustrate the impact of the loss function and the benefit of the second stage of training on improving the quality of images generated with only one step in the sampling process.", "section": "3.4 Distillation under Classifier-free Guidance"}, {"figure_path": "Ao0FiZqrXa/figures/figures_19_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure compares various acceleration methods for diffusion models based on the fine-tuning time and FID score (Fr\u00e9chet Inception Distance) at different numbers of function evaluations (NFEs).  It shows that the proposed method (SFD) achieves state-of-the-art performance with significantly reduced fine-tuning time compared to other methods, highlighting its efficiency and effectiveness in accelerating diffusion model sampling.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_20_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure compares different acceleration methods for diffusion models in terms of FID (Fr\u00e9chet Inception Distance) score and fine-tuning time. It shows that the proposed SFD method (Simple and Fast Distillation) achieves state-of-the-art performance with significantly reduced fine-tuning time compared to other methods.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_21_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure shows a comparison of different diffusion model acceleration methods, plotting the FID score against the fine-tuning time required on a single NVIDIA A100 GPU.  The x-axis is fine-tuning time (in hours, shifted for better visualization), and the y-axis is the Fr\u00e9chet Inception Distance (FID), a measure of image quality.  Various methods are represented, categorized into solver-based and distillation-based approaches. The figure highlights that the proposed SFD method achieves state-of-the-art FID scores with significantly lower fine-tuning time compared to other methods.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_21_2.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure compares different acceleration methods for diffusion models based on the FID score and the fine-tuning time required.  It shows that the proposed method (SFD) achieves state-of-the-art performance with significantly less fine-tuning time compared to other methods.  The x-axis is the fine-tuning time (in hours on a single NVIDIA A100 GPU), and the y-axis is the FID score, a measure of image generation quality. Lower FID indicates better quality. The chart highlights that SFD achieves a good balance between sample quality and the cost of fine-tuning.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_22_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure compares various acceleration methods for diffusion models in terms of their final FID score and the time it took to fine-tune the models.  It highlights that the proposed SFD method (Simple and Fast Distillation) achieves state-of-the-art performance with significantly less fine-tuning time compared to other methods.  The y-axis represents the final FID score (lower is better), while the x-axis shows the fine-tuning time in hours on a single NVIDIA A100 GPU. The figure uses a log scale for the x-axis to better visualize the large differences in fine-tuning times.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_22_2.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "The figure compares different acceleration methods for diffusion models in terms of FID score and fine-tuning time. It highlights that the proposed SFD method achieves state-of-the-art performance with significantly lower fine-tuning time compared to other methods.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_23_1.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares various diffusion model acceleration methods based on their FID score and fine-tuning time.  It highlights that the proposed SFD method (shown as \u2605) achieves state-of-the-art FID scores (a measure of image quality) with significantly lower fine-tuning time (approximately 1000x faster) compared to other methods. The x-axis is the fine-tuning time (in hours) on an NVIDIA A100 GPU, and the y-axis represents the FID score. The figure emphasizes SFD's efficiency in achieving high-quality image generation at a fraction of the computational cost.", "section": "1 Introduction"}, {"figure_path": "Ao0FiZqrXa/figures/figures_23_2.jpg", "caption": "Figure 1: Comparison of acceleration methods on diffusion models. For better visualization, the time axis is shifted by adding one hour to the actual time required. Our method achieves good performance with a small fine-tuning cost. Note that it takes about 200 hours to train a diffusion model from scratch in this setting.", "description": "This figure compares various acceleration methods for diffusion models based on the Fine-tuning time (in A100 hours) against the FID score (a measure of image quality).  It highlights that the proposed SFD method achieves state-of-the-art performance with significantly reduced fine-tuning time compared to other methods.  The x-axis is a log scale.", "section": "1 Introduction"}]