[{"figure_path": "OtvNLTWYww/figures/figures_6_1.jpg", "caption": "Figure 1: Synthetic experiments of in-context alignment with comparison between TF and GD (a), different reward noise p (b), model depth (c), and attention types (d), (e), (f).", "description": "This figure presents the results of synthetic experiments designed to validate the theoretical analysis presented in the paper.  The experiments compare the performance of transformers (TF) and gradient descent (GD) in an in-context learning setting for a linear regression task.  Several factors are investigated: (a) compares TF and GD; (b) explores the impact of noise in reward signals; (c) examines the effect of the number of layers in the transformer model; (d) contrasts softmax and linear attention mechanisms; (e) assesses the impact of the number of attention heads; and (f) investigates the role of the feed-forward network (FFN) module. The results show that transformers are capable of learning alignment tasks in-context and that various aspects of transformer architecture contribute to their ability to do this.", "section": "4 Verification on Synthetic Data"}, {"figure_path": "OtvNLTWYww/figures/figures_7_1.jpg", "caption": "Figure 1: Synthetic experiments of in-context alignment with comparison between TF and GD (a), different reward noise p (b), model depth (c), and attention types (d), (e), (f).", "description": "The figure presents the results of synthetic experiments evaluating in-context alignment.  It compares the performance of a Transformer model (TF) against gradient descent (GD) under various conditions. Panel (a) directly contrasts TF and GD performance. Panels (b), (c), (d), (e), and (f) investigate the effects of different levels of reward noise, model depth, attention type (softmax vs linear), number of attention heads, and the feed-forward network (FFN) module, respectively. Each panel shows the normalized mean squared error (MSE) as a function of the number of in-context examples, providing insights into the relative effectiveness of TF and GD and the impact of various architectural choices.", "section": "4 Verification on Synthetic Data"}, {"figure_path": "OtvNLTWYww/figures/figures_8_1.jpg", "caption": "Figure 3: Real world alignment experiment of different categories of biases (ses is short for Socioeconomic Status). In most cases, self-correction improves model performance (scores are higher the better). (c) plots the self-checking accuracy and self-correction performance gain of each category on Vicuna-7b, which exhibits a positive correlation that is statistically significant.", "description": "This figure presents the results of real-world experiments evaluating the effectiveness of self-correction in mitigating social biases in LLMs.  The experiments were conducted on two LLMs, Llama2-7b-chat and Vicuna-7b, across nine social dimensions (age, disability, gender, appearance, sexual orientation, race, religion, socioeconomic status, and nationality), plus two intersectional categories (race x socioeconomic status and race x gender).  Subplots (a) and (b) show the performance of each LLM with and without self-correction for each bias category using radar charts. Subplot (c) displays a scatter plot showing the correlation between self-checking accuracy and the gain in performance achieved through self-correction on Vicuna-7b, illustrating that higher self-checking accuracy is associated with greater performance gains from self-correction.", "section": "5 Exploring Self-correction on Real-world Alignment Tasks"}, {"figure_path": "OtvNLTWYww/figures/figures_9_1.jpg", "caption": "Figure 1: Synthetic experiments of in-context alignment with comparison between TF and GD (a), different reward noise p (b), model depth (c), and attention types (d), (e), (f).", "description": "This figure presents results from synthetic experiments designed to validate the theoretical analysis of in-context alignment.  Panel (a) compares the performance of a transformer-based model (TF) against gradient descent (GD) optimization, demonstrating that both methods effectively improve with increasing in-context examples. Panel (b) examines the impact of noise in reward signals (p) on performance. Panel (c) investigates the effect of the transformer's depth (number of layers) on performance. Finally, panels (d), (e), and (f) explore the effect of different attention mechanisms (softmax vs linear attention, varying number of heads, and presence/absence of the feed-forward network (FFN)), respectively.  Overall, the experiments show that transformers learn in-context alignment effectively and that certain architectural choices are crucial for this ability.", "section": "4 Verification on Synthetic Data"}, {"figure_path": "OtvNLTWYww/figures/figures_21_1.jpg", "caption": "Figure 3: Real world alignment experiment of different categories of biases (ses is short for Socioeconomic Status). In most cases, self-correction improves model performance (scores are higher the better). (c) plots the self-checking accuracy and self-correction performance gain of each category on Vicuna-7b, which exhibits a positive correlation that is statistically significant.", "description": "This figure presents the results of real-world experiments evaluating the effectiveness of self-correction in mitigating social biases in LLMs.  Subfigures (a) and (b) show the performance of Llama2-7b-chat and Vicuna-7b, respectively, on various bias categories (age, disability, gender, etc.) with and without self-correction.  The results indicate that self-correction generally improves performance across bias categories.  Subfigure (c) shows a correlation analysis on Vicuna-7b demonstrating a positive relationship between self-checking accuracy and the performance gain achieved through self-correction.", "section": "5.1 Alleviating Social Bias with Self-correction"}, {"figure_path": "OtvNLTWYww/figures/figures_21_2.jpg", "caption": "Figure 3: Real world alignment experiment of different categories of biases (ses is short for Socioeconomic Status). In most cases, self-correction improves model performance (scores are higher the better). (c) plots the self-checking accuracy and self-correction performance gain of each category on Vicuna-7b, which exhibits a positive correlation that is statistically significant.", "description": "This figure presents the results of real-world experiments on two LLMs (Llama2-7b-chat and Vicuna-7b) to evaluate the effectiveness of self-correction in mitigating social biases.  Subfigures (a) and (b) show the performance gains (difference in scores with and without self-correction) across various bias categories (age, disability, gender, nationality, race, religion, socioeconomic status, sexual orientation, and appearance), with positive gains indicating improved performance after self-correction. Subfigure (c) displays a correlation analysis specifically for Vicuna-7b, illustrating a statistically significant positive correlation between the self-checking accuracy and the performance gain achieved through self-correction.", "section": "Alleviating Social Bias with Self-correction"}, {"figure_path": "OtvNLTWYww/figures/figures_26_1.jpg", "caption": "Figure 7: Structure of one iterator of a transformer block in Proof E.3. Details of (1) and (2) are illustrated in Lemma E.6 and Lemma E.7 respectively.", "description": "This figure shows the architecture of one iteration in the proof of Theorem 3.3.  The proof uses a multi-layer transformer to implement the gradient descent of the Plackett-Luce model for in-context alignment. This specific diagram details one of the N-1 transformer blocks needed. Each block consists of a multi-head self-attention (MHSA) layer and a feed-forward network (FFN). The diagram shows how the inputs are processed through the MHSA and FFN to produce the final output.  Lemmas E.6 and E.7, referenced in the caption, provide further details about the specific calculations within the MHSA and FFN layers.", "section": "E Proofs"}]