[{"figure_path": "bZpZMdY1sj/figures/figures_1_1.jpg", "caption": "Figure 1: VLAD and SuperVLAD similarity measures under different clusterings (Voronoi cells). Orange triangles and blue diamonds depict local descriptors from two different images. In (a) and (b), orange and blue arrows are the sum of residuals (for VLAD). With different training data distributions, the different cluster centers are yielded, causing opposite similarity results using cosine similarity (or normalized L2 distance). Compared to VLAD, our SuperVLAD, as shown in (c) and (d), simply calculates the distance between the weighted sum of local features directly, freeing from the impact of cluster centers. Thus, only minor changes will occur when dealing with two different distributions.", "description": "This figure illustrates the difference between VLAD and SuperVLAD in handling different training data distributions. VLAD, shown in (a) and (b), uses cluster centers to aggregate local features, resulting in sensitivity to data distribution changes.  SuperVLAD, shown in (c) and (d), directly calculates the weighted sum of local features, making it more robust to these changes.", "section": "1 Introduction"}, {"figure_path": "bZpZMdY1sj/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the proposed SuperVLAD layer. It aggregates the patch tokens output by the transformer-based backbone and produces a K \u00d7 D vector as the global descriptor. Note that the VLAD core of SuperVLAD has no cluster center, which is the main difference from NetVLAD.", "description": "This figure illustrates the SuperVLAD layer architecture.  The input is the patch tokens from a transformer-based backbone. These tokens are then processed by a 1x1 convolutional layer and a softmax layer for soft-assignment to K clusters.  Unlike NetVLAD, there are no cluster centers. The weighted sum of the assigned local features is then computed in a VLAD core to form the global descriptor which is finally intra-normalized and L2 normalized.  The use of 'ghost' clusters is also shown, indicating that some clusters are not included in the final output.", "section": "3 Methodology"}, {"figure_path": "bZpZMdY1sj/figures/figures_3_2.jpg", "caption": "Figure 3: Unlike VLAD, since the parameters wk and bk used for soft-assignment in (1) NetVLAD are decoupled from cluster center ck, ck does not necessarily coincide with the true centroid of the cluster (Voronoi cell). Its robustness against domain shift can be improved to some extent. SuperVLAD completely eliminates the need for cluster centers and (2) avoids their negative impact.", "description": "This figure compares VLAD and NetVLAD's approaches to assigning local features to clusters and highlights SuperVLAD's improvement.  VLAD uses hard assignment based on distance to cluster centers (ck), while NetVLAD uses soft assignment, where weights (wk and bk) are decoupled from the cluster centers.  SuperVLAD improves further by completely removing the need for cluster centers, making it more robust to domain shift and training data variations. The figure uses Voronoi cells to illustrate cluster assignments and the impact of cluster centers.", "section": "3 Methodology"}, {"figure_path": "bZpZMdY1sj/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative results. In these four challenging examples (covering viewpoint variations, condition variations, dynamic objects, etc.), our SuperVLAD successfully retrieves the right database images, while other methods get the wrong results.", "description": "This figure presents four challenging examples where viewpoint, condition, and dynamic objects cause variations in the images.  It demonstrates the superior performance of SuperVLAD in successfully retrieving the correct database images, while other methods fail, highlighting SuperVLAD's robustness to various challenges.", "section": "4 Experiments"}, {"figure_path": "bZpZMdY1sj/figures/figures_7_1.jpg", "caption": "Figure 5: The comparison of some global-retrieval-based methods in Recall@1 (on Pitts30k), inference time (ms/single image), and descriptor dimensionality. The diameter of each dot is proportional to the descriptor dimension. Our SuperVLAD gets the best R@1 with the most compact descriptor.", "description": "This figure compares several global retrieval-based visual place recognition methods using three metrics: Recall@1 on the Pitts30k dataset, inference time per image, and descriptor dimensionality.  The size of each data point visually represents the dimensionality of the descriptor.  SuperVLAD demonstrates superior Recall@1 performance with a significantly smaller descriptor size and faster inference time compared to the other methods.", "section": "4.4 Ablation Study"}, {"figure_path": "bZpZMdY1sj/figures/figures_16_1.jpg", "caption": "Figure 1: VLAD and SuperVLAD similarity measures under different clusterings (Voronoi cells). Orange triangles and blue diamonds depict local descriptors from two different images. In (a) and (b), orange and blue arrows are the sum of residuals (for VLAD). With different training data distributions, the different cluster centers are yielded, causing opposite similarity results using cosine similarity (or normalized L2 distance). Compared to VLAD, our SuperVLAD, as shown in (c) and (d), simply calculates the distance between the weighted sum of local features directly, freeing from the impact of cluster centers. Thus, only minor changes will occur when dealing with two different distributions.", "description": "This figure compares the VLAD and SuperVLAD methods' similarity measures under varying clusterings.  It uses a visual representation of local descriptors from two images to illustrate how VLAD's reliance on cluster centers leads to sensitivity to training data distribution, resulting in potentially opposite similarity results depending on the training data.  SuperVLAD, in contrast, directly calculates the weighted sum of features, making it more robust to differences in training data distributions.", "section": "1 Introduction"}, {"figure_path": "bZpZMdY1sj/figures/figures_17_1.jpg", "caption": "Figure 7: Qualitative results on the MSLS dataset. The first query lacks distinctive landmarks. The first two examples show significant viewpoint changes between the query and the correct reference image. For the third query, most of the other methods returned the same erroneous place due to the inability to distinguish small-scale differences in the building surface. Only our method provides the correct result.", "description": "This figure shows three qualitative examples from the MSLS dataset demonstrating the performance of SuperVLAD against other state-of-the-art methods.  The first query image lacks distinctive landmarks, the second shows significant viewpoint differences between the query and correct match, and the third illustrates difficulty in distinguishing subtle differences in building appearance.  SuperVLAD is the only method that correctly identifies the place in all three scenarios.", "section": "4 Experiments"}, {"figure_path": "bZpZMdY1sj/figures/figures_17_2.jpg", "caption": "Figure 4: Qualitative results. In these four challenging examples (covering viewpoint variations, condition variations, dynamic objects, etc.), our SuperVLAD successfully retrieves the right database images, while other methods get the wrong results.", "description": "This figure shows four examples where the proposed SuperVLAD method successfully retrieves the correct images despite challenging conditions such as viewpoint changes, changing conditions (e.g., lighting, weather), and the presence of dynamic objects.  In contrast, other methods fail to retrieve the correct images, highlighting SuperVLAD's superior robustness.", "section": "4 Experiments"}, {"figure_path": "bZpZMdY1sj/figures/figures_17_3.jpg", "caption": "Figure 4: Qualitative results. In these four challenging examples (covering viewpoint variations, condition variations, dynamic objects, etc.), our SuperVLAD successfully retrieves the right database images, while other methods get the wrong results.", "description": "This figure shows four examples where various challenging conditions are present such as viewpoint changes, changes in lighting conditions and the presence of dynamic objects.  The results show that SuperVLAD is able to correctly identify the location in each of these four cases, unlike the other methods which mostly fail.", "section": "4 Experiments"}, {"figure_path": "bZpZMdY1sj/figures/figures_18_1.jpg", "caption": "Figure 4: Qualitative results. In these four challenging examples (covering viewpoint variations, condition variations, dynamic objects, etc.), our SuperVLAD successfully retrieves the right database images, while other methods get the wrong results.", "description": "This figure showcases qualitative results comparing SuperVLAD against other state-of-the-art methods on four challenging examples. The examples highlight various challenges, such as viewpoint variations, condition variations, and the presence of dynamic objects.  SuperVLAD successfully retrieves the correct database images for all four examples, whereas other methods consistently fail to retrieve the correct matches.", "section": "4 Experiments"}, {"figure_path": "bZpZMdY1sj/figures/figures_18_2.jpg", "caption": "Figure 4: Qualitative results. In these four challenging examples (covering viewpoint variations, condition variations, dynamic objects, etc.), our SuperVLAD successfully retrieves the right database images, while other methods get the wrong results.", "description": "This figure shows four examples where the proposed SuperVLAD method correctly retrieves the correct database images while other methods (NetVLAD, SFRS, CosPlace, EigenPlaces, and SelaVPR) fail. The examples cover various challenging scenarios, including significant viewpoint changes, different lighting conditions, the presence of dynamic objects, and perceptual aliasing, demonstrating the robustness and superior performance of SuperVLAD.", "section": "4 Experiments"}]