[{"figure_path": "AYntCZvoLI/figures/figures_2_1.jpg", "caption": "Figure 1: Left: A systematic overview of our method. We adopt the VAE-based framework [3] with hyperprior [4] and channel-wise autoregressive entropy model [35]; besides the original Rate-Distortion loss (LR, LD), we introduce an auxiliary entropy model and propose the causal context adjustment loss (LCCA) for better training the entropy model. Right: An illustration of the entropy model and the auxiliary entropy model. The auxiliary entropy model does not use the information to be encoded to predict the following representations, our LCCA encourage the predicting gap between the two models, so as to enhance the importance of causal context in early stages.", "description": "This figure provides a high-level overview of the proposed method for learned image compression.  The left side shows the overall architecture, highlighting the use of a VAE-based framework with a hyperprior and channel-wise autoregressive entropy model.  Key components include an encoder, decoder, hyper encoder, hyper decoder, and two entropy models (main and auxiliary). The main contribution, the Causal Context Adjustment loss (LCCA), is also highlighted. The right side illustrates the main and auxiliary entropy models in more detail, emphasizing how the LCCA aims to improve the prediction accuracy by leveraging causal context.", "section": "Causal Context Adjustment for Efficient Learned Image Compression"}, {"figure_path": "AYntCZvoLI/figures/figures_6_1.jpg", "caption": "Figure 1: Left: A systematic overview of our method. We adopt the VAE-based framework [3] with hyperprior [4] and channel-wise autoregressive entropy model [35]; besides the original Rate-Distortion loss (LR, LD), we introduce an auxiliary entropy model and propose the causal context adjustment loss (LCCA) for better training the entropy model. Right: An illustration of the entropy model and the auxiliary entropy model. The auxiliary entropy model does not use the information to be encoded to predict the following representations, our LCCA encourage the predicting gap between the two models, so as to enhance the importance of causal context in early stages.", "description": "This figure provides a high-level overview of the proposed method for learned image compression.  The left side shows the overall architecture, highlighting the use of a VAE-based framework with hyperprior and channel-wise autoregressive entropy model.  It also emphasizes the introduction of an auxiliary entropy model and a novel Causal Context Adjustment loss (LCCA) to improve training. The right side details the entropy model and auxiliary entropy model, illustrating how LCCA encourages a prediction gap between them to strengthen the importance of causal context in the early stages.", "section": "3 Preliminary: Learned Image Compression with Variational Auto-Encoder"}, {"figure_path": "AYntCZvoLI/figures/figures_7_1.jpg", "caption": "Figure 3: Rate-Distortion performance evaluation of PSNR on Kodak dataset (left), CLIC Professional Validation dataset (middle), Tecnick dataset (right), respectively.", "description": "This figure shows the rate-distortion performance curves of the proposed method and other state-of-the-art methods on three different datasets: Kodak, CLIC Professional Validation, and Tecnick.  The x-axis represents bits per pixel (bpp), a measure of compression rate, while the y-axis represents PSNR (Peak Signal-to-Noise Ratio), a measure of image quality.  The curves illustrate the trade-off between compression and image quality for each method.", "section": "5.3 Comparison with State-of-the-art Methods"}, {"figure_path": "AYntCZvoLI/figures/figures_8_1.jpg", "caption": "Figure 3: Rate-Distortion performance evaluation of PSNR on Kodak dataset (left), CLIC Professional Validation dataset (middle), Tecnick dataset (right), respectively.", "description": "This figure shows the rate-distortion performance curves for PSNR on three different datasets: Kodak, CLIC Professional Validation, and Tecnick.  The x-axis represents bits per pixel (bpp), indicating the compression rate, and the y-axis represents the peak signal-to-noise ratio (PSNR), measuring image quality. Each line on the graph represents the performance of a different compression method (including the authors' proposed method and other state-of-the-art methods). This visualization allows for a comparison of the trade-off between compression rate and image quality across various methods and datasets.", "section": "5.3 Comparison with State-of-the-art Methods"}, {"figure_path": "AYntCZvoLI/figures/figures_12_1.jpg", "caption": "Figure 1: Left: A systematic overview of our method. We adopt the VAE-based framework [3] with hyperprior [4] and channel-wise autoregressive entropy model [35]; besides the original Rate-Distortion loss (LR, LD), we introduce an auxiliary entropy model and propose the causal context adjustment loss (LCCA) for better training the entropy model. Right: An illustration of the entropy model and the auxiliary entropy model. The auxiliary entropy model does not use the information to be encoded to predict the following representations, our LCCA encourage the predicting gap between the two models, so as to enhance the importance of causal context in early stages.", "description": "The figure illustrates the proposed method for learned image compression.  The left side shows a block diagram of the overall system, highlighting the VAE framework with hyperprior, channel-wise autoregressive entropy model, rate-distortion loss, auxiliary entropy model, and the novel causal context adjustment loss (LCCA). The right side provides a detailed view of the entropy and auxiliary entropy models, emphasizing how the LCCA encourages a prediction gap between them to improve the utilization of causal context.", "section": "3 Preliminary: Learned Image Compression with Variational Auto-Encoder"}, {"figure_path": "AYntCZvoLI/figures/figures_13_1.jpg", "caption": "Figure 6: Compression results with different grouped schedules. Detailed experimental settings can be found in the main text.", "description": "The figure shows the rate-distortion curves for different values of hyperparameter k in the unevenly grouped autoregressive entropy model. The x-axis represents the bits per pixel (bpp), while the y-axis represents the peak signal-to-noise ratio (PSNR). The plot helps to determine the optimal value of k which balances compression efficiency and image quality. The inset plot magnifies the region of interest for better readability.", "section": "4.2.2 Channel-wise Unevenly Grouped Entropy Model"}, {"figure_path": "AYntCZvoLI/figures/figures_13_2.jpg", "caption": "Figure 3: Rate-Distortion performance evaluation of PSNR on Kodak dataset (left), CLIC Professional Validation dataset (middle), Tecnick dataset (right), respectively.", "description": "This figure showcases the rate-distortion performance of the proposed model and compares it to several other state-of-the-art methods and hand-crafted codecs.  The plots show the peak signal-to-noise ratio (PSNR) versus bits per pixel (bpp) on three different datasets: Kodak, CLIC Professional Validation, and Tecnick. Each dataset is shown in a separate sub-figure, allowing for a comparison across datasets.", "section": "5.3 Comparison with State-of-the-art Methods"}, {"figure_path": "AYntCZvoLI/figures/figures_14_1.jpg", "caption": "Figure 8: Visual comparison on reconstructed propeller airplane (kodim20) image.", "description": "This figure compares the reconstruction results of different image compression methods on the kodim20 image.  The methods compared include the authors' proposed method, VTM (a video compression standard), Liu et al.'s method (a state-of-the-art learned image compression method), and JPEG (a widely used image compression standard).  The comparison highlights visual differences in the reconstructed images, particularly in areas of detail such as the propeller and the plane's markings. The caption includes the bpp (bits per pixel) and PSNR (peak signal-to-noise ratio) values for each method.", "section": "D Image Reconstruction Visualization"}, {"figure_path": "AYntCZvoLI/figures/figures_15_1.jpg", "caption": "Figure 9: Visual comparison on reconstructed pattern on the walls of the house (kodim24) image.", "description": "This figure compares the visual quality of reconstructed images of the kodim24 image using different methods: Ground Truth (original image), VTM (Versatile Video Coding), Liu et al. (a state-of-the-art learned image compression method), WebP (a lossy image compression format), and the proposed method in this paper (Ours). The image shows the details of the reconstruction, especially focusing on intricate patterns on a wall of a house.  The metrics [bpp | PSNR(dB)] shown below each image indicate bits per pixel and Peak Signal-to-Noise Ratio values, respectively, which are commonly used to evaluate the trade-off between compression ratio and image quality. The results highlight the better preservation of visual details in the proposed method.", "section": "5.3 Comparison with State-of-the-art Methods"}]