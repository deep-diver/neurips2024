{"references": [{"fullname_first_author": "Joshua Achiam", "paper_title": "Constrained policy optimization", "publication_date": "2017-00-00", "reason": "This paper introduces constrained policy optimization, a crucial technique for safety-critical reinforcement learning applications, which is directly relevant to the paper's focus on robust constrained RL."}, {"fullname_first_author": "Eitan Altman", "paper_title": "Constrained Markov decision processes", "publication_date": "2021-00-00", "reason": "This book provides a comprehensive overview of constrained Markov decision processes (CMDPs), a fundamental concept in constrained reinforcement learning, which is closely related to the paper's discussion of robust constrained RL."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "This is a foundational textbook in reinforcement learning, providing the necessary background and context for the paper's work on extending standard RL to more general utility functions."}, {"fullname_first_author": "Junyu Zhang", "paper_title": "Variational policy gradient method for reinforcement learning with general utilities", "publication_date": "2020-00-00", "reason": "This paper introduces a variational policy gradient method for reinforcement learning with general utilities, which directly addresses a key component of the current work: the use of general utility functions in RL."}, {"fullname_first_author": "Arnab Nilim", "paper_title": "Robust control of Markov decision processes with uncertain transition matrices", "publication_date": "2005-00-00", "reason": "This paper addresses robust control of Markov decision processes (MDPs) with uncertain transition matrices, a concept fundamental to the paper's focus on robust reinforcement learning, providing essential theoretical groundwork for the current work."}]}