[{"figure_path": "MHCnLo2QeA/tables/tables_5_1.jpg", "caption": "Table 1: Performance comparisons across baseline models for doubly sparse video data on the AMASS test set. We report MPJRE [\u00b0], MPJPE [cm], and MPJVE [cm/s], with the best results highlighted in boldface. Models trained by us are marked with *. The notation data denotes temporally sparse data, data indicates imputed data, and all other cases involve dense data. Ts indicates the sliding window, x indicates the input of our whole pipeline, and y indicates the input of denoising Transformer.", "description": "This table compares the performance of different methods for estimating human body pose from doubly sparse egocentric video data on the AMASS test set.  The metrics used are Mean Per Joint Position Error (MPJPE), Mean Per Joint Velocity Error (MPJVE), and Mean Per Joint Rotation Error (MPJRE). The table shows the performance with different types of input data (dense, temporally sparse, imputed) and different imputation methods (interpolation, MAE).  The results highlight the effectiveness of the proposed method (DSPoser) compared to baselines.", "section": "4.2 Full Body Pose Estimation from Doubly Sparse data"}, {"figure_path": "MHCnLo2QeA/tables/tables_6_1.jpg", "caption": "Table 2: Performance comparisons across baseline models for doubly sparse video data on the Ego-Exo4D validation set. We report MPJPE [cm] and MPJVE [cm/s], with the best results highlighted in boldface. Models trained by us are marked with *. The notation Data denotes temporally sparse data, data indicates imputed data, and all other cases involve dense data.", "description": "This table presents a comparison of the performance of different methods for estimating human body pose from doubly sparse egocentric video data on the Ego-Exo4D validation dataset.  The methods are evaluated using two metrics: Mean Per Joint Position Error (MPJPE) and Mean Per Joint Velocity Error (MPJVE).  The table shows results for various methods using different data types (full body, head and hands, imputed hands using interpolation or MAE) and different sliding window sizes. The best results are highlighted in boldface, and models trained by the authors are marked with an asterisk.", "section": "4.2 Full Body Pose Estimation from Doubly Sparse data"}, {"figure_path": "MHCnLo2QeA/tables/tables_6_2.jpg", "caption": "Table 3: Performance comparisons across baseline models on the AMASS test set. We report MPJRE [\u00b0], MPJPE [cm], and MPJVE [cm/s], with the best results highlighted in boldface. Note that + is trained only with dense data without uncertainty.", "description": "This table presents a comparison of the performance of different methods for human pose estimation on the AMASS test dataset.  The metrics used are Mean Per Joint Position Error (MPJPE), Mean Per Joint Velocity Error (MPJVE), and Mean Per Joint Rotation Error (MPJRE).  The table highlights the best-performing method for each metric and shows that the proposed DSPoser method outperforms the baselines across the board, even when baselines are trained with dense data (no uncertainty).", "section": "4.2 Full Body Pose Estimation from Doubly Sparse data"}, {"figure_path": "MHCnLo2QeA/tables/tables_7_1.jpg", "caption": "Table 4: Ablation study for uncertainty guidance strategy", "description": "This table presents the ablation study for different uncertainty guidance strategies, including no uncertainty guidance, sample, distribution embedding, and dropout, on the AMASS dataset with a sliding window of 20.  The results show the impact of each strategy on the MPJPE, MPJVE, and MPJRE metrics. The sampling strategy shows the best performance in terms of all three metrics. ", "section": "4.4 Ablation Studies"}, {"figure_path": "MHCnLo2QeA/tables/tables_7_2.jpg", "caption": "Table 4: Ablation study for uncertainty guidance strategy", "description": "This table presents the ablation study of different uncertainty guidance strategies on the AMASS dataset using a sliding window of T=20.  It compares the model's performance (MPJPE, MPJVE, MPJRE) when using no uncertainty guidance, sampling, distribution embedding, and dropout. The results show that incorporating uncertainty guidance significantly improves pose estimation accuracy, with the sampling strategy providing the best results.", "section": "4.4 Ablation Studies"}, {"figure_path": "MHCnLo2QeA/tables/tables_7_3.jpg", "caption": "Table 6: Ablation study for \u03b2 for uncertainty capturing with MAE.", "description": "This table presents the ablation study result for the hyperparameter \u03b2 used in the uncertainty-aware Masked Autoencoder (MAE). It shows the effect of different \u03b2 values on the performance of the MAE in terms of Mean Per Joint Position Error (MPJPE) on the AMASS dataset. The results suggest that \u03b2 = 0.5 provides the best temporal completion for head and hand 3D positions from the doubly sparse input.", "section": "4.4 Ablation Studies"}, {"figure_path": "MHCnLo2QeA/tables/tables_7_4.jpg", "caption": "Table 7: Hand detection accuracy on Ego-Exo4D dataset.", "description": "This table presents the accuracy of hand detection on the Ego-Exo4D dataset. It shows the mean per-joint position error (MPJPE) for left and right hands separately, which are 9.51 cm and 9.63 cm respectively.  This indicates the average error in hand pose estimation. The lower the MPJPE, the higher the accuracy of hand pose detection.", "section": "4.5 Hand Detection Accuracy and Hand Visibility Statistics"}, {"figure_path": "MHCnLo2QeA/tables/tables_13_1.jpg", "caption": "Table 1: Performance comparisons across baseline models for doubly sparse video data on the AMASS test set. We report MPJRE [\u00b0], MPJPE [cm], and MPJVE [cm/s], with the best results highlighted in boldface. Models trained by us are marked with *. The notation data denotes temporally sparse data, data indicates imputed data, and all other cases involve dense data. Ts indicates the sliding window, x indicates the input of our whole pipeline, and y indicates the input of denoising Transformer.", "description": "This table compares the performance of the proposed DSPoser method against several baseline methods for ego-body pose estimation using doubly sparse video data on the AMASS dataset.  It shows the Mean Per Joint Position Error (MPJPE), Mean Per Joint Velocity Error (MPJVE), and Mean Per Joint Rotation Error (MPJRE) for different methods, varying the input data (dense or sparse) and imputation techniques (Interpolation or MAE).  The best results for each metric are highlighted in bold.  The table also indicates which models were trained by the authors and the sliding window size (Ts) used for the temporal context.", "section": "4.2 Full Body Pose Estimation from Doubly Sparse data"}]