[{"type": "text", "text": "Foundations of Multivariate Distributional Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Harley Wiltzer Mila \u2014 Qu\u00e9bec AI Institute McGill University harley.wiltzer@mail.mcgill.ca ", "page_idx": 0}, {"type": "text", "text": "Jesse Farebrother   \nMila \u2014 Qu\u00e9bec AI Institute McGill Unversity   \njfarebro@cs.mcgill.ca ", "page_idx": 0}, {"type": "text", "text": "Arthur Gretton Google DeepMind Gatsby Unit, University College London gretton@google.com ", "page_idx": 0}, {"type": "text", "text": "Mark Rowland Google DeepMind markrowland@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In reinforcement learning (RL), the consideration of multivariate reward signals has led to fundamental advancements in multi-objective decision-making, transfer learning, and representation learning. This work introduces the first oracle-free and computationally-tractable algorithms for provably convergent multivariate distributional dynamic programming and temporal difference learning. Our convergence rates match the familiar rates in the scalar reward setting, and additionally provide new insights into the fidelity of approximate return distribution representations as a function of the reward dimension. Surprisingly, when the reward dimension is larger than 1, we show that standard analysis of categorical TD learning fails, which we resolve with a novel projection onto the space of mass-1 signed measures. Finally, with the aid of our technical results and simulations, we identify tradeoffs between distribution representations that influence the performance of multivariate distributional RL in practice. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Distributional reinforcement learning [DRL; $\\mathrm{MSK^{+}10}$ , BDM17b, BDR23] focuses on the idea of learning probability distributions of an agent\u2019s random return, rather than the classical approach of learning only its mean. This has been highly effective in combination with deep reinforcement learning $[\\bar{\\mathrm{YZL}}^{\\mathcal{\\bar{+}}}19$ , $\\mathrm{BCC}^{+}20$ , $\\mathrm{WBK}^{+}22]$ , and DRL has found applications in risk-sensitive decision making [LM22, KEF23], neuroscience $[\\mathrm{DKNU}^{+}20]$ , and multi-agent settings $[\\mathrm{ROH}^{+}21$ , SLL21]. ", "page_idx": 0}, {"type": "text", "text": "In general, research in distributional reinforcement learning has focused on the classical setting of a scalar reward function. However, prior non-distributional approaches to multi-objective RL [RVWD13, $\\operatorname{HRB}^{+}22]$ and transfer learning $[\\mathrm{BDM^{+}17a}$ , $\\mathrm{BHB}^{+}2\\bar{0}\\bar{]}$ model value functions of multivariate cumulants,1 rather than a scalar reward. Having learnt such a multivariate value function, it is then possible to perform zero-shot evaluation and policy improvement for any scalar reward signal contained in the span of the coordinates of the multivariate cumulants, opening up a variety of applications in transfer learning, and multi-objective and constrained RL. ", "page_idx": 0}, {"type": "text", "text": "Multivariate distributional $R L$ combines these two ideas, and aims to learn the full probability distribution of returns given a multivariate cumulant function. Successfully learning the multivariate reward distribution opens up a variety of unique possibilities, such as zero-shot return distribution estimation $[\\mathrm{WFG}^{+}24]$ and risk-sensitive policy improvement $[{\\mathrm{CZZ}}^{+}24]$ . ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Pioneering works have already proposed algorithms for multivariate distributional RL. While these works all demonstrate beneftis from the proposed algorithmic approaches, each suffers from separate drawbacks, such as not modelling the full joint distribution [GBSL21], lacking theoretical guarantees [FSMT19, $Z\\!C Z^{+}21]$ , or requiring a maximum-likelihood optimisation oracle for implementation [WUS23]. Concurrently, the work of [LK24] analyzed algorithms for DRL with Banach-spacevalued rewards, and provided convergence guarantees for dynamic programming with non-parametric (intractable) distribution models. ", "page_idx": 1}, {"type": "text", "text": "Our central contribution in this paper is to propose algorithms for dynamic programming and temporaldifference learning in multivariate DRL which are computationally tractable and theoretically justified, with convergence guarantees. We show that reward dimensions strictly larger than 1 introduce new computational and statistical challenges. To resolve these challenges, we introduce multiple novel algorithmic techniques, including a randomized dynamic programming operator for efficiently approximating projected updates with high probability, and a novel TD-learning algorithm operating on mass-1 signed measures. These new techniques recover existing bounds even in the scalar reward case, and provide new insights into the behavior of distributional RL algorithms as a function of the reward dimension. ", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We consider a Markov decision process with Polish state space $\\mathcal{X}$ , action space $\\boldsymbol{\\mathcal{A}}$ , transition kernel $P:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\mathcal{P}(\\mathcal{X})$ , and discount factor $\\gamma\\in[0,1)$ . Unlike the standard RL setting, we consider a vector-valued reward function $r:\\boldsymbol{\\mathcal{X}}\\to[0,R_{\\mathrm{max}}]^{d}$ , as in the literature on successor features $[\\mathrm{BDM}^{+}17\\mathrm{a}]$ . Given a policy $\\pi:{\\mathcal{X}}\\to{\\mathcal{P}}(A)$ , we write the policy-conditioned transition kernel $\\begin{array}{r}{P^{\\pi}(\\cdot\\mid x)=\\int P(\\cdot\\mid x,\\bar{a})\\pi(\\dot{\\mathrm{d}a}\\mid x)}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "Multi-variate return distributions. We write $(X_{t})_{t\\geq0}$ for a trajectory generated by setting $X_{0}=x$ , and for each $t\\geq0$ , $X_{t+1}\\sim P^{\\pi}(\\cdot|X_{t})$ . The return obtained along this trajectory is then defined by $\\begin{array}{r}{G^{\\pi}(x)=\\sum_{t=0}^{\\infty}\\gamma^{t}r(X_{t})}\\end{array}$ , and the (multi-)return distribution function is $\\eta^{\\bar{\\pi}}(x)\\doteq\\operatorname{Law}\\left(G^{\\pi}(x)\\right)$ . ", "page_idx": 1}, {"type": "text", "text": "Zero-shot evaluation. An intriguing prospect of estimating multivariate return distributions is the ability to predict (scalar) return distributions for any reward function in the span of the cumulants. Indeed, $[Z\\mathrm{C}Z^{+}21$ , $\\mathrm{CZZ^{+}24]}$ show that for any reward function $\\tilde{r}:x\\mapsto\\langle r(x),w\\rangle$ for some $w\\in\\mathbf{R}^{d}$ , $\\begin{array}{r}{\\langle G^{\\pi}(x),w\\rangle\\!=\\!_{\\mathrm{law}}\\sum_{t\\geq0}\\gamma^{t}\\tilde{r}(X_{t})}\\end{array}$ for $X_{0}\\,=\\,x$ . Likewise, one might consider $r(x)\\,=\\,\\delta_{x}$ , in which case $G^{\\pi}(x)$ corresponds to the per-trajectory discounted state visitation measure, and $[\\mathrm{WFG}^{+}24]$ demonstrated methods for learning the distribution of $G^{\\pi}$ to infer the return distribution for any bounded deterministic reward function. ", "page_idx": 1}, {"type": "text", "text": "Multivariate distributional Bellman equation. It was shown in $[Z\\mathrm{C}Z^{+}21]$ that multi-return distributions obey a distributional Bellman equation, similar to the scalar case $[\\mathrm{MSK^{+}10}$ , BDM17b], and defines the multivariate distributional Bellman operator $\\mathcal{T}^{\\pi}:\\mathcal{P}(\\mathbf{R}^{d})^{\\mathcal{X}}\\rightarrow\\mathcal{P}(\\mathbf{R}^{d})^{\\mathcal{X}}$ by ", "page_idx": 1}, {"type": "equation", "text": "$$\n(\\mathcal T^{\\pi}\\eta)(x)=\\underset{X^{\\prime}\\sim P^{\\pi}(\\cdot\\vert x)}{\\mathbf{E}}\\left[(\\mathrm{b}_{r(x),\\gamma})_{\\sharp}\\eta(X^{\\prime})\\right],\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\mathrm{b}_{y,\\gamma}(z)~=~y+\\gamma z$ and $f_{\\sharp}\\mu~=~\\mu\\circ f^{-1}$ is the pushforward of a measure $\\mu$ through a measurable function $f$ . In particular, $[Z\\mathrm{C}Z^{+}21]$ showed that $\\eta^{\\pi}$ satisfies the multi-variate distributional Bellman equation $\\mathcal{T}^{\\pi}\\eta^{\\pi}\\ =\\ \\eta^{\\pi}$ , and that $\\mathcal{T}^{\\pi}$ is a $\\gamma$ -contraction in $\\overline{{W}}_{p}$ , where $\\begin{array}{r}{\\overline{{W}}_{p}(\\eta_{1},\\eta_{2})\\,=\\,\\operatorname*{sup}_{x\\in\\mathcal{X}}W_{p}(\\eta_{1}(x),\\eta_{2}(x))}\\end{array}$ and $W_{p}$ is the $p$ -Wasserstein metric [Vil09]. This suggests a convergent scheme for approximating $\\eta^{\\pi}$ in $\\overline{{W}}_{p}$ by distributional dynamic programming, that is, computing the iterates $\\eta_{k+1}=\\mathcal{T}^{\\pi}\\eta_{k}$ , following Banach\u2019s fixed point theorem. ", "page_idx": 1}, {"type": "text", "text": "Approximating multivariate return distributions. In practice, however, the iterates $\\eta_{k+1}=\\mathcal{T}^{\\pi}\\eta_{k}$ cannot be computed efficiently, because the size of the support of $\\eta_{k}$ may increase exponentially with $k$ . A variety of alternative approaches that aim to circumvent this computational difficulty have been considered [FSMT19, $Z{\\mathsf{C}}Z^{+}21$ , WUS23]. Many of these approaches have proven effective in combination with deep reinforcement learning, though as tabular algorithms, either lack theoretical guarantees, or rely on oracles for solving possibly intractable optimisation problems. A more complete account of multivariate DRL is given in Appendix A. A central motivation of our work is the development of computationally-tractable algorithms for multivariate distributional RL with theoretically guarantees. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Maximum mean discrepancies. A core tool in the development of our proposed algorithms, as well as some prior work [NTGV20, $Z(\\mathrm{CZ}^{+}21]$ , is the notion of distance over probability distributions given by maximum mean discrepancies $[\\mathrm{GBR}^{+}12\\$ , MMD]. A maximum mean discrepancy ${\\mathrm{MMD}}_{\\kappa}$ : $\\mathcal{P}(\\mathcal{Y})\\stackrel{\\cdot}{\\times}\\mathcal{P}(\\mathcal{Y})\\rightarrow\\mathbf{R}_{+}$ assigns a notion of distance to pairs of probability distributions, and is parametrised via a choice of kernel $\\kappa:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbf{R}$ , defined by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{MMD}_{\\kappa}(p,q)=\\mathbb{E}_{(Y_{1},Y_{2})\\sim p\\otimes p}[\\kappa(Y_{1},Y_{2})]-2\\mathbb{E}_{(Y,Z)\\sim p\\otimes q}[\\kappa(Y,Z)]+\\mathbb{E}_{(Z_{1},Z_{2})\\sim q\\otimes q}[\\kappa(Z_{1},Z_{2})]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "A useful alternative perspective on MMD is that the choice of kernel $\\kappa$ induces a reproducing kernel Hilbert space (RKHS) of functions $\\mathcal{H}$ , namely the closure of the span of functions of the form $z\\mapsto\\kappa(y,\\bar{z})$ for each $y\\in\\mathcal{V}$ , with respect to the norm $\\Vert\\cdot\\Vert_{\\mathcal{H}}$ induced by the inner product $\\langle\\kappa(y_{1},\\cdot),\\kappa(y_{2},\\cdot)\\rangle=\\kappa(y_{1},y_{2})$ . With this interpretation, $\\mathrm{MMD}_{\\kappa}(p,q)$ is equal to $\\lVert\\mu_{p}-\\mu_{q}\\rVert_{\\mathcal{H}}$ , where $\\begin{array}{r}{\\mu_{p}=\\int_{\\mathcal{Y}}\\kappa(\\cdot,y)p(\\mathrm{d}y)\\in\\mathcal{H}}\\end{array}$ is the mean embedding of $p$ (similarly for $\\mu_{q.}$ ). When $p\\mapsto\\mu_{p}$ is injective, the kernel $\\kappa$ is called characteristic, and ${\\mathrm{MMD}}_{\\kappa}$ is then a proper metric on $\\mathcal{P}(\\mathcal{D})\\left[\\mathrm{GBR}^{+}12\\right]$ . In the remainder of this work, we will assume that all spaces of measures will be over compact sets $\\boldsymbol{\\wp}$ ; thus with continuous kernels, we are ensured that distances between probability measures are bounded. When comparing return distributions, this is achieved by asserting that rewards are bounded. ", "page_idx": 2}, {"type": "text", "text": "We conclude this section by recalling a particular family of kernels, introduced in [SSGF13], that will be particularly useful for our analysis. These are the kernels induced by semimetrics. ", "page_idx": 2}, {"type": "text", "text": "Definition 1. Let $\\boldsymbol{\\wp}$ be a nonempty set, and consider a function $\\rho:\\mathcal{V}\\times\\mathcal{V}\\to\\mathbf{R}_{+}$ . Then $\\rho$ is called $a$ semimetric if it is symmetric and $\\rho(y_{1},y_{2})=0\\iff y_{1}=y_{2}$ . Additionally, $\\rho$ is said to have strong negative type if $\\begin{array}{r}{\\dot{\\mathrm{~\\,~}}\\!\\int\\rho\\;\\mathrm{d}([p-q]\\times[p-q])<0}\\end{array}$ whenever $p,q\\in\\mathcal{P}(\\mathcal{Y})$ with $p\\neq q$ . ", "page_idx": 2}, {"type": "text", "text": "Notably, certain semimetrics naturally induce characteristic kernels and probability metrics. ", "page_idx": 2}, {"type": "text", "text": "Theorem 1 ([SSGF13, Proposition 29]). Let $\\rho$ be a semimetric on a space $\\boldsymbol{\\wp}$ have strong negative type, in the sense that $\\begin{array}{r}{\\int\\rho\\mathrm{d}([p-q]\\times[p-q])<0}\\end{array}$ whenever $p\\neq q$ are probability measures on $a$ compact set $\\boldsymbol{\\wp}$ . Moreover, let $\\kappa:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbf{R}$ denote the kernel induced by $\\rho_{!}$ , that is ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\kappa(y_{1},y_{2})=\\frac{1}{2}(\\rho(y_{1},y_{0})+\\rho(y_{2},y_{0})-\\rho(y_{1},y_{2}))\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "for some $y_{0}\\in\\mathcal{V}$ . Then $\\kappa$ is characteristic, so $\\mathrm{MMD}_{\\kappa}$ is a metric. ", "page_idx": 2}, {"type": "text", "text": "Remark 1. An important class of semimetrics are the functions $\\rho_{\\alpha}:{\\mathbf{R}}^{d}\\times{\\mathbf{R}}^{d}\\rightarrow{\\mathbf{R}}_{+}$ given by $\\rho_{\\alpha}(y_{1},y_{2})=\\|y_{1}\\overset{\\cdot}{-}y_{2}\\|_{2}^{\\alpha}$ for $\\alpha\\in(0,2)$ . It is known that these semimetrics have strong negative type, and thus the kernels $\\kappa_{\\alpha}$ induced by $\\rho_{\\alpha}$ are characteristic [SR13, SSGF13]. The resulting metric $\\mathrm{MMD}_{\\kappa_{\\alpha}}$ is known as the energy distance. ", "page_idx": 2}, {"type": "text", "text": "3 Multivariate Distributional Dynamic Programming ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To warm up, we begin by demonstrating that indeed the (multivariate) distributional Bellman operator is contractive in a supremal form $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ of MMD, given by $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2})\\;\\;=$ $\\bar{\\operatorname*{sup}}_{x\\in\\mathcal{X}}\\operatorname{MMD}_{\\kappa}(\\eta_{1}(x),\\eta_{2}(x))$ , for a particular class of kernels $\\kappa$ . Our first theorem generalizes the analogous results of [NTGV20] in the scalar case to multivariate cumulants. The proof of Theorem 2, as well as proofs of all remaining results, are deferred to Appendix B. ", "page_idx": 2}, {"type": "text", "text": "Theorem 2 (Convergent MMD dynamic programming for the multi-return distribution function). Let $\\kappa$ be a kernel induced by a semimetric $\\rho$ on $[\\bar{0},(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d}$ with strong negative type, satisfying ", "page_idx": 2}, {"type": "text", "text": "1. Shift-invariance. For any $z\\in\\mathbf{R}^{d}$ ${\\mathit{\\Gamma}}^{l},\\,\\rho(z+y_{1},z+y_{2})=\\rho(y_{1},y_{2}).$ . ", "page_idx": 2}, {"type": "text", "text": "2. Homogeneity. For any $\\gamma\\in[0,1)$ , there exists $c>0$ for which $\\rho(\\gamma y_{1},\\gamma y_{2})=\\gamma^{c}\\rho(y_{1},y_{2}).$ . ", "page_idx": 2}, {"type": "text", "text": "Consider the sequence $\\{\\eta_{k}\\}_{k=1}^{\\infty}$ given by $\\eta_{k+1}=\\mathcal{T}^{\\pi}\\eta_{k}$ . Then $\\eta_{k}\\rightarrow\\eta^{\\pi}$ at a geometric rate of $\\gamma^{c/2}$ in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , as long as $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\leq C<\\infty$ . ", "page_idx": 2}, {"type": "text", "text": "Notably, the energy distance kernels $\\kappa_{\\alpha}$ satisfy the conditions of Theorem 2, and $\\rho_{\\alpha}(\\gamma y_{1},\\gamma y_{2})\\leq$ $\\gamma^{\\alpha}\\rho(y_{1},y_{2})$ by the homogeneity of the Euclidean norm, so $\\mathcal{T}^{\\pi}$ is a $\\gamma^{\\alpha/2}$ -contraction in the energy distances. This generalizes the analogous result of [NTGV20] in the one-dimensional case. ", "page_idx": 2}, {"type": "text", "text": "While Theorem 2 illustrates a method for approximating $\\eta^{\\pi}$ in MMD, it leaves a lot to be desired. Firstly, even in tabular MDPs, just as in the case of scalar distributional RL, return distribution functions have infinitely many degrees of freedom, precluding a tractable exact representation. As such, it will be necessary to study approximate, finite parameterizations of the return distribution functions, requiring more careful convergence analysis. Moreover, in RL it is generally assumed that the transition kernel and reward function are not known analytically\u2014we only have access to sampled state transitions and cumulants. Thus, $\\mathcal{T}^{\\pi}$ cannot be represented or computed exactly, and instead we must study algorithms for approximating $\\eta^{\\pi}$ from samples. We provide algorithms for resolving both of these concerns\u2014the former in Section 5 and the latter in Section 6\u2014where we illustrate the difficulties that arise once the cumulant dimension exceeds unity. ", "page_idx": 3}, {"type": "text", "text": "4 Particle-Based Multivariate Distributional Dynamic Programming ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our first algorithmic contribution is inspired by the empirically successful equally-weighted particle (EWP) representations of multivariate return distributions employed by $[Z\\mathrm{C}Z^{+}21]$ . ", "page_idx": 3}, {"type": "text", "text": "Temporal-difference learning with EWP representations. EWP representations, expressed by the class $\\mathcal{C}_{\\mathrm{EWP},m}$ , are defined by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\mathrm{EWP},m}=(\\mathcal{C}_{\\mathrm{EWP},m}^{\\circ})^{\\mathcal{X}},\\qquad\\mathcal{C}_{\\mathrm{EWP},m}^{\\circ}=\\left\\{\\frac{1}{m}\\sum_{i=1}^{m}\\delta_{\\theta_{i}}\\,:\\,\\theta_{i}\\in{\\bf R}^{d}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "For simplicity, we consider the case here where at each state $x$ , the multi-return distribution is approximated by $N(x)=m$ atoms. We can represent $\\eta\\in\\mathcal{C}_{\\mathrm{EWP},m}$ by $\\begin{array}{r}{\\eta(x)=\\frac{1}{m}\\sum_{i=1}^{m}\\delta_{\\theta_{i}(x)}}\\end{array}$ for $\\theta_{i}:\\mathcal{X}\\to\\mathbf{R}^{d}$ . The work of $[Z\\mathrm{C}Z^{+}21]$ introduced a TD-learning algorithm for learning a $\\mathcal{C}_{\\mathrm{EWP},m}$ representation of $\\eta^{\\pi}$ , computing iterates of the particles $(\\theta_{i}^{(k)})_{i=1}^{m}$ according to ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\theta_{i}^{(k+1)}(x)=\\theta_{i}^{(k)}(x)-\\lambda_{k}\\nabla_{\\theta_{i}(x)}\\mathrm{MMD}_{\\kappa}^{2}\\left(\\frac{1}{m}\\sum_{i=j}^{m}\\delta_{\\theta_{j}^{(k)}(x)},\\frac{1}{m}\\sum_{j=1}^{m}\\delta_{r(x)+\\gamma\\overline{{\\theta}}_{j}^{(k)}(X^{\\prime})}\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for step sizes $(\\lambda_{k})_{k\\geq0}$ and sampled next states $X^{\\prime}\\sim P^{\\pi}(\\cdot\\mid x)$ , where $\\overline{{\\theta}}=\\mathtt{s t o p-g r a d i e n t}(\\theta^{(k)})$ is a copy of $\\theta^{(k)}$ that does not propagate gradients. Despite the empirical success of this method in combination with deep learning, no convergence analysis has been established, owing to the nonconvexity of the MMD objective with respect to the particle locations. In this section we aim to understand to what extent analysis is possible for dynamic programming and temporal-difference learning algorithms based on the EWP representations in Equation (2). ", "page_idx": 3}, {"type": "text", "text": "Dynamic programming with EWP representations. As is often the case in approximate distributional dynamic programming $[\\mathrm{RBD^{+}18}$ , $\\mathrm{RMA}^{+}24]$ , we have $T^{\\pi}\\mathcal{C}_{\\mathrm{EWP},m}\\subset\\mathcal{C}_{\\mathrm{EWP},m}$ ; in words, the distributional Bellman operator does not map EWP representations to themselves. Concretely, as long as there exists a state $x$ at which the support of $P^{\\bar{\\pi}}(\\cdot\\mid x)$ is not a singleton, $(\\tau^{\\pi}\\eta)(x)$ will consist of more than $m$ atoms even when $\\eta\\in\\mathcal{C}_{\\mathrm{EWP},m}$ ; and secondly, if $P(\\cdot\\mid x)$ is not uniform, $(\\tau^{\\pi}\\eta)(x)$ will not consist of equally-weighted particles. ", "page_idx": 3}, {"type": "text", "text": "Consequently, to obtain a DP algorithm over EWP representations, we must consider a projected operator of the form $\\Pi_{\\mathrm{EWP}}\\tau^{\\pi}$ , for a projection $\\Pi_{\\mathrm{EWP}}:{\\mathcal{P}}(\\mathbf{R}^{d})^{\\mathcal{X}}\\to{\\mathcal{C}}_{\\mathrm{EWP},m}$ . A natural choice for this projection is the operator that minimizes the MMD of each multi-return distribution in $\\mathcal{C}_{\\mathrm{EWP},m}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n(\\Pi_{\\mathrm{EWP},\\kappa}^{m}\\eta)(x)\\in\\underset{p\\in\\mathcal{C}_{\\mathrm{EWP},m}^{\\mathrm{opmin}}}{\\mathrm{argmin}}\\,\\mathrm{MMD}_{\\kappa}(p,\\eta(x)).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Unfortunately, even in the scalar-reward $\\mathit{\\Pi}(d\\mathrm{\\\\Pi}=\\mathrm{\\Delta}1)$ ) case, the operator $\\Pi_{\\mathrm{EWP},\\kappa}^{m}$ is problematic; $(\\Pi_{\\mathrm{EWP},\\kappa}^{m}\\eta)(x)$ is not uniquely defined, and $\\Pi_{\\mathrm{EWP},\\kappa}^{m}$ is not a non-expansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ [LB22, $\\mathrm{RMA}^{+}24]$ . These pathologies present significant complications when analyzing even the convergence of dynamic programming routines for learning an EWP representation of the multi-return distribution \u2014 in particular, it is not even clear that $\\Pi_{\\mathrm{EWP},\\kappa}^{m}\\tau^{\\pi}$ has a fixed point (let alone a unique one). Another complication arises due to the computational difficulty of computing the projection (4): even in the case where $\\eta(x)$ has finite support for each state $x$ , the projection $(\\bar{\\Pi}_{\\mathrm{EWP},\\kappa}^{m}\\bar{\\eta})(x)$ is very similar to clustering, which can be intractable to compute exactly for large $m$ [She21]. Thus, the argmin projection in Equation (4) cannot be used directly to obtain a tractable DP algorithm. ", "page_idx": 3}, {"type": "text", "text": "Randomised dynamic programming. Towards this end, we introduce a tractable randomized dynamic programming algorithm for the EWP representation, by using a randomized proxy $\\mathsf{B o o t P r o j}_{\\kappa,n}^{\\pi}$ for $\\Pi_{\\kappa,m}\\tau^{\\pi}$ , that produces accurate return distribution estimates with high probability. The method produces the following iterates, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\eta_{k+1}(x)=\\mathsf{B o o t P r o j}_{\\kappa,m}^{\\pi}\\eta_{k}(x):=\\frac{1}{m}\\sum_{i=1}^{m}\\delta_{r(x)+\\gamma Z_{i}},\\qquad Z_{i}\\sim\\eta_{k}(X_{i}),\\ X_{i}\\stackrel{\\mathrm{iid}}{\\sim}P^{\\pi}(\\cdot\\mid x)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "A similar algorithm for categorical representations was discussed in concurrent work [LK24] without convergence analysis. ", "page_idx": 4}, {"type": "text", "text": "The intuition is that, particularly for large $m$ , the Monte Carlo error associated with the sample-based approximation to $(\\bar{T^{\\pi}}\\eta)(x)$ is small, and we can therefore expect the DP process, though randomised, to be accurate with high probability. This is summarised by a key theoretical result of this section; our proof of this result in the appendix provides a general approach to proving convergence for algorithms using arbitrary accurate approximations to (4) that we expect to be useful in future work. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3. Consider a kernel $\\kappa$ induced by the semimetric $\\rho(x,y)=\\|x-y\\|_{2}^{\\alpha}$ with $\\alpha\\in(0,2)$ , and suppose rewards are bounded in each dimension within $[0,R_{\\mathrm{max}}]$ . For any $\\eta_{0}$ such that $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\,\\leq\\,D\\,<\\,\\infty,$ , and any $\\delta\\,>\\,0$ , for the sequence $(\\eta_{k})_{k\\geq0}$ defined in Equation (5), with probability at least $1-\\delta$ we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{K},\\eta^{\\pi})\\in\\widetilde{O}\\left(\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}\\sqrt{m}}\\log\\left(\\frac{|\\mathcal{X}|\\delta^{-1}}{\\log\\gamma^{-\\alpha}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta_{k+1}=\\mathsf{B o o t P r o j}_{\\kappa,m}^{\\pi}\\eta_{k}$ and $\\begin{array}{r}{K=\\lceil\\frac{\\log{m}}{\\log{\\gamma^{-\\alpha}}}\\rceil}\\end{array}$ , and where $\\widetilde O$ omits logarithmic factors in $m$ ", "page_idx": 4}, {"type": "text", "text": "This shows that our novel randomised DP algorithm with EWP representations can tractably compute accurate approximations to the true multivariate return distributions, with only polynomial dependence on the dimension $d$ . Appendix $\\mathrm{C}$ illustrates explicitly how this procedure is more memory efficient than unprojected EWP dynamic programming. However, the guarantees associated with this algorithm hold only in high probability, and are weaker than the pointwise convergence guarantees of one-dimensional distributional DP algorithms $[\\mathrm{RBD^{+}18}$ , $\\mathrm{RMA}^{+}24$ , BDR23]. Consequently, these guarantees do not provide a clear understanding of the EWP-TD method described at the beginning of this section. However, in the sequel, we introduce DP and TD algorithms based on categorical representations, for which we derive dynamic programming and TD-learning convergence bounds. ", "page_idx": 4}, {"type": "text", "text": "The proof of Theorem 3 is hinges on the following proposition, which demonstrates that convergence of projected EWP dynamic programming is controlled by how far return distributions are transported under the projection map. ", "page_idx": 4}, {"type": "text", "text": "Proposition 1 (Convergence of EWP Dynamic Programming). Consider a kernel satisfying the hypotheses of Theorem 2, suppose rewards are globally bounded in each dimension in $[0,R_{\\mathrm{max}}]$ , and let $\\{\\Pi_{\\kappa,m}^{(k)}\\}_{k\\ge0}$ be a sequence of maps $\\Pi:\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d})^{\\mathcal{X}}\\to\\mathcal{C}_{\\mathrm{EWP},m}$ satisfying ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{MMD}_{\\kappa}((\\Pi_{\\kappa,m}^{(k)}\\eta)(x),\\eta(x))\\leq f(d,m)<\\infty\\qquad\\forall k\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Then the iterates $(\\eta_{k})_{k\\geq0}$ given by $\\eta_{k+1}=\\Pi_{\\kappa,m}^{(k)}\\mathcal{T}^{\\pi}\\eta_{k}$ with $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})=D<\\infty$ converge to a set $\\eta_{\\mathrm{EWP},\\kappa}^{m}\\,\\subset\\,\\overline{{B}}(\\eta^{\\pi},(1-\\gamma^{c/2})^{-1}f(d,m))$ in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , where $\\overline{B}$ denotes the closed ball in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\overline{{B}}(\\eta,R)\\triangleq\\left\\{\\eta^{\\prime}\\in\\mathcal{P}(\\mathbf{R}^{d})^{\\mathcal{X}}\\,:\\,\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta,\\eta^{\\prime})\\leq R\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As an immediate corollary of Proposition 1 and Theorem 3, we can derive an error rate for projected dynamic programming with $\\Pi_{\\mathrm{EWP},\\kappa}^{m}$ as well. ", "page_idx": 4}, {"type": "text", "text": "Corollary 1. For any kernel $\\kappa$ satisfying the hypotheses of Theorem 3, and for any $\\eta_{0}\\in\\mathcal{C}_{\\mathrm{EWP},m}$ for which $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\leq D<\\infty,$ , the iterates $\\eta_{k+1}=\\Pi_{\\mathrm{EWP},\\kappa}^{m}T^{\\pi}\\eta_{k}$ converge to a set $\\pmb{\\eta}_{\\mathrm{EWP},\\kappa}^{m}\\subset$ $\\mathcal{C}_{\\mathrm{EWP},m}$ , where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{EWP},\\kappa}^{m}\\subset\\overline{{B}}\\left(\\eta^{\\pi},\\frac{6d^{\\alpha/2}R_{\\mathrm{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "5 Categorical Multivariate Distributional Dynamic Programming ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our next contribution is the introduction of a convergent multivariate distributional dynamic programming algorithm based on a categorical representation of return distribution functions, generalizing the algorithms and analysis of $[\\bar{\\mathrm{RBD}}^{+}18]$ to the multivariate setting. ", "page_idx": 5}, {"type": "text", "text": "Categorical representations. As outlined above, to model the multi-return distribution function in practice, it is necessary to restrict each multi-return distribution to a finitely-parameterized class. In this work, we take inspiration from successful distributional RL algorithms [BDM17b, $\\mathrm{RBD}^{+}18\\mathrm{]}$ and employ a categorical representation. The work of [WUS23] proposed a categorical representation for multivariate DRL, but their categorical projection was not justified theoretically, and it required a particular choice of fixed support. We propose a novel categorical representation with a finite (possibly state-dependent) support R(x) = {\u03be(x)i}iN=(1x) , that models the multi-return distribution function $\\eta$ such that $\\eta(x)\\,\\in\\,\\Delta_{\\mathcal{R}(x)}$ for each $x\\in\\mathscr{X}$ . The notation $\\xi(\\boldsymbol{x})_{i}$ simply refers to the ith support point at state $x$ specified by $\\mathcal{R}$ , and $\\Delta_{A}$ denotes the probability simplex on the finite set $A$ . We refer to the mapping $\\mathcal{R}$ as the support map2 and we denote the class of multi-return distribution functions under the corresponding categorical representation as $\\begin{array}{r}{\\mathcal{C}_{\\mathcal{R}}\\triangleq\\prod_{x\\in\\mathcal{X}}\\Delta_{\\mathcal{R}(x)}}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "Categorical projection. Once again, the distributional Bellman operator is not generally closed over $\\mathcal{C}_{\\mathcal{R}}$ , that is, $\\mathcal{T}^{\\pi}\\mathcal{C}_{\\mathcal{R}}\\subset\\mathcal{C}_{\\mathcal{R}}$ . As such, we cannot actually employ the procedure described in Theorem $2-$ rather, we need to project applications of $\\mathcal{T}^{\\pi}$ back onto $\\mathcal{C}_{\\mathcal{R}}$ . Roughly, we need an operator $\\Pi:\\mathcal{P}(\\mathbf{R}^{d})^{\\chi}\\to\\mathcal{C}_{\\mathcal{R}}$ for which $\\Pi|\\boldsymbol{\\varphi}_{\\mathcal{R}}=\\mathrm{i}\\mathsf{d}$ . Given such an operator, as in the literature on categorical distributional RL [BDM17b, $\\mathrm{RBD}^{+}18]$ ], we will study the convergence of iterates $\\eta_{k+1}=\\Pi\\mathcal{T}^{\\pi}\\eta_{k}$ . ", "page_idx": 5}, {"type": "text", "text": "Projection operators used in the scalar categorical distributional RL literature are specific to distributions over $\\mathbf{R}$ , so we must introduce a new projection. We propose a projection similar to (4), ", "page_idx": 5}, {"type": "equation", "text": "$$\n(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta)(x)=\\operatorname*{arginf}_{p\\in\\Delta\\mathcal{R}(x)}\\ \\mathrm{MMD}_{\\kappa}(p,\\eta(x)).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We will now verify that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is well-defined, and that it satisfies the aforementioned properties. ", "page_idx": 5}, {"type": "text", "text": "Lemma 1. Let \u03ba be a kernel induced by a semimetric $\\rho$ on $[0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d}$ with strong negative type (cf. Theorem 1). Then $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is well-defined, $\\mathsf{R a n}\\big(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\big)\\subset\\mathcal{C}_{\\mathcal{R}}$ , and $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\vert\\boldsymbol{\\mathcal{C}}_{\\mathcal{R}}=\\mathsf{i d}$ . ", "page_idx": 5}, {"type": "text", "text": "It is worth noting that beyond simply ensuring the well-posedness of the projection $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ , Lemma 1 also certifies an efficient algorithm for computing the projection \u2014 namely, by solving the appropriate quadratic program (QP), as observed by $[\\mathrm{SZS^{+}08}]$ . We demonstrate pseudocode for computing the projected Bellman operator $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ with a QP solver QPSolve in Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 Projected Categorical Dynamic Programming ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Require: Support map $\\mathcal{R}$ , kernel $\\kappa$ , transition kernel $P^{\\pi}$ , reward function $r$ , discount $\\gamma$ Require: Return distribution function $\\eta\\in\\mathcal{C}_{\\mathcal{R}}$ ", "page_idx": 5}, {"type": "text", "text": "for $x\\in\\mathscr{X}$ do $\\begin{array}{r}{(\\mathcal T^{\\pi}\\eta)_{x}\\leftarrow\\sum_{x^{\\prime}\\in\\mathcal X}\\sum_{\\xi\\in\\mathcal R(x^{\\prime})}P^{\\pi}(x^{\\prime}\\mid x)\\eta_{x^{\\prime}}(\\xi)\\delta_{r(x)+\\gamma\\xi}}\\end{array}$ $K_{i,j}^{x}\\gets\\kappa(\\xi_{i},\\xi_{j})$ for each $(\\xi_{i},\\xi_{j})\\in\\mathcal{R}(x)^{2}$ $\\begin{array}{r}{q_{j}^{x}\\stackrel{\\sim}{\\leftarrow}\\sum_{\\xi\\in\\mathrm{supp}\\;({T^{\\pi}}\\eta)_{x}}({T^{\\pi}}\\eta)_{x}(\\xi)\\kappa(\\xi_{j},\\xi)}\\end{array}$ for each $\\xi_{j}\\in\\mathcal{R}(x)$ p \u2190QPSolve $\\begin{array}{r}{\\left(\\operatorname*{min}_{p\\in\\mathbf{R}^{|\\mathcal{R}(x)|}}\\left[p^{\\top}K^{x}p-2p^{\\top}q\\right]\\right.}\\end{array}$ subject to $p\\succeq0$ , $\\textstyle\\sum_{i}p_{i}=1\\!\\!$ $\\begin{array}{r}{(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta)_{x}\\leftarrow\\sum_{\\xi_{i}\\in\\mathcal{R}(x)}p_{i}\\delta_{\\xi_{i}}}\\end{array}$   \nend for ", "page_idx": 5}, {"type": "text", "text": "Lemma 2. Under the conditions of Lemma 1, $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ . That is, for any $\\eta_{1},\\eta_{2}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\operatorname*{max}}]^{d})^{\\chi}$ , we have $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{2})\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2})$ . ", "page_idx": 5}, {"type": "text", "text": "Categorical multivariate distributional dynamic programming. As an immediate consequence of Lemma 2, it follows that projected dynamic programming under the projection $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is convergent; ", "page_idx": 5}, {"type": "text", "text": "this is because $\\mathcal{T}^{\\pi}$ is a contraction in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ and $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , so the projected operator $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ is a contraction in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ ; a standard invokation of the Banach fixed point theorem appealing to the completenes of $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ certifies that repeated application of $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}T^{\\pi}$ will result in convergence to a unique fixed point. ", "page_idx": 6}, {"type": "text", "text": "Corollary 2. Let \u03ba be a kernel satisfying the conditions of Theorem 2. Then for any $\\eta_{0}\\in\\mathcal{C}_{\\mathcal{R}}$ , the iterates $\\{\\bar{\\eta}_{k}\\}_{k=1}^{\\infty}$ given by $\\eta_{k+1}=\\Pi_{\\mathrm{C},\\kappa}^{\\check{\\pi}}\\check{T}^{\\pi}\\eta_{k}$ converge geometrically to a unique fixed point. ", "page_idx": 6}, {"type": "text", "text": "Beyond the result of Theorem 2, Corollary 2 illustrates an algorithm for estimating $\\eta^{\\pi}$ in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ provided knowledge of the transition kernel and the reward function, which is computationally tractable in tabular MDPs. Indeed, the iterates $(\\eta_{k})_{k\\geq0}$ all lie in $\\mathcal{C}_{\\mathcal{R}}$ , having finitely-many degrees of freedom. Algorithm 1 outlines a computationally tractable procedure for learning $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ in this setting. We note that the work of [WUS23] provided an alternative multivariate categorical algorithm, which was not analyzed theoretically. Moreover, our method provides the additional ability to support state-dependent arbitrary support maps, while theirs requires support maps to be uniform grids. ", "page_idx": 6}, {"type": "text", "text": "Accurate approximations. We now provide bounds showing that the fixed point $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ from Corollary 2 can be made arbitrarily accurate by increasing the number of atoms. ", "page_idx": 6}, {"type": "text", "text": "To derive a bound on the quality of the fixed point, we provide a reduction via partitioning the space of returns to the covering number of this space. Proceeding, we define a class of partitions ${\\mathcal{P}}_{{\\mathcal{R}}(x)}$ , where each $P\\in\\mathcal P_{\\mathcal R(x)}$ satisfies ", "page_idx": 6}, {"type": "text", "text": "1. $|P|=N(x)$ ;   \n2. For any $\\theta_{1},\\theta_{2}\\in P$ , either $\\theta_{1}\\cap\\theta_{2}=\\emptyset$ or $\\theta_{1}=\\theta_{2}$ ;   \n3. $\\cup_{\\theta\\in P}\\theta=\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\operatorname*{max}}]^{d})$ ;   \n4. Each element $\\theta_{i}\\in P$ contains exactly one element $z_{i}\\in\\mathcal{R}(x)$ . ", "page_idx": 6}, {"type": "text", "text": "For any partition $P$ , we define a notion of mesh size relative to a kernel $\\kappa$ induced by a semimetric $\\rho$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathsf{m e s h}(P;\\kappa)=\\operatorname*{max}_{\\theta\\in P}\\operatorname*{sup}_{y_{1},y_{2}\\in\\theta}\\rho(y_{1},y_{2}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The following result confirms that $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ recovers $\\eta^{\\pi}$ as the mesh decreases. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4. Let \u03ba be a kernel induced by a c-homogeneous and shift-invariant semimetric $\\rho$ conforming to the conditions of Theorem 2. Then the fixed point $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ of $\\dot{\\Pi}_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Thus, for any sequence of supports $\\{\\mathcal{R}(x)_{m}\\}_{m\\ge1}$ for which the maximal space (in $\\rho$ ) between any two points in $\\mathcal{R}(x)_{m}$ tends to 0 as $m\\rightarrow\\infty$ , the fixed point $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ approximates $\\eta^{\\pi}$ to arbitrary precision for large enough $m$ . The next corollary illustrates this in a familiar setting. ", "page_idx": 6}, {"type": "text", "text": "Corollary 3. Let $\\mathcal{R}(x)=U_{m}$ , where $U_{m}$ is a set of m uniformly-spaced support points on $[0,(1-$ $\\gamma)^{-1}R_{\\mathrm{max}}\\bar{]}$ . For $\\kappa$ induced by the semimetric $\\rho(x,y)=\\|x-y\\|_{2}^{\\alpha}$ for $\\alpha\\in(0,2)$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(m^{1/d}-2)^{\\alpha/2}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "With $\\alpha\\,=\\,1$ and $d=1$ , the MMD in Corollary 3 is equivalent to the Cram\u00e9r metric [SR13], the setting in which categorical (scalar) distributional dynamic programming is well understood. Our rate matches the known $\\Theta(m^{-1/2})$ rate shown by $[\\mathrm{RBD^{+}18}]$ in this setting. Thus, our results offer a new perspective on categorical DRL, and naturally generalizes the theory to the multivariate setting. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4 relies on the following lemma about the approximation quality of the categorical MMD projection, which may be of independent interest. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3. Let \u03ba be kernel satisfying the conditions of Lemma 1, and for any finite $\\mathcal{R}\\subset\\mathbf{R}^{d}$ , define \u03a0 : $\\mathcal{P}(\\mathbf{R}^{d})\\rightarrow\\Delta_{\\mathcal{R}}$ via $\\Pi p=\\operatorname{arginf}_{q\\in\\Delta_{\\mathcal{R}}}\\mathrm{MMD}_{\\kappa}(p,q)$ . Then $\\mathrm{MMD}_{\\kappa}^{2}(\\Pi p,p)\\leq\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}}}$ mesh $(P;\\kappa)$ ", "page_idx": 6}, {"type": "text", "text": "At this stage, we have shown definitively that categorical dynamic programming converges in the multivariate case. In the sequel, we build on these results to provide a convergent multivariate categorical TD-learning algorithm. ", "page_idx": 6}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/ae40a8ab895fe7e5ea447b6dbf8ee477729d5930fcdc94c0e3a5010cfb8e22fe.jpg", "img_caption": ["Figure 1: Distributional SMs and associated predicted return distributions with the categorical (left) and EWP (right) representations. Simplex plots denote the distributional SM. Histograms denote the associated return distributions, predicted from a pair of held-out reward functions. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "5.1 Simulation: The Distributional Successor Measure ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "As a preliminary example, we consider 3-state MDPs with the cumulants $r(i)=(1-\\gamma)e_{i},i\\in[3]$ for $e_{i}$ the ith basis vector. In this setting, $\\eta^{\\pi}$ encodes the distribution over trajectory-wise discounted state occupancies, which was discussed in the recent work of $[\\mathrm{WFG}^{+}24]$ and called the distributional successor measure (DSM). Particularly, $[\\mathrm{WFG}^{+}24]$ showed that $x\\mapsto\\operatorname{Law}\\left(G_{x}^{\\top}\\tilde{r}\\right)$ for $G_{x}\\sim\\eta^{\\pi}(x)$ is the return distribution function for any scalar reward function $\\tilde{r}$ . Figure 1 shows that the projected categorical dynamic programming algorithm accurately approximates the distribution over discounted state occupancies as well as distributions over returns on held-out reward functions. ", "page_idx": 7}, {"type": "text", "text": "6 Multivariate Distributional TD-Learning ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Next, we devise an algorithm for approximating the multi-return distribution function when the transition kernel and reward function are not known, and are observed only through samples. Indeed, this is a strong motivation for TD-learning algorithms [Sut88], wherein state transition data alone is used to solve the Bellman equation. In this section, we devise a TD-learning algorithm for multivariate DRL, leveraging our results on categorical dynamic programming in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ . ", "page_idx": 7}, {"type": "text", "text": "Relaxation to signed measures. In the $d=1$ setting, the categorical projection presented above is known to be affine $[\\mathrm{RBD^{+}18}]$ , making scalar categorical TD-learning amenable to common techniques in stochastic approximation theory. However, the projection is not affine when $d\\geq2$ ; we give an explicit example in Appendix D. Thus, we relax the categorical representation to include signed measures, which will provide us with an affine projection [BRCM19]\u2014this is crucial for proving our main result, Theorem 6. We denote by $\\mathcal{M}^{1}(\\bar{\\mathcal{X}})$ the set of all signed measures $\\mu$ over $\\boldsymbol{\\wp}$ with $\\bar{\\mu(\\mathcal{V})}=1$ . We begin by noting that the MMD endows $\\mathcal{M}^{1}(\\mathcal{Y})$ with a metric structure. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4. Let $\\kappa:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbf{R}$ be a characteristic kernel over some space $\\boldsymbol{\\wp}$ . Then ${\\mathrm{MMD}}_{\\kappa}$ : $\\mathcal{M}^{1}(\\mathcal{V})\\times\\mathcal{M}^{1}(\\mathcal{V})\\rightarrow\\mathbf{R}_{+}$ given by $(p,q)\\mapsto\\|\\mu_{p}-\\mu_{q}\\|_{\\mathcal{H}}$ defines a metric on $\\mathcal{M}^{1}(\\mathcal{Y})$ , where $\\mu_{p}$ denotes the usual mean embedding of $p$ and $\\mathcal{H}$ is the RKHS with kernel $\\kappa$ . ", "page_idx": 7}, {"type": "text", "text": "We define the relaxed projection $\\begin{array}{r}{\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}:\\mathcal{M}^{1}([0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d})^{\\mathcal{X}}\\rightarrow\\prod_{x\\in\\mathcal{X}}\\mathcal{M}^{1}(\\mathcal{R}(x))=:\\mathcal{S}_{\\mathcal{R}},}\\end{array}$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\eta\\right)(x)\\in\\underset{p\\in\\mathcal{M}^{1}(\\mathcal{R}(x))}{\\mathrm{arginf}}\\mathrm{MMD}_{\\kappa}(p,\\eta(x)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Note that (10) is very similar to the definition of the categorical MMD projection in (7)\u2014the only difference is that the optimization occurs over the larger class of signed mass-1 measures. It is also worth noting that the distributional Bellman operator can be applied directly to signed measures, which yields the following convenient result. ", "page_idx": 7}, {"type": "text", "text": "Lemma 5. Under the conditions of Corollary 2, the projected operator $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}:\\mathcal{S}_{\\mathcal{R}}\\rightarrow\\mathcal{S}_{\\mathcal{R}}$ is affine, is contractive with contraction factor $\\gamma^{c/2}$ , and has a unique fixed point $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ . ", "page_idx": 7}, {"type": "text", "text": "While we have \u201crelaxed\u201d the projection, the fixed point $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ is a good approximation of $\\eta^{\\pi}$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 5. Under the conditions of Lemma 5, we have that ", "page_idx": 7}, {"type": "equation", "text": "$\\begin{array}{r}{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)};}\\end{array}$ ", "text_format": "latex", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\left(1+\\frac{1}{1-\\gamma^{c/2}}\\right)\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Notably, the second statement of Theorem 5 states that projecting $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ back onto the space of multi-return distribution functions yields approximately the same error as $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ when $\\gamma$ is near 1. ", "page_idx": 8}, {"type": "text", "text": "In the remainder of the section, we assume access to a stream of MDP transitions $\\{T_{t}\\}_{t=1}^{\\infty}\\subset$ $\\mathcal{X}\\times\\mathcal{A}\\times\\mathbf{R}^{d}\\times\\mathcal{X}$ consisting of elements $T_{t}=(X_{t},A_{t},R_{t},X_{t}^{\\prime})$ with the following structure, ", "page_idx": 8}, {"type": "equation", "text": "$$\nX_{t}\\sim{\\bf P}(\\cdot\\mid{\\mathcal F}_{t-1})\\qquad A_{t}\\sim\\pi(\\cdot\\mid X_{t})\\qquad R_{t}=r(X_{t})\\qquad X_{t}^{\\prime}\\sim P(\\cdot\\mid X_{t},A_{t})\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathbf{P}$ is some probability measure and $\\{\\mathcal{F}_{t}\\}_{t=1}^{\\infty}$ is the canonical flitration $\\mathcal{F}_{t}=\\sigma(\\cup_{t=1}^{t}T_{t})$ . Based on these transitions, we can define stochastic distributional Bellman backups by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{T}}_{t}^{\\pi}\\eta(x)=\\left\\{\\!\\!\\!\\begin{array}{l l}{(\\mathrm{b}_{R_{t},\\gamma})_{\\sharp}\\eta(X_{t}^{\\prime})}&{x=X_{t}}\\\\ {\\eta(x)}&{\\mathrm{otherwise}}\\end{array}\\!\\!,\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "which notably can be computed exactly without knowledge of $P,r$ . Due to the stronger convergence guarantees shown for projected multivariate distributional dynamic programming, we introduce an asynchronous incremental algorithm leveraging the categorical representation, which produces iterates $\\{\\widehat{\\eta}_{t}\\}_{t=1}^{\\infty}$ according to ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\eta}_{t+1}=(1-\\alpha_{t})\\widehat{\\eta}_{t}+\\alpha_{t}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\widehat{\\mathcal{T}}_{t}^{\\pi}\\widehat{\\eta}_{t}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for $\\widehat{\\eta}_{0}\\in\\mathcal{C}_{\\mathcal{R}}$ , where $\\left\\{\\alpha_{t}\\right\\}_{t=1}^{\\infty}$ is any sequence of (possibly) random step sizes adapted to the flitration $\\{\\mathcal{F}_{t}\\}_{t=1}^{\\infty}$ . The iterates of (13) closely resemble those of classic stochastic approximation algorithms [RM51] and particularly asynchronous TD learning algorithms [JJS93, Tsi94, BT96], but with iterates taking values in the space of state-indexed signed measures. Indeed, our next result draws on the techniques from these works to establish convergence of TD-learning on $\\mathcal{S}_{\\mathcal{R}}$ representations. ", "page_idx": 8}, {"type": "text", "text": "Theorem 6. For a kernel $\\kappa$ induced by a semimetric $\\rho$ of strong negative type, the sequence $\\{\\widehat{\\eta}_{t}\\}_{t=1}^{\\infty}$ given by (11)-(13) converges to $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ with probability $^{\\,l}$ . ", "page_idx": 8}, {"type": "text", "text": "6.1 Simulations: Distributional Successor Features ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To illustrate the behavior of our categorical TD algorithm, we employ it to learn the multi-return distributions for several tabular MDPs with random cumulants. We focus on the case of 2- and 3-dimensional cumulants, which is the setting studied in recent works regarding multivariate distributional RL $[Z\\mathrm{C}Z^{+}21$ , WUS23]. Interpreting the multi-return distributions as joint distributions over successor features $[\\mathrm{BDM^{+}17a}$ , SFs], we additionally evaluate the return distributions for random reward functions in the span of the cumulants. We compare our categorical TD approach with a tabular implementation of the EWP TD algorithm of $[Z\\bar{\\mathrm{C}}\\bar{Z}^{+}21]$ , for which no convergence bounds are known. ", "page_idx": 8}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/439d5c3ca752cf642abf70819907ed9abffa4785f3d3dc796bb5b883c28abe61.jpg", "img_caption": ["Figure 2: Error of zero-shot return distribution predictions over random MDPs, measured by Cram\u00e9r distance, and showing $95\\%$ confidence intervals. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 2a compares TD learning approaches based on their ability to accurately infer (scalar) return distributions on held out reward functions, averaged over 100 random MDPs, with transitions drawn from Dirichlet priors and 2-dimensional cumulants drawn from uniform priors. The performance of the categorical algorithms sharply increases as the number of atoms increases. On the other hand, the EWP TD algorithm performs well with few atoms, but does not improve very much with higher-resolution representations. We posit this is due to the algorithm getting stuck in local minima, given the non-convexity of the EWP MMD objective. This hypothesis is supported as well by Figure 3, which depicts the learned distributional SFs and return distribution predictions. ", "page_idx": 8}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/36bb45121e1ac120c3aadc87ec9cc1514f325e8c0fb4e3718cc91e4ae9dbf986.jpg", "img_caption": ["Figure 3: Distributional SFs and predicted return distributions with $m=400$ atoms, in a random MDP with known rectangular bound on cumulants. Left: Categorical TD. Right: EWP TD. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Particularly, we observe that the learned particle locations in the EWP TD approach tend to cluster in some areas or get stuck in low-density regimes, which suggests the presence of a local optimum. On the other hand, our provably-convergent categorical TD method learns a high fidelity quantization of the true multi-return distributions. ", "page_idx": 9}, {"type": "text", "text": "Naturally, however, the benefits of the $\\mathsf{p o l y}(d)$ bounds for EWP suggested by Theorem 3 become more present as we increase the cumulant dimension. Figure 2b repeats the experiment of Figure 2a with $d\\,=\\,3$ , using randomized support points for the categorical algorithm to avoid a cubic growth in the cardinality of the supports. Notably, our method is the first capable of supporting such unstructured supports. While the categorical TD approach can still outperform EWP, a much larger number of atoms is required. This is unsurprising in light of our theoretical results. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have provided the first provably convergent and computationally tractable algorithms for learning multivariate return distributions in tabular MDPs. Our theoretical results include convergence guarantees that indicate how accuracy scales with the number of particles $m$ used in distribution representations, and interestingly motivate the use of signed measures to develop provably convergent TD algorithms. ", "page_idx": 9}, {"type": "text", "text": "While it is difficult to scale categorical representations to high-dimensional cumulants, our algorithm is highly performant in the low $d$ setting, which has been the focus of recent work in multivariate distributional RL. Notably, even the $d=2$ setting has important applications\u2014indeed, efforts in safe RL depend on distinguishing a cost signal from a reward signal (see, e.g., [YSTS23]), which can be modeled by bivariate distributional RL. In this setting, our method can easily be scaled to large state spaces by approximating the categorical signed measures with neural networks; an illustrated example is given in Appendix F. ", "page_idx": 9}, {"type": "text", "text": "On the other hand, the prospect of learning multi-return distributions for high-dimensional cumulants also has many important applications, such as modeling close approximations to distributional successor measures $[\\mathrm{WFG}^{+}24]$ for zero-shot risk-sensitive policy evaluation. In this setting, we believe EWP-based multivariate DRL will be highly impactful. Our results concerning EWP dynamic programming provide promising evidence that the accuracy of EWP representations scales gracefully with $d$ for a fixed number of atoms. Thus, we believe that understanding convergence of EWP TD-learning algorithms is a very interesting and important open problem for future investigation. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The authors would like to thank Yunhao Tang, Tyler Kastner, Arnav Jain, Yash Jhaveri, Will Dabney, David Meger, and Marc Bellemare for their helpful feedback, as well as insightful suggestions from anonymous reviewers. This work was supported by the Fonds de Recherche du Qu\u00e9bec, the National Sciences and Engineering Research Council of Canada, and the compute resources provided by Mila (mila.quebec). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[BB96] Steven J. Bradtke and Andrew G. Barto. Linear least-squares algorithms for temporal difference learning. Machine Learning, 22(1):33\u201357, 1996.   \n$[\\mathbf{BBC}^{+}21]$ ] Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer, Felipe Llinares-L\u00f3pez, Fabian Pedregosa, and Jean-Philippe Vert. Efficient and modular implicit differentiation. In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \n$[\\mathbf{BCC}^{+}20]$ Marc G. Bellemare, Salvatore Candido, Pablo Samuel Castro, Jun Gong, Marlos C. Machado, Subhodeep Moitra, Sameera S. Ponda, and Ziyu Wang. Autonomous navigation of stratospheric balloons using reinforcement learning. Nature, 588(7836):77\u201382, December 2020.   \n$\\mathrm{BDM}^{+}17\\mathrm{a}_{-}^{-}$ ] Andr\u00e9 Barreto, Will Dabney, R\u00e9mi Munos, Jonathan J. Hunt, Tom Schaul, Hado P. van Hasselt, and David Silver. Successor features for transfer in reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2017.   \n[BDM17b] Marc G. Bellemare, Will Dabney, and R\u00e9mi Munos. A Distributional Perspective on Reinforcement Learning. In International Conference on Machine Learning (ICML), 2017. [BDR23] Marc G. Bellemare, Will Dabney, and Mark Rowland. Distributional Reinforcement Learning. The MIT Press, 2023.   \n[BEKS17] Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B. Shah. Julia: A fresh approach to numerical computing. SIAM Review, 59(1):65\u201398, 2017.   \n$[\\mathbf{B}\\mathbf{F}\\mathbf{H}^{+}18]$ James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye WandermanMilne, and Qiao Zhang. JAX: composable transformations of Python $^{+}$ NumPy programs, 2018.   \n$[{\\mathbf{B}}{\\mathrm{HB}}^{+}20]$ Andr\u00e9 Barreto, Shaobo Hou, Diana Borsa, David Silver, and Doina Precup. Fast reinforcement learning with generalized policy updates. Proceedings of the National Academy of Sciences (PNAS), 117(48):30079\u201330087, 2020.   \n[BRCM19] Marc G Bellemare, Nicolas Le Roux, Pablo Samuel Castro, and Subhodeep Moitra. Distributional reinforcement learning with linear function approximation. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2019. [BT96] Dimitri P. Bertsekas and John N. Tsitsiklis. Neuro-dynamic programming. Athena Scientific, 1996.   \n$[\\mathrm{CGH^{+}96}]$ Robert M. Corless, Gaston H. Gonnet, David E.G. Hare, David J. Jeffrey, and Donald E. Knuth. On the Lambert W function. Advances in Computational Mathematics, 5:329\u2013 359, 1996.   \n$[{\\bf C}Z Z^{+}24]$ Xin-Qiang Cai, Pushi Zhang, Li Zhao, Jiang Bian, Masashi Sugiyama, and Ashley Llorens. Distributional Pareto-optimal multi-objective reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2024.   \n[DKNU $^+20_{.}$ ] Will Dabney, Zeb Kurth-Nelson, Naoshige Uchida, Clara Kwon Starkweather, Demis Hassabis, R\u00e9mi Munos, and Matthew Botvinick. A distributional code for value in dopamine-based reinforcement learning. Nature, 577(7792):671\u2013675, 2020.   \n[DRBM18] Will Dabney, Mark Rowland, Marc G. Bellemare, and R\u00e9mi Munos. Distributional Reinforcement Learning with Quantile Regression. In AAAI Conference on Artificial Intelligence, 2018.   \n[FSMT19] Dror Freirich, Tzahi Shimkin, Ron Meir, and Aviv Tamar. Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN. In International Conference on Machine Learning (ICML), 2019.   \n$[\\mathrm{GBR}^{+}12]$ Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch\u00f6lkopf, and Alexander Smola. A Kernel Two-Sample Test. Journal of Machine Learning Research (JMLR), 13(25):723\u2013773, 2012.   \n[GBSL21] Michael Gimelfarb, Andr\u00e9 Barreto, Scott Sanner, and Chi-Guhn Lee. Risk-Aware Transfer in Reinforcement Learning using Successor Features. In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \n$[\\mathrm{HRB}^{+}22]$ Conor F. Hayes, Roxana Radulescu, Eugenio Bargiacchi, Johan K\u00e4llstr\u00f6m, Matthew Macfarlane, Mathieu Reymond, Timothy Verstraeten, Luisa M. Zintgraf, Richard Dazeley, Fredrik Heintz, Enda Howley, Athirai A. Irissappane, Patrick Mannion, Ann Now\u00e9, Gabriel de Oliveira Ramos, Marcello Restelli, Peter Vamplew, and Diederik M. Roijers. A practical guide to multi-objective reinforcement learning and planning. In Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2022. [JJS93] Tommi Jaakkola, Michael I. Jordan, and Satinder P. Singh. On the Convergence of Stochastic Iterative Dynamic Programming Algorithms. In Advances in Neural Information Processing Systems (NeurIPS), 1993. [KEF23] Tyler Kastner, Murat A. Erdogdu, and Amir-massoud Farahmand. Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning. In Advances in Neural Information Processing Systems (NeurIPS), 2023. [Lax02] Peter D. Lax. Functional analysis. John Wiley & Sons, 2002. [LB22] Alix Lh\u00e9ritier and Nicolas Bondoux. A Cram\u00e9r Distance perspective on Quantile Regression based Distributional Reinforcement Learning. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2022. [LK24] Dong Neuck Lee and Michael R. Kosorok. Off-policy reinforcement learning with high dimensional reward. CoRR, ans/2408.07660, 2024. [LM22] Shiau Hong Lim and Ilyas Malik. Distributional Reinforcement Learning for RiskSensitive Policies. In Advances in Neural Information Processing Systems (NeurIPS), 2022.   \n$[\\mathrm{MSK^{+}10}]$ Tetsuro Morimura, Masashi Sugiyama, Hisashi Kashima, Hirotaka Hachiya, and Toshiyuki Tanaka. Nonparametric return distribution approximation for reinforcement learning. In International Conference on Machine Learning (ICML), 2010.   \n[NTGV20] Thanh Nguyen-Tang, Sunil Gupta, and Svetha Venkatesh. Distributional Reinforcement Learning via Moment Matching. In AAAI Conference on Artificial Intelligence, 2020.   \n$[\\mathrm{RBD}^{+}18]$ Mark Rowland, Marc G. Bellemare, Will Dabney, Remi Munos, and Yee Whye Teh. An Analysis of Categorical Distributional Reinforcement Learning. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2018. [RM51] Herbert Robbins and Sutton Monro. A Stochastic Approximation Method. The Annals of Mathematical Statistics, 22(3):400\u2013407, September 1951.   \n[RMA+24] Mark Rowland, R\u00e9mi Munos, Mohammad Gheshlaghi Azar, Yunhao Tang, Georg Ostrovski, Anna Harutyunyan, Karl Tuyls, Marc G. Bellemare, and Will Dabney. An Analysis of Quantile Temporal-Difference Learning. Journal of Machine Learning Research (JMLR), 25(163):1\u201347, 2024.   \n$[\\mathrm{ROH}^{+}21]$ ] Mark Rowland, Shayegan Omidshafiei, Daniel Hennes, Will Dabney, Andrew Jaegle, Paul Muller, Julien P\u00e9rolat, and Karl Tuyls. Temporal difference and return optimism in cooperative multi-agent reinforcement learning. In AAMAS ALA Workshop, 2021.   \n[RVWD13] Diederik M. Roijers, Peter Vamplew, Shimon Whiteson, and Richard Dazeley. A survey of multi-objective sequential decision-making. Journal of Artificial Intelligence Research (JAIR), 48:67\u2013113, 2013. [Sch00] Bernhard Sch\u00f6lkopf. The Kernel Trick for Distances. In Advances in Neural Information Processing Systems (NeurIPS), 2000. [SFS24] Eiki Shimizu, Kenji Fukumizu, and Dino Sejdinovic. Neural-kernel conditional mean embeddings. In International Conference on Machine Learning (ICML), 2024. [She21] Vladimir Shenmaier. On the Complexity of the Geometric Median Problem with Outliers. CoRR, abs/2112.00519, 2021. [SLL21] Wei-Fang Sun, Cheng-Kuang Lee, and Chun-Yi Lee. DFAC framework: Factorizing the value function via quantile mixture for multi-agent distributional Q-learning. In International Conference on Machine Learning (ICML), 2021. [SR13] G\u00e1bor J. Sz\u00e9kely and Maria L. Rizzo. Energy statistics: A class of statistics based on distances. Journal of Statistical Planning and Inference, 143(8):1249\u20131272, August 2013.   \n[SSGF13] Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, and Kenji Fukumizu. Equivalence of distance-based and RKHS-based statistics in hypothesis testing. The Annals of Statistics, 41(5), October 2013. [Sut88] Richard S. Sutton. Learning to predict by the methods of temporal differences. Machine Learning, 3:9\u201344, 1988.   \n$[\\mathrm{SZS^{+}08}]$ Le Song, Xinhua Zhang, Alex Smola, Arthur Gretton, and Bernhard Sch\u00f6lkopf. Tailoring density estimation via reproducing kernel moment matching. In International Conference on Machine Learning (ICML), 2008. [Tsi94] John N. Tsitsiklis. Asynchronous stochastic approximation and Q-learning. Machine learning, 16:185\u2013202, 1994. [TSM17] Ilya Tolstikhin, Bharath K. Sriperumbudur, and Krikamol Mu. Minimax estimation of kernel mean embeddings. Journal of Machine Learning Research (JMLR), 18(86):1\u201347, 2017. [TVR97] J.N. Tsitsiklis and B. Van Roy. An analysis of temporal-difference learning with function approximation. IEEE Transactions on Automatic Control, 42(5):674\u2013690, 1997. [Vil09] C\u00e9dric Villani. Optimal transport: Old and new, volume 338. Springer, 2009. [VN02] Jan Van Neerven. Approximating Bochner integrals by Riemann sums. Indagationes Mathematicae, 13(2):197\u2013208, June 2002.   \n$[\\mathbf{WBK}^{+}22]$ Peter R Wurman, Samuel Barrett, Kenta Kawamoto, James MacGlashan, Kaushik Subramanian, Thomas J Walsh, Roberto Capobianco, Alisa Devlic, Franziska Eckert, Florian Fuchs, et al. Outracing champion gran turismo drivers with deep reinforcement learning. Nature, 602(7896):223\u2013228, 2022.   \n[WFG+24] Harley Wiltzer, Jesse Farebrother, Arthur Gretton, Yunhao Tang, Andr\u00e9 Barreto, Will Dabney, Marc G. Bellemare, and Mark Rowland. A distributional analogue to the successor representation. In International Conference on Machine Learning (ICML), 2024.   \n[WUS23] Runzhe Wu, Masatoshi Uehara, and Wen Sun. Distributional Offilne Policy Evaluation with Predictive Error Guarantees. In International Conference on Machine Learning (ICML), 2023.   \n[YSTS23] Qisong Yang, Thiago D. Sim\u00e3o, Simon H. Tindemans, and Matthijs T. J. Spaan. Safety-constrained reinforcement learning with a distributional safety critic. Machine Learning, 112(3):859\u2013887, 2023.   \n$[\\mathrm{YZL}^{+}19]$ Derek Yang, Li Zhao, Zichuan Lin, Tao Qin, Jiang Bian, and Tie-Yan Liu. Fully parameterized quantile function for distributional reinforcement learning. In Advances in Neural Information Processing Systems (NeurIPS), 2019.   \n$[Z\\!C Z^{+}21]$ Pushi Zhang, Xiaoyu Chen, Li Zhao, Wei Xiong, Tao Qin, and Tie-Yan Liu. Distributional Reinforcement Learning for Multi-Dimensional Reward Functions. In Advances in Neural Information Processing Systems (NeurIPS), 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Appendices ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendix B Proofs 16   \nB.1 Multivariate Distributional Dynamic Programming: Section 3 . . 16   \nB.2 EWP Dynamic Programming: Section 4 . . . 18   \nB.3 Categorical Dynamic Programming: Section 5 . 20   \nB.3.1 Quality of the Categorical Fixed Point . . 22   \nB.4 Categorical TD Learning: Section 6 24   \nB.4.1 The Signed Measure Relaxation 24   \nB.4.2 Convergence of Categorical TD Learning 26 ", "page_idx": 14}, {"type": "text", "text": "Appendix C Memory Efficiency of Randomized EWP Dynamic Programming 30 ", "page_idx": 14}, {"type": "text", "text": "Appendix D Nonlinearity of the Categorical MMD Projection ", "page_idx": 14}, {"type": "text", "text": "33 ", "page_idx": 14}, {"type": "text", "text": "Appendix E Experiment Details ", "page_idx": 14}, {"type": "text", "text": "Appendix F Neural Multivariate Distributional TD-Learning ", "page_idx": 14}, {"type": "text", "text": "33 ", "page_idx": 14}, {"type": "text", "text": "A In-Depth Summary of Related Work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Sections 1 and 2, we provided a high-level synopsis of the state of existing work in multivariate distributional RL. In this section, we elaborate further. ", "page_idx": 14}, {"type": "text", "text": "Analysis techniques. Our results in this paper mostly drawn on the analysis of one-dimensional distributional RL algorithms such as categorical and quantile dynamic programming, as well as their temporal-difference learning counterparts $[\\mathrm{RBD^{+}1\\bar{8}}$ , DRBM18, $\\mathrm{RMA}^{+}2\\bar{4}$ , BDR23]. The proof techniques in these works themselves are related to contraction-based arguments for reinforcement learning with function approximation [Tsi94, BT96, TVR97]. ", "page_idx": 14}, {"type": "text", "text": "Multivariate distributional RL algorithms. Several prior works have contributed algorithms for multivariate distributional reinforcement learning, along with empirical demonstrations and theoretical analysis, though as we note in the main paper, the approaches proposed in this paper are the first algorithms with strong theoretical guarantees and efficient tabular implementations. [FSMT19] propose a deep-learning-based approach in which generative adversarial networks are used to model multivariate return distributions, and use these predictions to inform exploration strategies. $[Z\\mathrm{C}Z^{+}21]$ propose the TD algorithm combing equally-weighted particle representations and an MMD loss that we recall in Equation (3). They demonstrate the effectiveness of this algorithm in combination with deep learning function approximators, though do not analyze it. [WUS23] propose a family of algorithms for multivariate distributional RL termed ftited likelihood evaluation. These methods mirror LSTD algorithms [BB96], iteratively minimising a batch objective function (in this case, a negative log-likelihood, NLL) over a growing dataset. [WUS23] demonstrate that these algorithms are performant in low-dimensional settings empirically, and provide theoretical analysis for FLE algorithms, assuming an oracle which can approximately optimise the NLL objective at each algorithm step. [SFS24] also propose a TD learning algorithm for one-dimensional distributional RL using categorical support and an MMD-based loss. They demonstrate strong performance of this algorithm in classic RL domains such as CartPole and Mountain Car, but do not analyze the algorithm. Our analysis in this paper suggests our novel relaxation to mass-1 signed measures may be crucial to obtaining a straightforwardly analyzable TD algorithm. ", "page_idx": 14}, {"type": "text", "text": "Finally, the concurrent work of [LK24] studied distributional Bellman operators for Banach-spacevalued reward functions. Their work focuses on analyzing how well the fixed point of a distributional finite-dimensional multivariate Bellman equation can approximate the fixed point of a distributional Banach-space-valued Bellman equation. In contrast, our work only studies finite-dimensional reward functions, but provides explicit convergence rates and approximation bounds when the distribution representations are finite dimensional, unlike [LK24]. Moreover, [LK24] considers a similar algorithm to that discussed in Theorem 3 but for categorical representations, though its convergence is not proved. Furthermore, [LK24] did not prove convergence of any TD-learning algorithms, although they did propose some TD-learning algorithms which achieved interesting results in simulation. ", "page_idx": 15}, {"type": "text", "text": "B Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Multivariate Distributional Dynamic Programming: Section 3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we will state some lemmas building up to the proof of Theorem 2. These lemmas generalize corresponding results of [NTGV20] that were specific to the scalar reward setting. We begin with a lemma that demonstrates a notion of convexity for the MMD induced by a conditional positive definite kernel. ", "page_idx": 15}, {"type": "text", "text": "Lemma 6. Let $(p_{a})_{a\\in\\mathcal{T}}\\,\\subset\\,\\mathcal{P}(\\mathcal{Y})$ and $(q_{a})_{a\\in\\mathcal{I}}\\;\\subset\\;\\mathcal{P}(\\mathcal{Y})$ be collections of probability measures indexed by an index set $\\mathcal{T}$ . Suppose $T\\in{\\mathcal{P}}({\\mathcal{T}})$ . Then for any characteristic kernel $\\kappa$ , the following holds, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname{MMD}_{\\kappa}(\\mathbf{E}_{a\\sim T}\\left[p_{a}\\right],\\mathbf{E}_{a^{\\prime}\\sim T}\\left[q_{a^{\\prime}}\\right])\\leq\\operatorname*{sup}_{a\\in\\mathcal{T}}\\operatorname{MMD}_{\\kappa}(p_{a},q_{a})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. It is known from [Sch00] that characteristic kernels generate RKHSs $\\mathcal{H}$ into which probability measures can be embedded. As such, it holds that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{MMD}_{\\kappa}(p,q)=\\|\\mu_{p}-\\mu_{q}\\|\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\|\\cdot\\|$ is the norm in the Hilbert space $\\mathcal{H}$ and $\\mu_{p}$ is the mean embedding of $p-$ that is, the unique element of $\\mathcal{H}$ such that $\\mathbf{E}_{y\\sim p}\\left[f(y)\\right]\\bar{=}\\left\\langle f,\\mu_{p}\\right\\rangle$ for every $f\\in\\mathcal H$ , and where $\\langle\\cdot,\\cdot\\rangle$ is the inner product in $\\mathcal{H}$ . ", "page_idx": 15}, {"type": "text", "text": "Let $T_{p}\\triangleq\\mathbf{E}_{a\\sim T}\\left[p_{a}\\right]$ and define $T_{q}$ analogously. We claim that $\\mu_{T p}=\\mathbf{E}_{a\\sim T}\\left[\\mu_{p_{a}}\\right]\\triangleq T\\mu_{p}$ . To see this, let $f\\in\\mathcal H$ , and observe that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{y\\sim T_{P}}{\\mathbf{E}}[f]\\left(y\\right)=\\int f(y)T p(\\mathrm{d}y)}\\\\ &{=\\iint f(y)T(\\mathrm{d}a)p_{a}(\\mathrm{d}y)}\\\\ &{=\\iint f(y)p_{a}(\\mathrm{d}y)T(\\mathrm{d}a)}\\\\ &{=\\int\\langle f,\\mu_{p_{a}}\\rangle T(\\mathrm{d}a)}\\\\ &{=\\left\\langle f,\\mu_{p_{a}}\\rangle T(\\mathrm{d}a)\\right.}\\\\ &{=\\left\\langle f,\\int\\mu_{p_{a}}T(\\mathrm{d}a)\\right\\rangle}\\\\ &{=\\left\\langle f,T\\mu_{p_{a}}\\right\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the third step invokes Fubini\u2019s theorem, and the penultimate steps leverages the linearity of the inner product. Notably, $T$ acts as a linear operator on mean embeddings. As a result, we see that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MMD}_{\\kappa}(T p,T q)=\\|\\mu_{T p}-\\mu_{T q}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\|T\\mu_{p}-T\\mu_{q}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\left\\|\\displaystyle\\int_{\\mathcal{Z}}(\\mu_{p_{\\alpha}}-\\mu_{q_{\\alpha}})T(\\mathrm{d}a)\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\int\\|\\mu_{p_{\\alpha}}-\\mu_{q_{\\alpha}}\\|T(\\mathrm{d}a)}\\\\ &{\\qquad\\qquad\\leq\\underset{a\\in\\mathcal{Z}}{\\operatorname*{sup}}\\,\\|\\mu_{p_{\\alpha}}-\\mu_{q_{\\alpha}}\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\underset{a\\in\\mathcal{Z}}{\\operatorname*{sup}}\\,\\mathrm{MMD}_{\\kappa}(\\mu_{p_{\\alpha}},\\mu_{q_{\\alpha}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the penultimate inequality is due to Jensen\u2019s inequality, and the final inequality holds since $\\begin{array}{r}{\\operatorname*{sup}_{a\\in\\mathcal{T}}\\|\\bar{\\mu_{p_{a}}}-\\mu_{q_{a}}\\|}\\end{array}$ upper bounds the integrand, and the integral is a monotone operator. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Next, we show how the ${\\mathrm{MMD}}_{\\kappa}$ under the kernels hypothesized in Theorem 2 behave under affine transformations to random variables. ", "page_idx": 16}, {"type": "text", "text": "Lemma 7. Let \u03ba be a kernel induced by a semimetric $\\rho$ of strong negative type defined over a compact subset $\\boldsymbol{\\mathcal{V}}\\subset\\mathbf{R}^{d}$ that is both shift invariant and $c$ -homogeneous (cf. Theorem 2). Then for any $a\\in\\mathcal{V}$ and $p,q\\in\\mathcal{P}(\\mathcal{Y})$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{MMD}_{\\kappa}((\\mathrm{b}_{a,\\gamma})_{\\sharp}p,(\\mathrm{b}_{a,\\gamma})_{\\sharp}q)\\leq\\gamma^{c/2}\\mathrm{MMD}_{\\kappa}(p,q).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. It is known $[\\mathrm{GBR}^{+}12]$ that the MMD can be expressed in terms of expected kernel evaluations, according to ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{dMD}_{\\kappa}^{2}(p,q)=\\mathbf{E}\\left[\\kappa(Y,Y^{\\prime})\\right]+\\mathbf{E}\\left[\\kappa(Z,Z^{\\prime})\\right]-2\\mathbf{E}\\left[\\kappa(Y,Z)\\right]\\qquad}&{{}(Y,Y^{\\prime},Z,Z^{\\prime})\\sim p\\otimes p\\otimes q\\otimes q}\\\\ {=\\mathbf{E}\\left[\\frac{1}{2}(\\rho(Y,y_{0})+\\rho(Y^{\\prime},y_{0})-\\rho(Y,Y^{\\prime}))\\right]}\\\\ {+\\mathbf{E}\\left[\\frac{1}{2}(\\rho(Z,y_{0})+\\rho(Z^{\\prime},y_{0})-\\rho(Z,Z^{\\prime}))\\right]}\\\\ {-\\mathbf{E}\\left[\\rho(Y,y_{0})+\\rho(Z,y_{0})-\\rho(Y,Z)\\right]}\\\\ {=\\mathbf{E}\\left[\\rho(Y,Z)\\right]-\\frac{1}{2}\\left(\\mathbf{E}\\left[\\rho(Y,Y^{\\prime})\\right]+\\mathbf{E}\\left[\\rho(Z,Z^{\\prime})\\right]\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last step invokes the definition of a kernel induced by a semimetric, and the linearity of expectation. Then, defining ${\\tilde{Y}},{\\tilde{Y}}^{\\prime}$ as independent samples from $(\\ensuremath{\\mathrm{b}}_{a,\\gamma})_{\\sharp}p$ and $\\tilde{Z},\\tilde{Z}^{\\prime}$ as independent samples from $(\\ensuremath{\\mathrm{b}}_{a,\\gamma})_{\\sharp}q$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{dMD}_{\\kappa}^{2}((\\ensuremath{\\mathbf{b}}_{a,\\gamma})_{\\sharp}p,(\\ensuremath{\\mathbf{b}}_{a,\\gamma})_{\\sharp}q)=\\ensuremath{\\mathbf{E}}\\left[\\rho(\\tilde{Y},\\tilde{Z})\\right]-\\frac{1}{2}\\left(\\ensuremath{\\mathbf{E}}\\left[\\rho(\\tilde{Y},\\tilde{Y}^{\\prime})\\right]+\\ensuremath{\\mathbf{E}}\\left[\\rho(\\tilde{Z},\\tilde{Z}^{\\prime})\\right]\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\ensuremath{\\mathbf{E}}\\left[\\rho(a+\\gamma Y,a+\\gamma Z)\\right]-\\frac{1}{2}\\left(\\ensuremath{\\mathbf{E}}\\left[\\rho(a+\\gamma Y,a+\\gamma Y^{\\prime})\\right]+\\ensuremath{\\mathbf{E}}\\left[\\rho(a+\\gamma Z,\\Biggr.}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\ensuremath{\\mathbf{E}}\\left[\\rho(\\gamma Y,\\gamma Z)\\right]-\\frac{1}{2}\\left(\\ensuremath{\\mathbf{E}}\\left[\\rho(\\gamma Y,\\gamma Y^{\\prime})\\right]+\\ensuremath{\\mathbf{E}}\\left[\\rho(\\gamma Z,\\gamma Z^{\\prime})\\right]\\right)\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\left.=\\gamma^{c}\\ensuremath{\\mathbf{E}}\\left[\\rho(Y,Z)\\right]-\\frac{\\gamma^{c}}{2}\\left(\\ensuremath{\\mathbf{E}}\\left[\\rho(Y,Y^{\\prime})\\right]+\\ensuremath{\\mathbf{E}}\\left[\\rho(Z,Z^{\\prime})\\right]\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\gamma^{c}\\ensuremath{\\mathrm{MMD}}_{\\kappa}^{2}(p,q),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the second step is a change of variables, the third step invokes the shift invariance of $\\rho$ , and the fourth step invokes the homogeneity of $\\rho$ . ", "page_idx": 16}, {"type": "text", "text": "Thus, it follows that $\\begin{array}{r}{\\mathrm{MMD}_{\\kappa}((\\mathrm{b}_{a,\\gamma})_{\\sharp}p,(\\mathrm{b}_{a,\\gamma})_{\\sharp}q)\\leq\\gamma^{c/2}\\mathrm{MMD}_{\\kappa}(p,q).}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "We are now ready to prove the main result of this section. ", "page_idx": 16}, {"type": "text", "text": "Theorem 2 (Convergent MMD dynamic programming for the multi-return distribution function). Let \u03ba be a kernel induced by a semimetric $\\rho$ on $[\\bar{0},(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d}$ with strong negative type, satisfying ", "page_idx": 17}, {"type": "text", "text": "1. Shift-invariance. For any $z\\in\\mathbf{R}^{d}$ $\\mathbf{\\xi}^{d},\\,\\rho(z+y_{1},z+y_{2})=\\rho(y_{1},y_{2}).$ . ", "page_idx": 17}, {"type": "text", "text": "2. Homogeneity. For any $\\gamma\\in[0,1)$ , there exists $c>0$ for which $\\rho(\\gamma y_{1},\\gamma y_{2})=\\gamma^{c}\\rho(y_{1},y_{2}).$ . ", "page_idx": 17}, {"type": "text", "text": "Consider the sequence $\\{\\eta_{k}\\}_{k=1}^{\\infty}$ given by $\\eta_{k+1}=\\mathcal{T}^{\\pi}\\eta_{k}$ . Then $\\eta_{k}\\rightarrow\\eta^{\\pi}$ at a geometric rate of $\\gamma^{c/2}$ in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , as long as $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\leq C<\\infty$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. We begin by showing that the distributional Bellman operator $\\mathcal{T}^{\\pi}$ is contractive in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ . We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{dMD}_{\\kappa}(\\mathcal{T}^{\\pi}\\eta_{1},7^{\\pi}\\eta_{2})=\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\mathrm{MMD}_{\\kappa}(\\mathcal{T}^{\\pi}\\eta_{1}(x),7^{\\pi}\\eta_{2}(x))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\mathrm{MMD}_{\\kappa}\\left(\\underset{x^{\\prime}\\sim P^{\\pi}(\\cdot|x)}{\\mathbf{E}}\\left[(\\mathsf{b}_{r(x),\\gamma})_{\\sharp}\\eta_{1}(x^{\\prime})\\right],\\underset{x^{\\prime\\prime}\\sim P^{\\pi}(\\cdot|x)}{\\mathbf{E}}\\left[(\\mathsf{b}_{r(x),\\gamma})_{\\sharp}\\eta_{2}(x^{\\prime\\prime})\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We apply Lemma 6 with $\\mathcal{T}=\\mathcal{X}$ and $T=P^{\\pi}(\\cdot\\mid x)$ , yielding ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{MMD}_{\\kappa}(\\mathcal{T}^{\\pi}\\eta_{1},\\mathcal{T}^{\\pi}\\eta_{2})\\leq\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{sup}_{x^{\\prime}\\in\\mathcal{X}}\\mathrm{MMD}_{\\kappa}\\left((\\mathfrak{b}_{r(x),\\gamma})_{\\sharp}\\eta_{1}(x^{\\prime}),(\\mathfrak{b}_{r(x),\\gamma})_{\\sharp}\\eta_{2}(x^{\\prime})\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Next, invoking Lemma 7 with the shift-invariance and $c$ -homogeneity of $\\kappa$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathcal{T}^{\\pi}\\eta_{1},\\mathcal{T}^{\\pi}\\eta_{2})\\leq\\gamma^{c/2}\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\ \\underset{x^{\\prime}\\in\\mathcal{X}}{\\operatorname*{sup}}\\ \\mathrm{MMD}_{\\kappa}\\left(\\eta_{1}(x^{\\prime}),\\eta_{2}(x^{\\prime})\\right)}\\\\ &{\\qquad\\qquad\\qquad=\\gamma^{c/2}\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\ \\mathrm{MMD}_{\\kappa}\\left(\\eta_{1}(x),\\eta_{2}(x)\\right)}\\\\ &{\\qquad\\qquad\\qquad=\\gamma^{c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "It follows that $\\begin{array}{r}{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k+1},\\eta^{\\pi})\\leq\\gamma^{c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathcal{T}^{\\pi}\\eta_{k},\\mathcal{T}^{\\pi}\\eta^{\\pi})=\\gamma^{c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathcal{T}^{\\pi}\\eta_{k},\\eta^{\\pi})}\\end{array}$ , since $\\eta^{\\pi}$ is a fixed point of $\\mathcal{T}^{\\pi}$ . Continuing, we see that $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k},\\eta^{\\pi})\\,\\le\\,\\gamma^{k c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\,\\le\\,\\$ $\\gamma^{k c/2}C\\;\\in\\;{\\cal O}(\\gamma^{k c/2})\\;\\subset\\;o(1)$ . Since $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ is a metric on $\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d})^{\\chi}$ for any characteristic kernel $\\kappa$ , it follows that $\\eta_{k}$ approaches $\\eta^{\\pi}$ at a geometric rate. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "B.2 EWP Dynamic Programming: Section 4 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we provide the proof of Theorem 3. To do so, we prove an abstract, general result, regarding any projection mapping that approximates the argmin MMD projection given in Equation (4). ", "page_idx": 17}, {"type": "text", "text": "Proposition 1 (Convergence of EWP Dynamic Programming). Consider a kernel satisfying the hypotheses of Theorem 2, suppose rewards are globally bounded in each dimension in $[0,R_{\\mathrm{max}}]$ , and let $\\{\\Pi_{\\kappa,m}^{(k)}\\}_{k\\ge0}$ be a sequence of maps $\\Pi:\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d})^{\\mathcal{X}}\\to\\mathcal{C}_{\\mathrm{EWP},m}$ satisfying ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{MMD}_{\\kappa}((\\Pi_{\\kappa,m}^{(k)}\\eta)(x),\\eta(x))\\leq f(d,m)<\\infty\\qquad\\forall k\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then the iterates $(\\eta_{k})_{k\\geq0}$ given by $\\eta_{k+1}=\\Pi_{\\kappa,m}^{(k)}\\mathcal{T}^{\\pi}\\eta_{k}$ with $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})=D<\\infty$ converge to a set $\\eta_{\\mathrm{EWP},\\kappa}^{m}\\,\\subset\\,\\overline{{B}}(\\eta^{\\pi},(1-\\gamma^{c/2})^{-1}f(d,m))$ in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , where $\\overline{B}$ denotes the closed ball in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\overline{{B}}(\\eta,R)\\triangleq\\left\\{\\eta^{\\prime}\\in\\mathcal{P}(\\mathbf{R}^{d})^{\\mathcal{X}}\\,:\\,\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta,\\eta^{\\prime})\\leq R\\right\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\Delta_{k}=\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k},\\eta^{\\pi})$ . Then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta_{k}=\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\kappa,m}^{(k)}\\mathcal{T}^{\\pi}\\eta_{k-1},\\mathcal{T}^{\\pi}\\eta^{\\pi})}\\\\ &{\\qquad\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\kappa,m}^{(k)}\\mathcal{T}^{\\pi}\\eta_{k-1},\\mathcal{T}^{\\pi}\\eta_{k-1})+\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathcal{T}^{\\pi}\\eta_{k-1},\\mathcal{T}^{\\pi}\\eta^{\\pi})}\\\\ &{\\qquad\\leq f(d,m)+\\gamma^{c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k-1},\\eta^{\\pi})}\\\\ &{\\therefore\\Delta_{k}\\leq f(d,m)+\\gamma^{c/2}\\Delta_{k-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first step invokes the identity that $\\eta^{\\pi}$ is the fixed point of $\\mathcal{T}^{\\pi}$ (which is well-defined by Theorem 2), the second step leverages the triangle inequality, and the third step follows by the definition of $f(d,m)$ and the contractivity of $\\mathcal{T}^{\\pi}$ established in Theorem 2. Unrolling the recurrence above, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k},\\eta^{\\pi})=\\Delta_{k}\\le\\gamma^{c k/2}\\Delta_{0}+f(d,m)\\displaystyle\\sum_{i=0}^{\\infty}\\gamma^{c i/2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le\\gamma^{c k/2}D+\\displaystyle\\frac{f(d,m)}{1-\\gamma^{c/2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "As such, as $k\\rightarrow\\infty$ , we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{k\\to\\infty}\\overline{{\\mathrm{MMD}_{\\kappa}}}\\left(\\eta_{k},\\overline{{B}}\\left(\\eta^{\\pi},\\frac{f(d,m)}{1-\\gamma^{c/2}}\\right)\\right)=0,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "proving our claim. ", "page_idx": 18}, {"type": "text", "text": "Proposition 1, despite its simplicity, reveals an interesting fact: given a good enough approximate MMD projection $\\Pi_{\\kappa,m}$ in the sense that $f(d,m)$ decays quickly with $m$ , the dynamic programming iterates $(\\eta_{k})_{k\\geq0}$ will eventually be contained in a (arbitrarily) small neighborhood of $\\eta^{\\pi}$ . The next result provides an example consequence of this abstract result, and establishes that $m\\in{\\mathsf{p o l y}}(d)$ is enough for convergence to an arbitrarily small set with projected distributional dynamic programming under the EWP representation. ", "page_idx": 18}, {"type": "text", "text": "Finally, we can now prove Theorem 3, which we restate below for convenience. ", "page_idx": 18}, {"type": "text", "text": "Theorem 3. Consider a kernel $\\kappa$ induced by the semimetric $\\rho(x,y)=\\|x-y\\|_{2}^{\\alpha}$ with $\\alpha\\in(0,2)$ , and suppose rewards are bounded in each dimension within $[0,R_{\\mathrm{max}}]$ . For any $\\eta_{0}$ such that $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\,\\leq\\,D\\,<\\,\\infty,$ , and any $\\delta\\,>\\,0$ , for the sequence $(\\eta_{k})_{k\\geq0}$ defined in Equation (5), with probability at least $1-\\delta$ we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{K},\\eta^{\\pi})\\in\\widetilde{O}\\left(\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}\\sqrt{m}}\\log\\left(\\frac{|\\mathcal{X}|\\delta^{-1}}{\\log\\gamma^{-\\alpha}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\eta_{k+1}=\\mathsf{B o o t P r o j}_{\\kappa,m}^{\\pi}\\eta_{k}$ and $\\begin{array}{r}{K=\\lceil\\frac{\\log{m}}{\\log{\\gamma^{-\\alpha}}}\\rceil}\\end{array}$ , and where $\\widetilde O$ omits logarithmic factors in $m$ ", "page_idx": 18}, {"type": "text", "text": "Proof. For each $x\\in\\mathscr{X}$ and $k\\in[K]$ , denote by $\\mathcal{E}_{x,k}$ the event given by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\dot{\\cdot}_{x,k}=\\left\\{\\mathrm{MMD}_{\\kappa}(\\mathsf{B o o t P r o j}_{\\kappa,m}^{\\pi}\\eta_{k}(x),7^{\\pi}\\eta_{k}(x))\\leq\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}+\\frac{4d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}\\log\\delta^{\\prime-1}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}=:f(d,m;\\,k)\\in\\mathsf{R e}^{\\alpha}\\right\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for $\\delta^{\\prime}\\,>\\,0$ a constant to be chosen shortly. Moreover, with $\\mathcal{E}\\,=\\,\\cap_{({x},{k})\\in{\\mathcal{X}}\\times[{K}]}{\\mathcal{E}}_{{x},{k}}$ , it holds that under $\\mathcal{E}$ , $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathsf{B o o t P r o j}_{\\kappa,m}^{\\pi}\\eta_{k},\\mathcal{T}^{\\pi}\\eta_{k})\\,\\le\\,f(d,m;\\delta^{\\prime})$ for all $k\\,\\in\\,[K]$ . Following the proof of Proposition 1, we have that, conditioned on $\\mathcal{E}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k},\\eta^{\\pi})\\leq\\gamma^{\\alpha k/2}D+\\frac{f(d,\\,m;\\,\\delta^{\\prime})}{1-\\gamma^{\\alpha/2}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}+\\frac{f(d,\\,m;\\,\\delta^{\\prime})}{1-\\gamma^{\\alpha/2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now, by [TSM17, Proposition A.1], event $\\mathcal{E}_{x,k}$ holds with probability at least $1-\\delta^{\\prime}$ , since each $(\\mathsf{B o o t P i n j}_{\\kappa,m}^{\\pi}\\eta_{k})(x)$ is generated independently by sampling $m$ independent draws from the distribution $\\tau^{\\pi}\\eta_{k}$ . Therefore, event $\\mathcal{E}$ holds with probability at least $1-|\\mathcal{X}|K\\delta^{\\prime}$ . Choosing $\\delta^{\\prime}=\\delta/(|\\boldsymbol{\\mathcal{X}}|K)$ , we have that, with probability at least $1-\\delta$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{dMD}_{\\kappa}}}(\\eta_{K},\\eta^{\\pi})\\leq\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}+\\frac{1}{1-\\gamma^{\\alpha/2}}\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}\\left(1+2\\log(|\\mathcal{X}|K\\delta^{-1})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}\\sqrt{m}}+\\frac{2d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}\\sqrt{m}}\\left(1+2\\log\\left(|\\mathcal{X}|\\left(1+\\frac{\\log m}{\\log\\gamma^{-\\alpha}}\\right)\\delta^{-1}\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "As such, there exist universal constants $C_{0},C_{1}\\in\\mathbf{R}_{+}$ such that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{K},\\eta^{\\pi})\\leq C_{1}\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{\\left(1-\\gamma^{\\alpha/2}\\right)\\left(1-\\gamma\\right)^{\\alpha}\\sqrt{m}}\\left(1+2\\log\\left(|\\mathcal{X}|\\left(1+\\frac{\\log m}{\\log\\gamma^{-\\alpha}}\\right)\\delta^{-1}\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{0}\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{\\left(1-\\gamma^{\\alpha/2}\\right)\\left(1-\\gamma\\right)^{\\alpha}\\sqrt{m}}\\left(\\log|\\mathcal{X}|+\\log\\frac{\\log m}{\\log\\gamma^{-\\alpha}}+\\log\\delta^{-1}\\right)}\\\\ &{\\qquad\\qquad=C_{0}\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{\\left(1-\\gamma^{\\alpha/2}\\right)\\left(1-\\gamma\\right)^{\\alpha}\\sqrt{m}}\\left(\\log\\left(\\frac{|\\mathcal{X}|\\delta^{-1}}{\\log\\gamma^{-\\alpha}}\\right)+\\log m\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Corollary 1. For any kernel $\\kappa$ satisfying the hypotheses of Theorem 3, and for any $\\eta_{0}\\in\\mathcal{C}_{\\mathrm{EWP},m}$ for which $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\leq D<\\infty,$ , the iterates $\\eta_{k+1}=\\Pi_{\\mathrm{EWP},\\kappa}^{m}T^{\\pi}\\eta_{k}$ converge to a set $\\pmb{\\eta}_{\\mathrm{EWP},\\kappa}^{m}\\subset$ $\\mathcal{C}_{\\mathrm{EWP},m}$ , where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{EWP},\\kappa}^{m}\\subset\\overline{{B}}\\left(\\eta^{\\pi},\\frac{6d^{\\alpha/2}R_{\\mathrm{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Proposition 1 shows that projected EWP dynamic programming converges to a set with radius controlled by the quantity $f(d,m)$ that upper bounds the distance $\\bar{f}(d,m)$ between $\\eta_{k}(x)$ and $\\Pi_{\\kappa,m}^{(k)}\\eta_{k}(x)$ at the worst state $x$ . In the proof of Theorem 3, we saw that with nonzero probability, the randomized projections satisfy f(d, m) \u2264 (61d\u2212\u03b1/\u03b32)\u03b1R\u03b1m\u221aamx. Thus, there exists a projection satisfying this bound. Since the projection $\\Pi_{\\mathrm{EWP},\\kappa}^{m}$ is, by definition, the projection with the smallest possible $f(d,m)$ , the claim follows directly by Proposition 1. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "B.3 Categorical Dynamic Programming: Section 5 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Lemma 1. Let \u03ba be a kernel induced by a semimetric $\\rho$ on $[0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{d}$ with strong negative type (cf. Theorem 1). Then $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is well-defined, $\\mathsf{R a n}\\big(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\big)\\subset\\mathcal{C}_{\\mathcal{R}}$ , and $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\vert\\boldsymbol{\\mathcal{C}}_{\\mathcal{R}}=\\mathsf{i d}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. Firstly, note that $\\Delta_{\\mathcal{R}(x)}$ is a bounded, finite-dimensional subspace for each $x\\in\\mathscr{X}$ . Thus, $\\Delta_{\\mathcal{R}(x)}$ is compact, and by the continuity of the MMD, the infimum in (7) is attained. ", "page_idx": 19}, {"type": "text", "text": "Following the technique of $[\\mathrm{SZS^{+}08}]$ , we establish that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ can be computed as the solution to a particular quadratic program with convex constraints. ", "page_idx": 19}, {"type": "text", "text": "Let $K\\in\\mathbf{R}^{N(x)\\times N(x)}$ denote a matrix where $K_{i,j}=\\kappa(\\xi(x)_{i},\\xi(x)_{j})$ . Since $\\kappa$ is a positive definite kernel when $\\kappa$ is characteristic $[\\mathrm{GBR}^{+}12]$ , it follows that $K$ is a positive definite matrix. Then, for any $\\varrho\\in\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\mathrm{max}}]^{\\bar{d}})$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left.\\begin{array}{l}{\\displaystyle\\mathbf{arginf}\\ \\ \\mathrm{MMD}_{\\kappa}(p,\\varrho)}\\\\ {\\displaystyle p\\in\\Delta_{\\pi(\\alpha)}}\\\\ {\\displaystyle=\\ \\underset{p\\in\\Delta_{\\mathcal{R}(\\alpha)}}{\\mathrm{arginf}}\\ \\mathrm{MMD}_{\\kappa}^{2}(p,\\varrho)}\\\\ {\\displaystyle=\\ \\underset{p\\in\\Delta_{\\mathcal{R}(\\alpha)}}{\\mathrm{arginf}}\\left\\{\\sum_{i=1}^{N(x)}\\sum_{j=1}^{N(x)}p_{i}p_{j}\\kappa(\\xi(x)_{i},\\xi(x)_{j})-2\\sum_{i=1}^{N(x)}p_{i}\\overbrace{\\int\\kappa(\\xi(x)_{i},y)\\varrho(\\mathrm{d}y)}^{b\\in\\mathbb{R}^{N(x)}}+M(\\kappa,\\mathcal{R},\\varrho)\\right\\}}\\\\ {\\displaystyle=\\ \\underset{p\\in\\Delta_{\\mathcal{R}(\\alpha)}}{\\mathrm{arginf}}\\ \\left\\{p^{\\top}K p-2p^{\\top}b\\right\\},}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $M(\\kappa,\\mathcal{R},\\varrho)$ is independent of $p$ , so it does not influence the minimization. Now, since $K$ is positive definite (by virtue of $\\kappa$ being characteristic) and $\\Delta_{\\mathcal{R}(x)}$ is a closed convex subset of ${\\mathbf{R}}^{N(x)}$ , it is well-known that there is unique optimum, and the infimum above is attained for some $p^{\\star}\\in\\Delta_{\\mathcal{R}(x)}$ . Therefore, $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is indeed well-defined, and its range is contained in $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ , confirming the first two claims. Finally, since $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is well-defined and since ${\\mathrm{MMD}}_{\\kappa}$ is nonnegative and separates points, $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ must map elements of $\\Delta_{\\mathcal{R}(x)}$ to themselves \u2013 this is because ${\\mathrm{MMD}}_{\\kappa}(p,p)=0$ for the kernels we consider. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Lemma 2. Under the conditions of Lemma 1, $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ . That is, for any $\\eta_{1},\\eta_{2}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\operatorname*{max}}]^{d})^{\\chi}$ , we have $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{2})\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2})$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. Fix any $x\\in\\mathscr{X}$ and denote $M(x)=\\{\\mu_{p}\\in{\\mathcal{H}}:p\\in\\Delta_{\\mathcal{R}(x)}\\}$ , where $\\mathcal{H}$ is the RKHS induced by the kernel $\\kappa$ and $\\mu_{p}$ denotes the mean embedding of $p$ in this RKHS. It is simple to verify that $p\\mapsto\\mu_{p}$ is linear: for any $p,q\\in\\mathcal{P}(\\mathbf{R}^{d})$ and $\\alpha,\\beta\\in\\mathbf{R}$ , for all $f\\in\\mathcal H$ with $\\|f\\|=1$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle f,\\mu_{\\alpha p+\\beta q}\\rangle=\\displaystyle\\int f(y)[\\alpha p+\\beta q](\\mathrm{d}y)=\\alpha\\displaystyle\\int f(y)p(\\mathrm{d}y)+\\beta\\displaystyle\\int f(y)q(\\mathrm{d}y)}\\\\ {=\\langle a,\\alpha\\mu_{p}+\\beta\\mu_{q}\\rangle,\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which implies that $\\mu_{\\alpha p+\\beta q}=\\alpha\\mu_{p}+\\beta\\mu_{q}$ . As a consequence, $M(x)$ inherits convexity from $\\Delta_{\\mathcal{R}(x)}$ . ", "page_idx": 20}, {"type": "text", "text": "We claim that $M(x)$ is closed as a subset of $\\mathcal{H}$ . Since $p\\mapsto\\mu_{p}$ is an injection $[\\mathrm{GBR}^{+}12]$ , by Lemma 1, since there is a unique $q\\in\\Delta_{\\mathcal{R}(x)}$ minimizing $\\mathrm{MMD}_{\\kappa}(p,q)$ , there is a unique $\\mu_{q}\\in M(x)$ attaining the infimum $\\lVert\\boldsymbol{\\mu_{p}}-\\boldsymbol{\\mu_{q}}\\rVert$ over $M(x)$ . Let $\\mu\\in\\mathcal{H}\\setminus M(x)$ . Then there exists $\\mu_{q}\\,\\in\\,M(x)$ such that $\\|\\mu_{q}-\\mu\\|=\\operatorname*{inf}_{\\nu\\in M(x)}\\|\\mu-\\nu\\|$ , and since $\\mu_{q}\\ne\\mu$ , it follows that $\\operatorname*{inf}_{\\nu\\in M(x)}\\|\\nu-\\mu\\|=\\epsilon>0$ . Since this is true for any $\\mu\\not\\in M(x)$ , it follows that $\\mathcal{H}\\backslash M(x)$ is open, so $M(x)$ is closed. ", "page_idx": 20}, {"type": "text", "text": "We will now show that $\\eta(x)\\mapsto\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta(x)$ is a nonexpansion in $\\mathcal{H}$ . Let $\\eta_{1},\\eta_{2}\\in\\mathcal{C}_{\\mathcal{R}}$ , and denote by $\\mu_{1}(x),\\mu_{2}(x)$ the mean embeddings of $\\eta_{1}(x),\\eta_{2}(x)$ . We slightly abuse notation and write $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{i}(x)$ to denote the mean embedding of $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{i}(x)$ . Since $M(x)$ is convex, for any $\\iota(x)\\,\\in\\,M(x)$ and $\\lambda\\in[0,1]$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MMD}_{\\kappa}(\\eta_{1}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1}(x))^{2}=\\|\\mu_{1}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\|\\mu_{1}(x)-(\\lambda\\iota(x)+(1-\\lambda)\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x))\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\|\\mu_{1}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)-\\lambda(\\iota(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x))\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now, by expanding the squared norms and taking $\\lambda\\downarrow0$ , since $M(x)$ is closed we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\langle\\mu_{1}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x),\\iota_{1}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\rangle\\leq0\\qquad\\forall\\iota_{1}(x),\\iota_{2}(x)\\in M(x)}\\\\ &{\\therefore\\left\\langle\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\mu_{2}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\iota_{2}(x)\\right\\rangle\\leq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second inequality follows by applying the same logic to $\\mu_{2}(x)$ . Choosing $\\iota_{1}(x)\\ =$ $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x),\\iota_{2}(x)=\\Pi_{\\mathrm{C},\\kappa}^{\\dot{\\mathcal{R}}}\\mu_{1}^{\\dot{\\mathsf{\\Pi}}}(x)\\in M(\\dot{x})$ and adding these inequalities yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle\\mu_{1}(x)-\\mu_{2}(x)+(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\rangle\\leq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Expanding, we see that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{2}(x))^{2}=\\|\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\langle\\mu_{2}(x)-\\mu_{1}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\rangle}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\|\\mu_{2}(x)-\\mu_{1}(x)\\|\\|\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{2}(x)-\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mu_{1}(x)\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathrm{MMD}_{\\kappa}(\\eta_{1}(x),\\eta_{2}(x))\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{2}(x))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\mathrm{MMD}_{\\kappa}(\\eta_{1}(x),\\eta_{2}(x)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "confirming that $\\eta(x)\\mapsto\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta(x)$ is a non-expansion. It follows that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{1},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{2})=\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\mathrm{MMD}_{\\kappa}(\\eta_{1}(x),\\eta_{2}(x))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\underset{x\\in\\mathcal{X}}{\\operatorname*{sup}}\\mathrm{MMD}_{\\kappa}(\\eta_{1}(x),\\eta_{2}(x))}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Corollary 2. Let \u03ba be a kernel satisfying the conditions of Theorem 2. Then for any $\\eta_{0}\\in\\mathcal{C}_{\\mathcal{R}}$ , the iterates $\\{\\bar{\\eta}_{k}\\}_{k=1}^{\\infty}$ given by $\\eta_{k+1}=\\Pi_{\\mathrm{C},\\kappa}^{\\check{\\pi}}\\check{T}^{\\pi}\\eta_{k}$ converge geometrically to a unique fixed point. ", "page_idx": 21}, {"type": "text", "text": "Proof. Combining Theorem 2 and Lemma 2, we see that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{1},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{2})\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\mathcal{T}^{\\pi}\\eta_{1},\\eta_{2})\\leq\\gamma^{c/2}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2})\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for some $c\\,>\\,0$ . Thus, $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ is a contraction on $(\\mathcal{C}_{\\mathcal{R}},\\overline{{\\mathrm{MMD}_{\\kappa}}})$ . If $\\mathcal{H}$ is the RKHS induced by $\\kappa$ , we showed in Lemma 2 that $\\mathcal{C}_{\\mathcal{R}}$ is isometric to a product of closed, convex subsets of $\\mathcal{H}$ . Therefore, by the completeness of $\\mathcal{H}$ , $\\mathcal{C}_{\\mathcal{R}}$ is isometric to a complete subspace, and consequently $\\mathcal{C}_{\\mathcal{R}}$ is a complete subspace under the metric $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ . Invoking the Banach fixed-point theorem, it follows that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}^{\\mathrm{2}}}\\mathcal{T}^{\\pi}$ has a unique fixed point $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ , and $\\eta_{k}\\rightarrow\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ geometrically. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "B.3.1 Quality of the Categorical Fixed Point ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "As we saw in our analysis of multivariate DRL with EWP representations, the distance between a distribution and its projection (as a function of $m,d)$ plays a major role in controlling the approximation error in projected distributional dynamic programming. Before proving the main results of this section, we begin by analyzing this quantity by reducing it to the largest distance between points among certain partitions of the space of returns. ", "page_idx": 21}, {"type": "text", "text": "Lemma 3. Let \u03ba be kernel satisfying the conditions of Lemma 1, and for any finite $\\mathcal{R}\\subset\\mathbf{R}^{d}$ , define \u03a0 : $\\mathcal{P}(\\mathbf{R}^{d})\\rightarrow\\Delta_{\\mathcal{R}}$ via $\\Pi p=\\mathrm{arginf}_{q\\in\\Delta\\pi}$ $\\mathrm{MMD}_{\\kappa}(p,q)$ . Then $\\mathrm{MMD}_{\\kappa}^{2}(\\Pi p,p)\\leq\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}}}$ mesh $(P;\\kappa)$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Our proof proceeds by establishing approximation bounds of Riemann sums to the Bochner integral $\\mu_{p}$ , similar to [VN02]. Let $P\\in\\mathcal P_{\\mathcal R}$ . Abusing notation to denote by $\\Pi p_{i}$ the probability of the $i$ th atom of the discrete support under $\\Pi p$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathrm{MMD}_{\\kappa}^{2}(p,\\Pi p)=\\|\\mu_{\\Pi p}-\\mu_{p}\\|^{2}}\\\\ {\\quad\\quad\\quad\\quad\\quad=\\left\\|\\int\\kappa(\\cdot,y)\\Pi p(\\mathrm{d}y)-\\int\\kappa(\\cdot,y)p(\\mathrm{d}y)\\right\\|^{2}}\\\\ {\\quad\\quad\\quad\\quad\\quad\\quad=\\left\\|\\displaystyle\\sum_{i}\\kappa(\\cdot,z_{i})\\Pi p_{i}-\\int\\kappa(\\cdot,y)p(\\mathrm{d}y)\\right\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mathcal{R}=\\{z_{i}\\}_{i=1}^{n}$ for some $n\\in\\mathbf N$ . Since $\\Pi p$ optimizes the MMD over all probability vectors in $\\Delta_{\\mathcal{R}}$ , for $q\\in\\Delta_{\\mathcal{R}}$ with $q_{i}=p(\\theta_{i})$ for the $i$ th element of $P$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MMD}_{\\kappa}^{2}(p,\\Pi p)\\leq\\left\\|\\displaystyle\\sum_{i}\\kappa(\\cdot,z_{i})p(\\theta_{i})-\\int\\kappa(\\cdot,y)p(\\mathrm{d}y)\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\left\\|\\displaystyle\\sum_{i}\\displaystyle\\sum_{j}\\int_{\\theta_{i}}(\\kappa(\\cdot,z_{i})-\\kappa(\\cdot,y))p(\\mathrm{d}y)\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\leq\\left\\|\\displaystyle\\sum_{i}\\displaystyle\\sum_{y_{1},y_{2}\\in\\theta_{i}}\\|\\kappa(\\cdot,y_{1})-\\kappa(\\cdot,y_{2})\\|p(\\theta_{i})\\right\\|^{2}}\\\\ &{\\qquad\\leq\\operatorname*{sup}_{\\theta\\in P_{1},y_{1},z\\in\\theta}\\|\\kappa(\\cdot,y_{1})-\\kappa(\\cdot,y_{2})\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "It was shown by [SSGF13] that $z\\mapsto\\kappa(\\cdot,z)$ is an isometry from $(\\mathbf{R}^{d},\\rho^{1/2})$ to $\\mathcal{H}$ , where $\\mathcal{H}$ is the RKHS induced by $\\kappa$ . Thus, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname{MMD}_{\\kappa}^{2}(p,\\Pi p)\\leq\\operatorname*{sup}_{\\theta\\in P}\\operatorname*{sup}_{y_{1},y_{2}\\in\\theta}\\rho(y_{1},y_{2})=\\mathsf{m e s h}(P;\\kappa).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since this is true for any partition $P\\in\\mathcal P_{\\mathcal R}$ , the claim follows by taking the infimum over $\\mathcal{P}_{\\mathcal{R}}$ . ", "page_idx": 21}, {"type": "text", "text": "We now move on to the main results. ", "page_idx": 21}, {"type": "text", "text": "Theorem 4. Let \u03ba be a kernel induced by a c-homogeneous and shift-invariant semimetric $\\rho$ conforming to the conditions of Theorem 2. Then the fixed point $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ of $\\dot{\\Pi}_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ satisfies ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. The proof begins in a similar manner to $[\\mathrm{RBD^{+}18}$ , Proposition 3]. Given that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion as shown in Lemma 2, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{MMD}_{\\kappa}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})=\\underset{x\\in\\mathcal{X}}{\\mathrm{supMMD}}_{\\kappa}(\\eta_{\\mathrm{C},\\kappa}^{\\pi}(x),\\eta^{\\pi}(x))}\\\\ {\\le\\underset{x\\in\\mathcal{X}}{\\mathrm{sup}}\\left[\\mathrm{MMD}_{\\kappa}(\\eta_{\\mathrm{C},\\kappa}^{\\pi}(x),\\Pi_{\\mathrm{C},\\kappa}^{\\pi}\\eta^{\\pi}(x))+\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi}(x),\\eta^{\\pi}(x))\\right]}\\\\ {\\le\\frac{\\kappa}{M\\mathrm{MD}_{\\kappa}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi})+\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})}\\\\ {\\overset{(a)}{\\le}\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}T^{\\pi}\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}T^{\\pi}\\eta^{\\pi})+\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})}\\\\ {\\overset{(b)}{\\le}\\mathrm{MMD}_{\\kappa}(T^{\\pi}\\eta_{\\mathrm{C},\\kappa}^{\\pi},T^{\\pi}\\eta^{\\pi})+\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})}\\\\ {\\overset{(c)}{\\le}\\gamma^{\\mathit{o f}/\\mathrm{MMD}_{\\kappa}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})+\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})}\\\\ {:\\mathrm{MMD}_{\\kappa}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\le\\frac{1}{1-\\gamma^{\\mathit{o f}/\\mathrm{MMD}_{\\kappa}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})},}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $(a)$ leverages the fact that $\\eta_{\\mathrm{C},\\kappa}^{\\pi}$ is the fixed point of $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ and that $\\eta^{\\pi}$ is the fixed point of $\\tau^{\\pi},(b)$ follows since $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion by Lemma 2, and $(c)$ follows by the contractivity of $\\mathcal{T}^{\\pi}$ established in Theorem 2. Finally, by Lemma 3, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{dMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi}(x),\\eta^{\\pi}(x))\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\kappa(x)}}\\sqrt{\\mathsf{m e s h}(P_{\\kappa}\\eta^{\\pi}(x),\\eta^{\\pi}(x))}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Finally, we explicitly derive a convergence rate for a particular support map under the energy distance kernels. ", "page_idx": 22}, {"type": "text", "text": "Corollary 3. Let $\\mathcal{R}(x)=U_{m}$ , where $U_{m}$ is a set of m uniformly-spaced support points on $[0,(1-$ $\\gamma)^{-1}R_{\\mathrm{max}}\\bar{]}$ . For $\\kappa$ induced by the semimetric $\\rho(x,y)=\\|x-y\\|_{2}^{\\alpha}$ for $\\alpha\\in(0,2)$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(m^{1/d}-2)^{\\alpha/2}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. We begin bounding mesh $(P;\\kappa)$ . Assume $m=n^{d}$ for some $n\\in\\mathbf N$ . We consider a partition $\\overline{{P}}\\subset\\mathcal{P}_{U_{m}}$ consisting of $d$ -dimensional hypercubes with side length $(1-\\gamma)^{-1}R_{\\mathrm{max}}/(n-1)$ . By definition of $U_{m}$ , it is clear that these hypercubes cover $[0,(1-\\gamma)^{-1}R_{\\mathrm{{max}}}]^{d}$ and each contain exactly one support point. Now, for each $\\theta\\in{\\overline{{P}}}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{y_{1},y_{2}\\in\\theta}\\rho(y_{1},y_{2})\\leq\\|y-(y+(1-\\gamma)^{-1}R_{\\operatorname*{max}}/(n-1)\\vec{1}\\|_{2}^{\\alpha}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\vec{1}$ is the vector of all ones, and $y$ is any element in $\\theta$ . Expanding, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{y_{1},y_{2}\\in\\theta}{\\operatorname*{sup}}\\rho(y_{1},y_{2})\\leq(1-\\gamma)^{-\\alpha}\\left(\\displaystyle\\sum_{i=1}^{d}\\left(\\frac{R_{\\operatorname*{max}}}{n-1}\\right)^{2}\\right)^{\\alpha/2}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}(n-1)^{\\alpha}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since this bound holds for any $\\theta\\in{\\overline{{P}}}$ , invoking Theorem 4 yields ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{MMD}_{\\kappa}(\\eta_{\\mathrm{c},\\kappa}^{\\tau},\\eta^{\\tau})\\leq\\frac{1}{1-\\gamma^{\\alpha/2}}\\operatorname*{sup}_{\\kappa\\in\\mathcal{N}_{\\kappa/\\kappa_{n}}}\\sqrt{\\mathrm{mexh}(P_{\\mathrm{c},\\kappa}^{\\tau})}}&{}\\\\ {\\leq\\frac{1}{1-\\gamma^{\\alpha/2}}\\operatorname*{sup}_{\\kappa\\in\\mathcal{N}}\\sqrt{\\mathrm{mexh}(\\Tilde{P}_{\\mathrm{c}})}\\kappa}\\\\ &{\\leq\\frac{1}{1-\\gamma^{\\alpha/2}}\\operatorname*{sup}_{\\kappa\\in\\mathcal{N}}\\sqrt{\\frac{d^{\\alpha/2}R_{\\mathrm{max}}^{\\alpha}}{(1-\\gamma)^{\\alpha}(n-2)^{\\alpha}}}}\\\\ &{=\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(n-1)^{\\alpha/2}}}\\\\ &{=\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(n-1)^{\\alpha/2}}}\\\\ &{=\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(n-1)^{\\alpha/2}}}\\\\ &{=\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\mathrm{max}}^{\\alpha/2}}{(n^{1/4}-1)^{\\alpha/2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If instead $m\\in((n-1)^{d},n^{d})$ , we omit all but $(n-1)^{d}$ of the support points, and achieve ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\operatorname*{max}}^{\\alpha/2}}{(\\lfloor m^{1/d}\\rfloor-1)^{\\alpha/2}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Alternatively, we may write ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{C},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha/2}}\\frac{d^{\\alpha/4}R_{\\operatorname*{max}}^{\\alpha/2}}{(m^{1/d}-2)^{\\alpha/2}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "B.4 Categorical TD Learning: Section 6 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we prove results leading up to and including the convergence of the categorical TDlearning algorithm over mass-1 signed measures. First, in Section B.4.1, we show that ${\\mathrm{MMD}}_{\\kappa}$ is in fact a metric on the space of mass-1 signed measures, and establish that the multivariate distributional Bellman operator is contractive under these distribution representations. Subsequently, in Section B.4.2, we analyze the temporal difference learning algorithm leveraging the results from Section B.4.1. ", "page_idx": 23}, {"type": "text", "text": "B.4.1 The Signed Measure Relaxation ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We begin by establishing that $\\mathrm{MMD}_{\\kappa}$ is a metric on $\\mathcal{M}^{1}(\\mathcal{Y})$ for spaces $\\boldsymbol{\\wp}$ under which ${\\mathrm{MMD}}_{\\kappa}$ is a metric on $\\mathscr{P}(\\mathscr{y})$ . ", "page_idx": 23}, {"type": "text", "text": "Lemma 4. Let $\\kappa:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbf{R}$ be a characteristic kernel over some space $\\boldsymbol{\\wp}$ . Then ${\\mathrm{MMD}}_{\\kappa}$ : $\\mathcal{M}^{1}(\\mathcal{V})\\times\\mathcal{M}^{1}(\\mathcal{V})\\rightarrow\\mathbf{R}_{+}$ given by $(p,q)\\mapsto\\|\\mu_{p}-\\mu_{q}\\|\\varkappa$ defines a metric on $\\mathcal{M}^{1}(\\mathcal{Y})$ , where $\\mu_{p}$ denotes the usual mean embedding of $p$ and $\\mathcal{H}$ is the RKHS with kernel $\\kappa$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. Naturally, since ${\\mathrm{MMD}}_{\\kappa}$ is given by a norm, it is non-negative, symmetric, and satisfies the triangle inequality. We must show that $\\mathrm{MMD}_{\\kappa}(p,q)\\,=\\,0\\,\\,\\,\\Longleftrightarrow\\,\\,\\,p\\,=\\,q$ . Firstly, it is clear that $\\mathrm{MMD}_{\\kappa}(p,p\\bar{)}=0$ by the positive homogeneity of the norm. It remains to show that ${\\mathrm{MMD}}_{\\kappa}(p,q)=$ $0\\implies p=q$ . ", "page_idx": 23}, {"type": "text", "text": "Let $p\\neq q\\in\\mathcal{M}^{1}(\\mathcal{Y})$ . For the sake of contradiction, assume that ${\\mathrm{MMD}}_{\\kappa}(p,q)=0$ . We will show that this implies that $\\mathrm{MMD}_{\\kappa}(P,Q)\\,=\\,0$ for a pair of distinct probability measures, which is a contradiction since ${\\mathrm{MMD}}_{\\kappa}$ with characteristic $\\kappa$ is known to be a metric on $\\mathcal{P}(\\mathcal{Y})$ . ", "page_idx": 23}, {"type": "text", "text": "By the Hahn decomposition theorem, we may write $p=\\tilde{p}^{+}-\\tilde{p}^{-}$ for non-negative measures $\\tilde{p}^{+},\\tilde{p}^{-}$ . Therefore, for some $a\\in\\mathbf{R}_{+}$ , we may express ", "page_idx": 23}, {"type": "equation", "text": "$$\np=(a+1)p^{+}-a p^{-}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $p^{+},p^{-}\\,\\in\\,\\mathcal{P}(\\mathcal{P})$ . Likewise, there exist $b\\in\\mathbf{R}_{+}$ and probability measure ${q}^{+},{q}^{-}$ for which $q=(b+1)q^{+}-b q^{-}$ . Since ${\\mathrm{MMD}}_{\\kappa}(p,q)=0$ by hypothesis, and by linearity of $p\\mapsto\\mu_{p}$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\allowdisplaybreaks\\mathbf{\\sigma}^{\\prime}=\\frac{\\vert\\vert\\mu\\nu_{p}}{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert}\\frac{\\mu_{q}\\vert\\vert\\mathcal{H}}{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert}}&{=\\frac{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}(b+1)\\mu_{q}-\\mathbf{\\sigma}(b+1)\\vert\\mu_{q}+\\vert\\vert\\mathcal{H}}{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert\\vert(a+1)\\vert\\mu_{q}+\\vert\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mu_{q}+\\vert\\vert\\mathbf{\\sigma}^{\\prime}\\vert\\vert}}\\\\ {\\mathbf{\\sigma}=\\vert\\vert(a+1)\\mu_{p^{+}}+b\\mu_{q^{-}}-(a\\mu_{p^{-}}+(b+1)\\mu_{q^{+}})\\vert\\vert\\mu_{q}}&{=\\frac{a+1}{a+b+1}\\frac{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}(b+1)\\vert\\mu_{q^{+}}}{a+b+\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert}\\frac{\\mu_{q}-\\mathbf{\\sigma}(b+1)\\mu_{q^{+}}}{a+b-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert}\\Bigg\\vert,\\;\\lambda=\\frac{a+1}{a+b+1},\\;\\lambda^{\\prime}=\\frac{a-1}{a+b-1}\\frac{\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}(b+1)\\vert\\mu_{q}}{a+b-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mu_{q}+\\mathbf{\\sigma}^{\\prime}\\vert\\vert}\\frac{\\mu_{q}-\\mathbf{\\sigma}(b+1)\\mu_{q^{+}}}{a-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mathbf{\\sigma}^{\\prime}-\\mathbf{\\sigma}^{\\prime}\\vert\\vert\\mu_{q}+\\vert\\mathbf{\\sigma}^{\\prime}\\vert\\vert}}\\\\ {\\mathbf{\\sigma}^{\\prime}=(a+b+1)\\vert\\vert\\mu_{P}-\\mu_{Q}\\vert\\vert\\mu_{q},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $P=\\lambda p^{+}+(1-\\lambda)q^{-}$ and $Q=\\lambda^{\\prime}p^{-}+(1-\\lambda^{\\prime})q^{+}$ are convex combinations of probability measures, and are therefore probability measures themselves. So, we have that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\lambda p^{+}-\\lambda^{\\prime}p^{-}=(1-\\lambda^{\\prime})q^{+}-(1-\\lambda)q^{-}}}\\\\ {{(a+1)\\lambda p^{+}-a p^{-}=(b+1)q^{+}-b q^{-}}}\\\\ {{\\therefore p=q,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "which contradicts our hypothesis. Therefore, $\\mathrm{MMD}_{\\kappa}(p,q)=0\\iff p=q$ for any $p,q\\in\\mathcal{M}^{1}(\\mathcal{V})$ , and it follows that $\\mathrm{MMD}_{\\kappa}$ is a metric. ", "page_idx": 24}, {"type": "text", "text": "Next, we show that the distributional Bellman operator is contractive on the space of mass-1 signed measure return distribution representations. ", "page_idx": 24}, {"type": "text", "text": "Lemma 5. Under the conditions of Corollary 2, the projected operator $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}:\\mathcal{S}_{\\mathcal{R}}\\rightarrow\\mathcal{S}_{\\mathcal{R}}$ is affine, is contractive with contraction factor $\\gamma^{c/2}$ , and has a unique fixed point $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. Indeed, $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ is, in a sense, a simpler operator than $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ . Since $\\mathcal{M}^{1}(\\mathcal{R}(\\boldsymbol{x}))$ is an affine subspace of $\\mathcal{M}^{1}(\\mathbf{R}^{d})$ , it holds that $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ is simply a Hilbertian projection, which is known to be affine and a nonexpansion [Lax02]. Moreover, since $\\mathcal{T}^{\\pi}$ acts identically on $\\mathcal{M}^{1}(\\mathbf{R}^{d})$ as it does on $\\mathcal{P}(\\mathbf{R}^{d})$ , it immediately follows that $\\mathcal{T}^{\\pi}$ is a $\\gamma^{c/2}$ -contraction on $\\mathcal{M}^{1}(\\mathbf{R}^{d})$ , inheriting the result from Theorem 2. Thus, we have that for any $\\eta_{1},\\eta_{2}\\in\\mathcal{S}_{\\mathcal{R}}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MMD}_{\\kappa}(\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{1},\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{2})\\leq\\mathrm{MMD}_{\\kappa}(\\mathcal{T}^{\\pi}\\eta_{1},\\mathcal{T}^{\\pi}\\eta_{2})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\gamma^{c/2}\\mathrm{MMD}_{\\kappa}(\\eta_{1},\\eta_{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "confirming that the projected operator is a contraction. Since ${\\mathrm{MMD}}_{\\kappa}$ is a metric on $\\mathcal{M}^{1}(\\mathcal{R}(x))$ for each $x\\in\\mathscr{X}$ , it follows that $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ is a metric on $\\mathcal{S}_{\\mathcal{R}}$ . The existence and uniqueness of the fixed point $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ follows by the Banach fixed point theorem. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Finally, we show that the fixed point of distributional dynamic programming with signed measure representations is roughly as accurate as \u03b7\u03c0C,\u03ba. ", "page_idx": 24}, {"type": "text", "text": "Theorem 5. Under the conditions of Lemma 5, we have that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)};a n d}\\\\ &{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\big(1+\\frac{1}{1-\\gamma^{c/2}}\\big)\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Since $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ is a nonexpansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ by Lemma 5, following the procedure of Theorem 4, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\eta^{\\pi}$ identifies the closest point (in $\\overline{{\\mathrm{MMD}_{\\kappa}}})$ ) to $\\eta^{\\pi}$ in $\\begin{array}{r}{\\mathcal{S}_{\\mathcal{R}}:=\\prod_{x\\in\\mathcal{X}}\\mathcal{M}^{1}(\\mathcal{R}(x))}\\end{array}$ and $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi}$ identifies the closest point to $\\eta^{\\pi}$ in $\\begin{array}{r}{\\mathcal{C}_{\\mathcal{R}}:=\\prod_{x\\in\\mathcal{X}}\\Delta_{\\mathcal{R}(x)}}\\end{array}$ . Since it is clear that $\\mathcal{C}_{\\mathcal{R}}\\subset\\mathcal{S}_{\\mathcal{R}}$ , it follows that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The first statement then directly follows since it was shown in Lemma 3 that $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})\\leq$ $\\begin{array}{r}{\\operatorname*{sup}_{x\\in\\mathcal{X}}\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "To prove the second statement, we apply the triangle inequality to yield ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi})+\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})+\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the second step leverages the fact that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is a nonexpansion in $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ by Lemma 2. Applying the conclusion of the first statement as well as the bound on $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta^{\\pi},\\eta^{\\pi})$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\eta_{\\mathrm{SC},\\kappa}^{\\pi},\\eta^{\\pi})\\leq\\frac{1}{1-\\gamma^{c/2}}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\displaystyle\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}+\\operatorname*{sup}_{x\\in\\mathcal{X}}\\displaystyle\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}}\\\\ {\\displaystyle}&{\\displaystyle=\\left(1+\\frac{1}{1-\\gamma^{c/2}}\\right)\\operatorname*{sup}_{x\\in\\mathcal{X}}\\displaystyle\\operatorname*{inf}_{P\\in\\mathcal{P}_{\\mathcal{R}(x)}}\\sqrt{\\mathsf{m e s h}(P;\\kappa)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "B.4.2 Convergence of Categorical TD Learning ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Convergence of the proposed categorical TD-learning algorithm will rely on studying the iterates through an isometry to an affine subspace of $\\prod_{x\\in\\mathcal{X}}\\mathbf{R}^{N(x)}$ . This affine subspace is that consisting of the set of state-conditioned \u201csigned probability vectors\u201d. We define $\\mathbf{R}_{1}^{n}$ as an affine subspace of $\\mathbf{R}^{n}$ for any $n\\in\\mathbf N$ according to ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbf{R}_{1}^{n}=\\left\\{v\\in\\mathbf{R}^{n}:\\sum_{i=1}^{n}v_{i}=1\\right\\}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We note that any element $\\eta$ of $\\mathcal{S}_{\\mathcal{R}}$ can be encoded in $\\textstyle\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ by expresing $\\eta(x)$ as the sequence of signed masses associated to each atom of ${\\mathcal{R}}(x)$ . In Lemma 8, we exhibit an isometry $\\mathcal{T}$ between $\\mathcal{S}_{\\mathcal{R}}$ and $\\textstyle\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ . ", "page_idx": 25}, {"type": "text", "text": "Lemma 8. Let $\\kappa$ be a characteristic kernel. There exists an affine isometric isomorphism $\\mathcal{T}$ between $\\mathcal{S}_{\\mathcal{R}}$ and an affine subspace $\\textstyle\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ (cf. (15)). ", "page_idx": 25}, {"type": "text", "text": "Proof. Since $\\kappa$ is characteristic, it is positive definite $[\\mathrm{GBR}^{+}12]$ . Thus, for each $x\\in\\mathscr{X}$ , define $K_{x}\\in\\mathbf{R}^{N(x)\\times N(x)}$ according to ", "page_idx": 25}, {"type": "equation", "text": "$$\n(K_{x})_{i,j}=\\kappa(z_{i},z_{j})\\qquad\\mathcal{R}(x)=\\{z_{k}\\}_{k=1}^{N(x)}\\,.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then each $K_{x}$ is positive definite since $\\kappa$ is a positive definite kernel. Let $p,q\\in\\Delta_{\\mathcal{R}(x)}$ , and define $P\\in\\mathbf{R}^{N(x)}$ and $Q\\in\\mathbf{R}^{N(x)}$ such that $P_{i}=p(z_{i})$ and $Q_{i}=q(z_{i})$ . Then, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathrm{MMD}_{\\kappa}^{2}(p,q)=\\|\\mu_{p}-\\mu_{q}\\|_{q}^{2}}\\\\ {=\\displaystyle\\left\\|\\sum_{i=1}^{N(x)}\\kappa(\\cdot,z_{i})p(z_{i})-\\sum_{i=1}^{N(x)}\\kappa(\\cdot,z_{i})q(z_{i})\\right\\|_{\\mu}^{2}}\\\\ {=\\displaystyle\\left\\langle\\sum_{i=1}^{N(x)}\\kappa(\\cdot,z_{i})(p(z_{i})-q(z_{i})),\\sum_{j=1}^{N(x)}\\kappa(\\cdot,z_{j})(p(z_{j})-q(z_{j}))\\right\\rangle_{\\mu}}\\\\ {=\\displaystyle\\sum_{i=1}^{N(x)}\\sum_{j=1}^{N(x)}(p(z_{i})-q(z_{i}))(p(z_{j})-q(z_{j}))\\kappa(z_{i},z_{j})}\\\\ {=(P-Q)^{\\top}K_{x}(P-Q)}\\\\ {=\\|P-Q\\|_{K}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since $K_{x}$ is positive definite, $\\|\\cdot\\|_{K_{x}}$ is a norm on ${\\mathbf{R}}^{N(x)}$ . Therefore, the map ${\\mathcal{Z}}_{x}^{1}$ : $(\\Delta_{\\mathbb{R}(x)},\\mathrm{MMD}_{\\kappa})\\,\\to\\,(\\mathbf{R}^{N(x)},\\parallel\\cdot\\parallel_{K_{x}})$ given by $\\mathcal{T}_{x}^{1}(p)\\;=\\;\\overline{{P}}$ is a linear isometric isomorphism onto the affine subspace of ${\\mathbf{R}}^{N(x)}$ with entries summing to 1, which we denote ${\\bf R}_{1}^{N(x)}$ . Moreover, since $({\\bf R}_{1}^{N(x)},\\parallel\\cdot\\parallel_{K_{x}})$ is a finite dimensional Hilbert space, it is well known that there exists a linear isometric isomorphism $\\mathcal{Z}_{x}^{2}\\,:\\,(\\mathbf{R}_{1}^{N(x)},\\,\\vert\\vert\\,\\cdot\\,\\vert\\vert_{K_{x}})\\,\\rightarrow\\,\\mathbf{R}_{1}^{N(x)}$ with the usual $L^{2}$ norm. Thus, $\\mathcal{Z}_{x}\\,=\\,\\mathcal{Z}_{x}^{2}\\mathcal{Z}_{x}^{1}\\,:\\,(\\Delta_{\\mathcal{R}(x)},\\mathrm{MMD}_{\\kappa})\\,\\rightarrow\\,{\\mathbf{R}}_{1}^{N(x)}$ R1N(x)is a linear isometric isomorphism. Consequently, it ifsoollmoewtrsi tch iasto $\\begin{array}{r}{\\mathcal{I}:(\\mathcal{C}_{\\mathcal{R}},\\overline{{\\mathrm{MMD}_{\\kappa}}})\\to\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}}\\end{array}$ $\\begin{array}{r}{\\mathcal{Z}=(\\prod_{x\\in\\mathcal{X}}\\mathbf{R}^{N(x)},\\parallel\\cdot\\parallel_{2,\\infty})}\\end{array}$ is a linear $\\begin{array}{r}{\\|v\\|_{2,\\infty}\\stackrel{}{=}\\operatorname*{sup}_{x\\in\\mathcal{X}}\\|v(x)\\|_{2}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "Lemma 9. Define the operator $\\begin{array}{r}{\\mathcal{U}^{\\pi}\\,:\\,\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}\\,\\to\\,\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}}\\end{array}$ by $\\mathcal{U}^{\\pi}\\,=\\,\\mathcal{I}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\mathcal{L}^{-1}$ , where $\\mathcal{T}$ is the isometry of Lemma 8. Let $\\{U_{t}\\}_{t=1}^{\\infty}$ be given by $U_{t}\\,=\\,\\mathcal{T}\\eta_{t}$ , where $\\{\\eta_{t}\\}_{t=1}^{\\infty}$ are the dynamic programming iterates $\\eta_{t+1}\\,=\\,\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}\\eta_{t}$ . Then $U_{t+1}\\,=\\,\\mathcal{U}^{\\pi}U_{t}$ . Moreover, $\\mathcal{U}^{\\pi}$ is contractive whenever $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}$ is, and in this case, $U_{t}\\to U^{\\star}$ , where $U^{\\star}$ is the unique fixed point of $\\mathcal{U}^{\\pi}$ . ", "page_idx": 26}, {"type": "text", "text": "Proof. By definition, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{t+1}=\\mathcal{Z}\\eta_{t+1}}\\\\ &{\\qquad=\\mathcal{Z}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{t})}\\\\ &{\\qquad=\\mathcal{Z}\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}(\\mathcal{Z}^{-1}U_{t})}\\\\ &{\\qquad=\\mathcal{U}^{\\pi}U_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "which proves the first claim. Moreover, for $U_{1}=\\mathbb{Z}\\eta_{1}$ and $U_{2}=\\mathbb{Z}\\eta_{2}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\Vert\\mathcal{U}^{\\pi}U_{1}-\\mathcal{U}^{\\pi}U_{2}\\Vert_{2,\\infty}=\\Vert\\mathcal{Z}\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{1}-\\mathcal{Z}\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{2}\\Vert_{2,\\infty}}\\\\ &{}&{=\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{1},\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\eta_{2}),\\Vert_{2,\\kappa}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the second step transforms the $\\|\\cdot\\|_{2,\\infty}$ to $\\overline{{\\mathrm{MMD}_{\\kappa}}}$ since $\\mathcal{T}$ is an isometry between those metric spaces. Therefore, if $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}T^{\\pi}$ is contractive with contraction factor $\\beta\\in(0,1)$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\mathcal{U}^{\\pi}U_{1}-\\mathcal{U}^{\\pi}U_{2}\\right\\|_{2,\\infty}\\leq\\beta\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{1},\\eta_{2})}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\beta\\left\\|\\mathcal{Z}\\eta_{1}-\\mathcal{Z}\\eta_{2}\\right\\|_{2,\\infty}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\beta\\left\\|U_{1}-U_{2}\\right\\|_{2,\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "so that $\\mathcal{U}^{\\pi}$ has the same contraction factor as $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}T^{\\pi}$ . Consequently, by the Banach fixed point theorem, $\\mathcal{U}^{\\pi}$ has a unique fixed point $U^{\\star}$ whenever $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}$ is contractive, and $U_{t}\\to U^{\\star}$ at the same rate as $\\eta_{t}\\rightarrow\\eta^{\\pi}$ . \u53e3 ", "page_idx": 26}, {"type": "text", "text": "The main theorem in this section is that temporal difference learning on the finite dimensional representations $\\mathcal{T}(\\eta_{t})$ converges. ", "page_idx": 26}, {"type": "text", "text": "Proposition 2 (Convergence of categorical temporal difference learning). Let $\\{U_{t}\\}_{t=1}^{\\infty}\\quad\\subset$ $\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ be given by $U_{t}=\\mathbb{Z}\\widehat{\\eta}_{t}$ , and let $\\kappa$ be a kernel satisfying the conditions of Theorem 2. Suppose that, for each $x\\in\\mathscr{X}$ , the states $\\{X_{t}\\}_{t=1}^{\\infty}$ and step sizes $\\{\\alpha_{t}\\}_{t=1}^{\\infty}$ satisfy the Robbins-Munro conditions ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=0}^{\\infty}\\alpha_{t}{\\mathbf1}_{[X_{t}=x]}=\\infty\\qquad\\sum_{t=0}^{\\infty}\\alpha_{t}^{2}{\\mathbf1}_{[X_{t}=x]}<\\infty.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then, with probability 1 $,U_{k}\\to U^{\\star}$ , where $U^{\\star}$ is the fixed point of $\\mathcal{U}^{\\pi}$ . ", "page_idx": 26}, {"type": "text", "text": "The proof of this result as a natural extension of the convergence analysis of Categorical TD Learning given in [BDR23] to the multivariate return setting under the supremal MMD metric. The analysis hinges on the following general lemma. ", "page_idx": 26}, {"type": "text", "text": "Lemma 10 ([BDR23, Theorem 6.9]). Let $\\mathcal{O}:(\\mathbf{R}^{n})^{\\mathcal{X}}\\rightarrow(\\mathbf{R}^{n})^{\\mathcal{X}}$ be a contractive operator with respect to $\\|\\cdot\\|_{2,\\infty}$ with fixed point $Z^{\\star}$ , and let $(\\Omega,\\check{\\mathcal{F}},\\{F_{k}\\}_{k=1}^{\\infty},\\mathbf{\\vec{P}})$ be a filtered probability space. Define a map $\\widehat{\\mathcal{O}}:(\\mathbf{R}^{n})^{\\mathcal{X}}\\times\\mathcal{X}\\times\\Omega\\rightarrow(\\mathbf{R}^{n})^{\\mathcal{X}}$ such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbf{E_{P}}\\left[\\widehat{\\mathcal{O}}(Z,X,\\omega)\\;\\Big|\\;X=x\\right]=(\\mathcal{O}Z)(x).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "For a stochastic process $\\{\\xi_{k}\\}_{k=1}^{\\infty}$ adapted to $\\{\\mathcal{F}_{k}\\}_{k=1}^{\\infty}$ with $\\xi_{k}=X_{k}\\oplus\\omega_{k}$ , consider a sequence $\\{Z_{k}\\}_{k=1}^{\\infty}\\subset(\\mathbf{R}^{n})^{\\chi}$ given by ", "page_idx": 27}, {"type": "equation", "text": "$$\nZ_{k+1}(x)=\\left\\{\\!\\!\\left(1-\\alpha_{k}\\right)\\!Z_{k}(x)+\\alpha_{k}\\widehat{\\mathcal{O}}(Z_{k},X_{k},\\omega_{k})(x)\\quad\\!X_{k}=x\\!\\right.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\{\\alpha_{k}\\}_{k=1}^{\\infty}$ is adapted to $\\{\\mathcal{F}_{k}\\}_{k=1}^{\\infty}$ and satisfies the Robbins-Munro conditions for each $x\\in\\mathscr{X}$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\infty}\\alpha_{k}{\\mathbf1}_{[X_{t}=x]}=\\infty,\\qquad\\sum_{k=1}^{\\infty}\\alpha_{k}^{2}{\\mathbf1}_{[X_{t}=x]}<\\infty.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "aFisnsualmlye,  tfhoer  ftohlleo pwrioncg esmsoesm $\\{w(x)_{k}\\}_{k=1}^{\\infty}$ hwohledrs,e $\\boldsymbol{w}(\\boldsymbol{x})_{k}\\,=\\,(\\widehat{\\mathcal{O}}(Z_{k},X_{k},\\omega_{k})\\,-\\,(\\mathcal{O}Z_{k})(X_{k}))\\mathbf{1}_{[X_{k}=x]},$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbf{E_{P}}\\left[\\|w(x)_{k}\\|^{2}\\mid\\mathcal{F}_{k}\\right]\\leq C_{1}+C_{2}\\|Z_{k}\\|_{2,\\infty}^{2}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for finite universal constants $C_{1},C_{2}$ . Then, with probability $^{\\,I}$ , $Z_{k}\\to Z^{\\star}$ . ", "page_idx": 27}, {"type": "text", "text": "The operator $\\scriptscriptstyle\\mathcal{O}$ of Lemma 10 will be substituted with $\\mathcal{U}^{\\pi}$ , governing the dynamics of the encoded iterates of the multi-return distribution. The stochastic operatorO  will be substituted with the corresponding stochastic TD operator for $\\mathcal{U}^{\\pi}$ , given by ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{U}}^{\\pi}(U,x_{1},(R,x_{2}))(x)=\\left\\{\\!\\!\\begin{array}{l l}{\\mathcal{T}\\left(\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}(\\mathrm{b}_{R,\\gamma})_{\\sharp}\\mathcal{Z}^{-1}U(x_{2})\\right)(x_{1})}&{x_{1}=x}\\\\ {U(x)}&{\\mathrm{otherwise}.}\\end{array}\\!\\right.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "This corresponds to applying a Bellman backup from a stochastic reward $R$ and next state $x_{2}$ , followed by projecting back onto $\\mathcal{S}_{\\mathcal{R}}$ , and applying the isometry back to $\\textstyle\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ . ", "page_idx": 27}, {"type": "text", "text": "Proof of Proposition 2. Let $n=\\operatorname*{max}_{x\\in\\mathcal{X}}N(x)$ . Note that for any $m\\leq n$ , ${\\mathbf{R}}^{m}$ can be isometrically embedded into ${\\mathbf{R}}^{n}$ by zero-padding. Thus, $\\prod_{x\\in\\mathcal{X}}\\mathbf{R}_{1}^{N(x)}$ can be isometrically embedded into $(\\mathbf{R}_{1}^{n})^{X}$ , so without loss of generality, we will assume that $N(x)\\equiv n$ . ", "page_idx": 27}, {"type": "text", "text": "Define the map $\\widehat{\\mathcal{U}}^{\\pi}:(\\mathbf{R}_{1}^{n})^{\\mathcal{X}}\\times\\mathcal{X}\\times(\\mathbf{R}^{d}\\times\\mathcal{X})\\rightarrow(\\mathbf{R}_{1}^{n})^{\\mathcal{X}}$ according to ", "page_idx": 27}, {"type": "equation", "text": "$$\n(\\widehat{\\mathcal{U}}^{\\pi}(U,x_{1},(R,x_{2})))(x)=\\left\\{\\!\\!\\begin{array}{l l}{\\!\\!\\!\\!Z(\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}(\\mathrm{b}_{R,\\gamma})_{\\sharp}\\mathscr{L}^{-1}U(x_{2}))(x_{1})}&{x_{1}=x}\\\\ {\\!\\!\\!\\!U(x)}&{\\mathrm{otherwise}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then, defining $\\widehat{\\mathcal{U}}_{k}^{\\pi}U=\\widehat{\\mathcal{U}}^{\\pi}(U,X_{k},(R_{k},X_{k}^{\\prime}))$ with $(X_{k},A_{k},R_{k},X_{k}^{\\prime})=T_{k}\\sim\\mathbf{P}$ as in (11), we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{k+1}(x)=(\\widehat{\\mathcal{T}}^{\\pi}\\widehat{\\eta}_{k+1})(x)}\\\\ &{\\qquad\\qquad=\\mathcal{T}\\left(\\mathbf{1}_{[X_{k}=x]}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}(\\mathrm{b}_{R_{k},\\gamma})_{\\sharp}\\widehat{\\eta}_{k}(X_{k}^{\\prime})+\\mathbf{1}_{[X_{k}\\neq x]}\\widehat{\\eta}_{k}(x)\\right)}\\\\ &{\\qquad\\qquad=\\mathbf{1}_{[X_{k}=x]}\\!\\!\\!\\mathcal{T}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}(\\mathrm{b}_{R_{k},\\gamma})_{\\sharp}\\widehat{\\eta}_{k}(X_{k}^{\\prime})+\\mathbf{1}_{[X_{k}\\neq x]}U_{k}(x)}\\\\ &{\\qquad\\qquad=(\\widehat{\\mathcal{U}}_{k}^{\\pi}U_{k})(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Note that, since $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ is a Hilbert projection onto an affine subspace, it is affine [Lax02]. Consequently, ${\\widehat{\\mathcal{U}}}^{\\pi}$ is an unbiased estimator of the operator $\\mathcal{U}^{\\pi}$ in the following sense, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{E}_{\\mathbf{P}}\\left[\\widehat{\\mathcal{U}}^{\\pi}(U,X_{k},(R_{k},X_{k}^{\\prime}))\\;\\middle|\\;X_{k}=x\\right]=\\mathbf{E}_{\\mathbf{P}}\\left[\\mathcal{I}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}(\\mathrm{b}_{R_{k},\\gamma})_{\\sharp}\\mathcal{Z}^{-1}U(X_{k}^{\\prime})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathcal{I}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathbf{E}_{X_{k}^{\\prime}\\sim P^{\\pi}(\\cdot|x)}\\left[(\\mathrm{b}_{r(x),\\gamma})_{\\sharp}\\mathcal{Z}^{-1}U(X_{k}^{\\prime})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathcal{I}\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\mathcal{Z}^{-1}U(x)=(\\mathcal{U}^{\\pi}U)(x),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the first step invokes the linearity of $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ , the second step invokes the linearity of the isometry established in Lemma 8 and the third step is due to the definition of $\\mathcal{T}^{\\pi}$ . As a result, we see that the conditions (16) and (17) of Lemma 10 are satisfied by ${\\widehat{\\mathcal{U}}}^{\\pi}$ , the iterates $\\{U_{k}\\}_{k=1}^{\\infty}$ , and the step sizes $\\{\\alpha_{k}\\}_{k=1}^{\\infty}$ . Moreover, for $w_{k}(x)$ defined by ", "page_idx": 28}, {"type": "equation", "text": "$$\nw_{k}(x)=\\left({\\widehat{\\mathcal{U}}}^{\\pi}(U_{k},X_{k},(R_{k},X_{k}^{\\prime}))-({\\mathcal{U}}^{\\pi}U_{k})(X_{k})\\right)\\mathbf{1}_{[X_{k}=x]}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "we have $\\|w_{k}(x)\\|^{2}\\leq C_{1}+C_{2}\\|U(x)\\|^{2}$ for universal constants $C_{1},C_{2}$ \u2014this is shown in Lemma 11.   \nAs such, the condition of (18) is satisfied. ", "page_idx": 28}, {"type": "text", "text": "Finally, since $\\mathcal{U}^{\\pi}$ inherits contractivity from $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}$ as shown in Lemma 5, we may invoke Lemma 10, which ensures that $U_{k}\\to U$ with probability 1, where is a unique fixed point. ", "page_idx": 28}, {"type": "text", "text": "Theorem 6. For a kernel $\\kappa$ induced by a semimetric $\\rho$ of strong negative type, the sequence $\\{\\widehat{\\eta}_{t}\\}_{t=1}^{\\infty}$ given by (11)-(13) converges to $\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ with probability $^{\\,l}$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. By Proposition 2, the sequence $\\{U_{t}\\}_{t=1}^{\\infty}$ with $U_{t}=\\mathbb{Z}\\eta_{t}$ converges to a unique fixed point $U$ with probability 1. Note that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U^{\\star}=\\mathcal{U}^{\\pi}U^{\\star}}\\\\ {\\mathcal{T}^{-1}U^{\\star}=\\mathcal{T}^{-1}\\mathcal{U}^{\\pi}U^{\\star}}\\\\ {=\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}(\\mathcal{T}^{-1}U^{\\star}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Therefore, ${\\mathcal{I}}^{-1}U^{\\star}$ is a fixed point of $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}$ . Since it was shown in Lemma 5 that $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}T^{\\pi}$ has a unique fixed point, it follows that $\\mathcal{I}^{-1}U^{\\star}=\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ . Since $\\mathcal{T}$ is an isometry, $\\widehat{\\eta}_{t}=\\mathcal{I}^{-1}U_{t}\\to\\mathcal{I}^{-1}U^{\\star}$ with probability 1, so indeed $\\widehat{\\eta}_{t}\\to\\eta_{\\mathrm{SC},\\kappa}^{\\pi}$ with probability 1. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "To conclude, we prove Lemma 11, which was invoked in the proof of Proposition 2. ", "page_idx": 28}, {"type": "text", "text": "Lemma 11. Under the conditions of Proposition 2, it holds that for any $x\\ \\in\\ \\mathcal{X}$ and $U\\ \\in$ x\u2208X RN(x)\u22121, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{X\\sim P^{\\pi}(\\cdot\\vert x)}{\\mathbf{E}}\\left[\\left\\Vert\\mathcal{U}^{\\pi}U(x)-\\widehat{\\mathcal{U}}^{\\pi}(U,x,(R(x),X))(x)\\right\\Vert^{2}\\right]\\leq C_{1}+C_{2}\\|U(x)\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for finite constants $C_{1},C_{2}\\in\\mathbf{R}_{+}$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. Since $\\mathcal{T}$ is an isometry, we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\mathcal{U}^{\\pi}U(x)-\\widehat{\\mathcal{U}}^{\\pi}(U,x,(r,x^{\\prime}))\\right\\|^{2}=\\left\\|\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\mathcal{T}^{\\pi}\\mathcal{Z}^{-1}U(x)-\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}\\left((\\mathrm{b}_{r,\\gamma})_{\\sharp}\\mathcal{Z}^{-1}(x^{\\prime})\\right)(x)\\right\\|_{\\mathcal{H}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where H is the RKHS induced by the kernel \u03ba. Moreover, since \u03a0SRC,\u03ba is a nonexpansion in \u2225\u00b7 \u2225H as argued in Lemma 5, we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{X\\sim P^{\\pi}(\\cdot\\vert x)}{\\mathbf{E}}\\left[\\left\\Vert\\mathcal{U}^{\\pi}U(x)-\\widehat{\\mathcal{U}}^{\\pi}(U,x,(R(x),X))(x)\\right\\Vert^{2}\\right]}\\\\ &{\\ \\leq\\underset{X\\sim P^{\\pi}(\\cdot\\vert x)}{\\mathbf{E}}\\left[\\big\\Vert\\mathcal{T}^{\\pi}\\mathcal{Z}^{-1}U(x)-\\left((\\mathrm{b}_{R,\\gamma})_{\\sharp}\\mathcal{Z}^{-1}U(X)\\right)(x)\\big\\Vert_{\\varkappa}^{2}\\right]}\\\\ &{\\ \\leq2\\underset{A}{\\underbrace{\\Vert\\mathcal{T}^{\\pi}\\mathcal{Z}^{-1}U(x)\\Vert_{\\mathcal{H}}^{2}}}+\\underset{\\underbrace{X\\sim P^{\\pi}(\\cdot\\vert x)}}{\\underbrace{\\mathbf{E}}{\\underbrace{\\mathbf{E}}{\\sim\\mathcal{P}^{\\pi}(\\cdot\\vert x)}}}\\left[\\big\\Vert\\left((\\mathrm{b}_{R,\\gamma})_{\\sharp}\\mathcal{Z}^{-1}U(X)\\right)(x)\\big\\Vert_{\\varkappa}^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proceeding, we will bound the terms $A,B$ . To bound $A$ , we simply have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A\\leq\\|T^{\\pi}\\mathcal{Z}^{-1}U(x)-\\eta^{\\pi}(x)\\|_{\\mathcal{H}}^{2}+\\|\\eta^{\\pi}(x)\\|_{\\mathcal{H}}^{2}}\\\\ &{\\quad\\leq\\gamma^{c/2}\\|\\mathcal{Z}^{-1}U(x)-\\eta^{\\pi}(x)\\|_{\\mathcal{H}}^{2}+\\|\\eta^{\\pi}(x)\\|_{\\mathcal{H}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where we invoke the contraction of $\\mathcal{U}^{\\pi}$ in ${\\mathrm{MMD}}_{\\kappa}$ from Theorem 2. Note that $\\eta^{\\pi}(x)\\in\\mathcal{P}([0,(1-$ $\\gamma)^{-1}R_{\\mathrm{max}}]^{d})$ , so it follows that $\\|\\eta^{\\pi}\\|_{\\mathcal{H}}^{2}\\le D_{1,1}$ for some constant $D_{1,1}$ since the kernel $\\kappa$ is bounded in compact domains. Expanding the norm of the difference above yields ", "page_idx": 29}, {"type": "equation", "text": "$$\nA\\leq(1+\\gamma^{c/2})D_{1,1}+D_{1,2}\\|\\mathcal{T}^{-1}U(x)\\|_{\\mathcal{H}}^{2}=(1+\\gamma^{c/2})D_{1,1}+D_{1,2}\\|U(x)\\|^{2}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for a finite constant $D_{1,2}$ , again invoking the isometry $\\mathcal{T}$ in the last step. ", "page_idx": 29}, {"type": "text", "text": "Our bound for $B$ is similar. Choose any $x^{\\prime}\\,\\in\\,\\operatorname{supp}P^{\\pi}(\\cdot\\mid x)$ . We consider the operator ${\\widetilde{\\mathcal{T}}}_{x^{\\prime}}$ : $\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\operatorname*{max}}]^{d})\\to\\mathcal{P}([0,(1-\\gamma)^{-1}R_{\\operatorname*{max}}]^{d})$ given by ", "page_idx": 29}, {"type": "equation", "text": "$$\n(\\widetilde{\\mathcal{T}}_{x^{\\prime}}\\eta)(x)=(\\mathrm{b}_{R(x),\\gamma})_{\\sharp}\\eta(x^{\\prime}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This operator is a contraction in ${\\mathrm{MMD}}_{\\kappa}$ , and correspondingly has a fixed point $\\eta_{x^{\\prime}}^{\\pi}$ . To see this, we note that ${\\widetilde{T}}_{x^{\\prime}}$ is simply a special case of $\\mathcal{U}^{\\pi}$ for the case $P^{\\pi}(\\cdot\\mid x)=\\delta_{x^{\\prime}}$ , so the contractivity and existence of the fixed point are inherited from Theorem 2. Proceeding in a manner similar to the bound on $A$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|\\left((\\mathrm{b}_{R,\\gamma})_{\\sharp}\\mathbb{Z}^{-1}U(x^{\\prime})\\right)(x)\\right\\|_{\\mathcal{H}}^{2}=\\left\\|\\widetilde{\\mathcal{T}}_{x^{\\prime}}\\mathbb{Z}^{-1}U(x)\\right\\|_{\\mathcal{H}}^{2}}&{}\\\\ {\\leq\\left\\|\\widetilde{\\mathcal{T}}_{x^{\\prime}}\\mathbb{Z}^{-1}U(x)-\\eta_{x^{\\prime}}\\right\\|_{\\mathcal{H}}^{2}+\\|\\eta_{x^{\\prime}}(x)\\|_{\\mathcal{H}}^{2}}&{}\\\\ {\\leq\\gamma^{c/2}\\|\\mathbb{Z}^{-1}U(x)-\\eta_{x^{\\prime}}\\|_{\\mathcal{H}}^{2}+\\|\\eta_{x^{\\prime}}(x)\\|_{\\mathcal{H}}^{2}}&{}\\\\ {\\leq(1+\\gamma^{c/2})D_{2,1}+D_{2,2}\\|U(x)\\|^{2}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the final step mirrors the bound on $A$ . Therefore, we have shown that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{X\\sim P^{\\pi}(\\cdot\\vert x)}{\\mathbf{E}}\\left[\\left\\Vert\\mathcal{U}^{\\pi}U(x)-\\widehat{\\mathcal{U}}^{\\pi}(U,x,(R(x),X))(x)\\right\\Vert^{2}\\right]}\\\\ &{\\leq2(1+\\gamma^{c/2})(D_{1,1}+D_{2,1})+(D_{1,2}+D_{2,2})\\Vert U(x)\\Vert^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "completing the proof. ", "page_idx": 29}, {"type": "text", "text": "C Memory Efficiency of Randomized EWP Dynamic Programming ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In Section 4, we argued for the necessity of considering a projection operator in EWP dynamic programming. While we provided a randomized projection, Theorem 3 requires that we apply only a finite amount of DP iterations. Thus, one might ask if, given that we apply only finitely many iterations, the naive unprojected EWP dynamic programming can produce accurate enough approximations of $\\eta^{\\pi}$ without costing too much in memory. ", "page_idx": 29}, {"type": "text", "text": "In this section, we demonstrate that, in fact, the algorithm described in Theorem 3 can approximate $\\eta^{\\pi}$ to any desired accuracy with many fewer particles. Suppose our goal is to derive some $\\eta$ such that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta,\\eta^{\\pi})\\leq\\epsilon\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for some $\\epsilon\\mathrm{~>~0~}$ . We will derive bounds on the number of required particles to attain such an approximation with unprojected EWP dynamic programming (denoting the number of particles $m_{\\mathsf{u n p r o j}})$ ) as well as with our algorithm described in Theorem 3 (denoting the number of particles $m_{\\mathsf{p r o j}}$ . In both cases, we will compute iterates starting with some $\\eta_{0}\\in\\mathcal{C}_{\\mathrm{EWP},m}$ with $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{0},\\eta^{\\pi})\\dot{\\leq}$ $D<\\infty$ . For simplicity, we will consider the energy distance kernel with $\\alpha=1$ . ", "page_idx": 29}, {"type": "text", "text": "The remainder of this section will show that the dependence of the number of atoms on both $\\epsilon$ and $|{\\mathcal{X}}|$ is substantially worse in the unprojected case (that is, $m_{\\mathsf{p r o j}}\\ll m_{\\mathsf{u n p r o j}}$ for large state spaces or low error tolerance). We demonstrate this with concrete lower bounds on $m_{\\mathsf{u n p r o j}}$ and upper bounds on $m_{\\mathsf{p r o j}}$ below; note that these bounds are not optimized for tightness or generality, and are instead aimed to provide straightforward evidence of our core points above. ", "page_idx": 29}, {"type": "text", "text": "We will begin by bounding $m_{\\mathsf{u n p r o j}}$ . In the best case, $\\eta_{0}(x)$ is supported on 1 particle for each $x$ . If any state can be reached from any other state in the MDP with non-zero probability, then applying the distributional Bellman operator to $\\eta_{0}$ will result in $\\eta_{1}(x)$ having support on $|\\mathcal{X}|$ atoms at each state $x$ (due to the mixture over successor states in the Bellman backup). Consequently, the iterate $\\eta_{k}(x)$ will be supported on $|\\mathcal{X}|^{k}$ atoms. Since $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{k},\\eta^{\\pi})\\le\\gamma^{1/2}\\bar{D}$ by Theorem 2, we require ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "equation", "text": "$$\nK\\geq{\\frac{2\\log(D/\\epsilon)}{\\log\\gamma^{-1}}}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "to ensure that $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{K},\\eta^{\\pi})\\leq\\epsilon$ . Thus, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\nm_{\\mathsf{u n p r o j}}\\geq|\\mathcal{X}|^{\\frac{2\\log(D/\\epsilon)}{\\log\\gamma^{-1}}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "On the other hand, the following lemma bounds $m_{\\mathsf{p r o j}}$ ; we prove the lemma at the end of this section. ", "page_idx": 30}, {"type": "text", "text": "Lemma 12. Let $\\eta_{m_{\\mathsf{p r o j}}}$ denote the output of the projected $E$ WP algorithm described by Theorem 3 with $m=m_{\\mathsf{p r o j}}$ particles. Then under the assumptions of Theorem 3 and with the energy distance kernel with $\\alpha=1$ , $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{m_{\\mathsf{p r o j}}},\\eta^{\\pi})\\leq\\epsilon$ is achievable with ", "page_idx": 30}, {"type": "equation", "text": "$$\nm_{\\mathsf{p r o j}}\\in\\Theta\\left(\\epsilon^{-2}\\frac{d R_{\\operatorname*{max}}^{2}}{(1-\\sqrt{\\gamma})^{2}(1-\\gamma)^{2}}\\mathsf{p o l y l o g}\\left(\\frac{1}{\\epsilon},\\frac{1}{\\delta},|\\mathcal{X}|,d,R_{\\operatorname*{max}},\\frac{1}{1-\\sqrt{\\gamma}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For any fixed MDP with $|\\mathcal{X}|\\ge4$ and $\\gamma\\geq1/2$ , we have that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m_{\\mathsf{u n p r o j}}\\geq\\exp\\left(2\\log|\\mathcal{X}|\\frac{\\log\\epsilon^{-1}}{\\log\\gamma^{-1}}\\right)\\exp\\left(2\\log|\\mathcal{X}|\\frac{\\log D}{\\log\\gamma^{-1}}\\right)}\\\\ &{\\qquad=\\exp\\left(2\\log|\\mathcal{X}|\\frac{\\log D}{\\log\\gamma^{-1}}\\right)\\epsilon^{-2\\frac{\\log|\\mathcal{X}|}{\\log\\gamma^{-1}}}}\\\\ &{\\qquad\\in\\Omega(\\epsilon^{-4})}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "since $D>0$ and does not depend on $\\epsilon$ . Meanwhile, we have $m_{\\mathsf{p r o j}}\\in\\Theta(\\epsilon^{-2}\\mathsf{p o l y l o g}(\\epsilon^{-1}))$ by Lemma 12, indicating a much more graceful dependence on $\\epsilon$ relative to the unprojected algorithm. ", "page_idx": 30}, {"type": "text", "text": "On the other hand, for any fixed tolerance $\\epsilon\\leq\\gamma D$ , we immediately have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m_{\\mathsf{u n p r o j}}\\in\\Omega(|\\mathcal{X}|^{2})}\\\\ &{\\quad m_{\\mathsf{p r o j}}\\in\\Theta(d\\cdot\\mathsf{p o l y l o g}(d,|\\mathcal{X}|)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In the worst case, we may have $d\\in\\Theta(|\\mathcal{X}|)$ (any larger $d$ will induce linearly dependent cumulants). Thus, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{m_{\\mathsf{p r o j}}}{m_{\\mathsf{u n p r o j}}}\\in\\left\\{\\widetilde{O}(|\\mathcal{X}|^{-1})\\quad d\\in\\omega(1)\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "so the projected algorithm scales much more gracefully with $|\\mathcal{X}|$ as well. ", "page_idx": 30}, {"type": "text", "text": "Proof of Lemma 12 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Finally, we prove Lemma 12, which determines the number of atoms required to achieve an $\\epsilon$ -accurate return distribution estimate with the algorithm of Theorem 3. ", "page_idx": 30}, {"type": "text", "text": "Lemma 12. Let $\\eta_{m_{\\mathsf{p r o j}}}$ denote the output of the projected EWP algorithm described by Theorem 3 with $m=m_{\\mathsf{p r o j}}$ particles. Then under the assumptions of Theorem 3 and with the energy distance kernel with $\\alpha=1$ , $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{m_{\\mathsf{p r o j}}},\\eta^{\\pi})\\leq\\epsilon$ is achievable with ", "page_idx": 30}, {"type": "equation", "text": "$$\nm_{\\mathsf{p r o j}}\\in\\Theta\\left(\\epsilon^{-2}\\frac{d R_{\\operatorname*{max}}^{2}}{(1-\\sqrt{\\gamma})^{2}(1-\\gamma)^{2}}\\mathsf{p o l y l o g}\\left(\\frac{1}{\\epsilon},\\frac{1}{\\delta},|\\mathcal{X}|,d,R_{\\operatorname*{max}},\\frac{1}{1-\\sqrt{\\gamma}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. Note that, by Theorem 3, increasing $m_{\\mathsf{p r o j}}$ can only decrease the error $\\epsilon$ as long as $m_{\\mathsf{p r o j}}\\geq1$ . Therefore, as shown in (14) in the proof of Theorem 3, there exists a universal constant $C_{0}>0$ such that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\epsilon:=C_{0}\\frac{1}{\\sqrt{m_{\\mathsf{p r o j}}}}\\underbrace{\\frac{d^{\\alpha/2}R_{\\operatorname*{max}}^{\\alpha}}{(1-\\gamma^{\\alpha/2})(1-\\gamma)^{\\alpha}}}_{c_{1}}\\left(\\underbrace{\\log\\left(\\frac{|\\mathcal{X}|\\delta^{-1}}{\\log\\gamma^{-\\alpha}}\\right)}_{c_{2}}+\\log m_{\\mathsf{p r o j}}\\right).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Now, we write $c_{3}=C_{0}c_{1}c_{2},c_{4}=C_{0}c_{1}$ , and $u:=\\sqrt{m_{\\mathsf{p r o j}}}$ , yielding ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\epsilon=\\frac{c_{3}}{u}+c_{4}\\frac{\\log{u^{2}}}{u}}\\\\ {\\displaystyle=\\frac{c_{3}}{u}+2c_{4}\\frac{\\log{u}}{u}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then, after isolating the logarithmic term and exponentiating, we see that ", "page_idx": 31}, {"type": "equation", "text": "$$\nu=\\exp\\left(\\frac{u\\epsilon-c_{3}}{2c_{4}}\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We now rearrange this expression and invoke the identity $W(z)e^{W(z)}=z$ where $W$ is a Lambert $W$ -function $[\\mathrm{CGH^{+}96}]$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{u e^{c_{3}/2c_{4}}\\exp\\left(-\\frac{u\\epsilon}{2c_{4}}\\right)=1}}\\\\ {{\\mathrm{}\\displaystyle-\\frac{u\\epsilon}{2c_{4}}\\exp\\left(-\\frac{u\\epsilon}{2c_{4}}\\right)=-\\frac{e^{-c_{3}/2c_{4}}\\epsilon}{2c_{4}}=-\\frac{e^{-c_{2}/2}\\epsilon}{2c_{4}}}}\\\\ {{\\mathrm{}\\displaystyle\\qquad\\qquad\\therefore z e^{z}=-\\frac{e^{-c_{2}/2}\\epsilon}{2c_{4}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\nz:=-\\frac{u\\epsilon}{2c_{4}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "There are two branches of the Lambert $W$ -function on the reals, namely $W_{0}$ and $W_{-1}$ . These two branches satisfy $W_{0}(z e^{z})=z$ when $z\\ge-1$ and $W_{-1}(z e^{z})=z$ when $z\\le-1$ . In our case, we know that $z$ is negative, and it is known $[\\mathrm{CGH^{+}96}]$ that $|W_{0}(z)|\\leq1$ when $z\\in[-1,0]$ . Consequently, when $z\\ge-1$ , we have $|\\frac{u\\epsilon}{2c_{4}}|\\leq1$ , and substituting $m_{\\mathsf{p r o j}}=u^{2}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\nm_{\\mathrm{proj}}\\leq\\frac{4c_{4}^{2}}{\\epsilon^{2}}\\;\\mathrm{when}\\;z\\geq-1.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "On the other hand, when $z\\le-1$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{c c}{{z=W_{-1}\\left(-\\frac{e^{-c_{2}/2}\\epsilon}{2c_{4}}\\right)}}\\\\ {{\\vdots-\\frac{u\\epsilon}{2c_{4}}=W_{-1}\\left(-\\frac{e^{-c_{2}/2}\\epsilon}{2c_{4}}\\right)}}\\\\ {{\\vdots\\cdot m_{\\mathsf{p r o j}}=\\frac{4c_{4}^{2}}{\\epsilon^{2}}W_{-1}^{2}\\left(-\\frac{e^{-c_{2}/2}\\epsilon}{2c_{4}}\\right),}}&{{z\\leq-1.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Since it is known $[\\mathrm{CGH^{+}96}$ , Equations 4.19, 4.20] that $W_{-1}^{2}(-\\overline{{z}})\\in\\mathsf{p o l y l o g}(1/\\overline{{z}})$ , incorporating (23), we have that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m_{\\mathrm{proj}}\\leq\\displaystyle\\left\\{\\frac{4c_{4}^{2}}{\\epsilon^{2}}\\right.}&{z\\geq-1}\\\\ &{\\quad\\quad\\left.\\leq\\frac{4c_{4}^{2}}{\\epsilon^{2}}W_{-1}^{2}\\left(-\\frac{e^{c_{2}/2}\\epsilon}{2c_{4}}\\right)\\right.\\quad z\\leq-1}\\\\ &{\\quad\\quad\\leq\\frac{4c_{4}^{2}}{\\epsilon^{2}}\\operatorname*{max}\\left(1,\\mathsf{p o l y l o g}(c_{4}e^{c_{2}/2}\\epsilon^{-1})\\right)}\\\\ &{\\quad\\quad\\leq\\frac{4C_{0}^{2}d R_{\\mathrm{max}}^{2}}{(1-\\sqrt{\\gamma})^{2}(1-\\gamma)^{2}\\epsilon^{2}}\\mathsf{p o l y l o g}\\left(\\frac{1}{\\epsilon},\\frac{1}{\\delta},|\\mathcal{X}|,d,R_{\\operatorname*{max}},\\frac{1}{1-\\sqrt{\\gamma}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The upper bound given above will generally not be an integer. Howevev\u221aer, increasing $m_{\\mathsf{p r o j}}$ can only improve the approximation error, as shown in Theorem 3 since $\\log m/{\\sqrt{m}}$ decreases monotonically when $m\\,>\\,7$ . So, we can round $m_{\\mathsf{p r o j}}$ up to the nearest integer (or round it down when $m\\leq7$ ) incurring a penalty of at most one atom. It follows that the randomized EWP dynamic programming algorithm of Theorem 3 run with $m_{\\mathsf{p r o j}}$ given by (21) produces a return distribution function $\\eta_{m_{\\mathsf{p r o j}}}$ for which $\\overline{{\\mathrm{MMD}_{\\kappa}}}(\\eta_{m_{\\mathrm{proj}}},\\eta^{\\pi})\\leq\\epsilon$ . \u53e3 ", "page_idx": 31}, {"type": "table", "img_path": "aq3I5B6GLG/tmp/63695058e3b0262a916da0d7d5241f112a22fa713cbac31e6238ea1fbaab4fd7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "D Nonlinearity of the Categorical MMD Projection ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "In Section 6, we noted that the categorical projection $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is non-affine. Here, we provide an explicit example certifying this phenomenon. ", "page_idx": 32}, {"type": "text", "text": "We consider a single-state MDP, since the nonlinearity issue is independent of the cardinality of the state space (the projection is applied to each state-conditioned distribution independently). We write $\\bar{\\mathcal{R}}=\\{0,\\ldots,\\bar{3}\\}^{2}$ , and consider the kernel $\\kappa$ induced by $\\rho(x,y)=\\|x-y\\|_{2}$ \u2014this resulting MMD is known as the energy distance, which is what we used in our experiments. We consider two distributions, $p_{1}=\\delta_{[1.5,1.5]}$ and $p_{2}=\\delta_{[2.5,0]}$ . ", "page_idx": 32}, {"type": "text", "text": "We consider $\\lambda=0.8$ and compare $q_{1}=\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}(\\lambda p_{1}\\!+\\!(1\\!-\\!\\lambda)p_{2})$ with $q_{2}=\\lambda\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}p_{1}+(1-\\lambda)\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}p_{2}$ , and we note that $q_{1}\\neq q_{2}$ ; confirming that $\\Pi_{\\mathrm{C},\\kappa}^{\\mathcal{R}}$ is not an affine map. The results are tabulated in Table 1, with bolded entries depicting the atoms with non-negligible differences in probability under $q_{1},q_{2}$ . ", "page_idx": 32}, {"type": "text", "text": "E Experiment Details ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "TD-learning experiments were conducted on a NVidia A100 80G GPU to parallelize experiments. Methods were implemented in Jax $[\\mathrm{BFH^{+}18}]$ , particularly with the help of JaxOpt $[\\mathrm{BBC}^{+}21]$ for vectorizing QP solutions \u2014 this was helpful for computing the categorical projections discussed in this work. SGD was used for optimization, using an annealed learning rate schedule $(\\lambda_{k})_{k\\geq0}$ with $\\lambda_{k}=k^{-3/5}$ , satisfying the conditions of Lemma 10. Experiments with constant learning rates yielded similar results, but were less stable\u2014this validates that the choice of learning rate schedule did not impede learning. ", "page_idx": 32}, {"type": "text", "text": "The dynamic programming experiments were implemented in the Julia programming language [BEKS17]. ", "page_idx": 32}, {"type": "text", "text": "In all experiments, we used the kernel induced by $\\rho(x,y)=\\|x-y\\|_{2}$ with reference point 0 for MMD optimization\u2014this corresponds to the energy distance, and satisfies the requisite assumptions for convergent multivariate distributional dynamic programming outlined in Theorem 2. ", "page_idx": 32}, {"type": "text", "text": "F Neural Multivariate Distributional TD-Learning ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "For the sake of illustration, in this section, we demonstrate that the signed categorical TD learning algorithm presented in Section 6 can be scaled to continuous state spaces with neural networks. We will consider an environment with visual (pixel) observations of a car in a parking lot, an example observation is shown in Figure 4. ", "page_idx": 32}, {"type": "text", "text": "Here, we consider 2-dimensional cumulants, where the first dimension tracks the $x$ coordinate of the car, and the second dimension is an indicator that is 1 if and only if the car is parked in the parking spot. We learn a multivariate return distribution function with transitions sampled from trajectories that navigate around the obstacle to the parking spot. Notably, the successor features (expectation of multivariate return distribution) will be zero in the first dimension, since the set of trajectories is horizontally symmetric. Thus, from the successor features alone, one cannot distinguish the observed policy from one that traverses straight through the obstacle! ", "page_idx": 33}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/16922e49c53b171a5bfb9f6c82c8b8c2d9b8ab7888500ac617fadae2b564f46f.jpg", "img_caption": ["Figure 4: Example state in the parking environment. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Fortunately, when modeling a distribution over multivariate returns,   \nwe should see that the support of the multivariate return distribution does not include points with vanishing first dimension. ", "page_idx": 33}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/6114a6ac12773889075fa723dbe3b9b66736c69313138a0c2740817c6f8d86bb.jpg", "img_caption": ["Figure 5: Neural architecture for modeling multi-return distributions from images. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "To learn the multivariate return distribution function from images, we use a convolutional neural architecture as shown in Figure 5. ", "page_idx": 33}, {"type": "text", "text": "Notably, we simply use convolutional networks to model the signed masses for the fixed atoms of the categorical representation. The projection $\\Pi_{\\mathrm{SC},\\kappa}^{\\mathcal{R}}$ is computed by a QP solver as discussed in Section 5, and is applied only to the target distributions (thus we do not backpropagate through it). ", "page_idx": 33}, {"type": "text", "text": "We compared the multi-return distributions learned by our signed categorical TD method with that of $[Z\\mathrm{C}Z^{\\bar{+}}21]$ . Our results are shown in Figure 6. We see that both TD-learning methods accurately estimate the distribution over multivariate returns, indicating that no multivariate return will have a vanishing lateral component. Quantitatively, we see that the EWP algorithm appears to be stuck in a local optimum, with some particles lying in regions of low probability mass. ", "page_idx": 33}, {"type": "text", "text": "Moreover, on the right side of Figure 6, we show predicted return distributions for two randomly sampled reward vectors, and quantitatively evaluate the two methods. The leftmost reward vector incentivizes the agent to take paths conservatively avoiding the obstacle on the left. The rightmost reward vector incentivizes the agent to get to the parking spot as quickly as possible. We see that the EWP TD learning algorithm of $\\bar{[}Z\\mathrm{C}Z^{+}\\bar{2}1]$ more accurately estimates the return distribution function corresponding to the latter reward vector, while our signed categorical TD algorithm more accurately estimates the return distribution function corresponding to the former reward vector. In both cases, both methods produce accurate estimations. ", "page_idx": 33}, {"type": "image", "img_path": "aq3I5B6GLG/tmp/cc3378f75a54c8fa3d8839cd70484d87a83fc064a0e8baedd6fda8e60ca78b39.jpg", "img_caption": [], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "Figure 6: Multi-return distributions learned by signed categorical TD and EWP TD, as well as examples of predicted return distributions on two randomly sampled reward functions. ", "page_idx": 34}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: As claimed, we provided convergence results for multivariate DRL algorithms, and tested them through simulations. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 34}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have explicitly stated all assumptions, and our simulation section and conclusion explicitly discuss the limitations of our proposed approach. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that ", "page_idx": 34}, {"type": "text", "text": "aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 35}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: All technical results are proved rigorously in the appendix. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 35}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Algorithms are described explicitly, experimental setup is detailed. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 35}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 36}, {"type": "text", "text": "Justification: Code will be provided. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 36}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 36}, {"type": "text", "text": "Justification: Hyperparameters are disclosed. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 36}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: $95\\%$ confidence intervals are shown in relevant plots. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified. ", "page_idx": 36}, {"type": "text", "text": "\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). \u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 37}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: This is discussed in the appendix. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 37}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: We adhere to the code of ethics and preserve anonymity Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 37}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: The contributions are theoretical in nature, and do not have any immediate societal impacts. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 37}, {"type": "text", "text": "\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA]   \nJustification: The paper does not pose any such risks. Guidelines:   \n\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not use existing assets. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA]   \nJustification: The paper does not release any new assets. Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 39}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 39}]