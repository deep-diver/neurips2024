[{"figure_path": "tdZLKY9usl/figures/figures_1_1.jpg", "caption": "Figure 1: A general framework of collaborative inference. The malicious server can infer input and predictions on the edge device. Our method defends against data leakage by reducing the mutual information between the model's intermediate outcomes and the edge device's data and predictions.", "description": "This figure illustrates a general framework for collaborative inference, where a model is split between an edge device and a cloud server. The edge device processes the input data and sends intermediate representations to the cloud server, which then performs further processing and sends back the results. A malicious server attempts to infer the input data and predictions from the exchanged information. The proposed method, InfoScissors, aims to prevent this data leakage by reducing the mutual information between the model's intermediate outputs and the edge device's input and predictions.", "section": "1 Introduction"}, {"figure_path": "tdZLKY9usl/figures/figures_6_1.jpg", "caption": "Figure 3: Images reconstructed by the KA attack on CIFAR10 under different defenses. Each row represents a different defense level. The bottom row applies the strongest defense, resulting in lower-quality reconstructed images and a sacrifice in accuracy.", "description": "This figure shows the results of the Knowledge Alignment (KA) attack on the CIFAR10 dataset using different defense mechanisms. Each row displays the reconstructed images under a specific level of defense, starting with no defense at the top and progressively stronger defenses towards the bottom.  The reconstructed image quality decreases as the defense strength increases, reflecting the trade-off between privacy protection and model accuracy.  The SSIM (Structural Similarity Index) values quantitatively measure the similarity between the original and reconstructed images.", "section": "5.1 Experimental Setup"}, {"figure_path": "tdZLKY9usl/figures/figures_7_1.jpg", "caption": "Figure 4: Model accuracy v.s. SSIM on CIFAR10 and CIFAR100 against MI attacks.", "description": "This figure shows the trade-off between model accuracy and the structural similarity index (SSIM) of reconstructed images under different defense methods against model inversion (MI) attacks.  Lower SSIM values indicate better defense against input leakage, while higher accuracy represents better model utility. The figure compares InfoScissors with DP, AN, PPDL, DC, and MID on both CIFAR10 and CIFAR100 datasets, using KA and rMLE attacks.  It demonstrates InfoScissors's superior performance in achieving low SSIM with minimal accuracy loss.", "section": "5.2 Results of Input Protection"}, {"figure_path": "tdZLKY9usl/figures/figures_8_1.jpg", "caption": "Figure 5: Model accuracy v.s. attack accuracy on CIFAR10 and CIFAR100 against PMC attack.", "description": "This figure compares the model accuracy against the attack accuracy on CIFAR10 and CIFAR100 datasets when using different defense methods against Passive Model Completion (PMC) attacks.  It shows the trade-off between maintaining model accuracy and the effectiveness of the defense in preventing successful attacks.  The results are presented for two variations of the PMC attack using different MLP architectures.", "section": "5.3 Results of Prediction Protection"}, {"figure_path": "tdZLKY9usl/figures/figures_9_1.jpg", "caption": "Figure 7: InfoScissors against KA and PMC.", "description": "This figure shows the results of the integrated defense of InfoScissors against the KA and PMC attacks on CIFAR10 and CIFAR100 datasets. It demonstrates the trade-off between model accuracy and the effectiveness of defense against both input and prediction leakage.  The shaded areas represent the range of results across multiple trials.", "section": "5.4 Integration of Input and Prediction Protection"}, {"figure_path": "tdZLKY9usl/figures/figures_12_1.jpg", "caption": "Figure 8: Reconstructed images of KA attack.", "description": "This figure shows the results of a Knowledge Alignment (KA) attack on CIFAR10.  The left column displays the original input images from the CIFAR10 dataset. The right column shows the images reconstructed by the KA attack, demonstrating the ability of the attacker to reconstruct input images from intermediate representations. The quality of the reconstructed images varies, highlighting the effectiveness of different defense mechanisms.", "section": "A Data Leakage in Collaborative Inference"}, {"figure_path": "tdZLKY9usl/figures/figures_15_1.jpg", "caption": "Figure 4: Model accuracy v.s. SSIM on CIFAR10 and CIFAR100 against MI attacks.", "description": "This figure shows the trade-off between model accuracy and the structural similarity index (SSIM) for various defense methods against model inversion attacks on CIFAR10 and CIFAR100 datasets.  Lower SSIM values indicate better defense performance against reconstructing input images, while higher accuracy reflects better model utility.  The red line represents the proposed InfoScissors method, while other lines represent baseline defense methods. The plots demonstrate InfoScissors's effectiveness in achieving low SSIM values (high defense performance) with minimal accuracy loss.", "section": "5.2 Results of Input Protection"}]