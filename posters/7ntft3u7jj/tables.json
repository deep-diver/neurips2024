[{"figure_path": "7Ntft3U7jj/tables/tables_2_1.jpg", "caption": "Table 1: The performance of different neuron removal methods on six datasets with GraphMAE.", "description": "This table presents the performance of GraphMAE model on six datasets after applying different neuron removal methods.  The methods vary the number of neurons retained, either proportionally across all layers or by removing layers entirely and altering the neurons in the remaining layers. The table shows the Micro-F1 and Macro-F1 scores for each method and dataset, along with the percentage change in the number of parameters compared to the original model. This illustrates the model's redundancy by demonstrating how much performance is retained even with a significant reduction in parameters.", "section": "2 The Model Redundancy in Graph Self-supervised Learning"}, {"figure_path": "7Ntft3U7jj/tables/tables_2_2.jpg", "caption": "Table 1: The performance of different neuron removal methods on six datasets with GraphMAE.", "description": "This table presents the results of experiments evaluating the performance of GraphMAE models after removing different proportions of neurons using various methods. The performance is measured using Micro-F1 (F1-Mi) and Macro-F1 (F1-Ma) scores across six datasets.  The \"Change-Param\" column indicates the percentage change in the number of parameters compared to the original model.", "section": "2 The Model Redundancy in Graph Self-supervised Learning"}, {"figure_path": "7Ntft3U7jj/tables/tables_6_1.jpg", "caption": "Table 3: Node classification accuracy (%\u00b1\u03c3) on six benchmark datasets with GraphMAE.", "description": "This table presents the results of node classification experiments using the GraphMAE model.  It compares the performance of three different fine-tuning methods (Linear Probing, Full Fine-tuning, and SLIDE) across six benchmark datasets.  The metrics reported are Micro-F1 and Macro-F1 scores, along with the percentage change in the number of parameters compared to the original model.  It shows the performance of the model on the node classification task after the parameters are removed by different methods.", "section": "4 Experiments"}, {"figure_path": "7Ntft3U7jj/tables/tables_6_2.jpg", "caption": "Table 3: Node classification accuracy (%\u00b1\u03c3) on six benchmark datasets with GraphMAE.", "description": "This table presents the performance of different node classification methods on six benchmark datasets using the GraphMAE framework.  It compares three approaches: Linear Probing (LP), Full Fine-tuning (FT), and the proposed SLIDE method.  The results are reported as accuracy with standard deviation, showing the Micro-F1 and Macro-F1 scores for each method and dataset. The \"Change-Param\" column indicates the percentage change in the number of parameters compared to the original model.  The table highlights the effectiveness of SLIDE in achieving comparable performance to full fine-tuning while using fewer parameters.", "section": "4 Experiments"}, {"figure_path": "7Ntft3U7jj/tables/tables_6_3.jpg", "caption": "Table 3: Node classification accuracy (%\u00b1\u03c3) on six benchmark datasets with GraphMAE.", "description": "This table presents the performance of different node classification methods (Linear Probing, Full Fine-tuning, and SLIDE) using the GraphMAE framework on six benchmark datasets.  The results are reported as accuracy with standard deviation, showing the impact of the neuron removal methods on classification performance. The 'Change-Param' column indicates the percentage change in the number of parameters compared to the original model.  The table highlights the model redundancy in GraphMAE, where even with significant parameter reduction, the performance remains relatively high.", "section": "4 Experiments"}, {"figure_path": "7Ntft3U7jj/tables/tables_12_1.jpg", "caption": "Table 6: The performance of different neuron removal methods on three datasets with MaskGAE on link prediction tasks.", "description": "This table presents the performance of the MaskGAE model on three datasets (Cora, CiteSeer, PubMed) after removing neurons using different methods.  It shows the Area Under the Curve (AUC) and Average Precision (AP) scores for link prediction. The \"Change-Param\" row indicates the percentage of parameters removed in the \"Half\" and \"Quarter\" GNN models compared to the original GNNs.", "section": "A More Experiences about Model Redundancy"}, {"figure_path": "7Ntft3U7jj/tables/tables_12_2.jpg", "caption": "Table 7: The performance of different neuron removal methods on four datasets with GraphMAE on graph classification tasks.", "description": "This table presents the results of experiments evaluating the performance of GraphMAE models on four graph classification datasets after removing different proportions of neurons.  The table shows the accuracy (ACC) achieved on each dataset after removing neurons at the neuron level (half, quarter) and layer level (2-original, 2-half, 2-quarter), and compares those accuracies to a model with no neuron removal (Original).  The \"Change-Param\" column shows the percentage of parameters removed in each slimmed model relative to the original model.  The results illustrate the level of redundancy in the GraphMAE model.", "section": "4 Experiments"}, {"figure_path": "7Ntft3U7jj/tables/tables_12_3.jpg", "caption": "Table 8: More details about paramters with different neuron removal methods for GraphMAE, where the parameters in GNN is not fine-tunable while the parameters in Linear is fine-tunable.", "description": "This table shows the number of parameters in GNN and Linear layers for different datasets (Cora, CiteSeer, PubMed, Photo, Computers, arXiv) using GraphMAE. It breaks down the parameter counts for the original model and variations created by removing neurons using different methods (Half, Quarter, 2-Original, 2-Half, 2-Quarter).  This allows for a comparison of parameter reduction strategies and their impact on the model's size.", "section": "B.1 GNN Parameters and Linear Parameters"}, {"figure_path": "7Ntft3U7jj/tables/tables_13_1.jpg", "caption": "Table 8: More details about paramters with different neuron removal methods for GraphMAE, where the parameters in GNN is not fine-tunable while the parameters in Linear is fine-tunable.", "description": "This table details the number of parameters (GNN and Linear) in the GraphMAE model before and after applying different neuron removal methods.  It shows the original number of parameters, and then the number remaining after randomly removing 50% (Half), 75% (Quarter), 50% in the second layer (2-Half), and 75% in the second layer (2-Quarter) of the neurons. This breakdown helps illustrate the model's redundancy by showing that a significant portion of parameters can be removed without substantial performance loss.  The 'Linear' parameters refer to the classifier layer which is fine-tuned, while the 'GNN' parameters represent the pre-trained graph neural network.", "section": "B More Details about Model Redundancy"}, {"figure_path": "7Ntft3U7jj/tables/tables_14_1.jpg", "caption": "Table 10: Dataset Statistics", "description": "This table presents the statistics of the six benchmark datasets used in the paper's experiments. For each dataset, it shows the number of nodes, edges, features, classes, and the split ratio for training, validation, and testing.", "section": "C Experimental Details"}, {"figure_path": "7Ntft3U7jj/tables/tables_14_2.jpg", "caption": "Table 11: Orthogonality experiment of our proposed SLIDE and traditional fine-tuning methods, using LoRA as an example.", "description": "This table presents the results of an experiment designed to show the orthogonality of the proposed SLIDE method with respect to traditional fine-tuning methods.  The experiment uses the LoRA (Low-Rank Adaptation) method as a representative example of fine-tuning techniques.  It compares the performance of linear probing, LoRA, Slim-LoRA (LoRA applied to a slimmed GNN), and SLIDE-LoRA (SLIDE combined with LoRA) on three datasets (Cora, CiteSeer, PubMed).  The metric used is accuracy (ACC). The results demonstrate that SLIDE can be effectively combined with other fine-tuning methods to improve model performance.", "section": "Additional Experiments and Analysis of SLIDE with Fine-Tuning Methods"}]