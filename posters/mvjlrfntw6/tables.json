[{"figure_path": "MvjLRFntW6/tables/tables_6_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative results of the experiments conducted to evaluate the performance of the proposed CoX-LMM framework and its baselines on five different tokens ('Dog', 'Bus', 'Train', 'Cat'). The evaluation metrics used are CLIPScore (CS) and BERTScore (BS), which measure the correspondence between the visual and textual grounding of the top-1 activating concept for each token. The table shows that the Semi-NMF variant of CoX-LMM generally outperforms other baselines in terms of both CLIPScore and BERTScore.  The results highlight the effectiveness of Semi-NMF as a dictionary learning method for concept extraction in LMMs and its potential for understanding internal representations of LMMs.", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_7_1.jpg", "caption": "Table 2: Overlap evaluation (LLaVA). Lower is better. Best score in bold, second best underlined.", "description": "This table presents the overlap between concepts for different variants of the CoX-LMM model using the LLaVA dataset.  The overlap measures how much the grounded words of different concepts share common words. Lower overlap scores indicate better disentanglement between concepts, suggesting that each concept represents unique semantic information. The results show that Semi-NMF achieves the best balance, offering a low overlap while maintaining high performance in other metrics.", "section": "A.1 Experiments with LLAVA"}, {"figure_path": "MvjLRFntW6/tables/tables_13_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative results of the proposed CoX-LMM framework and several baseline methods for concept extraction on five different tokens (Dog, Bus, Train, Cat).  It shows the CLIPScore (CS) and BERTScore (BS) for the top-1 activating concept, providing a comparison of the performance of the proposed Semi-NMF approach against other dictionary learning methods (Simple, PCA, K-Means), random word baselines (Rnd-Words), and baselines using noise images (Noise-Imgs).  The results indicate that the Semi-NMF method generally outperforms the baselines, demonstrating its effectiveness in identifying semantically relevant concepts within the LMM representations.", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_13_2.jpg", "caption": "Table 2: Overlap evaluation (LLaVA). Lower is better. Best score in bold, second best underlined.", "description": "This table presents the overlap between learnt concepts for different dictionary learning methods used in the CoX-LMM framework, specifically for the LLaVA model.  Lower overlap scores indicate better disentanglement between the extracted concepts.  The results show that Semi-NMF achieves the lowest overlap, suggesting that it produces more distinct and less entangled concepts compared to other methods like Simple, PCA, and KMeans.", "section": "A.1 Experiments with LLAVA"}, {"figure_path": "MvjLRFntW6/tables/tables_14_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative evaluation results of the proposed CoX-LMM framework and several baseline methods for concept extraction in Large Multimodal Models (LMMs).  The evaluation is performed on five different tokens ('Dog', 'Bus', 'Train', 'Cat', etc.) using two metrics: CLIPScore (CS) and BERTScore (BS), both measuring the correspondence between the learned concepts and the ground truth. The results are shown for the top-1 activating concept, comparing the performance of the proposed Semi-NMF based approach with baselines such as Random words, Noise images, a simple method, and PCA.  Higher scores indicate better performance. The table highlights the superior performance of Semi-NMF, showcasing its effectiveness in capturing semantically meaningful multimodal concepts.", "section": "4.1 Evaluation setup"}, {"figure_path": "MvjLRFntW6/tables/tables_15_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative results of the experiment.  It compares the performance of the proposed CoX-LMM framework against various baselines using two evaluation metrics: CLIPScore (CS) and BERTScore (BS). The evaluation focuses on the top-1 activating concept for five different tokens ('Dog', 'Bus', 'Train', 'Cat', and one other).  The table highlights the effectiveness of the Semi-NMF based dictionary learning method within the CoX-LMM framework, demonstrating superior performance compared to other methods (Simple, PCA, K-Means, 'Rnd-Words', 'Noise-Imgs', and using ground-truth captions as a benchmark).", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_17_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative evaluation results of the proposed CoX-LMM framework and several baseline methods on five different tokens (Dog, Bus, Train, Cat, and others). The evaluation metrics used are CLIPScore (CS) and BERTScore (BS), both measuring the correspondence between visual and textual information related to the concepts.  The table shows the top-1 activating concept scores for each method, including random word baselines, noise image baselines, simple baselines, and the proposed Semi-NMF approach. The best and second best scores for each token and metric are highlighted in bold and underlined, respectively. Statistical significance analysis is provided in Appendix D.", "section": "4.1 Evaluation setup"}, {"figure_path": "MvjLRFntW6/tables/tables_18_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative evaluation results of the proposed CoX-LMM framework and several baseline methods on five different tokens.  The evaluation metrics are CLIPScore (CS) and BERTScore (BS), both measuring the top-1 activating concept's correspondence to the test data.  The baselines include using random words, noisy images, a simple concept extraction approach, and PCA and K-Means clustering. The table highlights the performance of CoX-LMM using Semi-NMF, demonstrating its superiority in achieving high scores for both metrics across various tokens.  Statistical significance details are provided in Appendix D.", "section": "4.1 Evaluation setup"}, {"figure_path": "MvjLRFntW6/tables/tables_20_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative results of the proposed CoX-LMM framework and several baselines on five different tokens.  For each token, it shows the CLIPScore and BERTScore for the top-activated concept.  The baselines used include Rnd-Words (random words), Noise-Imgs (noise images), Simple (a simpler concept extraction method), and PCA and K-Means (other dictionary learning methods).  The table highlights the superior performance of the CoX-LMM framework using Semi-NMF (Semi-Non-negative Matrix Factorization) compared to the baselines. Statistical significance between the CoX-LMM and baselines is detailed in Appendix D.", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_20_2.jpg", "caption": "Table 2: Overlap evaluation (LLaVA). Lower is better. Best score in bold, second best underlined.", "description": "This table presents the overlap between the grounded words of concepts learned using different dictionary learning methods within the CoX-LMM framework.  Lower scores indicate less overlap, signifying more disentangled concepts. The results are specifically for the LLaVA model. The table shows that Semi-NMF achieves the best balance between learning useful concepts and keeping them distinct.  K-Means and Simple perform significantly worse, showing a high degree of overlap.", "section": "Experiments"}, {"figure_path": "MvjLRFntW6/tables/tables_21_1.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative results of the proposed CoX-LMM framework and several baselines on five different tokens.  It shows the CLIPScore and BERTScore for the top-1 activating concept using different dictionary learning methods (Simple, PCA, K-Means, Semi-NMF).  The table compares the performance of the methods to those using random words or noisy images as baselines. The best and second-best scores are highlighted.  Details about statistical significance are available in Appendix D.", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_21_2.jpg", "caption": "Table 1: Test data mean CLIPScore and BERTScore for top-1 activating concept for all baselines on five tokens. CLIPScore denoted as CS, and BERTScore as BS. Statistical significance is in Appendix D. Our CoX-LMM framework is evaluated with Semi-NMF as underlying dictionary learning method. Higher scores are better. Best score in bold, second best is underlined.", "description": "This table presents the quantitative evaluation results for the proposed CoX-LMM framework and several baseline methods.  It shows the CLIPScore and BERTScore for the top-1 activating concept on five different tokens ('Dog', 'Bus', 'Train', 'Cat', 'Bus').  The scores are compared across different methods, including a random words baseline, a noise images baseline, a simple baseline, and the proposed Semi-NMF method.  Higher scores indicate better performance, with statistically significant differences (detailed in Appendix D) indicating the superiority of the Semi-NMF approach.", "section": "4.2 Results and discussion"}, {"figure_path": "MvjLRFntW6/tables/tables_22_1.jpg", "caption": "Table 4: Overlap evaluation (LLaVA). Lower is better. Best score in bold, second best underlined.", "description": "This table presents the overlap between concepts for different dictionary learning methods when using the LLaVa model.  Lower scores indicate better disentanglement between the extracted concepts.  The results show that Semi-NMF generally outperforms other methods, achieving the lowest overlap.", "section": "A.1 Experiments with LLAVA"}]