[{"figure_path": "hH4bPkOhhh/tables/tables_7_1.jpg", "caption": "Table 1: P-values for CI tests in Driving.", "description": "This table presents the results of three conditional independence (CI) tests performed on the Driving dataset to verify whether subgoals can be identified as selections.  The tests assess the conditional independence of variables based on the presence or absence of subgoals. The p-values indicate the significance of the relationships, with lower values suggesting stronger dependence and supporting the hypothesis that subgoals function as selections.", "section": "5.1 Verifying Subgoals as Selections"}, {"figure_path": "hH4bPkOhhh/tables/tables_17_1.jpg", "caption": "Table 1: P-values for CI tests in Driving.", "description": "This table presents the p-values obtained from three conditional independence (CI) tests performed on the Driving dataset. These tests aim to verify the existence of selection variables (subgoals) in the data.  The tests assess the conditional independence between states (st) and actions (at) given the subgoal (gt), the conditional independence between the subgoal (gt) and the next action (at+1) given the next subgoal (gt+1), and the conditional independence between the next state (st+1) and the current subgoal (gt) given the current state (st) and action (at). The results from these tests support the hypothesis that subgoals function as selection variables.", "section": "5.1 Verifying Subgoals as Selections"}, {"figure_path": "hH4bPkOhhh/tables/tables_19_1.jpg", "caption": "Table 3: Effect of our method on the Color-3 (Simple) and Color-3 (Conditional) datasets (5 seeds) in terms of the precision, recall and F1 score for recovering the correct boundaries of subtasks.", "description": "This table presents the performance comparison of three different methods (VTA, LOVE, and the proposed method) on two datasets (Color-3 Simple and Color-3 Conditional) for subtask boundary detection.  The metrics used for comparison are precision, recall, and F1-score. The results show that the proposed method outperforms the other two methods, achieving near-perfect scores.", "section": "5.2 Evaluating the Effectiveness of Seq-NMF"}, {"figure_path": "hH4bPkOhhh/tables/tables_20_1.jpg", "caption": "Table 4: Hyperparameters in seq-NMF", "description": "This table lists the hyperparameters used in the seq-NMF algorithm for learning subtasks.  It specifies values for regularization strengths (\u03bbsim, \u03bb1, \u03bbbin), the number of subtasks for each dataset (Color 3, Color 10, Driving, Kitchen), the maximum time delay in a subtask (L) for each dataset, the maximum number of iterations (maxIter), and the iteration at which to start minimizing the binary loss (start_bin_loss_iter).", "section": "3.3 Learning Subtasks with Seq-NMF"}, {"figure_path": "hH4bPkOhhh/tables/tables_20_2.jpg", "caption": "Table 5: Hyperparameters in hierarchical IL", "description": "This table lists the hyperparameters used in the hierarchical imitation learning (IL) part of the experiments.  It shows settings for the policy network, the PPO (Proximal Policy Optimization) algorithm, and the discriminator in the Generative Adversarial Imitation Learning (GAIL) framework.  Specific hyperparameters include the number of samples per epoch, number of epochs, activation function, hidden layer dimensions, learning rate, and clipping parameters. These settings are crucial for fine-tuning the performance of the imitation learning model in transferring to new tasks.", "section": "5.3 Transfering to New Tasks"}]