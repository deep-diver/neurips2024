[{"figure_path": "BSYn7ah4KX/figures/figures_3_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and \u2462 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how practical LLM systems, such as multi-generation multi-agent systems and on-policy finetuning algorithms, involve knowledge transfer between different generations.  It maps these practical systems onto a Bayesian agent model, highlighting the three key phases: imitation (learning from a predecessor's demonstration), interaction (refining knowledge through interaction with an annotator or environment), and transmission (generating samples for the next generation). The figure visually represents how biases might be amplified or mitigated during this iterative process by comparing the results of interactions with an annotator.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_6_1.jpg", "caption": "Figure 2: Demonstration of conducting iterated ICL on the ACRE task.", "description": "This figure demonstrates how iterated in-context learning is performed on the Abstract Causal Reasoning (ACRE) task. It shows how an LLM agent learns from examples, refines its knowledge through an interaction phase (involving feedback from a human or another LLM), and then generates new examples for the next generation. The figure shows the transfer of knowledge between generations and how an agent's belief of a rule (h) is updated over time.", "section": "5 Experimental Verifications when the Hypothesis is Explicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_7_1.jpg", "caption": "Figure 3: Left: the mean and standard deviations of H(Plmw(h)) of experiments with different h* and d\u00ba (5 different seeds). Middle two: the probability of screen being off, where different colors represent six different levels of spurious bias. Right: the histogram of all Pimw(h) in the first and sixth generation, where the bars are colored based on the value of the last object in h.", "description": "This figure shows the results of experiments designed to visualize how the posterior distribution of hypotheses (h), entropy (H(Plmw(h))), and the probability of a specific bias ('screen: off') evolve across multiple generations of iterated learning. The left panel shows the entropy of the posterior distribution decreasing over generations for various temperature settings, indicating convergence. The middle two panels illustrate the evolution of the probability of the 'screen: off' bias under different prior bias levels and likelihood conditions.  The right panel displays histograms of the posterior distribution for the first and sixth generations, visually representing the amplification of the prior bias.", "section": "5 Experimental Verifications when the Hypothesis is Explicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_8_1.jpg", "caption": "Figure 4: Leftmost three: experiments in Section 6. First: how the ratio of easy samples changes in d\u00b9. N\u2091 is the number of easy examples in d\u2070. Second: how the average ranking of acronyms changes. Third: how the average length of acronyms changes. Rightmost two: results of on-policy DPO in Section 7. Fourth: average length of the responses. Fifth: win rate against the SFT baseline.", "description": "This figure shows the results of two sets of experiments. The left three panels show the results from the experiments in section 6, which studies how the ratio of easy samples, the average ranking of acronyms, and average length of acronyms change over generations in a self-data augmentation task. The right two panels shows the results from the experiments in section 7, which studies the effect of on-policy DPO on the average length of responses and win rate against SFT baseline.  Different lines represent different initial conditions (number of easy examples in d\u2070 and different bias settings).", "section": "6 Experiments on In-Weights Learning: On-Policy DPO as an Example"}, {"figure_path": "BSYn7ah4KX/figures/figures_15_1.jpg", "caption": "Figure 5: Illustrations of typical EM algorithm and an imitation-only iterated learning method.", "description": "This figure illustrates the analogy between the Expectation-Maximization (EM) algorithm and the imitation-only iterated learning.  The EM algorithm is a general method for finding maximum likelihood estimations in statistical models with hidden variables, iteratively improving an estimation of the parameters by updating a distribution over the hidden variables (E-step) and then maximizing the likelihood given this distribution (M-step). The figure shows how the imitation-only iterated learning mirrors the EM algorithm.  In the imitation-only iterated learning, agents learn from data samples generated by previous agents, updating their beliefs about the underlying hypothesis (analogous to the E-step in EM). The next generation of agents then samples new data based on these updated beliefs (analogous to the M-step in EM), and the process repeats, thus iteratively refining the hypothesis.", "section": "3 Bayesian Analysis of Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_19_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and \u2462 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how practical LLM systems, which involve knowledge transfer across multiple generations, can be approximated using Bayesian agents. The three phases of iterative learning (imitation, interaction, and transmission) are highlighted, showing how knowledge is acquired from predecessors, refined through interaction, and transmitted to the next generation.  The figure uses diagrams to visualize the flow of information between agents and the Bayesian updating process that occurs during each phase.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_21_1.jpg", "caption": "Figure 7: The prior probability of all possible h \u2208 H. The systematic mappings are sandwiched between degenerate and holistic mappings, which means Po(hdegen) > Po(hsys) > Po(hholi). Some mappings in the \"other\" group also have relatively large prior, because they contain degenerate components (e.g., mapping two or three objects to the same message).", "description": "This figure shows the prior probability distribution of all possible mappings (hypotheses, h) from the input set X to the output set Y in the iterated learning experiment.  The x-axis represents the index of the 256 possible mappings, while the y-axis represents the prior probability P<sub>o</sub>(h) of each mapping. The mappings are categorized into four groups: degenerate, holistic, others, and systematic.  The figure visually demonstrates that degenerate mappings have the highest prior probability, followed by holistic mappings, systematic mappings, and then \"others\".  This distribution reflects an inherent bias towards simpler or less complex mappings.", "section": "3.2 Iterated Learning of Bayesian Agents"}, {"figure_path": "BSYn7ah4KX/figures/figures_22_1.jpg", "caption": "Figure 8: Ratio of three different types of mappings during iterated learning (curves are the average of 15 different runs, shadow region is the variance). Left to right: 1.) d\u00ba is a holistic mapping; 2.) d\u00ba is a degenerate mapping; 3.) Starting from a holistic d\u00ba, but no longer conduct an interaction phase during training. Hence the degenerate language, which has the highest prior, will gradually dominate; 4.) Ablating the compressibility pressure by using a uniform prior distribution.", "description": "This figure shows the results of four different iterated learning experiments.  Each experiment tracks the proportion of three different types of mappings (degenerate, holistic, and systematic) over multiple generations. The first two experiments demonstrate the amplification of bias with an interaction phase, starting from holistic and degenerate mappings. The third experiment shows that the lack of an interaction phase leads to the dominance of degenerate mappings.  The final experiment shows how eliminating the compressibility pressure (using a uniform prior) affects the proportions of the different mapping types.", "section": "5.1 How the Knowledge of LLM Agents Evolves"}, {"figure_path": "BSYn7ah4KX/figures/figures_22_2.jpg", "caption": "Figure 9: The posterior probabilities of all h at the end of different generations.", "description": "This figure shows the posterior probabilities of all 256 possible mappings (hypotheses) at different generations (1, 10, and 200) during the iterated learning process.  The different colors represent different categories of mappings: degenerate, holistic, others, and systematic.  It visually demonstrates the shift in probability mass towards systematic mappings as the iterative learning progresses, highlighting the effect of both compressibility and expressivity pressures.", "section": "5.1 How the Knowledge of LLM Agents Evolves"}, {"figure_path": "BSYn7ah4KX/figures/figures_23_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and 3 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how practical LLM systems, which involve iterative knowledge transfer among different generations, can be approximated using Bayesian agents within an iterated learning (IL) framework.  The figure showcases three key phases of the process:\n\n1.  **Imitation Phase:** A new agent learns from data generated by its predecessor.\n2.  **Interaction Phase:** The agent interacts with the environment, refining its knowledge.\n3.  **Transmission Phase:** The agent generates new data to be used by the subsequent generation of agents. The figure visually represents these steps using diagrams of multi-agent systems, highlighting how Bayesian agents approximate the behavior of LLMs in this iterative, knowledge-transfer process.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_24_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and 3 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how practical LLM systems, involving multi-agent and multi-generational interactions, can be modeled using Bayesian agents.  It highlights the three key phases of iterative learning: imitation (agent learns from a predecessor), interaction (agent refines its knowledge through tasks), and transmission (agent shares knowledge with the next generation). The figure uses a multi-generation, multi-agent system to show how LLMs learn from other LLMs or themselves over time, and how this process can be seen as a Bayesian update of the agent's prior knowledge.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_25_1.jpg", "caption": "Figure 3: Left: the mean and standard deviations of H(Plmw(h)) of experiments with different h* and d\u00ba (5 different seeds). Middle two: the probability of screen being off, where different colors represent six different levels of spurious bias. Right: the histogram of all Pimw(h) in the first and sixth generation, where the bars are colored based on the value of the last object in h.", "description": "This figure presents a multi-faceted analysis of the evolution of the posterior distribution P(h) across multiple generations of iterated learning.  The left panel shows the entropy of the posterior distribution (H(Plmw(h))) decreasing over time for both strong and weak likelihood scenarios, indicating convergence. The central panels illustrate the impact of varying degrees of prior bias on the probability of 'screen:off' over different generations. The right panels display histograms showing how the posterior distribution evolves from a relatively flat distribution in generation 1 to a much more peaked one in generation 6, illustrating the concentration of probability on a limited subset of hypotheses (h). Different colors represent different levels of spurious bias.", "section": "5 Experimental Verifications when the Hypothesis is Explicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_25_2.jpg", "caption": "Figure 3: Left: the mean and standard deviations of H(Plmw(h)) of experiments with different h* and d\u00ba (5 different seeds). Middle two: the probability of screen being off, where different colors represent six different levels of spurious bias. Right: the histogram of all Pimw(h) in the first and sixth generation, where the bars are colored based on the value of the last object in h.", "description": "This figure presents an analysis of how bias is amplified in iterated learning using Large Language Models (LLMs) in an inductive reasoning task. The left panel shows the entropy of the posterior distribution of hypotheses (H(Plmw(h))), decreasing over generations, indicating convergence. The middle panels show the probability of 'screen:off', demonstrating how different prior biases and likelihoods affect the convergence speed. The right panels display histograms of the posterior distributions, illustrating bias amplification.", "section": "5 Experimental Verifications when the Hypothesis is Explicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_26_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and 3 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how Bayesian agents can be used to model the behavior of LLMs in practical systems that involve knowledge transfer between generations.  The three phases of iterated learning\u2014imitation, interaction, and transmission\u2014are highlighted, showing how an LLM learns from previous generations' data (imitation), refines its understanding through interaction with the environment or other agents (interaction), and then generates new data for subsequent generations (transmission). The figure uses a multi-generation, multi-agent system to visually represent this iterative process, showing how biases and knowledge evolve over time.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_27_1.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and \u2462 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how practical LLM systems, which involve knowledge transfer between generations (e.g., iterative self-data-augmentation, multi-agent LLM systems), can be approximated using Bayesian agents in an iterated learning framework. The three phases highlighted are imitation, interaction, and transmission.  The imitation phase shows how a new agent learns from the previous generation's output. The interaction phase represents refinement of knowledge, perhaps through interaction with the environment, feedback from other agents, or other processes.  Finally, the transmission phase illustrates the transfer of knowledge from one generation of agents to the next.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_27_2.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and 3 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates the process of iterative learning among different generations of LLMs.  It shows how LLMs can be approximated by Bayesian agents and how each generation of agents engages in three phases: imitation (learning from the previous generation), interaction (refining knowledge through tasks or feedback), and transmission (generating data for the next generation). The figure visually represents this iterative process using diagrams of multi-generation multi-agent systems, on-policy finetuning algorithms, and a Bayesian formulation of the multi-gen iterative learning process.", "section": "4 LLM-based Agents in Iterated Learning"}, {"figure_path": "BSYn7ah4KX/figures/figures_28_1.jpg", "caption": "Figure 17: Prompt design for iterated learning on the acronym data-generation task.", "description": "This figure shows the prompt design for an acronym brainstorming task using an LLM. The design involves iterated learning, with each generation producing new examples based on previous generations. The examples are generated by the LLM based on the provided prompts and constraints. The figure also highlights the process of imitation-only and interaction with different Heff (set of hypotheses that accomplish the task). The imitation-only setting involves the LLM generating new examples based solely on the initial set of examples, while the interaction with different Heff involves incorporating feedback from a carefully designed interaction phase to refine the generated examples. ", "section": "6 Experimental Verifications when the Hypothesis is Implicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_28_2.jpg", "caption": "Figure 18: Results when adding different interaction phases (4 different seeds). All three settings demonstrate similar evolutionary trends, which match our theory quite well.", "description": "This figure shows the results of experiments with three different interaction phases: imitation-only, self-refine, and hypothesis search. Each phase is repeated for several generations with four different random seeds.  The figure demonstrates that across various settings and models, the evolutionary trends are consistent with the theoretical predictions of the paper, particularly regarding bias amplification. Three metrics are used to assess the trends: the ratio of easy samples, the average ranking of words in the sample, and the average length of the words in the sample.  The consistency of trends across different models supports the robustness of the findings.", "section": "5 Experimental Verifications when the Hypothesis is Explicit"}, {"figure_path": "BSYn7ah4KX/figures/figures_28_3.jpg", "caption": "Figure 1: Examples of practical LLM systems that require knowledge transfer among different generations and how we use Bayesian agents to approximate their behaviors. \u2460, \u2461, and 3 denotes the imitation, interaction and transmission phases respectively.", "description": "This figure illustrates how the Bayesian-IL framework can be applied to understand the behavior of LLMs in practical systems.  It shows three phases in the iterative learning process: imitation (where a new agent learns from a previous generation's output), interaction (where the agent refines its knowledge), and transmission (where the agent generates data for the next generation). The figure uses a multi-generation multi-agent system as an example to demonstrate how LLMs transfer knowledge between generations, highlighting the parallels between practical LLM systems and the Bayesian agent model.", "section": "4 LLM-based Agents in Iterated Learning"}]