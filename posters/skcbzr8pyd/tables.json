[{"figure_path": "SKCbZR8Pyd/tables/tables_2_1.jpg", "caption": "Table 1: Results of NAR model's speech reconstruction performance with different AR tokens as input.", "description": "This table presents the results of a speech reconstruction experiment using a Neural Autoregressive (NAR) model.  The model's performance is evaluated using two different types of input: golden AR tokens (derived from real speech) and synthetic AR tokens (generated by an autoregressive model).  The table shows that the model performs significantly better when using golden AR tokens, demonstrating a performance degradation caused by a distribution gap between the training and inference phases.  WER (Word Error Rate) is used to quantify accuracy and SIM (Speaker Similarity) measures the consistency of timbre between the generated and prompt speech.", "section": "2.3 Distribution Gap Degrades Performance"}, {"figure_path": "SKCbZR8Pyd/tables/tables_3_1.jpg", "caption": "Table 2: Comparison between reconstructed speech from golden AR tokens versus synthetic AR tokens.", "description": "This table presents the results of a human evaluation comparing speech reconstructed from two types of audio representations: golden AR tokens (ground truth) and synthetic AR tokens (model-generated).  It shows the percentage of times human listeners preferred the speech generated from golden AR tokens (\"Golden Win\"), found them equivalent (\"Tie\"), or preferred the speech generated from synthetic AR tokens (\"Golden Lose\"). The results demonstrate the preference for ground truth representations over model-generated ones.", "section": "3.1 Preference Data Collection"}, {"figure_path": "SKCbZR8Pyd/tables/tables_6_1.jpg", "caption": "Table 3: Evaluation Results of zero-shot text-to-speech on LibriSpeech and VCTK. Each result is calculated as the average of ten separate evaluations.", "description": "This table presents the results of a zero-shot text-to-speech experiment using several models on two datasets, LibriSpeech and VCTK.  The models include a baseline (SpeechAlign-sft) and several variants using different preference optimization strategies (CoH, BoN, RLHF-PPO, and iterative DPO). For each model and dataset, the table shows the Word Error Rate (WER), Speaker Similarity (SIM), Quality Mean Opinion Score (QMOS), and Speaker Mean Opinion Score (SMOS).  Lower WER is better, while higher SIM, QMOS, and SMOS are better. The ground truth results are included for comparison, providing a quantitative assessment of the performance of various models in generating speech from text without prior training on those specific datasets.", "section": "4 Experiments"}]