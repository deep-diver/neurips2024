{"importance": "This paper is crucial because **it addresses the critical gap in aligning speech generation models with human preferences**.  Current methods neglect preference optimization, leading to suboptimal results.  **SpeechAlign provides a novel iterative framework**, bridging this gap and enabling continuous model improvement. This opens doors for **future research in human-centered AI**, especially within speech synthesis and related fields.", "summary": "SpeechAlign: Iteratively aligning speech generation models to human preferences via preference optimization, bridging distribution gaps for improved speech quality.", "takeaways": ["SpeechAlign introduces an iterative self-improvement strategy to align speech generation models with human preferences.", "The method addresses the distribution gap between training and inference phases in neural codec language models, leading to improved performance.", "SpeechAlign demonstrates robust generalization capabilities and works effectively even with smaller models."], "tldr": "Current speech generation models, while advanced, often ignore human preferences, resulting in suboptimal speech quality. This is mainly due to a distribution gap between training and inference stages.  This paper addresses this critical limitation. \n\nSpeechAlign tackles this issue through an innovative iterative approach. It leverages preference optimization, continuously improving the model by contrasting preferred (golden) codec tokens against synthetic ones. This cycle, involving preference dataset construction and optimization, enhances the model's ability to generate realistic and human-preferred speech. The method shows promising results in bridging the distribution gap and improving overall speech quality.", "affiliation": "Fudan University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Text Generation"}, "podcast_path": "SKCbZR8Pyd/podcast.wav"}