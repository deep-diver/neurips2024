[{"figure_path": "G0yxFmP87g/figures/figures_2_1.jpg", "caption": "Figure 1: The latency of LLaMA2 7B with scaled depth/width on various devices/deployment flows.", "description": "This figure shows the results of a profiling study on the efficiency of different LLM shapes (depth and width) across various devices (NVIDIA A5000 and NVIDIA Jetson Orin NX) and deployment flows (TensorRT-LLM, MLC-LLM, and vanilla PyTorch).  The depth is defined as the number of self-attention blocks, while the width represents the hidden dimensions.  The study reveals significant latency variations across different hardware and software combinations, highlighting the need for adaptable LLM structures to optimize efficiency across diverse real-world deployment scenarios.", "section": "2 Motivation and Profiling"}, {"figure_path": "G0yxFmP87g/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of our AmoebaLLM framework: (a) Stage 1: Generate the subnet selection strategy; (b) Stage 2: One-for-all fine-tuning. Zoom in for a better view.", "description": "This figure illustrates the two-stage process of AmoebaLLM. Stage 1 focuses on the knowledge-preserving subnet selection using dynamic programming for depth shrinking and an importance-driven method for width shrinking.  The output is a subnet selection strategy. Stage 2 performs one-for-all fine-tuning using a shape-aware mixture of LoRAs (SMOL) and in-place distillation with loss-magnitude balancing. The result is a set of subnets with diverse shapes.", "section": "3.1 AmoebaLLM: Methodology Overview"}, {"figure_path": "G0yxFmP87g/figures/figures_7_1.jpg", "caption": "Figure 3: Benchmark AmoebaLLM's achieved accuracy-latency trade-offs with SOTA LLM compression methods on an NVIDIA A5000 GPU.", "description": "This figure presents a comparison of AmoebaLLM's performance against state-of-the-art (SOTA) LLM compression methods on an NVIDIA A5000 GPU. The comparison focuses on the trade-off between accuracy and latency.  Two subfigures show the results for two different deployment flows: PyTorch and MLC-LLM.  Each subfigure shows how accuracy varies as a function of latency for AmoebaLLM, Shortened LLaMA, and FLAP, illustrating the relative performance and efficiency of each method.", "section": "4.3 Ablation Study: Effectiveness of Each Component"}]