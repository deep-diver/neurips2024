[{"figure_path": "8Hy3KMZTL5/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on standard benchmarks. The best-performing results are presented in bold, while the second-best results are underlined. \u201cVLM\u201d: visual language model.", "description": "This table compares the performance of the proposed H-CLIP model against other state-of-the-art methods on various open-vocabulary semantic segmentation benchmarks.  The benchmarks are evaluated using metrics like mIoU and are split into subsets with varying numbers of classes, reflecting different levels of difficulty. The table is organized to show results for models using traditional fine-tuning and those using parameter-efficient fine-tuning, highlighting the improvements achieved by H-CLIP in both scenarios.  The use of visual language models (VLMs) and additional backbones is also indicated.  The best and second-best results are clearly marked for each benchmark and model.", "section": "5.2 Main Results"}, {"figure_path": "8Hy3KMZTL5/tables/tables_6_1.jpg", "caption": "Table 2: Efficiency comparison in terms of learnable parameters.", "description": "This table compares the number of learnable parameters used in different open-vocabulary semantic segmentation methods. It shows that the proposed H-CLIP method significantly reduces the number of parameters compared to other state-of-the-art methods, while maintaining or improving performance. This highlights the efficiency of the proposed method.", "section": "5.2 Main Results"}, {"figure_path": "8Hy3KMZTL5/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study on the components of H-CLIP. \"LoRA\": a mainstream parameter-efficient tuning method with a comparable number of parameters for comparison. \u201cPOF\": Partial Orthogonal Fine-tuning. \"DCRC\": Dual Cross Relation Communication. The base model is ViT-B/16.", "description": "This table presents the ablation study of the proposed H-CLIP model. It shows the impact of each component (Partial Orthogonal Fine-tuning and Dual Cross Relation Communication) on the model performance. It also compares H-CLIP with another parameter-efficient tuning method LoRA, which has a similar number of trainable parameters. The performance is evaluated on six different test sets across three benchmarks.", "section": "5.2 Main Results"}, {"figure_path": "8Hy3KMZTL5/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study on different designs in POF. We show the impact of (a) different block dimensions q and (b) orthogonal constraints. The base model is ViT-B/16.", "description": "This table presents the ablation study on different designs in the Partial Orthogonal Fine-tuning (POF) method. It shows the effect of different block dimensions (q) and the impact of applying orthogonal constraints on the performance. The base model used for this experiment is ViT-B/16.", "section": "5.3 Ablative Studies"}]