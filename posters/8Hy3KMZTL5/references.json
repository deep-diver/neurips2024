{"references": [{"fullname_first_author": "Maxime Bucher", "paper_title": "Zero-shot semantic segmentation", "publication_date": "2019-MM-DD", "reason": "This paper is foundational for the open-vocabulary semantic segmentation task, introducing the concept of zero-shot learning to the field."}, {"fullname_first_author": "Holger Caesar", "paper_title": "Coco-stuff: Thing and stuff classes in context", "publication_date": "2018-MM-DD", "reason": "This paper introduced the COCO-Stuff dataset, a widely used benchmark dataset in semantic segmentation research that includes rich class annotations."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "This paper introduced CLIP, a powerful vision-language model that enables open-vocabulary capabilities and is central to the proposed H-CLIP method."}, {"fullname_first_author": "Seokju Cho", "paper_title": "Cat-seg: Cost aggregation for open-vocabulary semantic segmentation", "publication_date": "2024-MM-DD", "reason": "This paper is a direct competitor and highly relevant to the proposed work, offering a parameter-efficient approach to open-vocabulary semantic segmentation using CLIP."}, {"fullname_first_author": "Golnaz Ghiasi", "paper_title": "Scaling open-vocabulary image segmentation with image-level labels", "publication_date": "2022-MM-DD", "reason": "This paper addresses a key challenge in open-vocabulary semantic segmentation: scaling to a large number of classes, a problem also addressed by H-CLIP"}]}