[{"figure_path": "ftqjwZQz10/tables/tables_6_1.jpg", "caption": "Table 1: Average classification accuracy (%) and corresponding standard deviations over three runs for each dataset and method. Bold type indicates those of the highest classification accuracy.", "description": "This table presents the average classification accuracy and standard deviations obtained from three independent runs for four different vision datasets (ImageNette, Caltech101, Caltech256, Food101) and four Convolutional Neural Networks (SimpleNet, WideNet, EfficientNetV2, MobileNetV2).  Three methods are compared: downsampling, CoordConv, and the proposed DEX method. The bold values highlight the highest accuracy achieved for each dataset.  The table summarizes the performance of different approaches in handling limited memory on tiny AI accelerators.", "section": "4.2 Result"}, {"figure_path": "ftqjwZQz10/tables/tables_7_1.jpg", "caption": "Table 2: Model size (Size), utilization of the original image information (InfoRatio), accelerator's processor utilization for the first layer (ProcUtil), and inference latency on the accelerator (Latency) for different models and methods averaged over three runs.", "description": "This table presents a quantitative comparison of different methods (Downsampling, CoordConv, CoordConv (r), and DEX) applied to four different CNN models (SimpleNet, WideNet, EfficientNetV2, and MobileNetV2).  It shows the model size in kilobytes, the ratio of original image information utilized, the percentage of the accelerator's processors utilized in the first layer, and the inference latency in microseconds. The results are averages across three runs.", "section": "4.2 Result"}, {"figure_path": "ftqjwZQz10/tables/tables_8_1.jpg", "caption": "Table 2: Model size (Size), utilization of the original image information (InfoRatio), accelerator's processor utilization for the first layer (ProcUtil), and inference latency on the accelerator (Latency) for different models and methods averaged over three runs.", "description": "This table presents a quantitative comparison of different model architectures (SimpleNet, WideNet, EfficientNetV2, MobileNetV2) and methods (Downsampling, CoordConv, DEX) across four key metrics: model size (KB), the ratio of utilized original image information to the downsampled version, the percentage of utilized processors in the first layer of the CNN, and the inference latency in microseconds. The results are averaged over three runs and show the impact of DEX in terms of resource utilization and performance.", "section": "4.2 Result"}, {"figure_path": "ftqjwZQz10/tables/tables_8_2.jpg", "caption": "Table 4: Comparison of data extension strategies.", "description": "This table compares the performance of DEX with four alternative data extension strategies: repeating the same downsampled image across channels (Repetition), generating slightly different images through rotation (Rotation), dividing the original image into multiple tiles and stacking those tiles across channels (Tile), patch-wise sequential sampling, and patch-wise random sampling.  The table shows that DEX's approach of patch-wise even sampling is superior.", "section": "3.3 Further analysis on DEX"}, {"figure_path": "ftqjwZQz10/tables/tables_14_1.jpg", "caption": "Table 5: Comparison of MAX78000 and MAX78002.", "description": "This table compares the specifications of two tiny AI accelerator platforms: MAX78000 and MAX78002.  It details the MCU processor, flash memory, SRAM, CNN processor, data memory, weight memory, and bias memory for each platform, highlighting the differences in their hardware resources.", "section": "A.1 Tiny AI accelerator platforms"}, {"figure_path": "ftqjwZQz10/tables/tables_17_1.jpg", "caption": "Table 6: The power consumption of inference measured by varying the size of the channel extension with a Monsoon Power Monitor. All numbers are in milliwatts (mW).", "description": "This table shows the power consumption results measured using a Monsoon Power Monitor for different models (SimpleNet and WideNet) with varying channel sizes (Chan = 3, 6, 18, 36, 64).  The data demonstrates the increase in power consumption as the number of channels increases, due to higher processor utilization in the AI accelerator.", "section": "B.2 Power consumption"}]