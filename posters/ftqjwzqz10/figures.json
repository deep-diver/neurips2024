[{"figure_path": "ftqjwZQz10/figures/figures_1_1.jpg", "caption": "Figure 1: The architecture of a tiny AI accelerator (MAX78000 [34]).", "description": "This figure shows a simplified architecture of the MAX78000 tiny AI accelerator. It highlights key components such as the pooling engine, caching, convolutional engine, and the 64 parallel processors.  The dedicated data and weight memories for each processor are also shown. This architecture enables parallel processing of convolutional operations across multiple channels, which leads to significant performance gains compared to traditional MCUs.", "section": "1 Introduction"}, {"figure_path": "ftqjwZQz10/figures/figures_2_1.jpg", "caption": "Figure 3: Processor utilization with varying input channels on the AI accelerator.", "description": "This figure illustrates how the processors of a tiny AI accelerator are utilized when processing CNN inputs with different numbers of channels.  With only three input channels (e.g., RGB), only three processors are utilized, while the remaining 61 processors remain idle.  This highlights the underutilization of resources in existing methods which is addressed by the proposed DEX method.", "section": "3 DEX: Data channel extension for efficient CNN inference on AI accelerators"}, {"figure_path": "ftqjwZQz10/figures/figures_3_1.jpg", "caption": "Figure 4: Comparison among different input data. (a) an original image that exceeds the data memory limit of the AI accelerator, (b) a downsampled image that fits the data memory but does not fully utilize parallel processors and data memory, and (c) a DEX-generated image that incorporates more information from original image by extending data across channels with full utilization of parallel processors and data memory instances.", "description": "This figure compares three different ways of handling input images for tiny AI accelerators: (a) shows an original image that's too large for the accelerator's memory, (b) shows a downsampled image which fits into memory but underutilizes the parallel processors, and (c) shows the DEX method, which extends the image across channels to make full use of the available resources.", "section": "3 DEX: Data channel extension for efficient CNN inference on AI accelerators"}, {"figure_path": "ftqjwZQz10/figures/figures_3_2.jpg", "caption": "Figure 5: Overview of DEX. DEX divides the original image I into multiple patches. DEX then evenly samples pixels from each patch Pij and constructs an output pixel Oij by stacking samples across channels.", "description": "This figure illustrates the DEX process.  The original image is divided into patches.  DEX then uses patch-wise even sampling to select pixels evenly spaced across the original image while maintaining spatial relationships. These samples are then stacked channel-wise, creating an output image with extended channels (Co).  This process adds more information from the original image to the input without increasing the spatial dimensions (Ho, Wo).", "section": "3 DEX: Data channel extension for efficient CNN inference on AI accelerators"}, {"figure_path": "ftqjwZQz10/figures/figures_5_1.jpg", "caption": "Figure 6: The initial CNN layer's operation with DEX.", "description": "This figure illustrates how the initial convolutional layer of a CNN operates when using the DEX method.  The input to the layer is an image enhanced using DEX, which extends the number of channels from C1 to Co. This extended input is then processed by the convolutional layer, which uses kernels of size Lkernel_size. The operation of the layer is shown for three different channels, representing the original channels (C1) and the added channels using DEX (Co-C1).  The summation symbol (\u03a3) shows that the outputs from the individual channels are added to create the final output of the first convolutional layer (Lc_out).  The added channels via DEX provide extra information for better feature extraction by the model, leading to improved accuracy without affecting the inference speed.", "section": "3 DEX: Data channel extension for efficient CNN inference on AI accelerators"}, {"figure_path": "ftqjwZQz10/figures/figures_7_1.jpg", "caption": "Figure 7: Accuracy of DEX varying the channel size. The shaded areas are standard deviations.", "description": "This figure shows the impact of varying the number of channels (3, 6, 18, 36, and 64) used in DEX on the accuracy of four different CNN models (SimpleNet, WideNet, EfficientNetV2, and MobileNetV2) across four different datasets (ImageNette, Caltech101, Caltech256, and Food101).  The shaded regions represent standard deviations, illustrating the variability in accuracy across multiple experimental runs. The results demonstrate that increasing the channel size generally leads to improved accuracy, although there might be some exceptions depending on the specific model and dataset.", "section": "4.2 Result"}, {"figure_path": "ftqjwZQz10/figures/figures_8_1.jpg", "caption": "Figure 7: Accuracy of DEX varying the channel size. The shaded areas are standard deviations.", "description": "This figure shows the accuracy of the proposed DEX method (Data Channel Extension) as the number of channels in the input image is varied.  The accuracy is tested across four different datasets (ImageNette, Caltech101, Caltech256, and Food101) and four different CNN models. It demonstrates how the accuracy improves with increasing channel size, indicating the effectiveness of the DEX method in utilizing more information from the original input image.", "section": "4.2 Result"}, {"figure_path": "ftqjwZQz10/figures/figures_14_1.jpg", "caption": "Figure 9: Two tiny AI accelerator development platforms used in our work. Note that although the development platform is bulky, the actual size of the accelerators is tiny (e.g., 8mm\u00d78mm for MAX78000). All data storing and model inference is done only in the AI Accelerator part (MAX78000 and MAX78002).", "description": "This figure shows two different development platforms used for evaluating DEX: the MAX78000 Feather Board and the MAX78002 Evaluation Kit.  The image highlights the small size of the AI accelerators themselves (8mm x 8mm for the MAX78000 and 12mm x 12mm for the MAX78002) in contrast to the larger development boards.  The caption emphasizes that all data storage and model inference take place solely within the AI accelerator.", "section": "A.1 Tiny AI accelerator platforms"}, {"figure_path": "ftqjwZQz10/figures/figures_16_1.jpg", "caption": "Figure 10: Visulaization of four alternative data extension methods.", "description": "This figure visualizes four alternative data extension methods compared to DEX in the paper.  (a) Repetition: repeats the same downsampled image across channels. (b) Rotation: generates slightly different images through rotation. (c) Tile: divides the original image into multiple tiles and stacks them across channels. (d) Patch-wise sequential sampling: samples pixels sequentially within a patch. (e) Patch-wise random sampling: samples pixels randomly within a patch.  These methods are compared against DEX to highlight the effectiveness of DEX's approach of patch-wise even sampling and channel-wise stacking.", "section": "Alternative data channel extension methods' details"}, {"figure_path": "ftqjwZQz10/figures/figures_18_1.jpg", "caption": "Figure 11: Examples images generated from an original 3 \u00d7 350 \u00d7 350 image (ImageNette) to 3 \u00d7 32 \u00d7 32 downsampled image via DEX. k = 0 to k = 6 cases are shown only. Each generated image contains different pixel information, which collectively enhances feature learning in CNNs.", "description": "This figure shows example images generated by DEX from an original ImageNette image (350x350 pixels).  The original image is compared to downsampled versions (32x32 pixels) created using DEX with different sampling parameters (k=0 to k=6). Each downsampled image has different pixel information, which contributes to improved feature learning within CNNs by providing a more comprehensive representation of the original image.", "section": "C Example images generated from DEX"}, {"figure_path": "ftqjwZQz10/figures/figures_18_2.jpg", "caption": "Figure 12: Examples images generated from an original 3 \u00d7 350 \u00d7 350 image (ImageNette) to 3 \u00d7 32 \u00d7 32 downsampled image via DEX. k = 0 to k = 6 cases are shown only. Each generated image contains different pixel information, which collectively enhances feature learning in CNNs.", "description": "This figure shows example images generated by DEX from an original high-resolution image (350x350 pixels).  It demonstrates how DEX extends the number of channels by incorporating additional pixel information from the original image through patch-wise even sampling and channel-wise stacking. Each of the downsampled images (k=0 to k=6) represents a different set of sampled pixels, providing additional spatial context for the CNN.", "section": "C Example images generated from DEX"}, {"figure_path": "ftqjwZQz10/figures/figures_19_1.jpg", "caption": "Figure 13: Examples images generated from an original 3 \u00d7 350 \u00d7 350 image (ImageNette) to 3 \u00d7 32 \u00d7 32 downsampled image via DEX. k = 0 to k = 6 cases are shown only. Each generated image contains different pixel information, which collectively enhances feature learning in CNNs.", "description": "This figure shows example images generated using DEX, demonstrating how it extends the input image channels by incorporating additional pixel information. The original ImageNet image is shown alongside several downsampled versions, highlighting the diverse pixel information incorporated by the DEX method.", "section": "C Example images generated from DEX"}]