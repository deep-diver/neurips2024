[{"figure_path": "hKcx2wa3P0/tables/tables_3_1.jpg", "caption": "Table 1: Different losses with corresponding Lipschitz constant ML,b", "description": "This table lists several commonly used loss functions (Squared, Exponential, Check, Hinge, Huber, Logistic) and their corresponding Lipschitz constants (ML,b).  The Lipschitz constant quantifies the smoothness of the loss function, which is important for the theoretical analysis in the paper. The table shows that the Lipschitz constants for most of the common loss functions are 1, except for Huber loss which has Lipschitz constant \u03c4 and squared loss which has a Lipschitz constant that depends on U and \u03ba.", "section": "3 Standard Kernel-based Method"}, {"figure_path": "hKcx2wa3P0/tables/tables_13_1.jpg", "caption": "Table 2: Averaged MSE for different methods", "description": "This table presents the results of applying both the standard kernel method (KM) and the truncated kernel method (TKM) to a real-world dataset using the check loss function with three different quantile levels (\u03c4 = 0.3, 0.5, 0.7).  The mean squared error (MSE) is reported for each method and quantile level, along with the standard deviation.  The purpose is to demonstrate the effectiveness of the truncated kernel method.", "section": "A Real Data Analysis"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_1.jpg", "caption": "Table 3: Averaged MSE for different n (\u03c4 = 0.3).", "description": "This table presents the averaged Mean Squared Error (MSE) for different sample sizes (n) when using the check loss function with a quantile level (\u03c4) of 0.3.  It compares the performance of the standard kernel-based method (KM) and the truncated kernel-based method (TKM).  The results show the MSE for KM and TKM, with standard deviations, across four different sample sizes. The lower MSE values indicate better performance.", "section": "H.4 Determining r via Cross-validation"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_2.jpg", "caption": "Table 2: Averaged MSE for different methods", "description": "This table shows the averaged Mean Squared Error (MSE) for the standard Kernel Method (KM) and the Truncated Kernel Method (TKM) across three different quantile levels (\u03c4 = 0.3, 0.5, 0.7). The results are based on a real-world dataset, indicating the performance of both methods for quantile regression.", "section": "A Real Data Analysis"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_3.jpg", "caption": "Table 5: Averaged MSE for different n (\u03c4 = 0.5)", "description": "This table presents the results of a numerical experiment comparing the performance of KM and TKM methods for different sample sizes (n). The experiment uses the check loss function with \u03c4 = 0.5.  The table shows the averaged Mean Squared Error (MSE) for both methods across various sample sizes. The MSE is a measure of the average squared difference between predicted and actual values, with lower values indicating better performance. ", "section": "H.4 Determining r via Cross-validation"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_4.jpg", "caption": "Table 6: Averaged Empirical excess risk for different n (\u03c4 = 0.5).", "description": "This table presents the averaged empirical excess risk for different sample sizes (n = 100, 200, 300, 400) for both the standard kernel-based method (KM) and the truncated kernel-based method (TKM). The empirical excess risk is calculated for \u03c4 = 0.5 which represents the 50th quantile.", "section": "H.4 Determining r via Cross-validation"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_5.jpg", "caption": "Table 7: Averaged MSE for different n (\u03c4 = 0.7)", "description": "This table shows the averaged Mean Squared Error (MSE) for different sample sizes (n = 100, 200, 300, 400) when using the standard Kernel-based Method (KM) and the Truncated Kernel-based Method (TKM) for quantile regression with the quantile level \u03c4 set to 0.7.  The results are presented as mean \u00b1 standard deviation.", "section": "H.4 Determining r via Cross-validation"}, {"figure_path": "hKcx2wa3P0/tables/tables_45_6.jpg", "caption": "Table 8: Averaged Empirical excess risk for different n (\u03c4 = 0.7)", "description": "This table presents the averaged empirical excess risk for different sample sizes (n = 100, 200, 300, 400)  using both the standard Kernel Method (KM) and the Truncated Kernel Method (TKM). The results are shown for a quantile level (\u03c4) of 0.7.  The values represent the average empirical excess risk and the standard deviation.", "section": "H.4 Determining r via Cross-validation"}]