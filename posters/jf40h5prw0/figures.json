[{"figure_path": "Jf40H5pRW0/figures/figures_1_1.jpg", "caption": "Figure 1: Setup for Privacy Protection with Open vs Closed LLMs. The three parties involved are (1) an LLM provider who hosts the proprietary LLM, (2) a data curator, such as a company that curated private data, for example, of their customers' previous transactions, and (3) a querying party, i.e., a customer of the company who wants to perform a new private transaction. There are three steps where privacy leaks: A During the creation of the discrete prompt, the data curator's private data leaks to the LLM provider. B The private query of the querying party leaks to the LLM provider. C Private information from the data curator leaks to the querying party through the returned answers of the prompted LLM [17]. Prior methods for closed LLMs [16, 56, 63] only provide protection against C. None of them protects against A, B. To prevent leakage through A, they require access to a (powerful) local open LLM. As an alternative (dashed purple lines), the data curator could privately adapt the open LLM locally and let the querying party interact with this LLM, protecting against A, B, C.", "description": "This figure illustrates the three parties involved in using LLMs with private data: the LLM provider, data curator, and querying party.  It shows how existing methods for adapting closed LLMs to private data leak information (A, B, and C).  It then presents a privacy-preserving alternative using a local open LLM.", "section": "1 Introduction"}, {"figure_path": "Jf40H5pRW0/figures/figures_7_1.jpg", "caption": "Figure 2: Privacy-utility trade-off for classifications tasks. We use PrivateLoRA to adapt Vicuna-7b to the downstream tasks, PromptPATE, DP-ICL, and DP-FewShotGen with GPT3 Babbage. We analyze the privacy costs \u03b5 in the range [0, 8] (see corresponding Figure 3 for text generation tasks).", "description": "This figure shows the privacy-utility trade-off for four different classification tasks (SST2, Trec, MPQA, and Disaster).  It compares the performance of PrivateLoRA (using the Vicuna-7b open LLM) against three closed-LLM adaptation methods (PromptPATE, DP-ICL, and DP-FewShotGen using GPT-3 Babbage).  The x-axis represents the privacy cost (epsilon), and the y-axis represents the accuracy. The figure illustrates that PrivateLoRA consistently outperforms the closed-LLM methods across various privacy budgets, demonstrating its superiority in terms of both privacy and utility.", "section": "4.2 Comparing Performance"}, {"figure_path": "Jf40H5pRW0/figures/figures_8_1.jpg", "caption": "Figure 2: Privacy-utility trade-off for classifications tasks. We use PrivateLoRA to adapt Vicuna-7b to the downstream tasks, PromptPATE, DP-ICL, and DP-FewShotGen with GPT3 Babbage. We analyze the privacy costs \u03b5 in the range [0, 8] (see corresponding Figure 3 for text generation tasks).", "description": "This figure shows the results of an experiment comparing the performance of different methods for private adaptation of LLMs for classification tasks.  The x-axis represents the privacy cost (epsilon), and the y-axis represents the accuracy achieved.  The figure shows that using PrivateLoRA with an open LLM provides better accuracy at lower privacy costs compared to methods using closed LLMs like PromptPATE, DP-ICL, and DP-FewShotGen. The results for each dataset (SST2, Trec, Mpqa, and Disaster) are shown in separate subfigures.", "section": "4.2 Comparing Performance"}]