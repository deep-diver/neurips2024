[{"figure_path": "fG8TukiXa5/figures/figures_3_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure presents experimental results that offer insights into the utilization patterns of multi-head attention across different layers within a trained transformer model.  Specifically, it shows that multiple heads are utilized and essential in the first layer, while usually only one single head is dominantly utilized for the subsequent layers. This observation suggests that a multi-layer transformer may exhibit a preprocess-then-optimize algorithm on the context examples, a hypothesis that the paper subsequently explores.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_8_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure presents experimental results illustrating the role of multi-head attention in transformer-based in-context learning for sparse linear regression.  Subfigure (a) provides an overview of the experimental setup, including the task, data generation process, and transformer architecture. Subfigures (b), (c), and (d) showcase experimental findings demonstrating how multi-head attention is utilized differently across layers: multiple heads are crucial in the first layer, whereas usually only a single head is dominant in subsequent layers.  The experiments involve varying the number of heads, assessing their importance, and selectively pruning less important heads. These results support the proposed theory that the transformer employs a preprocess-then-optimize algorithm.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_14_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure summarizes the key experimental findings of the paper regarding the role of multi-head attention in transformer models for in-context learning. It shows the performance of transformers with varying numbers of heads and layers on a sparse linear regression task, and also includes the results of head assessment and probing experiments, which shed light on the working mechanisms of the model in different layers.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_14_2.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure presents experimental results on the role of multi-head attention in transformers for in-context learning in a sparse linear regression task. It shows the importance of multiple heads in the first layer, with only one head being predominantly used in subsequent layers. The figure also supports the \"preprocess-then-optimize\" algorithm proposed in the paper by comparing the performance of transformers with varying numbers of heads and layers.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_15_1.jpg", "caption": "Figure 5: Pruning and Probing, 3 layers", "description": "This figure displays the results of pruning and probing experiments on a transformer model with 3 layers.  The experimenters investigated the effects of selectively masking attention heads (pruning) and subsequently using linear probes to evaluate the model's performance.  Specifically, it shows the excess risk across different layers for three scenarios: using all heads, using only the most significant head, and a single-head transformer as baseline. The results are shown for different noise levels. The aim is to support the hypothesis that multi-head attention has different roles across layers, primarily in the first layer for preprocessing data before subsequent layers perform optimization.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_15_2.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure summarizes the key experimental findings of the paper regarding the utilization of multi-head attention in transformers for in-context learning. Subfigure (a) provides an overview of the experimental setup, including the task (sparse linear regression), data generation, transformer architecture, and the insights gained. Subfigure (b) shows the performance of the transformer model with varying numbers of heads and in-context examples. Subfigure (c) presents the assessment of the importance of each head in different layers, showing that multiple heads are crucial in the first layer while a single head dominates in subsequent layers. Finally, Subfigure (d) demonstrates the effect of pruning and probing on the model's performance.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_16_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure summarizes experimental results and insights into the role of multi-head attention in transformers' in-context learning performance for a sparse linear regression task.  Subfigures (a) through (d) show experimental setups, results on varying the number of heads, the relative importance of individual heads across layers, and pruning experiments respectively. These results highlight the distinct pattern of multi-head usage across layers (all heads utilized in the first layer, single dominant head in subsequent layers), suggesting the transformer operates using a two-phase preprocess-then-optimize mechanism.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_16_2.jpg", "caption": "Figure 5: Pruning and Probing, 3 layers", "description": "This figure shows the results of pruning and probing experiments conducted on a transformer model with 3 layers.  The experiments aimed to validate the hypothesis that multi-head transformers utilize heads differently across layers.  The \"pruned\" transformer was modified to keep only the most important head in subsequent layers (layers >1).  The results compare the excess risk of the full model (all heads used) against the pruned model and a single-head model, across varying noise levels and a range of input examples.  The close performance of the full and pruned models supports the hypothesis that only a single head is dominantly used in later layers.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_32_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure presents experimental results on multi-head attention's role in in-context learning for sparse linear regression. Subfigures (a) to (d) illustrate the experimental setup, varying the number of heads and their impact, head importance assessment across layers, and pruning and probing results to analyze the transformer's workings.  The findings indicate differing multi-head utilization patterns across layers, crucial in the first layer, but often singular in subsequent ones.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_33_1.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure presents experimental results illustrating the role of multi-head attention in in-context learning for a sparse linear regression task.  It shows how the utilization of multi-heads varies across layers in a trained transformer model. Subplots visualize the performance with varying heads, head assessment, and the impact of pruning and probing. These findings support the hypothesis that the model utilizes a preprocess-then-optimize approach. ", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}, {"figure_path": "fG8TukiXa5/figures/figures_33_2.jpg", "caption": "Figure 1: Experimental Insights into Multi-head Attention for In-context Learning", "description": "This figure summarizes the key experimental findings regarding the utilization patterns of multi-head attention across different layers of a trained transformer model for a sparse linear regression problem.  It includes subfigures illustrating: (a) An overview of the experimental setup, highlighting the task (in-context sparse linear regression), data generation process, transformer architecture, and the main research insights. (b) Excess risk curves for models with different numbers of heads (h) across increasing numbers of in-context examples, demonstrating the impact of multiple heads on performance. (c) The relative importance of different heads (i-th head) within each layer (i-th layer), illustrating uneven head usage across layers. (d) The performance of a pruned model (where only a single dominant head per layer is retained) compared to the original model, further supporting the hypothesis of different roles for heads in different layers.", "section": "3 Experimental Insights into Multi-head Attention for In-context Learning"}]