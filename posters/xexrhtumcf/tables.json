[{"figure_path": "xeXRhTUmcf/tables/tables_7_1.jpg", "caption": "Table 5.1: Results on FashionMNIST, with MNIST as OOD set. Results marked by are extracted from [23] and (A) are extracted from [27]. Deep Ensembles by [9], Mahalanobis Distance by [13], LL ratio by [23], DUQ by [27].", "description": "This table compares the performance of different methods for out-of-distribution (OOD) detection on the FashionMNIST dataset using MNIST as the OOD dataset.  The table shows the AUROC (Area Under the Receiver Operating Characteristic curve) score for each method.  The characteristics of each method are also listed, including whether it impacts the original model, requires specific model types that are difficult to train, needs to train multiple models or extra generative models.  The LD (Lens Depth) method proposed in the paper is compared to baseline methods, highlighting its non-intrusive nature and superior performance.", "section": "5.2 FashionMNIST vs MNIST"}, {"figure_path": "xeXRhTUmcf/tables/tables_8_1.jpg", "caption": "Table 5.2: Results on CIFAR10 with Tiny-ImageNet, CIFAR100 and SVHN as OOD sets. SN: Spectral Normalisation, JP: Jacobian Penalty.", "description": "This table presents the AUROC scores achieved by different uncertainty quantification methods on the CIFAR10 dataset, using Tiny-ImageNet, CIFAR100, and SVHN as out-of-distribution (OOD) datasets.  The methods compared include the proposed Lens Depth (LD) method, along with several baselines such as GDA, DDU, DUQ, SNGP, Energy-based, and Deep Ensembles.  Different model architectures (ResNet18 and Wide-ResNet-28-10) and training penalties (SN and JP) are also considered. The table highlights the performance of LD against established techniques for OOD detection.", "section": "5.3 CIFAR10 vs SVHN/Tiny-ImageNet/CIFAR100"}, {"figure_path": "xeXRhTUmcf/tables/tables_8_2.jpg", "caption": "Table 5.3: AUROC score with CIFAR100 as ID data and Tiny-ImageNet as OOD data. Results of other methods are extracted from [20] where all the methods were experimented on the same Wide-ResNet-28-10 model.", "description": "This table presents the AUROC (Area Under the Receiver Operating Characteristic curve) scores for out-of-distribution (OOD) detection experiments.  The experiments used CIFAR-100 as the in-distribution (ID) dataset and Tiny-ImageNet as the out-of-distribution (OOD) dataset.  The table compares the performance of the proposed Lens Depth (LD) method against several other state-of-the-art methods, including GDA, DUQ, SNGP, DDU, and an energy-based method. All methods were evaluated using the same Wide-ResNet-28-10 model for fair comparison. The results highlight the competitive performance of the LD method in this challenging OOD detection scenario.", "section": "5.3 CIFAR10 vs SVHN/Tiny-ImageNet/CIFAR100"}, {"figure_path": "xeXRhTUmcf/tables/tables_9_1.jpg", "caption": "Table 5.4: AUROC score for OOD data that are close to ID data", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) scores for out-of-distribution (OOD) detection.  It compares the performance of the proposed Lens Depth (LD) method and the Gaussian Discriminant Analysis (GDA) method. The key difference here is that the OOD data is very similar to the in-distribution (ID) data, obtained by performing a hold-one-out experiment on both MNIST and CIFAR10 datasets. This setup highlights the ability of LD to effectively separate data with similar features compared to the GDA method which uses a Gaussian assumption.", "section": "5.4 On the limitations of the Gaussian assumption: LD vs GDA"}, {"figure_path": "xeXRhTUmcf/tables/tables_16_1.jpg", "caption": "Table G.1: Comparing AUROC performance of strategies for reducing complexity of LD on Fashion-MNIST/MNIST", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) scores achieved by three different strategies to reduce the computational cost of Lens Depth (LD) in out-of-distribution (OOD) detection using the Fashion-MNIST dataset. The three strategies are: I. Random, II. K-Mean/Center, and III. K-Mean/Center+. Each strategy uses a varying number of training examples (500, 1000, and 1500) to compute the LD.  The AUROC is a measure of the classifier's ability to distinguish between in-distribution and out-of-distribution samples.  Higher AUROC values indicate better performance.  The table shows the AUROC for each strategy and the number of training examples used.", "section": "G Effectiveness of Reduced Lens Depth"}]