[{"type": "text", "text": "Variational Multi-scale Representation for Estimating Uncertainty in 3D Gaussian Splatting ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ruiqi Li, Yiu-ming Cheung Department of Computer Science, Hong Kong Baptist University {csrqli, ymc}@comp.hkbu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recently, 3D Gaussian Splatting (3DGS) has become popular in reconstructing dense 3D representations of appearance and geometry. However, the learning pipeline in 3DGS inherently lacks the ability to quantify uncertainty, which is an important factor in applications like robotics mapping and navigation. In this paper, we propose an uncertainty estimation method built upon the Bayesian inference framework. Specifically, we propose a method to build variational multi-scale 3D Gaussians, where we leverage explicit scale information in 3DGS parameters to construct diversified parameter space samples. We develop an offset table technique to draw local multi-scale samples efficiently by offsetting selected attributes and sharing other base attributes. Then, the offset table is learned by variational inference with multi-scale prior. The learned offset posterior can quantify the uncertainty of each individual Gaussian component, and be used in the forward pass to infer the predictive uncertainty. Extensive experimental results on various benchmark datasets show that the proposed method provides well-aligned calibration performance on estimated uncertainty and better rendering quality compared with the previous methods that enable uncertainty quantification with view synthesis. Besides, by leveraging the model parameter uncertainty estimated by our method, we can remove noisy Gaussians automatically, thereby obtaining a high-fidelity part of the reconstructed scene, which is of great help in improving the visual quality. 1 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The radiance field methods [1] for view synthesis have received increasing attention in the past few years due to their capability of achieving photorealistic results. Among them, the recently proposed 3D Gaussian Splatting (3DGS) algorithm [2] has pushed the boundary of real-time view synthesis with prominent quality and efficiency. However, a major functionality deficiency of 3DGS is that it cannot provide uncertainty information regarding the reconstructed model and predictions. Such uncertainty information would be useful in removing the noisy components in the model and providing confidence maps to assess the quality view synthesis results, which is important in applications such as autonomous driving simulation and robotics navigation. ", "page_idx": 0}, {"type": "text", "text": "Previous works in view synthesis made attempts to quantify the uncertainty in Neural Radiance Field (NeRF) models via ensemble, variational inference or Laplace\u2019s approximation methods [3, 4, 5, 6]. Although these works demonstrate the ability to quantify the uncertainty with NeRF models, they cannot be directly applied to 3D Gaussian Splatting models, due to the intrinsic difference between the implicit NeRF representation and explicit 3DGS. Furthermore, some prior works deal with the uncertainty in learning models with methods such as Monte-Carlo dropout [7], Deep Ensemble [8] and ", "page_idx": 0}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/8837e664746360450a7a3fdbf23216ab85976174dda045e590f1166438e62bb7.jpg", "img_caption": ["Figure 1: The results of cleaning up an unbounded scene reconstructed with 3DGS using our uncertainty estimation. We remove the Gaussians with large parameter uncertainty, the majority of which are under-reconstructed background. The desk at the center of the scene remains complete even after removing $90\\%$ of the Gaussians. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Subnetwork [9]. A major characteristic of these methods is that they can be seen as the approximation of Bayesian Inference, which estimates the distribution of posterior $p(\\theta|\\mathcal{D})$ and prediction $p(y|\\theta,x)$ , instead of point estimation. ", "page_idx": 1}, {"type": "text", "text": "The methods mentioned above can be seen as inferring the posterior distribution using model space samples. As mentioned in previous works [8, 10, 11], the key objectives for good model space samples are diversity and efficiency. To improve the quality of uncertainty estimation by increasing the diversity, the generated model space samples should explore the potential cases of true posterior as much as possible, which was not achieved in previous work on NeRF uncertainty estimation. Furthermore, although naive methods like ensemble provide good approximations, they require large storage and the computational cost which increase linearly with the number of samples. Thus, on top of diversity, efficiency is another important aspect we focus on when estimating the uncertainty for 3DGS, which means that we should use as few samples of parameters as possible. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we design an uncertainty estimation method for 3DGS by constructing diversified parameter space samples efficiently. Inspired by the Level-of-Detail (LoD) technique used in computer graphics [12, 13] and multi-scale representation widely used in computer vision [14, 15], we propose to investigate the potential of scale information in fitting the scene representation with diversified samples. Specifically, we design a multi-scale variational inference method for 3DGS, which increases the diversity of parameter samples by enforcing them to model local spatial areas with multiple scales. To reduce the number of extra parameters, we design a mechanism that spawns finer multi-scale Gaussians from the base Gaussian, which are heavily involved in the rendering process. Instead of creating actual new Gaussians, we maintain an offset table parameterizing only a subset of attributes and share the remainder with base Gaussian. This can further reduce the number of parameter samples by maintaining only the attributes that contribute to our multi-scale representation. ", "page_idx": 1}, {"type": "text", "text": "Extensive experiments demonstrate the remarkable performance of our method on uncertainty estimation without affecting the rendering quality. We also show that our method provides both accurate posterior and predictive uncertainty estimation. The posterior uncertainty can be utilized directly to remove noisy Gaussians, thanks to the explicit benefti of the 3DGS method. The predictive uncertainty can serve as a confidence map to interpret the synthesized novel views. ", "page_idx": 1}, {"type": "text", "text": "The main contributions of our work are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a multi-scale variational inference framework for uncertainty-aware view synthesis with the 3D Gaussian Splatting algorithm.   \n\u2022 We develop a spawning strategy to create multi-scale representations for 3DGS, and increase the sample diversity and inference efficiency by maintaining an offset table and sharing parameters. ", "page_idx": 1}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/3d61f349ab8583529d2bab23e1bf8645705bc2faab68c6a8065b1d049d854adf.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 2: The comparison between our multi-scale variational inference and other methods. (a) Laplace\u2019s Approximation ftis posterior with normal distribution where the mean equals maximum a posteriori solution $\\theta_{M A P}$ and precision equals fisher information ${\\cal{I}}(\\theta)$ . (b) The ensemble method learns multiple models simultaneously to form the model space samples. (c) Our method builds a multi-scale representation of the scene, where inference is done by sampling the offset distribution and forming finer Gaussians. ", "page_idx": 2}, {"type": "text", "text": "\u2022 We evaluate the accuracy of uncertainty estimation on various benchmarks, and demonstrate the application of the parameter uncertainty in cleaning up noisy components in the scene. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Uncertainty Quantification ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Providing uncertainty together with predictions of learning models is of great use such as interpreting the model output [16, 17] or providing guidance in active data collection [18, 19]. This goal can be achieved by Bayesian learning, which characterizes the predictive distribution and posterior distribution of model parameters with theoretical foundations [20]. One can use Hamiltonian Monte Carlo sampling for Bayesian learning in neural networks [21], which guarantees asymptotic performance. Previous works proposed other approximation methods such as Laplace\u2019s approximation [22]. These methods consider the correlations between parameters, and are known for not requiring further assumption while reducing computations. ", "page_idx": 2}, {"type": "text", "text": "More recent works borrow from regularization techniques such as the dropout method as an approximated Bayesian inference, such as Monte-Carlo DropOut (MCDO) [7], Concrete Dropout [23] and Variational Dropout [24]. Another line of work builds model ensembles from various subsets of data [8, 16], hyperparameters [25] or multiple subnetworks [9, 26] to infer the uncertainty. Some methods also introduce network modulation to form a model ensemble, among which BatchEnsemble [27] learns multiple low-rank weight matrices. Turkoglu et al. [28] introduce a set of linear modulation parameters. Other works focus on extra network components, such as Variational AutoEncoders (VAEs) methods [29] or auxiliary network [30]. ", "page_idx": 2}, {"type": "text", "text": "The commonality of the above methods is that they introduce randomness into the model and draw model space samples. Furthermore, the importance of diversity of model space samples in approximated Bayesian learning is demonstrated in [11, 31]. Unlike the implicit characteristics of neural networks, the parameters of 3DGS have physical meanings that we can handle explicitly. ", "page_idx": 2}, {"type": "text", "text": "For algorithms in the multi-view geometry in computer vision, the uncertainty of camera pose can be estimated from the covariance matrix of the transformation matrix using Monte Carlo methods [32]. In the Simultaneous Localization and Mapping (SLAM) system, the uncertainty can be estimated from the Kalman filter [33]. Our method can be aggregated to a dense SLAM system to provide uncertainty information for optimizing camera pose together with the map. ", "page_idx": 2}, {"type": "text", "text": "2.2 View Synthesis and Radiance Field ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Recently, the radiance field has become popular in 3D vision, which achieves great success in generating photo-realistic images of novel view directions from a set of calibrated images. Early research ", "page_idx": 2}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/8ceb1be8fc7e0052429fd9ce8ce80cd2a80bdbc277b6c2093d334256b7388a17.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 3: The pipeline of our variational multi-scale representation. We spawn base Gaussians, which are the major components in the scene, into multi-scale finer Gaussians. We learn an offset table to perform the spawn operation by offsetting a subset of attributes. The offset table is learned with variational inference with multi-scale prior. The predictive and parameter uncertainty can be inferred from the variational parameters stored in the table. ", "page_idx": 3}, {"type": "text", "text": "developed light field [34] and multiplane images based [35] methods for this task. Building upon previous research on implicit representations [36, 37, 38, 39], NeRF and its variants achieve a successful framework combining volume rendering and positional encoding to synthesize photorealistic novel views [1, 40, 41]. The recently proposed 3DGS [2] explicitly represents the 3D scene with points associated with the Gaussian function. Some works explore potential solutions to the anti-aliasing rendering problem, for example, Turki et al. [42] develop a multi-resolution feature grid, and Yan et al. [43] design a multi-scale Gaussian with level-of-detail. In our work, we propose a variational multi-scale representation for 3DGS by spreading only local deviations to form multi-scale samples of model parameters. ", "page_idx": 3}, {"type": "text", "text": "Some previous works focus on uncertainty estimation for NeRF models. Stochastic NeRF [4] addresses the uncertainty estimation in NeRF models via standard variational inference technique. NeRF Ensembles [6] leverages neural network ensemble technique to quantify the predictive uncertainty. CF-NeRF [5] models the predictive distribution via learning a conditional normalizing flow. ActiveRMAP [44] focuses on the active reconstruction task, and models the predictive uncertainty via entropy of ray density distribution. NeurAR and ActiveNeRF [45, 19] adopt the neural network to output uncertainty values for each pixel and learning with Negative Log-Likelihood loss. ProbNeRF [46] designs a learned variational autoencoder that can generate 3D models from 2D images and uses the Monte Carlo method at inference to provide predictive uncertainty. Bayes\u2019 Ray [3] performs a post-hoc Laplace\u2019s approximation for NeRF to quantify the uncertainty via applying perturbations to spatial points. Compared to the NeRF models, the uncertainty estimation of 3DGS is less discussed. FisherRF [47] design an uncertainty quantification method for 3DGS and apply it to active learning, which adopts Laplace\u2019s approximation to compute the uncertainty from Fisher Information. However, the approximation of posterior uncertainty needs extensive computations of gradient aggregating over the whole training views. In our work, we leverage variational inference to approximate the posterior distribution of parameters. ", "page_idx": 3}, {"type": "text", "text": "3 Proposed Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Preliminaries: Uncertainty Quantification for 3D Gaussian Splatting ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The goal of the view synthesis problem is to generate images from any viewpoint given a set of calibrated input images. NeRF [1] proposes to solve this problem by representing the geometry and appearance of the scene using a learned radiance field $f(\\bar{\\bf x},{\\bf d})\\rightarrow(\\bar{\\bf c},\\sigma)$ , where $\\mathbf{x}$ and $\\mathbf{d}$ represent a spatial point and view direction, c and $\\sigma$ represent the corresponding color and opacity of that point viewing from d. Based on this radiance field representation, 3D Gaussian Splatting algorithm [2] further proposes that the values in the field can be explicitly stored in a set of ellipsoids parameterized by the Gaussian function. The radiance value of each point in the scene $\\mathbf{x}$ is queried from its adjacent ellipsoid from the Gaussian function: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{G}(\\mathbf{p})=\\exp\\left(-\\frac{1}{2}\\left(\\mathbf{x}-\\mathbf{p}\\right)^{\\top}\\Sigma^{-1}\\left(\\mathbf{x}-\\mathbf{p}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{p}$ and $\\Sigma$ are the center and covariance matrix of the ellipsoid. The covariance is further decomposed to rotation $R$ and scale $S$ by $\\Sigma=R S S^{T}R^{T}$ . We referred to each ellipsoid as Gaussian $\\mathcal{G}$ . In the rendering process, each Gaussian component is projected to the image space and transformed into its 2D projections. After that, they are accumulated via alpha blending to form pixel values c in the rendered image: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{c}=\\sum_{n=1}^{N}\\mathbf{c}_{n}\\alpha_{n}\\mathcal{G}_{n}(\\mathbf{x})\\prod_{j=1}^{n-1}\\left(1-\\alpha_{j}\\mathcal{G}_{j}(\\mathbf{x})\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that the rendering process is deterministic. For each Gaussian $\\mathcal{G}$ , its learnable parameters $\\pmb{\\theta}$ are composed of position, color, density $\\alpha$ , and covariance: $\\pmb{\\theta}=\\{\\mathbf{p},\\mathbf{c},\\alpha,S,R\\}$ . The scale $S$ and rotation $R$ are learned respectively and form the covariance matrix $\\Sigma$ in rendering. ", "page_idx": 4}, {"type": "text", "text": "Standard 3D Gaussian Splatting algorithm applies a non-Bayesian approach to train the model with ${\\mathcal{L}}_{1}$ loss function, which can be seen as Maximum Likelihood Estimation (MLE) with the error following Laplace distribution [20]. However, this only performs point estimation which lacks the ability to quantify predictive uncertainty and provide confidence information. ", "page_idx": 4}, {"type": "text", "text": "Previous methods in Bayesian learning provide tools like variational inference and ensemble methods for estimating the predictive uncertainty of models. For example, with ensemble methods, we can train multiple 3DGS models with different data subsets, random seeds or hyperparameters, and compute the variance of their output as the predictive uncertainty. With variational inference methods, the model posterior $p(\\pmb\\theta|\\mathcal D)$ is approximated by a tractable variational distribution $q(\\pmb\\theta)$ , where $\\mathcal{D}$ is the training data. Then, the likelihood of pixel color $p(\\mathbf{c}|x,\\pmb{\\theta})$ at pixel $x$ together with the discrepancy between $p(\\pmb\\theta|\\mathcal D)$ and $q(\\pmb\\theta)$ is optimized. ", "page_idx": 4}, {"type": "text", "text": "3.2 Local Multi-scale 3D Gaussian ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "As discussed in previous works [8, 10, 11], the effectiveness of approximation methods in Bayesian inference highly depends on the diversity of model parameter space samples. With the explicit attributes of 3DGS parameters, we can manipulate the diversity of parameter samples and explore extensively the model parameter space. With more formations of the model representing the scene explored during learning, we can achieve better approximations in inferring the parameter posterior distribution. In the following, we will introduce a practical approach to building a representation with such diversification ability. ", "page_idx": 4}, {"type": "text", "text": "Local Multi-scale Representation. Different from NeRF-based scene representation where the model parameters are the neural network parameters with no explicit meaning, 3D Gaussian models the local area of the spatial scene with attributes describing the geometry and appearance. Therefore, we can perform heterogeneous operations for Gaussian attributes by diversifying the scale of the local Gaussian to increase the performance in approximations. In our local multi-scale 3D Gaussian, we propose to learn scene representations with multiple Gaussian scales to represent a local spatial area. Specifically, we first select Gaussians that contribute more to the representation of the scene, and draw new multi-scale samples that are attached to these Gaussians. The parameters of the new Gaussians are shared or learned with variational inference. Through this strategy, we are able to control the scale variance and achieve diversified model space samples $\\pmb{\\theta}$ in our uncertainty estimation. ", "page_idx": 4}, {"type": "text", "text": "Spawn from Base Gaussians. The pipeline for spawning local multi-scale 3D Gaussians is illustrated in Figure 3. For every fixed step in training, we perform a spawn operation for Gaussians. Specifically, we would like to select the Gaussians with larger scales and more contributions to the scene representation. We refer to them as base Gaussians, which is found by selecting Gaussians whose scale is larger than a threshold, and the average gradient magnitude received together with the opacity is above certain thresholds in the meantime. These base Gaussians are of greater contributions in the scene representation, which can be replaced by a set of Gaussians with various scales alternatively. Thresholding the gradient magnitude filters out trivial Gaussians such as those located in the distant background where they can hardly be seen. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Learn Finer Gaussians via Offset Table. After that, we spawn multi-scale finer Gaussians locally on top of base Gaussians. Instead of creating actual new Gaussians, to reduce the computational cost, we create a table $\\phi$ to store the parameters of offset distribution for $K$ finer Gaussians. We found that some of the attributes of finer Gaussians can be shared as the same as base Gaussians with losing representation ability. We select position $\\mathbf{p}$ , scale $S$ and opacity $\\alpha$ as the attributes maintained in the learned offset table, and the color c and rotation $R$ are shared by the base Gaussian associated. At inference, we apply the sampled offset to the base Gaussian to get the finer Gaussian. For example, the new position $\\mathbf{p}^{*}$ and scale $S^{*}$ after offset are: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{p^{*}}=\\mathbf{p}+\\chi_{\\mathbf{p}};\\qquad S^{*}=S+\\chi_{S},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\chi_{\\mathbf{p}}$ and $\\chi_{S}$ represent position and scale offset values sampled from the offset distribution parameterized by $\\tilde{\\phi}$ . There are total $K$ entries in the offset table $\\phi$ while only $M$ of them are selected randomly with equal probability and averaged to get the final offset distribution parameters $\\begin{array}{r}{\\tilde{\\phi}=\\frac{1}{M}\\sum_{m_{-}}^{M}\\phi(\\dot{i}_{m})}\\end{array}$ , where $i$ represents the index for the selected entries. By doing so, we create a subset of finer Gaussians with multiple scales and select a random mixture of their attribute distribution parameters each time. Therefore, we build a random scale alternative to the original large and significant base Gaussians. For the base Gaussians, the densification, splitting, and cloning operations are performed identically to the convention in [2], and these operations are also performed for the offset table. We will introduce how to learn the offset table with variance in scale using variational inference in the following. ", "page_idx": 5}, {"type": "text", "text": "3.3 Infer the Posterior of the Offset Table ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The offset table to learn contains entries for $K$ finer Gaussians, and the inference process introduces randomness in selecting the $M$ entries that form the final offset distribution parameters. After obtaining these parameters, we perform variational inference for the offset distribution that enforces the finer Gaussains to be multi-scaled by assigning the prior distribution for the offset. We can infer the uncertainty from the distribution of $\\pmb{\\theta}^{*}$ , the parameter after applying the offset. Specifically, to infer the posterior and learn a multi-scale representation, we let $q(\\chi)$ be the variational distribution for offset to approximate the true offset posterior distribution $p(\\chi|\\mathcal{D})$ and minimize the Kullback\u2013Leibler divergence between them: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{d_{K L}\\left[q(\\chi)\\|p(\\chi\\mid\\mathcal{D})\\right]:=\\displaystyle\\int_{\\chi}q(\\chi)\\log\\frac{q(\\chi)}{p(\\chi\\mid\\mathcal{D})}}\\\\ {\\quad\\qquad\\qquad=-\\mathbb{E}_{\\chi\\sim q(\\chi)}\\left[\\log p(\\chi,\\mathcal{D})-\\log q(\\chi)\\right]+\\log p(\\mathcal{D}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $p(\\chi)$ is the prior distribution for offset $\\chi$ . For position offset $\\chi_{\\mathbf{p}}$ and scale offset $\\chi_{S}$ , we assume normal distribution and uniform distribution respectively as the prior. Particularly, to learn multi-scale samples, we assume the offset prior distribution with the following parameters: ", "page_idx": 5}, {"type": "equation", "text": "$$\nq(\\chi_{S})\\sim U(-S_{b a s e}+(1-1/K)S_{b a s e},0);\\quad q(\\chi_{\\mathbf{p}})\\sim\\mathcal{N}(0,\\delta^{2}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $S_{b a s e}$ is the scale of base Gaussian that the finer Gaussian attached, $\\delta^{2}$ is the prior variance for the position offset. The range of scale after offset for a base Gaussian would be $[(1-1/K)S_{b a s e},S_{b a s e}]$ , which means that the scale after offset would vary with the associated base Gaussian. The lower bound of the prior is $(1-1/K)$ times the base Gaussian scale. This design choice ensures that the offset applied to the base Gaussian generates finer Gaussian with a larger scale range as the number of spawned Gaussians decreases, which means that larger diversity in scale is applied when there are fewer spawned Gaussians. Additionally, we choose zero mean value for the ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 The pseudo-code of the training process of our uncertainty-aware 3DGS. ", "page_idx": 6}, {"type": "text", "text": "Input: Images and corresponding camera poses   \nParameter: Maximum training step $T$ ; Spawn interval $t$ ; Threshold $\\tau$   \nOutput: Trained scene representation with parameter $\\pmb{\\theta}$ ; offset table $\\phi$ 1: while step $<T$ do   \n2: if step $\\%\\ t==0$ then   \n3: Select $\\mathcal{G}_{b a s e}=\\{\\mathcal{G}_{n}|\\sum||\\nabla\\pmb\\theta||>\\tau_{\\pmb\\theta},||S_{n}||>\\tau_{S},\\alpha>\\tau_{\\alpha}\\}$   \n4: Spawn $\\mathcal{G}_{b a s e}$ , create  offset table $\\phi=\\{\\phi_{S},~\\phi_{\\mathbf{p}},~\\phi_{\\alpha}\\}$   \n5: Assign prior $p(\\chi)$ for offsets   \n6: end if   \n7: Sample offset $\\chi$ , render image c and compute image loss $\\mathcal{L}_{1},\\mathcal{L}_{S S I M}$   \n8: Compute KL divergence $\\mathcal{L}_{K L}=d_{K L}(p(\\chi|\\mathcal{D})||q(\\chi))$   \n9: Optimize $\\theta,\\phi$ with total loss $\\mathcal{L}=\\mathcal{L}_{1}+\\mathcal{L}_{S S I M}+\\mathcal{L}_{K L}$ ", "page_idx": 6}, {"type": "text", "text": "10: end while ", "page_idx": 6}, {"type": "text", "text": "prior of position offset to enforce that the position lies around the base Gaussian, and the prior of opacity offset is given in the Appendix B. We learn the offset table $\\phi$ and with the reparameterization trick [24]. The total loss function is $\\mathcal{L}_{t o t a l}=\\mathcal{L}_{1}(\\hat{\\mathbf{c}},\\mathbf{c})+\\mathcal{L}_{S S I M}(\\hat{\\mathbf{c}},\\mathbf{c})+d_{K L}\\left[q(\\chi)\\|p(\\chi)\\right]$ , where c\u02c6 is the ground truth of color and $\\mathcal{L}_{S S I M}$ is structural similarity index measure loss introduced in [2]. At inference, predictive distribution is inferred by marginalizing over the offset distribution: ", "page_idx": 6}, {"type": "equation", "text": "$$\np(\\mathbf{c}\\mid x,\\mathcal{D})=\\underset{\\chi\\sim p(x\\mid\\mathcal{D})}{\\mathbb{E}}[p(\\mathbf{c}\\mid x,\\chi)]=\\int p(\\mathbf{c}\\mid x,\\chi)p(\\chi\\mid\\mathcal{D})\\mathrm{d}\\chi,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $p(\\mathbf{c}\\mid x,\\mathcal{D})$ is the color prediction for pixel $x$ . The pseudo-code of our proposer algorithm in shown in Algorithm 1. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate our uncertainty-aware view synthesis technique on multiple real-world scenes. We compare the quantitative metrics for predictive uncertainty by estimating its correlation with the prediction error. Furthermore, we also validate the quality of our posterior uncertainty by removing Gaussians using different uncertainty threshold levels, which is quite practical for cleaning up and removing noisy regions of the scene, as known as floaters [48]. We will first introduce the datasets, metrics and baseline methods we used for evaluation, then the implementation details of our multiscale variational inference algorithm. Finally, we will present quantitative results on uncertainty estimation, view synthesis and qualitative results on floater removal in the following. ", "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Details ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets. We use three datasets for evaluation: i) LF dataset [49] contains in total 8 indoor and outdoor scenes, each containing over 100 images from $360^{\\circ}$ view. Following the same setting with CF-NeRF [5], we use images from selected scenes torch, basket, africa, statue for evaluation. ii) LLFF dataset [34] contains 8 forward-facing and outdoor scenes, each containing 20 to 62 images where the camera positions are arranged in a grid pattern. iii) Mip-NeRF 360 dataset [50] contains 6 outdoor scenes, in each scene more than 200 images are captured in $360^{\\circ}$ view. The scenes in this dataset are unbounded and contain details region like grass fields, which is challenging for reconstruction. We use this dataset to demonstrate the noisy Gaussian removal ability of our method. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Metrics. For evaluating uncertainty estimation quantitatively, we first use the Area Under Sparsification Error (AUSE) with Mean Absolute Error (MAE) error. This metric evaluated the correlation between estimated uncertainty and true MAE error in each rendered view. It reorders the pixels according to the estimated uncertainty and calculates the difference between the reordered MAE array and the original ones. We normalize the error when calculating the difference. Secondly, we use the Negative Log-Likelihood (NLL) as a metric, which measures the likelihood of ground truth in the predictive distribution. This metric can evaluate both uncertainty and image quality at ", "page_idx": 6}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/68dcaa2c4d2e99a8babb81d079e1930289e472715e22de1a79e671981b5d5761.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 4: The visualization of predicted uncertainty map of novel view renderings. Our method demonstrates the best alignment of the uncertainty map with the error map. ", "page_idx": 7}, {"type": "text", "text": "the same time. For image quality evaluation, we use Peak Signal-to-Noise Ratio (PSNR) to estimate the noise level, Structural Similarity Index Measure (SSIM) to measure the structural distortion and Learned Perceptual Image Patch Similarity (LPIPS) to measure the perceptual quality. ", "page_idx": 7}, {"type": "text", "text": "Baseline Methods. i) CF-NeRF [5] enables the uncertainty estimation of NeRF models by modeling latent variables and learning a conditional normalizing flows model. ii) S-NeRF [4] applies Bayesian learning to the NeRF model, and is able to quantify both depth and color uncertainty. iii) Bayes\u2019 Ray [3] constructs a spatial uncertainty field that can add perturbations to the position input of the radiance field and performs Laplace\u2019s approximation. iv) Ensemble GS. In this method, we train 10 3DGS models with different subsets of initialization points from Structure from motion (SfM) [51]. We also use different random seeds for each model. The variance of the predictions between all models is regarded as the predictive uncertainty. ", "page_idx": 7}, {"type": "text", "text": "Implementation Details. We use an AdamW optimizer to update the learnable parameters of our variational multi-scale representation. The learning rate for 3DGS attributes is the same as the original algorithm [2]. We choose to spawn $K=10$ finer Gaussians in the offset table to perform our multi-scale variational inference. The learning rate of the offset table is 0.1 times the learning rate of each attribute. The experiments are performed on a single NVIDIA A100 GPU. ", "page_idx": 7}, {"type": "text", "text": "4.2 Uncertainty Estimation Quality Evaluation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We first evaluate the uncertainty of depth on the LF dataset. The calibration between uncertainty and depth error is quantified by AUSE reported in Table 1. On average, our method achieves performance the best performance. The performance of the ensemble method approaches our method while being superior to other methods. Our method requires much less computational cost compared to the ensemble. In the basket scene, our method largely improves the AUSE metric by 0.9 compared to the second-best ensemble method. ", "page_idx": 7}, {"type": "text", "text": "Furthermore, we evaluate the uncertainty quality of rendered images on the LF and LLFF datasets. In Table 2, we report the AUSE and NLL metrics for rendered images. The NLL is estimated by the multivariate kernel density estimator used in [5]. On the LF dataset, our method shows the best AUSE, and outperforms S-NeRF in both metrics. In terms of NLL, CF-NeRF shows comparable results in aligning the predictive distribution with the ground truth. A plausible reason is that CF-NeRF models radiance distribution which helps improve performance. For the results on the LLFF dataset, our method demonstrates the best performance in terms of the NLL metric. We also largely surpass methods other than ensemble in terms of the AUSE metric. Bayes\u2019 Ray models spatial perturbation; therefore, only depth uncertainty quality is rendered and evaluated for this method. Our method does not offset color attributes directly to maintain efficiency, while still being able to model the uncertainty of predictive color by offsetting other attributes. We also provide visualizations of the predicted uncertainty map shown in Figure 4. Our method aligns well with the prediction error, even in detailed regions with complex scene content and overlapping object parts. ", "page_idx": 7}, {"type": "table", "img_path": "qpeAtfUWOQ/tmp/8a06a6e25788361a7b937908d9c22240072dde0291e7d22fa7d5aa21dea3a979.jpg", "table_caption": ["Table 1: The depth uncertainty estimation performance on the LF dataset, quantified by the AUSE with MAE error. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "qpeAtfUWOQ/tmp/8ceae9a7106743f927bae916b5cfe301dc5e8efa487aa29ed498bef62a81a429.jpg", "table_caption": ["Table 2: The performance of novel view rendering and uncertainty estimation on rendered images within the LF and LLFF dataset. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.3 Rendering Quality Evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Apart from the quality of uncertainty, we also compare the quality of synthesized novel views on both LF and LLFF datasets. The results on both datasets demonstrate that our method shows superior image quality. Our method rivals the performance of the ensemble method in rendered image quality, without the need to learn an extensive number of additional parameters for Spherical Harmonics (SH) coefficients that store radiance information. In the LF dataset, our method shows the best quality in terms of SSIM. ", "page_idx": 8}, {"type": "text", "text": "We provide rendered images of the flower scene in Figure 4. Our method reconstructs the scene with clear details. The error pixels of the rendered image are located mainly in the region near the edge of the objects in the scene. A possible reason is that the slight error in the camera pose estimated by SfM can cause discrepancies between the rendered image and the ground truth. Some other error pixels are located on small distant object parts, such as small leaves in the background, which are more difficult to reconstruct. The comparison of rendered images demonstrates that our variational multi-scale representation is capable of providing the extra functionality of uncertainty estimation while maintaining the performance of reconstructing various kinds of scenes with high fidelity. ", "page_idx": 8}, {"type": "text", "text": "4.4 Removing Noisy Floaters with Posterior Uncertainty ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "When reconstructing unbounded scenes such as those in Mip-NeRF 360, the training camera trajectories are around the foreground object. Therefore, insufficient information regarding the background is contained in the collected images, and the geometry of the distant background object is hardly reconstructed. As a result, the generalization ability over novel views on those regions is poor, and moving testing cameras away from the training trajectory leads to significant drops in visual quality. In order to obtain a high-fidelity radiance field, one can remove these noisy Gaussians manually with editing tools. However, this requires a large amount of human labor. ", "page_idx": 8}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/48e2190f782293048ce85eece4ac164523dd2e3c5e7717c0cad1d94d2e8d421a.jpg", "img_caption": ["Figure 5: The results of noisy Gaussian removal on Mip-NeRF 360 scenes. By gradually deleting the Gaussians with large posterior uncertainty, our method removes the blurred floaters. The object of interest remains complete after the clean-up. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Our uncertainty estimation can be used to automatically remove floaters by deleting Gaussians where their parameters have relatively large posterior uncertainty estimated. The results of floater removal are shown in Figure 5. We retain $50\\%$ and $30\\%$ of the Gaussians with smaller posterior uncertainty in their parameters. Viewing from a distant camera, the novel view of the background scene fails to be synthesized due to the lack of the multi-view supervision signal. With the increasing number of removed Gaussians, the noisy Gaussians with large scale and irregular covariance in the background are removed gradually. After removing $70\\%$ of the Gaussians in the scene, the floaters in the background scene are mostly elliminated while leaving the clear Gaussians that capture the complete object of interest. By using our method, we can obtain clear foreground objects for further editing and presenting in VR/AR scenes. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we have proposed a probabilistic framework to address the uncertainty estimation problem in the 3D Gaussian Splatting algorithm. Different from previous work, we have discovered the merits of building multi-scale presentations to enhance the diversity of parameter space samples when performing Bayesian inference. Our method improves the efficiency of variational inference by parameter sharing and sampling only a subset of attributes of the model. Experimental results have demonstrated the accuracy of our method in uncertainty estimation and its effectiveness in removing floaters. The potential usage of our method can be further explored, such as quality assessment of 3DGS scenes, robotics navigation and guided interactive active data acquisition. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported in part by the NSFC / Research Grants Council (RGC) Joint Research Scheme under the grant: N_HKBU214/21, and the RGC Senior Research Fellow Scheme under the grant: SRFS2324-2S02. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. In European Conference on Computer Vision, pages 405\u2013421. Springer, 2020.   \n[2] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk\u00fchler, and George Drettakis. 3d gaussian splatting for real-time radiance field rendering. ACM Transactions on Graphics, 42(4), 2023.   \n[3] Lily Goli, Cody Reading, Silvia Sell\u00e1n, Alec Jacobson, and Andrea Tagliasacchi. Bayes\u2019 rays: Uncertainty quantification for neural radiance fields. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 20061\u201320070, 2024.   \n[4] Jianxiong Shen, Adria Ruiz, Antonio Agudo, and Francesc Moreno-Noguer. Stochastic neural radiance fields: Quantifying uncertainty in implicit 3d representations. In 2021 International Conference on 3D Vision, pages 972\u2013981. IEEE, 2021.   \n[5] Jianxiong Shen, Antonio Agudo, Francesc Moreno-Noguer, and Adria Ruiz. Conditional-flow nerf: Accurate 3d modelling with reliable uncertainty quantification. In European Conference on Computer Vision, pages 540\u2013557. Springer, 2022.   \n[6] Niko S\u00fcnderhauf, Jad Abou-Chakra, and Dimity Miller. Density-aware nerf ensembles: Quantifying predictive uncertainty in neural radiance fields. In 2023 IEEE International Conference on Robotics and Automation, pages 9370\u20139376. IEEE, 2023.   \n[7] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In International Conference on Machine Learning, pages 1050\u20131059. PMLR, 2016.   \n[8] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.   \n[9] Erik Daxberger, Eric Nalisnick, James U Allingham, Javier Antor\u00e1n, and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Bayesian deep learning via subnetwork inference. In International Conference on Machine Learning, pages 2510\u20132521. PMLR, 2021.   \n[10] Andrew G Wilson and Pavel Izmailov. Bayesian deep learning and a probabilistic perspective of generalization. Advances in neural information processing systems, 33:4697\u20134708, 2020.   \n[11] Danny Wood, Tingting Mu, Andrew M Webb, Henry WJ Reeve, Mikel Lujan, and Gavin Brown. A unified theory of diversity in ensemble learning. Journal of Machine Learning Research, 24(359):1\u201349, 2023.   \n[12] James H Clark. Hierarchical geometric models for visible surface algorithms. Communications of the ACM, 19(10):547\u2013554, 1976.   \n[13] Michael Garland. Multiresolution Modeling: Survey and Future Opportunities. In Eurographics 1999 - STARs. Eurographics Association, 1999.   \n[14] Shang-Hua Gao, Ming-Ming Cheng, Kai Zhao, Xin-Yu Zhang, Ming-Hsuan Yang, and Philip Torr. Res2net: A new multi-scale backbone architecture. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(2):652\u2013662, 2019.   \n[15] David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60:91\u2013110, 2004.   \n[16] Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, and Balaji Lakshminarayanan. Simple and principled uncertainty estimation with deterministic deep learning via distance awareness. Advances in neural information processing systems, 33:7498\u20137512, 2020.   \n[17] Joost Van Amersfoort, Lewis Smith, Yee Whye Teh, and Yarin Gal. Uncertainty estimation using a single deep deterministic neural network. In International Conference on Machine Learning, pages 9690\u20139700. PMLR, 2020.   \n[18] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data. In International Conference on Machine Learning, pages 1183\u20131192. PMLR, 2017.   \n[19] Xuran Pan, Zihang Lai, Shiji Song, and Gao Huang. Activenerf: Learning where to see with uncertainty estimation. In European Conference on Computer Vision, pages 230\u2013246. Springer, 2022.   \n[20] Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Springer, 2006.   \n[21] Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business Media, 2012.   \n[22] David JC MacKay. A practical bayesian framework for backpropagation networks. Neural computation, 4(3):448\u2013472, 1992.   \n[23] Yarin Gal, Jiri Hron, and Alex Kendall. Concrete dropout. Advances in neural information processing systems, 30, 2017.   \n[24] Durk P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. Advances in neural information processing systems, 28, 2015.   \n[25] Florian Wenzel, Jasper Snoek, Dustin Tran, and Rodolphe Jenatton. Hyperparameter ensembles for robustness and uncertainty quantification. Advances in neural information processing systems, 33:6514\u20136527, 2020.   \n[26] Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew Mingbo Dai, and Dustin Tran. Training independent subnetworks for robust prediction. In 9th International Conference on Learning Representations, 2021.   \n[27] Yeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: Efficient ensemble of deep neural networks via rank-1 perturbation. In Advances in neural information processing systems Workshop, 2019.   \n[28] Mehmet Ozgur Turkoglu, Alexander Becker, H\u00fcseyin Anil G\u00fcnd\u00fcz, Mina Rezaei, Bernd Bischl, Rodrigo Caye Daudt, Stefano D\u2019Aronco, Jan Wegner, and Konrad Schindler. Film-ensemble: probabilistic deep learning via feature-wise linear modulation. Advances in neural information processing systems, 35:22229\u201322242, 2022.   \n[29] Gianni Franchi, Andrei Bursuc, Emanuel Aldea, S\u00e9verine Dubuisson, and Isabelle Bloch. Encoding the latent posterior of bayesian neural networks for uncertainty quantification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.   \n[30] Ziyi Huang, Henry Lam, and Haofeng Zhang. Efficient uncertainty quantification and reduction for over-parameterized neural networks. Advances in neural information processing systems, 36, 2024.   \n[31] Taiga Abe, Estefany Kelly Buchanan, Geoff Pleiss, Richard Zemel, and John P Cunningham. Deep ensembles work, but are they necessary? Advances in neural information processing systems, 35:33646\u201333660, 2022.   \n[32] Richard Hartley and Andrew Zisserman. Multiple view geometry in computer vision. Cambridge university press, 2003.   \n[33] Sebastian Thrun. Probabilistic robotics. Communications of the ACM, 45(3):52\u201357, 2002.   \n[34] Ben Mildenhall, Pratul P Srinivasan, Rodrigo Ortiz-Cayon, Nima Khademi Kalantari, Ravi Ramamoorthi, Ren $\\mathrm{Ng}$ , and Abhishek Kar. Local light field fusion: Practical view synthesis with prescriptive sampling guidelines. ACM Transactions on Graphics, 38(4):1\u201314, 2019.   \n[35] Richard Tucker and Noah Snavely. Single-view view synthesis with multiplane images. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 551\u2013560, 2020.   \n[36] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Volume rendering of neural implicit surfaces. Advances in neural information processing systems, 34:4805\u20134815, 2021.   \n[37] Ziyuan Luo, Boxin Shi, Haoliang Li, and Renjie Wan. Imaging interiors: An implicit solution to electromagnetic inverse scattering problems. In European Conference on Computer Vision, 2024.   \n[38] Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. Advances in neural information processing systems, 33:7462\u20137473, 2020.   \n[39] Vincent Sitzmann, Michael Zollh\u00f6fer, and Gordon Wetzstein. Scene representation networks: Continuous 3d-structure-aware neural scene representations. Advances in neural information processing systems, 32, 2019.   \n[40] Qi Song, Ziyuan Luo, Ka Chun Cheung, Simon See, and Renjie Wan. Protecting nerfs\u2019 copyright via plug-and-play watermarking base model. In European Conference on Computer Vision, 2024.   \n[41] Xiufeng Huang, Ka Chun Cheung, Simon See, and Renjie Wan. Geometrysticker: Enabling ownership claim of recolorized neural radiance fields. In European Conference on Computer Vision, 2024.   \n[42] Haithem Turki, Michael Zollh\u00f6fer, Christian Richardt, and Deva Ramanan. Pynerf: Pyramidal neural radiance fields. Advances in neural information processing systems, 36, 2024.   \n[43] Zhiwen Yan, Weng Fei Low, Yu Chen, and Gim Hee Lee. Multi-scale 3d gaussian splatting for anti-aliased rendering. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 20923\u201320931, 2024.   \n[44] Huangying Zhan, Jiyang Zheng, Yi Xu, Ian Reid, and Hamid Rezatofighi. Activermap: Radiance field for active mapping and planning. arXiv preprint arXiv:2211.12656, 2022.   \n[45] Yunlong Ran, Jing Zeng, Shibo He, Jiming Chen, Lincheng Li, Yingfeng Chen, Gimhee Lee, and Qi Ye. Neurar: Neural uncertainty for autonomous 3d reconstruction with implicit neural representations. IEEE Robotics and Automation Letters, 8(2):1125\u20131132, 2023.   \n[46] Matthew D Hoffman, Tuan Anh Le, Pavel Sountsov, Christopher Suter, Ben Lee, Vikash K Mansinghka, and Rif A Saurous. Probnerf: Uncertainty-aware inference of 3d shapes from 2d images. In International Conference on Artificial Intelligence and Statistics, pages 10425\u201310444. PMLR, 2023.   \n[47] Wen Jiang, Boshu Lei, and Kostas Daniilidis. Fisherrf: Active view selection and uncertainty quantification for radiance fields using fisher information. arXiv preprint arXiv:2311.17874, 2023.   \n[48] Frederik Warburg, Ethan Weber, Matthew Tancik, Aleksander Holynski, and Angjoo Kanazawa. Nerfbusters: Removing ghostly artifacts from casually captured nerfs. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 18120\u201318130, October 2023.   \n[49] Kaan Y\u00fccer, Alexander Sorkine-Hornung, Oliver Wang, and Olga Sorkine-Hornung. Efficient 3d object segmentation from densely sampled light fields with applications to 3d reconstruction. ACM Transactions on Graphics, 35(3):1\u201315, 2016.   \n[50] Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P Srinivasan, and Peter Hedman. Mipnerf 360: Unbounded anti-aliased neural radiance fields. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5470\u20135479, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "[51] Johannes L Schonberger and Jan-Michael Frahm. Structure-from-motion revisited. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4104\u20134113, 2016. ", "page_idx": 13}, {"type": "text", "text": "A Optimizing Variational Inference Objectives ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Section 3.3, we have leveraged the KL-divergence as the optimization goal of the multi-scale offset table with variational inference. However, the objective given by KL-divergence is intractable. Therefore, we have to further transform the objective as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{d_{K L}\\left[q_{\\phi}(\\chi)\\|p(\\chi\\mid\\mathcal{D})\\right]:=\\int_{\\mathcal{X}}q_{\\phi}(\\chi)\\log\\frac{q_{\\phi}(\\chi)}{p(\\chi\\mid\\mathcal{D})}}}\\\\ &{}&{=\\mathbb{E}_{q_{\\chi}(\\chi)}\\left[\\log q_{\\phi}(\\chi)-\\log p(\\chi\\mid\\mathcal{D})\\right]}\\\\ &{}&{=\\mathbb{E}_{q_{\\phi}(\\chi)}\\left[\\log q_{\\phi}(\\chi)\\right]-\\mathbb{E}_{q_{\\phi}(\\chi)}[\\log p(\\chi,\\mathcal{D})-\\log p(D)]}\\\\ &{}&{=\\mathbb{E}_{q_{\\phi}(\\chi)}\\left[\\log q_{\\phi}(\\chi)-\\log p(\\chi,\\mathcal{D})\\right]+\\log p(\\mathcal{D}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\phi$ is the parameter of variational distribution, which we stored in the offset. We can transform this objective to the Evidence Lower BOund (ELBO) by considering only the expectation part, and taking the expectation of the term over the data distribution $\\mathcal{D}$ . This yields a tractable optimization objective to maximize as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{L}(\\phi)=\\mathbb{E}_{\\mathcal{D},q_{\\phi}(\\boldsymbol{\\chi})}\\left[\\log p(\\boldsymbol{\\chi},\\mathcal{D})-\\log q_{\\phi}(\\boldsymbol{\\chi})\\right]}\\\\ &{\\qquad=\\mathbb{E}_{\\mathcal{D},q_{\\phi}(\\boldsymbol{\\chi})}\\left[\\log p(\\mathcal{D}|\\boldsymbol{\\chi})+\\log p(\\boldsymbol{\\chi})-\\log q_{\\phi}(\\boldsymbol{\\chi})\\right]}\\\\ &{\\qquad=\\mathbb{E}_{\\boldsymbol{x},\\hat{\\mathbf{c}}}\\left[\\mathbb{E}_{\\boldsymbol{\\chi}\\sim q_{\\phi}(\\boldsymbol{\\chi})}\\left[\\log p(\\hat{\\mathbf{c}}=\\mathbf{c}\\mid\\boldsymbol{x},\\boldsymbol{\\chi})-d_{K L}(q(\\boldsymbol{\\chi})||p(\\boldsymbol{\\chi}))\\right]\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\log p(\\hat{\\mathbf{c}}=\\mathbf{c}\\mid x,\\chi)$ is the log-likelihood of ground truth color, $p(\\chi)$ is our multi-scale prior distribution, $q(\\chi)$ is the variational distribution. In our method, we assume Laplace distribution for the predictive variable $\\mathbf{c}$ , then in practice the loss function to optimize the prediction is the ${\\mathcal{L}}_{1}$ loss function. ", "page_idx": 14}, {"type": "text", "text": "B Prior Distribution of Opacity Offset ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To get the opacity offset $\\chi_{\\alpha}$ , we first sample $\\eta$ from the normal distribution, whose parameters are learned and stored in the offset table $\\phi$ . Then, we apply a mapping using sigmoid function with temperature $\\kappa$ to get the opacity offset $\\chi_{\\alpha}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\chi_{\\alpha}=\\frac{1}{1+e^{-\\kappa\\cdot\\eta}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The offset $\\chi_{\\alpha}$ is applied to opacity $\\alpha$ by multiplication: $\\alpha^{*}=\\alpha\\cdot\\chi_{\\alpha}$ . To derive the prior distribution for the offset $\\chi_{\\alpha}$ , one can use the change of variable technique. Firstly, the inverse transformation from $\\chi_{\\alpha}$ to $\\eta$ is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\eta=\\frac{1}{\\kappa}\\ln\\left(\\frac{\\chi_{\\alpha}}{1-\\chi_{\\alpha}}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The Probability Density Function (PDF) of $\\eta$ is given by the normal distribution: ", "page_idx": 14}, {"type": "equation", "text": "$$\np(\\eta)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\mu$ and $\\sigma$ are the parameters for normal distribution. Using the change of variables formula, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{p(\\chi_{\\alpha})=p(\\eta)\\left|\\frac{d\\eta}{d\\chi_{\\alpha}}\\right|\\ }}\\\\ {{\\ \\ \\ \\ \\ \\ \\ =\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-\\frac{\\left(\\frac{1}{\\kappa}\\ln\\left(\\frac{\\chi_{\\alpha}}{1-\\chi_{\\alpha}}\\right)-\\mu\\right)^{2}}{2\\sigma^{2}}\\,\\left|\\frac{1}{\\kappa\\cdot\\chi_{\\alpha}\\left(1-\\chi_{\\alpha}\\right)}\\right|\\,.}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The Cumulative Distribution Function (CDF) of opacity offset prior $\\chi_{\\alpha}$ is shown in Figure 6. The intuition for this offset prior is that we want to apply a small perturbation to the opacity in the variational inference. As shown in the CDF, with a positive $\\mu$ , the odds of offset $\\chi_{\\alpha}$ approaching 1 are high. Also, the sigmoid function is numerically stable in optimization. For computational simplicity, we minimize the KL divergence between the variational distribution and prior of $\\eta$ , instead of $\\chi_{\\alpha}$ . ", "page_idx": 15}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/defc2d027aa9e3881f430ae4e4cef29948edd85a5a58f539915e433e025e5030.jpg", "img_caption": ["Cumulative Distribution Function (CDF) of Opacity Offset ", "Figure 6: The Cumulative Distribution Function (CDF) of opacity offset prior. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "C Rendering Time Analysis ", "text_level": 1, "page_idx": 15}, {"type": "table", "img_path": "qpeAtfUWOQ/tmp/246249cd2021b9dcd2ea794323bb70c0ed10bffe9882287cafa9faf1a8796810.jpg", "table_caption": ["Table 3: Inference time for variants of our method and the ensemble method. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "The time for inferring a frame using our method compared with the ensemble method is shown in Table 3. We test on torch scene in the LF dataset with a single NVIDIA A100 GPU, and takes the average time of $1,000$ frames. $\\mathrm{Ours}_{f u l l}$ mean offset with all attributes, $\\mathrm{Ours}_{\\mathbf{p},S,\\mathbf{c}}$ mean offset with position, scaling and color. $\\mathrm{Ours}_{\\mathbf{p},S,\\alpha}$ mean offset with position, scale and opacity, which is the setting of our main experiments. The running time shows that our design choice can achieve the lowest inference time. ", "page_idx": 15}, {"type": "text", "text": "D Active Learning Experiments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In active data acquisition of 3DGS, image collection and the 3DGS model training are performed alternately. Our goal is to maximize the model quality with the same number of images used. At each image collection step, the most informative image is selected via an acquisition function, in our case the uncertainty of the rendered image. By using our uncertainty estimation method as the acquisition function, we can indicating where the model is uncertain about and acquiring more data around there. ", "page_idx": 15}, {"type": "text", "text": "We perform a simple experiment on active data acquisition of 3DGS on the LLFF dataset. Specifically, the original training dataset serves as the candidate image pool, and $10\\%$ of images are randomly chosen for training initially. Then, one image is chosen for every 500 steps until in total $30\\%$ of images are used. We render our uncertainty map and aggregate the pixel values to choose the most uncertain image from the pool as the next image added to the training set. After all images are chosen, the 3DGS model is further trained for 7K steps. The densification interval is 100 steps, and the spawning interval is 500 steps, and both operations are performed until training ends. As shown in Table 4, we found that the view synthesis quality of active 3DGS with our uncertainty estimation is better than choosing images randomly. As the experiment setting for active learning is intricate, we prefer to fully investigate the application of our uncertainty estimation on active learning, which is a limitation of this paper. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Table 4: The experiment on active learning with our uncertainty estimation. ", "page_idx": 16}, {"type": "table", "img_path": "qpeAtfUWOQ/tmp/56dc10d02e7b132694b1f8ae84177dab8b23710f70cd3bd775d58d51a0b7ea28.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "E Ablation Study on the Number of Spawned Gaussian ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We compare the view synthesis and uncertainty estimation performance using $K\\in{1,5,10}$ number of finer-level Gaussians spawned in the offset table. We train on all 8 scenes in the LLFF dataset and report the average results in Table 5. We found that improving the number of finer-level Gaussians $K$ shows a notable increase in the quality of uncertainty estimation. More finer level Gaussians improve the sample space diversity, therefore providing precise estimation of model parameter uncertainty and novel views. ", "page_idx": 16}, {"type": "table", "img_path": "qpeAtfUWOQ/tmp/8f3e3fd1acf695d9af19777a67c8537ebd9a047823ec4750b5a99f2b92b11072.jpg", "table_caption": ["Table 5: Ablation study on the number of spawned Gaussians. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "F Addtional Visualization ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Additional visualization results of view synthesis and uncertainty estimation of rendered images on scenes from the LLFF dataset using our method are provided in Figure 7. ", "page_idx": 16}, {"type": "image", "img_path": "qpeAtfUWOQ/tmp/06d3144c7501e48d1063a6a8841aed373d04f08b95ed1692b33dacd950301e3e.jpg", "img_caption": ["Figure 7: Addtional visualization results. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 18}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 18}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 18}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 18}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 18}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 18}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: The contributions are reflected. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The limitations are discussed. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: The proofs are complete. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provided such information. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 19}, {"type": "text", "text": "\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: We will release code once accepted. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ", "page_idx": 20}, {"type": "text", "text": "\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We provided such information. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We provided such information. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] Justification ", "page_idx": 21}, {"type": "text", "text": "Justification: We provided running time of algorithms. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. ", "page_idx": 21}, {"type": "text", "text": "\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We conform this. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: No significant negative impacts. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA]   \nJustification: No new data published.   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We conform that. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: No new assets. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] Justification: No such experiments. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] Justification: No such risks. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]