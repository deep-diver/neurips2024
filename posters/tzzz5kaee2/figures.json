[{"figure_path": "TzzZ5KAEE2/figures/figures_1_1.jpg", "caption": "Figure 1: Left: Image steganography framework: the encoder takes as input the cover image x and a secret binary message m and outputs the steganographic image s. The decoder then estimates m from s. Right: Randomly sampled cover images from the ImageNet dataset before and after optimization using our framework (described in Section 3). These optimized images demonstrate a significantly reduced error ||m \u2013 m|| while maintaining high image quality.", "description": "This figure illustrates the image steganography framework. The left panel shows a basic encoder-decoder structure where a secret message (m) is embedded into a cover image (x) to produce a steganographic image (s). The right panel showcases example images from ImageNet.  It compares randomly selected images with their optimized versions after undergoing the proposed cover selection framework.  The optimized images achieve significantly lower message recovery errors (||m - m||) while maintaining high visual quality.", "section": "3 Methodology"}, {"figure_path": "TzzZ5KAEE2/figures/figures_3_1.jpg", "caption": "Figure 2: DDIM-based cover selection framework overview. The input cover image x0 is first converted to the latent space xT via forward diffusion. Then, guided the message recovery loss, the latent space is fine-tuned, and the updated cover image is generated via the reverse diffusion process. The DDIM model as well as the steganographic encoder-decoder pair are pretrained.", "description": "This figure shows a schematic of the proposed DDIM-based cover selection framework.  The framework starts with an input cover image (x0) that undergoes a forward diffusion process to generate a latent representation (xT). This latent representation is then optimized to minimize the message recovery error, and the optimized latent vector is used in a reverse diffusion process to reconstruct a refined cover image. This refined image is then processed by a pretrained steganographic encoder-decoder pair, and the resulting message recovery error is fed back into the optimization process.  The process leverages pretrained models for both the DDIM and the encoder-decoder.", "section": "3 Methodology"}, {"figure_path": "TzzZ5KAEE2/figures/figures_6_1.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure visualizes the pixel-wise variances and residuals in three color channels (Red, Green, Blue) for a batch of 500 Robin images. The top row displays heatmaps representing the normalized variance of each pixel across the image batch, indicating the variability of pixel intensity.  The bottom row shows heatmaps of the absolute residuals (differences) between the original cover image and the steganographic image produced by the encoder, after the secret message has been embedded. The comparison helps demonstrate the correlation between low-variance pixels and the locations where the message is predominantly hidden by the encoder.  It supports the paper's claim that message embedding mainly occurs in low-variance pixels, a characteristic similar to the waterfilling algorithm.", "section": "4 Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_7_1.jpg", "caption": "Figure 4: Power coefficients Yi for each color channel, calculated using a batch of 500 Robin images.", "description": "This figure shows the results of applying the waterfilling algorithm to the variance of each color channel (red, green, blue) across 500 Robin images from the ImageNet dataset. The waterfilling algorithm is an optimal power allocation strategy for parallel Gaussian channels, assigning higher power to channels with lower variance to maximize the capacity for reliable transmission of information.  The resulting heatmaps illustrate the calculated power coefficients (Yi) for each pixel in each color channel, indicating where higher power would be allocated according to the waterfilling principle. Areas with darker shades represent higher power coefficients, suggesting that these regions (low-variance pixels) are optimal for embedding information. This visual representation directly relates to the paper's claim that their neural steganographic encoder embeds information into low variance pixels.", "section": "4.2 Analogy to waterfilling"}, {"figure_path": "TzzZ5KAEE2/figures/figures_7_2.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure shows the normalized pixel variances and residuals for a batch of 500 \"Robin\" images from the ImageNet dataset. The top row displays heatmaps representing the variance of each pixel across the red, green, and blue color channels.  The bottom row shows corresponding heatmaps of the residuals obtained after applying a pretrained steganographic encoder.  The comparison illustrates the correlation between low-variance pixels and the locations where the encoder predominantly embeds messages, supporting the paper's hypothesis about the encoder's strategy of utilizing low-variance pixels for concealing data.", "section": "4 Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_15_1.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure displays the normalized pixel variances and residuals for the red, green, and blue channels of 500 Robin images from the ImageNet dataset.  The top row shows heatmaps representing the variance of pixel intensities in each channel.  The bottom row displays heatmaps illustrating the residuals after applying a steganographic encoder to the images. The aim is to visually demonstrate the correlation between low-variance pixels and the locations where the steganographic encoder primarily embeds secret messages. Brighter colors indicate higher variance/residuals; darker colors represent lower values.", "section": "4 Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_16_1.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure visualizes the variances (top) and residuals (bottom) of pixel intensities across three color channels (Red, Green, Blue) for 500 Robin images from the ImageNet dataset.  The top row shows heatmaps representing the variance of each pixel.  Higher variance indicates greater variation in intensity within the pixel across all 500 images; lower values mean consistent intensity. The bottom row shows heatmaps of the residuals after applying a steganographic encoder.  The residuals represent the absolute differences between original cover images and their steganographic counterparts.  A high residual means a large change in the pixel intensity during the encoding process. The figure aims to demonstrate a correlation between low-variance pixels and high-magnitude residuals, suggesting that the steganographic encoder preferentially modifies pixels with low variance to embed the secret message. ", "section": "Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_16_2.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure visualizes the variance and residuals of pixel values for the red, green, and blue channels of a batch of 500 Robin images before any optimization is applied. The top row shows heatmaps representing the normalized pixel variances, indicating the variability of pixel intensity across the image. The bottom row shows heatmaps of the residuals, which represent the absolute difference between the original image and a steganographic version of the image after a message is embedded. The correlation between variance and residual magnitude suggests that the steganographic encoder preferentially modifies pixels with low variance, suggesting the effectiveness of targeting low-variance pixels for message embedding.", "section": "4 Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_17_1.jpg", "caption": "Figure 3: Normalized pixel variances (top) and residuals (bottom) calculated across a batch of 500 Robin images for each color channel, before optimization.", "description": "This figure visualizes the pixel-wise variance and residuals for a batch of 500 Robin images from the ImageNet dataset.  The top row shows heatmaps representing the normalized variance for each color channel (red, green, blue). The bottom row shows heatmaps of the residuals, calculated as the absolute difference between the original cover images and their steganographic counterparts. The figure illustrates a strong correlation between low variance pixels and larger residual magnitudes, suggesting that the neural steganographic encoder preferentially hides messages in low-variance regions of the image.", "section": "4 Analysis"}, {"figure_path": "TzzZ5KAEE2/figures/figures_17_2.jpg", "caption": "Figure 10: Generated DDIM cover images for different message payload values.", "description": "This figure shows example images generated using the DDIM-based cover selection framework.  It displays original images and their optimized counterparts for varying payload sizes (1, 2, 3, and 4 bits per pixel). The images are from the CelebA-HQ and AFHQ-Dog datasets, showcasing how the optimization impacts image quality at different bit rates.", "section": "E DDIM sample cover images"}, {"figure_path": "TzzZ5KAEE2/figures/figures_18_1.jpg", "caption": "Figure 11: Covers and their corresponding steganographic images.", "description": "This figure shows four pairs of cover images and their corresponding steganographic images generated using the LISO steganography framework at different bit rates (1, 2, 3, and 4 bits per pixel).  The images are from the CelebA-HQ and AFHQ datasets. The purpose of this figure is to visually demonstrate the effectiveness of the LISO framework in embedding secret messages into cover images while maintaining visual similarity.", "section": "F Sample steganographic images"}, {"figure_path": "TzzZ5KAEE2/figures/figures_19_1.jpg", "caption": "Figure 12: Generated steganographic images: GAN vs DDIM.", "description": "This figure compares the results of generating steganographic images using both GAN and DDIM methods.  It shows that the DDIM method preserves the semantic meaning and structure of the images better than the GAN method. While both methods produce images that are visually similar to the original covers, the GAN method tends to alter the images more significantly, sometimes affecting the semantic meaning of the original image.", "section": "G Sample steganographic images: DDIM vs GAN"}, {"figure_path": "TzzZ5KAEE2/figures/figures_20_1.jpg", "caption": "Figure 13: Image complexity metrics vs error rate", "description": "This figure shows the correlation between image complexity metrics (entropy, edge detection density, compression ratio, and color diversity) and the error rate of the steganographic process. Each subplot shows a scatter plot with one complexity metric on the y-axis and error rate on the x-axis. The plots visualize how these complexity metrics relate to the success of the steganographic process, revealing insights into which image characteristics influence the effectiveness of hiding messages.", "section": "H Image complexity metrics"}, {"figure_path": "TzzZ5KAEE2/figures/figures_20_2.jpg", "caption": "Figure 1: Left: Image steganography framework: the encoder takes as input the cover image x and a secret binary message m and outputs the steganographic image s. The decoder then estimates m from s. Right: Randomly sampled cover images from the ImageNet dataset before and after optimization using our framework (described in Section 3). These optimized images demonstrate a significantly reduced error ||m \u2013 m|| while maintaining high image quality.", "description": "The figure illustrates the image steganography framework where an encoder takes a cover image and a secret message as input, outputs a steganographic image, and a decoder recovers the message. It also shows the results of cover image optimization using the proposed framework. Optimized images significantly reduce the error between original and recovered messages while maintaining high image quality.", "section": "3 Methodology"}]