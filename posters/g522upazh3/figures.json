[{"figure_path": "G522UpazH3/figures/figures_4_1.jpg", "caption": "Figure 1: The visualization of the first-order gradient, the second-order gradient of y = sin x\u00b2. The black stars symbolize the location where the minimum values of y1 and y3 are achieved.", "description": "This figure visualizes the first-order gradient (y1), second-order gradient (y2), and their sum (y3) for the function y = sin(x\u00b2).  It demonstrates that minimizing the first-order gradient (a common approach in flatness-based optimization) doesn't guarantee minimization of the combined gradient (y3), which is relevant to the overall transferability of adversarial examples. The black stars highlight the points where y1 and y3 achieve their minimum values, showing the discrepancy between optimizing for flatness alone versus optimizing for overall transferability.", "section": "4 The Proposed Approach TPA"}, {"figure_path": "G522UpazH3/figures/figures_16_1.jpg", "caption": "Figure 4: We conduct targeted attacks and visualize attention maps of the target model to the resultant adversarial images.", "description": "The figure visualizes attention maps generated by different attack methods (VT, SSA, and TPA) on target model for targeted attack. It demonstrates how attention is shifted by the different attack methods.  The goal is to show how TPA's adversarial examples more effectively distract the model's attention away from the true object, leading to better transferability.", "section": "B.2 Attention Visualization for Targeted Attacks"}, {"figure_path": "G522UpazH3/figures/figures_17_1.jpg", "caption": "Figure 5: The attack effectiveness of TPA with varying \u03bb\u2208 {0.1,0.5,1,5,10},b \u2208 {1, 2, 4, 8, 12, 16},k \u2208 {0.01,0.03, 0.05, 0.07, 0.09}, 0.07,0.09}, \u039d \u2208 {5,10,15,20}. The proxy model is ResNet50. We set e = 8.", "description": "This figure shows the impact of four hyperparameters (\u03bb, b, k, N) on the attack success rate of TPA.  Each subplot shows the attack success rate for different values of a single hyperparameter while keeping the others constant. The results demonstrate how the hyperparameters affect the balance between local effectiveness and transferability, influencing the overall performance of TPA.", "section": "B.3 Impact of Hyperparameters"}, {"figure_path": "G522UpazH3/figures/figures_19_1.jpg", "caption": "Figure 4: We conduct targeted attacks and visualize attention maps of the target model to the resultant adversarial images.", "description": "This figure visualizes attention maps for targeted attacks using four different methods: original image, VT, SSA, and the proposed TPA method. The attention maps show how the target model focuses its attention on different parts of the image after adversarial examples are added.  The goal is to illustrate that TPA more effectively distracts the attention of the target model away from the object of interest.", "section": "B.2 Attention Visualization for Targeted Attacks"}, {"figure_path": "G522UpazH3/figures/figures_20_1.jpg", "caption": "Figure 7: An example for attacking four state-of-the-art search engines.", "description": "This figure visualizes an example of TPA against four state-of-the-art search engines. We observe that search engines fetch high-quality and similar images for normal samples. However, when we input the generated adversarial examples, the quality of retrieved images noticeably deteriorates, particularly in the case of Baidu.", "section": "6 Evaluation in Real World Applications"}]