[{"figure_path": "gktA1Qycj9/tables/tables_6_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed CigTime model against several baseline models on the task of corrective instruction generation for human motion.  The evaluation metrics include both instruction quality (BLEU, ROUGE, METEOR, CLIPScore) and reconstruction accuracy (MPJPE, FID).  The results show that CigTime significantly outperforms all the baselines across all metrics, demonstrating its effectiveness in generating high-quality corrective instructions.", "section": "4 Evaluation"}, {"figure_path": "gktA1Qycj9/tables/tables_7_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed CigTime model against several baselines on the task of corrective instruction generation for human motion.  The baselines include several large language models (LLMs) and motion-language models.  The results are presented in terms of instruction quality metrics (BLEU, ROUGE, METEOR, CLIPScore) and reconstruction accuracy metrics (MPJPE, FID). The table demonstrates that CigTime significantly outperforms all baselines, showcasing its effectiveness in this task.", "section": "4 Evaluation"}, {"figure_path": "gktA1Qycj9/tables/tables_7_2.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed method (CigTime) against various baselines for corrective instruction generation in human motion.  It uses metrics reflecting both the quality of generated instructions (BLEU, ROUGE, METEOR, CLIPScore) and the accuracy of reconstructing target motion (MPJPE, FID).  The results demonstrate a significant improvement of CigTime over the baselines.", "section": "4 Evaluation"}, {"figure_path": "gktA1Qycj9/tables/tables_13_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the proposed method (CigTime) against several baseline methods for corrective instruction generation.  The baselines include large language models (LLMs) like Llama-3-8B, and motion-language models such as MotionGPT.  The comparison uses metrics evaluating both the quality of the generated instructions (BLEU, ROUGE, METEOR, CLIPScore) and the accuracy of reconstructing the target motion based on the generated instructions (MPJPE, FID). The results show CigTime significantly outperforms all baselines across all metrics.", "section": "4 Evaluation"}, {"figure_path": "gktA1Qycj9/tables/tables_14_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed CigTime model against various baseline models for corrective instruction generation.  The baselines include large language models (LLMs) like Llama, Qwen, and Mistral, both with and without LoRA adaptation, and motion-language models like MotionGPT (with and without M2T adaptation).  The comparison is based on instruction quality metrics (BLEU, ROUGE, METEOR, CLIPScore) and reconstruction accuracy metrics (MPJPE, FID). The results show that CigTime significantly outperforms all baselines.", "section": "4.1 Experiment Setup"}, {"figure_path": "gktA1Qycj9/tables/tables_15_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed method, CigTime, against several baselines for corrective instruction generation.  The baselines include large language models (LLMs) such as Llama-3-8B, and motion-language models like MotionGPT. The table presents quantitative results using metrics like BLEU, ROUGE, METEOR, CLIPScore, MPJPE, and FID to evaluate both the quality of the generated instructions and the accuracy of the motion reconstruction after applying those instructions. The results show CigTime significantly outperforms all baselines across all metrics.", "section": "4.1 Experiment Setup"}, {"figure_path": "gktA1Qycj9/tables/tables_16_1.jpg", "caption": "Table 1: Comparison to the Existing Work. We compare our approach against large language (Llama-3-8B, Llama-3-8B-LoRA, Qwen-7B, Mistral-7B) and motion-language (MotionGPT, MotionGPT-M2T) models. We demonstrate that our approach, CigTime outperforms all the baselines by a large margin for corrective instruction generation for human motion.", "description": "This table compares the performance of the proposed CigTime method against several baseline methods for generating corrective instructions for human motion.  The baselines include large language models (LLMs) like Llama-3-8B, and motion-language models such as MotionGPT.  The comparison uses metrics related to instruction quality (BLEU, ROUGE, METEOR, CLIPScore) and reconstruction accuracy (MPJPE, FID) to assess how well each method generates instructions that lead to the desired motion correction.", "section": "4 Evaluation"}]