[{"figure_path": "Po7iQKKT5b/tables/tables_5_1.jpg", "caption": "Table 1: Model performances for the i.i.d. test videos and zero shot to the corresponding random dot stimuli with the same motion patterns. For all motion estimators, the same segmentation network is used to predict the figure-ground segmentation. Results are grouped by the motion estimation model and ordered by the performance on the random dot stimuli.", "description": "This table presents a comparison of various motion estimation models' performance on both original videos and their corresponding random dot stimuli.  It shows the Intersection over Union (IoU) and F-Score metrics for each model, broken down by training dataset and stimulus type (original/random dots). The results highlight the significant difference in zero-shot generalization capabilities between different model types, particularly showcasing the superiority of the neuroscience-inspired motion energy model.", "section": "4.1 Zero-Shot Random Dot Segmentation"}, {"figure_path": "Po7iQKKT5b/tables/tables_7_1.jpg", "caption": "Table 1: Model performances for the i.i.d. test videos and zero shot to the corresponding random dot stimuli with the same motion patterns. For all motion estimators, the same segmentation network is used to predict the figure-ground segmentation. Results are grouped by the motion estimation model and ordered by the performance on the random dot stimuli.", "description": "This table presents a comparison of different motion estimation models' performance on two types of video data: original videos and corresponding random dot stimuli. The random dot stimuli are generated to preserve the motion patterns of the original videos while making the appearance cues uninformative.  The table shows the Intersection over Union (IoU) and F-Score metrics for each model on both datasets, allowing assessment of how well each model generalizes to the zero-shot scenario.  The models are grouped by type (optical flow vs. motion energy) and ordered within each group by their performance on the random dot stimuli, highlighting the best-performing model in this scenario.", "section": "4.1 Zero-Shot Random Dot Segmentation"}, {"figure_path": "Po7iQKKT5b/tables/tables_15_1.jpg", "caption": "Table 1: Model performances for the i.i.d. test videos and zero shot to the corresponding random dot stimuli with the same motion patterns. For all motion estimators, the same segmentation network is used to predict the figure-ground segmentation. Results are grouped by the motion estimation model and ordered by the performance on the random dot stimuli.", "description": "This table presents a comparison of different motion estimation models' performance on two types of video data: original videos and their corresponding random dot stimuli. The random dot stimuli preserve the motion information from the original videos but remove appearance-based cues.  The table shows the Intersection over Union (IoU) and F-score for each model on both datasets, revealing the models' ability to generalize zero-shot to motion-only perception. The models are grouped by their architecture and ordered by their performance on the random dot stimuli.", "section": "4.1 Zero-Shot Random Dot Segmentation"}, {"figure_path": "Po7iQKKT5b/tables/tables_16_1.jpg", "caption": "Table 1: Model performances for the i.i.d. test videos and zero shot to the corresponding random dot stimuli with the same motion patterns. For all motion estimators, the same segmentation network is used to predict the figure-ground segmentation. Results are grouped by the motion estimation model and ordered by the performance on the random dot stimuli.", "description": "This table presents a comparison of various motion estimation models (including a neuroscience-inspired motion energy model and several state-of-the-art optical flow models) on two tasks: segmenting moving objects in standard videos and segmenting objects in videos where the appearance is replaced with random dots but the motion patterns are preserved. The table shows that the motion energy model significantly outperforms other models when tested on random-dot stimuli, indicating its ability to generalize to novel visual patterns based on motion information.", "section": "4.1 Zero-Shot Random Dot Segmentation"}, {"figure_path": "Po7iQKKT5b/tables/tables_16_2.jpg", "caption": "Table 1: Model performances for the i.i.d. test videos and zero shot to the corresponding random dot stimuli with the same motion patterns. For all motion estimators, the same segmentation network is used to predict the figure-ground segmentation. Results are grouped by the motion estimation model and ordered by the performance on the random dot stimuli.", "description": "This table presents a comparison of different motion estimation models' performance on both original videos and their corresponding random dot versions.  The models are categorized by type (e.g., optical flow, motion energy), training dataset, and the resulting Intersection over Union (IoU) and F-score metrics for each.  The table highlights how well each method generalizes to the zero-shot scenario of random dot stimuli, which lack appearance cues, demonstrating which models are capable of human-like generalization based on motion alone.", "section": "4.1 Zero-Shot Random Dot Segmentation"}]