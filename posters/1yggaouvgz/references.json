{"references": [{"fullname_first_author": "I. J. Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-00-00", "reason": "This paper is foundational to the field of adversarial machine learning, introducing the concept of adversarial examples and raising significant concerns about the robustness and reliability of machine learning models."}, {"fullname_first_author": "A. Ilyas", "paper_title": "Adversarial examples are not bugs, they are features", "publication_date": "2019-00-00", "reason": "This paper proposes the 'feature hypothesis', suggesting that adversarial perturbations, while appearing as random noise, contain class-specific features, providing a unified explanation for several puzzling phenomena associated with adversarial examples."}, {"fullname_first_author": "S. Arora", "paper_title": "Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks", "publication_date": "2019-00-00", "reason": "This paper provides a theoretical foundation for understanding generalization in overparameterized neural networks, which is relevant to the analysis of wide two-layer networks in the target paper."}, {"fullname_first_author": "Z. Allen-Zhu", "paper_title": "A convergence theory for deep learning via over-parameterization", "publication_date": "2019-00-00", "reason": "This paper offers a convergence theory for deep learning through over-parameterization, a concept that supports the lazy training regime assumed in the target paper."}, {"fullname_first_author": "S. Kumano", "paper_title": "Theoretical understanding of learning from adversarial perturbations", "publication_date": "2024-00-00", "reason": "This is a closely related work that provides theoretical justifications for perturbation learning, which the target paper builds upon and extends."}]}