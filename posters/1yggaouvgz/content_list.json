[{"type": "text", "text": "Wide Two-Layer Networks can Learn from Adversarial Perturbations ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Soichiro Kumano The University of Tokyo kumano@cvm.t.u-tokyo.ac.jp ", "page_idx": 0}, {"type": "text", "text": "Hiroshi Kera Chiba University, Zuse Institute Berlin kera@chiba-u.jp ", "page_idx": 0}, {"type": "text", "text": "Toshihiko Yamasaki The University of Tokyo yamasaki@cvm.t.u-tokyo.ac.jp ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adversarial examples have raised several open questions, such as why they can deceive classifiers and transfer between different models. A prevailing hypothesis to explain these phenomena suggests that adversarial perturbations appear as random noise but contain class-specific features. This hypothesis is supported by the success of perturbation learning, where classifiers trained solely on adversarial examples and the corresponding incorrect labels generalize well to correctly labeled test data. Although this hypothesis and perturbation learning are effective in explaining intriguing properties of adversarial examples, their solid theoretical foundation is limited. In this study, we theoretically explain the counterintuitive success of perturbation learning. We assume wide two-layer networks and the results hold for any data distribution. We prove that adversarial perturbations contain sufficient class-specific features for networks to generalize from them. Moreover, the predictions of classifiers trained on mislabeled adversarial examples coincide with those of classifiers trained on correctly labeled clean samples. The code is available at https://github.com/s-kumano/perturbation-learning. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adversarial examples [41], which are imperceptibly perturbed inputs designed to deceive machine learning models, have raised significant concerns about the robustness and reliability of these models. Despite their importance, the underlying mechanisms of adversarial examples are not yet fully understood. A prevailing hypothesis to explain the intriguing properties of adversarial examples is the \u201cfeature hypothesis\u201d [22]. This hypothesis posits that adversarial perturbations, while appearing as imperceptible noise to humans, contain class-specific features. The feature hypothesis provides a unified explanation for several puzzling phenomena associated with adversarial examples, such as their ability to deceive classifiers, transferability across models, and so on (cf. Section 2.1). ", "page_idx": 0}, {"type": "text", "text": "Perturbation learning [22] provides empirical evidence supporting the feature hypothesis. In this learning, classifiers are trained solely on adversarial examples that are mislabeled in human perception, yet they demonstrate remarkable generalization to clean test data (Fig. 1). For example, classifiers achieved $77\\%$ accuracy on the correctly labeled clean test dataset of CIFAR-10 [27], even though they ", "page_idx": 0}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/a0e47b0f522dcf6fa9147aa1cd14330f74aba1c2515ddb72fb79d0612acdf051.jpg", "img_caption": ["(Entirely mislabeled) ", "(Correctly labeled) "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: Counterintuitive generalization of perturbation learning.1 A classifier $g$ is trained solely on mislabeled adversarial examples $\\mathcal{D}^{\\mathrm{adv}}:=\\hat{\\{}(\\pmb{x}_{n}^{\\mathrm{adv}},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}$ . These examples ${\\pmb x}_{n}^{\\mathrm{adv}}$ are generated to mislead a classifier $f$ , which is trained on correctly labeled clean samples $\\tilde{\\cal D}:=\\{(x_{n},\\stackrel{\\cdot}{y_{n}})\\}_{n=1}^{N}$ into predicting $y_{n}^{\\mathrm{adv}}\\left(\\ne y_{n}\\right)$ . Surprisingly, despite being trained only on mislabeled data, the classifier $g$ generalizes well to clean test samples. This counterintuitive result suggests that adversarial perturbations contain label-aligned class features, enabling the classifier $g$ to generalize from them. ", "page_idx": 1}, {"type": "text", "text": "were trained on entirely mislabeled adversarial examples (e.g., a cat adversarial image labeled as a bird) [28]. This surprising result suggests that adversarial perturbations encode class-relevant features that enable classifiers to learn meaningful representations. However, despite the empirical support, the theoretical foundations of the feature hypothesis and perturbation learning remain limited. While a recent study [28] provided theoretical justifications, their results rely on stringent assumptions about data distribution, perturbation design, training procedure, and model architectures. ", "page_idx": 1}, {"type": "text", "text": "In this study, we theoretically address the understanding and justification of the feature hypothesis and perturbation learning. First, to support the feature hypothesis, we show that adversarial perturbations, while appearing as random noise, are parallel to the weighted sum of all training samples. This result suggests that a single perturbation derived from a classifier and input can potentially contain information about the entire training dataset. In particular, for some specific cases (e.g., when training samples are mutually orthogonal), perturbations include all training data and labels without loss of information. We then reveal that class features within perturbations enable classifiers to generalize from them. Specifically, under three mild conditions, the predictions of a classifier trained on adversarial perturbations are consistent with those of a classifier trained on correctly labeled clean samples. These three conditions can be interpreted from geometric and quantitative perspectives. Finally, we demonstrate that under similar conditions, the prediction agreement is observed between a classifier trained on mislabeled adversarial examples and one trained on correctly labeled clean samples, justifying the empirical success of perturbation learning. ", "page_idx": 1}, {"type": "text", "text": "Our analysis assumes two-layer neural networks with sufficient width but does not impose any assumptions on data distribution, which is a substantial progress from prior work [28] that considered mutually orthogonal training samples. In addition, our perturbation design, training procedure, activation functions, and bias availability are milder. In short, as shown in Tab. 1, except for the wide width assumption, our analysis requires milder conditions than prior work. Our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We provide a theoretical justification for the feature hypothesis and perturbation learning using wide two-layer neural networks, considering any data distribution and realistic problem settings. Except for the wide width, our assumptions are substantially milder than [28]. \u2022 We demonstrate that adversarial perturbations are parallel to the weighted sum of training samples, suggesting that a single perturbation can potentially contain information about the entire training dataset. This result supports the feature hypothesis. \u2022 We prove that under three mild conditions, the predictions of a classifier trained on perturbations are consistent with those of a classifier trained on correctly labeled clean samples. Moreover, under similar conditions, the prediction agreement between a classifier trained on mislabeled adversarial samples and one trained on clean samples is observed, providing a theoretical justification for the empirical success of perturbation learning. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Feature Hypothesis and Perturbation Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "It has been hypothesized that adversarial perturbations contain class-specific features, although appearing as random noise [22]. This hypothesis, or feature hypothesis, offers a unified explanation for several open questions related to adversarial examples. For example, misclassification by classifiers and transferability across models [21, 41] can be attributed to the response to features within perturbations. Furthermore, according to this hypothesis, adversarially robust models achieve robustness by discarding brittle yet predictive features and focusing on more stable and semantically meaningful features. This interpretation explains the phenomena observed with robust models, such as the trade-off between accuracy and robustness [13, 32, 34, 35, 40, 42, 46, 47], perceptually-aligned gradients [1, 4, 7, 17, 18, 26, 38, 39, 42, 48], and enhanced transfer learning capabilities [1, 12, 37, 43]. ", "page_idx": 2}, {"type": "text", "text": "Perturbation learning1 [22] provides empirical support for the feature hypothesis. In perturbation learning, the dataset appears entirely mislabeled to human perception. However, the hypothesis suggests that adversarial perturbations in the dataset include label-aligned class features. Indeed, it has been observed that classifiers trained through perturbation learning can extract generalizable features from these perturbations and achieve high test accuracy (e.g., $92\\%$ for MNIST [11], $54\\%$ for FashionMNIST [45], and $77\\%$ for CIFAR-10 [27]), empirically justifying the feature hypothesis [22, 28]. ", "page_idx": 2}, {"type": "text", "text": "While the feature hypothesis and perturbation learning are empirically effective in understanding adversarial examples, their theoretical foundations are very limited. Only one recent study [28] theoretically demonstrated that perturbations contain class features and that classifiers can generalize from them. However, their results relied on stringent conditions (e.g., mutually orthogonal training samples), which might not fully explain the success of perturbation learning in diverse settings. ", "page_idx": 2}, {"type": "text", "text": "In this study, for wide two-layer networks, we obtain results equivalent to those in [28] under more relaxed conditions (cf. Section 3.4). We provide the first theoretical justification for the feature hypothesis and perturbation learning under any data distribution and in a mild training setting. ", "page_idx": 2}, {"type": "text", "text": "2.2 Theoretical Framework: Lazy Training ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Theoretical analysis of neural networks is generally challenging due to the non-convex nature of the loss surface. To address this, recent studies have focused on the lazy training regime, where the parameters of neural networks hardly change during training [5, 6, 9, 20, 25, 30, 33, 44, 49]. In this regime, neural networks behave almost linearly around their initialization, simplifying the learning dynamics. One of the key observation in lazy training is that, in wide two-layer neural networks, most derivatives of hidden outputs through (Leaky-) ReLU activation remain constant during training [30], which forms the basis of our theoretical framework (cf. Section 3.3). This observation has been extended to show that the neural tangent kernel remains invariant during training [2, 3, 14, 15, 23, 29]. ", "page_idx": 2}, {"type": "text", "text": "In contrast, the feature learning regime, where parameters move significantly away from their initialization, has been explored in various studies [9, 20, 44]. Prior work on justifying perturbation learning [28] employs the feature learning regime, building on related findings in this area [19, 24, 31]. In our study, we adopt the lazy training regime and relax several conditions assumed in previous work [28] by introducing a wide width assumption (cf. Tab. 1). This adjustment is enabled by differences in the theoretical tools used. ", "page_idx": 2}, {"type": "text", "text": "3 Theoretical Results ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Notation. For $n\\in\\mathbb N$ , let $[n]:=\\{1,\\ldots,n\\}$ . For $z_{1},z_{2}\\in\\mathbb{R}^{d}$ , we denote the Euclidean norm by $\\|z_{1}\\|$ and the inner product by $\\langle z_{1},z_{2}\\rangle$ . Vectors $z_{1}$ and $z_{2}$ are called parallel and are denoted by $z_{1}/z_{2}$ if there exists $C\\in\\mathbb{R}$ such that $z_{1}=C z_{2}$ . Let ${\\mathcal{N}}(\\mu,\\sigma^{2})$ be the Gaussian distribution with mean $\\mu\\in\\mathbb{R}$ and variance $\\sigma^{2}\\geq0$ and $U(S)$ be the uniform distribution on a set ${\\mathcal{S}}\\subset\\mathbb{R}$ . We use $\\Omega(\\,\\cdot\\,),\\Theta(\\,\\cdot\\,)$ , and $O(\\,\\cdot\\,)$ only to hide constant factors, and $\\tilde{\\Omega}(\\,\\cdot\\,),\\tilde{\\Theta}(\\,\\cdot\\,)$ , and $\\tilde{\\mathcal{O}}(\\,\\cdot\\,)$ to hide polylogarithmic factors. ", "page_idx": 2}, {"type": "text", "text": "Table 1: Comparison with existing work [28]. With a wide network assumption, we improve the existing results from the perspective of data distribution, perturbation design, training time, loss function, and network architecture. Note that the non-bias and leaky-ReLU assumptions of [28] are critical for deriving their results. A detailed comparison can be found in Section 3.4. ", "page_idx": 3}, {"type": "table", "img_path": "1YGgaouVgZ/tmp/5d85c2ad0a6aaa053a7255211da81cf18cdd7a3e576f99fc964006756f431468.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "3.1 Problem Setup ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this study, we consider the dynamics of perturbation learning in binary classification problem with a two-layer neural network trained by gradient flow. First, we formally define the perturbation learning framework. The outline of perturbation learning is as follows: (i) train a classifier on correctly labeled clean samples, (ii) create adversarial samples based on the trained classifier, and (iii) train another classifier on the mislabeled adversarial samples. ", "page_idx": 3}, {"type": "text", "text": "Network trained on correctly labeled clean samples. We consider a two-layer neural network $f:$ $\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ . Let $V:=(\\pmb{v}_{1},\\dots,\\pmb{\\dot{v}}_{m})^{\\top}\\in\\mathbb{R}^{m\\times d}$ and $\\bar{\\pmb{a}}:=(a_{1},\\dots,a_{m})^{\\top}\\in\\mathbb{R}^{m}$ be the hidden weight and bias, respectively. We also describe $V:=(V_{i j})_{1\\le i\\le m,1\\le j\\le d}$ . Let $\\pmb{\\alpha}:=(\\alpha_{1},\\dots,\\alpha_{m})^{\\top}\\in\\mathbb{R}^{m}$ be the readout weight. While $V$ and $\\textbf{\\em a}$ are trainable, $_{\\alpha}$ is fixed during training. Denote the trainable parameters by $\\theta_{V,a}:=\\{V,a\\}$ . We initialize $V_{i j}\\sim\\mathcal{N}(0,1/d).$ , $a_{i}\\sim\\mathcal{N}(0,1)$ , and $\\alpha_{i}\\sim\\mathcal{N}(0,1/m)$ for each $i\\,\\in\\,[m]$ and $j~\\in~[d]$ . The activation function is either ReLU or Leaky-ReLU $\\phi({\\boldsymbol{x}}):=$ $\\operatorname*{max}(\\gamma x,x)$ for $\\gamma\\in[0,1)$ . Finally, the network is given by $\\begin{array}{r}{f(x;\\theta_{V,a}):=\\sum_{i=1}^{m}\\bar{\\alpha}_{i}\\phi(\\langle v_{i},\\dot{x}\\rangle+a_{i})}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Network trained on mislabeled adversarial samples. Similarly to $f$ , we define a network trained on mislabeled adversarial samples as $\\begin{array}{r}{g(\\pmb{x};\\pmb{\\theta}_{W,b}):=\\sum_{i=1}^{m}\\beta_{i}\\phi(\\backslash\\pmb{\\omega}_{i},\\pmb{x})+b_{i})}\\end{array}$ . Note that the initializations of $f$ and $g$ are independent. ", "page_idx": 3}, {"type": "text", "text": "Loss function. We consider a differentiable, non-decreasing loss function $\\ell:\\mathbb{R}\\rightarrow\\mathbb{R}$ , satisfying $\\ell^{\\prime}(z)\\,\\geq\\,0$ for any $z\\ \\in\\ \\mathbb{R}$ . Examples of such loss functions include the identity loss $\\ell(z)\\;:=\\;z$ exponential loss $\\ell(z):=\\exp(z)$ , and logistic loss $\\ell(z):=\\ln(1+\\exp(z))$ . ", "page_idx": 3}, {"type": "text", "text": "Training. We here describe the training process of the network $f$ on correctly labeled clean samples. The training of $g$ is similarly defined. Let $\\mathcal{D}:=\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}\\stackrel{\\cdot}{\\subset}\\mathbb{R}^{d}\\times\\{\\pmb{\\pmb{\\pmb{\\mathrm{1}}}}\\}$ be a correctly labeled training dataset. The loss over $\\mathcal{D}$ is defined as $\\begin{array}{r}{\\mathcal{L}(\\pmb{\\theta}_{V,a};\\mathcal{D}):=(1/N)\\sum_{n=1}^{N}\\ell(-y_{n}f(\\pmb{x}_{n};\\pmb{\\theta}_{V,a}))}\\end{array}$ The network parameters are updated by gradient flow $\\mathrm{d}\\theta_{V,a}(t)/\\mathrm{d}t:=-\\;\\partial\\mathscr{L}(\\theta_{V,a}(t);\\mathscr{D})/\\partial\\theta_{V,a}$ where $t\\geq0$ is the training time. We consider $T_{f}>0$ training steps, producing $f(\\,\\cdot\\,;\\theta_{V,a}(T_{f}))$ . For notational simplicity, we write $f(\\,\\cdot\\,;t):=f(\\,\\cdot\\,;\\!\\overline{{\\pmb{\\theta}_{V,a}(t)}})$ . ", "page_idx": 3}, {"type": "text", "text": "Note that we do not consider whether $f(\\,\\cdot\\,;T_{f})$ perfectly classify $\\mathcal{D}$ . We discuss whether the classifier $g$ , trained on adversarial examples crafted via $f(\\,\\cdot\\,;T_{f})$ , can mimic the predictions of $f({}\\cdot{};T_{f})$ . ", "page_idx": 3}, {"type": "text", "text": "Adversarial perturbations. We consider a single-step gradient-based perturbation, which is a common perturbation design [21]. An adversarial example $\\pmb{x}_{n}^{\\mathrm{adv}}\\ \\in\\ \\mathbb{R}^{\\bar{d}}$ and its corresponding adversarial perturbation $r_{n}\\in\\mathbb{R}^{d}$ are defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nx_{n}^{\\mathrm{adv}}:=x_{n}+r_{n},\\qquad\\qquad\\qquad r_{n}:=-\\epsilon\\frac{\\nabla_{x_{n}}\\ell(-y_{n}^{\\mathrm{adv}}f({\\pmb x}_{n};T_{f}))}{\\|\\nabla_{x_{n}}\\ell(-y_{n}^{\\mathrm{adv}}f({\\pmb x}_{n};T_{f}))\\|},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\epsilon>0$ is the perturbation constraint and $y_{n}^{\\mathrm{adv}}\\in\\{\\pm1\\}$ is the target label. The adversarial perturbation ${\\boldsymbol{r}}_{n}$ on ${\\pmb x}_{n}$ is designed to increase $y_{n}^{\\mathrm{adv}}f(x_{n}^{\\mathrm{adv}};T_{f})$ under the constraint $\\lVert\\pmb{r}_{n}\\rVert\\leq\\epsilon$ . ", "page_idx": 3}, {"type": "text", "text": "Mislabeled dataset. We consider two configurations of a dataset $\\mathcal{D}^{\\mathrm{adv}}$ for training $g$ . First, we follow tshuep eorripgoisneadl  poenr tnuartbuartialo ni mleaagrenis,n gi. ea.p, $\\mathbf{\\Theta}^{\\mathrm{{Dadv}}}:=\\{(\\mathbf{x}_{n}^{\\mathrm{{adv}}},y_{n}^{\\mathrm{{adv}}})\\}_{n=1}^{N}$ .r aiTnheids  soent taidnvge rhsealrpisa lt op eurtnudrebrasttiaonnds the prior perturbation learning process. Second, we directly consider learning from perturbations rather than adversarial examples, i.e., $\\smash{\\ensuremath{\\mathcal{D}^{\\mathrm{adv}}}:=\\{(\\ensuremath{\\boldsymbol{r}}_{\\!\\!\\:n},\\ensuremath{\\boldsymbol{y}_{\\!\\!n}^{\\mathrm{adv}}})\\}_{n=1}^{\\!\\!\\!\\sim}}$ )}nN=1. This setting directly addresses the question of whether classifiers can generalize from class features in perturbations. ", "page_idx": 4}, {"type": "text", "text": "Summary. The problem setting is summarized as follows: ", "page_idx": 4}, {"type": "text", "text": "Setting 3.1 (Perturbation learning). Independently initialize $V_{i j}\\sim\\mathcal{N}(0,1/d)$ , $W_{i j}\\sim\\mathcal{N}(0,1/d)$ , $a_{i}\\sim\\tilde{\\mathcal{N}}(0,1),b_{i}\\sim\\mathcal{N}(0,1),\\alpha_{i}\\stackrel{\\_}{\\sim}\\mathcal{N}(0,\\dot{1}/m)$ , and $\\beta_{i}\\sim\\mathcal{N}(0,\\dot{1}/m)$ for each $i\\in[m]$ and $j\\in[d]$ . Train a two-layer neural network $f$ parameterized by $\\theta_{V,a}$ with ( $\\gamma$ -scaled Leaky-) ReLU on a dataset $\\mathbf{\\mathcal{D}}:=\\{(\\mathbf{x}_{n},y_{n})\\}_{n=1}^{N}$ using gradient flow with a loss $\\mathcal{L}(\\theta_{V,a};\\mathcal{D})$ for training time $T_{f}>0$ . Create a dataset $\\mathcal{D}^{\\mathrm{adv}}$ by one of the following procedures with $\\{y_{n}^{\\mathrm{adv}}\\}_{n=1}^{N}\\in\\{\\pm1\\}^{N}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{D}^{\\mathrm{adv}}:=\\{({\\boldsymbol r}_{n},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N},}\\\\ &{\\mathcal{D}^{\\mathrm{adv}}:=\\{({\\boldsymbol x}_{n}^{\\mathrm{adv}},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Train a two-layer neural network $g$ parameterized by $\\theta_{W,b}$ on the dataset $\\mathcal{D}^{\\mathrm{adv}}$ using gradient flow with a loss $\\mathcal{L}(\\theta_{W,b};D^{\\mathrm{adv}})$ for training time $T_{g}>0$ . ", "page_idx": 4}, {"type": "text", "text": "Our interests are (i) the relationship between perceptually-noise-like adversarial perturbations $\\{r_{n}\\}_{n=1}^{N}$ and clean training samples $\\{(x_{n},y_{n})\\}_{n=1}^{N^{\\mathrm{{}}}}$ (cf. Theorem 3.3), and (ii) whether the classifier $g(\\,\\cdot\\,;T_{g})$ trained on the adversarial perturbations or samples $\\mathcal{D}^{\\mathrm{adv}}$ can mimic the predictions of the classifier $f(\\,\\cdot\\,;T_{f})$ trained on the clean samples $\\mathcal{D}$ (cf. Theorems 3.4 and 3.5). ", "page_idx": 4}, {"type": "text", "text": "3.2 Main Results ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For $z_{1},z_{2}\\in\\mathbb{R}^{d}$ , we use $\\Phi(z_{1},z_{2})\\in(\\gamma(1+\\gamma)/2,(1+\\gamma)/2]$ defined as (cf. Lemma C.4): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Phi(z_{1},z_{2}):=\\mathbb{E}_{\\pmb{v}\\sim\\mathcal{N}(0,I/d),a\\sim\\mathcal{N}(0,1)}[\\phi^{\\prime}(\\langle\\pmb{v},z_{1}\\rangle+a)\\phi^{\\prime}(\\langle\\pmb{v},z_{2}\\rangle+a)],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\phi^{\\prime}(x):=\\mathrm{d}\\phi(x)/\\mathrm{d}x$ . First, we introduce an assumption on network width. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.2 (Wide network). Network width $m$ satisfies ", "page_idx": 4}, {"type": "equation", "text": "$$\nm>\\tilde{\\mathcal{O}}\\left(d^{2}\\Bigg\\{\\frac{1}{N}\\sum_{n=1}^{N}\\left(\\int_{0}^{T_{f}}\\ell^{\\prime}(-y_{n}f(x_{n};t))\\,\\mathrm{d}t+\\int_{0}^{T_{g}}\\ell^{\\prime}(-y_{n}^{\\mathrm{adv}}f(x_{n}^{\\prime};t))\\,\\mathrm{d}t\\right)\\Bigg\\}^{2}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{\\Delta}\\mathbf{x}_{n}^{\\prime}\\mathbf{\\Delta}:=\\mathbf{\\Delta}\\mathbf{r}_{n}$ for Scenario (a) and $\\pmb{x}_{n}^{\\prime}:=\\pmb{x}_{n}^{\\mathrm{adv}}$ for Scenario (b) in Setting 3.1. In particular, $m>\\tilde{\\mathcal{O}}(d^{2}(T_{f}+T_{g})^{2})$ for $\\ell(s)=s$ . ", "page_idx": 4}, {"type": "text", "text": "This assumption requires sufficiently large width $m$ that regularizes the variations in parameters and forms the basis of lazy training (cf. Section 3.3). The width is always required to grow with the speed of the squared input dimension $d^{2}$ . The relationship between the width and two training times, $T_{f}$ and $T_{g}$ , depends on the training set $\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ and loss function $\\ell$ . For example, if the training set is easily separable and the loss has an exponential tail, the derivative of the loss function might decrease rapidly with training time $t$ and small $m$ is enough to satisfy the assumption. For the identity loss, $m$ is consistently required to satisfy $\\tilde{\\Omega}(d^{2}(T_{f}+T_{g})^{2})$ . Note that the required values of $T_{f}$ and $T_{g}$ (and the corresponding $m$ ) for a desirable loss value remain an open question in the community. Our experimental results show that $m\\approx100$ is sufficient to verify our theorems for high-dimensional Gaussian distributions. Under this assumption, we consider the direction of the adversarial perturbation. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.3 (Direction of adversarial perturbation). Let $\\delta=\\Theta(1)$ be a small positive number. Under Assumption 3.2, for any $n\\in[N]$ , with probability at least $1-\\delta$ , the adversarial perturbation $r_{n}$ is parallel to the weighted sum of training samples as follows: ", "page_idx": 4}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/15ad235cd6e0df99a0dad720c615329b128bad367555c6ff5964ed7a23aa2155.jpg", "img_caption": ["Figure 2: The regions where Ineqs. (9) and (10) and Eq. (11) hold (colored areas) and their intersection. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\nr_{n}//\\frac{1}{N}\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})x_{k}\\int_{0}^{T_{f}}\\ell^{\\prime}(-y_{k}f(x_{k};t))\\,\\mathrm{d}t+\\xi_{n},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\xi_{n}$ satisfies $\\|\\pmb{\\xi}_{n}\\|=\\tilde{O}(1)$ . In particular, for $\\ell(s)=s,$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\nr_{n}//\\frac{T_{f}}{N}\\sum_{k}^{N}y_{k}\\Phi({\\pmb x}_{n},{\\pmb x}_{k}){\\pmb x}_{k}+{\\pmb\\xi}_{n}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that the confidence level $\\delta$ only logarithmically affects the norm of the remainder term $\\xi_{n}$ . This theorem indicates that the direction of a single perturbation can be represented as the weighted sum of $y_{k}\\mathbf{x}_{k}$ and remainder term $\\xi_{n}$ . Interestingly, this result suggests that a single perturbation derived from a classifier and sample can potentially contain information about the entire training dataset $\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ . Particularly, in some cases (e.g., training samples are mutually orthogonal), $y_{k}\\mathbf{x}_{k}$ are not cancelled out by each other, and thus the single perturbation ${\\boldsymbol{r}}_{n}$ contains all training data and labels without loss of information.2 These results theoretically support the feature hypothesis. Consider the case with the identity loss. While the norm of the first term is ${\\mathcal{O}}(T_{f}{\\sqrt{d}})$ , the norm of the remainder is constrained to $\\tilde{\\mathcal{O}}(1)$ , suggesting that larger training time $T_{f}$ and input dimension $d$ strengthen the alignment between the perturbation and weighted sum. ", "page_idx": 5}, {"type": "text", "text": "Then, we consider the learning solely from these perturbations. The following theorem is a special case of Theorem D.17, which addresses a broader loss class and any sampling of $y_{n}^{\\mathrm{adv}}\\in\\{\\pm1\\}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.4 (Perturbation learning, Scenario (a), special case of Theorem D.17). Consider Scenario (a) in Setting 3.1. Assume $\\ell(s)=s$ and $y_{n}^{\\mathrm{adv}}\\sim U(\\{\\pm1\\})$ for every $n\\in[N]$ . Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{f}(z):=\\frac{1}{N}\\sum_{n=1}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle,\\quad\\hat{g}_{a}(z):=\\frac{1}{N^{2}}\\sum_{n=1}^{N}\\Phi(r_{n},z)\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , $i f$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\mathrm{(Functional~margin~condition~1)}\\quad}&&{|\\hat{f}(z)|>\\tilde{\\mathcal{O}}\\bigg(1+\\frac{1}{T_{f}}\\bigg),}\\\\ &{\\mathrm{(Functional~margin~condition~2)}\\quad}&&{|\\hat{g}_{a}(z)|>\\tilde{\\mathcal{O}}\\bigg(\\displaystyle\\frac{1}{T_{f}}+\\frac{\\sqrt{d}}{\\epsilon}\\bigg(\\frac{1}{T_{g}}+\\frac{1}{\\sqrt{N}}\\bigg)\\bigg),}\\\\ &{\\mathrm{(Agreement~condition~})\\quad}&&{\\mathrm{sgn}(\\hat{f}(z))=\\mathrm{sgn}(\\hat{g}_{a}(z)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "then, with probability at least $1-\\delta$ , $\\operatorname{sgn}(f(z;T_{f}))=\\operatorname{sgn}(g(z;T_{g}))$ holds. ", "page_idx": 5}, {"type": "text", "text": "Note that the confidence level $\\delta$ only logarithmically affects the right terms of Ineqs. (9) and (10), which is why these terms appear independent of $\\delta$ . This theorem states that the predictions of a classifier $g$ trained solely on adversarial perturbations $\\{(\\boldsymbol{r}_{\\!\\;\\!n},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}$ coincide with those of a classifier $f$ trained on standard training samples $\\{(x_{n},y_{n})\\}_{n=1}^{N}$ if the three conditions hold. The two functions, $\\hat{f}$ and $\\hat{g}$ , which govern these conditions, can be viewed as key components that significantly influence the predictions of $f$ and $g$ (cf. Section 3.3). The conditions can be interpreted as follows. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Geometrical perspective. The functional margin conditions, Ineqs. (9) and (10), require the functional margins of $\\hat{f}$ and $\\hat{g}$ to exceed certain thresholds. In the input space $z\\in\\mathbb{R}^{d}$ , these conditions correspond to regions far from the decision boundaries $\\hat{f}(z)=0$ and $\\hat{g}(z)=0$ (Fig. 2(a) and (b)). In a $d_{\\cdot}$ -dimensional space, $L_{2}$ -distance scales with $\\sqrt{d}$ , making the right terms of Ineqs. (9) and (10) relatively small when the perturbation size $\\epsilon=\\Theta({\\sqrt{d}})$ ; hence, a larger $d$ facilitates the satisfaction of these conditions. Furthermore, Eq. (11) necessitates the agreement of the signs of these two decision boundaries (Fig. 2(c)). Consequently, the region where all conditions hold, i.e., where the prediction match occurs, can be characterized by the two piecewise linear functions (Fig. 2(d)). ", "page_idx": 6}, {"type": "text", "text": "Quantitative perspective (functional margin conditions). A large perturbation size $\\epsilon$ facilitates the satisfaction of Ineq. (10). In high-dimensional spaces, achieving the required margin conditions demands perturbations of at least $\\Omega({\\sqrt{d}})$ in magnitude, aligning with empirical scaling laws for $L_{2}$ perturbations. However, increasing $\\epsilon$ alone is insufficient for the satisfaction because the right term of Ineq. (10) has an $\\epsilon$ -irrelevant term $\\tilde{\\mathcal{O}}(1/T_{f})$ . Assume $\\epsilon=\\Theta({\\sqrt{d}})$ . The absolute values of $\\hat{f}$ and $\\hat{g}$ grow with $\\Theta(d)$ due to $\\langle\\pmb{x},z\\rangle$ , while the right terms of Ineqs. (9) and (10) are independent of $d$ Thus, a larger $d$ consistently facilitates the satisfaction. The training times $T_{f}$ and $T_{g}$ can reduce the right terms, but these terms contain time-independent terms $\\tilde{\\mathcal{O}}(1)$ and $\\tilde{\\mathcal{O}}(1/\\sqrt{N})$ , indicating that longer training times do not necessarily guarantee the satisfaction. A large sample size $N$ also helps to satisfy Ineq. (10), but similarly, it is not sufficient. In summary, while a larger input dimension $d$ consistently support the success of perturbation learning, a larger perturbation size $\\epsilon$ , sample size $N$ and training times $T_{f},T_{g}$ provide partial, but not definitive, benefits. ", "page_idx": 6}, {"type": "text", "text": "Quantitative perspective (agreement condition).3 It is difficult to interpret the agreement condition, Eq. (11), in its current form. We consider the following sufficient condition (cf. Lemma D.19): ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{|\\sum_{n=1}^{N}y_{n}\\langle x_{n},z\\rangle|}{\\operatorname*{max}_{x\\in\\{x_{1},\\ldots,x_{N},z\\}}\\sum_{n=1}^{N}\\lambda(x_{n},x)|\\langle x_{n},z\\rangle|}>\\frac{1-\\gamma}{1+\\gamma}\\qquad\\Rightarrow\\qquad\\mathrm{Eq.~}(11),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "equation", "text": "$$\n\\lambda(z_{1},z_{2}):=1-\\sqrt{\\frac{e}{2\\pi}\\frac{\\|z_{1}\\|^{2}\\|z_{2}\\|^{2}-\\langle z_{1},z_{2}\\rangle^{2}+d\\|z_{1}-z_{2}\\|^{2}}{\\|z_{1}\\|^{2}\\|z_{2}\\|^{2}+\\langle z_{1},z_{2}\\rangle^{2}+d\\|z_{1}+z_{2}\\|^{2}+2d^{2}}}=\\Theta(1).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Note that the left term can exceed one as $\\lambda(z_{1},z_{2})$ lies in (0.34, 1]. It is clear that a large negative slope of Leaky-ReLU $\\gamma$ facilitates the satisfaction. The magnitude of the left term depends on the consistency of the correlation (inner product) between $_{\\textit{z}}$ and $y_{n}\\mathbf{x}_{n}$ for every $n$ . For example, when $_{z}$ consistently exhibits a positive or negative correlation with $y_{n}\\mathbf{\\boldsymbol{x}}_{n}$ , the left term exceeds one, and the condition is satisfied. In contrast, if $_{z}$ positively correlates with half of the samples and negatively with the other half, the left term may output a small value, and the condition is not satisfied. In summary, the agreement condition depends on the consistency of the correlation between $_{\\textit{z}}$ and $y_{n}\\mathbf{\\boldsymbol{x}}_{n}$ . ", "page_idx": 6}, {"type": "text", "text": "Finally, we justify the success of perturbation learning in Scenario (b). ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5 (Perturbation learning, Scenario (b), special case of Theorem D.18). Consider Scenario $(b)$ in Setting 3.1. Assume $\\ell(s)=s$ and $y_{n}^{\\mathrm{adv}}\\sim U(\\{\\pm1\\})$ for every $n\\in[N]$ . Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\hat{g}_{b}(z):=\\frac{1}{N^{2}}\\sum_{n=1}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , if the functional margin condition $^{\\,I}$ (Ineq. (9)), ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{(Func.~margin~cond.~2)}\\qquad|\\hat{g}_{b}(z)|>\\tilde{\\mathcal{O}}\\left(\\frac{1}{T_{f}}+\\frac{\\sqrt{d}}{\\epsilon}\\left(\\frac{1}{T_{g}}+\\frac{\\sqrt{\\sum_{n}^{N}(\\langle x_{n},z\\rangle+1)^{2}}}{N}\\right)\\right),}\\\\ &{\\mathrm{(Agreement~condition)}\\quad\\mathrm{sgn}(\\hat{f}(z))=\\mathrm{sgn}(\\hat{g}_{b}(z)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This is a special case of Theorem D.18, which addresses differentiable, non-decreasing losses and aofn ya  sclaamsspilfiinerg ft $y_{n}^{\\mathrm{adv}}\\in\\{\\pm1\\}$ .o mSilym illaabrellye tdo  aTdvheerosraerima l 3e.x4,a tmhpisl etsh hceo ipnrceiddiec tiwoinths $g$ $\\{(\\pmb{x}_{,n}^{\\mathrm{adv}},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}$ those of a classifier $f$ trained on standard training samples $\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ if the three conditions hold. Functional margin condition 1 is consistent with that in Theorem 3.4, i.e., Ineq. (9). The definition of $\\hat{g}_{b}(z)$ is slightly different from $\\hat{g}_{a}(z)$ in Theorem 3.4, with $r_{n}$ replaced by ${\\pmb x}_{n}^{\\mathrm{adv}}$ . Due to this change in the definition of $\\hat{g}_{b}(z)$ , functional margin condition 2, Ineq. (15), and the agreement condition, Eq. (16), slightly differ from those in Theorem 3.4. ", "page_idx": 7}, {"type": "text", "text": "Assume $\\epsilon=\\Theta({\\sqrt{d}})$ . Similarly to Ineq. (10), the left term of Ineq. (15) grows with $O(d)$ due to the inner product. In contrast to Ineq. (10), the right term of Ineq. (15) includes a term that grows with $\\begin{array}{r}{\\sqrt{\\sum_{n}^{N}(\\langle\\pmb{x}_{n},z\\rangle+1)^{2}}/N=\\mathcal{O}(d/\\sqrt{N})}\\end{array}$ . This suggests that Scenario (b) necessitates a larger sample size $N$ than Scenario (a) to mitigate the effect of $d$ . ", "page_idx": 7}, {"type": "text", "text": "Furthermore, Eqs. (11) and (16) hold simultaneously (i.e., $\\mathrm{sgn}(\\hat{f}(z))=\\mathrm{sgn}(\\hat{g}_{a}(z))=\\mathrm{sgn}(\\hat{g}_{b}(z)))$ if $\\begin{array}{r}{\\sum_{k=1}^{N}y_{k}\\Phi(\\pmb{x}_{n},\\pmb{x}_{k})\\langle\\pmb{x}_{k},\\pmb{z}\\rangle}\\end{array}$ outputs the same sign for any $n$ . This indicates that there might exist re gions where the prediction match is observed regardless of the scenarios, and these regions are partially determined by the $n$ linear boundaries. Note that Ineq. (12) also serves as a sufficient condition for Eq. (16), and the quantitative analysis for Eq. (11) can be applied to Eq. (16) as well. ", "page_idx": 7}, {"type": "text", "text": "3.3 Sketch of Proof ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, for simplicity, we provide a sketch of the proof for Theorems 3.3 and 3.4 with infinite network width $m\\rightarrow\\infty$ , networks without biases, and identity loss. A proof for the general case can be found in Appendix D. ", "page_idx": 7}, {"type": "text", "text": "Lazy training. First, we introduce the concept of lazy training, where network parameters and outputs of hidden neurons change negligibly during training when the network width is sufficiently large [9, 30]. Since a readout weight $\\alpha_{i}$ is sampled from $\\mathcal{N}(0,1/m)$ , from gradient flow, for any $z\\in\\mathbb{R}^{d}$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left|\\left\\langle\\int_{0}^{T_{f}}\\frac{\\mathrm{d}v_{i}(t)}{\\mathrm{d}t}\\,\\mathrm{d}t\\,,z\\right\\rangle\\right|=\\left|\\frac{1}{N}\\sum_{n=1}^{N}y_{n}\\alpha_{i}\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\phi^{\\prime}(\\langle v_{i}(t),x_{n}\\rangle)\\,\\mathrm{d}t\\right|=\\tilde{\\mathcal{O}}\\Big(\\frac{d T_{f}}{\\sqrt{m}}\\Big).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Therefore, as $m\\rightarrow\\infty$ , the inner product between the time variation of a hidden parameter and an input approaches zero. This suggests that the sign of the output of a hidden neuron do not change: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname{sgn}(\\langle v_{i}(T_{f}),z\\rangle)=\\operatorname{sgn}\\left(\\langle v_{i}(0),z\\rangle+\\left\\langle\\int_{0}^{T_{f}}{\\frac{\\mathrm{d}v_{i}(t)}{\\mathrm{d}t}}\\,\\mathrm{d}t\\,,z\\right\\rangle\\right)\\xrightarrow{\\!\\!m\\to\\infty\\!\\!}\\operatorname{sgn}(\\langle v_{i}(0),z\\rangle).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Therefore, ${\\phi}^{\\prime}(\\langle{\\pmb v}_{i}(T_{f}),{\\pmb z}\\rangle)=\\phi^{\\prime}(\\langle{\\pmb v}_{i}(0),{\\pmb z}\\rangle)$ . Recall $\\phi(z):=\\operatorname*{max}(\\gamma z,z)$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.3. From the perturbation definition Eq. (1), the perturbation ${\\boldsymbol{r}}_{n}$ is parallel to ${\\pmb{\\nabla}}_{{\\pmb{x}}_{n}}f({\\pmb{x}}_{n};V(T_{f}))$ . Using $\\dot{\\phi^{\\prime}}(\\langle{\\pmb v}_{i}(T_{f}),{\\pmb z}\\rangle)=\\phi^{\\prime}(\\langle{\\pmb v}_{i}(0),{\\pmb z}\\rangle)$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\nr_{n}//\\nabla_{x_{n}}f(x_{n};V(T_{f}))=\\sum_{i=1}^{m}\\alpha_{i}\\phi^{\\prime}(\\langle v_{i}(0),x_{n}\\rangle)\\Bigg(v_{i}(0)+\\int_{0}^{T_{f}}\\frac{\\mathrm{d}v_{i}(t)}{\\mathrm{d}t}\\,\\mathrm{d}t\\Bigg).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The first term is constrained to $\\tilde{\\mathcal{O}}(1)$ . Let $\\Phi(\\pmb{x}_{n},\\pmb{x}_{k})\\;:=\\;\\mathbb{E}_{\\pmb{v}\\sim\\mathcal{N}(0,1/d)}[\\phi^{\\prime}(\\langle\\pmb{v},\\pmb{x}_{n}\\rangle)\\phi^{\\prime}(\\langle\\pmb{v},\\pmb{x}_{k}\\rangle)]$ . Using $\\begin{array}{r}{\\sum_{i=1}^{m}\\alpha_{i}^{2}\\phi^{\\prime}(\\langle v_{i}(0),x_{n}\\rangle)\\phi^{\\prime}(\\langle v_{i}(0),x_{k}\\rangle)\\to\\Phi(x_{n},x_{k})}\\end{array}$ as $m\\rightarrow\\infty$ , the second term becomes ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}\\alpha_{i}\\phi^{\\prime}(\\langle v_{i}(0),x_{n}\\rangle)\\int_{0}^{T_{f}}\\frac{\\mathrm{d}v_{i}(t)}{\\mathrm{d}t}\\,\\mathrm{d}t=\\frac{T_{f}}{N}\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Theorem 3.4. Similarly to the above, we can represent the adversarial perturbation $r_{n}$ as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\nr_{n}:=\\epsilon y_{n}^{\\mathrm{adv}}\\frac{\\mathbf{V}_{x_{n}}f(x_{n};V(T_{f}))}{\\|\\nabla_{x_{n}}f(x_{n};V(T_{f}))\\|}\\approx\\Omega\\biggl(\\frac{\\epsilon}{N\\sqrt{d}}\\biggr)y_{n}^{\\mathrm{adv}}\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Assuming $\\begin{array}{r}{\\sum_{i=1}^{m}{\\alpha_{i}\\phi^{\\prime}(\\langle v_{i}(0),z\\rangle)\\langle v_{i}(0),z\\rangle}\\,=\\,\\tilde{\\mathcal{O}}(1)\\,\\approx\\,0}\\end{array}$ for simplicity, the network prediction $f(z;V(T_{f}))$ trained on $\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ can be represented as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\nf(z;V(T_{f}))=\\sum_{i=1}^{m}\\alpha_{i}\\phi^{\\prime}(\\langle v_{i}(0),z\\rangle)\\langle v_{i}(T_{f}),z\\rangle\\approx\\frac{T_{f}}{N}\\sum_{n=1}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "and $\\begin{array}{r}{\\mathrm{sgn}(f(z;V(T_{f})))\\,=\\,\\mathrm{sgn}(\\sum_{n=1}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle)}\\end{array}$ . In addition, $g(z;W(T_{f}))$ trained on $\\{(\\boldsymbol{r}_{n},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}$ can be represented as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\ng(z;W(T_{g}))\\approx\\Omega\\bigg(\\frac{\\epsilon T_{g}}{N^{2}\\sqrt{d}}\\bigg)\\sum_{n=1}^{N}\\Phi(r_{n},z)\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "acnodn $\\begin{array}{r}{\\mathrm{sgn}(g(z;W(T_{g})))=\\mathrm{sgn}(\\sum_{n=1}^{N}\\Phi(r_{n},z)\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle)}\\end{array}$ . Thus, if the agreement $\\operatorname{sgn}(f(z;V(T_{f})))=\\operatorname{sgn}(g(z;W(T_{g})))$ ", "page_idx": 8}, {"type": "text", "text": "Formal proof. In the above sketch of proof, we have introduced several approximations. Rigorous evaluations are provided in Appendix D. For example, in the sketch, we assumed $m\\rightarrow\\infty$ , ensuring that the signs of all hidden layer outputs remain unchanged. In contrast, the formal proof derives a bound on the width $m$ that ensures that the number of hidden neurons with flipped signs is at most ${\\mathcal{O}}({\\sqrt{m}})$ , which makes the discussion (e.g., about Eqs. (18) and (19)) more complicated. Moreover, in Eq. (21), we neglected the first term of Eq. (19), but the formal proof carefully considers the impact on the subsequent steps. The functional margin conditions arise from the evaluation of these remainder terms. ", "page_idx": 8}, {"type": "text", "text": "3.4 Comparison with Prior Work and Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we compare our results with [28] and discuss the limitations of our work. In summary, our results justify the feature hypothesis and perturbation learning under substantially milder conditions than [28], except for network width (cf. Tab. 1). The assumption of wide two-layer networks is our main limitation. ", "page_idx": 8}, {"type": "text", "text": "Goals, results, and tools. The goals of our work and [28] are the same: justifying the feature hypothesis and perturbation learning. The conclusions drawn are also equivalent. However, our assumptions are much milder than theirs. This is due to the differences in the analytical approaches. While they leverage research on feature learning [19, 24, 31], we utilize the concept of lazy training [9, 30], which enables us to substantially relax the conditions. ", "page_idx": 8}, {"type": "text", "text": "Data distribution. Prior work imposes a strong assumption that training samples with/without adversarial perturbations are mutually orthogonal, i.e., $\\langle\\pmb{x}_{n},\\pmb{x}_{k}\\rangle\\approx0$ and $\\langle\\bar{\\mathbf{x}}_{n}^{\\mathrm{adv}},\\bar{\\mathbf{x}}_{k}^{\\mathrm{adv}}\\rangle\\approx0$ for any $n\\not=k$ . This condition is stringent and is hard to hold for real-world datasets. Moreover, it may not even hold for data sampled from a zero-mean Gaussian distribution in some common situations (e.g., the sample size is sufficiently larger than the dimension). We do not impose any assumptions on the data distribution. This is the first result that theoretically supports the feature hypothesis and the success of perturbation learning on realistic data distribution. ", "page_idx": 8}, {"type": "text", "text": "Perturbation design. Prior work defined the perturbation form using the decision boundary of a classifier. However, this is not only uncommon but also theoretically computable only in limited problem settings. Additionally, they constrained perturbation size to $\\epsilon=\\Theta(\\sqrt{d/N})$ , which becomes unrealistically small for a large sample size and is far from the practical constraint $\\epsilon\\,=\\,\\Theta({\\sqrt{d}})$ . We employ a single-step gradient-based method [21], which is commonly used in practice, and the perturbation constraint can be set arbitrarily. ", "page_idx": 8}, {"type": "text", "text": "Training time, loss function, network bias, and activation. First, it should be noted that these constraints are critical for deriving the results in [28]. This is because their theoretical framework [19, 24, 31] substantially requires the above conditions. We consider arbitrary training time, a wide class of loss functions, and (Leaky-) ReLU networks with bias availability. In contrast, they considered infinite training time, loss functions with exponential tails, homogeneous neural networks (thus requiring no bias), and Leaky-ReLU networks (the theorem becomes harder to hold as the negative slope of Leaky-ReLU approaches zero), which are essential for deriving their results (cf. the proofs of Theorem 4.4 in [31] and the proof of Theorem 3.2 in [19]). ", "page_idx": 8}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/e3b641a49e4cfec652b49b9791565c0f960bff0ff91e8880c696cd7cc87d2240.jpg", "img_caption": ["Figure 3: Accuracy on the mean-shifted Gaussian dataset in Scenario (a). The blue lines represent accuracy of the classifier $f$ on $\\mathcal{D}$ , i.e., training accuracy. The orange lines represent accuracy of the classifier $g$ on $\\mathcal{D}$ . "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Limitations. Compared to [28], our main limitation is the requirement for sufficient, though finite, network width. Moreover, our analysis is confined to two-layer networks, a common constraint in previous work. In practice, perturbation learning often employs deeper, and not necessarily wider, networks, which limits the direct applicability of our theoretical insights to more complex architectures. This assumption of a shallow network introduces another limitation. While deep neural networks typically capture high-level features from images and adversarial attacks are considered to exploit them, our framework focuses solely the low-level features (i.e., ${\\pmb x}_{n}$ itself) in adversarial perturbations and their extraction through perturbation learning, as shown in Theorems 3.3 to 3.5. Relaxing the shallow network constraint may allow us to capture a broader set of features present in adversarial perturbations. Despite these limitations, our work is the first to rigorously support the feature hypothesis and validate perturbation learning under realistic data distributions, perturbation designs, and training settings, marking a substantial advancement in the theoretical understanding of adversarial examples. ", "page_idx": 9}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "A comprehensive set of experiments conducted to validate our theorems can be found in Appendix B. In this section, we briefly present two results that confirm Theorem 3.4. As a training dataset $\\mathbf{\\mathcal{D}}:=\\{(\\mathbf{x}_{n},y_{n})\\}_{n=1}^{N}$ ,p sw pe eertmuprlboaytieodn  al esayrnntihnegti icn t rbaoitnhi nsgc ednataarisoets ,t oa se apsrieldyi cctheadn gbey  tohuer i tnhpeuot rdeimmse. nNsiootne, tgheante trahtee dp esrytnutrhbeattiico dna ltae aarnndi nlga boeln t ecda nG sfioaunn ddi sitnri tbhueti oli 2:, $\\{{\\pmb x}_{n}\\}_{n=1}^{N}$ $\\mathcal{N}(0.3\\times y_{n}\\times\\mathbf{1},I)$ $y_{n}$ $n\\in[N/2]$ one otherwise. The experimental settings are as follows: $d=100$ , $N=1,000$ , $m=100$ , $\\gamma=0$ , $\\ell(s)\\;:=\\;s$ , $\\epsilon\\;=\\;0.01$ , and the number of training steps is set to 1,000 for both $f$ and $g$ . The experimental results for perturbation learning under Scenario (a) are shown in Fig. 3. A high input dimension facilitates the alignment between $f$ and $g$ . Our theoretical results assume a wide network width, and Fig. 3 indicates that a sufficiently large width consistently stabilize the alignment. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We provided a theoretical justification for perturbation learning and the feature hypothesis. We demonstrated that adversarial perturbations contain class-specific features sufficient for networks to generalize from. Moreover, we revealed that the predictions of a classifier trained solely on these perturbations or mislabeled adversarial examples coincide with those of a classifier trained on correctly labeled training samples under three mild conditions. Except for wide two-layer networks, our assumption is substantially milder than prior work [28]. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "S. Kumano was supported by JSPS KAKENHI Grant Number JP23KJ0789 and by JST, ACT-X Grant Number JPMJAX23C7, JAPAN. H. Kera was supported by JSPS KAKENHI Grant Number JP22K17962. T. Yamasaki was supported by JSPS KAKENHI Grant Number JP22H03640, JST ", "page_idx": 9}, {"type": "text", "text": "ASPIRE Program Grant Number JPMJAP2303, and Institute for AI and Beyond of The University of Tokyo. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] G. Aggarwal, A. Sinha, N. Kumari, and M. Singh. On the beneftis of models with perceptuallyaligned gradients. In ICLR WS, 2020.   \n[2] Z. Allen-Zhu, Y. Li, and Z. Song. A convergence theory for deep learning via overparameterization. In ICML, pages 242\u2013252, 2019.   \n[3] S. Arora, S. Du, W. Hu, Z. Li, and R. Wang. Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks. In ICML, pages 322\u2013332, 2019.   \n[4] M. Augustin, A. Meinke, and M. Hein. Adversarial robustness on in-and out-distribution improves explainability. In ECCV, pages 228\u2013245, 2020.   \n[5] Y. Cao and Q. Gu. Generalization bounds of stochastic gradient descent for wide and deep neural networks. In NeurIPS, volume 32, 2019.   \n[6] Y. Cao and Q. Gu. Generalization error bounds of gradient descent for learning overparameterized deep relu networks. In AAAI, volume 34, pages 3349\u20133356, 2020.   \n[7] P. Chalasani, J. Chen, A. R. Chowdhury, X. Wu, and S. Jha. Concise explanations of neural networks using adversarial training. In ICML, pages 1383\u20131391, 2020.   \n[8] S.-H. Chang, P. C. Cosman, and L. B. Milstein. Chernoff-type bounds for the gaussian error function. IEEE Transactions on Communications, 59(11):2939\u20132944, 2011.   \n[9] L. Chizat, E. Oyallon, and F. Bach. On lazy training in differentiable programming. In NeurIPS, volume 32, 2019.   \n[10] Y. Cho and L. Saul. Kernel methods for deep learning. In NeurIPS, volume 22, 2009.   \n[11] L. Deng. The MNIST database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6):141\u2013142, 2012.   \n[12] Z. Deng, L. Zhang, K. Vodrahalli, K. Kawaguchi, and J. Y. Zou. Adversarial training helps transfer learning via better representations. In NeurIPS, volume 34, pages 25179\u201325191, 2021.   \n[13] E. Dobriban, H. Hassani, D. Hong, and A. Robey. Provable tradeoffs in adversarially robust classification. IEEE Transactions on Information Theory, 2023.   \n[14] S. Du, J. Lee, H. Li, L. Wang, and X. Zhai. Gradient descent finds global minima of deep neural networks. In ICML, pages 1675\u20131685, 2019.   \n[15] S. S. Du, X. Zhai, B. Poczos, and A. Singh. Gradient descent provably optimizes overparameterized neural networks. In ICLR, 2019.   \n[16] J. Duchi. Lecture notes on statistics and information theory, 2023.   \n[17] L. Engstrom, A. Ilyas, S. Santurkar, D. Tsipras, B. Tran, and A. Madry. Adversarial robustness as a prior for learned representations. arXiv:1906.00945, 2019.   \n[18] C. Etmann, S. Lunz, P. Maass, and C.-B. Sch\u00f6nlieb. On the connection between adversarial robustness and saliency map interpretability. In ICML, 2019.   \n[19] S. Frei, G. Vardi, P. L. Bartlett, N. Srebro, and W. Hu. Implicit bias in leaky relu networks trained on high-dimensional data. In ICLR, 2023.   \n[20] M. Geiger, S. Spigler, A. Jacot, and M. Wyart. Disentangling feature and lazy training in deep neural networks. Journal of Statistical Mechanics: Theory and Experiment, 2020(11):113301, 2020.   \n[21] I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. In ICLR, 2015.   \n[22] A. Ilyas, S. Santurkar, D. Tsipras, L. Engstrom, B. Tran, and A. Madry. Adversarial examples are not bugs, they are features. In NeurIPS, volume 32, pages 125\u2013136, 2019.   \n[23] A. Jacot, F. Gabriel, and C. Hongler. Neural tangent kernel: Convergence and generalization in neural networks. In NeurIPS, volume 31, 2018.   \n[24] Z. Ji and M. Telgarsky. Directional convergence and alignment in deep learning. In NeurIPS, volume 33, pages 17176\u201317186, 2020.   \n[25] Z. Ji and M. Telgarsky. Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow relu networks. In ICLR, 2020.   \n[26] S. Kaur, J. Cohen, and Z. C. Lipton. Are perceptually-aligned gradients a general property of robust classifiers? In NeurIPS WS, 2019.   \n[27] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.   \n[28] S. Kumano, H. Kera, and T. Yamasaki. Theoretical understanding of learning from adversarial perturbations. In ICLR, 2024.   \n[29] J. Lee, L. Xiao, S. Schoenholz, Y. Bahri, R. Novak, J. Sohl-Dickstein, and J. Pennington. Wide neural networks of any depth evolve as linear models under gradient descent. In NeurIPS, volume 32, 2019.   \n[30] Y. Li and Y. Liang. Learning overparameterized neural networks via stochastic gradient descent on structured data. In NeurIPS, volume 31, 2018.   \n[31] K. Lyu and J. Li. Gradient descent maximizes the margin of homogeneous neural networks. In ICLR, 2020.   \n[32] M. Mehrabi, A. Javanmard, R. A. Rossi, A. Rao, and T. Mai. Fundamental tradeoffs in distributionally adversarial training. In ICML, pages 7544\u20137554, 2021.   \n[33] A. Montanari and Y. Zhong. The interpolation phase transition in neural networks: Memorization and generalization under lazy training. The Annals of Statistics, 50(5):2816\u20132847, 2022.   \n[34] A. Raghunathan, S. M. Xie, F. Yang, J. Duchi, and P. Liang. Understanding and mitigating the tradeoff between robustness and accuracy. In ICML, 2020.   \n[35] A. Raghunathan, S. M. Xie, F. Yang, J. C. Duchi, and P. Liang. Adversarial training can hurt generalization. In ICML WS, 2019.   \n[36] P. Rigollet and J.-C. H\u00fctter. High-dimensional statistics. arXiv:2310.19244, 2023.   \n[37] H. Salman, A. Ilyas, L. Engstrom, A. Kapoor, and A. Madry. Do adversarially robust imagenet models transfer better? In NeurIPS, volume 33, pages 3533\u20133545, 2020.   \n[38] S. Santurkar, A. Ilyas, D. Tsipras, L. Engstrom, B. Tran, and A. Madry. Image synthesis with a single (robust) classifier. In NeurIPS, volume 32, 2019.   \n[39] S. Srinivas, S. Bordt, and H. Lakkaraju. Which models have perceptually-aligned gradients? an explanation via off-manifold robustness. In NeurIPS, volume 36, 2023.   \n[40] D. Su, H. Zhang, H. Chen, J. Yi, P.-Y. Chen, and Y. Gao. Is robustness the cost of accuracy?\u2013a comprehensive study on the robustness of 18 deep image classification models. In ECCV, pages 631\u2013648, 2018.   \n[41] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. In ICLR, 2014.   \n[42] D. Tsipras, S. Santurkar, L. Engstrom, A. Turner, and A. Madry. Robustness may be at odds with accuracy. In ICLR, 2019.   \n[43] F. Utrera, E. Kravitz, N. B. Erichson, R. Khanna, and M. W. Mahoney. Adversarially-trained deep nets transfer better: Illustration on image classification. In ICLR, 2021.   \n[44] B. Woodworth, S. Gunasekar, J. D. Lee, E. Moroshko, P. Savarese, I. Golan, D. Soudry, and N. Srebro. Kernel and rich regimes in overparametrized models. In COLT, pages 3635\u20133673, 2020.   \n[45] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. arXiv:1708.07747, 2017.   \n[46] Y.-Y. Yang, C. Rashtchian, H. Zhang, R. R. Salakhutdinov, and K. Chaudhuri. A closer look at accuracy vs. robustness. In NeurIPS, volume 33, pages 8588\u20138601, 2020.   \n[47] H. Zhang, Y. Yu, J. Jiao, E. Xing, L. El Ghaoui, and M. Jordan. Theoretically principled trade-off between robustness and accuracy. In ICML, pages 7472\u20137482, 2019.   \n[48] T. Zhang and Z. Zhu. Interpreting adversarially trained convolutional neural networks. In ICML, pages 7502\u20137511, 2019.   \n[49] D. Zou, Y. Cao, D. Zhou, and Q. Gu. Gradient descent optimizes over-parameterized deep relu networks. Machine Learning, 109:467\u2013492, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Comparison with Prior Work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we compare our findings with those of prior work [28] and highlight new insights beyond technical contributions. ", "page_idx": 13}, {"type": "text", "text": "A.1 Feature Hypothesis (Theorem 3.3) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Our result offers a new insight into the alignment between perturbations and training samples through the residual term $\\xi_{n}$ . The direction of a perturbation vector comprises two components: a weighted sum of the training samples (the main term) and a residual term. Our result suggests that as the input dimension increases, the residual term becomes smaller than the main term, thereby enhancing the alignment. In other words, perturbations more robustly encode class-specific features. This insight is unattainable in prior research due to the absence of a residual term in their limited problem setting. ", "page_idx": 13}, {"type": "text", "text": "Additionally, our finding suggests that extended training time reinforces the directional alignment between perturbations and training samples. This concept is supported by practical intuition and experience but not addressed in prior work. ", "page_idx": 13}, {"type": "text", "text": "Our result further introduces a coefficient, $\\Phi({\\pmb x}_{n},{\\pmb x}_{k})$ , for each adversarial perturbation. The coefficient $\\Phi({\\pmb x}_{n},{\\pmb x}_{k})$ depends on the slope of the activation function and the similarity between ${\\pmb x}_{n}$ and $\\pmb{x}_{k}$ (cf. Eq. (4)). This suggests that training samples with higher similarity to each other exhibit a stronger influence within a perturbation. Although prior work includes similar coefficients, they cannot be explicitly computed. ", "page_idx": 13}, {"type": "text", "text": "A.2 Perturbation Learning (Theorems 3.4 and 3.5) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Our result establishes an explicit connection between the success of perturbation learning and training factors, such as training time $T$ , perturbation size $\\epsilon$ , input dimension $d$ , sample size $N$ , and confidence level $\\delta$ . This result enhances our understanding of how these factors influence perturbation learning. For example, perturbation learning is more likely to succeed with a larger input dimension $d$ and sample size $N$ . Notably, our findings indicate that while a larger $d$ consistently facilitates successful perturbation learning, a larger $N$ alone is insufficient. In contrast, existing research does not elucidate the roles of these variables, merely showing that success is achievable when both $d$ and $N$ approach infinity. ", "page_idx": 13}, {"type": "text", "text": "B Experimental Settings and Other Results ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "B.1 Datasets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "WMeN IuStiTl i[z4e5d] . tTwhoe  sfyirsntt hsyetnitch edtiact adsaettass eat nisd  dtewriov edw ifdroelmy  au zseerdo -dmaetaasn etGs,a usMsiNanI SdTis t[ri1b1u]t iaonn:d $\\{{\\pmb x}_{n}\\}_{n=1}^{N}$ are independently sampled from and are independently sampled from $U(\\{\\pm1\\})$ The second synthetic dataset is based on a mean-shifted Gaussian distribution: $\\{\\dot{\\bf x}_{n}\\}_{n=1}^{N}$ are independently sampled from $\\mathcal{N}(0.3\\times y_{n}\\times\\mathbf{1},I)$ and $y_{n}$ is set to one for $n\\in[N/2]$ and minus one otherwise. We used data only from classes 1 and 2 in MNIST (i.e., digits 1 and 2) and those from classes 0 and 9 in Fashion-MNIST (i.e., T-shirt and ankle boot). To measure the agreement ratio between network predictions from standard training and perturbation learning, for the real-world dataset cases, we used standard test datasets, and for the synthetic dataset cases, we used 1,000 samples independently and identically sampled according to the training data distribution. ", "page_idx": 13}, {"type": "text", "text": "B.2 Settings ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, for notational simplicity, we denote the number of training epochs in standard training by $T_{f}$ and in perturbation learning by $T_{g}$ . Note that the original definitions of $T_{f}$ and $T_{g}$ are continuous training steps in gradient flow, i.e., gradient descent with an infinitely small learning rate (cf. Section 3.1), which is conceptually distinct from the discrete steps in gradient descent with finitely small learning rates in practice. In addition, we denote the learning rates in standard training and perturbation learning as $\\eta_{f}$ and $\\eta_{g}$ , respectively. ", "page_idx": 13}, {"type": "text", "text": "We used non-stochastic gradient descent (i.e., each gradient calculation uses the entire dataset) with 0.9 momentum and the learning rate scheduler that multiplies a learning rate by 0.1 when a training loss has stopped improving during 10 epochs. For Figs. 3 to A12, we selected the best accuracy, agreement ratio, and cosine similarity from training with multiple initial learning rates. ", "page_idx": 14}, {"type": "text", "text": "In Figs. A4 to A11, the blue lines represent the accuracy of the classifier from standard training on the training dataset $\\{(x_{n},y_{n})\\}_{n=1}^{N}$ . Namely, these mean the training accuracy of $f(\\,\\cdot\\,;T_{f})$ . The tmraeianni ntgh ed raattaisoe tt $\\{(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ t irvaet hgeer ntehraanli tzhatei opne rotcurcburesd.  dNaotates etth $\\{(\\pmb{x}_{n}^{\\mathrm{adv}},y_{n}^{\\mathrm{adv}})\\}_{n=1}^{N}$ s.t aNya amroeluyn, dt hfeifstey percent (chance accuracy) if adversarial perturbations are not included in $\\!\\left\\{x_{n}^{\\mathrm{adv}}\\right\\}_{n=1}^{N}$ (cf. $\\epsilon=0$ in Figs. A4 to A11). The green lines represent the agreement ratio between predictions $f(\\,\\cdot\\,;T_{f})$ and $g(\\bar{\\mathbf{\\Gamma}}\\cdot;T_{g})$ on a test dataset. ", "page_idx": 14}, {"type": "text", "text": "The cosine similarity in Fig. A12 is the average one between the experimentally calculated adversarial perturbation and the theoretically predicted one (cf. Eq. (1)) across all $n$ . The blue lines are the same as those in Figs. A4 to A11. ", "page_idx": 14}, {"type": "text", "text": "The two axes in Fig. A13 are the normalized average vectors of samples from the positive and negative classes, respectively. The blue circles and orange crosses correspond to the projections of positive and negative samples onto these axes. The gray and green areas indicate regions where two predictions are consistent and inconsistent, respectively. The red solid lines represent $\\hat{f}(z)=0$ . The black dashed lines represent $\\hat{g}_{a}(z)=0$ in Scenario (a) and $\\hat{g}_{b}(z)=0$ in Scenario (b). ", "page_idx": 14}, {"type": "text", "text": "Mean-Shifted Gaussian and Scenario (a). A common experimental setting for the mean-shifted Gaussian dataset and Scenario (a) in Figs. A4 and A12 is as follows: input dimension $d=100$ , hidden dimension $m=100$ , activation function slope $\\gamma=0$ , number of training samples $N=1,000$ , loss function $\\ell(s)=s$ , training epochs in standard training $T_{f}=1,000$ and in perturbation learning $T_{g}\\,=\\,1,000$ , perturbation size $\\epsilon\\,=\\sqrt{d\\times0.001^{2}}\\,=\\,0.01$ , and learning rates in standard training $\\eta_{f}=1$ or 0.1 and in perturbation learning $\\eta_{g}=1$ or 0.1. However, for the comparison of $T_{f}$ (i.e., the graph in the fourth row and the first column in Fig. A4), we set $\\eta_{f}$ only to 0.1. For the comparison of $d$ (i.e., the graph in the first row in Fig. A4), we employed $\\epsilon=\\sqrt{d\\times0.001^{2}}$ . In Fig. A13, we used $d=100$ , $m=100$ , $\\gamma=0$ , $N=1,000$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{d\\times0.001^{2}}=0.01$ , $\\eta_{f}=1$ , and $\\eta_{g}=1$ . ", "page_idx": 14}, {"type": "text", "text": "Mean-Shifted Gaussian and Scenario (b). A common experimental setting for the mean-shifted Gaussian dataset and Scenario (b) in Figs. A5 and A12 is as follows: $d=5,000$ , $m=100$ , $\\gamma=0$ , $N\\,=\\,10,000$ , $\\ell(s)\\,=\\,s$ , $T_{f}\\,=\\,1,000$ , $T_{g}\\,=\\,1,000$ , $\\epsilon\\,=\\,\\sqrt{d\\times0.01^{2}}\\,=\\,0.7$ , $\\eta_{f}\\,=\\,1$ or 0.1, and $\\eta_{g}\\,=\\,1$ or 0.1. However, for the comparison of $T_{f}$ (i.e., the graph in the fourth row and the first column in Fig. A5), we set $\\eta_{f}$ only to 0.01. In addition, for the comparison of $T_{g}$ (i.e., the graph in the fourth row and the second column in Fig. A5), we set $\\eta_{g}$ only to 0.01. Furthermore, we set $\\eta_{f}=10,5,1,0.1,0.01$ and $\\eta_{g}=10,5,1,0.1,0.01$ for the evaluation with the logistic loss (i.e., the graph in the first row and the second column in Fig. A5). For the comparison of $d$ (i.e., the graph in the first row in Fig. A5), we employed $\\epsilon=\\sqrt{d\\times0.01^{2}}$ . In Fig. A13, we used $d=100$ , $m=100$ , $\\gamma=0$ , $N=5,000$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{d\\times0.01^{2}}=0.1$ , $\\eta_{f}=1$ , and $\\eta_{g}=1$ . ", "page_idx": 14}, {"type": "text", "text": "Zero-Mean Gaussian and Scenario (a). A common experimental setting for the zero-mean Gaussian dataset and Scenario (a) in Figs. A6 and A12 is as follows: $d\\;=\\;10,000$ , $m\\:=\\:100$ , $\\gamma\\,=\\,0$ , $N=10,000$ , $\\ell(s)\\,=\\,s$ , $T_{f}\\,=\\,1,000$ , $T_{g}\\,=\\,1,000$ , $\\epsilon=\\sqrt{d\\times0.001^{2}}=0.1$ , $\\eta_{f}\\,=\\,1$ or 0.1, and $\\eta_{g}\\,=\\,1$ or 0.1. However, for the comparison of $T_{f}$ (i.e., the graph in the fourth row and the first column in Fig. A6), we set $\\eta_{f}$ only to 0.1. For the comparison of $d$ (i.e., the graph in the first row in Fig. A6), we employed $\\epsilon=\\sqrt{d\\times0.001^{2}}.$ . In Fig. A13, we used $d=1,000,m=1,000,\\gamma=0,$ $N=2,000,\\ell(s)=s,T_{f}=1,000,T_{g}=1,000,\\epsilon=\\sqrt{d\\times0.001^{2}}=0.031$ , $\\eta_{f}=1$ , and $\\eta_{g}=1$ . ", "page_idx": 14}, {"type": "text", "text": "Zero-Mean Gaussian and Scenario (b). A common experimental setting for the zero-mean Gaussian dataset and Scenario (b) in Figs. A7 and A12 is as follows: $d\\;=\\;10,000,\\;m\\;=\\;100,\\;\\gamma\\;=\\;0,$ $N=10$ , 000, $\\ell(s)=s$ , $T_{f}=1,000$ , $T_{g}=1,000$ , $\\epsilon=\\sqrt{d\\times0.1^{2}}=10$ , $\\eta_{f}=1$ or 0.1, and $\\eta_{g}=1$ or 0.1. However, for the comparison of $T_{f}$ (i.e., the graph in the fourth row and the first column in Fig. A7), we set $\\eta_{f}$ only to 0.1. In addition, for the comparison of $T_{g}$ (i.e., the graph in the fourth row and the second column in Fig. A7), we set $\\eta_{g}$ only to 0.1. For the comparison of $d$ (i.e., the graph in the first row in Fig. A7), we employed $\\epsilon=\\sqrt{d\\times0.1^{2}}$ . In Fig. A13, we used $d=1,000$ , $m=1,000$ , $\\gamma=0$ , $N=10,000$ , $\\ell(s)=s$ , $T_{f}=1,000$ , $T_{g}=1,000$ , $\\epsilon=\\sqrt{d\\times0.01^{2}}=0.31$ , $\\eta_{f}=0.1$ , and \u03b7g = 0.1. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "MNIST and Scenario (a). A common experimental setting for MNIST and Scenario (a) in Figs. A8 and A12 is as follows: $m=100$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=$ 0.14, $\\eta_{f}\\,=\\,0.01$ or 0.001, and $\\eta_{g}\\,=\\,0.01$ or 0.001. In Fig. A13, we used $m\\,=\\,1,000$ , $\\gamma\\,=\\,0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=0.14$ , $\\eta_{f}=0.01$ , and $\\eta_{g}=0.01$ . ", "page_idx": 15}, {"type": "text", "text": "MNIST and Scenario (b). A common experimental setting for MNIST and Scenario (b) in Figs. A9 and A12 is as follows: $m=100$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=$ 0.14, $\\eta_{f}\\,=\\,0.01$ or 0.001, and $\\eta_{g}\\,=\\,0.01$ or 0.001. In Fig. A13, we used $m\\,=\\,1,000$ , $\\gamma\\,=\\,0$ , $\\ell(s)=s$ , $T_{f}=1,000$ , $T_{g}=1,000$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=0.14$ , $\\eta_{f}=0.01$ , and $\\eta_{g}=0.01$ . ", "page_idx": 15}, {"type": "text", "text": "Fashion-MNIST and Scenario (a). A common experimental setting for Fashion-MNIST and Scenario (a) in Figs. A10 and A12 is as follows: $m=100$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=0.14$ , $\\eta_{f}=0.01$ or 0.001, and $\\eta_{g}=0.01$ or 0.001. In Fig. A13, we used $m=1,000$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt[]{784\\times0.01^{2}}/2=0.14$ , $\\eta_{f}=0.01$ , and \u03b7g = 0.01. ", "page_idx": 15}, {"type": "text", "text": "Fashion-MNIST and Scenario (b). A common experimental setting for Fashion-MNIST and Scenario (b) in Figs. A11 and A12 is as follows: $m=100$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.01^{2}}/2=0.14$ , $\\eta_{f}=0.01$ or 0.001, and $\\eta_{g}=0.01$ or 0.001. In Fig. A13, we used $m=1,000$ , $\\gamma=0$ , $\\ell(s)=s$ , $T_{f}=100$ , $T_{g}=100$ , $\\epsilon=\\sqrt{784\\times0.1^{2}}/2=1.4$ , $\\eta_{f}=0.001$ , and $\\eta_{g}=0.001$ . ", "page_idx": 15}, {"type": "text", "text": "C Lemmas ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we derive fundamental properties of random variables. ", "page_idx": 15}, {"type": "text", "text": "Lemma C.1 (Properties of Gaussian random variables). Let $\\sigma^{2}\\,>\\,0$ be a positive constant. Let $X_{1},\\ldots,X_{m}\\in\\mathbb{R}$ be $m\\in\\mathbb{N}$ i.i.d. Gaussian random variables that follow $\\bar{\\mathcal{N}}(0,\\sigma^{2})$ . ", "page_idx": 15}, {"type": "text", "text": "(a) For $0<\\delta<1$ , with probability at least $1-\\delta$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{i}|X_{i}|<\\sqrt{2\\sigma^{2}\\ln(2m/\\delta)}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "(b) Let $Y_{1},\\dots,Y_{m}\\in[\\gamma^{2},1]$ be m independent random variables with $0\\leq\\gamma^{2}<1$ . Suppose that $Y_{1},\\ldots,Y_{m}$ are independent of $X_{1},\\ldots,X_{m}$ . For $0<\\delta<1$ , with probability at least $1-\\delta$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}X_{i}^{2}Y_{i}-\\sigma^{2}\\sum_{i}^{m}\\mathbb{E}[Y_{i}]\\right|<\\operatorname*{max}\\left(16\\sigma^{2}\\ln\\!\\left({\\frac{2}{\\delta}}\\right),{\\sqrt{128m\\sigma^{4}\\ln\\!\\left({\\frac{2}{\\delta}}\\right)}}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "(c) For $\\exp\\bigl(-2(\\eta\\sqrt{m}+1)^{2}/m\\bigr)<\\delta<1$ , with probability at least $1-\\delta$ , there are at most $\\eta\\sqrt{m}\\in[m-1]$ instances such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n|X_{i}|<\\sqrt{-\\frac{\\pi\\sigma^{2}}{2}\\ln\\left(1-\\left(\\frac{\\eta\\sqrt{m}+1}{m}-\\sqrt{-\\frac{\\ln\\delta}{2m}}\\right)^{2}\\right)}\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. Let $C>0$ be a positive constant. ", "page_idx": 15}, {"type": "text", "text": "(a) From [36], ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\operatorname*{max}_{i}|X_{i}|\\geq C]\\leq2m\\exp\\left(-\\frac{C^{2}}{2\\sigma^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Thus, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big[\\operatorname*{max}_{i}|X_{i}|\\geq\\sqrt{2\\sigma^{2}\\ln(2m/\\delta)}\\Big]\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/4b2574a3d59e221623a65597a08b1dc7698e269fe66e8f5e5681b9d3763f9484.jpg", "img_caption": ["Figure A4: Accuracy and agreement ratio on the mean-shifted Gaussian in Scenario (a). The blue lines represent the accuracy of the classifier $f$ on $\\mathbf{\\mathcal{D}}:=\\{(\\mathbf{x}_{n},y_{n})\\}_{n=1}^{N}$ , i.e., training accuracy. The orange lines represent the accuracy of the classifier $g$ on $\\mathcal{D}$ . The green lines represent the prediction agreement between $f$ and $g$ on the test dataset. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "(b) For any $i\\in[m]$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\big[\\exp\\big(t(X_{i}^{2}Y_{i}-\\mathbb{E}[X_{i}^{2}]\\mathbb{E}[Y_{i}])\\big)\\big]=\\mathbb{E}\\Bigg[\\sum_{n=0}^{\\infty}\\frac{t^{n}(X_{i}^{2}Y_{i}-\\mathbb{E}[X_{i}^{2}]\\mathbb{E}[Y_{i}])^{n}}{n!}\\Bigg]}\\\\ {=1+\\displaystyle\\sum_{n=2}^{\\infty}\\frac{t^{n}\\mathbb{E}[(X_{i}^{2}Y_{i}-\\mathbb{E}[X_{i}^{2}]\\mathbb{E}[Y_{i}])^{n}]}{n!}}\\\\ {\\le1+\\displaystyle\\sum_{n=2}^{\\infty}\\frac{t^{n}\\mathbb{E}[(X_{i}^{2}Y_{i}+\\mathbb{E}[X_{i}^{2}]\\mathbb{E}[Y_{i}])^{n}]}{n!}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Jensen\u2019s inequality, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{n=2}^{\\infty}\\frac{t^{n}\\mathbb{E}[(X_{i}^{2}Y_{i}+\\mathbb{E}[X_{i}^{2}]\\mathbb{E}[Y_{i}])^{n}]}{n!}\\leq\\sum_{n=2}^{\\infty}\\frac{2^{n-1}t^{n}(\\mathbb{E}[X_{i}^{2n}]\\mathbb{E}[Y_{i}^{n}]+\\mathbb{E}[X_{i}^{2}]^{n}\\mathbb{E}[Y_{i}]^{n})}{n!}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/348d057b3384f35ac77aa35c7f3aed6d6ed4f9069ace4f812e63613fa597c120.jpg", "img_caption": ["Figure A5: Accuracy and agreement ratio on the mean-shifted Gaussian in Scenario (b). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 17}, {"type": "equation", "text": "$$\n\\leq\\sum_{n=2}^{\\infty}\\frac{2^{n}t^{n}\\mathbb{E}[X_{i}^{2n}]\\mathbb{E}[Y_{i}^{n}]}{n!}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since $\\mathbb{E}[X_{i}^{2n}]=\\sigma^{2n}(2n-1)!!\\leq2^{n}\\sigma^{2n}n!$ and $\\mathbb{E}[Y_{i}^{n}]\\leq1$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n1+\\sum_{n=2}^{\\infty}\\frac{2^{n}t^{n}\\mathbb{E}[X_{i}^{2n}]\\mathbb{E}[Y_{i}^{n}]}{n!}\\leq1+\\sum_{n=2}^{\\infty}4^{n}t^{n}\\sigma^{2n}=1+\\frac{16t^{2}\\sigma^{4}}{1-4t\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For $|t|\\leq1/(8\\sigma^{2})$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n1+{\\frac{16t^{2}\\sigma^{4}}{1-4t\\sigma^{2}}}\\leq1+32t^{2}\\sigma^{4}\\leq\\exp\\bigl(32t^{2}\\sigma^{4}\\bigr).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, $X_{i}^{2}Y_{i}$ follows $\\mathrm{SE}(64\\sigma^{4},8\\sigma^{2})$ , where $S E(a,b)$ is a sub-exponential random variable with parameters $a,b\\,>\\,0$ . Note that a random variable $Z$ is called sub-exponential with parameters $a,b>0$ , $\\operatorname{SE}(a,b)$ , if its moment generating function satisfies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\forall|t|\\leq\\frac{1}{b},\\qquad\\mathbb{E}[\\exp(t(Z-\\mathbb{E}[Z]))]\\leq\\exp\\!\\bigg(\\frac{t^{2}a}{2}\\bigg).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/e49772cd19e10dae347b12ee7940cec74514f4dd0b2f1fcf6e3bac3bc529a27c.jpg", "img_caption": ["Figure A6: Accuracy and agreement ratio on the zero-mean Gaussian in Scenario (a). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "By [16], $\\sum_{i}^{m}X_{i}^{2}Y_{i}$ follows $\\mathrm{SE}(64m\\sigma^{4},8\\sigma^{2})$ . In addition, by [16], $Z\\sim\\operatorname{SE}(a,b)$ satisfies ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}[|Z-\\mathbb{E}[Z]|\\ge C]\\le2\\exp\\!\\left(-\\frac{1}{2}\\operatorname*{min}\\left(\\frac{C^{2}}{a},\\frac{C}{b}\\right)\\!\\right)\\!.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, with probability at least $1-\\delta$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n|Z-\\mathbb{E}[Z]|<\\operatorname*{max}\\left(2b\\ln\\!\\left({\\frac{2}{\\delta}}\\right),{\\sqrt{2a\\ln\\!\\left({\\frac{2}{\\delta}}\\right)}}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "(c) Let $k\\in[m-1]$ be a positive integer. Let $\\operatorname{Bi}(m,p)$ be the Binomial distribution and $\\mathrm{Be}(p)$ be the Bernoulli distribution with $p\\in(0,(k+1)/m)$ . By Hoeffding\u2019s inequality, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i=k+1}^{m}\\binom{m}{i}p^{i}(1-p)^{m-i}=\\mathbb{P}_{Y\\sim\\mathrm{Bi}(m,p)}[Y\\geq k+1]}}\\\\ &{}&{\\qquad=\\mathbb{P}_{Z_{1},\\ldots,Z_{m}\\sim\\mathrm{Be}(p)}\\left[\\displaystyle\\sum_{i=1}^{m}Z_{i}\\geq k+1\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/50a2d84c398a5edc24405a87ec4bdde988379d84c4efccb4922e9046a2b222af.jpg", "img_caption": ["Figure A7: Accuracy and agreement ratio on the zero-mean Gaussian in Scenario (b). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq\\exp\\biggl(-\\frac{2(k+1-m p)^{2}}{m}\\biggr)}\\\\ {\\displaystyle=\\exp\\biggl(-2m\\biggl(\\frac{k+1}{m}-p\\biggr)^{2}\\biggr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=\\sum_{i=k+1}^{m}\\binom{m}{i}\\mathbb{P}[|X_{i}|<C]^{i}\\mathbb{P}[|X_{i}|\\ge C]^{m-i}}\\\\ {\\displaystyle\\le\\exp\\Bigg({-2m\\bigg(\\frac{k+1}{m}-\\mathbb{P}[|X_{i}|<C]\\bigg)^{2}\\Bigg).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For $\\delta>\\exp\\biggl(-\\frac{2(k{+}1)^{2}}{m}\\biggr)$ and $\\begin{array}{r}{\\mathbb{P}[|X_{i}|<C]\\le\\frac{k+1}{m}-\\sqrt{-\\frac{\\ln{\\delta}}{2m}},}\\end{array}$ ", "page_idx": 19}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/3037ade937ef5b943e17744d2e904dd4e1f7d57f7e9b9f868bb52f7fecf197b7.jpg", "img_caption": ["Figure A8: Accuracy and agreement ratio on MNIST in Scenario (a). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Since the areas of a square with sides of length $x$ and a quarter-circle with a radius of $2x/\\sqrt{\\pi}$ are the same, and because $s^{2}+t^{2}$ is always larger in the square than in the quarter-circle outside the common area, an upper bound of $\\operatorname{erf}(x)$ can be computed as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\mathrm{erf}(\\boldsymbol{x})^{2}=\\frac{4}{\\pi}\\int_{0}^{x}\\int_{0}^{x}\\exp\\bigl(-(s^{2}+t^{2})\\bigr)\\,\\mathrm{d}s\\,\\mathrm{d}t}\\\\ {\\displaystyle\\le\\frac{4}{\\pi}\\int_{0}^{2x/\\sqrt{\\pi}}\\int_{0}^{\\frac{\\pi}{2}}r\\exp\\bigl(-r^{2}\\bigr)\\,\\mathrm{d}\\theta\\,\\mathrm{d}r}\\\\ {\\displaystyle=1-\\exp\\biggl(-\\frac{4}{\\pi}x^{2}\\biggr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}[|X_{i}|<C]=\\mathrm{erf}\\left(\\frac{C}{\\sqrt{2\\sigma^{2}}}\\right)\\leq\\sqrt{1-\\exp\\left(-\\frac{2C^{2}}{\\pi\\sigma^{2}}\\right)}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\nC\\leq\\sqrt{-\\frac{\\pi\\sigma^{2}}{2}\\ln\\left(1-\\left(\\frac{k+1}{m}-\\sqrt{-\\frac{\\ln\\delta}{2m}}\\right)^{2}\\right)}\\Longrightarrow\\mathbb{P}[|X_{i}|<C]\\leq\\frac{k+1}{m}-\\sqrt{-\\frac{\\ln\\delta}{2m}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma C.2 (Hoeffding\u2019s inequality). Let $s_{1},\\ldots,s_{N}\\in\\mathbb{R}$ be real numbers and $X_{1},\\allowbreak\\cdot\\cdot,X_{N}\\in$ $\\{\\pm1\\}$ be i.i.d. random variables. Suppose that $\\mathbb{E}[X_{n}]=0$ for every $n\\in[N]$ . Then, for $0<\\delta<1$ , ", "page_idx": 20}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/50ac48a61d47b237bfa342c66383ade12812cc5553e5a37cc605d0e84b5f966a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure A9: Accuracy and agreement ratio on MNIST in Scenario (b). The description is the same as Fig. A4. ", "page_idx": 21}, {"type": "text", "text": "with probability at least $1-\\delta$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\sum_{n}^{N}s_{n}X_{n}\\right|<\\sqrt{2\\ln\\!\\left(\\frac{2}{\\delta}\\right)\\sum_{n}^{N}s_{n}^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. By Hoeffding\u2019s inequality, the claim is established. ", "page_idx": 21}, {"type": "text", "text": "Lemma C.3 (Expectation of product of derivatives of activation functions, part 1). Denote a symmetric positive definite matrix by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Sigma:=\\left[\\!\\!{\\begin{array}{l l}{a}&{b}\\\\ {b}&{c}\\end{array}}\\!\\!\\right],\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $a,c>0$ and $a c-b^{2}>0$ . Then, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\displaystyle\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\frac{\\phi^{\\prime}(x_{1})\\phi^{\\prime}(x_{2})}{2\\pi\\sqrt{|\\Sigma|}}\\exp\\left(-\\frac{1}{2}x^{\\top}\\Sigma^{-1}x\\right)\\mathrm{d}x-\\frac{(1+\\gamma)^{2}}{4}\\right|}\\\\ &{\\leq\\!\\frac{(1+\\gamma)(1-\\gamma)}{4}\\!\\left(1-\\sqrt{\\frac{e}{2\\pi}\\frac{a c-b^{2}}{a c+b^{2}}}\\right)\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. The inverse of $\\Sigma$ is ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Sigma^{-1}=\\frac{1}{a c-b^{2}}\\left[\\!\\!\\!\\begin{array}{c c}{{c}}&{{-b}}\\\\ {{-b}}&{{a}}\\end{array}\\!\\!\\right]=:\\frac{\\tilde{\\Sigma}^{-1}}{a c-b^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/c038b4fffa6fa625d1bc0773eb2f298625a32e83e585fc882dcc19f66d8d2e05.jpg", "img_caption": ["Figure A10: Accuracy and agreement ratio on Fashion-MNIST in Scenario (a). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Using $\\pmb{y}:=\\pmb{x}/\\sqrt{a c-b^{2}}$ , the quadratic form can be represented as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\boldsymbol{x}^{\\top}\\Sigma^{-1}\\boldsymbol{x}=\\frac{\\boldsymbol{x}^{\\top}\\tilde{\\Sigma}^{-1}\\boldsymbol{x}}{a c-b^{2}}=\\boldsymbol{y}^{\\top}\\tilde{\\Sigma}^{-1}\\boldsymbol{y}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Because $|\\partial\\mathbf{x}/\\partial\\mathbf{y}|=a c-b^{2}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\frac{\\phi^{\\prime}(x_{1})\\phi^{\\prime}(x_{2})}{2\\pi\\sqrt{|\\Sigma|}}\\exp\\mathopen{}\\mathclose\\bgroup\\left(-\\frac12{\\pmb x^{\\intercal}}\\Sigma^{-1}{\\pmb x}\\aftergroup\\egroup\\right)\\,\\mathrm{d}{\\pmb x}}\\\\ &{=\\displaystyle\\frac{\\sqrt{a c-b^{2}}}{2\\pi}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{1})\\phi^{\\prime}(y_{2})\\exp\\mathopen{}\\mathclose\\bgroup\\left(-\\frac12{\\pmb y^{\\intercal}}\\tilde{\\Sigma}^{-1}{\\pmb y}\\aftergroup\\egroup\\right)\\,\\mathrm{d}{\\pmb y}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "With $z:=y_{1}-b y_{2}/c$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\pmb{y}^{\\top}\\tilde{\\Sigma}^{-1}\\pmb{y}=c\\bigg(y_{1}-\\frac{b y_{2}}{c}\\bigg)^{2}+\\bigg(a-\\frac{b^{2}}{c}\\bigg)y_{2}^{2}=c z^{2}+\\bigg(a-\\frac{b^{2}}{c}\\bigg)y_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{1})\\phi^{\\prime}(y_{2})\\exp\\mathopen{}\\mathclose\\bgroup\\left(-\\frac12y^{\\top}\\tilde{\\Sigma}^{-1}y\\aftergroup\\egroup\\right)\\mathrm{d}y}\\\\ {\\displaystyle=\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{2})\\mathopen{}\\mathclose\\bgroup\\left(\\displaystyle\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(z+b y_{2}/c)\\exp\\mathopen{}\\mathclose\\bgroup\\left(-\\frac{c}{2}z^{2}\\aftergroup\\egroup\\right)\\mathrm{d}z\\aftergroup\\egroup\\right)\\exp\\mathopen{}\\mathclose\\bgroup\\left(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\aftergroup\\egroup\\right)\\mathrm{d}y_{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The integral along $z$ can be computed as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(z+b y_{2}/c)\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z\n$$", "text_format": "latex", "page_idx": 22}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/006cb2584ae80d806e0a0012f7d556e50f8dfdb7cb48e056cd315548b5cd7f95.jpg", "img_caption": ["Figure A11: Accuracy and agreement ratio on Fashion-MNIST in Scenario (b). The description is the same as Fig. A4. "], "img_footnote": [], "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\int_{-b y_{2}/c}^{\\infty}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z+\\gamma\\int_{-\\infty}^{-b y_{2}/c}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z}\\\\ &{=\\displaystyle\\int_{0}^{\\infty}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z-\\int_{0}^{-b y_{2}/c}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z}\\\\ &{\\quad+\\displaystyle\\gamma\\int_{-\\infty}^{0}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z-\\gamma\\int_{-b y_{2}/c}^{0}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z}\\\\ &{=(1+\\gamma)\\displaystyle\\int_{0}^{\\infty}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z-(1-\\gamma)\\displaystyle\\int_{0}^{-b y_{2}/c}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z}\\\\ &{=(1+\\gamma)\\sqrt{\\frac{\\pi}{2c}}+(1-\\gamma)\\displaystyle\\int_{0}^{b y_{2}/c}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Using the above equation, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{1})\\phi^{\\prime}(y_{2})\\exp\\biggl(-\\frac{1}{2}y^{\\top}\\tilde{\\Sigma}^{-1}y\\biggr)\\,\\mathrm{d}y}}\\\\ {{\\displaystyle=(1+\\gamma)\\sqrt{\\frac{\\pi}{2c}}\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{2})\\exp\\biggl(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\biggr)\\,\\mathrm{d}y_{2}}}\\\\ {{\\displaystyle\\quad+\\,(1-\\gamma)\\int_{-\\infty}^{\\infty}\\phi^{\\prime}(y_{2})\\int_{0}^{b y_{2}/c}\\exp\\biggl(-\\frac{c}{2}z^{2}\\biggr)\\,\\mathrm{d}z\\exp\\biggl(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\biggr)\\,\\mathrm{d}y_{2}}}\\\\ {{\\displaystyle=\\frac{\\pi(1+\\gamma)^{2}}{2\\sqrt{a c-b^{2}}}+(1+\\gamma)(1-\\gamma)\\int_{0}^{\\infty}\\int_{0}^{b y_{2}/c}\\exp\\biggl(-\\frac{c}{2}z^{2}\\biggr)\\,\\mathrm{d}z\\exp\\biggl(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\biggr)\\,\\mathrm{d}y_{2}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/6292012139bdcc09aeba1aa2f87a7f59d3d84a29c4de2aa2c96b0e938fcb75e4.jpg", "img_caption": ["Figure A12: Standard training accuracy and cosine similarity. The blue lines represent the accuracy of the classifier $f$ on $\\pmb{\\mathcal{D}}:=\\tilde{\\{}(\\pmb{x}_{n},y_{n})\\}_{n=1}^{N}$ , i.e., training accuracy. The orange lines represent the average cosine similarity between the experimentally calculated adversarial perturbations and the theoretically predicted ones. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Thus, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}\\frac{\\phi^{\\prime}(x_{1})\\phi^{\\prime}(x_{2})}{2\\pi\\sqrt{|\\Sigma|}}\\exp\\biggl(-\\frac{1}{2}x^{\\top}\\Sigma^{-1}x\\biggr)\\,\\mathrm{d}x}\\\\ &{=\\displaystyle\\frac{(1+\\gamma)^{2}}{4}}\\\\ &{\\quad+\\,\\displaystyle\\frac{(1+\\gamma)(1-\\gamma)\\sqrt{a c-b^{2}}}{2\\pi}\\int_{0}^{\\infty}\\int_{0}^{b y_{2}/c}\\exp\\biggl(-\\frac{c}{2}z^{2}\\biggr)\\,\\mathrm{d}z\\exp\\biggl(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\biggr)\\,\\mathrm{d}y_{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Using $t:=\\operatorname{sgn}(b)z\\sqrt{c/2}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\int_{0}^{b y_{2}/c}\\exp\\Bigl(-\\frac{c}{2}z^{2}\\Bigr)\\,\\mathrm{d}z=\\mathrm{sgn}(b)\\sqrt{\\frac{2}{c}}\\int_{0}^{\\sqrt{\\frac{b^{2}}{2c}}y_{2}}\\exp\\bigl(-t^{2}\\bigr)\\,\\mathrm{d}t}}\\\\ &{}&{=\\mathrm{sgn}(b)\\sqrt{\\frac{\\pi}{2c}}\\Biggl(1-\\mathrm{erfc}\\left(\\sqrt{\\frac{b^{2}}{2c}}y_{2}\\right)\\Biggr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "From [8], with $\\alpha=\\sqrt{e/(2\\pi)}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\alpha\\exp\\!\\left(-\\frac{b^{2}}{c}y_{2}^{2}\\right)\\leq\\mathrm{erfc}\\left(\\sqrt{\\frac{b^{2}}{2c}}y_{2}\\right),}\\\\ {\\displaystyle\\left\\vert\\int_{0}^{b y_{2}/c}\\exp\\!\\left(-\\frac{c}{2}z^{2}\\right)\\mathrm{d}z\\right\\vert\\leq\\!\\sqrt{\\frac{\\pi}{2c}}\\!\\left(1-\\alpha\\exp\\!\\left(-\\frac{b^{2}}{c}y_{2}^{2}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "image", "img_path": "1YGgaouVgZ/tmp/ee146268c6c8a49ad166e8ffecce88fad97de430a83b6b3a3ea35d626443f387.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure A13: Prediction matching between the classifiers from standard training and perturbation learning, $f$ and $g$ . The two axes are the normalized average vectors of samples from the positive and negative classes, respectively. The blue circles and orange crosses correspond to the projections of positive and negative samples onto these axes. The gray and green areas indicate regions where two predictions are consistent and inconsistent, respectively. The red solid lines represent $\\hat{f}(z)=0$ . The black dashed lines represent $\\hat{g}_{a}(z)=0$ in Scenario (a) and $\\hat{g}_{b}(z)=0$ in Scenario (b). ", "page_idx": 25}, {"type": "text", "text": "Thus, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\int_{0}^{\\infty}\\int_{0}^{b y_{2}/c}\\exp\\left(-\\frac{c}{2}z^{2}\\right)\\mathrm{d}z\\exp\\left(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\right)\\mathrm{d}y_{2}\\right|}\\\\ &{\\leq\\sqrt{\\frac{\\pi}{2c}}\\left(\\int_{0}^{\\infty}\\exp\\left(-\\frac{a c-b^{2}}{2c}y_{2}^{2}\\right)\\mathrm{d}y_{2}-\\alpha\\int_{0}^{\\infty}\\exp\\left(-\\frac{a c+b^{2}}{2c}y_{2}^{2}\\right)\\mathrm{d}y_{2}\\right)}\\\\ &{=\\sqrt{\\frac{\\pi}{2c}}\\left(\\frac{1}{2}\\sqrt{\\frac{2\\pi c}{a c-b^{2}}}-\\frac{\\alpha}{2}\\sqrt{\\frac{2\\pi c}{a c+b^{2}}}\\right)}\\\\ &{=\\frac{\\pi}{2}\\left(\\frac{1}{\\sqrt{a c-b^{2}}}-\\frac{\\alpha}{\\sqrt{a c+b^{2}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Finally, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\left|\\displaystyle\\int_{-\\infty}^{\\infty}\\displaystyle\\int_{-\\infty}^{\\infty}\\frac{\\phi^{\\prime}(x_{1})\\phi^{\\prime}(x_{2})}{2\\pi\\sqrt{|\\Sigma|}}\\exp\\!\\left(-\\frac{1}{2}x^{\\top}\\Sigma^{-1}x\\right)\\mathrm{d}x-\\frac{(1+\\gamma)^{2}}{4}\\right|}\\\\ &{\\le\\!\\frac{(1+\\gamma)(1-\\gamma)\\sqrt{a c-b^{2}}}{2\\pi}\\!\\left(\\frac{\\pi}{2}\\!\\left(\\displaystyle\\frac{1}{\\sqrt{a c-b^{2}}}-\\frac{\\alpha}{\\sqrt{a c+b^{2}}}\\right)\\right)}\\\\ &{=\\!\\frac{(1+\\gamma)(1-\\gamma)}{4}\\!\\left(1-\\alpha\\sqrt{\\frac{a c-b^{2}}{a c+b^{2}}}\\right)\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Lemma C.4 (Expectation of product of derivatives of activation functions, part 2). For any $z_{1}\\neq$ $z_{2}\\in\\mathbb{R}^{d}$ , ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left|\\Phi(z_{1},z_{2})-\\frac{(1+\\gamma)^{2}}{4}\\right|\\leq\\frac{(1+\\gamma)(1-\\gamma)}{4}\\lambda(z_{1},z_{2}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. By the reproductive property of Gaussian distributions, $\\langle\\pmb{v},z_{1}\\rangle\\!+\\!a$ follows $\\mathcal{N}(0,\\|z_{1}\\|^{2}/d{+}1)$ . Since any linear combination of $\\langle{\\pmb v},{\\pmb z}_{1}\\rangle+a$ and $\\langle\\pmb{v},z_{2}\\rangle+a$ has a univariate Gaussian distribution, $\\langle\\pmb{v},z_{1}\\rangle+a$ and $\\langle\\pmb{v},z_{2}\\rangle+a$ follow a multivariate Gaussian distribution. The covariance matrix $\\Sigma$ can be computed as ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\Sigma=\\left[\\begin{array}{c c}{||z_{1}||^{2}/d+1}&{\\langle z_{1},z_{2}\\rangle/d+1}\\\\ {\\langle z_{1},z_{2}\\rangle/d+1}&{\\|z_{2}\\|^{2}/d+1}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Thus, by Lemma C.3, the claim is established. ", "page_idx": 26}, {"type": "text", "text": "D Main Proof ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "For notational simplicity, we use the following abbreviation for $i\\in[m]$ and $n\\in[N]$ : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{f,i,t}(z):=\\langle v_{i}(t),z\\rangle+a_{i}(t),\\qquad\\qquad h_{g,i,t}(z):=\\langle w_{i}(t),z\\rangle+b_{i}(t),}\\\\ &{\\psi_{f,i,t}(z):=\\!\\phi(h_{f,i,t}(z)),\\qquad\\qquad\\psi_{g,i,t}(z):=\\!\\phi(h_{g,i,t}(z)),}\\\\ &{\\psi_{f,i,t}^{\\prime}(z):=\\!\\phi^{\\prime}(h_{f,i,t}(z)),\\qquad\\qquad\\psi_{g,i,t}^{\\prime}(z):=\\!\\phi^{\\prime}(h_{g,i,t}(z)),}\\\\ &{\\ell_{f,n,t}:=\\!\\ell(-y_{n}f(x_{n};\\theta_{V,a}(t))),\\qquad\\quad\\ell_{g,n,t}:=\\!\\ell(-y_{n}^{\\mathrm{adv}}g(x_{n}^{\\mathrm{adv}};\\theta_{W,b}(t))),}\\\\ &{\\ell_{f,n,t}^{\\prime}:=\\!\\ell^{\\prime}(-y_{n}f(x_{n};\\theta_{V,a}(t))),\\qquad\\qquad\\ell_{g,n,t}^{\\prime}:=\\!\\ell^{\\prime}(-y_{n}^{\\mathrm{adv}}g(x_{n}^{\\mathrm{adv}};\\theta_{W,b}(t))),}\\\\ &{\\bar{\\ell}_{f}^{\\prime}(t):=\\!\\frac{1}{N}\\sum_{n}^{N}\\ell_{f,n,t}^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Moreover, denote the subset of $[m]$ consisting of the smallest $\\eta\\sqrt{m}\\in[m-1]$ elements in terms of $\\left|h_{f,i,0}(z)\\right|$ by $S_{f}(z)$ . Similarly, we define $S_{g}(z)$ based on $|h_{g,i,0}(z)|$ . The function $\\kappa_{f,i}(z)$ returns one if $i\\in S_{f}(z)$ and zero otherwise. Similarly, we define $\\kappa_{g,i}(z)$ . For $\\exp\\bigl(-2(\\eta\\sqrt{m}+1)^{2}/m\\bigr)<$ $\\delta<1$ , let ", "page_idx": 26}, {"type": "equation", "text": "$$\nC_{\\mathrm{thr}}(z,\\delta):=\\sqrt{-\\pi\\bigg(\\frac{\\|z\\|^{2}}{d}+1\\bigg)\\ln\\left(1-\\bigg(\\frac{\\eta\\sqrt{m}+1}{m}-\\sqrt{-\\frac{\\ln\\delta}{2m}}\\bigg)^{2}\\right)}=\\tilde{\\Theta}(1).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "D.1 Assumptions on Properties of Neural Networks and Their Justifications ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "For reference, we state the following assumption on the network $f$ : ", "page_idx": 26}, {"type": "text", "text": "Assumption D.1 (Properties of neural network $f$ ). Let $z~\\in~\\mathbb{R}^{d}$ be a real-valued vector and $\\exp\\bigl(-\\bar{2}(\\eta\\sqrt{m}+1)^{2}/\\dot{m}\\bigr)<\\delta<1$ be a positive value. ", "page_idx": 26}, {"type": "text", "text": "(a) For any $i\\in[m]$ and $j\\in[d],|v_{i,j}(0)|<\\sqrt{(2/d)\\ln(2d m/\\delta)}.$   \n(b) For any $i\\in[m]$ , $|\\alpha_{i}|<\\sqrt{(2/m)\\ln(2m/\\delta)}$ .   \n(c) For any $i\\in[m]$ $||\\boldsymbol{v}_{i}(0),\\boldsymbol{z}\\rangle|<\\sqrt{(2/d)\\ln(2m/\\delta)}||\\boldsymbol{z}||.$   \n(d) For any $i\\in[m]$ , $|h_{f,i,0}(z)|<\\sqrt{2(\\|z\\|^{2}/d+1)\\ln(2m/\\delta)}.$   \n(e) $|f(z;0)|<\\sqrt{2(\\|z\\|^{2}/d+1)\\ln(2/\\delta)}$ .   \n(f) For any $j\\in[d]$ ,   \n$\\left|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})v_{i,j}(0)\\right|<\\sqrt{\\frac{2}{m}\\ln\\left(\\frac{2}{\\delta}\\right)\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}(x_{n})^{2}v_{i,j}(0)^{2}}.$ ", "page_idx": 26}, {"type": "text", "text": "(g) ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})\\langle{\\pmb v}_{i}(0),{\\pmb z}\\rangle\\right|<\\sqrt{\\frac{2}{m}\\ln\\!\\left(\\frac{2}{\\delta}\\right)\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})^{2}\\langle{\\pmb v}_{i}(0),{\\pmb z}\\rangle^{2}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(h) ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})\\psi_{f,i,0}^{\\prime}({\\pmb z})-\\Phi({\\pmb x}_{n},{\\pmb z})\\right|<\\frac{16}{\\sqrt{m}}\\ln\\!\\left(\\frac{2}{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(i) There are at most $\\scriptstyle\\eta{\\sqrt{m}}$ instances such that $|h_{f,i,0}(z)|<C_{\\mathrm{thr}}(z,\\delta)/\\sqrt{2}$ . ", "page_idx": 27}, {"type": "text", "text": "Assumption D.1 is justified as follows: ", "page_idx": 27}, {"type": "text", "text": "Lemma D.2 (Justification of Assumption D.1). ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "(a) With probability at least $1-\\delta$ , Assumption $D.I(a)$ holds.   \n(b) With probability at least $1-\\delta$ , Assumption $D.I(b)$ holds.   \n(c) With probability at least $1-\\delta$ , Assumption $D.I(c)$ holds.   \n(d) With probability at least $1-\\delta$ , Assumption D.1(d) holds.   \n(e) With probability at least $1-\\delta$ , Assumption D.1(e) holds.   \n(f) With probability at least $1-\\delta$ , Assumption D.1(f) holds.   \n(g) With probability at least $1-\\delta$ , Assumption D.1(g) holds.   \n(h) With probability at least $1-\\delta$ , Assumption D.1(h) holds.   \n(i) With probability at least $1-\\delta$ , Assumption D.1(i) holds.   \n$(j)$ With probability at least $1-9\\delta$ , Assumption D.1 holds. ", "page_idx": 27}, {"type": "text", "text": "Proof. ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "(a), (b) and (h) See Lemma C.1. ", "page_idx": 27}, {"type": "text", "text": "(c) to (g) and (i) By the reproductive property of Gaussian random variables, $\\langle\\pmb{v}_{i}(0),\\pmb{z}\\rangle$ , $\\begin{array}{r}{h_{f,i,0}(z),\\:f(z;0),\\:\\sum_{i}^{\\dot{m}}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})v_{i,j}(0)}\\end{array}$ , and $\\begin{array}{r}{\\sum_{i}^{}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})\\langle\\pmb{v}_{i}(0),\\pmb{z}\\rangle}\\end{array}$ follow the Gaussian $\\mathcal{N}(0,\\|z\\|^{2}/d)$ , $\\mathcal{N}(0,\\|z\\|^{2}/d+1)$ , $\\mathcal{N}(0,\\|z\\|^{2}/d+1)$ , $\\begin{array}{r}{\\mathcal{N}(0,(1/m)\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})^{2}v_{i,j}(0)^{2})}\\end{array}$ , and $\\begin{array}{r}{\\mathcal{N}(0,(1/m)\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})^{2}\\langle\\boldsymbol{v}_{i}(0),\\boldsymbol{z}\\rangle^{2})}\\end{array}$ , respectively. By Lemma C.1, the claim is established. ", "page_idx": 27}, {"type": "text", "text": "(j) By Bonferroni\u2019s inequality, the claim is established. ", "page_idx": 27}, {"type": "text", "text": "Similarly, we consider the following assumption on the network $g$ and its justification: ", "page_idx": 27}, {"type": "text", "text": "Assumption D.3 (Properties of neural network $g$ ). Let $z~\\in~\\mathbb{R}^{d}$ be a real-valued vector and $\\exp\\bigl(-\\bar{2}(\\eta\\sqrt{m}+1)^{2}/\\dot{m}\\bigr)<\\delta<1$ be a positive value. ", "page_idx": 27}, {"type": "text", "text": "(a) For any $i\\in[m]$ and $j\\in[d],|w_{i,j}(0)|<\\sqrt{(2/d)\\ln(2d m/\\delta)}.$   \n(b) For any $i\\in[m]$ , $|\\beta_{i}|<\\sqrt{(2/m)\\ln(2m/\\delta)}$ .   \n(c) For any $i\\in[m]$ , $|\\langle{\\pmb w}_{i}(0),{\\pmb z}\\rangle|<\\sqrt{(2/d)\\ln(2m/\\delta)}\\|{\\pmb z}\\|$ .   \n(d) For any $i\\in[m]$ , $|h_{g,i,0}(z)|<\\sqrt{2(\\|z\\|^{2}/d+1)\\ln(2m/\\delta)}.$   \n(e) $|g(z;0)|<\\sqrt{2(\\|z\\|^{2}/d+1)\\ln(2/\\delta)}$ .   \n(f) For any $j\\in[d]$ ,   \n$\\left|\\sum_{i}^{m}\\beta_{i}\\psi_{g,i,0}^{\\prime}(x_{n}^{\\mathrm{adv}})w_{i,j}(0)\\right|<\\sqrt{\\frac{2}{m}\\ln\\left(\\frac{2}{\\delta}\\right)\\sum_{i}^{m}\\psi_{g,i,0}^{\\prime}(x_{n}^{\\mathrm{adv}})^{2}w_{i,j}(0)^{2}}.$ ", "page_idx": 27}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(g) ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}\\beta_{i}\\psi_{g,i,0}^{\\prime}(x_{n}^{\\mathrm{adv}})\\langle w_{i}(0),z\\rangle\\right|<\\sqrt{\\frac{2}{m}\\ln\\!\\left(\\frac{2}{\\delta}\\right)\\sum_{i}^{m}\\psi_{g,i,0}^{\\prime}(x_{n}^{\\mathrm{adv}})^{2}\\langle w_{i}(0),z\\rangle^{2}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "(h) ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}\\beta_{i}^{2}\\psi_{g,i,0}^{\\prime}(x_{n}^{\\mathrm{adv}})\\psi_{g,i,0}^{\\prime}(z)-\\Phi(x_{n}^{\\mathrm{adv}},z)\\right|<\\frac{16}{\\sqrt{m}}\\ln\\Biggl(\\frac{2}{\\delta}\\Biggr).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "(i) There are at most $\\scriptstyle\\eta{\\sqrt{m}}$ instances such that $|h_{g,i,0}(z)|<C_{\\mathrm{thr}}(z,\\delta)/\\sqrt{2}$ . ", "page_idx": 28}, {"type": "text", "text": "Lemma D.4 (Justification of Assumption D.3). With probability at least $1-9\\delta$ , Assumption $D.3$ holds. ", "page_idx": 28}, {"type": "text", "text": "D.2 Wide Width Assumptions ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Then, we consider the condition of network width for lazy training. ", "page_idx": 28}, {"type": "text", "text": "Assumption D.5 (Wide width for neural network $f$ ). Let $z\\,\\in\\,\\mathbb{R}^{d}$ be a real-valued vector and $\\exp(-\\bar{2}(\\eta\\sqrt{m}+\\mathrm{i})^{2}/m)\\,<\\delta<1$ be a positive value. Network width $m$ satisfies the following inequalities: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m>\\!\\frac{4\\ln(2m/\\delta)(\\sum_{n}^{N}(\\vert\\langle{x_{n},z}\\rangle\\vert+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t)^{2}}{N^{2}C_{\\mathrm{thr}}(z,\\delta)^{2}}=\\tilde{\\mathcal{O}}\\left(d^{2}\\!\\left(\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right)^{2}\\right),}\\\\ &{m>\\!\\frac{4\\sum_{n,k}^{N}\\vert\\langle{x_{n},x_{k}}\\rangle\\vert\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}{N^{2}}=\\tilde{\\mathcal{O}}\\left(d^{2}\\!\\left(\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right)^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Note that only Ineq. (A90) is required to satisfy lazy training. We impose Ineq. (A91) to simplify some rearrangements of equations. This assumption restricts the transitions of the derivatives of hidden outputs during training. ", "page_idx": 28}, {"type": "text", "text": "Lemma D.6 (Lazy training in network $f$ ). If Assumptions D.1 and D.5 hold, then $\\psi_{f,i,t}^{\\prime}(z)=$ $\\psi_{f,i,0}^{\\prime}(z)$ for any $i\\in[m]\\setminus S_{f}(z)$ and $0\\leq t\\leq T_{f}$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. By Assumption D.1, the time evolution of $h_{f,i,t}(z)$ from $t=0$ to $t=T_{f}$ can be computed as ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left|\\Delta h_{f,i,T_{f}}(z)\\right|:=\\left|\\left\\langle-\\int_{0}^{T_{f}}\\nabla_{v_{i}}\\mathcal{L}(\\theta_{V,a}(t);\\mathcal{D})\\,\\mathrm{d}t\\,,z\\right\\rangle-\\int_{0}^{T_{f}}\\nabla_{a_{i}}\\mathcal{L}(\\theta_{V,a}(t);\\mathcal{D})\\,\\mathrm{d}t\\right|}\\\\ {\\displaystyle\\qquad\\qquad\\qquad=\\left|\\int_{0}^{T_{f}}\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{n})(\\left\\langle x_{n},z\\right\\rangle+1)\\,\\mathrm{d}t\\right|}\\\\ {\\displaystyle\\qquad\\qquad\\leq\\frac{|\\alpha_{i}|}{N}\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle\\qquad\\qquad<\\frac{1}{N}\\sqrt{\\frac{2}{m}\\ln\\left(\\frac{2m}{\\delta}\\right)}\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "By Assumption D.1, if the right term of Ineq. (A95) is smaller than $C_{\\mathrm{thr}}(z,\\delta)/\\sqrt{2}$ , then the largest $m-\\eta\\sqrt{m}$ instances in terms of $|h_{f,i,0}(z)|$ satisfy $\\mathrm{sgn}(h_{f,i,t}(z))=\\mathrm{sgn}(h_{f,i,0}(z))$ for $0\\leq t\\leq T_{f}$ . This condition can be represented as Ineq. (A90). \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Assumption D.7 (Wide width for neural network $g$ ). Let $\\boldsymbol{z}^{\\mathrm{~\\,~}}\\in\\mathbb{R}^{d}$ be a real-valued vector and $\\exp\\bigl(-2(\\eta\\sqrt{m}+1)^{2}/m\\bigr)\\,<\\,\\delta\\,<\\,1$ be a positive value. Network width $m$ satisfies the following inequalities: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m>\\!\\frac{4\\ln(2m/\\delta)(\\sum_{n}^{N}(|\\langle\\mathbf{x}_{n}^{\\mathrm{adv}},z\\rangle|+1)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t)^{2}}{N^{2}C_{\\mathrm{thr}}(z,\\delta)^{2}}=\\tilde{\\mathcal{O}}\\left(d^{2}\\!\\left(\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\right)^{2}\\right),}\\\\ &{m>\\!\\frac{4\\sum_{n,k}^{N}|\\langle\\mathbf{x}_{n}^{\\mathrm{adv}},\\mathbf{x}_{k}^{\\mathrm{adv}}\\rangle|\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\int_{0}^{T_{g}}\\ell_{g,k,t}^{\\prime}\\,\\mathrm{d}t}{N^{2}}=\\tilde{\\mathcal{O}}\\left(d^{2}\\!\\left(\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\right)^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Lemma D.8 (Lazy training in network $g$ ). If Assumptions $D.3$ and D.7 hold, then $\\psi_{g,i,t}^{\\prime}(z)\\;=\\;$ $\\psi_{g,i,0}^{\\prime}(z)$ for any $i\\in[m]\\setminus S_{g}(z)$ and $0\\leq t\\leq T_{g}$ . ", "page_idx": 29}, {"type": "text", "text": "We can integrate Assumptions D.1 and D.3 into Assumption 3.2. ", "page_idx": 29}, {"type": "text", "text": "D.3 Main Part ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Lemma D.9 (Representation of network $f$ ). If Assumptions $D.I$ and $D.5$ hold, then the network output at the training time $T_{f}$ can be represented as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{f(z;T_{j})=f(z;0)+\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,T_{j}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))h_{f,i,0}(z)}}\\\\ {{\\ }}\\\\ {{\\displaystyle~~+\\frac{1}{N}\\sum_{n}^{N}y_{n}((x_{n},z)+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)-\\Phi(x_{n},z)\\right)}}\\\\ {{\\ }}\\\\ {{\\displaystyle~~+\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left.\\ }}\\\\ {{\\ }}\\\\ {{\\displaystyle~~+\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{n})}}\\\\ {{\\ }}\\\\ {{\\displaystyle~~~\\times\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})\\psi_{f,i,T_{j}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z))\\,\\mathrm{d}t\\ .~~~~~~~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. First, see Lemma D.6. The time evolution of ${\\pmb v}_{i}(t)$ from $t=0$ to $t=T_{f}$ can be computed as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\Delta v_{i}(T_{f}):=-\\int_{0}^{T_{f}}\\nabla_{v_{i}}\\mathcal{L}(\\theta_{V,a}(t);\\mathcal{D})\\,\\mathrm{d}t}\\\\ {\\displaystyle}&{\\displaystyle=\\int_{0}^{T_{f}}\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}f_{f,n}^{\\prime}\\nu_{f,i}^{\\prime}(x_{n})x_{n}\\,\\mathrm{d}t}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}x_{n}\\int_{0}^{T_{f}}\\ell_{f,n}^{\\prime}\\ell_{f,i}^{\\prime}(x_{n})\\,\\mathrm{d}t}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}(1-\\kappa_{f,i}(x_{n}))y_{n}x_{n}\\psi_{f,i,0}^{\\prime}(x_{n})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle}&{\\displaystyle~~~+\\,\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}\\kappa_{f,i}(x_{n})y_{n}x_{n}\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{n})\\,\\mathrm{d}t}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=\\frac{\\alpha_{i}}{N}\\sum_{n}y_{n}x_{n}\\psi_{f,i,0}^{\\prime}(x_{n})\\left(\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right.}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\left.+\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}\\kappa_{f,i}(x_{n})y_{n}x_{n}^{\\prime}\\psi_{f,i,0}^{\\prime}(x_{n})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right.}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\left.-\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}x_{n}\\psi_{f,i,0}^{\\prime}(x_{n})\\sum_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{n})\\,\\mathrm{d}t\\right.}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\left.+\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}\\kappa_{f,i}(x_{n})y_{n}x_{n}\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\,\\mathrm{d}t\\right..}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Similarly, the time evolution of $a_{i}(t)$ from $t=0$ to $t=T_{f}$ can be computed as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\Delta a_{i}(T_{f})=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}({\\pmb x}_{n})\\,\\mathrm{d}t}\\ ~}\\\\ {{\\displaystyle~~~~~~~~~=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\ ~}\\\\ {{\\displaystyle~~~~~~~~~~+\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}\\kappa_{f,i}({\\pmb x}_{n})y_{n}\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}({\\pmb x}_{n})-\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n}))\\,\\mathrm{d}t}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Thus, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Delta h_{f,i,T_{f}}(z)}\\\\ {\\displaystyle=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{n})\\,\\mathrm{d}t}\\\\ {\\displaystyle=\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\psi_{f,i,0}^{\\prime}(x_{n})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle\\quad+\\,\\frac{\\alpha_{i}}{N}\\sum_{n}^{N}\\kappa_{f,i}(x_{n})y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The original network at the training time $T_{f}$ can be computed as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{f(z;T_{f}):=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}(z)}}\\ ~}\\\\ {{\\displaystyle{\\quad~~~~=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(z)h_{f,i,0}(z)+\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(z)\\Delta h_{f,i,T_{f}}(z))}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The first term of Eq. (A110) can be rearranged as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(z)h_{f,i,0}(z)}}\\\\ {{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}(1-\\kappa_{f,i}(z))\\psi_{f,i,0}^{\\prime}(z)h_{f,i,0}(z)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)\\psi_{f,i,T_{f}}^{\\prime}(z)h_{f,i,0}(z)}}\\\\ {{\\displaystyle=f(z;0)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))h_{f,i,0}(z).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The second term of Eq. (A110) can be rearranged as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(z)\\Delta h_{f,i,T_{f}}(z))}\\\\ &{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}(1-\\kappa_{f,i}(z))\\psi_{f,i,0}^{\\prime}(z)\\Delta h_{f,i,T_{f}}(z)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)\\psi_{f,i,T_{f}}^{\\prime}(z)\\Delta h_{f,i,T_{f}}(z)}\\\\ &{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(z)\\Delta h_{f,i,T_{f}}(z)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)\\big(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z)\\big)\\Delta h_{f,i,T_{f}}(z).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The first term of Eq. (A114) can be rearranged as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\sum_{i}^{m}a_{i}\\psi_{j,i}^{\\prime}(z)\\Delta h_{j,i,\\tau_{j}}(z)}\\\\ &{=\\displaystyle\\sum_{i}^{m}a_{i}\\psi_{j,i,0}^{\\prime}(z)\\left[\\frac{\\alpha_{i}}{N}\\sum_{m}^{}y_{m}((x_{n},z)+1)\\psi_{j,i,0}^{\\prime}(x_{n})\\int_{0}^{\\tau_{j}}\\ell_{f,n,i}^{\\prime}\\,d t\\right.}\\\\ &{\\quad\\left.+\\frac{\\alpha_{i}}{N}\\sum_{m}^{N}\\kappa_{j,i}(x_{n})y_{m}((x_{n},z)+1)\\int_{0}^{\\tau_{j}}\\ell_{f,n,i}^{\\prime}(\\psi_{j,i,0}^{\\prime}(x_{n})-\\psi_{j,i,0}^{\\prime}(x_{n}))\\,\\mathrm{d}t\\right]}\\\\ &{=\\displaystyle\\frac{1}{N}\\sum_{m}^{N}y_{m}((x_{n},z)+1)\\int_{0}^{\\tau_{j}}\\ell_{f,n,i}^{\\prime}\\,d t\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{j,i,0}^{\\prime}(x_{n})\\psi_{j,i,0}^{\\prime}(z)}\\\\ &{\\quad+\\displaystyle\\frac{1}{N}\\sum_{m}^{N}y_{n}((x_{n},z)+1)}\\\\ &{\\quad\\times\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{j,i}(x_{n})\\psi_{j,i,0}^{\\prime}(z)\\int_{0}^{\\tau_{j}}\\ell_{f,n,i}^{\\prime}(\\psi_{j,i,1}^{\\prime}(x_{n})-\\psi_{j,i,0}^{\\prime}(x_{n}))\\,\\mathrm{d}t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The first term of Eq. (A116) can be rearranged as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)}\\\\ {\\displaystyle=\\!\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left(\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)-\\Phi(x_{n},z)\\right)}\\\\ {\\displaystyle\\;\\;\\;+\\left.\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The second term of Eq. (A114) can be rearranged as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,\\,T_{f}}^{\\prime}(z)-\\psi_{f,i,\\,0}^{\\prime}(z))\\Delta h_{f,i,\\,T_{f}}(z)}\\\\ &{=\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,\\,T_{f}}^{\\prime}(z)-\\psi_{f,i,\\,0}^{\\prime}(z))}\\\\ &{\\quad\\displaystyle\\times\\cfrac{\\alpha_{i}}{N}\\sum_{w}^{N}y_{n}((x_{n},z)+1)\\int_{0}^{T}\\ell_{f,n,\\,t}^{\\prime}\\psi_{f,i,\\,t}^{\\prime}(x_{n})\\,\\mathrm{d}t}\\\\ &{=\\displaystyle\\cfrac{1}{N}\\sum_{w}^{N}y_{n}((x_{n},z)+1)}\\\\ &{\\quad\\displaystyle\\times\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(z)(\\psi_{f,i,\\,T_{f}}^{\\prime}(z)-\\psi_{f,i,\\,0}^{\\prime}(z))\\int_{0}^{T}\\ell_{f,n,\\,t}^{\\prime}\\psi_{f,i,\\,t}^{\\prime}(x_{n})\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The sum of the second term of Eq. (A116) and Eq. (A121) can be rearranged as ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\frac1N\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{n})\\psi_{f,i,0}^{\\prime}(z)\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\,\\mathrm{d}t}}\\\\ {{\\displaystyle\\quad+\\,\\frac1N\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(z)(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{n})\\,\\mathrm{d}t}}\\\\ {{\\displaystyle=\\frac1N\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{n})}}\\\\ {{\\displaystyle\\quad\\quad\\times\\int_{0}^{T_{f}}\\ell_{f,i,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z))\\,\\mathrm{d}t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Lemma D.10 (Upper bounds of terms in Lemma D.9). Assume Assumptions D.1 and D.5. ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "(a) ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\displaystyle\\left|\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))h_{f,i,0}(z)\\right|}\\\\ &{<\\!2\\eta(1-\\gamma)\\ln(2m/\\delta)\\sqrt{\\|z\\|^{2}/d+1}=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "(b) ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\left\\lvert\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left(\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)-\\Phi(x_{n},z)\\right)\\right\\rvert}\\\\ &{}&{\\displaystyle<\\frac{8C_{\\mathrm{thr}}(z,\\delta)\\ln(2/\\delta)}{\\sqrt{\\ln(2m/\\delta)}}=\\tilde{\\mathcal{O}}(1).}&{(\\mathrm{A12})}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "(c) ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\lvert\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{n})\\right.}\\\\ {\\displaystyle\\left.\\times\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z))\\,\\mathrm{d}t\\,\\right\\rvert}\\\\ {\\displaystyle<\\eta(1-\\gamma^{2})C_{\\mathrm{thr}}(z,\\delta)\\sqrt{\\ln(2m/\\delta)}=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Proof. ", "page_idx": 32}, {"type": "text", "text": "(a) By Assumption D.1, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\left\\vert\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))h_{f,i,0}(z)\\right\\vert\\le\\!(1-\\gamma)\\displaystyle\\sum_{i}^{m}|\\alpha_{i}\\kappa_{f,i}(z)h_{f,i,0}(z)|\\displaystyle}\\\\ {\\displaystyle<2\\eta(1-\\gamma)\\ln(2m/\\delta)\\sqrt{\\|z\\|^{2}/d+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "(b) By Assumption D.1, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\displaystyle\\frac{1}{N}\\sum_{n}^{N}y_{n}(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)-\\Phi(x_{n},z)\\right)\\right|}\\\\ &{<\\displaystyle\\frac{16}{N\\sqrt{m}}\\ln\\!\\left(\\displaystyle\\frac{2}{\\delta}\\right)\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "By Assumption D.5, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\displaystyle\\frac{16}{N\\sqrt{m}}\\ln\\left(\\frac{2}{\\delta}\\right)\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{<\\displaystyle\\frac{N C_{\\mathrm{thr}}(z,\\delta)}{2\\sqrt{\\ln(2m/\\delta)}\\sum_{n}^{N}(|\\langle x_{n},z\\rangle|+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}}\\\\ &{~~~\\displaystyle\\times\\,\\frac{16}{N}\\ln\\left(\\frac{2}{\\delta}\\right)\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{\\le\\displaystyle\\frac{8C_{\\mathrm{thr}}(z,\\delta)\\ln(2/\\delta)}{\\sqrt{\\ln(2m/\\delta)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "(c) By Assumption D.1, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\vert\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(\\pmb{x}_{n})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(\\pmb{x}_{n})\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{n})\\psi_{f,i,0}^{\\prime}(z))\\,\\mathrm{d}t\\right\\vert}\\\\ {\\displaystyle\\le(1-\\gamma^{2})\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(\\pmb{x}_{n})}\\\\ {\\displaystyle<\\frac{2\\eta(1-\\gamma^{2})}{\\sqrt{m}}\\ln\\left(\\frac{2m}{\\delta}\\right)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By Assumption D.5, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\frac{2\\eta(1-\\gamma^{2})}{N\\sqrt{m}}\\ln\\left(\\frac{2m}{\\delta}\\right)\\displaystyle\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{<\\displaystyle\\frac{N C_{\\mathrm{thr}}(z,\\delta)}{2\\sqrt{\\ln(2m/\\delta)}\\sum_{n}^{N}(|\\langle x_{n},z\\rangle|+1)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}}\\\\ &{\\quad\\times\\displaystyle\\frac{2\\eta(1-\\gamma^{2})}{N}\\ln\\left(\\frac{2m}{\\delta}\\right)\\displaystyle\\sum_{n}^{N}|\\langle x_{n},z\\rangle+1|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{\\leq\\!\\eta(1-\\gamma^{2})C_{\\mathrm{thr}}(z,\\delta)\\sqrt{\\ln(2m/\\delta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Lemma D.11 (Network prediction of $f$ ). Assume Assumptions D.1 and D.5. If ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\left|\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(\\boldsymbol{x}_{n},z)\\langle\\boldsymbol{x}_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right|\\geq\\tilde{\\mathcal{O}}\\left(1+\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right),\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "then ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathrm{sgn}(f(z;T_{f}))=\\mathrm{sgn}\\left(\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. By Assumption D.1 and Lemmas D.9 and D.10, if ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\lvert\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right\\rvert}\\\\ {\\displaystyle\\geq\\lvert f(z;0)\\rvert+\\left\\lvert\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(z)(\\psi_{f,i,T_{f}}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(z))h_{f,i,0}(z)\\right\\rvert}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\left|\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{n}^{N}y_{n}(\\{x_{n},z\\}+1)\\int_{0}^{T_{f}}{\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z)-\\Phi(x_{n},z)\\right)\\right|}\\\\ &{\\quad+\\left|\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{n}^{N}y_{n}(\\{x_{n},z\\}+1)\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}^{\\prime}(x_{n})\\right.}\\\\ &{\\qquad\\,\\times\\left.\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{n})\\psi_{f,i,T}^{\\prime}(z)-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(z))\\,\\mathrm{d}t\\right|}\\\\ &{\\quad+\\left|\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right|}\\\\ &{\\quad-\\tilde{O}\\left(1+\\displaystyle\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "then ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathrm{sgn}(f(z;T_{f}))=\\mathrm{sgn}\\left(\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Lemma D.12 (Adversarial perturbation). If Assumptions $D.I$ and D.5 hold, then the adversarial perturbation defined as Eq. (1) can be represented as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{n}=\\mathrm{e}_{\\parallel_{n}}^{\\prime\\prime\\prime}\\frac{\\sum_{i=1}^{n}\\alpha_{i}\\mathrm{e}_{j,i,j^{\\prime},\\left(\\alpha_{n}\\right)\\mathrm{e}_{i}}\\left(T_{j}\\right)}{\\left\\|\\sum_{i=1}^{n}\\alpha_{i}\\mathrm{e}_{j,i^{\\prime},j^{\\prime}}\\left(\\alpha_{n}\\right)\\mathrm{e}_{i}T_{n}\\right\\|},\\quad\\mathrm{and}}\\\\ &{\\Bigg\\Updownarrow}\\\\ &{\\sum_{i=1}^{n}\\alpha_{i}\\mathrm{e}_{j,i^{\\prime},j^{\\prime}}\\left(\\alpha_{n}\\right)\\mathrm{e}_{i}\\left(T_{j}\\right)}\\\\ &{=\\frac{\\sum_{i=1}^{n}\\alpha_{i}\\mathrm{e}_{j,i^{\\prime}}\\left(\\alpha_{n}\\right)\\mathrm{e}_{i}\\left(0\\right)}{\\sum_{i=1}^{n}\\alpha_{i}\\mathrm{e}_{j,i}\\left(\\alpha_{n}\\right)\\left(e_{i,i,j^{\\prime},\\left(\\alpha_{n}\\right)}^{\\prime}-\\mathrm{e}_{j,i,j^{\\prime},\\left(\\alpha_{n}\\right)}^{\\prime}\\right)\\mathrm{e}_{i}\\left(0\\right)}}\\\\ &{\\qquad+\\frac{1}{N}\\frac{N}{N}\\mathrm{e}_{i}\\alpha_{n}\\mathrm{e}_{j}^{\\prime\\prime}\\left(\\tau_{j}^{\\prime}\\mathrm{e}_{i,i}\\mathrm{e}\\left(\\Bigg(\\sum_{i=1}^{n}\\alpha_{i}^{\\prime}\\mathrm{e}_{j,i,j^{\\prime}}\\left(\\alpha_{n}\\right)\\mathrm{e}_{j,i,j^{\\prime},\\left(\\alpha_{n}\\right)}^{\\prime}-\\mathrm{e}_{i,j^{\\prime},i,j^{\\prime}}\\right)\\right)}\\\\ &{\\qquad+\\frac{1}{N}\\frac{N}{N}\\mathrm{e}_{i}\\alpha(\\alpha_{n},\\alpha_{i})\\mathrm{e}_{j}\\Bigg[\\tau_{j}^{\\prime\\prime}\\left(\\ell_{j,i,k}^{\\prime\\prime}\\mathrm{e}_{i,i}\\mathrm{e}\\left(\\mathrm{e}_{1,i}^{\\prime\\prime}\\right)-\\mathrm{e}_{i,j^{\\prime},k}^{\\prime\\prime}\\mathrm{e}_{i,j^{\\prime},\\left(\\alpha_{n}\\right)}^{\\prime}\\right)}\\\\ &{\\qquad+\\frac{1}{N}\\frac{N}{N}\\mathrm{e}_{i}\\alpha \n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. The main term of the adversarial perturbation can be computed as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\nabla_{\\pmb{x}_{n}}\\ell_{f,n,T_{f}}}{\\|\\nabla_{\\pmb{x}_{n}}\\ell_{f,n,T_{f}}\\|}=\\!\\frac{-y_{n}^{\\mathrm{adv}}\\ell_{f,n,T_{f}}^{\\prime}\\nabla_{\\pmb{x}_{n}}f\\left(\\pmb{x}_{n};\\pmb{\\theta}_{V,a}(T_{f})\\right)}{\\|\\ell_{f,n,T_{f}}^{\\prime}\\nabla_{\\pmb{x}_{n}}f\\left(\\pmb{x}_{n};\\pmb{\\theta}_{V,a}(T_{f})\\right)\\|}}\\\\ &{}&{=-\\,y_{n}^{\\mathrm{adv}}\\frac{\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(\\pmb{x}_{n})\\pmb{v}_{i}(T_{f})}{\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(\\pmb{x}_{n})\\pmb{v}_{i}(T_{f})\\|}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The leading term can be rearranged as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})v_{i}(T_{f})=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})v_{i}(0)+\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\Delta v_{i}(T_{f}).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The first term of Eq. (A144) can be rearranged as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})v_{i}(0)}\\\\ &{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})v_{i}(0)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))v_{i}(0).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The second term of Eq. (A144) can be rearranged as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\Delta v_{i}(T_{f})}\\\\ &{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})\\Delta v_{i}(T_{f})+\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n})\\Delta v_{i}(T_{f}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The first term of Eq. (A146) can be rearranged as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\bf x}_{n})\\Delta{\\bf v}_{i}(T_{f})}\\ ~}\\\\ {{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\bf x}_{n})\\left[\\frac{\\alpha_{i}}{N}\\sum_{k}^{N}y_{k}x_{k}\\psi_{f,i,0}^{\\prime}(x_{k})\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right.}\\ ~}\\\\ {{\\displaystyle~~~\\left.+\\frac{\\alpha_{i}}{N}\\sum_{k}^{N}\\kappa_{f,i}(x_{k})y_{k}x_{k}\\int_{0}^{T}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\right]}\\ ~}\\\\ {{\\displaystyle=\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k})}\\ ~}\\\\ {{\\displaystyle~~~+\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\psi_{f,i,0}^{\\prime}(x_{n})\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t}\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The second term of Eq. (A146) can be rearranged as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\Delta v_{i}(T_{f})}\\ ~}\\\\ {{\\displaystyle=\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\frac{\\alpha_{i}}{N}\\sum_{k}^{N}y_{k}x_{k}\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{k})\\,\\mathrm{d}t}\\ ~}\\\\ {{\\displaystyle=\\!\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{k})\\,\\mathrm{d}t\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The sum of the second term of Eq. (A148) and Eq. (A150) can be rearranged as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\psi_{f,i,0}^{\\prime}(x_{n})\\left(x_{n}\\right)\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t}\\\\ {\\displaystyle\\quad+\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i,T_{i}}(x_{n})(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\psi_{f,i,t}^{\\prime}(x_{k})\\,\\mathrm{d}t}\\\\ {\\displaystyle=\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})}\\\\ {\\displaystyle\\quad\\times\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma D.13 (Upper bound of norm of adversarial perturbation). Assume Assumptions D.1 and D.5. (a) ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})v_{i}(0)\\right\\|^{2}<4\\ln(2d m/\\delta)\\ln(2/\\delta)=\\tilde{\\mathcal{O}}(1).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "(b) ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(\\pmb{x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}(\\pmb{x}_{n})-\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{n}))\\pmb{v}_{i}(0)\\right\\|^{2}}\\\\ &{<4\\eta^{2}(1-\\gamma)^{2}\\ln(2m/\\delta)\\ln(2d m/\\delta)=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "(c) ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\displaystyle\\frac{1}{N}\\sum_{k}^{N}y_{k}\\pmb{x}_{k}\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{n})\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{k})-\\Phi(\\pmb{x}_{n},\\pmb{x}_{k})\\right)\\right\\|^{2}}\\\\ &{<64\\ln^{2}{(2/\\delta)}=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "(d) ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\|\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\right.}\\\\ {\\displaystyle\\quad\\times\\left.\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\right\\|^{2}}\\\\ {\\displaystyle<\\eta^{2}(1-\\gamma^{2})^{2}\\ln^{2}(2m/\\delta)=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "(e) ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(\\mathbf{x}_{n})\\mathbf{v}_{i}(T_{f})\\right\\|<\\tilde{\\mathcal{O}}\\left(\\sqrt{d}\\int_{0}^{T_{f}}\\bar{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "$(f)$ Let ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle r_{n}^{\\prime}:=\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\bf x}_{n})\\boldsymbol\\ v_{i}(0)+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}({\\bf x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}({\\bf x}_{n})-\\psi_{f,i,0}^{\\prime}({\\bf x}_{n}))\\boldsymbol v_{i}(0)}\\\\ {\\displaystyle\\ ~~~~~+\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\left(\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}({\\bf x}_{n})\\psi_{f,i,0}^{\\prime}({\\bf x}_{k})-\\Phi({\\bf x}_{n},{\\bf x}_{k})\\right)}\\\\ {\\displaystyle~~~~~~+\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})}\\\\ {\\displaystyle~~~~~\\times\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}({\\bf x}_{k})-\\psi_{f,i,0}^{\\prime}({\\bf x}_{n})\\psi_{f,i,0}^{\\prime}({\\bf x}_{k}))\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then, $\\lVert\\pmb{r}_{n}^{\\prime}\\rVert<\\tilde{O}(1)$ . ", "page_idx": 36}, {"type": "text", "text": "Proof. ", "page_idx": 36}, {"type": "text", "text": "(a) The given left term can be rearranged as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})v_{i}(0)\\right\\|^{2}=\\sum_{j}^{d}\\left(\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})v_{i,j}(0)\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By Assumption D.1, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left(\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})v_{i,j}(0)\\right)^{2}<(2/m)\\ln(2/\\delta)\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n})^{2}v_{i,j}(0)^{2}}}\\\\ &{}&{\\mathrm{<}(4/d)\\ln(2d m/\\delta)\\ln(2/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "(b) The given left term can be rearranged as ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left\\|\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(\\mathbf{x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}(\\mathbf{x}_{n})-\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n}))v_{i}(0)\\right\\|^{2}}\\\\ &{=\\displaystyle\\sum_{j}^{d}\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(\\mathbf{x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}(\\mathbf{x}_{n})-\\psi_{f,i,0}^{\\prime}(\\mathbf{x}_{n}))v_{i,j}(0)\\right)^{2}}\\\\ &{\\le(1-\\gamma)^{2}\\displaystyle\\sum_{j}^{d}\\left(\\displaystyle\\sum_{i}^{m}|\\alpha_{i}\\kappa_{f,i}(\\mathbf{x}_{n})v_{i,j}(0)|\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "By Assumption D.1, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\left(\\sum_{i}^{m}|\\alpha_{i}\\kappa_{f,i}(\\pmb{x}_{n})v_{i,j}(0)|\\right)^{2}<(4\\eta^{2}/d)\\ln(2m/\\delta)\\ln(2d m/\\delta).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "(c) By Assumption D.1, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\left\\|\\frac{1}{N}\\sum_{k}^{N}y_{k}{\\pmb x}_{k}\\int_{0}^{T_{f}}{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})\\psi_{f,i,0}^{\\prime}({\\pmb x}_{k})-\\Phi({\\pmb x}_{n},{\\pmb x}_{k})\\right)\\right\\|^{2}}}\\\\ {{\\displaystyle<\\frac{256}{m N^{2}}\\ln^{2}\\left(\\frac{2}{\\delta}\\right)\\sum_{n,k}^{N}|\\langle{\\pmb x}_{n},{\\pmb x}_{k}\\rangle|\\displaystyle\\int_{0}^{T_{f}}{\\ell}_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\displaystyle\\int_{0}^{T_{f}}{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "By Assumption D.5, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{256}{N^{2}}\\ln^{2}\\left(\\frac{2}{\\delta}\\right)\\sum_{n,k}^{N}|\\langle x_{n},x_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\qquad4\\sum_{n,k}^{N}|\\langle x_{n},x_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle<64\\ln^{2}(2/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "(d) The given left term can be rearranged as ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left|\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(\\boldsymbol{x}_{k})\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(\\boldsymbol{x}_{n})\\psi_{f,i,t}^{\\prime}(\\boldsymbol{x}_{k})-\\psi_{f,i,0}^{\\prime}(\\boldsymbol{x}_{n})\\psi_{f,i,0}^{\\prime}(\\boldsymbol{x}_{k}))\\,\\mathrm{d}t\\right|}\\\\ &{\\le\\!(1-\\gamma^{2})\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(\\boldsymbol{x}_{k})\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "By Assumption D.1, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})<\\frac{2\\eta}{\\sqrt{m}}\\ln\\biggl(\\frac{2m}{\\delta}\\biggr).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Thus, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\left\\|\\frac{1}{N}\\sum_{k}^{N}y_{k}x_{k}\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\right\\|^{2}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n<\\!\\frac{4\\eta^{2}(1-\\gamma^{2})^{2}}{m N^{2}}\\ln^{2}\\left(\\frac{2m}{\\delta}\\right)\\sum_{n,k}^{N}|\\langle{\\pmb x}_{n},{\\pmb x}_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "By Assumption D.5, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\ \\ \\displaystyle\\frac{4\\eta^{2}(1-\\gamma^{2})^{2}}{m N^{2}}\\ln^{2}\\left(\\frac{2m}{\\delta}\\right)\\sum_{n,k}^{N}|\\langle x_{n},x_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}}\\\\ {{\\ \\ \\ <\\displaystyle\\frac{4\\eta^{2}(1-\\gamma^{2})^{2}}{N^{2}}\\ln^{2}\\left(\\frac{2m}{\\delta}\\right)\\sum_{n,k}^{N}|\\langle x_{n},x_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}}\\\\ {{\\ \\ \\ \\ \\times\\displaystyle\\frac{N^{2}}{4\\sum_{n,k}^{N}|\\langle x_{n},x_{k}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}}}\\\\ {{\\ \\ \\ =\\eta^{2}(1-\\gamma^{2})^{2}\\ln^{2}(2m/\\delta).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "(e) As $\\begin{array}{r}{\\|s_{1}\\,+\\,s_{2}\\,+\\,s_{3}\\,+\\,s_{4}\\,+\\,s_{5}\\|^{2}\\ \\le\\ 25\\operatorname*{max}(\\|s_{1}\\|^{2},\\|s_{2}\\|^{2},\\|s_{3}\\|^{2},\\|s_{4}\\|^{2},\\|s_{5}\\|^{2})}\\end{array}$ for any $s_{1},s_{2},s_{3},s_{4},s_{5}\\in\\mathbb{R}^{d}$ , ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(\\mathbf{x}_{n})\\boldsymbol{v}_{i}(T_{f})\\right\\|^{2}<25\\operatorname*{max}\\left(\\left(\\begin{array}{c}{4\\ln(2d m/\\delta)\\ln(2/\\delta),}\\\\ {4\\eta^{2}(1-\\gamma)^{2}\\ln(2m/\\delta)\\ln(2d m/\\delta),}\\\\ {64\\ln^{2}(2/\\delta),}\\\\ {\\eta^{2}(1-\\gamma^{2})^{2}\\ln^{2}(2m/\\delta),}\\\\ {\\left(\\displaystyle\\left\\|\\frac{1}{N}\\sum_{k}^{N}y_{k}\\Phi(\\mathbf{x}_{n},\\mathbf{x}_{k})\\boldsymbol{x}_{k}\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right\\|^{2}\\right).}\\end{array}\\right)\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "(f) Similarly to (e), ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\|r_{n}^{\\prime}\\|^{2}<16\\operatorname*{max}\\left(4\\eta^{2}(1-\\gamma)^{2}\\ln(2d m/\\delta)\\ln(2/\\delta),\\right).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Lemma D.14 (Upper bounds of inner products with adversarial perturbation). Assume Assumptions $D.I$ and $D.5$ . ", "page_idx": 38}, {"type": "text", "text": "(a) ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\left|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\pmb x}_{n})\\langle{\\pmb v}_{i}(0),{\\pmb z}\\rangle\\right|<2\\sqrt{(1/d)\\ln(2/\\delta)\\ln(2m/\\delta)}\\|{\\pmb z}\\|=\\tilde{O}(1).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "(b) ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\left|\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(\\pmb{x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}(\\pmb{x}_{n})-\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{n}))\\langle\\pmb{v}_{i}(0),\\pmb{z}\\rangle\\right|}\\\\ &{<2\\eta(1-\\gamma)\\ln(2m/\\delta)\\|z\\|/\\sqrt{d}=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "(c) ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left|\\frac{1}{N}\\sum_{k}^{N}y_{k}\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\left(\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k})-\\Phi(x_{n},x_{k})\\right)\\right|_{0}^{t}}}\\\\ &{}&{\\displaystyle<\\frac{8C_{\\mathrm{thr}}(z,\\delta)\\ln(2/\\delta)}{\\sqrt{\\ln(2m/\\delta)}}=\\tilde{\\mathcal{O}}(1).}&{(\\mathrm{A})}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "(d) ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\frac{1}{N}\\sum_{k}^{N}y_{k}\\langle x_{k},z\\rangle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\right.}\\\\ &{\\displaystyle\\qquad\\times\\left.\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\right\\rvert}\\\\ &{\\displaystyle<\\eta(1-\\gamma^{2})C_{\\mathrm{thr}}(z,\\delta)\\sqrt{\\ln(2m/\\delta)}=\\tilde{\\mathcal{O}}(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Proof. ", "page_idx": 39}, {"type": "text", "text": "(a) By Assumption D.1, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\left\\lvert\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}({\\boldsymbol x}_{n})\\langle{\\boldsymbol v}_{i}(0),{\\boldsymbol z}\\rangle\\right\\rvert<\\!\\sqrt{\\displaystyle\\frac{2}{m}\\ln\\!\\left(\\frac{2}{\\delta}\\right)\\displaystyle\\sum_{i}^{m}\\psi_{f,i,0}^{\\prime}({\\boldsymbol x}_{n})^{2}\\langle{\\boldsymbol v}_{i}(0),{\\boldsymbol z}\\rangle^{2}}}}\\\\ {{\\displaystyle\\qquad\\qquad\\qquad\\leq\\!\\sqrt{\\displaystyle\\frac{2}{m}\\ln\\!\\left(\\frac{2}{\\delta}\\right)\\displaystyle\\sum_{i}^{m}\\langle{\\boldsymbol v}_{i}(0),{\\boldsymbol z}\\rangle^{2}}}}\\\\ {{\\displaystyle\\qquad\\qquad<2\\sqrt{(1/d)\\ln\\!\\left(2/\\delta\\right)\\ln\\!\\left(2m/\\delta\\right)}\\lVert{\\boldsymbol z}\\rVert.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "(b) By Assumption D.1, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\lvert\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(\\pmb{x}_{n})(\\psi_{f,i,T_{f}}^{\\prime}(\\pmb{x}_{n})-\\psi_{f,i,0}^{\\prime}(\\pmb{x}_{n}))\\langle\\pmb{v}_{i}(0),\\pmb{z}\\rangle\\right\\rvert}\\\\ {\\displaystyle\\leq(1-\\gamma)\\sum_{i}^{m}\\left\\lvert\\alpha_{i}\\kappa_{f,i}(\\pmb{x}_{n})\\langle\\pmb{v}_{i}(0),\\pmb{z}\\rangle\\right\\rvert}\\\\ {\\displaystyle<2\\eta(1-\\gamma)\\ln(2m/\\delta)\\lVert\\pmb{z}\\rVert/\\sqrt{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "(c) and (d) Similarly to Lemma D.10. ", "page_idx": 39}, {"type": "text", "text": "Lemma D.15 (Representation of network $g$ ). Suppose that Assumptions D.1, D.3, D.5 and D.7. (a) In Scenario (a), i.e., $\\pmb{x}_{n}^{\\mathrm{adv}}:=\\pmb{r}_{n}$ , ", "page_idx": 39}, {"type": "equation", "text": "$$\ng(z;T_{g})\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=g(z;0)+\\displaystyle\\sum_{i}^{m}\\beta_{i}\\kappa_{i,\\theta}\\alpha_{i}\\alpha_{j}(\\nu_{\\theta,i}^{\\prime},r_{\\alpha}(z)-\\nu_{\\theta,i}^{\\prime},\\alpha_{i}(z))h_{\\theta,i,\\theta}(z)}\\\\ {\\displaystyle\\ +\\frac{1}{N}\\sum_{i}^{N}\\nu_{m}^{\\mathrm{adv}}(r_{m},z)+1\\sum_{i}^{T^{*}}\\ell_{\\xi,n}^{\\prime},\\mathrm{d}t}\\\\ {\\displaystyle\\ \\ \\ \\times\\left(\\sum_{i}^{m}\\beta_{i}^{2}\\ell_{\\theta,i}^{\\prime}(r_{m})\\psi_{\\theta,i}^{\\prime}(z)-\\Phi(r_{n},z)\\right)}\\\\ {\\displaystyle\\ +\\frac{1}{N}\\sum_{i}^{N}\\nu_{m}^{\\mathrm{adv}}\\Phi(r_{m},z)\\int_{0}^{T^{*}}\\ell_{\\theta,n}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle\\ +\\frac{1}{N}\\sum_{i}^{N}y_{i}^{\\mathrm{adv}}(r_{m},z)+1\\sum_{i}^{m}\\beta_{i}^{2}\\kappa_{i,\\theta}(r_{n})}\\\\ {\\displaystyle\\ \\ \\ \\times\\int_{0}^{T^{*}}\\ell_{\\phi,n}^{\\prime}(\\psi_{\\theta,i}^{\\prime}(r_{n})\\psi_{\\phi,i}^{\\prime}(z)-\\psi_{\\theta,i}^{\\prime}(r_{n})\\psi_{\\phi,i}^{\\prime}(z))\\,\\mathrm{d}t}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad=\\frac{c}{N!\\prod_{s}^{N}}\\frac{c}{\\prod_{s}^{N}(x_{t},y_{t}^{\\prime})\\prod_{s}^{N}(x_{t})}\\prod_{s}^{N}\\left[\\displaystyle\\sum_{s=1}^{N}\\phi(r_{s,t+1})\\int_{0}^{x_{t}}\\psi_{\\mu,\\mu}^{(\\pm)}\\psi_{\\nu,\\mu}^{(\\pm)}d t\\right]}\\\\ &{\\quad\\times\\frac{\\partial}{\\partial{\\phi_{s}^{N}}_{1}}\\chi_{\\mu,\\nu}^{(\\pm)}(x_{t})\\psi_{\\mu,\\nu}^{(0)}(x_{t}),}\\\\ &{\\quad\\times\\frac{\\partial}{\\partial{\\phi_{s}^{N}}_{2}}\\chi_{\\mu,\\nu}^{(\\pm)}(x_{t})\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})-\\psi_{\\mu,\\mu}^{(\\pm)}(x_{s}))(\\psi_{\\nu,\\mu}^{(0)}(x_{t}),s)}\\\\ &{\\quad+\\sum_{s}^{N}\\alpha_{t}\\chi_{\\mu,\\nu}^{(\\pm)}(x_{t})\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})-\\psi_{\\mu,\\mu}^{(\\pm)}(x_{s})\\psi_{\\nu,\\mu}^{(\\pm)}(x_{s}),s)}\\\\ &{\\quad+\\frac{1}{N!}\\sum_{s}^{N}\\beta_{t}\\chi_{\\mu,\\nu}^{(\\pm)}\\sum_{s=1}^{N}\\psi_{\\mu,\\nu}^{(\\pm)}(\\sum_{s=1}^{N}\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})-\\phi(x_{s},x_{t})\\right)}\\\\ &{\\quad+\\frac{1}{N!}\\sum_{s}^{N}\\beta_{t}\\chi_{\\mu,\\nu}^{(\\pm)}\\sum_{s=1}^{N}\\alpha_{t}^{2}\\chi_{\\mu,\\nu}^{(\\pm)}(x_{s})}\\\\ &{\\quad\\times\\int_{0}^{x}\\psi_{\\mu,\\nu}^{(\\pm)}(\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})-\\psi_{\\mu,\\nu}^{(\\pm)}(x_{s})\\psi \n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "(b) In Scenario $(b)_{\\cdot}$ , i.e., ${\\pmb x}_{n}^{\\mathrm{adv}}:={\\pmb x}_{n}+{\\pmb r}_{n}$ ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(\\tau|\\tau)}\\\\ &{\\otimes(\\tau|\\tau)+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(0,t)\\big(\\eta_{k+1}^{t},\\tau_{k}^{t};0\\big)-\\eta_{k+1}^{t}(\\alpha,t)\\big(\\hat{b}_{k+1}(\\alpha)\\big)}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(0,t)\\big(\\hat{b}_{k+1}^{t}+\\eta_{k}^{t};0\\big)}\\\\ &{\\qquad\\times\\left(\\sum_{k=1}^{\\infty}\\jmath_{k}(\\tau|u_{k+1}^{t})\\big)\\right)\\leq\\tilde{\\eta}_{k}\\leq\\tilde{\\mathcal{G}}(\\tau),}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(0,t)\\big(\\hat{b}_{k+1}^{t}+\\eta_{k}^{t};0\\big)}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(\\tau|u_{k+1}^{t})\\big(\\hat{b}_{k+1}(\\alpha)\\big)+\\int_{0}^{t}\\ell_{k}\\ d u_{k}}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(\\tau|u_{k+1}^{t})\\big(\\hat{b}_{k+1}^{t}+\\eta_{k}^{t};0\\big)}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(\\tau|u_{k+1}^{t})\\big(\\hat{b}_{k+1}^{t}+\\eta_{k}^{t};0\\big)}\\\\ &{\\qquad\\times\\int_{0}^{t}\\ell_{k}\\ d u_{k}\\big(\\hat{b}_{k+1}^{t}\\big)\\tilde{\\eta}_{k}\\leq\\tilde{\\mathcal{G}}(\\tau),(u_{k}^{t})\\big(\\hat{b}_{k+1}^{t})\\tilde{\\eta}_{k+1}(0,t)\\big(\\hat{b}_{k}^{t})}\\\\ &{+\\frac{1}{\\sqrt{2}}\\sum_{k=1}^{\\infty}\\jmath_{k}(\\tau|u_{k+1}^{t})\\big(\\hat{b}_{k}^{t}+\\eta_{k}^{t};0\\big)\\bigg(\\hat{b}_{k}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\quad\\times\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\,\\Bigg\\}}\\\\ {\\displaystyle\\quad\\quad\\quad+\\,\\frac{1}{N}\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ {\\displaystyle\\quad\\quad\\quad\\times\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,\\Bigg\\].}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Proof. Similarly to Lemma D.9, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{g(z;T_{p})=g(z;0)+\\displaystyle\\sum_{i=1}^{n}\\beta_{i}\\beta_{i,i}\\alpha_{i}(z)(\\psi_{\\beta,i,T_{p}}^{\\alpha}(z)-\\psi_{\\beta,i,B}^{\\alpha}(z))h_{\\beta,i,B}(z)}\\\\ &{+\\displaystyle\\frac{1}{N}\\sum_{m^{\\prime}}\\psi_{\\beta,i}^{\\alpha\\beta_{i}}(z(x,\\psi_{\\beta^{\\prime}}^{\\alpha})+1)\\int_{0}^{\\infty}\\ell_{p,x,i}^{\\alpha\\beta}d t}\\end{array}}\\\\ &{\\begin{array}{r l}&{\\times\\left(\\displaystyle\\sum_{j=0}^{n}\\beta_{j}^{\\alpha\\beta_{j}}(x_{\\beta^{\\prime},i}^{-}(x_{\\beta^{\\prime}}^{-})\\psi_{\\beta,i,B}^{\\alpha\\beta}(z)-\\psi(x_{\\beta^{\\prime},i}^{\\alpha\\beta}),z)\\right)}\\\\ &{+\\displaystyle\\frac{1}{N}\\sum_{m^{\\prime}}\\psi_{\\beta,i}^{\\alpha\\beta_{i}}(z(x_{\\beta^{\\prime},i}^{\\alpha\\beta}),z)\\langle x_{\\beta^{\\prime},i}^{\\alpha\\beta},z\\rangle\\end{array}}\\\\ &{+\\displaystyle\\frac{1}{N}\\sum_{m^{\\prime}}\\psi_{\\beta,i}^{\\alpha\\beta_{i}}\\psi_{\\beta,i}^{\\alpha\\beta}(z(x_{\\beta^{\\prime}}^{\\alpha\\beta},z),\\psi_{\\beta^{\\prime},i,B}^{\\alpha\\beta},z)\\end{array}}\\\\ &{+\\displaystyle\\frac{1}{N}\\sum_{m^{\\prime}}\\psi_{\\beta,i}^{\\alpha\\beta_{i}}(z(x_{\\beta^{\\prime}}^{-},z)+1)\\sum_{j=0}^{n}\\ell_{p,x,i}^{\\alpha\\beta_{j}}d t}\\\\ &{+\\displaystyle\\frac{1}{N}\\sum_{m^{\\prime}}\\psi_{\\beta,i}^{\\alpha\\beta_{i}}(z(x_{\\beta^{\\prime}}^{-},z)+1)\\sum_{j=0}^{n}\\beta_{i,j}^{\\alpha\\beta_{i}}(z_{\\beta,i}^{\\alpha\\beta_{j}})}\\\\ &{~~~~\\times\\int_{0}^{\\infty}\\ell_{p,x,i}^{\\alpha\\beta_{i}}(y_{\\beta,i,B}^{\\alpha\\beta_{j}}(x_{\\beta^{\\\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "By Lemma D.12, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{N}\\sum_{n}^{N}y_{n}^{\\mathrm{adv}}\\Phi(x_{n}^{\\mathrm{adv}},z)\\langle r_{n},z\\rangle\\displaystyle\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{\\displaystyle=\\!\\frac{\\epsilon\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\langle v_{i}(T_{f}),z\\rangle}{N\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}(x_{n})v_{i}(T_{f})\\|}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "The numerator can be also rearranged as ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{MeV}},z)\\int_{0}^{T_{S}}\\ell_{g,n,t}^{\\prime}\\,d t\\,\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{I}}^{\\prime}(x_{n})\\langle v_{i}(T_{I}),z\\rangle}\\\\ &{=\\displaystyle\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{MeV}},z)\\int_{0}^{T_{S}}\\ell_{g,n,t}^{\\prime}\\,d t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,0}^{\\prime}(x_{n})\\langle v_{i}(0),z\\rangle\\right.}\\\\ &{\\displaystyle\\left.\\quad+\\sum_{i}^{m}\\alpha_{i}\\kappa_{f,i}(x_{n})(\\psi_{f,i,T_{I}}^{\\prime}(x_{n})-\\psi_{f,i,0}^{\\prime}(x_{n}))\\langle v_{i}(0),z\\rangle\\right.}\\\\ &{\\displaystyle\\left.\\quad+\\frac{1}{N}\\sum_{k}\\Re\\langle x_{k},z\\rangle\\int_{0}^{T}\\ell_{f,k,t}^{\\prime}\\,d t\\left(\\displaystyle\\sum_{i}^{m}\\alpha_{i}^{2}\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k})-\\Phi(x_{n},x_{k})\\right)}\\\\ &{\\displaystyle\\left.\\quad+\\frac{1}{N}\\sum_{k}^{N}y_{k}\\langle x_{k},z\\rangle\\sum_{i}^{m}\\alpha_{i}^{2}\\kappa_{f,i}(x_{k})\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle~~\\times\\,\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}(\\psi_{f,i,T_{f}}^{\\prime}(x_{n})\\psi_{f,i,t}^{\\prime}(x_{k})-\\psi_{f,i,0}^{\\prime}(x_{n})\\psi_{f,i,0}^{\\prime}(x_{k}))\\,\\mathrm{d}t\\,\\Bigg)}}\\\\ {{\\displaystyle~+\\,\\frac{1}{N}\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Lemma D.16 (Network prediction of $g$ ). Suppose that Assumptions D.1, D.3, D.5 and D.7. (a) In Scenario (a), if ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Biggl|\\displaystyle\\frac{1}{N^{2}}\\displaystyle\\sum_{n}^{N}\\Phi(\\boldsymbol{r}_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(\\boldsymbol{x}_{n},\\boldsymbol{x}_{k})\\langle\\boldsymbol{x}_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{>\\tilde{\\mathcal{O}}\\Biggr(\\frac{\\sqrt{d}\\int_{0}^{T_{f}}\\bar{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t}{\\epsilon}\\Biggl(1+\\Biggl|\\frac{1}{N}\\sum_{n}^{N}y_{n}^{\\mathrm{adv}}\\Phi(\\boldsymbol{r}_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\Biggr|\\Biggr)}\\\\ &{\\quad+\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\Biggr),}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "then ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{sgn}\\big(g(z;T_{g})\\big)=\\mathrm{sgn}\\left(\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi(r_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\right.}\\\\ {\\displaystyle\\left.\\times\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "(b) In Scenario $(b),\\,i f$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\lefteqn{\\left|\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right|}}\\\\ &{}&{>\\tilde{O}\\Bigg(\\frac{\\sqrt{d}\\int_{0}^{T_{f}}\\bar{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t}{\\epsilon}\\Bigg(1+\\left|\\frac{1}{N}\\sum_{n}^{N}y_{n}^{\\mathrm{adv}}\\Phi(x_{n}^{\\mathrm{adv}},z)(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\Bigg|\\Bigg)}\\\\ &{}&{+\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\Bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "then ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{sgn}(g(z;T_{g}))=\\mathrm{sgn}\\left(\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi({\\boldsymbol x}_{n}^{\\mathrm{adv}},{\\boldsymbol z})\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\right.}}\\\\ &{}&{\\qquad\\qquad\\qquad\\times\\left.\\sum_{k}^{N}y_{k}\\Phi({\\boldsymbol x}_{n},{\\boldsymbol x}_{k})\\langle{\\boldsymbol x}_{k},{\\boldsymbol z}\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Proof. We prove (a). Similarly, (b) can be established. By Lemmas D.10 and D.13 to D.15, if ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\left\\vert\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi({\\bf r}_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi({\\bf x}_{n},{\\bf x}_{k})\\langle{\\bf x}_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right\\vert}\\ ~}}\\\\ {{\\displaystyle>\\frac{\\|\\sum_{i}^{m}\\alpha_{i}\\psi_{f,i,T_{f}}^{\\prime}({\\bf x}_{n})v_{i}(T_{f})\\|}{\\epsilon}\\left\\{|g(z;0)|+\\left\\vert\\sum_{i}^{m}\\beta_{i}\\kappa_{i,g}(z)(\\psi_{g,i,T_{g}}^{\\prime}(z)-\\psi_{g,i,0}^{\\prime}(z))h_{g,i,0}(z)\\right\\vert\\right\\}}\\ ~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|{\\frac{1}{N}}\\sum_{k=0}^{\\infty}e^{k k(x_{1}-x_{2})}+\\prod_{s=1}^{\\infty}e^{-\\frac{1}{k}y_{1}}e^{\\lambda(x_{2}-y_{2})}+e^{\\frac{1}{k}y_{2}}\\Bigg|\\Bigg(\\sum_{s=1}^{\\infty}e^{\\frac{y_{1}}{2}(k\\omega_{1}/y_{2})}\\Bigg)e^{\\frac{y_{1}}{2}(k\\omega_{1}/y_{2})}+\\cdots\\Bigg|(y_{1}>1\\Bigg)}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }\\ \\ \\ \\ }\\\\ &{=\\left|{\\frac{1}{N}\\sum_{k=0}^{N}e^{\\frac{y_{1}}{2}y_{2}}+e^{-\\frac{y_{2}}{2}(k\\omega_{1}/y_{3})}\\int_{0}^{y_{2}}e^{-\\frac{y_{2}}{2}(k\\omega_{1}/y_{3})}\\right|\\Bigg|}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\times\\left|{\\frac{1}{N}}\\sum_{k=0}^{\\infty}e^{\\frac{y_{1}}{2}(k\\omega_{1}/y_{2})}+\\prod_{s=1}^{\\infty}e^{\\frac{y_{1}}{2}\\ y_{2}}e^{\\frac{y_{2}}{2}(k\\omega_{1}/y_{3})}\\right|}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\times\\int_{0}^{\\infty}e^{-\\frac{y_{1}}{2}(k\\omega_{1}/y_{3})}\\Big|\\Bigg(y_{1}^{T}e^{\\frac{y_{1}}{2}}\\Big)e^{-y_{2}}\\Big|\\Bigg(\\sum_{s=1}^{\\infty}e^{\\frac{y_{1}}{2}(k\\omega_{1}/y_{2})}\\Big|y_{1}^{T}e^{\\frac{y_{1}}{2}}\\Big)\\Bigg|\\Bigg|}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "then ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{sgn}(g(z;T_{g}))}\\\\ {\\displaystyle=\\mathrm{sgn}\\left(\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi(r_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Theorem D.17 (Perturbation learning, Scenario (a), general case). Consider Scenario (a) in Setting 3.1. Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\hat{f}^{\\mathrm{gen}}(z):=\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,,}}\\\\ {{\\displaystyle\\hat{g}_{a}^{\\mathrm{gen}}(z):=\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi(r_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , $i f$ ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{f}^{\\mathrm{gen}}(z)|>\\tilde{\\mathcal{O}}\\left(1+\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}\\,\\mathrm{d}t\\right),}\\\\ &{|\\hat{g}_{a}^{\\mathrm{gen}}(z)|}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle>\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{d}\\int_{0}^{T_{f}}\\bar{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t}{\\epsilon}\\bigg(1+\\bigg|\\frac{1}{N}\\sum_{n}y_{n}^{\\mathrm{adv}}\\Phi(r_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\bigg|\\right)+\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\bigg)\\,\\mathrm{,}}}\\\\ {{\\displaystyle~~~\\mathrm{sgn}(\\hat{f}^{\\mathrm{gen}}(z))=\\mathrm{sgn}(\\hat{g}_{a}^{\\mathrm{gen}}(z)),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "then, with probability at least $1-\\delta$ , $\\operatorname{sgn}(f(z;T_{f}))=\\operatorname{sgn}(g(z;T_{g}))$ holds. ", "page_idx": 44}, {"type": "text", "text": "Proof. By Bonferroni\u2019s inequality and Assumptions D.5 and D.7 and Lemmas D.2, D.4, D.11 and D.16, the claim is established. \u53e3 ", "page_idx": 44}, {"type": "text", "text": "Theorem D.18 (Perturbation learning, Scenario (b), general case). Consider Scenario (b) in Setting 3.1. Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\hat{f}^{\\mathrm{gen}}(z):=\\frac{1}{N}\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\,,}\\\\ {{\\displaystyle\\hat{g}_{b}^{\\mathrm{gen}}(z):=\\frac{1}{N^{2}}\\sum_{n}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{k}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,k,t}^{\\prime}\\,\\mathrm{d}t\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , $i f$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{f}^{\\mathrm{gen}}(z)|>\\tilde{\\mathcal{O}}\\mathopen{}\\mathclose\\bgroup\\left(1+\\int_{0}^{T_{f}}\\bar{\\ell}_{f,n,t}\\,\\mathrm{d}t\\aftergroup\\egroup\\right),}\\\\ &{|\\hat{g}_{b}^{\\mathrm{gen}}(z)|}\\\\ &{>\\tilde{\\mathcal{O}}\\mathopen{}\\mathclose\\bgroup\\left(\\frac{\\sqrt{d}\\int_{0}^{T_{f}}\\bar{\\ell}_{f,k,t}^{\\prime}\\,\\mathrm{d}t}{\\epsilon}\\bigg(1+\\bigg|\\frac{1}{N}\\sum_{n}^{N}y_{n}^{\\mathrm{adv}}\\Phi(x_{n}^{\\mathrm{adv}},z)(\\langle x_{n},z\\rangle+1)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\bigg|\\bigg)}\\\\ &{\\ \\ \\ +\\int_{0}^{T_{g}}\\bar{\\ell}_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\bigg),}\\\\ &{\\mathrm{sgn}(\\hat{f}^{\\mathrm{gen}}(z))=\\mathrm{sgn}(\\hat{g}_{b}^{\\mathrm{gen}}(z)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "then, with probability at least $1-\\delta$ $\\delta,\\,\\operatorname{sgn}(f(z;T_{f}))=\\operatorname{sgn}(g(z;T_{g}))$ holds. ", "page_idx": 44}, {"type": "text", "text": "Proof. By Bonferroni\u2019s inequality and Assumptions D.5 and D.7 and Lemmas D.2, D.4, D.11 and D.16, the claim is established. \u53e3 ", "page_idx": 44}, {"type": "text", "text": "Theorem 3.3 (Direction of adversarial perturbation). Let $\\delta=\\Theta(1)$ be a small positive number. Under Assumption 3.2, for any $n\\in[N]$ , with probability at least $1-\\delta$ , the adversarial perturbation $r_{n}$ is parallel to the weighted sum of training samples as follows: ", "page_idx": 44}, {"type": "equation", "text": "$$\nr_{n}//\\frac{1}{N}\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})x_{k}\\int_{0}^{T_{f}}\\ell^{\\prime}(-y_{k}f(x_{k};t))\\,\\mathrm{d}t+\\xi_{n},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $\\xi_{n}$ satisfies $\\|\\pmb{\\xi}_{n}\\|=\\tilde{O}(1)$ . In particular, for $\\ell(s)=s$ , ", "page_idx": 44}, {"type": "equation", "text": "$$\nr_{n}//\\frac{T_{f}}{N}\\sum_{k}^{N}y_{k}\\Phi({\\pmb x}_{n},{\\pmb x}_{k}){\\pmb x}_{k}+{\\pmb\\xi}_{n}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Proof. By Bonferroni\u2019s inequality and Assumptions D.5 and D.7 and Lemmas D.2, D.4, D.12 and D.13, the claim is established. \u53e3 ", "page_idx": 44}, {"type": "text", "text": "Theorem 3.4 (Perturbation learning, Scenario (a), special case of Theorem D.17). Consider Scenario (a) in Setting 3.1. Assume $\\bar{\\ell(s)}=s$ and $y_{n}^{\\mathrm{adv}}\\sim U(\\{\\pm1\\})$ for every $n\\in[N]$ . Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\hat{f}(z):=\\frac{1}{N}\\sum_{n=1}^{N}y_{n}\\Phi({\\pmb x}_{n},z)\\langle{\\pmb x}_{n},z\\rangle,\\quad\\hat{g}_{a}(z):=\\frac{1}{N^{2}}\\sum_{n=1}^{N}\\Phi({\\pmb r}_{n},z)\\sum_{k=1}^{N}y_{k}\\Phi({\\pmb x}_{n},{\\pmb x}_{k})\\langle{\\pmb x}_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , $i f$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\mathrm{(Functional~margin~condition~1)}\\quad}&&{|\\hat{f}(z)|>\\tilde{\\mathcal{O}}\\bigg(1+\\frac{1}{T_{f}}\\bigg),}\\\\ &{\\mathrm{(Functional~margin~condition~2)}\\quad}&&{|\\hat{g}_{a}(z)|>\\tilde{\\mathcal{O}}\\bigg(\\displaystyle\\frac{1}{T_{f}}+\\frac{\\sqrt{d}}{\\epsilon}\\bigg(\\frac{1}{T_{g}}+\\frac{1}{\\sqrt{N}}\\bigg)\\bigg),}\\\\ &{\\mathrm{(Agreement~condition~})\\quad}&&{\\mathrm{sgn}(\\hat{f}(z))=\\mathrm{sgn}(\\hat{g}_{a}(z)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "then, with probability at least $1-\\delta$ , $\\operatorname{sgn}(f(z;T_{f}))=\\operatorname{sgn}(g(z;T_{g}))$ holds. ", "page_idx": 45}, {"type": "text", "text": "Proof. By Bonferroni\u2019s inequality and Lemma C.2 and Theorem D.17, the claim is established. ", "page_idx": 45}, {"type": "text", "text": "Theorem 3.5 (Perturbation learning, Scenario (b), special case of Theorem D.18). Consider Scenario (b) in Setting 3.1. Assume $\\ell(s)=s$ and $y_{n}^{\\mathrm{adv}}\\sim U(\\{\\pm1\\})$ for every $n\\in[N]$ . Let $\\delta=\\Theta(1)$ be a small positive number and ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\hat{g}_{b}(z):=\\frac{1}{N^{2}}\\sum_{n=1}^{N}\\Phi(x_{n}^{\\mathrm{adv}},z)\\sum_{k=1}^{N}y_{k}\\Phi(x_{n},x_{k})\\langle x_{k},z\\rangle.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Under Assumption 3.2, for any $z\\in\\mathbb{R}^{d}$ , if the functional margin condition $^{\\,I}$ (Ineq. (9)), ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{(Func.~margin~cond.~2)}\\qquad|\\hat{g}_{b}(z)|>\\tilde{\\mathcal{O}}\\left(\\frac{1}{T_{f}}+\\frac{\\sqrt{d}}{\\epsilon}\\left(\\frac{1}{T_{g}}+\\frac{\\sqrt{\\sum_{n}^{N}(\\langle x_{n},z\\rangle+1)^{2}}}{N}\\right)\\right),}\\\\ &{\\mathrm{(Agreement~condition)}\\quad\\mathrm{sgn}(\\hat{f}(z))=\\mathrm{sgn}(\\hat{g}_{b}(z)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "then, with probability at least $1-\\delta$ , $\\operatorname{sgn}(f(z;T_{f}))=\\operatorname{sgn}(g(z;T_{g}))$ holds. ", "page_idx": 45}, {"type": "text", "text": "Proof. By Bonferroni\u2019s inequality and Lemma C.2 and Theorem D.18, the claim is established. ", "page_idx": 45}, {"type": "text", "text": "Lemma D.19 (Sufficient condition of agreement condition). If ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\frac{|\\sum_{n}^{N}y_{n}\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,|}{\\operatorname*{max}_{x\\in\\{x_{1},\\ldots,x_{N},z\\}}\\sum_{n}^{N}\\lambda(x_{n},x)|\\langle x_{n},z\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}>\\frac{1-\\gamma}{1+\\gamma},\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "then $\\mathrm{sgn}(\\hat{f}^{\\mathrm{gen}}(z))=\\mathrm{sgn}(\\hat{g}_{a}^{\\mathrm{gen}}(z))=\\mathrm{sgn}(\\hat{g}_{b}^{\\mathrm{gen}}(z))$ holds. ", "page_idx": 45}, {"type": "text", "text": "Proof. By Lemma C.4, ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left|\\sum_{n}^{N}y_{n}\\langle\\pmb{x}_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\left(\\Phi(\\pmb{x}_{n},z)-\\frac{(1+\\gamma)^{2}}4\\right)\\right|}\\\\ {\\displaystyle\\leq\\frac{(1+\\gamma)(1-\\gamma)}4\\sum_{n}^{N}\\lambda(\\pmb{x}_{n},z)|\\langle\\pmb{x}_{n},z\\rangle|\\left|\\pmb{\\zeta}_{f,n,t}^{T_{f}}\\,\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "In addition, ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{(1+\\gamma)^{2}}{4}\\Biggl|\\displaystyle\\sum_{n}^{N}y_{n}\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\Biggr|}\\\\ &{>\\frac{(1+\\gamma)(1-\\gamma)}{4}\\displaystyle\\sum_{n}^{N}\\lambda(x_{n},z)|\\langle x_{n},z\\rangle|\\langle x_{n},z\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}\\\\ &{\\leftarrow\\frac{\\left|\\sum_{n}^{N}y_{n}\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right|}{\\sum_{n}^{N}\\lambda(x_{n},z)|\\langle x_{n},z\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}>\\frac{1-\\gamma}{1+\\gamma}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Thus, if Ineq. (A207) holds, then ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathrm{sgn}\\left(\\sum_{n}^{N}y_{n}\\Phi(x_{n},z)\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right)=\\mathrm{sgn}\\left(\\sum_{n}^{N}y_{n}\\langle x_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Similarly, for any $k\\in[N]$ , if ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\frac{\\left|\\sum_{n}^{N}y_{n}\\langle\\pmb{x}_{n},\\pmb{z}\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right|}{\\sum_{n}^{N}\\lambda(\\pmb{x}_{n},\\pmb{x}_{k})|\\langle\\pmb{x}_{n},\\pmb{z}\\rangle|\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t}>\\frac{1-\\gamma}{1+\\gamma},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "then ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathrm{sgn}\\left(\\sum_{n}^{N}y_{n}\\Phi(\\mathbf{x}_{n},\\mathbf{x}_{k})\\langle\\mathbf{x}_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right)=\\mathrm{sgn}\\left(\\sum_{n}^{N}y_{n}\\langle\\mathbf{x}_{n},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "When Ineq. (A209) holds for every $k\\in[N]$ , ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{sgn}\\left(\\displaystyle\\sum_{n}^{N}\\Phi(\\boldsymbol{r}_{n},z)\\int_{0}^{T_{g}}\\ell_{g,n,t}^{\\prime}\\,\\mathrm{d}t\\sum_{l}^{N}y_{l}\\Phi(\\boldsymbol{x}_{n},\\boldsymbol{x}_{l})\\langle\\boldsymbol{x}_{l},z\\rangle\\int_{0}^{T_{f}}\\ell_{f,l,t}^{\\prime}\\,\\mathrm{d}t\\right)}\\\\ &{=\\mathrm{sgn}\\left(\\displaystyle\\sum_{l}^{N}y_{l}\\Phi(\\boldsymbol{x}_{n},\\boldsymbol{x}_{l})\\langle\\boldsymbol{x}_{l},z\\rangle\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,l,t}^{\\prime}\\,\\mathrm{d}t\\right)}\\\\ &{=\\mathrm{sgn}\\left(\\displaystyle\\sum_{n}^{N}y_{n}\\langle\\boldsymbol{x}_{n},\\boldsymbol{z}\\rangle\\displaystyle\\int_{0}^{T_{f}}\\ell_{f,n,t}^{\\prime}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "By integrating Ineqs. (A207) and (A209), the claim is established. ", "page_idx": 46}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: We have accurately described the contributions and limitations in Abstract and Introduction. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 47}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: The limitations are described in Section 3.4. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 47}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: The assumption is described in Assumption 3.2 and a brief proof is provided in Section 3.3. The complete proof can be found in Appendix D. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 48}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: The experimental setup is described in detail in Appendix B. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 48}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: All datasets we used are either openly accessible or can be artificially generated.   \nThe code is provided as supplementary material. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/pu blic/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 49}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: The experimental setup is described in detail in Appendix B. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 49}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 49}, {"type": "text", "text": "Answer: [No] ", "page_idx": 49}, {"type": "text", "text": "Justification: Error bars were not measured due to computational costs. However, we provide extensive experimental results to support our theoretical findings in Appendix B. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 49}, {"type": "text", "text": "", "page_idx": 50}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 50}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 50}, {"type": "text", "text": "Justification: Our experiments were conducted on an NVIDIA A100. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 50}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 50}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 50}, {"type": "text", "text": "Justification: Our paper strictly adheres to the NeurIPS Code of Ethics. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 50}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: This does not apply as it is a theoretical study. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: Our theoretical research does not involve such releases. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 51}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 51}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 51}, {"type": "text", "text": "Justification: We have accurately cited credits. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 51}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 52}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: We do not provide such assets. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 52}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: We did not conduct such experiments. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 52}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: We did not conduct experiments that require this. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 52}]