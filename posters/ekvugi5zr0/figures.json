[{"figure_path": "eKVugi5zr0/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the staged recruitment scheme. At each recruitment stage (each time point), a new participant is recruited and observed. At the same time, all participants who were recruited prior to the current stage are also observed again. Observations are not collected from participants who have yet to be recruited. For simplicity, we assume one participant is recruited at each stage.", "description": "This figure illustrates the staged recruitment process used in the study.  New participants are added at each stage, and data is collected on all previously recruited participants at each stage.  This creates a triangular data structure where the number of observations increases with each stage.", "section": "3 Setting"}, {"figure_path": "eKVugi5zr0/figures/figures_8_1.jpg", "caption": "Figure 2: Cumulative regret in the (a) Homogeneous Users, (b) Heterogeneous Users, and (c) Nonlinear settings. RoME performs competitively in the first setting (the simplest), and it substantially outperforms the next-best method (IntelPooling) in the others.", "description": "This figure displays the average cumulative regret for four different contextual bandit algorithms across three simulation settings: homogeneous users, heterogeneous users, and nonlinear setting.  The x-axis represents the stage of the simulation, and the y-axis represents the cumulative regret. The plot shows that RoME is competitive with other methods in the simplest setting (homogeneous users), but significantly outperforms them in the more complex settings (heterogeneous and nonlinear).", "section": "6.1 Competitor Comparison Simulation"}, {"figure_path": "eKVugi5zr0/figures/figures_9_1.jpg", "caption": "Figure 3: (left) Boxplot of unbiased estimates of the average per-trial reward for all five competing algorithms, relative to the reward obtained under the pre-specified Valentine randomization policy across 100 bootstrap samples. Within each box, the asterisk (*) indicates the mean value, while the mid-bar represents the median. (right) Heatmap of p-values from the pairwise paired t-tests.", "description": "The left panel of the figure displays boxplots of the unbiased estimates of the average per-trial rewards for five different contextual bandit algorithms, including RoME, relative to the rewards obtained using a pre-specified randomization policy.  The right panel shows a heatmap of p-values from pairwise paired t-tests comparing the performance of these five algorithms.", "section": "6.2 Valentine Study Analysis Results"}, {"figure_path": "eKVugi5zr0/figures/figures_14_1.jpg", "caption": "Figure 4: (left) The baseline reward function g(Sit) used in the simulation study. The proposed method allows this function to be a nonlinear function of the context vectors. The baseline was generated using a combination of recursive partitioning and by summing scaled, shifted, and rotated Gaussian densities. (right) The time-specific parameters used in the simulation study. These parameters cause the advantage function to vary over time. We set them such that the advantage function changes quickly at the beginning of the study then stabilizes.", "description": "The left panel shows a heatmap representing the nonlinear baseline reward function used in the simulation. This function's complexity highlights the challenge addressed by the RoME algorithm.  The right panel displays the time-varying parameters incorporated in the simulation, illustrating how these parameters influence the treatment effect (differential reward) over time. These parameters are designed to change significantly at the beginning of the study before stabilizing later.", "section": "Additional Details for Simulation Study"}, {"figure_path": "eKVugi5zr0/figures/figures_15_1.jpg", "caption": "Figure 2: Cumulative regret in the (a) Homogeneous Users, (b) Heterogeneous Users, and (c) Nonlinear settings. RoME performs competitively in the first setting (the simplest), and it substantially outperforms the next-best method (IntelPooling) in the others.", "description": "This figure compares the cumulative regret of RoME against four other bandit algorithms across three different simulation settings: homogeneous users, heterogeneous users, and nonlinear settings.  The x-axis represents the stage of the simulation, and the y-axis represents the cumulative regret.  The results show that RoME performs competitively in the simplest setting (homogeneous users), but significantly outperforms the other algorithms in the more complex settings (heterogeneous users and nonlinear settings).  This demonstrates RoME's robustness and superior performance in scenarios with user heterogeneity and non-linear relationships between context and reward.", "section": "6.1 Competitor Comparison Simulation"}, {"figure_path": "eKVugi5zr0/figures/figures_16_1.jpg", "caption": "Figure 2: Cumulative regret in the (a) Homogeneous Users, (b) Heterogeneous Users, and (c) Nonlinear settings. RoME performs competitively in the first setting (the simplest), and it substantially outperforms the next-best method (IntelPooling) in the others.", "description": "This figure displays the average cumulative regret for four different bandit algorithms across three different simulation settings: homogeneous users, heterogeneous users, and nonlinear settings.  The x-axis represents the stage of the simulation, and the y-axis represents the cumulative regret.  The figure shows that the RoME algorithm performs competitively with other algorithms in the simple homogeneous setting but significantly outperforms other algorithms in the more complex heterogeneous and nonlinear settings.", "section": "6.1 Competitor Comparison Simulation"}, {"figure_path": "eKVugi5zr0/figures/figures_18_1.jpg", "caption": "Figure 2: Cumulative regret in the (a) Homogeneous Users, (b) Heterogeneous Users, and (c) Nonlinear settings. RoME performs competitively in the first setting (the simplest), and it substantially outperforms the next-best method (IntelPooling) in the others.", "description": "This figure displays the average cumulative regret for four different contextual bandit algorithms across three different simulation settings: Homogeneous Users, Heterogeneous Users, and Nonlinear.  The algorithms compared are RoME, IntelPooling, Neural-Linear, Action-Centered (AC), and Standard Thompson Sampling.  The results show that RoME performs competitively in the simplest setting (Homogeneous Users), but significantly outperforms the other algorithms in the more complex settings (Heterogeneous Users and Nonlinear).  The shaded areas represent the standard deviation across 50 simulations.", "section": "6.1 Competitor Comparison Simulation"}, {"figure_path": "eKVugi5zr0/figures/figures_18_2.jpg", "caption": "Figure 2: Cumulative regret in the (a) Homogeneous Users, (b) Heterogeneous Users, and (c) Nonlinear settings. RoME performs competitively in the first setting (the simplest), and it substantially outperforms the next-best method (IntelPooling) in the others.", "description": "This figure displays the cumulative regret for four different bandit algorithms across three distinct simulation settings: Homogeneous Users, Heterogeneous Users, and Nonlinear.  The x-axis represents the stage of the simulation (time), and the y-axis represents the cumulative regret. Each line represents a different algorithm (RoME, IntelPooling, Neural-Linear, AC, and Standard).  The shaded regions around the lines represent confidence intervals.  The figure demonstrates that the RoME algorithm performs comparably to the other algorithms in the simplest setting (Homogeneous Users) but significantly outperforms them in the more complex settings (Heterogeneous Users and Nonlinear), particularly in terms of cumulative regret.", "section": "6.1 Competitor Comparison Simulation"}, {"figure_path": "eKVugi5zr0/figures/figures_22_1.jpg", "caption": "Figure 9: The time heterogeneity in the pseudo-outcomes. We calculated the pseudo-outcomes using (4), then averaged them across participants and plotted them over time. This exploratory analysis shows evidence that the causal effects vary substantially over time.", "description": "This figure shows the time heterogeneity in the treatment effects from the Valentine study. The pseudo-outcomes were calculated, averaged across participants, and plotted over time.  The resulting curve shows substantial variation in the treatment effects over the course of the study, indicating a non-stationary effect.", "section": "B.2 Justification of Assumption 4"}, {"figure_path": "eKVugi5zr0/figures/figures_23_1.jpg", "caption": "Figure 10: (left) Unbiased estimates of the average per-trial reward for all three ablation algorithms, relative to the reward obtained under the pre-specified Valentine Study randomization policy across 20 multiple-imputed data sets. And (right) p-values from the pairwise paired t-tests.", "description": "This figure displays a boxplot showing the unbiased estimates of the average per-trial reward for three algorithms: RoME, RoME-SU (RoME without user-specific effects), and NNR-Linear (network-cohesion bandit algorithm). The estimates are relative to the reward obtained under the pre-specified Valentine Study randomization policy. The boxplot is accompanied by a heatmap displaying the p-values from pairwise paired t-tests, comparing the performance of the three algorithms.", "section": "B.4 An ablation study"}, {"figure_path": "eKVugi5zr0/figures/figures_26_1.jpg", "caption": "Figure 3: (left) Boxplot of unbiased estimates of the average per-trial reward for all five competing algorithms, relative to the reward obtained under the pre-specified Valentine randomization policy across 100 bootstrap samples. Within each box, the asterisk (*) indicates the mean value, while the mid-bar represents the median. (right) Heatmap of p-values from the pairwise paired t-tests.", "description": "The left panel shows the boxplots of unbiased reward estimates for five algorithms in the Valentine study, comparing their performance relative to a standard randomization policy.  The right panel provides a heatmap showing p-values from paired t-tests comparing the average reward of each pair of algorithms.  The results indicate whether the differences are statistically significant.", "section": "6.2 Valentine Study Analysis Results"}, {"figure_path": "eKVugi5zr0/figures/figures_26_2.jpg", "caption": "Figure 10: (left) Unbiased estimates of the average per-trial reward for all three ablation algorithms, relative to the reward obtained under the pre-specified Valentine Study randomization policy across 20 multiple-imputed data sets. And (right) p-values from the pairwise paired t-tests.", "description": "This figure displays the results of an ablation study comparing three variations of the RoME algorithm: RoME, RoME-SU (without user-specific effects), and NNR-Linear (without DML).  The left panel shows boxplots of the unbiased estimates of the average per-trial reward for each algorithm, relative to a control (Valentine Study randomization policy). The asterisk (*) indicates the mean. The right panel shows p-values from pairwise paired t-tests comparing the algorithms. Darker shading indicates statistical significance at the p \u2264 0.01 level.", "section": "6.2 Valentine Study Analysis Results"}]