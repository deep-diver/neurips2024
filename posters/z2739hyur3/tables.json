[{"figure_path": "z2739hYuR3/tables/tables_1_1.jpg", "caption": "Table 1: Comparison between previous works and ours in terms of the regret, computation cost and storage cost. Here \u03baand \u03ba* are exponentially small problem-dependent quantities defined in Assumption 1, d is the feature dimension, H is the episode length and K is the number of episodes. The computational cost and storage cost per episode indicate the dependence on episode count k.", "description": "This table compares the regret, computation cost, and storage cost of different reinforcement learning algorithms for Markov Decision Processes (MDPs) that use multinomial logit (MNL) function approximation.  It shows how the proposed algorithms (UCRL-MNL-OL and UCRL-MNL-LL) improve upon the existing state-of-the-art (Hwang and Oh [2023]) in terms of computational and storage efficiency while achieving comparable or better regret bounds.  The table also presents a lower bound on the regret, highlighting the near-optimality of the proposed algorithms.", "section": "Related Work"}]