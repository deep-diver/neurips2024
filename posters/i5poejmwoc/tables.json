[{"figure_path": "i5PoejmWoC/tables/tables_1_1.jpg", "caption": "Table 1: Results of 4-shot with CoT prompting on Sudoku solving by two of the frontier LLM models. ", "description": "This table presents the results of a 4-shot Chain of Thought (CoT) prompting experiment on Sudoku puzzle solving using two state-of-the-art large language models (LLMs): GPT-4 and Gemini-1.5 Pro.  The experiment evaluated the models' ability to completely solve Sudoku puzzles and their accuracy in correctly filling individual cells.  The results show that both models performed poorly, achieving 0% success in fully solving any puzzles, with cell accuracy only slightly above random guessing.", "section": "1 Introduction"}, {"figure_path": "i5PoejmWoC/tables/tables_7_1.jpg", "caption": "Table 2: Performance (cell accuracy and complete puzzle accuracy) change as we increase beam-width in beam-search.", "description": "This table shows the performance of the model in terms of cell accuracy and complete puzzle accuracy when using beam search with different beam widths (k=1, 3, and 5).  The results demonstrate how increasing the beam width improves both cell accuracy and complete puzzle accuracy, suggesting that exploring multiple hypotheses during decoding enhances the model's ability to solve Sudoku puzzles.", "section": "3.5 Beam-search decoding"}, {"figure_path": "i5PoejmWoC/tables/tables_9_1.jpg", "caption": "Table 3: Candidate set equivalence accuracy when the number of filled cells is different in the given puzzle. The candidate-set equivalence accuracy measures the average overlap between the solver's and the model's candidate set for the correctly solved puzzles.", "description": "This table presents the accuracy of candidate set equivalence for different numbers of filled cells in Sudoku puzzles.  The accuracy represents the average overlap between the candidate sets generated by a human solver and the model's predictions for correctly solved puzzles. The more filled cells, the higher the accuracy, indicating improved agreement between the solver and the model.", "section": "4.2 Emergence of candidate set information in the model"}, {"figure_path": "i5PoejmWoC/tables/tables_16_1.jpg", "caption": "Table 2: Performance (cell accuracy and complete puzzle accuracy) change as we increase beam-width in beam-search.", "description": "This table presents the results of an experiment to evaluate the impact of beam width on the performance of a model trained to solve Sudoku puzzles. The experiment measures two performance metrics: cell accuracy and complete puzzle accuracy. Cell accuracy refers to the percentage of cells that are correctly filled in the puzzle, whereas complete puzzle accuracy refers to the percentage of puzzles which are fully solved correctly (without any mistakes). The table shows that increasing the beam width improves both cell accuracy and complete puzzle accuracy.", "section": "3.5 Beam-search decoding"}, {"figure_path": "i5PoejmWoC/tables/tables_18_1.jpg", "caption": "Table 4: Evaluating our model on the evaluation dataset of Sudoku given in Recurrent Relational Network (RRN) by Palm et al. [PPW18]. Our trained model performs comparably to the RRN model but does not require handcrafting the network and training procedure for training on the Sudoku puzzles.", "description": "This table compares the performance of the proposed causal language model on Sudoku puzzles with a neural network-based Sudoku solver from prior work.  The comparison focuses on evaluation accuracy (percentage of correctly solved cells) and complete puzzle accuracy (percentage of fully correctly solved puzzles).  It highlights that the language model achieves comparable results without requiring the architecture-specific design or training of the neural network approach.", "section": "F.1 Comparison with neural network-based Sudoku solver"}, {"figure_path": "i5PoejmWoC/tables/tables_21_1.jpg", "caption": "Table 5: Zebra puzzle results. The training dataset contains Zebra puzzles with the no. of entities and the no. of attributes in {3, 4, 5, 6} set. For each combination of the no. of entries and attributes, we generate 20k puzzles therefore, the complete dataset contains 320k puzzles of varying sizes. From the complete dataset, we randomly choose 15k puzzles for evaluation and the rest of the puzzles for training the model. Evaluation accuracy: the percentage of correctly predicted attributes on the evaluation set and eval complete puzzle accuracy: the percentage of correctly and completely solved puzzles.", "description": "This table presents the results of experiments conducted on Zebra puzzles.  It shows the evaluation accuracy (percentage of correctly predicted attributes) and complete puzzle accuracy (percentage of completely and correctly solved puzzles) for different beam search widths (1, 3, and 5). The training data consisted of 320,000 Zebra puzzles with varying numbers of entities and attributes, generated to ensure solvability.  The model's performance is evaluated on a separate test set of 15,000 puzzles.", "section": "Experiments on Zebra puzzles"}]