{"references": [{"fullname_first_author": "Tom B Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for the field of large language models, demonstrating their ability to perform well on various tasks with limited training data."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduced the chain-of-thought prompting technique which significantly improves the reasoning capabilities of large language models."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This paper details the use of reinforcement learning from human feedback to align language models with human intentions and preferences, improving their helpfulness and safety."}, {"fullname_first_author": "Kushal Lakhotia", "paper_title": "On generative spoken language modeling from raw audio", "publication_date": "2021-12-01", "reason": "This paper is highly relevant as it explores the use of raw audio for spoken language modeling, which is central to the work presented in the current paper."}, {"fullname_first_author": "Tu Anh Nguyen", "paper_title": "Generative spoken dialogue language modeling", "publication_date": "2023-12-01", "reason": "This work directly addresses generative spoken dialogue modeling, which is the core focus of the current paper and shares a similar objective."}]}