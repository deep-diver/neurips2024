[{"figure_path": "MqeCU0tXAY/figures/figures_1_1.jpg", "caption": "Figure 1: The feature channel sensitivity to domain and class shifts are quantified through employing the histogram of their standard deviations across different domains and classes. We analyze CLIP\u2019s image embeddings using the ViT-B/16 backbone on OfficeHome [52] dataset. For each channel, the average outputs are computed across all samples from each domain/class, and the standard deviations are calculated on domain/class dimension.", "description": "This figure shows the sensitivity of CLIP's visual feature channels to domain and class shifts.  Histograms display the standard deviations of channel activations across different domains (a) and classes (b).  The OfficeHome dataset and ViT-B/16 backbone are used for analysis.  CLIPCEIL's impact on reducing domain sensitivity and increasing class sensitivity is illustrated by comparison with the standard CLIP zero-shot approach.", "section": "1 Introduction"}, {"figure_path": "MqeCU0tXAY/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of the proposed framework. We fixed the CLIP visual encoder I and text encoder T and trained a lightweight adapter g during the training. The channel refinement ensures each feature channel contains domain-invariant (minimizing domain variance) and class-relevant (maximizing class variance) information. To further align the image and text, we maximize the image-text similarity and minimize direction loss with the help of text class descriptions based on data pairs from different classes and domains.", "description": "This figure illustrates the CLIPCEIL framework, which consists of three main components: a lightweight adapter that integrates multi-scale CLIP features, visual channel refinement to ensure domain-invariant and class-relevant visual features, and image-text alignment to maintain consistency between image and text embeddings. The adapter processes multi-scale visual features from the CLIP visual encoder, minimizing inter-domain variance and maximizing inter-class variance. Image-text alignment is achieved by maximizing similarity and minimizing directional loss between image and text embeddings. The text encoder is fixed, and only the adapter is trained during training.", "section": "3.2 Framework Overview"}, {"figure_path": "MqeCU0tXAY/figures/figures_4_1.jpg", "caption": "Figure 3: The architecture of the adapter g.", "description": "The figure shows the architecture of the adapter g, a lightweight component in the CLIPCEIL model.  It consists of a Transformer layer followed by a Multi-Layer Perceptron (MLP) projector. The Transformer layer integrates multi-scale visual features (from different layers of CLIP's visual encoder) and maps them into a latent feature space. The MLP projector then further refines the feature representations.  The adapter's role is crucial for improving the model's generalizability by learning domain-invariant and class-relevant features.  In short, it processes multiple CLIP visual features to make them more robust against domain shift and improve classification.", "section": "3.3 Adapter g"}, {"figure_path": "MqeCU0tXAY/figures/figures_4_2.jpg", "caption": "Figure 4: Diagram of calculating the channel domain sensitivity across different domains.", "description": "This figure illustrates the calculation of channel domain sensitivity. It starts with feature vectors from multiple domains.  For each channel, it calculates the average value across all samples in each domain. Then, it computes the variance of these average values across the domains. This variance represents the sensitivity of that channel to domain shifts.  Channels with low variance are considered domain-invariant. The visualization shows how the calculation proceeds step-by-step from individual samples to channel-wise averages, and finally to inter-domain variance for each channel.", "section": "3.4 Channel Refinement"}, {"figure_path": "MqeCU0tXAY/figures/figures_8_1.jpg", "caption": "Figure 5: t-SNE [49] visualization on image features of CLIPCEIL and CLIP pre-trained models across different classes and domains. Different colors indicate different classes or domains", "description": "This figure shows the results of t-SNE dimensionality reduction applied to image features extracted by both CLIPCEIL and the original CLIP model.  The plots visualize how the features cluster across different classes and domains.  Panel (a) shows CLIP zero-shot across classes, panel (b) CLIPCEIL across classes, panel (c) CLIP zero-shot across domains, and panel (d) CLIPCEIL across domains.  The goal is to illustrate that CLIPCEIL produces features that are more discriminative between classes while showing less sensitivity to domain shifts.", "section": "4.3 Ablation Studies"}, {"figure_path": "MqeCU0tXAY/figures/figures_8_2.jpg", "caption": "Figure 10: Full accuracy bar results of different channel refinement strategies on the five DG datasets.", "description": "This figure presents a bar chart comparing the average accuracy achieved by three different channel refinement strategies across five domain generalization (DG) benchmark datasets.  The strategies are: using only inter-class variance, only inter-domain variance, and using both. The datasets are PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. The chart visually demonstrates the relative performance of each strategy on each dataset, highlighting the effectiveness of combining both inter-class and inter-domain variance for improved accuracy across various domains.", "section": "4.3 Ablation Studies"}, {"figure_path": "MqeCU0tXAY/figures/figures_18_1.jpg", "caption": "Figure 5: t-SNE [49] visualization on image features of CLIPCEIL and CLIP pre-trained models across different classes and domains. Different colors indicate different classes or domains", "description": "This figure shows the results of t-SNE dimensionality reduction applied to image features extracted by both CLIPCEIL and a standard CLIP model.  The visualizations help to understand how well each model separates image features by class and domain.  Distinct clusters indicate good separation, while overlapping clusters suggest difficulty in distinguishing between classes or domains.  The differences in clustering patterns between CLIPCEIL and CLIP highlight CLIPCEIL's improved ability to generate domain-invariant features while preserving class-relevant information.", "section": "4.3 Ablation Studies"}, {"figure_path": "MqeCU0tXAY/figures/figures_19_1.jpg", "caption": "Figure 5: t-SNE [49] visualization on image features of CLIPCEIL and CLIP pre-trained models across different classes and domains. Different colors indicate different classes or domains", "description": "This figure shows the results of t-SNE dimensionality reduction applied to image features extracted by both CLIPCEIL and the original CLIP model.  The visualizations help understand the impact of CLIPCEIL on feature representation by comparing how features from different classes and domains are clustered.  The goal is to show that CLIPCEIL generates features that are more discriminative between classes while being less sensitive to domain shifts than features from the original CLIP.", "section": "4.3 Ablation Studies"}, {"figure_path": "MqeCU0tXAY/figures/figures_19_2.jpg", "caption": "Figure 5: t-SNE [49] visualization on image features of CLIPCEIL and CLIP pre-trained models across different classes and domains. Different colors indicate different classes or domains", "description": "This figure visualizes the image features extracted by both CLIPCEIL and the original CLIP model using t-SNE.  It shows the distribution of features across different classes and domains.  The purpose is to illustrate that CLIPCEIL better separates features by class, indicating improved class discrimination, and that the features from different domains are more intermixed, showcasing the model's enhanced domain invariance compared to the original CLIP.", "section": "4.3 Ablation Studies"}, {"figure_path": "MqeCU0tXAY/figures/figures_19_3.jpg", "caption": "Figure 5: t-SNE [49] visualization on image features of CLIPCEIL and CLIP pre-trained models across different classes and domains. Different colors indicate different classes or domains", "description": "This figure shows the t-SNE visualization of image features from both the CLIPCEIL model and the pre-trained CLIP model.  The visualization is performed separately for different classes and domains. Different colors represent different classes or domains. The purpose is to show how CLIPCEIL improves the separation of classes compared to the pre-trained CLIP model, especially across domains. This illustrates CLIPCEIL's ability to learn domain-invariant and class-relevant features.", "section": "4.3 Ablation Studies"}]