[{"figure_path": "woRFmNJiLp/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of pre-training data quality before and after data alignment rewriting.", "description": "The figure shows a comparison of the quality of pre-training data before and after data alignment rewriting.  The \"Origin Dataset\" column illustrates various issues present in the raw data, including format inconsistencies (e.g., improperly formatted Arabic and English text), unfair value judgements, hate speech, and advertisements.  The \"Alignment Dataset\" column demonstrates how these issues have been addressed and corrected through the data alignment rewriting process, resulting in well-formatted text, fair values, moderated content (replacing hate speech with more neutral phrasing), and removal of advertisements.", "section": "2 Methodology: Native Alignment at Pre-training"}, {"figure_path": "woRFmNJiLp/figures/figures_2_1.jpg", "caption": "Figure 2: Demonstration of pre-training data processing workflow for native alignment.", "description": "This figure illustrates the four-step data processing workflow for native alignment.  First, web data undergoes deduplication. Then, a subset is sampled and annotated by an alignment expert, providing examples of correctly aligned data. These annotated data pairs are used to train smaller LLMs, which then act as 'alignment workers' to process the remaining pre-training data, generating a large quantity of rewritten, aligned data. The process is guided by a set of 'polishing instructions' which focus on issues of format, values, content moderation, and knowledge preservation.", "section": "2 Methodology: Native Alignment at Pre-training"}, {"figure_path": "woRFmNJiLp/figures/figures_3_1.jpg", "caption": "Figure 3: Perplexity before and after native alignment of Arabic data.", "description": "This figure shows the distribution of perplexity scores for Arabic data before and after the native alignment process.  Perplexity is a measure of how well a language model predicts a sequence of words. Lower perplexity indicates better prediction and thus, higher data quality.  The figure visually demonstrates that the data after native alignment (rewritten data) shows lower perplexity scores compared to the original, indicating an improvement in the quality of the data due to the alignment process. This suggests improved fluency and consistency in the rewritten data.", "section": "2.2 Preliminary Analysis on Alignment Data"}, {"figure_path": "woRFmNJiLp/figures/figures_4_1.jpg", "caption": "Figure 4: The left side illustrates the datasets utilized during the pre-training phase of the model, while the right side represents the benchmarks employed in the experiments.", "description": "This figure shows the data used for pre-training the language model and the benchmarks used to evaluate its performance.  The left-hand pie chart details the proportion of data from various sources used for pre-training, including ArabicText2022, SlimPajama, MAP-CC, Proof-Pile-2, and Wikipedia. The right-hand side illustrates the benchmarks used to evaluate the model's performance which are categorized into knowledge assessment (ArabicMMLU, EXAMS), Arabic localization (ACVA_clean, ACVA_all) and trustworthiness (AraTrust).", "section": "3 Experiments: Practical Applications in Arabic"}, {"figure_path": "woRFmNJiLp/figures/figures_6_1.jpg", "caption": "Figure 5: The ratio of metrics for base models relative to ChatGPT-40 on the BeaverTails dataset.", "description": "This figure presents a bar chart comparing the performance of several Arabic LLMs (Jais-13B, AceGPT-7B, Llama3-8B, Llama3-8B (Align-12B), and ChatGPT-40) on the BeaverTails dataset.  The chart displays the ratios of harmlessness and helpfulness scores relative to ChatGPT-40 (the baseline). Llama3-8B trained with native alignment (Align-12B) shows significant improvements in both harmlessness and helpfulness compared to the other models, highlighting the effectiveness of the native alignment strategy.", "section": "4.2 Native Alignment vs. Conventional Pre-training (RQ 1)"}, {"figure_path": "woRFmNJiLp/figures/figures_7_1.jpg", "caption": "Figure 6: The left graph illustrates the metric improvements under various training strategies. The right graph demonstrates the performance gains as the volume of alignment data increases. In both graphs, the baseline model, \u2018Pre-train-12B + SFT-50K\u2019, is initially trained on 12 billion tokens from an unaligned dataset and later fine-tuned using instruction-tuning datasets with 50,000 samples.", "description": "This figure presents the results of an ablation study comparing different training strategies for large language models (LLMs). The left-hand graph shows the improvement in harmlessness and helpfulness metrics when using only native alignment data, compared to using only the baseline pre-training data. It also shows the combined effect of both pre-training data and native alignment data (Hybrid model).  The right-hand graph illustrates the scaling law of native alignment by demonstrating the incremental improvement in harmlessness and helpfulness metrics with the increasing volume of native alignment data used for pre-training.", "section": "4.2 Native Alignment vs. Conventional Pre-training (RQ 1)"}, {"figure_path": "woRFmNJiLp/figures/figures_14_1.jpg", "caption": "Figure 1: Comparison of pre-training data quality before and after data alignment rewriting.", "description": "The figure shows the differences in the quality of pre-training data before and after applying data alignment rewriting techniques.  The original dataset contains various issues, including format problems, unfair values, hate speech, advertisements, and other inappropriate content. In contrast, the aligned dataset presents well-formatted text and fair values, while the hate speech, advertisements, and other unsuitable content have been removed. The figure illustrates the effectiveness of data alignment in enhancing the quality and safety of the data used for pre-training large language models.", "section": "2 Methodology: Native Alignment at Pre-training"}, {"figure_path": "woRFmNJiLp/figures/figures_17_1.jpg", "caption": "Figure 2: Demonstration of pre-training data processing workflow for native alignment.", "description": "This figure illustrates the four steps involved in the pre-training data processing workflow for native alignment.  Step 1 is deduplication of web data. Step 2 involves annotation by alignment experts who rewrite a subset of data according to provided polishing instructions (a code of conduct outlining expected LLM behavior). Step 3 is training smaller LLMs on the annotated pairs of original and rewritten data to create alignment workers.  Step 4 is rewriting the vast dataset using the trained alignment workers to produce the final alignment dataset.", "section": "2 Methodology: Native Alignment at Pre-training"}]