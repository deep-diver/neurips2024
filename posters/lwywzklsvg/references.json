{"references": [{"fullname_first_author": "A. Athalye", "paper_title": "Synthesizing robust adversarial examples", "publication_date": "2018-07-10", "reason": "This paper is foundational in the field of adversarial attacks, introducing a method for generating robust adversarial examples that are effective against various defenses."}, {"fullname_first_author": "N. Carlini", "paper_title": "Towards evaluating the robustness of neural networks", "publication_date": "2017-05-22", "reason": "This paper is highly influential due to its introduction of a method for evaluating robustness of neural networks against adversarial attacks."}, {"fullname_first_author": "I. Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-01-01", "reason": "This is a seminal paper in the field of adversarial machine learning, providing insights into the nature of adversarial examples and proposing a method to generate them."}, {"fullname_first_author": "A. Madry", "paper_title": "Towards deep learning models resistant to adversarial attacks", "publication_date": "2018-01-01", "reason": "This paper is highly regarded for introducing a formal framework and methodology for evaluating and improving the robustness of deep learning models against adversarial attacks."}, {"fullname_first_author": "S. Thys", "paper_title": "Fooling automated surveillance cameras: Adversarial patches to attack person detection", "publication_date": "2019-01-01", "reason": "This paper is important due to its demonstration of the effectiveness of physical adversarial attacks in the real world against pedestrian detection systems, setting a precedent for further research in this area."}]}