[{"figure_path": "7t6aq0Fa9D/tables/tables_5_1.jpg", "caption": "Table 1: Topic quality results of Cv (topic coherence) and TD (topic diversity). The best is in bold. \u2021 denotes the gain of FASTopic is statistically significant at 0.05 level.", "description": "This table presents the results of evaluating topic quality using two metrics: topic coherence (Cv) and topic diversity (TD).  The table compares the performance of FASTopic against several baseline topic models across six different benchmark datasets (NYT, 20NG, WoS, NeurIPS, ACL, Wikitext-103).  Higher Cv scores indicate better coherence between top words in a topic, while higher TD scores indicate greater diversity among the topics.  The best result for each metric and dataset is highlighted in bold, and statistically significant improvements by FASTopic are denoted.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_7_1.jpg", "caption": "Table 4: Topic quality results of Cv (topic coherence) and TD (topic diversity) under different topic numbers (K). The best is in bold.", "description": "This table presents the results of topic coherence (Cv) and topic diversity (TD) for different topic model baselines (LDA-Mallet, NMF, BERTopic, CombinedTM, GINopic, ProGBN, HyperMiner, ECRTM) and the proposed FASTopic model.  The results are shown for six different numbers of topics (K = 75, 100, 125, 150, 175, 200). The best performing model for each metric and topic number is highlighted in bold. This table demonstrates the effectiveness of FASTopic compared to other topic models in terms of producing coherent and diverse topics.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_7_2.jpg", "caption": "Table 5: Document clustering results of Purity and NMI under different topic numbers (K). The best is in bold.", "description": "This table presents the results of document clustering using Purity and NMI metrics.  The clustering was performed with different numbers of topics (K=75, 100, 125, 150, 175, 200).  The table compares FASTopic's performance against several baseline topic modeling methods. The best performance for each metric (Purity and NMI) and for each number of topics (K) is highlighted in bold.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_9_1.jpg", "caption": "Table 6: Ablation study. w/o ETP means using parameterized softmax (Eq. (2)) to model semantic relations. See also Table 8 for results on other datasets.", "description": "This ablation study compares the performance of FASTopic with and without the Embedding Transport Plan (ETP) method.  The \"w/o ETP\" row shows results using the standard parameterized softmax approach instead of ETP.  The results show that ETP significantly improves the topic quality (Cv, TD) and document clustering quality (Purity, NMI) across three benchmark datasets (20NG, NYT, and WoS).", "section": "4.7 Ablation Study"}, {"figure_path": "7t6aq0Fa9D/tables/tables_17_1.jpg", "caption": "Table 7: Dataset statistics.", "description": "This table presents the statistics of six benchmark datasets used in the paper's experiments.  For each dataset, the number of documents (#docs), the average document length (Average Length), the vocabulary size (Vocabulary size), and the number of labels (#labels) are provided. The number of labels is not available for NeurIPS, ACL, and Wikitext-103 datasets.", "section": "4.1 Experiment Setup"}, {"figure_path": "7t6aq0Fa9D/tables/tables_18_1.jpg", "caption": "Table 6: Ablation study. w/o ETP means using parameterized softmax (Eq. (2)) to model semantic relations. See also Table 8 for results on other datasets.", "description": "This table presents the ablation study results comparing the performance of FASTopic with and without the Embedding Transport Plan (ETP) method.  The \"w/o ETP\" row shows the results when the simpler parameterized softmax is used to model semantic relations, while the FASTopic row shows the results using the proposed ETP method.  The table demonstrates the significance of ETP in improving the quality of topic modeling, as measured by topic coherence (Cv), topic diversity (TD), Purity, and NMI.  Results are shown for three datasets (20NG, NYT, and WoS).", "section": "4.7 Ablation Study"}, {"figure_path": "7t6aq0Fa9D/tables/tables_19_1.jpg", "caption": "Table 1: Topic quality results of Cv (topic coherence) and TD (topic diversity). The best is in bold. \u2021 denotes the gain of FASTopic is statistically significant at 0.05 level.", "description": "This table presents the results of topic coherence (Cv) and topic diversity (TD) for different topic models across six benchmark datasets: 20NG, NYT, WoS, NeurIPS, ACL, and Wikitext-103.  FASTopic's performance is compared against several baselines (LDA-Mallet, NMF, BERTopic, CombinedTM, GINopic, ProGBN, HyperMiner, and ECRTM).  The 'best' performance for each metric and dataset is highlighted in bold, and a statistical significance test (at the 0.05 level) is indicated using the \u2021 symbol.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_19_2.jpg", "caption": "Table 10: Topic quality results with different document embedding models.", "description": "This table shows the results of topic coherence (Cv) and topic diversity (TD) using different pretrained document embedding models.  The models compared are all-mpnet-base-v2, all-distilroberta-v1, and all-MiniLM-L6-v2.  Results are shown across six benchmark datasets (20NG, NYT, WoS, NeurIPS, ACL, and Wikitext-103).  The table helps assess how the choice of document embedding model impacts the quality of the resulting topic model.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_19_3.jpg", "caption": "Table 11: Document clustering results with different document embedding models.", "description": "This table shows the purity and NMI scores achieved by using different document embedding models for document clustering.  The results are presented for three different datasets (20NG, NYT, and WoS).  The table allows for a comparison of the impact of different document embedding models on the quality of topic modeling results.  It is used to demonstrate the effectiveness and robustness of the FASTopic model.", "section": "4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality"}, {"figure_path": "7t6aq0Fa9D/tables/tables_20_1.jpg", "caption": "Table 12: Running time breakdowns (in seconds) of BERTopic and our FASTopic on the NYT dataset.", "description": "This table compares the running time of BERTopic and FASTopic on the NYT dataset. The running time is broken down into four steps for BERTopic (loading document embeddings, dimensionality reduction, clustering document embeddings, and computing word weights), and two steps for FASTopic (loading document embeddings and training).  The table shows that FASTopic is significantly faster than BERTopic, completing in 12.95 seconds compared to 32.42 seconds for BERTopic. This highlights the efficiency advantage of FASTopic.", "section": "4.4 Efficiency: Running Speed"}, {"figure_path": "7t6aq0Fa9D/tables/tables_20_2.jpg", "caption": "Table 12: Running time breakdowns (in seconds) of BERTopic and our FASTopic on the NYT dataset.", "description": "This table compares the running time of BERTopic and FASTopic on the NYT dataset. The running time is broken down into steps for each method: Load doc embeddings and Training.  It demonstrates the significantly faster training time of FASTopic compared to BERTopic. ", "section": "4.4 Efficiency: Running Speed"}, {"figure_path": "7t6aq0Fa9D/tables/tables_21_1.jpg", "caption": "Table 13: Topic quality results of Cv (topic coherence) and TD (topic diversity) under different dataset sizes (N) of WoS. The best is in bold.", "description": "This table presents the results of topic coherence (Cv) and topic diversity (TD) for the WoS dataset under different dataset sizes (N).  It shows how the topic quality metrics vary as the number of documents in the dataset changes, allowing for an analysis of the model's performance stability and scalability with varying data volumes. The best performing model for each metric and dataset size is highlighted in bold.", "section": "4.6 Adaptivity and Stability"}, {"figure_path": "7t6aq0Fa9D/tables/tables_21_2.jpg", "caption": "Table 14: Document clustering results of Purity and NMI under different dataset sizes (N) of WoS. The best is in bold.", "description": "This table presents the results of document clustering experiments performed using different topic models on the WoS dataset, with varying dataset sizes (N). The performance of each model is evaluated using two metrics: Purity and NMI. The best results achieved by each model are highlighted in bold.", "section": "4.6 Adaptivity and Stability"}, {"figure_path": "7t6aq0Fa9D/tables/tables_21_3.jpg", "caption": "Table 15: Topic quality results of Cv (topic coherence) and TD (topic diversity) under different vocabulary sizes (V) of WoS. The best is in bold.", "description": "This table presents the results of topic coherence (Cv) and topic diversity (TD) for the WoS dataset under different vocabulary sizes.  The performance of several topic modeling methods (LDA-Mallet, NMF, BERTopic, CombinedTM, GINopic, ProGBN, HyperMiner, ECRTM, and FASTopic) are compared across four vocabulary sizes (V=20k, V=30k, V=40k, V=50k).  The best performance for each metric and vocabulary size is highlighted in bold. This demonstrates the stability and robustness of FASTopic across varying vocabulary sizes.", "section": "4.6 Adaptivity and Stability"}, {"figure_path": "7t6aq0Fa9D/tables/tables_21_4.jpg", "caption": "Table 15: Topic quality results of Cv (topic coherence) and TD (topic diversity) under different vocabulary sizes (V) of WoS. The best is in bold.", "description": "This table presents the results of evaluating topic quality using topic coherence (Cv) and topic diversity (TD) metrics on the WoS dataset, with varying vocabulary sizes (V).  The performance of several topic models is compared, showing how well each model maintains topic quality as the vocabulary size increases.  The best performing model is highlighted in bold for each metric and vocabulary size.", "section": "4.6 Adaptivity and Stability"}]