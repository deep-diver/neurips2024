[{"figure_path": "oSOVME9kl2/figures/figures_1_1.jpg", "caption": "Figure 1: Implicit regularization of SAM on balancedness. The losses for NOP and OP are E[||xy \u2013 (A + N)||2] and E[||xy \u2013 (a + an)||2], respectively. Here, A is the ground truth matrix, N is the Gaussian noise, and a controls the SNR. Left of (a) and (b): |||xt||2 \u2013 ||yt||2| vs. iteration. Right of (a) and (b): |||gxt ||2 - ||gyt ||2| vs. iteration, where (gxt, gy\u2081) denotes stochastic gradients.", "description": "This figure demonstrates the implicit regularization of Sharpness-Aware Minimization (SAM) on balancedness, a new metric introduced in the paper.  It shows the absolute difference between the squared norms of two variables (||xt||\u00b2 - ||yt||\u00b2) and the difference between their gradient norms (||gxt||\u00b2 - ||gyt||\u00b2) over training iterations for both non-overparametrized (NOP) and overparametrized (OP) problems. Different signal-to-noise ratios (SNR) are also tested. The results illustrate that SAM promotes balancedness (the difference approaches zero) while SGD does not, and this regularization effect is stronger when there are data anomalies (low SNR).", "section": "1 Introduction"}, {"figure_path": "oSOVME9kl2/figures/figures_5_1.jpg", "caption": "Figure 2: Implicit regularization of SAM on NOP E[||xy \u2013 (A + \u03b1N)||2], where \u03b1 controls SNR. (a) the threshold of balancedness B in Corollary 1; (b) implicit vs. explicit regularization.", "description": "This figure illustrates the implicit regularization of Sharpness Aware Minimization (SAM) on balancedness for non-overparametrized problems.  Panel (a) shows how the absolute difference between the squared norms of two variables (balancedness) changes over iterations for SAM and a thresholded version of SAM at different signal-to-noise ratios (SNR).  The right side of (a) depicts the difference between the squared norms of the gradients of the two variables. Panel (b) compares the performance of SAM, SGD, and two proposed variants (OBAR, nBAR) that explicitly incorporate balancedness, again showing how the balancedness changes with iterations.  In both cases, it is shown that SAM promotes balancedness, and that this effect is stronger in the presence of noise (lower SNR).", "section": "3 SAM for Non-Overparametrized Problems"}, {"figure_path": "oSOVME9kl2/figures/figures_6_1.jpg", "caption": "Figure 1: Implicit regularization of SAM on balancedness. The losses for NOP and OP are E[||xy \u2013 (A + N)||2] and E[||xy \u2013 (A + \u03b1N)||2], respectively. Here, A is the ground truth matrix, N is the Gaussian noise, and \u03b1 controls the SNR. Left of (a) and (b): ||xt||2 \u2013 ||yt||2| vs. iteration. Right of (a) and (b): ||gxt||2 \u2013 ||gyt||2| vs. iteration, where (gxt, gyt) denotes stochastic gradients.", "description": "This figure demonstrates the implicit regularization of Sharpness-Aware Minimization (SAM) on balancedness, which is defined as the difference between the squared norms of two variables (x and y).  The left panels show the absolute difference between the norms of x and y over training iterations for non-overparametrized (NOP) and overparametrized (OP) scenarios.  The right panels display the corresponding difference in the norms of their gradients.  The results illustrate that SAM promotes balancedness (the difference in norms approaches zero), and this effect is stronger when the signal-to-noise ratio (SNR) is lower (more noise).", "section": "Implicit Regularization of SAM on Balancedness"}, {"figure_path": "oSOVME9kl2/figures/figures_17_1.jpg", "caption": "Figure 1: Implicit regularization of SAM on balancedness. The losses for NOP and OP are E[||xy \u2013 (A + N)||2] and E[||xy \u2013 (A + \u03b1N)||2], respectively. Here, A is the ground truth matrix, N is the Gaussian noise, and \u03b1 controls the SNR. Left of (a) and (b): |||xt||2 \u2013 ||yt||2| vs. iteration. Right of (a) and (b): |||gxt||2 \u2013 ||gyt||2| vs. iteration, where (gxt, gyt) denotes stochastic gradients.", "description": "This figure shows the implicit regularization of Sharpness Aware Minimization (SAM) on balancedness for both non-overparametrized (NOP) and overparametrized (OP) problems.  The plots show the absolute difference between the squared norms of two variables (||xt||\u00b2 - ||yt||\u00b2) and the difference between the squared norms of their gradients (|||gxt||\u00b2 - ||gyt||\u00b2) over training iterations.  Different subplots show the effect of varying signal-to-noise ratio (SNR).  The results show that SAM promotes balancedness (i.e. equal norms), and this regularization is stronger for data with lower SNR.", "section": "1 Introduction"}]