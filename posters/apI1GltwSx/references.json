{"references": [{"fullname_first_author": "Tongzhou Wang", "paper_title": "Dataset distillation", "publication_date": "2018-11-01", "reason": "This paper is foundational to the field of dataset distillation, introducing the core concept and methodology that many subsequent works build upon."}, {"fullname_first_author": "Bo Zhao", "paper_title": "Dataset condensation with gradient matching", "publication_date": "2020-06-01", "reason": "This work explores an alternative approach to dataset distillation using gradient matching, offering a different perspective on optimizing synthetic data."}, {"fullname_first_author": "George Cazenavette", "paper_title": "Dataset distillation by matching training trajectories", "publication_date": "2022-01-01", "reason": "This paper proposes a method for dataset distillation that focuses on matching training trajectories, providing another significant technique in the area."}, {"fullname_first_author": "Zeyuan Yin", "paper_title": "Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective", "publication_date": "2023-01-01", "reason": "This paper addresses the challenge of scaling dataset distillation to large datasets like ImageNet, introducing a novel method that significantly improves efficiency."}, {"fullname_first_author": "Peng Sun", "paper_title": "On the diversity and realism of distilled dataset: An efficient dataset distillation paradigm", "publication_date": "2024-01-01", "reason": "This recent work tackles the issue of limited diversity in generated datasets, presenting a new approach that enhances diversity and improves the quality of the distilled data."}]}