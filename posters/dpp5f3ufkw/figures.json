[{"figure_path": "DpP5F3UfKw/figures/figures_1_1.jpg", "caption": "Figure 1: Schematic of our experimental approach. The LM takes as input the current word along with its preceding context to produce the current word's LM embedding. This embedding is then used as input to a ridge regression model to predict the human brain responses associated with the word. The Mean Squared Error (MSE) between the predicted and actual MEG responses is calculated. Finally, an LLM-based hypothesis proposer is employed to formulate natural language hypotheses explaining the divergence between the predicted and actual MEG responses.", "description": "This figure illustrates the experimental workflow of the study.  It begins with text input processed by a Language Model (LM) to generate word embeddings. These embeddings are then used in a ridge regression model to predict MEG (Magnetoencephalography) brain responses.  The model's accuracy is measured by calculating the Mean Squared Error (MSE) between predicted and actual MEG responses. High MSE indicates areas where the LM doesn't accurately capture human brain activity. Finally, an LLM-based hypothesis proposer is used to explain these prediction errors in natural language.", "section": "2 Predictive MEG Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_5_1.jpg", "caption": "Figure 3: Distribution of human responses for (A) the top 10 and (B) the bottom 10 hypotheses, ranked by the percentage of 'Divergent Sentence' responses.", "description": "This figure shows the results of a human validation experiment designed to verify the hypotheses generated by the LLM-based hypothesis proposer.  The experiment presented participants with pairs of sentences and a hypothesis, asking them to choose which sentence better fit the hypothesis.  The figure displays the distribution of responses ('Divergent Sentence', 'Equal', 'Convergent Sentence') for the top 10 and bottom 10 hypotheses, ranked by the percentage of participants who selected \"Divergent Sentence\". This helps illustrate the difference in human judgement between the sentences the language model struggles to interpret vs. those it interprets well.  Panel A shows the distribution for the top 10 hypotheses (those that best capture the difference between LM predictions and human brain responses), while Panel B shows the distribution for the bottom 10 hypotheses.", "section": "3 Identifying Phenomena of Interest"}, {"figure_path": "DpP5F3UfKw/figures/figures_6_1.jpg", "caption": "Figure 4: Performance comparison of the base model with models fine-tuned on (A) social and (B) physical datasets. Each panel's y-axis shows the percentage of channels in the fine-tuned model with better, worse, or non-significantly different performance (measured by Pearson correlation) compared to the base model. Fine-tuned models outperform the base model during language processing time windows. Refer to Appendix L for a detailed view of each MEG channel plotted.", "description": "This figure compares the performance of the base language model with models fine-tuned on social and physical datasets.  It shows the percentage of MEG channels where the fine-tuned models performed better, worse, or similarly to the base model across different time windows after word onset.  The results indicate that fine-tuning improves performance during the typical language processing time period.", "section": "5 Improving Brain Alignment via Fine-tuning"}, {"figure_path": "DpP5F3UfKw/figures/figures_8_1.jpg", "caption": "Figure 5: Comparison of improved MSE between (A) social and (B) physical words and those outside each category evaluated on models fine-tuned on corresponding datasets. Positive values denote lower MSEs in the fine-tuned model. Shaded region indicates standard error. Asterisks denote time points with significant differences between the two groups (Student's t-test with FDR correction, p=0.05).", "description": "This figure displays a comparison of the Mean Squared Error (MSE) improvement between words categorized as 'social' or 'physical', and those outside these categories, after fine-tuning language models on datasets specific to each category. The x-axis represents time (in milliseconds) post-word onset, and the y-axis represents the difference in MSE between the fine-tuned model and the base model. Positive values indicate better performance of the fine-tuned model. Error bars are shown as shaded regions, and asterisks denote statistically significant differences between the two groups.", "section": "5.3 Comparing Fine-tuned Models with the Base Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_15_1.jpg", "caption": "Figure 6: Pearson correlation between actual MEG responses and predicted responses from (A) GPT-2 XL and (B) Llama-2 across LM layers and time after word onset on the Harry Potter dataset. Both models exhibit high correlations in early and intermediate layers at around 200ms. Correlation is computed across words and averaged across MEG channels.", "description": "This figure displays the Pearson correlation between actual MEG responses and those predicted by GPT-2 XL and Llama-2 across different layers and time points relative to word onset in the Harry Potter dataset.  High correlations are observed in the early and intermediate layers of both models at approximately 200ms post-word onset, suggesting a strong correspondence between the language models' representations and human brain activity during language processing.", "section": "2.3 Best Language Model Layer for Predicting MEG Responses"}, {"figure_path": "DpP5F3UfKw/figures/figures_16_1.jpg", "caption": "Figure 7: Sample sentences from the Harry Potter dataset, with colors indicating prediction error levels. Each of the five colors corresponds to a 20-percentile range of words from the entire dataset.", "description": "This figure shows sample sentences from the Harry Potter dataset color-coded according to their prediction error.  The colors represent five 20-percentile ranges of words, from those with the highest prediction error (most divergent from human brain responses) to those with the lowest (least divergent). This illustrates the challenge in manually identifying patterns in large datasets of text.", "section": "3 Identifying Phenomena of Interest"}, {"figure_path": "DpP5F3UfKw/figures/figures_16_2.jpg", "caption": "Figure 2: Pearson correlation of actual MEG responses with predicted responses using embeddings from layer 7 of GPT-2 XL on the Harry Potter dataset. The displayed layout is a flattened representation of the helmet-shaped sensor array. Deeper reds indicate more accurate LM predictions. Language regions are well predicted in language processing time windows (refer to \u00a72.4 for more details).", "description": "This figure shows the Pearson correlation between actual MEG responses and those predicted by the GPT-2 XL language model's layer 7 embeddings for the Harry Potter dataset.  The correlation is visualized across different time windows (0-500ms) post-word onset.  The layout is a flattened representation of the MEG sensor array, where redder colors represent stronger correlations (more accurate predictions) between the model's predictions and actual brain activity. The caption highlights that language regions show high correlation during typical language processing timeframes.", "section": "2 Predictive MEG Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_17_1.jpg", "caption": "Figure 2: Pearson correlation of actual MEG responses with predicted responses using embeddings from layer 7 of GPT-2 XL on the Harry Potter dataset. The displayed layout is a flattened representation of the helmet-shaped sensor array. Deeper reds indicate more accurate LM predictions. Language regions are well predicted in language processing time windows (refer to \u00a72.4 for more details).", "description": "This figure displays the Pearson correlation between actual MEG responses and predicted responses generated using embeddings from layer 7 of the GPT-2 XL language model.  The correlation is shown across various time windows (25ms intervals) after a word is presented.  The visualization is a flattened representation of the MEG sensor array on the scalp, with color intensity representing the strength of the correlation.  Higher intensity (deeper red) indicates better alignment between model predictions and actual brain responses. The caption notes that language regions show particularly good prediction accuracy within specific time windows.", "section": "2 Predictive MEG Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_22_1.jpg", "caption": "Figure 1: Schematic of our experimental approach. The LM takes as input the current word along with its preceding context to produce the current word's LM embedding. This embedding is then used as input to a ridge regression model to predict the human brain responses associated with the word. The Mean Squared Error (MSE) between the predicted and actual MEG responses is calculated. Finally, an LLM-based hypothesis proposer is employed to formulate natural language hypotheses explaining the divergence between the predicted and actual MEG responses.", "description": "This figure illustrates the experimental process used in the paper.  It shows how language model embeddings are used to predict MEG (Magnetoencephalography) responses to words. The process starts with the language model receiving a word and its context to generate an embedding. This embedding then goes into a ridge regression model which predicts the MEG response to that word. The MSE is then calculated to measure the difference between the predicted and the actual MEG response. Finally, an LLM is used to generate hypothesis to explain the differences.", "section": "2 Predictive MEG Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_23_1.jpg", "caption": "Figure 4: Performance comparison of the base model with models fine-tuned on (A) social and (B) physical datasets. Each panel's y-axis shows the percentage of channels in the fine-tuned model with better, worse, or non-significantly different performance (measured by Pearson correlation) compared to the base model. Fine-tuned models outperform the base model during language processing time windows. Refer to Appendix L for a detailed view of each MEG channel plotted.", "description": "This figure compares the performance of the base language model and the models fine-tuned on social and physical datasets. The y-axis represents the percentage of MEG channels showing better, worse, or no significant difference in performance (measured by Pearson correlation) between the fine-tuned and base models. The x-axis shows time in milliseconds. The results show that the fine-tuned models outperform the base model, particularly during the language processing time windows.", "section": "5.3 Comparing Fine-tuned Models with the Base Model"}, {"figure_path": "DpP5F3UfKw/figures/figures_24_1.jpg", "caption": "Figure 13: Comparison of improved MSE between (A) social and (B) physical words and those outside each category evaluated on models fine-tuned on corresponding datasets. Positive values denote lower MSEs in the fine-tuned model. Shaded region indicates standard error. Asterisks denote time points with significant differences between the two groups (Student's t-test with FDR correction, p=0.05).", "description": "This figure compares the mean squared error (MSE) improvements for social and physical words versus non-social and non-physical words after fine-tuning language models on social and physical datasets.  Lower MSE indicates better alignment between model predictions and actual MEG responses. The shaded areas represent standard error, and asterisks mark statistically significant differences (p<0.05 after FDR correction).  The figure shows that fine-tuning improves alignment specifically for words in the target category (social/physical) across various time windows.", "section": "5.3 Comparing Fine-tuned Models with the Base Model"}]