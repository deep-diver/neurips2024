[{"type": "text", "text": "From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mohammad Pedramfar McGill University and Mila \u2217 mohammad.pedramfar@mila.quebec ", "page_idx": 0}, {"type": "text", "text": "Vaneet Aggarwal Purdue University vaneet@purdue.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This paper introduces the notion of upper-linearizable/quadratizable functions, a class that extends concavity and DR-submodularity in various settings, including monotone and non-monotone cases over different types of convex sets. A general meta-algorithm is devised to convert algorithms for linear/quadratic maximization into ones that optimize upper-linearizable/quadratizable functions, offering a unified approach to tackling concave and DR-submodular optimization problems. The paper extends these results to multiple feedback settings, facilitating conversions between semi-bandit/first-order feedback and bandit/zeroth-order feedback, as well as between first/zeroth-order feedback and semi-bandit/bandit feedback. Leveraging this framework, new algorithms are derived using existing results as base algorithms for convex optimization, improving upon state-of-the-art results in various cases. Dynamic and adaptive regret guarantees are obtained for DRsubmodular maximization, marking the first algorithms to achieve such guarantees in these settings. Notably, the paper achieves these advancements with fewer assumptions compared to existing state-of-the-art results, underscoring its broad applicability and theoretical contributions to non-convex optimization. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Overview: The prominence of optimizing continuous adversarial $\\gamma$ -weakly up-concave functions (with DR-submodular and concave functions as special cases) has surged in recent years, marking a crucial subset within the realm of non-convex optimization challenges, particularly in the forefront of machine learning and statistics. This problem has numerous real-world applications, such as revenue maximization, mean-field inference, recommendation systems [4, 20, 30, 12, 24, 18, 26]. This problem is modeled as a repeated game between an optimizer and an adversary. In each round, the optimizer selects an action, and the adversary chooses a $\\gamma$ -weakly up-concave reward function. Depending on the scenario, the optimizer can then query this reward function either at any arbitrary point within the domain (called full information feedback) or specifically at the chosen action (called semi-bandit/bandit feedback), where the feedback can be noisy/deterministic. The performance metric of the algorithm is measured with multiple regret notions - static adversarial regret, dynamic regret, and adaptive regret. The algorithms for the problem are separated into the ones that use a projection operator to project the point to the closest point in the domain, and the projectionfree methods that replace the projection with an alternative such as Linear Optimization Oracles (LOO) or Separation Oracles (SO). This interactive framework introduces a range of significant challenges, influenced by the characteristics of the up-concave function (monotone/non-monotone), the constraints imposed, the nature of the queries, projection-free/projection-based algorithms, and the different regret definitions. ", "page_idx": 0}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/25b927b41cb2b66a68838b4531cfc1e0e287261314f3484360f9f8182dd389ae.jpg", "table_caption": ["Table 1: Online up-concave maximization "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "This table compares different static regret results for the online up-concave maximization. The logarithmic terms in regret are ignored. Here $h:=\\mathrm{min}_{\\mathbf{z}\\in K}\\left\\|\\mathbf{z}\\right\\|\\infty$ . Our algorithm is projection-free and use a separation oracle. The rows marked with $\\ddagger$ use gradient ascent, requiring potentially computationally expensive projections. The rows marked with $(*)$ denote results that could be considered special case of our framework. In particular, we obtain those results if we use Online Gradient Ascent instead of SO-OGA as the base algorithm in Corollary 7. Note that the result of [39], marked by $\\ddag\\ddag$ , uses a convex optimization subroutine in each iteration, which could potentially be more expensive than projection and therefore not considered a projection-free result. It is also the only existing result, in all the tables, that outperforms ours. We note that stochastic results can be used in deterministic, and bandit/semi-bandit in full information and thus cases where our result is not added, our result improves state-of-the-art projection free result because of the result in less information setup. All results assume that functions are Lipschitz. Except for our results on monotone functions over general convex sets, all results also assume differentiability. All previous results assume that functions are DR-submodular, while we only require up-concavity. Results of [35] and [39] also assume functions are smooth, i.e., their gradients are Lipschitz. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we present a comprehensive approach to solving adversarial up-concave optimization problems, encompassing different feedback types (including bandit, semi-bandit and fullinformation feedback), characteristics of the up-concave function and constraint region, projectionfree/projection-based algorithms, and regret definitions. While the problem has been studied in many special cases, the main contribution of this work is a framework that is based on a novel notion of the function class being upper-linearizable (or upper-quadratizable). We design a metaalgorithm that converts certain algorithms designed for online linear maximization to algorithms capable of handling upper-linearizable function classes. This allows us to reduce the problem of up-concave maximization in three different settings to online linear maximization and obtain corresponding regret bounds. In particular, our results include monotone $\\gamma.$ -weakly up-concave functions over general convex set, monotone $\\gamma$ -weakly up-concave functions over convex sets containing the origin and non-monotone up-concave functions. While the above result is for first order feedback, we then derive multiple results that increase the applicability of the above results. We extend the applicability of FOTZO and STB algorithm introduced in [34] to our setting which allows us to convert algorithms for first-order/semi-bandit feedback into algorithms for zeroth-order/bandit feedback. We also design a meta-algorithm that allows us to convert algorithms that require full-information feedback into algorithms that only require semi-bandit/bandit feedback. ", "page_idx": 1}, {"type": "text", "text": "We demonstrate the usefulness of results through two applications as described in the following. In the first application, we use the SO-OGD Algorithm in [17] as the base algorithm for online linear optimization, which is a projection-free algorithm. Using this, we first obtain the adaptive regret (and therefore also static regret) guarantees for the three setups of DR-submodular (or more generally, upconcave) optimization with semi-bandit feedback/first order feedback in the respective cases. Then, the meta-algorithms for conversion of first-order/semi-bandit to zeroth-order/bandit are used to get result with zeroth-order/bandit feedback. In the cases where the algorithms are full-information and not (semi-)bandit, we use another meta-algorithm to obtain algorithms in (semi-)bandit feedback setting. In the next application, we use the \u201cImproved Ader\u201d algorithm of [43] which is a projection based algorithm providing dynamic regret guarantees for the convex optimization. Afterwards, the same approach as above are used to obtain the results in the three scenarios of up-concave optimization with first-order feedback. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Technical Novelty: The main technical novelties in this work are as follows. ", "page_idx": 2}, {"type": "text", "text": "1. We proposes a novel notion of linearizable/quadratizable functions and extend the metaalgorithm framework of [34] from convex functions to linearizable/quadratizable functions. This allows us to relates a large class of algorithms and regret guarantees for optimization of linear/quadratic functions to that for linearizable/quadratizable functions.   \n2. We show that the class of quadratizable function optimization is general, and includes not only concave, but up-concave optimization in several cases. For some of the cases, this proof uses a generalization of the idea of boosting ([46, 48]) which was proposed for DR-submodular maximization, as mentioned in Corollaries 2 and 3.   \n3. We design a new meta-algorithm, namely SFTT, that captures the idea of random permutations (sometimes referred to as blocking) as used in several papers such as [45, 47, 35]. While previous works used this idea in specific settings, our meta-algorithm is applicable in general settings.   \n4. We note the generality of the above results in this paper. Our results are general in the following three aspects: a) In this work, we improve results for projection-free static regret guarantees for DRsubmodular optimization in all considered cases and obtain the first results for dynamic and adaptive regret. Moreover, these guarantees follow from existing algorithms for the linear optimization, using only the statement of the regret bounds and simple properties of the algorithms. b) We consider 3 classes of DR-submodular functions in this work. However, to extend these results to another function class, all one needs to do is to (i) prove that the function class is quadratizable; and (ii) provide an unbiased estimator of $\\mathfrak{g}$ (as described in Equation 1). c) We consider 2 different feedback types in offline setting (first/zero order) and 4 types of feedback in the online setting (first/zero order and full-information/trivial query). Converting results between different cases is obtained through meta-algorithms and guarantees for the meta-algorithms which only relies on high level properties of the base algorithms (See Theorems 5, 7, 6 and 8) ", "page_idx": 2}, {"type": "text", "text": "Key contributions: The key contributions in this work are summarized as follows. ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "1. We formulate the notion of upper-quadratizable/upper-linearizeble functions, which is a class that generalizes the notion of strong-concavity/concavity and also DR-submodularity in several settings. In particular, we demonstrate the the following function classes are upperquadratizable: (i) monotone $\\gamma$ -weakly $\\mu$ -strongly DR-submodular functions with curvature $c$ over general convex sets, (ii) monotone $\\gamma.$ -weakly DR-submodular functions over convex sets containing the origin, and (iii) non-monotone DR-submodular optimization over general convex sets.   \n2. We provide a general meta-algorithm that converts algorithms for linear/quadratic maximization to algorithms that maximize upper-quadratizable functions. This results is a unified approach to maximize both concave functions and DR-submodular functions in several settings.   \n3. While the above provides results for semi-bandit feedback (for monotone DR-submodular optimization over general convex sets) and first-order feedback (for monotone DR-submodular optimization over convex sets containing the origin, and non-monotone DR-submodular optimization over general convex sets), the results could be extended to more general feedback settings. Four meta algorithms are provided that relate semi-bandit/first-order feedback to bandit/zeroth order feedback; that relate; first order to deterministic zeroth order; and that relate ", "page_idx": 2}, {"type": "text", "text": "first/zeroth order feedback to semi-bandit/bandit feedback. Together they allow us to obtain results in 5 feedback settings (first/zeroth order full-information and semi-bandit/bandit; and deterministic zeroth order). We also discuss a meta-algorithm to convert online results to offline guarantees. ", "page_idx": 3}, {"type": "text", "text": "4. The above framework is applied using different algorithms as the base algorithms for linear optimization. SO-OGD [17] is a projection-free algorithm using separation oracles that provides adaptive regret guarantees for online convex optimization. We use our framework to cover the 18 cases in Table 1. We improve the regret guarantees for the previous SOTA projection-free algorithms in all the cases. If we also allow comparisons with the algorithms that are not projection-free, we still improve the SOTA results in 12 cases and match the SOTA in 5 cases.   \n5. Using our framework, we convert online results using SO-OGD to offline results to obtain 6 projection free algorithms described in Table 2. We improve the regret guarantees for the previous SOTA projection-free algorithms in all the cases, except for deterministic first order feedback where existing results are already SOTA. If we also allow comparisons with the algorithms that are not projection-free, we still improve the SOTA results in 6 cases and match the SOTA in the remaining 3 cases.   \n6. We use our framework to convert the adaptive regret guarantees of SO-OGD to obtain projectionfree algorithms with adaptive regret bounds that cover all cases in Table 3. Our results are first algorithms with adaptive regret guarantee for online DR-submodular maximization.   \n7. \u201cImproved Ader\u201d [43] is an algorithm providing dynamic regret guarantees for online convex optimization. We use our framework to obtain 6 algorithms which provide the dynamic regret guarantees as shown in Table 3. Our results are first algorithms with dynamic regret guarantee for online DR-submodular maximization.   \n8. For monotone $\\gamma$ -weakly functions with bounded curvature over general convex sets, we improve the approximation ratio (See Lemma 1).   \n9. As mentioned in the descriptions of the tables, in all cases considered, whenever there is another existing result, we obtain our results using fewer assumptions than the existing SOTA. ", "page_idx": 3}, {"type": "text", "text": "2 Problem Setup and Definitions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "For a set $\\mathcal{D}\\subseteq\\mathbb{R}^{d}$ , we define its affine hull af $(\\mathcal{D})$ to be the set of $\\alpha\\mathbf{x}+(1-\\alpha)\\mathbf{y}$ for all $\\mathbf x,\\mathbf y$ in $\\kappa$ and $\\alpha\\in\\mathbb{R}$ . The relative interior of $\\mathcal{D}$ is defined as $\\mathrm{relint}({\\mathcal{D}}):=\\{\\mathbf{x}\\in{\\mathcal{D}}\\mid\\exists r>0,\\mathbb{B}_{r}(\\mathbf{x})\\cap\\mathrm{aff}({\\mathcal{D}})\\subseteq$ $\\mathcal{D}\\}$ . For any $\\mathbf{u}\\in\\boldsymbol{\\kappa}^{T}$ , we define the path length $\\begin{array}{r}{P_{T}(\\mathbf u):=\\sum_{i=1}^{T-1}\\|\\mathbf u_{i}-\\mathbf u_{i+1}\\|}\\end{array}$ . Given $\\mu\\geq0$ and $0<\\gamma\\leq1$ , we say a differentiable function $f:K\\to\\mathbb{R}$ is $\\mu$ -strongly $\\gamma$ -weakly up-concave if it is $\\mu$ -strongly $\\gamma$ -weakly concave along positive directions. Specifically if, for all $\\mathbf x\\leq\\mathbf y$ in $\\kappa$ , we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\gamma\\left(\\langle\\nabla f(\\mathbf{y}),\\mathbf{y}-\\mathbf{x}\\rangle+{\\frac{\\mu}{2}}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right)\\leq f(\\mathbf{y})-f(\\mathbf{x})\\leq{\\frac{1}{\\gamma}}\\left(\\langle\\nabla f(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-{\\frac{\\mu}{2}}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We say $\\tilde{\\nabla}f:\\mathcal{K}\\to\\mathbb{R}^{d}$ is a $\\mu$ -strongly $\\gamma$ -weakly up-super-gradient of $f$ if for all $\\mathbf x\\leq\\mathbf y$ in $\\kappa$ , the above holds with $\\tilde{\\nabla}$ instead of $\\nabla$ . We say $f$ is $\\mu$ -strongly $\\gamma$ -weakly up-concave if it is continuous and it has a $\\mu$ -strongly $\\gamma$ -weakly up-super-gradient. When it is clear from the context, we simply refer to ${\\tilde{\\nabla}}f$ as an up-super-gradient for $f$ . When $\\gamma\\,=\\,1$ and the above inequality holds for all $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{K}}$ , we say $f$ is $\\mu$ -strongly concave. A differentiable function $f:K\\rightarrow\\mathbb{R}$ is called $\\gamma$ -weakly continuous $D R$ -submodular if for all $\\mathbf x\\leq\\mathbf y$ , we have $\\nabla f(\\mathbf{x})\\,\\geq\\,\\gamma\\nabla f(\\mathbf{y})$ . It follows that any $\\gamma$ - weakly continuous DR-submodular functions is $\\gamma$ -weakly up-concave. We refer to Appendix B for more details. ", "page_idx": 3}, {"type": "text", "text": "Given a continuous monotone function $f:K\\to\\mathbb{R}$ , its curvature is defined as the smallest number $c\\in[0,1]$ such that $f(\\mathbf{y}+\\mathbf{z})\\,-\\,f(\\mathbf{y})\\,\\geq\\,(1-c)(f(\\mathbf{x}+\\mathbf{z})-f(\\mathbf{x}))$ , for all $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{K}}$ and $\\textbf{z}\\geq0$ such that ${\\mathbf{x}}+{\\mathbf{z}},{\\mathbf{y}}+{\\mathbf{z}}\\in K$ . We define the curvature of a function class $\\mathbf{F}$ as the supremum of the curvature of functions in $\\mathbf{F}$ . ", "page_idx": 3}, {"type": "text", "text": "Online optimization problems can be formalized as a repeated game between an agent and an adversary. The game lasts for $T$ rounds on a convex domain $\\kappa$ where $T$ and $\\kappa$ are known to both players. In $t$ -th round, the agent chooses an action $\\mathbf{x}_{t}$ from an action set $\\kappa\\subseteq\\mathbb{R}^{d}$ , then the adversary chooses a loss function $f_{t}\\,\\in\\,\\mathbf{F}$ and a query oracle for the function $f_{t}$ . Then, for $1\\,\\leq\\,i\\,\\leq\\,k_{t}$ , ", "page_idx": 3}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/a8ba0438e5f7740902e251db9a97906f675af3a5adffb4331f130bb4ad6651f6.jpg", "table_caption": ["Table 2: Offline up-concave maximization "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "This table compares the different results for the number of oracle calls (complexity) within the constraint set for up-concave maximization. We refer to [36] for a more comprehensive table that includes results for deterministic first order feedback. Here $h:=\\mathrm{min}_{\\mathbf{z}\\in K}\\left\\|\\mathbf{z}\\right\\|_{\\infty}$ and $\\gamma^{\\prime}:=\\gamma+1/\\gamma$ . $\\ddagger$ [20], [46] and [48] use gradient ascent, requiring potentially computationally expensive projections. All previous results assume that functions are differentiable, DR-submodular, Lipschitz and smooth (i.e., their gradients are Lipschitz). Result of [19] also requires the function Hessians to be Lipschitz. It also requires the density of the stochastic oracle to be known and the log of density to be 4 times differentiable with bounded 4th derivatives. We only require the functions to be up-concave, differentiable and Lipschitz, except for results on monotone functions over general convex sets where we do not need differentiability. ", "page_idx": 4}, {"type": "text", "text": "the agent chooses a points $\\mathbf{y}_{t,i}$ and receives the output of the query oracle. The precise definition of agent $(\\Omega^{A},{\\mathcal{A}}^{\\mathrm{action}},{\\mathcal{A}}^{\\mathrm{query}})$ is given in Appendix B, with the query oracle being any of stochastic/deterministic first/zeroth order or semi-bandit/bandit. ", "page_idx": 4}, {"type": "text", "text": "An adversary Adv is a set of realized adversaries $\\boldsymbol{B}~=~(\\boldsymbol{B}_{1},\\cdot\\cdot\\cdot\\,,\\boldsymbol{B}_{T})$ , where each $B_{t}$ maps $({\\bf x}_{1},\\cdot\\cdot\\cdot\\mathbf{\\xi},{\\bf x}_{t})\\ \\in\\ K^{T}$ to $(f_{t},\\mathcal{Q}_{t})$ where $f_{t}\\in\\textbf{F}$ and $\\mathcal{Q}_{t}$ is a query oracle for $f_{t}$ . Adversaries can be oblivious $\\mathbf{\\nabla}\\{B_{t}$ are constant and independent of $\\left(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}\\right))$ ), weakly adaptive $\\mathbf{\\nabla}\\{B_{t}$ are independent of ${\\bf x}_{t}$ ), or fully adaptive (no restrictions). We use $\\operatorname{Adv}_{i}^{\\mathrm{f}}(\\mathbf{F})$ to denote the set of all possible realized adversaries with deterministic $i$ -th order oracles. If the oracle is instead stochastic and bounded by $B$ , we use $\\operatorname{Adv}_{i}^{\\mathrm{f}}(\\mathbf{F},B)$ to denote such an adversary. Finally, we use $\\operatorname{Adv}_{i}^{0}(\\mathbf{F})$ and $\\mathrm{Adv}_{i}^{0}({\\dot{\\mathbf{F}}},B)$ to denote all oblivious realized adversaries with $i$ -th order deterministic and stochastic oracles, respectively. In order to handle different notions of regret with the same approach, for an agent $\\boldsymbol{\\mathcal{A}}$ , adversary Adv, compact set $\\mathcal{U}\\ \\subseteq\\ K^{T}$ , approximation coefficient $0~<~\\alpha~\\leq~1$ and $1\\ \\leq\\ a\\ \\leq\\ b\\ \\leq\\ T$ , we define regret as $\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(\\mathcal{U})[a,b]\\;:=$ $\\begin{array}{r}{\\operatorname*{sup}_{\\mathcal{B}\\in\\mathrm{Adv}}\\mathbb{E}\\left[\\alpha\\operatorname*{max}_{\\mathbf{u}=(\\mathbf{u}_{1},\\cdots,\\mathbf{u}_{T})\\in\\mathcal{U}}\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right],}\\end{array}$ , where the expectation in the definition of the regret is over the randomness of the algorithm and the query oracle. We use the notation $\\mathcal{R}_{\\alpha,\\boldsymbol{B}}^{A}(\\widecheck{\\mathcal{U}})[a,b]\\ :=\\ \\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(\\mathcal{U})[a,b]$ when $\\bar{\\bf A}\\mathrm{dv}\\,\\,=\\,\\,\\{\\boldsymbol{B}\\}$ is a singleton. We may drop $\\alpha$ when it is equal to 1. When $\\alpha\\mathrm{~\\ensuremath~{~<~}~}1$ , we often assume that the functions are nonnegative. Static adversarial regret or simply adversarial regret corresponds to $a\\,=\\,1,\\;b\\;=\\;T$ and $\\mathcal{U}\\;=\\;\\mathcal{K}_{\\star}^{T}\\;:=\\;\\{(\\mathbf{x},\\cdot\\cdot\\cdot\\,,\\mathbf{x})^{\\flat}\\;|\\;\\mathbf{x}\\;\\in\\;\\mathcal{K}\\}$ . When $a\\ =\\ 1$ , $b\\,=\\,T$ and $\\boldsymbol{\\mathcal{U}}$ contains only a single element then it is referred to as the dynamic regret [51, 43]. Adaptive regret is defined as $\\begin{array}{r}{\\operatorname*{max}_{1\\leq a\\leq b\\leq T}\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(K_{\\star}^{T})[a,b]}\\end{array}$ [23]. We drop $a,\\,b$ and $\\boldsymbol{\\mathcal{U}}$ when the statement is independent of their value or their value is clear from the context. ", "page_idx": 4}, {"type": "text", "text": "3 Formulation of Upper-Quadratizable Functions and Regret Relation to that of Quadratic Functions ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $\\boldsymbol{\\kappa}\\subseteq\\mathbb{R}^{d}$ be a convex set, $\\mathbf{F}$ be a function class over $\\kappa$ . We say the function class $\\mathbf{F}$ is upperquadratizable if there are maps $\\mathfrak{g}:\\mathbf{F}\\times\\mathcal{K}\\rightarrow\\mathbb{R}^{d}$ and $h:K\\to K$ and constants $\\mu\\geq0$ , $0<\\alpha\\leq1$ ", "page_idx": 4}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/950296a3440d21bbba2222f2341a3fa875f74df7213b73cca2e1a6b77bcc52f6.jpg", "table_caption": ["Table 3: Non-stationary up-concave maximization "], "table_footnote": ["This table includes different results for non-stationary up-concave maximization, while no prior results exist in this setup to the best of our knowledge. The results for adaptive regret are projection-free and use a separation oracle while results for dynamic regret use convex projection. Note that full-information algorithms with deterministic feedback require 2 queries per function while the ones with stochastic feedback only require one, at the cost of higher regret. "], "page_idx": 5}, {"type": "text", "text": "and $\\beta>0$ such that 2 ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha f(\\mathbf{y})-f(h(\\mathbf{x}))\\leq\\beta\\left(\\langle\\mathfrak{g}(f,\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "As a special case, when $\\mu~=~0$ , we say $\\mathbf{F}$ is upper-linearizable. We use the notation $\\mathbf{F}_{\\mu,\\mathbf{g}}$ to denote the class of functions $\\begin{array}{r}{q(\\mathbf{y}):=\\langle\\mathfrak{g}(f,\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}:K\\to\\mathbb{R}}\\end{array}$ , for all $f\\in\\mathbf{F}$ and $\\textbf{x}\\in\\mathcal{K}$ . Similarly, for any $B_{1}\\,>\\,0$ , we use the notation $\\mathbf{\\bar{Q}}_{\\mu}[B_{1}]$ to denote the class of functions $\\begin{array}{r}{q(\\mathbf{y})\\,:=\\,\\langle\\mathbf{o},\\mathbf{y}-\\mathbf{x}\\rangle-\\,\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}:\\mathcal{K}\\to\\mathbb{R}}\\end{array}$ , for all $\\textbf{x}\\in\\mathcal{K}$ and $\\mathbf{o}\\,\\in\\,\\mathbb{B}_{B_{1}}(\\mathbf{0})$ . A similar notion of lower-quadratizable/linearizable may be similarly defined for minimization problems such as convex minimization. 3 ", "page_idx": 5}, {"type": "text", "text": "We say an algorithm $\\mathcal{G}$ is a first order query algorithm for $\\mathfrak{g}$ if, given a point $\\mathbf{x}\\in\\mathcal{K}$ and a first order query oracle for $f$ , it returns (a possibly unbiased estimate of) ${\\mathfrak{g}}(f,\\mathbf{x})$ . We say $\\mathcal{G}$ is bounded by $B_{1}$ if the output of $\\mathcal{G}$ is always within the ball $\\mathbb{B}_{B_{1}}^{d}(\\mathbf{0})$ and we call it trivial if it simply returns the output of the query oracle at $\\mathbf{x}$ . ", "page_idx": 5}, {"type": "text", "text": "Recall that an online agent $\\boldsymbol{\\mathcal{A}}$ is composed of action function $\\mathcal{A}^{\\mathrm{action}}$ and query function $A^{\\mathrm{query}}$ . Informally, given an online algorithm $\\boldsymbol{\\mathcal{A}}$ with semi-bandit feedback, we may think of ${\\mathcal A}^{\\prime}:=0\\mathbb{M B Q}({\\mathcal A},{\\mathcal G},h)$ as the online algorithm with $(\\mathcal{A}^{\\prime})^{\\mathrm{action}}\\approx h(\\mathcal{A}^{\\mathrm{action}})$ and $({\\mathcal{A}}^{\\prime})^{\\mathrm{query}}\\approx{\\mathcal{G}}$ . As a special case, when $h=\\mathrm{Id}$ and $\\mathcal{G}$ is trivial, we have ${\\bar{A^{\\prime}}}={\\bar{A}}$ . ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1: Online Maximization By Quadratization - $0{\\tt M B Q}({\\cal A},{\\cal G},h)$ ", "page_idx": 5}, {"type": "text", "text": "Input : horizon $T$ , semi-bandit algorithm $\\boldsymbol{\\mathcal{A}}$ , query algorithm $\\mathcal{G}$ for $\\mathfrak{g}$ , the map $h:K\\to K$   \nfor $t=1,2,\\ldots,T$ do Play $h(\\mathbf{x}_{t})$ where $\\mathbf{x}_{t}$ is the action chosen by $\\mathcal{A}$ The adversary selects $f_{t}$ and a first order query oracle for $f_{t}$ Run $\\mathcal{G}$ with access to $\\mathbf{x}_{t}$ and the query oracle for $f_{t}$ to calculate $\\mathbf{o}_{t}$ Return $\\mathbf{o}_{t}$ as the output of the query oracle to $\\mathcal{A}$   \nend ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. Let A be algorithm for online optimization with semi-bandit feedback. Also let $\\mathbf{F}$ be a function class over $\\kappa$ that is quadratizable with $\\mu\\geq0$ and maps $\\mathfrak{g}:\\mathbf{F}\\times\\dot{K}\\rightarrow\\mathbb{R}^{d}$ and $h:K\\to K$ , let $\\mathcal{G}$ be a query algorithm for $\\mathfrak{g}$ and let ${\\mathcal{A}}^{\\prime}=0{\\mathrm{MBQ}}({\\mathcal{A}},{\\mathcal{G}},h)$ . Then the following are true. ", "page_idx": 6}, {"type": "text", "text": "1.If $\\mathcal{G}$ returns the exact value of $\\mathfrak{g}$ , then we have $\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{f}(\\mathbf{F})}^{\\mathcal{A}^{\\prime}}\\le\\beta\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{f}(\\mathbf{F}_{\\mu,\\mathfrak{g}})}^{\\cal{A}}.$ 2.tOhne nt hwee  ohthaevre $\\mathcal{G}$ .ate of $\\mathfrak{g}$ and the output of $\\mathcal{G}$ is bounded by $B_{1}$ , $\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A^{\\prime}}\\le\\beta\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{f}(\\mathbf{Q}_{\\mu}[B_{1}])}^{A}.$ ", "page_idx": 6}, {"type": "text", "text": "As a special case, when $f$ is concave, we may choose $\\alpha\\,=\\,\\beta\\,=\\,1$ , $h\\,=\\,\\mathrm{Id}$ , and ${\\mathfrak{g}}(f,\\mathbf{x})$ to be a super-gradient of $f$ at $\\mathbf{x}$ . In this case, Theorem 1 reduces to the concave version of Theorems 2 and 5 in [34]. ", "page_idx": 6}, {"type": "text", "text": "4 Up-concave function optimization is upper-quadratizable function optimization ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we study three classes of up-concave functions and show that they are upperquadratizable. We further use this property to obtain meta-algorithms that convert algorithms for quadratic optimization into algorithms for up-concave maximization. ", "page_idx": 6}, {"type": "text", "text": "4.1 Monotone up-concave optimization over general convex sets ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For differentiable DR-submodular functions, the following lemma is proven for the case $\\gamma=1$ in Lemma 2 in [13] and for the case $\\mu=0$ in [20] (See Inequality 7.5 in the arXiv version). We show the result for general $\\mu$ -strongly $\\gamma$ -weakly up-concave function with curvature bounded by $c$ , See Appendix $\\mathrm{D}$ for proof. ", "page_idx": 6}, {"type": "text", "text": "Lemma 1. Let $f\\;:\\;[0,1]^{d}\\;\\to\\;\\mathbb{R}$ be a non-negative monotone $\\mu$ -strongly $\\gamma$ -weakly up-concave function with curvature bounded by $c$ . Then, for all $\\mathbf{x},\\mathbf{y}\\in[0,1]^{d}$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{\\gamma^{2}}{1+c\\gamma^{2}}f(\\mathbf{y})-f(\\mathbf{x})\\leq\\frac{\\gamma}{1+c\\gamma^{2}}\\left(\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where ${\\tilde{\\nabla}}f$ is an up-super-gradient for $f$ . ", "page_idx": 6}, {"type": "text", "text": "Further, we show that any semi-bandit feedback online linear optimization algorithm for fully adaptive adversary is also an online up-concave optimization algorithm. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. Let $K\\subseteq[0,1]^{d}$ be a convex set, let $\\mu\\geq0,\\,\\gamma\\in(0,1],\\,c\\in[0,1]$ and let $\\boldsymbol{\\mathcal{A}}$ be algorithm for online optimization with semi-bandit feedback. Also let $\\mathbf{F}$ be an $M_{1}$ -Lipschitz function class over $\\kappa$ where every $f\\in\\mathbf{F}$ is may be extended to a monotone $\\mu$ -strongly $\\gamma$ -weakly up-concave function curvature bounded by $c$ defined over $[0,1]^{d}$ . Then, for any $B_{1}\\geq M_{1}$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{\\prime}(\\mathbf{F})}^{A}\\leq\\frac{\\gamma}{1+c\\gamma^{2}}\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{\\prime}(\\mathbf{Q}_{\\mu}[M_{1}])}^{A},\\quad\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{\\circ}(\\mathbf{F},B_{1})}^{A}\\leq\\frac{\\gamma}{1+c\\gamma^{2}}\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{\\prime}(\\mathbf{Q}_{\\mu}[B_{1}])}^{A}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "These results follows immediately from Theorem 1 and Lemma 1. Note that it is important to assume that every function in $\\mathbf{F}$ may be extended to a non-negative up-concave function over $[0,1]^{d}$ for Lemma 1 to be applied. ", "page_idx": 6}, {"type": "text", "text": "Corollary 1. The results of [20], [8] and [13] on monotone continuous DR-submodular maximization over general convex sets may be thought of as special cases of Theorem 2 when A is the online gradient ascent algorithm. ", "page_idx": 6}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/af702abc46cf3bb4b6991b7e5c2d96cb508019c29d1bdbdfbd9f9b1153e95d03.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4.2 Monotone up-concave optimization over convex sets containing the origin ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The following lemma is proven for differentiable DR-submodular functions in Theorem 2 and Proposition 1 of [46]. The proof works for general up-concave functions as well. We include a proof in Appendix E for completeness. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2. Let $f:[0,1]^{d}\\,\\to\\,\\mathbb{R}$ be a non-negative monotone $\\gamma$ -weakly up-concave differentiable function and let $F:[0,1]^{d}\\to\\mathbb{R}$ be the function defined by ", "page_idx": 7}, {"type": "equation", "text": "$$\nF(\\mathbf{x}):=\\int_{0}^{1}\\frac{\\gamma e^{\\gamma(z-1)}}{(1-e^{-\\gamma})z}\\big(f(z*\\mathbf{x})-f(\\mathbf{0})\\big)d z.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Then $F$ is differentiable and, if the random variable $\\mathcal{Z}\\in[0,1]$ is defined by the law ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\forall z\\in[0,1],\\quad\\mathbb{P}(\\mathcal{Z}\\leq z)=\\int_{0}^{z}\\frac{\\gamma e^{\\gamma(u-1)}}{1-e^{-\\gamma}}d u,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then we have $\\mathbb{E}\\left[\\nabla f(\\mathcal{Z}*\\mathbf{x})\\right]\\ =\\ \\nabla F(\\mathbf{x})$ . Moreover, we have $(1\\;-\\;e^{-\\gamma})f({\\bf y})\\;-\\;f({\\bf x})\\;\\;\\leq$ 1\u2212\u03b3e\u2212\u03b3\u27e8\u2207F(x), y \u2212x\u27e9. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3. Let $K\\,\\subseteq\\,[0,1]^{d}$ be a convex set containing the origin, let $\\gamma\\,\\in\\,(0,1]$ and let $\\boldsymbol{\\mathcal{A}}$ be algorithm for online optimization with semi-bandit feedback. Also let $\\mathbf{F}$ be a function class over $\\kappa$ where every $f\\in\\mathbf{F}$ is the restriction of a monotone $\\gamma$ -weakly up-concave function defined over $[0,1]^{d}$ to the set $\\kappa$ . Assume $\\mathbf{F}$ is differentiable and $M_{1}$ -Lipschitz for some $M_{1}>0$ . Then, for any $B_{1}\\geq M_{1}$ , we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A^{\\prime}}\\leq\\frac{1-e^{-\\gamma}}{\\gamma}\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{f}(\\mathbf{Q}_{\\mu}[B_{1}])}^{A}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\mathcal{A}^{\\prime}=0\\mathtt{M B Q}(\\mathcal{A},\\mathtt{B Q M O},\\mathrm{Id})$ . ", "page_idx": 7}, {"type": "text", "text": "This result now follows immediately from Theorem 1 and Lemma 2. ", "page_idx": 7}, {"type": "text", "text": "Corollary 2. The result of [46] in the online setting (when there is no delay) may be seen as an application of Theorem 3 when $\\boldsymbol{\\mathcal{A}}$ is chosen to be online gradient ascent. ", "page_idx": 7}, {"type": "text", "text": "4.3 Non-monotone up-concave optimization over general convex sets ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The following lemma is proven for differentiable DR-submodular functions in Corollary 2, Theorem 4 and Proposition 2 of [48]. The arguments works for general up-concave functions as well. We include a proof in Appendix F for completeness. ", "page_idx": 7}, {"type": "text", "text": "Lemma 3. Let $f\\quad:\\quad[0,1]^{d}\\quad\\to\\quad\\mathbb{R}$ be $a$ non-negative continuous up-concave differentiable function and let $\\begin{array}{r l r}{\\underline{{\\mathbf{x}}}}&{{}\\in}&{K}\\end{array}$ . Define $F\\,\\,:\\,\\,\\,[0,1]^{d}\\,\\,\\,\\to\\,\\,\\,\\mathbb{R}$ as the function $F(\\mathbf{x})\\quad:=$ 013z(12\u2212z )3 f z2 \u2217(x \u2212x) + x \u2212f(x) dz. Then F is differentiable and, if the random variable $\\mathcal{Z}\\in[0,1]$ is defined by the law ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\forall z\\in[0,1],\\quad\\mathbb{P}(\\mathcal{Z}\\leq z)=\\int_{0}^{z}\\frac{1}{3(1-\\frac{u}{2})^{3}}d u,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then we have $\\begin{array}{r}{\\mathbb{E}\\left[\\nabla f\\left(\\frac{\\mathcal{Z}}{2}*\\left(\\mathbf{x}-\\underline{{\\mathbf{x}}}\\right)+\\underline{{\\mathbf{x}}}\\right)\\right]=\\nabla F(\\mathbf{x})}\\end{array}$ . Moreover, we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{1-\\|\\mathbf{x}\\|_{\\infty}}{4}f(\\mathbf{y})-f\\left(\\frac{\\mathbf{x}+\\underline{{\\mathbf{x}}}}{2}\\right)\\le\\frac{3}{8}\\langle\\nabla F(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Theorem 4. Let $K\\subseteq[0,1]^{d}$ be a convex set, $\\underline{{\\mathbf{u}}}\\in\\mathcal{K},\\,h:=\\|\\underline{{\\mathbf{u}}}\\|_{\\infty}$ and $\\boldsymbol{\\mathcal{A}}$ be algorithm for online optimization with semi-bandit feedback. Also let $\\mathbf{F}$ be a function class over $\\kappa$ where every $f\\in\\mathbf{F}$ is the restriction of an up-concave function defined over $[0,1]^{d}$ to the set $\\kappa$ . Assume $\\mathbf{F}$ is differentiable and $M_{1}$ -Lipschitz for some $M_{1}>0$ . Then, for any $B_{1}\\geq M_{1}$ and $\\begin{array}{r}{\\mathcal{A}^{\\prime}=0\\mathbb{M}\\mathrm{BQ}(\\mathcal{A},\\mathtt{B Q N},\\mathbf{x}\\mapsto\\frac{\\mathbf{x}_{t}+\\mathbf{x}}{2})}\\end{array}$ , ", "page_idx": 7}, {"type": "text", "text": "These results now follows immediately from Theorem 1 and Lemma 3. ", "page_idx": 7}, {"type": "text", "text": "Corollary 3. The result of $[48]$ in the online setting without delay may be seen as an application of Theorem 4 when $\\boldsymbol{\\mathcal{A}}$ is chosen to be online gradient ascent. ", "page_idx": 7}, {"type": "text", "text": "Algorithm 3: Boosted Query oracle for Non-monotone up-concave functions over general convex sets \u2013 BQN Input : First order query oracle, point x Sample $z\\in[0,1]$ according to Equation 3 Return the output of the query oracle at $\\begin{array}{r}{\\frac{z}{2}*\\left(\\mathbf{x}-\\underline{{\\mathbf{x}}}\\right)+\\underline{{\\mathbf{x}}}}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "5 Meta algorithms for other feedback cases ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we study several meta-algorithms that allow us to convert between different feedback types and also convert results from the online setting to the offline setting. ", "page_idx": 8}, {"type": "text", "text": "First order/semi-bandit to zeroth order/bandit feedback: In this section we discuss metaalgorithms that convert algorithms designed for first order feedback into algorithms that can handle zeroth order feedback. These algorithms and results are generalization of similar results in [34] to the case where $\\alpha<1$ . ", "page_idx": 8}, {"type": "text", "text": "We choose a point $\\mathbf{c}\\in\\mathrm{relint}(K)$ and a real number $r>0$ such that $\\smash{\\{\\mathbf{f}\\}(K)\\cap\\mathbb{B}_{r}(\\mathbf{c})\\subseteq K}$ . Then, for any shrinking parameter $0\\leq\\delta<r$ , we define $\\begin{array}{r}{\\hat{\\mathcal{K}}_{\\delta}:=(1-\\frac{\\delta}{r})\\mathcal{K}+\\frac{\\delta}{r}\\mathbf c}\\end{array}$ . For a function $f:K\\to\\mathbb{R}$ defined on a convex set $\\kappa\\subseteq\\mathbb{R}^{d}$ , its $\\delta$ -smoothed version $\\hat{f}_{\\delta}:\\hat{\\mathcal{K}}_{\\delta}\\rightarrow\\mathbb{R}$ is given as ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\hat{f}_{\\delta}(\\mathbf{x}):=\\mathbb{E}_{\\mathbf{z}\\sim\\mathrm{aff}(K)\\cap\\mathbb{B}_{\\delta}(\\mathbf{x})}[f(\\mathbf{z})]=\\mathbb{E}_{\\mathbf{v}\\sim\\mathcal{L}_{0}\\cap\\mathbb{B}_{1}(\\mathbf{0})}[f(\\mathbf{x}+\\delta\\mathbf{v})],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathcal{L}_{0}=\\mathrm{aff}(K)-\\mathbf{x}$ , for any $\\mathbf{x}\\in{\\mathcal{K}}$ , is the linear space that is a translation of the affine hull of $\\kappa$ and $\\mathbf{v}$ is sampled uniformly at random from the $k=\\dim(\\mathcal{L}_{0})$ -dimensional ball $\\mathcal{L}_{0}\\cap\\mathbb{B}_{1}(\\mathbf{0})$ . Thus, the function value $\\hat{f}_{\\delta}(\\mathbf{x})$ is obtained by \u201caveraging\u201d $f$ over a sliced ball of radius $\\delta$ around $\\mathbf{x}$ . For a function class $\\mathbf{F}$ over $\\kappa$ , we use $\\hat{\\mathbf{F}}_{\\delta}$ to denote $\\{\\hat{f}_{\\delta}\\mid f\\in{\\bf F}\\}$ . We will drop the subscript $\\delta$ when there is no ambiguity (See Appendix $\\mathrm{G}$ for the description of the algorithms and the proof.). ", "page_idx": 8}, {"type": "text", "text": "Theorem 5. Let $\\mathbf{F}$ be an $M_{1}$ -Lipschitz function class over a convex set $\\kappa$ and choose c and $r$ as described above and let $\\delta<r$ . Let $\\mathcal{U}\\subseteq\\mathcal{K}^{T}$ be a compact set and let $\\begin{array}{r}{\\hat{\\mathcal{U}}=(1-\\frac{\\delta}{r})\\mathcal{U}+\\frac{\\delta}{r}\\mathbf{c}}\\end{array}$ . Assume $\\boldsymbol{\\mathcal{A}}$ is an algorithm for online optimization with first order feedback. Then, if $A^{\\prime}=\\operatorname{F0TZ0}(A)$ where FOTZO is described by Algorithm 5 and $0<\\alpha\\le1$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{\\mathcal{A}^{\\prime}}(\\mathcal{U})\\leq\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\hat{\\mathbf{F}},\\frac{k}{\\delta}B_{0})}^{\\mathcal{A}}(\\hat{\\mathcal{U}})+\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "On the other hand, $i f$ we assume that $\\boldsymbol{\\mathcal{A}}$ is semi-bandit, then the same regret bounds hold with $A^{\\prime}=\\operatorname{STB}(A)$ , where STB is described by Algorithm $^{6}$ . ", "page_idx": 8}, {"type": "text", "text": "Theorem 6. Under the assumptions of Theorem $^{5}$ , if $A^{\\prime}=\\operatorname{F0TZ0-2P}(A)$ where FOTZO-2P is described by Algorithm 7 and $0<\\alpha\\le1$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathcal{A}^{\\prime}}(\\mathcal{U})\\leq\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\hat{\\mathbf{F}},k M_{1})}^{\\mathcal{A}}(\\hat{\\mathcal{U}})+\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Full information to trivial query: In this section, we discuss a meta-algorithm that converts algorithms that require full-information feedback into algorithms that have a trivial query oracle. In particular, it converts algorithms that require first-order full-information feedback into semi-bandit algorithms and algorithms that require zeroth-order full-information feedback into bandit algorithms. ", "page_idx": 8}, {"type": "text", "text": "Here we assume that $A^{\\mathrm{query}}$ does not depend on the observations in the current round. If the number of queries $k_{t}$ is not constant for each time-step, we simply assume that $\\boldsymbol{\\mathcal{A}}$ queries extra points and then discards them, so that we obtain an algorithm that queries exactly $K$ points at each time-step, where $K$ does not depend on $t$ . We say a function class $\\mathbf{F}$ is closed under convex combination if for any $f_{1},\\cdot\\cdot\\cdot,f_{k}\\in\\mathbf{F}$ and any $\\delta_{1},\\cdots\\,,\\delta_{k}\\ge0$ with $\\textstyle\\sum_{i}\\delta_{i}=1$ , we have $\\textstyle\\sum_{i}\\delta_{i}f_{i}\\in\\mathbf{F}$ . ", "page_idx": 8}, {"type": "text", "text": "Theorem 7. Let $\\boldsymbol{\\mathcal{A}}$ be an online optimization algorithm with full-information feedback and with $K$ queries at each time-step where $A^{q u e r y}$ does not depend on the observations in the current round and $A^{\\prime}\\,=\\,\\operatorname{SFTT}(A)$ . Then, for any $M_{1}$ -Lipschitz function class $\\mathbf{F}$ that is closed under convex combination and any $B_{1}\\geq M_{1}$ , $0\\,<\\,\\alpha\\,\\leq\\,1$ and $1\\,\\leq\\,a\\,\\leq\\,b\\,\\leq\\,T,$ , let $a^{\\prime}=\\lfloor(a-1)/L\\rfloor+1,$ , $b^{\\prime}=\\lceil b/L\\rceil$ , $D=\\dim(K)$ and let $\\{T\\}$ and $\\{T/L\\}$ denote the horizon of the adversary. Then, we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})\\{T\\}}^{A^{\\prime}}(K_{\\star}^{T})[a,b]\\leq M_{1}D K(b^{\\prime}-a^{\\prime}+1)+L\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})\\{T/L\\}}^{A^{\\prime}}(K_{\\star}^{T/L})[a^{\\prime},b^{\\prime}],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "This result (proof in Appendix $\\mathrm{H}$ ) is based on the idea of random permutations used in [45, 47, 35]. ", "page_idx": 8}, {"type": "text", "text": "Online to Offline: An offline optimization problem can be though of as an instance of online optimization where the adversary picks the same function and query oracle at each round. Moreover, instead of regret, the performance of the algorithm is measured by sample complexity, i.e., the minimum number of queries required so that the expected error from the $\\alpha$ -approximation of the optimal value is less than $\\epsilon$ . ", "page_idx": 8}, {"type": "text", "text": "Conversions of online algorithms to offline are referred to online-to-batch techniques and are well-known in the literature (See [38]). A simple approach is to simply run the online algorithm and if the actions chosen by the algorithm are $\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{T}$ , return $\\mathbf{x}_{t}$ for $1\\leq t\\leq T$ with probability $1/T$ . We use OTB to denote the meta-algorithm that uses this approach to convert online algorithms to offline algorithms. The following theorem is a corollary which we include for completion (See Appendix I for the proof.). ", "page_idx": 9}, {"type": "text", "text": "Theorem 8. Let $\\boldsymbol{\\mathcal{A}}$ be an online algorithm that queries no more than $K=T^{\\theta}$ times per timestep that obtains an $\\alpha$ -regret bound of $O(T^{\\eta})$ over an oblivious adversary Adv. Then the sample complexity of ${\\mathsf{O T B}}({\\mathcal{A}})$ over $\\left\\{(f,\\mathcal{Q}_{f})\\right.\\right.\\left|$ $((f,\\mathcal{Q}_{f}),\\cdot\\cdot\\cdot\\;,(f,\\mathcal{Q}_{f}))\\in\\mathrm{Adv}\\}$ is $O(\\epsilon^{-\\frac{1+\\theta}{1-\\eta}})$ . ", "page_idx": 9}, {"type": "text", "text": "Algorithm 4: Stochastic Full-information To Trivial query - SFTT(A) ", "page_idx": 9}, {"type": "image", "img_path": "dGaMSMeeF8/tmp/e84512471ae5053df2f96612acf7cb22368adc7d8bf1873b139946660561e249.jpg", "img_caption": [], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Applications ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Figure 6 captures the applications that are mentioned in Tables 1, 2 and 3. The exact statements are stated in Corollaries 7 and 8 in the Appendix. To obtain a result from the graph, let $\\boldsymbol{\\mathcal{A}}$ be one of SO-OGA or IA and select a directed path that has the following properties: (i) The path starts at one of the three nodes on the left. (ii) The path must be at least of length 1 and the edges must be the same color. (iii) If $\\boldsymbol{\\mathcal{A}}$ is IA, the path should not contain SFTT or OTB. ", "page_idx": 9}, {"type": "text", "text": "For example, if $~A~=~{\\bf S}0{-}0{\\bf G}{\\bf A}$ and the path starts at the middle node on the left, then passes through OMBQ, FOTZO, SFTT, we get SFTT(FOTZO(OMBQ(SO-OGA, BQM0, Id))), which is a projection-free algorithm (using separation oracles) with bandit feedback for ", "page_idx": 9}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/d2b45f78783fe7236d9b5d03a6d6f747f158f0e3e83a3d74e820e574a2be0ec5.jpg", "table_caption": ["Figure 1: Summary of applications "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "monotone up-concave functions over convex sets that contain the origin. As mentioned in Table 3 and Corollary 7-(c), the adaptive regret of this algorithm is of order $O(T^{4/5})$ . Note that the text written in the three nodes on the left correspond to the inputs of the meta-algorithm OMBQ. Also note that the color red corresponds to the setting where $\\mathcal{G}$ is a trivial query algorithm which means that the output of OMBQ is semi-bandit. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we have presented a comprehensive framework for addressing optimization problems involving upper-quadratizable functions, encompassing both concave and DR-submodular functions across various settings and feedback types. Our contributions include the formulation of upperquadratizable functions as a generalized class, the development of meta-algorithms for algorithmic conversions, and the derivation of new algorithms with improved static/ dynamic/ adaptive regret guarantees. Exploring more subset of classes of upper-quadratizable functions where such a framework could be applied is an important future direction. ", "page_idx": 9}, {"type": "text", "text": "8 Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was supported in part by the National Science Foundation under grant CCF-2149588. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. Operations Research, 63(5):1227\u20131244, 2015. [2] An Bian, Kfir Levy, Andreas Krause, and Joachim M Buhmann. Continuous DR-submodular maximization: Structure and algorithms. In Advances in Neural Information Processing Systems, 2017. [3] Andrew An Bian, Baharan Mirzasoleiman, Joachim Buhmann, and Andreas Krause. Guaranteed Non-convex Optimization: Submodular Maximization over Continuous Domains. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, April 2017. [4] Yatao Bian, Joachim Buhmann, and Andreas Krause. Optimal continuous DR-submodular maximization and applications to provable mean field inference. In Proceedings of the 36th International Conference on Machine Learning, June 2019.   \n[5] Gruia Calinescu, Chandra Chekuri, Martin P\u00b4al, and Jan Vondra\u00b4k. Maximizing a monotone submodular function subject to a matroid constraint. SIAM Journal on Computing, 40(6):1740\u2013 1766, 2011. [6] Chandra Chekuri, T.S. Jayram, and Jan Vondrak. On multiplicative weight updates for concave and submodular function maximization. In Proceedings of the 2015 Conference on Innovations in Theoretical Computer Science, pages 201\u2013210, 2015. [7] Lin Chen, Christopher Harshaw, Hamed Hassani, and Amin Karbasi. Projection-free online optimization with stochastic gradient: From convexity to submodularity. In Proceedings of the 35th International Conference on Machine Learning, July 2018. [8] Lin Chen, Hamed Hassani, and Amin Karbasi. Online continuous submodular maximization. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, April 2018.   \n[9] Lin Chen, Mingrui Zhang, and Amin Karbasi. Projection-free bandit convex optimization. In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics, pages 2047\u20132056. PMLR, 2019.   \n[10] Shengminjie Chen, Donglei Du, Wenguo Yang, Dachuan Xu, and Suixiang Gao. Continuous non-monotone DR-submodular maximization with down-closed convex constraint. arXiv preprint arXiv:2307.09616, July 2023.   \n[11] Amit Daniely, Alon Gonen, and Shai Shalev-Shwartz. Strongly adaptive online learning. In Proceedings of the 32nd International Conference on Machine Learning, pages 1405\u20131411. PMLR, 2015.   \n[12] Josip Djolonga and Andreas Krause. From map to marginals: Variational inference in Bayesian submodular models. Advances in Neural Information Processing Systems, 2014.   \n[13] Maryam Fazel and Omid Sadeghi. Fast first-order methods for monotone strongly drsubmodular maximization. In SIAM Conference on Applied and Computational Discrete Algorithms (ACDA23), 2023.   \n[14] Yuval Filmus and Justin Ward. A tight combinatorial algorithm for submodular maximization subject to a matroid constraint. In 2012 IEEE 53rd Annual Symposium on Foundations of Computer Science, pages 659\u2013668, 2012.   \n[15] Abraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms, pages 385\u2013394, 2005.   \n[16] Dan Garber and Ben Kretzu. Improved regret bounds for projection-free bandit convex optimization. In Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics, pages 2196\u20132206. PMLR, 2020.   \n[17] Dan Garber and Ben Kretzu. New projection-free algorithms for online convex optimization with adaptive regret guarantees. In Proceedings of Thirty Fifth Conference on Learning Theory, pages 2326\u20132359. PMLR, 2022.   \n[18] Shuyang Gu, Chuangen Gao, Jun Huang, and Weili Wu. Profit maximization in social networks and non-monotone DR-submodular maximization. Theoretical Computer Science, 957:113847, 2023.   \n[19] Hamed Hassani, Amin Karbasi, Aryan Mokhtari, and Zebang Shen. Stochastic conditional gradient++: (non)convex minimization and continuous submodular maximization. SIAM Journal on Optimization, 30(4):3315\u20133344, 2020.   \n[20] Hamed Hassani, Mahdi Soltanolkotabi, and Amin Karbasi. Gradient methods for submodular maximization. In Advances in Neural Information Processing Systems, 2017.   \n[21] Elad Hazan and Satyen Kale. Projection-free online learning. In Proceedings of the 29th International Coference on International Conference on Machine Learning, ICML\u201912, pages 1843\u20131850. Omnipress, 2012.   \n[22] Elad Hazan and Edgar Minasyan. Faster projection-free online learning. In Proceedings of Thirty Third Conference on Learning Theory, pages 1877\u20131893. PMLR, 2020.   \n[23] Elad Hazan and C. Seshadhri. Efficient learning algorithms for changing environments. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML $^{\\circ9}$ , pages 393\u2013400. Association for Computing Machinery, 2009.   \n[24] Shinji Ito and Ryohei Fujimaki. Large-scale price optimization via network flow. Advances in Neural Information Processing Systems, 2016.   \n[25] Duksang Lee, Nam Ho-Nguyen, and Dabeen Lee. Non-smooth, h\\\u201dolder-smooth, and robust submodular maximization. arXiv preprint arXiv:2210.06061, 2023.   \n[26] Yuanyuan Li, Yuezhou Liu, Lili Su, Edmund Yeh, and Stratis Ioannidis. Experimental design networks: A paradigm for serving heterogeneous learners under networking constraints. IEEE/ACM Transactions on Networking, 2023.   \n[27] Yucheng Liao, Yuanyu Wan, Chang Yao, and Mingli Song. Improved Projection-free Online Continuous Submodular Maximization. arXiv preprint arXiv:2305.18442, May 2023.   \n[28] Zhou Lu, Nataly Brukhim, Paula Gradu, and Elad Hazan. Projection-free adaptive regret with membership oracles. In Proceedings of The 34th International Conference on Algorithmic Learning Theory, pages 1055\u20131073. PMLR, 2023.   \n[29] Zakaria Mhammedi. Efficient projection-free online convex optimization with membership oracle. In Proceedings of Thirty Fifth Conference on Learning Theory, pages 5314\u20135390. PMLR, 2022.   \n[30] Siddharth Mitra, Moran Feldman, and Amin Karbasi. Submodular+ concave. Advances in Neural Information Processing Systems, 2021.   \n[31] Aryan Mokhtari, Hamed Hassani, and Amin Karbasi. Stochastic conditional gradient methods: From convex minimization to submodular maximization. The Journal of Machine Learning Research, 21(1):4232\u20134280, 2020.   \n[32] Loay Mualem and Moran Feldman. Resolving the approximability of offline and online nonmonotone DR-submodular maximization over general convex sets. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, April 2023.   \n[33] Rad Niazadeh, Negin Golrezaei, Joshua Wang, Fransisca Susan, and Ashwinkumar Badanidiyuru. Online learning via offline greedy algorithms: Applications in market design and optimization. Management Science, 69(7):3797\u20133817, July 2023.   \n[34] Mohammad Pedramfar and Vaneet Aggarwal. A unified framework for analyzing metaalgorithms in online convex optimization. arXiv preprint arXiv:2402.08621, 2024.   \n[35] Mohammad Pedramfar, Yididiya Y. Nadew, Christopher John Quinn, and Vaneet Aggarwal. Unified projection-free algorithms for adversarial DR-submodular optimization. In The Twelfth International Conference on Learning Representations, 2024.   \n[36] Mohammad Pedramfar, Christopher Quinn, and Vaneet Aggarwal. A unified approach for maximizing continuous $\\gamma$ -weakly DR-submodular functions. optimization-online preprint optimization-online:25915, 2024.   \n[37] Mohammad Pedramfar, Christopher John Quinn, and Vaneet Aggarwal. A unified approach for maximizing continuous DR-submodular functions. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[38] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends\u00ae in Machine Learning, 4(2):107\u2013194, 2012.   \n[39] Zongqi Wan, Jialin Zhang, Wei Chen, Xiaoming Sun, and Zhijie Zhang. Bandit multi-linear dr-submodular maximization and its applications on adversarial submodular bandits. In International Conference on Machine Learning, 2023.   \n[40] Yibo Wang, Wenhao Yang, Wei Jiang, Shiyin Lu, Bing Wang, Haihong Tang, Yuanyu Wan, and Lijun Zhang. Non-stationary projection-free online learning with dynamic and adaptive regret guarantees. Proceedings of the AAAI Conference on Artificial Intelligence, 38(14):15671\u2013 15679, 2024.   \n[41] Bryan Wilder. Equilibrium computation and robust optimization in zero sum games with submodular structure. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32, 2018.   \n[42] Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian. Efficient projection-free online methods with stochastic recursive gradient. Proceedings of the AAAI Conference on Artificial Intelligence, 34(4):6446\u20136453, 2020.   \n[43] Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments. In Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[44] Lijun Zhang, Tianbao Yang, jin, and Zhi-Hua Zhou. Dynamic regret of strongly adaptive methods. In Proceedings of the 35th International Conference on Machine Learning, pages 5882\u20135891. PMLR, 2018.   \n[45] Mingrui Zhang, Lin Chen, Hamed Hassani, and Amin Karbasi. Online continuous submodular maximization: From full-information to bandit feedback. In Advances in Neural Information Processing Systems, volume 32, 2019.   \n[46] Qixin Zhang, Zengde Deng, Zaiyi Chen, Haoyuan Hu, and Yu Yang. Stochastic continuous submodular maximization: Boosting via non-oblivious function. In Proceedings of the 39th International Conference on Machine Learning, 2022.   \n[47] Qixin Zhang, Zengde Deng, Zaiyi Chen, Kuangqi Zhou, Haoyuan Hu, and Yu Yang. Online learning for non-monotone DR-submodular maximization: From full information to bandit feedback. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, April 2023.   \n[48] Qixin Zhang, Zongqi Wan, Zengde Deng, Zaiyi Chen, Xiaoming Sun, Jialin Zhang, and Yu Yang. Boosting gradient ascent for continuous DR-submodular maximization. arXiv preprint arXiv:2401.08330, 2024.   \n[49] Peng Zhao, Guanghui Wang, Lijun Zhang, and Zhi-Hua Zhou. Bandit convex optimization in non-stationary environments. Journal of Machine Learning Research, 22(125):1\u201345, 2021.   \n[50] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Dynamic regret of convex and smooth functions. In Advances in Neural Information Processing Systems, volume 33, pages 12510\u201312520, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "[51] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th international conference on machine learning (icml-03), pages 928\u2013 936, 2003. ", "page_idx": 13}, {"type": "text", "text": "A Related works ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "DR-submodular maximization Two of the main methods for continuous DR-submodular maximization are Frank-Wolfe type methods and Boosting based methods. This division is based on how the approximation coefficient appears in the proof. ", "page_idx": 14}, {"type": "text", "text": "In Frank-Wolfe type algorithms, the approximation coefficient appears by specific choices of the Frank-Wolfe update rules. (See Lemma 8 in [35]) The specific choices of the update rules for different settings have been proposed in [3, 2, 32, 37, 10]. The momentum technique of [31] has been used to convert algorithms designed for deterministic feedback to stochastic feedback setting. [19] proposed a Frank-Wolfe variant with access to a stochastic gradient oracle with known distribution. Frank-Wolfe type algorithms been adapted to the online setting using Meta-Frank-Wolfe [8, 9] or using Blackwell approachablity [33]. Later [45] used a Meta-Frank-Wolfe with random permutation technique to obtain full-information results that only require a single query per function and also bandit results. This was extended to another settings by [47] and generalized to many different settings with improved regret bounds by [35]. ", "page_idx": 14}, {"type": "text", "text": "Another approach, referred to as boosting, is to construct an alternative function such that maximization of this function results in approximate maximization of the original function. Given this definition, we may consider the result of [20, 8, 13] as the first boosting based results. However, in these cases (i.e., the case of monotone DR-submodular functions over general convex sets), the alternative function is identical to the original function. The term boosting in this context was first used in [46] for monotone functions over convex sets containing the origin, based on ideas presented in [14, 30]. This idea was used later in [39, 27] in bandit and projection-free full-information settings. Finally, in [48] a boosting based method was introduced for non-monotone functions over general convex sets. ", "page_idx": 14}, {"type": "text", "text": "Up-concave maximization Not all continuous DR-submodular functions are concave and not all concave functions are continuous DR-submodular. [30] considers functions that are the sum of a concave and a continuous DR-submodular function. It is well-known that continuous DRsubmodular functions are concave along positive directions [5, 3]. Based on this idea, [41] defined an up-concave function as a function that is concave along positive directions. Up-concave maximization has been considered in the offline setting before, e.g. [25], but not in online setting. In this work, we focus on up-concave maximization which is a generalization of DR-submodular maximization. ", "page_idx": 14}, {"type": "text", "text": "Projection-free optimization In the past decade, numerous projection-free online convex optimization algorithms have emerged to tackle the computational limitations of their projection-based counterparts [21, 7, 42, 9, 22, 16, 29, 17]. In the context of DR-submodular maximization, the Frank-Wolfe type methods discussed above are projection-free. ", "page_idx": 14}, {"type": "text", "text": "Non-stationary regret Dynamic regret was first analyzed in [51] for first order deterministic feedback. Later [43] obtained the lower bound and optimal algorithm in this setting. This was later expanded to bandit setting in [49]. Adaptive regret was first analyzed in [23] and the first optimal algorithm for projection-free adaptive regret was proposed in [17]. We refer to [23, 1, 11, 44, 43, 50, 49, 28, 40, 17] and references therein for more details. ", "page_idx": 14}, {"type": "text", "text": "Optimization by quadratization The framework discussed here for analyzing online algorithms is based on the convex optimization framework introduced in [34]. We extend the framework to allows us to work with $\\alpha$ -regret.Moreover, [34] also demonstrates that algorithms that are designed for quadratic/linear optimization with fully adaptive adversary obtain a similar regret in the convex setting. In this paper we introduce the notion of quadratizable functions generalizes this idea beyond convex functions to all quadratizable functions. (see Theorem 1) This allows us to integrate the boosting method with our framework to obtain various meta-algorithms for continuous DR-submodular maximization. ", "page_idx": 14}, {"type": "text", "text": "B Problem Setup in Detail ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we further expand on the description in Section 2. ", "page_idx": 14}, {"type": "text", "text": "A function class is a set of real-valued functions. Given a set $\\mathcal{D}$ , a function class over $\\mathcal{D}$ is a subset of all real-valued functions on $\\mathcal{D}$ . A set $\\boldsymbol{\\kappa}\\subseteq\\mathbb{R}^{d}$ is called a convex set if for all $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{K}}$ and $\\alpha~\\in~[0,1]$ , we have $\\alpha\\mathbf{x}+(1\\mathrm{~-~}\\alpha)\\mathbf{y}\\;\\in\\;K$ . For any $\\textbf{u}\\in\\;\\kappa^{T}$ , we define the path length $\\begin{array}{r}{P_{T}(\\mathbf u):=\\sum_{i=1}^{T-1}\\|\\mathbf u_{i}-\\mathbf u_{i+1}\\|}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "A real-valued differentiable function $f$ is called concave if $f(y)\\,-\\,f(x)\\,\\leq\\,f^{\\prime}(x)(y\\,-\\,x)$ , for all $x,y\\in\\operatorname{Dom}(f)$ . More generally, given $\\mu\\geq0$ and $0<\\gamma\\leq1$ , we say a real-valued differentiable function is $\\mu$ -strongly $\\gamma$ -weakly concave if ", "page_idx": 15}, {"type": "equation", "text": "$$\nf(y)-f(x)\\leq{\\frac{1}{\\gamma}}\\left(f(x)^{\\prime}(y-x)-{\\frac{\\mu}{2}}|y-x|^{2}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for all $x,y\\in\\operatorname{Dom}(f)$ . ", "page_idx": 15}, {"type": "text", "text": "We say a differentiable function $f:K\\to\\mathbb{R}$ is $\\mu$ -strongly $\\gamma$ -weakly up-concave if it is $\\mu$ -strongly $\\gamma$ -weakly concave along positive directions. Specifically if, for all $\\mathbf x\\leq\\mathbf y$ in $\\kappa$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\gamma\\left(\\langle\\nabla f(\\mathbf{y}),\\mathbf{y}-\\mathbf{x}\\rangle+{\\frac{\\mu}{2}}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right)\\leq f(\\mathbf{y})-f(\\mathbf{x})\\leq{\\frac{1}{\\gamma}}\\left(\\langle\\nabla f(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-{\\frac{\\mu}{2}}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This notion could be generalized in the following manner. We say $\\tilde{\\nabla}f:\\boldsymbol{\\mathcal{K}}\\to\\mathbb{R}^{d}$ is a $\\mu$ -strongly $\\gamma$ -weakly up-super-gradient of $f$ if for all $\\mathbf x\\leq\\mathbf y$ in $\\kappa$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\gamma\\left(\\langle\\tilde{\\nabla}f(\\mathbf{y}),\\mathbf{y}-\\mathbf{x}\\rangle+\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right)\\leq f(\\mathbf{y})-f(\\mathbf{x})\\leq\\frac{1}{\\gamma}\\left(\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}\\|^{2}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we say $f$ is $\\mu$ -strongly $\\gamma$ -weakly up-concave if it is continuous and it has a $\\mu$ -strongly $\\gamma$ -weakly up-super-gradient. When it is clear from the context, we simply refer to ${\\tilde{\\nabla}}f$ as an up-super-gradient for $f$ . When $\\gamma=1$ and the above inequality holds for all $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{K}}$ , we say $f$ is $\\mu$ -strongly concave. A differentiable function $f:\\,K\\,\\rightarrow\\,\\mathbb{R}$ is called continuous $D R$ -submodular if for all $\\textbf{x}\\leq\\textbf{y}$ , we have $\\nabla f(\\mathbf{x})\\,\\geq\\,\\nabla f(\\mathbf{y})$ . More generally, we say $f$ is $\\gamma$ -weakly continuous $D R$ -submodular if for all $\\mathbf x\\leq\\mathbf y$ , we have $\\nabla f(\\mathbf{x})\\ge\\gamma\\nabla f(\\mathbf{y})$ . It follows that any $\\gamma$ -weakly continuous DR-submodular functions is $\\gamma$ -weakly up-concave. ", "page_idx": 15}, {"type": "text", "text": "Given a continuous monotone function $f:K\\to\\mathbb{R}$ , its curvature is defined as the smallest number $c\\in[0,1]$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\nf(\\mathbf{y}+\\mathbf{z})-f(\\mathbf{y})\\geq(1-c)(f(\\mathbf{x}+\\mathbf{z})-f(\\mathbf{x})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for all $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{K}}$ and $\\mathbf{z}\\geq0$ such that ${\\mathbf{x}}+{\\mathbf{z}},{\\mathbf{y}}+{\\mathbf{z}}\\in K$ . 4 We define the curvature of a function class $\\mathbf{F}$ as the supremum of the curvature of functions in $\\mathbf{F}$ . ", "page_idx": 15}, {"type": "text", "text": "Online optimization problems can be formalized as a repeated game between an agent and an adversary. The game lasts for $T$ rounds on a convex domain $\\kappa$ where $T$ and $\\kappa$ are known to both players. In $t$ -th round, the agent chooses an action $\\mathbf{x}_{t}$ from an action set $\\kappa\\subseteq\\mathbb{R}^{d}$ , then the adversary chooses a loss function $f_{t}\\,\\in\\,\\mathbf{F}$ and a query oracle for the function $f_{t}$ . Then, for $1\\,\\leq\\,i\\,\\leq\\,k_{t}$ , the agent chooses a points $\\mathbf{y}_{t,i}$ and receives the output of the query oracle. Here $k_{t}$ denotes the total number of queries made by the agent at time-step $t$ , which may or may not be known in advance. ", "page_idx": 15}, {"type": "text", "text": "To be more precise, an agent consists of a tuple $(\\Omega^{A},{\\mathcal{A}}^{\\mathrm{action}},{\\mathcal{A}}^{\\mathrm{query}})$ , where $\\Omega^{A}$ is a probability space that captures all the randomness of $\\boldsymbol{\\mathcal{A}}$ . We assume that, before the first action, the agent samples $\\omega\\,\\in\\,\\Omega$ . The next element in the tuple, $\\mathcal{A}^{\\mathrm{action}}\\,=\\,\\left(\\mathcal{A}_{1}^{\\mathrm{action}},\\cdot\\cdot\\cdot\\,,\\mathcal{A}_{T}^{\\mathrm{action}}\\right)$ is a sequence of functions such that $A_{t}$ that maps the history $\\Omega^{A}\\times\\textstyle K^{t-1}\\times\\prod_{s=1}^{t-1}(K\\times{\\mathcal{O}})^{k_{s}}$ to $\\mathbf{x}_{t}\\,\\in\\,\\mathcal{K}$ where we use $\\scriptscriptstyle\\mathcal{O}$ to denote range of the query oracle. The last element  in the tuple, $A^{\\mathrm{query}}$ , is the query policy. For each $1\\leq t\\leq T$ and $1\\,\\leq\\,i\\,\\leq\\,k_{t}$ $\\begin{array}{r}{\\leq k_{t},\\,A_{t,i}^{\\mathrm{query}}:\\Omega^{A}\\times\\mathcal{K}^{t}\\times\\prod_{s=1}^{t-1}(\\stackrel{\\cdot}{\\mathcal{K}}\\times\\mathcal{O})^{k_{s}}\\times(\\mathcal{K}\\stackrel{\\cdot}{\\times}\\mathcal{O})^{i-1}}\\end{array}$ is a function that, given previous actions and observations, either selects a point $\\mathbf{y}_{t}^{i}\\in\\mathcal{K}$ , i.e., query, or signals that the query policy at this time-step is terminated. We may drop $\\omega$ as one of the inputs of the above functions when there is no ambiguity. We say the agent query function is trivial if ", "page_idx": 15}, {"type": "equation", "text": "$$\nc=1-\\operatorname*{inf}_{\\substack{{\\bf x},{\\bf y}\\in\\mathcal{K},1\\leq i\\leq d}}\\frac{[\\nabla f({\\bf y})]_{i}}{[\\nabla f({\\bf x})]_{i}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$k_{t}=1$ and $\\mathbf{y}_{t,1}=\\mathbf{x}_{t}$ for all $1\\leq t\\leq T$ . In this case, we simplify the notation and use the notation $\\pmb{\\mathcal{A}}=\\pmb{\\mathcal{A}}^{\\mathrm{action}}=(\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{T})$ to denote the agent action functions and assume that the domain of $A_{t}$ is $\\Omega^{A}\\times(K\\stackrel{\\cdot}{\\times}\\mathcal{O})^{t-1}$ . ", "page_idx": 16}, {"type": "text", "text": "A query oracle is a function that provides the observation to the agent. Formally, a query oracle for a function $f$ is a map $\\mathcal{Q}$ defined on $\\kappa$ such that for each $\\mathbf{x}\\in K$ , the $\\mathcal{Q}(\\mathbf{x})$ is a random variable taking value in the observation space $\\scriptscriptstyle\\mathcal{O}$ . The query oracle is called a stochastic value oracle or stochastic zeroth order oracle if $\\mathcal{O}=\\mathbb{R}$ and $f(\\mathbf{x})=\\mathbb{E}[\\mathcal{Q}(\\mathbf{x})]$ . Similarly, it is called a stochastic up-supergradient oracle or stochastic first order oracle if $\\mathcal{O}=\\mathbb{R}^{d}$ and $\\mathbb{E}[\\mathcal{Q}(\\mathbf{x})]$ is a up-super-gradient of $f$ at $\\mathbf{x}$ . In all cases, if the random variable takes a single value with probability one, we refer to it as a deterministic oracle. Note that, given a function, there is at most a single deterministic gradient oracle, but there may be many deterministic up-super-gradient oracles. We will use $\\nabla$ to denote the deterministic gradient oracle. We say an oracle is bounded by $B$ if its output is always within the Euclidean ball of radius $B$ centered at the origin. We say the agent takes semi-bandit feedback if the oracle is first-order and the agent query function is trivial. Similarly, it takes bandit feedback if the oracle is zeroth-order and the agent query function is trivial. 5 If the agent query function is non-trivial, then we say the agent requires full-information feedback. ", "page_idx": 16}, {"type": "text", "text": "An adversary Adv is a set such that each element $\\boldsymbol{B}\\in$ Adv, referred to as a realized adversary, is a sequence $(\\boldsymbol{B}_{1},\\cdot\\cdot\\cdot\\,,\\boldsymbol{B}_{T})$ of functions where each $B_{t}$ maps a tuple $\\left(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}\\right)\\in\\mathcal{K}^{t}$ to a tuple $(f_{t},\\mathcal{Q}_{t})$ where $f_{t}\\,\\in\\,\\mathbf{F}$ and $\\mathcal{Q}_{t}$ is a query oracle for $f_{t}$ . We say an adversary Adv is oblivious if for any realization $\\boldsymbol{B}\\,=\\,(\\beta_{1},\\cdot\\cdot\\cdot\\,,\\beta_{T})$ , all functions $B_{t}$ are constant, i.e., they are independent of $\\left(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}\\right)$ . In this case, a realized adversary may be simply represented by a sequence of functions $(f_{1},\\cdot\\cdot\\cdot\\,,f_{T})\\in\\mathbf{F}^{T}$ and a sequence of query oracles $\\left(\\boldsymbol{\\mathcal{Q}}_{1},\\cdot\\cdot\\cdot\\,,\\boldsymbol{\\mathcal{Q}}_{T}\\right)$ for these functions. We say an adversary is a weakly adaptive adversary if each function $B_{t}$ described above does not depend on $\\mathbf{x}_{t}$ and therefore may be represented as a map defined on $\\kappa^{t-1}$ . In this work we also consider adversaries that are fully adaptive, i.e., adversaries with no restriction. Clearly any oblivious adversary is a weakly adaptive adversary and any weakly adaptive adversary is a fully adaptive adversary. Given a function class $\\mathbf{F}$ and $i\\in\\{0,1\\}$ , we use $\\operatorname{Adv}_{i}^{\\mathrm{f}}(\\mathbf{F})$ to denote the set of all possible realized adversaries with deterministic $i$ -th order oracles. If the oracle is instead stochastic and bounded by $B$ , we use $\\operatorname{Adv}_{i}^{\\mathrm{f}}(\\mathbf{F},B)$ to denote such an adversary. Finally, we use $\\operatorname{Adv}_{i}^{0}(\\mathbf{F})$ and $\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)$ to denote all oblivious realized adversaries with $i$ -th order deterministic and stochastic oracles, respectively. ", "page_idx": 16}, {"type": "text", "text": "In order to handle different notions of regret with the same approach, for an agent $\\boldsymbol{\\mathcal{A}}$ , adversary Adv, compact set $\\mathcal{U}\\subseteq\\mathcal{K}^{T}$ , approximation coefficient $0<\\alpha\\le1$ and $1\\leq a\\leq b\\leq T$ , we define regret as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(\\mathcal{U})[a,b]:=\\operatorname*{sup}_{B\\in\\mathrm{Adv}}\\mathbb{E}\\left[\\alpha\\operatorname*{max}_{\\mathbf{u}=(\\mathbf{u}_{1},\\cdots,\\mathbf{u}_{T})\\in\\mathcal{U}}\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the expectation in the definition of the regret is over the randomness of the algorithm and the query oracle. We use the notation $\\mathcal{R}_{\\alpha,\\boldsymbol{B}}^{A}(\\mathcal{U})\\breve{[}a,b]\\,:=\\,\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(\\mathcal{U})[a,b]$ R\u03b1A,Adv(U)[a, b] when Adv = {B} is a singleton. We may drop $\\alpha$ when it is equal to 1. When $\\alpha<1$ , we often assume that the functions are non-negative. ", "page_idx": 16}, {"type": "text", "text": "Static adversarial regret or simply adversarial regret corresponds to $a=1$ , $b=T$ and $\\mathcal{U}=\\kappa_{\\star}^{T}:=$ $\\{(\\mathbf{x},\\cdot\\cdot\\cdot,\\mathbf{x})\\mid\\mathbf{x}\\in\\bar{\\mathcal{K}}\\}$ . When $a=1$ , $b=T$ and $\\boldsymbol{\\mathcal{U}}$ contains only a single element then it is referred to as the dynamic regret [51, 43]. Adaptive regret, is defined as $\\begin{array}{r}{\\operatorname*{max}_{1\\le a\\le b\\le T}\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(K_{\\star}^{T})[a,b]}\\end{array}$ [23]. We drop $a,\\,b$ and $\\boldsymbol{\\mathcal{U}}$ when the statement is independent of their value or their value is clear from the context. ", "page_idx": 16}, {"type": "text", "text": "C Proof of Theorem 1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The proof is similar to the proof of Theorems 2 and 5 in [34]. ", "page_idx": 16}, {"type": "text", "text": "Proof. ", "page_idx": 16}, {"type": "text", "text": "Deterministic oracle: ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We first consider the case where $\\mathcal{G}$ is a deterministic query oracle for $\\mathfrak{g}$ . Let $\\mathbf{o}_{t}=\\mathfrak{g}(f_{t},\\mathbf{x}_{t})$ denote the output of $\\mathcal{G}$ at time-step $t$ . For any realization $\\mathcal{B}\\,=\\,(\\mathcal{B}_{1},\\cdot\\cdot\\cdot\\,,\\mathcal{B}_{T})\\,\\in\\,\\mathrm{Adv}_{1}^{\\mathrm{f}}(\\mathbf{F})$ , we define $B_{t}^{\\prime}({\\bf x}_{1},\\bar{\\cdot}\\cdot\\cdot{\\bf\\Omega},{\\bf x}_{t})$ to be the tuple $(q_{t},\\nabla)$ where ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\mathcal{B}}_{t}^{\\prime}(\\mathbf{x}_{1},\\cdot\\cdot\\cdot{\\mathbf{\\nabla}},\\mathbf{x}_{t}):=q_{t}:=\\mathbf{y}\\mapsto\\langle\\mathbf{o}_{t},\\mathbf{y}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}_{t}\\|^{2},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and $B^{\\prime}=(B_{1}^{\\prime},\\cdot\\cdot\\cdot,B_{T}^{\\prime})$ . Note that each $B_{t}^{\\prime}$ is a deterministic function of $\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}$ and therefore $B^{\\prime}\\in\\operatorname{Adv}_{1}^{\\mathrm{f}}\\big(\\mathbf{F}_{\\mu,\\mathfrak{g}}\\big)$ . Since the algorithm uses semi-bandit feedback, the sequence of random vectors $\\left(\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T}\\right)$ chosen by $\\boldsymbol{\\mathcal{A}}$ is identical between the game with $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and $\\boldsymbol{{\\beta^{\\prime}}}$ . Therefore, according to definition of quadratizable functions, for any $\\mathbf{y}\\in{\\mathcal{K}}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\beta\\left(q_{t}(\\mathbf{y})-q_{t}(\\mathbf{x}_{t})\\right)=\\beta\\left(\\langle\\mathbf{o}_{t},\\mathbf{y}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}_{t}\\|^{2}\\right)\\geq\\alpha f_{t}(\\mathbf{y})-f_{t}(h(\\mathbf{x}_{t})),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\left(\\alpha\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(h(\\mathbf{x}_{t}))\\right)\\leq\\beta\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\left(\\sum_{t=a}^{b}q_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}q_{t}(\\mathbf{x}_{t})\\right),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{\\ell}(\\mathbf{F})}^{\\mathcal{A}^{\\prime}}=\\underset{B\\in\\mathrm{Adv}_{1}^{\\ell}(\\mathbf{F})}{\\operatorname*{sup}}\\,\\mathcal{R}_{\\alpha,\\mathrm{A}^{\\ell}}^{\\mathcal{A}^{\\prime}}}\\\\ &{\\qquad\\qquad=\\underset{B\\in\\mathrm{Adv}_{1}^{\\ell}(\\mathbf{F})}{\\operatorname*{sup}}\\,\\mathbb{E}\\left[\\underset{\\operatorname*{max}}{\\operatorname*{max}}\\left(\\alpha\\underset{t=a}{\\overset{b}{\\sum}}f_{t}(\\mathbf{u}_{t})-\\underset{t=a}{\\overset{b}{\\sum}}f_{t}(h(\\mathbf{x}_{t}))\\right)\\right]}\\\\ &{\\qquad\\qquad\\leq\\underset{B\\in\\mathrm{Adv}_{1}^{\\ell}(\\mathbf{F})}{\\operatorname*{sup}}\\,\\mathbb{E}\\left[\\beta\\underset{\\mathbf{u}\\in\\mathrm{A}^{\\ell}}{\\operatorname*{max}}\\left(\\underset{t=a}{\\overset{b}{\\sum}}q_{t}(\\mathbf{u}_{t})-\\underset{t=a}{\\overset{b}{\\sum}}q_{t}(\\mathbf{x}_{t})\\right)\\right]}\\\\ &{\\qquad\\qquad\\leq\\beta\\underset{B^{\\ell}\\in\\mathrm{Adv}_{1}^{\\ell}(\\mathbf{F}_{\\ell},q_{t})}{\\operatorname*{sup}}\\,\\mathcal{R}_{1,B^{\\ell}}^{\\mathcal{A}}=\\beta\\mathcal{R}_{1,A\\mathrm{dv}_{1}^{\\ell}(\\mathbf{F}_{\\ell},q_{t})}^{\\mathcal{A}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Stochastic oracle: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Next we consider the case where $\\mathcal{G}$ is a stochastic query oracle for $\\mathfrak{g}$ . ", "page_idx": 17}, {"type": "text", "text": "Let $\\Omega^{\\mathcal{Q}}=\\Omega_{1}^{\\mathcal{Q}}\\times\\cdot\\cdot\\cdot\\times\\Omega_{T}^{\\mathcal{Q}}$ capture all sources of randomness in the query oracles of $\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\mathbf{F},B_{1})$ , i.e., for any choice of $\\theta\\ \\in\\ \\Omega^{\\mathcal{Q}}$ , the query oracle is deterministic. Hence for any $\\theta\\;\\in\\;\\Omega^{\\mathcal{Q}}$ and realized adversary $B\\,\\in\\,\\mathrm{Adv}_{1}^{\\mathrm{o}}(\\mathbf{F},B_{1})$ , we may consider $B_{\\theta}$ as an object similar to an adversary with a deterministic oracle. However, note that $B_{\\theta}$ does not satisfy the unbiasedness condition of the oracle, i.e., the returned value of the oracle is not necessarily the gradient of the function at that point. Recall that $B_{t}$ maps a tuple $\\left(\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}\\right)$ to a tuple of $f_{t}$ and a stochastic query oracle for $f_{t}$ . We will use $\\mathbb{E}_{\\Omega^{Q}}$ to denote the expectation with respect to the randomness of query oracle and $\\mathbb{E}_{\\Omega_{t}^{\\mathcal{Q}}}[\\cdot]:=\\mathbb{E}_{\\Omega^{\\mathcal{Q}}}[\\cdot|f_{t},\\mathbf{x}_{t}]$ to denote the expectation conditioned the action of the agent and the adversary. Similarly, let $\\mathbb{E}_{\\Omega^{A}}$ denote the expectation with respect to the randomness of the agent. Let $\\mathbf{o}_{t}$ be the random variable denoting the output of $\\mathcal{G}$ at time-step $t$ and let ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{o}}_{t}:=\\mathbb{E}[\\mathbf{o}_{t}\\mid f_{t},\\mathbf{x}_{t}]=\\mathbb{E}_{\\Omega_{t}^{\\mathcal{Q}}}[\\mathbf{o}_{t}]=\\mathfrak{g}(f_{t},\\mathbf{x}_{t}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Similar to the deterministic case, for any realization $\\mathcal{B}=(f_{1},\\cdot\\cdot\\cdot\\,,f_{T})\\in\\mathrm{Adv}^{\\circ}(\\mathbf{F})$ and any $\\theta\\in\\Omega^{\\mathcal{Q}}$ , we define $B_{\\theta,t}^{\\prime}({\\bf x}_{1},\\cdot\\cdot\\cdot\\mathbf{\\Omega},{\\bf x}_{t})$ to be the pair $(q_{t},\\nabla)$ where ", "page_idx": 17}, {"type": "equation", "text": "$$\nq_{t}:=\\mathbf{y}\\mapsto\\langle\\mathbf{o}_{t},\\mathbf{y}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{y}-\\mathbf{x}_{t}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We also define $B_{\\theta}^{\\prime}:=(B_{\\theta,1}^{\\prime},\\cdot\\cdot\\cdot,B_{\\theta,T}^{\\prime})$ . Note that a specific choice of $\\theta$ is necessary to make sure that the function returned by $\\mathcal{B}_{\\theta,t}^{\\prime}$ is a deterministic function of $\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{t}$ and not a random variable and therefore $B_{\\theta}^{\\prime}$ belongs to $\\operatorname{Adv}_{1}^{\\mathrm{f}}(\\mathbf{Q}_{\\mu}[B_{1}])$ . ", "page_idx": 17}, {"type": "text", "text": "Since the algorithm uses (semi-)bandit feedback, given a specific value of $\\theta$ , the sequence of random vectors $(\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T})$ chosen by $\\boldsymbol{\\mathcal{A}}$ is identical between the game with $B_{\\theta}$ and $B_{\\theta}^{\\bar{\\prime}}$ . Therefore, for any $\\mathbf{u}_{t}\\in\\mathcal{K}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\alpha f_{t}(\\mathbf{u}_{t})-f_{t}(h(\\mathbf{x}_{t}))\\le\\beta\\left(\\langle\\overline{{\\mathbf{0}}}_{t},\\mathbf{u}_{t}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{u}_{t}-\\mathbf{x}_{t}\\|^{2}\\right)}&{}\\\\ {=\\beta\\left(\\langle\\mathbb{E}\\left[\\mathbf{0}_{t}\\mid f_{t},\\mathbf{x}_{t}\\right],\\mathbf{u}_{t}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{u}_{t}-\\mathbf{x}_{t}\\|^{2}\\right)}&{}\\\\ {=\\beta\\left(\\mathbb{E}\\left[\\langle\\mathbf{0}_{t},\\mathbf{u}_{t}-\\mathbf{x}_{t}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{u}_{t}-\\mathbf{x}_{t}\\|^{2}\\mid f_{t},\\mathbf{x}_{t}\\right]\\right)}&{}\\\\ {=\\beta\\left(\\mathbb{E}\\left[\\mathbf{q}_{t}(\\mathbf{u}_{t})-q_{t}(\\mathbf{x}_{t})\\mid f_{t},\\mathbf{x}_{t}\\right]\\right),}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the first inequality follows from the fact that $f_{t}$ is up-quadratizable and $\\bar{\\bf o}_{t}\\;=\\;{\\bf g}(f_{t},{\\bf x}_{t})$ . Therefore we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}{\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(h(\\mathbf{x}_{t}))\\right]\\le\\beta\\mathbb{E}\\left[\\displaystyle\\sum_{t=a}^{b}\\mathbb{E}\\left[q_{t}(\\mathbf{u}_{t})-q_{t}(\\mathbf{x}_{t})|f_{t},\\mathbf{x}_{t}\\right]\\right]}&{}\\\\ {=\\beta\\mathbb{E}\\left[\\displaystyle\\sum_{t=a}^{b}q_{t}(\\mathbf{u}_{t})-q_{t}(\\mathbf{x}_{t})\\right].}&{}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ is oblivious, the sequence $(f_{1},\\cdot\\cdot\\cdot,f_{T})$ is not affected by the randomness of query oracles or the agent. Therefore we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\alpha,B}^{A}=\\mathbb{E}\\left[\\displaystyle\\alpha\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\displaystyle\\sum_{t=0}^{b}f_{t}(\\mathbf{u}_{t})-\\displaystyle\\sum_{t=\\alpha}^{b}f_{t}(h(\\mathbf{x}_{t}))\\right]}\\\\ &{\\phantom{=}=\\displaystyle\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=\\alpha}^{b}f_{t}(\\mathbf{u}_{t})-\\displaystyle\\sum_{t=\\alpha}^{b}f_{t}(h(\\mathbf{x}_{t}))\\right]}\\\\ &{\\phantom{=}\\displaystyle\\mathcal{B}\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\mathbb{E}\\left[\\displaystyle\\sum_{t=\\alpha}^{b}q_{t}(\\mathbf{u}_{t})-\\displaystyle\\sum_{t=\\alpha}^{b}q_{t}(\\mathbf{x}_{t})\\right]}\\\\ &{\\phantom{=}\\displaystyle\\mathcal{B}\\mathbb{E}\\left[\\displaystyle\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}}\\left(\\sum_{t=\\alpha}^{b}q_{t}(\\mathbf{u}_{t})-\\displaystyle\\sum_{t=\\alpha}^{b}q_{t}(\\mathbf{x}_{t})\\right)\\right]=\\beta\\mathbb{E}\\left[\\mathcal{R}_{1,b_{s}^{\\prime}}^{A}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the second inequality follows from Jensen\u2019s inequality. Hence we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{0}(\\mathbf{F},B_{1})}^{\\mathcal{A}}=\\underset{\\mathcal{B}\\in\\mathrm{Adv}_{1}^{0}(\\mathbf{F},B_{1})}{\\operatorname*{sup}}\\mathcal{R}_{\\alpha,\\mathcal{B}}^{\\mathcal{A}}\\leq\\underset{\\mathcal{B}\\in\\mathrm{Adv}_{1}^{0}(\\mathbf{F},B_{1}),\\theta\\in\\Omega^{\\mathcal{Q}}}{\\operatorname*{sup}}\\beta\\mathcal{R}_{1,\\mathcal{B}_{\\theta}^{\\prime}}^{\\mathcal{A}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\underset{\\mathcal{B^{\\prime}}\\in\\mathrm{Adv}_{1}^{\\mathrm{f}}(\\mathbf{Q}_{\\mu}[B_{1}])}{\\operatorname*{sup}}\\beta\\mathcal{R}_{1,\\mathcal{B}^{\\prime}}^{\\mathcal{A}}=\\beta\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{\\mathrm{f}}(\\mathbf{Q}_{\\mu}[B_{1}])}^{\\mathcal{A}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "D Proof of Lemma 1 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. We have $\\mathbf{x}\\vee\\mathbf{y}+\\mathbf{x}\\wedge\\mathbf{y}=\\mathbf{x}+\\mathbf{y}$ . Therefore, following the definition of curvature, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\nf(\\mathbf{x}\\vee\\mathbf{y})-f(\\mathbf{y})\\geq(1-c)(f(\\mathbf{x})-f(\\mathbf{x}\\wedge\\mathbf{y})).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since $f$ is non-negative, this implies that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{(f(\\mathbf{x}\\vee\\mathbf{y})-f(\\mathbf{x}))+\\frac{1}{\\gamma^{2}}(f(\\mathbf{x}\\wedge\\mathbf{y})-f(\\mathbf{x}))}}\\\\ &{=(f(\\mathbf{y})-f(\\mathbf{x}))+(f(\\mathbf{x}\\vee\\mathbf{y})-f(\\mathbf{y}))+\\frac{1}{\\gamma^{2}}(f(\\mathbf{x}\\wedge\\mathbf{y})-f(\\mathbf{x}))}\\\\ &{\\ge(f(\\mathbf{y})-f(\\mathbf{x}))+(1-c-\\frac{1}{\\gamma^{2}})(f(\\mathbf{x})-f(\\mathbf{x}\\wedge\\mathbf{y}))}\\\\ &{=f(\\mathbf{y})-(c+\\frac{1}{\\gamma^{2}})f(\\mathbf{x})+(-1+c+\\frac{1}{\\gamma^{2}})f(\\mathbf{x}\\wedge\\mathbf{y})}\\\\ &{\\ge f(\\mathbf{y})-(c+\\frac{1}{\\gamma^{2}})f(\\mathbf{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "On the other hand, according to the definition, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f({\\mathbf x}\\vee{\\mathbf y})-f({\\mathbf x})\\le\\frac{1}{\\gamma}\\left(\\langle\\tilde{\\nabla}f({\\mathbf x}),{\\mathbf x}\\vee{\\mathbf y}-{\\mathbf x}\\rangle-\\frac{\\mu}{2}\\|{\\mathbf x}\\vee{\\mathbf y}-{\\mathbf x}\\|^{2}\\right),}\\\\ &{f({\\mathbf x})-f({\\mathbf x}\\wedge{\\mathbf y})\\ge\\gamma\\left(\\langle\\tilde{\\nabla}f({\\mathbf x}),{\\mathbf x}-{\\mathbf x}\\wedge{\\mathbf y}\\rangle+\\frac{\\mu}{2}\\|{\\mathbf x}-{\\mathbf x}\\wedge{\\mathbf y}\\|^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, using Inequality 5 and the fact that $f(\\mathbf{x}\\wedge\\mathbf{y})\\geq0$ , we see that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{\\tau}_{\\mathbf{\\tilde{y}}}\\displaystyle-\\frac{1+c\\gamma^{2}}{\\gamma^{2}}f(\\mathbf{x})\\leq\\left(f(\\mathbf{x}\\vee\\mathbf{y})-f(\\mathbf{x})\\right)+\\frac{1}{\\gamma^{2}}(f(\\mathbf{x}\\wedge\\mathbf{y})-f(\\mathbf{x}))}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{1}{\\gamma}\\left(\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{x}\\vee\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{x}\\vee\\mathbf{y}-\\mathbf{x}\\|^{2}+\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{x}\\wedge\\mathbf{y}-\\mathbf{x}\\rangle\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.-\\frac{\\mu}{2}\\|\\mathbf{x}-\\mathbf{x}\\wedge\\mathbf{y}\\|^{2}\\right)}\\\\ &{\\qquad\\qquad=\\frac{1}{\\gamma}\\left(\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{x}\\vee\\mathbf{y}+\\mathbf{x}\\wedge\\mathbf{y}-2\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{x}\\vee\\mathbf{y}-\\mathbf{x}\\|^{2}-\\frac{\\mu}{2}\\|\\mathbf{x}-\\mathbf{x}\\wedge\\mathbf{y}\\|^{2}\\right)}\\\\ &{\\qquad=\\frac{1}{\\gamma}\\left(\\langle\\tilde{\\nabla}f(\\mathbf{x}),\\mathbf{y}-\\mathbf{x}\\rangle-\\frac{\\mu}{2}\\|\\mathbf{x}-\\mathbf{y}\\|^{2}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where we used $\\mathbf{x}\\vee\\mathbf{y}+\\mathbf{x}\\wedge\\mathbf{y}=\\mathbf{x}+\\mathbf{y}$ and ", "page_idx": 19}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{\\|\\mathbf{x}\\vee\\mathbf{y}-\\mathbf{x}\\|^{2}+\\|\\mathbf{x}-\\mathbf{x}\\wedge\\mathbf{y}\\|^{2}=\\displaystyle\\sum_{[y]_{i}\\geq[x]_{i}}(y_{i}-x_{i})^{2}+\\displaystyle\\sum_{[y]_{i}<[x]_{i}}(x_{i}-y_{i})^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{i}(x_{i}-y_{i})^{2}=\\|\\mathbf{x}-\\mathbf{y}\\|^{2}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "in the last equality. The claim now follows from multiply both sides by $\\scriptstyle{\\frac{\\gamma^{2}}{1+c\\gamma^{2}}}$ . ", "page_idx": 19}, {"type": "text", "text": "E Proof of Lemma 2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. Clearly we have $F(\\mathbf{0})\\ =\\ 0$ . For any $\\textbf{x}\\neq\\textbf{0}$ , the integrand in the definition of $F$ is a continuous non-negative function of $z$ that is bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\gamma e^{\\gamma(z-1)}}{(1-e^{-\\gamma})z}(f(z*\\mathbf{x})-f(\\mathbf{0}))\\leq\\frac{\\gamma e^{\\gamma(z-1)}}{(1-e^{-\\gamma})z}M_{1}\\Vert z*\\mathbf{x}\\Vert\\leq\\frac{\\gamma}{1-e^{-\\gamma}}M_{1}\\Vert\\mathbf{x}\\Vert.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore $F$ is well-defined on $[0,1]^{d}$ . Moreover, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\int_{0}^{1}\\frac{\\gamma e^{\\gamma(z-1)}}{(1-e^{-\\gamma})}\\nabla f(z*\\mathbf{x})d z=\\nabla\\int_{0}^{1}\\frac{\\gamma e^{\\gamma(z-1)}}{(1-e^{-\\gamma})z}(f(z*\\mathbf{x})-f(\\mathbf{0}))d z=\\nabla F(\\mathbf{x}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "6Note that we do not require the gradient $\\nabla f$ to be defined everywhere for this equality to hold. It is sufficient for $\\nabla f$ to exist at Lebesgue almost every point on every line segment. This is satisfied when the 1-dimensional Hausdorff measure of the set $\\{\\mathbf{x}\\in[\\dot{0},\\dot{1}]^{d}\\mid\\nabla f$ is undefined $\\}$ is zero. ", "page_idx": 19}, {"type": "text", "text": "It follows that $F$ is differentiable everywhere and $\\mathbb{E}\\left[\\nabla f(\\mathcal{Z}*\\mathbf{x})\\right]\\;=\\;\\nabla F(\\mathbf{x})$ . To prove the last claim, first we note that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1-e^{-\\gamma}}{\\gamma}\\langle\\nabla F(\\mathbf{x}),\\mathbf{x}\\rangle=\\left\\langle\\displaystyle\\int_{0}^{1}e^{\\gamma(z-1)}\\nabla f(z*\\mathbf{x})d z,\\mathbf{x}\\right\\rangle}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\int_{0}^{1}e^{\\gamma(z-1)}\\langle\\nabla f(z*\\mathbf{x}),\\mathbf{x}\\rangle d z}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\int_{0}^{1}e^{\\gamma(z-1)}d f(z*\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=e^{\\gamma(z-1)}f(z*\\mathbf{x})\\displaystyle\\int_{z=0}^{1}-\\int_{0}^{1}f(z*\\mathbf{x})\\displaystyle\\frac{d e^{\\gamma(z-1)}}{d z}d z}\\\\ &{\\qquad\\qquad\\qquad=f(\\mathbf{x})-f(0)-\\displaystyle\\int_{0}^{1}\\gamma e^{\\gamma(z-1)}f(z*\\mathbf{x})d z.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "On the other hand, using monotonicity and up-concavity of $f$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1-e^{-\\gamma}}{\\gamma}\\langle\\nabla F(\\mathbf{x}),\\mathbf{y}\\rangle=\\displaystyle\\int_{0}^{1}e^{\\gamma(z-1)}\\langle\\nabla f(z*\\mathbf{x}),\\mathbf{y}\\rangle d z}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\int_{0}^{1}e^{\\gamma(z-1)}\\langle\\nabla f(z*\\mathbf{x}),\\mathbf{y}\\vee(z*\\mathbf{x})-z*\\mathbf{x}\\rangle d z}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\int_{0}^{1}\\gamma e^{\\gamma(z-1)}\\left(f(\\mathbf{y}\\vee(z*\\mathbf{x}))-f(z*\\mathbf{x})\\right)d z}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\int_{0}^{1}\\gamma e^{\\gamma(z-1)}\\left(f(\\mathbf{y})-f(z*\\mathbf{x})\\right)d z}\\\\ &{\\qquad\\qquad\\qquad\\qquad=(1-e^{-\\gamma})f(\\mathbf{y})-\\left(\\displaystyle\\int_{0}^{1}\\gamma e^{\\gamma(z-1)}f(z*\\mathbf{x})d z\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where we used $\\textstyle\\int_{0}^{1}e^{\\gamma(z-1)}\\gamma d z=1-e^{-\\gamma}$ in the last equality. Therefore ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{1-e^{-\\gamma}}{\\gamma}\\langle\\nabla F({\\mathbf x}),{\\mathbf y}-{\\mathbf x}\\rangle\\ge(1-e^{-\\gamma})f({\\mathbf y})-f({\\mathbf x})+f(\\mathbf{0})\\ge(1-e^{-\\gamma})f({\\mathbf y})-f({\\mathbf x}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "F Proof of Lemma 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We start by extending a useful lemma from the literature. Versions of the following lemma for DRsubmodular functions appeared in [2, 6, 32] and it was later extended to $\\gamma$ -weakly DR-submodular functions in [36]. Here we further extend it to $\\gamma$ -weakly up-concave functions. The proof is similar, but we include it for completeness. ", "page_idx": 20}, {"type": "text", "text": "Lemma 4. For any two vectors $\\mathbf{x},\\mathbf{y}\\,\\in\\,[0,1]^{d}$ and any continuously differentiable non-negative $\\gamma$ -weakly up-concave function $f$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nf(\\mathbf{x}\\vee\\mathbf{y})\\ge(1-\\gamma\\|\\mathbf{x}\\|_{\\infty})f(\\mathbf{y}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma 4. If $\\|\\mathbf{x}\\|_{\\infty}=0$ , then $\\mathbf{x}$ is the zero vector, and the lemma is trivially true. On the other hand, if $\\mathbf{x}\\vee\\mathbf{y}=\\mathbf{y}$ , the lemma follows from non-negativity of $f$ . Thus, we may assume that $\\mathbf z:=\\mathbf x\\vee\\mathbf y-\\mathbf y>\\mathbf0$ and $\\|\\mathbf{x}\\|_{\\infty}>0$ . We have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\mathbf x\\vee\\mathbf y)-f(\\mathbf y)=\\displaystyle\\int_{0}^{1}\\frac{d f(\\mathbf y+r\\cdot\\mathbf z)}{d r}\\bigg\\rvert_{r=t}\\,d t=\\displaystyle\\int_{0}^{1}\\langle\\mathbf z,\\nabla f(\\mathbf y+t\\cdot\\mathbf z)\\rangle d t}\\\\ &{\\qquad\\qquad=\\|\\mathbf x\\|_{\\infty}\\cdot\\displaystyle\\int_{0}^{1/\\|\\mathbf x\\|_{\\infty}}\\langle\\mathbf z,\\nabla f(\\mathbf y+\\|\\mathbf x\\|_{\\infty}\\cdot t^{\\prime}\\cdot\\mathbf z)\\rangle d t^{\\prime}}\\\\ &{\\qquad\\qquad\\geq\\|\\mathbf x\\|_{\\infty}\\cdot\\displaystyle\\int_{0}^{1/\\|\\mathbf x\\|_{\\infty}}\\langle\\mathbf z,\\gamma\\nabla f(\\mathbf y+t^{\\prime}\\cdot\\mathbf z)\\rangle d t^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where (6) holds by changing the integration variable to $t^{\\prime}=\\,t/\\|\\mathbf{x}\\|_{\\infty}$ , and the inequality follows from $\\gamma$ -weakly up-concavity of $f$ , in particular because $f$ is $\\gamma.$ -weakly concave along the line segment $[{\\bf y},{\\bf y}+\\dot{t}^{\\prime}.{\\bf z}]\\subseteq[0,1]^{d}$ . To see that the last inclusion holds, note that, for every $1\\leq i\\leq d$ , if $x_{i}\\leq y_{i}$ , then $y_{i}+t^{\\prime}\\cdot z_{i}=y_{i}\\leq1$ , and if $x_{i}\\geq y_{i}$ , then ", "page_idx": 21}, {"type": "equation", "text": "$$\ny_{i}+t^{\\prime}\\cdot z_{i}\\leq y_{i}+{\\frac{z_{i}}{\\|\\mathbf{x}\\|_{\\infty}}}=y_{i}+{\\frac{x_{i}-y_{i}}{\\|\\mathbf{x}\\|_{\\infty}}}\\leq{\\frac{x_{i}}{\\|\\mathbf{x}\\|_{\\infty}}}\\leq1.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Next we see that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\int_{0}^{1/\\|\\mathbf{x}\\|_{\\infty}}\\langle\\mathbf{z},\\gamma\\nabla f(\\mathbf{y}+t^{\\prime}\\cdot\\mathbf{z})\\rangle d t^{\\prime}=\\gamma\\int_{0}^{1/\\|\\mathbf{x}\\|_{\\infty}}\\langle\\mathbf{z},\\nabla f(\\mathbf{y}+t^{\\prime}\\cdot\\mathbf{z})\\rangle d t^{\\prime}}}\\\\ &{=\\gamma\\int_{0}^{1/\\|\\mathbf{x}\\|_{\\infty}}\\,\\frac{d f(\\mathbf{y}+r\\cdot\\mathbf{z})}{d r}\\bigg|_{r=t^{\\prime}}d t^{\\prime}}\\\\ &{=\\gamma f\\left(\\mathbf{y}+\\frac{\\mathbf{z}}{\\|\\mathbf{x}\\|_{\\infty}}\\right)-\\gamma f(\\mathbf{y})\\geq-\\gamma f(\\mathbf{y}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the inequality follows from non-negativity of $f$ . The lemma now follows by plugging this inequality into Inequality (6) and rearranging the terms. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Proof of Lemma 3. Clearly we have $F(\\underline{{\\mathbf{x}}})=0$ . For any $\\mathbf{x}\\neq\\underline{{\\mathbf{x}}}$ , the integrand in the definition of $F$ is a continuous function of $z$ that is bounded by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\frac{2}{3z(1-\\frac{z}{2})^{3}}\\left(f\\left(\\frac{z}{2}*(\\mathbf{x}-\\mathbf{x})+\\mathbf{x}\\right)-f(\\mathbf{x})\\right)\\Bigg|\\leq\\frac{2}{3z(1-\\frac{z}{2})^{3}}M_{1}\\|\\frac{z}{2}*(\\mathbf{x}-\\mathbf{x})\\|\\leq\\frac{8}{3}M_{1}\\|\\mathbf{x}-\\mathbf{x}\\|.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore $F$ is well-defined on $[0,1]^{d}$ . Moreover, we have 7 ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{0}^{1}\\frac{1}{3(1-\\frac{z}{2})^{3}}\\nabla f\\left(\\frac{z}{2}*(\\mathbf{x}-\\mathbf{x})+\\mathbf{x}\\right)d z=\\nabla\\int_{0}^{1}\\frac{2}{3z(1-\\frac{z}{2})^{3}}\\left(f\\left(\\frac{z}{2}*(\\mathbf{x}-\\mathbf{x})+\\mathbf{x}\\right)-f(\\mathbf{x})\\right)d z}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\nabla F(\\mathbf{x})}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "It follows that $F$ is differentiable everywhere and $\\begin{array}{r}{\\mathbb{E}\\left[\\nabla f\\left(\\frac{\\mathcal{Z}}{2}*\\left(\\mathbf{x}-\\underline{{\\mathbf{x}}}\\right)+\\underline{{\\mathbf{x}}}\\right)\\right]=\\nabla F(\\mathbf{x}).}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "To prove the last claim, let $\\begin{array}{r}{\\mathbf{x}_{z}:=\\frac{z}{2}\\ast(\\mathbf{x}-\\underline{{\\mathbf{x}}})+\\underline{{\\mathbf{x}}}}\\end{array}$ and $\\begin{array}{r}{\\omega(z)=\\frac{1}{8(1-\\frac{z}{2})^{3}}}\\end{array}$ . We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{3}{\\delta}\\langle\\nabla F(\\mathbf{x}),\\mathbf{y}\\rangle=\\displaystyle\\int_{0}^{1}\\omega(z)\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{y}\\rangle d z}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\int_{0}^{1}\\omega(z)\\left(\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{y}-\\mathbf{x}_{z}\\wedge\\mathbf{y}\\rangle+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\wedge\\mathbf{y}-\\mathbf{x}_{z}\\rangle+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\rangle\\right)d z}\\\\ &{\\quad\\quad\\quad\\quad=\\displaystyle\\int_{0}^{1}\\omega(z)\\left(\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\vee\\mathbf{y}-\\mathbf{x}_{z}\\rangle+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\wedge\\mathbf{y}-\\mathbf{x}_{z}\\rangle+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\rangle\\right)d z}\\\\ &{\\quad\\quad\\quad\\quad\\ge\\displaystyle\\int_{0}^{1}\\omega(z)\\left((f(\\mathbf{x}_{z}\\vee\\mathbf{y})-f(\\mathbf{x}_{z}))+(f(\\mathbf{x}_{z}\\wedge\\mathbf{y})-f(\\mathbf{x}_{z}))+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\rangle\\right)d z}\\\\ &{\\quad\\quad\\quad\\ge\\displaystyle\\int_{0}^{1}\\omega(z)\\left(f(\\mathbf{x}_{z}\\vee\\mathbf{y})-2f(\\mathbf{x}_{z})+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\rangle\\right)d z.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "7Similar to Lemma 2, we do not require the gradient $\\nabla f$ to be defined everywhere for this equality to hold. It is sufficient for $\\nabla f$ to exist at Lebesgue almost every point on every line segment. This is satisfied when the 1-dimensional Hausdorff measure of the set $\\{\\mathbf{x}\\in[0,\\dot{1}]^{d}\\mid\\nabla f$ is undefined $\\}$ is zero. ", "page_idx": 21}, {"type": "text", "text": "Using Lemma 4, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\mathbf{x}_{z}\\vee\\mathbf{y})\\geq(1-\\|\\mathbf{x}_{z}\\|_{\\infty})f(y)}\\\\ &{\\qquad\\qquad\\geq\\left(1-\\left(\\left(1-\\frac{z}{2}\\right)\\|\\mathbf{x}\\|_{\\infty}+\\frac{z}{2}\\|\\mathbf{x}\\|_{\\infty}\\right)\\right)f(y)}\\\\ &{\\qquad\\qquad\\geq\\left(1-\\left(\\left(1-\\frac{z}{2}\\right)\\|\\mathbf{x}\\|_{\\infty}+\\frac{z}{2}\\right)\\right)f(y)}\\\\ &{\\qquad\\qquad=\\left(1-\\frac{z}{2}\\right)\\left(1-\\|\\mathbf{x}\\|_{\\infty}\\right)f(y).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{3}{8}\\langle\\nabla F(\\mathbf{x}),\\mathbf{y}\\rangle\\ge\\int_{0}^{1}\\omega(z)\\left(\\left(1-\\frac{z}{2}\\right)\\left(1-\\left\\|\\mathbf{x}\\right\\|_{\\infty}\\right)f(y)-2f(\\mathbf{x}_{z})+\\langle\\nabla f(\\mathbf{x}_{z}),\\mathbf{x}_{z}\\rangle\\right)d z.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next we bound $\\langle\\nabla F(\\mathbf{x}),\\mathbf{x}\\rangle$ . We have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{3}{8}\\langle\\nabla F({\\mathbf x}),{\\mathbf x}\\rangle=\\int_{0}^{1}\\omega(z)\\langle\\nabla f({\\mathbf x}),{\\mathbf x}-{\\mathbf x}_{z}\\rangle d z+\\int_{0}^{1}\\omega(z)\\langle\\nabla f({\\mathbf x}),{\\mathbf x}_{z}\\rangle d z\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For the first term, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\int_{0}^{1}\\omega(z)\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}-\\mathbf{x}_{z}\\rangle d z=\\displaystyle\\int_{0}^{1}\\omega(z)\\left\\langle\\nabla f(\\mathbf{x}),\\left(1-\\frac{z}{2}\\right)(\\mathbf{x}-\\mathbf{x})\\right\\rangle d z}\\\\ &{\\displaystyle=\\int_{0}^{1}(2-z)\\omega(z)\\left\\langle\\nabla f(\\mathbf{x}),\\frac{\\mathbf{x}-\\mathbf{x}}{2}\\right\\rangle d z}\\\\ &{\\displaystyle=\\int_{0}^{1}(2-z)\\omega(z)d f(\\mathbf{x}_{z})}\\\\ &{\\displaystyle=(2-z)\\omega(z)f(\\mathbf{x}_{z})|_{z=0}^{1}-\\int_{0}^{1}((2-z)\\omega^{\\prime}(z)-\\omega(z))f(\\mathbf{x}_{z})d z}\\\\ &{\\displaystyle=f(\\mathbf{x}_{1})-\\frac{1}{4}f(\\mathbf{x})-\\int_{0}^{1}\\frac{1}{4(1-\\frac{z}{2})^{3}}f(\\mathbf{x}_{z})d z,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which implies that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{3}{8}\\langle\\nabla F(\\mathbf{x}),\\mathbf{x}\\rangle=f(\\mathbf{x}_{1})-\\displaystyle\\frac{1}{4}f(\\mathbf{x})-\\int_{0}^{1}\\frac{1}{4(1-\\frac{z}{2})^{3}}f(\\mathbf{x}_{z})d z+\\int_{0}^{1}\\omega(z)\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}_{z}\\rangle d z}\\\\ &{\\qquad\\qquad\\qquad\\leq f(\\mathbf{x}_{1})-\\displaystyle\\int_{0}^{1}2\\omega(z)f(\\mathbf{x}_{z})d z+\\int_{0}^{1}\\omega(z)\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}_{z}\\rangle d z}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Combining Equations 7 and 8, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{3}{8}\\langle\\nabla F({\\mathbf x}),{\\mathbf y}-{\\mathbf x}\\rangle\\ge\\int_{0}^{1}\\omega(z)\\left(\\left(1-\\frac{z}{2}\\right)\\left(1-\\|{\\mathbf x}\\|_{\\infty}\\right)f(y)-2f({\\mathbf x}_{z})+\\langle\\nabla f({\\mathbf x}_{z}),{\\mathbf x}_{z}\\rangle\\right)d z}\\\\ &{\\qquad\\qquad\\qquad-\\mathbf{\\Xi}f({\\mathbf x}_{1})+\\int_{0}^{1}2\\omega(z)f({\\mathbf x}_{z})d z-\\int_{0}^{1}\\omega(z)\\langle\\nabla f({\\mathbf x}),{\\mathbf x}_{z}\\rangle d z}\\\\ &{\\qquad\\qquad\\quad=\\frac{1-\\|{\\mathbf x}\\|_{\\infty}}{4}f({\\mathbf y})\\int_{0}^{1}4\\left(1-\\frac{z}{2}\\right)\\omega(z)d z-f({\\mathbf x}_{1})}\\\\ &{\\qquad\\qquad\\quad=\\frac{1-\\|{\\mathbf x}\\|_{\\infty}}{4}f({\\mathbf y})-f\\left(\\frac{{\\mathbf x}+\\mathbf x}{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "G Proof of Theorem 5 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The algorithms are special cases of Algorithms 2 and 3 in [34] where the shrinking parameter and the smoothing parameter are equal. We include a description of the algorithms for completion. ", "page_idx": 23}, {"type": "text", "text": "Algorithm 5: First order to zeroth order - FOTZO(A) ", "page_idx": 23}, {"type": "text", "text": "Input : Shrunk domain $\\hat{\\mathcal{{K}}}_{\\delta}$ , Linear space $\\mathcal{L}_{0}$ , smoothing parameter $\\delta\\leq r$ , horizon $T$ , algorithm A   \nPass $\\hat{\\mathcal{{K}}}_{\\delta}$ as the domain to $\\boldsymbol{\\mathcal{A}}$   \n$k\\gets\\mathrm{dim}(\\mathcal{L}_{0})$   \nfor $t=1,2,\\ldots,T$ do $\\mathbf{x}_{t}\\gets$ the action chosen by $\\boldsymbol{\\mathcal{A}}$ Play $\\mathbf{x}_{t}$ Let $f_{t}$ be the function chosen by the adversary for $i$ starting from $^{\\,l}$ , while $\\mathcal{A}^{q u e r y}$ is not terminated for this time-step do Sample $\\mathbf v_{t,i}\\in\\mathbb S^{1}\\cap\\mathcal L_{0}$ uniformly Let $\\mathbf{y}_{t,i}$ be the query chosen by $A^{\\mathrm{query}}$ Query the oracle at the point $\\mathbf{y}_{t,i}+\\delta\\mathbf{v}_{t,i}$ to get $o_{t,i}$ Pass $\\frac{k}{\\delta}o_{t}{\\bf v}_{t}$ as the oracle output to $\\boldsymbol{\\mathcal{A}}$ end   \nend ", "page_idx": 23}, {"type": "text", "text": "Algorithm 6: Semi-bandit to bandit - $\\mathtt{S T B}({\\mathcal{A}})$ ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Input : Shrunk domain $\\hat{\\mathcal{{K}}}_{\\delta}$ , Linear space $\\scriptstyle{\\mathcal{L}}_{0}$ , smoothing parameter $\\delta\\leq r$ , horizon $T$ , algorithm A   \nPass $\\hat{\\mathcal{{K}}}_{\\delta}$ as the domain to $\\boldsymbol{\\mathcal{A}}$   \n$k\\gets\\mathrm{dim}(\\mathcal{L}_{0})$   \nfor $t=1,2,\\ldots,T$ do Sample $\\mathbf v_{t}\\in\\mathbb S^{1}\\cap\\mathcal L_{0}$ uniformly $\\mathbf{x}_{t}\\gets$ the action chosen by $\\boldsymbol{\\mathcal{A}}$ Play $\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t}$ Let $f_{t}$ be the function chosen by the adversary Let $o_{t}$ be the output of the value oracle Pass $\\begin{array}{r}{\\frac{k}{\\delta}o_{t}\\mathbf v_{t}}\\end{array}$ as the oracle output to $\\boldsymbol{\\mathcal{A}}$   \nend ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Algorithm 7: First order to zeroth order with Two Point gradient estimator - FOTZO-2P(A) ", "page_idx": 23}, {"type": "text", "text": "Input : Shrunk domain $\\hat{\\mathcal{{K}}}_{\\delta}$ , Linear space $\\scriptstyle{\\mathcal{L}}_{0}$ , smoothing parameter $\\delta\\leq r$ , horizon $T$ , algorithm $\\mathcal{A}$   \nPass $\\hat{\\mathcal{{K}}}_{\\delta}$ as the domain to $\\boldsymbol{\\mathcal{A}}$   \n$k\\gets\\mathrm{dim}(\\mathcal{L}_{0})$   \nfor $t=1,2,\\ldots,T$ do $\\mathbf{x}_{t}\\gets$ the action chosen by $\\boldsymbol{\\mathcal{A}}$ Play $\\mathbf{x}_{t}$ Let $f_{t}$ be the function chosen by the adversary for $i$ starting from $^{\\,l}$ , while $\\mathcal{A}^{q u e r y}$ is not terminated for this time-step do Sample $\\mathbf v_{t,i}\\in\\mathbb S^{1}\\cap\\mathcal L_{0}$ uniformly Let $\\mathbf{y}_{t,i}$ be the query chosen by $A^{\\mathrm{query}}$ Query the deterministic oracle at the points $\\mathbf{y}_{t,i}+\\delta\\mathbf{v}_{t,i}$ and $\\mathbf{y}_{t,i}+\\delta\\mathbf{v}_{t,i}$ Pass $\\frac{k}{2\\delta}$ $\\mathbf{\\Pi}_{\\left\\{\\right.}}\\left(f_{t}(\\mathbf{y}_{t,i}+\\delta\\mathbf{v}_{t,i})-f_{t}(\\mathbf{y}_{t,i}-\\delta\\mathbf{v}_{t,i})\\right)\\mathbf{v}_{t}$ as the oracle output to $\\boldsymbol{\\mathcal{A}}$ end   \nend ", "page_idx": 23}, {"type": "text", "text": "The proof of Theorems 5 and 6 are similar to the proof of Theorems 6, 7 and 8 in [34]. The only difference being that we prove the result for $\\alpha$ -regret instead of regret. We include a proof for completion. ", "page_idx": 23}, {"type": "text", "text": "Proof of Theorem 5. ", "page_idx": 23}, {"type": "text", "text": "Regret bound for STB: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Note that any realized adversary $B\\,\\in\\,\\mathrm{Adv}_{0}^{\\mathrm{o}}(\\mathbf{F},B_{0})$ may be represented as a sequence of functions $(f_{1},\\cdot\\cdot\\cdot,f_{T})$ and a corresponding sequence of query oracles $\\left(\\boldsymbol{\\mathcal{Q}}_{1},\\cdot\\cdot\\cdot\\,,\\boldsymbol{\\mathcal{Q}}_{T}\\right)$ . For such realized adversary $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , we define $\\hat{B}$ to be the realized adversary corresponding to $(\\hat{f}_{1},\\cdot\\cdot\\cdot,\\hat{f}_{T})$ with the stochastic gradient oracles ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{Q}}_{t}(\\mathbf{x}):=\\frac{k}{\\delta}\\mathcal{Q}_{t}(\\mathbf{x}+\\delta\\mathbf{v})\\mathbf{v},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\mathbf{v}$ is a random vector, taking its values uniformly from $\\mathbb{S}^{1}\\cap\\mathcal{L}_{0}\\,=\\,\\mathbb{S}^{1}\\cap(\\mathrm{aff}(K)\\mathrm{-}\\,\\mathbf{z})$ , for any $\\mathbf{z}\\in\\mathcal{K}$ and $k=\\dim(\\mathcal{L}_{0})$ . Since $\\mathcal{Q}_{t}$ is a stochastic value oracle for $f_{t}$ , according to Remark 4 in [37], $\\hat{\\mathcal{Q}}_{t}({\\bf x})$ is an unbiased estimator of $\\nabla\\hat{f}_{t}(\\mathbf{x})$ . 8 Hence we have $\\hat{B}\\in\\operatorname{Adv}_{1}^{0}(\\hat{\\mathbf{F}},\\frac{k}{\\delta}B_{0})$ . Using Equation 9 and the definition of the Algorithm 6, we see that the responses of the queries are the same between the game $(\\mathcal{A},\\hat{\\mathcal{B}})$ and $(\\mathcal{A}^{\\prime},\\mathcal{B})$ . It follows that the sequence of actions $(\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T})$ in $(\\mathcal{A},\\hat{\\mathcal{B}})$ corresponds to the sequence of actions $\\left(\\mathbf{x}_{1}+\\delta\\mathbf{v}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T}+\\delta\\mathbf{v}_{T}\\right)$ in $(\\mathcal{A}^{\\prime},\\mathcal{B})$ . ", "page_idx": 24}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathbf{u}\\in\\mathop{\\mathrm{argmax}}_{\\mathbf{u}\\in\\mathcal{U}}\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})}\\end{array}$ and $\\begin{array}{r}{\\hat{\\mathbf{u}}\\in\\operatorname{argmax}_{\\mathbf{u}\\in\\hat{\\mathcal{U}}}\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{u}_{t})}\\end{array}$ . We have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\alpha,\\mathcal{B}}^{\\mathcal{A}^{\\prime}}-\\mathcal{R}_{\\alpha,\\mathcal{\\hat{B}}}^{\\mathcal{A}}=\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t})\\right]-\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[\\left(\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t})\\right)+\\alpha\\left(\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "According to Lemma 3 in [37], we have $|\\hat{f}_{t}(\\mathbf{x}_{t})-f_{t}(\\mathbf{x}_{t})|\\le\\delta M_{1}$ . By using Lipschitz property for the pair $\\left(\\mathbf{x}_{t},\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t}\\right)$ , we see that ", "page_idx": 24}, {"type": "equation", "text": "$$\n|f_{t}(\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t})-\\hat{f}_{t}(\\mathbf{x}_{t})|\\leq|f_{t}(\\mathbf{x}_{t}+\\delta\\mathbf{v}_{t})-f_{t}(\\mathbf{x}_{t})|+|f_{t}(\\mathbf{x}_{t})-\\hat{f}_{t}(\\mathbf{x}_{t})|\\leq2\\delta M_{1}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "On the other hand, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{\\mathrm{t}}(\\mathbf{i}_{t})=\\operatorname*{max}_{t=0}^{\\infty}\\displaystyle\\sum_{n=1}^{b}\\hat{f}_{\\mathrm{t}}(\\mathbf{i}_{t})}&{}\\\\ {\\displaystyle\\ge-\\delta M_{\\mathrm{I}}T+\\operatorname*{max}_{n\\le t=a}^{\\infty}\\sum_{n=1}^{b}f_{\\mathrm{t}}(\\mathbf{i}_{t})}&{}\\\\ {\\displaystyle}&{=-\\delta M_{\\mathrm{I}}T+\\operatorname*{max}_{n\\le t=a}^{\\infty}\\sum_{t=b}^{b}f_{\\mathrm{t}}\\left(\\left(1-\\frac{\\delta}{r}\\right)u_{t}+\\frac{\\delta}{r}\\right)}\\\\ {\\displaystyle}&{=-\\delta M_{\\mathrm{I}}T+\\operatorname*{max}_{n\\le t\\le b}^{\\infty}\\sum_{t=b}^{b}f_{\\mathrm{t}}\\left(\\mathbf{u}_{t}+\\frac{\\delta}{r}(\\mathbf{c}-\\mathbf{x})\\right)}\\\\ {\\displaystyle}&{\\ge-\\delta M_{\\mathrm{I}}T+\\operatorname*{max}_{n\\le t=b}^{\\infty}\\sum_{t=1}^{b}\\left(f_{\\mathrm{t}}(\\mathbf{u}_{t})-\\frac{2\\delta M_{\\mathrm{I}}D}{r}\\right)}\\\\ {\\displaystyle}&{=-\\left(1+\\frac{2D}{r}\\right)\\delta M_{\\mathrm{I}}T+\\sum_{t=b}^{b}f_{\\mathrm{t}}(\\mathbf{u}_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, using Equation 10, we see that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{R}_{B}^{A^{\\prime}}-\\mathcal{R}_{\\hat{B}}^{A}\\leq2\\delta M_{1}T+\\alpha\\left(1+\\frac{2D}{r}\\right)\\delta M_{1}T\\leq\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\mathrm{Adv_{0}^{0}}(\\mathbf{F},B_{0})}^{\\mathcal{A}^{\\prime}}=\\underset{{B\\in\\mathrm{Adv_{0}^{0}}(\\mathbf{F},B_{0})}}{\\operatorname*{sup}}\\mathcal{R}_{B}^{\\mathcal{A}^{\\prime}}}\\\\ &{\\qquad\\qquad\\leq\\underset{{B\\in\\mathrm{Adv_{0}^{0}}(\\mathbf{F},B_{0})}}{\\operatorname*{sup}}\\mathcal{R}_{\\ B}^{\\mathcal{A}}+\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T}\\\\ &{\\qquad\\qquad\\leq\\underset{{B\\in\\mathrm{Adv_{0}^{0}}(\\mathbf{F},B_{0})}}{\\operatorname*{sup}}\\mathcal{R}_{\\ B}^{\\mathcal{A}}+\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T}\\\\ &{\\qquad\\qquad\\leq\\mathcal{R}_{\\mathrm{Adv_{0}^{0}}(\\mathbf{F},\\frac{k}{\\delta}B_{0})}^{{A}}+\\left(3+\\frac{2D}{r}\\right)\\delta M_{1}T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Regret bound for FOTZO: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The proof of the bounds for this case is similar to the previous case. As before, we see that the responses of the queries are the same between the game $(\\mathcal{A},\\hat{\\mathcal{B}})$ and $({\\mathcal{A}}^{\\prime},{\\mathcal{B}})$ . It follows from the description of Algorithm 5 that the sequence of actions $\\left(\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T}\\right)$ in $({\\mathcal{A}},{\\hat{\\mathcal{B}}})$ corresponds to the same sequence of actions in $(\\mathcal{A}^{\\prime},\\mathcal{B})$ . ", "page_idx": 25}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathbf{u}\\in\\mathop{\\mathrm{argmax}}_{\\mathbf{u}\\in\\mathcal{U}}\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})}\\end{array}$ and $\\begin{array}{r}{\\hat{\\mathbf{u}}\\in\\operatorname{argmax}_{\\mathbf{u}\\in\\hat{\\mathcal{U}}}\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{u}_{t})}\\end{array}$ . We have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathcal{R}_{B}^{A^{\\prime}}-\\mathcal{R}_{\\hat{B}}^{A}=\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right]-\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})\\right]}&{{}}&{}\\\\ {=\\mathbb{E}\\left[\\left(\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})-\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right)+\\alpha\\left(\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})\\right)\\right].}&{{}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To obtain the same bound as before, instead of Inequality 11, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n|f_{t}(\\mathbf{x}_{t})-\\hat{f}_{t}(\\mathbf{x}_{t})|\\leq\\delta M_{1}<2\\delta M_{1}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The rest of the proof follows verbatim. ", "page_idx": 25}, {"type": "text", "text": "Proof of Theorem $6$ . Note that any realized adversary $\\beta\\,\\in\\,\\mathrm{Adv}_{0}^{\\mathrm{o}}(\\mathbf{F})$ may be represented as a sequence of functions $(f_{1},\\cdot\\cdot\\cdot,f_{T})$ . For such realized adversary $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , we define B\u02c6 to be the realized adversary corresponding to $(\\hat{f}_{1},\\cdot\\cdot\\cdot,\\hat{f}_{T})$ with the stochastic gradient oracles ", "page_idx": 25}, {"type": "equation", "text": "$$\n{\\hat{\\mathcal{Q}}}_{t}(\\mathbf{x}):={\\frac{k}{2\\delta}}\\left(f_{t}(\\mathbf{x}+\\delta\\mathbf{v})-f_{t}(\\mathbf{x}-\\delta\\mathbf{v})\\right)\\mathbf{v},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\mathbf{v}$ is a random vector, taking its values uniformly from $\\mathbb{S}^{1}\\cap\\mathcal{L}_{0}=\\mathbb{S}^{1}\\cap\\left(\\mathrm{aff}(K)-\\mathbf{z}\\right)$ , for any $\\mathbf{z}\\in\\mathcal{K}$ and $k=\\dim(\\mathcal{L}_{0})$ . Since $\\mathcal{Q}_{t}$ is a stochastic value oracle for $f_{t}$ , according to Lemma 5 in [37], $\\hat{\\mathcal{Q}}_{t}({\\bf x})$ is an unbiased estimator of $\\nabla\\hat{f}_{t}(\\mathbf{x})$ . Moreover, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\|{\\frac{k}{2\\delta}}\\left(f_{t}(\\mathbf{x}+\\delta\\mathbf{v})-f_{t}(\\mathbf{x}-\\delta\\mathbf{v})\\right)\\mathbf{v}\\|\\leq{\\frac{k}{2\\delta}}M_{1}\\|(\\mathbf{x}+\\delta\\mathbf{v})-(\\mathbf{x}-\\delta\\mathbf{v})\\|\\leq k M_{1}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hence we have $\\hat{B}\\in\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\hat{\\mathbf{F}},k M_{1})$ . Using Equation 13 and the definition of the Algorithm 5, we see that the responses of the queries are the same between the game $(\\mathcal{A},\\hat{\\mathcal{B}})$ and $(\\mathcal{A}^{\\prime},\\mathcal{B})$ . It follows that the sequence of actions $(\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T})$ in $({\\mathcal{A}},{\\hat{\\mathcal{B}}})$ corresponds to the same sequence of actions in $(\\mathcal{A}^{\\prime},\\mathcal{B})$ . ", "page_idx": 25}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathbf{u}\\in\\mathop{\\mathrm{argmax}}_{\\mathbf{u}\\in\\mathcal{U}}\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})}\\end{array}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{1\\in\\mathrm{argmax}_{{\\mathbf{u}}\\in\\mathcal{U}}\\sum_{t=a}^{\\infty}f_{t}(\\mathbf{u}_{t})\\mathrm{~and~}\\hat{\\mathbf{u}}\\in\\mathrm{argmax}_{\\mathbf{u}\\in\\hat{\\mathcal{U}}}\\sum_{t=a}^{\\infty}f_{t}(\\mathbf{u}_{t}).\\mathrm{~we~have}}}\\\\ {{\\mathcal{R}_{\\mathcal{B}}^{A^{\\prime}}-\\mathcal{R}_{\\mathcal{B}}^{A}=\\mathbb{E}\\left[\\alpha\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right]-\\mathbb{E}\\left[\\alpha\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})\\right]}}\\\\ {{\\qquad=\\mathbb{E}\\left[\\left(\\displaystyle\\sum_{t=a}^{b}\\hat{f}_{t}(\\mathbf{x}_{t})-\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{x}_{t})\\right)+\\alpha\\left(\\displaystyle\\sum_{t=a}^{b}f_{t}(\\mathbf{u}_{t})-\\sum_{t=a}^{b}\\hat{f}_{t}(\\hat{\\mathbf{u}}_{t})\\right)\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "According to Lemma 3 in [37], we have $|\\hat{f}_{t}(\\mathbf{x}_{t})-f_{t}(\\mathbf{x}_{t})|\\le\\delta M_{1}$ . On the other hand, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=0}^{b}\\hat{f}_{t}(\\mathbf{u}_{t})=\\operatorname*{max}_{t=0}^{\\infty}\\displaystyle\\sum_{n=1}^{b}\\hat{f}_{t}(\\mathbf{u}_{t})}&{}\\\\ {\\displaystyle\\geq-\\delta M_{1}T+\\operatorname*{max}_{n\\in\\mathbb{Z}}\\displaystyle\\sum_{i=1}^{b}f_{i}(\\mathbf{\\hat{u}}_{i})}&{}\\\\ {\\displaystyle=-\\delta M_{1}T+\\operatorname*{max}_{n\\in\\mathbb{Z}}\\displaystyle\\sum_{t=1}^{b}f_{i}\\left(\\left(1-\\frac{\\delta}{r}\\right)\\mathbf{u}_{t}+\\frac{\\delta}{r}\\mathbf{\\hat{c}}\\right)}&{}\\\\ {\\displaystyle=-\\delta M_{1}T+\\operatorname*{max}_{n\\in\\mathbb{Z}}\\displaystyle\\sum_{t=1}^{b}f_{i}\\left(\\mathbf{u}_{t}+\\frac{\\delta}{r}(\\mathbf{c}-\\mathbf{x})\\right)}&{}\\\\ {\\displaystyle\\geq-\\delta M_{1}T+\\operatorname*{max}_{n\\in\\mathbb{Z}}\\displaystyle\\sum_{t=1}^{b}\\left(f_{i}(\\mathbf{u}_{t})-\\frac{2\\delta M_{1}D}{r}\\right)}&{}\\\\ {\\displaystyle=-\\left(1+\\frac{2D}{r}\\right)\\delta M_{1}T+\\sum_{t=1}^{b}f_{t}(\\mathbf{u}_{t})}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Therefore, using Equation 14, we see that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{R}_{B}^{A^{\\prime}}-\\mathcal{R}_{\\hat{B}}^{A}\\le\\delta M_{1}T+\\alpha\\left(1+\\frac{2D}{r}\\right)\\delta M_{1}T\\le\\left(2+\\frac{2D}{r}\\right)\\delta M_{1}T.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Therefore, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathcal{R}_{\\mathrm{Adv_{0}}^{\\prime}(\\mathbf{F})}^{\\mathcal{A}^{\\prime}}=\\operatorname*{sup}_{B\\in\\mathbb{A}\\mathrm{dv}_{0}^{\\prime}(\\mathbf{F})}\\mathcal{R}_{B}^{\\mathcal{A}^{\\prime}}}}\\\\ &{}&{\\le\\operatorname*{sup}_{B\\in\\mathrm{Adv}_{0}^{\\circ}(\\mathbf{F})}\\mathcal{R}_{\\bar{B}}^{\\mathcal{A}}+\\left(2+\\displaystyle\\frac{2D}{r}\\right)\\delta M_{1}T}\\\\ &{}&{\\le\\operatorname*{sup}_{B\\in\\mathrm{Adv}_{0}^{\\circ}(\\mathbf{F})}\\mathcal{R}_{\\bar{B}}^{\\mathcal{A}}+\\left(2+\\displaystyle\\frac{2D}{r}\\right)\\delta M_{1}T}\\\\ &{}&{\\le\\mathcal{R}_{\\mathrm{Adv}_{1}^{\\circ}(\\hat{\\mathbf{F}},k M_{1})}^{\\mathcal{A}}+\\left(2+\\displaystyle\\frac{2D}{r}\\right)\\delta M_{1}T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Corollary 4. Under the assumptions of Theorem $^{5}$ , if we have $\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A}\\,=\\,O(B_{1}T^{\\eta})$ $\\delta=T^{(\\eta-1)/2}$ , then we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{\\mathcal{A}^{\\prime}}=O(B_{0}T^{(1+\\eta)/2}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Corollary 5. Under the assumptions of Theorem $\\theta,$ , if we have $\\delta=T^{-1}$ , then $\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{A^{\\prime}}$ has the same order of regret as that of $\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A}$ with $B_{1}$ replaced with $k M_{1}$ . ", "page_idx": 26}, {"type": "text", "text": "H Proof of Theorem 7 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Proof. Given a realized adversary $\\boldsymbol{B}\\in\\operatorname{Adv}_{i}^{\\circ}(\\mathbf{F},B)\\{T\\}$ , we may define $\\hat{\\mathcal{B}}=\\mathrm{Adv}_{i}^{\\circ}(\\mathbf{F},B)\\{T/L\\}$ ttho eb feu tnhcet iroenasl iczheods aedn vbeyr $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ ya rce $f_{1},\\cdot\\cdot\\cdot,f_{T}$ ,y t haev efruangcitnigo nesa cchh $T/L$ bbyl $\\hat{\\boldsymbol{B}}$ ka roef $\\begin{array}{r}{\\hat{f}_{q}:=\\frac{1}{L}\\sum_{t=(q-1)L+1}^{q L}f_{t}}\\end{array}$ $L$ for $1\\leq q\\leq T/L$ . Note that, for any $\\mathbf{x}\\in\\mathcal{K}$ and $(q-1)L<t\\leq q L$ , we have $\\mathbb{E}[f_{t}(\\mathbf{x})]=\\hat{f}_{q}(\\mathbf{x})$ and if each $f_{t}$ is differentiable at $\\mathbf{x}$ , then $\\mathbb{E}[\\nabla f_{t}(\\mathbf{x})]=\\nabla\\hat{f}_{q}(\\mathbf{x})$ . If the query oracles selected by $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ are $\\mathcal{Q}_{1},\\cdot\\cdot\\cdot\\,,\\mathcal{Q}_{T}$ , then for any $1\\,\\leq\\,q\\,\\leq\\,T/L$ we define the query oracle $\\hat{\\mathcal{Q}}_{q}$ as the algorithm that first selects an integer $(q-1)L+1\\leq t\\leq q L$ with uniform probability and then returns the output of $\\mathcal{Q}_{t}$ . It follows that $\\hat{\\mathcal{Q}}_{q}$ is a query oracle for $\\hat{f}_{q}$ . It is clear from the description of Algorithm 4 that, when the adversary is $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , the output returned to the base algorithm corresponds to $\\hat{\\boldsymbol{B}}$ . We have $1\\leq(a^{\\prime}-1)L+1\\leq a\\leq b\\leq b^{\\prime}L\\leq\\bar{T}$ . Hence ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{\\xi_{n}}^{\\xi^{\\prime}}(K_{*}^{\\top})|_{0,b}\\mathbb{I}=\\mathbb{E}\\left[\\left.\\operatorname*{max}_{i=0}^{k}\\frac{\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})-\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})}{\\sum_{l=0}^{k}f_{j}({\\bf u}_{0})-\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})}\\right]\\right.}\\\\ &{=\\mathbb{E}\\left[L\\left(\\operatorname*{max}_{i=0}^{k}\\frac{1}{L}\\sum_{l=0}^{k}f_{l}({\\bf u}_{0})-\\frac{1}{L}\\sum_{j=1}^{k}f_{l}({\\bf x}_{0})\\right)\\right]}\\\\ &{\\leq\\mathbb{E}\\left[L\\left(\\operatorname*{max}_{i=0}^{k}\\frac{1}{L}\\sum_{l=0}^{k}f_{l}({\\bf u}_{0})-1\\right)\\!-\\!\\frac{\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})}{L}f_{l}({\\bf x}_{0})\\right)\\right]}\\\\ &{=\\mathbb{E}\\left[\\left.\\sum_{n=0}^{k}\\frac{\\sum_{j=1}^{k}f_{j}({\\bf r}_{j}({\\bf u}_{0})-f_{l}({\\bf r}_{1}))+L}{\\sum_{l=0}^{k}\\sum_{n=0}^{k}\\!\\sum_{n=0}^{k}\\!\\sum_{n=1}^{k}\\!\\left(f_{l}({\\bf u}_{0})-{\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})}\\right)}\\right]}\\\\ &{\\leq\\frac{\\sum_{j=1}^{k}K M_{1}D+L}{\\sum_{n=0}^{k}\\sum_{n=0}^{k}\\!\\left[\\operatorname*{max}_{i=0}^{k}\\frac{\\sum_{j=1}^{k}({\\bf u}_{0})-{\\sum_{j=1}^{k}f_{j}({\\bf u}_{0})}}{\\sum_{n=0}^{k}\\sum_{n=0}^{k}\\sum_{n=1}^{k}\\left(\\operatorname*{max}_{i=0}^{k}\\frac{\\sum_{j=1}^{k}({\\bf u}_{0})-{\\sum_{j=1}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Therefore ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\boldsymbol{\\alpha},\\mathrm{Adv}_{i}^{0}(\\mathbb{F},B)\\{T\\}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})[\\boldsymbol{a},\\boldsymbol{b}]=\\underset{\\boldsymbol{B}\\in\\mathrm{Adv}_{i}^{0}(\\mathbb{F},B)\\{T\\}}{\\operatorname*{sup}}\\mathcal{R}_{\\boldsymbol{\\alpha},\\boldsymbol{B}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})[\\boldsymbol{a},\\boldsymbol{b}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq M_{1}D K(\\boldsymbol{b}^{\\prime}-\\boldsymbol{a}^{\\prime}+1)+L\\underset{\\boldsymbol{\\dot{B}}\\in\\mathrm{Adv}_{1}^{0}(\\mathbb{F},B)\\{T/L\\}}{\\operatorname*{sup}}\\mathcal{R}_{\\boldsymbol{\\alpha},\\boldsymbol{\\hat{B}}}^{\\mathcal{A}}(K_{\\star}^{T/L})[\\boldsymbol{a}^{\\prime},\\boldsymbol{b}^{\\prime}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=M_{1}D K(\\boldsymbol{b}^{\\prime}-\\boldsymbol{a}^{\\prime}+1)+L\\mathcal{R}_{\\boldsymbol{\\alpha},\\mathrm{Adv}_{i}^{0}(\\mathbb{F},B)\\{T/L\\}}^{\\mathcal{A}}(K_{\\star}^{T/L})[\\boldsymbol{a}^{\\prime},\\boldsymbol{b}^{\\prime}].\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Remark 1. Note that in the above proof, we did not need to assume that the query oracles are bounded. Specifically, what we require is that the set of query oracles to be closed under convex combinations. This holds when all query oracles are bounded by $B$ , but it also holds under many other assumptions, e.g., if we assume all query oracles variances are bounded by some $\\sigma^{2}>0$ . ", "page_idx": 27}, {"type": "text", "text": "Corollary 6. Under the assumptions of Theorem 7, if we have $\\begin{array}{r}{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{o}(\\mathbf{F},B)}^{A^{\\prime}}(\\mathcal{K}_{\\star}^{T})[a,b]=O(B T^{\\eta}),}\\end{array}$ $K=O(T^{\\theta})$ and L = T 2\u2212\u03b7 , then we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{o}(\\mathbf{F},B)}^{\\mathcal{A}^{\\prime}}(\\mathcal{K}_{\\star}^{T})[a,b]=O\\left(B T^{\\frac{(1+\\theta)(1-\\eta)+\\eta}{2-\\eta}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "As a special case, when $K=O(1)$ , then we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{o}(\\mathbf{F},B)}^{\\mathcal{A}^{\\prime}}(\\mathcal{K}_{\\star}^{T})[a,b]=O\\left(B T^{\\frac{1}{2-\\eta}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. We have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T\\}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})[a,b]\\le M_{1}D K(b^{\\prime}-a^{\\prime}+1)+L\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T/L\\}}^{{A}^{\\prime}}(K_{\\star}^{T/L})[a^{\\prime},b^{\\prime}]}\\\\ &{\\hphantom{{\\mathcal{A}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T/L\\}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})}}\\le M_{1}D K(T/L)+L\\mathcal{R}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T/L\\}}^{A}(K_{\\star}^{T/L})[a^{\\prime},b^{\\prime}]}\\\\ &{\\hphantom{{\\mathcal{A}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T/L\\}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})}}=O(K T/L)+O(L B(T/L)^{\\eta})}\\\\ &{\\hphantom{{\\mathcal{A}_{\\alpha,\\mathrm{Adv}_{i}^{0}(\\mathbf{F},B)\\{T/L\\}}^{\\mathcal{A}^{\\prime}}(K_{\\star}^{T})}}=O\\left(B T^{\\frac{(1+\\theta)(1-\\eta)+\\eta}{2-\\eta}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "I Proof of Theorem 8 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof. Since $\\boldsymbol{\\mathcal{A}}$ requires $T^{\\theta}$ queries per time-step, it requires a total of $T^{1+\\theta}$ queries. The expected error is bounded by the regret divided by time. Hence we have $\\epsilon=O(T^{\\eta-1})$ after $T^{1+\\theta}$ queries. Therefore, the total number of queries to keep the error bounded by $\\epsilon$ is $O(\\epsilon^{-\\frac{1+\\theta}{1-\\eta}})$ . \u53e3 ", "page_idx": 28}, {"type": "text", "text": "J Projection-free adptive regret ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "The SO-OGD algorithm in [17] is a deterministic algorithm with semi-bandit feedback, designed for online convex optimization with a deterministic gradient oracle. Here we assume that the separation oracle is deterministic. ", "page_idx": 28}, {"type": "text", "text": "Here we use the notation c, $r$ and $\\hat{\\mathcal{{K}}}_{\\delta}$ described in Section 5. ", "page_idx": 28}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/1ff5619e9cb815f82a5442f02ce486744eda76afef1de1d487a96a955c7292d0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Note that here we use a maximization version of the algorithm, which we denote by SO-OGA. Here $\\mathbf{P}_{\\mathcal{K}}$ denotes projection into the convex set $\\kappa$ . The original version, which is designed for minimization, uses the update rule $\\mathbf{x}_{t+1}^{\\prime}=\\mathbf{x}_{t}-\\eta\\mathbf{o}_{t}$ in Algorithm 8 instead. ", "page_idx": 28}, {"type": "text", "text": "Algorithm 9: Infeasible Projection via a Separation Oracle - SO-IPK(y0)   \nInput : Constraint set $\\kappa$ , shrinking parameter $\\delta<r$ , initial point y0   \n1 $\\mathbf{y}_{1}\\leftarrow\\mathbf{P}_{\\mathrm{aff}(\\kappa)}\\big(\\mathbf{y}_{0}\\big)$   \n2 y2 \u2190c +max{1y,1\u2225\u2212y1c\u2225/D} /\\* y1 is projection of y0 over $\\mathbb{B}_{D}(\\mathbf{c})\\cap\\mathrm{aff}(K)\\ */$   \n3 for $i=1,2,\\dots$ do   \n4 Call $\\mathrm{SO}_{\\kappa}$ with input $\\mathbf{y}_{i}$   \n5 if $\\mathbf{y}_{i}\\notin\\mathcal{K}$ then   \n6 Set $\\mathbf{g}_{i}$ to be the hyperplane returned by $\\mathrm{SO}_{\\kappa}$ /\\* \u2200x \u2208K, $\\langle{\\bf y}_{i}-{\\bf x},{\\bf g}_{i}\\rangle>0\\,\\mathrm{~}^{\\ast/}$   \n7 $\\begin{array}{r l}&{\\mathbf{g}_{i}^{\\prime}\\leftarrow\\mathbf{P}_{\\mathrm{aff}(K)-\\mathbf{c}}(\\mathbf{g}_{i})}\\\\ &{\\mathrm{Update}\\;\\mathbf{y}_{i+1}\\leftarrow\\mathbf{y}_{i}-\\delta\\frac{\\mathbf{g}_{i}^{\\prime}}{\\|\\mathbf{g}_{i}^{\\prime}\\|}}\\end{array}$   \n8   \n9 else   \n10 Return y \u2190yi   \n11 end   \n12 end ", "page_idx": 28}, {"type": "text", "text": "Lemma 5. Algorithm 9 stops after at most $(\\mathrm{dist}(\\mathbf{y}_{0},\\hat{\\mathcal{K}}_{\\delta})^{2}-\\mathrm{dist}(\\mathbf{y},\\hat{\\mathcal{K}}_{\\delta})^{2})/\\delta^{2}+1$ iterations and returns $\\mathbf{y}\\in{\\mathcal{K}}$ such that $\\forall\\mathbf{z}\\in\\hat{\\mathcal{K}}_{\\delta}$ , we have $\\|\\mathbf{y}-\\mathbf{z}\\|\\leq\\|\\mathbf{y}_{0}-\\mathbf{z}\\|$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. We first note that this algorithm is invariant under translations. Hence it is sufficient to prove the result when $\\mathbf{c}=0$ . ", "page_idx": 28}, {"type": "text", "text": "Let $\\mathrm{SO}_{K}^{\\prime}$ denote the following separation oracle. If $\\textbf{y}\\in\\mathcal{K}$ or ${\\textbf{y}}\\notin\\operatorname{aff}(K)$ , then $\\mathrm{SO}_{K}^{\\prime}$ returns the same output as $\\mathrm{SO}_{\\mathcal{K}}$ . Otherwise, it returns $\\mathbf{P}_{\\mathrm{aff}(K)}(\\mathbf{g})$ where $\\mathbf{g}\\in\\mathbb{R}^{d}$ is the output of $\\mathrm{SO}_{\\mathcal{K}}$ . To prove that this is indeed a separation oracle, we only need to consider the case where $\\mathbf{y}\\in\\operatorname{aff}(K)\\setminus K$ . We know that $\\mathbf{g}$ is a vector such that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\forall\\mathbf{x}\\in K,\\quad\\langle\\mathbf{y}-\\mathbf{x},\\mathbf{g}\\rangle>0.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Since $\\mathbf{P}_{\\mathrm{aff}(K)}$ is an orthogonal projection, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\langle\\mathbf{y}-\\mathbf{x},\\mathbf{P}_{\\mathrm{aff}(K)}(\\mathbf{g})\\rangle=\\langle\\mathbf{P}_{\\mathrm{aff}(K)}(\\mathbf{y}-\\mathbf{x}),\\mathbf{g}\\rangle=\\langle\\mathbf{y}-\\mathbf{x},\\mathbf{g}\\rangle>0.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for all $\\mathbf{x}\\in K$ , which implies that $\\mathrm{SO}_{K}^{\\prime}$ is a separation oracle. ", "page_idx": 28}, {"type": "text", "text": "Now we see that Algorithm 9 is an instance of Algorithm 6 in [17] applied to the initial point $\\mathbf{y}_{1}$ using the separation oracle $\\mathrm{SO}_{K}^{\\prime}$ . Hence we may use Lemma 13 in [17] directly to see that Algorithm 9 stops after at most $(\\mathrm{dist}(\\mathbf{\\dot{y}}_{1},\\hat{\\boldsymbol{K}}_{\\delta})^{2}-\\mathrm{dist}(\\mathbf{y},\\hat{\\boldsymbol{K}}_{\\delta})^{2})/\\delta^{2}+1$ iterations and returns $\\mathbf{y}\\in{\\mathcal{K}}$ such that $\\forall\\mathbf{z}\\in\\hat{\\mathcal{K}}_{\\delta}$ , we have $\\|\\mathbf{y}-\\mathbf{z}\\|\\leq\\|\\mathbf{y}_{1}-\\mathbf{z}\\|$ Since $\\mathbf{y}_{1}$ is the projection of $\\mathbf{y}$ over aff $(\\mathcal{K})$ , we see that Algorithm 9 stops after at most ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathrm{dist}(\\mathbf{y}_{1},\\hat{K}_{\\delta})^{2}-\\mathrm{dist}(\\mathbf{y},\\hat{K}_{\\delta})^{2}}{\\delta^{2}}+1=\\frac{\\mathrm{dist}(\\mathbf{y}_{0},\\hat{K}_{\\delta})^{2}-\\mathrm{dist}(\\mathbf{y},\\hat{K}_{\\delta})^{2}}{\\delta^{2}}-\\frac{\\|\\mathbf{y}_{0}-\\mathbf{y}_{1}\\|^{2}}{\\delta^{2}}+1}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\frac{\\mathrm{dist}(\\mathbf{y}_{0},\\hat{K}_{\\delta})^{2}-\\mathrm{dist}(\\mathbf{y},\\hat{K}_{\\delta})^{2}}{\\delta^{2}}+1}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "steps and ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall\\mathbf{z}\\in\\hat{\\mathcal{K}}_{\\delta}\\subseteq\\mathrm{aff}(\\mathcal{K}),\\quad\\|\\mathbf{y}-\\mathbf{z}\\|\\leq\\|\\mathbf{y}_{1}-\\mathbf{z}\\|\\leq\\|\\mathbf{y}_{0}-\\mathbf{z}\\|.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "In the following, we use the notation ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}:=\\underset{1\\leq a\\leq b\\leq T}{\\operatorname*{max}}\\,\\mathcal{R}_{\\alpha,\\mathrm{Adv}}^{A}(\\mathcal{K}_{*}^{T})[a,b],}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "to denote the adaptive regret. ", "page_idx": 29}, {"type": "text", "text": "Theorem 9. Let L be a class of linear functions over $\\kappa$ such that $\\|l\\|\\leq M_{1}$ for all ${\\mathbf{\\nabla}}l\\in{\\bf L}$ and let $D=\\dim(K)$ . Fix $v>0$ such that $\\delta=v T^{-1/2}\\in(0,1)$ and set $\\begin{array}{r}{\\eta=\\frac{v r}{2M_{1}}T^{-1/2}}\\end{array}$ . Then we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{f}({\\bf L})}^{{\\bf S0}\\mathrm{-}0\\mathrm{GA}}=O(M_{1}T^{1/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. Since the algorithm is deterministic, according to Theorem 1 in [34], it is sufficient to prove this regret bound against the oblivious adversary $\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\mathbf{L})$ . ", "page_idx": 29}, {"type": "text", "text": "Note that this algorithm is invariant under translations. Hence it is sufficient to prove the result when $\\mathbf{c}=0$ . If af $\\mathbb{I}(K)=\\mathbb{R}^{d}$ , then we have $\\mathbb{B}_{r}(\\mathbf{0})\\subseteq{\\boldsymbol{K}}\\subseteq\\mathbb{B}_{R}(\\mathbf{0})$ and we may use Theorem 14 from [17] to obtain the desired result for the oblivious adversary $\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\mathbf{L})$ . On the other hand, the assumption $\\mathbb{B}_{r}(\\mathbf{0})\\subseteq\\mathcal{K}$ is only used in the proof of Lemma 13 in [17]. Here we use Lemma 5 instead which does not require this assumption. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "The following corollary is an immediate consequence of the above theorem and Theorems 2, 3, 4, 8 and Corollaries 4, 5 and 6. ", "page_idx": 29}, {"type": "text", "text": "Corollary 7. Let SO-OGA denote the algorithm described above. Then the following are true. ", "page_idx": 29}, {"type": "text", "text": "a) Under the assumptions of Theorem 2, we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathcal{A}\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{f}({\\bf F})}^{{\\bf S}0-0\\mathrm{Gh}}\\leq O(M_{1}T^{1/2}),}\\\\ &{}&{\\mathcal{A}\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{o}({\\bf F},B_{1})}^{{\\bf S}0-0\\mathrm{Gh}}\\leq O(B_{1}T^{1/2}),}\\\\ &{}&{\\mathcal{A}\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{0}^{o}({\\bf F})}^{{\\bf F}0\\mathrm{TZ}0({\\bf S}0-0\\mathrm{Gh})}\\leq O(M_{1}T^{1/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{\\mathrm{STB}(\\mathrm{S}0-0\\mathrm{GA})}\\leq O(B_{0}T^{3/4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "b) Under the assumptions of Theorem 3, we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A}\\leq O(B_{1}T^{1/2}),}\\\\ {A\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathrm{F0TZ0}(A)}\\leq O(M_{1}T^{1/2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\mathcal{A}=0\\mathtt{M B Q}$ (SO-OGA, BQM0, Id). Note that $\\boldsymbol{\\mathcal{A}}$ is a first order full-information algorithm that requires a single query per time-step. If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{A}\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A_{\\mathrm{semi-bandit}}}\\leq O(B_{1}T^{2/3}),}\\\\ &{\\mathcal{A}\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{full-info-0}}}\\leq O(B_{0}T^{3/4})}\\\\ &{\\mathcal{A}\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{bandit}}}\\leq O(B_{0}T^{4/5})}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A_{\\mathrm{{semi}\\cdot\\mathrm{{bandit}}}}=\\mathrm{{SFT}}(A),\\quad A_{\\mathrm{{full}\\cdot\\mathrm{{info}}-0}}=\\mathrm{{F0TZ0}}(A),\\quad A_{\\mathrm{{bandit}}}=\\mathrm{{SFT}}(A_{\\mathrm{{full}\\cdot\\mathrm{{info}}-0}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "c) Under the assumptions of Theorem 4, we have: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A}\\leq O(B_{1}T^{1/2}),}\\\\ {A\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathrm{F0TZ0}(A)}\\leq O(M_{1}T^{1/2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathcal{A}=\\mathsf{O M B Q}(\\mathtt{S O-O G A},\\mathtt{B Q N},\\mathbf{x}\\mapsto\\frac{\\mathbf{x}_{t}+\\mathbf{x}}{2})}\\end{array}$ . Note that $\\boldsymbol{\\mathcal{A}}$ is $a$ first order full-information algorithm that requires a single query per time-step. If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{A_{\\mathrm{semi-bandit}}}\\leq O(B_{1}d^{1/2}T^{2/3}),}\\\\ &{A\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{full-info-0}}}\\leq O(B_{0}d^{1/2}T^{3/4}),}\\\\ &{A\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{bandit}}}\\leq O(B_{0}d^{1/2}T^{4/5}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A_{\\mathrm{semi-bandit}}=\\mathrm{SFT}(A),\\quad A_{\\mathrm{full-info-0}}=\\mathrm{F0TZO}(\\mathcal{A}),\\quad A_{\\mathrm{bandit}}=\\mathrm{SFT}(A_{\\mathrm{full-info-0}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "K Dynamic regret ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Improved Ader (IA) algorithm [43] is a deterministic algorithm with semi-bandit feedback, designed for online convex optimization with a deterministic gradient oracle. ", "page_idx": 30}, {"type": "text", "text": "Algorithm 10: Improved Ader - IA ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Input : horizon $T$ , constraint set $\\kappa$ , step size $\\lambda$ , a set $\\mathcal{H}$ containing step sizes for experts   \nActivate a set of experts $\\{E^{\\eta}\\mid\\eta\\in\\mathcal{H}\\}$ by invoking Algorithm 11 for each step size $\\eta\\in\\mathcal{H}$   \nSort step sizes in ascending order $\\eta_{1}\\leq\\cdots\\leq\\eta_{N}$ , and set $\\begin{array}{r}{w_{1}^{\\eta_{i}}=\\frac{C}{i(i+1)}}\\end{array}$ where C = 1 +|1H|   \nfor $t=1,2,\\ldots,T$ do Receive $\\mathbf{x}_{t}^{\\eta}$ from each expert $E^{\\eta}$ Play the action $\\begin{array}{r}{{\\bf x}_{t}=\\sum_{\\eta\\in\\mathcal{H}}w_{t}^{\\eta}{\\bf x}_{t}^{\\eta}}\\end{array}$ and observe $\\mathbf{o}_{t}=\\nabla f_{t}\\big(\\mathbf{x}_{t}\\big)$ Define $l_{t}(\\mathbf{y}):=\\left\\langle\\mathbf{o}_{t},\\mathbf{y}\\,\\overset{\\cdot}{-}\\,\\mathbf{x}_{t}\\right\\rangle$ Update the weight of each expert by $\\begin{array}{r}{w_{t+1}^{\\eta}=\\frac{w_{t}^{\\eta}e^{-\\lambda l_{t}(\\mathbf{x}_{t}^{\\eta})}}{\\sum_{\\mu\\in\\mathcal{H}}w_{t}^{\\mu}e^{-\\lambda l_{t}(\\mathbf{x}_{t}^{\\mu})}}}\\end{array}$ Send the gradient $\\mathbf{o}_{t}$ to each expert $E^{\\eta}$   \nend ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 30}, {"type": "table", "img_path": "dGaMSMeeF8/tmp/018922357518e819364a59b83efcb9156c55319759b7ebf6d260d4e247e40431.jpg", "table_caption": [], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "In Algorithm 11, $\\mathbf{P}_{\\mathcal{K}}$ denotes projection into the convex set $\\kappa$ . Note that here we used the maximization version of this algorithm. The original version, which is designed for minimization, uses the update rule $\\mathbf{x}_{t+1}^{\\eta}=\\mathbf{P}_{\\hat{\\mathcal{K}}}(\\mathbf{x}_{t}^{\\eta}-\\eta\\mathbf{o}_{t})$ in Algorithm 11 instead. ", "page_idx": 31}, {"type": "text", "text": "Theorem 10. Let L be a class of linear functions over $\\kappa$ such that $\\|l\\|\\leq M_{1}$ for all ${\\mathbf{\\nabla}}l\\in{\\bf L}$ and let D = diam(K). Set H := {\u03b7i = 2i\u2212M11D 27T where $N=\\lceil\\frac{1}{2}\\log_{2}(1+4T/7)\\rceil+1$ and $\\lambda=\\sqrt{2/(T M_{1}^{2}D^{2})}$ . Then for any comparator sequence $\\mathbf{u}\\in\\boldsymbol{\\kappa}^{T}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{R}_{1,\\mathrm{Adv}_{1}^{f}(\\mathbf{L})}^{\\mathtt{I A}}(\\mathbf{u})=O(M_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. If we use the oblivious adversary $\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\mathbf{L})$ instead, this theorem is simply a restatement of the special case (i.e. when the functions are linear) of Theorem 4 in [43]. 9 Since the algorithm is deterministic, according to Theorem 1 in [34], the regret bound remains unchanged when we replace $\\operatorname{Adv}_{1}^{\\mathrm{o}}(\\mathbf{L})$ with $\\operatorname{Adv}_{1}^{\\mathrm{f}}(\\mathbf{L})$ . \u53e3 ", "page_idx": 31}, {"type": "text", "text": "The following corollary is an immediate consequence of the above theorem and Theorems 2, 3, 4, and Corollaries 4 and 5. ", "page_idx": 31}, {"type": "text", "text": "Note that we do not use the meta-algorithm OTB since Improved Ader is designed for non-stationary regret and does not offer any advantages in the offline case. On the other hand, we do not use the meta-algorithm SFTT in this case since Theorem 7 is only for the setting where the comparator is $\\kappa_{*}^{T}$ and does not allow us to convert bounds for dynamic regret. ", "page_idx": 31}, {"type": "text", "text": "Corollary 8. Let IA denote \u201cImproved Ader\u201d described above. Then the following are true. ", "page_idx": 31}, {"type": "text", "text": "a) Under the assumptions of Theorem 2, we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{f}(\\mathbf{F})}^{\\mathrm{IA}}(\\mathbf{u})=O(M_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}),}\\\\ {\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{\\mathrm{IA}}(\\mathbf{u})=O(B_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}),}\\\\ {\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathrm{FOTZ0}(\\mathrm{IA})}(\\mathbf{u})=O(M_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\frac{\\gamma^{2}}{1+c\\gamma^{2}},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{\\mathrm{STB}(\\mathrm{IA})}(\\mathbf{u})=O(B_{0}T^{3/4}(1+P_{T}(\\mathbf{u}))^{1/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "b) Under the assumptions of Theorem 3, we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{\\mathcal{A}}(\\mathbf{u})=O(B_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))})}\\\\ &{\\quad\\mathcal{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathrm{F0TZ0}(\\mathrm{IA})}(\\mathbf{u})=O(M_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\mathcal{A}\\,=\\,0\\mathtt{M B Q}(\\mathtt{I A},\\mathtt{B Q M O},\\mathtt{I d})$ . Note that $\\boldsymbol{\\mathcal{A}}$ is a first order full-information algorithm that requires a single query per time-step. If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathscr{R}_{1-e^{-\\gamma},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{full-info-0}}}(\\mathbf{u})=O(B_{0}T^{3/4}(1+P_{T}(\\mathbf{u}))^{1/2}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where ${\\mathcal{A}}_{\\mathrm{full-info-0}}=\\operatorname{FOTZO}(A)$ . ", "page_idx": 31}, {"type": "text", "text": "c) Under the assumptions of Theorem 4, we have: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{1}^{o}(\\mathbf{F},B_{1})}^{\\mathcal{A}}(\\mathbf{u})=O(B_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}),}\\\\ {\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{0}^{o}(\\mathbf{F})}^{\\mathrm{F0TZ0}(\\mathrm{IA})}(\\mathbf{u})=O(M_{1}\\sqrt{T(1+P_{T}(\\mathbf{u}))}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathcal{A}=0\\mathrm{MBQ}(\\mathtt{I A},\\mathtt{B Q N},\\mathbf{x}\\mapsto\\frac{\\mathbf{x}_{t}+\\mathbf{x}}{2})}\\end{array}$ ). Note that $\\boldsymbol{\\mathcal{A}}$ is a first order full-information algorithm that requires a single query per time-step. If we also assume $\\mathbf{F}$ is bounded by $M_{0}$ and $B_{0}\\geq M_{0}$ , then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}_{\\frac{1-h}{4},\\mathrm{Adv}_{0}^{o}(\\mathbf{F},B_{0})}^{A_{\\mathrm{full-info-0}}}(\\mathbf{u})=O(B_{0}T^{3/4}(1+P_{T}(\\mathbf{u}))^{1/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where ${\\mathcal{A}}_{\\mathrm{full-info-0}}=\\operatorname{FOTZO}(A)$ . ", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The abstract and introduction clearly state the paper\u2019s contribution and scope. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The statements of the results have the precise assumptions. Further, some limitations are also discussed in the conclusions section as a future work direction. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have clearly stated the required assumptions and an accompanying complete proof in the appendix for each theory result. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: Our paper is primarily of theoretical nature and does not include experiments. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our paper is primarily of theoretical nature and does not include experiments. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our paper is primarily of theoretical nature and does not include experiments. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our paper is primarily of theoretical nature and does not include experiments. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our paper is primarily of theoretical nature and does not include experiments. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our research conforms, in every respect, to the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our work is primarily of theoretical nature and has no immediate societal impact. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. ", "page_idx": 36}, {"type": "text", "text": "\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: No high risk data or model have been used. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: No existing asset has been used in the paper. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 37}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: No new asset is introduced in the paper. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: No experiments with human subjects were conducted. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: We conducted no experiments with human subjects. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]