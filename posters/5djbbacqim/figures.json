[{"figure_path": "5DJBBACqim/figures/figures_1_1.jpg", "caption": "Figure 1: Graph Structure and Neural Network Modules of the 6 Leg Centipede. Left: The robot's joints are labeled numerically and circled. Right: The joints form the nodes and the links are the edges. The subset of joints that form each leg module are circled in red, while those that comprise each body module are circled in blue. Neural network modules are denoted as W, where k refers to the type, e.g. all leg modules are type 0, and i denotes different instances of the same module type.", "description": "The figure shows the graph structure representation of a 6-legged robot's physical structure (left) and its corresponding modular neural network controller (right). The physical structure displays individual joints of the robot, which are represented as nodes in the graph structure. Connections between these joints form the edges of the graph. The modular neural network controller shows the division of the network into different modules, each responsible for controlling specific parts of the robot (e.g., legs or body).", "section": "1 Introduction"}, {"figure_path": "5DJBBACqim/figures/figures_2_1.jpg", "caption": "Figure 2: Effect of Modularity Objectives. Consider a module with 5 actuators, denoted in orange, trained to push a lever clockwise. As the state of the lever is a function of its angle \u03b8, a module trained by MeMo represents the control signals as a one-dimensional manifold with respect to B's signal. When noise is added to B's signal, the outputted actions remain on the manifold. Without MeMo, perturbations to B's signals cause deviations from the high reward trajectory.", "description": "This figure illustrates the impact of the modularity objective in MeMo on a robot arm task.  With MeMo, the worker module (W) learns a low-dimensional representation of the actions needed to control the lever, effectively mapping the boss module's (B) signal to an appropriate lever position. Adding noise to B's signal results in minimal impact on lever position because W maintains its narrow interface.  In contrast, without MeMo, W doesn't learn such a narrow interface, and noise in B's signal causes significant deviations from the desired trajectory. This highlights how MeMo's modularity objective forces the worker module to learn a more robust and efficient control strategy.", "section": "2 Motivation for Modularity Objectives"}, {"figure_path": "5DJBBACqim/figures/figures_3_1.jpg", "caption": "Figure 3: Noise Injection Error. Over the course of training, we compute ratio = |Lp|/(L1+L2) where Lp is the magnitude of the mean product term over the minibatch and L\u2081 and L2 are the mean behavior cloning and invariance to noise losses. We compute training statistics over 5 runs and indicate standard deviation by shaded areas. (Left)-(Right): For all starting morphologies, the modularity objectives dominate the loss as the ratio is less than 1 for all updates.", "description": "This figure shows the ratio of the magnitude of the mean product term to the sum of the behavior cloning loss and invariance to noise loss during training.  The ratio is consistently less than 1 across different robot morphologies (centipede, worm, hybrid, claw), indicating that the modularity objectives dominate the overall loss. The shaded areas represent the standard deviation over 5 training runs.", "section": "3.1 Objective"}, {"figure_path": "5DJBBACqim/figures/figures_4_1.jpg", "caption": "Figure 4: Training Pipeline Overview. In Phase 1, we first train an expert controller for the training robot using RL. In Phase 2, we pretrain modules with noise injection during imitation learning. In Phase 3, we transfer the modules to a different context and retrain the boss controller B3.", "description": "This figure illustrates the three-phase training pipeline used in the MeMo framework. Phase 1 involves training an expert controller using reinforcement learning (RL). Phase 2 uses imitation learning with noise injection to pretrain modular controllers.  Phase 3 transfers the pretrained modules to a new context (different robot morphology or task) and retrains the boss controller.", "section": "3 Method"}, {"figure_path": "5DJBBACqim/figures/figures_5_1.jpg", "caption": "Figure 5: Structure Transfer Tasks. Left: Transfer \"leg\" and \"body\" modules from a 6 to a 12 leg centipede. Left Middle: Transfer \"body\" and \"head\" modules from a 6 to a 10 leg worm. Right Middle: Transfer \"leg,\" \"head,\" and \"body\" modules from a 6 to a 10 leg hybrid. Right: Transfer \"arm\" and \"finger\" modules from a 4 to a 5 finger claw.", "description": "This figure shows four examples of structure transfer tasks used in the paper's experiments. Each example demonstrates transferring learned modules from a simpler robot morphology to a more complex one. The figure highlights the modularity of the approach by showing how specific modules (legs, body, head, arm, fingers) can be reused and adapted for different robot designs.", "section": "5.1 Transfer Learning"}, {"figure_path": "5DJBBACqim/figures/figures_6_1.jpg", "caption": "Figure 6: Structure Transfer Results. Left: 6 leg centipede to 12 leg centipede transfer on the Frozen Terrain. Left Middle: 6 leg worm to 10 leg worm transfer on the Frozen Terrain. Right Middle: 6 leg hybrid to 10 leg hybrid transfer on the Frozen Terrain. Right: 4 finger claw to 5 finger claw transfer on grasping a cube. The dashed orange line shows that the final performance of the closest baseline is achieved by MeMo within half of the total number of timesteps.", "description": "This figure presents the results of structure transfer experiments. Four different structure transfer tasks are shown, each comparing the performance of MeMo against several baselines.  The tasks involve transferring learned modules from a simpler robot morphology to a more complex one. The dashed orange lines highlight that MeMo achieves comparable or better performance than the best baseline within half the number of timesteps.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_6_2.jpg", "caption": "Figure 7: Task Transfer Results. Left: The first three plots show results on transferring from the 6 leg centipede walking over the Frozen Terrain to the same centipede walking over a terrain with ridges, a terrain with gaps, and a terrain with upward steps. Right: The last plot shows the transfer from a 4-finger claw grasping a cube to the same claw grasping a sphere. MeMo either has comparable training efficiency to the strongest baseline or outperforms all baselines.", "description": "This figure presents the results of task transfer experiments.  The left side shows three locomotion task transfer experiments, where a pretrained controller is tested on terrains with different levels of difficulty (ridges, gaps, steps) compared to its training terrain.  The right side shows a grasping task transfer experiment, comparing the ability to transfer a controller trained on grasping a cube to grasping a sphere.  The key takeaway is that MeMo demonstrates either comparable or superior performance in training efficiency compared to other methods.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_7_1.jpg", "caption": "Figure 8: Ablation Results. Left: MeMo outperforms all other variants that are pretrained with IL. Right: MeMo outperforms all variants that pretrain modules with RL. In both settings, MeMo achieves the final performance of the closest baseline within half of the total number of timesteps.", "description": "This figure presents the results of ablation studies performed to analyze the impact of different components of the MeMo framework. The left panel shows the results of ablations on the imitation learning (IL) stage, comparing the performance of MeMo against variants without noise injection, with L1 or L2 regularization, or using Jacobian penalty. The right panel shows results of ablations on the reinforcement learning (RL) stage, comparing MeMo's performance against a standard modular RL approach and variants with naive or selective noise injection during RL pretraining.  The results demonstrate MeMo's superior performance in sample efficiency compared to all variants.", "section": "5.3 Ablation Study"}, {"figure_path": "5DJBBACqim/figures/figures_8_1.jpg", "caption": "Figure 9: Singular Value Distributions of Actuator-Boss Jacobians. For modular architectures trained with and without the noise injection, we plot the normalized singular values of Jacobian matrices over an expert\u2019s trajectories. With noise injection, the mass of the distribution is much closer to 0, showing that the modules learn better representations of the actuator space.", "description": "This figure compares the singular value distributions of the Jacobian matrices of the actuator-boss for models trained with and without noise injection.  The singular values represent the sensitivity of the modules' outputs to changes in the boss controller's signal. The distribution's mass being closer to 0 for models trained with noise injection indicates that those models have learned a more efficient and compact representation of the actuator space, making the modules more robust to noise and more easily transferable.", "section": "5.4 Analysis"}, {"figure_path": "5DJBBACqim/figures/figures_12_1.jpg", "caption": "Figure 10: Modular Architecture with Noise Injection. Our architecture consists of a higher-level boss controller B that outputs a hidden embedding, x. During imitation learning, Gaussian noise is added to x to compute H. H is split into signals that are passed into modules that output the mean of the action distribution. The dotted lines represent that in addition to H, the modules also take in subsets of the full observation vector corresponding to the state of the joints within the modules.", "description": "This figure illustrates the modular architecture of MeMo, showing how a higher-level \"boss\" controller (B) processes the robot's global and local observations.  It then uses these observations, along with added noise, to generate signals for lower-level \"worker\" modules (W). Each worker module is responsible for controlling a specific part of the robot, enabling modularity and transferability to other robot morphologies.", "section": "3.2 Modular Architecture and Training Pipeline"}, {"figure_path": "5DJBBACqim/figures/figures_12_2.jpg", "caption": "Figure 11: Module Subgraph and Architecture. Left: Module W\u2081 is responsible for computing the mean actions of actuators 0 and 1. Right: A module consists of separate networks that compute each actuator's mean action. The inputs include the local observations of the actuator concatenated with the signal sent to the module it belongs to.", "description": "This figure shows the internal structure of a module in the MeMo architecture.  The left panel illustrates a subgraph representing how actuators are grouped into modules. The right panel shows the detailed architecture of a single module (W\u1d62),  which consists of separate Multilayer Perceptrons (MLPs) for each actuator in the module. Each MLP takes as input both local observations specific to that actuator and a shared signal from the boss controller.  This modular design is crucial for the transferability of the controller to different robot morphologies.", "section": "3.2 Modular Architecture and Training Pipeline"}, {"figure_path": "5DJBBACqim/figures/figures_18_1.jpg", "caption": "Figure 12: Fixed NerveNet-Conv on 6 to 12 Leg Centipede Transfer. All weights of the NerveNet-Conv baseline, pretrained on the 6 leg centipede, are fixed during transfer to the 12 leg centipede on the Frozen Terrain, resulting in suboptimal performance.", "description": "This figure shows the results of transferring a pretrained NerveNet-Conv model from a 6-legged centipede to a 12-legged centipede while keeping all weights fixed.  The experiment is performed on the \"Frozen Terrain\" task. The plot shows that the reward obtained remains consistently low, indicating that the model fails to adapt effectively to the new morphology and significantly underperforms compared to fine-tuning or retraining.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_18_2.jpg", "caption": "Figure 6: Structure Transfer Results. Left: 6 leg centipede to 12 leg centipede transfer on the Frozen Terrain. Left Middle: 6 leg worm to 10 leg worm transfer on the Frozen Terrain. Right Middle: 6 leg hybrid to 10 leg hybrid transfer on the Frozen Terrain. Right: 4 finger claw to 5 finger claw transfer on grasping a cube. The dashed orange line shows that the final performance of the closest baseline is achieved by MeMo within half of the total number of timesteps.", "description": "This figure presents the results of structure transfer experiments on four different robotic morphologies.  The plots show the learning curves (reward vs. timesteps) for MeMo and several baseline methods on each transfer task. The dashed orange lines highlight MeMo's improved sample efficiency, reaching the performance of the best baseline method in fewer training steps.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_19_1.jpg", "caption": "Figure 6: Structure Transfer Results. Left: 6 leg centipede to 12 leg centipede transfer on the Frozen Terrain. Left Middle: 6 leg worm to 10 leg worm transfer on the Frozen Terrain. Right Middle: 6 leg hybrid to 10 leg hybrid transfer on the Frozen Terrain. Right: 4 finger claw to 5 finger claw transfer on grasping a cube. The dashed orange line shows that the final performance of the closest baseline is achieved by MeMo within half of the total number of timesteps.", "description": "This figure presents the results of structure transfer experiments across four different robotic morphologies.  It showcases the performance of MeMo (the proposed method) compared to several baselines (RL with MLP, RL with modular architecture, pretrained NerveNet-Conv, pretrained NerveNet-Snowflake, and pretrained MetaMorph).  Each subplot shows the training curves for a specific transfer task. For example, the first subplot displays the results of transferring a controller trained on a 6-legged centipede to a 12-legged centipede. The dashed orange line highlights the improved training efficiency of MeMo, achieving comparable performance to the best baseline in considerably fewer training steps.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_19_2.jpg", "caption": "Figure 5: Structure Transfer Tasks. Left: Transfer \u201cleg\u201d and \u201cbody\u201d modules from a 6 to a 12 leg centipede. Left Middle: Transfer \u201cbody\u201d and \u201chead\u201d modules from a 6 to a 10 leg worm. Right Middle: Transfer \u201cleg,\u201d \u201chead,\u201d and \u201cbody\u201d modules from a 6 to a 10 leg hybrid. Right: Transfer \u201carm\u201d and \u201cfinger\u201d modules from a 4 to a 5 finger claw.", "description": "This figure shows four different structure transfer tasks used to evaluate the MeMo framework.  Each task involves transferring learned modules from a simpler robot morphology to a more complex one.  The tasks showcase MeMo's ability to generalize across various robot designs by reusing previously learned modules.  The simpler robots are 6-legged centipedes, 6-legged worms, 6-legged hybrids, and 4-fingered claws; the more complex robots are 12-legged centipedes, 10-legged worms, 10-legged hybrids, and 5-fingered claws, respectively.", "section": "5.1 Transfer Learning"}, {"figure_path": "5DJBBACqim/figures/figures_19_3.jpg", "caption": "Figure 16: Additional Singular Value Distributions. Left: For various ablations of MeMo, we plot the normalized singular values of Jacobian matrices computed over an expert\u2019s trajectories. With noise injection, the mass of the distribution is much closer to 0. Right: With injected noise sampled from a Gaussian distribution with standard deviation 0.5 instead of 1.0, the mass of the distribution is closer to 1.", "description": "This figure shows the distribution of normalized singular values of Jacobian matrices for different versions of the MeMo algorithm.  The left plot compares MeMo with ablations (removing noise injection or using L1/L2 regularization instead). It demonstrates that noise injection is key to producing a distribution where most singular values are close to zero, indicating a lower-dimensional representation of the actuator space. The right plot shows that even with less noise (standard deviation 0.5 instead of 1.0), the distribution shifts towards having more singular values closer to 1, highlighting the importance of sufficient noise for this effect.", "section": "5.4 Analysis"}, {"figure_path": "5DJBBACqim/figures/figures_20_1.jpg", "caption": "Figure 17: Architecture Variants of MeMo on 6 to 12 Leg Centipede Transfer: We run experiments where either the size of the boss controller or the size of the modules is increased from 2 to 4 layers. Both of these variants achieve comparable performance to the original architecture with 2 layer MLPs.", "description": "This figure shows the results of an ablation study on the MeMo architecture.  The experiment involved transferring a controller trained on a 6-legged robot to a 12-legged robot. Three different architectures were compared: the original MeMo architecture, a variant with a 4-layer boss controller, and a variant with 4-layer modules.  The results show that all three architectures achieve comparable performance, indicating the robustness of the MeMo approach to variations in network depth.", "section": "5.2 Results"}, {"figure_path": "5DJBBACqim/figures/figures_20_2.jpg", "caption": "Figure 5: Structure Transfer Tasks. Left: Transfer \u201cleg\u201d and \u201cbody\u201d modules from a 6 to a 12 leg centipede. Left Middle: Transfer \u201cbody\u201d and \u201chead\u201d modules from a 6 to a 10 leg worm. Right Middle: Transfer \u201cleg\u201d, \u201chead\u201d, and \u201cbody\u201d modules from a 6 to a 10 leg hybrid. Right: Transfer \u201carm\u201d and \u201cfinger\u201d modules from a 4 to a 5 finger claw.", "description": "This figure demonstrates four different structure transfer tasks used in the paper's experiments.  Each task involves transferring pre-trained modules (representing robot components like legs or arms) from a simpler robot morphology to a more complex one.  The figure visually shows the initial and final robot morphologies for each transfer task, illustrating how the pre-trained modules are reused and adapted to control the new, more complex robot.", "section": "5.1 Transfer Learning"}, {"figure_path": "5DJBBACqim/figures/figures_21_1.jpg", "caption": "Figure 19: Graph Structure and Modules of the 6 Leg Worm. Left: Rendered robot, with joints labeled numerically and circled. Right: Corresponding graph structure with joints as nodes and links as edges. The joints circled in red can be thought of the \"head\" while the joints circled in blue form the \"body\" modules.", "description": "This figure shows the 6-leg worm robot and its corresponding graph representation.  The left panel displays a rendered image of the robot, with each joint numerically labeled and circled. The right panel presents a graph where nodes represent joints and edges represent connections between joints.  Crucially, the joints grouped as \"head\" modules are circled in red, while those forming the \"body\" modules are circled in blue.  This visualization illustrates the modular structure that the MeMo framework leverages for controller design.", "section": "5.1 Transfer Learning"}, {"figure_path": "5DJBBACqim/figures/figures_21_2.jpg", "caption": "Figure 1: Graph Structure and Neural Network Modules of the 6 Leg Centipede. Left: The robot's joints are labeled numerically and circled. Right: The joints form the nodes and the links are the edges. The subset of joints that form each leg module are circled in red, while those that comprise each body module are circled in blue. Neural network modules are denoted as W, where k refers to the type, e.g. all leg modules are type 0, and i denotes different instances of the same module type.", "description": "This figure shows the graph structure representation of a six-legged robot. The left panel shows a physical rendering of the robot with its joints numerically labeled.  The right panel provides an abstract graph representation of the robot where nodes represent joints and edges represent connections between joints.  The figure highlights how the joints are grouped into modules; those forming legs are circled in red, while those forming the body are circled in blue.  Each module will be associated with a neural network for control.", "section": "1 Introduction"}, {"figure_path": "5DJBBACqim/figures/figures_21_3.jpg", "caption": "Figure 19: Graph Structure and Modules of the 6 Leg Worm. Left: Rendered robot, with joints labeled numerically and circled. Right: Corresponding graph structure with joints as nodes and links as edges. The joints circled in red can be thought of the \"head\" while the joints circled in blue form the \"body\" modules.", "description": "This figure shows the graph structure and the neural network modules for a 6-legged worm robot.  The left panel shows a rendered image of the robot with its joints numerically labeled. The right panel provides a graphical representation of the robot's structure as a graph, where each node is a joint and each edge indicates a connection between joints. The joints comprising the \"head\" module are highlighted in red, while those forming the \"body\" modules are highlighted in blue.  This visualization aids in understanding how the robot's morphology is represented in a modular way for control purposes within the MeMo framework.", "section": "5.1 Transfer Learning"}, {"figure_path": "5DJBBACqim/figures/figures_22_1.jpg", "caption": "Figure 10: Modular Architecture with Noise Injection. Our architecture consists of a higher-level boss controller B that outputs a hidden embedding, x. During imitation learning, Gaussian noise is added to x to compute H. H is split into signals that are passed into modules that output the mean of the action distribution. The dotted lines represent that in addition to H, the modules also take in subsets of the full observation vector corresponding to the state of the joints within the modules.", "description": "This figure shows the modular architecture of the MeMo framework.  It depicts a hierarchical structure where a higher-level \"boss\" controller (B) processes the overall robot state and generates a hidden embedding (x).  Gaussian noise is injected into this embedding before being split and fed into individual lower-level worker modules (W). Each module is responsible for controlling a specific assembly of the robot, shown as different colored circles. Importantly, each module also receives a subset of the full observation vector related specifically to the joints it controls (shown as dotted lines).", "section": "3.2 Modular Architecture and Training Pipeline"}]