[{"figure_path": "m5dyKArVn8/figures/figures_4_1.jpg", "caption": "Figure 1: Polarizations \u03b7\u03c1 obtained from ResNet18 trained on CIFAR-10 with various sets of hyper-parameters tested on (a) an out-of-sample CIFAR-10 and (b) an out-of-distribution dataset, CIFAR-10.1. Red dashed line indicates y = 4/3, a suggested value of polarization appears in Theorem 1 and Conjecture 1.", "description": "This figure shows the polarization (\u03b7\u03c1) values obtained from ResNet18 models trained on CIFAR-10, tested on both in-distribution (CIFAR-10) and out-of-distribution (CIFAR-10.1) datasets.  Each point represents a different set of hyperparameters used during training. The red dashed line represents the theoretical value of 4/3, which is predicted by the neural polarization law proposed in the paper.  The figure aims to support the conjecture that interpolating neural networks have a polarization close to 4/3, regardless of the dataset or hyperparameters.", "section": "3 The Polarization of an Ensemble"}, {"figure_path": "m5dyKArVn8/figures/figures_5_1.jpg", "caption": "Figure 1: Polarizations \u03b7\u03c1 obtained from ResNet18 trained on CIFAR-10 with various sets of hyper-parameters tested on (a) an out-of-sample CIFAR-10 and (b) an out-of-distribution dataset, CIFAR-10.1. Red dashed line indicates y = 4/3, a suggested value of polarization appears in Theorem 1 and Conjecture 1.", "description": "This figure shows the polarization (\u03b7\u03c1) values obtained from various experiments using ResNet18 trained on CIFAR-10.  The experiments vary hyperparameters and test on both in-distribution (CIFAR-10) and out-of-distribution (CIFAR-10.1) datasets. The plots illustrate that the polarization is relatively constant across different hyperparameter settings and datasets, and is approximately 4/3.  This supports the paper's Conjecture 1, the Neural Polarization Law, suggesting that most interpolating neural network models have a polarization of 4/3.", "section": "3 The Polarization of an Ensemble"}, {"figure_path": "m5dyKArVn8/figures/figures_5_2.jpg", "caption": "Figure 2: Polarization \u03b7\u03c1 obtained (a) from various architectures trained on CIFAR-10 and (b) only from interpolating classifiers trained on various datasets. Red dashed line indicates y = 4/3. In subplot (b), we observe that the polarization of all interpolating models expect one are smaller than 4/3, which aligns with Conjecture 1.", "description": "This figure visualizes the polarization (\u03b7\u03c1) of different ensemble models trained on various datasets. Subplot (a) shows the polarization for different neural network architectures trained on CIFAR-10, while subplot (b) focuses on interpolating models across various datasets.  A red dashed line at y=4/3 is shown as a reference, representing the neural polarization law proposed in the paper. The figure supports the paper's conjecture that most interpolating neural networks are 4/3-polarized, with the majority of points falling below this line.", "section": "3 The Polarization of an Ensemble"}, {"figure_path": "m5dyKArVn8/figures/figures_6_1.jpg", "caption": "Figure 3: Comparing our new bound from Corollary 1 (colored black), which is the right hand side of inequality (10), with bounds from previous studies. Green corresponds to the C-bound in inequality (3), and blue corresponds to the right hand side of inequality (6). ResNet18, ResNet50, ResNet101 models with various sets of hyperparameters are trained on CIFAR-10 then tested on (a) the out-of-sample CIFAR-10, (b) an out-of-distribution dataset, CIFAR-10.1", "description": "This figure compares the new bound on the majority vote error rate from Corollary 1 with existing bounds from previous works.  The plot shows that the new bound is tighter than the previous bounds for both in-distribution (CIFAR-10) and out-of-distribution (CIFAR-10.1) datasets.  Different ResNet models and hyperparameters were used, demonstrating the bound's efficacy across various settings.", "section": "4 Entropy-Restricted Ensembles"}, {"figure_path": "m5dyKArVn8/figures/figures_8_1.jpg", "caption": "Figure 3: Comparing our new bound from Corollary 1 (colored black), which is the right hand side of inequality (10), with bounds from previous studies. Green corresponds to the C-bound in inequality (3), and blue corresponds to the right hand side of inequality (6). ResNet18, ResNet50, ResNet101 models with various sets of hyperparameters are trained on CIFAR-10 then tested on (a) the out-of-sample CIFAR-10, (b) an out-of-distribution dataset, CIFAR-10.1", "description": "This figure compares the new upper bound on the majority vote error rate derived in Corollary 1 with existing bounds from previous studies.  It shows the majority vote error rate against different upper bounds for two datasets: CIFAR-10 (in-distribution) and CIFAR-10.1 (out-of-distribution).  ResNet18, ResNet50, and ResNet101 models with varying hyperparameters were used. The plot demonstrates that the new bound (black line) provides a tighter estimation of the majority vote error rate compared to previous bounds (green and blue lines).", "section": "4 Entropy-Restricted Ensembles"}]