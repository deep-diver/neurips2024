[{"type": "text", "text": "How many classifiers do we need? ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hyunsuk Kim ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Statistics University of California, Berkeley hyskim7@berkeley.edu ", "page_idx": 0}, {"type": "text", "text": "Liam Hodgkinson School of Mathematics and Statistics University of Melbourne, Australia lhodgkinson@unimelb.edu.au ", "page_idx": 0}, {"type": "text", "text": "Ryan Theisen ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Harmonic Discovery ryan@harmonicdiscovery.com ", "page_idx": 0}, {"type": "text", "text": "Michael W. Mahoney ICSI, LBNL, and Dept. of Statistics University of California, Berkeley mmahoney@stat.berkeley.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As performance gains through scaling data and/or model size experience diminishing returns, it is becoming increasingly popular to turn to ensembling, where the predictions of multiple models are combined to improve accuracy. In this paper, we provide a detailed analysis of how the disagreement and the polarization (a notion we introduce and define in this paper) among classifiers relate to the performance gain achieved by aggregating individual classifiers, for majority vote strategies in classification tasks. We address these questions in the following ways. (1) An upper bound for polarization is derived, and we propose what we call a neural polarization law: most interpolating neural network models are $4/3$ -polarized. Our empirical results not only support this conjecture but also show that polarization is nearly constant for a dataset, regardless of hyperparameters or architectures of classifiers. (2) The error of the majority vote classifier is considered under restricted entropy conditions, and we present a tight upper bound that indicates that the disagreement is linearly correlated with the target, and that the slope is linear in the polarization. (3) We prove results for the asymptotic behavior of the disagreement in terms of the number of classifiers, which we show can help in predicting the performance for a larger number of classifiers from that of a smaller number. Our theories and claims are supported by empirical results on several image classification tasks with various types of neural networks. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As performance gains through scaling data and/or model size experience diminishing returns, it is becoming increasingly popular to turn to ensembling, where the predictions of multiple models are combined, both to improve accuracy and to form more robust conclusions than any individual model alone can provide. In some cases, ensembling can produce substantial benefits, particularly when increasing model size becomes prohibitive. In particular, for large neural network models, deep ensembles [LPB17] are especially popular. These ensembles consist of independently trained models on the same dataset, often using the same hyperparameters, but starting from different initializations. ", "page_idx": 0}, {"type": "text", "text": "The cost of producing new classifiers can be steep, and it is often unclear whether the additional performance gains are worth the cost. Assuming that constructing two or three classifiers is relatively cheap, procedures capable of deciding whether to continue producing more classifiers are needed. To do so requires a precise understanding of how to predict ensemble performance. Of particular interest are majority vote strategies in classification tasks, noting that regression tasks can also be formulated in this way by clustering outputs. In this case, one of the most effective avenues for predicting performance is the disagreement [JNBK22, BJRK22]: measuring the degree to which classifiers provide different conclusions over a given dataset. Disagreement is concrete, easy to compute, and strongly linearly correlated with majority vote prediction accuracy, leading to its use in many applications. However, a priori, the precise linear relationship between disagreement and accuracy is unclear, preventing the use of disagreement for predicting ensemble performance. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Our goal in this paper is to go beyond disagreement-based analysis to provide a more quantitative understanding of the number of classifiers one should use to achieve a desired level of performance in modern practical applications, in particular for neural network models. In more detail, our contributions are as follows. ", "page_idx": 1}, {"type": "text", "text": "(i) We introduce and define the concept of polarization, a notion that measures the higherorder dispersity of the error rates at each data point, and which indicates how polarized the ensemble is from the ground truth. We state and prove an upper bound for polarization (Theorem 1). Inspired by the theorem, we propose what we call a neural polarization law (Conjecture 1): most interpolating (Definition 2) neural network models are 4/3-polarized. We provide empirical results supporting the conjecture (Figures 1 and 2). ", "page_idx": 1}, {"type": "text", "text": "(ii) Using the notion of polarization, we develop a refined set of bounds on the majority vote test error rate. For one, we provide a sharpened bound for any ensembles with a finite number of classifiers (Corollary 1). For the other, we offer a tighter-than-ever bound under an additional condition on the entropy of the ensemble (Theorem 4). We provide empirical results that demonstrate our new bounds perform significantly better than the existing bounds on the majority vote test error (Figure 3). ", "page_idx": 1}, {"type": "text", "text": "(iii) The asymptotic behavior of the majority vote error rate is determined as the number of classifiers increases (Theorem 5). Consequently, we show that we can predict the performance for a larger number of classifiers from that of a smaller number. We provide empirical results that show such predictions are considerably accurate across various pairs of model architecture and dataset (Figure 4). ", "page_idx": 1}, {"type": "text", "text": "In Section 2, we define the notations that will be used throughout the paper, and we introduce upper bounds for the error rate of the majority vote from previous work. The next three sections are the main part of the paper. In Section 3, we introduce the notion of polarization, $\\eta_{\\rho}$ , which plays a fundamental role in relating the majority vote error rate to average error rate and disagreement. We explore the properties of the polarization and present empirical results that corroborate our claims. In Section 4, we present tight upper bounds for the error rate of the majority vote for ensembles that satisfy certain conditions; and in Section 5, we prove how disagreement behaves in terms of the number of classifiers. All of these ingredients are put together to estimate the error rate of the majority vote for a large number of classifiers using information from only three sampled classifiers. In Section 6, we provide a brief discussion and conclusion. Additional material is presented in the appendices. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we introduce notation that we use throughout the paper, and we summarise previous work on the performance of the majority vote error rate. ", "page_idx": 1}, {"type": "text", "text": "2.1 Notations ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We focus on $K$ -class classification problems, with features $X\\in\\mathcal{X}$ , labels $Y\\in[K]=\\{1,2,...,K\\}$ and feature-label pairs $(X,Y)\\sim{\\mathcal{D}}$ . A classifier $h:{\\mathcal{X}}\\to[K]$ is a function that maps a feature to a label. We define the error rate of a single classifier $h$ , and the disagreement and the tandem loss [MLIS20] between two classifiers, $h$ and $h^{\\prime}$ , as the following: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathrm{Error~rate:~}L(h)=\\mathbb{E}_{\\mathcal{D}}[\\mathbb{1}(h(X)\\neq Y)]}\\\\ &{\\mathrm{Disagreement:~}D(h,h^{\\prime})=\\mathbb{E}_{\\mathcal{D}}[\\mathbb{1}(h(X)\\neq h^{\\prime}(X))]}\\\\ &{\\quad\\mathrm{Tandem~loss:~}L(h,h^{\\prime})=\\mathbb{E}_{\\mathcal{D}}[\\mathbb{1}(h(X)\\neq Y)\\mathbb{1}(h^{\\prime}(X)\\neq Y)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where the expectation $\\mathbb{E}_{\\mathcal{D}}$ is used to denote $\\mathbb{E}_{(X,Y)\\sim{\\cal D}}$ . Next, we consider a distribution of classifiers, $\\rho$ , which may be viewed as an ensemble of classifiers. This distribution can represent a variety of different cases. Examples include: (1) a discrete distribution over finite number of $h_{i}$ , e.g., a weighted sum of $h_{i}$ ; and (2) a distribution over a parametric family $h_{\\theta}$ , e.g., a distribution of classifiers resulting from one or multiple trained neural networks. Given the ensemble $\\rho$ , the (weighted) majority vote $h_{\\rho}^{\\mathrm{MV}}:{\\mathcal{X}}\\to[K]$ is defined as ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\nh_{\\rho}^{\\mathrm{MV}}(x)=\\underset{y\\in[K]}{\\arg\\operatorname*{max}}~\\mathbb{E}_{\\rho}[\\mathbb{1}(h(x)=y)].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Again, $\\mathbb{E}_{\\rho}$ denotes $\\mathbb{E}_{h\\sim\\rho}$ , and we use $\\mathbb{E}_{\\rho},\\mathbb{E}_{\\rho^{2}},\\mathbb{P}_{\\rho}$ for $\\mathbb{E}_{h\\sim\\rho},\\mathbb{E}_{(h,h^{\\prime})\\sim\\rho^{2}},\\mathbb{P}_{h\\sim\\rho}$ , respectively, throughout the paper. In this sense, $\\mathbb{E}_{\\rho}[L(h)]$ represents the average error rate under a distribution of classifiers $\\rho$ and $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ represents the average disagreement between classifiers under $\\rho$ . Hereafter, we refer to $\\mathbb{E}_{\\rho}[L(h)],\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ , and $L(h_{\\rho_{\\!\\circ}}^{\\mathrm{MV}})$ as the average error rate, the disagreement, and the majority vote error rate, respectively, with ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})=\\mathbb{E}_{\\mathcal{D}}[\\mathbb{1}(h_{\\rho}^{\\mathrm{MV}}(X)\\neq Y)].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Lastly, we define the point-wise error rate, $W_{\\rho}(X,Y)$ , which will serve a very important role in this paper (for clarity, we will denote $W_{\\rho}(X,Y)$ by $W_{\\rho}$ unless otherwise necessary): ", "page_idx": 2}, {"type": "equation", "text": "$$\nW_{\\rho}(X,Y)=\\mathbb{E}_{\\rho}[\\mathbb{1}(h(X)\\neq Y)].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "2.2 Bounds on the majority vote error rate ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The simplest relationship between the majority vote error $L(h_{\\rho}^{\\mathrm{MV}})$ and the average error rate $\\mathbb{E}_{\\rho}[L(h)]$ was introduced in [McA98]. It states that the error in the majority vote classifier cannot exceed twice the average error rate: ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq2\\mathbb{E}_{\\rho}[L(h)]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "A simple proof for this relationship can be found in [MLIS20] using Markov\u2019s inequality. Although (2) does not provide useful information in practice, it is worth noting that this bound is, in fact, tight. There exist pathological examples where $h_{\\rho}^{\\mathrm{MV}}$ exhibits twice the average error rate (see Appendix C in $[\\mathrm{TKY^{+}24}]$ . This suggests that we can hardly obtain a useful or tighter bound by relying on only the \u201cfirst-order\u201d term, $\\mathbb{E}_{\\rho}[L(h)]$ . ", "page_idx": 2}, {"type": "text", "text": "Accordingly, more recent work constructed bounds in terms of \u201csecond-order\u201d quantities, $\\mathbb{E}_{\\rho^{2}}[L(h,\\bar{h^{\\prime}})]$ and $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ . In particular, [LMRR17] and [MLIS20] designed a so-called $C$ -bound using the Chebyshev-Cantelli inequality, establishing that, if $\\mathbb{E}_{\\rho}[L(h)]<1/2$ , then ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\frac{\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]-\\mathbb{E}_{\\rho}[L(h)]^{2}}{\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]-\\mathbb{E}_{\\rho}[L(h)]+\\frac{1}{4}}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "As an alternative approach, [MLIS20] incorporated the disagreement $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ into the bound as well, albeit restricted to the binary classification problem, to obtain: ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq4\\mathbb{E}_{\\rho}[L(h)]-2\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "While (3) and (4) may be tighter in some cases, once again, there do exist pathological examples where this bound is as uninformative as the first-order bound (2). Motivated by these weak results, $[\\mathrm{TKY^{+}24}]$ take a new approach by restricting $\\rho$ to be a \u201cgood ensemble,\u201d and introducing the competence condition (see Definition 3 in our Appendix A). Informally, competent ensembles are those where it is more likely\u2014in average across the data\u2014that more classifiers are correct than not. Based on this notion, $[\\mathrm{TKY}^{+}24]$ prove that competent ensembles are guaranteed to have weighted majority vote error smaller than the weighted average error of individual classifiers: ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\mathbb{E}_{\\rho}[L(h)].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "That is, the majority vote classifier is always beneficial. Moreover, $[\\mathrm{TKY^{+}24}]$ proves that any competent ensemble $\\rho$ of $K$ -class classifiers satisfy the following inequality. ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\frac{4(K-1)}{K}\\left(\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "We defer further discussion of competence to Appendix A, where we introduce simple cases for which competence does not hold. In these cases, we show how one can overcome this issue so that the bounds (5) and (6) still hold. In particular, in Appendix A.3, we provide an example to show the bound (6) is tight. ", "page_idx": 2}, {"type": "text", "text": "3 The Polarization of an Ensemble ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce a new quantity, $\\eta_{\\rho}$ , which we refer to as the polarization of an ensemble $\\rho$ . First, we provide examples as to what this quantity represents and draw a connection to previous studies. Then, we present theoretical and empirical results that show this quantity plays a fundamental role in relating the majority vote error rate to average error rate and disagreement. In Theorem 1, we prove an upper bound for the polarization $\\eta_{\\rho}$ , which highlights a fundamental relationship between the polarization and the constant $\\textstyle{\\frac{4}{3}}$ . Inspired from the theorem, we propose Conjecture 1 which we call a neural polarization law. Figures 1 and 2 present empirical results on an image recognition task that corroborates the conjecture. ", "page_idx": 3}, {"type": "text", "text": "We start by defining the polarization of an ensemble. In essence, the polarization is an improved (smaller) coefficient on the Markov\u2019s inequality on $\\mathbb{P}_{D}(W_{\\rho}>0.5)$ , where $W_{\\rho}$ is the point-wise error rate defined as equation (1). It measures how much the ensemble is \u201cpolarized\u201d from the truth, with consideration of the distribution of $W_{\\rho}$ . ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (POLARIZATION). An ensemble $\\rho$ is $\\eta$ -polarized if ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\eta\\mathbb{E}_{\\mathcal{D}}[W_{\\rho}^{2}]\\geq\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>1/2).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The polarization of an ensemble $\\rho$ is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\eta_{\\rho}:=\\frac{\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>1/2)}{\\mathbb{E}_{\\mathcal{D}}[W_{\\rho}^{2}]},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is the smallest value of $\\eta$ satisfies inequality (7). ", "page_idx": 3}, {"type": "text", "text": "Note that the polarization always takes a value in $[0,4]$ , due to the positivity constraint and Markov\u2019s inequality. Also note that ensemble $\\rho$ with polarization $\\eta_{\\rho}$ is $\\eta$ -polarized for any $\\eta\\geq\\eta_{\\rho}$ . ", "page_idx": 3}, {"type": "text", "text": "To understand better what this quantity represents, consider the following examples. The first example demonstrates that polarization increases as the majority vote becomes more polarized from the truth, while the second example demonstrates how polarization increases when the constituent classifiers are more evenly split. ", "page_idx": 3}, {"type": "text", "text": "Example 1. Consider an ensemble $\\rho$ where $75\\%$ of classifiers output Label 1 with probability one, and the other $25\\%$ classifiers output Label 2 with probability one. ", "page_idx": 3}, {"type": "text", "text": "- Case 1. The true label is Label 1 for the whole data. In this case, the majority vote in $\\rho$ results in zero error rate. The point-wise error rate $W_{\\rho}$ is 0.25 on the entire dataset, and thus $\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>0.5)=0$ . The polarization $\\eta_{\\rho}$ is 0.   \n- Case 2. The true label is Label 1 for half of the data and is Label 2 for the other half. In this case, the majority vote is only correct for half of the data. The point-wise error rate $W_{\\rho}$ is 0.25 for this half, and is 0.75 for the other half. The polarization $\\eta_{\\rho}$ is $0.5/0.3125=1.6\\$ .   \n- Case 3. The true label is Label 2 for the whole data. In this case, the majority vote in $\\rho$ is wrong on every data point. The point-wise error rate $W_{\\rho}$ is 0.75 on the entire dataset and thus $\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>0.5)=1$ . The polarization $\\eta_{\\rho}$ is $1/0.3125=3.{\\dot{2}}$ . ", "page_idx": 3}, {"type": "text", "text": "Example 2. Now consider an ensemble $\\rho$ of which $51\\%$ of classifiers always output Label 1, and the other $49\\%$ classifiers always output Label 2. ", "page_idx": 3}, {"type": "text", "text": "Case 1. The polarization $\\eta_{\\rho}$ is now 0, the same as in Example 1 ", "page_idx": 3}, {"type": "text", "text": "Case 2. The polarization $\\eta_{\\rho}$ is $0.5/0.2501\\approx2$ , which is larger than 1.6 in Example 1. ", "page_idx": 3}, {"type": "text", "text": "Case 3. The polarization $\\eta_{\\rho}$ is now $1/0.2501\\approx4$ , which is larger than 3.2 in Example 1. ", "page_idx": 3}, {"type": "text", "text": "In addition, the following proposition draws a connection between polarization and the competence condition mentioned in Section 2.2. It states that the polarization of competent ensembles cannot be very large. The proof is deferred to Appendix A.2. ", "page_idx": 3}, {"type": "text", "text": "Proposition 1. Competent ensembles are 2-polarized. ", "page_idx": 3}, {"type": "text", "text": "Now we delve more into this new quantity. We introduce Theorem 1, which establishes (by means of concentration inequalities) an upper bound on the polarization $\\eta_{\\rho}$ . The proof of Theorem 1 is deferred to Appendix B.1. ", "page_idx": 3}, {"type": "image", "img_path": "m5dyKArVn8/tmp/16c3d19b76cbd714b612dd89c5f7b706c95ab1c45f603524029d1d61058a7eec.jpg", "img_caption": ["Figure 1: Polarizations $\\eta_{\\rho}$ obtained from ResNet18 trained on CIFAR-10 with various sets of hyper-parameters tested on (a) an out-of-sample CIFAR-10 and (b) an out-of-distribution dataset, CIFAR-10.1. Red dashed line indicates $y\\,=\\,4/3$ , a suggested value of polarization appears in Theorem 1 and Conjecture 1. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Theorem 1. Let $\\{(X_{i},Y_{i})\\}_{i=1}^{m}$ be independent and identically distributed samples from $\\mathcal{D}$ that are independent of an ensemble $\\rho$ . Then the polarization of the ensemble, $\\eta_{\\rho}$ , satisfies ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\eta_{\\rho}\\leq\\operatorname*{max}\\left\\{\\frac{4}{3},\\left(\\frac{\\sqrt{\\frac{3}{8m}\\log\\frac{1}{\\delta}}+\\sqrt{\\frac{3}{8m}\\log\\frac{1}{\\delta}+4S P}}{2S}\\right)^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with probability at least $1-\\delta$ , where $\\begin{array}{r}{S=\\frac{1}{m}\\sum_{i=1}^{m}W_{\\rho}^{2}(X_{i},Y_{i})}\\end{array}$ and $P=\\textstyle{\\frac{1}{m}}\\mathbb{1}(W_{\\rho}(X_{i},Y_{i})>1/2)$ . ", "page_idx": 4}, {"type": "text", "text": "Surprisingly, in practice, $\\begin{array}{l}{\\eta_{\\rho}\\,=\\,\\frac{4}{3}}\\end{array}$ appears to be a good choice for a wide variety of cases. See Figure 1 and Figure 2, which show the polarization $\\eta_{\\rho}$ obtained from VGG11 [SZ14], DenseNet40 [HLVDMW17], ResNet18, ResNet50 and ResNet101 [HZRS16] trained on CIFAR-10 [Kri09] with various hyperparameters choices. The trend does not deviate even when evaluated on an out-ofdistribution dataset, CIFAR-10.1 [RRSS18, TFF08]. For more details on these empirical results, see Appendix C. ", "page_idx": 4}, {"type": "text", "text": "Remark. We emphasize that values for $\\eta_{\\rho}$ that are larger than $\\frac{4}{3}$ does not contradict Theorem 1. This happens when the non-constant second term in (9) is larger than $\\begin{array}{l}{{\\frac{4}{3}}}\\end{array}$ , which is often the case for classifiers which are not interpolating (or, indeed, that underfit or perform poorly). ", "page_idx": 4}, {"type": "text", "text": "Definition 2 (INTERPOLATING, [BHMM19]). A classifier is interpolating if it achieves an accuracy of $I O O\\%$ on the training data. ", "page_idx": 4}, {"type": "text", "text": "Putting Theorem 1 and the consistent empirical trend shown in Figure 2(b) together, we propose the following conjecture. ", "page_idx": 4}, {"type": "text", "text": "Conjecture 1 (NEURAL POLARIZATION LAW). The polarization of ensembles comprised of independently trained interpolating neural networks is smaller than $\\begin{array}{l}{{\\frac{4}{3}}}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "4 Entropy-Restricted Ensembles ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we first present an upper bound on the majority vote error rate, $L(h_{\\rho}^{\\mathrm{MV}})$ , in Theorem 2, using our notion of polarization $\\eta_{\\rho}$ which we introduced and defined in the previous section. Then, we present Theorems 3 and 4 which are the main elements in obtaining tighter upper bounds on $L({\\dot{h_{\\rho}^{\\mathrm{MV}}}})$ . Figure 3 shows our proposed bound offers a significant improvement over state-of-the-art results. The new upper bounds are inspired from the fact that classifier prediction probabilities tend to concentrate on a small number of labels, rather than be uniformly spread over all the possible labels. This is analogous to the phenomenon of neural collapse [Kot22]. As an example, in the context of a computer vision model, when presented with a photo of a dog, one might expect that a large portion of reasonable models might classify the photo as an animal other than a dog, but not as a car or an airplane. ", "page_idx": 4}, {"type": "image", "img_path": "m5dyKArVn8/tmp/f9521d264be37d5edc7d5a34a3ad5e211174bace90cfc09c5dff26615287299e.jpg", "img_caption": ["(b) Interpolating models on various datasets "], "img_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "m5dyKArVn8/tmp/ad679b62bfcf733bfa528f5c83e6f01eaf71068c0f03acf6e781adb6a84c5d86.jpg", "img_caption": ["Figure 2: Polarization $\\eta_{\\rho}$ obtained (a) from various architectures trained on CIFAR-10 and ${\\bf(b)}$ only from interpolating classifiers trained on various datasets. Red dashed line indicates $y=4/3$ . In subplot ${\\bf(b)}$ , we observe that the polarization of all interpolating models expect one are smaller than $4/3$ , which aligns with Conjecture 1. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "We start by stating an upper bound on the majority vote error, $L(h_{\\rho}^{\\mathrm{MV}})$ as a function of polarization $\\eta_{\\rho}$ . This upper bound is tighter (smaller) than the previous bound in inequality (6) when the polarization is lower than 2, which is the case for competent ensembles. The proof is deferred to Appendix B.2. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. For an ensemble $\\rho$ of $K$ -class classifiers, ", "page_idx": 5}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\frac{2\\eta_{\\rho}(K-1)}{K}\\left(\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\eta_{\\rho}$ is the polarization of the ensemble $\\rho$ . ", "page_idx": 5}, {"type": "text", "text": "Based on the upper bound stated in Theorem 2, we add a restriction on the entropy of constituent classifiers to obtain Theorem 3. The theorem provides a tighter scalable bound that does not have explicit dependency on the total number of labels, with a small cost in terms of the entropy of constituent classifiers. The proof of Theorem 3 is deferred to Appendix B.3. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3. Let $\\rho$ be any $\\eta$ -polarized ensemble of $K$ -class classifiers that satisfies $\\mathbb{P}_{\\rho}(h(x)\\notin$ $A(x))\\leq\\Delta$ , where $y\\in A(x)\\subset[K]$ and $|A(x)|\\leq{\\dot{M}}$ , for all data points $(x,y)\\in\\mathcal{D}$ . Then, we have ", "page_idx": 5}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\,\\frac{2\\eta(M\\!-\\!1)}{M}\\left[\\left(1+\\frac{\\Delta}{M\\!-\\!1}\\right)\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "While Theorem 3 might provide a tighter bound than prior work, coming up with pairs $(M,\\Delta)$ that satisfy the constraint is not an easy task. This is not an issue for a discrete ensemble, however. If $\\rho$ is a discrete distribution of $N$ classifiers, then we observe that the assumption of Theorem 3 must always hold with $(M,\\Delta)=(N{+}1,0)$ . We state this as the following corollary. ", "page_idx": 5}, {"type": "text", "text": "Corollary 1 (FINITE ENSEMBLE). For an ensemble $\\rho$ that is a weighted sum of $N$ classifiers, we have ", "page_idx": 5}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\,\\frac{2\\eta_{\\rho}N}{N\\!+\\!1}\\left(\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\eta_{\\rho}$ is the polarization of the ensemble $\\rho$ . ", "page_idx": 5}, {"type": "text", "text": "See Figure 3, which provides empirical results that compare the bound in Corollary 1 with the C-bound in inequality (3), and with inequality (6) proposed in $[\\mathrm{TKY^{+}24}]$ . We can observe that the ", "page_idx": 5}, {"type": "image", "img_path": "m5dyKArVn8/tmp/168b9b1c921c2f023ac2639c98e5bc38cbe0562645700d0e4ad64c2a8a8ff1ec.jpg", "img_caption": ["Figure 3: Comparing our new bound from Corollary 1 (colored black), which is the right hand side of inequality (10), with bounds from previous studies. Green corresponds to the C-bound in inequality (3), and blue corresponds to the right hand side of inequality (6). ResNet18, ResNet50, ResNet101 models with various sets of hyperparameters are trained on CIFAR-10 then tested on (a) the out-of-sample CIFAR-10, (b) an out-of-distribution dataset, CIFAR-10.1 "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "new bound in Corollary 1 is strictly tighter than the others. For more details on these empirical results, see Appendix C. ", "page_idx": 6}, {"type": "text", "text": "Although the bound in Corollary 1 is tighter than the bounds from previous studies, it\u2019s still not tight enough to use it as an estimator for $L(h_{\\rho}^{\\mathrm{MV}})$ . In the following theorem, we use a stronger condition on the entropy of an ensemble to obtain a tighter bound. The proof is deferred to Appendix B.4. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4. For any $\\eta$ -polarized ensemble $\\rho$ that satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}\\left(h(X)\\neq Y,h^{\\prime}(X)\\neq Y,h(X)\\neq h^{\\prime}(X)\\right)\\right]\\leq\\varepsilon\\,\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}\\left(h(X)\\neq Y\\right)\\right],\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\,\\eta\\,\\left[(1+\\varepsilon)\\,\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The condition (11) can be rephrased as follows: compared to the error $\\mathbb{P}_{\\rho}(h(x)\\neq y)$ , the entropy of the distribution of wrong predictions is small, and it is concentrated on a small number of labels. A potential problem is that one must know or estimate the smallest possible value of $\\varepsilon$ in advance. At least, we can prove that $\\begin{array}{r}{\\varepsilon=\\frac{K-2}{2(K-1)}}\\end{array}$ always satisfies the condition (11) for an ensemble of $K$ -class classifiers. The proof is deferred to Appendix B.4. ", "page_idx": 6}, {"type": "text", "text": "Corollary 2. For any $\\eta$ -polarized ensemble $\\rho$ of $K_{\\l}$ -class classifiers, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\,\\eta\\,\\left[\\left(1+\\frac{K\\!-\\!2}{2(K\\!-\\!1)}\\right)\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Naturally, this $\\varepsilon$ is not good enough for our goal. We discuss more on how to estimate the smallest possible value of $\\varepsilon$ in the following section. ", "page_idx": 6}, {"type": "text", "text": "5 A Universal Law for Ensembling ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, our goal is to predict the majority vote error rate of an ensemble with large number of classifiers by just using information we can obtain from an ensemble with a small number, e.g., three, ", "page_idx": 6}, {"type": "text", "text": "of classifiers. Among the elements in the bound in Theorem 4, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\eta\\,\\left[(1+\\varepsilon)\\,\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right],\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "we plug in $\\begin{array}{r}{\\eta=\\frac{4}{3}}\\end{array}$ as a result of Theorem 1; and since $\\mathbb{E}_{\\rho}[L(h)]$ is invariant to the number of classifiers, it remains to predict the behavior of $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ and the smallest possible value of $\\varepsilon$ , $\\varepsilon_{\\rho}\\,=$ ED[P\u03c12(h(X2)\u0338=Y[,h\u2032((hX()X\u0338=)\u0338Y=,Yh ()]X)\u0338=h\u2032(X))]. Since the denominator ED [P\u03c1 (h(X) \u0338= Y )] = E\u03c1[L(h)] is invariant to the number of classifiers, and the numerator resembles the disagreement between classifiers, $\\varepsilon_{\\rho}$ is expected to follow a similar pattern as $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ . Note that the numerator of $\\varepsilon_{\\rho}$ has the same form as the disagreement, differing by only one less label. Both are $V$ -statistics that can be expressed as a multiple of a $U$ -statistic, as shown in equation (12). In the next theorem, we show that the disagreement for a finite number of classifiers can be expressed as the sum of a hyperbolic curve and an unbiased random walk. Here, $[x]$ denotes the greatest integer less than or equal to $x$ and $\\mathcal{D}[0,1]$ is the Skorokhod space on $[0,1]$ (see Appendix B.5). ", "page_idx": 7}, {"type": "text", "text": "Theorem 5. Let $\\rho_{N}$ denote an empirical distribution of $N$ independent classifiers $\\{h_{i}\\}_{i=1}^{N}$ sampled from a distribution $\\rho$ and $\\sigma_{1}^{2}=\\bar{\\mathsf{V a r}}_{h\\sim\\rho}(\\mathbb{E}_{h^{\\prime}\\sim\\rho}\\mathbb{P}_{\\mathcal{D}}(h(X)\\neq h^{\\bar{\\prime}}(X))$ ). Then, there exists $D_{\\infty}>0$ such that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{(h,h^{\\prime})\\sim\\rho_{N}^{2}}[D(h,h^{\\prime})]=\\left(1-\\frac{1}{N}\\right)\\left(D_{\\infty}+\\frac{2}{\\sqrt{N}}Z_{N}\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\mathbb{E}Z_{N}=0$ , $\\mathsf{V a r}Z_{N}\\to\\sigma_{1}^{2}$ and $\\begin{array}{r}{\\{\\frac{\\sqrt{t}}{\\sigma_{1}}Z_{[N t]}\\}_{t\\in[0,1]}}\\end{array}$ converges weakly to a standard Wiener process in $\\mathcal{D}[0,1]$ as $N\\rightarrow\\infty$ . ", "page_idx": 7}, {"type": "text", "text": "Proof. Let $\\Phi(h_{i},h_{j})=\\mathbb{P}_{\\mathcal{D}}(h_{i}(X)\\neq h_{j}(X))$ . We observe that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{N^{2}}{N(N-1)}\\mathbb{E}_{(h,h^{\\prime})\\sim\\rho_{N}^{2}}[D(h,h^{\\prime})]=\\displaystyle\\frac{1}{N(N-1)}\\sum_{i,j=1}^{N}\\mathbb{P}_{\\mathcal{D}}(h_{i}(X)\\neq h_{j}(X))}\\\\ {\\displaystyle=\\frac{1}{N(N-1)}\\sum_{i,j=1}^{N}\\Phi(h_{i},h_{j})\\underset{\\Phi(h_{i},h_{i})=0}{\\overset{=}{\\longrightarrow}}\\frac{2}{N(N-1)}\\sum_{1\\leq i<j\\leq N}\\Phi(h_{i},h_{j})=:U_{N},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "which is a $U$ -statistic with the kernel function $\\Phi$ . Let $\\Phi_{0}=\\mathbb{E}_{(h,h^{\\prime})\\sim\\rho^{2}}\\Phi(h,h^{\\prime})$ . ", "page_idx": 7}, {"type": "text", "text": "The invariance principle of $U$ -statistics (Theorem 7 in Appendix B.5) states that the process $\\xi_{N}=$ $(\\xi_{N}(t),t\\in[0,1])$ , defined by $\\begin{array}{r}{\\xi_{N}(\\frac{k}{N})=\\frac{k}{2\\sqrt{N\\sigma_{1}^{2}}}(U_{k}-\\Phi_{0})}\\end{array}$ and $\\xi_{N}(t)=\\xi_{N}{\\big(}{\\frac{[N t]}{N}}{\\big)}$ , converges weakly to a standard Wiener process in $\\mathcal{D}[0,1]$ as $N\\to\\infty$ , since $\\sigma_{1}^{2}=\\mathsf{V a r}_{h\\sim\\rho}\\mathbb{E}_{h^{\\prime}\\sim\\rho}\\Phi(h,h^{\\prime})$ . Therefore, $U_{N}$ converges in probability as $N\\!\\to\\!\\infty$ to $D_{\\infty}:=\\Phi_{0}$ . ", "page_idx": 7}, {"type": "text", "text": "Letting $\\begin{array}{r}{Z_{N}\\!=\\!\\sigma_{1}\\xi_{N}(1)\\!=\\!\\frac{\\sqrt{N}}{2}(U_{N}\\!-\\!D_{\\infty})}\\end{array}$ , we can express $U_{N}$ as $\\begin{array}{r}{U_{N}\\!=\\!D_{\\infty}\\!+\\!\\frac{2}{\\sqrt{N}}Z_{N}}\\end{array}$ , with $\\mathbb{E}Z_{N}\\!=\\!0$ and $\\mathsf{V a r}Z_{N}\\to\\sigma_{1}^{2}$ . Since $\\begin{array}{r}{\\frac{\\sqrt{t}}{\\sigma_{1}}Z_{[N t]}\\!=\\!\\sqrt{\\frac{N t}{[N t]}}\\,\\xi_{N}\\!\\left(\\frac{[N t]}{N}\\right)\\!=\\!\\sqrt{\\frac{N t}{[N t]}}\\,\\xi_{N}(t)}\\end{array}$ , it follows by Slutsky\u2019s Theorem that $\\begin{array}{r}{\\{\\frac{\\sqrt{t}}{\\sigma_{1}}Z_{[N t]}\\}_{t\\in[0,1]}}\\end{array}$ converges weakly to a standard Wiener process in $\\mathcal{D}[0,1]$ as $N\\!\\to\\!\\infty$ . \u53e3 ", "page_idx": 7}, {"type": "text", "text": "Theorem 5 suggests that the disagreement within $N$ classifiers, $\\mathbb{E}_{\\rho_{N}^{2}}[D(h,h^{\\prime})]$ , can be approximated as $\\begin{array}{r}{\\frac{N-1}{N}D_{\\infty}}\\end{array}$ . From the disagreement within $M(\\ll N)$ classifiers, $D_{\\infty}$ can be approximated as $\\begin{array}{r}{\\frac{M}{M-1}\\mathbb{E}_{\\rho_{M}^{2}}[D(h,h^{\\prime})]}\\end{array}$ , and therefore we get ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho_{N}^{2}}[D(h,h^{\\prime})]\\approx\\frac{N-1}{N}\\cdot\\frac{M}{M-1}\\mathbb{E}_{\\rho_{M}^{2}}[D(h,h^{\\prime})].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Assume that we have three classifiers sampled from $\\rho$ . We denote the average error rate, the disagreement, and the $\\varepsilon_{\\rho}$ from these three classifiers by $\\mathbb{E}_{3}[L(h)],\\mathbb{E}_{3}[D(h,h^{\\prime})]$ , and $\\varepsilon_{3}$ , respectively. Then, from Theorem 4 and approximation (13) (which applies to both disagreement and $\\varepsilon_{\\rho}$ ), we ", "page_idx": 7}, {"type": "image", "img_path": "m5dyKArVn8/tmp/5b7c68aa63ff0b085c980c21b613d10ff69e2a2550aa6d5174210ff8771e506f.jpg", "img_caption": ["Figure 4: Comparing the estimated (extrapolated) majority vote error rates in equation (14) (bluedashed lines) and (15) (orange-dashed lines) with the true majority vote error (green solid line) for each number of classifiers. The solid sky-blue line corresponds to the average error rate of constituent classifiers. Subplots (a1), (b), (c), (d), (e) show the results from different pairs of (classification model, dataset). Subplot (a2) overlays the right hand side of inequality (3) (C-bound, colored red) and inequality (6) $\\phantom{+}[\\Gamma\\mathrm{KY}^{+}24]$ bound, colored purple) on the subplot (a1). These two quantities from previous studies are much larger compared to the average error rate. We see the same pattern for other (architecture, dataset) pairs, which we therefore omit from the plot. For more details on these empirical results, see Appendix C. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "estimate the majority vote error rate of $N$ classifiers from $\\rho$ as the following: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L(h_{\\rho}^{\\mathrm{MV}})\\lesssim\\frac{4}{3}\\left[\\left(1+\\frac{N-1}{N}\\cdot\\frac{3}{2}\\cdot\\varepsilon_{3}\\right)\\,\\mathbb{E}_{3}[L(h)]-\\frac{N-1}{N}\\cdot\\frac{3}{2}\\cdot\\frac{1}{2}\\mathbb{E}_{3}[D(h,h^{\\prime})]\\right]}\\\\ &{\\quad\\quad\\quad=\\frac{4}{3}\\left[\\mathbb{E}_{3}[L(h)]+\\frac{3(N-1)}{2N}\\left(\\varepsilon_{3}\\mathbb{E}_{3}[L(h)]-\\frac{1}{2}\\mathbb{E}_{3}[D(h,h^{\\prime})]\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Alternatively, we can use the polarization measured from three classifiers, $\\eta_{3}$ , instead of $\\begin{array}{r}{\\eta=\\frac{4}{3}}\\end{array}$ , to obtain: ", "page_idx": 8}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})=\\eta_{3}\\left[\\mathbb{E}_{3}[L(h)]+\\frac{3(N-1)}{2N}\\left(\\varepsilon_{3}\\mathbb{E}_{3}[L(h)]-\\frac{1}{2}\\mathbb{E}_{3}[D(h,h^{\\prime})]\\right)\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Figure 4 presents empirical results that compare the estimated (extrapolated) majority vote error rates in equations (14) and (15) with the true majority vote error for each number of classifiers. ResNet18 models are tested on four different dataset: CIFAR-10, CIFAR-10.1, Fashion-MNIST [XRV17] and Kuzushiji-MNIST $[\\mathrm{CBIK^{+}18}]$ where the models are trained on the corresponding train data. MobileNet [How17] is trained and tested on the MNIST [Den12] dataset. Not only do the estimators show significant improvement compared to the bounds introduced in Section 2.2, we observe that the estimators are very close to the actual majority vote error rate; and thus the estimators have practical usages, unlike the bounds from previous studies. In Figure 4(a2), existing bounds (3) and (6) are much larger compared to the average error rate. This is also the case for (architecture, dataset) pairs of other subplots. ", "page_idx": 8}, {"type": "text", "text": "6 Discussion and Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work addresses the question: how does the majority vote error rate change according to the number of classifiers? While this is an age-old question, it is one that has received renewed interest in recent years. On the journey to answering the question, we introduce several new ideas of independent interest. (1) We introduced the polarization $\\eta_{\\rho}$ , of an ensemble of classifiers. This notion plays an important role throughout this paper and appears in every upper bound presented. Although Theorem $1$ gives some insight into polarization, our conjectured neural polarization law (Conjecture 1) is yet to be proved or disproved, and it provides an exciting avenue for future work. (2) We proposed two classes of ensembles whose entropy is restricted in different ways. Without these constraints, there will always be examples that saturate even the least useful majority vote error bounds. We believe that accurately describing how models behave in terms of the entropy of their output is key to precisely characterizing the behavior of majority vote, and likely other ensembling methods. ", "page_idx": 9}, {"type": "text", "text": "Throughout this paper, we have theoretically and empirically demonstrated that polarization is fairly invariant to the hyperparameters and architecture of classifiers. We also proved a tight bound for majority vote error, under an assumption with another quantity $\\varepsilon$ , and we presented how the components of this tight bound behave according to the number of classifiers. Altogether, we have sharpened bounds on the majority vote error to the extent that we are able to identify the trend of majority vote error rate in terms of number of classifiers. ", "page_idx": 9}, {"type": "text", "text": "We close with one final remark regarding the metrics used to evaluate an ensemble. Majority vote error rate is the most common and popular metric used to measure the performance of an ensemble. However, it seems unlikely that a practitioner would consider an ensemble to have performed adequately if the majority vote conclusion was correct, but was only reached by a relatively small fraction of the classifiers. With the advent of large language models, it is worth considering whether the majority vote error rate is still as valuable. The natural alternative in this regard is the probability $\\mathbb{P}_{\\rho}(W_{\\rho}>\\mathrm{i}/2)$ , that is, the probability that at least half of the classifiers agree on the correct answer. This quantity is especially well-behaved, and it frequently appears in our proofs. (Indeed, every bound presented in this work serves as an upper bound for $\\mathbb{P}_{\\rho}(W_{\\rho}>1/2)$ .) We conjecture that this quantity is useful much more generally. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements. We would like to thank the DOE, IARPA, NSF, and ONR for providing partial support of this work. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[BHMM19] Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off. Proceedings of the National Academy of Sciences, 116(32):15849\u201315854, 2019. [Bil13] Patrick Billingsley. Convergence of probability measures. John Wiley & Sons, 2nd edition, 2013. [BJRK22] Christina Baek, Yiding Jiang, Aditi Raghunathan, and Zico Kolter. Agreement-onthe-line: Predicting the performance of neural networks under distribution shift. Advances in Neural Information Processing Systems, 35:19274\u201319289, 2022. $[\\mathrm{CBIK}^{+}18]$ Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha. Deep learning for classical japanese literature. arXiv preprint arXiv:1812.01718, 2018. [Den12] Li Deng. The MNIST database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6):141\u2013142, 2012. [HLVDMW17] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4700\u20134708, 2017. [How17] Andrew G Howard. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. ", "page_idx": 9}, {"type": "text", "text": "[HZRS16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013778, 2016.   \n[JNBK22] Yiding Jiang, Vaishnavh Nagarajan, Christina Baek, and J Zico Kolter. Assessing generalization of SGD via disagreement. In International Conference on Learning Representations, 2022. [Kal21] Olav Kallenberg. Foundations of modern probability. Springer, 3rd edition, 2021. [KB13] Vladimir S. Korolyuk and Yu V. Borovskich. Theory of $U$ -statistics. Springer Science & Business Media, 2013. [Kot22] Vignesh Kothapalli. Neural collapse: A review on modelling principles and generalization. arXiv preprint arXiv:2206.04041, 2022. [Kri09] Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.   \n[LMRR17] Fran\u00e7ois Laviolette, Emilie Morvant, Liva Ralaivola, and Jean-Francis Roy. Risk upper bounds for general ensemble methods with an application to multiclass classification. Neurocomputing, 219:15\u201325, 2017. [LPB17] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in Neural Information Processing Systems, 30, 2017. [McA98] David A. McAllester. Some PAC-Bayesian theorems. In Proceedings of the eleventh annual conference on Computational Learning Theory, pages 230\u2013234, 1998.   \n[MLIS20] Andr\u00e9s Masegosa, Stephan Lorenzen, Christian Igel, and Yevgeny Seldin. Second order PAC-Bayesian bounds for the weighted majority vote. Advances in Neural Information Processing Systems, 33:5263\u20135273, 2020.   \n[RRSS18] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do CIFAR-10 classifiers generalize to CIFAR-10? arXiv preprint arXiv:1806.00451, 2018. [SZ14] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. [TFF08] Antonio Torralba, Rob Fergus, and William T Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. IEEE transactions on Pattern Analysis and Machine Intelligence, 30(11):1958\u20131970, 2008.   \n$[\\mathrm{TKY}^{+}24]$ Ryan Theisen, Hyunsuk Kim, Yaoqing Yang, Liam Hodgkinson, and Michael W. Mahoney. When are ensembles really effective? Advances in Neural Information Processing Systems, 36, 2024.   \n[XRV17] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017. ", "page_idx": 10}, {"type": "text", "text": "A More discussion on competence ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "In this section, we delve more into the competence condition that was introduced in $[\\mathrm{TKY^{+}24}]$ . We explore in which cases the competence condition might not work and how to overcome these issues. We discuss a few milder versions of competence that are enough for bounds (5) and (6) to hold. Then we discuss how to check whether these weaker competence conditions hold in practice, with or without a separate validation set. We start by formally stating the original competence condition. ", "page_idx": 11}, {"type": "text", "text": "Definition 3 (Competence, $[\\mathrm{TKY^{+}}24]$ ). The ensemble $\\rho$ is competent if for every $0\\le t\\le1/2$ , ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\in[t,1/2))\\ge\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\in[1/2,1-t]).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "A.1 Cases when competence fails ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "One tricky part in the definition of competence is that it requires inequality (16) to hold for every $0\\le t\\le\\dot{1}/\\bar{2}$ . In case $t=1/2$ , the inequality becomes ", "page_idx": 11}, {"type": "equation", "text": "$$\n0\\geq\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}=1/2).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "This is not a significant issue in the case that $\\rho$ is a continuous distribution over classifiers, e.g., a Bayes posterior or a distribution over a parametric family $h_{\\theta}$ , as $\\{W_{\\rho}=1/2\\}$ would be a measure-zero set. In the case that $\\rho$ is a discrete distribution over finite number of classifiers, however, $\\mathbb{P}_{D}(W_{\\rho}=1/2)$ is likely to be a positive quantity, in which case it can violate the competence condition. ", "page_idx": 11}, {"type": "text", "text": "That being said, $\\{(x,y)\\ |\\ W_{\\rho}(x,y)\\,=\\,1/2\\}$ represent tricky data points that deserves separate attention. This event can be divided into two cases: 1) all the classifiers that incorrectly made a prediction output the same label; or 2) incorrect predictions consist of multiple labels so that the majority vote outputs the true label. Among these two possibilities, the first case is troublesome. We denote such data points by $\\mathrm{TIE}(\\rho,\\mathcal{D})$ : ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{TIE}(\\rho,\\mathcal{D}):=}&{{}}\\\\ {\\{(x,y)\\mid\\mathbb{P}_{\\rho}(\\mathbb{1}(h(x)=j))=\\mathbb{P}_{\\rho}(\\mathbb{1}(h(x)=y))=1/2}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "In this case, the true label and an incorrect label are chosen by exactly the same $\\rho-$ weights of classifiers. An easy way to resolve this issue is to slightly tweak the weights. For instance, if $\\rho$ is an equally weighted sum of two classifiers, we can change each of their weights to be $(1/2+\\epsilon,1/2-\\epsilon)$ , instead of $\\bar{(1/2,1/2)}$ . This change may seem manipulative, but it corresponds to a deterministic tie-breaking rule which prioritizes one classifier over the other, which is a commonly used tiebreaking rule. ", "page_idx": 11}, {"type": "text", "text": "Definition 4 (Tie-free ensemble). An ensemble is tie-free if $\\begin{array}{r}{:\\mathbb{P}_{\\mathcal{D}}(T I E(\\rho,\\mathcal{D}))=0.}\\end{array}$ ", "page_idx": 11}, {"type": "text", "text": "Proposition 2. An ensemble with a deterministic tie-breaking rule is tie-free. ", "page_idx": 11}, {"type": "text", "text": "With such tweak to make the set $\\mathrm{TIE}(\\rho,\\mathcal{D})$ to be an empty set or a measure-zero set, we present a slightly milder condition that is enough for the bounds (5) and (6) to still hold. ", "page_idx": 11}, {"type": "text", "text": "Definition 5 (Semi-competence). The ensemble $\\rho$ is semi-competent if for every $0\\le t<1/2$ , ", "page_idx": 11}, {"type": "equation", "text": "$$\nP(W_{\\rho}\\in[t,1/2])\\geq\\mathbb{P}(W_{\\rho}\\in(1/2,1-t]).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Note that inequality (17) is a strictly weaker condition than inequality (16), and hence competence implies semi-competence. The converse is not true. An ensemble is semi-competent even if the pointwise error $W_{\\rho}(X,Y)=1/2$ on every data points, but such an ensemble is not competent. ", "page_idx": 11}, {"type": "text", "text": "Theorem 6. For a tie-free ensemble and semi-competent ensemble $\\rho$ , $L(h_{\\rho}^{\\mathrm{MV}})\\leq\\mathbb{E}_{\\rho}[L(h)]$ and ", "page_idx": 11}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\leq\\frac{4(K-1)}{K}\\left(\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right)\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "holds in $K$ -class classification setting. ", "page_idx": 11}, {"type": "text", "text": "We provide the proof as a separate subsection below. ", "page_idx": 11}, {"type": "text", "text": "A.2 Proof of Theorem $\\mathbf{6}$ and Proposition $^{1}$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We start with the following lemma, which is a semi-competence version of Lemma 2 from $[\\mathrm{TKY^{+}24}]$ . ", "page_idx": 12}, {"type": "text", "text": "Lemma 1. For a semi-competent ensemble $\\rho$ and any increasing function $g$ satisfying $g(0)=0$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{D}}[g(W_{\\rho})\\mathbb{1}_{W_{\\rho}\\leq1/2}]~\\geq~\\mathbb{E}_{\\mathcal{D}}[g(\\widetilde{W_{\\rho}})\\mathbb{1}_{\\widetilde{W_{\\rho}}<1/2}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\widetilde{W_{\\rho}}=1-W_{\\rho}$ . ", "page_idx": 12}, {"type": "text", "text": "Proof. For every $x\\in[0,1]$ , it holds that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\mathbb{1}_{W_{\\rho}\\leq1/2}\\geq x)=\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\in[x,1/2])\\,\\mathbb{1}_{x\\leq1/2},}\\\\ &{\\mathbb{P}_{\\mathcal{D}}(\\widetilde{W_{\\rho}}\\mathbb{1}_{\\widetilde{W_{\\rho}}<1/2}\\geq x)=\\mathbb{P}_{\\mathcal{D}}(\\widetilde{W_{\\rho}}\\in[x,1/2))\\,\\mathbb{1}_{x\\leq1/2}=\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\in(1/2,1-x])\\,\\mathbb{1}_{x\\leq1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "From the definition of semi-competence, this implies that $\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\mathbb{1}_{W_{\\rho}\\leq1/2}\\quad\\geq\\quad x)\\quad\\geq$ $\\mathbb{P}_{\\mathcal{D}}(\\widetilde{W_{\\rho}}\\mathbb{1}_{\\widetilde{W_{\\rho}}<1/2}\\,\\geq\\,x)$ for every $x\\in[0,1]$ . Using the fact that $g(x\\,\\mathbb{1}_{x\\leq c})\\,=\\,g(x)\\mathbb{1}_{x\\leq c}$ for any increasing function $g$ with $g(0)=0$ , we obtain ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{D}}(h(W_{\\rho})\\mathbb{1}_{W_{\\rho}\\leq1/2}\\geq x)\\geq\\mathbb{P}_{\\mathcal{D}}(h(\\widetilde{W_{\\rho}})\\mathbb{1}_{\\widetilde{W_{\\rho}}<1/2}\\geq x).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Putting these together with a well-known equality $\\begin{array}{r}{\\mathbb{E}X\\,=\\,\\int_{0}^{\\infty}\\mathbb{P}(X\\,\\geq\\,x)\\mathrm{d}x}\\end{array}$ for a non-negative random variable $X$ proves the lemma. ", "page_idx": 12}, {"type": "text", "text": "Now we use Lemma 1 and Theorem 2 to prove Theorem 6. ", "page_idx": 12}, {"type": "text", "text": "Proof of Theorem $^ \u1e0a 6 \u1e0c$ . Applying Lemma 1 with $g(x)=2x^{2}$ gives, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}\\mathbb{1}_{W_{\\rho}\\leq1/2}]\\geq\\mathbb{E}_{\\mathcal{D}}[2\\widetilde{W_{\\rho}}^{2}\\mathbb{1}_{\\widetilde{W_{\\rho}}<1/2}]=\\mathbb{E}_{\\mathcal{D}}[(2-4W_{\\rho}+2W_{\\rho}^{2})\\mathbb{1}_{W_{\\rho}>1/2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Putting this together with the following decomposition of $\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}]$ shows that the ensemble $\\rho$ is 2-polarized: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}]\\;\\ge\\;\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}\\mathbb{1}_{W_{\\rho}>1/2}]+\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}\\mathbb{1}_{W_{\\rho}\\le1/2}]}\\\\ &{\\quad\\quad\\quad\\quad\\;\\;\\ge\\frac{5}{(18)}\\mathbb{E}_{\\mathcal{D}}[2W_{\\rho}^{2}\\mathbb{1}_{W_{\\rho}>1/2}]+\\mathbb{E}_{\\mathcal{D}}[(2-4W_{\\rho}+2W_{\\rho}^{2})\\mathbb{1}_{W_{\\rho}>1/2}]}\\\\ &{\\quad\\quad\\quad\\quad\\ge\\;\\mathbb{E}_{\\mathcal{D}}[(1-2W_{\\rho})^{2}\\mathbb{1}_{W_{\\rho}>1/2}]+\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>1/2)}\\\\ &{\\quad\\quad\\quad\\quad\\ge\\;\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>1/2).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Therefore, applying Theorem 2 with constant $\\eta=2$ concludes the proof. ", "page_idx": 12}, {"type": "text", "text": "We also state the following proof of Proposition 1 for completeness. ", "page_idx": 12}, {"type": "text", "text": "Proof of Proposition 1. Inequality (19) with Lemma 3 proves the proposition. ", "page_idx": 12}, {"type": "text", "text": "A.3 Example that the bound (6) is tight ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Here, we provide a combination of $(\\rho,\\mathcal{D})$ of which $L(h_{\\rho}^{\\mathrm{MV}})$ is arbitrarily close to the bound. ", "page_idx": 12}, {"type": "text", "text": "Consider, for each feature $x$ , that exactly $(1-\\epsilon)$ fraction of classifiers predict the correct label, and that the remaining $\\epsilon$ fraction of classifiers predict a wrong label. In this case, $L(h_{\\rho}^{\\mathrm{MV}})\\,=\\,0$ , $\\mathbb{E}_{\\rho}[L(h)]=\\epsilon$ , and $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]=2\\epsilon(1-\\epsilon)$ . Hence, the upper bound (6) is $\\frac{4(K{-}1)}{K}\\epsilon^{2}$ , which can be arbitrarily close to 0. ", "page_idx": 12}, {"type": "text", "text": "B Proofs of our main results ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide proofs for our main results. ", "page_idx": 13}, {"type": "text", "text": "B.1 Proof of Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We start with the following lemma which shows the concentration of a linear combination of $W_{\\rho}^{2}$ and $\\mathbb{1}(W_{\\rho}>1/2)$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma 2. For sampled data points $\\{(X_{i},Y_{i})\\}_{i=1}^{m}\\,\\sim\\,{\\mathcal{D}}$ , define $\\textstyle Z_{2}\\,:=\\,\\sum_{i=1}^{m}W_{\\rho}^{2}(X_{i},Y_{i})$ and $\\textstyle Z_{0}:=\\sum_{i=1}^{m}\\mathbb{1}(W_{\\rho}(X_{i},Y_{i})>1/2)$ . The ensemble $\\rho$ is $\\eta$ -polarized with probability at least $1-\\delta\\;i f$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{m}(\\eta Z_{2}-Z_{0})>\\sqrt{\\frac{\\operatorname*{max}\\{\\frac{3\\eta}{4},1\\}}{2m}\\log\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Let $Z_{2i}=W_{\\rho}^{2}(X_{i},Y_{i})$ and $Z_{0i}=\\mathbb{1}(W_{\\rho}(X_{i},Y_{i})>1/2)$ . Observe that $\\eta\\,Z_{2i}-Z_{0i}$ always takes a value between $\\begin{array}{r}{\\left[\\frac{\\eta}{4}\\!-\\!1,\\operatorname*{max}\\!\\left\\{\\frac{\\eta}{4},\\eta\\!-\\!1\\right\\}\\right]}\\end{array}$ since $W_{\\rho}(X_{i},Y_{i})\\in[0,1]$ . This implies that $\\eta Z_{2i}\\!-\\!Z_{0i}\\mathbf s$ are i.i.d. sub-Gaussian random variable with parameter $\\sigma=\\operatorname*{max}\\{\\frac{3\\eta}{4},1\\}/2$ . ", "page_idx": 13}, {"type": "text", "text": "By letting $A_{2}=\\mathbb{E}[\\eta W_{\\rho}^{2}-\\mathbb{1}(W_{\\rho}\\geq1/2)]$ and using the Hoeffding\u2019s inequality, we obtain ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{m}(\\eta Z_{2}-Z_{0})-A_{2}\\le\\sqrt{\\frac{\\operatorname*{max}\\{\\frac{3\\eta}{4},1\\}}{2m}\\log\\frac{1}{\\delta}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "with probability at least $1-\\delta$ . ", "page_idx": 13}, {"type": "text", "text": "Therefore, $\\rho$ is $\\eta$ -polarized with probability at least $1-\\delta$ if ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{m}(\\eta Z_{2}-Z_{0})>\\sqrt{\\frac{\\operatorname*{max}\\{\\frac{3\\eta}{4},1\\}}{2m}\\log\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Now we use Lemma 2 to prove Theorem 1. ", "page_idx": 13}, {"type": "text", "text": "Proof of Theorem 1. Observe that $\\textstyle S={\\frac{1}{m}}Z_{2}$ , $\\textstyle P={\\frac{1}{m}}Z_{0}$ , and thus $\\begin{array}{r}{\\frac{1}{m}(\\eta Z_{2}-Z_{0})=\\eta S-P}\\end{array}$ . For $\\begin{array}{r}{\\eta\\geq\\frac{4}{3}}\\end{array}$ , the lower bound in Lemma \u221a2 is simply $\\sqrt{\\frac{3\\eta}{8m}\\log\\frac{1}{\\delta}}$ , and the inequality (20) can be viewed as a quadratic inequality in terms of $\\sqrt{\\eta}$ . From quadratic formula, we know that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{if}\\quad\\sqrt{\\eta}>\\frac{\\sqrt{\\frac{3\\eta}{8m}\\log\\frac{1}{\\delta}}+\\sqrt{\\frac{3\\eta}{8m}\\log\\frac{1}{\\delta}+4S P}}{2S},\\quad\\mathrm{then}\\quad\\eta S-P-\\sqrt{\\frac{3\\eta}{8m}\\log\\frac{1}{\\delta}}>0.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Putting this together with Lemma 2 proves the theorem: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta\\ge\\operatorname*{max}\\left\\{\\cfrac{4}{3},\\left(\\cfrac{\\sqrt{\\frac{3}{8m}\\log\\frac1\\delta}+\\sqrt{\\frac{3}{8m}\\log\\frac1\\delta+4S P}}{2S}\\right)^{2}\\right\\}}\\\\ &{\\qquad\\qquad\\Rightarrow\\quad\\eta S-P>\\sqrt{\\frac{3\\eta}{8m}\\log\\frac1\\delta}\\qquad\\underset{\\mathrm{Lemma2}}{\\Rightarrow}\\quad\\rho\\mathrm{~is~}\\eta\\mathrm{-polarized~w.p.~1-}\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and thus the polarization $\\eta_{\\rho}$ , the smallest $\\eta$ such that $\\rho$ is $\\eta$ -polarized, is upper bounded by the right hand side of inequality (21). \u53e3 ", "page_idx": 13}, {"type": "text", "text": "B.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We start by proving the following lemma which relates the error rate of the majority vote, $L(h_{\\rho}^{\\mathrm{MV}})$ , with the point-wise error rate, $W_{\\rho}$ , using Markov\u2019s inequality. In general, $L(h_{\\rho}^{\\mathrm{MV}})\\leq\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}\\geq1/2)$ is true for any ensemble $\\rho$ . We prove a tighter version of this. The difference between the two can be non-negligible when dealing with an ensemble with finite number of classifiers. Refer to Appendix A.1 and Definition 4 for more details regarding this difference and tie-free ensembles. ", "page_idx": 13}, {"type": "text", "text": "Proof. For given feature $x$ , $W_{\\rho}\\leq1/2$ implies that more than or exactly $\\rho-$ weighted half of the classifiers outputs the true label. Since the ensemble $\\rho$ is tie-free, $h_{\\rho}^{\\mathrm{MV}}$ outputs the true label if $W_{\\rho}\\leq1/2$ . Therefore, $\\{(x,y)\\mid W_{\\rho}(x,y)\\leq1/2\\}\\subset\\{(x,y)\\mid h_{\\rho}^{\\mathrm{MV}}(x)=y\\}$ . Applying $\\mathbb{P}_{\\mathcal{D}}$ on the both sides proves the lemma. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "The following lemma appears as Lemma 2 in [MLIS20]. This lemma draws the connection between the point-wise error rate, $W_{\\rho}$ and the tandem loss, $\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma 4. The equality $\\mathbb{E}_{\\mathcal{D}}[{W_{\\rho}}^{2}]=\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]$ holds. ", "page_idx": 14}, {"type": "text", "text": "The next lemma appears as Lemma 4 in $[\\mathrm{TKY^{+}24}]$ . This lemma provides an upper bound on the tandem loss, $\\mathbb{E}_{\\rho^{2}}[\\bar{L}(\\bar{h},h^{\\prime})]$ , in terms of the average error rate, $\\mathbb{E}_{\\rho}[L(\\bar{h})]$ , and the average disagreement, $\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma 5. For the $K$ -class problem, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]\\leq\\frac{2(K-1)}{K}\\left(\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now we use these results to prove Theorem 2. ", "page_idx": 14}, {"type": "text", "text": "Proof of Theorem 2. Putting Lemmas 3, 4, and 5 and the definition of the polarization together proves the theorem: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{L(h_{\\rho}^{\\mathrm{MV}})\\sum_{\\mathrm{Lemma\\,}3}\\!\\!\\!\\!\\!\\!\\!\\!}}&{\\subset}&{\\!\\!\\!\\!\\mathbb{P}_{D}(W_{\\rho}>1/2)\\underset{\\mathrm{polaization}}{\\leq}}\\eta_{\\rho}\\mathbb{E}_{\\mathcal D}[W_{\\rho}^{2}]}\\\\ &{}&{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "B.3 Proof of Theorem 3 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We start with a lemma which is a corollary of Newton\u2019s inequality. ", "page_idx": 14}, {"type": "text", "text": "Lemma 6. For any collection of probabilities $p_{1},\\ldots,p_{n}$ , the following inequality holds. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{1\\leq i<j\\leq n}p_{i}p_{j}\\;\\leq\\;{\\frac{n-1}{2n}}\\left(\\sum_{i=1}^{n}p_{i}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. Newton\u2019s inequality states that ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\frac{e_{2}}{\\binom{n}{2}}}\\leq\\left({\\frac{e_{1}}{n}}\\right)^{2}\\qquad{\\mathrm{where}}\\quad e_{1}=\\sum_{i=1}^{n}p_{i}\\quad{\\mathrm{and}}\\quad e_{2}=\\sum_{1\\leq i<j\\leq n}p_{i}\\,p_{j}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Rearranging the terms gives the lemma. ", "page_idx": 14}, {"type": "text", "text": "Now we use this and the previous lemmas to prove Theorem 3. ", "page_idx": 14}, {"type": "text", "text": "Proof of Theorem 3. From Lemma 3, Lemma 4, and the definition of $\\eta$ -polarized ensemble, we have the following relationship between $L(h_{\\rho}^{\\mathrm{MV}})$ and $\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\nL(h_{\\rho}^{\\mathrm{MV}})\\sum_{\\mathrm{Lem.\\;3}}\\mathbb{P}_{\\mathcal{D}}(W_{\\rho}>1/2)\\sum_{\\eta\\cdot\\mathrm{polarized}}\\eta\\,\\mathbb{E}_{\\mathcal{D}}[W_{\\rho}^{\\;2}]\\underset{\\mathrm{Lemma\\;4}}{=}\\eta\\,\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "From this, it suffices to prove that $h_{\\alpha}\\,\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]$ is smaller than the upper bound in the theorem. First, observe the following decomposition of $\\mathbb{E}_{\\rho^{2}}[\\bar{L}(h,h^{\\prime})]$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]=\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)^{2}\\right]=\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)-\\mathbb{P}_{\\rho^{2}}(h(X)\\neq Y,h^{\\prime}(X)=Y)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For any predictor mapping into $K$ classes, let $y$ denote the true label for an input $x$ . Now we derive a lower bound of $\\mathbb{P}_{\\rho^{2}}\\bar{(}h(\\bar{X})\\neq Y,h^{\\prime}(X)=Y\\backslash\\$ ) using the following decomposition of $\\mathbb{P}_{\\rho^{2}}(h(x)\\neq$ $h^{\\prime}(x))$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))}}\\\\ &{}&{=\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y)+\\sum_{\\stackrel{i\\notin A(x)}{j\\in A(x)\\setminus\\{y\\}}}p_{i}p_{j},+\\sum_{\\stackrel{i,j\\in A(x)\\setminus\\{y\\}}{i<j}}p_{i}p_{j}+\\sum_{\\stackrel{i,j\\notin A(x)}{i<j}}p_{i}p_{j},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $p_{i}:=p_{i}(x)=\\mathbb{P}_{\\rho}(h(x)=i)$ . We let $\\Delta_{x}:=\\mathbb{P}_{\\rho}(h(x)\\not\\in A(x))$ and apply Lemma 6 to the last two terms: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overset{!}{\\underset{=}{\\mathbb{P}}}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))}\\\\ &{\\quad=\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y)+\\Delta_{x}(1-p_{Y}-\\Delta_{x})+\\underset{i,j\\in A(x)\\backslash\\{y\\}}{\\sum}p_{i}p_{j}+\\underset{i,j\\notin A(x)}{\\sum}p_{i}p_{j}}\\\\ &{\\quad\\underset{\\underset{=}{\\leq}}{\\leq}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y)+\\Delta_{x}(1-p_{y}-\\Delta_{x})+\\frac{M-2}{2(M-1)}(1-p_{y}-\\Delta_{x})^{2}+\\frac{K-M-1}{2(K-M)}\\Delta_{x}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Rearranging the terms and plugging $1\\!-\\!p_{Y}=\\mathbb{P}_{\\rho}(h(x)\\neq y)$ gives ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y)}\\\\ &{\\quad\\ge\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))-\\frac{\\Delta_{x}}{M-1}\\mathbb{P}_{\\rho}(h(x)\\neq y)-\\frac{M-2}{2(M-1)}\\mathbb{P}_{\\rho}(h(x)\\neq y)^{2}}\\\\ &{\\quad\\quad\\quad+\\frac{K-1}{2(K-M)(M-1)}\\Delta_{x}^{2}}\\\\ &{\\quad\\ge\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))-\\frac{\\Delta_{x}}{M-1}\\mathbb{P}_{\\rho}(h(x)\\neq y)-\\frac{M-2}{2(M-1)}\\mathbb{P}_{\\rho}(h(x)\\neq y)^{2}}\\\\ &{\\quad\\ge\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))-\\frac{\\Delta}{M-1}\\mathbb{P}_{\\rho}(h(x)\\neq y)-\\frac{M-2}{2(M-1)}\\mathbb{P}_{\\rho}(h(x)\\neq y)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last inequality comes from the condition $\\Delta_{x}:=\\mathbb{P}_{\\rho}(h(x)\\notin A(x))\\,\\leq\\,\\Delta$ . Putting this together with the equality (23) gives ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)^{2}\\right]\\leq\\left(1+\\displaystyle\\frac{\\Delta}{M-1}\\right)\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)\\right]-\\displaystyle\\frac{1}{2}\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq h^{\\prime}(X))\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\frac{M-2}{2(M-1)}\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)^{2}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which implies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]=\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)^{2}\\right]}\\\\ &{\\phantom{\\mathbb{E}_{\\rho^{2}}}\\leq\\frac{2(M-1)}{M}\\left[\\left(1+\\frac{\\Delta}{M-1}\\right)\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)\\right]-\\frac{1}{2}\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq h^{\\prime}(X))\\right]\\right]}\\\\ &{\\phantom{\\mathbb{E}_{\\rho^{2}}}=\\frac{2(M-1)}{M}\\left[\\left(1+\\frac{\\Delta}{M-1}\\right)\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Combining this with inequality (22) concludes the proof. ", "page_idx": 15}, {"type": "text", "text": "B.4 Proof of Theorem 4 and Corollary 2 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "First, we prove Theorem 4 by decomposing the point-wise disagreement between constituent classifiers. ", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem 4. The following decomposition of $\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))$ holds: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq h^{\\prime}(x))=\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y)+\\frac{1}{2}\\mathbb{P}_{\\rho^{2}}(h(x)\\neq y,h^{\\prime}(x)=y,h(x)\\neq h^{\\prime}(x)).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Applying $\\mathbb{E}_{\\mathcal{D}}$ to both sides and using the given condition (11), we obtain, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\mathbb{E}_{\\mathcal{D}}[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq h^{\\prime}(X))]\\leq\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq Y,h^{\\prime}(X)=Y)\\right]+\\varepsilon\\,\\mathbb{E}_{\\mathcal{D}}[\\mathbb{P}_{\\rho}(h(X)\\neq Y)].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The left hand side equals $\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]$ , and the second term on the right hand side is simply $\\varepsilon\\mathop{\\mathbb{E}_{\\rho}}[L(h)]$ . Hence, the inequality above can be rephrased as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]-\\varepsilon\\,\\mathbb{E}_{\\rho}[L(h)]\\leq\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq Y,h^{\\prime}(X)=Y)\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Putting this together with the inequality (22) and the equality (23), gives ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L(h_{\\rho}^{\\mathrm{MV}})\\underset{\\mathrm{Ineq.22}}{\\leq}\\eta\\,\\mathbb{E}_{\\rho^{2}}[L(h,h^{\\prime})]\\underset{\\mathrm{Eq.23}}{=}\\eta\\,\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho}(h(X)\\neq Y)-\\mathbb{P}_{\\rho^{2}}(h(X)\\neq Y,h^{\\prime}(X)=Y)\\right]}\\\\ &{\\quad\\quad\\quad=\\quad\\eta\\,\\left[\\mathbb{E}_{\\rho}[L(h)]-\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{P}_{\\rho^{2}}(h(X)\\neq Y,h^{\\prime}(X)=Y)\\right]\\right]}\\\\ &{\\quad\\quad\\quad\\underset{\\mathrm{Ineq.24}}{\\leq}\\eta\\,\\left[(1+\\varepsilon)\\mathbb{E}_{\\rho}[L(h)]-\\frac{1}{2}\\mathbb{E}_{\\rho^{2}}[D(h,h^{\\prime})]\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, we use Lemma 6 to prove Corollary 2. ", "page_idx": 16}, {"type": "text", "text": "Proof of Corollary 2. Let $p_{i}:=\\mathbb{P}_{\\rho}(h(x)=i)$ for $i\\in[K]$ , and let $y=K$ be the true label, without loss of generality. Then, we observe ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\rho^{2}}\\left(h(X)\\neq Y,h^{\\prime}(X)\\neq Y,h(X)\\neq h^{\\prime}(X)\\right)=\\sum_{\\stackrel{i,j=1}{i\\neq j}}^{K-1}p_{i}p_{j}\\quad\\mathrm{and}\\quad\\mathbb{P}_{\\rho}\\left(h(X)\\neq Y\\right)=\\sum_{i=1}^{K-1}p_{i}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Lemma 6 gives us the following: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\sum_{1\\leq i\\neq j\\leq K-1}p_{i}p_{j}}{2\\sum_{1\\leq i\\leq K-1}p_{i}}\\leq\\frac{\\sum_{1\\leq i\\neq j\\leq K-1}p_{i}p_{j}}{2(\\sum_{1\\leq i\\leq K-1}p_{i})^{2}}\\leq\\frac{\\sum_{1\\leq i<j\\leq K-1}p_{i}p_{j}}{(\\sum_{1\\leq i\\leq K-1}p_{i})^{2}}\\underset{\\mathrm{Lemma}\\;6}{\\leq}\\frac{K-2}{2(K-1)},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the first inequality used the fact that $\\begin{array}{r}{\\sum_{i=1}^{K-1}p_{i}\\leq1}\\end{array}$ . Thus, $\\begin{array}{r}{\\varepsilon=\\frac{K-2}{2(K-1)}}\\end{array}$ satisfies the condition (11), and the result follows from Theorem 4. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B.5 Invariance principle of $U$ -statistics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this subsection, we state the invariance principle of $U$ -statistics, which plays a main role in the proof of Theorem 5. We note that this is a special case of an approximation of random walks (Theorem 23.14 in [Kal21]) combined with functional central limit theorem (Donsker\u2019s theorem). Here, $\\mathcal{D}[0,1]$ is the Skorokhod space on $[0,1]$ , which is the space of all real-valued right-continuous functions on $[0,1]$ equipped with the Skorokhod metric/topology (see Section 14 in [Bil13]). ", "page_idx": 16}, {"type": "text", "text": "Theorem 7 (Theorem 5.2.1 in [KB13]). Define a $U$ -statistic $\\begin{array}{r}{U_{k}\\,=\\,\\binom{k}{2}^{-1}\\sum_{1\\leq i<j\\leq k}\\Phi(h_{i},h_{j}),}\\end{array}$ , the expectation of the kernel $\\Phi$ as $\\Phi_{0}~=~\\mathbb{E}_{(h,h^{\\prime})\\sim\\rho^{2}}\\Phi(h,h^{\\prime})$ and the first-coordinate variance $\\sigma_{1}^{2}=\\mathsf{V a r}_{h\\sim\\rho}(g_{1}(h))$ , where $g_{1}(h)=\\mathbb{E}_{h^{\\prime}\\sim\\rho}\\Phi(h^{\\prime},h)$ . Let $\\xi_{n}=(\\xi_{n}(t),t\\in[0,1])$ , where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\xi_{n}\\left(\\frac{k}{n}\\right)=\\frac{k(U_{k}-\\Phi_{0})}{2\\sqrt{n\\sigma_{1}^{2}}}\\qquad f o r\\ \\ k=0,1,...,n-1,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and $\\xi_{n}(t)=\\xi_{n}([n t]/n),$ , with $[x]$ denoting the greatest integer less than or equal to $x$ . Then, $\\xi_{n}$ converges weakly in $\\mathcal{D}[0,1]$ to a standard Wiener process as $n\\to\\infty$ . ", "page_idx": 16}, {"type": "text", "text": "C Details on our empirical results ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we provide additional details on our empirical results. ", "page_idx": 16}, {"type": "text", "text": "C.1 Trained classifiers ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "On CIFAR-10 [Kri09] train set with size 50, 000, the following models were trained with 100 epochs, learning rate starting with 0.05. For models trained with learning rate decay, we used learning rate 0.005 after epoch 50, and used 0.0005 after epoch 75. For following models, 5 classifiers are trained for each hyperparameter combination. Five classifiers differ in weight initialization and vary due to the randomized batches used during training. ", "page_idx": 17}, {"type": "text", "text": "\u2022 ResNet18, every combination (width, batch size) of - Width:4, 8, 16, 32, 64, 128 - Batch size: 16, 128, 256, 1024, with learning rate decay Additional batch size of 64, 180, 364 for without learning rate decay   \n\u2022 ResNet50, ResNet101, every combination (width, batch size) of - Width:8, 16 - Batch size: 64, 256, without learning rate decay   \n\u2022 VGG11, every combination (width, batch size) of - Width:16, 64 - Batch size: 64, 256, without learning rate decay   \n\u2022 DenseNet40, every combination (width, batch size) of - Width:5, 12, 40 - Batch size: 64, 256, without learning rate decay ", "page_idx": 17}, {"type": "text", "text": "For models in Figure 4, more than 5 classifiers were trained. The classifiers differ in weight initialization and vary due to the randomized batches used during training. ", "page_idx": 17}, {"type": "text", "text": "\u2022 ResNet18 on CIFAR-10, width 16 and batch size 64 without learning rate decay (20 classifiers)   \nThe models below are trained with learning rate 0.05, momentum 0.9 and weight decay 5e-4   \nwith cosine annealing. \u2022 MobileNet on MNIST, batch size 128 (10 classifiers) \u2022 ResNet18 on FMNIST, width 48 and batch size 128 (10 classifiers) \u2022 ResNet18 on KMNIST, every combination of widths and batch sizes below (8 classifiers each) - Width: 48, 64 - Batch size: 32, 64, 128 ", "page_idx": 17}, {"type": "text", "text": "C.2 Majority vote and tie-free ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For an ensemble with $N$ classifiers, we generated $N$ uniformly-distributed random numbers $e_{1},...,e_{N}\\in[0,0.0001]$ . Then used $\\begin{array}{r}{(\\frac{1}{N}+\\check{e}_{1},\\ldots\\frac{1}{N}+e_{N})}\\end{array}$ after normalization as weights for each classifier. This guarantees the ensemble to be tie-free. ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Main claims made in the abstract and introduction accurately reflect the paper\u2019s contribution and scope. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We discuss the difficulties in estimating certain quantities we are working with. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We provided the proof as clearly as possible. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Details are provided in Appendix C. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce ", "page_idx": 19}, {"type": "text", "text": "the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 20}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: Most of the experiments are straightforward to reproduce. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Details are provided in Appendix C. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We repeated the same procedure across various models and hyperparameter choices. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: The experiment requires no additional time beyond training each classifier. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The research conducted in this paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: All assets used in the paper are properly credited. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]