{"references": [{"fullname_first_author": "Robert Tibshirani", "paper_title": "Regression shrinkage and selection via the Lasso", "publication_date": "1996", "reason": "This paper introduces the Lasso method, a fundamental technique for regularization and feature selection in statistical modeling, which is highly relevant to the concept of sparsity discussed in the target paper."}, {"fullname_first_author": "Cynthia Rudin", "paper_title": "Interpretable machine learning: Fundamental principles and 10 grand challenges", "publication_date": "2022", "reason": "This survey paper provides a comprehensive overview of interpretable machine learning, establishing a strong theoretical foundation for the work on decision sparsity presented in the target paper."}, {"fullname_first_author": "W James Murdoch", "paper_title": "Definitions, methods, and applications in interpretable machine learning", "publication_date": "2019-01-01", "reason": "This paper offers a structured review of interpretable machine learning methods, which contextualizes the concept of decision sparsity within the broader field of interpretability."}, {"fullname_first_author": "Yiyang Sun", "paper_title": "Sparse and faithful explanations without sparse models", "publication_date": "2024", "reason": "This paper introduces the Sparse Explanation Value (SEV), a key concept that forms the basis of the research presented in the target paper."}, {"fullname_first_author": "Ramaravind K Mothilal", "paper_title": "Explaining machine learning classifiers through diverse counterfactual explanations", "publication_date": "2020", "reason": "This paper explores counterfactual explanations, an alternative approach to explaining model decisions, which is compared and contrasted with the SEV approach in the target paper."}]}