[{"figure_path": "SjQ1iIqpfU/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of the average performance of CoBo across different sampling strategies for updating the weights of client pairs in the collaboration matrix. All strategies demonstrate performance close to that of the non-sampling oracle. However, the mixed strategy, which combines a constant sampling rate at the start with a time-dependent rate during later training phases, shows superior performance.", "description": "This table compares the performance of the CoBo algorithm using three different sampling strategies for updating collaboration weights: constant, time-dependent, and mixed.  The results are compared against a non-sampling oracle (all pairs updated). The metrics used are accuracy and loss.  The mixed strategy, which combines initial constant sampling with later time-dependent sampling, shows the best performance, closely matching the oracle.", "section": "4.1 Cross-silo federated learning experiment with 8 clients"}, {"figure_path": "SjQ1iIqpfU/tables/tables_8_1.jpg", "caption": "Table 2: Comparisons of model quality and fairness measure of personalized models for cross-silo experiment with 8 clients, and cross-device experiment with 80 clients, and the language modelling experiment with 4 clients having different languages. Federated clustering (FC) is not scalable with number of clients due to its O(n\u00b2) complexity, and therefore ignored in the cross-device fl experiment. The clustering algorithms IFCA and FC are not applicable to LLMs and there ignored. Note that Oracle is not defined in the LLMs experiment. The column \"Imp.(%)\" demonstrates the percentage of clients with improved performance compared to local training.", "description": "This table compares the performance of various collaborative learning algorithms across three different experimental settings: a cross-silo experiment with 8 clients, a cross-device experiment with 80 clients, and a language modeling experiment with 4 clients using different languages.  The table shows the accuracy, loss, and improvement percentage compared to local training for each algorithm in each setting.  For the language modeling experiment, perplexity and its improvement are reported instead of accuracy and loss.  Note that the \"Oracle\" represents an ideal scenario, and is only defined for the first two experiments, and that Federated Clustering is not scalable for the 80-client experiment.", "section": "4 Experiments"}]