[{"figure_path": "QXQY58xU25/figures/figures_1_1.jpg", "caption": "Figure 1: Neural program decomposition for scene recognition.", "description": "This figure illustrates the decomposition of a scene recognition task into a neural model and a program. The neural model (M\u03b8) processes an image and identifies objects within the scene. The output of the neural model is then fed into a program (P) that utilizes a large language model (LLM), specifically GPT-4 in this instance, to determine the room type based on the identified objects. The input image shows a kitchen scene with a sink, cup, dish and paper towel. The neural model detects these objects and provides this information as input to the program. The program then utilizes this input to query the LLM, resulting in the final output of \"kitchen.\"", "section": "1 Introduction"}, {"figure_path": "QXQY58xU25/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of our inference pipeline for the leaf classification task. leaf_id can be written with a decision tree (top program) or with a call to GPT-4 (bottom program).", "description": "This figure illustrates the inference pipeline for the leaf classification task. The input is a leaf image, which is processed by a neural model to predict three leaf characteristics: shape, margin, and texture. These characteristics are then used as input to a program, leaf_id, which can be implemented either as a traditional decision tree or as a call to GPT-4. The output of leaf_id is a classification of the leaf species along with a probability score indicating the confidence of the prediction.", "section": "Leaf Classification"}, {"figure_path": "QXQY58xU25/figures/figures_8_1.jpg", "caption": "Figure 3: Accuracy vs. Time for sum3.", "description": "This figure shows a comparison of the accuracy over time for the ISED and A-NeSI methods on the 'sum3' task from the MNIST-R benchmark.  The x-axis represents training time in seconds, and the y-axis shows the accuracy.  The blue line and squares represent ISED, while the orange line and circles represent A-NeSI. Shaded areas show standard deviations.  The figure illustrates that ISED achieves higher accuracy more quickly than A-NeSI in the early stages of training.", "section": "4.5 RQ3: Data Efficiency"}, {"figure_path": "QXQY58xU25/figures/figures_8_2.jpg", "caption": "Figure 3: Accuracy vs. Time for sum3.", "description": "This figure shows the accuracy of ISED and A-NeSI over training time (in seconds) for the sum3 task from the MNIST-R benchmark.  ISED demonstrates significantly faster learning, reaching a higher accuracy much sooner than A-NeSI, highlighting ISED's greater sample efficiency.  The shaded regions represent standard deviations.", "section": "4.5 RQ3: Data Efficiency"}]