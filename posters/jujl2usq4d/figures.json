[{"figure_path": "juJl2uSq4D/figures/figures_2_1.jpg", "caption": "Figure 1: Highlevel description of LMDP-OMLE. In the online phase, we find a new test policy under which models in the confidence set do not agree. Then the exploration policy is constructed with our new notion of segmentation of policies within test that are executed throughout. In the offline phase, we add the batched sample trajectories to dataset and update the confidence set of models.", "description": "This figure shows a high-level overview of the LMDP-OMLE algorithm.  The algorithm iteratively refines a confidence set of models. In the online phase, it finds a new test policy that reveals disagreement among the models in the confidence set. It then constructs an exploration policy using the new concept of segmented policies, executing multiple policies sequentially, potentially incorporating random actions at specific checkpoints. In the offline phase, the algorithm updates the confidence set by incorporating new data generated during the online exploration phase.", "section": "Efficient Exploration in LMDPs"}]