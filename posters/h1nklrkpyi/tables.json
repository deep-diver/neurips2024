[{"figure_path": "H1NklRKPYi/tables/tables_6_1.jpg", "caption": "Table 1: Classification accuracy on real-scanned point clouds (ScanObjectNN). We report the overall accuracy (%) on three variants. \"#Params\" represents the model\u2019s parameters and FLOPs refer to the model\u2019s floating point operations. GPT, CL, and MPM respectively refer to pre-training strategies based on autoregression, contrastive learning, and masked point modeling.  is the reported results from the original paper.  is the result reproduced in our downstream settings.", "description": "This table presents a comparison of various point cloud models on the ScanObjectNN dataset, focusing on classification accuracy.  It includes both supervised and self-supervised learning methods, showcasing the performance of the proposed LCM model against existing state-of-the-art techniques.  Key metrics such as model parameters (#Params), floating point operations (FLOPs), and classification accuracy on three different ScanObjectNN variants (OBJ-BG, OBJ-ONLY, PB-T50-RS) are presented, allowing for a comprehensive comparison of model efficiency and effectiveness.", "section": "4.2.1 Object Classification"}, {"figure_path": "H1NklRKPYi/tables/tables_7_1.jpg", "caption": "Table 1: Classification accuracy on real-scanned point clouds (ScanObjectNN). We report the overall accuracy (%) on three variants. \"#Params\" represents the model's parameters and FLOPs refer to the model's floating point operations. GPT, CL, and MPM respectively refer to pre-training strategies based on autoregression, contrastive learning, and masked point modeling.  is the reported results from the original paper.  is the result reproduced in our downstream settings.", "description": "This table presents a comparison of various point cloud models' performance on the ScanObjectNN dataset, focusing on classification accuracy.  It breaks down the results by pre-training method (autoregressive, contrastive learning, masked point modeling), showing the overall accuracy, number of parameters, and floating point operations for each model.  The table also includes comparisons to results reported in original papers and results reproduced by the authors using consistent downstream settings.  This allows for a comprehensive assessment of model efficiency and accuracy.", "section": "4.2.1 Object Classification"}, {"figure_path": "H1NklRKPYi/tables/tables_8_1.jpg", "caption": "Table 4: Effects of the Network Structure of the Locally Constrained Compact Encoder.", "description": "This table presents an ablation study on the locally constrained compact encoder, showing the impact of different components (Local Aggregation Layer, MLPs, FFN) on the model's performance (ScanObjectNN accuracy).  It demonstrates the importance of local geometric perception and aggregation for point cloud feature extraction.  Comparing the results of configurations A through D indicates that including a local aggregation layer and MLPs significantly improves performance, while the FFN provides a small additional benefit.", "section": "4.3 Ablation Study"}, {"figure_path": "H1NklRKPYi/tables/tables_8_2.jpg", "caption": "Table 5: Effects of Locally Constrained Mamba-based Decoder.", "description": "This table presents the ablation study results, focusing on the impact of different decoder architectures on the performance of the model.  It compares the performance of a standard Transformer decoder against a locally constrained Mamba-based decoder, both with and without the addition of a Local Constraints Feedforward Network (LCFFN). The results are shown in terms of classification accuracy on the ScanObjectNN dataset.", "section": "4.3 Ablation Study"}, {"figure_path": "H1NklRKPYi/tables/tables_17_1.jpg", "caption": "Table 1: Classification accuracy on real-scanned point clouds (ScanObjectNN). We report the overall accuracy (%) on three variants. \"#Params\" represents the model\u2019s parameters and FLOPs refer to the model\u2019s floating point operations. GPT, CL, and MPM respectively refer to pre-training strategies based on autoregression, contrastive learning, and masked point modeling.  is the reported results from the original paper.  is the result reproduced in our downstream settings.", "description": "This table presents a comparison of various point cloud models' performance on the ScanObjectNN dataset, focusing on classification accuracy.  It breaks down the results by different pre-training methods (GPT, CL, MPM), showing overall accuracy, the number of parameters (#Params), and floating point operations (FLOPs).  The table also highlights the improvements achieved by the proposed LCM model compared to existing Transformer-based models.  Both original reported and reproduced results are included.", "section": "4.2.1 Object Classification"}, {"figure_path": "H1NklRKPYi/tables/tables_17_2.jpg", "caption": "Table 1: Classification accuracy on real-scanned point clouds (ScanObjectNN). We report the overall accuracy (%) on three variants. \"#Params\" represents the model's parameters and FLOPs refer to the model's floating point operations. GPT, CL, and MPM respectively refer to pre-training strategies based on autoregression, contrastive learning, and masked point modeling.  is the reported results from the original paper.  is the result reproduced in our downstream settings.", "description": "This table compares the performance of various point cloud models on the ScanObjectNN dataset, focusing on classification accuracy.  It breaks down the results by three variants of the dataset and includes the number of parameters (#Params), floating point operations (FLOPs), and pre-training strategy used for each model (GPT, CL, MPM).  It also notes whether results are from the original papers or reproduced by the authors.  The table highlights the performance improvements achieved by LCM compared to other models.", "section": "4.2.1 Object Classification"}]