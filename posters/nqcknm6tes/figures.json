[{"figure_path": "NQCkNM6TES/figures/figures_0_1.jpg", "caption": "Figure 1: Comparison of our DiMoP3D with the SoTA baseline [5]. Purple meshes represent observations, and yellow meshes denote predictions. DiMoP3D produces high-fidelity, diverse sequences tailored to real-world 3D scenes, while BeLFusion's inadequate scene context integration leads to issues such as object penetration, motion incoherence, and scene inconsistency.", "description": "This figure compares the performance of the proposed DiMoP3D model against a state-of-the-art baseline (BeLFusion) for diverse human motion prediction in 3D scenes.  The purple meshes represent the observed human motion, while the yellow meshes show the predicted motion from each model. DiMoP3D generates predictions that are more realistic, diverse and consistent with the surrounding environment, as opposed to BeLFusion, which suffers from issues such as object penetration, incoherent motion, and inconsistencies with the scene.", "section": "Abstract"}, {"figure_path": "NQCkNM6TES/figures/figures_3_1.jpg", "caption": "Figure 2: The architecture of DiMoP3D. DiMoP3D incorporates two modalities of input, the past motion and the 3D scene point cloud. Initially, the Context-aware Intermodal Interpreter encodes the point cloud to features Fs, identifies interactive objects O, and uses a cross-modal InterestNet to pinpoint potential interest areas, sampling a target instance Og according to interest map M. Following this, the Behaviorally-consistent Stochastic Planner forecasts the interactive human end-pose L+\u2206L, and devises an obstacle-free trajectory plan towards this pose. The sampled end-pose and trajectory are incorporated as a stochastic conditional factor to prompt the Self-prompted Motion Generator to generate physically consistent future motions.", "description": "This figure illustrates the architecture of the DiMoP3D model, which takes past human motion and a 3D scene point cloud as input.  It shows how the model processes this information through three main components: Context-aware Intermodal Interpreter, Behaviorally-Consistent Stochastic Planner, and Self-Prompted Motion Generator. The first component identifies potential interaction targets within the scene. The second component plans obstacle-free trajectories to those targets. Finally, the third component generates diverse and physically consistent future motion predictions conditioned on the planned trajectory and target.", "section": "3 Method"}, {"figure_path": "NQCkNM6TES/figures/figures_8_1.jpg", "caption": "Figure 3: Visual comparisons between DiMoP3D and SoTA BeLFusion in bedroom and seminar room scenarios. BeLFusion's predictions, which rely solely on past human motion without considering 3D scene context, are shown on the left. In contrast, DiMoP3D, displayed on the right, incorporates interactive goals and designs obstacle-free trajectories for each sequence. Purple meshes depict observed motions, while yellow ones signify predicted future motions. For clarity, distortions in BeLFusion's predictions are marked: red boxes for object penetration, green boxes for motion incoherence, and yellow boxes for scene inconsistency.", "description": "This figure compares the motion prediction results of DiMoP3D and BeLFusion, a state-of-the-art method.  The left side shows BeLFusion's predictions, highlighting issues like object penetration, motion incoherence, and scene inconsistency because it doesn't consider the 3D scene context.  The right side displays DiMoP3D's results, demonstrating accurate and physically plausible motion predictions with obstacle avoidance and consideration for interactive goals within the 3D scene.", "section": "4.4 Visualization"}, {"figure_path": "NQCkNM6TES/figures/figures_9_1.jpg", "caption": "Figure 4: Visualizations of diverse predicted end-poses across five object point clouds. The HOI-Estimator can generate a variety of human-object interactive poses tailored to specific scenarios.", "description": "This figure visualizes the diverse end poses generated by the HOI-Estimator for five different object types: chair, table, bed, cabinet, and another object.  It shows how the model predicts various plausible interactions between humans and objects in 3D scenes, illustrating the model's ability to produce diverse and contextually appropriate human poses in different scenarios.", "section": "4.4 Visualization"}, {"figure_path": "NQCkNM6TES/figures/figures_19_1.jpg", "caption": "Figure 5: Visualization samples of the modified A* trajectory planner. Black lines denote the observed trajectory, while colored lines represent the generated paths.", "description": "This figure visualizes the paths generated by the modified A* trajectory planner.  It shows three examples of trajectories planned from a starting point to a destination point in a 3D environment. The black lines represent the observed trajectory while the colored lines represent the planned trajectories. The planner is designed to generate diverse and obstacle-free paths between the points. The figure highlights the ability of the modified A* algorithm to find multiple valid paths that avoid obstacles in complex environments.", "section": "3.3 Behaviorally-Consistent Stochastic Planner"}, {"figure_path": "NQCkNM6TES/figures/figures_19_2.jpg", "caption": "Figure 6: Visualization of 3D scene instance segmentation (upper) and the corresponding interest map (lower). Red points in the interest map denote higher interest, while blue points denote lower interest. Leveraging the insight provided by the predicted interest map enables the exclusion of improbable or illogical targets, thereby enhancing the reliability and scene congruency of predictions.", "description": "This figure shows the results of 3D scene instance segmentation and interest map prediction. The upper part shows the instance segmentation results for three different scenes (bedroom, living room, and laboratory), color-coded for different objects. The lower part shows the predicted interest map for each scene. The color intensity represents the level of human interest in that area, with red indicating high interest and blue indicating low interest. This method helps identify the probable target object for motion prediction.", "section": "3.2 Context-Aware Intermodal Interpreter"}, {"figure_path": "NQCkNM6TES/figures/figures_20_1.jpg", "caption": "Figure 3: Visual comparisons between DiMoP3D and SoTA BeLFusion in bedroom and seminar room scenarios. BeLFusion's predictions, which rely solely on past human motion without considering 3D scene context, are shown on the left. In contrast, DiMoP3D, displayed on the right, incorporates interactive goals and designs obstacle-free trajectories for each sequence. Purple meshes depict observed motions, while yellow ones signify predicted future motions. For clarity, distortions in BeLFusion's predictions are marked: red boxes for object penetration, green boxes for motion incoherence, and yellow boxes for scene inconsistency.", "description": "This figure compares the motion predictions of DiMoP3D and BeLFusion in two different scenarios: a bedroom and a seminar room.  DiMoP3D uses 3D scene context to generate diverse and physically realistic motion predictions, while BeLFusion, which only uses past motion data, produces unrealistic predictions with issues such as object penetration, motion incoherence, and scene inconsistency.  The figure highlights the advantages of incorporating 3D scene information into motion prediction.", "section": "4.4 Visualization"}, {"figure_path": "NQCkNM6TES/figures/figures_20_2.jpg", "caption": "Figure 3: Visual comparisons between DiMoP3D and SoTA BeLFusion in bedroom and seminar room scenarios. BeLFusion's predictions, which rely solely on past human motion without considering 3D scene context, are shown on the left. In contrast, DiMoP3D, displayed on the right, incorporates interactive goals and designs obstacle-free trajectories for each sequence. Purple meshes depict observed motions, while yellow ones signify predicted future motions. For clarity, distortions in BeLFusion's predictions are marked: red boxes for object penetration, green boxes for motion incoherence, and yellow boxes for scene inconsistency.", "description": "This figure compares the motion predictions of DiMoP3D and BeLFusion in two different scenarios: a bedroom and a seminar room.  BeLFusion, a state-of-the-art method that doesn't consider the 3D scene context, produces predictions with artifacts such as object penetration, motion incoherence, and scene inconsistency. In contrast, DiMoP3D generates high-fidelity predictions with diverse and physically consistent motion trajectories that avoid obstacles and interact naturally with the scene.", "section": "4.4 Visualization"}]