[{"figure_path": "pR5g1bBqoV/figures/figures_1_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multi-Layer Perceptron (MLP) trained on CIFAR10 using Sharpness Aware Minimization (SAM) with different parameterizations.  The left panel shows a contour plot of test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various MLP widths.  It highlights that only the \u00b5P\u00b2 parameterization allows for transferability of optimal hyperparameters across different model widths. The right panel shows a slice of the left panel at the optimal learning rate for each parameterization and width 4096, further emphasizing the superior generalization performance of \u00b5P\u00b2.  The figure demonstrates the importance of layerwise perturbation scaling for achieving consistent performance across different model scales.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_3_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the results of experiments on a 3-layer MLP trained with SAM on CIFAR10 dataset.  The experiments test different parameterizations of SAM, varying learning rate (\u03b7) and perturbation radius (\u03c1) for MLPs of different widths.  The left panel shows a contour plot illustrating the test accuracy across various learning rates and perturbation radii, highlighting the optimal parameter region for each configuration. The right panel presents a slice through the optimal learning rate for a width of 4096, emphasizing the superior generalization performance of the proposed \u00b5P\u00b2 parameterization.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_6_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure empirically demonstrates the performance of different parameterizations of SAM across various model widths.  The left panel shows a contour plot illustrating the test accuracy as a function of the learning rate and perturbation radius for a 3-layer MLP trained on CIFAR10.  It highlights that only the proposed \u00b5P\u00b2 parameterization allows for transfer of optimal hyperparameters (learning rate and perturbation radius) across different model widths. The right panel shows the same data but sliced at the optimal learning rate for each parameterization, further emphasizing \u00b5P\u00b2's superior generalization performance.", "section": "4 Sharpness Aware Minimization in the infinite-width limit"}, {"figure_path": "pR5g1bBqoV/figures/figures_8_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "The figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using different parameterizations of Sharpness Aware Minimization (SAM).  The left panel shows a heatmap depicting test accuracy across various learning rates (\u03b7) and perturbation radii (\u03c1) for different network widths and parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2). The right panel shows a line graph of the test accuracy at the optimal learning rate for each parameterization, highlighting that \u00b5P\u00b2 achieves the best generalization performance and is the only parameterization where both optimal learning rate (\u03b7) and perturbation radius (\u03c1) transfer across different model widths.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_9_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs.'\u00d7' denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using different parameterizations of Sharpness Aware Minimization (SAM).  The left panel shows a contour plot illustrating how test accuracy varies with learning rate (\u03b7) and perturbation radius (\u03c1) for different model widths and SAM parameterizations. \u00b5P\u00b2 represents the proposed Maximal Update and Perturbation Parameterization. The right panel shows the same data but sliced at the optimal learning rate for each parameterization and width of 4096, highlighting that \u00b5P\u00b2 achieves the best generalization performance and is the only parameterization where both the optimal learning rate and perturbation radius transfer across different model widths.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_9_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure displays the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using Sharpness Aware Minimization (SAM) with different parameterizations. The left subplot shows test accuracy as a function of learning rate and perturbation radius, highlighting the joint optimal hyperparameters for different model widths. The right subplot shows a slice of this data at the optimal learning rate for each parameterization and width 4096. The results indicate that only \u00b5P\u00b2 achieves transferability of optimal hyperparameters across model widths, which shows that \u00b5P\u00b2 is the most effective parameterization for SAM.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_54_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the impact of different parameterizations on the test accuracy of a 3-layer Multi-Layer Perceptron (MLP) trained on CIFAR10 dataset using Sharpness Aware Minimization (SAM).  The left panel displays a heatmap showing the test accuracy as a function of learning rate (\u03b7) and perturbation radius (p) for various MLP widths and different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, and \u00b5P\u00b2). The right panel shows a slice of the left panel at the optimal learning rate for each parameterization and width 4096, highlighting the superior generalization performance of \u00b5P\u00b2.  The figure demonstrates that \u00b5P\u00b2 is the only parameterization that effectively transfers both the optimal learning rate and perturbation radius across different model scales.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_55_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the impact of different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) on the test accuracy of a 3-layer MLP trained on CIFAR10 with SAM.  The left panel shows a heatmap illustrating test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various network widths. It highlights that only the \u00b5P\u00b2 parameterization allows for the joint transfer of optimal \u03b7 and \u03c1 across different network widths.  The right panel shows the test accuracy for each parameterization at the optimal learning rate for a network of width 4096.  \u00b5P\u00b2 consistently outperforms other parameterizations, demonstrating its superior generalization ability.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_56_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and \u03c1): Test accuracy as a function of learning rate \u03b7 and perturbation radius \u03c1 of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling \u03c1 = \u0398(n\u22121/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 2\u03c3-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 dataset using different parameterizations of Sharpness Aware Minimization (SAM). The left panel shows a 2D heatmap of test accuracy as a function of learning rate and perturbation radius for various MLP widths.  The right panel shows a 1D slice of the left panel at the optimal learning rate for each parameterization and width 4096.  The results demonstrate that only the \u00b5P\u00b2 parameterization achieves both hyperparameter transfer (optimal learning rate and perturbation radius remain similar across model sizes) and the best generalization performance.", "section": "Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_57_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "The figure shows the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM with different parameterizations as a function of learning rate (\u03b7) and perturbation radius (\u03c1).  The left panel shows the results across various model widths and parameterizations.  The right panel shows the same results but only for the largest model width (4096), with the x-axis showing only the perturbation radius and the lines representing different parameterizations at the optimal learning rate for each. The figure demonstrates that only the \u00b5P\u00b2 parameterization allows for transferability of optimal hyperparameters across model scales. The other parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, SP-LP) do not effectively allow this transfer.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_57_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using Sharpness Aware Minimization (SAM) with different parameterizations.  The left plot shows a contour plot of test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various network widths.  The right plot is a slice of the left plot at the optimal learning rate for each parameterization and width 4096.  The figure demonstrates that only the proposed \u00b5P\u00b2 parameterization achieves both hyperparameter transfer and optimal generalization performance.  The different parameterizations represent different scaling approaches for the perturbation radius.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_58_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the effect of different parameterizations on the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM.  It compares four parameterizations: SP-naive (no perturbation scaling), \u00b5P-naive (no perturbation scaling), \u00b5P-global (global perturbation scaling), and \u00b5P2 (Maximal Update and Perturbation Parameterization with layerwise scaling). The left panel shows a contour plot of test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various network widths. The right panel shows a slice of this contour plot at the optimal learning rate for each parameterization and width 4096.  The results highlight that only \u00b5P2 allows for transfer of optimal hyperparameters (\u03b7 and \u03c1) across different network widths, indicating the importance of layerwise perturbation scaling for effective SAM.", "section": "Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_58_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the impact of different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) on the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM.  The left panel shows test accuracy as a heatmap across various learning rates (\u03b7) and perturbation radii (\u03c1) for different widths and parameterizations.  The right panel shows the same data but sliced at the optimal learning rate for each parameterization at width 4096.  The \u00b5P\u00b2 parameterization consistently shows the largest stable region of high accuracy across different widths and is highlighted as the best-performing method.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_58_3.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM with different parameterizations.  The left panel shows a heatmap illustrating the relationship between the learning rate (\u03b7) and perturbation radius (p) for achieving optimal test accuracy.  Different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) are compared, showcasing the effect of layerwise perturbation scaling on hyperparameter sensitivity. The right panel provides a slice of the heatmap at the optimal learning rate for each parameterization, further highlighting \u00b5P\u00b2's superior performance and hyperparameter transferability.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_59_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using Sharpness Aware Minimization (SAM) with different parameterizations.  The left panel shows the accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for different MLP widths and parameterizations.  The right panel shows a slice of the left panel at the optimal learning rate for each parameterization for a width of 4096.  It demonstrates the superior generalization performance of \u00b5P2 parameterization across various model widths compared to other parameterizations like SP (Standard Parameterization) and \u00b5P (Maximal Update Parameterization). The plots highlight the optimal hyperparameters, regions of high accuracy, and unstable regions.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_60_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using the Sharpness Aware Minimization (SAM) algorithm.  The figure explores the effect of different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) on the test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1).  The left side shows the complete landscape, while the right side shows a slice at the optimal learning rate for each parameterization and a width of 4096.  The \u00b5P\u00b2 parameterization demonstrates superior generalization performance and the ability to transfer optimal hyperparameters (\u03b7 and \u03c1) across different model widths.", "section": "Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_60_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the impact of different parameterizations on the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 with SAM.  The left panel shows a contour plot illustrating the test accuracy across varying learning rates (\u03b7) and perturbation radii (p) for four different parameterizations: SP-naive, \u00b5P-naive, \u00b5P-global, and \u00b5P\u00b2.  The right panel shows a line plot depicting the test accuracy at the optimal learning rate for each parameterization at width 4096.  The results indicate that \u00b5P\u00b2 achieves superior generalization performance, and that only \u00b5P\u00b2 allows for transfer of both optimal learning rate and perturbation radius across different model widths.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_60_3.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer MLP trained on CIFAR10 with SAM under different parameterizations as a function of learning rate and perturbation radius.  The left panel shows the results for various network widths, while the right panel focuses on width 4096, showing test accuracy at the optimal learning rate for each parameterization.  The results highlight that only the \u00b5P\u00b2 parameterization (Maximal Update and Perturbation Parameterization) allows for the transfer of both the optimal learning rate and perturbation radius across different model widths. Other parameterizations, such as the naive approach (no perturbation scaling) and a global perturbation scaling approach, fail to demonstrate this transferability.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_60_4.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 using different parameterizations of Sharpness Aware Minimization (SAM).  The left panel shows a heatmap illustrating the test accuracy as a function of the learning rate (\u03b7) and perturbation radius (\u03c1) for various MLP widths.  Different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) are compared, each using a different approach to scaling the perturbation radius with respect to the network width (n). The right panel shows slices of this heatmap at the optimal learning rate for each parameterization and width 4096, highlighting that \u00b5P\u00b2 achieves the best generalization performance and is the only parameterization where both the optimal learning rate and perturbation radius transfer across different network widths.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_61_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the results of an experiment comparing different parameterizations of SAM on a 3-layer MLP trained on CIFAR10.  The left panel shows a heatmap of test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various network widths and parameterizations.  The right panel shows a line plot of test accuracy at the optimal learning rate for each parameterization at a width of 4096. The figure demonstrates that only the \u00b5P\u00b2 parameterization achieves both hyperparameter transfer (optimal \u03b7 and \u03c1 remain similar across model widths) and the best generalization performance.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_61_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multi-Layer Perceptron (MLP) trained on CIFAR10 using different parameterizations of the Sharpness Aware Minimization (SAM) algorithm.  The left plots show a heatmap of the test accuracy across different values of the learning rate and perturbation radius, demonstrating the effect of hyperparameter choices.  The right plots show the test accuracy at the optimal learning rate for each parameterization. The figure highlights the effectiveness of the proposed Maximal Update and Perturbation Parameterization (\u00b5P\u00b2) method, which achieves better generalization performance and transferability of optimal hyperparameters across different model sizes.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_62_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 2\u03c3-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM with different parameterizations.  The left panel shows a contour plot of test accuracy as a function of learning rate and perturbation radius for different network widths.  It highlights that only the \u00b5P\u00b2 parameterization allows for transfer of optimal hyperparameters across different network widths. The right panel shows the test accuracy at the optimal learning rate for each parameterization and width 4096, demonstrating \u00b5P\u00b2's superior generalization performance.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_62_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P\u00b2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the results of an experiment comparing different parameterizations of Sharpness Aware Minimization (SAM) on a 3-layer Multilayer Perceptron (MLP) trained on the CIFAR10 dataset.  The left panel shows a contour plot of test accuracy as a function of learning rate (\u03b7) and perturbation radius (p) for various network widths.  The right panel shows a slice of this data at the optimal learning rate for each parameterization and width 4096.  The key finding is that only the \u00b5P\u00b2 parameterization achieves both hyperparameter transfer (optimal \u03b7 and p are consistent across network widths) and the best generalization performance.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_63_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the impact of different parameterizations (SP-naive, \u00b5P-naive, \u00b5P-global, \u00b5P\u00b2) on the test accuracy of a 3-layer MLP trained on CIFAR10 using SAM.  The left panel shows a heatmap of test accuracy as a function of learning rate and perturbation radius for various network widths.  The right panel shows a slice of this heatmap at the optimal learning rate for each parameterization and width 4096. The results demonstrate that only \u00b5P\u00b2 allows for consistent transfer of optimal hyperparameters across different network widths, achieving the best generalization performance.  The other parameterizations show either instability or limited effectiveness.", "section": "4 Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}, {"figure_path": "pR5g1bBqoV/figures/figures_63_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer MLP trained with SAM on CIFAR10 as a function of learning rate and perturbation radius.  It compares different parameterizations of SAM: standard SAM (SP-naive), SAM with global perturbation scaling (\u00b5P-global), and the proposed \u00b5P\u00b2 parameterization. The left panel shows the results for various network widths. The right panel shows a slice of the left panel at the optimal learning rate for each parameterization, focusing on width 4096.  The figure demonstrates that only the \u00b5P\u00b2 parameterization achieves both hyperparameter transfer (optimal learning rate and perturbation radius remain consistent across model widths) and superior generalization performance.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_64_1.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "This figure shows the test accuracy of a 3-layer Multi-Layer Perceptron (MLP) trained on CIFAR10 using different parameterizations of Sharpness Aware Minimization (SAM) as a function of learning rate and perturbation radius.  The left panel shows a heatmap illustrating the performance across various learning rates and perturbation radii for different SAM parameterizations and model widths. The right panel is a slice of the left panel at the optimal learning rate for each parameterization, showing that \u00b5P\u00b2 achieves significantly higher performance than other methods. The figure demonstrates the impact of layerwise perturbation scaling on SAM's performance and hyperparameter transferability.", "section": "Contributions"}, {"figure_path": "pR5g1bBqoV/figures/figures_64_2.jpg", "caption": "Figure 1: Left (Only \u00b5P\u00b2 transfers both \u03b7 and p): Test accuracy as a function of learning rate \u03b7 and perturbation radius p of a 3-layer MLP trained with SAM on CIFAR10 for various widths and in different parameterizations (see subplot title), averaged over 3 independent runs. \u2018\u00d7\u2019 denotes the optimum. Blue contours (the darker, the wider) denote the region within 1% of the optimal test accuracy smoothened with a Gaussian filter. Grey regions (the lighter, the wider) denote the unstable regime below 30% test accuracy. \u2018naive\u2019 denotes no perturbation scaling, \u2018global\u2019 denotes global perturbation scaling p = \u0398(n-1/2). Right (\u00b5P2 achieves the best generalization performance): Same as left but sliced at the optimal learning rate of each parameterization for width 4096. Dashed horizontal lines denote the base optimizer SGD in SP (green) and in \u00b5P (blue), respectively. Average and 20-CI from 16 independent runs. SP-LP denotes SP with layerwise perturbation scaling.", "description": "The figure shows the test accuracy of a 3-layer Multilayer Perceptron (MLP) trained on CIFAR10 dataset using Sharpness Aware Minimization (SAM) with different parameterizations.  The left panel shows the test accuracy as a function of learning rate (\u03b7) and perturbation radius (\u03c1) for various MLP widths.  The right panel shows a slice of the left panel at the optimal learning rate for each parameterization and a width of 4096.  The results demonstrate that only the \u00b5P\u00b2 parameterization achieves optimal hyperparameter transfer (both learning rate and perturbation radius) across different model widths, leading to the best generalization performance.", "section": "Maximal Update and Perturbation Parameterization (\u00b5P\u00b2)"}]