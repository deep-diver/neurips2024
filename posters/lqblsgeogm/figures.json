[{"figure_path": "LQBlSGeOGm/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of proposed guidelines when incorporated in our MolPhenix contrastive phenomolecular retrieval framework. We address challenges by utilizing uni-modal pretrained MAE & MPNN models, inter-sample weighting with a dosage aware S2L loss, undersampling inactive molecules, and encoding molecular concentration.", "description": "This figure illustrates the architecture of the MolPhenix model, highlighting the three key guidelines employed to improve contrastive phenomolecular retrieval. Guideline 1 uses uni-modal pretrained models for phenomics (MAE) and molecular data (MPNN) to leverage knowledge learned from large datasets and mitigate data scarcity issues. Guideline 2 addresses the challenge of inactive molecules by incorporating a soft-weighted sigmoid locked loss (S2L) that weighs similarities between samples, undersampling inactive pairs. Guideline 3 incorporates molecular concentration information explicitly and implicitly using S2L, enhancing the model's ability to generalize across different concentrations.", "section": "1 Introduction"}, {"figure_path": "LQBlSGeOGm/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the contrastive phenomolecular retrieval challenge. Image x\u2081 and a set of molecules and corresponding concentrations (mk, ck) get mapped into a Rd latent space. Their similarities get computed with fsim and ranked to evaluate whether the paired perturbation appears in the top K%.", "description": "This figure illustrates the core challenge addressed in the paper: contrastive phenomolecular retrieval.  Given a microscopy image (xi) showing a cell's morphology after treatment with a molecule, the task is to identify which molecule (from a set of candidates {mk, ck}) caused the observed morphological change. The model learns a joint embedding space for both image and molecular data.  The similarity between the image embedding (zxi) and each molecule embedding (zm) is calculated using a similarity metric (fsim). The correct molecule should ideally rank highly (within the top K%) in terms of similarity.", "section": "Challenge 1: Phenomic Pretraining and Generalization"}, {"figure_path": "LQBlSGeOGm/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of the contrastive phenomolecular retrieval challenge. Image x\u2081 and a set of molecules and corresponding concentrations (mk, ck) get mapped into a Rd latent space. Their similarities get computed with fsim and ranked to evaluate whether the paired perturbation appears in the top K%.", "description": "This figure illustrates the contrastive phenomolecular retrieval challenge.  Given a microscopy image (x\u1d62) of cells exhibiting a morphological change, the goal is to identify the molecule (m\u1d62) and its concentration (c\u1d62) that caused the change from a set of possible molecules and concentrations.  The process involves embedding both the image and each molecule-concentration pair into a shared latent space (R<sup>d</sup>).  A similarity metric (f<sub>sim</sub>) is used to compare the image embedding with each molecule-concentration pair embedding and rank the pairs based on similarity.  A successful retrieval occurs if the correct molecule and concentration are ranked within the top K%.", "section": "Challenge 1: Phenomic Pretraining and Generalization"}, {"figure_path": "LQBlSGeOGm/figures/figures_7_1.jpg", "caption": "Figure 4: Comparison of training phenomic encoder from scratch and utilizing pre-trained Phenom1 unseen dataset. X-axis plotted on logarithmic scale.", "description": "This figure compares the performance of three different models on a molecular retrieval task: MolPhenix trained with Phenom1, CLOOME trained with Phenom1, and CLOOME trained with images.  The x-axis shows the number of samples seen during training, plotted on a logarithmic scale to better visualize the progression. The y-axis represents the top 1% retrieval accuracy. Two lines are shown for each model, one for all compounds and one for only active compounds, revealing the performance differences between these two groups. The figure demonstrates that MolPhenix trained with the pre-trained Phenom1 model significantly outperforms the other two models, highlighting the effectiveness of utilizing a pre-trained phenomics encoder.  The gap between the performance on all compounds and active compounds is also notable for each model.", "section": "5.1 Evaluation on cumulative concentrations"}, {"figure_path": "LQBlSGeOGm/figures/figures_9_1.jpg", "caption": "Figure 5: Ablations of top-1% recall accuracy with (top-left) the size of embedding dimension, (top-center) number of parameters, (top-right) batch size, (bottom-left) cutoff p-value, (bottom-center) fingerprint type, and (bottom-right) random batch averaging. Compact embedding sizes from pretrained models, larger number of parameters, larger batch sizes, lower cutoff p-values, pretrained MolGPS fingerprints and presence of random batch averaging improving retrieval of our MolPhenix framework.", "description": "This figure shows the ablation study on MolPhenix, examining the effects of different hyperparameters and design choices on the model's performance.  It demonstrates the positive impact of using compact embeddings from pre-trained models, larger numbers of parameters, larger batch sizes, lower cutoff p-values, using pretrained MolGPS fingerprints, and incorporating random batch averaging.", "section": "5 Results and Discussion"}, {"figure_path": "LQBlSGeOGm/figures/figures_24_1.jpg", "caption": "Figure 6: Plotted are cumulative densities of distance metrics for cosine similarity and arctangent of L2 distances between embeddings. Random mol corresponds to Phenom1 distances between random molecules, high pval corresponds to distances between molecules with high p-values, low pval corresponds to distances between active molecules with low p-values, finally high-low corresponds to distances between active and inactive molecules.", "description": "This figure shows the cumulative distribution functions (CDFs) of two distance metrics (cosine similarity and arctangent of L2 distance) calculated between Phenom1 embeddings.  Four groups of molecule pairs are compared: those with random molecule selection, those where both molecules are active (low p-value), those where both are inactive (high p-value), and those with one active and one inactive molecule (high-low). The comparison highlights the difference in distribution separability between cosine similarity and the arctangent of L2 distance, particularly for distinguishing between active and inactive molecules. The arctangent of L2 distance shows a better separation between these groups, suggesting that it's a more effective metric for this task.", "section": "Challenge 1: Phenomic Pretraining and Generalization"}, {"figure_path": "LQBlSGeOGm/figures/figures_27_1.jpg", "caption": "Figure 7: U-map demonstrating dimensionality reduction of the chemical embeddings of unseen dataset RXRX3. First two dimensions are visualized and points are colored corresponding to their activity measured in phenomics experiments. Activity is evaluated using p-values calculated using technical replicability of Phenom1 embeddings. Top plot shows the u-map figure of all chemical embeddings, and bottom figure contains u-map figure of representations at specific concentrations.", "description": "This figure shows the results of dimensionality reduction on the chemical embeddings from the unseen RXRX3 dataset using UMAP.  The points are colored according to their activity (p-values from Phenom1). The top panel shows all embeddings together, while the bottom panels show separate UMAPs for different concentrations.", "section": "E Additional Results"}, {"figure_path": "LQBlSGeOGm/figures/figures_28_1.jpg", "caption": "Figure 2: Illustration of the contrastive phenomolecular retrieval challenge. Image x\u2081 and a set of molecules and corresponding concentrations (mk, ck) get mapped into a Rd latent space. Their similarities get computed with fsim and ranked to evaluate whether the paired perturbation appears in the top K%.", "description": "This figure illustrates the core challenge of contrastive phenomolecular retrieval.  A single phenomic image (x\u2081) is presented along with a set of molecules (mk) and their associated concentrations (ck). The goal is for a model to learn a joint latent space where the image and molecule/concentration pairs are meaningfully related. The model should be able to identify (within the top K%) the correct molecule/concentration pair (mk, ck) that corresponds to the observed effects in image x\u2081.  This zero-shot retrieval task requires the model to effectively capture cross-modal relationships between phenomic images and molecular representations, highlighting the core challenge of the paper.", "section": "Challenge 1: Phenomic Pretraining and Generalization"}, {"figure_path": "LQBlSGeOGm/figures/figures_29_1.jpg", "caption": "Figure 7: U-map demonstrating dimensionality reduction of the chemical embeddings of unseen dataset RXRX3. First two dimensions are visualized and points are colored corresponding to their activity measured in phenomics experiments. Activity is evaluated using p-values calculated using technical replicability of Phenom1 embeddings. Top plot shows the u-map figure of all chemical embeddings, and bottom figure contains u-map figure of representations at specific concentrations.", "description": "This figure displays the results of dimensionality reduction using UMAP on chemical embeddings from the unseen RXRX3 dataset. The points are colored by their activity (p-values), showing distinct clusters for different activity levels. The top panel shows the overall distribution, while the bottom panels display the distributions for specific concentrations (0.25\u00b5M, 1.0\u00b5M, 2.5\u00b5M, 10.0\u00b5M). This visualization helps to understand how well the model separates active and inactive molecules based on their chemical features and concentration.", "section": "E Additional Results"}, {"figure_path": "LQBlSGeOGm/figures/figures_29_2.jpg", "caption": "Figure 1: Illustration of proposed guidelines when incorporated in our MolPhenix contrastive phenomolecular retrieval framework. We address challenges by utilizing uni-modal pretrained MAE & MPNN models, inter-sample weighting with a dosage aware S2L loss, undersampling inactive molecules, and encoding molecular concentration.", "description": "This figure illustrates the architecture of MolPhenix, a contrastive phenomolecular retrieval model.  The model incorporates three key guidelines to improve performance: 1) using pre-trained uni-modal models for phenomics (MAE) and molecular (MPNN) data; 2) employing a novel soft-weighted sigmoid locked loss (S2L) that addresses the effects of inactive molecules and uses inter-sample similarities; and 3) explicitly encoding molecular concentration.  The figure shows how these components work together to generate molecular and phenomic embeddings that are compared to achieve contrastive learning and accurate retrieval.", "section": "1 Introduction"}, {"figure_path": "LQBlSGeOGm/figures/figures_30_1.jpg", "caption": "Figure 1: Illustration of proposed guidelines when incorporated in our MolPhenix contrastive phenomolecular retrieval framework. We address challenges by utilizing uni-modal pretrained MAE & MPNN models, inter-sample weighting with a dosage aware S2L loss, undersampling inactive molecules, and encoding molecular concentration.", "description": "This figure illustrates the architecture of the MolPhenix model, highlighting three key guidelines for improved performance: using pretrained unimodal models for phenomics and molecular data, incorporating a novel inter-sample similarity-aware loss function (S2L) to handle inactive molecules, and encoding molecular concentration explicitly.  The diagram shows the flow of data through the model, from input phenomics experiments and molecular structures, to the final similarity logits used for retrieval.", "section": "1 Introduction"}, {"figure_path": "LQBlSGeOGm/figures/figures_33_1.jpg", "caption": "Figure 1: Illustration of proposed guidelines when incorporated in our MolPhenix contrastive phenomolecular retrieval framework. We address challenges by utilizing uni-modal pretrained MAE & MPNN models, inter-sample weighting with a dosage aware S2L loss, undersampling inactive molecules, and encoding molecular concentration.", "description": "This figure illustrates the architecture of the MolPhenix model, a contrastive phenomolecular retrieval framework. It highlights three key guidelines to improve retrieval performance: (1) utilizing uni-modal pretrained models for phenomics (MAE) and molecular (MPNN) data; (2) employing a novel soft-weighted sigmoid locked loss (S2L) to address inactive molecules and inter-sample similarities; and (3) encoding molecular concentration explicitly and implicitly within the S2L loss.  The diagram shows the flow of data through the various components of the model, emphasizing the integration of these guidelines.", "section": "1 Introduction"}]