[{"figure_path": "ZC0PSk6Mc6/tables/tables_15_1.jpg", "caption": "Table 1: SCoBots and guided SCoBots obtain similar results than deep agents averaged over 3 seeded runs. Neural refers to the agent that use a CNN instead of our ICB layers. We added the results reported in the original paper Schulman et al. [2017] (original), which are on par with ours, as well as ones from a Random baseline and Humans (from van Hasselt et al. [2016]). Our agents have been trained with only 20M frames.", "description": "This table compares the performance of different reinforcement learning agents on various Atari games.  It shows human-normalized scores (accounting for human and random baselines), highlighting the competitive performance of SCoBots (Successive Concept Bottleneck Agents) compared to standard deep reinforcement learning agents.  It also includes results from variations of SCoBots (with and without guidance) and deep agents from previous work, indicating that object-centric agents can achieve similar or even better scores than purely neural agents.  The training of the agents was limited to 20M frames in this study.", "section": "A.2 Detailed numerical results"}, {"figure_path": "ZC0PSk6Mc6/tables/tables_18_1.jpg", "caption": "Table 3: Descriptions of properties and relations used by SCoBots.", "description": "This table lists the properties and relations used by the Successive Concept Bottleneck Agents (SCoBots) in the paper.  The properties describe individual features of objects in the environment (e.g., position, color), while relations capture the relationships between these objects (e.g., distance, speed).  The table provides a detailed definition and description for each property and relation, including its mathematical notation or calculation method. This information is crucial for understanding how SCoBots process information from the environment to make decisions. ", "section": "A.5.1 The properties and features used for SCoBots"}, {"figure_path": "ZC0PSk6Mc6/tables/tables_18_2.jpg", "caption": "Table 4: Feature selection and pruning for guided SCoBots. \u2713 denotes the included features, whereas X the features that are pruned out.", "description": "This table shows which features (properties and relations) are used by the SCoBots agents for each of the nine Atari games.  It also indicates whether certain features were removed (pruned) during the guided SCoBots experiments.  The pruning was done to reduce the complexity of the decision-making process and to test whether the removal of less-relevant features impacts the model's ability to learn effective policies. The table is organized by game and feature category. For each feature, a checkmark indicates inclusion, while an 'X' indicates removal or pruning in the respective game.", "section": "A.5.1 The properties and features used for SCoBots"}, {"figure_path": "ZC0PSk6Mc6/tables/tables_22_1.jpg", "caption": "Table 5: SCoBots (with OCAtari) train faster than deep agents, particularly in environments with a limited number of objects. Computational training time of each method on each used environment (format HH:MM).", "description": "This table presents a comparison of the training time for SCoBots (with OCAtari), deep agents, and SCoBots without guidance (NG) across nine different Atari games. The training times are given in hours and minutes (HH:MM). The results show that SCoBots generally require less training time compared to deep agents, especially in games with a smaller number of objects.", "section": "Experimental Evaluations"}]