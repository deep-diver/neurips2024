[{"figure_path": "DQD0DNRjxk/figures/figures_2_1.jpg", "caption": "Figure 1: Framework of Gaussian Voxel Kernel Functions (GVKF) for scene representation. In this framework, discrete Gaussian primitives G represent continuous opacity density p(t) on the ray via kernel regression. After slightly modifying the rasterization pipeline, the kernel function can be integrated into alpha blending rasterization without introducing dense points sampling. Additionally, we directly define the mapping relationship between the neural opacity field and the implicit surface.", "description": "This figure illustrates the framework of the Gaussian Voxel Kernel Functions (GVKF) method. It shows how discrete Gaussian primitives are used to represent a continuous scene opacity density field through kernel regression.  The method integrates this with a modified rasterization pipeline and directly maps the resulting neural opacity field to an implicit surface for mesh reconstruction.", "section": "3 Methods"}, {"figure_path": "DQD0DNRjxk/figures/figures_4_1.jpg", "caption": "Figure 2: Comparison of Volume Rendering, 3D Gaussian Splatting with Alpha Blending, and GVKF Rendering.", "description": "This figure compares three different rendering methods: volume rendering, 3D Gaussian splatting with alpha blending, and the proposed GVKF rendering. It illustrates how each method represents the opacity density function p(t) along a ray.  Volume rendering uses a continuous representation. 3D Gaussian splatting uses discrete Gaussians, leading to a discontinuous opacity function. GVKF combines the speed of 3DGS rasterization with a continuous opacity representation via kernel regression, creating a smoother, more accurate representation.", "section": "3 Methods"}, {"figure_path": "DQD0DNRjxk/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of functions \u03a6(u), \u03a6'(u), p(u).", "description": "This figure illustrates the relationship between three functions: \u03a6(u), \u03a6'(u), and p(u), which are crucial for understanding the implicit surface mapping in the GVKF method.  \u03a6(u) represents the cumulative distribution function (CDF) of the probability that a ray hits a particle. \u03a6'(u) represents the probability density function (PDF), showing the probability of a ray encountering a particle at a specific point. p(u) is the opacity density function, indicating the probability of a ray being blocked at a given point. The dashed black line represents the location of the surface (where D(t*) = 0). The figure demonstrates how the peak of \u03a6'(u) precedes the actual surface location, highlighting the need for a more sophisticated method (using Logistic Function) to accurately map from the opacity density to the surface location.", "section": "3.3 Implicit Surface Mapping"}, {"figure_path": "DQD0DNRjxk/figures/figures_6_1.jpg", "caption": "Figure 5: Qualitative comparison of novel view synthesis and surface reconstruction on the Waymo Open Dataset [32], with each subplot annotated with PSNR values to quantify image quality. Our method shows higher geometric precision and detail, validating its efficiency and superiority in processing open scenes, especially in geometric accuracy and detail reproduction.", "description": "This figure compares the results of novel view synthesis and surface reconstruction on the Waymo Open Dataset between the proposed GVKF method and two other methods (StreetSurf and 2DGS).  Each row shows the ground truth image alongside the results from the three different methods for a different scene. PSNR (Peak Signal-to-Noise Ratio) values are included to quantify the image quality of the reconstruction. The results suggest that the GVKF method outperforms the others in terms of geometric accuracy and detail, particularly in open scenes.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/figures/figures_6_2.jpg", "caption": "Figure 3: Illustration of functions \u03a6(u), \u03a6'(u), p(u).", "description": "This figure illustrates the relationship between the opacity density function p(u), the cumulative distribution function \u03a6(u), and its derivative \u03a6'(u) near the surface of an object.  The x-axis represents the distance u (negative signed distance from the surface), and the y-axis represents the values of these functions. The peak of \u03a6'(u) indicates the most likely location of the surface along the ray, while \u03a6(u) represents the cumulative probability of a ray hitting the surface up to distance u.  The function p(u) depicts the opacity density at a given distance from the surface.", "section": "3.3 Implicit Surface Mapping"}, {"figure_path": "DQD0DNRjxk/figures/figures_7_1.jpg", "caption": "Figure 6: Qualitative comparison on the Tanks and Temples dataset [16] shows that our method excels in reconstructing complex backgrounds with high geometric granularity. In contrast, 2DGS often results in fragmented backgrounds, while SuGaR displays uneven spherical shapes, affecting both visual and geometric quality.", "description": "This figure compares the qualitative results of surface reconstruction on the Tanks and Temples dataset between the proposed GVKF method and other existing methods (SuGaR and 2DGS). The results show that GVKF outperforms other methods by having higher geometric granularity and reconstructing more complex backgrounds, while SuGaR and 2DGS produce fragmented backgrounds and uneven spherical shapes. The red boxes highlight areas where the difference is prominent.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/figures/figures_13_1.jpg", "caption": "Figure 7: Ray-Gaussian Intersection in local 3DGS coordinate.", "description": "This figure illustrates the transformation of a 3D Gaussian primitive G(x) into a 1D Gaussian function p(t) along a ray.  The 3D Gaussian is projected onto a line (the ray), resulting in a 1D Gaussian distribution with its peak at t_i representing the point of maximum impact of the 3D Gaussian on that specific ray.  The formula and derivation of this transformation are mathematically explained in the paper.", "section": "3.2 Neural Opacity Field of 3DGS"}, {"figure_path": "DQD0DNRjxk/figures/figures_14_1.jpg", "caption": "Figure 8: Additional experimental results on the Mip-NeRF360 dataset [1]. From left to right: Ground Truth, Novel View Synthesis, Rendered Depth Map, and Normal Map.", "description": "This figure shows a qualitative comparison of the proposed GVKF method with ground truth data on the Mip-NeRF360 dataset.  For several scenes, it displays the ground truth image alongside a rendered image produced by the GVKF method. It also shows the depth map and normal map generated by GVKF for each scene. This allows for a visual assessment of the accuracy and quality of the method's reconstruction in terms of geometry, depth, and surface normals.", "section": "4. Experiments"}, {"figure_path": "DQD0DNRjxk/figures/figures_15_1.jpg", "caption": "Figure 8: Additional experimental results on the Mip-NeRF360 dataset [1]. From left to right: Ground Truth, Novel View Synthesis, Rendered Depth Map, and Normal Map.", "description": "This figure presents a qualitative comparison of the proposed GVKF method with ground truth data on the Mip-NeRF360 dataset.  It shows several example scenes where the method was tested, with the ground truth, novel view synthesis results, depth maps, and normal maps presented side-by-side for each scene. This allows for a visual assessment of the accuracy and quality of the surface reconstruction and novel view synthesis achieved by the GVKF method.", "section": "4.2 Analysis"}, {"figure_path": "DQD0DNRjxk/figures/figures_15_2.jpg", "caption": "Figure 10: GVKF Gaussian point visualization compared to traditional Gaussian method.", "description": "This figure compares the Gaussian point visualization of the proposed GVKF method with that of the traditional 3DGS method.  The reference image shows a clear, detailed view of the scene. The 3DGS visualization shows a scattered distribution of Gaussian points with some areas appearing denser than others. In contrast, the GVKF visualization demonstrates a more even and organized distribution of Gaussian points, leading to a smoother and more coherent representation of the scene's geometry. This highlights the effectiveness of the GVKF method in efficiently managing and representing Gaussian primitives for 3D surface reconstruction.", "section": "3 Methods"}, {"figure_path": "DQD0DNRjxk/figures/figures_15_3.jpg", "caption": "Figure 11: Failure case. The sparse view area with less Gaussians tends to appear uneven surface.", "description": "This figure shows a failure case of the GVKF method where a sparse view area results in an uneven surface due to insufficient Gaussian points to represent the surface details accurately.  It highlights a limitation of the approach when dealing with scenes where some areas have limited view coverage.", "section": "4.3 Ablation Study"}]