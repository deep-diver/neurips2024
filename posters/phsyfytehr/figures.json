[{"figure_path": "PhsYFyTeHr/figures/figures_1_1.jpg", "caption": "Figure 1: The generation process of NATs starts from a masked canvas, decode multiple tokens per step, and are then mapped to the pixel space using a pre-trained VQ-decoder [13].", "description": "This figure illustrates the progressive generation process of Non-autoregressive Transformers (NATs) for image synthesis.  It begins with a completely masked image canvas (t=0), represented by grey squares.  At each step, a subset of the masked tokens are decoded in parallel, revealed as light blue squares. The process iteratively continues until all tokens are revealed (t=T), forming the complete image. Finally, a pre-trained vector quantizer decoder (VQ Dec) maps the decoded token sequence to the final pixel-space image.", "section": "1 Introduction"}, {"figure_path": "PhsYFyTeHr/figures/figures_3_1.jpg", "caption": "Figure 2: An ablation study on four types of spatial interactions. The essential spatial interaction is the [M] to [V] attention. In contrast, the [V] to [M] attention only marginally affects the model.", "description": "This figure shows the results of an ablation study on four types of spatial interactions in NATs. The study investigates the impact of different attention mechanisms on the model's performance. By removing different attention mechanisms, the researchers observed a significant drop in performance when removing [M] to [V] attention, indicating that this interaction is crucial for the model. Removing the other attention mechanisms resulted in less significant performance drops.", "section": "4.1 Spatial Level Interaction"}, {"figure_path": "PhsYFyTeHr/figures/figures_4_1.jpg", "caption": "Figure 3: (a) Existing works of NATs process visible and [MASK] tokens equivalently. (b) Our disentangled architecture independently encodes visible tokens and integrates their fully contextualized features into the [MASK] token decoding process. M is the indicator of [MASK] tokens while M is the indicator of visible tokens. The SC-Attention concatenates the visible and mask token features to produce keys and values, providing a complete context for the mask token decoding.", "description": "This figure compares the existing NATs architecture with the proposed ENAT architecture.  The existing approach processes visible tokens and masked tokens uniformly, while ENAT's disentangled architecture independently encodes visible tokens. These encoded visible token features are then integrated into the decoding process for the masked tokens using SC-Attention. This allows for more efficient computation and better performance.", "section": "4.1 Spatial Level Interaction"}, {"figure_path": "PhsYFyTeHr/figures/figures_5_1.jpg", "caption": "Figure 4: Overview of ENAT. Based on the disentangled architecture in Fig. 3b, we further propose to only encode the critical (i.e., newly decoded) tokens and maximally reuse previously extracted features to supplement necessary information. A is the indicator of newly decoded tokens. Only one transformer block is illustrated for simplicity.", "description": "This figure illustrates the inference process of ENAT, showing how it builds upon the disentangled architecture from Figure 3b.  Instead of encoding all tokens at each step, ENAT prioritizes newly decoded tokens, reusing the previously computed features for computational efficiency.  The diagram shows the flow of information between steps, highlighting the reuse of features from the previous step to enhance the current step's decoding process.", "section": "4 EfficientNAT (ENAT)"}, {"figure_path": "PhsYFyTeHr/figures/figures_5_2.jpg", "caption": "Figure 4: Overview of ENAT. Based on the disentangled architecture in Fig. 3b, we further propose to only encode the critical (i.e., newly decoded) tokens and maximally reuse previously extracted features to supplement necessary information. A is the indicator of newly decoded tokens. Only one transformer block is illustrated for simplicity.", "description": "This figure illustrates the ENAT model's architecture. It builds upon the disentangled architecture from Figure 3b by reusing previously computed features.  Only newly decoded tokens are encoded, and the model efficiently integrates previously extracted features to supplement information. This reduces computation, making the process more efficient.", "section": "4 EfficientNAT (ENAT)"}, {"figure_path": "PhsYFyTeHr/figures/figures_5_3.jpg", "caption": "Figure 5: Feature similarity analysis. (a) We randomly choose two samples and visualize the token-to-token feature similarity between adjacent steps (2 & 3 and 6 & 7), with the positions of newly decoded tokens visualized on the right. (b) The token feature similarity averaged over 50,000 generated samples in each pair of adjacent steps (t = 1\u21922, t = 2 \u2192 3, . . ., t = 7\u21928).", "description": "This figure visualizes the similarity of token features between consecutive steps in the image generation process of NATs.  (a) shows heatmaps for two example image generations, comparing steps 2&3 and 6&7.  The heatmaps highlight which tokens changed significantly between steps, revealing that these changes primarily occur around the newly decoded tokens. (b) presents an aggregated view showing the average similarity between steps across many generations, confirming that similarity decreases more for newly decoded tokens than other tokens between steps.", "section": "4.2 Temporal Level Interaction"}, {"figure_path": "PhsYFyTeHr/figures/figures_8_1.jpg", "caption": "Figure 6: Practical efficiency of ENAT. As a reference, we also plot the TFLOPs for generating a single image in (a). GPU time is measured on an A100 GPU with batch size 50. CPU time is measured on Xeon 8358 CPU with batch size 1. \u2020: DPM-Solver [40] augmented diffusion models.", "description": "This figure demonstrates the practical efficiency of ENAT by comparing its performance with other state-of-the-art generative models across three metrics: FID (Fr\u00e9chet Inception Distance), GPU time, and CPU time.  It shows that ENAT achieves superior performance with significantly reduced computational costs, as indicated by lower FID scores and shorter processing times on both GPU and CPU.", "section": "5.1 Main Results"}, {"figure_path": "PhsYFyTeHr/figures/figures_8_2.jpg", "caption": "Figure 9: Selected samples of ENAT-L with 8 generation steps on ImageNet 256x256 and 512x512.", "description": "This figure showcases several example images generated by the ENAT-L model.  The images span both the ImageNet 256x256 and 512x512 datasets, demonstrating the model's ability to produce high-quality images at different resolutions. Each image represents a successful image generation from the model after 8 generation steps.", "section": "More Qualitative Results"}, {"figure_path": "PhsYFyTeHr/figures/figures_9_1.jpg", "caption": "Figure 3: (a) Existing works of NATs process visible and [MASK] tokens equivalently. (b) Our disentangled architecture independently encodes visible tokens and integrates their fully contextualized features into the [MASK] token decoding process. M is the indicator of [MASK] tokens while M is the indicator of visible tokens. The SC-Attention concatenates the visible and mask token features to produce keys and values, providing a complete context for the mask token decoding.", "description": "The figure shows the comparison between existing NATs architecture and the proposed ENAT architecture. The existing NATs process visible tokens and [MASK] tokens equally. The proposed ENAT disentangles the computations of visible and [MASK] tokens. Visible tokens are encoded independently. [MASK] tokens are decoded based on the fully encoded visible tokens. A SC-Attention mechanism is used to improve performance. ", "section": "4.1 Spatial Level Interaction"}, {"figure_path": "PhsYFyTeHr/figures/figures_17_1.jpg", "caption": "Figure 8: System-level comparisons on ImageNet 256x256. All baseline results are sourced from their original papers, except for the few-step MDT results (\u2020).", "description": "This figure compares the performance of ENAT with other state-of-the-art image generation models on ImageNet 256x256 dataset. The x-axis represents the total computational cost (in TFLOPs) required to generate a single image, and the y-axis shows the Fr\u00e9chet Inception Distance (FID) score, a measure of image quality. The lower the FID score, the better the image quality. The figure demonstrates that ENAT achieves superior performance (lower FID) with significantly lower computational cost (lower TFLOPs) compared to other methods.  The baseline results are taken from their original papers, with the exception of the MDT results which have been reproduced using DPM-Solver for fair comparison.", "section": "5.1 Main Results"}, {"figure_path": "PhsYFyTeHr/figures/figures_17_2.jpg", "caption": "Figure 9: Selected samples of ENAT-L with 8 generation steps on ImageNet 256x256 and 512x512.", "description": "This figure shows several examples of images generated by the ENAT-L model.  The images are from the ImageNet dataset, with resolutions of 256x256 and 512x512 pixels. The model was trained using 8 generation steps.  The figure aims to showcase the visual quality and diversity of images generated by the proposed ENAT model.", "section": "More Qualitative Results"}]