[{"type": "text", "text": "Fast and accurate training and sampling of Restricted Boltzmann Machines ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Thanks to their simple architecture, Restricted Boltzmann Machines (RBMs) are   \n2 powerful tools for modeling complex systems and extracting interpretable insights   \n3 from data. However, training RBMs, as other energy-based models, on highly   \n4 structured data poses a major challenge, as effective training relies on mixing the   \n5 Markov chain Monte Carlo simulations used to estimate the gradient. This process   \n6 is often hindered by multiple second-order phase transitions and the associated   \n7 critical slowdown. In this paper, we present an innovative method in which the   \n8 principal directions of the dataset are integrated into a low-rank RBM through a   \n9 convex optimization procedure. This approach enables efficient sampling of the   \n10 equilibrium measure via a static Monte Carlo process. By starting the standard   \n11 training process with a model that already accurately represents the main modes of   \n12 the data, we bypass the initial phase transitions. Our results show that this strategy   \n13 successfully trains RBMs to capture the full diversity of data in datasets where   \n14 previous methods fail. Furthermore, we use the training trajectories to propose a   \n15 new sampling method, parallel trajectory tempering, which allows us to sample   \n16 the equilibrium measure of the trained model much faster than previous optimized   \n17 MCMC approaches and a better estimation of the log-likelihood. We illustrate the   \n18 success of the training method on several highly structured datasets. ", "page_idx": 0}, {"type": "text", "text": "19 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "20 Energy-based models (EBMs) are a classic approach to generative modeling that has been studied for   \n21 decades. They were introduced using the Restricted Boltzmann Machine formulation by Smolen  \n22 sky [1] and later further developed by Sejnowski et al. [2]. They provide a straightforward method for   \n23 modeling effective interactions within complex data distributions and for sufficiently simple energy   \n24 functions, such as the Boltzmann machine (BM) [3], it is also possible to interpret and infer the   \n25 underlying constituent rules from the observed data. This inference strategy is often associated with   \n26 the inverse Ising problem and pairwise interaction models [4], and it has found a great variety of   \n27 applications in fields such as neuroscience [5] or computational biology [6]. A recent work has   \n28 proposed replacing the use of pairwise models with the Restricted Boltzmann Machine (RBM) [7],   \n29 as it allows the same direct interpretation of its energy function as an explicit many-body interaction   \n30 model while greatly extending the expressive power of the model. RBMs are also very useful for   \n31 grouping data into hierarchical families [8]. On the diametrically opposite side (on interpretability)   \n32 are generative ConvNets [9, 10], where the energy function is formulated as a deep neural network,   \n33 which are capable of synthesizing photorealistic images but are almost impossible to interpret as a   \n34 physical model.   \n35 The applications of simple EBMs in science are very diverse. For example, they are often used today   \n36 to encode the Hamiltonian of physical many-body systems, such as Quantum wave functions [11]   \n37 or the accurate determination of ground state wave functions of strongly interacting and entangled   \n38 quantum spins [12] or they have proven to be suitable for the representation of the AdS/CFT   \n39 correspondence in theories of quantum gravity [13, 14]. Simple EBMs are also very common to   \n40 encode the evolutionary constraints in protein families [6, 15], and to predict mutations [16], or to   \n41 generate realistic synthetic sequences, such as fake human genomes [17, 18]. These examples show   \n42 that, despite their somewhat old-fashioned architecture, shallow EBMs are increasingly seen as useful   \n43 tools for better understanding modern physics/biology, as they allow for a certain level of analytical   \n44 description.   \n45 Despite the appealing modeling properties of RBMs, they are notoriously difficult to train, a challenge   \n46 common to EBMs in general. The main difficulty arises from the computation of the log-likelihood   \n47 gradient, which requires an ergodic exploration of a dynamically evolving and potentially complex   \n48 free energy landscape using Markov Chain Monte Carlo (MCMC) processes. Recent studies have   \n49 shown that models trained with non-convergent MCMC processes suffer from out-of-equilibrium   \n50 dynamic memory effects [19, 20, 21]. This dynamical behavior can be explained analytically using   \n51 moment-matching arguments [19, 22]. While exploiting these effects can yield fast and accurate   \n52 generative models, even for highly structured data [23] or high-quality images with RBMs [24], this   \n53 approach results in a sharp separation between the model\u2019s Gibbs-Boltzmann distribution and the   \n54 dataset distribution, thereby undermining the interpretability of the model parameters [22, 7]. Thus,   \n55 to extract meaningful information from datasets using RBMs, it is essential to ensure proper mixing   \n56 of the chains during training, in short, one needs equilibrium models.   \n57 Both the ability to train an RBM in equilibrium and to generate convincing new samples from its   \n58 equilibrium measure strongly depend on the dataset in question. For typical image datasets such   \n59 as MNIST or CIFAR-10, good RBMs can be obtained by increasing the number of MCMC steps.   \n60 However, this approach is no longer feasible for highly structured datasets [25]. Datasets from   \n61 which one seeks scientific insights are often highly structured, such as genomics/proteomics data   \n62 or low-temperature many-body physical systems. These datasets typically exhibit distinct clusters,   \n63 identifiable via principal component analysis (PCA) which form distant groups of similar entries.   \n64 We show an example of the PCA of 4 clustered dataset we will be studying in this work in Fig. 1;   \n65 details about these datasets are given in the caption and in the Supplemental Information (SI). During   \n66 training, the model must evolve from an initial normal distribution to an increasingly multimodal   \n67 distribution. Sampling from multimodal distributions is particularly challenging because the mixing   \n68 times are determined by the transition times between modes. But this is not the only difficulty. These   \n69 distant modes are encoded by second-order phase transitions during training [26, 27, 28], leading to   \n70 diverging mixing times in these regions \u2014 a phenomenon known as critical slowdown \u2014, which   \n71 means that mixing times are expected to grow with a power of their system size. This sampling   \n72 challenge not only hinders the training process, but also limits the model\u2019s ability to generate new   \n73 samples. Obtaining new and independent configurations would require an impractically large number   \n74 of sampling steps. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "75 2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "76 Training EBMs by maximizing log-likelihood has long been a challenge in the community [29, 10].   \n77 EBMs gained popularity with the introduction of the contrastive divergence algorithm [30], in which   \n78 a set of parallel chains is initialized on independent examples in the minibatch and the MCMC   \n79 process iterates for a few steps. Despite its widespread use, this algorithm yields models with poor   \n80 equilibrium properties that are ineffective as generative models [31, 32, 21]. An improvement is the   \n81 persistent contrastive divergence (PCD) algorithm [33], which maintains a permanent chain in which   \n82 the last configurations used to estimate the previous gradient update are reused. PCD acts like a   \n83 slow annealing process improving gradient estimation quality. However, it often fails on clustered   \n84 data as the statistical properties of the permanent chain quickly move away from the equilibrium   \n85 measure and degrade the model [25]. This problem, which is primarily related to phase coexistence,   \n86 can be addressed with constrained MCMC methods if appropriate order parameters are identified.   \n87 For RBMs, these order parameters are related to the singular value decomposition of the model   \n88 coupling matrix, which enables efficient reconstruction of multimodal distributions [25]. Although   \n89 this method is effective for evaluating model quality, it is too computationally intensive to be used   \n90 in training, even if it leads to models with good equilibrium properties. Other optimized MCMC   \n91 methods, such as the Parallel Tempering (PT) [34] algorithm, simulate multiple models at different   \n92 temperatures, facilitating mixing through temperature exchange [35, 32]. However, PT is costly and   \n93 often ineffective, especially because EBMs undergo first-order phase transitions at the temperature   \n94 where PT typically fails because one needs too many temperatures to make the moves accepted. We   \n95 will see below that a more appropriate approach exchanges the models at different training times,   \n96 which only implies crossing second-order phase transitions.   \n97 The population annealing algorithm, which reweights parallel chains during learning based on their   \n98 relative weight changes during parameter updates, was proposed as an alternative [36]. Similarly,   \n99 reweighting chains using non-equilibrium physics concepts such as the Jarzynski equality has been   \n100 proposed [37]. Both approaches struggle with highly structured data sets. To prevent the different   \n101 chains to get too correlated around the training phase transitions, one must either increase the   \n102 number of sampling steps or decrease the learning rate, which in practice means very long training   \n103 processes to ensure a proper equilibrium training. Another strategy is to use EBMs as corrections   \n104 for straightforward-to-sample flow-based models [38]. This simplifies sampling and learning, but   \n105 sacrifices the interpretability of the energy function, which was our goal. An evolving flow model   \n106 can be used as a fast sampling moves proposer for the EBM [39] objective. This method requires the   \n107 training of two different networks in parallel and may result in the drop of the move acceptancy as   \n108 the EBM becomes specialized.   \n109 For RBMs, a recent method called \u201cstacked tempering\" [40] dramatically speeds up sampling by   \n110 training smaller RBMs with latent variables from previous models, allowing fast updates to be   \n111 proposed using a PT like algorithm. Authors also showed that this algorithm was much faster than   \n112 the standard PT. While effective, it is too cumbersome for use in training. Also for RBMs, it has   \n113 recently been shown that it is possible to train a low-rank RBM that accurately reproduces the   \n114 statistics of the data projected along the $d$ first data principal directions through a convex and very   \n115 fast optimization process (see [41] and the discussion below). This low-rank model can be seen as a   \n116 good approximation to the correct RBM needed to describe the data, and has the nice property that it   \n117 can be efficiently sampled via a static Monte Carlo process.   \n118 In this paper, we will show how to drastically reduce training times by starting the RBM training   \n119 process at this low-rank RBM, as this means that the first and strongest dynamic effects associated   \n120 with them are directly bypassed. We also show that one can exploit the training trajectory to develop   \n121 an effective sampling method, the parallel trajectory tempering (PTT) that outperforms the \u201cstacked   \n122 tempering\" [40] and only requires saving a reduced number of models during the training. This   \n123 strategy also allows to obtain reliable estimations for the log-likelihood in well-trained models, much   \n124 better than those obtained with the standard Annealing Important Sampling (AIS) techniques [42].   \n125 Using both strategies, we show that we are able to train and evaluate methods that accurately represent   \n126 the different modes in the dataset, where standard methods lead to mode collapse effects. ", "page_idx": 1}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/9f9f808046dab896831ef92d3d560bd5ca10fe1285ad5d2405a7b965d1f83c95.jpg", "img_caption": ["Figure 1: Clustered datasets. In A-C we show the 4 different clustered data sets that we will consider in this paper, projected onto their first two PCA components. In A we show the data of the MNIST 01 dataset (both projected and some instances), which contains only the 0-1 images of the complete MNIST dataset. In B, we show the Mickey dataset, an artificial dataset whose PCA forms a \u201cMickey\"\u201d face shape. In C, we show data from the Human Genome Dataset (HGD), which contains binary vectors each corresponding to a human individual and whose sites correspond to selected genes. A value of 1 at a particular position means that a mutation was observed there compared to an individual reference sequence. Details of these data sets can be found in the SI. In D-F we show the samples we generate with the low-rank RBMs that are used as initial point of a standard training. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "127 3 The Restricted Boltzmann Machine ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "128 The RBM is composed by $N_{\\mathrm{v}}$ visible nodes and $N_{\\mathrm{h}}$ hidden nodes. In our study, we primarily use   \n129 binary variables $\\{0,1\\}$ or $\\pm1$ for both layers. The two layers (visible and hidden) interact via a   \n130 weight matrix $\\pmb{w}$ , with no direct couplings within a given layer. Variables are also adjusted by visible   \n131 and hidden local biases, $\\pmb{\\theta}$ and $\\eta$ , respectively. The Gibbs-Boltzmann distribution for this model is   \n132 expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\np(v,h)={\\frac{1}{Z}}\\exp\\left[-{\\mathcal{H}}(v,h)\\right]{\\mathrm{~where~}}{\\mathcal{H}}(v,h)=-\\sum_{i a}v_{i}w_{i a}h_{a}-\\sum_{i}\\theta_{i}v_{i}-\\sum_{a}\\eta_{a}h_{a},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "133 where $Z$ is the partition function of the system. As with other models containing hidden variables, the   \n134 training objective is to minimize the distance between the empirical distribution of the data, $p_{\\mathcal{D}}(\\pmb{v})$ ,   \n135 and the model\u2019s marginal distribution over the visible variables, $\\begin{array}{r}{p(\\pmb{v})=\\sum_{\\pmb{h}}\\exp\\left[-\\mathcal{H}(\\pmb{v},\\pmb{h})\\right]/\\tilde{Z}=}\\end{array}$   \n136 $\\exp\\left[-H(\\pmb{v})\\right]/Z$ . Minimizing the Kullback-Leibler divergence is equ ivalent to maximizing the   \n137 likelihood of observing the dataset in the model. Thus, the log-likelihood ${\\mathcal L}\\,=\\,\\langle-H({\\boldsymbol v})\\rangle_{{\\mathcal D}}\\,-$   \n138 $\\log{Z}$ can be maximized using the classical stochastic gradient ascent. For a training dataset $\\mathcal{D}=$   \n139 $\\{\\bar{\\pmb{v^{(m)}}}\\}_{m=1,\\dots,M}$ , the log-likelihood gradient is given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial w_{i a}}=\\langle v_{i}h_{a}\\rangle_{\\mathcal{D}}-\\langle v_{i}h_{a}\\rangle_{\\mathrm{RBM}},\\ \\frac{\\partial\\mathcal{L}}{\\partial\\theta_{i}}=\\langle v_{i}\\rangle_{\\mathcal{D}}-\\langle v_{i}\\rangle_{\\mathrm{RBM}},\\ \\frac{\\partial\\mathcal{L}}{\\partial\\eta_{a}}=\\langle h_{a}\\rangle_{\\mathcal{D}}-\\langle h_{a}\\rangle_{\\mathrm{RBM}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "140 where $\\langle\\cdot\\rangle_{\\mathcal{D}}$ denotes the average with respect to the entries in the dataset, and $\\langle\\cdot\\rangle_{\\mathrm{RBM}}$ with respect   \n141 to $p(\\pmb{v},h)$ . Since $Z$ is intractable, the model averages in the gradient are typically estimated us  \n142 ing $N_{\\mathrm{s}}$ independent MCMC processes, and observable averages $\\langle o(v,h)\\rangle_{\\mathrm{RBM}}$ are replaced by   \n143 $\\begin{array}{r}{\\sum_{r=1}^{R}o({\\pmb v}^{(r)},{\\pmb h}^{(r)})/R}\\end{array}$ , with $(\\pmb{v}^{(r)},\\pmb{h}^{(r)})$ being the last configurations reached with each of the   \n144 $r\\,=\\,1,\\ldots,R$ parallel chains. To obtain reliable estimates, it should be ensured that each of the   \n145 Markov chains mix well before each parameter update. However, ensuring equilibrium at each update   \n146 is impractical, slow and tedious. The common use of non-convergent MCMC processes is the cause   \n147 of most difficulties and weird dynamical behaviors encountered in training RBMs [21].   \n148 Typical MCMC mixing times in RBMs are very small at the beginning of the training and grow as   \n149 it progresses [21], suffering with sharp increases every-time the training trajectory crosses each of   \n150 the critical transitions that give birth to new modes [28]. In order to minimize out-of-equilibrium   \n151 effects, it is often useful to keep $R$ permanent (or persistent) chains, which means that the last   \n152 configurations reached with the MCMC process used to estimate the gradient at a given parameter   \n153 update $t$ , $P_{t}\\equiv\\{(\\pmb{v}_{t}^{(r)},\\pmb{h}_{t}^{(r)})\\}_{r=1}^{R}$ , are used to initialize the chains of the subsequent update $t+1$   \n154 This algorithm is typically referred as PCD. In this scheme, the process of training can be mimicked   \n155 to a slow cooling process, only that instead of varying a single parameter, the temperature, a whole   \n156 set of parameters $\\pmb{\\Theta}_{t}=\\left(\\pmb{w}_{t},\\pmb{\\theta}_{t},\\pmb{\\eta}_{t}\\right)$ are updated at every step to $\\Theta_{t+1}=\\Theta_{t}+\\gamma\\nabla{\\mathcal{L}}_{t}$ with $\\nabla\\mathcal{L}_{t}$   \n157 being the gradient in Eq. (2) estimated using the configurations in $P_{t}$ , and $\\gamma$ being the learning rate.   \n159 In Ref. [41], it was shown that it is possible to train exactly (i.e. by direct numerical integration   \n160 instead of MCMC sampling) an RBM containing a reduced number of modes in the weight matrix   \n161 W by exploiting a mapping between the RBM and a Restricted Coulomb Machine and solving a   \n162 convex optimization problem, see the SI. In other words, it is possible to train a RBM with a coupling   \n163 matrix of this simplified form ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pmb{W}=\\sum_{\\alpha=1}^{d}w_{\\alpha}\\bar{\\pmb{u}}_{\\alpha}\\pmb{u}_{\\alpha}^{\\top},\\qquad\\mathrm{with}\\qquad\\left(\\pmb{u}_{\\alpha},\\bar{\\pmb{u}}_{\\alpha}\\right)\\in\\mathbb{R}^{N_{v}}\\times\\mathbb{R}^{N_{h}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "164 and where the right singular vectors $\\{{\\pmb u}_{\\alpha}\\}_{\\alpha=1}^{d}$ correspond exactly to the first $d$ principal directions   \n165 of the data set. Under this assumption, it is possible to write $p(v)$ only as a function of $d$ o\u221arder   \n166 parameters given by the magnetizations along each of the $u_{\\alpha}$ components, $m_{\\alpha}(\\pmb{v})=\\pmb{u}_{\\alpha}\\cdot\\pmb{v}/\\sqrt{N_{\\mathrm{v}}}$ ,   \n167 and in particular, ", "page_idx": 4}, {"type": "equation", "text": "$$\nH(v)=-\\sum_{a}\\log\\cosh\\left(\\sqrt{N_{\\mathrm{v}}}\\bar{u}_{a}\\sum_{\\alpha=1}^{d}w_{\\alpha}m_{\\alpha}+\\eta_{a}\\right)=\\mathcal{H}(m(v)),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "168 where $\\pmb{m}\\,=\\,(m_{1},\\pmb{.}\\,.\\,.\\,,m_{\\alpha})$ . As proposed in [41], the optimal parameters of such a model can   \n169 basically be determined by solving a regression problem. We describe this method in details in the   \n170 SI. This means that once the model is trained, we obtain a probability $p(m)$ defined on a much   \n171 lower dimension than the original $p(v)$ . Such a probability can be straightforwardly sampled using   \n172 inverse transform sampling. Since this method requires a discretization of the $\\mathbf{\\nabla}m$ -space both for   \n173 training and generation, we cannot consider intrinsic space dimension $d>4$ dimensions in practice.   \n174 These low-rank RBMs are then trained to reproduce the statistics of the dataset projected in its first $d$   \n175 principal components. Despite their simplicity, the low-rank models are already able to generate an   \n176 approximate version of the dataset, as shown in Fig. 1\u2013D-F for the 4 datasets previously presented.   \n177 In the initial stage of the standard learning process, the model encodes the strongest PCA components   \n178 of the data through multiple critical transitions [26, 27, 28]. Pre-training with the low-rank construc  \n179 tion allows us to bypass these transitions and avoid out-of-equilibrium effects caused by critical   \n180 slowing down associated to these transitions. Once the main directions are incorporated, training can   \n181 efficiently continue with standard algorithms like PCD, as the mixing times of pre-trained machines   \n182 tend to be much shorter. In particular, in the PCD-100 training with MNIST01, relaxation times for   \n183 the visible variables\u2019 time correlation reach $5\\cdot10^{5}\\;\\mathrm{MCMC}$ steps at the first three transitions, coincid  \n184 ing with the growth of singular values in the model weight matrix $W$ . In contrast, the pre-trained   \n185 machine has a much shorter relaxation time of $\\sim10^{3}$ , allowing us to safely restart the PCD process   \n186 from a set of equilibrium samples generated by static sampling of the low-rank RBM.   \n187 Overcoming these transitions has dramatic implications for the quality of the models we can train   \n188 and how accurately they reproduce the statistics of the data. In Fig. 2, we show for 3 datasets the   \n189 equilibrium samples drawn from 3 RBMs trained with identical number of samples, minibatch size,   \n190 $k=100$ Gibbs steps, and learning rate $\\gamma=0.01$ , but different training strategies. In particular,   \n191 we consider 2 RBMs trained from scratch with the standard PCD [33] and the recently proposed   \n192 Jarzynski reweighing method [23] (see SI for our specific implementation in the RBM), and a final   \n193 machine trained with PCD and pre-trained with a low-rank RBM. In all cases, the quality of the   \n194 generated samples is significantly better when pre-training is used. For the Mickey dataset, neither   \n195 JarRBM nor normal PCD are able to generate convincing data. For the MNIST01 dataset, all 3   \n196 methods are able to generate convincing data, but only Pretrain+PCD is able to correctly balance all   \n197 modes, as can be seen in Fig. 3, where we compare the histograms of the generated data projected   \n198 onto the first 3 PCA directions with those of the dataset and a random selection of the generated   \n199 samples. We see that the pre-training $+\\mathrm{PCD}$ training perfectly balances the different modes (here we   \n200 show the first 3 directions, but it goes much further), unlike the other 2 methods, and also generates   \n201 more diverse images. We can also compare the log-likelihood of all 3 models and find that the   \n202 pre-trained RBM achieves higher values. At this point, it is important to emphasize that in order to   \n203 properly quantify the increase in log-likelihood, we need to use the PTT algorithm (see section 5) to   \n204 correctly thermalize in these well-trained machines. For comparison, we show our PTT measure in   \n205 dark and solid lines, while the standard AIS [42] estimate is shown in light dashed lines.   \n206 Already from the scatter plots we see that the pre-training has a dramatic effect in obtaining models   \n207 where all modes are properly balanced, but also has important effects in the maximum test-likelihood   \n208 we can achieve. In all cases, these equilibrium samples are drawn using the trajectory PT algorithm   \n209 that will be explained in the next section, and the log-likelihood obtained using the equilibrium   \n210 configurations obtained at different epochs as a result of the trajectory PT flow. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/3ad7d9f9a419fb5d097200ebcae54827aa47defd2c77bfde9057fdaa4429f5d7.jpg", "img_caption": ["Figure 2: We compare the equilibrium samples generated by RBMs trained on the Mickey, MNIST01, and HGD datasets using three different training schemes: Jarzynski (JarRBM), PCD, and PCD initialized on low-rank RBMs (used to generate the samples in Fig. 1\u2013D-F). To assess the fitting of the modes, we show a density plot of the projections of the data in the first two principal directions of each dataset. We compare these results with the density plot of the original datasets in the first column. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "211 5 Standard Gibbs sampling vs. Parallel Trajectory Tempering (PTT) ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "212 One major challenge with structured datasets is quantifying the model\u2019s quality, since sampling the   \n213 equilibrium measure of a well-trained model is often too time-consuming. This affects the reliability of   \n214 generated samples and indirect measures as log-likelihood\u2019s estimation through Annealing Importance   \n215 Sampling (AIS) [42], making them inaccurate and meaningless.   \n216 To illustrate this problem, let us consider the MNIST01 and the HGD datasets. MNIST01 dataset is   \n217 bimodal and the HGD highly multimodal as shown in their PCA in Figs. 1\u2013A and C. Let us consider   \n218 that we want to sample the equilibrium measure of the RBMs trained using low-rank RBM pretraining.   \n219 In order to draw new samples from these models, one would typically run MCMC processes from   \n220 random initialization and iterate them until convergence. The mixing time is controlled by the   \n221 jumping time between clusters. To accurately estimate the relative weight between modes, the   \n222 MCMC processes must be ergodic, requiring many back-and-forth jumps. However, as shown in   \n223 Figs. 4\u2013A and C for the MNIST01 and HGD datasets, Gibbs sampling dynamics are extremely slow,   \n224 rarely producing jumps even after $10^{4}$ MCMC steps. The yellow curves in Figs. 4\u2013B and D show the   \n225 mean number of jumps over 100 independent chains as a function of MCMC steps, indicating that a   \n226 proper equilibrium generation would require at least $10^{6}-10^{7}$ MCMC steps.   \n227 One effective way to accelerate the dynamics is to exploit the training trajectory, where the model   \n228 progressively specializes through second-order phase transitions. To achieve this, we save RBMs   \n229 trained at various epochs and propose swaps between configurations of similarly trained models. We ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/cdb0d695869d30de7257a08a06784c10008de775233925868cf087ff2d14551f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 3: We compare the samples generated by the 3 RBMs (JarRBM, PCD, pretrain $\\mathbf{+PCD}$ ) trained with MNIST01 data. In A, we show the histograms of the generated data projected on the first, second and third principal directions with those of the dataset. We see that only the pretrain $+\\mathrm{PCD}$ correctly balances the different modes. In B we show 10 images generated by each machine. In C, we compare the log-likelihood of each model\u2019s dataset as a function of training time. The dark and full curves were obtained using the PTT algorithm discussed in section 5, and the lighter and dashed curves using the AIS method [42]. ", "page_idx": 6}, {"type": "text", "text": "230 call this the Parallel Trajectory Tempering (PTT) algorithm. Unlike the standard Parallel Tempering   \n231 (PT) algorithm, which attempts swaps configurations between different temperatures, the PTT swaps   \n232 between model parameters with different degrees of specialization. This approach is more natural   \n233 for this problem because it involves crossing only second-order transitions, unlike the first-order   \n234 transitions occurring in temperature annealing. And in fact, we show in Figs. 4\u2013A and C, that this   \n235 approach allows us to sharply accelerate the dynamics, as opposed to the standard PT algorithm   \n236 (studied in detail for the MNIST dataset in [40]).   \n237 In the PTT algorithm, the configurations $\\boldsymbol{\\mathbf{\\mathit{x}}}=(\\boldsymbol{\\mathbf{\\mathit{v}}},h)$ of neighboring machines indexed by $t$ and $t-1$   \n238 are interchanged with the probability ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\np_{\\mathrm{acc}}(\\boldsymbol{x}^{t}\\leftrightarrow\\boldsymbol{x}^{t-1})=\\mathrm{min}\\left(1,\\exp\\left(\\Delta\\mathcal{H}^{t}(\\boldsymbol{x}^{t})-\\Delta\\mathcal{H}^{t}(\\boldsymbol{x}^{t-1})\\right)\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "239 This move satisfies detailed balance with our target equilibrium distribution $p(\\pmb{x})=\\exp(-\\mathcal{H}(\\pmb{x}))/Z$ ,   \n240 ensuring that the moves lead to the same equilibrium measure. As \u201cnonspecialized\" models mix   \n241 very quickly, either because the distribution is essentially Gaussian at the initialisation of a standard   \n242 training, or because the low-rank RBM can be sampled with a static Monte Carlo process (yielding   \n243 independent configurations each time), the trajectory flow significantly accelerates convergence   \n244 to equilibrium. The time interval between successive machines is selected in such a way that the   \n245 probability of accepting interchanges between neighboring machines remains around 0.3. Pre-trained   \n246 machines require a significant fewer number of models to be effective, because most selected models   \n247 are positioned at the most prominent phase transitions. We give the number of machines used for   \n248 each sampling process in the SI. We also provide there a specific and detailed description of the   \n249 algorithm used.   \n250 In the red curves in Fig. (4)\u2013B and D, we show the number of jumps between clusters as a function   \n251 of the number of elementary MCMC steps, which in the PTT scheme refer to 1 Gibbs sampling step   \n252 $^+$ one swap proposal. For the DNA dataset, we have two measures corresponding to jumps along the   \n253 two principal component directions. We observe at $10^{4}$ MCMC steps an increase of the number of   \n254 jumps by a factor of 80 for MNIST01 and by a factor of 1350 for the HGD in this machine, although   \n255 we achieve higher factors in other machines, as we show in the SI. The sampling of RBMs training   \n256 on the MNIST01 dataset was the subject of the study of the \u201cstacked tempering\" algorithm in [40].   \n257 If we compare the numbers with their work, we see that we achieve a 3-4 times higher speedup factor,   \n258 where our model has the advantage that it does not need additional training, but simply uses the stored   \n259 machines correctly.   \n260 Another desirable advantage of our PTT algorithm is that we can easily use it to compute an improved   \n261 estimate of the AIS log-likelihood, except that in our case we consider the training trajectory instead   \n262 of a cooling process and use the equilibrium samples obtained for each of the models to compute the   \n263 model averages. In Figs. 3\u2013C 5\u2013A we compare the log-likelihood estimates obtained with our method   \n264 (AIS-PTT) in full and dark lines and in light and dashed lines the AIS estimate (AIS). We see that   \n265 both measures coincide for most parts of the training and that they split when the sampling becomes   \n266 too long to thermalize along the temperature annealing curve in AIS. This effect is particularly evident   \n267 for the JarRBM run in 5\u2013A, where AIS takes a long time to recognize that the model suffers from a   \n268 strong mode-collapse effect. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/19cca33f540ecebc2d6b6dc6a5b870a61d03b3c2c7d38858cc53d0468a8b3e77.jpg", "img_caption": ["Figure 4: Comparison between PTT and classical Gibbs sampling for the MNIST01 dataset (A and B, respectively) and the human genome dataset (C and D, respectively). In A and C, we show the trajectory of two independent chains (red and orange) projected onto the PCA along the sampling process of the pretraining $\\mathbf{\\cdot}+\\mathbf{P}\\mathbf{CD}$ model for $10^{4}$ MCMC steps. The black contour represents the density proflie of the dataset and the position of the chains is plotted every 10 steps. In B and D we show the average number of jumps from one cluster to another as a function of the MCMC steps performed. The average is calculated over a population of 100 chains. In D, we show the average jump time between clusters along the first (solid line) and second (dashed line) principal components of the data. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "269 6 Overfitting and privacy loss as quality indicators ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "270 In this section, we examine the quality of the samples generated, regarding overfitting and privacy   \n271 criteria which have been defined for genomic data in particular. We look at this on the models trained   \n272 with PCD with and without pre-training. We do not include the Jarzysnki method here, as this method   \n273 fails to obtain a reliable model as clearly shown in the evolution of the Log-likelihood in Fig. 5. We   \n274 focus on the human genome dataset, as shown in Fig. 1\u2013C, to evaluate the ability of various state  \n275 of-the-art generative models to generate realistic fake genomes while minimizing privacy concerns   \n276 (i.e., reducing overfitting). Recent studies [17, 18] have thoroughly investigated this for a variety of   \n277 generative models. Both studies concluded that the RBM was the most accurate method for generating   \n278 high-quality and private synthetic genomes. The comparison between models relies primarily on the   \n279 Nearest Neighbor Adversarial Accuracy $(A A_{\\mathrm{{TS}}})$ and privacy loss indicators, introduced in Ref. [43],   \n280 which quantify the similarity and the level of \"privacy\" of the data generated by a model w.r.t. the   \n281 training set. We have $\\begin{array}{r}{A A_{\\mathrm{TS}}\\,=\\,\\frac{1}{2}\\bigl(A A_{\\mathrm{True}}+\\dot{A}A_{\\mathrm{Synth}}\\bigr)}\\end{array}$ where $A A_{\\mathrm{True}}$ [resp. $A A_{\\mathrm{Synth}}]$ are two ", "page_idx": 7}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/f48b7353d449938794baee1c7e4d58e96e9f68d15471f66d752f9b5e5785dfb0.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 5: We compare the quality of the RBMs trained with the human genome data (HGD). In A, we show the log-likelihood as a function of the training epochs for the 3 training procedures. Solid lines correspond to AIS-PTT and dashed lines to AIS. The JarRBM falls down because the training breaks eventually. In B and C we compare privacy and overfitting based on the $A A_{\\mathrm{TS}}$ indicator. ", "page_idx": 8}, {"type": "text", "text": "282 quantities in $[0,1]$ obtained by merging two sets of real and synthetic data of equal size $N_{s}$ and   \n283 measuring respectively the frequency that a real [rep. synthetic] has a synthetic [resp. real] as   \n284 nearest neighbor. If the generated samples are statistically indistinguishable from real samples, both   \n285 frequencies $A A_{\\mathrm{True}}$ and $A A_{\\mathrm{Synth}}$ should converge to 0.5 at large $N_{\\mathrm{s}}$ . $A A_{\\mathrm{TS}}$ can be evaluated both   \n286 with train or test samples and the privacy loss indicator is defined as Privacy $\\mathrm{loss}=A A_{\\mathrm{TS}}^{\\mathrm{test}}\\,{-}\\,A A_{\\mathrm{TS}}^{\\mathrm{train}}$   \n287 and is expected to be strictly positive. Fig. 5 shows the comparison of $A A_{\\mathrm{TS}}$ and privacy loss values   \n288 obtained with our two models, demonstrating that the pre-trained RBM clearly outperforms the   \n289 other model, and even achieves better results $A A_{\\mathrm{TS}}$ values much closer to 0.5) than those discussed   \n290 in [17, 18]. ", "page_idx": 8}, {"type": "text", "text": "291 7 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "292 We have shown that the strategy of initiating the training on a pre-trained low-rank RBM is an   \n293 extremely effective strategy to obtain high quality models for structured datasets that accurately   \n294 represent all the modes in the datasets and with significantly higher log-likelihoods. We have also   \n295 shown that the models obtained in that way are: (i) better generative models than those obtained   \n296 with standard trainings, both, in the sense that they over-fit less at the same time they are more   \n297 indistinguishable from the test samples, (ii) they display faster relaxational dynamics.   \n298 We have also proposed a new fast sampling method that exploits the progressive learning of features   \n299 in the training of RBMs to design an efficient trajectory PT strategy that allows accelerating the   \n300 parallel Gibbs sampling dynamics by many orders of magnitude and overcome the performance   \n301 of recent efficient sampling methods without adding any extra cost than saving models during the   \n302 training.   \n303 Both strategies for training and sampling are very general, and could be generalized to more complex   \n304 EBMs. In this sense, the low-rank RBM model could be used as a more efficient pre-initialisation   \n305 in deeper structures, and the trajectory PT algorithm is suitable to be directly used in any EBM no   \n306 matter how complex it is. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "307 8 Code availability ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "308 The code and datasets are available at https://github.com/nbereux/fast-RBM. ", "page_idx": 8}, {"type": "text", "text": "309 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "310 [1] Paul Smolensky. In Parallel Distributed Processing: Volume 1 by D. Rumelhart and J. McLel  \n311 land, chapter 6: Information Processing in Dynamical Systems: Foundations of Harmony   \n312 Theory. 194-281. MIT Press, 1986.   \n313 [2] David H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for   \n314 Boltzmann machines. Cognitive science, 9(1):147\u2013169, 1985.   \n315 [3] Geoffrey E Hinton and Terrence J Sejnowski. Optimal perceptual inference. In Proceedings of   \n316 the IEEE conference on Computer Vision and Pattern Recognition, volume 448, pages 448\u2013453.   \n317 Citeseer, 1983.   \n318 [4] H Chau Nguyen, Riccardo Zecchina, and Johannes Berg. Inverse statistical problems: from the   \n319 inverse ising problem to data science. Advances in Physics, 66(3):197\u2013261, 2017.   \n320 [5] John Hertz, Yasser Roudi, and Joanna Tyrcha. Ising models for inferring network structure from   \n321 spike data. 2011.   \n322 [6] Simona Cocco, Christoph Feinauer, Matteo Figliuzzi, R\u00e9mi Monasson, and Martin Weigt.   \n323 Inverse statistical physics of protein sequences: a key issues review. Reports on Progress in   \n324 Physics, 81(3):032601, 2018.   \n325 [7] Aur\u00e9lien Decelle, Cyril Furtlehner, Alfonso de Jes\u00fas Navas G\u00f3mez, and Beatriz Seoane. In  \n326 ferring effective couplings with restricted boltzmann machines. SciPost Physics, 16(4):095,   \n327 2024.   \n328 [8] Aur\u00e9lien Decelle, Beatriz Seoane, and Lorenzo Rosset. Unsupervised hierarchical clustering   \n329 using the learning dynamics of restricted boltzmann machines. Phys. Rev. E, 108:014110, Jul   \n330 2023.   \n331 [9] Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu. A theory of generative convnet. In   \n332 Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International   \n333 Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research,   \n334 pages 2635\u20132644, New York, New York, USA, 20\u201322 Jun 2016. PMLR.   \n335 [10] Yang Song and Diederik P Kingma. How to train your energy-based models. arXiv preprint   \n336 arXiv:2101.03288, 2021.   \n337 [11] Giuseppe Carleo and Matthias Troyer. Solving the quantum many-body problem with artificial   \n338 neural networks. Science, 355(6325):602\u2013606, 2017.   \n339 [12] Roger G Melko, Giuseppe Carleo, Juan Carrasquilla, and J Ignacio Cirac. Restricted boltzmann   \n340 machines in quantum physics. Nature Physics, 15(9):887\u2013892, 2019.   \n341 [13] Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, and Akio Tomiya. Deep learning and the   \n342 ads/cft correspondence. Physical Review D, 98(4):046019, 2018.   \n343 [14] Koji Hashimoto. Ads/cft correspondence as a deep boltzmann machine. Physical Review $D$ ,   \n344 99(10):106017, 2019.   \n345 [15] J\u00e9r\u00f4me Tubiana, Simona Cocco, and R\u00e9mi Monasson. Learning protein constitutive motifs   \n346 from sequence data. Elife, 8:e39397, 2019.   \n347 [16] Juan Rodriguez-Rivas, Giancarlo Croce, Maureen Muscat, and Martin Weigt. Epistatic models   \n348 predict mutable sites in sars-cov-2 proteins and epitopes. Proceedings of the National Academy   \n349 of Sciences, 119(4):e2113118119, 2022.   \n350 [17] Burak Yelmen, Aur\u00e9lien Decelle, Linda Ongaro, Davide Marnetto, Corentin Tallec, Francesco   \n351 Montinaro, Cyril Furtlehner, Luca Pagani, and Flora Jay. Creating artificial human genomes   \n352 using generative neural networks. PLoS genetics, 17(2):e1009303, 2021.   \n353 [18] Burak Yelmen, Aur\u00e9lien Decelle, Leila Lea Boulos, Antoine Szatkownik, Cyril Furtlehner,   \n354 Guillaume Charpiat, and Flora Jay. Deep convolutional and conditional neural networks for   \n355 large-scale genomic data generation. PLOS Computational Biology, 19(10):e1011584, 2023.   \n356 [19] Erik Nijkamp, Mitch Hill, Song-Chun Zhu, and Ying Nian Wu. Learning non-convergent   \n357 non-persistent short-run mcmc toward energy-based model. Advances in Neural Information   \n358 Processing Systems, 32, 2019.   \n359 [20] Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, and Ying Nian Wu. On the anatomy   \n360 of mcmc-based maximum likelihood learning of energy-based models. In Proceedings of the   \n361 AAAI Conference on Artificial Intelligence, volume 34, pages 5272\u20135280, 2020.   \n362 [21] Aur\u00e9lien Decelle, Cyril Furtlehner, and Beatriz Seoane. Equilibrium and non-equilibrium   \n363 regimes in the learning of restricted boltzmann machines. Advances in Neural Information   \n364 Processing Systems, 34:5345\u20135359, 2021.   \n365 [22] Elisabeth Agoritsas, Giovanni Catania, Aur\u00e9lien Decelle, and Beatriz Seoane. Explaining the   \n366 effects of non-convergent sampling in the training of energy-based models. arXiv preprint   \n367 arXiv:2301.09428, 2023.   \n368 [23] Alessandra Carbone, Aur\u00e9lien Decelle, Lorenzo Rosset, and Beatriz Seoane. Fast and   \n369 functional structured data generators rooted in out-of-equilibrium physics. arXiv preprint   \n370 arXiv:2307.06797, 2023.   \n371 [24] Renjie Liao, Simon Kornblith, Mengye Ren, David J Fleet, and Geoffrey Hinton. Gaussian  \n372 bernoulli rbms without tears. arXiv preprint arXiv:2210.10318, 2022.   \n373 [25] Nicolas B\u00e9reux, Aur\u00e9lien Decelle, Cyril Furtlehner, and Beatriz Seoane. Learning a restricted   \n374 boltzmann machine using biased monte carlo sampling. SciPost Physics, 14(3):032, 2023.   \n375 [26] A. Decelle, G. Fissore, and C. Furtlehner. Spectral dynamics of learning in restricted boltzmann   \n376 machines. Europhysics Letters, 119(6):60001, nov 2017.   \n377 [27] Aur\u00e9lien Decelle, Giancarlo Fissore, and Cyril Furtlehner. Thermodynamics of restricted   \n378 boltzmann machines and related learning dynamics. Journal of Statistical Physics, 172:1576\u2013   \n379 1608, 2018.   \n380 [28] A. Anonymous. Cascade of phase transitions in the training of energy-based models. arXiv:,   \n381 2024.   \n382 [29] Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and Fujie Huang. A tutorial on energy  \n383 based learning. Predicting structured data, 1(0), 2006.   \n384 [30] Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural   \n385 computation, 14(8):1771\u20131800, 2002.   \n386 [31] Ruslan Salakhutdinov and Iain Murray. On the quantitative analysis of deep belief networks. In   \n387 Proceedings of the 25th international conference on Machine learning, pages 872\u2013879, 2008.   \n388 [32] Guillaume Desjardins, Aaron Courville, Yoshua Bengio, Pascal Vincent, and Olivier Delalleau.   \n389 Tempered markov chain monte carlo for training of restricted boltzmann machines. In Proceed  \n390 ings of the thirteenth international conference on artificial intelligence and statistics, pages   \n391 145\u2013152. JMLR Workshop and Conference Proceedings, 2010.   \n392 [33] Tijmen Tieleman. Training restricted boltzmann machines using approximations to the likeli  \n393 hood gradient. In Proceedings of the 25th international conference on Machine learning, pages   \n394 1064\u20131071, 2008.   \n395 [34] Enzo Marinari and Giorgio Parisi. Simulated tempering: a new monte carlo scheme. Europhysics   \n396 letters, 19(6):451, 1992.   \n397 [35] Russ R Salakhutdinov. Learning in markov random fields using tempered transitions. Advances   \n398 in neural information processing systems, 22, 2009.   \n399 [36] Oswin Krause, Asja Fischer, and Christian Igel. Population-contrastive-divergence: Does   \n400 consistency help with rbm training? Pattern Recognition Letters, 102:1\u20137, 2018.   \n401 [37] Davide Carbone, Mengjian Hua, Simon Coste, and Eric Vanden-Eijnden. Efficient training of   \n402 energy-based models using jarzynski equality. Advances in Neural Information Processing   \n403 Systems, 36, 2024.   \n404 [38] E Nijkamp, R Gao, P Sountsov, S Vasudevan, B Pang, S-C Zhu, and YN Wu. Mcmc should   \n405 mix: learning energy-based model with neural transport latent space mcmc. In International   \n406 Conference on Learning Representations (ICLR 2022)., 2022.   \n407 [39] Louis Grenioux, \u00c9ric Moulines, and Marylou Gabri\u00e9. Balanced training of energy-based models   \n408 with adaptive flow sampling. In ICML 2023 Workshop on Structured Probabilistic Inference   \n409 and Generative Modeling, 2023.   \n410 [40] Cl\u00e9ment Roussel, Jorge Fernandez-de Cossio-Diaz, Simona Cocco, and Remi Monasson.   \n411 Accelerated sampling with stacked restricted boltzmann machines. In The Twelfth International   \n412 Conference on Learning Representations, 2023.   \n413 [41] Aur\u00e9lien Decelle and Cyril Furtlehner. Exact training of restricted boltzmann machines on   \n414 intrinsically low dimensional data. Physical Review Letters, 127(15):158303, 2021.   \n415 [42] Oswin Krause, Asja Fischer, and Christian Igel. Algorithms for estimating the partition function   \n416 of restricted boltzmann machines. Artificial Intelligence, 278:103195, 2020.   \n417 [43] Andrew Yale, Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, and Kristin P Ben  \n418 nett. Generation and evaluation of privacy preserving synthetic health data. Neurocomputing,   \n419 416:244\u2013255, 2020. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "420 A Details of the pre-training of a low rank RBM ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "421 A.1 The low-rank RBM and its sampling procedure ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "422 Our goal is to pre-train an RBM to directly encode the first $d$ principal modes of the dataset in the   \n423 model\u2019s coupling matrix. This approach avoids the standard procedure of progressively encoding   \n424 these modes through a series of second-order phase transitions, which negatively impact the quality   \n425 of gradient estimates during standard training. It also helps prevent critical relaxation slowdown of   \n426 MCMC dynamics in the presence of many separated clusters.   \n427 Given a dataset, we want to find a good set of model parameters $\\mathbf{\\nabla}w,\\pmb{\\theta}$ and $\\eta$ ) for which the statistics   \n428 of the generated samples exactly match the statistics of the data projected onto the first $d$ directions   \n429 of the PCA dec\u221aomposition of the training set. Let us call each of these $\\alpha=1,\\ldots,d$ projections   \n430 $m_{\\alpha}=\\pmb{u}_{\\alpha}\\cdot\\pmb{v}/\\sqrt{N_{\\mathrm{v}}}$ the magnetizations along the mode $\\alpha$ , where $\\pmb{u}_{\\alpha}$ is the $\\alpha$ -th mode of the PCA   \n431 decomposition of the dataset. A simple way to encode these $d$ -modes is to parameterize the $w$ -matrix   \n432 as: ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "equation", "text": "$$\n\\pmb{w}=\\sum_{\\alpha=1}^{d}w_{\\alpha}\\bar{\\pmb{u}}_{\\alpha}\\pmb{u}_{\\alpha}^{\\top},\\qquad\\mathrm{with}\\qquad\\big(\\pmb{u}_{\\alpha},\\bar{\\pmb{u}}_{\\alpha}\\big)\\in\\mathbb{R}^{N_{v}}\\times\\mathbb{R}^{N_{h}},\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "433 where $\\textbf{\\em u}$ and $\\hat{\\pmb u}$ are respectively the right-hand and left-hand singular vectors of $\\mathbf{\\nabla}w$ , the former being   \n434 directly given by the PCA, while $w_{\\alpha}$ are the singular values of $\\mathbf{\\nabla}w$ . Using this decomposition, the   \n435 marginal energy on the visible variables, $\\begin{array}{r}{\\mathcal{H}(\\pmb{v})=\\log\\sum_{h}\\exp{\\mathcal{H}(\\pmb{v},\\pmb{h})}}\\end{array}$ can be rewritten in terms of   \n436 these magnetizations $\\pmb{m}\\equiv(m_{1},\\ldots,m_{d})$ ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathcal{H}(v)=-\\sum_{a}\\log\\cosh\\left(\\sqrt{N_{\\mathrm{v}}}\\bar{u}_{a}\\sum_{\\alpha=1}^{d}w_{\\alpha}m_{\\alpha}+\\eta_{a}\\right)=\\mathcal{H}(m(v)).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "437 Now, the goal of our pre-training is not to match the entire statistics of the data set, but only the   \n438 marginal probability of these magnetizations. In other words, we want to model the marginal   \n439 distribution ", "page_idx": 11}, {"type": "equation", "text": "$$\np_{\\mathrm{emp}}(\\boldsymbol{m})\\equiv\\sum_{\\boldsymbol{v}}p_{\\mathrm{emp}}(\\boldsymbol{v})\\prod_{\\alpha=1}^{d}\\delta\\left(m_{\\alpha}-\\frac{1}{\\sqrt{N_{\\mathrm{v}}}}\\boldsymbol{u}_{\\alpha}^{T}\\boldsymbol{v}\\right),\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "440 where $\\delta$ is the Dirac $\\delta$ -distristribution. In this formulation, the distribution of the model over the   \n441 magnetization $\\mathbf{\\nabla}m$ can be easily characterized ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle p({\\pmb m})=\\frac{1}{Z}\\sum_{v}e^{-{\\mathcal{H}}(v)}\\prod_{\\alpha=1}^{d}\\delta\\left(m_{\\alpha}-\\frac{1}{\\sqrt{N_{\\mathrm{v}}}}u_{\\alpha}^{T}v\\right)}}\\\\ {~~~~~=\\frac{1}{Z}{\\mathcal{N}}({\\pmb m})\\exp\\sum_{a}\\log\\cosh\\left(\\bar{u}_{a}\\sum_{\\alpha=1}^{d}w_{\\alpha}m_{\\alpha}+\\eta_{a}\\right)}}\\\\ {~~~~~=\\frac{1}{Z}e^{-{\\mathcal{H}}({\\pmb m})+N_{\\mathrm{v}}s({\\pmb m})}=\\frac{1}{Z}e^{-N_{\\mathrm{v}}f({\\pmb m})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "442 where $\\begin{array}{r}{\\mathcal{N}(\\pmb{m})=\\sum_{\\pmb{v}}\\prod_{\\alpha=1}^{d}\\delta\\left(m_{\\alpha}-\\frac{1}{\\sqrt{N_{\\mathrm{v}}}}\\pmb{u}_{\\alpha}^{T}\\pmb{v}\\right)}\\end{array}$ is the number of configurations with magnetiza  \n443 tions $\\mathbf{\\nabla}m$ , and thus $S(\\pmb{m})=\\log\\bar{N}(\\pmb{m})/N_{\\mathrm{v}}$ is the associated entropy. Now, for large $N_{\\mathrm{v}}$ the entropic   \n444 term can be determined using large deviation theory, and in particular the G\u00e4rtner-Ellis theorem: ", "page_idx": 12}, {"type": "equation", "text": "$$\np_{\\mathrm{prior}}(m)=\\frac{e^{N_{\\mathrm{v}}s(m)}}{2^{N_{\\mathrm{v}}}}\\approx\\exp\\left(-N_{\\mathrm{v}}\\mathcal{Z}(m)\\right),\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "445 with the rate function ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathcal{Z}(\\pmb{m})=\\operatorname*{sup}_{\\pmb{\\mu}}\\left[\\pmb{m}^{T}\\pmb{\\mu}-\\phi(\\pmb{\\mu})\\right]=\\pmb{m}^{T}\\pmb{\\mu}^{*}-\\phi(\\pmb{\\mu}^{*}),\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "446 and ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\phi({\\pmb\\mu})=\\operatorname*{lim}_{N_{\\mathrm{v}}\\rightarrow\\infty}\\frac{1}{N_{\\mathrm{v}}}\\log\\left<e^{N_{\\mathrm{v}}m^{T}{\\pmb\\mu}}\\right>=\\operatorname*{lim}_{N_{\\mathrm{v}}\\rightarrow\\infty}\\frac{1}{N_{\\mathrm{v}}}\\log\\frac{1}{2^{N_{\\mathrm{v}}}}\\sum_{v}e^{\\sqrt{N_{\\mathrm{v}}}\\sum_{\\alpha=1}^{d}\\mu_{\\alpha}\\sum_{i}u_{\\alpha,i}v_{i}}}}\\\\ {{\\displaystyle\\qquad=\\operatorname*{lim}_{N_{\\mathrm{v}}\\rightarrow\\infty}\\frac{1}{N_{\\mathrm{v}}}\\sum_{i=1}^{N_{\\mathrm{v}}}\\log\\cosh\\left(\\sqrt{N_{\\mathrm{v}}}\\sum_{\\alpha=1}^{d}\\mu_{\\alpha}u_{\\alpha,i}\\right).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "447 Then, given a magnetization $\\mathbf{\\nabla}m$ , we can compute the minimizer $\\pmb{\\mu}^{*}(\\pmb{m})$ of $\\phi(\\boldsymbol{\\mu})-\\boldsymbol{m}^{T}\\boldsymbol{\\mu}$ which is   \n448 convex, using e.g. Newton method which converge really fast since we are in small dimension. Note   \n449 that in practice we will obviously use finite estimates of $\\phi$ , assuming $N_{v}$ is large enough. As a result   \n450 we get $\\pmb{\\mu}^{*}(\\pmb{m})$ satisfying implicit equations given by the constraints given at given $N_{v}$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\nm_{\\alpha}=\\frac{1}{\\sqrt{N_{\\mathrm{v}}}}\\sum_{i=1}^{N_{\\mathrm{v}}}u_{i}^{\\alpha}\\operatorname{tanh}\\left(\\sqrt{N_{\\mathrm{v}}}\\sum_{\\beta=1}^{d}u_{i}^{\\beta}\\mu_{\\beta}^{*}\\right).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "451 It is then straightforward to check that spins distributed as ", "page_idx": 12}, {"type": "equation", "text": "$$\np_{\\mathrm{prior}}(v|m)\\propto e^{N_{\\mathrm{v}}\\pmb{\\mu}^{*\\,T}m(\\pmb{v})}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "452 fulfill well the requirement, as $\\left\\langle u_{\\alpha}^{T}v/\\sqrt{N_{\\mathrm{v}}}\\right\\rangle_{p_{\\mathrm{prior}}}=m_{\\alpha}$ . In other words, we can generate samples   \n453 having mean magnetization $m_{\\alpha}$ just by choosing $v_{i}$ as ", "page_idx": 12}, {"type": "equation", "text": "$$\np_{\\mathrm{prior}}(v_{i}=1|m)=\\mathrm{sigmoid}\\left(2\\sqrt{N_{\\mathrm{v}}}\\sum_{\\alpha=1}^{d}u_{\\alpha,i}\\mu_{\\alpha}^{*}(m)\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "454 The training can therefore be done directly in the subspace of dimension $d$ . In Ref. [41], it has been   \n455 shown that such RBM can be trained by mean of the Restricted Coulomb Machine, where the gradient   \n456 is actually convex in the parameter\u2019s space. It is then possible to do a mapping from the RCM to   \n457 the RBM to recover the RBM\u2019s parameters. In brief, the training of the low-dimensional RBM is   \n458 performed by the RCM, and then the parameters are obtrained via a direct relation between the RCM   \n459 and the RBM\u2019s parameters. The detail of the definition and of the training of the RCM is detailed in   \n460 the appendix A.2. ", "page_idx": 12}, {"type": "text", "text": "461 A.2 The Restricted Coulomb Machine ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "462 As introduced in [41], it is possible to exactly train a surrogate model for the RBM, called the   \n463 Restricted Coulomb Machine (RCM), on a low dimensional dataset without explicitly sampling the   \n464 machine allowing to learn even heavily clustered datasets. We will briefly outline the main steps to   \n465 train the RCM. A more detailed explanation can be found in Appendix A.2. ", "page_idx": 13}, {"type": "text", "text": "466 The RCM is an approximation of the marginal distribution of the RBM with $\\{-1,1\\}$ binary variables: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{H}(\\pmb{v})=-\\sum_{i}v_{i}\\theta_{i}-\\sum_{a}\\log\\cosh\\left(\\sum_{i}w_{i a}v_{i}+\\eta_{a}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "467 We then project both the parameters and variables of the RBM on the first $d$ principal components of   \n468 the dataset: ", "page_idx": 13}, {"type": "equation", "text": "$$\nm_{\\alpha}:=\\frac{1}{\\sqrt{N_{v}}}\\sum_{i=1}^{N_{v}}s_{i}u_{i\\alpha},\\quad w_{\\alpha a}:=\\sum_{i=1}^{N_{v}}w_{i a}u_{i\\alpha},\\quad\\theta_{\\alpha}:=\\frac{1}{\\sqrt{N_{v}}}\\sum_{i=1}^{N_{v}}\\theta_{i}u_{i\\alpha}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "469 with $\\alpha\\in\\{1,\\ldots,d\\}$ and $\\pmb{v}$ the projection matrix of the PCA. The projected distribution of the model   \n470 is then given by ", "page_idx": 13}, {"type": "equation", "text": "$$\np_{\\mathtt{R M M}}(m)=\\frac{\\exp\\left(N_{v}\\left[S(m)+\\sum_{\\alpha=1}^{d}\\theta_{\\alpha}m_{\\alpha}+\\frac{1}{N_{v}}\\sum_{a=1}^{N_{h}}\\log\\cosh\\left(\\sqrt{N_{v}}\\sum_{\\alpha=1}^{d}m_{\\alpha}w_{\\alpha a}+\\eta_{a}\\right)\\right]\\right)}{Z}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "471 where we ignore the fluctuations related to the transverse directions and $S[m]$ accounts for the   \n472 non-uniform prior on $\\mathbf{\\nabla}m$ due to the projection of the uniform prior on $\\pmb{s}$ for the way to compute it. ", "page_idx": 13}, {"type": "text", "text": "473 The RCM is then built by approximating ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\log\\cosh(x)\\simeq|x|-\\log2,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "474 which is valid for $x$ large enough. The probability of the RCM is thus given by: ", "page_idx": 13}, {"type": "equation", "text": "$$\np_{\\mathrm{RCM}}(m)=\\frac{\\exp\\left(N_{v}\\left[S(m)+\\sum_{\\alpha=1}^{d}\\theta_{\\alpha}m_{\\alpha}+\\sum_{a=1}^{N_{h}}q_{a}\\left|\\sum_{\\alpha=1}^{d}n_{\\alpha}m_{\\alpha}+z_{a}\\right|\\right]\\right)}{Z}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "475 where ", "page_idx": 13}, {"type": "equation", "text": "$$\nq_{a}=\\sqrt{N_{v}\\sum_{\\alpha=1}^{d}w_{\\alpha a}^{2}},\\quad n_{a}=\\frac{w_{\\alpha a}}{\\sqrt{\\sum_{\\alpha=1}^{d}w_{\\alpha a}^{2}}},\\quad z_{a}=\\frac{\\eta_{a}}{\\sqrt{N_{v}\\sum_{\\alpha=1}^{d}w_{\\alpha a}^{2}}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "476 This can be easily inverted as ", "page_idx": 13}, {"type": "equation", "text": "$$\nw_{\\alpha a}=\\frac{1}{\\sqrt{N_{v}}}q_{a}n_{a}\\mathrm{\\qquad~and\\qquad}\\eta_{a}=q_{a}z_{a},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "477 in order to obtain the RBM from the RCM. The model is then trained through log-likelihood   \n478 maximization over its parameters. However, this objective is non-convex if all the parameters are   \n479 trained through gradient ascent. To relax the problem, since we\u2019re in low dimension, we can define a   \n480 family of hyperplanes $(n,z)$ covering the space and let the model only learn the weights of each to   \n481 the hyperplane. We can then discard the ones with a weight low enough for the approximation (21) to   \n482 be bad. ", "page_idx": 13}, {"type": "text", "text": "483 The gradients are given by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial J(\\Theta)}{\\partial q_{a}}=\\mathbb{E}_{m\\sim p_{\\mathcal{D}}(m)}\\left[\\left|n_{a}^{T}m+z_{a}\\right|\\right]-\\mathbb{E}_{m\\sim p_{\\mathrm{RCM}}(m)}\\left[\\left|n_{a}^{T}m+z_{a}\\right|\\right],\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "484 ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial J(\\Theta)}{\\partial\\theta_{\\alpha}}=E_{m\\sim p_{\\mathcal{D}}(m)}\\left[m_{\\alpha}\\right]-\\mathbb{E}_{m\\sim p_{\\mathrm{RCM}}(m)}\\left[m_{\\alpha}\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "485 The positive term is straightforward to compute. For the negative term, we rely on a discretization of   \n486 the longitudinal space to estimate the probability density of the model and compute the averages. ", "page_idx": 13}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/03546c18f7274d3c576faa7c256bca812fd98cb5794951aa93dfe360cbb4340a.jpg", "img_caption": ["Figure 6: Scheme of PTT. We Initialize the chains of the models by starting from a configuration $\\pmb{x}_{0}^{(0)}$ and passing it through the machines along the training trajectory, each time performing k\u02dc mcmc steps. For pre-train $\\mathsf{1+P C D}$ , $\\pmb{x}_{0}^{(0)}$ is a sampling from the RCM, otherwise it is a uniform random initialization. The sampling consists of alternating one mcmc step for each model with a swap attempt between adjacent machines. For pre-train+PCD, at each step we sample a new independent configuration for $\\mathrm{RBM_{0}}$ using the RCM. "], "img_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "TEwQSWWn7S/tmp/584e79b009fda848af9ff57f4706a0bd6114133189c6e680a8157809c49fcbcf.jpg", "table_caption": [], "table_footnote": ["Table 1: Performance comparison of different models on various datasets for the sampling using PTT versus Gibbs sampling for $10^{4}$ mcmc steps. The acceleration factor is defined as the ratio of the average number of jumps obtained until $\\mathrm{10^{4}}$ steps between PTT and Gibbs sampling. For pre-train+PCD, the RCM machine has not to be counted among the list of models (hence the $+1$ ) because it is very fast to sample from. "], "page_idx": 14}, {"type": "text", "text": "487 B Sampling via Parallel Tempering using the learning trajectory ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "488 Assuming we have successfully trained a robust equilibrium model, there remains the challenge of   \n489 efficiently generating equilibrium configurations from this model. Although models trained at equi  \n490 librium exhibit faster and more ergodic dynamics compared to poorly trained models, the sampling   \n491 time can still be excessively long when navigating a highly rugged data landscape. Consequently,   \n492 we devised a novel method for sampling equilibrium configurations that draws inspiration from   \n493 the well-established parallel tempering approach. In this traditional method, multiple simulations   \n494 are conducted in parallel at various temperatures, and configurations are exchanged among them   \n495 using the Metropolis rule. Unlike this conventional technique, our method involves simultaneously   \n496 simulating different models that are selected from various points along the training trajectory. This   \n497 approach is motivated by the perspective that learning represents an annealing process for the model,   \n498 encountering second-order type phase transitions during training. In contrast, annealing related to   \n499 temperature changes involves first-order phase transitions, making traditional parallel tempering less   \n500 effective for sampling from clustered multimodal distributions.   \n501 A sketch of the Parallel Trajectory Tempering (PTT) is represented in fig. 6. Specifically, we save   \n502 $t_{\\mathrm{f}}$ models at checkpoints $t=1,\\ldots,t_{\\mathrm{f}}$ along the training trajectory. We denote the Hamiltonian of   \n503 the model at checkpoint $t$ as $\\mathcal{H}_{t}$ , and refer to the Hamiltonian of the RCM model as $\\mathcal{H}_{0}$ . We define   \n504 GibbsSampling $(\\mathcal{H},x,k)$ as the operation of performing $k$ Gibbs sampling updates using the model   \n505 $\\mathcal{H}$ starting from the state $\\textbf{\\em x}$ . In all our sampling simulations we used $k=1$ .   \n506 The first step is to initialize the models\u2019 configurations efficiently. This involves sampling $N$   \n507 chains from the RCM model, $x_{0}^{(0)}\\sim\\mathrm{RCMSampling}(\\mathcal{H}^{0})$ , and then passing the chains through   \n508 all the models from $t\\ =\\ 1$ to $\\mathrm{~\\textit~{~t~}~}=\\mathrm{~\\it~t_{\\mathrm{f}}~}$ , performing $k$ Gibbs steps at each stage: $x_{t}^{(0)}~\\sim$   \n509 GibbsSampling $(\\mathcal{H}_{t},\\pmb{x}_{t-1}^{(0)},k)$ .   \n510 The sampling process proceeds in steps where we update the configuration of each model except $\\mathcal{H}_{0}$   \n511 with $k$ Gibbs steps, and sample a completely new configuration for the RCM model $\\mathcal{H}_{0}$ . Following   \n512 this update step, we propose swapping chains between adjacent models with an acceptance probability   \n513 given by: ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "equation", "text": "$$\np_{\\mathrm{acc}}(\\pmb{x}_{t}\\leftrightarrow\\pmb{x}_{t-1})=\\mathrm{min}\\left(1,\\exp\\left(\\Delta\\mathcal{H}_{t}(\\pmb{x}_{t})-\\Delta\\mathcal{H}_{t}(\\pmb{x}_{t-1})\\right)\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "514 where $\\begin{array}{r}{\\Delta\\mathcal{H}_{t}(\\pmb{x})=\\mathcal{H}_{t}(\\pmb{x})-\\mathcal{H}_{t-1}(\\pmb{x}).}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "515 We continue alternating between the update step and the swap step until a total of $N_{\\mathrm{mcmc}}$ steps is   \n516 reached. The sampling procedure is illustrated in the following pseudo-code:   \n517 Input: Set of models $\\{\\mathcal{H}_{t}\\}$ , $t=0,\\ldots,t_{\\mathrm{f}}$ , Number of Gibbs steps $k$ , Number of MCMC steps   \n518 Nmcmc   \n519 Output: Configurations $\\pmb{x}_{t}$ for $t=1,\\ldots,t_{\\mathrm{f}}$   \n520 Initialize: Sample $N$ chains from the RCM model $\\pmb{x}_{0}^{(0)}\\sim\\mathrm{RCMSampling}(\\mathcal{H}_{0})$   \n521 for to $t_{\\mathrm{f}}$ do   \n522 $\\pmb{x}_{t}^{(0)}\\sim\\mathrm{GibbsSampling}(\\mathcal{H}_{t},\\pmb{x}_{t-1}^{(0)},\\tilde{\\pmb{k}})$   \n523 end for   \n524 for $n=1$ to $\\lfloor N_{\\mathrm{mcmc}}/k\\rfloor$ do   \n552265 for $t=1$ $\\pmb{x}_{t}^{(n)}\\sim\\mathrm{GibbsSampling}(\\mathcal{H}_{t},\\pmb{x}_{t}^{(n-1)},\\pmb{k})$ $t_{\\mathrm{f}}$   \n527 end for   \n528 Resample x(0n)\u223cRCMSampling(H0)   \n529 for $t=1$ to $t_{\\mathrm{f}}$ do   \n530 Compute acceptance probability   \n$p_{\\mathrm{acc}}(\\pmb{x}_{t}^{(n)}\\leftrightarrow\\pmb{x}_{t-1}^{(n)})=\\operatorname*{min}\\left(1,\\exp\\left(\\Delta\\mathcal{H}_{t}(\\pmb{x}_{t}^{(n)})-\\Delta\\mathcal{H}_{t}(\\pmb{x}_{t-1}^{(n)})\\right)\\right)$   \n531 Swap xt $\\pmb{x}_{t}^{(n)}$ and $\\pmb{x}_{t-1}^{(n)}$ with probability $p_{\\mathrm{acc}}(\\mathbf{\\boldsymbol{x}}_{t}^{(n)}\\leftrightarrow\\mathbf{\\boldsymbol{x}}_{t-1}^{(n)})$ )   \n532 end for   \n533 end for ", "page_idx": 15}, {"type": "text", "text": "534 A comparison of performances between PTT and standard Gibbs sampling is reported in Tab. 1. ", "page_idx": 15}, {"type": "text", "text": "535 C Training details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "536 We describe in Tables 2 and 3 the datasets and hyperparameters used during training. The test set was used to evaluate the metrics. All experiments were run on a RTX 4090 with an AMD Ryzen 9 ", "page_idx": 15}, {"type": "table", "img_path": "TEwQSWWn7S/tmp/6d210d692cb9fddea06d926396bf6b700869cc0520dc11b664d36b76c8b82d9b.jpg", "table_caption": ["Table 2: Details of the datasets used during training. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "537   \n538 5950X. ", "page_idx": 15}, {"type": "text", "text": "539 D Training of the RBM using the Jarzynski equation ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "540 In this section, we describe a procedure similar to the one introduced in [37] for training the RBM   \n541 by leveraging the Jarzynki equation. In one of its formulations, the Jarzynski equation states that   \n542 we can relate the ensemble average of an observable $\\scriptscriptstyle\\mathcal{O}$ with the average obtained through many ", "page_idx": 15}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/e2d1e8e9358c7747c9a0f12440528a3aa4cf3381e5a3b837563cdda6bb302d8c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 7: Comparison between PTT and standard Gibbs Sampling for RBMs trained using PCD (A and B) and JarRBM (C and D) on the MNIST01 dataset. A and C show the sampling trajectory of two chains recorded every 10 steps for a total of $10^{4}$ mcmc steps. B and D show the average number of jumps of a population of 100 chains as a function of the sampling time. ", "page_idx": 16}, {"type": "image", "img_path": "TEwQSWWn7S/tmp/e9880d759d8a2e27a89cc3ee9d6ca0653431966628e5b1c434ba05ffba2a4f40.jpg", "img_caption": ["Figure 8: Comparison between PTT and standard Gibbs Sampling for RBMs trained using PCD on the Human Genome dataset. The sampling has been performed under the same conditions of fig. 7. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "543 repetitions of an out-of-equilibrium dynamical process. If we consider the training trajectory of an   \n544 RBM, $p_{0}\\rightarrow p_{1}\\rightarrow\\cdot\\cdot\\cdot\\rightarrow p_{t-1}\\rightarrow p_{t}$ , we can write ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\langle\\mathcal{O}\\rangle_{t}=\\frac{\\left\\langle\\mathcal{O}e^{-W_{t}}\\right\\rangle_{\\mathrm{traj}}}{\\left\\langle e^{-W_{t}}\\right\\rangle_{\\mathrm{traj}}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "545 where the average on the lhs is done over the last model $p_{t}$ , the averages on the rhs are taken   \n546 across many different trajectory realizations and $W_{t}$ is a trajectory-dependent importance factor. By   \n547 all practical means, under the assumption of having quasi-adiabatic parameters updates, namely   \n548 $p(\\ensuremath{\\vec{\\Theta}}_{t-1}\\,\\rightarrow\\,\\Theta_{t})\\,=\\,p(\\Theta_{t}\\,\\rightarrow\\,\\Theta_{t-1})$ , this means that we can assign to each Markov chain of the   \n549 simulation $\\pmb{x}^{(r)}$ , $r=1,\\ldots,R$ , an importance weight given by: ", "page_idx": 16}, {"type": "equation", "text": "$$\nW_{t}^{(r)}=\\sum_{\\tau=1}^{t}[\\mathcal{H}_{\\tau}(\\pmb{x}_{\\tau-1}^{(r)})-\\mathcal{H}_{\\tau-1}(\\pmb{x}_{\\tau-1}^{(r)})]\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "550 and then compute the gradient of the log-likelihood by means of a weighted average over the chains: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\langle\\mathcal{O}\\rangle_{t}\\simeq\\frac{\\sum_{r=1}^{R}\\mathcal{O}(\\pmb{x}^{(r)})\\ e^{-W_{t}^{(r)}}}{\\sum_{r=1}^{R}e^{-W_{t}^{(r)}}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "table", "img_path": "TEwQSWWn7S/tmp/b062e550172e2329d7d09eae02a387ae55d9ec9ffbd2d6d1d847e423d7cf9b60.jpg", "table_caption": ["Table 3: Hyperparameters used for the training of RBMs. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "551 Notice that, since Eq. (27) is an exact result, the importance weights should, in principle, eliminate   \n552 the bias brought by the non-convergent chains used for approximating the log-likelihood gradient in   \n553 the classical PCD scheme. However, after many updates of the importance weights, one finds that   \n554 only a few chains carry almost all the importance mass. In other words, the vast majority of the chains   \n555 we are simulating are statistically irrelevant, and we expect to get large fluctuations in the estimate of   \n556 the gradient because of the small effective number of chains contributing to the statistical average. A   \n557 good observable for monitoring this effect is the Effective Sample Size (ESS), defined as [37] ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{ESS}=\\frac{\\left(R^{-1}\\sum_{r=1}^{R}e^{-W^{(r)}}\\right)^{2}}{R^{-1}\\sum_{r=1}^{R}e^{-2W^{(r)}}}\\in[0,1],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "558 which measures the relative dispersion of the weights distribution. A way of circumventing the weight   \n559 concentration on a few chains, then, is to resample the chain population according to the importance   \n560 weights every time the ESS drops below a certain threshold, for instance 0.5. After this resampling,   \n561 all the chain weights have to be set to 1 $(W^{(r)}=0\\;\\forall r=1,\\ldots,R)$ . ", "page_idx": 17}, {"type": "text", "text": "562 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "563 The checklist is designed to encourage best practices for responsible machine learning research,   \n564 addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove   \n565 the checklist: The papers not including the checklist will be desk rejected. The checklist should   \n566 follow the references and precede the (optional) supplemental material. The checklist does NOT   \n567 count towards the page limit.   \n568 Please read the checklist guidelines carefully for information on how to answer these questions. For   \n569 each question in the checklist:   \n570 \u2022 You should answer [Yes] , [No] , or [NA] .   \n571 \u2022 [NA] means either that the question is Not Applicable for that particular paper or the   \n572 relevant information is Not Available.   \n573 \u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA).   \n574 The checklist answers are an integral part of your paper submission. They are visible to the   \n575 reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it   \n576 (after eventual revisions) with the final version of your paper, and its final version will be published   \n577 with the paper.   \n578 The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.   \n579 While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a   \n580 proper justification is given (e.g., \"error bars are not reported because it would be too computationally   \n581 expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering   \n582 \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we   \n583 acknowledge that the true answer is often more nuanced, so please just use your best judgment and   \n584 write a justification to elaborate. All supporting evidence can appear either in the main paper or the   \n585 supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification   \n586 please point to the section(s) where related material for the question can be found.   \n587 1. Claims   \n588 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n589 paper\u2019s contributions and scope?   \n590 Answer: [Yes]   \n591 Justification:   \n592 Guidelines:   \n593 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n594 made in the paper.   \n595 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n596 contributions made in the paper and important assumptions and limitations. A No or   \n597 NA answer to this question will not be perceived well by the reviewers.   \n598 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n599 much the results can be expected to generalize to other settings.   \n600 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n601 are not attained by the paper.   \n602 2. Limitations   \n603 Question: Does the paper discuss the limitations of the work performed by the authors?   \n604 Answer: [Yes]   \n605 Justification:   \n606 Guidelines:   \n607 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n608 the paper has limitations, but those are not discussed in the paper.   \n609 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "634 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n635 a complete (and correct) proof?   \n636 Answer: [NA]   \n637 Justification:   \n638 Guidelines:   \n639 \u2022 The answer NA means that the paper does not include theoretical results.   \n640 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n641 referenced.   \n642 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n643 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n644 they appear in the supplemental material, the authors are encouraged to provide a short   \n645 proof sketch to provide intuition.   \n646 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n647 by formal proofs provided in appendix or supplemental material.   \n648 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced.   \n649 4. Experimental Result Reproducibility   \n650 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n651 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n652 of the paper (regardless of whether the code and data are provided or not)?   \n653 Answer: [Yes]   \n654 Justification:   \n655 Guidelines:   \n656 \u2022 The answer NA means that the paper does not include experiments.   \n657 \u2022 If the paper includes experiments, a No answer to this question will not be perceived   \n658 well by the reviewers: Making the paper reproducible is important, regardless of   \n659 whether the code and data are provided or not.   \n660 \u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken   \n661 to make their results reproducible or verifiable.   \n62 \u2022 Depending on the contribution, reproducibility can be accomplished in various ways.   \n63 For example, if the contribution is a novel architecture, describing the architecture fully   \n64 might suffice, or if the contribution is a specific model and empirical evaluation, it may   \n65 be necessary to either make it possible for others to replicate the model with the same   \n66 dataset, or provide access to the model. In general. releasing code and data is often   \n67 one good way to accomplish this, but reproducibility can also be provided via detailed   \n68 instructions for how to replicate the results, access to a hosted model (e.g., in the case   \n69 of a large language model), releasing of a model checkpoint, or other means that are   \n70 appropriate to the research performed.   \n71 \u2022 While NeurIPS does not require releasing code, the conference does require all submis  \n72 sions to provide some reasonable avenue for reproducibility, which may depend on the   \n73 nature of the contribution. For example   \n74 (a) If the contribution is primarily a new algorithm, the paper should make it clear how   \n75 to reproduce that algorithm.   \n76 (b) If the contribution is primarily a new model architecture, the paper should describe   \n77 the architecture clearly and fully.   \n78 (c) If the contribution is a new model (e.g., a large language model), then there should   \n79 either be a way to access this model for reproducing the results or a way to reproduce   \n80 the model (e.g., with an open-source dataset or instructions for how to construct   \n81 the dataset).   \n82 (d) We recognize that reproducibility may be tricky in some cases, in which case   \n83 authors are welcome to describe the particular way they provide for reproducibility.   \n84 In the case of closed-source models, it may be that access to the model is limited in   \n85 some way (e.g., to registered users), but it should be possible for other researchers   \n86 to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "713 6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "714 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n715 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n716 results?   \n717 Answer: [Yes]   \n718 Justification:   \n719 Guidelines:   \n720 \u2022 The answer NA means that the paper does not include experiments.   \n721 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n722 that is necessary to appreciate the results and make sense of them.   \n723 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n724 material.   \n725 7. Experiment Statistical Significance   \n726 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n727 information about the statistical significance of the experiments?   \n728 Answer: [No]   \n729 Justification:   \n730 Guidelines:   \n731 \u2022 The answer NA means that the paper does not include experiments.   \n732 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n733 dence intervals, or statistical significance tests, at least for the experiments that support   \n734 the main claims of the paper.   \n735 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n736 example, train/test split, initialization, random drawing of some parameter, or overall   \n737 run with given experimental conditions).   \n738 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n739 call to a library function, bootstrap, etc.)   \n740 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n741 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n742 of the mean.   \n743 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n744 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n745 of Normality of errors is not verified.   \n746 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n747 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n748 error rates).   \n749 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n750 they were calculated and reference the corresponding figures or tables in the text.   \n751 8. Experiments Compute Resources   \n752 Question: For each experiment, does the paper provide sufficient information on the com  \n753 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n754 the experiments?   \n755 Answer: [Yes]   \n756 Justification:   \n757 Guidelines:   \n758 \u2022 The answer NA means that the paper does not include experiments.   \n759 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n760 or cloud provider, including relevant memory and storage.   \n761 \u2022 The paper should provide the amount of compute required for each of the individual   \n762 experimental runs as well as estimate the total compute.   \n763 \u2022 The paper should disclose whether the full research project required more compute   \n764 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n765 didn\u2019t make it into the paper).   \n766 9. Code Of Ethics   \n767 Question: Does the research conducted in the paper conform, in every respect, with the   \n768 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n769 Answer: [Yes]   \n770 Justification:   \n771 Guidelines:   \n772 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n773 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n774 deviation from the Code of Ethics.   \n775 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n776 eration due to laws or regulations in their jurisdiction).   \n777 10. Broader Impacts   \n778 Question: Does the paper discuss both potential positive societal impacts and negative   \n779 societal impacts of the work performed?   \n780 Answer: [NA]   \n781 Justification:   \n782 Guidelines:   \n783 \u2022 The answer NA means that there is no societal impact of the work performed.   \n784 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n785 impact or why the paper does not address societal impact.   \n786 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n787 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n788 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n789 groups), privacy considerations, and security considerations.   \n790 \u2022 The conference expects that many papers will be foundational research and not tied   \n791 to particular applications, let alone deployments. However, if there is a direct path to   \n792 any negative applications, the authors should point it out. For example, it is legitimate   \n793 to point out that an improvement in the quality of generative models could be used to   \n794 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n795 that a generic algorithm for optimizing neural networks could enable people to train   \n796 models that generate Deepfakes faster.   \n797 \u2022 The authors should consider possible harms that could arise when the technology is   \n798 being used as intended and functioning correctly, harms that could arise when the   \n799 technology is being used as intended but gives incorrect results, and harms following   \n800 from (intentional or unintentional) misuse of the technology.   \n801 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n802 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n803 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n804 feedback over time, improving the efficiency and accessibility of ML).   \n805 11. Safeguards   \n806 Question: Does the paper describe safeguards that have been put in place for responsible   \n807 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n808 image generators, or scraped datasets)?   \n809 Answer: [NA]   \n810 Justification:   \n811 Guidelines:   \n812 \u2022 The answer NA means that the paper poses no such risks.   \n813 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n814 necessary safeguards to allow for controlled use of the model, for example by requiring   \n815 that users adhere to usage guidelines or restrictions to access the model or implementing   \n816 safety filters.   \n817 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n818 should describe how they avoided releasing unsafe images. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "822 12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "23 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n24 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n25 properly respected?   \n26 Answer: [NA]   \n27 Justification:   \n28 Guidelines:   \n29 \u2022 The answer NA means that the paper does not use existing assets.   \n30 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n31 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n32 URL.   \n33 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n34 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n35 service of that source should be provided.   \n36 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n37 package should be provided. For popular datasets, paperswithcode.com/datasets   \n38 has curated licenses for some datasets. Their licensing guide can help determine the   \n39 license of a dataset.   \n40 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n41 the derived asset (if it has changed) should be provided.   \n42 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n43 the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "858 14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "859 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n860 include the full text of instructions given to participants and screenshots, if applicable, as   \n861 well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No]   \nJustification:   \nGuidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. ", "page_idx": 23}, {"type": "text", "text": "\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, ", "page_idx": 24}, {"type": "text", "text": "71 or other labor should be paid at least the minimum wage in the country of the data   \n72 collector.   \n73 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n74 Subjects   \n75 Question: Does the paper describe potential risks incurred by study participants, whether   \n76 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n77 approvals (or an equivalent approval/review based on the requirements of your country or   \n78 institution) were obtained?   \n79 Answer: [NA]   \n80 Justification:   \n81 Guidelines:   \n82 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n83 human subjects.   \n84 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n85 may be required for any human subjects research. If you obtained IRB approval, you   \n86 should clearly state this in the paper.   \n87 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n88 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n89 guidelines for their institution.   \n90 \u2022 For initial submissions, do not include any information that would break anonymity (if   \n91 applicable), such as the institution conducting the review. ", "page_idx": 24}]