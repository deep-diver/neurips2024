[{"figure_path": "w50ICQC6QJ/tables/tables_3_1.jpg", "caption": "Table 3: Causal relation extraction results in AppleGastronome.", "description": "This table presents the quantitative results of causal relation extraction in the AppleGastronome benchmark.  For various LLMs (GPT-4, GPT-3.5, Mistral-Large, etc.), it shows the performance of both direct LLM reasoning (PAIRWISE) and the COAT framework (COAT). The metrics used are Structural Hamming Distance (SHD), Structural Intervention Distance (SID), and the F1 score for pairwise causal relation accuracy.  Lower SHD and SID values indicate better performance.  Higher F1 scores indicate better accuracy in identifying the causal relationships.", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/tables/tables_7_1.jpg", "caption": "Table 5: Full Results on the Apple Gastronome Benchmark.", "description": "This table presents the complete results of the AppleGastronome benchmark, showing the performance of different methods (META, DATA, DATA+COT, and COAT) across various LLMs.  The metrics used are MB (number of factors in the Markov blanket), NMB (number of undesired factors in the Markov blanket), OT (number of other unexpected factors), Recall, Precision, and F1-score.  This provides a comprehensive comparison of the effectiveness of each approach in identifying relevant factors for predicting apple ratings.", "section": "3 Empirical Analysis of COAT"}, {"figure_path": "w50ICQC6QJ/tables/tables_8_1.jpg", "caption": "Table 7: Causal discovery results in Neuropathic. PA, AN, and OT refer to the parents, ancestors, and others, respectively. Accuracy and F1 measure the recovery of the causal ancestors.", "description": "This table presents the results of causal discovery experiments on the Neuropathic dataset using different methods and LLMs.  It compares the performance of different methods (META, DATA, DATA+COT, COAT) in identifying causal parents (PA), ancestors (AN), and other variables (OT) related to the target variable (right shoulder impingement). The accuracy and F1-score metrics evaluate the effectiveness of each method in recovering the causal ancestors.  The table shows that COAT generally outperforms the baselines in recovering the causal ancestors. ", "section": "COAT with Different Causal Discovery Algorithm"}, {"figure_path": "w50ICQC6QJ/tables/tables_19_1.jpg", "caption": "Table 3: Causal relation extraction results in AppleGastronome.", "description": "This table presents the results of causal relation extraction experiments conducted on the AppleGastronome dataset using various LLMs and methods.  The metrics used include Structural Hamming Distance (SHD), Structural Intervention Distance (SID), recall, precision and F1 score for pairwise causal relation extraction.  The table shows that COAT generally outperforms the baseline of using LLMs directly for causal reasoning, indicating improved performance in uncovering causal relationships within the dataset. ", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/tables/tables_24_1.jpg", "caption": "Table 3: Causal relation extraction results in AppleGastronome.", "description": "This table presents the results of causal relation extraction experiments conducted on the AppleGastronome dataset using different LLMs and methods (PAIRWISE and COAT).  It shows the performance metrics for each LLM and method including Structural Hamming Distance (SHD), Structural Intervention Distance (SID), Recall, Precision, and F1-score.  The results highlight the effectiveness of the COAT framework in achieving higher accuracy and F1 scores in uncovering causal relationships compared to directly using LLMs (PAIRWISE).", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/tables/tables_24_2.jpg", "caption": "Table 4: Independence tests of the annotation noises with annotated features and other noises in AppleGastronome.", "description": "This table presents the results of independence tests performed to assess whether the annotation noises are independent from the annotated features and other noise sources within the AppleGastronome dataset.  The tests are likely used to evaluate the quality and reliability of the LLM-based annotations. The p-values indicate the statistical significance of the relationships.", "section": "E More Details about Experiments"}, {"figure_path": "w50ICQC6QJ/tables/tables_28_1.jpg", "caption": "Table 5: Full Results on the Apple Gastronome Benchmark.", "description": "This table presents the complete results of the Apple Gastronome benchmark experiment.  For various LLMs (GPT-4, GPT-3.5, Mistral-Large, Mistral-Medium, LLAMA-3-70B, LLAMA-2-70B, Qwen-1.5-110B, DeepSeek-V2, Claude-3-Opus), it shows the performance of different methods: META (zero-shot factor proposal), DATA (factor proposal given context), DATA+COT (one round of COAT), and COAT (multiple rounds of COAT with feedback). The results are presented as mean \u00b1 standard deviation across multiple runs for each metric: MB (number of Markov Blanket factors), NMB (number of non-Markov Blanket factors), OT (number of other factors), Recall, Precision, and F1-score.", "section": "3 Empirical Analysis of COAT"}, {"figure_path": "w50ICQC6QJ/tables/tables_29_1.jpg", "caption": "Table 6: Full Result of Causal Metrics each Round each LLM on Apple Gastronome Benchmark", "description": "This table presents a comprehensive evaluation of the causal discovery performance of various Large Language Models (LLMs) across multiple rounds of the COAT framework.  For each LLM, the table shows the perception score, capacity score, and mutual information I(y;x|hs) for each iteration (round). The perception score reflects the LLM's ability to propose valid causal factors, the capacity score measures the reduction in uncertainty about the target variable given the identified factors, and the mutual information quantifies the remaining uncertainty.", "section": "E More Details about Experiments"}, {"figure_path": "w50ICQC6QJ/tables/tables_39_1.jpg", "caption": "Table 7: Causal discovery results in Neuropathic. PA, AN, and OT refer to the parents, ancestors, and others, respectively. Accuracy and F1 measure the recovery of the causal ancestors.", "description": "This table presents the results of causal discovery experiments using different causal discovery methods (including FCI and LiNGAM) in the Neuropathic dataset. It compares the performance of various methods in terms of accurately identifying parents (PA), ancestors (AN), and other variables (OT) related to the target variable (right shoulder impingement). The accuracy and F1-score metrics evaluate the effectiveness of the methods in recovering the causal ancestors.", "section": "COAT with Different Causal Discovery Algorithm"}, {"figure_path": "w50ICQC6QJ/tables/tables_39_2.jpg", "caption": "Table 8: Results about Ablation Study on Hyperparameters.", "description": "This ablation study investigates the impact of modifying two hyperparameters in COAT, specifically the number of clusters used in the feedback mechanism and the size of the groups in the prompt.  The results demonstrate that COAT's performance is robust to these changes in hyperparameters, consistently outperforming baseline methods.", "section": "G Ablation Study"}, {"figure_path": "w50ICQC6QJ/tables/tables_40_1.jpg", "caption": "Table 9: COAT with changed prompt template", "description": "This table presents the ablation study results on the prompt template of COAT. Three different LLMs (GPT-4, GPT-3.5-TURBO, and Mistral-Medium) were evaluated using a modified prompt template. The results show the number of Markov blanket factors (MB), non-Markov blanket factors (NMB), and other factors (OT) identified by COAT, along with recall, precision, and F1 score. The results demonstrate the robustness of COAT to the choice of prompt templates.", "section": "G Ablation Study"}, {"figure_path": "w50ICQC6QJ/tables/tables_42_1.jpg", "caption": "Table 10: Summary of Benchmark Data", "description": "This table summarizes the benchmark datasets used in the paper. For each dataset, it provides the type (synthetic or real-world), the source, the sample type (textual, image, or NetCDF), the sample size, and whether the ground truth is available.", "section": "H Summary of Benchmark Data"}, {"figure_path": "w50ICQC6QJ/tables/tables_47_1.jpg", "caption": "Table 11: Performance about trading strategy according to each factors", "description": "This table presents the performance evaluation of different trading strategies based on the factors identified by COAT in the Stock News case study.  It shows key metrics for each factor (Buy and Hold, Product Focus, Legal/Regulatory Issues, Market Strategy, Innovation and Technology Focus), including Expected Return, Sharpe Ratio, T-Stat, Information Ratio, alpha, alpha T-stat, Max Loss, and Skew. These metrics provide a quantitative comparison of the risk-adjusted returns and overall performance of each factor's trading strategy. The Innovation and Technology focus shows significantly higher returns and better risk-adjusted performance compared to other factors.", "section": "J.2 Result and Discussion"}]