[{"figure_path": "w50ICQC6QJ/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's three stages: factor proposal, factor annotation, and causal discovery & feedback construction.  In the factor proposal stage, an LLM (Large Language Model) proposes high-level factors (like size and aroma) relevant to apple ratings.  These factors, along with annotation guidelines, are then used by another LLM in the factor annotation stage to structure the unstructured user reviews into a usable format.  Finally, the causal discovery and feedback construction stage uses causal discovery (CD) algorithms to identify causal relationships between the proposed factors and the ratings.  The system iteratively refines the proposed factors using feedback from the CD algorithm, improving the accuracy of the causal relationships discovered.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs to identify high-level factors influencing apple ratings from unstructured reviews, then uses a causal discovery (CD) algorithm to find relationships between factors.  A feedback loop refines the process iteratively. The three stages are shown: (a) factor proposal by LLM, (b) factor annotation by LLM, and (c) causal discovery and feedback construction by the CD algorithm, enabling the LLM to improve factor identification.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of variables that could be discovered with COAT. Let W \u2208 h<t(X) be an identified variable, and assume there exists a latent variable w to be discovered. When w is the direct parent or child of Y, finding hard-to-explain samples can help uncover it. When w is the direct parent and also a child of W, or the spouse of Y with W as the common child of Y and w, conditioning on W facilitates the discovery of w.", "description": "This figure illustrates how COAT discovers latent variables using feedback from causal discovery.  It shows four scenarios involving a target variable Y, an identified variable W, and a latent variable w. The scenarios illustrate how finding samples that are not well-explained by the current model (Y | X | h<t(X)) can help uncover latent causal relationships, particularly when w is a parent or child of Y, or when there are confounding relationships between W and w. ", "section": "2.3 Causal Feedback"}, {"figure_path": "w50ICQC6QJ/figures/figures_6_1.jpg", "caption": "Figure 4: Quantitative evaluation of the causal capabilities of LLMs in COAT.", "description": "This figure quantitatively evaluates the causal capabilities of various Large Language Models (LLMs) within the COAT framework.  It presents three subfigures. (a) shows the accuracy of Apple attributes prediction, comparing different LLMs and a random baseline. (b) displays the accuracy of preference matching, again comparing LLMs and a random baseline. (c) provides a scatter plot illustrating the relationship between the 'perception score' and 'capacity score' of each LLM, offering a visualization of their overall causal reasoning abilities within the COAT system.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_7_1.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares causal graphs generated by different methods for analyzing apple ratings.  The \"ground truth\" shows the actual relationships between factors influencing the ratings.  The \"GPT-4 META\" graph shows the causal relationships identified by simply using a large language model (LLM). The \"GPT-3.5 COAT\" and \"Claude-3-Opus COAT\" graphs depict the results obtained using the Causal representation AssistanT (COAT) framework.  COAT demonstrates improved accuracy and recall in identifying the true causal relationships, suggesting that the LLM-assisted approach is more effective than using LLMs alone.", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/figures/figures_8_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings. It highlights three stages:\n1. **Factor Proposal (a):** An LLM analyzes reviews to suggest high-level factors influencing the ratings (e.g., size, smell).\n2. **Factor Annotation (b):** Another LLM annotates the reviews based on the proposed factors.\n3. **Causal Discovery & Feedback (c):** A causal discovery algorithm identifies causal relationships between the factors. Feedback is constructed from samples unexplained by current factors, iteratively refining the process.  The goal is to uncover the Markov Blanket (a set of factors that explains the target variable - score)", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_9_1.jpg", "caption": "Figure 7: The final causal graph found by COAT in the ENSO case study", "description": "This figure shows a causal graph of climate factors related to ENSO (El Ni\u00f1o-Southern Oscillation). The graph illustrates the relationships between various factors like air temperature, cloud cover, soil moisture, sea level pressure, and wind components, and how they influence the change in sea surface temperature (SST) in the Nino3 region, a key indicator of ENSO events.  The nodes are categorized into three regions: Equatorial Pacific Region, Nino3 Region, and South American Coastal Region.  Different node shapes indicate whether the factor is stationary (circle) or non-stationary (diamond).", "section": "4.3 More Real-world Results"}, {"figure_path": "w50ICQC6QJ/figures/figures_20_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework. COAT uses LLMs (Large Language Models) and causal discovery algorithms to identify the factors influencing a target variable (apple ratings in this example). The process involves three steps:\n\n(a) **Factor Proposal:** LLMs analyze reviews to propose high-level factors.\n(b) **Factor Annotation:** LLMs annotate the unstructured reviews according to the defined factors.\n(c) **Causal Discovery & Feedback:** A causal discovery algorithm identifies causal relations between factors.  If the ratings aren't well-explained by existing factors, feedback is generated to refine the proposed factors iteratively. This iterative process refines the causal model and factor identification.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_25_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to identify high-level factors influencing a target variable (apple ratings in this example). The LLMs propose factors, annotate data according to those factors, and then a causal discovery (CD) algorithm identifies causal relationships.  The CD algorithm also provides feedback to the LLMs, which iteratively refines the proposed factors and helps discover more relevant causal relationships.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_25_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors. We show that LLMs and CDs are mutually beneficial and the constructed feedback provably also helps with the factor proposal.", "description": "The figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to identify high-level factors relevant to a target variable (in this case, apple ratings). The LLMs propose potential factors, then annotate unstructured data (reviews) to create structured data, and finally, a causal discovery algorithm identifies causal relations between the factors.  The process iteratively refines the factors through feedback between the LLMs and causal discovery.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_26_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  It shows a three-stage process: 1. **Factor Proposal:** An LLM analyzes unstructured data (e.g., apple reviews) to suggest high-level factors relevant to the target variable (apple rating). 2. **Factor Annotation:** Another LLM annotates the data according to the proposed factors, converting unstructured text into structured data. 3. **Causal Discovery & Feedback:** A causal discovery algorithm identifies causal relationships between factors, and any unexplained ratings provide feedback to the LLM, iteratively refining the factor selection and annotation until a satisfactory Markov blanket is found. The feedback loop between the LLMs and the causal discovery algorithm is central to COAT's iterative refinement.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_26_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's three main steps: factor proposal, factor annotation, and causal discovery & feedback construction.  It uses the example of AppleGastronome ratings to show how LLMs are used to propose and annotate high-level factors from unstructured reviews, which are then used by causal discovery algorithms to find causal relationships.  The process is iterative, with feedback from the causal discovery step used to refine the factor proposals. This iterative process helps to uncover the underlying causal mechanisms associated with the AppleGastronome ratings.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_27_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple rating scores.  It shows three stages: 1) Factor Proposal: LLMs process reviews to suggest high-level factors (like size or aroma) and annotation guidelines. 2) Factor Annotation: Another LLM annotates reviews based on the proposed factors. 3) Causal Discovery & Feedback: A causal discovery algorithm identifies causal relations among factors and uses unexplained ratings to provide feedback for iterative LLM refinement, aiming to discover the complete Markov blanket.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_29_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings.  It shows three stages: 1) Factor Proposal: Using an LLM to propose relevant factors (size, aroma) from unstructured reviews; 2) Factor Annotation: Another LLM structures the reviews based on these factors; 3) Causal Discovery & Feedback Construction: A causal discovery algorithm identifies causal relationships and provides feedback to the initial LLM, iteratively refining factor selection and uncovering the underlying causal structure.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_30_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings.  It showcases the three main stages: Factor Proposal (LLM suggests high-level factors from reviews), Factor Annotation (another LLM structures the unstructured reviews based on those factors), and Causal Discovery & Feedback Construction (a causal discovery algorithm identifies causal relationships and provides feedback to refine the LLM's factor proposals).  The iterative process aims to identify the complete Markov blanket for the target variable (apple rating) by leveraging the strengths of LLMs and causal discovery algorithms.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_31_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's three stages: 1. Factor Proposal: An LLM processes reviews to suggest high-level factors influencing apple ratings and annotation guidelines. 2. Factor Annotation: Another LLM annotates reviews based on proposed factors. 3. Causal Discovery & Feedback: A causal discovery (CD) algorithm identifies causal relationships; unexplained ratings trigger feedback to refine the LLM's factor proposals.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_31_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's three stages:  First, an LLM proposes high-level factors related to apple ratings (size, smell, etc.) from user reviews, including annotation guidelines. Second, another LLM annotates the unstructured reviews using these factors. Finally, a causal discovery (CD) algorithm identifies causal relationships between the factors, and feedback from unexplained ratings refines the factor selection process, iteratively improving accuracy.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_32_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings.  It demonstrates a three-step process: 1) Factor Proposal (LLM proposes high-level factors from unstructured reviews), 2) Factor Annotation (LLM structures the unstructured reviews based on proposed factors), and 3) Causal Discovery & Feedback Construction (Causal Discovery algorithms identify causal relationships, and feedback refines factor proposals iteratively).", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_32_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's three main steps: 1) Factor Proposal: An LLM analyzes user reviews to identify high-level factors influencing apple ratings. 2) Factor Annotation: Another LLM annotates the unstructured reviews based on the proposed factors. 3) Causal Discovery & Feedback Construction: A causal discovery (CD) algorithm identifies causal relationships between factors and provides feedback to the LLM to refine factor proposals iteratively.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_33_1.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares the causal graphs discovered by directly using LLMs and by using the COAT framework, against the ground truth.  The ground truth shows the correct causal relationships between factors like size, smell, taste, nutrition, juiciness and market potential that influence the apple rating scores.  The \"LLM reasoning\" graphs exhibit many false positive edges due to the limitations of directly using LLMs for causal inference. In contrast, COAT produces graphs that much more closely resemble the ground truth in terms of accuracy and recall, showing its effectiveness in uncovering accurate causal relationships. However, the limitations of the FCI algorithm used in COAT prevented it from recovering the direct causal relationship between \"taste\" and \"juiciness\".", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/figures/figures_33_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  It demonstrates how COAT leverages LLMs to address the challenge of limited high-quality variables in real-world causal discovery. COAT uses LLMs to propose high-level factors from unstructured data, annotate data according to those factors, and then employs a causal discovery algorithm to identify causal relationships. Finally, it uses the causal discovery results to provide feedback to the LLMs to iteratively refine the process and uncover more accurate causal factors.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_34_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to propose high-level factors from unstructured data (e.g., apple reviews), then annotates this data using another LLM, and finally employs a causal discovery (CD) algorithm to identify causal relationships between the factors and the target variable (apple rating score).  A feedback loop is incorporated to refine the factor proposals based on the CD algorithm's results, iteratively improving the model's accuracy.  The three steps are: (a) Factor Proposal, (b) Factor Annotation, (c) Causal Discovery & Feedback Construction.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_34_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to identify high-level factors relevant to a target variable (in this case, apple ratings).  The LLMs first propose potential factors, then annotate unstructured data (reviews) according to these factors.  A causal discovery (CD) algorithm identifies causal relationships between the factors. The CD algorithm provides feedback to refine the factors proposed by the LLMs. This iterative process helps COAT to progressively build a more accurate representation of the causal mechanisms underlying the ratings.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_35_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings.  It shows three stages: 1) Factor Proposal:  An LLM proposes high-level factors influencing the ratings based on unstructured reviews. 2) Factor Annotation: Another LLM annotates the reviews according to the proposed factors. 3) Causal Discovery & Feedback Construction: A causal discovery algorithm identifies causal relationships, and the results are used to refine the factors iteratively via feedback to the LLMs, leading to a refined Markov Blanket.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_36_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's three main steps for analyzing AppleGastronome ratings.  First, an LLM proposes candidate factors (e.g., size, smell) based on the reviews. Second, another LLM annotates the reviews according to these factors. Finally, a causal discovery (CD) algorithm identifies causal relationships between the factors and provides feedback to the LLM to refine factor selection.  This iterative process helps discover the Markov blanket (factors directly influencing the ratings).", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_37_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to identify high-level factors influencing a target variable (apple ratings in this example). The LLMs first propose candidate factors, then annotate data according to those factors. A causal discovery (CD) algorithm identifies causal relations, and any unexplained ratings provide feedback to refine the factors iteratively, improving the accuracy of the causal model.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_37_2.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares the causal graphs discovered by directly using LLMs versus using the COAT framework, which integrates LLMs with causal discovery algorithms.  The ground truth causal graph is shown alongside the results of two different methods. The key finding is that COAT, by iteratively refining factor proposals with feedback from causal discovery, yields significantly more accurate results. The limitations of the FCI (Fast Causal Inference) algorithm are highlighted in the discrepancies between the ground truth and COAT results.", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_1.jpg", "caption": "Figure 3: Illustration of variables that could be discovered with COAT. Let W \u2208 h<t(X) be an identified variable, and assume there exists a latent variable w to be discovered. When w is the direct parent or child of Y, finding hard-to-explain samples can help uncover it. When w is the direct parent and also a child of W, or the spouse of Y with W as the common child of Y and w, conditioning on W facilitates the discovery of w.", "description": "This figure illustrates how COAT can discover latent variables (represented by 'w') in a causal graph.  It shows three scenarios: 1) 'w' is a direct cause or effect of the target variable ('Y'); 2) 'w' is a parent of 'Y' and also a child of a known variable ('W'); and 3) 'w' is a spouse of 'Y', sharing a common child ('W'). COAT uses hard-to-explain samples to identify these latent variables.", "section": "2.3 Causal Feedback"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors. We show that LLMs and CDs are mutually beneficial and the constructed feedback provably also helps with the factor proposal.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework. It demonstrates how COAT uses LLMs (Large Language Models) to propose high-level factors from unstructured data (like customer reviews), then annotates this data using another LLM, and finally employs a causal discovery (CD) algorithm to identify causal relationships. The process iteratively refines factor proposals through feedback loops between the LLMs and CD algorithm.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_3.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's three main steps: factor proposal, factor annotation, and causal discovery & feedback construction.  It shows how LLMs are used to propose high-level factors from unstructured data (e.g., customer reviews), annotate this data to create structured features, and then how causal discovery algorithms are used to identify causal relationships.  The feedback loop between causal discovery and the LLM ensures iterative refinement of the proposed factors until a comprehensive understanding of the causal structure is reached.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_4.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple ratings.  It shows three main stages: 1) Factor Proposal: An LLM proposes high-level factors (e.g., size, smell) influencing the ratings from unstructured reviews. 2) Factor Annotation: Another LLM annotates the reviews according to the proposed factors. 3) Causal Discovery & Feedback Construction: A causal discovery (CD) algorithm identifies causal relationships between the factors, using the annotated data; feedback from the CD process refines the factor proposal iteratively.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_5.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to propose high-level factors from unstructured data (e.g., customer reviews) and then uses a causal discovery algorithm to find causal relationships between those factors.  The system iteratively refines the factor selection by providing feedback to the LLMs based on discrepancies between the causal model and the observed data. The three main stages are shown: factor proposal, factor annotation, and causal discovery & feedback.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_6.jpg", "caption": "Figure 3: Illustration of variables that could be discovered with COAT. Let W \u2208 h<t(X) be an identified variable, and assume there exists a latent variable w to be discovered. When w is the direct parent or child of Y, finding hard-to-explain samples can help uncover it. When w is the direct parent and also a child of W, or the spouse of Y with W as the common child of Y and w, conditioning on W facilitates the discovery of w.", "description": "This figure illustrates how COAT can discover latent variables using feedback from the causal discovery process. It shows different scenarios where discovering hard-to-explain samples aids in uncovering latent variables that are either direct causes or effects of the target variable Y or are indirectly related to it through another identified variable.", "section": "2.3 Causal Feedback"}, {"figure_path": "w50ICQC6QJ/figures/figures_38_7.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors.", "description": "The figure illustrates the COAT (Causal representation AssistanT) framework's three steps: factor proposal using LLMs (Large Language Models) based on unstructured data (e.g., customer reviews); factor annotation using LLMs to transform the unstructured data into structured data; causal discovery and feedback construction using causal discovery (CD) algorithms to identify causal relationships and provide feedback to LLMs to refine factors.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_41_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors.", "description": "This figure illustrates the COAT framework's three-step process: 1. Factor proposal using an LLM to extract high-level factors from unstructured reviews. 2. Factor annotation using another LLM to transform unstructured reviews into structured data based on the proposed factors. 3. Causal discovery and feedback construction, using a causal discovery algorithm to identify causal relations among the identified factors and provide feedback to the LLM for iterative refinement.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_41_2.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares causal graphs generated by different methods applied to AppleGastronome data.  The ground truth graph is shown alongside graphs produced by directly using LLMs (GPT-3.5 and GPT-4) for causal reasoning. It also shows the results of using the proposed COAT framework with these LLMs. The comparison highlights COAT's effectiveness in accurately identifying causal relationships, with higher precision and recall than direct LLM reasoning.  The limitations of the Fast Causal Inference (FCI) algorithm used in COAT are also noted.", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/figures/figures_41_3.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to propose high-level factors from unstructured data (like customer reviews of apples), annotates the data according to those factors, and then employs causal discovery (CD) algorithms to identify causal relationships between the factors.  A feedback loop allows the LLMs to iteratively refine factor proposals based on the results of the causal discovery.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_41_4.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares the causal graphs discovered by directly using LLMs and by using the COAT framework in the AppleGastronome benchmark.  The ground truth causal graph shows the expected relationships between different factors (size, aroma, taste, nutrition, juiciness, score, market potential). The graph generated by directly applying LLMs is noisy and has many false positive edges. In contrast, the COAT framework produces a more accurate causal graph with higher precision and recall.  However, the COAT framework, due to using FCI algorithm limitations, fails to capture all the relations present in the ground truth, missing the direct relationship between 'taste' and 'juiciness'.", "section": "Empirical Analysis of COAT"}, {"figure_path": "w50ICQC6QJ/figures/figures_41_5.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework for causal discovery using LLMs.  The process is shown in three stages:\n(a) Factor Proposal: An LLM reads unstructured reviews and proposes high-level factors (e.g., apple size, smell) relevant to the rating score.\n(b) Factor Annotation: Another LLM annotates the unstructured reviews according to the proposed factors.\n(c) Causal Discovery & Feedback Construction: A causal discovery (CD) algorithm identifies causal relations among the annotated factors.  The results are used to provide feedback to the LLM to iteratively refine factor proposals, improving the accuracy and completeness of causal discovery.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_43_1.jpg", "caption": "Figure 33: The initial input to COAT in the Brain Tumor case study. Each row contains 5 samples randomly selected from one category (top-down: glioma, meningioma, and no tumor).", "description": "This figure shows the input data used for the Brain Tumor case study.  The image data consists of MRI scans of the brain, divided into three categories: glioma, meningioma, and no tumor. Each row in the image contains 5 randomly selected examples from one of the three categories. This data is used as input to the COAT system for feature extraction and causal analysis.", "section": "I Case Study on Brain Tumor"}, {"figure_path": "w50ICQC6QJ/figures/figures_44_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  The framework uses LLMs (Large Language Models) to propose high-level factors from unstructured data (such as customer reviews of apples), annotate this data, and then employs a causal discovery (CD) algorithm to identify causal relationships among the factors.  A feedback loop is incorporated, where the CD algorithm's results inform the LLM to refine factor proposals in iterative steps.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_44_2.jpg", "caption": "Figure 35: Final causal graph by COAT in the Brain Tumor case study.", "description": "The figure shows the final causal graph obtained by the COAT algorithm for the brain tumor case study. The graph visually represents the causal relationships between factors related to tumor type. The nodes represent high-level factors such as contrast enhancement and mass effect, and the edges indicate the causal relationships between them. This graph is derived from the COAT algorithm\u2019s analysis of MRI images. The study aims to understand the causal relationships between different factors to assist in brain tumor diagnosis.", "section": "I Case Study on Brain Tumor"}, {"figure_path": "w50ICQC6QJ/figures/figures_45_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's workflow for analyzing apple ratings.  It shows three stages: 1. Factor Proposal (LLM proposes candidate factors like size and smell based on reviews), 2. Factor Annotation (another LLM structures the unstructured reviews based on the proposed factors), and 3. Causal Discovery & Feedback Construction (a causal discovery algorithm identifies causal relationships, providing feedback to the LLM to refine factor proposals iteratively).", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_45_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework.  COAT uses LLMs (Large Language Models) to identify high-level factors related to a target variable (apple ratings in this example). The LLMs propose potential factors and annotation guidelines. Another LLM then annotates the data based on these factors.  Finally, a causal discovery (CD) algorithm identifies causal relationships between the factors, creating feedback for the LLMs to refine the factors iteratively.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_46_1.jpg", "caption": "Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \"taste\" and \"juiciness\" can not be recovered by COAT because of the limitations of FCI.", "description": "This figure compares causal graphs generated by different methods for analyzing apple ratings.  The ground truth graph shows the actual relationships between factors like size, aroma, taste, and score.  The \"GPT-4 META\" graph represents results from using a large language model (LLM) directly without the COAT framework, highlighting many incorrect connections. The \"GPT-3.5 COAT\" graph shows results using the COAT framework, improving accuracy and capturing most of the true relationships. The \"Claude-3-Opus COAT\" graph demonstrates the COAT framework's robustness, as it also captures most of the true relationships. Note that the lack of an edge between \"taste\" and \"juiciness\" in the COAT graphs is attributed to limitations in the FCI (Fast Causal Inference) algorithm.", "section": "3.2 Analysis with AppleGastronome Benchmark"}, {"figure_path": "w50ICQC6QJ/figures/figures_46_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "The figure illustrates the COAT framework's three stages for analyzing apple ratings. Stage 1 uses an LLM to propose candidate factors based on reviews. Stage 2 uses another LLM to annotate the unstructured review data. Stage 3 employs a causal discovery (CD) algorithm to identify causal relations, providing feedback for iterative refinement of proposed factors.", "section": "1 Introduction"}, {"figure_path": "w50ICQC6QJ/figures/figures_47_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's three main steps: factor proposal, factor annotation, and causal discovery & feedback construction.  In the factor proposal step, an LLM proposes high-level factors related to apple ratings from unstructured reviews.  The factor annotation step uses another LLM to annotate the reviews based on these factors. Finally, a causal discovery algorithm identifies causal relationships between the factors, providing feedback to the LLM to improve the factor proposal iteratively. This iterative process helps refine the understanding of the causal relationships involved in determining apple ratings.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_47_2.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing AppleGastronome ratings.  It details a three-step process: 1) Factor Proposal (LLM proposes high-level factors from reviews), 2) Factor Annotation (another LLM structures the unstructured reviews based on proposed factors), and 3) Causal Discovery & Feedback Construction (a causal discovery algorithm identifies causal relations, and feedback is provided to the LLM to iteratively refine the factors). The goal is to identify factors influencing the apple ratings, progressing through iterative refinement.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_48_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "The figure illustrates the COAT (Causal representation AssistanT) framework's workflow for analyzing apple rating scores.  It shows three stages: 1) Factor Proposal: An LLM proposes high-level factors (e.g., size, smell) influencing the scores based on user reviews; 2) Factor Annotation: Another LLM annotates the reviews according to these factors; 3) Causal Discovery & Feedback: A causal discovery algorithm identifies causal relationships between factors, and feedback is provided to the LLM to iteratively refine the factors and improve the model's accuracy in explaining the ratings. This iterative process aims to accurately reveal the factors impacting the apple ratings.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_48_2.jpg", "caption": "Figure 42: The visualization of the target variable defined in the ENSO case study. The oscillation pattern can be seen.", "description": "This figure shows a time series plot visualizing the target variable used in the ENSO case study, which is the monthly change in sea surface temperature (SST) in the Ni\u00f1o3 region.  The plot displays the SST change over a long period, clearly showing the oscillatory pattern characteristic of El Ni\u00f1o-Southern Oscillation (ENSO) events. The positive values represent El Ni\u00f1o events (warming), and the negative values represent La Ni\u00f1a events (cooling).  The oscillation pattern is visually apparent in the plot.", "section": "K.1 Setting and Data processing"}, {"figure_path": "w50ICQC6QJ/figures/figures_49_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's three main steps: (a) Factor Proposal, where an LLM proposes high-level factors based on unstructured data; (b) Factor Annotation, where another LLM annotates the data according to those factors; (c) Causal Discovery & Feedback Construction, where a causal discovery algorithm identifies causal relationships and provides feedback to refine the factors iteratively.  The framework aims to bridge the gap between unstructured data and causal discovery methods by leveraging LLMs.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_50_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT (Causal representation AssistanT) framework. It shows how COAT uses LLMs (Large Language Models) to identify high-level factors from unstructured data (such as customer reviews), annotates this data, employs causal discovery algorithms to find causal relationships, and then uses the results to provide feedback to the LLMs, iteratively refining the factor identification process.  The goal is to identify the Markov Blanket of a target variable (in this case, apple ratings). The diagram highlights the three main steps: factor proposal, factor annotation, and causal discovery & feedback construction.", "section": "2 Representation Assistant for Causal Discovery"}, {"figure_path": "w50ICQC6QJ/figures/figures_51_1.jpg", "caption": "Figure 7: The final causal graph found by COAT in the ENSO case study.", "description": "This figure illustrates the causal relationships between various climate factors and the change in sea surface temperature (SST) in the Nino3 region, a key indicator of El Ni\u00f1o-Southern Oscillation (ENSO) events.  The graph, generated by the Causal representation AssistanT (COAT) framework, reveals both direct and indirect causal links among factors like cloud cover, air temperature, soil moisture, wind patterns, and sea level pressure, providing valuable insights into the complex dynamics of ENSO. The figure highlights both stationary and non-stationary factors and their influence on SST change.", "section": "4.3 More Real-world Results"}, {"figure_path": "w50ICQC6QJ/figures/figures_52_1.jpg", "caption": "Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fit the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors.", "description": "This figure illustrates the COAT framework's three main steps for analyzing apple ratings.  First, an LLM proposes high-level factors (e.g., size, smell) from unstructured reviews. Second, another LLM annotates the reviews based on these factors. Finally, a causal discovery algorithm identifies causal relationships between the factors, and feedback is generated to refine the factor proposals iteratively.", "section": "2 Representation Assistant for Causal Discovery"}]