[{"figure_path": "wsHMb4J2o9/tables/tables_7_1.jpg", "caption": "Table 1: HP scalings for MLPs under the dense setting (for the sparse setting, replace k and d by 1). For L fixed, both MF+\u00b5P and FSC coincide with \u00b5P. Values in red are exact, the others are up to a multiplicative factor in (1).", "description": "This table presents a comparison of three different hyperparameter (HP) scaling schemes for Multilayer Perceptrons (MLPs) under two settings: dense and sparse.  For each scaling (NTK, MF+\u00b5P, FSC), it shows the initialization standard deviation (init. std. \u03c3\u2113) and learning rate (LR \u03b7\u2113) for the input, hidden, and output layers.  The \"dense\" setting represents a scenario with a dense input and a dense output, while the \"sparse\" setting would involve sparse inputs and outputs.  The table highlights that for a fixed depth (L), the MF+\u00b5P and FSC scalings are equivalent to the \u00b5P scaling.", "section": "5.2 Characterizing HP scalings for MLPs"}, {"figure_path": "wsHMb4J2o9/tables/tables_7_2.jpg", "caption": "Table 2: FSC scalings identified in Prop. 5.4 for ResNets. All HPs are specified up to a multiplicative factor in (1). When \u03b2 = \u0398(L\u2212\u00b9\u00b2) and k = d = \u0398(1), these scalings coincide with the so-called \"depth \u00b5P\" introduced in [Bordelon et al., 2023] and also studied in Yang et al. [2023b].", "description": "This table presents the hyperparameter (HP) scalings for ResNets that satisfy the properties of signal propagation, feature learning, loss decay, and balanced contributions.  It shows the initialization standard deviations (init. std. \u03c3<sub>\u2113</sub>) and learning rates (LR \u03b7<sub>\u2113</sub>) for the input, hidden, and output layers of the network.  The scalings are expressed up to a multiplicative factor, meaning that they are correct within a constant factor. Notably, when the branch scale \u03b2 is proportional to 1/\u221aL (where L is the depth) and the input/output dimensions k and d are constant, these scalings align with the \"depth \u00b5P\" scaling previously identified in other research.", "section": "5.3 Characterizing HP scalings for ResNets"}]