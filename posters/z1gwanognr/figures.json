[{"figure_path": "z1GwaNoGnr/figures/figures_1_1.jpg", "caption": "Figure 1: The overall framework of XMask3D. The 3D model with only coarse 3D-2D-text alignment struggles to segment novel categories with accurate boundaries. We propose to incorporate a 2D open mask generator conditioned on global 3D geometry features to create geometry-aware segmentation masks of novel categories. Then we apply fine-grained mask-level regularization on 3D features, thereby enhancing the dense open vocabulary capability of the 3D model. The cross-modal fusion block leverages the strengths of both branches to achieve optimal results.", "description": "This figure illustrates the overall framework of the XMask3D model, which uses a cross-modal mask reasoning approach for open vocabulary 3D semantic segmentation. It highlights the limitations of traditional methods that rely on global feature alignment, and showcases the XMask3D's approach of incorporating a 2D open mask generator conditioned on 3D geometry features to generate geometry-aware segmentation masks of novel categories. This is followed by mask-level regularization on 3D features and a cross-modal fusion block that combines the strengths of the 2D and 3D branches.", "section": "3 Approach"}, {"figure_path": "z1GwaNoGnr/figures/figures_3_1.jpg", "caption": "Figure 2: The detailed architecture of XMask3D. We introduce an auxiliary 2D branch, which utilizes global point cloud features as conditional input to generate open vocabulary masks. The contour of the mask is utilized for regularization at the mask level on 3D features, and the embeddings of the mask are fused with the 3D features to enhance cross-modal complementarity.", "description": "This figure shows the detailed architecture of the XMask3D model. It consists of three main components: a 3D geometry extraction branch, a 2D mask generation branch, and a 3D-2D feature fusion module. The 3D branch extracts geometric features from a point cloud.  The 2D branch uses a diffusion model to generate open vocabulary masks, conditioned on global 3D features. These masks are then used for mask-level regularization on the 3D features to ensure fine-grained alignment between 3D and 2D feature spaces. Finally, a fusion block merges the features from both branches to leverage their respective strengths and produce a more accurate result.  The CLIP text and image encoders are used in conjunction with the mask generator and the fusion block.", "section": "3 Approach"}, {"figure_path": "z1GwaNoGnr/figures/figures_8_1.jpg", "caption": "Figure 3: Visualization Comparisons between XMask3D and Previous Methods. We compare XMask3D with PLA [11] and OpenScene [34] on the novel categories table, bookshelf, chair and bed. The regions corresponding to the novel categories are highlighted in red boxes.", "description": "This figure compares the performance of XMask3D against two other state-of-the-art methods, PLA and OpenScene, on four novel object categories (table, bookshelf, chair, and bed).  For each category, it shows the view image, the ground truth segmentation, and the segmentation results produced by each of the three methods. Red boxes highlight the regions of interest (i.e., the novel categories). The visual comparison aims to demonstrate that XMask3D achieves more accurate and precise segmentation boundaries compared to the other two methods.", "section": "4.3 Ablation Studies"}, {"figure_path": "z1GwaNoGnr/figures/figures_9_1.jpg", "caption": "Figure 3: Visualization Comparisons between XMask3D and Previous Methods. We compare XMask3D with PLA [11] and OpenScene [34] on the novel categories table, bookshelf, chair and bed. The regions corresponding to the novel categories are highlighted in red boxes.", "description": "This figure compares the performance of XMask3D against two other methods (PLA and OpenScene) on the task of segmenting novel object categories in 3D scenes.  It shows several example scenes with ground truth segmentations and the corresponding segmentations generated by each of the three methods.  The red boxes highlight the regions of the images containing the novel object categories.  The figure demonstrates that XMask3D achieves better segmentation accuracy and more precise boundary delineation compared to the other methods, particularly for fine-grained objects.", "section": "4.3 Ablation Studies"}, {"figure_path": "z1GwaNoGnr/figures/figures_15_1.jpg", "caption": "Figure 3: Visualization Comparisons between XMask3D and Previous Methods. We compare XMask3D with PLA [11] and OpenScene [34] on the novel categories table, bookshelf, chair and bed. The regions corresponding to the novel categories are highlighted in red boxes.", "description": "This figure presents a visual comparison of the segmentation results obtained by XMask3D, PLA [11], and OpenScene [34] on four novel categories (table, bookshelf, chair, and bed).  Each row shows a different scene, with the leftmost image displaying the original view image, followed by the ground truth segmentation, and then the results from PLA, OpenScene, and finally XMask3D (with its three individual branches and their fusion results).  The red boxes highlight the regions corresponding to the four novel categories. The comparison aims to showcase XMask3D's superior accuracy and more refined segmentation boundaries in comparison to the other methods.", "section": "4.3 Ablation Studies"}, {"figure_path": "z1GwaNoGnr/figures/figures_15_2.jpg", "caption": "Figure 3: Visualization Comparisons between XMask3D and Previous Methods. We compare XMask3D with PLA [11] and OpenScene [34] on the novel categories table, bookshelf, chair and bed. The regions corresponding to the novel categories are highlighted in red boxes.", "description": "This figure compares the segmentation results of XMask3D with two other methods (PLA and OpenScene) on four novel categories: table, bookshelf, chair, and bed.  The comparison highlights the superior accuracy and finer segmentation boundaries achieved by XMask3D, particularly in correctly identifying the novel categories. The red boxes clearly show the areas where the novel categories are located, making it easy to compare the performance of the different methods.", "section": "4.3 Ablation Studies"}, {"figure_path": "z1GwaNoGnr/figures/figures_16_1.jpg", "caption": "Figure 7: Failure cases of XMask3D. We focus on shower curtain, picture, and sink novel categories in each line, respectively.", "description": "This figure showcases three failure cases of the XMask3D model in identifying novel categories (shower curtain, picture, sink).  Each row displays the input image, the ground truth segmentation, the segmentation results from the 2D branch, the 3D branch, and the final fused output.  The model struggles in these cases due to various factors, such as similar object shapes and textures, occlusions, and incomplete point clouds.", "section": "C Failure Cases Analysis"}]