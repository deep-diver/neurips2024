[{"figure_path": "1PNwacZYik/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Existing methods with n-step iterative optimization. (b) FastDrag with one-step warpage optimization.", "description": "This figure compares existing drag-based image editing methods with the proposed FastDrag method.  (a) illustrates how traditional methods typically involve multiple iterative steps (n-step) to achieve semantic optimization, using either motion-based or gradient-based approaches.  Each step requires small-scale adjustments.  (b) shows that FastDrag uses a novel one-step warpage optimization strategy, making the process significantly faster. It leverages a latent warpage function (LWF) to directly calculate the necessary adjustments in one go.", "section": "1 Introduction"}, {"figure_path": "1PNwacZYik/figures/figures_3_1.jpg", "caption": "Figure 2: Overall framework of FastDrag with four phases: diffusion inversion, diffusion sampling, one-step warpage optimization and BNNI. Diffusion inversion yields a noisy latent zt and diffusion sampling reconstructs the image from the optimized noisy latent z\u0142. One-step warpage optimization is used for noisy latent optimization, where LWF is proposed to generate warpage vectors to adjust the location of individual pixels on the noisy latent with a simple latent relocation operation. BNNI is used to enhance the semantic integrity of noisy latent. A consistency-preserving strategy is introduced to maintain the consistency between original image and edited image.", "description": "The figure shows the overall framework of the FastDrag method, which consists of four main phases: diffusion inversion, one-step warpage optimization, bilateral nearest neighbor interpolation (BNNI), and diffusion sampling.  Diffusion inversion generates a noisy latent representation of the input image.  The one-step warpage optimization uses a latent warpage function (LWF) to adjust pixel locations in the latent space based on user-specified drag instructions. BNNI interpolates null regions that may arise from the warpage. Finally, diffusion sampling reconstructs the edited image from the optimized latent representation. The process also incorporates a consistency-preserving strategy to maintain coherence between the original and edited images.", "section": "3 Proposed Method"}, {"figure_path": "1PNwacZYik/figures/figures_4_1.jpg", "caption": "Figure 3: Geometric representation of v*. Circle O is the circumscribed circle of the circumscribed rectangle enclosing the mask's shape. pj is the feature point requiring relocation, and p* is its new position following the drag instruction di", "description": "This figure illustrates the geometric interpretation of the component warpage vector v*.  A circle O circumscribes the mask region.  The vector v* connects a feature point pj to its new position p* after a drag operation.  The length of v* is inversely proportional to the distance between the feature point pj and the handle point si of the drag instruction di. The vector v* is parallel to the drag instruction di.  The point q is the intersection of the lines extending from si to pj and ei to p*. The length of v* is determined by the distances si to pj, ei to p*, and si to q, showing how the magnitude of the warpage vector decreases as the feature point pj approaches the circle O.", "section": "3.2.1 Warpage Vector Calculation using LWF"}, {"figure_path": "1PNwacZYik/figures/figures_5_1.jpg", "caption": "Figure 4: Illustration of bilateral nearest neighbor interpolation.", "description": "This figure illustrates the Bilateral Nearest Neighbor Interpolation (BNNI) method used in FastDrag to address the issue of null regions in the latent space after applying the latent warpage function. The leftmost image shows the noisy latent with null points represented by the beige color. The image in the middle shows how BNNI finds the four nearest neighboring points (with values) to a null point, denoted as up, right, down, and left, and then calculates the weighted average of their values to interpolate the null point's value. This weighted average is computed using a weight formula which involves distances to the reference points and numbers of pixels in each direction, as described in the caption. The rightmost image shows the interpolated latent space after BNNI is applied, thus effectively enhancing the semantic integrity of the edited image.", "section": "3.3 Bilateral Nearest Neighbor Interpolation"}, {"figure_path": "1PNwacZYik/figures/figures_5_2.jpg", "caption": "Figure 5: Illustration of consistency-preserving strategy.", "description": "This figure illustrates the consistency-preserving strategy used in FastDrag.  The top half shows the self-attention module (Q, K, V) within the U-Net during the inversion process. The bottom half shows the same module during the sampling process.  Key and value pairs (K, V) from the inversion process are used to guide the sampling process, ensuring consistency between the edited and original images. The dotted lines indicate the flow of information from the inversion to the sampling stage.", "section": "3.4 Consistency-Preserving Strategy"}, {"figure_path": "1PNwacZYik/figures/figures_6_1.jpg", "caption": "Figure 6: Illustration of qualitative comparison with the state-of-the-art methods.", "description": "This figure shows a qualitative comparison of FastDrag with three other state-of-the-art drag-based image editing methods: DragDiffusion, FreeDrag, and DragNoise.  The results are shown for four different image editing tasks.  Each row shows the user edit instruction (leftmost column) and the results obtained by each method.  The figure highlights that FastDrag achieves better image quality and more effective drag operations, especially in complex scenarios.", "section": "4.1 Qualitative Evaluation"}, {"figure_path": "1PNwacZYik/figures/figures_7_1.jpg", "caption": "Figure 2: Overall framework of FastDrag with four phases: diffusion inversion, diffusion sampling, one-step warpage optimization and BNNI. Diffusion inversion yields a noisy latent zt and diffusion sampling reconstructs the image from the optimized noisy latent z\u0142. One-step warpage optimization is used for noisy latent optimization, where LWF is proposed to generate warpage vectors to adjust the location of individual pixels on the noisy latent with a simple latent relocation operation. BNNI is used to enhance the semantic integrity of noisy latent. A consistency-preserving strategy is introduced to maintain the consistency between original image and edited image.", "description": "This figure illustrates the overall framework of the FastDrag method, which consists of four main phases: 1. Diffusion inversion: generating a noisy latent representation from the original image. 2. One-step warpage optimization: using a Latent Warpage Function (LWF) and a latent relocation operation to adjust the position of individual pixels based on drag instructions, achieving one-step semantic optimization. 3. Bilateral Nearest Neighbor Interpolation (BNNI): interpolating null regions in the latent space to improve semantic integrity. 4. Diffusion sampling: generating the final edited image from the optimized noisy latent. A consistency-preserving strategy is also employed to ensure consistency between the original and edited images.", "section": "3 Proposed Method"}, {"figure_path": "1PNwacZYik/figures/figures_8_1.jpg", "caption": "Figure 8: Ablation study on number of inversion steps in terms of drag effect.", "description": "This figure shows the results of an ablation study on the number of inversion steps used in the FastDrag method. The top row shows the original image and the user edit. The subsequent rows show the results of the editing process with different numbers of inversion steps (4, 6, 8, 10, 12, 14, 20, and 30). The goal is to visually demonstrate how the number of inversion steps affects the outcome of the image editing process.  The image shows two penguins. The user intends to move the penguin on the right, slightly away from the penguin on the left.", "section": "4.3 Ablation Study"}, {"figure_path": "1PNwacZYik/figures/figures_8_2.jpg", "caption": "Figure 9: Ablation study on bilateral nearest neighbor interpolation.", "description": "This figure shows an ablation study comparing different interpolation methods for handling null points (missing data) in the latent space during image editing.  The methods compared are: maintaining the original value, interpolating with zeros, interpolating with random noise, and using the proposed Bilateral Nearest Neighbor Interpolation (BNNI).  The results demonstrate that BNNI effectively addresses semantic losses by using similar features from neighboring areas to improve the quality of drag-based image editing.", "section": "3.3 Bilateral Nearest Neighbor Interpolation"}, {"figure_path": "1PNwacZYik/figures/figures_8_3.jpg", "caption": "Figure 10: Ablation study on consistency-preserving strategy.", "description": "This ablation study compares the results of FastDrag with and without the consistency-preserving strategy.  The images show that using the consistency-preserving strategy helps maintain the image consistency between the original and the edited image, resulting in better drag editing effects.  The consistency-preserving strategy uses information from the original image, saved in the self-attention module during diffusion inversion, to guide the diffusion sampling process.", "section": "4.3 Ablation Study"}, {"figure_path": "1PNwacZYik/figures/figures_9_1.jpg", "caption": "Figure 6: Illustration of qualitative comparison with the state-of-the-art methods.", "description": "This figure shows a qualitative comparison of FastDrag with three other state-of-the-art drag-based image editing methods: DragDiffusion, FreeDrag, and DragNoise.  Each row represents a different image editing task, and each column shows the results of a different method. The results demonstrate that FastDrag produces more effective drag results while maintaining high image quality, even in images with complex textures, compared to existing methods.  FastDrag successfully rotates an animal's face while preserving intricate fur textures, stretches a sofa's back while preserving the content in unmasked regions, and moves a sleeve to a higher position accurately. In contrast, other methods may fail to perform the drag operation correctly, or the drag results appear less natural.", "section": "4.1 Qualitative Evaluation"}, {"figure_path": "1PNwacZYik/figures/figures_9_2.jpg", "caption": "Figure 12: Illustration of the limitation analysis with failed and successful drag editing for highly relying on precise drag instruction. (a) It is best to exclude the face from the mask region. (b) The handle point should ideally be placed where the \u201cbeak", "description": "This figure shows two examples of drag-based image editing where the success of the editing depends highly on the precision of the user's drag instruction. The first example (a) shows an attempt to thin the hair while keeping the face size. It shows a failed and a successful result. The failure is likely due to including the face in the mask region. The second example (b) shows an attempt to lengthen the beak of a hummingbird. It also shows a failed and a successful result. Here, the failure is likely due to not placing the handle point precisely on the beak. This figure highlights the importance of precise drag instructions for successful drag-based image editing, especially for fine-grained manipulations.", "section": "5 Limitations"}, {"figure_path": "1PNwacZYik/figures/figures_12_1.jpg", "caption": "Figure 7: Ablation study on number of inversion steps in terms of quantitative metrics.", "description": "This figure shows the result of an ablation study on the number of inversion steps used in the FastDrag method.  The x-axis represents the number of inversion steps, while the y-axis shows the mean distance (MD) and image fidelity (1 - LPIPS) values.  The graph illustrates how the number of inversion steps affects the quantitative metrics of the method.  The optimal number of steps for this method is shown to be around 6-14 steps.", "section": "4.3 Ablation Study"}, {"figure_path": "1PNwacZYik/figures/figures_12_2.jpg", "caption": "Figure 7: Ablation study on number of inversion steps in terms of quantitative metrics.", "description": "This figure shows the impact of varying the number of inversion steps during the diffusion process on the quantitative metrics of the FastDrag model.  The x-axis represents the number of inversion steps, while the y-axis shows the Mean Distance (MD) and Image Fidelity (1-LPIPS).  Lower MD values indicate more precise drag results, and higher 1-LPIPS values reflect better similarity between the generated and original images. The graph helps to determine the optimal number of inversion steps that balance image quality and editing precision.  The results show that a sweet spot exists, with too few steps resulting in poor results and too many steps not significantly improving the metrics.", "section": "4.3 Ablation Study"}, {"figure_path": "1PNwacZYik/figures/figures_12_3.jpg", "caption": "Figure 15: Overall editing time comparison with different diffusion steps between FastDrag and DragDiffusion. All experiments are conducted on RTX 3090 with diffusion step set as 1, 20, and 50 respectively. Optimization means latent optimization.", "description": "This figure shows a bar chart comparing the time taken for different stages (inversion, sampling, optimization) of image editing using FastDrag and DragDiffusion methods with varying diffusion steps (1, 20, and 50).  It highlights FastDrag's significantly faster processing time across all stages, especially in the optimization phase, which is the most time-consuming part in conventional methods.", "section": "4.3 Ablation Study"}, {"figure_path": "1PNwacZYik/figures/figures_14_1.jpg", "caption": "Figure 16: More visualized results of FastDrag.", "description": "This figure shows additional examples of image manipulations achieved using the FastDrag method.  It showcases the versatility of the method across a range of image types and editing tasks, demonstrating its ability to accurately reflect user intentions in manipulating objects or image regions, even those with intricate details or complex textures.", "section": "More Results"}]