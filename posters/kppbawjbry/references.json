{"references": [{"fullname_first_author": "Gu, T.", "paper_title": "Badnets: Identifying vulnerabilities in the machine learning model supply chain", "publication_date": "2017-08-06", "reason": "This paper introduces the concept of backdoors in machine learning models, a crucial foundation for understanding the privacy backdoor attack presented in the main paper."}, {"fullname_first_author": "Shokri, R.", "paper_title": "Membership inference attacks against machine learning models", "publication_date": "2017-05-01", "reason": "This foundational paper introduces membership inference attacks (MIAs), which the main paper builds upon to create the privacy backdoor attack."}, {"fullname_first_author": "Carlini, N.", "paper_title": "Membership inference attacks from first principles", "publication_date": "2022-05-01", "reason": "This paper provides a refined and robust framework for MIAs, serving as a base for the attack's evaluation methodology in the main paper."}, {"fullname_first_author": "Tram\u00e8r, F.", "paper_title": "Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets", "publication_date": "2022-11-01", "reason": "This paper explores targeted poisoning attacks which inspired the approach for poisoning pre-trained models to amplify MIA success."}, {"fullname_first_author": "Hu, E. J.", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2021-06-09", "reason": "This paper introduces LoRA, a crucial fine-tuning method used in the main paper's experiments and ablation studies to demonstrate the attack\u2019s effectiveness across different fine-tuning approaches."}]}