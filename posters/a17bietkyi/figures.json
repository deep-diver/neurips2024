[{"figure_path": "a17biETKyI/figures/figures_7_1.jpg", "caption": "Figure 1: Section 4.2: (a) Test accuracy for each intensity level in ImageNet-C. (b) Performance degeneration in the defocus blur corruption with intensity 4. Section 4.3.1: (c) Maximum performance changes under different model selection methods. We present performances for individual corruptions in Appendix. For all boxplots used in the paper, the box represents interquantile range with whiskers as \u00b1 1.5 interquantile range and the horizontal line inside the box represents the median.", "description": "This figure visualizes the results of experiments on ImageNet-C dataset. (a) shows the test accuracy across different corruption intensity levels using three methods: Self-training, ELR, and AnCon. (b) focuses on the defocus blur corruption with intensity level 4 and shows the performance degradation over epochs using the same three methods. (c) displays the maximum performance change among three model selection methods (InfoMax, Corr-C, Ent) across various corruption intensities.  The box plots in (a) illustrate the distribution of test accuracy across multiple runs.", "section": "4.2 Self-training under synthetic corruption operations"}, {"figure_path": "a17biETKyI/figures/figures_8_1.jpg", "caption": "Figure 1: Section 4.2: (a) Test accuracy for each intensity level in ImageNet-C. (b) Performance degeneration in the defocus blur corruption with intensity 4. Section 4.3.1: (c) Maximum performance changes under different model selection methods. We present performances for individual corruptions in Appendix. For all boxplots used in the paper, the box represents interquantile range with whiskers as \u00b11.5 interquantile range and the horizontal line inside the box represents the median.", "description": "This figure visualizes the results of experiments on ImageNet-C dataset. (a) shows the test accuracy for different corruption intensity levels. (b) focuses on the performance degradation of defocus blur with intensity 4. (c) displays the maximum performance changes under various model selection methods, highlighting the robustness of AnCon.", "section": "4.3 Versatility of AnCon"}, {"figure_path": "a17biETKyI/figures/figures_8_2.jpg", "caption": "Figure 1: Section 4.2: (a) Test accuracy for each intensity level in ImageNet-C. (b) Performance degeneration in the defocus blur corruption with intensity 4. Section 4.3.1: (c) Maximum performance changes under different model selection methods. We present performances for individual corruptions in Appendix. For all boxplots used in the paper, the box represents interquantile range with whiskers as \u00b1 1.5 interquantile range and the horizontal line inside the box represents the median.", "description": "This figure shows the results of experiments conducted to evaluate the performance of different methods under various conditions.  Panel (a) presents the test accuracy for ImageNet-C dataset across five different corruption intensity levels and shows the robustness of AnCon. Panel (b) focuses specifically on the defocus blur corruption with intensity 4, highlighting the performance degradation of various methods. Panel (c) illustrates the robustness of AnCon against different model selection methods.", "section": "4.1 Self-training under domain shifts"}, {"figure_path": "a17biETKyI/figures/figures_18_1.jpg", "caption": "Figure 4: (a) The accuracy of the generalized temporal ensemble along with the number of confident samples under different degrees of distribution shifts. Here, the temporal ensemble is constructed by averaging all predictions over iterations. (b) On-average accuracies per the number of confident samples over iterations under different thresholding rules.", "description": "This figure shows the accuracy of different ensemble methods (generalized temporal ensemble and temporal ensemble) compared to using only pseudo labels.  The x-axis represents the number of confident samples, and the y-axis represents accuracy.  Subfigure (a) demonstrates the accuracy under varying degrees of distribution shifts, while subfigure (b) shows the impact of different thresholding rules on the average accuracy.", "section": "C.1 Empirical evidence for Theorem 3.1"}, {"figure_path": "a17biETKyI/figures/figures_19_1.jpg", "caption": "Figure 1: Section 4.2: (a) Test accuracy for each intensity level in ImageNet-C. (b) Performance degeneration in the defocus blur corruption with intensity 4. Section 4.3.1: (c) Maximum performance changes under different model selection methods. We present performances for individual corruptions in Appendix. For all boxplots used in the paper, the box represents interquantile range with whiskers as \u00b11.5 interquantile range and the horizontal line inside the box represents the median.", "description": "This figure shows three subfigures. (a) shows the test accuracy for each intensity level in ImageNet-C dataset for different methods such as self-training, ELR, and AnCon. (b) shows the performance degeneration in the defocus blur corruption with intensity 4. (c) shows the maximum performance changes under different model selection methods. The box plots show the distribution of the results, with the median, interquartile range, and whiskers representing the central tendency and variability of the data.", "section": "4.2 Self-training under synthetic corruption operations"}, {"figure_path": "a17biETKyI/figures/figures_19_2.jpg", "caption": "Figure 6: Ablation study of (a) weighting and (b) prediction schemes.", "description": "This ablation study investigates the impact of different weighting schemes (AnCon, Entropy, Maxprob, Dirichlet) and prediction methods (AnCon (Hard), different softmax temperature values) on the self-training performance.  The box plots show relative performance changes compared to the default AnCon method, across various datasets and distribution shifts.  The results demonstrate that the default choices of AnCon for weighting and prediction yield superior performance compared to alternatives.", "section": "4.3 Versatility of AnCon"}]