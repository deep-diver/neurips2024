[{"figure_path": "RY3rDQV0tQ/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between conventional and proposed methods of image generation based on diffusion models. The conventional method runs on digital electronics based computing units such as GPUs or TPUs. The proposed method utilizes an optical denoising unit that is formed by passive optical layers. The image to be denoised is sent to the system with a modulator and the output is read out with a detector.", "description": "This figure compares the conventional digital approach for image generation using diffusion models with the novel optical approach proposed in the paper. The conventional method uses digital electronics (like GPUs or TPUs) and a denoising neural network to iteratively remove noise from an input image, eventually generating a new sample.  The proposed optical method uses passive optical layers to perform the denoising process, resulting in higher speed and energy efficiency.  Noisy images are input to the system through an optical modulator, and the final, denoised image is obtained from an optical detector.", "section": "1 Introduction"}, {"figure_path": "RY3rDQV0tQ/figures/figures_1_2.jpg", "caption": "Figure 1: Comparison between conventional and proposed methods of image generation based on diffusion models. The conventional method runs on digital electronics based computing units such as GPUs or TPUs. The proposed method utilizes an optical denoising unit that is formed by passive optical layers. The image to be denoised is sent to the system with a modulator and the output is read out with a detector.", "description": "This figure compares two approaches to image generation using diffusion models: a conventional digital method and a novel optical method.  The conventional method uses digital electronics (like GPUs or TPUs) and a denoising neural network to iteratively reduce noise from a random image until a realistic sample is generated.  In contrast, the proposed optical method uses passive optical layers and light beam propagation to perform the denoising process. The input image is modulated optically, passed through a series of passive optical elements, and the resulting image is read by an optical detector. The key difference is that the optical method aims for higher speed and energy efficiency by replacing computationally expensive digital steps with physical optical processes.", "section": "1 Introduction"}, {"figure_path": "RY3rDQV0tQ/figures/figures_3_1.jpg", "caption": "Figure 2: The main operation principle of ODU. Consequent modulation and free space propagation events can be represented with multiplication and convolution operations. When the input beam Uo(x, y), which is patterned with noisy input images, rt, is introduced to the ODU, the output intensity pattern ||Uf(x, y)||\u00b2 corresponds to the trained optical system\u2019s prediction of the noise component in the input pattern, e\u03b8(rt).", "description": "This figure illustrates the main working principle of the Optical Denoising Unit (ODU).  It shows how a noisy input image is processed through a series of passive optical layers (L1-L4). Each layer modulates the light beam according to a trained modulation pattern.  The process of modulation and free-space propagation is mathematically represented by convolution operations. The final output intensity pattern, after passing through all layers, represents the predicted noise component in the original noisy image, which can then be used for denoising.", "section": "3.2 Propagation of Modulated Light Beams"}, {"figure_path": "RY3rDQV0tQ/figures/figures_5_1.jpg", "caption": "Figure 3: Images generated by the Optical Diffusion Model at different timesteps and when trained with various datasets. The generated images and their corresponding Inception and FID scores are calculated between timesteps T = 10 to T = 950 are acquired after training with the MNIST digits dataset. Final outputs at time T = 1000, acquired from ODUs trained for the MNIST digits samples have FID = 206.6, for Fashion MNIST, FID = 227.7 and for Quick, Draw!, FID = 131.4", "description": "This figure shows the image generation results of the Optical Diffusion Model at various timesteps (T=10, 400, 650, 800, 900, 950, 1000) for three different datasets: MNIST digits, Fashion-MNIST, and Quick, Draw!. Each dataset's image generation process is shown across multiple timesteps in a grid format.  The bottom graphs show the Inception Score and Fr\u00e9chet Inception Distance (FID) scores, metrics that evaluate image quality and realism respectively, as a function of the denoising steps.", "section": "4 Results"}, {"figure_path": "RY3rDQV0tQ/figures/figures_5_2.jpg", "caption": "Figure 4: Scaling of the denoising capabilities (left) and generation performance (right) of Optical Diffusion, and pure digital convolutional U-Net and fully connected networks with the output image resolution.", "description": "This figure shows the scaling of denoising capabilities and generation performance of three different methods: Optical Diffusion, a convolutional U-Net, and a fully connected network. The x-axis represents the output image resolution, while the y-axis represents the MSE score (left) and FID score (right).  The results demonstrate how the performance of each method scales with increasing resolution.  Optical Diffusion shows better performance in both metrics across different resolutions.", "section": "4 Results"}, {"figure_path": "RY3rDQV0tQ/figures/figures_6_1.jpg", "caption": "Figure 5: The dependency of denoising performance (MSE) and generation quality scores(FID, KID and Inception score), on the hyperparameters of the ODUs (number of pixels of optical modulation layers, number of modulation layers and number of denoising layer sets (M)).", "description": "This figure analyzes how different hyperparameters of the Optical Denoising Unit (ODU) affect the performance of the model.  The hyperparameters examined are: the resolution of the optical modulation layers (in pixels), the number of modulation layers, and the number of denoising layer sets (M).  The performance is measured using Mean Squared Error (MSE) for denoising and Fr\u00e9chet Inception Distance (FID), Kernel Inception Distance (KID), and Inception Score (IS) for image generation quality.  The results show the trade-offs between these hyperparameters and their impact on model performance.", "section": "4 Results"}, {"figure_path": "RY3rDQV0tQ/figures/figures_7_1.jpg", "caption": "Figure 6: The relationship between the total number of parameters in an ODU and its generation performance in terms of FID scores.", "description": "This figure shows the relationship between the total number of parameters in an Optical Denoising Unit (ODU) and its performance in generating images, as measured by the Fr\u00e9chet Inception Distance (FID) score.  The plot demonstrates a power-law relationship, indicating that increasing the number of parameters improves image generation quality. A single outlier point highlights that the single-layer ODU performs significantly worse than the others, emphasizing the benefit of multiple layers in this architecture.", "section": "4 Results"}, {"figure_path": "RY3rDQV0tQ/figures/figures_8_1.jpg", "caption": "Figure 7: The upper block illustrates the online training scheme. The forward pass is calculated with the experiment (blue), while the gradients of the prediction error are backpropagated using a DT of the experiment (green) and updating the physical trainable parameters. The difference between the outputs of the experimental setup and the DT continuously refines the DT (red). The lower graph block compares offline and online training methods. Offline training relies on a pre-trained DT for both the forward and backward passes, with the experimental performance of this method indicated by the star. Experimental backpropagation executes the physical forward pass but does not incorporate DT refinement.", "description": "This figure shows a schematic of the online training scheme used in the paper, comparing it to offline training and experimental backpropagation. The online training scheme uses a digital twin (DT) to refine the physical system's parameters, improving its performance and aligning it more closely with desired outcomes.  The graph illustrates the mean squared error (MSE) and discrepancy between the experiment and the DT over training epochs for each method, showing that online training leads to faster convergence and lower error.", "section": "4.3 Higher Experimental Fidelity with the Online Learning Algorithm"}, {"figure_path": "RY3rDQV0tQ/figures/figures_14_1.jpg", "caption": "Figure 8: Comparison of image generation performances on the AFHQ dataset's cat class [4] at 40-by-40 resolution.", "description": "This figure compares the image generation performance of three different models: Fully Connected, U-Net, and ODU (Optical Diffusion Unit) on the AFHQ cat dataset at 40x40 resolution. For each model, the mean squared error (MSE) and Fr\u00e9chet Inception Distance (FID) scores are shown for different timesteps (T=500, T=750, T=1000).  The figure visually demonstrates the image generated at different stages for each model.  The goal is to show the relative performance of the optical method compared to traditional digital methods at a higher resolution than MNIST.", "section": "4.2 Effects of Optical Model's Dimensionality on the Image Denoising and Generation Performance"}, {"figure_path": "RY3rDQV0tQ/figures/figures_15_1.jpg", "caption": "Figure 9: Some input patterns, output intensities at the camera plane, and the corresponding noise prediction for Fashion MNIST. The intensities on the camera plane are converted to noise predictions by downsampling and normalization.", "description": "This figure shows examples of how the optical system processes input patterns.  The top row displays example input patterns from the Fashion MNIST dataset at different denoising steps. The middle row shows the corresponding output intensities measured at the camera. These intensities are then processed to extract the predicted noise, which is shown in the bottom row.  The predicted noise reflects the system's estimation of the remaining noise in the image at each step, a key component in the diffusion model's denoising process.", "section": "A.3 Details of the Experimental System and Online Learning"}, {"figure_path": "RY3rDQV0tQ/figures/figures_15_2.jpg", "caption": "Figure 7: The upper block illustrates the online training scheme. The forward pass is calculated with the experiment (blue), while the gradients of the prediction error are backpropagated using a DT of the experiment (green) and updating the physical trainable parameters. The difference between the outputs of the experimental setup and the DT continuously refines the DT (red). The lower graph block compares offline and online training methods. Offline training relies on a pre-trained DT for both the forward and backward passes, with the experimental performance of this method indicated by the star. Experimental backpropagation executes the physical forward pass but does not incorporate DT refinement.", "description": "This figure shows a schematic of the online training process, comparing it to offline training and experimental backpropagation.  It highlights the use of a digital twin (DT) to refine the model parameters and improve the alignment between the digital simulation and the physical experiment. The lower graph illustrates the differences in Mean Squared Error (MSE) and decorrelation between the approaches over several epochs, demonstrating the effectiveness of the online learning method.", "section": "4.3 Higher Experimental Fidelity with the Online Learning Algorithm"}]