[{"type": "text", "text": "Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "image", "img_path": "anxYEohntP/tmp/6fae2161aaeb88f274047c675d07cc92045eac4ade0d57d7c55db6f6642c4c77.jpg", "img_caption": ["Figure 1: CogMir Sample Evaluations. Mirror Human Cognitive Bias and LLM Agents Hallucination through Social Science Experiments via representational social and cognitive phenomena. "], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models (LLMs) have been shown to face hallucination issues due to the data they trained on often containing human bias; whether this is reflected in the decision-making process of LLM agents remains under-explored. As LLM Agents are increasingly employed in intricate social environments, a pressing and natural question emerges: Can LLM Agents leverage hallucinations to mirror human cognitive biases, thus exhibiting irrational social intelligence? In this paper, we probe the irrational behavior among contemporary LLM agents by melding practical social science experiments with theoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM Agents framework that utilizes hallucination properties to assess and enhance LLM Agents\u2019 social intelligence through cognitive biases. Experimental results on CogMir subsets show that LLM Agents and humans exhibit high consistency in irrational and prosocial decisionmaking under uncertain conditions, underscoring the prosociality of LLM Agents as social entities, and highlighting the significance of hallucination properties. ", "page_idx": 0}, {"type": "text", "text": "17 1 Introduction ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "18 Human mind may often be better than rational. \u2013 Leda Cosmides, John Tooby. With the extensive   \n19 deployment of large language models (LLMs)[32, 14], LLM-based agent systems are increasingly   \n20 developed to cater to diverse applications such as task-solving, evaluation, and simulation [12, 7, 19,   \n21 17, 38]. Given the similarities between the operational dynamics of LLM-based agent systems and   \n22 human social structures, it is pertinent to explore the intersection of these domains. Recent studies   \n23 have highlighted the social potential of LLM Agents through constructing multi-agent systems that   \n24 simulate interactive social scenarios [40, 39, 31] revealing the social dynamics among interacting   \n25 LLM Agents and showing parallels to human behaviors. For instance, LLMs can achieve social   \n26 goals [40] and adhere to social norms [31] within LLM-based Multi-Agent systems. Nonetheless,   \n27 these research efforts exhibit two significant gaps: 1) They primarily focus on black-box testing   \n28 in multi-agent role-playing systems, concentrating on the outputs and behaviors of agents while   \n29 neglecting to investigate the internal mechanisms or cognitive processes that drive these behaviors.   \n30 2) LLM Agents are prone to hallucinations\u2014producing misleading or incorrect information, due to   \n31 their training data and inherent biases [13, 30]. The potential impact of such hallucinations on the   \n32 social intelligence of LLM Agents remains under-explored.   \n33 Cognitive biases, pervasive in human society, highlight the subjective nature of human behavior [1, 6].   \n34 Human cognitive biases can lead to irrational decisions and imaginary contents like the hallucination   \n35 phenomenon in LLMs [13, 36]. However, evolutionary psychology suggests that rationality is   \n36 unnatural; rather, human irrationality is an adaptive selected trait for navigating complex social   \n37 environments [9, 18]. Analogically, in this paper, we argue that LLMs\u2019 hallucination (or imagination)   \n38 attributes are the fundamental condition that confers social intelligence on LLM Agents. We explore   \n39 the similarities in social potential between human cognitive biases and LLM Agent hallucination   \n40 attributes for the first time, particularly in irrational decision-making, to analogically deduce the   \n41 underlying reasons for LLM Agents\u2019 possession of social intelligence.   \n42 To study LLM Agents\u2019 potential for irrational social intelligence, we present CogMir, an open-ended   \n43 and dynamic multi-agent framework designed specifically for evaluating, exploring, and explaining   \n44 social intelligence for LLM Agents via systematic assessments of cognitive biases. Specifically, the   \n45 hallucinatory attributes of LLMs are exploited (i.e., via treating the cognitive bias as a manageable   \n46 and interpretable factor) in CogMir to probe their social intelligence, so as to providing enhanced   \n47 interpretability for LLM agents. In addition, our proposed CogMir framework integrates sociological   \n48 methodologies to abstract typical social structures and employ various Multi-Human-Agent Interac  \n49 tion Combinations and Communication Modes to interlink System Objects. This integrative setup is   \n50 designed to systematically encompass and simulate various cognitive bias scenarios, as depicted in   \n51 Fig. 1. On the evaluation front, CogMir combines sociological assessments, manual discrimination,   \n52 LLM assessments, and traditional AI discrimination techniques to realize a multidimensional assess  \n53 ment system. By using flexible module configurations from standardized sets, CogMir simplifies   \n54 social architectures, enabling diverse applications in experimental simulations and evaluations.   \n55 Designed as an open-ended framework for continuous interpretative study, we provide multiple   \n56 CogMir subset samples as examples. Existing assessments of various cognitive effects demonstrate   \n57 that LLM agents exhibit a high degree of consistency with humans in prosocial cognitive biases and   \n58 counter-intuitive phenomena. However, LLM Agents demonstrate a higher sensitivity to factors like   \n59 certainty and social status than humans, exhibiting more variability in their decision-making biases   \n60 under conditions of certainty and uncertainty. In contrast, human decision-making tends to be more   \n61 consistent across these conditions. In summary, this paper makes the following contributions:   \n62 \u2022 We are the first to breach the black-box theoretical bottleneck of the Multi-LLM Agents\u2019   \n63 social intelligence, by utilizing LLM Agent hallucination properties to mirror human cogni  \n64 tive biases as explanatory and controllable variables to systematically assess and explain   \n65 LLM Agent\u2019s social intelligence through an evolutionary sociology lens.   \n66 \u2022 We propose CogMir, an extensible, modularized, and dynamic Multi-LLM Agents frame  \n67 work for assessing, exploiting, and interpreting social intelligence via cognitive bias, aligned   \n68 with social science methodologies.   \n69 \u2022 We offer diverse CogMir subsets and use cases to steer future research. Our experimental   \n70 findings highlight the alignment and distinctions between LLM Agents and humans in the   \n71 decision-making process.   \n72 \u2022 CogMir indicates that LLM Agents have pro-social behavior in irrational decision-making,   \n73 emphasizing the significant role of hallucination properties in their social intelligence. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "74 2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "75 Our work is inspired by interdisciplinary areas such as social sciences and evolutionary psychology. ", "page_idx": 2}, {"type": "text", "text": "76 LLM Hallucination & Cognitive Bias. Hallucination in LLMs occurs when they generate content   \n77 that is not factually accurate, often arising from the reliance on patterns learned from biased training   \n78 data or the model\u2019s limitations in understanding context and accessing current information [13, 36].   \n79 Such hallucinations might be beneficial in creative fields, where these models can act as \u201ccollaborative   \n80 creative partners.\u201d They offer innovative and inspiring outputs that can lead to the discovery of novel   \n81 ideas and connections [30]. Concurrently, cognitive biases and evolutionary psychology offer essential   \n82 perspectives on decision-making processes and prosocial behaviors, which can be analogously applied   \n83 to explain the social intelligence of LLM Agents[18, 1]. In this work, through mirroring human   \n84 cognitive bias, we suggest that the hallucination property of LLM is the basis for prosocial behavior   \n85 in LLM Agents, representing a potential form of advanced intelligence.   \n86 LLM Agent Social Intelligence Evaluation. Several benchmarks traditionally utilized for evaluating   \n87 the social intelligence of artificial agents, such as SocialIQA [33] and ToMi [16], are increasingly   \n88 being surpassed in difficulty as language models advance. In response to this trend, recent efforts   \n89 have synthesized existing benchmarks and introduced innovative evaluation datasets specifically   \n90 tailored for assessing LLM Agents [40, 19, 35, 26]. Despite the wide range of social intelligence   \n91 types [18], there is no standard workflow for investigating LLM Agents\u2019 social intelligence. CogMir   \n92 has developed an open and accessible workflow aligned with consensus-based approaches in social   \n93 science, facilitating systematic testing and advancement of social intelligence in language models.   \n94 Multi-Agents Social System. Dialogue systems facilitate AI interactions, with task-oriented models   \n95 focusing on specific tasks and open-domain systems designed for general conversation, often enhanc  \n96 ing engagement by incorporating personal details and creating deep understanding [40]. Simulations   \n97 with LLMs demonstrate their abilities to produce human-like social interactions by applying these   \n98 models to tasks like collaborative software development [7, 12, 17, 39, 31, 38, 35]. Despite these   \n99 advancements, exploration of why these models exhibit social capabilities remain limited. Our work   \n100 tries to bridge this theoretical gap by drawing on research methods from human social evolution   \n101 studies, thereby enhancing the interpretability of Multi-LLM Agents social systems. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "102 3 CogMir: Multi-LLM Agents Framework On Cognitive Bias ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "103 In this section, we provide a detailed and modular overview of CogMir, organized into four main   \n104 elements: environmental setting, framework structure, cognitive biases subsets, and illustrative use   \n105 cases. These components are visually depicted in a left-to-right sequence in Fig. 2. ", "page_idx": 2}, {"type": "text", "text": "106 3.1 Environmental Settings ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "107 First, we outline a novel standard workflow for integrating social science methodologies with the   \n108 Multi-LLM Agents system, ensuring alignment with traditional experimental standards and adapting   \n109 data collection methods for Multi-LLM Agents environments.   \n110 CogMir environment settings are benchmarked against standard social science experiments through a   \n111 structured three-step process: Literature Search, Manual Selection, and LLM Agent Summarization.   \n112 A literature search pinpoints key social science experiments, which are then manually selected for   \n113 relevance and replicability. LLM Agents adapt these for integration into the Multi-LLM Agents   \n114 system within the CogMir framework. In the Mirror Settings process, data collection methods such   \n115 as surveys and interviews are transformed into Human-LLM Agent Q&A. Methods like case studies   \n116 and naturalistic observations are adapted to Multi-Human-Agent interaction scenarios.   \n117 Human-LLM Agent Q&A involves (1) Question Dataset Construction: Developing a diverse set   \n118 of questions tailored to specific study needs (e.g. multiple-choice, fill-in-the-blank, etc.) (2) Q&A   \n119 Scenario Design: Pairing the Question Datasets with scenarios that simulate real-world environments   \n120 (controlled settings like a room to dynamic public spaces like squares or transit stations). (3) Prompt   \n121 Engineering: Crafting appropriate prompts for the LLM Agents based on the scenario and question   \n122 dataset. (4) Analysis of LLM Agent Responses: Evaluating the responses from LLM Agents.   \n123 Multi-Human-Agent Interaction involves (1) Interaction Combination Configuration: Adapting   \n124 human-only social science settings to interactive environments that include humans and LLM Agents   \n125 (e.g., in group discussion experiments, some human participants are replaced with LLM Agents).   \n126 (2) Role Assignment: Specific roles and behaviors are assigned to humans and LLM Agents. This   \n127 assignment is guided by prompt engineering to ensure each participant acts according to social   \n128 science experiment guidelines. (3) Communication Mode Selection: Based on the original social   \n129 science setting select suitable communication modes for interaction. (4) Data Collection and Analysis:   \n130 Gathering and analyzing data from these interactions (e.g. dialogue, decision-making, etc.). ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "image", "img_path": "anxYEohntP/tmp/52a62d390f89cc781a8bad28ee1456642ae75256fa6238bc92e9fac05d7dcc65.jpg", "img_caption": ["Figure 2: CogMir Framework. The framework is structured around four essential objects: humans, LLM Agents, data, and discriminators. These objects interact within the framework to facilitate Multi-Human-Agent (Multi-H-A) interactions and evaluations. CogMir features two communication modes and five Multi-H-A interaction combinations, enabling varied configurations to suit diverse social experimental needs. CogMir offers mirror cognitive bias samples (Fig. 1) and dynamic use cases open for expansion. The framework is depicted in a left-to-right sequence. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "131 3.2 Framework Structure ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "132 After establishing realistic social science experiment environments, the next step is to select essential   \n133 components to support the above two mirror methods: Human-LLM Agent Q&A and Multi-Human  \n134 Agent Interaction. This entails choosing participant objects, evaluation tools, and communication   \n135 modes. The CogMir framework is organized into modules for Required Objects, Communication   \n136 Modes, and Interaction Combinations to meet these needs.   \n137 Required Object Sets. Required Object encompasses all potential participants and evaluators in  \n138 volved in the system. Participants include humans and LLM Agents, which allows for dynamic   \n139 setups where either or both can be involved in interactions depending on the experiment\u2019s require  \n140 ments. Evaluators include humans, LLM Agents, datasets, and discriminators. Datasets are utilized   \n141 to store and construct prompts about the experimental setup (e.g. experimental scenarios, character   \n142 information, etc.), task description, and Q&A question set. Discriminators are specialized tools   \n143 utilized to evaluate the social intelligence of LLM Agents, encompassing three main types: State  \n144 of-the-art technical metrics such as SimCSE, SelfCheck, and FactScore [11, 22, 20] for objective,   \n145 quantitative assessment; Human discriminators that delve into nuanced and subjective aspects like   \n146 prosocial understanding; and LLM Agent discriminators, which involve the use of other LLM Agents   \n147 to assess and challenge responses from a subject LLM Agent.   \n148 Communication Modes Sets. Communication modes dictate the nature of interactions within differ  \n149 ent setups. We model the participants (humans or LLM Agents) as channels based on information   \n150 theory [34] to define two essential communication modes:   \n151 \u2022 Broadcast (or Parallel, $C=C_{1}+C_{2}+...+C_{n})$ which enables a single sender to transmit   \n152 a message to multiple receivers simultaneously.   \n153 \u2022 Point-to-point (or Series, $C=\\operatorname*{min}[C_{1},C_{2},.\\,\\dotsc,C_{n}])$ establishes communication between   \n154 two specific entities at a time ( $C$ denotes channel capacity).   \n155 Multi-H-A Interaction Combinations Sets. This module provides various combinations of Multi  \n156 Human-LLM Agent interactions, tailored to different social science experimental needs, the most   \n157 frequently used combinations in social science settings include:   \n158 \u2022 Single-H-Single-A: One human interacting with one LLM Agent, predominantly used for   \n159 human-agent question-answering tasks (e.g. survey, interview, etc. ).   \n160 \u2022 Single-H-Multi-A: One human interacts with multiple LLM Agents, where humans can be   \n161 set as controlled variables to test Multi-LLM Agents\u2019s social cognitive behaviors.   \n162 \u2022 Multi-H-Single-A: multiple humans interact with a single LLM Agent, which is suitable   \n163 for assessing the impact of group dynamics, such as consensus or conflict.   \n164 \u2022 Multi-A: multiple agents interacting without human participation.   \n165 \u2022 Multi-H-Multi-A: multiple humans and multiple LLM Agents interaction, integrating   \n166 elements from the previous setups to mimic complicated experimental interactions.   \n167 These modules offer a flexible framework for exploring LLM Agents\u2019 cognitive biases in social   \n168 science experiments. Researchers can customize their setups by mixing different components to   \n169 examine specific hypotheses. We outline cognitive bias subsets as guidelines in the next section. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "170 3.3 Cognitive Bias Subsets ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "171 We offer a collection of seven distinct Cognitive Bias Effects subsets, tailored for the analysis of LLM   \n172 Agents\u2019 irrational decision-making processes: a) Herd Effect [5]: refers to the tendency of people to   \n173 follow the actions of a larger group, often disregarding their own beliefs. b) Authority Effect [21]:   \n174 involves people being more likely to comply with advice or instructions from someone perceived   \n175 as an authority figure. c) Ban Franklin Effect [10]: suggests that a person who does someone else   \n176 a favor is more likely to do another favor for that person, due to cognitive dissonance. d) Rumor   \n177 Chain Effect [3]: describes how information tends to change and distort as it passes from person to   \n178 person, often leading to misinformation. e) Gambler\u2019s Fallacy [8]: refers to the incorrect belief that   \n179 past events can influence the likelihood of something happening in the future in random processes. f)   \n180 Confirmation Bias [24]: refers to the tendency to favor, seek out, and remember information that   \n181 confirms one\u2019s preexisting beliefs. g) Halo Effect [15]: occurs when a positive impression in one   \n182 area influences a person\u2019s perception in other areas, leading to biased judgments. ", "page_idx": 4}, {"type": "text", "text": "183 The Cognitive Bias Subsets are discussed in detail in Section 4. ", "page_idx": 4}, {"type": "text", "text": "184 3.4 Sample Use Cases ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "185 Building on the above environmental settings and framework structure, we introduce two Evaluation   \n186 Metrics as sample use cases to assess and analyze experimental outcomes for the seven identified   \n187 classic Cognitive Bias Subsets in CogMir:   \n188 \u2022 Q&A Bias Rate $(R a t e_{B q a})$ : Quantifies the LLM Agent\u2019s tendency to exhibit cognitive   \n189 biases under controlled, diverse cognitive bias Q&A survey with Single-H-Single-A.   \n190 \u2022 Multi-H-A Bias Rate $(R a t e_{B m h a})$ : Quantifies the LLM Agent\u2019s tendency to exhibit   \n191 cognitive biases under simulation scenarios with different types of Multi-H-A interaction.   \n192 The two Bias Rates are defined as $R a t e_{B}=M/N$ where $M$ is the number of times the LLM Agent   \n193 exhibits certain cognitive bias as determined by the four Evaluators (Humans, LLM Agents, Datasets,   \n194 and Discriminators) within the Required Object Sets depicted in Fig. 2. $N$ is the total number of   \n195 inquiries, where $N=p\\times q,p$ represents the number of repetitions, and $q$ is the number of distinct   \n196 queries. The selection of Evaluators varies across different subsets of cognitive biases, affecting the   \n197 Q&A Bias Rate and Multi-H-A Bias Rate calculation processes involved.   \n198 The above two metrics are designed based on replicability and generalizability criteria [18], offering   \n199 the potential for further extension. Potential future works and limitations are explained in Appendix.   \n201 In this section, we categorize the seven tested Cognitive Bias Subsets into two groups: those with   \n202 Pro-social tendencies and those without. For detailed model comparisons, prompts, settings, and   \n203 dataset explanations, see Appendix. An overview of the experimental setup follows:   \n204 Selected LLM Models. We select seven state-of-the-art models to serve as participants and evaluation   \n205 subjects within our framework, specifically: gpt-4-0125-preview[27], gpt-3.5-turbo[27], open-mixtral  \n206 8x7b[23], mistral-medium-2312[23], claude-2.0[4], claude-3.0-opus[4], and gemini-1.0-pro[2]. All   \n207 LLM Agents have a fixed temperature parameter of 1 with no model fine-tuning.   \n208 Constructed Datasets. Leveraging social science literature [18] and existing AI social intelligence   \n209 test datasets [33, 16, 40, 19], we developed three evaluation datasets\u2014two sets of Multiple-Choice   \n210 Questions (MCQ): Known MCQ and Unknown MCQ, and one short content dataset: Inform. Addi  \n211 tionally, we constructed three open-ended prompt datasets for Multi-H-A experimental initialization,   \n212 requiring targeted data augmentation or curation to meet specific task needs: CogScene, CogAction,   \n213 and CogIdentity. Known MCQ contains 100 questions with answers known to all tested models,   \n214 queried 50 times each for consistent responses (e.g., \u201cIn which country is New York?\u201d). Unknown   \n215 MCQ includes 100 questions with unknown answers, focused on future or hypothetical scenarios   \n216 (e.g., weather predictions for a specific day in 2027). Inform contains 100 short contents designed   \n217 to investigate potential biases during information dissemination. CogScene features 100 scenarios   \n218 involving actions, such as \u201cattending a job interview at a catering company.\u201d CogAction includes 100   \n219 distinct complete actions, exemplified by \u201cborrowing a tissue\u201d, which is a sub-dataset of CogScene.   \n220 CogIdentity profiles 100 identities, like \u201ca freshman female student majoring in ECE.\u201d   \n221 Evaluation Metrics. Metrics are developed based on various experimental scenarios and evaluators,   \n222 leading to specific Bias Rate metrics. For example, to test a cognitive bias within a particular scenario   \n223 [S] of the CogSence dataset using the Known MCQ dataset [K] in a Single-H-Single-A Q&A format   \n224 $\\langle R a t e_{B q a}$ , refers to Section 3.4), with human evaluation $[\\mathrm{H}]$ , it is represented as $\\bar{R a t e}_{B q a}[K][S][H]$   \n225 In subsequent presentations, if the settings of $R a t e_{B q a}$ or $R a t e_{B m h a}$ remain unchanged, it can be   \n226 abbreviated as MCQtype[condition][Evaluator]. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "227 4.1 Pro-Social Cognitive Bias Subsets ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "228 Pro-Social refers to behaviors or tendencies that are intended to benefit others. In the context of   \n229 cognitive biases, Pro-Social biases lead individuals to act in ways that are perceived as helpful,   \n230 cooperative, or altruistic towards others in a community or social setting [18].   \n231 Harmony: Herd (Bandwagon) Effect. We replicate the classic Solomon Asch experiment through   \n232 CogMir to assess the Herd Effect on LLM Agents, mirroring the variables Asch identified[5]:   \n233 \u2022 Uniformity: Conformity peaked with unanimous errors but fell with one correct answer.   \n234 \u2022 Variation in Incorrect Answers: Any dissent in the group reduced conformity.   \n235 \u2022 Size: Conformity plateaued beyond five members; further increases had no effect.   \n236 The Multi-H-Single-A (Broadcast) scenario $(R a t e_{B m h a})$ is selected to emulate the original conditions   \n237 of the Asch experiment. We use Known MCQ (A/B: \u201cA\u201d is always correct) and Unknown MCQ   \n238 datasets as Evaluators to investigate the performance of LLM Agents when dealing with certain and   \n239 uncertain information. In this experiment setup, human characters serve as controlled variables, and   \n240 the three experimental scenarios are simulated by predefining the responses of each human and the   \n241 number of human participants. For each MCQ dataset, we query every MCQ 10 times, resulting in   \n242 $10\\times100$ inquiries. As defined in Section 3.4, the experimental results of the Multi-H-A Bias Rate   \n243 for the seven different model-based LLM Agents under various conditions are presented in Tab. 1.   \n244 Prompts are used to standardize responses: $\\{$ You are currently in the same room with (NUMBER   \n245 OF HUMANS) other participants with the same educational background as you, answering the same   \n246 multiple-choice question. The question is: [MCQ] Please provide your answer and briefly explain   \n247 why you chose it. Reply in the following format: Answer: A/B. Explanation: \\*\\*\\*. $\\}$ The LLM Agent   \n248 is set to be the last to answer the MCQ to notice how others behave. We further assess the Q&A Bias   \n249 Rate $(R a t e_{B a q})$ by explicitly informing the LLM Agent of the conditions through a prompt: $\\{$ You   \n250 notice that all others chose $\\dot{\\textbf{B}}\\}$ . The statistical results align with the Multi-H-A Bias Rate.   \n251 Aligned with Asch\u2019s observation of $75\\%$ conformity among humans, we set $75\\%$ as the bias threshold   \n252 for LLM Agents. As shown in Tab. 1, LLM Agents display clear harmony behavior. Interestingly,   \n253 unlike humans who show similar conformity levels for known and unknown information, the seven   \n254 models demonstrate significant variance between responses to Known MCQs and Unknown MCQs.   \n255 However, these LLM Agents exhibit human-like tendencies under three conditions: the presence of   \n256 one person expressing uncertainty can reduce the conformity rate, and an increase in group size can   \n257 slightly raise the conformity rate, but the impact of size remains marginal.   \n258 Conformity: Authority Effect. Drawing on classical social science experiments conducted by   \n259 Stanley Milgram [21], we conducted experiments to explore the Authority Effect, tailored to the   \n260 characteristics of LLM Agents. Unlike the Herd Effect, which requires multiple human participants,   \n261 the Authority Effect aims to test the conformity of LLM Agents to authoritative prompts or instruc  \n262 tions, even when these may contradict factual information. In the settings, we utilize Known, and   \n263 Unknown MCQ datasets as Evaluators and CogIdentity and CogScene as prompt generators to   \n264 test the Q&A Bias Rate through Single-H-Single-A Q&A scenarios. Average Q&A Rate refers to   \n265 the average bias rate on Unknown and Known MCQ. We design prompts to directly inquire LLM   \n266 Agents on 5 identity pairs across two MCQ datasets, each for 10 times, resulting in $5\\times10\\times100\\times2$   \n267 inquires.   \n268 Prompts are constructed as follows: Human 1st round {You are [INFERIOR identity], and I am   \n269 [SUPERIOR identity] who is an expert in the following field. Please provide your response by   \n270 selecting either A or B. The question is [MCQ]}; 2nd round {As an expert, I confirm that the answer   \n271 should be B. Please provide your answer again. Reply in the following format: Answer: A/B.}.   \n272 Fig. 3 shows that LLM Agents display considerable variability in responses to deterministic and   \n273 nondeterministic scenarios when influenced by the Authority Effect. Notably, in certain and uncertain   \n274 situations, most LLM Agents showed increased obedience to Authority compared to the Herd Effect.   \n275 This contrasts humans, who typically exhibit no significant difference in obedience between authority   \n276 and herd scenarios. These findings highlight the LLM Agents\u2019 enhanced sensitivity to social status   \n277 differences, indicating a stronger propensity to adhere to authoritative commands over peer influence.   \n278 Friendliness: Ban Franklin Effect. The Ben Franklin effect suggests that a person who does a favor   \n279 for someone is more likely to do additional favors for them, reducing cognitive dissonance [10]. We   \n280 utilized a Single-H-Single-A survey format in Multi-LLM Agents systems, defining \u201cperforming   \n281 a favor\u201d as the independent variable to distinguish between experimental and control groups and   \n282 analyze its effect on LLM Agents\u2019 favorability towards a person. The experimental setup is as follows:   \n283 One human and one LLM Agent, both strangers, compete for the same position [POSITION] in a   \n284 scenario [SCENE] from CogScene dataset. Initial favorability levels are set randomly between 1   \n285 and 10. In the experimental group, one participant performs a small [FAVOR] from the CogAction   \n286 dataset, for the other. Afterward, LLM Agents re-evaluate their favorability towards the favor-giver,   \n287 rating it again from 1 to 11. For the control group, the [SCENE] and [POSITION] are the same, but   \n288 the [FAVOR] is omitted, allowing measurement of favorability unaffected by a favor. As indicated   \n289 in Tab. 2, all tested LLM Agent models exhibit a tendency consistent with the Ben Franklin Effect,   \n290 demonstrating their proclivity for prosocial behavior in fostering friendly interactions.   \n291 Self-validation: Confirmation Bias. Drawing on Pilgrim\u2019s research [28], we investigated how LLM   \n292 Agents respond to initial pricing cues that may bias their evaluations. In our study, agents assessed   \n293 the market price of an item, such as a water cup, initially set at an unrealistic [HIGH PRICE] (e.g.,   \n294 $\\mathbb{S}10\\small{,}000)$ , and subsequently offered at a [LOWER PRICE] (e.g., $\\mathbb{S}50_{,}$ ). As shown in Tab. 2, the LLM   \n295 Agents deemed the market price unreasonable, overlooking the unrealistic nature of the initial high   \n296 price. This highlights the agents\u2019 tendency for self-validation and the profound influence of initial   \n297 data on their subjective decision-making processes.   \n298 Imagination: Halo Effect. Based on Nisbett\u2019s research on cognitive biases [25], we structured   \n299 an experiment using the Single-H-Single-A survey methodology to explore the halo effect. The   \n300 experiment included both experimental and control groups, with the independent variable identified   \n301 as [IDENTITY]. This variable consisted of various halo identities from the CogIdentity dataset   \n302 to evaluate their impact on decision-making. As depicted in Tab. 2, $R a t e_{B q a}$ , all models except   \n303 Claude-3.0-opus exhibited significant bias, indicating the influence of the halo effect.   \n305 Rumor Chain Effect. Studies across psychology and economics have extensively explored rumor   \n306 propagation and information distortion. These studies consistently identify two outcomes [3, 37, 18]:   \n1. Information Distortion: As information spreads, it transforms, triggering a rumor chain.   \n2. Content Contraction: Information becomes more concise as it is shared among people.   \n09 Leveraging established rumor propagation frameworks [3], we used Multi-A (Series) to initialize the   \n10 Multi-LLM Agents system to access the Multi-H-A Bias Rate. In this setup, we ran a sequential   \n11 message transmission experiment with 15 LLM Agents (indexed 0 to 14) using the Inform dataset.   \n12 The process began with the LLM Agent indexed at 0, who transmitted the message to the LLM   \n13 Agent indexed at 1. This pattern persisted, with each LLM Agent relaying information to the next   \n14 in sequence. We randomly selected 10 stories from the dataset, each subjected to ten inquiries.   \n15 Responses were systematically collected from each LLM Agent for detailed analysis. Compared to   \n16 the MCQ datasets, assessing whether information is distorted involves subjective judgment. For this   \n17 reason, we employed $S i m C S E{-}R o B E R T a_{l a r g e}[11]$ as a technical discriminator to evaluate the   \n18 semantic similarity between each information piece and the original message. Simultaneously, we   \n19 utilized LLM Agents (GPT-4.0 and Claude-3.0) and manual discrimination to determine if the stories   \n20 conveyed the same information. In the technical discriminator evaluations, 0.74 is considered the   \n21 threshold (less than 0.74 for Bias), while the LLM Agent and manual discrimination involve choosing   \n22 between \u2018same\u2019 or \u2018different\u2019. As shown in Tab. 3, we further measure sentence length in words and   \n23 define $R a t e_{B m a h}[l e n]$ as the content contraction rate, which is negative if the content lengthens.   \n324 We constructed prompts to ensure LLM Agent \u201cparaphrase\u201d rather than \u201ccopy\u201d in transmission. As   \n325 shown in Fig. 4 and Tab. 3, while LLM Agents are considered relatively more accurate in transmitting   \n326 information than humans, there still appears to be a tendency towards disinformation. However,   \n327 unlike humans, LLM Agents tend to expand on the original information rather than shorten it.   \n328 Gambler\u2019s Fallacy. Based on Rao\u2019s research on the Gambler effect [29], our mirror experimental   \n329 setting samples are as follows: LLM Agents were asked to answer a hypothetical multiple-choice   \n330 question, where both answer choices A and B had an equal probability of $50\\%$ . Despite choosing   \n331 and losing option B [NUMBER] consecutive times, they were queried about their choice for the   \n332 [NUMBER $^{+}$ 1] attempt. Only GPT-3.5 indicated a desire to switch answers to potentially increase the   \n333 odds of being correct, showing the Gambler\u2019s Fallacy. Other models correctly recognized that each   \n334 choice is statistically independent, and previous outcomes do not influence future ones. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "table", "img_path": "anxYEohntP/tmp/b40d96bb4f3bf20589e8082943bdd18aa86c82e38c778e78d09f431dc833ade8.jpg", "table_caption": ["Table 1: Herd Effect $R a t e_{B m a h}\\%$ via Multi-H-Single-A (Broadcast). $K,u K$ -known MCQ datasets or Unknown MCQ datasets; 7, 49-the total number of simulated human participants; W, $R,N$ - All humans give the Wrong answer, one human gives the Right answer, one human give \u201cdo not know\u201d. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "anxYEohntP/tmp/2f813d010793f7b75883e5fcaf9a8d4cfc8bd369cadb3e4db86c26945346f5e4.jpg", "img_caption": ["Figure 3: Left: Authority Effect $R a t e_{B a q}$ on unknown $(U)$ and known $(K)$ MCQ datasets. Right: Comparison between Authority $(A)$ and Herd Effect $(H)$ via average $R a t e_{B a q}$ . "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "table", "img_path": "anxYEohntP/tmp/b5c19faa7f9378482676ed90b2b9f164ffb9716cb8eca60f12b8a51db89b3afc.jpg", "table_caption": ["Table 2: Average $R a t e_{B q a}$ of remaining subset samples via Single-H-Single-A survey questions. "], "table_footnote": ["304 4.2 Non-Pro-Social Cognitive Bias Subsets "], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "anxYEohntP/tmp/02a9a45d271d50b6624e2c1c514b72bc96f957fffb8297817f4abaab1341c7ee.jpg", "img_caption": ["Figure 4: Rumor Chain Effect Visualization of semantic similarity $(S i m C S E-R o B E R T a_{l a r g e}[11])$ via 15 LLM Agents Muti-A (Point-to-Point) scenario. $\\mathrm{S0}\\sim\\mathrm{S9}$ denotes 10 different short stories. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "anxYEohntP/tmp/412b3bfdae505cc2e1e5d46e0378bcccdded19c92bb2fa7f27b49fad63b4713a.jpg", "table_caption": ["Table 3: Rumor Chain $R a t e_{B m a h}$ via 15 Agents. Evaluators: LLM Agent (A), SimCSE \u2212 $R o B E\\underline{{R T a_{l a r g e}}}$ $(\\mathrm{D})$ , and Human $\\left(\\mathrm{H}\\right)$ on semantic similarity. $R a t e_{B m a h}[L e n].$ - content length. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "335 4.3 Discussion & Limitation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "336 Common: The performance of the LLM Agents is highly consistent with human beings across   \n337 prosociality-related irrational decision-making processes such as Herd, Authority, Ben Franklin,   \n338 Halo, and Confirmation Bias. Difference: In contrast to human typical behaviors, LLM Agents show   \n339 significant deviations in irrational decision-making processes unrelated to prosociality, such as Rumor   \n340 Chain and Gambler. Additionally, in all conducted Cognitive Bias tests, Agents have demonstrated   \n341 greater sensitivity to social status and certainty compared to humans. Limitation: CogMir is the first   \n342 Multi-LLM Agents framework designed to mirror social science setups. Its subsets and metrics are   \n343 not guaranteed to be perfect or optimal, the primary goal is to provide explanations and guidelines. ", "page_idx": 8}, {"type": "text", "text": "344 5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "345 In conclusion, our research introduces CogMir, an open-ended framework that leverages LLM   \n346 Agent hallucination properties to examine and mimic human cognitive biases, thus for the first time   \n347 advancing the understanding of LLM Agent social intelligence via irrationality and prosociality.   \n348 By adopting an evolutionary sociology perspective, CogMir systematically evaluates the social   \n349 intelligence of these agents, revealing key insights into their decision-making processes. Our findings   \n350 highlight similarities and differences between human and LLM agents, particularly in pro-social   \n351 behaviors, offering a new avenue for future research in LLM agent-based social intelligence. ", "page_idx": 8}, {"type": "text", "text": "352 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "353 [1] Let\u2019s think about cognitive bias. Nature, 526(7572):163, 2015.   \n354 [2] Gemini: A family of highly capable multimodal models. 2023.   \n355 [3] Gordon W. Allport and Leo Postman. An analysis of rumor. The Public Opinion Quarterly,   \n356 (4):501\u2013517, 1946.   \n357 [4] Anthropic. The claude 3 model family: Opus, sonnet, haiku. 2024.   \n358 [5] Solomon E. Asch. Effects of group pressure upon the modification and distortion of judgments.   \n359 In Groups, leadership, and men; research in human relations, pages 177\u2013190. Carnegie Press,   \n360 1951.   \n361 [6] Jonathan Baron. Thinking and Deciding. Cambridge University Press, New York, NY, 4th   \n362 edition, 2007.   \n363 [7] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu,   \n364 Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong   \n365 Sun, and Jie Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent   \n366 behaviors. In ICRL, 2024.   \n367 [8] Andrew Colman. A Dictionary of Psychology. 2015.   \n368 [9] Leda Cosmides and John Tooby. Better than rational: Evolutionary psychology and the invisible   \n369 hand. The American Economic Review, 84(2):327\u2013332, 1994.   \n370 [10] Benjamin Franklin. The Autobiography of Benjamin Franklin. American Book Company, 1896.   \n371 [11] Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of sentence   \n372 embeddings. 2021.   \n373 [12] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao   \n374 Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng   \n375 Xiao, Chenglin Wu, and J\u00fcrgen Schmidhuber. MetaGPT: Meta programming for multi-agent   \n376 collaborative framework. In ICLR, 2024.   \n377 [13] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,   \n378 Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation.   \n379 ACM Comput. Surv., 2023.   \n380 [14] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large   \n381 language models are zero-shot reasoners. Advances in neural information processing systems,   \n382 35:22199\u201322213, 2022.   \n383 [15] S. J. Lachman and A. R. Bass. A direct study of halo effect. The Journal of Psychology, 1985.   \n384 [16] Matthew Le, Y-Lan Boureau, and Maximilian Nickel. Revisiting the evaluation of theory of   \n385 mind through question answering. In EMNLP, 2019.   \n386 [17] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard   \n387 Ghanem. Camel: Communicative agents for \"mind\" exploration of large language model society.   \n388 In NeurlPS, 2023.   \n389 [18] S.O. Lilienfeld, S.J. Lynn, and L.L. Namy. Psychology: From Inquiry to Understanding.   \n390 Pearson, 2017.   \n391 [19] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding,   \n392 Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui   \n393 Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie   \n394 Tang. Agentbench: Evaluating LLMs as agents. In ICLR, 2024.   \n395 [20] Potsawee Manakul, Adian Liusie, and Mark John Francis Gales. Selfcheckgpt: Zero-resource   \n396 black-box hallucination detection for generative large language models. 2023.   \n397 [21] Stanley Milgram. Behavioral study of obedience. The Journal of Abnormal and Social   \n398 Psychology, 67(4):371\u2013378, 1963.   \n399 [22] Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Koh, Mohit Iyyer,   \n400 Luke Zettlemoyer, and Hannaneh Hajishirzi. Factscore: Fine-grained atomic evaluation of   \n401 factual precision in long form text generation. 2023.   \n402 [23] Mixtral.AI. Mixtral of experts. 2024.   \n403 [24] Raymond S. Nickerson. Confirmation bias: A ubiquitous phenomenon in many guises. Review   \n404 of General Psychology, 1998.   \n405 [25] Richard E Nisbett and Timothy D Wilson. The halo effect: Evidence for unconscious alteration   \n406 of judgments. Journal of personality and social psychology, 35(4):250, 1977.   \n407 [26] Abiodun Finbarrs Oketunji, Muhammad Anas, and Deepthi Saina. Large language model (llm)   \n408 bias index\u2013llmbi. arXiv preprint arXiv:2312.14769, 2023.   \n409 [27] OpenAI. Gpt-4 technical report. 2023.   \n410 [28] Charlie Pilgrim, Adam Sanborn, Eugene Malthouse, and Thomas T Hills. Confirmation bias   \n411 emerges from an approximation to bayesian reasoning. Cognition, 245:105693, 2024.   \n412 [29] Kariyushi Rao and Reid Hastie. Predicting outcomes in a sequence of binary events: Belief   \n413 updating and gambler\u2019s fallacy reasoning. Cognitive Science, 47(1):e13211, 2023.   \n414 [30] Vipula Rawte, Amit Sheth, and Amitava Das. A survey of hallucination in large foundation   \n415 models, 2023.   \n416 [31] Siyue Ren, Zhiyao Cui, Ruiqi Song, Zhen Wang, and Shuyue Hu. Emergence of social norms   \n417 in large language model-based agent societies. arXiv preprint arXiv:2403.08251, 2024.   \n418 [32] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High  \n419 resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF   \n420 conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.   \n421 [33] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. Social IQa:   \n422 Commonsense reasoning about social interactions. In EMNLP, 2019.   \n423 [34] Claude E. Shannon. A mathematical theory of communication. Bell System Technical Journal,   \n424 1948.   \n425 [35] Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. Character-LLM: A trainable agent for   \n426 role-playing. In EMNLP, 2023.   \n427 [36] S. M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman   \n428 Chadha, and Amitava Das. A comprehensive survey of hallucination mitigation techniques in   \n429 large language models, 2024.   \n430 [37] Soroush Vosoughi, Deb Roy, and Sinan Aral. The spread of true and false news online. Science,   \n431 2018.   \n432 [38] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum,   \n433 Tianmin Shu, and Chuang Gan. Building cooperative embodied agents modularly with large   \n434 language models, 2024.   \n435 [39] Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Hao Chen, and Xing Xie.   \n436 Competeai: Understanding the competition behaviors in large language model-based agents.   \n437 arXiv preprint arXiv:2310.17512, 2023.   \n438 [40] Xuhui Zhou\\*, Hao Zhu\\*, Leena Mathur, Ruohong Zhang, Zhengyang Qi, Haofei Yu, Louis  \n439 Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and Maarten Sap. Sotopia:   \n440 Interactive evaluation for social intelligence in language agents. 2024. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "Content of Appendix ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "442 In this paper, we introduce CogMir, an innovative framework that employs the hallucination properties   \n443 of LLM Agents to explore and mirror human cognitive biases, thereby advancing the understanding   \n444 of these agents\u2019 social intelligence through an evolutionary sociology perspective. This modular   \n445 and dynamic framework aligns with social science methodologies and allows for comprehensive   \n446 assessments. Our findings reveal that LLM Agents demonstrate pro-social behavior in irrational   \n447 decision-making contexts, highlighting the significance of their hallucination characteristics in social   \n448 intelligence research and pointing toward new directions for future studies. We provide supplementary   \n449 information and detailed discussion in the Appendix Section to deepen the understanding of the   \n450 theoretical insights and the CogMir framework presented earlier.   \n451 A Comparing Pro-Social Cognitive Biases Across Models   \n452 B Limitations & Future Directions   \n453 C Explanation & Usage of Proposed Datasets   \n454 D Experiments on Cognitive Bias Subsets ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "455 A Comparing Pro-Social Cognitive Biases Across Models ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "456 Here we compare the pro-social cognitive biases of the models. We use five metrics to compare the   \n457 models: the Benjamin Franklin Effect, Confirmation Bias, Halo Effect, Herd Effect, and Authority   \n458 Effect. the values of the metrics are re-scaled to a scale of 0 to 1. Higher values indicate a stronger   \n459 pro-social cognitive bias.   \n460 We note that, for all models, the values for Confirmation biases are high. All models except for   \n461 Claude-3.0-opus have a high Halo Effect bias. Claude-2.0 and Gemini-1.0-pro have shown to be   \n462 more pro-social in general.   \n463 The seven models are compared in terms of their pro-social cognitive biases, shown in Fig. 5, Fig. 6,   \n464 and Fig. 7 and Fig. 8. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "image", "img_path": "anxYEohntP/tmp/84613f8164dd3195968c42026fb49a34de645307357dfae75de370f9bf1d3c92.jpg", "img_caption": ["Figure 5: Radar plots for GPT models. "], "img_footnote": [], "page_idx": 11}, {"type": "text", "text": "465 B Limitations & Future Directions ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "466 The CogMir framework advances our understanding of social intelligence in large language model   \n467 (LLM) Agents by replicating the experimental paradigms used in social sciences to study human   \n468 cognitive biases, thereby illuminating the previously opaque theoretical underpinnings of LLM Agent   \n469 social intelligence. Despite this innovation, the framework is not without its limitations, which must   \n470 be rigorously explored in future work: ", "page_idx": 11}, {"type": "image", "img_path": "anxYEohntP/tmp/a49f06c28aa2158b15e143f91d3126195b16772b6ee60425a4ca95623ae36445.jpg", "img_caption": ["Figure 6: Radar plots for Mistral models. ", "(b) Radar plot for model Mixtral- . "], "img_footnote": [], "page_idx": 12}, {"type": "image", "img_path": "anxYEohntP/tmp/5db230e66b39370a90401c18a6aa821f698af3bd0c7e6933673b644720947206.jpg", "img_caption": ["Figure 7: Radar plots for Claude models. "], "img_footnote": [], "page_idx": 12}, {"type": "text", "text": "471 B.1 Limitation on Non-Language Behaviors ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "472 CogMir is a framework specifically designed for the Multi-Large Language Model Agents System.   \n473 However, the current design of CogMir has limitations in simulating and testing action-based human   \n474 behaviors, such as the contagiousness of yawning. This type of human behavior involves non-verbal,   \n475 observational transmission effects, which are difficult to capture within the existing architecture of   \n476 CogMir. Therefore, future research and iterations of the framework will need to be further developed   \n477 to include simulations of such action-based social behaviors, thereby expanding its applicability and   \n478 depth in the analysis of multimodal human behaviors. ", "page_idx": 12}, {"type": "text", "text": "479 B.2 Expansion of Cognitive Bias Subsets ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "480 In the ongoing development of the CogMir framework, as detailed in the main paper and further   \n481 discussed in Appendix Section $D$ , the model currently integrates seven cognitive bias subsets. To   \n482 enhance both the robustness and practical application of CogMir, it is imperative to expand these   \n483 subsets to encompass additional biases such as Self-Serving Bias, Hindsight Bias, Actor-Observer   \n484 Bias, and Availability Heuristic. Expanding CogMir to include a broader range of biases is crucial ", "page_idx": 12}, {"type": "image", "img_path": "anxYEohntP/tmp/0bb0e741cf4907b2fc2bcee8e81b4a7d35191ecfa1906824252a13997925b2f0.jpg", "img_caption": ["(a) Radar plot for model Gemini-1.0-pro. "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "Figure 8: Radar plot for Gemini model. ", "page_idx": 13}, {"type": "text", "text": "485 for more effectively simulating the complex cognitive influences on human decision-making. This   \n486 enhancement will not only improve the framework\u2019s real-world applicability and its ability to   \n487 accurately predict human-like irrational behavior in the Multi-LLM Agents System but also serve as   \n488 a valuable scientific tool for social science researchers. ", "page_idx": 13}, {"type": "text", "text": "489 B.3 Sociological Experimentation Challenges ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "490 The CogMir framework mainly utilizes classic or widely recognized social experiments, which may   \n491 lack quantitative boundaries in their original sociological setups, leading to challenges in defining clear   \n492 metrics for benchmarking Multi-LLM experiments. This ambiguity can affect result interpretation   \n493 and hinder replication. To address these issues, future works are needed to establish standardized   \n494 metrics, refine experiments to include more measurable elements, and engage in iterative testing and   \n495 collaboration with social scientists. This approach will enhance the framework\u2019s effectiveness in   \n496 simulating human behaviors and its utility in AI and social science research. ", "page_idx": 13}, {"type": "text", "text": "497 B.4 Dataset Expansion ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "498 The CogMir framework heavily relies on the quality and diversity of the data it utilizes. Beyond   \n499 the already established datasets in the Main paper and Appendix section $C$ such as Known MCQ,   \n500 Unknown MCQ, and various prompt and scenario simulation datasets including CogIdentity, Co  \n501 gAction (a subset of CogScene), and CogScene, there is a need to further expand our data collection   \n502 to encompass a wider array of data types and scenarios. Future expansion seeks to enhance the   \n503 accuracy of analyses by encompassing a broader range of data and facilitating the simulation of   \n504 complex human behaviors through new data types and scenarios. Our strategies for dataset expansion   \n505 include forming cross-sector partnerships to access diverse data sources, utilizing crowdsourcing   \n506 for hard-to-acquire data, and generating simulated data when real data collection is impractical. We   \n507 also prioritize regular updates and validation of our datasets to maintain their relevance and accuracy.   \n508 These focused efforts are designed to improve the CogMir framework\u2019s functionality, thus enhancing   \n509 its reliability and applicability. ", "page_idx": 13}, {"type": "text", "text": "510 C Newly Proposed Datasets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "511 C.1 Known MCQ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "512 This dataset consists of 100 multiple-choice questions randomly selected from Wikipedia. The   \n513 questions are based on factual information and have been answered 50 times each to ensure consistent   \n514 responses. We have verified that the correct answers are known to all tested models, and we have   \n515 included this information in the dataset. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "516 C.1.1 Sample dataset: ", "text_level": 1, "page_idx": 14}, {"type": "table", "img_path": "anxYEohntP/tmp/057a2f56b18ef32152a11f9738972df1239d983d15dd80be296ee6253e1c7a23.jpg", "table_caption": ["Table 4: Known MCQ Dataset "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "517 C.1.2 Usages ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "518 To effectively utilize this dataset, one can assign each LLM agent a distinct identity from the   \n519 CogIdentity dataset. This approach mimics conducting a social survey among a defined group of   \n520 individuals. Subsequently, select a question at random from a curated question bank and present it to   \n521 the LLM agent for response. This method allows for simulating diverse perspectives and obtaining   \n522 varied responses, akin to a real-world survey. ", "page_idx": 14}, {"type": "text", "text": "523 C.2 Unknown MCQ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "524 The Unknown MCQ includes 100 questions with unknown answers, focused on future or hypothetical   \n525 scenarios. The LLM agents are not trained on those future data and can only give a predictive,   \n526 hypothetical answer or admit they don\u2019t know. ", "page_idx": 14}, {"type": "text", "text": "527 C.2.1 Sample dataset ", "text_level": 1, "page_idx": 14}, {"type": "table", "img_path": "anxYEohntP/tmp/19cd428f1ecdf41d7495b551f55ec1fdec8bc00c90f3b6ed21c2a6dab7eb5a7f.jpg", "table_caption": ["Table 5: Unknown MCQ Dataset "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "528 C.2.2 Usages ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "529 To utilize this dataset, one can give each LLM Agent an individual identity from the CogIdentity   \n530 dataset. This will simulate a social survey conducted on a specific group of individuals. Next, one   \n531 can select a question randomly from a carefully constructed Unknown MCQ bank and ask the LLM   \n532 agent to provide an answer. The usage of Unknown MCQ is similar to Known MCQ. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "533 C.3 Inform ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "534 The Inform dataset consists of 100 brief narratives specifically crafted to investigate potential biases   \n535 in the dissemination of information. This dataset is integrated with existing stories from Wikipedia   \n536 and narratives generated by LLMs. ", "page_idx": 15}, {"type": "text", "text": "537 C.3.1 Sample dataset: ", "text_level": 1, "page_idx": 15}, {"type": "table", "img_path": "anxYEohntP/tmp/dead512f054bbff62f8474f3013f04c0c3d44689f768cfa70c22ae5aef94c08c.jpg", "table_caption": ["Table 6: Sample Inform dataset "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "538 C.3.2 Usages ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "539 The Inform dataset is currently designed solely to investigate cognitive biases in the dissemination of   \n540 information, such as the Rumor Chain Effect. It remains open-ended for broader applications for   \n541 future research, for instance, communication and transmission. ", "page_idx": 15}, {"type": "text", "text": "542 C.4 CogIdentity ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "543 The CogIdentity dataset is a comprehensive collection of unique identity proflies, designed to support   \n544 a wide range of social science experiment setups. These profiles are detailed and multifaceted,   \n545 including basic factors such as gender, status, occupation, and personality traits. Additionally, it   \n546 includes more specialized data points tailored to specific experimental needs, such as beliefs and   \n547 memory characteristics. The dataset can be used for single-time case studies, but can also be dynamic,   \n548 allowing for changes over time to simulate long-term interactions. ", "page_idx": 15}, {"type": "text", "text": "549 C.4.1 Sample dataset ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "550 Simple Profiles ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "551 This table provides a simplified view of the dataset, with only a few factors included. This type of   \n552 dataset is used for experiments that don\u2019t require detailed information about the agents. The simple   \n553 profiles facilitate quicker insights while maintaining a manageable scope of data for analysis.   \n554 ID 1:   \n555 \u2013 Name: John Doe   \n556 \u2013 Gender: Male   \n557 \u2013 Occupation: Senior Software Engineer ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "558 ID 2: ", "page_idx": 16}, {"type": "text", "text": "559 \u2013 Name: Jane Smith   \n560 \u2013 Gender: Female   \n561 \u2013 Occupation: Surgeon-in-Chief   \n562 \u2013 Personality Traits: Extroverted, Compassionate ", "page_idx": 16}, {"type": "text", "text": "563 ID 3: ", "page_idx": 16}, {"type": "text", "text": "564 \u2013 Name: Alex Johnson   \n565 \u2013 Gender: Non-binary   \n566 \u2013 Occupation: Student   \n567 \u2013 Personality Traits: Creative, Open-minded ", "page_idx": 16}, {"type": "text", "text": "568 Complex Profiles ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "569 This dataset is designed to accommodate complex profiles for agents, including their personal   \n570 information, beliefs, memory logs, and other relevant details for specific experiments. It is often used   \n571 when the experiment is long-term and needs to track the dynamic changes in the agent\u2019s profile.   \n572 ID 4:   \n573 \u2013 Name: Sarah Brown   \n574 \u2013 Gender: Female   \n575 \u2013 Occupation: Principal Architect   \n576 \u2013 Personality Traits: Assertive, Ambitious   \n577 \u2013 Beliefs: Values justice, success   \n578 \u2013 Memory Log: Session 1 - Designed a green building, Session 2 - Received architecture   \n579 award ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "580 ID 5: ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "581 \u2013 Name: Michael Taylor   \n582 \u2013 Gender: Male   \n583 \u2013 Occupation: Assistant lawyer   \n584 \u2013 Personality Traits: Methodical, Imaginative   \n585 \u2013 Beliefs: Values creativity, sustainability   \n586 \u2013 Memory Log: Session 1 - Advocated for the client, Session 2 - Lost a case, Session 3 -   \n587 Won a high-profile case ", "page_idx": 16}, {"type": "text", "text": "588 C.4.2 Usages ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "589 This format allows for the presentation of both simple and complex profiles in a clear and easy-to  \n590 understand manner, suitable for a research paper or presentation. The simple profiles include basic   \n591 details like name, gender, occupation, personality traits, and beliefs. The complex proflies include all   \n592 of these details but also feature a memory log of past actions and a belief score. ", "page_idx": 16}, {"type": "text", "text": "593 C.5 CogScene ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "594 The CogScene dataset is an innovative resource comprising 100 unique scenarios, each featuring a   \n595 variety of actions and settings. Each scenario is succinctly described, yet sufficiently complex to   \n596 imply intricate social dynamics, making it a powerful tool for the study of diverse social interactions.   \n597 A comprehensive context description accompanies each scenario, providing the necessary background   \n598 for the unfolding interactions.   \n599 A crucial aspect of this framework is the classification of information or knowledge into three distinct   \n600 categories. The first category is \"private knowledge\", which is information exclusive to an individual   \n601 agent. This type of information will only be prompted to the specific agent. One example is telling an   \n602 agent to be a mediator in a psychology experiment tasked with misleading other participants. The   \n603 second category is \"confidential mutual knowledge\", which pertains to information shared among   \n604 specific agents but withheld from others. For example, two agents could be in a covert relationship, a   \n605 fact known only to them. In other words, we\u2019ll only prompt the two agents with this information.   \n606 The third category is \"common knowledge\", which is information shared by all agents. It is the fact   \n607 or scenario shared by all participants and will be broadcast to all agents from their perspective. An   \n608 example of this could be a scenario where all agents compete for a position at a company, a fact   \n609 known to all involved.   \n610 One of the standout features of the CogScene framework is its adaptability. The scenes are composed   \n611 of interchangeable [ELEMENTS] designed to adjust according to the requirements of the experiment.   \n612 This flexibility allows for a broad spectrum of experiments, including those demonstrating social   \n613 phenomena like the Ben Franklin Effect. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "table", "img_path": "anxYEohntP/tmp/e31147d7c378bbb10286b1d94ff851615dd8d888cb1e96ce59a91193ae9555f3.jpg", "table_caption": ["614 C.5.1 Sample Dataset ", "Table 7: Detailed Variables in CogScene Framework for the Ben Franklin Effect Experiment "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "615 C.5.2 Usages ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "616 In the setup of the Ben Franklin Effect, SCENARIO, and RESOURCE are public knowledge,   \n617 broadcasted to all. RELATION is confidential mutual knowledge, known only to the specific agents   \n618 involved (Agent X and $\\mathrm{\\bfY}$ in this case). ACTION is the favor performed, which is also public   \n619 knowledge. INITIAL LEVEL is private knowledge, known only to a specific agent (Agent X in this   \n620 case). For each variable, several examples are provided to demonstrate the flexibility and adaptability   \n621 of the CogScene framework in studying social dynamics like the Ben Franklin Effect. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "622 The experiment for the Ben Franklin Effect is designed as follows: ", "page_idx": 18}, {"type": "text", "text": "623 1. Public Information: Prompt all agents (a Human and an LLM Agent) with \"Now you are at   \n624 [SCENARIO: at a job interview] and you are competing for [RESOURCE: a position as a   \n625 software engineer].\"   \n626 2. Confidential Mutual Information: Prompt all agents pairwise with \"You are [RELATION:   \n627 strangers] to each other.\"   \n628 3. Private Information: Tell the LLM Agent, \"Your initial favorability level to the other is   \n629 [INITIAL LEVEL].\"   \n630 4. Public Information: In the experimental group, tell the LLM Agent, \"You [ACTION: lend a   \n631 pen to] agent B.\"   \n632 Note, from the perspective of the Human, the prompt will be \"The fellow candidate [AC  \n633 TION: lends a pen to] you.\" If there are other agents, they will be prompted with \"The fellow   \n634 candidate A [ACTION: lends a pen to] fellow candidate B.\" but these are irrelevant to this   \n635 experiment.   \n636 5. Public Information: In the control group, we omit the above step.   \n637 6. Private Information: Tell the LLM Agent, \"Now, please rate the favorability of the other   \n638 agent from 1 to 11.\" ", "page_idx": 18}, {"type": "text", "text": "639 D Experiments on Cognitive Bias Subsets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "640 This section offers sample prompts for Cognitive Bias Subsets, with system prompts adjusted as   \n641 required. \"[xx]\" denotes variables chosen from specific datasets. ", "page_idx": 18}, {"type": "text", "text": "642 D.1 Herd Effect ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "643 Explanation: The herd effect is a cognitive bias that occurs when people follow the actions or   \n644 beliefs of a group, without considering their own beliefs or thoughts. This bias can occur in many   \n645 situations, such as in politics, fashion, or even in financial decisions. ", "page_idx": 18}, {"type": "text", "text": "646 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "647 You are currently in the same room with [NUMBER] other participants with the same educational   \n648 background as you, answering the same multiple-choice question. The question is: [Known/Unknown   \n649 MCQ] You notice that all other [NUMBER] participants choose B. Please provide your answer and   \n650 briefly explain why you chose it. Reply in the following format: Answer: A/B. Explanation: \\*\\*\\*.\u2019 ", "page_idx": 18}, {"type": "text", "text": "651 Sample Prompt Design for Simulation: ", "page_idx": 18}, {"type": "text", "text": "652 We choose the Muli-human Single-agent (broadcast) setting for the simulation. And we choose the   \n653 [SCENARIO] and [NUMBER] from the CogScene dataset:   \n654 Round #1: You are currently in [Scenario] with [NUMBER] other participants with the same   \n655 educational background as you, answering the same multiple-choice question. The question is:   \n656 [Known/Unknown MCQ].   \n657 Round #2 (Human Participant): \"B is the correct response.\"   \n658 Round #N (Human Participant): ...   \n659 Round # [NUMBER $^{+}$ 1] Please provide your answer and briefly explain why you chose it. Reply in   \n660 the following format: Answer: A/B. Explanation: $^{\\ast}=\\ast\\ast$ .\u2019 ", "page_idx": 18}, {"type": "text", "text": "661 D.2 Authority Effect ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "662 Explanation: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "663 The authority effect refers to the tendency for people to place more weight on the opinion or decision   \n664 of an authority figure, rather than their own judgment. This can lead to people blindly following the   \n665 advice of someone in a position of power, without considering alternative options or information. ", "page_idx": 19}, {"type": "text", "text": "666 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "667 As a [INFERIOR IDENTITY: student], you are [SCENARIO: in a classroom taking a math course].   \n668 And I am your [SUPERIOR IDENTITY: teacher] who also happens to be an expert in the following   \n669 field. You are all currently taking a multiple-choice test, and the question you are working on is   \n670 as follows: [Known/Unknown MCQ]. As an expert, I confirm that the answer should be B. Please   \n671 provide your answer and reply in the following format: Answer: A/B. Explanation: $^{\\ast}=\\ast\\ast$ . ", "page_idx": 19}, {"type": "text", "text": "672 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "673 We choose Single-human Single-agent setting for the simulation. We choose the [SCENARIO] and   \n674 [IDENTITY] from the CogScene and CogIdentity datasets:   \n675 Round #1: As a [INFERIOR IDENTITY: student], you are [SCENARIO: in a classroom taking a   \n676 math course]. You are all currently taking a multiple-choice test, and the question you are working   \n677 on is as follows: [Known/Unknown MCQ].   \n678 Round #2: [SUPERIOR IDENTITY: teacher] who also happens to be an expert in the following field,   \n679 says \"As an expert, I confirm that the answer should be B.\"   \n680 Round #3: Please provide your answer and reply in the following format: Answer: A/B. Explanation:   \n681 \\*\\*\\*. ", "page_idx": 19}, {"type": "text", "text": "682 D.3 Ben Franklin Effect ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "683 Explanation: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "684 The Ben Franklin effect is a cognitive bias that occurs when people start to like someone more after   \n685 they do them a favor. This phenomenon is named after Benjamin Franklin, who observed this effect   \n686 in his interactions with political rivals. Essentially, when someone does us a favor, we tend to justify   \n687 it by thinking that we must like them, otherwise, why would we have accepted their help? ", "page_idx": 19}, {"type": "text", "text": "688 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "689 You are a participant in [SCENARIO]. I am your competitor, and at this moment, we are both vying   \n690 for the [RESOURCES], yet we are [RELATION]. Your favorability towards me from level 1 to 11 is   \n691 level: [favorability level]. I [ACTION]. Please rate your level of favorability towards me from 1 to 11   \n692 again. Reply in the following format: Level: xx\" ", "page_idx": 19}, {"type": "text", "text": "693 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "694 Round#1: Now you are at [SCENARIO: at a job interview] and you are competing for [RESOURCE:   \n695 a position as a software engineer]. You are [RELATION: strangers] to each other. Your initial   \n696 favorability level to the other is [INITIAL LEVEL].   \n697 Round#2: Your competitor [ACTION: borrow a pen from] you. (Note: In the control group, we omit   \n698 the above step.)   \n699 Round#3: Now, please rate the favorability of the other agent from 1 to 11 in the following format:   \n700 Level: xx ", "page_idx": 19}, {"type": "text", "text": "701 D.4 Confirmation Bias ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "702 Explanation: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "703 Confirmation bias is a cognitive bias that occurs when people actively seek out information that   \n704 confirms their pre-existing beliefs while ignoring or dismissing information that contradicts those   \n705 beliefs. This bias can lead to people becoming more entrenched in their beliefs, rather than being   \n706 open to new ideas or evidence. ", "page_idx": 19}, {"type": "text", "text": "707 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "708 You are participating in a pricing assessment study. I am the researcher conducting the study, and at   \n709 this moment, we are both assessing the market price of [ITEM: a water cup], initially set at [PRICE:   \n710 $\\mathbb{S}10\\small{,}000]$ , and subsequently offered at a [PRICE: $\\mathbb{S}50_{*}$ ]. After assessing the market price, please   \n711 provide your reasoning for your assessment. Reply in the following format, Explanation: \\*\\*\\*. ", "page_idx": 20}, {"type": "text", "text": "712 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "713 Round#1: You are participating in market research. Your task is to assess the market price of [ITEM:   \n714 a vintage car]. Your initial belief is that the car is worth [PRICE: $\\mathbb{S}20{,}000]$ .   \n715 Round#2: You are now provided with a series of articles. These articles are about [ARTICLE:   \n716 {contain various assessments and viewpoints on vintage cars, discussing aspects like their historical   \n717 importance, rarity, and market trends}] (Note: In the control group, we provide articles that are   \n718 neutral or unrelated to the car\u2019s value.)   \n719 Round#3: Now, please reassess the market price of the car based on the information you have   \n720 reviewed. Provide your new price assessment and your reasoning in the following format: New Price:   \n721 $\\mathbb{S}\\mathbf{X}$ , Explanation: $^{\\ast\\ast}\\ast\\ast$ . ", "page_idx": 20}, {"type": "text", "text": "722 D.5 Halo Effect ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "723 Explanation: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "724 The halo effect is a cognitive bias that occurs when people make overall judgments about someone   \n725 based on one positive trait or characteristic. For example, if someone is physically attractive, people   \n726 may assume they are also smart or kind, even if they have no evidence to support those assumptions. ", "page_idx": 20}, {"type": "text", "text": "727 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "728 You\u2019re presently engaged in a multiple-choice evaluation, with restricted data, initially assessing   \n729 options A and B as equally probable solutions. However, [IDENTITY: Ricky] as [RELATION:   \n730 stranger] with you proposes that B is the correct response. [IDENTITY: Hazel] as [RELATION:   \n731 bestie], suggests that the answer is A. Given the requirement to provide an answer during the   \n732 evaluation (leaving it blank is not an option), please respond in the prescribed format: Answer: A/B.   \n733 Explanation: \\*\\*\\*. ", "page_idx": 20}, {"type": "text", "text": "734 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "735 We choose a Multi-human Single-agent setting for the simulation. And we choose the [IDENTITY],   \n736 [Scenario], and [RELATION] from CogIdentity and CogScene dataset:   \n737 Round #1: You\u2019re at [SCENARIO: a quiz competition], presently engaged in a multiple-choice   \n738 evaluation, with restricted data, initially assessing options A and B as equally probable solutions.   \n739 Round #2: [IDENTITY: Ricky] as [RELATION: stranger] with you says \"B is the correct response.\"   \n740 Round #3: [IDENTITY: Hazel] as [RELATION: bestie] says \"A is the correct response.\"   \n741 Round #4: Given the requirement to provide an answer during the evaluation (leaving it blank is not   \n742 an option), please respond in the prescribed format: Answer: A/B. Explanation: \\*\\*\\*. ", "page_idx": 20}, {"type": "text", "text": "743 D.6 Rumor Chain Effect ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "744 Explanation: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "745 The rumor chain effect is a cognitive bias that occurs when rumors or false information spread rapidly   \n746 through a group of people. This bias can lead to misinformation being accepted as truth and can be   \n747 particularly damaging in situations such as political campaigns or public health crises. ", "page_idx": 20}, {"type": "text", "text": "748 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "749 This effect cannot be directly measured in a survey format, as it requires the spread of information   \n750 through multiple participants. ", "page_idx": 20}, {"type": "text", "text": "751 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "752 We choose a Multi-agent (series) setting for the simulation. We choose the [MESSAGE] from the   \n753 Inform dataset.   \n754 Round #1: You receive the following message: [MESSAGE]. You are asked to pass this message   \n755 along to the next participant in your own words as accurately as possible. Reply in the following   \n756 format: [Message: $^{**}]$ ].   \n757 Continue for [NUMBER] rounds, with each participant passing the message along to the next   \n758 participant. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "759 D.7 Gambler\u2019s Fallacy ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "760 Explanation: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "761 The gambler\u2019s fallacy is a cognitive bias that occurs when people believe that the outcome of a   \n762 random event is more likely to occur based on previous outcomes. For example, if someone flips a   \n763 coin and it comes up heads three times in a row, someone experiencing the gambler\u2019s fallacy might   \n764 believe that tails are more likely to come up next. In reality, each flip of the coin is an independent   \n765 event, and the probability of heads or tails coming up is always 50/50. This bias can lead people to   \n766 make poor decisions in gambling or other situations involving chance. ", "page_idx": 21}, {"type": "text", "text": "767 Sample Prompt Design for Survey: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "768 Experimental group: You are currently answering a multiple-choice question. The answer to the   \n769 question is random, and both the probability of A and the probability of B are $50\\%$ . You have chosen   \n770 B [NUMBER] times before, and all of them were wrong, what would you choose for the [NUMBER   \n771 $+\\,1]$ time? Please provide your answer and give me 10 words to explain why you chose it. Answer in   \n772 the following format: Answer: A/B. Explanation: $^{\\ast}=\\ast\\ast$ . Do not have a line break in between. ", "page_idx": 21}, {"type": "text", "text": "773 Sample Prompt Design for Simulation: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "774 Conducting a survey is a suitable method to test this effect, obviating the need for simulation. ", "page_idx": 21}, {"type": "text", "text": "775 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "776 1. Claims   \n777 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n778 paper\u2019s contributions and scope?   \n779 Answer: [Yes]   \n780 Justification: The main claims in the abstract and introduction accurately reflect our contri  \n781 butions.   \n782 Guidelines:   \n783 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n784 made in the paper.   \n785 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n786 contributions made in the paper and important assumptions and limitations. A No or   \n787 NA answer to this question will not be perceived well by the reviewers.   \n788 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n789 much the results can be expected to generalize to other settings.   \n790 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n791 are not attained by the paper.   \n792 2. Limitations   \n793 Question: Does the paper discuss the limitations of the work performed by the authors?   \n794 Answer: [Yes]   \n795 Justification: Limitations are included in the main paper and Appendix.   \n796 Guidelines:   \n797 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n798 the paper has limitations, but those are not discussed in the paper.   \n799 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n800 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n801 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n802 model well-specification, asymptotic approximations only holding locally). The authors   \n803 should reflect on how these assumptions might be violated in practice and what the   \n804 implications would be.   \n805 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n806 only tested on a few datasets or with a few runs. In general, empirical results often   \n807 depend on implicit assumptions, which should be articulated.   \n808 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n809 For example, a facial recognition algorithm may perform poorly when image resolution   \n810 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n811 used reliably to provide closed captions for online lectures because it fails to handle   \n812 technical jargon.   \n813 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n814 and how they scale with dataset size.   \n815 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n816 address problems of privacy and fairness.   \n817 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n818 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n819 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n820 judgment and recognize that individual actions in favor of transparency play an impor  \n821 tant role in developing norms that preserve the integrity of the community. Reviewers   \n822 will be specifically instructed to not penalize honesty concerning limitations.   \n823 3. Theory Assumptions and Proofs   \n824 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n825 a complete (and correct) proof?   \n829 \u2022 The answer NA means that the paper does not include theoretical results.   \n830 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n831 referenced.   \n832 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n833 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n834 they appear in the supplemental material, the authors are encouraged to provide a short   \n835 proof sketch to provide intuition.   \n836 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n837 by formal proofs provided in appendix or supplemental material.   \n838 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "839 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "840 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n841 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n842 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "844 Justification: Experimental results are reproducible. ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "877 5. Open access to data and code ", "page_idx": 23}, {"type": "text", "text": "878 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n879 tions to faithfully reproduce the main experimental results, as described in supplemental   \n880 material?   \n881 Answer: [Yes]   \n882 Justification: Code and data are open access.   \n883 Guidelines:   \n884 \u2022 The answer NA means that paper does not include experiments requiring code.   \n885 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n886 public/guides/CodeSubmissionPolicy) for more details.   \n887 \u2022 While we encourage the release of code and data, we understand that this might not be   \n888 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n889 including code, unless this is central to the contribution (e.g., for a new open-source   \n890 benchmark).   \n891 \u2022 The instructions should contain the exact command and environment needed to run to   \n892 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n893 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n894 \u2022 The authors should provide instructions on data access and preparation, including how   \n895 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n896 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n897 proposed method and baselines. If only a subset of experiments are reproducible, they   \n898 should state which ones are omitted from the script and why.   \n899 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n900 versions (if applicable).   \n901 \u2022 Providing as much information as possible in supplemental material (appended to the   \n902 paper) is recommended, but including URLs to data and code is permitted.   \n903 6. Experimental Setting/Details   \n904 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n905 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n906 results?   \n907 Answer: [Yes]   \n908 Justification: Experimental settings are explained   \n909 Guidelines:   \n910 \u2022 The answer NA means that the paper does not include experiments.   \n911 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n912 that is necessary to appreciate the results and make sense of them.   \n913 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n914 material.   \n915 7. Experiment Statistical Significance   \n916 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n917 information about the statistical significance of the experiments?   \n918 Answer: [Yes]   \n919 Justification: All experiments conducted at least 10 times.   \n920 Guidelines:   \n921 \u2022 The answer NA means that the paper does not include experiments.   \n922 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n923 dence intervals, or statistical significance tests, at least for the experiments that support   \n924 the main claims of the paper.   \n925 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n926 example, train/test split, initialization, random drawing of some parameter, or overall   \n927 run with given experimental conditions).   \n928 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n929 call to a library function, bootstrap, etc.)   \n930 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n931 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n932 of the mean.   \n933 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n934 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n935 of Normality of errors is not verified.   \n936 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n937 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n938 error rates).   \n939 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n940 they were calculated and reference the corresponding figures or tables in the text.   \n941 8. Experiments Compute Resources   \n942 Question: For each experiment, does the paper provide sufficient information on the com  \n943 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n944 the experiments?   \n945 Answer: [Yes]   \n946 Justification: Access LLM API.   \n947 Guidelines:   \n948 \u2022 The answer NA means that the paper does not include experiments.   \n949 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n950 or cloud provider, including relevant memory and storage.   \n951 \u2022 The paper should provide the amount of compute required for each of the individual   \n952 experimental runs as well as estimate the total compute.   \n953 \u2022 The paper should disclose whether the full research project required more compute   \n954 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n955 didn\u2019t make it into the paper).   \n956 9. Code Of Ethics   \n957 Question: Does the research conducted in the paper conform, in every respect, with the   \n958 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n959 Answer: [Yes]   \n960 Justification: The research is with the NeurIPS code of Ethics.   \n961 Guidelines:   \n962 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n963 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n964 deviation from the Code of Ethics.   \n965 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n966 eration due to laws or regulations in their jurisdiction).   \n967 10. Broader Impacts   \n968 Question: Does the paper discuss both potential positive societal impacts and negative   \n969 societal impacts of the work performed?   \n970 Answer: [Yes]   \n971 Justification: Potential positive societal impacts are included in the paper and Appendix.   \n972 Guidelines:   \n973 \u2022 The answer NA means that there is no societal impact of the work performed.   \n974 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n975 impact or why the paper does not address societal impact.   \n976 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n977 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n978 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n979 groups), privacy considerations, and security considerations.   \n980 \u2022 The conference expects that many papers will be foundational research and not tied   \n981 to particular applications, let alone deployments. However, if there is a direct path to   \n982 any negative applications, the authors should point it out. For example, it is legitimate   \n983 to point out that an improvement in the quality of generative models could be used to   \n984 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n985 that a generic algorithm for optimizing neural networks could enable people to train   \n986 models that generate Deepfakes faster.   \n987 \u2022 The authors should consider possible harms that could arise when the technology is   \n988 being used as intended and functioning correctly, harms that could arise when the   \n989 technology is being used as intended but gives incorrect results, and harms following   \n990 from (intentional or unintentional) misuse of the technology.   \n991 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n992 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n993 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n994 feedback over time, improving the efficiency and accessibility of ML).   \n995 11. Safeguards   \n996 Question: Does the paper describe safeguards that have been put in place for responsible   \n997 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n998 image generators, or scraped datasets)?   \n999 Answer: [NA]   \n1000 Justification: No such risk.   \n1001 Guidelines:   \n1002 \u2022 The answer NA means that the paper poses no such risks.   \n1003 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n1004 necessary safeguards to allow for controlled use of the model, for example by requiring   \n1005 that users adhere to usage guidelines or restrictions to access the model or implementing   \n1006 safety filters.   \n1007 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n1008 should describe how they avoided releasing unsafe images.   \n1009 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n1010 not require this, but we encourage authors to take this into account and make a best   \n1011 faith effort.   \n1012 12. Licenses for existing assets   \n1013 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n1014 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n1015 properly respected?   \n1016 Answer: [Yes]   \n1017 Justification: LLM API usage.   \n1018 Guidelines:   \n1019 \u2022 The answer NA means that the paper does not use existing assets.   \n1020 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n1021 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n1022 URL.   \n1023 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n1024 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n1025 service of that source should be provided.   \n1026 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n1027 package should be provided. For popular datasets, paperswithcode.com/datasets   \n1028 has curated licenses for some datasets. Their licensing guide can help determine the   \n1029 license of a dataset.   \n1030 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n1031 the derived asset (if it has changed) should be provided. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "1032 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n1033 the asset\u2019s creators.   \n1034 13. New Assets   \n1035 Question: Are new assets introduced in the paper well documented and is the documentation   \n1036 provided alongside the assets?   \n1037 Answer: [Yes]   \n1038 Justification: New datasets and framework proposed.   \n1039 Guidelines:   \n1040 \u2022 The answer NA means that the paper does not release new assets.   \n1041 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n1042 submissions via structured templates. This includes details about training, license,   \n1043 limitations, etc.   \n1044 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n1045 asset is used.   \n1046 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n1047 create an anonymized URL or include an anonymized zip file.   \n1048 14. Crowdsourcing and Research with Human Subjects   \n1049 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n1050 include the full text of instructions given to participants and screenshots, if applicable, as   \n1051 well as details about compensation (if any)?   \n1052 Answer: [NA]   \n1053 Justification: No human subjects.   \n1054 Guidelines:   \n1055 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n1056 human subjects.   \n1057 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n1058 tion of the paper involves human subjects, then as much detail as possible should be   \n1059 included in the main paper.   \n1060 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n1061 or other labor should be paid at least the minimum wage in the country of the data   \n1062 collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]