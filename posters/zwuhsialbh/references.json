{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This paper is foundational to the field of instruction following for LLMs, introducing the RLHF method that the current paper builds upon and analyzes for factual accuracy improvements."}, {"fullname_first_author": "Yuntao Bai", "paper_title": "Training a helpful and harmless assistant with reinforcement learning from human feedback", "publication_date": "2022-04-27", "reason": "This paper is highly influential as it establishes a key methodology for aligning LLMs with human values, a process the current research extends to specifically address factual accuracy."}, {"fullname_first_author": "Sewon Min", "paper_title": "FActScore: Fine-grained atomic evaluation of factual precision in long-form text generation", "publication_date": "2023-07-01", "reason": "This paper introduces FACTSCORE, a crucial metric for evaluating factuality in LLM outputs that is used extensively in this current work to assess model performance."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-18", "reason": "This paper introduces the Llama 2 model, the base LLM used in the current study, providing essential context for understanding the model's capabilities and limitations in relation to factual accuracy."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is a foundational work demonstrating the few-shot learning capabilities of LLMs, which is implicitly leveraged in the current paper's methods and is important for understanding the baseline capabilities of the models."}]}