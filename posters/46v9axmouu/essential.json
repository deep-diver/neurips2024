{"importance": "This paper is crucial because **it addresses the critical issue of model generalization in automatic prompt optimization (APO) for text-to-image models.**  Current APO methods struggle to adapt to new, unseen models. This work introduces a novel solution, improving efficiency and reducing the need for retraining when new models are released. This advancement is highly relevant to researchers working on prompt engineering, diffusion models, and large language model applications. The proposed method opens avenues for more robust and efficient approaches to text-to-image generation. ", "summary": "AP-Adapter boosts text-to-image diffusion model generalization by using a two-stage prompt optimization method that leverages large language models and inter-model differences.", "takeaways": ["AP-Adapter, a two-stage prompt optimization method, significantly improves generalization of automatic prompts on unseen text-to-image diffusion models.", "The method uses a large language model to rewrite prompts and constructs an enhanced representation space by leveraging inter-model differences to improve generalization.", "Experiments show AP-Adapter's ability to generate high-quality images with consistent semantics across various unseen models."], "tldr": "Most existing Automatic Prompt Optimization (APO) methods for text-to-image generation are model-specific, hindering their use with newly emerging models.  This necessitates retraining the APO method for each new model, a time-consuming and inefficient process. This paper introduces the problem of Model-Generalized Automatic Prompt Optimization (MGAPO), focusing on training APO methods that generalize well to unseen models. \nThe paper proposes AP-Adapter, a two-stage method that addresses MGAPO.  The first stage uses a large language model for prompt rewriting.  The second stage constructs an enhanced representation space using inter-model differences, creating domain prototypes that adapt prompt representations for various models.  Experiments demonstrate that AP-Adapter significantly improves both semantic consistency and image quality compared to existing methods, even on unseen models.  This method shows the potential for generating high-quality images effectively and efficiently across different diffusion models.", "affiliation": "State Key Laboratory for Novel Software Technology, Nanjing University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Text Generation"}, "podcast_path": "46V9axmOuU/podcast.wav"}