[{"figure_path": "WCc440cUhX/tables/tables_4_1.jpg", "caption": "Table 2: Top-1 accuracy of optimal rule. We look at the average top-1 accuracy of the optimal rule versus LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random validation stories (around 22K tokens total). Model size: 160M.", "description": "This table presents the top-1 accuracy of the optimal rule compared to the LLM predictions. The optimal rule is selected based on the minimum average distance between LLM predictions and rule predictions for rules of varying strength and context length. The results are averaged across 100 random validation stories and the model size is 160M.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_9_1.jpg", "caption": "Table 2: Top-1 accuracy of optimal rule. We look at the average top-1 accuracy of the optimal rule versus LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random validation stories (around 22K tokens total). Model size: 160M.", "description": "This table presents the top-1 accuracy results comparing the optimal rule's predictions against the LLM's predictions.  The accuracy is calculated for different rule complexities (context lengths from 1 to 7) and three different rule types (all, subgram, suffix). A baseline using a simple backoff method is also included. The results are averaged across 100 validation stories, offering a comprehensive evaluation of the rule's effectiveness in approximating LLM predictions.", "section": "7 Rule Performance"}, {"figure_path": "WCc440cUhX/tables/tables_13_1.jpg", "caption": "Table 3: Model specifications.", "description": "This table presents the architectural hyperparameters of the transformer models used in the experiments.  It shows the number of layers, the number of attention heads, the dimension of the key/value vectors (dkey/dvalue), and the overall model dimension (dmodel) for three different model sizes: 160M, 420M, and 1.4B parameters. These specifications are based on the Chinchilla architecture.", "section": "Experimental Setup"}, {"figure_path": "WCc440cUhX/tables/tables_18_1.jpg", "caption": "Table 4: Optimal rule distance (TinyStories, variational distance). We look at the average optimal rule distance with LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random TinyStories validation stories (around 22K tokens total). Model size: 160M.", "description": "This table shows the average optimal rule distance between the LLM predictions and the rule predictions for different rulesets (Rall, Rsubgram, Rsuffix, and backoffM) and context lengths (1-7). The optimal rule distance measures how well the LLM predictions can be approximated by the rules in each ruleset.  A lower optimal rule distance indicates a better approximation. The data is from 100 random TinyStories validation stories, and the model size is 160M. ", "section": "D.1 TinyStories"}, {"figure_path": "WCc440cUhX/tables/tables_19_1.jpg", "caption": "Table 5: Top-1 accuracy of optimal rule (TinyStories, L\u221e distance). The analogue of Table 2 but with L\u221e distance instead of variational distance for selecting the optimal rule. Model size: 160M.", "description": "This table shows the top-1 accuracy of the optimal rule for different rulesets and context lengths, using the L\u221e distance metric.  It's a comparison to Table 2, which used the variational distance. The model size used was 160M parameters.  The results indicate the performance of using different N-gram rules to predict the next token in the TinyStories dataset.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_19_2.jpg", "caption": "Table 6: Optimal rule distance (TinyStories, L\u221e distance). The analogue of Table 4 but with L\u221e distance instead of variational distance. Model size: 160M.", "description": "This table shows the average optimal rule distance between LLM predictions and optimal rules for different rule strengths and maximum context lengths (1-7 tokens).  The L\u221e distance metric is used instead of the variational distance used in Table 4.  The model size used is 160M.  This table helps to understand how well the predictions made by the language model (LLM) can be approximated by the simple statistical rules defined in the paper, using a different distance metric than Table 4.", "section": "D Rule Performance: Additional Analysis and Examples"}, {"figure_path": "WCc440cUhX/tables/tables_20_1.jpg", "caption": "Table 2: Top-1 accuracy of optimal rule. We look at the average top-1 accuracy of the optimal rule versus LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random validation stories (around 22K tokens total). Model size: 160M.", "description": "This table presents the top-1 accuracy results of using optimal rules to predict the next token, compared to the LLM's predictions.  It shows the average top-1 accuracy across various rule complexities (context lengths) and rule types, providing insights into how well N-gram based rules can approximate transformer predictions. The results are averaged across 100 validation stories, for a 160M parameter model.", "section": "7 Rule Performance"}, {"figure_path": "WCc440cUhX/tables/tables_20_2.jpg", "caption": "Table 4: Optimal rule distance (TinyStories, variational distance). We look at the average optimal rule distance with LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random TinyStories validation stories (around 22K tokens total). Model size: 160M.", "description": "This table shows the average optimal rule distance between the LLM predictions and the rule predictions for rules of varying strength and maximum context length, computed over each token prediction from 100 random validation stories. The model size is 160M.  The table helps to understand how the approximation improves with increasing rule strength.", "section": "D Rule Performance: Additional Analysis and Examples"}, {"figure_path": "WCc440cUhX/tables/tables_20_3.jpg", "caption": "Table 2: Top-1 accuracy of optimal rule. We look at the average top-1 accuracy of the optimal rule versus LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random validation stories (around 22K tokens total). Model size: 160M.", "description": "This table shows the top-1 accuracy of the optimal rule compared to the LLM predictions for different rulesets (Rall, Rsubgram, Rsuffix) and maximum context lengths (M=1 to 7).  The accuracy is averaged over 100 random validation stories and calculated for each token. The model size used is 160M. It demonstrates how the accuracy changes as the complexity of the rule and the amount of context used increase.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_20_4.jpg", "caption": "Table 6: Optimal rule distance (TinyStories, L\u221e distance). The analogue of Table 4 but with L\u221e distance instead of variational distance. Model size: 160M.", "description": "This table shows the average optimal rule distance with LLM predictions for rules of varying strength and maximum context length.  The L\u221e distance is used instead of the variational distance. The average is computed over each token prediction from 100 random TinyStories validation stories. The model size used is 160M.", "section": "D Rule Performance: Additional Analysis and Examples"}, {"figure_path": "WCc440cUhX/tables/tables_20_5.jpg", "caption": "Table 11: TinyStories metrics. How average cross entropy loss, top-1 accuracy, and model distance to the ground truth scale with model size on a holdout set of 100 stories.", "description": "This table shows how the average cross-entropy loss, top-1 accuracy, and model distance to the ground truth change with different model sizes (160M, 420M, and 1.4B parameters) on a held-out set of 100 stories from the TinyStories dataset.  The results demonstrate the impact of model size on performance metrics.", "section": "D.3 Model Scaling"}, {"figure_path": "WCc440cUhX/tables/tables_21_1.jpg", "caption": "Table 12: Wikipedia metrics. How average cross entropy loss, top-1 accuracy, and model distance to the ground truth scale with model size on a holdout set of 10 Wikipedia chunks.", "description": "This table shows how the evaluation metrics (cross-entropy loss, top-1 accuracy, and model distance to ground truth) change with different model sizes (160M, 420M, and 1.4B) on a held-out set of 10 Wikipedia chunks.  It demonstrates the scaling behavior of the model's performance as its size increases.", "section": "D.3 Model Scaling"}, {"figure_path": "WCc440cUhX/tables/tables_21_2.jpg", "caption": "Table 13: Top-1 accuracy of optimal rule with model scale (TinyStories, variational distance). How top-1 accuracy of the optimal rule varies with model size and rule context length. Optimal rule from is selected from Rall using variational distance.", "description": "This table shows the top-1 accuracy of the optimal rule for different model sizes (160M, 420M, and 1.4B parameters) and varying context lengths (1 to 7).  The optimal rule is selected from the Rall ruleset using the variational distance metric.  The results indicate how the top-1 accuracy of the optimal rule changes with increasing model size and context length.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_21_3.jpg", "caption": "Table 14: Optimal rule distance with model scale (TinyStories, variational distance). How optimal rule distance varies with model size and rule context length. Optimal rule is selected from Rall using variational distance.", "description": "This table shows how the minimum distance between an LLM's next-token prediction and the prediction of an optimal rule varies with model size (160M, 420M, 1.4B parameters) and maximum context length (1-7 tokens).  The optimal rule is selected from the set of all possible rules (Rall) based on the variational distance between the LLM and rule predictions.  Lower distances indicate better approximation by the rules.", "section": "D.3 Model Scaling"}, {"figure_path": "WCc440cUhX/tables/tables_21_4.jpg", "caption": "Table 15: Top-1 accuracy of optimal rule with model scale (TinyStories, L\u221e distance). How top-1 accuracy of the optimal rule varies with model size and rule context length. Optimal rule from is selected from Rall using L\u221e distance.", "description": "This table shows the top-1 accuracy of the optimal rule selected from the Rall ruleset using the L\u221e distance metric for different model sizes (160M, 420M, and 1.4B parameters) and context lengths (1 to 7).  The results indicate the performance of using simple N-gram rules to approximate the complex predictions of the transformer model. The accuracy increases with increasing context length and model size, suggesting that larger models with more context are better able to capture the statistical properties of the data and make better predictions.", "section": "D.3 Model Scaling"}, {"figure_path": "WCc440cUhX/tables/tables_21_5.jpg", "caption": "Table 2: Top-1 accuracy of optimal rule. We look at the average top-1 accuracy of the optimal rule versus LLM predictions for rules of varying strength and maximum context length M. We compute this average over each token prediction from 100 random validation stories (around 22K tokens total). Model size: 160M.", "description": "This table shows the top-1 accuracy of the optimal rule compared to the LLM predictions for different rule complexities (context lengths) and different types of rulesets.  The results are averaged over 100 validation stories with a total of approximately 22,000 tokens. The model size used is 160M parameters.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_21_6.jpg", "caption": "Table 7: Top-1 accuracy of optimal rule (Wikipedia, L\u221e distance). We look at the average top-1 accuracy between optimal rule and LLM predictions for rules of varying strength and maximum context length. We compute this average over each token prediction from 10 holdout Wikipedia sequences each consisting of 2048 tokens. Model size: 1.4B.", "description": "This table shows the top-1 accuracy of the optimal rule on the Wikipedia dataset using the L\u221e distance for rule selection.  The results are presented for varying context lengths (1-7) and for three different rule sets (Rall, Rsubgram, and Rsuffix).  A backoff method is included for comparison.  The model size used was 1.4B. The average is computed across each token prediction from 10 heldout sequences, each 2048 tokens long.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_22_1.jpg", "caption": "Table 18: Optimal rule distance with model scale (Wikipedia, variational distance). How optimal rule distance varies with model size and rule context length. Optimal rule is selected from R<sup>M</sup><sub>all</sub> using variational distance.", "description": "This table shows how the average optimal rule distance between LLM predictions and optimal rules changes with different model sizes (160M, 420M, 1.4B parameters) and rule context lengths (1-7 tokens).  The optimal rules are selected using the variational distance.  Lower values indicate better approximation of LLM predictions by the N-gram rules.", "section": "D.3 Model Scaling"}, {"figure_path": "WCc440cUhX/tables/tables_22_2.jpg", "caption": "Table 7: Top-1 accuracy of optimal rule (Wikipedia, L\u221e distance). We look at the average top-1 accuracy between optimal rule and LLM predictions for rules of varying strength and maximum context length. We compute this average over each token prediction from 10 holdout Wikipedia sequences each consisting of 2048 tokens. Model size: 1.4B.", "description": "This table presents the top-1 accuracy of the optimal rule, comparing it against LLM predictions.  The optimal rule is selected using the L\u221e distance. The results are averaged over each token prediction from 10 heldout Wikipedia sequences, each consisting of 2048 tokens. The model size used is 1.4B. Different rule strengths and maximum context lengths (M) are considered.", "section": "7 Rule Peformance"}, {"figure_path": "WCc440cUhX/tables/tables_22_3.jpg", "caption": "Table 16: Optimal rule distance with model scale (TinyStories, L\u221e distance). How optimal rule distance varies with model size and rule context length. Optimal rule is selected from R<sup>M</sup><sub>all</sub> using L<sup>\u221e</sup> distance.", "description": "This table shows how the optimal rule distance (using the L\u221e metric) changes with different model sizes (160M, 420M, 1.4B) and rule context lengths (1-7).  The optimal rule is selected from the R<sup>M</sup><sub>all</sub> ruleset. Lower values indicate better approximation of LLM predictions by the rules.", "section": "D.3 Model Scaling"}]