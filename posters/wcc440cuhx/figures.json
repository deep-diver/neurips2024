[{"figure_path": "WCc440cUhX/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of rule approximation. Given a context, different N-gram based rules formed out of the context will yield different next-token predictive distributions. In the above example, the context consists of three tokens. The first rule uses all three tokens of the context and makes a prediction based on the corresponding 4-gram rule derived from the training data; the second rule uses only the first and last tokens to form a corresponding 3-gram rule (and so the next token \"slept\" will be assigned less weight than the first rule since the \"tired\" token is ignored); and the third rule makes a prediction using the N-gram statistics obtained from aggregating over three token contexts from the training data where the second token is arbitrary (i.e. the second token is marginalized). Given a list of such rules, one can ask which rule's predictive distribution best matches that of the transformer.", "description": "The figure illustrates how different N-gram rules, derived from the training data and applied to a given context, produce different predictive distributions for the next token.  The example shows three rules applied to the context \"the tired dog\": one using all three tokens (4-gram), one using only the first and last (3-gram), and one marginalizing over the middle token (also 3-gram). The choice of which rule best matches the transformer's prediction is a key aspect of the paper's methodology.", "section": "1 Introduction"}, {"figure_path": "WCc440cUhX/figures/figures_6_1.jpg", "caption": "Figure 2: TinyStories 7-grams. Every point in the above plots represents a 7-gram context. Shaded regions are obtained by bucketing along the x-axis and computing one standard deviation within the mean along the y-axis. Slope and R<sup>2</sup> values of plots are with respect to the linear fit of the data. Optimal rule distances and model variances are computed with respect to five model runs. (a): d(p(t|C), P<sub>full</sub>(t|C)) vs count of C. (b): d(p(t|C), P<sub>full</sub>(t|C)) vs model variance. (c): model variance vs count of C. (d): similar to (b) but now the y-axis is optimal rule distance of the optimal rule from R<sub>suffix</sub>. Model size: 160M.", "description": "This figure visualizes the relationship between the frequency of 7-gram contexts in the TinyStories dataset, the model variance of LLM predictions for those contexts, and how well those predictions can be approximated by N-gram rules.  Panel (a) shows the distance between LLM predictions and the full-context 8-gram rule versus the context's frequency. Panel (b) shows the same distance versus model variance. Panel (c) shows model variance versus context frequency. Panel (d) shows the distance to the best-fitting N-gram rule (from a set of suffix-based rules) versus model variance. The figure demonstrates that contexts with low model variance tend to be well-approximated by N-gram rules, even when rare.  This supports the paper's approximation criterion.", "section": "Approximation Criterion"}, {"figure_path": "WCc440cUhX/figures/figures_7_1.jpg", "caption": "Figure 3: Training Dynamics. Left: Models reach their lowest distance to more complex rules later in training. For rules with four tokens of context or less, the variational distance eventually starts increasing later in training. For six and seven tokens of context, the variational distance continues to decrease. Center & Right: The optimal rule selected always has nonincreasing distance and nondecreasing top1-accuracy relative to the ground truth (interpreted as a one-hot distribution pgt), despite distances to model predictions eventually increasing or plateauing for rules with less than six tokens of context. This shows that the optimal rule selection is improving with additional training even if the optimal rule distance with respect to model predictions is not improving. (One can imagine the rule predictions as a mesh in probability space, with LLM predictions navigating this space through training. The distance to the mesh may plateau but which rule is closest can continue to change.) Model size: 160M.", "description": "This figure shows the learning dynamics of LLMs.  The left panel shows that the distance between LLM predictions and the optimal rules (based on n-gram statistics) decreases as training progresses, with more complex rules being learned later in training. The central and right panels show that while the overall distance between LLM predictions and the optimal rules may plateau, the quality of the optimal rule selection increases over training as measured by top-1 accuracy relative to the ground truth.", "section": "6.1 Curriculum Learning"}, {"figure_path": "WCc440cUhX/figures/figures_7_2.jpg", "caption": "Figure 4: Overfitting Detection. We plot both train loss (solid lines) and validation loss (dashed lines) for the full transformer and limited context length transformers (the latter are marked with an \"x\" for emphasis) on TinyStories. Unlike the full transformer which overfits, those with limited context length have train and validation loss curves closely following each other. Model size: 1.4B.", "description": "This figure shows the training and validation loss curves for various LLMs trained on the TinyStories dataset.  The models differ in their context length\u2014the number of previous tokens they consider when predicting the next token. The full transformer model exhibits overfitting, showing a decreasing training loss but an increasing validation loss.  In contrast, the models with limited context lengths show nearly identical training and validation loss curves, indicating that they do not overfit.  This suggests that overfitting occurs when LLMs try to memorize long contexts instead of generalizing from shorter sub-contexts.", "section": "6.2 Early Stopping Criterion"}, {"figure_path": "WCc440cUhX/figures/figures_8_1.jpg", "caption": "Figure 5: Rule selection for a TinyStories validation sequence. The above is a sequence from a heldout story. In the second and third columns are the ground truth, token by token, along with the rule context (as defined in Section 4) associated to the optimal rule from Rall. The heatmap indicates the variational distance between optimal rule and LLM next token distributions at the given token. The first column shows at most two tokens, which are chosen as follows: If the LLM top-1 prediction disagrees with the ground truth, the LLM prediction is shown. If in addition, the rule selected makes a different top-1 prediction from the transformer, that token is shown as the second token and the corresponding ground truth token is colored red. Thus red tokens are precisely the locations of disagreement between LLM and optimal rule greedy predictions. The last column shows the number of contexts supporting the optimal rule. Model size: 160M.", "description": "This figure shows an example of rule selection for a heldout story from the TinyStories dataset. It compares the LLM's next-token predictions with the ground truth and optimal rule predictions, highlighting disagreements using color-coding. The heatmap visualizes the variational distance between the LLM and optimal rule distributions for each token. The context of the optimal rule and its supporting context count are also provided.", "section": "Rule Peformance"}, {"figure_path": "WCc440cUhX/figures/figures_15_1.jpg", "caption": "Figure 6: Comparison with TinyStories bigram model. We evaluate transformer models (trained with either full context or context length equal to one) on all 22.8K distinct unigrams of TinyStories and record the corresponding variational distance with the bigram rule. Grouping unigrams based on count and averaging the variational distances result in the above scatterplots. Model size: 160M.", "description": "This figure compares the performance of two transformer models, one trained with full context and another trained with a context length of 1, against a bigram model on the TinyStories dataset.  The x-axis represents the count of each unigram, and the y-axis represents the variational distance between the transformer model's predictions and the bigram model's predictions for that unigram. The scatter plot shows that as the unigram count increases, the variational distance generally decreases for both transformer models, indicating improved approximation of the bigram model by the transformers.  The figure highlights the impact of context length on the ability of transformer models to learn simple bigram statistics.", "section": "C.1 Full-context vs Subcontext"}, {"figure_path": "WCc440cUhX/figures/figures_15_2.jpg", "caption": "Figure 2: TinyStories 7-grams. Every point in the above plots represents a 7-gram context. Shaded regions are obtained by bucketing along the x-axis and computing one standard deviation within the mean along the y-axis. Slope and R2 values of plots are with respect to the linear fit of the data. Optimal rule distances and model variances are computed with respect to five model runs. (a): d(p(t|C), Pfull(t|C)) vs count of C. (b): d(p(t|C'), Pfull(t|C)) vs model variance. (c): model variance vs count of C. (d): similar to (b) but now the y-axis is optimal rule distance of the optimal rule from Rsuffix. Model size: 160M.", "description": "This figure visualizes the relationship between the frequency of 7-gram contexts in the training data, the variance of LLM predictions across different training runs, and how well those predictions can be approximated by N-gram rules. It shows that contexts with low variance tend to be well-approximated by rules, even if they are rare in the training data. The plots show the distances between LLM predictions and the best-fitting N-gram rule, as well as model variance, against the count of each 7-gram context in the training data. ", "section": "Approximation Criterion"}, {"figure_path": "WCc440cUhX/figures/figures_17_1.jpg", "caption": "Figure 2: TinyStories 7-grams. Every point in the above plots represents a 7-gram context. Shaded regions are obtained by bucketing along the x-axis and computing one standard deviation within the mean along the y-axis. Slope and R2 values of plots are with respect to the linear fit of the data. Optimal rule distances and model variances are computed with respect to five model runs. (a): d(p(t|C), Pfull(t|C)) vs count of C. (b): d(p(t|C'), Pfull(t|C)) vs model variance. (c): model variance vs count of C. (d): similar to (b) but now the y-axis is optimal rule distance of the optimal rule from Rsuffix. Model size: 160M.", "description": "This figure visualizes the relationship between the frequency of 7-gram contexts in the training data, the variance of LLM predictions across different runs, and the distance between LLM predictions and the predictions of the best-fitting N-gram rule.  It shows that contexts with low variance across runs tend to be well-approximated by N-gram rules, even when those contexts are rare in the data. The figure supports the paper's approximation criterion, demonstrating how LLMs rely on simpler rules for low-variance predictions and leverage more complex rules for high-variance predictions.", "section": "Approximation Criterion"}, {"figure_path": "WCc440cUhX/figures/figures_18_1.jpg", "caption": "Figure 2: TinyStories 7-grams. Every point in the above plots represents a 7-gram context. Shaded regions are obtained by bucketing along the x-axis and computing one standard deviation within the mean along the y-axis. Slope and R2 values of plots are with respect to the linear fit of the data. Optimal rule distances and model variances are computed with respect to five model runs. (a): d(p(t|C), Pfull(t|C)) vs count of C. (b): d(p(t|C'), Pfull(t|C)) vs model variance. (c): model variance vs count of C. (d): similar to (b) but now the y-axis is optimal rule distance of the optimal rule from Rsuffix. Model size: 160M.", "description": "This figure visualizes the relationship between the frequency of 7-gram contexts in the training data, model variance, and the distance of LLM predictions from the full-context 8-gram rule. It shows that low model variance in LLM predictions is associated with a closer approximation to N-gram rules, particularly for higher-frequency contexts.", "section": "Approximation Criterion"}, {"figure_path": "WCc440cUhX/figures/figures_23_1.jpg", "caption": "Figure 5: Rule selection for a TinyStories validation sequence. The above is a sequence from a heldout story. In the second and third columns are the ground truth, token by token, along with the rule context (as defined in Section 4) associated to the optimal rule from Rall. The heatmap indicates the variational distance between optimal rule and LLM next token distributions at the given token. The first column shows at most two tokens, which are chosen as follows: If the LLM top-1 prediction disagrees with the ground truth, the LLM prediction is shown. If in addition, the rule selected makes a different top-1 prediction from the transformer, that token is shown as the second token and the corresponding ground truth token is colored red. Thus red tokens are precisely the locations of disagreement between LLM and optimal rule greedy predictions. The last column shows the number of contexts supporting the optimal rule. Model size: 160M.", "description": "This figure demonstrates an example of rule selection for a held-out TinyStories sequence.  It shows the ground truth tokens, the LLM's top-1 predictions, the optimal rule's predictions, and the variational distance between the LLM's and optimal rule's probability distributions for each token.  Red tokens indicate disagreements between the LLM and the optimal rule's top-1 predictions. The context used for each rule is also shown, along with the number of times that context appeared in the training data.  This helps illustrate how the model's predictions relate to simple statistical rules extracted from the training data.", "section": "Rule Peformance"}, {"figure_path": "WCc440cUhX/figures/figures_24_1.jpg", "caption": "Figure 5: Rule selection for a TinyStories validation sequence. The above is a sequence from a heldout story. In the second and third columns are the ground truth, token by token, along with the rule context (as defined in Section 4) associated to the optimal rule from Rall7. The heatmap indicates the variational distance between optimal rule and LLM next token distributions at the given token. The first column shows at most two tokens, which are chosen as follows: If the LLM top-1 prediction disagrees with the ground truth, the LLM prediction is shown. If in addition, the rule selected makes a different top-1 prediction from the transformer, that token is shown as the second token and the corresponding ground truth token is colored red. Thus red tokens are precisely the locations of disagreement between LLM and optimal rule greedy predictions. The last column shows the number of contexts supporting the optimal rule. Model size: 160M.", "description": "This figure shows an example of rule selection for a heldout TinyStories sequence.  It demonstrates how the model's top-1 prediction compares to the ground truth and the predictions of an optimal N-gram rule. The heatmap visually represents the variational distance between the model and rule predictions for each token. Red tokens highlight discrepancies between the model's top-1 prediction and both the ground truth and the optimal rule.", "section": "Rule Peformance"}, {"figure_path": "WCc440cUhX/figures/figures_25_1.jpg", "caption": "Figure 5: Rule selection for a TinyStories validation sequence. The above is a sequence from a heldout story. In the second and third columns are the ground truth, token by token, along with the rule context (as defined in Section 4) associated to the optimal rule from Rall. The heatmap indicates the variational distance between optimal rule and LLM next token distributions at the given token. The first column shows at most two tokens, which are chosen as follows: If the LLM top-1 prediction disagrees with the ground truth, the LLM prediction is shown. If in addition, the rule selected makes a different top-1 prediction from the transformer, that token is shown as the second token and the corresponding ground truth token is colored red. Thus red tokens are precisely the locations of disagreement between LLM and optimal rule greedy predictions. The last column shows the number of contexts supporting the optimal rule. Model size: 160M.", "description": "This figure shows an example of rule selection for a heldout story from the TinyStories dataset. It compares the ground truth, the LLM prediction, and the prediction of the optimal rule from the ruleset Rall. The heatmap visualizes the variational distance between the LLM and optimal rule predictions for each token. Tokens where the LLM prediction and ground truth disagree are highlighted, showing where the model and optimal rule diverge.  The number of contexts supporting the optimal rule is also given, providing insights into the model's reliance on specific contexts.", "section": "Rule Peformance"}, {"figure_path": "WCc440cUhX/figures/figures_26_1.jpg", "caption": "Figure 5: Rule selection for a TinyStories validation sequence. The above is a sequence from a heldout story. In the second and third columns are the ground truth, token by token, along with the rule context (as defined in Section 4) associated to the optimal rule from Rall. The heatmap indicates the variational distance between optimal rule and LLM next token distributions at the given token. The first column shows at most two tokens, which are chosen as follows: If the LLM top-1 prediction disagrees with the ground truth, the LLM prediction is shown. If in addition, the rule selected makes a different top-1 prediction from the transformer, that token is shown as the second token and the corresponding ground truth token is colored red. Thus red tokens are precisely the locations of disagreement between LLM and optimal rule greedy predictions. The last column shows the number of contexts supporting the optimal rule. Model size: 160M.", "description": "This figure shows an example of how the model selects rules for a held-out sequence from the TinyStories dataset. The heatmap visualizes the difference between the model's prediction and the optimal rule's prediction for each token. Red tokens highlight discrepancies between the model and the optimal rule. The context and count of supporting contexts for each rule are also provided.", "section": "Rule Peformance"}]