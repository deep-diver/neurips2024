[{"figure_path": "wgpmDyJgsg/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of Camera Rotation and Center Accuracy with SPARF [38]. We use three pose estimation baselines (RelPose++ [18], Ray Diff. [47], DUSt3R [41]) and measure rotation accuracy at two thresholds (5 and 15 degrees) and camera center accuracy at a threshold of 0.1 (of the scene scale). Eight images are used.", "description": "This table compares the camera pose accuracy of three different methods: RelPose++, Ray Diffusion, and DUSt3R, each with and without the SPARF and SparseAGS methods.  The accuracy is measured using rotation error at 5 and 15-degree thresholds and camera center error at a threshold of 0.1 of the scene scale.  The results show improvements in accuracy when SparseAGS is used with each of the baselines.  The experiment used eight images per object.", "section": "4.1 Experimental Setup"}, {"figure_path": "wgpmDyJgsg/tables/tables_7_1.jpg", "caption": "Table 2: Evaluation of Camera Pose Accuracy with Varying Numbers of Input Images on NAVI [9]. Here we use the same evaluation protocols as Tab. 1.", "description": "This table presents a quantitative comparison of camera pose accuracy using different numbers of input images (N=6, 10, 16). Three different baseline pose estimation methods (RelPose++, Ray Diff., DUSt3R) are used, each combined with SparseAGS.  The results show rotation accuracy at 5\u00b0 and 15\u00b0 thresholds, and camera center accuracy at a 0.1 threshold of the scene scale.  The improvements provided by SparseAGS over the baselines are highlighted, indicating increased accuracy with more images.", "section": "4.2 Evaluation"}, {"figure_path": "wgpmDyJgsg/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative Comparison of 3D Reconstruction on NAVI [9]. We compare our method with two unposed approaches: LEAP [12] and UpFusion [13], using varying numbers of input images (N). We adopt two pose initializations (Ray Diff. [47], DUSt3R [41]) reporting PSNR and LPIPS.", "description": "This table presents a quantitative comparison of 3D reconstruction performance on the NAVI dataset.  It compares the proposed SparseAGS method against two baselines (LEAP and UpFusion) using different numbers of input images (N=6, 8, 10).  The evaluation metrics are Peak Signal-to-Noise Ratio (PSNR) and Learned Perceptual Image Patch Similarity (LPIPS), and two different initial camera pose estimations (Ray Diffusion and DUSt3R) are used as input to SparseAGS.", "section": "4.2 Evaluation"}, {"figure_path": "wgpmDyJgsg/tables/tables_8_2.jpg", "caption": "Table 4: Ablation Study. Using initial poses from Ray Diffusion [47] for eight input images, we ablate the effect of each proposed component of our approach.", "description": "This table presents the results of an ablation study conducted to evaluate the contribution of each component in the SparseAGS framework. The study uses initial poses from Ray Diffusion [47] and eight input images.  The table shows the impact of each component on camera pose accuracy (Rotation accuracy at 5\u00b0 and 15\u00b0 thresholds, Camera center accuracy at 0.1 threshold), 3D reconstruction quality (PSNR and LPIPS), and F1 score at a threshold of 0.01. The components evaluated are: Pose-3D co-optimization without SDS, adding vanilla Zero-1-to-3 SDS, using the proposed 6-DoF Zero-1-to-3 SDS, and finally, adding outlier removal and correction. By comparing the results across rows, one can assess the individual contributions of each component to the overall performance of the SparseAGS system.", "section": "4.3 Ablation Study"}, {"figure_path": "wgpmDyJgsg/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of Camera Rotation and Center Accuracy with SPARF [38]. We use three pose estimation baselines (RelPose++ [18], Ray Diff. [47], DUSt3R [41]) and measure rotation accuracy at two thresholds (5 and 15 degrees) and camera center accuracy at a threshold of 0.1 (of the scene scale). Eight images are used.", "description": "This table compares the camera pose accuracy of SparseAGS against three baseline methods (RelPose++, Ray Diffusion, DUSt3R) and SPARF, using eight images.  It measures rotation accuracy at 5 and 15-degree thresholds and camera center accuracy within 10% of the scene scale. The results show improvements in pose accuracy when SparseAGS is used with the baselines.", "section": "4.1 Experimental Setup"}, {"figure_path": "wgpmDyJgsg/tables/tables_14_2.jpg", "caption": "Table 6: Evaluation of Rotation Accuracy on Three Synthetic Datasets (GSO [7], ABO [4] and OmniObject3D [44]). We test our method on ID-Pose [3] with eight images as input. We measure rotation accuracy at two thresholds (15 and 30 degrees).", "description": "This table presents a quantitative comparison of the rotation accuracy achieved by the proposed SparseAGS method and the baseline ID-Pose method on three synthetic datasets: GSO, ABO, and OmniObject3D.  The evaluation uses eight input images and measures rotation accuracy at two thresholds (15 and 30 degrees).  The results show improvements in rotation accuracy when using SparseAGS compared to ID-Pose across all datasets and thresholds. The numbers represent the percentage of samples with errors less than the specified threshold.", "section": "4.2 Evaluation"}]