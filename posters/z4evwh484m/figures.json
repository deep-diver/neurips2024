[{"figure_path": "z4eVwH484M/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Existing approaches relying on single-frame inference cannot capture the entire map information in the BEV features [26, 22, 23]. (b) Recent alternatives explore temporal information via streaming, but they cannot address the inherent nature of maps and propagate noise from previous timestamps. (c) We directly unveil hidden maps in BEV features by interacting with clip tokens that contain high-level map information. We visualize BEV features by 1D PCA projection. The BEV features are extracted from (a) MapTRv2 [23], (b) StreamMapNet [46], and (c) our MapUnveiler.", "description": "This figure compares three different approaches for vectorized HD map construction: (a) single-frame inference, (b) streaming inference, and (c) clip-level inference (the proposed method).  It highlights the limitations of single-frame and streaming approaches in handling occlusions and temporal inconsistencies, showcasing how the proposed clip-level method utilizes clip tokens to effectively unveil hidden map information and propagate temporal context for more accurate and robust map construction. The visualization of BEV features via 1D PCA projection further illustrates the improvements achieved by the proposed approach.", "section": "1 Introduction"}, {"figure_path": "z4eVwH484M/figures/figures_2_1.jpg", "caption": "Figure 2: Our framework takes clip-level multi-view images and outputs clip-level vectorized HD maps. All components in the frame-level MapNet (i.e., Backbone, PV to BEV, Map Decoder) are adopted from MapTRv2 [23]. The frame-level MapNet extracts map queries and BEV features independently at each frame. MapUnveiler generates compact clip tokens that contain clip-level temporal map information and directly interact with dense BEV features. With the updated BEV features, we construct high-quality clip-level vectorized maps. The generated map tokens and clip tokens are then written to memory.", "description": "This figure illustrates the overall architecture of the proposed MapUnveiler framework for online vectorized HD map construction.  It shows how the framework takes clip-level multi-view images as input and processes them through several key modules: a frame-level MapNet (based on MapTRv2), an Intra-clip Unveiler, and an Inter-clip Unveiler. The frame-level MapNet extracts BEV features and map queries. The Intra-clip Unveiler generates clip tokens, updates BEV features, and generates map tokens.  The Inter-clip Unveiler manages long-term temporal information via memory, updating BEV features across clips. Finally, the system outputs high-quality vectorized HD maps. The figure highlights the interaction between BEV features, clip tokens, and map tokens within the MapUnveiler module, showcasing the key elements that enable the system to unveil hidden map information.", "section": "3 Method"}, {"figure_path": "z4eVwH484M/figures/figures_3_1.jpg", "caption": "Figure 3: A detailed implementation of Intra-clip Unveiler. We use blue, red, and green arrows to indicate the flows of map tokens, BEV features, and clip tokens, respectively. In each attention and feed forward layer, standard layer normalization, dropout, and residual connections are followed.", "description": "This figure shows a detailed architecture of the Intra-clip Unveiler module. The Intra-clip Unveiler module is a core component of the MapUnveiler framework proposed in the paper. It takes frame-level map queries, BEV features, and memory reads as input and generates clip-level map tokens. It consists of three main steps: Clip Token Generator, BEV Updater, and Map Generator. The Clip Token Generator generates compact clip tokens, which are then used by the BEV Updater to update BEV features to unveil hidden map elements. Finally, the Map Generator generates clip-level map tokens from the updated BEV features. The figure also shows positional embeddings used for the map tokens, BEV features, and clip tokens.", "section": "3 Method"}, {"figure_path": "z4eVwH484M/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparisons on two range variants of nuScenes val set: 60\u00d730m and 100\u00d750m. We compare our MapUnveiler with MapTRv2 [23] and StreamMapNet [46]. We marked significant improvements from MapTRv2 and StreamMapNet using green boxes.", "description": "This figure shows a qualitative comparison of the map construction results between MapUnveiler, MapTRv2, and StreamMapNet on the nuScenes validation set. Two different perception ranges are considered: 60x30m and 100x50m. Green boxes highlight the areas where MapUnveiler shows significant improvement over the other two methods.", "section": "Experiments"}, {"figure_path": "z4eVwH484M/figures/figures_9_1.jpg", "caption": "Figure 6: Qualitative comparisons on nuScenes val with 60\u00d730m perception range setting.", "description": "This figure displays a qualitative comparison of the proposed MapUnveiler model with two other models, MapTRv2 and StreamMapNet, on the nuScenes validation set. The perception range is set to 60x30 meters.  Each row represents a sequence of frames from a driving scene. The leftmost column shows the input images from multiple cameras. The subsequent columns visualize the ground truth map (GT) and the predictions from each model.  The color coding of the map elements likely represents different map element types (e.g., lane lines, road boundaries). The figure aims to showcase the visual differences in map construction accuracy between the models.", "section": "4.3 Comparisons"}, {"figure_path": "z4eVwH484M/figures/figures_14_1.jpg", "caption": "Figure 6: Qualitative comparisons on nuScenes val with 60\u00d730m perception range setting.", "description": "This figure displays a qualitative comparison of the proposed MapUnveiler model with two other models, MapTRv2 and StreamMapNet, on the nuScenes validation set using a 60x30m perception range.  Each row shows a sequence of input images from a driving scene and corresponding vectorized HD map predictions from each method. Ground truth (GT) maps are also provided for reference. The visualization highlights the strengths and weaknesses of each model in accurately reconstructing various map elements such as lane lines, road boundaries, and crosswalks in different scenarios.  By comparing the predictions against the ground truth, one can visually assess the performance of each model in terms of accuracy, completeness, and robustness to occlusions and challenging driving conditions.", "section": "4.3 Comparisons"}, {"figure_path": "z4eVwH484M/figures/figures_15_1.jpg", "caption": "Figure 6: Qualitative comparisons on nuScenes val with 60\u00d730m perception range setting.", "description": "This figure shows a qualitative comparison of the proposed MapUnveiler model with two other state-of-the-art methods (MapTRv2 and StreamMapNet) on the nuScenes validation set using a 60x30m perception range.  It displays several time steps, showing the input images from multiple cameras, the ground truth map, and the predictions from each of the three methods. The results highlight the improved accuracy and completeness of the MapUnveiler model in reconstructing the vectorized HD map, especially for complex road layouts and in scenarios with partial occlusions.", "section": "4.3 Comparisons"}, {"figure_path": "z4eVwH484M/figures/figures_16_1.jpg", "caption": "Figure 6: Qualitative comparisons on nuScenes val with 60\u00d730m perception range setting.", "description": "This figure presents a qualitative comparison of the proposed MapUnveiler model against two other state-of-the-art models, MapTRv2 and StreamMapNet, on the nuScenes validation set using a 60x30m perception range. The figure shows several sequences of images from the dataset along with the ground truth map and the results produced by each model.  Each row represents a different time step (or a short sequence of steps), and the columns show the input images, the ground truth map (GT), the MapTRv2 predictions, the StreamMapNet predictions, and finally the MapUnveiler predictions.  This visual comparison allows one to assess the relative accuracy and robustness of each method in handling different scenarios and levels of occlusion.", "section": "4.3 Comparisons"}, {"figure_path": "z4eVwH484M/figures/figures_17_1.jpg", "caption": "Figure 6: Qualitative comparisons on nuScenes val with 60\u00d730m perception range setting.", "description": "This figure compares the ground truth map with the maps generated by MapTRv2, StreamMapNet, and the proposed MapUnveiler method on the nuScenes validation set using a 60x30m perception range.  Each row shows a sequence of input images and the corresponding map predictions for each method.  The results visually demonstrate MapUnveiler's improved accuracy in map construction compared to the other methods, especially in terms of correctly identifying and representing lane lines and other road elements.", "section": "4.3 Comparisons"}]