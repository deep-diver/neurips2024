[{"figure_path": "hjhpCJfbFG/tables/tables_1_1.jpg", "caption": "Table 1: Table of contributions of ProtoVit (Ours) compared to existing works.", "description": "This table compares ProtoViT with three other existing interpretable image classification models: ProtoPNet, Deformable ProtoPNet, and ProtoPformer.  The comparison is made across five key features: whether the model supports Vision Transformer (ViT) backbones, whether it uses deformable prototypes, whether the resulting prototypes are semantically coherent, whether the prototypes have adaptive sizes, and finally whether the model is inherently interpretable. ProtoViT is shown to be superior in most of the features, improving upon limitations seen in previous work.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/tables/tables_7_1.jpg", "caption": "Table 2: Comparison of ProtoVit implemented with DeiT and CaiT backbones to other existing works.", "description": "This table compares the performance of ProtoViT (using DeiT and CaiT backbones) against other existing methods on the CUB-200-2011 and Cars datasets.  It shows ProtoViT's accuracy and compares it to baselines and other prototype-based models, highlighting its superior performance.  The table also includes model parameters for context.", "section": "4.1 Case Study 1: Bird Species Identification"}, {"figure_path": "hjhpCJfbFG/tables/tables_9_1.jpg", "caption": "Table 3: Experimental results on the Location Misalignment Benchmark. We compare our ProtoViT (Deit-Small) with other prototype-based models with CNN backbones (ResNet34). We found that our model performs similarly to or better than the existing models with CNN backbones in terms of the misalignment metrics and test accuracy.", "description": "This table presents the results of a Location Misalignment Benchmark, comparing the performance of ProtoViT (using a DeiT-Small backbone) against other prototype-based models that utilize CNN backbones (ResNet34). The comparison focuses on evaluating the models' robustness against adversarial attacks that aim to misalign the spatial location of prototypes.  Metrics include Percentage Change in Location (PLC), Percentage Change in Activation (PAC), Percentage Change in Ranking (PRC), and Accuracy (before and after the attack), along with the Accuracy Change (AC). Lower values for PLC, PAC, and PRC indicate better performance.", "section": "4.1 Case Study 1: Bird Species Identification"}, {"figure_path": "hjhpCJfbFG/tables/tables_15_1.jpg", "caption": "Table 2: Comparison of ProtoVit implemented with DeiT and CaiT backbones to other existing works.", "description": "This table compares the performance of ProtoViT, implemented with DeiT and CaiT backbones, against other existing works on the CUB-200-2011 and Cars datasets.  It shows the accuracy achieved by each model, along with the number of parameters used. The table highlights ProtoViT's superior performance and efficiency compared to alternative methods, especially those using CNN backbones.", "section": "4 Experiments"}, {"figure_path": "hjhpCJfbFG/tables/tables_16_1.jpg", "caption": "Table 2: Comparison of ProtoVit implemented with DeiT and CaiT backbones to other existing works.", "description": "This table compares the performance of ProtoViT (using DeiT and CaiT backbones) against other existing methods on the CUB-200-2011 and Cars datasets.  It highlights ProtoViT's superior accuracy while also providing a comparison with models using CNN backbones (DenseNet-161) for reference.  The table includes the model architecture, number of parameters, and accuracy results for CUB and Cars.", "section": "4 Experiments"}, {"figure_path": "hjhpCJfbFG/tables/tables_17_1.jpg", "caption": "Table 6: Ablation study on ProtoViT. Model is compared with K = 4, and r = 1 for slots and adjacency mask settings. We use Deit-Small as the backbone, and the model is trained on CUB-200-2011 dataset. For the current setting of ProtoViT, we included class token, coherence loss, and adjacency mask along with the greedy matching algorithm.", "description": "This table presents the results of ablation studies performed on the ProtoViT model.  It shows the impact of removing key components (class token, coherence loss, and adjacency mask) on the model's accuracy and location misalignment (PLC). The experiments were conducted using the DeiT-Small backbone and the CUB-200-2011 dataset. The table helps to understand the contribution of each component to the overall performance and robustness of the model.", "section": "E Ablation studies"}, {"figure_path": "hjhpCJfbFG/tables/tables_19_1.jpg", "caption": "Table 2: Comparison of ProtoVit implemented with DeiT and CaiT backbones to other existing works. Our model is not only inherently interpretable but also superior in performance compared to other methods using the same backbone. We also include models with a CNN backbone (Densenet-161) for reference in the top section. The reported accuracies are the final results after all training stages.", "description": "This table compares the performance of ProtoViT (using DeiT and CaiT backbones) with other existing image classification methods, including those using CNN backbones (DenseNet-161).  It highlights ProtoViT's superior accuracy and interpretability compared to other methods using the same backbones, demonstrating its effectiveness in image classification.  The accuracy values represent the final performance achieved after all training stages have been completed.", "section": "4.1 Case Study 1: Bird Species Identification"}, {"figure_path": "hjhpCJfbFG/tables/tables_22_1.jpg", "caption": "Table 8: ProtoViT performance with K = 5 and K = 6 using DeiT-Small backbone", "description": "This table presents the results of experiments conducted to evaluate the performance of the ProtoViT model using different numbers of sub-prototypes (K) and adjacency mask ranges (r). Specifically, it shows the accuracy achieved by the model when using 4, 5, and 6 sub-prototypes with corresponding optimal adjacency mask ranges. The results highlight the impact of these hyperparameters on the model's performance.", "section": "4.1.1 Predictive Performance Results"}, {"figure_path": "hjhpCJfbFG/tables/tables_35_1.jpg", "caption": "Table 2: Comparison of ProtoVit implemented with DeiT and CaiT backbones to other existing works.", "description": "This table compares the performance of ProtoViT, using DeiT and CaiT backbones, against other existing interpretable image classification methods.  It shows accuracy results on the CUB and Cars datasets, highlighting the superior performance of ProtoViT while using fewer parameters compared to some other methods.  A CNN-based model is also included as a benchmark for comparison.", "section": "4 Experiments"}]