[{"figure_path": "hjhpCJfbFG/figures/figures_1_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models: ProtoPNet, Deformable ProtoPNet, and ProtoViT.  Each model attempts to classify a test image of a male Ruby-throated Hummingbird.  The figure showcases the prototypes used by each model to arrive at its classification.  ProtoPNet uses rigid rectangular prototypes, leading to ambiguous explanations. Deformable ProtoPNet uses deformable prototypes, but these lack semantic coherence and the explanations are still unclear.  ProtoViT, the authors' proposed method, employs deformable prototypes that adapt to shape and maintain semantic coherence, resulting in clear and faithful interpretations.  The bounding boxes highlight the prototypes used in the classification process for each method.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_3_1.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure illustrates the architecture of ProtoViT, a novel prototype-based vision transformer.  It consists of three main layers: a feature encoder (f), which uses a vision transformer (like DeiT or CaiT) to extract features from input images; a greedy matching and prototype layer (g), which deforms prototypes into smaller sub-prototypes, matches them with the most similar image patches, and incorporates an adaptive slots mechanism to select relevant sub-prototypes; and an evidence layer (h), which combines similarity scores to produce final classification logits. The figure highlights the adaptive nature of the prototype selection and the use of adjacency masks to ensure spatial coherence.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_8_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models.  ProtoPNet uses rectangular prototypes that lead to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes, but these lack semantic coherence.  ProtoViT (the authors' model) uses deformed prototypes that adapt to the shape of the object and offer greater semantic coherence, providing clearer and more accurate explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_8_2.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows a comparison of nearest prototypes to test images and nearest training/test patches to the prototypes. The left side shows the prototypes identified by ProtoViT for several test images, highlighting the key features used for classification.  The right side demonstrates how the model finds similar image patches in the training and test datasets, that correspond to the identified prototypes.  This visualization helps to understand the model's reasoning process by illustrating the semantic similarity between prototypes and actual images.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_15_1.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure illustrates the architecture of ProtoViT, a novel prototype-based vision transformer for interpretable image classification.  It shows three main layers: a feature encoder (f), a greedy matching and prototype layer (g), and an evidence layer (h).  The feature encoder processes the input image using a Vision Transformer backbone. The greedy matching layer compares the encoded image features to learned prototypes, allowing for geometrically adaptive comparisons. The adaptive slots mechanism efficiently selects the most relevant sub-prototypes for the classification. Finally, the evidence layer aggregates the similarity scores from the matching process to produce the final classification logits.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_17_1.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure illustrates the architecture of ProtoViT, a novel prototype-based vision transformer. It comprises three main layers: a feature encoder (f), a greedy matching and prototype layer (g), and an evidence layer (h).  The feature encoder processes the input image using a Vision Transformer (ViT) backbone. The greedy matching layer compares the encoded image patches to learned prototypes, identifying the closest matches while handling geometric variations and dynamically selecting relevant prototype parts using an adaptive slots mechanism. Finally, the evidence layer aggregates the similarity scores to generate the final classification.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_18_1.jpg", "caption": "Figure 7: Histogram analysis of mean activation for ProtoViT with and without class token.", "description": "The figure shows three histograms visualizing the distribution of mean correct class activation, the largest mean incorrect class activation, and the difference between the two for ProtoViT models trained with and without the class token.  The class token version shows a greater separation between correct and incorrect class activations.", "section": "E Ablation studies"}, {"figure_path": "hjhpCJfbFG/figures/figures_18_2.jpg", "caption": "Figure 7: Histogram analysis of mean activation for ProtoViT with and without class token.", "description": "This figure presents a histogram analysis comparing the mean activation of ProtoViT models with and without class tokens.  Three histograms are shown: one showing the mean correct class activation, one showing the largest mean incorrect class activation, and one showing the difference between the mean correct class activation and the largest mean incorrect class activation. Each histogram is displayed for both the model with and without the class token, allowing for a comparison of the impact of including the class token on the model's activation patterns.", "section": "E Ablation studies"}, {"figure_path": "hjhpCJfbFG/figures/figures_18_3.jpg", "caption": "Figure 7: Histogram analysis of mean activation for ProtoViT with and without class token.", "description": "This figure presents a histogram analysis comparing the mean activation of ProtoViT models with and without a class token. Three histograms are shown, visualizing: the mean correct class activation, the largest mean incorrect class activation, and the difference between the mean correct and incorrect class activations.  The distributions for models with and without the class token are compared within each histogram, to demonstrate the impact of the class token on the model's ability to distinguish between correct and incorrect classifications.", "section": "E Ablation studies"}, {"figure_path": "hjhpCJfbFG/figures/figures_20_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models: ProtoPNet, Deformable ProtoPNet, and ProtoViT.  Each model attempts to classify a test image of a male Ruby-Throated Hummingbird. The figure highlights how the different approaches handle the comparison between the test image and learned prototypes. ProtoPNet uses rectangular prototypes which lead to ambiguous explanations. Deformable ProtoPNet uses deformable prototypes but lacks semantic coherence. ProtoViT, in contrast, utilizes deformed prototypes that adapt to the shape of the object and maintain semantic coherence, resulting in more clear and faithful interpretations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_21_1.jpg", "caption": "Figure 8: How ProtoViT without adjacency mask makes predictions (left) vs. how ProtoViT makes predictions. The test image of a least tern is correctly classified by the two models, and the test image of a black tern is classified as a pigeon guillemot by both of the models.", "description": "This figure compares the reasoning process of ProtoViT with and without the adjacency mask. The left column shows the results of ProtoViT without the adjacency mask, while the right column shows the results of ProtoViT with the adjacency mask.  The figure uses two examples to illustrate how the adjacency mask improves the coherence and accuracy of the model's predictions. In the first example, both models correctly classify a Least Tern image. In the second example, ProtoViT without the adjacency mask misclassifies a Black Tern image as a Pigeon Guillemot, while ProtoViT with the adjacency mask correctly classifies the Black Tern. This highlights how the adjacency mask helps to prevent the model from making incoherent and inaccurate predictions by ensuring that the sub-prototypes within each prototype are geometrically contiguous.", "section": "E Ablation studies"}, {"figure_path": "hjhpCJfbFG/figures/figures_22_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure demonstrates how three different prototype-based models classify a test image.  ProtoPNet uses rectangular prototypes, leading to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes, but the parts lack semantic coherence. ProtoViT (the authors' model) uses deformed prototypes with better shape adaptation and semantic coherence, resulting in clearer and more accurate interpretations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_22_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure demonstrates how three different prototype-based models classify a test image of a male Ruby-Throated Hummingbird.  It highlights the differences in how each model identifies and uses prototypes to reach a classification decision. ProtoPNet uses rectangular prototypes leading to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes, but the features lack semantic coherence.  ProtoViT (the authors' model) uses deformed prototypes with clear and coherent semantics, illustrating its superiority in providing interpretable explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_23_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows a comparison between the nearest prototypes to test images and the nearest training/test image patches to the learned prototypes.  The left side displays prototypes projected onto their closest test image patches. The right side shows the training and test patches that are most similar to each learned prototype.  The visualization demonstrates the model's ability to identify semantically coherent and geometrically consistent features from images during training and testing.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_23_2.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows two types of analysis to demonstrate the semantic consistency of the prototypes generated by ProtoViT.  The left side displays local analysis, showing the most semantically similar prototypes to each test image. The right side shows global analysis, presenting the top three nearest training and testing images to the prototypes (excluding the training image itself that was used to create the prototype). The purpose is to show that the learned prototypes consistently represent a single, meaningful concept and the model comparisons are reasonable.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_24_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models in identifying a test image of a male Ruby-Throated Hummingbird.  ProtoPNet uses rectangular prototypes leading to ambiguous explanations.  Deformable ProtoPNet uses deformed prototypes, but lacks semantic coherence. ProtoViT (the authors' model) offers deformed prototypes that adapt to the shape and maintain semantic coherence.  The bounding boxes highlight the prototypes in each model's reasoning process.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_25_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based models for image classification: ProtoPNet, Deformable ProtoPNet, and ProtoViT. Each model's inference process is illustrated, showing how it compares the test image with its learned prototypes to arrive at a classification decision.  The key takeaway is how ProtoViT utilizes deformed prototypes that adapt to the shape of the target image, leading to more precise and interpretable explanations than the other models which employ rectangular or ambiguously deformed prototypes.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_25_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares three different prototype-based models' reasoning process for classifying a test image of a male Ruby-Throated Hummingbird.  It illustrates how the models use learned prototypes (visual representations of features) to match against an input image.  ProtoPNet uses rectangular prototypes, which can be too broad and lead to ambiguous explanations. Deformable ProtoPNet improves upon this by using deformable prototypes, which adjust to the image's shape, but still lacks semantic coherence in their representations. ProtoViT, the proposed model, uses deformable prototypes that both adapt to the image's shape and provide clear, coherent prototypical feature representations, resulting in more accurate and interpretable classifications. The bounding boxes visually highlight the prototypes and their correspondence to parts of the input image.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_26_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models.  ProtoPNet uses rectangular prototypes that lead to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes but lacks semantic coherence, making the explanations unclear.  ProtoViT (the authors' model) uses deformed prototypes that adapt well to the image shape and provide coherent, clear explanations of the classification.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_26_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "The figure compares the reasoning process of three different prototype-based image classification models. ProtoPNet uses rectangular prototypes, resulting in ambiguous explanations. Deformable ProtoPNet uses deformed prototypes, but lacks semantic coherence. ProtoViT (the authors' model) uses deformed prototypes that adapt to shape and maintain semantic coherence, providing clearer and more accurate explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_27_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares three different prototype-based models on a single example image: ProtoPNet, Deformable ProtoPNet, and ProtoViT. The goal is to illustrate how each method identifies the image's class (Male Ruby-Throated Hummingbird) by comparing image patches to its learned prototypes.  It highlights the differences in how the models use prototypes, particularly regarding their shape and resulting explanations.  ProtoPNet uses rigid rectangular prototypes leading to vague explanations. Deformable ProtoPNet improves by allowing deformed prototypes, but the resulting explanations still lack semantic coherence. ProtoViT, the proposed model, uses deformed prototypes with improved semantic coherence resulting in clearer explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_27_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares how three different prototype-based models classify a test image. ProtoPNet uses rectangular prototypes that lead to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes that lack semantic coherence. ProtoViT (the proposed model) uses deformed prototypes that are both adaptive and semantically coherent, offering more accurate and clear explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_28_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure demonstrates the reasoning process of three different prototype-based image classification models.  It showcases how each model identifies the class of a test image (a male Ruby-Throated Hummingbird) by comparing it to learned prototypes.  The figure highlights the differences in how the models represent and utilize their prototypes.  ProtoPNet uses broad rectangular prototypes, leading to ambiguous explanations. Deformable ProtoPNet uses deformable prototypes which are better but still lack semantic coherence, meaning the parts of the prototypes do not clearly correspond to meaningful features of the hummingbird.  ProtoViT (the authors' proposed model) utilizes deformed prototypes that adapt to the shape of the hummingbird and possess semantic coherence, providing clearer and more interpretable explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_28_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares three different prototype-based models' reasoning processes when classifying a male Ruby-Throated Hummingbird image.  The top row shows the results of ProtoPNet, demonstrating ambiguous explanations due to rectangular prototypes. The middle row illustrates Deformable ProtoPNet, where deformed prototypes adapt to the shape but lack semantic coherence. Finally, the bottom row showcases ProtoViT (the proposed model), exhibiting both shape adaptation and improved semantic coherence in its explanations through deformed prototypes.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_29_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "The figure compares how three different prototype-based models (ProtoPNet, Deformable ProtoPNet, and ProtoViT) classify a test image of a male Ruby-throated Hummingbird. It highlights the differences in how the models use prototypes to reach a classification decision. ProtoPNet uses rectangular prototypes that are too broad and result in ambiguous explanations. Deformable ProtoPNet uses deformed prototypes that adapt to the shape of the bird but lack semantic coherence, making it unclear what aspects of the bird each prototype captures.  ProtoViT, in contrast, uses deformed prototypes that adapt to shape and exhibit semantic coherence, leading to clearer and more accurate explanations. The bounding boxes visually represent the prototypes in each model and how they match with regions of the test image.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_30_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares three different prototype-based models' reasoning processes for classifying a male Ruby-throated Hummingbird image.  ProtoPNet uses rectangular prototypes leading to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes but lacks semantic coherence.  ProtoViT (the authors' model) uses deformed prototypes with improved semantic coherence, better adapting to the image's shape and providing clearer explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_31_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure demonstrates the local and global analysis conducted to evaluate the semantic consistency and coherence of ProtoViT's prototypes. The left side displays local analysis, showing the most semantically similar prototypes to each test image.  The right side shows global analysis, showcasing the top three nearest training and testing images to each prototype. This helps validate that the model's learned prototypes are faithful and consistent across various instances of the same visual concept.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_32_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows the results of the local and global analysis for ProtoViT. The left side shows the nearest prototypes to the test images, while the right side displays the nearest training and testing image patches to the prototypes.  By comparing these images, the authors illustrate the model's ability to learn prototypes that consistently activate on the same, meaningful concept across different images.  The exclusion of the nearest training patch serves to highlight the model's ability to generalize beyond simply memorizing the training data.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_33_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure visualizes the nearest prototypes to test images and the nearest image patches to prototypes. The left side shows the nearest prototypes to test images, while the right side shows the nearest training patches to prototypes.  It excludes the nearest training patch which is the prototype itself because of projection. This comparison helps demonstrate the semantic consistency and coherence of learned prototypes.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_34_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "The figure illustrates how three different prototype-based models (ProtoPNet, Deformable ProtoPNet, and ProtoViT) classify a test image of a male Ruby-throated Hummingbird.  It highlights the differences in how each model identifies the bird's class by comparing the test image to its learned prototypes. ProtoPNet uses rectangular prototypes which can lead to ambiguous explanations.  Deformable ProtoPNet improves upon this by using deformable prototypes, but these lack semantic coherence. ProtoViT, the authors' proposed model, provides the clearest and most coherent explanations by using deformed prototypes with better semantic coherence. The bounding boxes around the prototypes visually represent the area being compared in each image.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_35_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares three different prototype-based models' reasoning processes in classifying a male Ruby-throated Hummingbird image.  It highlights the differences in the quality of explanations generated by each model. ProtoPNet uses rectangular prototypes resulting in ambiguous explanations.  Deformable ProtoPNet uses deformed prototypes but lacks semantic coherence. ProtoViT (the authors' model) adapts deformed prototypes to the image shape while maintaining semantic coherence, offering clearer and more faithful interpretations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_36_1.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure presents the architecture of ProtoViT, which consists of three main components: a feature encoder layer (f), a greedy matching and prototype layer (g), and an evidence layer (h). The feature encoder extracts features from input images.  The greedy matching layer deforms prototypes into sub-prototypes and matches them to image patches, while the adaptive slots mechanism filters out less relevant sub-prototypes. Finally, the evidence layer combines similarity scores to produce class predictions.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_36_2.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure shows the architecture of ProtoViT, a novel method for interpretable image classification. It consists of three main components: a feature encoder (f), a greedy matching and prototype layer (g), and an evidence layer (h). The feature encoder processes the input image and extracts latent feature representations. The greedy matching and prototype layer compares these representations to learned prototypes, finding the most similar ones and adapting to geometric variations. The evidence layer aggregates the similarity scores to produce the final classification.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_37_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models.  It highlights how each model identifies the class of a test image showing a male Ruby-Throated Hummingbird.  The models differ in their use of prototypes (the learned feature representations used to classify images). The top row shows ProtoPNet, which uses rectangular prototypes that are too broad and lead to ambiguous explanations. The middle row illustrates Deformable ProtoPNet, which uses deformable prototypes, but the explanations lack semantic coherence (the prototypes don't clearly capture the meaning of the hummingbird). The bottom row shows ProtoViT, the proposed model in the paper, that utilizes deformable prototypes that are both adaptive (adjust to the shape of the object) and semantically coherent (the components of the prototype relate meaningfully to the features of the hummingbird).  The bounding boxes indicate the regions that each prototype is compared to in the test image.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_37_2.jpg", "caption": "Figure 2: Architecture of ProtoViT. The feature encoder layer f can be any kind of vision transformer encoders such as DeiT and CaiT. The greedy matching and prototype layer g deforms the prototypes into sub-prototypes and finds the closest non-overlapping feature patches from the test image. Our adaptive slots mechanism filters out some number of sub-prototypes, and the sum of the remaining similarity scores (with a correction to avoid down-weighting prototypes with more sub-prototypes filtered out) is returned. The evidence layer h is a fully connected layer that computes the logit predictions based on the summed similarity scores.", "description": "This figure shows the architecture of ProtoViT, a novel prototype-based vision transformer for interpretable image classification. It consists of three main layers:\n\n1.  **Feature Encoder Layer (f):** Extracts image features using a Vision Transformer (ViT) backbone (e.g., DeiT or CaiT).\n2.  **Greedy Matching and Prototype Layer (g):** Deforms learned prototypes into sub-prototypes and matches them to the most similar image patches, incorporating an adjacency mask and an adaptive slots mechanism to ensure geometrically contiguous and coherent prototypes.\n3.  **Evidence Layer (h):** Aggregates the similarity scores from the matching layer to produce class predictions using a fully connected layer.", "section": "3.1 Architecture Overview"}, {"figure_path": "hjhpCJfbFG/figures/figures_38_1.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure compares the reasoning process of three different prototype-based image classification models.  The models are ProtoPNet, Deformable ProtoPNet, and ProtoViT (the authors' model). For each model, a test image of a male Ruby-throated Hummingbird is shown, along with the prototypes used to classify it. The ProtoPNet uses rectangular prototypes that are too broad and lead to ambiguous explanations. The Deformable ProtoPNet employs deformed prototypes that better adapt to the image's shape, but the features still lack semantic coherence.  In contrast, the ProtoViT model uses deformed prototypes that are both shape-adaptive and semantically coherent, resulting in clearer and more faithful explanations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_38_2.jpg", "caption": "Figure 1: Reasoning process of how prototype based models identify a test image of a male Ruby-Throated Hummingbird as the correct class. Prototypes are shown in the bounding boxes.", "description": "This figure demonstrates the reasoning process of three different prototype-based image classification models when classifying a test image of a male Ruby-Throated Hummingbird.  The models are ProtoPNet, Deformable ProtoPNet, and ProtoViT (the authors' model).  It highlights the differences in how each model uses prototypes to identify the image class and the resulting quality of the explanations.  ProtoPNet uses rectangular prototypes, leading to ambiguous explanations. Deformable ProtoPNet uses deformed prototypes, but these lack semantic coherence.  ProtoViT's deformed prototypes adapt to the shape of the bird and offer coherent and clear interpretations.", "section": "1 Introduction"}, {"figure_path": "hjhpCJfbFG/figures/figures_39_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure demonstrates the visual representation of ProtoViT's prototypes and their relationship to the training and testing data.  The left side shows the nearest prototypes to test images, highlighting the visual similarity between learned prototypes and unseen images. The right side displays the nearest training patches to each prototype, revealing how the prototypes are grounded in the training data through projection.  By excluding the nearest training patch (the prototype itself), the figure focuses on how well the prototype captures the essence of visual features shared across similar images in the training set and test set.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_39_2.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows the results of local and global analysis of the proposed method, ProtoViT. The left side displays local analysis examples, visualizing the most semantically similar prototypes to each test image.  The right side shows global analysis examples, presenting the top three nearest training and testing images to the prototypes.  The local analysis confirms that across distinct classes and prototypes, the comparisons made are reasonable. The global analysis shows that each prototype consistently highlights a single, meaningful concept across various poses and scales.", "section": "4.1.2 Reasoning Process and Analysis"}, {"figure_path": "hjhpCJfbFG/figures/figures_40_1.jpg", "caption": "Figure 4: Nearest prototypes to test images (left), and the nearest image patches to prototypes (right). We exclude the nearest training patch, which is the prototype itself by projection.", "description": "This figure shows a comparison between nearest prototypes to test images and nearest training/test image patches to prototypes. The left side shows the top three nearest prototypes to each test image. The right side shows the three nearest training and test image patches to each prototype. This visualization helps to confirm the semantic consistency and coherence of the learned prototypes across different classes and prototypes.", "section": "4.1.2 Reasoning Process and Analysis"}]