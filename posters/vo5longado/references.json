{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of diffusion models, introducing the core denoising process used in many subsequent works, including the target paper."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-10-26", "reason": "This paper is highly influential for its introduction of the Vision Transformer architecture, which is a critical component of the transformer-based diffusion models discussed in the target paper."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This work demonstrated the superior performance of diffusion models over GANs in image synthesis, significantly boosting interest in the technology and shaping the direction of research in the field."}, {"fullname_first_author": "Fan Bao", "paper_title": "All are worth words: A vit backbone for diffusion models", "publication_date": "2023-01-01", "reason": "This paper shows the effective use of Vision Transformers (ViTs) as backbones in diffusion models, advancing the state of the art and providing inspiration for the architecture of the models analyzed in the target paper."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "This paper directly addresses the scalability challenges of diffusion models using transformers, a central theme that the target paper also tackles and builds upon."}]}