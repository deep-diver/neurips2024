[{"figure_path": "EQZlEfjrkV/tables/tables_8_1.jpg", "caption": "Table 1: Experimental result on synthetic data using MSE (mean (std)).", "description": "This table presents the mean and standard deviation of the Mean Squared Error (MSE) for two different parameter estimation methods (Estimator and Estimator-TR) applied to synthetic datasets.  The MSE is calculated for two scenarios: up to group sign indeterminacy (GS Case) and up to orthogonal transformation indeterminacy (OT Case).  The results are shown for three different sample sizes (2k, 5k, and 10k) to demonstrate the performance of the methods across varying data amounts.", "section": "5 Experiments"}, {"figure_path": "EQZlEfjrkV/tables/tables_23_1.jpg", "caption": "Table 2: Performance under violation of normality using uniform noise terms in MSE (mean (std)).", "description": "This table presents the mean and standard deviation of the Mean Squared Error (MSE) for estimating parameters up to group sign indeterminacy.  The experiment uses uniform noise instead of Gaussian noise, violating the normality assumption of the model.  The results are shown for different sample sizes (2k, 5k, 10k) and for two different estimators: Estimator and Estimator-TR.", "section": "5.3 Misspecification Behavior"}, {"figure_path": "EQZlEfjrkV/tables/tables_23_2.jpg", "caption": "Table 3: Performance under violation of linearity using leaky relu in MSE (mean (std)).", "description": "This table presents the Mean Squared Error (MSE) up to group sign for two different estimators (Estimator and Estimator-TR) under varying degrees of nonlinearity introduced by the leaky ReLU function. The experiment uses the GS case with 10k samples.  The results show the MSE under different alpha (\u03b1) values, which control the linearity of the leaky ReLU (\u03b1=0.8 being close to linear, \u03b1=0.6 quite nonlinear, and \u03b1=0.3 very nonlinear).  It demonstrates the robustness of the estimation methods to deviations from perfect linearity.", "section": "5.3 Misspecification Behavior"}]