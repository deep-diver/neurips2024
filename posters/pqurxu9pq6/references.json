{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduced CLIP, a foundational model for multi-modal contrastive learning, which the current paper builds upon and extends."}, {"fullname_first_author": "Le Xue", "paper_title": "ULIP: Learning a unified representation of language, images, and point clouds for 3D understanding", "publication_date": "2023-06-01", "reason": "This paper introduced ULIP, providing a crucial multi-modal model for 3D data that the current paper uses and extends."}, {"fullname_first_author": "Benjamin Elizalde", "paper_title": "CLAP: Learning audio concepts from natural language supervision", "publication_date": "2023-05-01", "reason": "This paper introduced CLAP, a model for audio-text contrastive learning, which is integrated into the methods of the current paper."}, {"fullname_first_author": "Rohit Girdhar", "paper_title": "ImageBind: One embedding space to bind them all", "publication_date": "2023-06-01", "reason": "This paper introduced ImageBind, which is a significant advancement in multi-modal learning that the current work compares to and leverages."}, {"fullname_first_author": "Zehan Wang", "paper_title": "Connecting multi-modal contrastive representations", "publication_date": "2023-05-01", "reason": "This paper is directly related to the current paper as it provides the foundation for the Ex-MCR model proposed in the current work."}]}