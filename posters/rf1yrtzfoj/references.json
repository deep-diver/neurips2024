{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is the basis of the research in this paper."}, {"fullname_first_author": "James Kirkpatrick", "paper_title": "Overcoming catastrophic forgetting in neural networks", "publication_date": "2017-03-15", "reason": "This paper addresses the problem of catastrophic forgetting in continual learning, which is a central challenge tackled by this paper."}, {"fullname_first_author": "Arslan Chaudhry", "paper_title": "On tiny episodic memories in continual learning", "publication_date": "2019-02-28", "reason": "This paper explores techniques to mitigate catastrophic forgetting in continual learning, directly relevant to this paper's focus on continual learning with vision-language models."}, {"fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "publication_date": "2022-09-01", "reason": "This work explores prompt-based methods for vision-language models, a key technique used and improved upon in this paper."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a large multimodal model, highlighting the increasing importance of multimodal foundation models in continual learning."}]}