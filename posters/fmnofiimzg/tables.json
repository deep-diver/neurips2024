[{"figure_path": "FmNoFIImZG/tables/tables_5_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained using six different downstream predictors on eight real-world tabular datasets.  The accuracy is evaluated using data augmentation with various methods, including TabEBM and several benchmark algorithms.  The results are shown for varying sizes of the real training dataset and are aggregated across the six predictors to provide a comprehensive comparison.  The table highlights TabEBM's consistent superior performance compared to using only real data or other augmentation techniques.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_7_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the results of a classification accuracy experiment comparing TabEBM against other data augmentation methods.  It shows the mean and standard deviation of balanced accuracy across several datasets, for different numbers of real training samples used and different numbers of classes in the dataset.  Higher accuracy ranks indicate better performance.  N/A indicates when the method wasn't applicable or the classifier failed to converge for a given data condition.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_9_1.jpg", "caption": "Table 2: Comparison of the properties between TabEBM and prior tabular generative methods. TabEBM has novel design rationales of training-free class-specific models, and TabEBM is highly practicable with wide applicability and consistent accuracy improvement.", "description": "This table compares TabEBM against other existing methods from three perspectives: training (the type of distribution learned and whether it's training-free), generation (whether class-specific models or stratified generation are used), and practicality (scalability to unlimited classes and consistent downstream accuracy improvements across different datasets).  Each method's characteristics are summarized with checkmarks or crosses, highlighting TabEBM's advantages.", "section": "Discussion & Related Work"}, {"figure_path": "FmNoFIImZG/tables/tables_17_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comparison of classification accuracy across various data augmentation techniques on eight real-world tabular datasets.  The accuracy is calculated using six different downstream predictors, averaged across multiple runs.  The table includes results for different real data set sizes, allowing for the evaluation of each method's performance under data scarcity. The mean and standard deviation of balanced accuracy are presented, along with an average rank across all datasets.  'N/A' indicates cases where a method was not applicable or did not converge.  The goal is to highlight TabEBM's consistent superior performance compared to using real data alone and other baseline/benchmark methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_24_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. Our method, TabEBM, consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained using six different downstream predictors on eight real-world tabular datasets.  The accuracy is calculated using data augmentation with various methods including TabEBM and several benchmark methods (SMOTE, TVAE, CTGAN, NFLOW, TabDDPM, ARF, GOGGLE, TabPFGen).  The table shows the mean and standard deviation of the balanced accuracy, and the average accuracy rank across all datasets for different sample sizes (20, 50, 100, 200, 500).  Results are presented to demonstrate TabEBM's superior performance compared to training only with real data and other generative methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_24_2.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. Our method, TabEBM, consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comparison of classification accuracy achieved by six different downstream predictors when using various data augmentation methods on eight real-world tabular datasets.  The results are shown for various sizes of the real training data, demonstrating how each augmentation method affects prediction accuracy.  The table highlights TabEBM's consistent superior performance over training with only real data and other benchmark methods across different dataset sizes and numbers of classes.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_25_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comprehensive comparison of the classification accuracy achieved by different data augmentation methods on eight real-world tabular datasets.  The results are aggregated across six downstream prediction models (LR, KNN, MLP, RF, XGBoost, TabPFN). The table shows the mean and standard deviation of the balanced accuracy for each dataset and various sample sizes (20, 50, 100, 200, 500).  A higher rank indicates better performance.  'N/A' signifies cases where a specific augmentation method was inapplicable or the predictor failed to converge.  The table highlights TabEBM's superior performance compared to baseline and other methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_27_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained using six different downstream predictors on eight real-world tabular datasets.  The accuracy is evaluated using data augmentation with several generative methods (including TabEBM), and results are shown for various amounts of real training data (Nreal).  The table reports the mean and standard deviation of the balanced accuracy, as well as the average rank across all datasets.  A higher rank indicates better performance.  'N/A' indicates cases where a generator was not applicable or the predictor failed to converge.  The key takeaway is that TabEBM consistently outperforms the baseline (no data augmentation) and other generative methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_28_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained using six different downstream predictors on eight real-world tabular datasets, with data augmentation performed by TabEBM and other state-of-the-art methods.  The table shows mean \u00b1 standard deviation of the balanced accuracy for different real data availabilities (Nreal).  Higher rank indicates better performance.  The \"N/A\" entries represent cases where a method was not applicable or the predictor did not converge.  TabEBM's consistently superior performance is highlighted by bolding the best accuracy for each dataset size.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_29_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy of six different downstream machine learning models trained on eight real-world tabular datasets.  The accuracy is evaluated using balanced accuracy (mean \u00b1 standard deviation) and average rank, across datasets, and for different sample sizes.  The results show the impact of data augmentation using TabEBM and other methods on classification accuracy.  Higher accuracy ranks indicate better performance.  \"N/A\" indicates that a method was inapplicable or the model failed to converge for a given dataset and sample size.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_30_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comparison of classification accuracy across different data augmentation methods on eight real-world tabular datasets. The accuracy is averaged across six downstream predictors (Logistic Regression, KNN, MLP, Random Forest, XGBoost, TabPFN) for different sample sizes (20, 50, 100, 200, 500).  The table reports mean \u00b1 standard deviation of balanced accuracy and the average rank across all datasets.  A higher rank indicates better performance. N/A indicates when a specific generator was not applicable or the predictor failed to converge. The results show that TabEBM consistently outperforms training on real data alone (Baseline) and other benchmark generators (SMOTE, TVAE, CTGAN, NFLOW, TabDDPM, ARF, GOGGLE, TabPFGen).", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_31_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comparison of classification accuracy across multiple tabular datasets, using six different prediction models and nine different data generation methods. The results are organized by dataset, sample size, and method, showing mean balanced accuracy and rank. The table highlights the performance of TabEBM, a newly proposed method, relative to baseline and other well-established methods.  It shows the impact of data augmentation on model accuracy across various datasets and sample sizes, particularly highlighting TabEBM's superior performance, especially in small datasets.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_32_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results of six different downstream predictors, each trained on synthetic data generated using different data augmentation methods (including TabEBM) and real data.  The results are averaged across eight tabular datasets, with varying amounts of real training data used.  The table shows the mean and standard deviation of balanced accuracy, as well as the average rank of the models, where a higher rank indicates better performance.  The \u201cN/A\u201d entries indicate cases where either a specific data augmentation method was not applicable to the dataset or the predictor model failed to converge during training.  The key takeaway is that TabEBM consistently outperforms both training on real data alone (Baseline) and other data augmentation methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_33_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the results of a classification accuracy experiment comparing TabEBM against several other data augmentation methods.  The experiment measures the balanced accuracy and average accuracy rank across eight real-world tabular datasets with varying amounts of real training data.  Higher ranks indicate better performance.  'N/A' indicates where a method wasn't applicable or the downstream predictor didn't converge.  The table highlights TabEBM's consistent superior performance.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_33_2.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained from six different downstream predictors using eight real-world tabular datasets.  The accuracy is evaluated with varied amounts of real training data (Nreal), showing the impact of data augmentation.  The table reports the mean and standard deviation of balanced accuracy and the average rank across all datasets for each data augmentation method, including TabEBM and eight benchmark methods. A higher rank indicates better performance.  'N/A' indicates where a method was not applicable or the predictor failed to converge.  The results demonstrate TabEBM's superior performance, consistently outperforming methods that use only real data and other benchmark data augmentation techniques.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_33_3.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results achieved by various data augmentation methods on eight real-world datasets.  The accuracy is averaged across six different downstream prediction models and reported with standard deviation for both balanced and average accuracy.  Higher ranks indicate better performance.  The table shows results for different amounts of real training data to demonstrate the effect of data augmentation on datasets of varying size. Notably, it highlights TabEBM's superior performance compared to using real data alone and other benchmark methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_34_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results obtained using six different downstream predictors on eight real-world tabular datasets.  The accuracy is evaluated with and without data augmentation using nine different data generation methods, including TabEBM.  The table shows mean and standard deviation of balanced accuracy for different sample sizes of the training data.  A higher rank indicates a better performance.  Note that some methods were not applicable to all datasets or predictors; where this occurred the rank was computed from the mean of the other methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_35_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for eight real-world tabular datasets.  Six different downstream predictors were used, and the results are averaged.  Data augmentation was performed using TabEBM and eight other methods at various real data availabilities (sample sizes).  The table reports the mean and standard deviation of balanced accuracy for each method, dataset, and sample size and includes a ranking of methods by accuracy.  'N/A' indicates when a method was not applicable or failed to converge for a particular combination of dataset and sample size. TabEBM consistently outperforms other methods, especially in low-sample-size scenarios.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_36_1.jpg", "caption": "Table 7: Classification accuracy (%) of LR, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the results of a classification accuracy experiment using Logistic Regression (LR).  Eight real-world tabular datasets were used, with varying amounts of real training data. The table shows the mean and standard deviation of balanced accuracy and an average accuracy rank across the datasets.  The rank is higher for better performance.  'N/A' indicates cases where a specific data generator was not applicable or where the LR model failed to converge. The table highlights the superior performance of the proposed TabEBM method against a baseline (no data augmentation) and other state-of-the-art data augmentation methods.", "section": "D.5.1 Results on eight OpenML datasets"}, {"figure_path": "FmNoFIImZG/tables/tables_37_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents a comparison of classification accuracy across eight real-world tabular datasets using six different downstream predictors.  The comparison includes TabEBM and eight other data generation methods, with varying amounts of real training data.  The results are aggregated to show the average balanced accuracy and rank for each method under different conditions.  The table highlights TabEBM's superior performance, especially when real data is scarce.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_38_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for eight real-world tabular datasets, comparing different data augmentation methods and the baseline (no augmentation). Six downstream predictors were used.  The table shows the mean and standard deviation of the balanced accuracy for each method across different sample sizes (20, 50, 100, 200, 500). The average accuracy rank across all datasets is also provided.  Note that N/A values indicate that a method was not applicable for a particular dataset or sample size.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_39_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results from six different downstream prediction models using eight different tabular datasets.  The results compare the performance of TabEBM against several baseline and benchmark data augmentation techniques.  The accuracy is reported as the mean \u00b1 standard deviation of the balanced accuracy, and the average rank across datasets is also shown, with a higher rank indicating better performance.  The table demonstrates that TabEBM consistently outperforms using real data alone, particularly in datasets with fewer samples.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_40_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for eight real-world tabular datasets using six different downstream predictors.  The accuracy is evaluated using data augmentation with various generative models, including TabEBM and several state-of-the-art methods.  The table shows the mean and standard deviation of the balanced accuracy and an average accuracy rank across all datasets, providing a comparative analysis of the different methods' performance at various sample sizes. The best performing method is highlighted for each dataset and sample size.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_41_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for eight datasets using six different downstream predictors.  The accuracy is calculated using the mean \u00b1 standard deviation of the balanced accuracy across multiple runs for different sample sizes (20, 50, 100, 200, 500) and compared across different data augmentation methods (SMOTE, TVAE, CTGAN, NFLOW, TabDDPM, ARF, GOGGLE, TabPFGen, and TabEBM). A higher rank indicates better performance.  The table shows TabEBM consistently outperforms other methods, especially with smaller datasets.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_42_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results of six different downstream predictors trained using data augmented by eight different tabular data generators on eight datasets.  The results are organized by dataset, the number of real data samples used for training, and the method used for data augmentation.  The table shows the mean and standard deviation of the balanced accuracy, as well as the average rank across all datasets.  A higher rank indicates better performance.  TabEBM consistently outperforms the baseline and other benchmark data augmentation methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_43_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for different data augmentation methods on eight tabular datasets.  The accuracy is averaged across six different downstream prediction models. The table shows the mean and standard deviation of the balanced accuracy for each method and dataset, along with the average rank of each method across all datasets.  A higher rank indicates better performance.  The table also highlights that TabEBM consistently outperforms the baseline (no data augmentation) and other methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_44_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results of six different downstream predictors (Logistic Regression, KNN, MLP, Random Forest, XGBoost, and TabPFN) when applied to eight real-world tabular datasets after data augmentation with nine different methods (Baseline, SMOTE, TVAE, CTGAN, NFLOW, TabDDPM, ARF, GOGGLE, TabPFGen, TabEBM). The table shows the mean and standard deviation of the balanced accuracy for each method and dataset, with different sizes of real training data (Nreal) used for augmentation.  A higher rank indicates better performance.  It highlights TabEBM's consistent outperformance across various dataset sizes and the Baseline.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_45_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the results of comparing TabEBM's performance to eight other tabular data generation methods across various sample sizes and eight datasets.  The table shows the mean and standard deviation of the balanced accuracy for each method, as well as the average rank of each method across the datasets.  A higher rank indicates better performance. The table highlights TabEBM's consistent superior performance.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_46_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. Our method, TabEBM, consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results from six different downstream predictors using eight real-world tabular datasets.  The results compare the performance of data augmentation using TabEBM against eight other data generation methods and a baseline (no augmentation).  Accuracy is measured using mean \u00b1 std balanced accuracy and average rank.  The table shows TabEBM's consistent superior performance compared to the other methods and the baseline, especially in low sample size scenarios.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_47_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results of six different downstream predictors (LR, KNN, MLP, RF, XGBoost, TabPFN) across eight real-world tabular datasets.  The accuracy is calculated using both real data and synthetic data generated by TabEBM and other methods (SMOTE, TVAE, CTGAN, NFLOW, TabDDPM, ARF, GOGGLE, TabPFGen). The table compares the performance of different data augmentation techniques using mean \u00b1 std balanced accuracy and average rank across datasets.  A higher rank indicates better performance.  N/A indicates that a specific generator was not applicable or the predictor failed to converge.  The best performing method for each dataset and sample size is highlighted in bold.", "section": "3.1 Data Augmentation Improvement (Q1)"}, {"figure_path": "FmNoFIImZG/tables/tables_48_1.jpg", "caption": "Table 1: Classification accuracy (%) aggregated over six downstream predictors, comparing data augmentation on eight real-world tabular datasets with varied real data availability. We report the mean \u00b1 std balanced accuracy and average accuracy rank across datasets. A higher rank implies higher accuracy. Note that \u201cN/A\u201d denotes that a specific generator was not applicable or the downstream predictor failed to converge, and the rank is computed with the mean balanced accuracy of other methods. We bold the highest accuracy for each dataset of different sample sizes. TabEBM consistently outperforms training on real data alone, and achieves the best overall performance against Baseline and benchmark generators.", "description": "This table presents the classification accuracy results for eight real-world tabular datasets, comparing different data augmentation methods.  Six different downstream predictors were used to evaluate the performance of each method with varying amounts of real training data.  The table reports mean and standard deviation of the balanced accuracy for each method and dataset size, along with the average accuracy rank.  TabEBM consistently outperforms the baseline (no data augmentation) and other state-of-the-art methods.", "section": "3.1 Data Augmentation Improvement (Q1)"}]