[{"figure_path": "FmNoFIImZG/figures/figures_0_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This radar chart compares TabEBM against other state-of-the-art tabular data generation methods across six metrics: Inverse KL, KS test, Efficiency, Utility, DCR, and \u03b4-presence.  Each axis represents a metric, and the area of each polygon section corresponds to the method's performance on that metric. A larger polygon area indicates better performance.  The chart highlights TabEBM's superior performance in data augmentation (utility), demonstrating its effectiveness in generating high-quality synthetic data.", "section": "Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_1_1.jpg", "caption": "Figure 2: An overview of TabEBM. We learn distinct class-specific Energy-Based Models (EBMs) Eblue(x) and Ered(x) exclusively on the points of their respective class. Each EBM approximates a class-conditional distribution p(x|y). TabEBM allows synthetic data generation by sampling from the estimated distributions for each class p(x|y = blue) and p(x|y = red).", "description": "This figure illustrates the TabEBM process.  First, the real data, separated by class (blue and red), is shown. Then, two separate EBMs, one for each class, are trained on their respective data. Each EBM learns the class-conditional distribution p(x|y), where x represents the data features and y represents the class label.  Finally, new synthetic data is generated by sampling from the learned class-conditional distributions. This illustrates the key concept of using distinct class-specific EBMs for more robust generation, especially on small or ambiguous datasets.", "section": "2 TabEBM"}, {"figure_path": "FmNoFIImZG/figures/figures_2_1.jpg", "caption": "Figure 3: The class-specific energy function E<sub>c</sub>(x) from the surrogate binary task, where the blue region represents low energy (i.e., high data density). Placing the negative samples in a hypercube distant from the data results in an accurate energy function.", "description": "This figure shows the energy landscape learned by TabEBM for a single class.  The blue areas represent low energy, corresponding to high probability density. The dark orange dots represent negative samples that are placed far from the real data points (light blue dots) in the corners of a hypercube.  The placement of negative samples is a key aspect of TabEBM;  it allows TabPFN, the classifier used to construct the energy function, to learn accurate marginal class distributions even when classes overlap or are unbalanced.  The figure highlights TabEBM's ability to generate robust energy landscapes that accurately capture the data distribution.", "section": "Distinct Class-Specific Energy-Based Models"}, {"figure_path": "FmNoFIImZG/figures/figures_6_1.jpg", "caption": "Figure 4: Mean normalised balanced accuracy improvement (%) across different sample sizes (Left) and across datasets with varying numbers of classes (Right). Because TabPFGen is not applicable for datasets with more than ten classes, we plot short bars at zeros for visual clearance. Positive values indicate that the generator improves downstream classification performance. TabEBM generally outperforms benchmark generators across varying sample sizes and number of classes.", "description": "This figure shows the results of experiments evaluating the impact of TabEBM on data augmentation. The left panel shows the mean normalized balanced accuracy improvement across different sample sizes (20, 50, 100, 200, 500) for various tabular data augmentation methods, highlighting the consistent superior performance of TabEBM, especially for small datasets.  The right panel displays the mean normalized balanced accuracy improvement across datasets with varying numbers of classes.  TabEBM again shows a marked improvement compared to other methods, particularly those with more than 10 classes, indicating its robustness in complex, multi-class scenarios.", "section": "3 Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_6_2.jpg", "caption": "Figure 4: Mean normalised balanced accuracy improvement (%) across different sample sizes (Left) and across datasets with varying numbers of classes (Right). Because TabPFGen is not applicable for datasets with more than ten classes, we plot short bars at zeros for visual clearance. Positive values indicate that the generator improves downstream classification performance. TabEBM generally outperforms benchmark generators across varying sample sizes and number of classes.", "description": "This figure shows the mean normalized balanced accuracy improvement achieved by different data augmentation methods across various sample sizes (left panel) and different numbers of classes (right panel).  The left panel demonstrates that TabEBM consistently outperforms other methods, particularly with smaller sample sizes.  The right panel illustrates TabEBM's robustness across different numbers of classes, whereas other methods show performance degradation as the number of classes increases.", "section": "3 Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_6_3.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM against other state-of-the-art tabular generative models using six different metrics: KS test, Inverse KL, Efficiency, Utility, DCR, and \u03b4-presence.  Each metric is represented as a polygon whose area corresponds to the model's performance on that metric, with larger areas indicating better performance. The figure shows that TabEBM outperforms all other methods, particularly in terms of data augmentation (utility).", "section": "Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_7_1.jpg", "caption": "Figure 8: (Left) Logit distribution of TabPFN trained on our surrogate binary tasks at increasing distances from the real data (on \u201csteel\u201d). (Right) The corresponding unnormalised density approximated by TabEBM. TabEBM assigns higher density closer to the real data.", "description": "This figure shows the logit distribution learned by TabPFN, a pre-trained tabular in-context model, when trained on surrogate binary classification tasks.  The left panel plots the logits against the Euclidean distance from real data points. As the distance increases, the logits decrease, indicating uncertainty as the classifier becomes less sure of the class label. The right panel shows the unnormalized density estimated by TabEBM using these logits.  It reveals that the estimated density decreases sharply as the distance from real data increases, indicating TabEBM effectively captures data distribution and focuses on generating samples close to the real data.", "section": "3.4 Why is TabEBM effective for estimating Energy-Based Models? (Q4)"}, {"figure_path": "FmNoFIImZG/figures/figures_18_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM to 8 other state-of-the-art tabular data generation methods across 6 different metrics that evaluate the quality of the generated synthetic data.  The size of each colored area on the radar chart is proportional to the performance of the corresponding method on the metric.  A larger area indicates better performance. TabEBM is shown to outperform the others, particularly regarding the \"utility\" metric which specifically measures the effectiveness of data augmentation.", "section": "Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_20_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM against other state-of-the-art tabular data generation methods using six evaluation metrics (KS test, Inverse KL, Efficiency, Utility, DCR, and 8-presence).  Each method is represented by a polygon whose area corresponds to its overall performance across all metrics.  Larger areas indicate better performance.  The figure highlights that TabEBM has the largest area, indicating superior performance, especially in data augmentation (utility).", "section": "Experiments"}, {"figure_path": "FmNoFIImZG/figures/figures_21_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM against eight other state-of-the-art tabular generative methods using six evaluation metrics: KS test, inverse KL, efficiency, utility, DCR, and \u03b4-presence.  Each method is represented by a polygon where the size of the polygon's area corresponds to its performance. TabEBM's larger area indicates superior performance across the metrics, particularly in the \"utility\" metric, demonstrating its effectiveness in data augmentation.", "section": "1 Introduction"}, {"figure_path": "FmNoFIImZG/figures/figures_22_1.jpg", "caption": "Figure 12: Evaluating the approximated class-conditional distributions on a toy dataset of 300 samples with varying class imbalances. The two clusters maintain their positions. Darker blue indicates a higher assigned probability. TabPFGen uses a single shared energy-based model to infer the class-conditional distribution p(x|y). As class imbalance increases, TabPFGen starts assigning high probability in areas far from the real data, for instance, in the case of p(x|y = 1) for class ratio 10:290. In contrast, our TabEBM fits class-specific energy models only on the class-wise data Xc = {x(i) | Yi = c}. This results in very robust inferred conditional distributions even under heavy class imbalance (e.g., see that p(x|y = 1) remains relatively constant).", "description": "This figure compares the performance of TabPFGen and TabEBM in approximating class-conditional distributions under various levels of class imbalance.  It shows that TabPFGen, using a single shared model, struggles to accurately represent the distributions as imbalance increases, while TabEBM, using distinct class-specific models, maintains robust and accurate approximations even under severe imbalance.", "section": "Distinct Class-Specific Energy-Based Models"}, {"figure_path": "FmNoFIImZG/figures/figures_23_1.jpg", "caption": "Figure 3: The class-specific energy function E<sub>c</sub>(x) from the surrogate binary task, where the blue region represents low energy (i.e., high data density). Placing the negative samples in a hypercube distant from the data results in an accurate energy function.", "description": "This figure shows how the class-specific energy function, a key component of TabEBM, is learned from real data samples (blue) and artificial negative samples (orange).  The negative samples are strategically placed at the corners of a hypercube to ensure that they are easily distinguishable from the real data points.  The resulting energy function accurately reflects the data density, with lower energy values corresponding to regions of higher probability density.  This accurate representation is crucial for the effectiveness of the TabEBM model in generating high-quality synthetic data.", "section": "Distinct Class-Specific Energy-Based Models"}, {"figure_path": "FmNoFIImZG/figures/figures_25_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM against several other state-of-the-art tabular data generation methods across six different evaluation metrics. Each method is represented by a polygon, where the size of the polygon corresponds to its performance. The larger the polygon, the better the performance. TabEBM shows the largest polygon, indicating that it significantly outperforms other methods in terms of utility for data augmentation.", "section": "Introduction"}, {"figure_path": "FmNoFIImZG/figures/figures_26_1.jpg", "caption": "Figure 1: Evaluation of TabEBM and other state-of-the-art tabular generative methods across six key metrics (larger area indicates better performance). The results demonstrate that TabEBM excels in data augmentation (utility), with a larger area than all other methods.", "description": "This figure compares TabEBM against other state-of-the-art tabular generative models using six evaluation metrics: KS test, inverse KL, efficiency, utility, DCR, and \u03b4-presence. Each metric is represented as a 2D area where larger area represents better performance. The results show that TabEBM outperforms other methods, especially in data augmentation (utility).", "section": "Experiments"}]