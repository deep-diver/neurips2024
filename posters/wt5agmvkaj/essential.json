{"importance": "This paper is crucial for researchers in computer vision and AI, particularly those working on image retrieval and responsible AI.  It directly addresses the significant problem of **misalignment between vision models and human aesthetic preferences**, a challenge hindering the widespread adoption of AI-powered retrieval systems. By introducing a novel method combining large language models, reinforcement learning, and novel benchmarks, this research **opens exciting new avenues for developing more human-centric and responsible AI systems.** Its findings will likely influence future retrieval algorithms and inspire related work concerning AI alignment with human values.", "summary": "This paper presents a novel method to align vision models with human aesthetics in image retrieval, using large language models (LLMs) for query rephrasing and preference-based reinforcement learning for model fine-tuning, achieving significant improvement in aesthetic behavior, as validated through a novel benchmark dataset.", "takeaways": ["A novel method is proposed to align vision models with human aesthetics in image retrieval, effectively combining LLMs, reinforcement learning, and aesthetic models.", "The method significantly improves the aesthetic quality of retrieval results, surpassing existing approaches.", "A novel benchmark dataset, HPIR, is introduced to evaluate the alignment of retrieval systems with human aesthetics, addressing a significant gap in the current benchmarks."], "tldr": "Modern vision models, while powerful, often fail to align with human aesthetic preferences in image retrieval tasks. This is problematic as it leads to outputs that might not reflect user intents or even be harmful. Existing retrieval systems that address this issue using cascaded aesthetic models are limited to low-level features and fail to consider broader contexts, such as culture or knowledge. This paper proposes a novel method to tackle this limitation by combining large language models (LLMs) with reinforcement learning.  The LLM is used to enrich search queries by explicitly adding information related to the user's understanding of beauty. The refined query is then used to retrieve images using a vision model, whose outputs are then reranked using public aesthetic models to incorporate inductive biases. Finally, a preference-based reinforcement learning method fine-tunes the vision model to further align with human preferences. This approach addresses the limitations of existing methods by incorporating high-level reasoning and contextual information into the retrieval process. The paper evaluates the proposed method using two new benchmarks: a human-judged dataset (HPIR) and GPT-4V.  Experimental results show that the proposed method significantly enhances the aesthetic quality of image retrieval results.", "affiliation": "Southeast University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "wT5AgMVkaJ/podcast.wav"}