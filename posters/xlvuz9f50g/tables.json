[{"figure_path": "XlvUz9F50g/tables/tables_2_1.jpg", "caption": "Table 1: Regret bounds for partial monitoring, graph bandits, and multi-armed bandits (MAB) with paid observations. The number of rounds is denoted as T, the number of actions as k, and the minimum suboptimality gap as Amin. The variables cg is defined in Section 5, D is a constant dependent on the outcome distribution. The graph complexity measures \u03b4, \u03b4*, satisfying \u03b4* < \u03b4 for graphs with no self-loops, are defined in Section 6, and \u03b4* < \u03b4 is the fractional weak domination number [13]. The parameter c is the paid cost for observing a loss of actions. AwSB is the abbreviation of the adversarial regime with a self-bounding constraint. MS-type means that the bound in AdvSB has a form similar to the bound established by Masoudian and Seldin [43].", "description": "This table compares the regret bounds (in both stochastic and adversarial settings, and adversarial setting with self-bounding constraint) achieved by different algorithms for three online learning problems: partial monitoring, graph bandits, and multi-armed bandits with paid observations.  The comparison highlights the improvements achieved by the proposed algorithm, particularly in achieving the best-of-both-worlds (BOBW) property.", "section": "1 Introduction"}, {"figure_path": "XlvUz9F50g/tables/tables_3_1.jpg", "caption": "Table 1: Regret bounds for partial monitoring, graph bandits, and multi-armed bandits (MAB) with paid observations. The number of rounds is denoted as T, the number of actions as k, and the minimum suboptimality gap as Amin. The variables cg is defined in Section 5, D is a constant dependent on the outcome distribution. The graph complexity measures \u03b4, \u03b4*, satisfying \u03b4* < \u03b4 for graphs with no self-loops, are defined in Section 6, and \u03b4* < \u03b4 is the fractional weak domination number [13]. The parameter c is the paid cost for observing a loss of actions. AwSB is the abbreviation of the adversarial regime with a self-bounding constraint. MS-type means that the bound in AdvSB has a form similar to the bound established by Masoudian and Seldin [43].", "description": "This table compares the regret bounds for three online learning problems: partial monitoring, graph bandits, and multi-armed bandits with paid observations, under both stochastic and adversarial settings.  It shows existing results and the improved bounds achieved by the proposed method.  Key parameters like number of rounds (T), actions (k), and suboptimality gap (Amin) are included.", "section": "1 Introduction"}]