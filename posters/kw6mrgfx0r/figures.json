[{"figure_path": "Kw6MRGFx0R/figures/figures_2_1.jpg", "caption": "Figure 1: Binary weights initialization phase: starting from the target weight W, we construct N binary matrices B\u00bf and scaling vectors a\u017c analytically. The 1st binary weight and scaling vector are obtained using Eq. 2 while the subsequent ones use Eq. 3.", "description": "This figure illustrates the process of initializing binary weights.  Starting with the original weight matrix W, the method iteratively creates N binary matrices (B1 to BN) and their corresponding scaling vectors (\u03b11 to \u03b1N). Each binary matrix approximates the residual error from the previous approximation. The first binary matrix and scaling vector are calculated analytically using equation 2, and subsequent ones are calculated using equation 3.  This analytical initialization serves as the foundation for the subsequent iterative optimization.", "section": "3.1 Layer-wise input-agnostic weights binarization"}, {"figure_path": "Kw6MRGFx0R/figures/figures_2_2.jpg", "caption": "Figure 2: Iterative weights binarization: Starting from the weights initialized as shown in Fig. 1, we update the binary weights one-by-one, where at each step i \u2208 {1 . . . N}, only B\u00bf is updated by minimizing the loss function in eq. (4), while the rest are frozen. Note that all of the scaling vectors a\u017c are updated at every step.", "description": "This figure illustrates the iterative process of weights binarization.  Starting with weights initialized analytically (as in Figure 1), the algorithm iteratively refines the approximation of the original weights using multiple binary matrices (Bi) and scaling vectors (\u03b1i).  In each step, only one binary matrix is updated while minimizing the L2 distance between the approximation and the original weights. All scaling vectors are updated in every step.", "section": "3.1 Layer-wise input-agnostic weights binarization"}, {"figure_path": "Kw6MRGFx0R/figures/figures_5_1.jpg", "caption": "Figure 3: Per-layer reconstruction error for a Phi-2 model when varying the initialization used: random, without the cascaded (residual) init, and with.", "description": "This figure compares the per-layer reconstruction error of a Phi-2 model under three different weight initialization strategies: random initialization, initialization without the cascaded (residual) method, and initialization with the cascaded method.  The cascaded initialization method, a key component of the proposed QBB approach, shows significantly lower errors, demonstrating its effectiveness in minimizing the quantization error for each layer.", "section": "4.1 Impact of the proposed components"}, {"figure_path": "Kw6MRGFx0R/figures/figures_5_2.jpg", "caption": "Figure 4: Proportion of binary weights that changed their state (bit flips) after applying the proposed iterative training process, shown for the first 20 layers of a Phi-2 model for all 4 bases.", "description": "This figure visualizes the changes in binary weights during the iterative training process of the proposed quantization method.  It shows, for each of the four binary bases used in approximating the weight matrix, the proportion of weights that change their value (+1 to -1 or vice versa) across 20 layers of a Phi-2 language model. The figure helps in understanding how different bases are modified to obtain better accuracy and the impact of the iterative approach on the weight adjustments across different layers of the model.", "section": "4.2 Binary weights and process analysis"}, {"figure_path": "Kw6MRGFx0R/figures/figures_6_1.jpg", "caption": "Figure 5: The PPL on WikiText-2 with Phi-2 (2.7b) trained on a variable number of training samples. Here, we compare the performance when using the generated data directly, or when filtering is applied.", "description": "This figure shows the perplexity (PPL) on the WikiText-2 benchmark for a Phi-2 (2.7B) model trained using different numbers of training samples. Two training strategies are compared: one using randomly generated data and another using filtered data (only keeping sequences with high teacher-student discrepancy). The filtered data approach leads to faster convergence and lower perplexity for the same number of samples, demonstrating its efficiency.", "section": "4.4 Effect of data filtering"}, {"figure_path": "Kw6MRGFx0R/figures/figures_6_2.jpg", "caption": "Figure 6: Per-layer reconstruction error after the initial layer-by-layer optimization for a Phi-2 model. Notice that the performance is generally stable for N \u2265 3.", "description": "This figure shows the L2 error (reconstruction error) for each layer of a Phi-2 model after the initial layer-by-layer optimization. The x-axis represents the layer ID, and the y-axis shows the L2 error. Multiple lines represent the error for different numbers of binary bases (N) used in the approximation.  The figure demonstrates that the reconstruction error is generally stable and low when using 3 or more binary bases (N\u22653), indicating that the proposed method effectively approximates the weights with the selected number of bases.", "section": "4.5 How many binary bases should we use?"}, {"figure_path": "Kw6MRGFx0R/figures/figures_7_1.jpg", "caption": "Figure 7: Per-layer reconstruction error after the initial layer-by-layer optimization for a Phi-2 model. Notice that the performance is generally stable for N \u2265 3.", "description": "This figure compares the per-layer reconstruction error achieved by two different optimization strategies: iterative and simultaneous.  The iterative approach, which updates binary weights one-by-one, shows significantly lower errors than the simultaneous update method. The results indicate that the proposed iterative strategy is more stable and effective for optimizing binary weights, particularly important in layers that are challenging to quantize. This figure supports the claim that the iterative approach improves the overall binarization process and is especially beneficial in handling the quantization challenges present in harder-to-quantize layers.", "section": "4.5.1 Effect of iterative optimisation"}]