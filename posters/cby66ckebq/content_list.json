[{"type": "text", "text": "A Unified Principle of Pessimism for Offline Reinforcement Learning under Model Mismatch ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yue Wang Zhongchang Sun Department of Electrical and Computer Engineering epartment of Electrical Engineering University of Central Florida University at Buffalo Orlando, FL, 32816 Buffalo, NY, 14260 yue.wang@ucf.edu zhongcha@buffalo.edu ", "page_idx": 0}, {"type": "text", "text": "Shaofeng Zou School of Electrical, Computer and Energy Engineering Arizona State University Tempe, AZ 85287 zou@asu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we address the challenges of offline reinforcement learning (RL) under model mismatch, where the agent aims to optimize its performance through an offline dataset that may not accurately represent the deployment environment. We identify two primary challenges under the setting: inaccurate model estimation due to limited data and performance degradation caused by the model mismatch between the dataset-collecting environment and the target deployment one. To tackle these issues, we propose a unified principle of pessimism using distributionally robust Markov decision processes. We carefully construct a robust MDP with a single uncertainty set to tackle both data sparsity and model mismatch, and demonstrate that the optimal robust policy enjoys a near-optimal sub-optimality gap under the target environment across three widely used uncertainty models: total variation, $\\chi^{\\tilde{2}}$ divergence, and KL divergence. Our results improve upon or match the state-of-the-art performance under the total variation and KL divergence models, and provide the first result for the $\\chi^{2}$ divergence model. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Reinforcement learning (RL) [40] learns a policy to maximize cumulative rewards through online interactions with the environment. However, in real-world applications such as autonomous vehicles [16] and health care [61], the trial-and-error nature of interacting with the environment can be both costly and dangerous, rendering online learning impractical. To circumvent these challenges, the concept of offilne RL has emerged [17, 18], seeking to learn an optimal policy from a pre-collected dataset, eliminating the need for real-time interaction with the environment. ", "page_idx": 0}, {"type": "text", "text": "Despite its potential, offline RL faces two significant challenges that impact its performance. The first challenge stems from the nature of the offline dataset itself. Offline RL demonstrates impressive performance only when the dataset is of high quality, as exemplified by [41, 9, 52, 18]. However, in most RL scenarios, the data collection process can be expensive, constrained, and subject to specific behavior policies. This often results in a dataset with insufficient samples and limited coverage. The limited coverage of state-action pairs in the dataset presents a substantial hurdle, making it challenging to fully learn the environment model and the model learned may be inaccurate, leading to a poorly performing policy. and hindering the discovery of the optimal policy, particularly when the behavior policy is sub-optimal. Existing solutions involve introducing pessimism during policy learning, by penalizing the reward function for state-action pairs that are not adequately covered by the dataset, known as the lower confidence bound (LCB) approach [15, 33, 19], demonstrating potential both numerically and theoretically in solving offline RL. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The second critical challenge in offline RL pertains to its vulnerability to model mismatch. As the offline dataset is collected in advance, it only encapsulates the environment\u2019s information at the time of data collection. In practical applications, environments often undergo variations due to e.g., unexpected perturbations, heterogeneity, or non-stationarity. This inherent variability introduces a model mismatch between the target environment and the one where the dataset is collected, leading to significant performance degradation when deploying the learned policy in the real environment. Robust RL or distributionally robust optimization (DRO) framework is then proposed to address this challenge [13, 28], which incorporates the pessimism principle to effectively tackle model uncertainty. By constructing an uncertainty set containing \u2018plausible\u2019 environments, robust RL optimizes the worst-case performance among them, providing a performance guarantee for the real environment. ", "page_idx": 1}, {"type": "text", "text": "To summarize, there are two sources of uncertainty in offline RL: Uncertainty from limited data: This stems from the inherent uncertainty introduced by limited offilne datasets and lack of exploration; Uncertainty from model-mismatch: This arises from distribution shifts between data-collection and deployment environments, as well as between data-collection distribution and the distribution induced by the optimal policy. Each challenge can be addressed through its corresponding principle of pessimism, as in previous works: limited data coverage can be mitigated with reward estimation penalties (LCB), while model mismatch can be tackled with distribution estimation penalties (DRO). However, existing approaches often address these uncertainties separately, e.g., [36, 5, 24], leading to methodological redundancy or complexity (more discussions and comparisons can be found in Section 5). In this paper, we propose a unified framework that integrates both principles of pessimism into a single robust Markovian decision process (MDP) model for offline RL, offering a clear and streamlined conceptual formulation and providing improved or matched theoretical guarantees compared to existing methods. Our major contributions can be summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "A unified distributionally robust formulation for offline RL under model mismatch. As discussed before, offline RL faces challenges including limited dataset coverage and model mismatch. Specifically, we first tackle the challenge of model mismatch using the approach of distributionally robust MDP, which optimizes the worst-case performance over an uncertainty set specified by e.g., total variation, $\\chi^{2}$ or Kullback-Leibler divergence. We then show that the uncertainty from data sparsity can be transformed into a data-dependent penalization term that is added to the radius of the constructed uncertainty set. Our formulation hence unifies the two principles of pessimism to a single DRO problem that tackles both sources of uncertainty without additional structures and enjoys an easier implementation compared to existing works. ", "page_idx": 1}, {"type": "text", "text": "Augmented design of radius to achieve tight theoretical guarantees. Designing the uncertainty set for the model mismatch is typically straightforward, often relying on domain knowledge [39]. However, incorporating an additional penalty term to address data sparsity presents significant challenges. Balancing the conservativeness for less-visited state-action pairs estimation and the overall performance of learned policies requires careful consideration. In our work, we conduct a meticulous analysis to understand how the penalty radius impacts the performance of the learned policy. We then design penalty radii for three widely studied uncertainty set models: total variation, $\\bar{\\chi}^{2}$ divergence, and KL divergence. Our analysis provides insights into the performance of learned policies under these penalty radii, showcasing the versatility of our framework across both metricbased and non-metric-based models. Moreover, our designs enable us to derive tight theoretical guarantees. Specifically, we improve upon existing results for robust offline RL under the total variation model [5], match the state-of-the-art performance under the KL divergence model [36], and present the first result under the $\\chi^{2}$ divergence model. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Markov Decision Process (MDP) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "An MDP is specified by a tuple $(\\mathcal{S},\\mathcal{A},\\mathsf{P},r,\\gamma)$ , where S and $\\mathcal{A}$ are the state and action spaces, respectively, $\\bar{\\mathsf{P}}=\\{\\mathsf{P}_{s}^{a}\\in\\varDelta(\\bar{\\mathsf{S}}),s\\in\\mathring{\\mathsf{S}},a\\in\\varDelta\\}^{1}$ is the transition kernel, $r:\\mathcal{S}\\times\\mathcal{A}\\to[0,1]$ denotes the reward function, and $\\gamma\\in[0,1)$ is the discount factor. Let $S$ be the number of states and $A$ be the number of actions. For any transition kernel P, $\\mathsf{P}_{s}^{a}=\\big(p_{s,s^{\\prime}}^{a}\\big)_{s^{\\prime}\\in\\mathcal{S}}$ , where $p_{s,s^{\\prime}}^{a}$ denotes the probability of transiting from state $s$ to state $s^{\\prime}$ after taking action $a$ . The reward of the transition when taking action $a$ at state $s$ is denoted by $r(s,a)$ . ", "page_idx": 2}, {"type": "text", "text": "For a stationary policy $\\pi$ that maps from state $s\\in\\mathcal{S}$ to a distribution over action $a\\in{\\mathcal{A}}$ , it specifies the probability of the agent taking actions at each state. The value function of a policy $\\pi$ is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\nV_{\\mathsf{P}}^{\\pi}(s)\\triangleq\\mathbb{E}_{\\mathsf{P}}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,\\pi\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbb{E}_{\\mathsf{P}}$ denotes the expectation with respect to the distribution induced by the transition kernel $\\mathsf{P}$ . Let $\\rho$ be the distribution of the initial state $s$ , the value function under the distribution $\\rho$ is denoted by $V_{\\mathsf{P}}^{\\pi}(\\rho)\\,=\\,\\mathbb{E}_{s\\sim\\rho}[V_{\\mathsf{P}}^{\\pi}(s)]$ . Let $d_{\\mathsf{P}}^{\\pi}(s)$ and $d_{\\mathsf{P}}^{\\pi}(s,a)$ denote the state occupancy measure and state-action occupancy measure of policy $\\pi$ when the initial state $s$ follows distribution $\\rho$ : $\\begin{array}{r}{d_{\\mathsf{P}}^{\\pi}(s)=(1-\\gamma)\\sum_{t=0}^{\\infty^{*}}\\gamma^{t}\\mathbb{\\dot{P}}(s_{t}=s|s_{0}\\sim\\dot{\\rho},\\pi,\\dot{\\mathsf{P}}),d_{\\mathsf{P}}^{\\pi}(s,a)=d_{\\mathsf{P}}^{\\pi}(s)\\pi(a|s).}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "2.2 Distributionally Robust MDP ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A robust MDP is defined as $(\\mathcal{S},\\mathcal{A},\\mathcal{P},r,\\gamma)$ , where the transition kernel is not fixed but lies in some uncertainty set $\\Phi$ . In this work we consider the $(s,a)$ -rectangular uncertainty set: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{P}=\\bigotimes_{s,a}\\mathcal{P}_{s}^{a},\\;\\mathcal{P}_{s}^{a}=\\{q\\in\\varDelta(\\mathcal{S}):D(q,\\mathsf{P}_{s}^{a})\\leq R\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\otimes_{s,a}$ means the uncertainty sets for every state-action pair are independently defined, $\\mathsf{P}_{s}^{a}$ is some nominal transition kernel for $(s,a)$ -pair, $D$ is some function that measures the difference between two distributions, e.g., total variation and KL divergence, and $R$ is the radius of the uncertainty set. The robust MDP aims to find the policy that optimizes the worst-case performance among all possible transition kernels from $\\Phi$ . Such a worst-case performance can be characterized by the robust value function $V_{\\mathcal{P}}^{\\pi}(s)$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi}(s)\\triangleq\\operatorname*{min}_{\\zeta\\in\\mathcal{P}}V_{\\zeta}^{\\pi}(s),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which is shown to be the unique solution to the robust Bellman equation [13]: ", "page_idx": 2}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi}(s)=\\sum_{a}\\pi(a|s)\\left(r(s,a)+\\gamma\\sigma_{\\mathcal{P}_{s}^{a}}(V_{\\mathcal{P}}^{\\pi})\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with $\\begin{array}{r}{\\sigma_{\\mathcal{P}_{s}^{a}}(V)\\triangleq\\operatorname*{min}_{q\\in\\mathcal{P}_{s}^{a}}q^{\\top}V}\\end{array}$ being the support function of a vector $V$ on the uncertainty set $\\mathcal{P}_{s}^{a}$ ", "page_idx": 2}, {"type": "text", "text": "Similar to the standard MDP setting, $V_{\\mathcal{P}}^{\\pi}(\\rho)$ can also be defined w.r.t. the initial state distribution $\\rho$ .   \nThe goal here is then to find the optimal robust policy arg $\\operatorname*{max}_{\\pi}V_{\\mathcal P}^{\\pi}(\\rho)$ . ", "page_idx": 2}, {"type": "text", "text": "3 Problem Formulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In offilne RL, the agent does not receive new samples by interacting with the environment. Instead, it is given a previously collected dataset $\\mathcal{D}$ which consists of $N$ tuples $\\{(s_{i},a_{i},s_{i}^{\\prime},r_{i}):i=1,\\cdot\\cdot\\cdot,N\\}$ The dataset is generated according to some distribution $\\mu$ , i.e., $(s_{i},a_{i})\\sim\\mu$ , and $s_{i}^{\\prime}\\sim\\mathsf{P}_{s_{i}}^{a_{i}}$ follows the nominal transition kernel $\\mathsf{P}$ , and $r_{i}=r(s_{i},a_{i})$ is a deterministic reward function. As discussed, due to the potential model mismatch between the environment that generates the offline dataset and the one in which the learned policy is going to be deployed, we design an uncertainty set that captures such a model mismatch as in (2), aiming to learn a policy that performs well under the true deployment environment through the robust RL framework: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi^{*}=\\arg\\operatorname*{max}_{\\pi}V_{\\mathcal{P}}^{\\pi}(\\rho),\\mathrm{~where~}\\mathcal{P}=\\bigotimes_{s,a}\\mathcal{P}_{s}^{a},\\;\\mathcal{P}_{s}^{a}=\\{q\\in\\varDelta(\\mathcal{S}):D(q,\\mathsf{P}_{s}^{a})\\leq R\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $R$ represents the similarities of the two environments. $D$ and $R$ are generally designed by domain experts, so we do not focus on their design and consider them as pre-settled in this work. ", "page_idx": 3}, {"type": "text", "text": "A key challenge here is that the nominal transition kernel ${\\sf P}_{0}$ is unknown, but only an offilne dataset generated from ${\\sf P}_{0}$ is given. Due to the limited exploration and distributional shift, the dataset $\\mathcal{D}$ may not cover all possible states or transitions that the agent might encounter in the environment. ", "page_idx": 3}, {"type": "text", "text": "To guarantee that a provable efficient algorithm can be designed based on the dataset $\\mathcal{D}$ , we adopt an assumption on the distributional mismatch between the dataset distribution and the occupancy measure induced by a comparator policy $\\pi^{*}$ . A comparator policy refers to a policy having satisfying worst-case performance and is set to be the optimal robust policy in many cases, but our approach can be applied to an arbitrary policy that may not be optimal. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. (Robust single-policy clipped concentrability $[36]$ ). The data distribution $\\mu$ satisfies ", "page_idx": 3}, {"type": "equation", "text": "$$\nC^{\\pi^{*}}\\triangleq\\operatorname*{max}_{(s,a,\\mathbf{Q})\\in\\mathbb{S}\\times A\\times\\Phi}\\frac{\\operatorname*{min}\\{d_{\\mathbf{Q}}^{\\pi^{*}}(s,a),\\frac{1}{S}\\}}{\\mu(s,a)}<+\\infty.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In Assumption 1, we only require that the dataset covers the state-action pairs that are visited by the comparator policy, known as partial coverage. When there is no model mismatch, Assumption 1 reduces to the single-policy clipped concentrability assumption in [19] for non-robust offline RL. ", "page_idx": 3}, {"type": "text", "text": "We hence formulate the offilne RL problem with model mismatch as the following concrete problem: Solve the robust RL problem (5) using only a fixed offline dataset $\\mathcal{D}$ satisfying Assumption $^{\\,I}$ . ", "page_idx": 3}, {"type": "text", "text": "4 Framework Design and Main Results ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To simultaneously address the two sources of uncertainty (1) uncertainty arising from the model mismatch between the data-collected environment and the deployment environment; and (2) uncertainty in the nominal (data-collection) model estimation attributed to an insufficient amount of data and limited coverage of the offilne dataset, we develop a unified principle of pessimism, and theoretically characterize the finite sample complexity of the proposed algorithms. Our algorithms are easier and more efficient to implement than existing approaches, and yield improved or matching results. ", "page_idx": 3}, {"type": "text", "text": "Denote $\\begin{array}{r}{N(s,a)=\\sum_{i=1}^{N}\\mathbf{1}_{(s_{i},a_{i})=(s,a)}}\\end{array}$ as the number of samples that transit from $(s,a)$ in $\\mathcal{D}$ , where 1 is the indicator f unction. The empirical transition kernel is then obtained as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathsf{P}}_{s,s^{\\prime}}^{a}=\\left\\{\\frac{\\sum_{i=1}^{N}\\mathbf{1}_{(s_{i},a_{i},s_{i}^{\\prime})=(s,a,s^{\\prime})}}{N(s,a)},\\,\\,\\,\\,\\mathrm{if}\\,\\,N(s,a)>0\\right.}\\\\ {\\frac{1}{S},\\,\\,\\,\\,\\qquad\\qquad\\qquad\\,\\,\\,\\mathrm{if}\\,\\,N(s,a)=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "and we also define the empirical reward function as ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\hat{r}}(s,a)=\\left\\{{\\frac{\\sum_{(s_{i},a_{i})=(s,a)}r_{i}}{N(s,a)}},\\right.\\,\\,\\,{\\mathrm{if}}\\,N(s,a)>0\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The MDP $\\hat{M}=(\\mathcal{S},\\mathcal{A},\\hat{\\mathsf{P}},\\hat{r})$ with the empirical transition kernel $\\hat{\\mathsf{P}}$ and empirical reward function $\\hat{r}$ is referred to as the empirical MDP, representing our estimation of the nominal model from the dataset. A straightforward approach is to construct an uncertainty set \u02c6P by replacing the nominal kernel $\\mathsf{P}$ in (5) by $\\bar{\\mathsf{P}}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{\\mathbb{P}}_{s}^{a}=\\{q\\in\\Delta(\\mathbb{S}):D(q,\\hat{\\mathbb{P}}_{s}^{a})\\leq R\\}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "and solve the corresponding robust RL problem. Although it tackles the model mismatch uncertainty through the uncertainty set, it generally results in a sub-optimal performance due to the lack of consideration of the estimation error within the empirical model. ", "page_idx": 3}, {"type": "text", "text": "To tackle this estimation error, previous works introduce some additional structures other than the above DRO framework (9), including a penalty term in reward [36] or an additional uncertainty set and making it a bi-level DRO [5] (more discussions and comparisons can be found in Section 5). In this work, we construct a single, unified uncertainty set of environments, showing that such an estimation error can be incorporated into the distribution uncertainty set and developing a unified principle of pessimism to address both uncertainties. Specifically, for any $s\\in\\mathcal{S}$ and $a\\in{\\mathcal{A}}$ , we set ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tilde{\\mathbb{P}}_{s}^{a}=\\{q\\in\\varDelta(\\mathbb{S}):D(q,\\hat{\\mathsf{P}}_{s}^{a})\\leq R+\\kappa_{s}^{a}\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\kappa_{s}^{a}$ is a function (will be specified later) inversely proportional to $N(s,a)$ that measures the degree of confidence when estimating the empirical transition kernel; and $R$ accounts for the model mismatch. Intuitively, for the less-observed state-action pairs, $\\kappa_{s}^{a}$ becomes larger and we are less confident and more pessimistic when estimating the transition kernel $\\hat{\\mathsf{P}}_{s}^{a}$ , and vice versa. ", "page_idx": 4}, {"type": "text", "text": "We claim and show later that the additional uncertainty or pessimism by enlarging the uncertainty set effectively tackles the uncertainty from the limited dataset, and the whole uncertainty set results in a conservative estimation of the worst-case performance. We then optimize the worst-case performance under this uncertainty set \u02dcP, which can be efficiently solved through the standard robust dynamic programming approach [28, 13]. Our algorithm is presented as Algorithm 1. For the convenience of analysis, we modify the vanilla robust value iteration algorithm [13] by setting the output policy to select actions that occur in the dataset when there is a tie. Such an output policy always exists (shown in Lemma 11 in the Appendix) and enables us to derive a tighter analysis of the sub-optimality gap. It is also worth noting that for all the uncertainty set models we consider, our Algorithm 1 can be efficiently applied with a polynomial computational complexity and a linear convergence rate [13]. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Robust Value Iteration for Offline RL with Model Mismatch ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Input: D, $V=0$   \nEstimate the empirical reward $\\hat{r}$ and empirical uncertainty set $\\tilde{\\mathcal{P}}$ according to (8) and (10)   \nrepeat $\\mathbf{\\hat{\\boldsymbol{V}}}(\\cdot)\\gets\\operatorname*{max}_{a\\in\\mathcal{A}}\\{\\hat{\\boldsymbol{r}}(\\cdot,a)+\\gamma\\sigma_{\\tilde{\\Phi}_{\\cdot}^{a}}(\\boldsymbol{V})\\}$   \nuntil convergence   \nfor $\\begin{array}{r l}&{\\mathbf{r}\\;s\\in\\partial\\;\\mathbf{q}}\\\\ &{\\tilde{\\pi}(s)\\in\\Bigl\\{\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\hat{r}(s,a)+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{a}}(V)\\Bigr\\}\\cap\\{a:N(s,a)>0\\}}\\end{array}$   \nend for   \nOutput: $\\tilde{\\pi}$ ", "page_idx": 4}, {"type": "text", "text": "In the following sections, we consider three widely used uncertainty set models: total variation, $\\chi^{2}$ divergence, and KL divergence models. We show that, for all three models, the uncertainty from the dataset can be incorporated into the uncertainty set as an additional term in the radius, and with a carefully designed uncertainty set, the optimal robust policy $\\tilde{\\pi}$ obtained has a near-optimal performance under the target uncertainty set $\\Phi$ , i.e., our approach effectively and efficiently solves the offline RL problems under model mismatch. ", "page_idx": 4}, {"type": "text", "text": "4.1 Total Variation (TV) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We first consider the case of TV defined uncertainty $\\mathrm{set}^{2}$ . Specifically, the uncertainty set is constructed using $\\begin{array}{r}{D(q,p)\\,=\\,\\frac{1}{2}\\|q-p\\|_{1}}\\end{array}$ in eq. (10). Note that when the radius is greater than 2, the defined uncertainty set reduces to the whole probability simplex $\\varDelta(\\mathcal{S})$ . Our first attempt is to set $\\kappa_{s}^{a}$ large enough such that the true uncertainty set $\\Phi$ falls into the constructed one $\\tilde{\\mathcal{P}}$ , such that the robust value function of $\\tilde{\\mathcal{P}}$ lower bounds the true robust value function $V_{\\mathcal{P}}^{\\pi}$ , as a conservative estimation. We note that as long as the true nominal transition kernel P and the empirical transition kernel $\\hat{\\mathsf{P}}$ are close: $\\|\\mathsf{P}_{s}^{a}-\\hat{\\mathsf{P}}_{s}^{a}\\|\\leq\\kappa_{s}^{a}$ holds with high probability, the triangle inequality implies $\\mathcal{P}\\subseteq\\tilde{\\mathcal{P}}$ with high probability. Therefore, the optimal robust policy $\\tilde{\\pi}$ provides a performance guarantee for the original problem (5). Following this approach, we can show the following results. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1. Consider TV defined uncertainty set. For each state-action pair $(s,a)$ , set $\\kappa_{s}^{a}\\ =$ $\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}}$ . Then with probability at least $1-2\\delta$ , the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ satisfies that ", "page_idx": 5}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{S^{2}C^{\\pi^{*}}}{(1-\\gamma)^{4}N}}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\tilde{\\mathcal{()}}$ notation absorbs universal constants and log terms. ", "page_idx": 5}, {"type": "text", "text": "Remark 1. To achieve an \u03f5 sub-optimality gap, a dataset of size $N=\\tilde{\\mathcal{O}}(S^{2}C^{\\pi^{*}}(1-\\gamma)^{-4}\\epsilon^{-2})$ is required. This result matches the previous one in $[5J.$ . ", "page_idx": 5}, {"type": "text", "text": "The construction above is based on distribution, to ensure the resulting uncertainty set $\\tilde{\\mathcal{P}}$ is larger than the target one $\\Phi$ . However, such a distribution-based construction can result in an overly large uncertainty set and an overly pessimistic policy, as observed in [47, 19]. To improve, one observation is that we can design a smaller uncertainty set such that the resulting robust value function $V_{\\tilde{\\mathcal P}}^{\\pi}$ approximately lower bounds the true robust value function, without using the distribution-based framework. We hence further design a novel uncertainty set that turns out to be less conservative (the intuition of such a design will be discussed in the next section). ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. For any $(s,a)$ , let $\\begin{array}{r}{\\kappa_{s}^{a}=\\frac{\\log\\frac{S A}{\\delta}}{N(s,a)}}\\end{array}$ For the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ , with probability at least $1-4\\delta$ , it holds that ", "page_idx": 5}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{C^{\\pi^{*}}S+\\frac{1}{\\mu_{\\operatorname*{min}}}}{N(1-\\gamma)^{3}}}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $\\begin{array}{r}{\\mu_{\\mathrm{min}}\\triangleq\\operatorname*{min}_{s,a}\\{\\mu(s,a):\\mu(s,a)>0\\}}\\end{array}$ denotes the smallest non-zero entry of the distribution $\\mu$ that generates the dataset. ", "page_idx": 5}, {"type": "text", "text": "Remark 2. Combining the two results, we showed that our approach can obtain an \u03f5-optimal robust policy when the dataset is of size $\\begin{array}{r}{\\tilde{\\mathcal{O}}\\big(\\frac{{C^{\\pi^{*}}S}}{(1-\\gamma)^{3}\\epsilon^{2}}\\operatorname*{min}\\{\\frac{S}{1-\\gamma},\\frac{1}{\\mu_{\\operatorname*{min}}}\\}\\big)}\\end{array}$ for the TV defined model. This result is better than the previous result in $I5J,$ , illustrating our approach is more efficient. Moreover, our framework is much simpler than the one in $[5]$ and can be effectively solved in a polynomial time (see detailed discussion in Section $^{5}$ ). ", "page_idx": 5}, {"type": "text", "text": "4.2 $\\chi^{2}$ Divergence ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We then study the uncertainty models with the $\\chi^{2}$ divergence: $\\begin{array}{r}{D(p,q)=\\sum_{s}q(s)\\left(1-\\frac{p(s)}{q(s)}\\right)^{2}}\\end{array}$ . Note that $\\chi^{2}$ divergence is not a metric, implying the failure of the triangle inequality and the distributionbased design as in the previous section. While it is possible to design $\\kappa$ such that $D(\\hat{\\mathsf{P}}_{s}^{a},\\mathsf{P}_{s}^{a})\\leq\\kappa_{s}^{a}$ [31], it does not imply $\\mathcal{P}_{s}^{a}\\subset\\tilde{\\mathcal{P}}_{s}^{a}$ and no lower bound guarantee can be obtained. ", "page_idx": 5}, {"type": "text", "text": "To address this issue, we similarly adapt the value function-based construction, by taking a closer look at the error decomposition. The main idea of our distribution-based construction for the TV defined model is to construct an uncertainty set that is large enough to include the true transition kernel with high probability. Then the sub-optimality gap can be decomposed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}=\\underbrace{V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}}_{\\varDelta_{1}}+\\underbrace{V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}}_{\\varDelta_{2}\\leq0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and $\\varDelta_{2}\\leq0$ from $\\mathcal{P}_{s}^{a}\\subset\\tilde{\\mathcal{P}}_{s}^{a}$ , which however fails under non-metric models. On the other hand, if we further decompose $\\varDelta_{2}$ as ", "page_idx": 5}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}=\\underbrace{V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}}}_{\\Delta_{21}}+\\underbrace{V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}}_{\\Delta_{22}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\hat{\\mathcal{P}}$ is the empirical uncertainty set (9). We note that $\\varDelta_{22}$ is the concentration error due to the limited dataset, which is independent of the term $\\kappa_{s}^{a}$ (ignoring the dependence of $\\tilde{\\pi}$ on $\\kappa$ for discussion connivance); $\\varDelta_{21}$ will be a negative term since ${\\hat{\\mathcal{P}}}\\subset{\\tilde{\\mathcal{P}}}$ , thus we should set the term $\\kappa$ such that the negative bound on $\\varDelta_{21}$ cancels out with the concentration bound on $\\varDelta_{22}$ , leading to a non-zero yet tight overall bound on $\\varDelta_{2}$ . Instead of ensuring the uncertainty set inclusion, we directly ensure the bound on the value function difference $\\varDelta_{2}$ is small. Clearly, the clue function-based design can be applied to both non-metric and metric models, and is less conservative than the distribution-based for the metric models, since closeness in distribution is stronger than the closeness in value functions [47]. This observation results in our second design for the total variation model in Theorem 2, showing an improvement in sample complexity. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Based on this intuition, we present our radius design and results. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. Consider $\\chi^{2}$ divergence-defined uncertainty set. For any $(s,a)$ , let $\\begin{array}{r}{\\kappa_{s}^{a}=\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{1+R}{N(s,a)}}\\right)}\\end{array}$ When N \u2265\u02dcO C\u03c0\u2217S\u00b52 , with probability at least $1-4\\delta$ , the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{C^{\\pi^{*}}S}{N(1-\\gamma)^{4}}}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Remark 3. To achieve an $\\epsilon$ -optimal robust policy under the $\\chi^{2}$ model, our approach requires the total number of samples ", "page_idx": 6}, {"type": "equation", "text": "$$\nN=\\tilde{\\mathcal{O}}\\bigg(\\underbrace{\\frac{C^{\\pi^{*}}S}{(1-\\gamma)^{4}\\epsilon^{2}}}_{\\epsilon-d e p e n d e n t}+\\underbrace{\\frac{S}{C^{\\pi^{*}}\\mu_{\\mathrm{min}}^{2}}}_{b u r n\\cdot i n\\;c o s t}\\bigg).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Our sample complexity has two parts: the $\\epsilon$ -dependent part which dominates as the accuracy \u03f5 decreases, and a fixed amount of burn-in cost, whose existence is because we cannot expect to learn a near-optimal policy when the dataset is too limited. When the desired accuracy $\\epsilon$ decreases, the first term dominates the overall complexity, resulting in the asymptotic result presented in the theorem. ", "page_idx": 6}, {"type": "text", "text": "Our approach and result stand for the first concrete study for offline robust RL with $\\chi^{2}$ divergencedefined uncertainty sets. It is also worth noting that our sample complexity asymptotically matches the sample complexity of the model-based robust RL with a generative model [38]. These observations hence demonstrate the optimality of our results and the effectiveness of our approach. ", "page_idx": 6}, {"type": "text", "text": "4.3 KL Divergence ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we consider the KL divergence defined uncertainty set, i.e., $\\begin{array}{r l}{D(p,q)}&{{}=}\\end{array}$ s p(s) log qp((ss)). Similarly, KL divergence is not a metric, we hence adapt our design discussed above for $\\chi^{2}$ models here. The following theorem presents our design of the uncertainty set and sample complexity results. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4. Consider $K L$ divergence defined uncertainty set. For any $(s,a)$ , let $\\kappa_{s}^{a}\\ =$ $\\begin{array}{r}{C_{1}\\sqrt{\\frac{\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,a)\\hat{\\mathsf{P}}_{\\operatorname*{min}}}}.}\\end{array}$ , if $N\\,\\geq\\,\\frac{8\\log\\frac{1}{\\delta}}{\\mu_{\\operatorname*{min}}\\mathsf{P}_{\\operatorname*{min}}}$ , then with probability at least $1-4\\delta$ , the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{C^{\\pi^{*}}S}{(1-\\gamma)^{4}N\\mathsf{P}_{\\mathrm{min}}}}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Here, $\\mathsf{P}_{\\mathrm{min}}$ and $\\ensuremath{\\hat{\\mathsf{P}}}_{\\operatorname*{min}}$ represents the minimal non-zero entry of the nominal transition kernel P and empirical nominal kernel \u02c6P. ", "page_idx": 6}, {"type": "text", "text": "Remark 4. Similarly, for the $K L$ divergence model, our approach requires a total number of $\\begin{array}{r}{\\tilde{\\mathcal{O}}\\left(\\frac{C^{\\pi^{*}}S}{(1-\\gamma)^{4}\\mathsf{P}_{\\operatorname*{min}}\\epsilon^{2}}+\\frac{\\dot{1}}{\\mathsf{P}_{\\operatorname*{min}}\\mu_{\\operatorname*{min}}}\\right)}\\end{array}$ samples to find an $\\epsilon$ -optimal policy. The sample complexity also contains two parts, an asymptotically dominated term and a fixed burn-in cost. Our result matches the one of [36] and is better than the one of [5]. ", "page_idx": 6}, {"type": "text", "text": "To summarize, our unified framework can be adapted to different uncertainty models and solve offilne robust RL problems, offering improved or matched sample complexity results and a more efficient implementation. More discussion can be found in Section 5. We also provide some numerical experiments to verify the effectiveness and efficiency of our algorithm, which can be found in Appendix A. Under all three uncertainty set models, our algorithm enjoys a smaller or similar sample complexity compared to LCB approaches, and always outperform the non-robust dynamic programming approach. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5 Related Works ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "5.1 Comparison with prior art ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we compare our works with the most related existing works [36, 5], where offline RL with model mismatch is studied. Compared to them, our methods enjoy three major advantages: (1). A more unified and straightforward framework of single pessimism principle; (2). Improved or matched sample complexity; And (3). Enhanced computational complexity. ", "page_idx": 7}, {"type": "text", "text": "Unified framework for double pessimism principles. In [36], the two principles of pessimism are separately employed, where a reward penalty term $b$ is used to penalize less visited state-action pairs in addition to the uncertainty set that accounts for the model mismatch, and the update rule is ", "page_idx": 7}, {"type": "equation", "text": "$$\nV(s)\\leftarrow\\operatorname*{max}_{a}\\big\\{r(s,a)+\\gamma\\sigma_{\\hat{\\mathcal{P}}_{s}^{a}}(V)-b(s,a)\\big\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Our approach, on the other hand, enjoys a straightforward and simple formulation. Specifically, we incorporate the two principles of pessimism into a single uncertainty set, developing our unified principle. Moreover, it is noted that design of the penalty term $b$ is complicated, whereas our addition term $\\kappa$ has a simple and clear form. It is worth noting that although the LCB approach and ours share a similar updating rule, there is a fundamental difference in the algorithm design motivation and analysis. In the LCB approach, the penalty term $b$ is designed such that the resulting estimation $V$ is less than the true robust value function $V_{\\mathcal{P}}^{\\pi}$ , to ensure the conservativeness of LCB approaches; Whereas our resulting estimation $V_{\\tilde{\\mathcal{P}}}^{\\pi}$ is not necessarily less than $V_{\\mathcal{P}}^{\\pi}$ , since we directly tackle the distribution uncertainty but not through value function estimations. This hence requires novel technique innovations in our analysis. ", "page_idx": 7}, {"type": "text", "text": "In another closely related work [5], a double pessimism principle is adopted to address the two sources of uncertainty, under TV and KL divergence models. Specifically, a TV distance-based uncertainty set $\\hat{\\mathcal{P}}$ is first constructed to tackle the model estimation uncertainty from the dataset; Then centered at each transition kernel $\\hat{\\mathsf{P}}\\in\\hat{\\mathcal{P}}$ , a second layer of uncertainty set $\\varPhi(\\hat{\\mathsf{P}})$ to reflect the distributional robustness to model mismatch. They then take the optimal policy of ", "page_idx": 7}, {"type": "equation", "text": "$$\nV_{p e s s^{2}}^{\\pi}=\\operatorname*{inf}_{\\hat{\\mathsf{P}}\\in\\hat{\\mathcal{P}}}\\operatorname*{inf}_{\\tilde{\\mathsf{P}}\\in\\varPhi(\\hat{\\mathsf{P}})}V_{\\tilde{\\mathsf{P}}}^{\\pi}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "as the output policy. Although their approach indicates that the data estimation uncertainty can also be captured by a distributional uncertainty set, they still employ the two principles separately, although both in the form of DRO formulations. Instead of designing two uncertainty sets as in [5], we unify the two types of pessimism and use a single uncertainty set with a composed design of the radius to address both the model estimation uncertainty and the model mismatch. ", "page_idx": 7}, {"type": "text", "text": "Improved or Matched Sample Complexity. In terms of sample complexity, the comparison are included in Table 1. Compared to [36], our theoretical result matches theirs under the KL divergence model, and we moreover develop results for the other two uncertainty set models that are not considered therein. The numerical experiment results can be found in Appendix A, which further verify our discussion. Compared with [5], our results achieve better sample complexity in both KL and TV models. In the TV model, our sample complexity outperforms [5] in terms of dependence on $S$ and $(1-\\gamma)$ ; For the KL model, our complexity is linearly dependent on $S$ , while [5] has a quadratic dependence. Furthermore, as noted in [5], their result\u2019s exponential term can be replaced by utilizing both $\\mathsf{P}_{\\mathrm{min}}$ and $\\mu_{\\mathrm{min}}$ , while our (asymptotic) complexity result depends solely on $\\mathsf{P}_{\\mathrm{min}}$ . ", "page_idx": 7}, {"type": "text", "text": "Enhanced Computational Complexity. Our algorithms are also better in terms of computational complexity or practical implementations than both baselines. ", "page_idx": 7}, {"type": "text", "text": "The two-layer optimization problem in [5] is an extension of the model studied in [42] to the robust setting, both involving non-rectangular uncertainty sets that are NP-hard to solve [50]. This creates ", "page_idx": 7}, {"type": "table", "img_path": "cBY66CKEbq/tmp/a0a5d5451734d8cec2a5813c26205ae95bc7172c73dd3f5105dc7df253a1d98d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 1: Comparison with related works on offline RL under model mismatch. In [5], $C_{r o b}^{\\pi^{*}}$ is the robust partial coverage coefficient [5], which is similar to $C^{\\pi^{*}}$ , and the $\\exp((1-\\gamma)^{-1})$ term can be eliminated with an additional cost on $\\mathsf{P}_{\\operatorname*{min}}^{-1}$ and $\\mu_{\\mathrm{min}}^{-1}$ . ", "page_idx": 8}, {"type": "text", "text": "uncertainty regarding the solvability of their models. Specifically, due to the unsolvability of the non-robust model in [42], an adversarial training-based algorithm is designed in [34] with only an experimental convergence guarantee, highlighting the implementation challenges of [5]. In contrast, our algorithm can be implemented with polynomial complexity. Specifically, the total computational complexity of our algorithm in the TV, CS and KL models are $\\stackrel{\\triangledown}{\\operatorname{\\mathcal{O}}}(S^{2}A\\operatorname{liog}S),\\stackrel{\\triangledown}{\\operatorname{\\mathcal{O}}}(S^{2}A\\operatorname{log}S)$ , and $\\tilde{\\mathcal{O}}(S^{\\bar{2}}A)$ . ", "page_idx": 8}, {"type": "text", "text": "Compared to [36], our algorithms also offer better computational complexity. Specifically, the penalty term in [36] requires a complicated computation involving a minimum operator, resulting in an additional max-min structure in their algorithm update. The comparison/max-min operator in the LCB algorithm is executed $S A$ times per step, significantly increasing computational complexity. In contrast, our algorithms have a simple structure and do not require additional operators, making them more computationally efficient. We also use numerical experiment to further illustrate our enhanced computational efficiency, in Appendix A. ", "page_idx": 8}, {"type": "text", "text": "5.2 Other related works ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We then discuss some of the other related works. ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Offline RL without model mismatch. Offline RL focuses on learning an optimal policy from a pre-collected dataset, and the target deployment environment is identical to the one where the dataset is collected. Many previous works make the global coverage assumption, i.e., the behavior policy can cover all state-action pairs, e.g., [35, 7, 27, 58, 59, 14, 45, 20, 21, 64, 41, 9, 52, 18, 2, 10]. This assumption is too restrictive and is often violated in practice since it requires the history data to cover all the state-action pairs [12, 1, 11]. Recently, a relaxed partial coverage setting was proposed, which assumes that the density ratio between the occupancy measure induced by a single target policy and the behavior policy is finite for all state-action pairs, and the goal is to learn a policy that is no worse than the target policy. The partial coverage assumption only requires that the history data visit the state-action pairs that the target policy will visit. Under the partial coverage assumption, optimal policy can be learned for offilne RL incorporated with the pessimism principle facing the uncertainty, e.g., [15, 42, 51, 53, 33, 62, 60, 37, 19, 63, 47]. However in our setting, we also consider the potential model mismatch between the two environments, which possibly due to e.g., non-stationarity, heterogeneity and sim-to-real gap, and formulate the problem as offline RL under model mismatch. ", "page_idx": 8}, {"type": "text", "text": "Robust RL. Robust RL [13, 28, 54] aims to tackle the model mismatch in RL, by optimizing the worst-case performance over the uncertainty set. Existing works mainly focus on the online setting [48, 49, 46, 4, 8, 25, 23] or with a generative model [57, 55, 29, 38]. Studies for robust RL with an offline dataset, besides the two mentioned above [36, 5], are developed in recent works including [24, 44, 65, 30, 56, 26, 57]. These works either focus on the linear MDPs, or adapt strong assumptions including global coverage or absorbing states. More importantly, all these works employ the two pessimism principles separately through the LCB penalty and DRO uncertainty set. Compared to them, we focus on general MDPs and develop our unified framework. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion and Discussions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we investigated the offilne RL problem under model mismatch under the most general partial coverage setting, where two sources of uncertainty are presented: inaccurate estimation of transition dynamics due to limited dataset coverage, and model mismatch between training and testing environments. We developed a unified DRO-based framework containing a single uncertainty set with a composed radius of two parts to tackle the two sources of uncertainty discussed above. Our approach can be implemented in a much easier and more straightforward way than existing approaches and can be applied to both metric-based and non-metric-based uncertainty models. Specifically, we investigated three types of uncertainty sets defined by total variation, $\\dot{\\chi}^{2}$ divergence, and KL divergence. Our methodology can be easily extended to handle other uncertainty set models. Among them, we obtain near-optimal sample complexity results that improve or match the existing results under the total variation and KL divergence models and provide the first algorithm and finite sample complexity analysis for the uncertainty set defined by the $\\chi^{2}$ divergence. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Limitations. It is in our future interest to extend our unified framework to address large-scale problems. This includes robust MDPs with latent structures, such as linear MDPs, as opposed to previous work that uses the $\\mathrm{LCB}+\\mathrm{DRO}$ framework, for example [24, 44], and more general MDPs with function approximation techniques. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Yue Wang is supported by DARPA under Agreement No. HR0011-24-9-0427. The work of Zhongchang Sun and Shaofeng Zou is supported by the National Science Foundation under Grants CCF-2438429 and ECCS-2438392 (CAREER). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] A. Agarwal, S. Kakade, and L. F. Yang. Model-based reinforcement learning with a generative model is minimax optimal. In Conference on Learning Theory, pages 67\u201383. PMLR, 2020. [2] A. Antos, R. Munos, and C. Szepesvari. Fitted Q-iteration in continuous action-space mdps. In Neural Information Processing Systems, 2007.   \n[3] M. A. Arcones. A bernstein-type inequality for u-statistics and u-processes. Statistics & probability letters, 22(3):239\u2013247, 1995.   \n[4] K. P. Badrinath and D. Kalathil. Robust reinforcement learning using least squares policy iteration with provable performance guarantees. In Proc. International Conference on Machine Learning (ICML), pages 511\u2013520. PMLR, 2021.   \n[5] J. Blanchet, M. Lu, T. Zhang, and H. Zhong. Double pessimism is provably efficient for distributionally robust offline reinforcement learning: Generic algorithm and robust partial coverage. arXiv preprint arXiv:2305.09659, 2023.   \n[6] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba. OpenAI Gym. arXiv preprint arXiv:1606.01540, 2016. [7] J. Chen and N. Jiang. Information-theoretic considerations in batch reinforcement learning. In International Conference on Machine Learning, pages 1042\u20131051. PMLR, 2019. [8] J. Dong, J. Li, B. Wang, and J. Zhang. Online policy optimization for robust mdp. arXiv preprint arXiv:2209.13841, 2022. [9] Y. Duan, Z. Jia, and M. Wang. Minimax-optimal off-policy evaluation with linear function approximation. In Proc. International Conference on Machine Learning (ICML), pages 2701\u2013 2709. PMLR, 2020.   \n[10] A. M. Farahmand, R. Munos, and C. Szepesv\u00e1ri. Error propagation for approximate policy and value iteration. In Advances in Neural Information Processing Systems, 2010.   \n[11] J. Fu, A. Kumar, O. Nachum, G. Tucker, and S. Levine. D4RL: Datasets for deep data-driven reinforcement learning. arXiv preprint arXiv:2004.07219, 2020.   \n[12] C. Gulcehre, Z. Wang, A. Novikov, T. L. Paine, S. G. Colmenarejo, K. Zolna, R. Agarwal, J. Merel, D. Mankowitz, C. Paduraru, et al. RL unplugged: Benchmarks for offilne reinforcement learning. arXiv preprint arXiv:2006.13888, 2020.   \n[13] G. N. Iyengar. Robust dynamic programming. Mathematics of Operations Research, 30(2):257\u2013 280, 2005.   \n[14] N. Jiang. On value functions and the agent-environment boundary. arXiv preprint arXiv:1905.13341, 2019.   \n[15] Y. Jin, Z. Yang, and Z. Wang. Is pessimism provably efficient for offline RL? In International Conference on Machine Learning, pages 5084\u20135096, 2021.   \n[16] B. R. Kiran, I. Sobh, V. Talpaert, P. Mannion, A. A. Al Sallab, S. Yogamani, and P. P\u00e9rez. Deep reinforcement learning for autonomous driving: A survey. IEEE Transactions on Intelligent Transportation Systems, 23(6):4909\u20134926, 2021.   \n[17] S. Lange, T. Gabel, and M. Riedmiller. Batch reinforcement learning. In Reinforcement learning, pages 45\u201373. Springer, 2012.   \n[18] S. Levine, A. Kumar, G. Tucker, and J. Fu. Offline reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020.   \n[19] G. Li, L. Shi, Y. Chen, Y. Chi, and Y. Wei. Settling the sample complexity of model-based offline reinforcement learning. in preparation, 2022.   \n[20] P. Liao, Z. Qi, and S. Murphy. Batch policy learning in average reward Markov decision processes. arXiv preprint arXiv:2007.11771, 2020.   \n[21] B. Liu, Q. Cai, Z. Yang, and Z. Wang. Neural trust region/proximal policy optimization attains globally optimal policy. In Proc. Advances in Neural Information Processing Systems (NeurIPS), 2019.   \n[22] Z. Liu, Q. Bai, J. Blanchet, P. Dong, W. Xu, Z. Zhou, and Z. Zhou. Distributionally robust Q-learning. In International Conference on Machine Learning, pages 13623\u201313643. PMLR, 2022.   \n[23] Z. Liu and P. Xu. Distributionally robust off-dynamics reinforcement learning: Provable efficiency with linear function approximation. arXiv preprint arXiv:2402.15399, 2024.   \n[24] Z. Liu and P. Xu. Minimax optimal and computationally efficient algorithms for distributionally robust offline reinforcement learning. arXiv preprint arXiv:2403.09621, 2024.   \n[25] M. Lu, H. Zhong, T. Zhang, and J. Blanchet. Distributionally robust reinforcement learning with interactive data collection: Fundamental hardness and near-optimal algorithm. arXiv preprint arXiv:2404.03578, 2024.   \n[26] X. Ma, Z. Liang, J. Blanchet, M. Liu, L. Xia, J. Zhang, Q. Zhao, and Z. Zhou. Distributionally robust offline reinforcement learning with linear function approximation. arXiv preprint arXiv:2209.06620, 2022.   \n[27] R. Munos. Error bounds for approximate value iteration. In Proceedings of the National Conference on Artificial Intelligence, volume 20, page 1006. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2005.   \n[28] A. Nilim and L. El Ghaoui. Robustness in Markov decision problems with uncertain transition matrices. In Proc. Advances in Neural Information Processing Systems (NIPS), pages 839\u2013846, 2004.   \n[29] K. Panaganti and D. Kalathil. Sample complexity of robust reinforcement learning with a generative model. In International Conference on Artificial Intelligence and Statistics, pages 9582\u20139602. PMLR, 2022.   \n[30] K. Panaganti, Z. Xu, D. Kalathil, and M. Ghavamzadeh. Robust reinforcement learning using offline data. arXiv preprint arXiv:2208.05129, 2022.   \n[31] K. Panaganti, Z. Xu, D. Kalathil, and M. Ghavamzadeh. Bridging distributionally robust learning and offline rl: An approach to mitigate distribution shift and partial data coverage. arXiv preprint arXiv:2310.18434, 2023.   \n[32] Y. Pitcan. A note on concentration inequalities for u-statistics. arXiv preprint arXiv:1712.06160, 2017.   \n[33] P. Rashidinejad, B. Zhu, C. Ma, J. Jiao, and S. Russell. Bridging offline reinforcement learning and imitation learning: A tale of pessimism. Advances in Neural Information Processing Systems, 34:11702\u201311716, 2021.   \n[34] M. Rigter, B. Lacerda, and N. Hawes. Rambo-rl: Robust adversarial model-based offline reinforcement learning. arXiv preprint arXiv:2204.12581, 2022.   \n[35] B. Scherrer. Approximate policy iteration schemes: A comparison. In Proc. International Conference on Machine Learning (ICML), pages 1314\u20131322, 2014.   \n[36] L. Shi and Y. Chi. Distributionally robust model-based offline reinforcement learning with near-optimal sample complexity. arXiv preprint arXiv:2208.05767, 2022.   \n[37] L. Shi, G. Li, Y. Wei, Y. Chen, and Y. Chi. Pessimistic Q-learning for offline reinforcement learning: Towards optimal sample complexity. International Conference on Machine Learning, pages 19967\u201320025, 2022.   \n[38] L. Shi, G. Li, Y. Wei, Y. Chen, M. Geist, and Y. Chi. The curious price of distributional robustness in reinforcement learning with a generative model. arXiv preprint arXiv:2305.16589, 2023.   \n[39] T. Siddique, J. L. Hau, S. Atallah, and M. Petrik. Robust pest management using reinforcement learning. The Multi-disciplinary Conference on Reinforcement Learning and Decision Making, 2019.   \n[40] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.   \n[41] M. Uehara, J. Huang, and N. Jiang. Minimax weight and Q-function learning for off-policy evaluation. In Proc. International Conference on Machine Learning (ICML), pages 9659\u20139668. PMLR, 2020.   \n[42] M. Uehara and W. Sun. Pessimistic model-based offline reinforcement learning under partial coverage. arXiv preprint arXiv:2107.06226, 2021.   \n[43] R. Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018.   \n[44] H. Wang, L. Shi, and Y. Chi. Sample complexity of offilne distributionally robust linear markov decision processes. arXiv preprint arXiv:2403.12946, 2024.   \n[45] L. Wang, Q. Cai, Z. Yang, and Z. Wang. Neural policy gradient methods: Global optimality and rates of convergence. In International Conference on Learning Representations, 2019.   \n[46] Q. Wang, C. P. Ho, and M. Petrik. Policy gradient in robust mdps with global convergence guarantee, 2023.   \n[47] Y. Wang, J. Xiong, and S. Zou. Achieving the minimax optimal sample complexity of offline reinforcement learning: A dro-based approach, 2023.   \n[48] Y. Wang and S. Zou. Online robust reinforcement learning with model uncertainty. In Proc. Advances in Neural Information Processing Systems (NeurIPS), volume 34, pages 7193\u20137206, 2021.   \n[49] Y. Wang and S. Zou. Policy gradient method for robust reinforcement learning. In Proc. International Conference on Machine Learning (ICML), volume 162, pages 23484\u201323526. PMLR, 2022.   \n[50] W. Wiesemann, D. Kuhn, and B. Rustem. Robust Markov decision processes. Mathematics of Operations Research, 38(1):153\u2013183, 2013.   \n[51] T. Xie, C.-A. Cheng, N. Jiang, P. Mineiro, and A. Agarwal. Bellman-consistent pessimism for offline reinforcement learning. arXiv preprint arXiv:2106.06926, 2021.   \n[52] T. Xie and N. Jiang. Batch value-function approximation with only realizability. arXiv preprint arXiv:2008.04990, 2020.   \n[53] T. Xie, N. Jiang, H. Wang, C. Xiong, and Y. Bai. Policy finetuning: Bridging sample-efficient offilne and online reinforcement learning. Advances in neural information processing systems, 34:27395\u201327407, 2021.   \n[54] H. Xu and S. Mannor. Distributionally robust Markov decision processes. In Proc. Advances in Neural Information Processing Systems (NIPS), pages 2505\u20132513, 2010.   \n[55] Z. Xu, K. Panaganti, and D. Kalathil. Improved sample complexity bounds for distributionally robust reinforcement learning. In International Conference on Artificial Intelligence and Statistics, pages 9728\u20139754. PMLR, 2023.   \n[56] R. Yang, C. Bai, X. Ma, Z. Wang, C. Zhang, and L. Han. Rorl: Robust offline reinforcement learning via conservative smoothing. Advances in neural information processing systems, 35:23851\u201323866, 2022.   \n[57] W. Yang, L. Zhang, and Z. Zhang. Towards theoretical understandings of robust Markov decision processes: Sample complexity and asymptotics. arXiv preprint arXiv:2105.03863, 2021.   \n[58] M. Yin, Y. Bai, and Y.-X. Wang. Near-optimal offline reinforcement learning via double variance reduction. arXiv preprint arXiv:2102.01748, 2021.   \n[59] M. Yin and Y.-X. Wang. Optimal uniform ope and model-based offilne reinforcement learning in time-homogeneous, reward-free and task-agnostic settings. arXiv preprint arXiv:2105.06029, 2021.   \n[60] M. Yin and Y.-X. Wang. Towards instance-optimal offline reinforcement learning with pessimism. Advances in neural information processing systems, 34, 2021.   \n[61] C. Yu, J. Liu, S. Nemati, and G. Yin. Reinforcement learning in healthcare: A survey. ACM Computing Surveys (CSUR), 55(1):1\u201336, 2021.   \n[62] A. Zanette, M. J. Wainwright, and E. Brunskill. Provable benefits of actor-critic methods for offline reinforcement learning. Advances in neural information processing systems, 34, 2021.   \n[63] W. Zhan, B. Huang, A. Huang, N. Jiang, and J. D. Lee. Offline reinforcement learning with realizability and single-policy concentrability. arXiv preprint arXiv:2202.04634, 2022.   \n[64] J. Zhang, A. Koppel, A. S. Bedi, C. Szepesvari, and M. Wang. Variational policy gradient method for reinforcement learning with general utilities. In Proc. Advances in Neural Information Processing Systems (NeurIPS), volume 33, pages 4572\u20134583, 2020.   \n[65] Z. Zhou, Q. Bai, Z. Zhou, L. Qiu, J. Blanchet, and P. Glynn. Finite-sample regret bound for distributionally robust offilne tabular reinforcement learning. In Proc. International Conference on Artifical Intelligence and Statistics (AISTATS), pages 3331\u20133339. PMLR, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide simulation results to demonstrate the performance of our algorithm. We consider two problems: the Frozen-Lake problem [6] and the gambler problem [40, 65, 36]. ", "page_idx": 13}, {"type": "text", "text": "For the Frozen-Lake problem, an agent aims to cross a $4\\times4$ frozen lake from Start to Goal without falling into any Holes. The reward is set to be 1 when the agent reaches Goal and 0 otherwise. Due to the slippery nature of the frozen lake, the agent may not always move along the intended direction. ", "page_idx": 13}, {"type": "text", "text": "We formulate the gambler problem as an infinite-horizon MDP. A gambler engages in a betting game based on a sequence of coin filps. The gambler wins the stake when the coin lands on heads and loses it when the coin lands on tails. The probability of heads for the coin filp is $p=0.6$ . The game begins with an initial balance and ends when the gambler\u2019s balance either reaches 20 or 0. The reward is set to be 1 when the state reaches 20 and 0 otherwise. ", "page_idx": 13}, {"type": "text", "text": "A.1 Comparison under the total variation uncertainty set model ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We first evaluate our algorithm under the total variation uncertainty set. We adapt the construction in [36] to design an DRVI-LCB approach for the TV defined uncertainty set as a baseline, and implement the two variants of our algorithm: distribution-based design and value function-based design. The robustness level $R$ is set to be 0.1. We generate the dataset according to $\\begin{array}{r}{\\mu(s,a)=\\frac{\\mathbf{1}_{a=\\pi^{*}(s)}}{2}\\overline{{+\\frac{\\mathbf{1}_{a=\\eta}}{2}}}}\\end{array}$ where $\\eta$ is a random action, and $\\pi^{*}(s)$ denotes the optimal robust policy. Clearly the dataset satisfies the partial coverage assumption 1. ", "page_idx": 13}, {"type": "text", "text": "We run the algorithms independently for 10 times and plot the mean of the sub-optimality gap and mean plus and minus the standard deviations of the 10 runs as the envelop. It can be seen from Fig.1 and Fig. 2 that the value function-based construction has a smaller sub-optimality gap and converges faster than the distribution-based construction and the DRVI-LCB, which demonstrates that our algorithm is less conservative and more effective. ", "page_idx": 13}, {"type": "image", "img_path": "cBY66CKEbq/tmp/f21fed1e28c574d18911265b62718b50e372672f21a564a09513b36a98f3cd7c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "image", "img_path": "cBY66CKEbq/tmp/9f6f8fe5c9d112b379437a6dc5605135964ce16fa27a1ad0aed90f4880a9b8fa.jpg", "img_caption": ["Figure 1: Frozen-Lake: TV Distance Defined Uncer- Figure 2: Gambler: TV Distance Defined Uncertainty tainty Set Set "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "A.2 Comparison under the $\\chi^{2}$ divergence uncertainty set model ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We then compare our algorithm with the DRVI-LCB under the $\\chi^{2}$ divergence model. Similarly, we adapt their penalty term design for the uncertainty set, and run the experiment under the two environments. We similarly generate dataset following $\\mu$ constructed above and run the algorithm for 10 times. The robustness level $R$ is set to be 0.1. It can be seen from Fig.3 and Fig.4 that the non-robust DP converges much slower to the optimal policy, whereas our approach has a similar convergence rate to the DRVI-LCB to the optimal policy, which validates our theoretical results. ", "page_idx": 13}, {"type": "image", "img_path": "cBY66CKEbq/tmp/a9045b1c4792f2e243625f40ddac776a9b3b7dc064d92d065391bb457e3d21d8.jpg", "img_caption": ["Figure 3: Frozen-Lake: $\\chi^{2}$ Divergence Defined Uncertainty Set "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "cBY66CKEbq/tmp/4ed41bacc26f303bf6caf4788a8a1ce2f44c784268523b4981c9b477a71f29ed.jpg", "img_caption": ["Figure 4: Gambler: $\\chi^{2}$ Divergence Defined Uncertainty Set "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "A.3 Comparison under the KL divergence uncertainty set model ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We then compare the performance of our algorithm and the one in [36] under the KL divergence model. We similarly generate dataset following $\\mu$ constructed above and run the algorithm for 10 times. The robustness level $R$ is set to be 0.1. It can be seen from Fig.5 and Fig.6 that the non-robust DP converges much slower to the optimal policy, whereas our approach has a similar convergence rate to the DRVI-LCB to the optimal policy, which validates our theoretical results. ", "page_idx": 14}, {"type": "image", "img_path": "cBY66CKEbq/tmp/1084f9c824c7a564c3dad2036c7ccbef0aa2cb9c95eb89bd1d262683df5b852a.jpg", "img_caption": ["Figure 5: Frozen-Lake: KL Divergence Defined Uncertainty Set "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "cBY66CKEbq/tmp/6f5d6483c4372ae3e9a35188605e3cbeaab3e5827e2f6962190253b6cb2310e8.jpg", "img_caption": ["Figure 6: Gambler: KL Divergence Defined Uncertainty Set "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "We further run the three algorithms on the two uncertainty sets for the gambler problem. The robustness level $R$ is set to be 0.2. From Fig. 4 and Fig. 6, it can be seen that the non-robust DP converges much slower, whereas our approach solves the problem efficiently. Compared to LCB approaches, our method enjoys a similar performance and convergence rate, further demonstrating the effectiveness and efficiency of our approach. ", "page_idx": 14}, {"type": "text", "text": "A.4 Execution time ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To illustrate our computational efficiency, we implemented the LCB algorithm from [36] and our DRO algorithm under the KL model, monitoring the execution time of both methods while learning the same policy from the same dataset. We plotted the execution time for each dataset versus the size of the dataset in three environments: Gambler\u2019s game, Frozen Lake, and N-chain. As shown in Appendix A.4, our algorithm consistently requires less execution time across all three environments, demonstrating lower computational complexity. ", "page_idx": 14}, {"type": "image", "img_path": "cBY66CKEbq/tmp/f31c83ecc6a224415bde29faa948da2d6374987c392cf565d9df85438c20e5b1.jpg", "img_caption": ["Figure 7: Execution time: DRO vs LCB [36] "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "B Proofs of Section 4.1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lemma 1. For each state-action pair $(s,a)$ , set ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\kappa_{s}^{a}=\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then with probability at least $1-\\delta$ , $\\mathcal{P}_{s}^{a}\\subseteq\\tilde{\\mathcal{P}}_{s}^{a}$ . ", "page_idx": 15}, {"type": "text", "text": "We then present the sub-optimality gap in the following theorem. ", "page_idx": 15}, {"type": "text", "text": "Proof. For the $(s,a)$ pairs with $N(s,a)=0$ , the statement is trivial due to the fact that $\\tilde{\\Phi}_{s}^{a}=\\varDelta(\\mathcal{S})$ .   \nIt is hence sufficient to consider the pairs with $N(s,a)>0$ . ", "page_idx": 15}, {"type": "text", "text": "By directly applying the Hoeffding\u2019s inequality [22], we have that for each pair $(s,a,x)$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}(|\\hat{\\mathsf{P}}_{s,x}^{a}-\\mathsf{P}_{s,x}^{a}|\\ge k)\\le\\exp\\left(-2N(s,a)k^{2}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "It hence can be further shown that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\hat{\\mathsf{P}}_{s}^{a}-\\mathsf{P}_{s}^{a}\\|\\leq\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "simultaneously for any $(s,a)$ -pair with probability at least $1-\\delta$ ", "page_idx": 15}, {"type": "text", "text": "Now consider any $q\\in\\mathcal{P}_{s}^{a}$ , it holds that $\\|q-\\mathsf{P}_{s}^{a}\\|\\leq R$ . Hence ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|q-\\hat{\\mathsf{P}}_{s}^{a}\\|\\le\\|q-\\mathsf{P}_{s}^{a}\\|+\\|\\hat{\\mathsf{P}}_{s}^{a}-\\mathsf{P}_{s}^{a}\\|\\le R+\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which implies that $\\mathcal{P}_{s}^{a}\\subseteq\\tilde{\\mathcal{P}}_{s}^{a}$ for any $(s,a)$ with probability at least $1-\\delta$ ", "page_idx": 15}, {"type": "text", "text": "Theorem 5. For the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ , with probability at least $1-2\\delta$ , it holds that ", "page_idx": 15}, {"type": "equation", "text": "$$\n{V_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\frac{2}{(1-\\gamma)^{2}}\\sqrt{\\frac{8\\log\\frac{S A}{\\delta}\\log\\frac{4S A}{\\delta}}{2N\\mu_{\\mathrm{min}}}},}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. First note that ", "page_idx": 15}, {"type": "equation", "text": "$$\nV_{\\Phi}^{\\pi^{*}}-V_{\\Phi}^{\\tilde{\\pi}}=V_{\\Phi}^{\\pi^{*}}-V_{\\tilde{\\Phi}}^{\\tilde{\\pi}}+V_{\\tilde{\\Phi}}^{\\tilde{\\pi}}-V_{\\Phi}^{\\tilde{\\pi}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Due to the fact that $\\mathcal{P}_{s}^{a}\\subseteq\\tilde{\\mathcal{P}}_{s}^{a}$ with probability $1-\\delta$ , it holds that ", "page_idx": 15}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\leq V_{\\mathcal{P}}^{\\tilde{\\pi}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and hence ", "page_idx": 15}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}\\leq V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "It can be further bounded as ", "page_idx": 15}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\pi^{*}})-\\underset{a}{\\mathrm{max}}\\{r(s,a)+\\gamma\\tilde{\\sigma}_{s}^{a}(V_{\\mathcal P}^{\\pi})\\}}\\\\ &{\\overset{(a)}{\\leq}r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\pi^{*}})-r(s,\\pi^{*}(s))-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\pi^{*}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\pi^{*}})-\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})}\\\\ &{\\leq\\gamma(\\mathsf{P}_{\\tilde{V}})_{s}^{*}(V_{\\mathcal P}^{\\pi^{*}}-V_{\\mathcal P}^{\\tilde{\\pi}})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal P}^{\\tilde{\\pi}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(a)$ is from $\\tilde{\\pi}=\\arg\\operatorname*{max}_{\\pi}V_{\\tilde{\\mathcal P}}^{\\pi}$ , and the last inequality is from the fact $\\mathsf{P}_{\\tilde{V}}\\in\\mathcal{P}_{s}^{*}$ and hence $\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})\\le(\\mathsf{P}_{\\tilde{V}})_{s}^{*}V_{\\mathcal{P}}^{\\pi^{*}}$ . ", "page_idx": 16}, {"type": "text", "text": "Applying the inequality above recursively implies ", "page_idx": 16}, {"type": "equation", "text": "$$\nV_{\\mathfrak{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)\\leq\\frac{1}{1-\\gamma}\\sum_{x}d_{\\mathsf{P}_{\\bar{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})|.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle=\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})+\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\leq\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|+\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\leq\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|+\\frac{1}{1-\\gamma}\\sqrt{\\frac{8\\log\\frac{4S A}{\\delta}\\log\\frac{S A}{\\delta}}{\\mathcal{S}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last inequality is from ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\hat{\\sigma}^{*}(V_{\\bar{y}}^{\\bar{\\pi}})-\\bar{\\sigma}^{*}(V_{\\bar{y}}^{\\bar{\\pi}})\\|}\\\\ &{\\overset{(a)}{=}\\operatorname*{max}_{s}\\left\\{\\bigg|\\operatorname*{max}_{0\\le\\lambda\\le\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{y}}^{\\bar{\\pi}}-\\mu)-R\\mathsf{S p a n}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)\\Big\\}\\right.}\\\\ &{\\quad-\\operatorname*{max}_{0\\le\\lambda\\le\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)-(\\kappa_{s}^{*}+R)\\mathsf{S p a n}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)\\Big\\}\\bigg|\\Bigg\\}}\\\\ &{\\overset{(b)}{\\le}\\operatorname*{max}_{s}\\left\\{\\bigg|\\operatorname*{max}_{0\\le\\lambda\\le\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)+R\\mathsf{S p a n}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)-\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)-(\\kappa_{s}^{*}+R)\\mathsf{S p a n}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)}\\\\ &{\\le\\operatorname*{max}_{s}\\left\\{\\operatorname*{max}_{0\\le\\lambda\\le\\frac{1}{1-\\gamma}}|\\kappa_{s}^{*}\\mathsf{S p a n}(V_{\\bar{y}}^{\\bar{\\pi}}-\\lambda)|\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(a)$ is from the dual form of $\\sigma_{\\mathcal{P}}(V)$ and $(b)$ is from the fact that $|\\operatorname*{max}_{x}F(x)-\\operatorname*{max}_{x}G(x)|\\leq$ $\\mathrm{max}_{x}\\left|F(x)-G(x)\\right|$ . ", "page_idx": 16}, {"type": "text", "text": "From the definition of \u03basa = S2 $\\begin{array}{r}{\\kappa_{s}^{a}=\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}}}\\end{array}$ \u03b4) , it holds that \u03bas\u2217 = 2NS (lso,g\u03c0 \u2217\u03b4(s)) $\\begin{array}{r}{\\kappa_{s}^{*}=\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,\\pi^{*}(s))}}\\leq\\sqrt{\\frac{8S\\log\\frac{4S A}{\\delta}\\log\\frac{S A}{\\delta}}{2N\\mu(s,\\pi^{*}(s))}}}\\end{array}$ and hence ", "page_idx": 16}, {"type": "equation", "text": "$$\n|\\kappa_{s}^{*}\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)|\\leq\\frac{1}{1-\\gamma}\\sqrt{\\frac{8S\\log\\frac{4S A}{\\delta}\\log\\frac{S A}{\\delta}}{2N\\mu(s,\\pi^{*}(s))}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "To further bound (28), we first note that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{1-\\gamma}\\sum_{s,a}d_{\\mathsf{P}_{\\tilde{V}}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\leq\\!\\frac{1}{1-\\gamma}\\sum_{s,a}d_{\\mathsf{P}_{\\tilde{V}}}^{*}(s,a)\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}|\\mathsf{P}_{s}^{a}[V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}]_{\\lambda}-\\hat{\\mathsf{P}}_{s}^{a}[V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}]_{\\lambda}|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which is from the dual form of $\\sigma_{\\mathcal{P}}(V)$ , i.e., ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sigma_{\\mathscr P_{s}^{a}}(V)=\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\{{\\sf P}_{s}^{a}[V]_{\\lambda}-{\\bf S p a n}([V]_{\\lambda})\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and $[V]_{\\lambda}(s)=\\operatorname*{min}\\{V(s),\\lambda\\}$ . We then involve (20), and it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{1-\\gamma}\\sum_{s,a}d_{p_{\\delta}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\widehat{\\gamma}}^{\\widehat{\\mathbf{a}}})-\\hat{\\sigma}_{s}^{*}(V_{\\widehat{\\gamma}}^{\\widehat{\\mathbf{a}}})|}\\\\ &{\\displaystyle\\overset{(a)}{\\leq}\\frac{1}{1-\\gamma}\\sum_{s,a}d_{p_{\\delta}}^{*}(s,a)\\operatorname*{max}_{0\\leq\\lambda\\leq1,\\ldots}\\left|P_{s}^{a}[V_{\\widehat{\\gamma}}^{\\widehat{\\mathbf{a}}}]_{\\lambda}-\\hat{P}_{s}^{\\widehat{\\mathbf{a}}}[V_{\\widehat{\\gamma}}^{\\widehat{\\mathbf{a}}}]_{\\lambda}\\right|}\\\\ &{\\displaystyle\\leq\\frac{1}{1-\\gamma}\\sum_{s,a}d_{p_{\\delta}}^{*}(s,a)\\left(\\sqrt{\\frac{S\\log\\frac{S A}{\\delta}}{2N(s,a)}}\\frac{1}{1-\\gamma}\\right)}\\\\ &{\\displaystyle\\leq\\frac{1}{(1-\\gamma)^{2}}\\sum_{s,a}d_{p_{\\delta}}^{*}(s,a)\\left(\\sqrt{\\frac{S\\log S_{\\delta}^{\\widehat{\\mathbf{a}}}\\log\\frac{4S A}{\\delta}}{2N\\mu(s,a^{*}(s))}}\\right)}\\\\ &{\\displaystyle\\leq\\frac{1}{(1-\\gamma)^{2}}\\sqrt{\\frac{S\\log S_{\\delta}^{\\widehat{\\mathbf{a}}}\\log\\frac{4S A}{\\delta}}{2N\\mu(s,a^{*}(s))}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Plugging this inequality to (27) and from the definition of $C^{\\pi^{*}}$ , we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\\leq\\frac{4S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}}\\sqrt{\\frac{C^{\\pi^{*}}}{N}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which completes the proof. ", "page_idx": 17}, {"type": "text", "text": "Theorem 6. For the output policy $\\tilde{\\pi}$ of algorithm $^{\\,l}$ , with probability at least $1-4\\delta$ , it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\tilde{\\mathcal{O}}\\left(\\frac{(C^{\\pi^{*}}S+\\frac{1}{\\mu_{\\operatorname*{min}}})}{N(1-\\gamma)^{2}}+\\sqrt{\\frac{(C^{\\pi^{*}}S+\\frac{1}{\\mu_{\\operatorname*{min}}})}{N(1-\\gamma)^{3}}}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Note that Lemma 8 of [36] states that with probability $1-\\delta$ , for any $(s,a)$ pair, ", "page_idx": 17}, {"type": "equation", "text": "$$\nN(s,a)\\geq{\\frac{N\\mu(s,a)}{8\\log{\\frac{4S A}{\\delta}}}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We hence conduct our proof under the occurrence of this event. Note that for any $s$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)=\\underbrace{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{\\Bar{P}}}^{\\tilde{\\pi}}(s)}_{(A)}+\\underbrace{V_{\\mathcal{\\Bar{P}}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)}_{(B)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "From Lemma 2 and Lemma 3, the above bound can be bounded as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{P}}^{\\pi}(s)}\\\\ &{\\leq(32+4\\sqrt{s})\\sqrt{\\frac{16c_{1}\\log\\frac{45A N}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\operatorname*{min}}}\\log\\frac{45A}{\\delta}}\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}}\\\\ &{\\quad+\\frac{2(8K_{1}+16)\\log\\frac{45A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}}\\\\ &{\\quad+\\sqrt{\\frac{16K_{2}^{2}C^{\\pi*}S\\log\\frac{45A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\frac{(128K_{2}^{2}+32K_{1}+32)C^{\\pi^{*}}S\\log\\frac{45A}{\\delta}}{(1-\\gamma)^{2}N}}\\\\ &{\\quad+4K_{2}\\sqrt{\\frac{8C^{\\pi^{*}}S\\log\\frac{45A}{\\delta}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n=\\tilde{\\mathcal{O}}\\left(\\frac{(C^{\\pi^{*}}S+\\frac{1}{\\mu_{\\mathrm{min}}})}{N(1-\\gamma)^{2}}+\\sqrt{\\frac{(C^{\\pi^{*}}S+\\frac{1}{\\mu_{\\mathrm{min}}})}{N(1-\\gamma)^{3}}}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which completes the proof. ", "page_idx": 18}, {"type": "text", "text": "Lemma 2. (Bound on Term $A$ ) With probability at least $1-2\\delta$ , it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\widetilde{\\mathcal{P}}}^{\\pi}(s)}\\\\ &{\\leq4\\sqrt{\\frac{16K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\frac{(128K_{2}^{2}+32K_{1}+32)C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N}}\\\\ &{\\quad+\\,4K_{2}\\sqrt{\\frac{8C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. To bound term $(A)$ , note that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{P}}^{\\pi}(s)}\\\\ &{=r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\underset{a}{\\mathrm{max}}\\{r(s,a)+\\gamma\\tilde{\\sigma}_{s}^{a}(V_{\\mathcal{P}}^{\\tilde{\\pi}})\\}}\\\\ &{\\overset{(a)}{\\leq}r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-r(s,\\pi^{*}(s))-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{\\leq\\gamma(\\mathsf{P}_{\\mathcal{P}})_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{P}}^{\\pi})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $(a)$ is from $\\tilde{\\pi}=\\arg\\operatorname*{max}_{\\pi}V_{\\tilde{\\mathcal P}}^{\\pi}$ , and the last inequality is from the fact $\\mathsf{P}_{\\tilde{V}}\\in\\mathcal{P}_{s}^{*}$ and hence $\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})\\le(\\mathsf{P}_{\\tilde{V}})_{s}^{*}V_{\\mathcal{P}}^{\\pi^{*}}$ . ", "page_idx": 18}, {"type": "text", "text": "Applying (40) recursively implies ", "page_idx": 18}, {"type": "equation", "text": "$$\nV_{\\mathfrak{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)\\leq\\frac{1}{1-\\gamma}\\sum_{x}d_{\\mathsf{P}_{\\bar{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\widetilde{\\sigma}_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})|.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle=\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})+\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\le\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})|+\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\le\\sum_{x}d_{\\mathbb{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\tilde{\\pi}})|+\\frac{16C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)N},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last inequality is from ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\sigma}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})-\\bar{\\sigma}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})\\|}\\\\ &{\\overset{(a)}{=}\\operatorname*{max}_{s}\\bigg\\{\\bigg|\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)-R\\mathsf{S p a n}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)\\Big\\}}\\\\ &{\\quad-\\displaystyle\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)-(\\kappa_{s}^{*}+R)\\mathsf{S p a n}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)\\Big\\}\\bigg|\\bigg\\}}\\\\ &{\\overset{(b)}{\\leq}\\operatorname*{max}_{s}\\bigg\\{\\bigg|\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\Big\\{\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)+R\\mathsf{S p a n}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)-\\hat{\\mathsf{P}}_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)-(\\kappa_{s}^{*}+R)\\mathsf{S p a n}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\lambda)\\Big\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\leq\\operatorname*{max}_{s}\\left\\{\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\vert\\kappa_{s}^{*}\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)\\vert\\right\\},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $(a)$ is from the dual form of $\\sigma_{\\mathcal{P}}(V)$ and $(b)$ is from the fact that $|\\operatorname*{max}_{x}F(x)-\\operatorname*{max}_{x}G(x)|\\leq$ $\\mathrm{max}_{x}\\left|F(x)-G(x)\\right|$ . ", "page_idx": 19}, {"type": "text", "text": "Since $\\begin{array}{r}{N(s,a)\\ge\\frac{N\\mu(s,a)}{8\\log\\frac{4S A}{\\delta}}}\\end{array}$ , from Assumption 1, we have that $\\frac{1}{N(s,\\pi^{*}(s)}\\leq\\frac{8\\log\\frac{4S A}{\\delta}}{N\\mu(s,\\pi^{*}(s))}\\leq\\frac{8C^{\\pi^{*}}\\log\\frac{4S A}{\\delta}}{\\operatorname*{min}\\{d_{P_{\\tilde{V}}}^{*}(s,\\pi^{*}(s)),\\frac{1}{S}\\}}\\leq\\frac{8C^{\\pi^{*}}\\log\\frac{4S A}{\\delta}}{N}\\Big(S+\\frac{1}{d_{P_{\\tilde{V}}}^{*}(s,\\pi^{*}(s))}\\Big).$ ", "page_idx": 19}, {"type": "text", "text": "From the definition of $\\begin{array}{r}{\\kappa_{s}^{a}=\\frac{1}{N(s,a)}}\\end{array}$ , it holds that $\\begin{array}{r}{\\kappa_{s}^{*}=\\frac{1}{N(s,\\pi^{*}(s))}\\leq\\frac{8\\log\\frac{4S A}{\\delta}}{N\\mu(s,\\pi^{*}(s))}\\leq\\frac{8C^{\\pi^{*}}\\log\\frac{4S A}{\\delta}}{N}\\Big(S+}\\end{array}$ $\\frac{1}{d_{\\mathsf{P}_{\\tilde{V}}}^{*}(s,\\pi^{*}(s))}\\bigg)$ and hence ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{s,a}d_{\\mathbb{P}_{\\widetilde{V}}}^{*}\\left(s,a\\right)\\mathbf{Span}(V_{\\mathcal{P}}^{\\widetilde{\\pi}}-\\lambda)\\kappa_{s}^{*}\\leq\\sum_{s,a}d_{\\mathbb{P}_{\\widetilde{V}}}^{*}\\left(s,a\\right)\\frac{8C^{\\pi^{*}}\\log\\frac{4S A}{\\delta}}{\\left(1-\\gamma\\right)N}\\left(S+\\frac{1}{d_{\\mathbb{P}_{\\widetilde{V}}}^{*}\\left(s,\\pi^{*}(s)\\right)}\\right)\\leq\\frac{16C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\left(1-\\gamma\\right)N}\\leq\\frac{\\gamma_{1}}{\\gamma_{1}},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "To further bound (42), we first note that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{1-\\gamma}\\sum_{s,a}d_{\\mathsf{P}_{\\tilde{V}}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\displaystyle\\leq\\!\\frac{1}{1-\\gamma}\\sum_{s,a}d_{\\mathsf{P}_{\\tilde{V}}}^{*}(s,a)\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}|\\mathsf{P}_{s}^{a}[V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}]_{\\lambda}-\\hat{\\mathsf{P}}_{s}^{a}[V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}]_{\\lambda}|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which is from the dual form of $\\sigma_{\\mathcal{P}}(V)$ , i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sigma_{\\mathscr P_{s}^{a}}(V)=\\operatorname*{max}_{0\\leq\\lambda\\leq\\frac{1}{1-\\gamma}}\\{{\\sf P}_{s}^{a}[V]_{\\lambda}-{\\bf S p a n}([V]_{\\lambda})\\},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and $[V]_{\\lambda}(s)=\\operatorname*{min}\\{V(s),\\lambda\\}$ . We then utilize Lemma 15 and (44), and it holds that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{n(1-\\gamma)}\\underset{\\leq\\varepsilon}{\\sum_{j\\leq\\varepsilon}}\\varphi_{\\varepsilon}(s_{i},\\alpha_{j}|\\varepsilon^{\\varepsilon}|^{p})-\\beta_{x}^{-1}(\\varepsilon^{\\varepsilon}|^{p})|}\\\\ &{\\leq\\frac{1}{1-\\gamma}\\underset{\\leq\\varepsilon}{\\sum_{j\\leq\\varepsilon}}\\varphi_{\\varepsilon}(s_{i},\\alpha_{j}\\frac{\\operatorname*{max}_{\\varepsilon}}{\\operatorname*{sup}_{\\varepsilon}(s_{i},\\alpha_{j})})\\underset{\\leq\\varepsilon}{\\operatorname*{max}_{\\varepsilon}}\\left\\{\\gamma_{1}\\gamma_{2}^{\\varepsilon}\\int_{\\mathbb{R}(\\varepsilon)}^{\\varepsilon}-\\varepsilon^{\\varepsilon}|\\zeta_{j}^{\\varepsilon}|_{\\mathbb{R}(\\varepsilon)}^{2}\\right.}\\\\ &{\\leq\\frac{1}{1-\\gamma}\\underset{\\leq\\varepsilon}{\\sum_{j\\leq\\varepsilon}}\\varphi_{\\varepsilon}(s_{i},\\alpha_{j})\\left(\\frac{\\operatorname*{max}_{\\varepsilon}-\\sqrt{n}}{(1-\\gamma)\\varepsilon^{\\varepsilon}(\\log{n})}+K_{\\gamma}\\Bigg|\\frac{\\sqrt{n}\\pi_{\\varepsilon}(\\gamma_{2}^{\\varepsilon})}{|\\sqrt{n}_{\\varepsilon}(\\pi_{2})|}\\right)}\\\\ &{\\leq\\frac{1}{1-\\gamma}\\underset{\\geq\\varepsilon}{\\sum_{j\\leq\\varepsilon}}\\varphi_{\\varepsilon}(s_{i},\\alpha_{j})\\left(\\frac{\\operatorname*{max}_{\\varepsilon}-\\sqrt{n}\\pi_{\\varepsilon}^{\\varepsilon}\\delta_{j}}{(1-\\gamma)\\varepsilon^{\\frac{\\varepsilon}{\\varepsilon}}}\\Big(\\delta_{\\varepsilon}+\\frac{\\alpha_{j}}{\\sqrt{n}_{\\varepsilon}(\\pi_{2})}\\Big)+K_{\\gamma}\\Bigg|\\frac{\\sqrt{n}\\pi_{\\varepsilon}(\\gamma_{2}^{\\varepsilon})}{|\\sqrt{n}_{\\varepsilon}(\\pi_{2})|}\\right)}\\\\ &{\\leq\\frac{16K_{\\varepsilon}\\varepsilon^{\\varepsilon}\\gamma_{5}\\log\\frac{n\\delta_{x}}{2}}{|\\gamma(1-\\gamma)|^{2}}+\\frac{K_{\\varepsilon}}{1-\\gamma}\\underset{\\geq\\varepsilon}{\\sum_{\\varepsilon}}\\varepsilon_{\\varepsilon}(s_{i},\\alpha_{j})\\sqrt{\\frac{n}{\\sqrt{n}_{\\varepsilon}(\\pi_{2})}}}\\\\ &{\\leq\\frac{16K_{\\varepsilon}\\varepsilon^{\\varepsilon}\\gamma_{ \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We then bound the two terms as follows. ", "page_idx": 20}, {"type": "text", "text": "Bound on Term $A_{1}$ We first claim the following inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+2|\\gamma\\tilde{\\sigma}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\ge0.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To prove (49), we note that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathfrak{P}}^{\\pi}(s)=\\underset{a}{\\mathrm{max}}\\,Q_{\\bar{\\mathfrak P}}^{\\bar{\\pi}}(s,a)}\\\\ &{\\qquad\\geq Q_{\\bar{\\mathfrak P}}^{\\bar{\\pi}}(s,\\pi^{*}(s))}\\\\ &{\\qquad=\\hat{r}(s,\\pi^{*}(s))+\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\tilde{\\pi}})}\\\\ &{\\qquad=\\hat{r}(s,\\pi^{*}(s))+\\gamma(\\mathsf{P}_{\\bar{\\nu}})^{*}V_{\\bar{\\mathfrak P}}^{\\pi}-\\gamma(\\mathsf{P}_{\\bar{\\nu}})^{*}V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}}+\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\tilde{\\pi}})}\\\\ &{\\qquad=\\hat{r}(s,\\pi^{*}(s))+\\gamma(\\mathsf{P}_{\\bar{\\nu}})^{*}V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}}+\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}})-\\gamma\\sigma_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}})}\\\\ &{\\qquad\\geq\\hat{r}(s,\\pi^{*}(s))+\\gamma(\\mathsf{P}_{\\bar{\\nu}})^{*}V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}}-2|\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}})-\\gamma\\sigma_{s}^{*}(V_{\\bar{\\mathfrak P}}^{\\bar{\\pi}})|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and hence for any $s\\in\\mathcal{S}$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)-\\gamma(\\mathsf{P}_{\\tilde{V}})_{s}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+2|\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma_{s}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\geq\\hat{r}(s,\\pi^{*}(s))\\geq0,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which proves (49). ", "page_idx": 20}, {"type": "text", "text": "Now with (49), we first note that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(V_{\\mathfrak{F}}^{\\tilde{\\pi}}\\circ V_{\\mathfrak{F}}^{\\tilde{\\pi}})-(\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\circ(\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{=(V_{\\mathfrak{F}}^{\\tilde{\\pi}}-\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\circ(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\leq(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+2|\\gamma\\tilde{\\sigma}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|)\\circ(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\leq\\cfrac{2}{1-\\gamma}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+2|\\gamma\\tilde{\\sigma}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the last inequality is due to the fact $\\begin{array}{r}{\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}+\\gamma\\mathsf{P}_{\\tilde{V}}^{*}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\|\\le\\frac{2}{1-\\gamma}}\\end{array}$ and (49). ", "page_idx": 20}, {"type": "text", "text": "We first have that ", "text_level": 1, "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in\\mathcal{N}_{\\ell}}(\\gamma_{\\ell}\\cup\\mathrm{Yor}_{\\ell})\\sum_{\\ell=1}^{n}(V_{\\ell})}\\\\ &{=(\\delta_{\\ell}\\gamma_{\\ell})\\psi_{\\ell}(V_{\\ell}^{\\star}\\times V_{\\ell}^{\\star})-(\\Gamma_{\\ell}\\vee V_{\\ell}^{\\star})=(\\mathcal{V}_{\\ell}V_{\\ell}^{\\star})}\\\\ &{\\le\\left\\langle d_{\\psi_{\\ell}}\\mathcal{P}_{\\psi}(V_{\\ell}^{\\star})e^{-\\psi_{\\ell}^{\\star}}\\right\\rangle-\\frac{1}{\\gamma_{2}}(V_{\\ell}^{\\star})^{2}\\sigma(V_{\\ell}^{\\star})+\\frac{2}{\\gamma_{1}(1-\\gamma)}(V_{\\ell}^{\\star}-\\gamma_{\\ell}\\psi_{\\ell}^{\\star}+2|\\gamma^{\\star}(V_{\\ell}^{\\star})-\\gamma^{\\prime}(V_{\\ell}^{\\star})|)}\\\\ &{\\overset{,,}{\\le}\\left\\langle d_{\\psi_{\\ell}}\\mathcal{P}_{\\psi}(V_{\\ell}^{\\star})e^{-\\psi_{\\ell}^{\\star}}\\right\\rangle-\\frac{1}{\\gamma_{2}}(V_{\\ell}^{\\star})^{2}\\sigma(V_{\\ell}^{\\star})+\\frac{2}{\\gamma_{1}(1-\\gamma)}(I-\\gamma_{\\ell})\\psi_{\\ell}^{\\star}+\\frac{2}{\\gamma_{1}(1-\\gamma)}\\left|\\gamma^{\\star}(V_{\\ell}^{\\star})-\\gamma^{\\star}(V_{\\ell}^{\\star})\\right|}\\\\ &{=\\left\\langle d_{\\psi_{\\ell}}\\mathcal{P}_{\\ell}(V_{\\ell}^{\\star})(V_{\\ell}^{\\star})\\sigma(V_{\\ell}^{\\star})+\\frac{2}{\\gamma_{2}(1-\\gamma)}(I-\\gamma_{\\ell})V_{\\ell}^{\\star}\\right\\rangle+\\frac{4}{\\gamma_{2}(1-\\gamma)}\\left|\\gamma^{\\star}(V_{\\ell}^{\\star})-\\gamma^{\\star}(V_{\\ell}^{\\star})\\right|}\\\\ &{=(d_{\\psi_{\\ell}}\\mathcal{P}_{\\ell})^{2}(I-\\gamma_{\\ell})\\varphi\\left(\\frac{1}{\\gamma}(V_{\\ell}^{\\star})\\sigma(V_{\\ell}^{\\\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $(a)$ is from (52), $(b)$ is due to $\\gamma<1$ , $(c)$ is from the definition of visitation distribution. ", "page_idx": 20}, {"type": "text", "text": "Note that by Cauchy\u2019s inequality, $\\begin{array}{r}{\\sum_{s}d_{\\mathsf{P}_{\\hat{V}}}^{*}(s)\\sqrt{\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\hat{V}})_{s}^{*}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}~\\le~\\sqrt{\\sum_{s}d_{\\mathsf{P}_{\\hat{V}}}^{*}(s)\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\hat{V}})_{s}^{*}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})},}\\end{array}$ hence ", "page_idx": 21}, {"type": "text", "text": "$\\begin{array}{r l}&{\\sum_{k_{l}}\\bigg(\\frac{\\partial}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.}\\\\ &{\\leq\\sum_{i=1}^{{\\mathcal{N}_{E}}}\\bigg\\langle\\frac{\\partial}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.\\bigg.}\\\\ &{\\leq\\sum_{i=1}^{{\\mathcal{N}_{E}}}\\bigg\\langle\\frac{\\partial}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.\\sum_{k_{l}=1}^{\\mathcal{N}_{E}}\\bigg\\langle\\frac{\\partial}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.\\frac{1}{\\partial{\\alpha_{l}}}\\bigg.\\bigg.}\\\\ &{\\qquad\\bigg.\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.\\sum_{k_{l}=1}^{\\mathcal{N}_{E}}\\bigg\\langle\\beta_{l}u_{k_{l}}^{k_{l}}\\bigg\\rangle\\bigg\\langle\\beta_{l}u_{k_{l}}^{k_{l}}u_{l}^{k_{l}}\\bigg\\rangle}\\\\ &{\\qquad\\bigg.\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.}\\\\ &{\\leq\\bigg.\\bigg.\\bigg.\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\alpha_{l}}\\bigg.\\bigg.\\bigg.\\sum_{k_{l}=1}^{\\mathcal{N}_{E}}\\bigg\\langle\\beta_{l}u_{k_{l}}^{k_{l}}\\bigg\\rangle\\bigg\\langle\\beta_{l}u_{k_{l}}^{k_{l}}-\\frac{1}{\\sqrt{\\beta_{l}}}u_{k_{l}}^{k_{l}}u_{l}^{k_{l}}\\bigg\\rangle}\\\\ &{\\qquad\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\beta_{l}}\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial}{\\partial\\beta_{l}}\\bigg.\\bigg.\\bigg.}\\\\ &{\\qquad\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\beta_{l}}\\bigg.\\bigg.\\bigg\\langle\\frac{\\partial}{\\partial\\beta_{l}}\\bigg.\\bigg.\\langle\\beta_{l}u_{k_{l}}^{k_{l}}\\bigg\\rangle\\bigg\\langle\\frac{\\partial^{\\mathcal{N}_{E}}}{\\partial\\beta_{l}}\\bigg.\\bigg.\\bigg\\rangle\\bigg\\langle\\frac{\\partial}{\\partial\\beta_{l}}\\bigg.}\\\\ &{\\qquad\\bigg.\\bigg.\\bigg\\langle\\frac{$ $\\begin{array}{r l}{\\gamma}&{\\quad\\mapsto\\cdots}\\\\ &{\\qquad\\cdots}\\\\ &{\\qquad\\zeta\\stackrel{(a,b)\\leq}\\cdots\\frac{n(a)}{n(a)}\\sqrt{\\frac{n}{n}(Z_{n}(a)\\log(a))}+\\sqrt{\\frac{n(a,b)}{n}(Z_{n}(a,b)\\log(a))}}\\\\ &{\\leq\\sqrt{\\frac{n(a)^{2}\\log(a)}{n}}\\frac{\\sqrt{n}}{\\sqrt{n}}\\sum_{i,j=1,\\cdots,i\\neq j}^{\\infty}\\gamma_{i,j}(a,b)\\log(a)\\sqrt{\\frac{n}{n}}}\\\\ &{\\leq\\sqrt{\\frac{(2)^{2}\\sigma^{2}\\kappa^{2}\\kappa_{1}\\sigma_{1}^{2}}{\\sqrt{n}}}\\frac{\\sqrt{n}}{\\sqrt{n}}\\frac{\\sqrt{n}}{\\sqrt{n}+1+\\sqrt{n}\\sigma^{2}\\kappa_{1}\\sigma_{1}^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\frac{1}{n(a)}\\sqrt{n(b)}}\\\\ &{\\leq\\sqrt{\\frac{(2)^{2}\\sigma^{2}\\kappa^{2}\\kappa_{1}\\sigma_{1}^{2}}{\\sqrt{n}}}\\frac{\\sqrt{n}}{\\sqrt{n}}\\frac{\\sqrt{n}}{\\sqrt{n}(1-\\sqrt{n})}\\frac{\\sqrt{n}}{\\sqrt{n}}\\sqrt{\\left(Z_{n}(a)\\log(a)\\right)}\\sqrt{n},\\frac{\\sqrt{n}(c)^{\\prime}\\sigma^{2}\\kappa_{1}^{2}}{\\sqrt{n}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\frac{1}{n(a)}\\sqrt{\\alpha^{2}\\kappa_{1}\\sigma_{1}^{2}}\\cdots\\sqrt{n}\\sigma^{2}\\nabla_{n}^{(d)}}\\\\ &{\\leq\\sqrt{\\frac{n(a)^{2}\\sigma^{2}\\kappa_{1}\\sigma_{1}^{2}}{\\sqrt{n}}}\\frac{\\sqrt{n}}{\\sqrt{n}}+\\frac{\\sqrt{n}\\sigma^{2}\\kappa_{1}\\sigma_{1}^{2}}{\\sqrt{n}}\\frac{\\sqrt{n}}{\\sqrt{n}}+\\frac{1}{\\sqrt{n}\\sigma^{2}\\kappa_{1}}\\sqrt{n}\\langle\\sigma_{1},b\\rangle\\sqrt{n}\\sigma^{2}\\nu_{1}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\$ (1 \u2212\u03b3)K2N ", "page_idx": 21}, {"type": "text", "text": "where the first inequality is from (44) and the last inequality follows similarly as (42). ", "page_idx": 21}, {"type": "text", "text": "Hence, Term $A_{1}$ can be bounded as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A_{1}\\leq\\sqrt{\\frac{64K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\frac{64K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}+\\frac{1}{2(1-\\gamma)}\\langle d_{\\tilde{\\mathbf{P}}_{\\tilde{V}}}^{*},|\\sigma^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}^{*}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\rangle}\\\\ {+\\underbrace{16C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}_{(1-\\gamma)^{2}N}.\\eqno(S\\\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Bound on Term $A_{2}$ ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "From Lemma 10, it is straightforward to see that for any transition kernel $q_{s}^{a}\\in\\mathcal{P}_{s}^{a}$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\vert\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{q_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\vert\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=|\\mathbf{Var}_{\\mathbb{P}_{s}^{a}}(V_{\\widetilde{\\mathcal{P}}}^{\\pi}-\\underset{s}{\\min}V_{\\widetilde{\\mathcal{P}}}^{\\pi}(s))-\\mathbf{Var}_{q_{s}^{a}}(V_{\\widetilde{\\mathcal{P}}}^{\\pi}-\\underset{s}{\\min}V_{\\widetilde{\\mathcal{P}}}^{\\pi}(s))|}\\\\ &{\\leq\\|\\mathsf{P}_{s}^{a}-q_{s}^{a}\\|_{1}\\|V_{\\widetilde{\\mathcal{P}}}^{\\pi}-\\underset{s}{\\min}V_{\\widetilde{\\mathcal{P}}}^{\\pi}(s)\\|^{2}}\\\\ &{\\leq2R(\\mathbf{Span}(V_{\\widetilde{\\mathcal{P}}}^{\\pi}))^{2}}\\\\ &{\\leq\\frac{2}{\\gamma^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Hence ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sum_{\\varrho}d_{\\varrho}^{*}(s,a)\\sqrt{\\frac{|\\mathrm{Varp}_{\\varrho}(V_{\\ g}^{*})-\\mathrm{Varp}_{\\varrho}(V_{g}^{*})|}{N(s,a)}}}\\\\ &{\\leq\\sum_{\\varrho,a}d_{\\varrho}^{*}(s,a)\\sqrt{\\frac{32C^{C^{*}}\\mathrm{Sloog}\\frac{4\\mathrm{S}A}{N(s,a)}|\\mathrm{Varp}_{\\varrho}(V_{g}^{*})-\\mathrm{Varp}_{\\varrho}(V_{g}^{*})|}{N}}}\\\\ &{=\\sqrt{\\frac{32C^{C^{*}}\\mathrm{Slog}\\frac{4\\mathrm{S}A}{N}}{N}}\\sum_{\\varrho,a}d_{\\varrho}^{*}(s,a)\\sqrt{\\mathrm{Varp}_{\\varrho}(V_{g}^{*})-\\mathrm{Varp}_{\\varrho}(V_{g}^{*})|}}\\\\ &{\\leq\\sqrt{\\frac{32C^{C^{*}}\\mathrm{Slog}\\frac{4\\mathrm{S}A}{N}}{N}}\\sum_{\\varrho,a}d_{\\varrho}^{*}(s,a)\\sqrt{\\frac{2}{\\gamma^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}}\\\\ &{\\leq\\sqrt{\\frac{32C^{C^{*}}\\mathrm{Slog}\\frac{4\\mathrm{S}A}{N}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus Term $A_{2}$ can be bounded as ", "page_idx": 22}, {"type": "equation", "text": "$$\nA_{2}\\leq K_{2}\\sqrt{\\frac{32C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Combine the bounds we obtained for terms $A_{1}$ and $A_{2}$ in (55) and (58), we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{1-\\gamma}\\displaystyle\\sum_{s,a}d_{\\mathsf{P}_{\\hat{V}}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\bar{\\ p}}^{\\bar{\\pi}})-\\hat{\\sigma}_{s}^{*}(V_{\\bar{p}}^{\\bar{\\pi}})|}\\\\ &{\\leq\\sqrt{\\frac{64K_{2}^{2}C^{\\pi*}S\\log\\frac{4S A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\frac{64K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma(1-\\gamma)^{2}N}+\\frac{1}{2(1-\\gamma)}\\displaystyle\\sum_{s,a}d_{\\mathsf{P}_{\\hat{V}}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\bar{p}}^{\\bar{\\pi}})-\\hat{\\sigma}_{s}^{*}(V_{\\bar{p}}^{\\bar{\\pi}})|}\\\\ &{\\quad+\\frac{16C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N}+K_{2}\\sqrt{\\frac{32C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}+\\frac{16K_{1}C^{\\pi^{*}}S\\log\\bar{\\delta}}{N(1-\\gamma)^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which further implies that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{1-\\gamma}\\displaystyle\\sum_{s,a}d_{\\mathbb{P}_{\\hat{\\nu}}}^{*}(s,a)|\\sigma_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{*}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\leq4\\sqrt{\\frac{16K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\frac{64K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma(1-\\gamma)^{2}N}+\\frac{(32K_{1}\\log\\frac{4S A}{\\delta}+16\\log\\frac{4S A}{\\delta})C^{\\pi^{*}}S}{(1-\\gamma)^{2}N}}\\\\ &{\\quad+4K_{2}\\sqrt{\\frac{8C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{N}}\\sqrt{\\frac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, combine (41), (42) and the inequality above, we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\cfrac{1}{1-\\gamma}\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\bar{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\bar{\\pi}})|}\\\\ &{\\leq\\cfrac{1}{1-\\gamma}\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\bar{\\pi}})-\\hat{\\sigma}_{x}^{*}(V_{\\hat{\\mathcal{P}}}^{\\bar{\\pi}})|+\\cfrac{8C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N}}\\\\ &{\\leq4\\sqrt{\\cfrac{16K_{2}^{2}C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\gamma^{2}(1-\\gamma)^{3}N}}+\\cfrac{(128K_{2}^{2}+32K_{1}+32)C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N}}\\\\ &{\\phantom{=.4K_{2}\\sqrt{\\cfrac{8C^{\\pi^{*}}S\\log\\frac{4S A}{\\delta}}{\\delta}}\\sqrt{\\cfrac{2}{\\gamma^{2}(1-\\gamma)^{2}\\operatorname*{max}\\{(1-\\gamma),R\\}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which completes the proof. ", "page_idx": 23}, {"type": "text", "text": "Lemma 3. (Bound on Term B) If N \u2265196c1( l1o\u2212g\u03b3 4)S2\u03b4ANN\u00b5lmoing 4S\u03b4A, then with probability at least $1-2\\delta$ , it holds that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{B\\leq(32+4\\sqrt{8})\\sqrt{\\frac{16c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\operatorname*{min}}}}\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}}\\\\ &{\\phantom{A\\leq}+\\frac{2(8K_{1}+16)\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. From the robust Bellman equation, it holds that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)}}\\\\ {{\\ }}\\\\ {{\\ }}\\\\ {{\\ }=\\hat{r}(s,\\tilde{\\pi}(s))+\\gamma\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\hat{r}(s,\\tilde{\\pi}(s))-\\gamma\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ {{\\ }=\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}}))}\\\\ {{\\ }=\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathrm{Pr})_{\\mathcal{S}}^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}+(\\mathrm{Pr})_{\\mathcal{S}}^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}}))}\\\\ {{\\ }=\\gamma(\\mathrm{P}_{V})_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}})+\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathrm{Pr})_{\\mathcal{S}}^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ {{\\ }=\\displaystyle\\frac{\\gamma}{1-\\gamma}\\sum_{x}d_{\\tilde{\\mathbb{P}}_{V}}^{\\tilde{\\pi}}(x)(\\tilde{\\sigma}_{x}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathrm{P}_{V})_{\\mathcal{X}}^{\\tilde{\\pi}(x)}V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ {{\\ }\\le\\displaystyle\\frac{\\gamma}{1-\\gamma}\\sum_{x}d_{\\tilde{\\mathbb{P}}_{V}}^{\\tilde{\\pi}}(x)(\\tilde{\\sigma}_{x}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathrm{P}_{V})_\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $(\\mathsf{P}_{V})_{s}^{\\tilde{\\pi}(s)}=\\arg\\operatorname*{min}_{q\\in\\mathcal{P}_{s}^{\\tilde{\\pi}(s)}}q V_{\\mathcal{P}}^{\\tilde{\\pi}}$ , and $(\\mathsf{P}_{\\tilde{V}})_{s}^{\\tilde{\\pi}(s)}=\\arg\\operatorname*{min}_{q\\in\\mathcal{P}_{s}^{\\tilde{\\pi}(s)}}q V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ , and the last inequality is from $(\\mathsf{P}_{V})_{s}^{\\tilde{\\pi}(s)}\\in\\mathcal{P}_{s}^{\\pi^{*}(s)}$ and $(\\mathsf{P}_{\\tilde{V}})_{s}^{\\tilde{\\pi}(s)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}=\\sigma_{\\Phi_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq(\\mathsf{P}_{V})_{s}^{\\tilde{\\pi}(s)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ ", "page_idx": 23}, {"type": "text", "text": "On the other hand, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)}\\\\ &{=\\hat{r}(s,\\tilde{\\pi}(s))+\\gamma\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\hat{r}(s,\\tilde{\\pi}(s))-\\gamma\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}}))}\\\\ &{=\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathbb{P}_{\\tilde{\\pi}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}+(\\mathbb{P}_{\\tilde{\\nu}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}}))}\\\\ &{\\overset{(a)}{\\geq}\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathbb{P}_{\\tilde{\\nu}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}+(\\mathbb{P}_{\\tilde{\\nu}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}-(\\mathbb{P}_{\\tilde{\\nu}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma(\\mathbb{P}_{\\mathcal{P}})^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}})+\\gamma(\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-(\\mathbb{P}_{\\mathcal{P}})^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\frac{\\gamma}{1-\\gamma}\\sum_{\\pi}d_{\\mathcal{P}}^{\\tilde{\\pi}}\\gamma(x)(\\tilde{\\sigma}_{x}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $(a)$ is from the fact that $\\mathsf{P}_{\\tilde{V}}\\in\\mathcal{P}$ and hence $\\sigma_{s}^{\\tilde{\\pi}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})\\leq(\\mathsf{P}_{\\tilde{V}})_{s}^{\\tilde{\\pi}(s)}V_{\\mathcal{P}}^{\\tilde{\\pi}}$ . ", "page_idx": 23}, {"type": "text", "text": "Hence we have that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)\\|\\le\\operatorname*{max}\\bigg\\{\\underbrace{\\bigg|\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{x}d_{\\mathsf{P}_{V}}^{\\tilde{\\pi}}(x)(\\tilde{\\sigma}_{x}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-(\\mathsf{P}_{\\tilde{V}})_{x}^{\\tilde{\\pi}(x)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\bigg|}_{I},}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\underbrace{\\bigg|\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\tilde{V}}}^{\\tilde{\\pi}}(x)(\\tilde{\\sigma}_{x}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-(\\mathsf{P}_{\\tilde{V}})_{x}^{\\tilde{\\pi}(x)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\bigg|}_{I I}\\bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We then bound terms $(I)$ and $(I I)$ . Note that the only difference between the two terms are the visitation distributions, i.e, d\u03c0P\u02dcV and d\u03c0P\u02dc \u02dc . ", "page_idx": 24}, {"type": "text", "text": "Bound on Term $(I)$ ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We first note that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-(\\mathsf{P}_{\\tilde{V}})_{s}^{\\tilde{\\pi}(s)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}|}\\\\ &{\\,\\,=\\,|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\,\\,\\le\\,\\underbrace{|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}_{(B_{1})}+\\underbrace{|\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}_{(B_{2})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "hence it is sufficient to bound $B_{1},B_{2}$ . ", "page_idx": 24}, {"type": "text", "text": "To bound $B_{1}$ , note that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widetilde\\sigma_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathfrak{p}}}^{\\tilde{\\pi}})-\\widehat\\sigma_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathfrak{p}}}^{\\tilde{\\pi}})|}\\\\ &{\\overset{(a)}{=}|\\operatorname*{max}\\{\\widehat{\\mathfrak{p}}_{s}^{\\tilde{\\pi}(s)}(V_{\\tilde{\\mathfrak{p}}}^{\\tilde{\\pi}}-\\lambda)-(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)\\}-\\operatorname*{max}_{\\lambda}\\{\\widehat{\\mathfrak{p}}_{s}^{\\tilde{\\pi}(s)}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)-R\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)\\}}\\\\ &{\\le\\underset{\\lambda}{\\operatorname*{max}}\\{\\kappa_{s}^{\\tilde{\\pi}(s)}\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)\\}}\\\\ &{\\quad\\underset{\\kappa^{\\tilde{\\pi}(s)}}{=}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $(a)$ is from the dual form of the support function [13] and the last inequality is because $\\begin{array}{r}{\\mathbf{Span}(\\dot{V})\\stackrel{}{\\leq}\\frac{1}{1-\\gamma}}\\end{array}$ for any $\\begin{array}{r}{0\\leq V\\leq\\frac{1}{1-\\gamma}}\\end{array}$ . ", "page_idx": 24}, {"type": "text", "text": "We then bound $B_{2}$ . Similarly from the dual form, it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\n|\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\operatorname*{max}_{\\lambda}\\{|(\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}-\\mathsf{P}_{s}^{\\tilde{\\pi}(s)})(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\lambda)\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We then apply Lemma 15, it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\lambda}{\\operatorname*{max}}\\{|(\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}-\\mathsf{P}_{s}^{\\tilde{\\pi}(s)})(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}}-\\lambda)\\}}\\\\ &{\\leq\\frac{K_{1}}{N(s,\\tilde{\\pi}(s))(1-\\gamma)}+\\sqrt{\\frac{c_{1}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}})}{N(s,\\tilde{\\pi}(s))}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "with probability at least $1-\\delta$ and $\\begin{array}{r}{K_{1}=\\left(2+c_{2}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)+\\sqrt{2c_{1}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)}\\right).}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Note that for any $s,a$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{Var}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\widetilde{\\pi}})}\\\\ &{=\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\mathcal{P}}^{\\widetilde{\\pi}})+(\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\widetilde{\\pi}})-\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\mathcal{P}}^{\\widetilde{\\pi}}))+(\\mathbf{Var}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\widetilde{\\pi}})-\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\widetilde{\\pi}})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Hence ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathfrak{P}}}^{\\bar{\\pi}})}\\le\\sqrt{\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\mathcal P}^{\\bar{\\pi}})}+\\sqrt{|\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\bar{\\mathcal P}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\mathcal P}^{\\tilde{\\pi}})|}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n+\\,\\sqrt{|\\mathbf{Var}_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Firstly, Lemma 7 of [38] and Lemma 10 imply that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{x}d_{\\mathsf{P}_{V}}^{\\widetilde{\\pi}}(x)\\sqrt{\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{x}^{a}}\\!\\left(V_{\\mathcal{P}}^{\\widetilde{\\pi}}\\right)}\\le\\sqrt{\\frac{8\\mathbf{Span}(V_{\\mathcal{P}}^{\\widetilde{\\pi}})}{\\gamma^{2}}}\\le\\sqrt{\\frac{64}{\\operatorname*{max}\\{R,1-\\gamma\\}}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To bound $\\sqrt{|\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})|}$ , note that it holds that $|\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})~-$ $\\mathbf{Var}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\Phi}^{\\tilde{\\pi}})|\\leq\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}\\|^{2}$ , thus ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{x}d_{\\mathsf{P}_{V}}^{\\tilde{\\pi}}(x)\\sqrt{|\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{x}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{x}^{a}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})|}\\leq\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}\\|.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "And the last term can be bounded as ", "page_idx": 25}, {"type": "equation", "text": "$$\n|\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\frac{2}{\\gamma^{2}\\operatorname*{max}\\{R,1-\\gamma\\}}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "using (56), and hence ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{x}d_{\\mathsf{P}_{V}}^{\\tilde{\\pi}}(x)\\sqrt{|\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{x}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{V})_{x}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\leq\\sqrt{\\frac{8}{\\operatorname*{max}\\{R,1-\\gamma\\}}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hence by combining (72),(73) and (75) we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{x}d_{\\mathbf{P}_{V}}^{\\tilde{\\pi}}(x)\\sqrt{\\frac{\\mathbf{V}\\mathbf{ar}_{\\mathbf{P}_{\\tilde{s}}^{\\pi}(s)}\\left(V_{\\tilde{\\mathbf{p}}}^{\\tilde{\\pi}}\\right)}{N(s,\\tilde{\\pi}(s))}}}\\\\ &{\\leq\\displaystyle\\sum_{x}d_{\\mathbf{P}_{V}}^{\\tilde{\\pi}}(x)\\sqrt{\\frac{8\\log\\frac{4S A}{\\delta}\\mathbf{Var}_{\\mathbf{P}_{\\tilde{s}}^{\\pi(s)}}\\left(V_{\\tilde{\\mathbf{p}}}^{\\tilde{\\pi}}\\right)}{N\\mu_{\\mathrm{min}}}}}\\\\ &{\\leq\\sqrt{\\frac{8\\log\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}}}\\left(\\|V_{\\tilde{\\mathbf{p}}}^{\\tilde{\\pi}}-V_{\\mathbf{P}}^{\\tilde{\\pi}}\\|+(8+\\sqrt{8})\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus plug the inequality above and the bound of $B_{1}$ in (63), we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I\\leq\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{x}d_{\\mathrm{p}_{V}}^{\\pi}(x)(\\tilde{\\sigma}_{s}^{\\pi}(V_{\\tilde{\\mathcal{P}}}^{\\pi})-(\\mathsf{P}_{\\tilde{V}})^{\\tilde{\\pi}(s)}V_{\\tilde{\\mathcal{P}}}^{\\pi})}\\\\ &{\\quad\\leq\\sqrt{\\frac{16c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}}\\left(\\|V_{\\tilde{\\mathcal{P}}}^{\\pi}-V_{\\mathcal{P}}^{\\pi}\\|+(8+\\sqrt{8})\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}\\right)}\\\\ &{\\quad\\quad+\\,\\frac{4K_{1}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}+\\frac{8\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\operatorname*{min}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Bound on Term $I I$ ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Similarly to the analysis in bounding the Term (I), we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\n|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-(\\mathsf{P}_{\\tilde{V}})_{s}^{\\tilde{\\pi}(s)}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}|\\leq\\underbrace{|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}_{(B_{1})}+\\underbrace{|\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|}_{(B_{2})},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $B_{1}$ can be bounded as ", "page_idx": 25}, {"type": "equation", "text": "$$\n|\\tilde{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\frac{\\kappa_{s}^{\\tilde{\\pi}(s)}}{1-\\gamma}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The bound on $B_{2}$ similarly follows as in Term $(I)$ . Note that ", "page_idx": 25}, {"type": "text", "text": "$|\\hat{\\sigma}_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\frac{K_{1}}{N(s,\\tilde{\\pi}(s))(1-\\gamma)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathbf{V}\\mathbf{ar}_{\\mathrm{p}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}{N(s,\\tilde{\\pi}(s))}}$ with probability at least $1-\\delta$ and $\\begin{array}{r}{K_{1}=\\left(2+c_{2}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)+\\sqrt{2c_{1}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)}\\right).}\\end{array}$ Note that for any $s,a$ , ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbf{Var}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})=\\mathbf{Var}_{(\\mathsf{P}_{\\bar{\\mathcal{V}}})_{s}^{a}}(V_{\\mathcal{P}}^{\\tilde{\\pi}})+(\\mathbf{Var}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{Var}_{(\\mathsf{P}_{\\bar{\\mathcal{V}}})_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Hence ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})}\\le\\sqrt{\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\bar{V}})_{s}^{a}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})}+\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\bar{V}})_{s}^{a}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Similarly, Lemma 13 of [38] and Lemma 10 imply that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{s}d_{\\mathbb{P}_{\\tilde{V}}}^{\\tilde{\\pi}}(s)\\sqrt{\\mathbf{V}\\mathbf{ar}_{(\\mathbb{P}_{\\tilde{V}})_{s}^{a}}\\!\\left(V_{\\mathcal{P}}^{\\tilde{\\pi}}\\right)}\\leq\\sqrt{\\frac{8\\mathbf{S}\\!\\mathbf{p}\\mathbf{an}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}{\\gamma^{2}}}\\leq\\sqrt{\\frac{64}{\\operatorname*{max}\\{R,1-\\gamma\\}}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "And to bound $\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\tilde{V}})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}$ , note that ", "page_idx": 26}, {"type": "equation", "text": "$$\n|\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\tilde{V}})_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\frac{2}{\\gamma^{2}\\operatorname*{max}\\{R,1-\\gamma\\}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "from (56), and hence ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{s}d_{\\mathsf{P}_{\\bar{V}}}^{\\tilde{\\pi}}(s)\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\mathbf{V}\\mathbf{ar}_{(\\mathsf{P}_{\\bar{V}})_{s}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})}\\leq\\sqrt{\\frac{8}{\\operatorname*{max}\\{R,1-\\gamma\\}}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Hence by combining (83) and (85) we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{s}d_{\\mathbf{\\hat{P}}_{\\hat{V}}}^{\\boldsymbol{\\pi}}(s)\\sqrt{\\frac{\\mathrm{\\mathbf{V}}\\mathbf{a}_{\\mathbf{r_{p}}\\frac{\\pi}{s}(s)}\\left(V_{\\mathbf{\\hat{y}}}^{\\pi}\\right)}{N(s,\\widetilde{\\pi}(s))}}}\\\\ &{\\displaystyle\\leq\\sum_{s}d_{\\mathbf{\\hat{P}}_{\\hat{V}}}^{\\boldsymbol{\\pi}}(s)\\sqrt{\\frac{8\\log\\frac{4S A}{\\delta}\\mathrm{\\mathbf{Var}}_{\\mathbf{p}_{s}^{\\widetilde{\\tau}(s)}}\\left(V_{\\mathbf{\\hat{y}}}^{\\widetilde{\\tau}}\\right)}{N\\mu_{\\mathrm{min}}}}}\\\\ &{\\displaystyle\\leq\\sqrt{\\frac{8\\log\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}}}\\left((8+\\sqrt{8})\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Thus plug the inequality above and the bound of $B_{1}$ , we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I I\\leq\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{s}d_{\\mathsf{P}_{V}}^{\\widetilde{\\mathsf{\\pi}}}(s)(\\widetilde{\\sigma}_{s}^{\\widetilde{\\pi}}(V_{\\widetilde{\\mathfrak{P}}}^{\\widetilde{\\pi}})-(\\mathsf{P}_{\\widetilde{V}})_{s}^{\\widetilde{\\pi}(s)}V_{\\widetilde{\\mathfrak{P}}}^{\\widetilde{\\pi}})}\\\\ &{\\quad\\leq\\sqrt{\\frac{16c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}}\\left((8+\\sqrt{8})\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}\\right)}\\\\ &{\\quad\\quad+\\,\\frac{4K_{1}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}+\\frac{8\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\operatorname*{min}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then we combine the bounds of terms $(I)$ and $(I I)$ together, and we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)\\|}\\\\ &{\\le\\sqrt{\\frac{16c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\operatorname*{min}}(1-\\gamma)^{2}}}\\left(\\|V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}\\|+(16+2\\sqrt{8})\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n+\\,\\frac{8K_{1}\\log\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}(1-\\gamma)^{2}}+\\frac{16\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Due to the fact that $\\begin{array}{r}{N\\ge\\frac{196c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}}\\end{array}$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}\\|\\leq(32+4\\sqrt{8})\\sqrt{\\frac{16c_{1}\\log\\frac{4S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}}\\sqrt{\\frac{1}{\\operatorname*{max}\\{R,1-\\gamma\\}}}}\\\\ &{\\qquad\\qquad\\qquad+\\,\\frac{2(8K_{1}+16)\\log\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}(1-\\gamma)^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and hence completes the proof. ", "page_idx": 27}, {"type": "text", "text": "C Proofs of Section 4.2 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Theorem 7. With probability at least $1-4\\delta$ , the output policy $\\tilde{\\pi}$ of algorithm $I$ satisfies ", "page_idx": 27}, {"type": "equation", "text": "$$\nV_{\\Phi}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq40\\sqrt{\\frac{(1+R)\\log\\frac{24S A N}{\\delta}\\log\\frac{4S A}{\\delta}C^{\\pi^{*}}S}{N(1-\\gamma)^{4}}}+\\frac{\\gamma K_{2}S\\sqrt{1+R}\\log\\frac{8S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. Using the similar decomposition implies that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)=\\underbrace{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{\\Bar{P}}}^{\\tilde{\\pi}}(s)}_{(A)}+\\underbrace{V_{\\mathcal{\\Bar{P}}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)}_{(B)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "The proof is then completed by combing the following two lemmas. ", "page_idx": 27}, {"type": "text", "text": "T ", "page_idx": 27}, {"type": "text", "text": "Lemma 4. (Bound on Term $A$ ) With probability at least $1-4\\delta$ , it holds that ", "page_idx": 27}, {"type": "equation", "text": "$$\nV_{\\mathfrak{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)\\leq40\\sqrt{\\frac{(1+R)C^{\\pi^{*}}S\\log\\frac{24S A N}{\\delta}\\log\\frac{4S A}{\\delta}}{N(1-\\gamma)^{4}}}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. To bound term $(A)$ , note that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{P}}^{\\pi}(s)}\\\\ &{=r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\underset{a}{\\mathrm{max}}\\{r(s,a)+\\gamma\\tilde{\\sigma}_{s}^{a}(V_{\\mathcal{P}}^{\\tilde{\\pi}})\\}}\\\\ &{\\overset{(a)}{\\leq}r(s,\\pi^{*}(s))+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-r(s,\\pi^{*}(s))-\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{=\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})-\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{\\leq\\gamma(\\mathsf{P}_{\\mathcal{T}})_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{P}}^{\\tilde{\\pi}})+\\gamma\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{*}(V_{\\mathcal{P}}^{\\tilde{\\pi}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $(a)$ is from $\\tilde{\\pi}=\\arg\\operatorname*{max}_{\\pi}V_{\\tilde{\\mathcal P}}^{\\pi}$ , and the last inequality is from the fact $\\mathsf{P}_{\\tilde{V}}\\in\\mathcal{P}_{s}^{*}$ and hence $\\sigma_{s}^{*}(V_{\\mathcal{P}}^{\\pi^{*}})\\le(\\mathsf{P}_{\\tilde{V}})_{s}^{*}V_{\\mathcal{P}}^{\\pi^{*}}$ . ", "page_idx": 27}, {"type": "text", "text": "Applying (93) recursively implies ", "page_idx": 27}, {"type": "equation", "text": "$$\nV_{\\mathfrak{P}}^{\\pi^{*}}(s)-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)\\leq\\frac{1}{1-\\gamma}\\sum_{x}d_{\\mathsf{P}_{\\bar{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\widetilde{\\sigma}_{x}^{*}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})|.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Note that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{x}d_{\\mathsf{P}_{\\tilde{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}})-\\tilde{\\sigma}_{x}^{*}(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}})|\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})-\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})+\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})-\\tilde{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})|}\\\\ &{\\le\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\hat{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})-\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})|+\\displaystyle\\sum_{x}d_{\\mathsf{P}_{\\hat{V}}}^{*}(x)|\\hat{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})-\\tilde{\\sigma}_{x}^{*}(V_{\\bar{\\mathcal{P}}}^{\\pi})|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The first term in (95) can be bounded as follows. Recall the dual form of the support function w.r.t. the uncertainty set ${\\mathcal{P}}=\\{q\\in{\\varDelta}({\\mathcal{S}}):\\chi^{2}(q||p)\\leq R\\}$ as follows: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sigma_{\\Phi}(V)=\\operatorname*{max}_{\\alpha\\in[0,V]}\\bigg\\{p V_{\\alpha}-\\sqrt{R\\mathbf{V}\\!\\mathbf{a}\\mathbf{r}_{p}(V_{\\alpha})}\\bigg\\},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $V_{\\alpha}(s)=\\operatorname*{min}\\{V(s),\\alpha\\}$ . ", "page_idx": 28}, {"type": "text", "text": "Applying the dual form further implies that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\sigma_{s}^{a}(V_{\\mathfrak{p}}^{\\tilde{\\pi}})-\\hat{\\sigma}_{s}^{a}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|}\\\\ &{\\leq\\displaystyle\\operatorname*{max}_{0\\leq\\alpha\\leq\\frac{1}{1-\\gamma}}\\left\\vert(\\mathsf{P}_{s}^{a}-\\hat{\\mathsf{P}}_{s}^{a})(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha}-\\left(\\sqrt{R\\mathbf{\\bar{V}}_{\\mathbf{arp}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha})}-\\sqrt{R\\mathbf{\\bar{V}}_{\\mathbf{\\bar{P}}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha}}\\right)\\right\\vert}\\\\ &{\\leq\\displaystyle\\operatorname*{max}_{0\\leq\\alpha\\leq\\frac{1}{1-\\gamma}}\\left\\vert(\\mathsf{P}_{s}^{a}-\\hat{\\mathsf{P}}_{s}^{a})(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha}\\right\\vert+\\displaystyle\\operatorname*{max}_{0\\leq\\alpha\\leq\\frac{1}{1-\\gamma}}\\left\\vert\\left(\\sqrt{R\\mathbf{V}_{\\mathbf{arp}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha})}-\\sqrt{R\\mathbf{V}_{\\mathbf{\\bar{P}}}\\mathbf{ar}_{\\bar{\\mathsf{P}}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha})}\\right)\\right\\vert}\\\\ &{\\leq2\\sqrt{\\frac{\\log\\frac{2S A N}{\\delta}}{N(s,a)(1-\\gamma)^{2}}}+\\displaystyle\\operatorname*{max}_{0\\leq\\alpha\\leq\\frac{1}{1-\\gamma}}\\left\\vert\\left(\\sqrt{R\\mathbf{\\bar{V}}_{\\mathbf{arp}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha})}-\\sqrt{R\\mathbf{\\bar{V}}_{\\mathbf{\\bar{P}}}\\mathbf{ar}_{\\bar{\\mathsf{P}}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})_{\\alpha})}\\right)\\right\\vert+\\frac{R}{(1-\\gamma)N(1-\\gamma)N(1-\\gamma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last inequality directly follows from the Hoeffding\u2019s inequality [38] and $\\textstyle{\\frac{1}{N}}$ -net technique used in Lemma 15. ", "page_idx": 28}, {"type": "text", "text": "As for the second term in (97), we utilize Lemma 7 and the technique of $\\epsilon$ -net, which implies that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\sigma_{s}^{a}((V_{\\widetilde{\\mathcal{P}}}^{\\pi})_{\\alpha})-\\hat{\\sigma}_{s}^{a}(V_{\\widetilde{\\mathcal{P}}}^{\\pi})|}\\\\ &{\\leq2\\sqrt{\\frac{\\log\\frac{2S A N}{\\delta}}{N(s,a)(1-\\gamma)^{2}}}+2\\sqrt{\\frac{2R\\log\\frac{24S A N}{\\delta}}{N(s,a)(1-\\gamma)^{2}}}}\\\\ &{\\leq4\\sqrt{\\frac{2(1+R)\\log\\frac{24S A N}{\\delta}}{N(s,a)(1-\\gamma)^{2}}}+\\frac{R}{(1-\\gamma)N}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This hence bounds the first term in (95). For the second term in (95), similarly apply the dual form and we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{\\sigma}_{s}^{a}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})-\\tilde{\\sigma}_{s}^{a}(V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})|}\\\\ &{\\overset\\le\\operatorname*{max}_{0\\le\\alpha\\le\\frac1{1-\\gamma}}\\bigg|\\left(\\sqrt{R\\mathbf{V}\\mathbf{a}\\mathbf{r}_{\\bar{\\mathcal{P}}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})_{\\alpha})}-\\sqrt{(R+\\kappa_{s}^{a})\\mathbf{V}\\mathbf{a}\\mathbf{r}_{\\hat{\\mathcal{P}}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})_{\\alpha})}\\right)\\bigg|}\\\\ &{\\le\\frac{\\kappa_{s}^{a}}{\\sqrt{R}+\\sqrt{R+\\kappa_{s}^{a}}}\\operatorname*{max}_{0\\le\\alpha\\le\\frac1{1-\\gamma}}\\sqrt{\\mathbf{V}\\mathbf{a}\\mathbf{r}_{\\hat{\\mathcal{P}}_{s}^{a}}((V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}})_{\\alpha})}}\\\\ &{\\le\\sqrt{\\frac{(1+R)\\log\\frac{24S A N}{\\delta}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last inequality is from the fact that $\\begin{array}{r}{\\mathbf{Var}(V_{\\alpha})\\leq\\frac{1}{(1-\\gamma)^{2}}}\\end{array}$ for any $\\begin{array}{r}{V\\le\\frac{1}{1-\\gamma}}\\end{array}$ and any $\\begin{array}{r}{\\alpha\\leq\\frac{1}{1-\\gamma}}\\end{array}$ . We now plug (98) and (99) to (95) and (94), and we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\zeta_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{\\Bar{P}}}^{\\pi}(s)\\leq\\frac{1}{1-\\gamma}\\sum_{x}d_{\\mathcal{P}_{\\Bar{V}}}^{*}(x)|\\sigma_{x}^{*}(V_{\\mathcal{\\Bar{P}}}^{\\pi})-\\tilde{\\sigma}_{x}^{*}(V_{\\mathcal{\\Bar{P}}}^{\\pi})|}}\\\\ &{}&{\\leq\\frac{1}{1-\\gamma}\\sum_{x}d_{\\mathcal{P}_{\\mathcal{V}}}^{*}(x)\\left(\\sqrt{\\frac{(1+R)\\log\\frac{24S A N}{\\delta}}{N(x,\\pi^{*}(x))(1-\\gamma)^{2}}}+4\\sqrt{\\frac{2(1+R)\\log\\frac{24S A N}{\\delta}}{N(x,\\pi^{*}(x))(1-\\gamma)^{2}}}+\\frac{1}{(1-\\gamma)^{2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\leq40{\\sqrt{\\frac{(1+R)C^{\\pi^{*}}S\\log{\\frac{24S A N}{\\delta}}\\log{\\frac{4S A}{\\delta}}}{N(1-\\gamma)^{4}}}}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the last inequality is from (44). This hence completes the proof. ", "page_idx": 29}, {"type": "text", "text": "Lemma 5. (Bound on Term $B$ ) With probability at least $1-4\\delta$ , it holds that ", "page_idx": 29}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(s)\\leq\\frac{\\gamma K_{2}S\\sqrt{1+R}\\log\\frac{8S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\mathrm{min}}}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. Similarly to the proof of Lemma 4, note that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}}(s)-V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}}(s)}\\\\ &{=r(s,\\widetilde{\\pi}(s))+\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}})-r(s,\\widetilde{\\pi}(s))-\\gamma\\sigma_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}})}\\\\ &{=\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}})-\\gamma\\sigma_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})}\\\\ &{=\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}})-\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})+\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})-\\gamma\\sigma_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})}\\\\ &{\\le\\gamma(\\tilde{\\boldsymbol{\\nabla}}_{V})\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}}-V_{\\mathcal{\\Bar{P}}}^{\\Bar{\\pi}})+\\gamma\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})-\\gamma\\sigma_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})}\\\\ &{\\le\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{s}d_{\\nu}^{\\Bar{\\pi}}(s)\\left(\\tilde{\\sigma}_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})-\\sigma_{s}^{\\Bar{\\pi}(s)}(V_{\\mathcal{P}}^{\\Bar{\\pi}})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $(\\tilde{\\mathsf{P}}_{V})_{s}^{\\tilde{\\pi}(s)}=\\arg\\operatorname*{min}_{q\\in\\tilde{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}q V_{\\Phi}^{\\tilde{\\pi}}$ . We then bound the term $\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}})$ ", "page_idx": 29}, {"type": "text", "text": "From Lemma 6, it holds that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V_{\\mathfrak{P}}^{\\tilde{\\pi}})-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}})}\\\\ &{\\,\\,\\leq\\frac{\\gamma}{1-\\gamma}\\displaystyle\\sum_{s}d_{v}^{\\tilde{\\pi}}(s)\\frac{K_{2}S\\sqrt{1+R}}{(1-\\gamma)N(s,a)}}\\\\ &{\\,\\,=\\frac{\\gamma K_{2}S\\sqrt{1+R}\\log\\frac{8S A}{\\delta}}{(1-\\gamma)^{2}N\\mu_{\\operatorname*{min}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which completes the proof. ", "page_idx": 29}, {"type": "text", "text": "Lemma 6. With probability at least $1-\\delta$ , it holds that for any $s\\in\\mathcal{S}$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n-\\sigma_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}})+\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V_{\\mathcal{P}}^{\\tilde{\\pi}})\\leq\\frac{K_{2}S\\sqrt{1+R}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. We first consider a vector $V$ that is independent from $\\hat{\\mathsf{P}}$ . ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V)-\\sigma_{s}^{\\tilde{\\pi}(s)}(V)}\\\\ &{\\quad=\\underset{\\alpha}{\\operatorname*{max}}\\{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha})-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{Var}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha})}\\}-\\underset{\\alpha}{\\operatorname*{max}}\\{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha})-\\sqrt{R\\mathbf{Var}_{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha})}\\}}\\\\ &{\\quad\\le\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha^{*}})-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{Var}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})-\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha^{*}})+\\sqrt{R\\mathbf{Var}_{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})},\\qquad(10)\\leqslant\\Gamma_{\\alpha^{*}(s)}\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\alpha^{*}\\triangleq\\arg\\operatorname*{max}_{\\alpha}\\{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha})-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha})}\\}$ , and the last inequality is from the fact that $-\\operatorname*{max}{f}\\le-f(x)$ for any $x$ . ", "page_idx": 29}, {"type": "text", "text": "We then construct an $\\epsilon_{1}$ -net over $[0,\\frac{1}{1-\\gamma}]$ , such that there exists $\\beta$ with $\\|V_{\\alpha^{*}}-V_{\\beta}\\|\\leq\\epsilon_{1}$ . Then we further have that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V)-\\sigma_{s}^{\\tilde{\\pi}(s)}(V)}\\\\ &{\\leq\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha^{*}})-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{Var}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})}-\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}(V_{\\alpha^{*}})+\\sqrt{R\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})}}\\\\ &{\\leq\\cfrac{c_{1}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}+\\sqrt{\\cfrac{c_{2}\\mathbf{Var}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}{N(s,\\tilde{\\pi}(s))}}+\\cfrac{\\epsilon_{1}}{(1-\\gamma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n-\\,\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})}+\\sqrt{R\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})},\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we use the Bernstein inequality and the technique of $\\epsilon_{1}$ -net. To bound the last two terms, we note that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})}\\mathbf{Var}_{\\hat{\\mathbf{p}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})+\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\alpha^{*}})}}&\\\\ &{\\overset{(a)}{=}-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})}\\mathbf{Var}_{\\hat{\\mathbf{p}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})+\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}-\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}+\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}+\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}}&\\\\ &{\\overset{(b)}{=}-\\sqrt{(R+\\kappa_{s}^{\\tilde{\\pi}(s)})}\\mathbf{Var}_{\\hat{\\mathbf{p}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})+\\sqrt{R\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}+\\sqrt{\\frac{\\epsilon_{1}}{(1-\\gamma)}}}&\\\\ &{\\quad+\\sqrt{R}\\left(\\sqrt{\\frac{C_{1}\\mathbf{Var}_{\\mathbf{p}_{s}^{\\tilde{\\pi}(s)}}(V_{\\beta})}{N(s,\\tilde{\\pi}(s))}}+\\frac{C_{2}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}\\right),}&{\\quad{\\mathrm{(107)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we again use the $\\epsilon_{1}$ -net technique in $(a)$ , and apply Lemma 7 in $(b)$ . Combining (106) and (107) implies that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V})=\\sigma_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V})}\\\\ &{\\leq\\frac{c_{1}}{(1-\\gamma)^{N}(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}+\\sqrt{\\frac{c_{2}\\mathbf{R}_{0}\\boldsymbol{V}_{\\parallel,\\hat{\\varepsilon}^{\\mathrm{2sin}}}(\\boldsymbol{V})}{N(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}}+\\frac{c_{1}}{(1-\\gamma)}}\\\\ &{\\quad-\\sqrt{(\\boldsymbol{R}+\\boldsymbol{R}_{0}^{\\ast}(\\boldsymbol{V}))\\mathbf{W}_{\\theta\\in\\mathcal{I}}(\\boldsymbol{V})},}\\\\ &{\\quad+\\sqrt{R}\\left(\\sqrt{\\frac{f_{\\mathrm{T}}\\mathbf{R}_{0}\\boldsymbol{V}_{\\parallel,\\hat{\\varepsilon}^{\\mathrm{2sin}}}(\\boldsymbol{V})}{N(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}}+\\frac{C_{2}}{(1-\\gamma)^{N}(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}\\right)}\\\\ &{=\\frac{c_{1}}{(1-\\gamma)^{N}(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}+\\frac{c_{1}}{(1-\\gamma)}+\\sqrt{\\frac{c_{1}}{(1-\\gamma)}}\\frac{d}{(1-\\gamma)}}\\\\ &{\\quad-\\sqrt{(\\boldsymbol{R}+\\boldsymbol{R}_{0}^{\\ast}(\\boldsymbol{V}))\\mathbf{W}_{\\theta\\in\\mathcal{I}}(\\boldsymbol{V})}+\\sqrt{R\\mathbf{W}_{\\theta\\in\\mathcal{I}}(\\boldsymbol{V})}+\\sqrt{\\frac{f_{\\mathrm{T}}\\mathbf{R}_{0}}{N(k-\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}}+\\sqrt{\\frac{c_{2}\\mathbf{R}_{0}\\boldsymbol{V}_{\\parallel,\\hat{\\varepsilon}^{\\mathrm{2sin}}}(\\boldsymbol{V})}{N(k,\\tilde{\\sigma}_{\\mathbf{k}}^{\\mathrm{2sin}}(\\boldsymbol{V}))}}}\\\\ &{=\\frac{c_{1}}{(1-\\gamma)^{N}(k\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Clearly, if we set $C=\\sqrt{c_{2}}+\\sqrt{R C_{1}}$ and ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\kappa_{s}^{\\tilde{\\pi}(s)}=\\frac{C}{N(s,\\tilde{\\pi}(s))}+2\\sqrt{\\frac{C R}{N(s,\\tilde{\\pi}(s))}}=\\tilde{\\mathcal{O}}\\left(\\sqrt{\\frac{1}{N(s,\\tilde{\\pi}(s))}}\\right),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "then $\\begin{array}{r}{\\left(\\sqrt{\\frac{c_{2}}{N(s,\\tilde{\\pi}(s))}}+\\sqrt{\\frac{R C_{1}}{N(s,\\tilde{\\pi}(s))}}+\\sqrt{R}-\\sqrt{R+\\kappa_{s}^{\\tilde{\\pi}(s)}}\\right)\\leq0,}\\end{array}$ , and hence ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\tilde{\\sigma}_{s}^{\\tilde{\\pi}(s)}(V)-\\sigma_{s}^{\\tilde{\\pi}(s)}(V)\\leq\\frac{c_{1}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}+\\frac{\\epsilon_{1}}{(1-\\gamma)}+\\sqrt{\\frac{\\epsilon_{1}}{(1-\\gamma)}}+\\frac{C_{2}\\sqrt{R}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}}\\\\ &{}&{\\leq\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{1+R}}{(1-\\gamma)N(s,\\tilde{\\pi}(s))}\\right),\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (1-\\gamma)\\sqrt{R(s,\\tilde{\\pi}(s))}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "by setting $\\epsilon_{1}\\leq\\tilde{\\mathcal{O}}\\big(\\frac{1}{N}\\big)$ . ", "page_idx": 30}, {"type": "text", "text": "Now to show the claim for $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ , we construct an $\\epsilon_{2}$ -net over $[0,\\frac{1}{1-\\gamma}]^{S}$ . By applying the similar trick, we complete the proof. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "Lemma 7. For any vector $V\\in[0,\\frac{1}{1-\\gamma}]$ that is independent with $\\mathsf{P}$ , with probability at least $1-\\delta$ , it holds that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left|\\sqrt{{W}\\!\\!r_{\\mathsf{P}_{s}^{a}}(V)}-\\sqrt{{W}\\!\\!a r_{\\mathsf{P}_{s}^{a}}(V)}\\right|\\le\\sqrt{\\frac{C_{1}{W}\\!\\!a r_{\\mathsf{P}_{s}^{a}}(V)}{N(s,a)}}+\\frac{C_{2}}{(1-\\gamma)N(s,a)}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. This result can be derived from the Bernstein inequality for $U$ -statistics [3, 32], by noting that the sample standard deviation $\\sqrt{\\frac{n}{n-1}\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{a}}(V)}$ is an $U$ -statistics and ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left|\\sqrt{\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{a}}(V)}-\\sqrt{\\frac{n}{n-1}\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{a}}(V)}\\right|\\leq\\sqrt{\\frac{\\mathbf{V}\\mathbf{ar}_{\\hat{\\mathsf{P}}_{s}^{a}}(V)}{n-1}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "D Proofs of Section 4.3 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Theorem 8. If $N\\ \\geq\\ {\\frac{8\\log\\,{\\frac{1}{\\delta}}}{\\mu_{\\operatorname*{min}}}}$ 8 \u00b5lomgi n\u03b41 , then there exists some universal constants C1, C2, such that with probability at least $1-4\\delta$ , it holds that ", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{\\Phi}^{\\pi^{*}}(\\rho)-V_{\\mathcal{P}}^{\\tilde{\\pi}}(\\rho)\\leq\\frac{8}{N R(1-\\gamma)^{2}}+\\frac{2C_{2}\\sqrt{C^{\\pi^{*}}}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)^{\\delta}}}{R(1-\\gamma)^{2}}\\sqrt{\\frac{S}{N\\mathsf{P}_{\\mathrm{min}}}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Note that ", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}=\\underbrace{V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{\\tilde{P}}}^{\\tilde{\\pi}}}_{\\varDelta_{1}}+\\underbrace{V_{\\mathcal{\\tilde{P}}}^{\\tilde{\\pi}}-V_{\\mathcal{P}}^{\\tilde{\\pi}}}_{\\varDelta_{2}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The proof completes by combining the bounds on the two terms, shown in the following two lemmas. \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Lemma 8. There exists a constant $C_{2}$ , such that with probability at least $1-\\delta$ , it holds that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\rho^{\\top}\\varDelta_{1}{\\leq}\\frac{4}{N R(1-\\gamma)^{2}}+\\frac{2C_{2}\\sqrt{C^{\\pi^{*}}}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)^{\\delta}}}{R(1-\\gamma)^{2}}\\sqrt{\\frac{S}{N\\mathsf P_{\\mathrm{min}}}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. From the definition, ", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=\\operatorname*{max}_{a}Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,a)\\ge Q_{\\mathcal{\\Bar{P}}}^{\\tilde{\\pi}}(s,\\pi^{*}(s))=\\Hat{r}(s,\\pi^{*}(s))+\\gamma\\sigma_{\\mathfrak{\\Hat{P}}^{\\pi^{*}}}(V_{\\Bar{\\mathcal{P}}}^{\\tilde{\\pi}}),\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "hence ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varDelta_{1}(s)=V_{\\mathcal{P}}^{\\pi^{*}}(s)-V_{\\mathcal{\\tilde{P}}}^{\\pi}(s)}\\\\ &{\\quad\\quad=\\hat{r}(s,\\pi^{*}(s))+\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{P}}^{*})-V_{\\mathcal{\\tilde{P}}}^{\\pi}(s)}\\\\ &{\\quad\\quad\\leq\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{P}}^{\\pi^{*}})-\\gamma\\sigma_{\\mathcal{\\tilde{P}}_{s}^{\\pi^{*}}}(V_{\\mathcal{\\tilde{P}}}^{\\pi})}\\\\ &{\\quad\\quad=\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{P}}^{*})-\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{\\tilde{P}}}^{\\pi})+\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{\\tilde{P}}}^{\\pi})-\\gamma\\sigma_{\\mathcal{\\tilde{P}}_{s}^{\\pi^{*}}}(V_{\\mathcal{\\tilde{P}}}^{\\pi})}\\\\ &{\\quad\\quad\\overset{(a)}{\\leq}\\gamma q_{s}^{\\pi^{*}}(V_{\\mathcal{P}}^{\\pi^{*}}-V_{\\mathcal{\\tilde{P}}}^{\\pi})+c(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $q_{s}^{a}$ is the worst-case transition kernel of $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ in $\\mathcal{P}_{s}^{a}$ , and $(a)$ is from $\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\mathcal{P}}^{\\pi^{*}})-\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})=$ $\\sigma_{\\mathfrak{P}_{s}^{\\pi^{*}}}(V_{\\mathfrak{P}}^{\\pi^{*}})-(q_{s}^{\\pi^{*}})(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})\\leq(q_{s}^{\\pi^{*}})(V_{\\mathfrak{P}}^{\\pi^{*}}-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})$ , and $c(s)\\triangleq\\gamma\\sigma_{\\mathcal{P}_{s}^{\\pi^{*}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\pi^{*}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})$ . ", "page_idx": 31}, {"type": "text", "text": "Recursively applying (117) further implies that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\rho^{\\top}\\varDelta_{1}\\leq\\frac{1}{1-\\gamma}\\langle d_{q}^{\\pi^{*}},c\\rangle.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We moreover rewrite $c$ as ", "page_idx": 32}, {"type": "equation", "text": "$$\nc(s)=\\underbrace{\\gamma\\sigma_{\\mathfrak{P}_{s}^{\\pi^{*}}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\pi^{*}}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})}_{\\varDelta_{1,1}}+\\underbrace{\\gamma\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\pi^{*}}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\pi^{*}}}(V_{\\bar{\\mathfrak{P}}}^{\\tilde{\\pi}})}_{\\varDelta_{1,2}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Moreover, we introduce two sets ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{S}_{1}=\\{s:\\displaystyle\\operatorname*{max}_{\\mathbb{Q}\\in\\mathcal{P}}d_{\\mathbb{Q}}^{\\pi^{*}}(s,\\pi^{*}(s))=0\\},}\\\\ &{\\mathfrak{S}_{2}=(\\mathfrak{S}_{1})^{c}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "For $s\\in\\mathcal{S}_{1}$ , (216) of [36] implies that $d_{q}^{\\pi^{*}}(s)=0$ . ", "page_idx": 32}, {"type": "text", "text": "We then focus on $s~\\in~\\mathcal{S}_{2}$ . It has been shown in [36] that $\\mu(s,\\pi^{*}(s))\\,>\\,0$ and $N(s,\\pi^{*}(s))\\geq$ $\\frac{N\\operatorname*{min}\\{\\frac{1}{S},d_{q}^{\\pi^{*}}(s)\\}}{12C^{\\pi^{*}}}$ ", "page_idx": 32}, {"type": "text", "text": "Thus Lemma 17 first implies that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{|\\sigma_{\\mathcal{P}_{s}^{\\pi*}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\pi*}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})|\\leq\\displaystyle\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,\\pi^{*}(s))\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{\\pi*}}}}\\\\ &{}&{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\displaystyle\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{12C^{\\pi^{*}}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{\\pi*}N\\operatorname*{min}\\{\\frac{1}{S},d_{q}^{\\pi^{*}}(s)\\}}};}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "To bound $\\varDelta_{1,2}$ , note that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Delta_{1,2}(s)=-\\operatorname*{sup}_{\\hat{\\mathcal{X}}^{\\prime}}(\\mathcal{Y}_{j})(s)-\\operatorname*{sup}_{\\hat{\\mathcal{X}}^{\\prime}}(\\mathcal{Y}_{j})(s)}\\\\ {\\overset{(a)}{\\underset{\\mathcal{Y}^{\\prime}}{=}}\\operatorname*{sup}_{\\hat{\\mathcal{X}}^{\\prime}}\\Bigg\\{-\\operatorname*{sup}_{\\hat{\\mathcal{Y}}^{\\prime}}\\bigg(\\hat{\\mathcal{X}}_{j}^{\\prime}\\cdot\\mathbf{epp}\\bigg(\\frac{\\mathcal{Y}_{j}^{\\prime}}{\\lambda}\\bigg)\\bigg)-\\lambda\\mathcal{R}\\Bigg\\}}\\\\ &{\\qquad-\\operatorname*{sup}_{\\hat{\\mathcal{X}}^{\\prime}}\\Bigg\\{-\\lambda\\log_{2}\\bigg(\\hat{\\mathcal{Y}}_{j}^{\\prime}\\cdot\\mathbf{epp}\\bigg(\\frac{\\mathcal{Y}_{j}^{\\prime}}{\\lambda}\\bigg)\\bigg)-\\lambda(R+\\kappa_{j}^{\\prime}\\cdot\\mathcal{U}_{j}^{\\prime})\\Bigg\\}}\\\\ {\\overset{(b)}{\\underset{\\mathcal{Y}^{\\prime}\\leq}{=}}\\operatorname*{sup}_{\\frac{\\mathcal{Y}^{\\prime}}{(1-\\lambda)(R+\\lambda)^{2}}\\tau^{2(\\tau)}}\\Bigg\\{-\\lambda\\log_{2}\\bigg(\\hat{\\mathcal{Y}}_{j}^{\\prime}\\cdot\\mathbf{ep}\\bigg(\\frac{\\mathcal{Y}_{j}^{\\prime}}{\\lambda}\\bigg)\\bigg)-\\lambda(R+\\kappa_{j}^{\\prime}\\cdot\\mathcal{U}_{j}^{\\prime})\\Bigg\\}}\\\\ &{\\qquad-\\operatorname*{sup}_{\\frac{\\mathcal{Y}^{\\prime}}{(1-\\lambda)(R+\\lambda)^{2}}\\tau^{2(\\tau)}}\\Bigg\\{-\\lambda\\log_{2}\\bigg(\\hat{\\mathcal{Y}}_{j}^{\\prime}\\cdot\\mathbf{epp}\\bigg(\\frac{\\mathcal{Y}_{j}^{\\prime}}{\\lambda}\\bigg)\\bigg)-\\lambda(R+\\kappa_{j}^{\\prime}\\cdot\\mathcal{U}_{j}^{\\prime})\\Bigg\\}}\\\\ {\\overset{(c)}{\\underset{\\mathcal{Y}^{\\prime}\\leq}{=}}\\underset{\\mathcal{X}^{\\prime}\\leq}{\\frac{\\operatorname*{max}_{\\mathcal{X}^{\\prime}}}{\\frac{\\operatorname*{max}_{\\mathcal{Y}^{\\prime}\\in\\mathcal{Y}}(1-\\lambda)^{2}}{(1-\\lambda)(R+\\lambda)^{2}}}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $(a)$ is from the dual solution of KL-divergence, and $(b)$ is due to the fact that the optimal solutions to both dual forms satisfy (1\u2212\u03b3)(R1+\u03bas\u03c0\u2217(s)) [65], and (c) is due to max f \u2212max g \u2264 $\\operatorname*{max}\\left|f-g\\right|$ . ", "page_idx": 32}, {"type": "text", "text": "Then we plug in the definition of \u03bas\u03c0\u2217(s)= C1 N(sl,o\u03c0g \u22172((s1()1+) \u2212Rm\u03b3)i)Nn\u03b4x SP\u02c6s\u03c0,\u2217x and using (202) of [36], we have that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\varDelta_{1,2}(s)\\leq\\frac{C_{1}}{(1-\\gamma)R}\\sqrt{\\frac{8C^{\\pi^{*}}\\log^{2}\\frac{N S}{\\delta}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N\\operatorname*{min}\\{\\frac{1}{S},d_{q}^{\\pi^{*}}(s)\\}\\mathsf{P}_{\\operatorname*{min}}}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Combine (122) and (124), we have that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{c(s)\\leq\\displaystyle\\frac{C_{1}}{(1-\\gamma)R}\\sqrt{\\frac{8C^{\\pi^{*}}\\log\\frac{N S}{\\delta}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N\\operatorname*{min}\\{\\frac{1}{S},d_{q}^{\\pi^{*}}(s)\\}\\mathrm{P}_{\\operatorname*{min}}}}+\\displaystyle\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{12C^{\\pi^{*}}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{\\pi^{*}}N\\operatorname*{min}\\{\\frac{1}{S},d_{q}^{\\pi^{*}}(s)\\}}}}\\\\ {+\\displaystyle\\frac{4}{N R(1-\\gamma)}.\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(12.01)}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Thus we have that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle d_{q}^{\\pi^{*}},c\\rangle=\\displaystyle\\sum_{s}d_{q}^{\\pi^{*}}(s)c(s)}\\\\ &{\\qquad\\quad\\le\\displaystyle\\sum_{s}d_{q}^{\\pi^{*}}(s)\\left(\\frac{C_{2}}{(1-\\gamma)R}\\sqrt{\\frac{C^{\\pi^{*}}\\log\\frac{N S}{\\delta}\\log\\frac{2(1+R)N^{3S}}{(1-\\gamma)\\delta}}{N\\P_{\\operatorname*{min}}\\operatorname*{min}\\{\\frac{1}{\\delta},d_{q}^{\\pi^{*}}(s)\\}}}+\\frac{4}{N R(1-\\gamma)}\\right)}\\\\ &{\\qquad\\stackrel{(a)}{\\le}\\displaystyle\\frac{4}{N R(1-\\gamma)}+\\frac{2C_{2}\\sqrt{C^{\\pi^{*}}\\log^{2}\\frac{2(1+R)N^{3S}}{(1-\\gamma)\\delta}}}{R(1-\\gamma)}\\sqrt{\\sum_{s}\\frac{d_{q}^{\\pi^{*}}(s)}{\\operatorname*{min}\\{\\frac{1}{\\delta},d_{q}^{\\pi^{*}}(s)\\}}}\\sqrt{\\frac{1}{N P_{\\operatorname*{min}}}}}\\\\ &{\\qquad\\stackrel{(b)}{\\le}\\displaystyle\\frac{4}{N R(1-\\gamma)}+\\frac{2C_{2}\\sqrt{C^{\\pi^{*}}\\log^{2}\\frac{2(1+R)N^{3S}}{(1-\\gamma)\\delta}}}{R(1-\\gamma)}\\sqrt{\\frac{S}{N P_{\\operatorname*{min}}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $(a)$ is from Cauchy inequality, and $(b)$ is from (220) of [36], which hence completes the proof. \u53e3 ", "page_idx": 33}, {"type": "text", "text": "We then bound the term $\\varDelta_{2}$ . ", "page_idx": 33}, {"type": "text", "text": "Lemma 9. ", "text_level": 1, "page_idx": 33}, {"type": "equation", "text": "$$\n\\rho^{\\top}\\varDelta_{2}\\leq\\frac{4}{N R(1-\\gamma)^{2}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. First, note that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\varDelta}_{2}(s)=V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)-V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}(s)}\\\\ &{\\quad\\quad\\quad=\\gamma(\\sigma_{\\tilde{\\mathfrak{P}}\\tilde{\\mathfrak{P}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\mathfrak{P}}^{\\tilde{\\pi}}))}\\\\ &{\\quad\\quad\\quad=\\gamma(\\sigma_{\\tilde{\\mathfrak{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})+\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}))}\\\\ &{\\quad\\quad\\quad=\\gamma(\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\mathfrak{P}}^{\\tilde{\\pi}}))+\\gamma(\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathfrak{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}))}\\\\ &{\\quad\\quad\\quad\\stackrel{(a)}{\\leq}\\gamma q_{s}^{\\tilde{\\pi}}(V_{\\tilde{\\mathfrak{P}}}^{\\tilde{\\pi}}-V_{\\mathfrak{P}}^{\\tilde{\\pi}})+b(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $q_{s}^{\\tilde{\\pi}}$ is the worst-case transition kernel of $V_{\\mathcal{P}}^{\\tilde{\\pi}}$ in $\\mathcal{P}_{s}^{\\tilde{\\pi}}$ , and $b(s)\\triangleq\\gamma(\\sigma_{\\tilde{\\Phi}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}})-\\sigma_{\\mathcal{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\Phi}}^{\\tilde{\\pi}}))$ . Recursively applying (128) implies ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\rho^{\\top}\\varDelta_{2}\\leq\\frac{1}{1-\\gamma}\\langle d_{q}^{\\tilde{\\pi}},b\\rangle.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We further introduce two sets as follows. ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{S}_{1}=\\big\\{s:\\mu\\big(s,\\tilde{\\pi}(s)\\big)=0\\big\\},}\\\\ {\\displaystyle\\mathbb{S}_{2}=\\big\\{s:\\mu\\big(s,\\tilde{\\pi}(s)\\big)>0\\big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "For $s\\in\\mathcal{S}_{1}$ , $\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}}=\\varDelta(\\mathcal{S})$ , hence ", "page_idx": 33}, {"type": "equation", "text": "$$\nb(s)=\\gamma(\\sigma_{\\tilde{\\mathbb{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathbb{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathbb{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathbb{P}}}^{\\tilde{\\pi}}))\\leq0.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "For $s\\in\\mathcal{S}_{2}$ , we have that ", "page_idx": 33}, {"type": "equation", "text": "$$\nb(s)=\\gamma(\\sigma_{\\tilde{\\mathcal{P}}_{\\tilde{s}}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathcal{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}))\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n=\\gamma(\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})+\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathcal{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Hence invoke Lemma 17, we have that for $s\\in\\mathcal{S}_{2}$ , with probability at least $1-\\delta$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sigma_{\\hat{\\mathbb{P}}_{s}^{\\tilde{\\pi}}}\\big(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\big)-\\sigma_{\\mathbb{P}_{s}^{\\tilde{\\pi}}}\\big(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\big)\\le\\operatorname*{min}\\Bigg\\{\\frac{1}{1-\\gamma},\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,\\tilde{\\pi}(s))\\operatorname*{min}_{x}\\hat{\\mathbb{P}}_{s,x}^{\\tilde{\\pi}}}}\\Bigg\\}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "To further bound the RHS of (134), we first note that Lemma 8 of [36] states that if $N\\mu(s,a)\\geq$ $8\\log{\\frac{1}{\\delta}}$ , then with probability $1-\\delta$ , for any $(s,a)$ pair, ", "page_idx": 34}, {"type": "equation", "text": "$$\nN(s,a)\\geq{\\frac{N\\mu(s,a)}{8\\log{\\frac{4}{\\delta}}}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "This moreover implies that with probability $1-\\delta$ , for $s\\in\\mathcal{S}_{2}$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\nN(s,\\tilde{\\pi}(s))\\geq\\frac{N\\mu(s,\\tilde{\\pi}(s))}{8\\log\\frac{4}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "On the other hand, (202) of [36] states that with probability at least $1-\\delta$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{\\operatorname*{min}_{x}\\mathsf{P}_{s,x}^{\\tilde{\\pi}}}{8\\log(N S/\\delta)}\\le\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{\\tilde{\\pi}}\\le e^{2}\\operatorname*{min}_{x}\\mathsf{P}_{s,x}^{\\tilde{\\pi}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Hence by plugging (136) and (137) in (134) we have that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathcal{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{8\\log\\frac{N S}{\\delta}\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,\\tilde{\\pi}(s))\\mathsf{P}_{\\mathrm{min}}}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "On the other hand, similarly to (123), it holds that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{\\hat{\\mathbf{y}}_{s}^{\\pi}}(V_{\\bar{\\mathfrak{P}}}^{\\bar{\\pi}})-\\sigma_{\\hat{\\mathbf{y}}_{s}^{\\bar{\\pi}}}(V_{\\bar{\\mathfrak{P}}}^{\\bar{\\pi}})}\\\\ &{=\\underset{0\\leq\\lambda\\leq\\frac{1}{(1-\\gamma)R}}{\\operatorname*{max}}\\left\\{-\\lambda\\log\\left(\\hat{\\mathbf{P}}_{s}^{\\bar{\\pi}}\\mathbf{exp}\\left(\\frac{-V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}}{\\lambda}\\right)\\right)-\\lambda R\\right\\}}\\\\ &{\\quad-\\underset{0\\leq\\lambda\\leq\\frac{1}{(1-\\gamma)(R+\\kappa_{s}^{\\bar{\\pi}(s)})}}{\\operatorname*{max}}\\left\\{-\\lambda\\log\\left(\\hat{\\mathbf{P}}_{s}^{\\bar{\\pi}}\\mathbf{exp}\\left(\\frac{-V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}}{\\lambda}\\right)\\right)-\\lambda(R+\\kappa_{s}^{\\bar{\\pi}(s)})\\right\\}}\\\\ &{\\stackrel{(a)}{\\geq}\\frac{1}{(1-\\gamma)R}\\kappa_{s}^{\\bar{\\pi}(s)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the last inequality is from the fact that max $F-\\operatorname*{max}G\\geq F(x)-G(x),\\forall x$ . ", "page_idx": 34}, {"type": "text", "text": "Combining with(134) further implies that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{\\hat{\\ensuremath{\\mathbb P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\ensuremath{\\mathbb P}}}^{\\tilde{\\pi}})-\\sigma_{\\Phi_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\ensuremath{\\mathbb P}}}^{\\tilde{\\pi}})}\\\\ &{\\ \\le\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,\\tilde{\\pi}(s))\\operatorname*{min}_{x}\\hat{\\ensuremath{\\mathbb P}}_{s,x}^{\\tilde{\\pi}}}}}\\\\ &{\\ \\le\\frac{4}{N R(1-\\gamma)}+\\sigma_{\\hat{\\ensuremath{\\mathbb P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\ensuremath{\\mathbb P}}}^{\\tilde{\\pi}})-\\sigma_{\\hat{\\ensuremath{\\mathbb P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\ensuremath{\\mathbb P}}}^{\\tilde{\\pi}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "by combining (138) and (139). Thus ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})-\\sigma_{\\mathcal{P}_{s}^{\\tilde{\\pi}}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\frac{4}{N R(1-\\gamma)}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Hence combine with (129) and (132), we further have that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\rho^{\\top}\\varDelta_{2}\\leq\\frac{4}{N R(1-\\gamma)^{2}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "E Auxiliary Lemmas ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Lemma 10. It holds that ", "page_idx": 35}, {"type": "equation", "text": "$$\nS p a n(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\frac{1}{\\gamma\\operatorname*{max}\\{R,1-\\gamma\\}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. Note that when $\\begin{array}{r}{N>\\frac{8\\log\\frac{4S A}{\\delta}}{(1-R)\\mu_{\\mathrm{min}}}}\\end{array}$ and the fact that $\\begin{array}{r}{N(s,a)\\ge\\frac{8\\log\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}}}\\end{array}$ , it holds that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R+\\kappa_{s}^{\\tilde{\\pi}(s)}\\leq R+\\displaystyle\\frac{1}{N(s,\\tilde{\\pi}(s))}}\\\\ &{\\qquad\\qquad\\leq R+\\displaystyle\\frac{8\\log\\displaystyle\\frac{4S A}{\\delta}}{N\\mu_{\\mathrm{min}}}}\\\\ &{\\qquad\\qquad<1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Denote $s^{*}=\\arg\\operatorname*{min}_{s}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)$ . Then it holds that ", "page_idx": 35}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s^{*})=\\{\\hat{r}(s^{*},\\tilde{\\pi}(s))+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We denote the optimal action $\\tilde{\\pi}(s)$ by $a$ in the following proof. Note that there exists a vector $q_{s}^{a}\\in\\mathbb{R}^{S}$ , such that $\\hat{\\mathsf{P}}_{s}^{a}\\,\\geq\\,q_{s}^{a}\\,\\geq\\,0$ , and $\\begin{array}{r}{\\sum_{s^{\\prime}}q_{s}^{a}(s^{\\prime})=1-R-\\kappa_{s}^{a}}\\end{array}$ . This is doable because $\\begin{array}{r}{\\sum_{s^{\\prime}}\\hat{\\mathsf{P}}_{s}^{a}(s^{\\prime})=1}\\end{array}$ and $R+\\kappa_{s}^{a}\\;\\leq\\;1$ . Hence it implies that the transition kernel $q_{s}^{a}+(R+\\kappa_{s}^{a})\\mathbf{1}_{s_{*}}\\;\\in\\;\\tilde{\\mathcal{P}}_{s}^{a}$ , since $\\|q_{s}^{a}+(R+\\kappa_{s}^{a})\\mathbf{1}_{s_{*}}-\\hat{\\mathsf{P}}_{s}^{a}\\|\\leq\\|q_{s}^{a}-\\hat{\\mathsf{P}}_{s}^{a}\\|+(R+\\kappa_{s}^{a})\\leq2(R+\\kappa_{s}^{a})$ . ", "page_idx": 35}, {"type": "text", "text": "Hence ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{\\tilde{\\mathcal{P}}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq(q_{s}^{a}+(R+\\kappa_{s}^{a})\\mathbf{1}_{s_{*}})V_{\\tilde{\\mathcal{P}}}^{\\pi}}\\\\ &{\\qquad\\qquad\\leq(R+\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s_{*})+q_{s}^{a}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}}\\\\ &{\\qquad\\qquad\\leq(R+\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s_{*})+\\|q_{s}^{a}\\|_{1}\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\|}\\\\ &{\\qquad\\qquad=(R+\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s_{*})+(1-R-\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s^{*}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the last equation is from $\\begin{array}{r}{\\sum_{s^{\\prime}}q_{s}^{a}(s^{\\prime})=1-R-\\kappa_{s}^{a}}\\end{array}$ and $\\|V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\|=\\operatorname*{max}_{s}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s^{*})$ Plug this inequality in (145), and it holds that ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s^{*})=V_{\\operatorname*{max}}\\leq\\hat{r}(s^{*},a)+\\gamma(R+\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s_{*})+\\gamma(1-R-\\kappa_{s}^{a})V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s^{*})}\\\\ &{\\qquad\\qquad\\qquad\\leq1+\\gamma(R+\\kappa_{s}^{a})V_{\\operatorname*{min}}+\\gamma(1-R-\\kappa_{s}^{a})V_{\\operatorname*{max}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Thus ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{V_{\\mathrm{max}}\\le\\frac{1+\\gamma(R+\\kappa_{s}^{a})V_{\\mathrm{min}}}{1-\\gamma(1-R-\\kappa_{s}^{a})}}}\\\\ &{}&{\\qquad=\\frac{1+\\gamma(R+\\kappa_{s}^{a})V_{\\mathrm{min}}}{1-\\gamma+\\gamma R+\\gamma\\kappa_{s}^{a}}}\\\\ &{}&{\\qquad\\le\\frac{1}{1-\\gamma+\\gamma(R+\\kappa_{s}^{a})}+V_{\\mathrm{min}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "which implies that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbf{Span}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\frac{1}{1-\\gamma+\\gamma(R+\\kappa_{s}^{a})}\\leq\\frac{1}{\\gamma\\operatorname*{max}\\{R,1-\\gamma\\}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma 11. Recall the set $\\mathbb{S}^{0}\\triangleq\\{s\\in\\mathbb{S}:N(s)=0\\}$ . Then ", "page_idx": 35}, {"type": "text", "text": "(1). For any policy $\\pi$ and $s\\in\\mathcal{S}^{0}$ , $V_{\\tilde{\\mathcal{P}}}^{\\pi}(s)=0,$ ; ", "page_idx": 35}, {"type": "text", "text": "(2). There exists a deterministic robust optimal policy $\\tilde{\\pi}$ , such that for any $s\\notin\\mathcal{S}^{0}$ , $N(s,{\\tilde{\\pi}}(s))>0$ . ", "page_idx": 35}, {"type": "text", "text": "Proof. Proof of (1). ", "page_idx": 36}, {"type": "text", "text": "For any $s\\in\\mathcal{S}^{0}$ , it holds that $N(s,a)=0$ for any $a\\in{\\mathcal{A}}$ . Hence $\\hat{r}(s,a)=0$ and $\\tilde{\\mathcal{P}}_{s}^{a}=\\varDelta(\\mathcal{S})$ . Then for any policy $\\pi$ and $a\\in{\\mathcal{A}}$ , it holds that ", "page_idx": 36}, {"type": "equation", "text": "$$\nQ_{\\tilde{\\mathcal{P}}}^{\\pi}(s,a)=\\hat{r}(s,a)+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\pi})\\leq\\gamma V_{\\tilde{\\mathcal{P}}}^{\\pi}(s).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Thus ", "page_idx": 36}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\pi}(s)=\\sum_{a}\\pi(a|s)Q_{\\hat{\\mathcal{P}}}^{\\pi}(s,a)\\leq\\gamma V_{\\tilde{\\mathcal{P}}}^{\\pi}(s),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "which implies $V_{\\tilde{\\mathcal{P}}}^{\\pi}(s)=0$ together with the fact that $V_{\\tilde{\\mathcal{P}}}^{\\pi}\\geq0$ . ", "page_idx": 36}, {"type": "text", "text": "Proof of (2). ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We prove Claim (2) by contradiction. Assume that for any optimal policy $\\tilde{\\pi}$ , there exists $s\\notin\\mathcal{S}^{0}$ such that $N(s,{\\tilde{\\pi}}(s))=0$ . We then consider a fixed pair $(\\widetilde{\\pi},s)$ . ", "page_idx": 36}, {"type": "text", "text": "$N(s,{\\tilde{\\pi}}(s))=0$ further implies $\\hat{r}(s,\\tilde{\\pi}(s))=0$ , $\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}=\\varDelta(\\mathcal{S})$ , and ", "page_idx": 36}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=\\operatorname*{max}_{a}Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,a)=Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,\\tilde{\\pi}(s))=\\hat{r}(s,\\tilde{\\pi}(s))+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\gamma V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the last inequality is from \u02dcPs\u03c0\u02dc(s) $\\tilde{\\Phi}_{s}^{\\tilde{\\pi}(s)}=\\varDelta(\\mathcal{S}),\\,\\hat{r}(s,\\tilde{\\pi}(s))=0.$ , and $\\sigma_{\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq\\mathbf{1}_{s}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)$ .   \nThis further implies that $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=0$ because $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\geq0$ . ", "page_idx": 36}, {"type": "text", "text": "On the other hand, since $s\\notin\\mathcal{S}^{0}$ , there exists another action $b\\neq\\tilde{\\pi}(s)$ such that $N(s,b)>0$ , and hence ${\\hat{r}}(s,b)=r(s,b)$ . We consider the following two cases. ", "page_idx": 36}, {"type": "text", "text": "(I). If $r(s,b)>0$ , then ", "page_idx": 36}, {"type": "equation", "text": "$$\nQ_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,b)=\\hat{r}(s,b)+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{s}^{b}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})>0=Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,\\tilde{\\pi}(s)),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "which is contradict to $\\begin{array}{r}{V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=\\operatorname*{max}_{a}Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,a)=Q_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s,\\tilde{\\pi}(s)).}\\end{array}$ . ", "page_idx": 36}, {"type": "text", "text": "(II). If $r(s,b)=0$ , Lemma 12 then implies the modified policy $f_{b}^{s}(\\tilde{\\pi})$ is also optimal, and satisfies $N(x,f_{b}^{s}(\\tilde{\\pi})(x))=N(x,\\tilde{\\pi}(x))$ for any $x\\neq s$ , and $N(s,f_{b}^{s}(\\tilde{\\pi})(s))>0$ . ", "page_idx": 36}, {"type": "text", "text": "Then consider the modified policy $f_{b}^{s}(\\tilde{\\pi})$ . ", "page_idx": 36}, {"type": "text", "text": "If there still exists $s^{\\prime}\\notin\\mathcal{S}^{0}$ such that $N(s^{\\prime},f_{b}^{s}(\\tilde{\\pi})(s^{\\prime}))=0$ , then similarly, there exists another action $b^{\\prime}\\ne f_{b}^{s}(\\tilde{\\pi})(s^{\\prime})$ such that $N(s^{\\prime},b^{\\prime})>0$ . Then whether $r(s^{\\prime},b^{\\prime})>0$ , which falls into Case (I) and leads to a contradiction, or applying Lemma 12 again implies another optimal policy $f_{b^{\\prime}}^{s^{\\prime}}(f_{b}^{s}(\\tilde{\\pi}))$ , such that $N(s,f_{b^{\\prime}}^{s^{\\prime}}(f_{b}^{s}(\\tilde{\\pi}))(x))\\,=\\,N(s,f_{b}^{s}(\\tilde{\\pi})(x))\\,>\\,0$ for $x\\notin\\{s,s^{\\prime}\\}$ , $N(s,f_{b^{\\prime}}^{s^{\\prime}}(f_{b}^{s}(\\tilde{\\pi}))(s))\\,=$ $N(s,f_{b}^{s}(\\tilde{\\pi})(s))>0$ and $N(s^{\\prime},f_{b^{\\prime}}^{s^{\\prime}}(f_{b}^{s}(\\tilde{\\pi}))(s^{\\prime}))>0$ . ", "page_idx": 36}, {"type": "text", "text": "Repeating this procedure recursively further implies there exists an optimal policy $\\pi$ , such that $N({\\bar{s}},\\pi({\\bar{s}}))>0$ for any $s\\notin\\mathcal{S}^{0}$ , which is a contraction to our assumption. ", "page_idx": 36}, {"type": "text", "text": "Therefore it completes the proof. ", "page_idx": 36}, {"type": "text", "text": "Lemma 12. For a robust optimal policy $\\tilde{\\pi}$ , if there exists a state $s\\notin\\mathcal{S}^{0}$ and an action $b$ such that $N(s,{\\tilde{\\pi}}(s))=0$ , $r(s,b)=0$ and $N(s,b)>0,$ , define a modified policy $f_{b}^{s}(\\tilde{\\pi})$ as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{f_{b}^{s}(\\tilde{\\pi})(s)=b,}}\\\\ {{f_{b}^{s}(\\tilde{\\pi})(x)=\\tilde{\\pi}(x),\\,f o r\\,x\\neq s.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then the modified policy $f_{b}^{s}(\\tilde{\\pi})$ is also optimal, and satisfies $N(s,f_{b}^{s}(\\tilde{\\pi})(s))>0,$ , $N(x,f_{b}^{s}(\\tilde{\\pi})(x))=$ $N(x,\\tilde{\\pi}(x)),\\forall x\\neq s$ . ", "page_idx": 36}, {"type": "text", "text": "Proof. Recall that $\\tilde{\\Phi}_{s}^{\\tilde{\\pi}(s)}=\\varDelta(\\mathcal{S})$ and $\\tilde{\\mathcal{P}}_{s}^{b}\\subseteq\\varDelta(\\mathcal{S})$ , we have that ", "page_idx": 36}, {"type": "equation", "text": "$$\nV_{\\tilde{\\Phi}}^{f_{b}^{s}(\\tilde{\\pi})}\\geq V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\tilde{\\mathcal{P}}_{s}^{b}$ is a modified uncertainty set defined as ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\tilde{\\Phi_{s}^{b}})_{s}^{b}=\\varDelta(\\mathcal{S}),}\\\\ &{(\\tilde{\\Phi_{s}^{b}})_{x}^{a}=\\tilde{\\Phi_{x}^{a}},\\mathrm{~for~}(x,a)\\neq(s,b).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Now we have that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}(s)=Q_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}(s,b)=r(s,b)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}_{s}^{b})_{s}^{b}}(V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})})\\leq\\gamma V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "which further implies $V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}(s)=0$ . Note that in eq. (152), we have shown $V_{\\tilde{\\Phi}}^{\\tilde{\\pi}}(s)\\,=\\,0$ , hence $V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}(s)=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=0.$ ", "page_idx": 37}, {"type": "text", "text": "Now consider the two robust Bellman operator $\\begin{array}{r}{\\mathbf{T}_{b}^{s}V(x)=\\sum_{a}f_{b}^{s}(\\tilde{\\pi})(a|x)(\\hat{r}(x,a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}_{s}^{b})_{x}^{a}}(V))}\\end{array}$ and $\\mathbf{T}V(x)=\\hat{r}(x,\\tilde{\\pi}(x))+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{x}^{\\tilde{\\pi}(x)}}(V)$ . It is known that $V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}$ is the unique fixed point of the robust Bellman operator $\\mathbf{T}_{b}^{s}$ and $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is the unique fixed point of $\\mathbf{T}$ . ", "page_idx": 37}, {"type": "text", "text": "When $x\\neq s$ , ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{T}_{b}^{s}V_{\\bar{p}}^{\\tilde{\\pi}}(x)=\\displaystyle\\sum_{a}f_{b}^{s}(\\tilde{\\pi})(a|x)(\\hat{r}(x,a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}_{s}^{\\tilde{b}})_{x}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}))}\\\\ &{\\phantom{m m m m m m m}\\overset{(a)}{=}\\displaystyle\\sum_{a}\\tilde{\\pi}(a|x)(\\hat{r}(x,a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}_{s}^{\\tilde{b}})_{x}^{a}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}))}\\\\ &{\\phantom{m m m m m m m}=\\hat{r}(x,\\tilde{\\pi}(x))+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}_{s}^{\\tilde{b}})_{x}^{\\tilde{\\pi}}}(v)(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\overset{(b)}{=}\\hat{r}(x,\\tilde{\\pi}(x))+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{\\bar{x}}^{\\tilde{\\pi}}}(v)(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\phantom{m m m m m m}=\\mathbf{T}V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(x)=V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(x),}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where (a) is from f bs (\u03c0\u02dc)(x) = \u03c0\u02dc(x) when x \u0338= s, (b) is from ( P\u02dcbs)x\u03c0\u02dc(x)= \u02dcPx\u03c0\u02dc(x). And for $s$ , it holds that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{T}_{b}^{s}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=\\hat{r}(s,b)+\\gamma\\sigma_{(\\hat{\\mathcal{P}}_{s}^{b})_{s}^{b}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\stackrel{(a)}{=}\\hat{r}(s,\\tilde{\\pi}(s))+\\gamma\\sigma_{\\varDelta(\\mathbb{S})}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\quad\\quad\\quad\\quad\\stackrel{(b)}{=}\\hat{r}(s,\\tilde{\\pi}(s))+\\gamma\\sigma_{\\hat{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})}\\\\ &{\\quad\\quad\\quad=\\mathbf{T}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)}\\\\ &{\\quad\\quad\\quad=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $(a)$ is from $(\\tilde{\\mathcal{P}}_{s}^{b})_{s}^{b}=\\varDelta(\\mathcal{S})$ and $\\hat{r}(s,b)=r(s,b)=0=\\hat{r}\\big(s,\\tilde{\\pi}(s)\\big)$ , and $(b)$ follows from the fact $\\tilde{\\mathcal{P}}_{s}^{\\tilde{\\pi}(s)}=\\varDelta(\\mathcal{S})$ . ", "page_idx": 37}, {"type": "text", "text": "to eq. (160) and eq. (161) further imply that $V_{\\tilde{\\mathcal{P}}_{s}}^{f_{b}^{s}(\\tilde{\\pi})}$ , i.e., $V_{\\tilde{\\mathcal{P}}_{s}}^{f_{b}^{s}(\\tilde{\\pi})}=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ . $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is also a fixed point of $\\mathbf{T}_{b}^{s}$ . Hence it must be identical ", "page_idx": 37}, {"type": "text", "text": "Combine with eq. (156), we have ", "page_idx": 37}, {"type": "equation", "text": "$$\nV_{\\tilde{\\mathcal{P}}}^{f_{b}^{s}(\\tilde{\\pi})}\\geq V_{\\tilde{\\mathcal{P}}_{s}^{b}}^{f_{b}^{s}(\\tilde{\\pi})}=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}},\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "which implies that $f_{b}^{s}(\\tilde{\\pi})$ is also optimal with $N(s,f_{b}^{s}(\\tilde{\\pi})(s))=N(s,b)>0$ . And since $f_{b}^{s}(\\tilde{\\pi})(x)=$ $\\tilde{\\pi}(\\boldsymbol{x})$ for $x\\neq s$ , then $\\tilde{N}(x,f_{b}^{s}(\\tilde{\\pi})\\bar{(x)})=N(x,\\dot{\\tilde{\\pi}}(x)\\breve{)}$ . This thus completes the proof. \u53e3 ", "page_idx": 37}, {"type": "text", "text": "Lemma 13 (Lemma 4, [19]). For any $\\delta$ , with probability $1-\\delta$ $\\begin{array}{r l r}{\\mathrm{~}}&{{}}&{,\\mathrm{~max}\\{12N(s,a),8\\log\\frac{N S}{\\delta}\\}\\mathrm{~}\\geq}\\end{array}$ $N\\mu(s,a),\\forall s,a$ . ", "page_idx": 37}, {"type": "text", "text": "Lemma 14 (Lemma 9, [19]). For any $(s,a)$ pair with $N(s,a)>0$ , if $V$ is an vector independent of $\\hat{\\mathsf{P}_{s}^{a}}$ obeying $\\begin{array}{r}{\\|V\\|\\le\\frac{1}{1-\\gamma}}\\end{array}$ , then with probability at least $1-\\delta$ , ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|(\\hat{\\mathsf{P}}_{s}^{a}-\\mathsf{P}_{s}^{a})V|\\leq\\sqrt{\\frac{48V a r_{\\hat{\\mathsf{P}}_{s}^{a}}(V)\\log\\frac{4N}{\\delta}}{N(s,a)}}+\\frac{48\\log\\frac{4N}{\\delta}}{(1-\\gamma)N(s,a)},}\\\\ &{\\qquad\\pmb{V}a r_{\\hat{\\mathsf{P}}_{s}^{a}}(V)\\leq2V\\pmb{a}r_{\\mathsf{P}_{s}^{a}}(V)+\\frac{5\\log\\frac{4N}{\\delta}}{3(1-\\gamma)^{2}N(s,a)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Lemma 15. For the total variation uncertain set and for any fixed $s,a$ and $\\delta$ , with probability at least $1-\\delta_{i}$ , it holds that ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{T}_{s}^{a}(V_{\\bar{\\mathcal P}}^{\\bar{\\pi}})-\\hat{\\sigma}_{s}^{a}(V_{\\bar{\\mathcal P}}^{\\bar{\\pi}})|}\\\\ &{\\leq\\frac{1}{N(s,a)(1-\\gamma)}\\left(2+c_{2}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)+\\sqrt{2c_{1}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)}\\right)+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})V a r_{\\mathcal P}(V_{\\mathcal P}^{a}(V_{\\mathcal P}^{a}(\\mathcal P)))}{N(s,a)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "and ", "page_idx": 38}, {"type": "equation", "text": "$$\nW\\pmb{a}r_{\\hat{\\mathsf{P}}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\leq2W\\pmb{a}r_{\\mathsf{P}_{s}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})+\\frac{41\\log\\frac{2N}{(1-\\gamma)\\delta}}{(1-\\gamma)^{2}N(s,a)}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Proof. Step 1: Construct an auxiliary robust MDP. For the state $s\\in\\mathcal{S}$ and any constant $u\\in[0,1]$ , we construct the following MDP $M^{s,\\v{u}}=(\\S,\\mathcal{A},r^{s,{u}},{\\sf P}^{s,{u}})$ with transition kernel $\\mathsf{P}^{s,u}$ and reward $r^{s,u}$ : ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathsf{P}^{s,u})_{x}^{a}=\\mathbf{1}_{s},\\;\\mathrm{if}\\;x=s;}\\\\ &{(\\mathsf{P}^{s,u})_{x}^{a}=\\hat{\\mathsf{P}}_{x}^{a},\\;\\mathrm{if}\\;x\\neq s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "and ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{r^{s,u}(x,a)=u,\\,\\mathrm{if}\\,\\,x=s;}\\\\ {r^{s,u}(x,a)=r(x,a),\\,\\mathrm{if}\\,\\,x\\neq s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Centered at $M^{s,u}$ , we further construct the following robust MDP $\\tilde{M}^{s,u}=(\\mathcal{S},\\mathcal{A},\\tilde{\\mathcal{P}}^{s,u},r^{s,u})$ : ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}=\\{(\\mathsf{P}^{s,u})_{x}^{a}\\},\\,\\mathrm{if}\\,\\,x=s;}\\\\ &{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}=\\tilde{\\mathcal{P}}_{x}^{a},\\,\\mathrm{if}\\,\\,x\\neq s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "The robust Bellman operator associated with this robust MDP is hence ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{T}}^{s,u}\\boldsymbol{V}(\\boldsymbol{x})=\\operatorname*{max}_{a}\\{r^{s,u}(\\boldsymbol{x},a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}}(\\boldsymbol{V})\\},\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "and we denote the robust value function w.r.t. it by $V^{s,u}$ . ", "page_idx": 38}, {"type": "text", "text": "Step 2: Prove $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is a robust value function w.r.t. $\\tilde{M}^{s,u^{*}}$ for some $u^{*}\\in[0,1]$ . We claim that if we set $u^{*}=(1-\\gamma)V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\\in[0,1]$ , then the robust value function w.r.t. $\\tilde{M}^{s,u^{*}}$ is equal to $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ . ", "page_idx": 38}, {"type": "text", "text": "To prove the claim, recall that $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is the unique fixed point of the optimal robust Bellman operator ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{T}}V(x)=\\operatorname*{max}_{a}\\{r(x,a)+\\gamma\\sigma_{(\\tilde{\\mathbf{\\mathcal{P}}})_{x}^{a}}(V)\\}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "For the state $s$ , note that ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathbf{T}}^{s,u}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)=\\underset{a}{\\operatorname*{max}}\\{r^{s,u^{*}}(s,a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\}}\\\\ &{\\quad\\quad\\quad\\quad=\\underset{a}{\\operatorname*{max}}\\{u^{*}+\\gamma(\\mathsf{P}^{s,u})_{s}^{a}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\}}\\\\ &{\\quad\\quad\\quad\\quad=\\underset{a}{\\operatorname*{max}}\\{(1-\\gamma)V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)+\\gamma V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s),\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "which is due to the construction of $\\tilde{M}^{s,u^{*}}$ ; And for states $x\\neq s$ , we have that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathbf{T}}^{s,u}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(x)=\\underset{a}{\\mathrm{max}}\\{r^{s,u^{*}}(x,a)+\\gamma\\sigma_{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\}}\\\\ &{\\qquad\\qquad\\quad=\\underset{a}{\\mathrm{max}}\\{r(x,a)+\\gamma\\sigma_{\\tilde{\\mathcal{P}}_{x}^{a}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})\\}}\\\\ &{\\qquad\\quad=\\tilde{\\mathbf{T}}(V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}})(x)}\\\\ &{\\qquad\\quad=V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(x),}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "which is from the construction of $\\tilde{M}^{s,u^{*}}$ and the fact that $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is the fixed point of $\\tilde{\\bf T}$ . ", "page_idx": 39}, {"type": "text", "text": "These two equations hence imply that $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is a fixed point of the robust Bellman operator $\\mathbf{T}^{s,u^{*}}$ , which further proves the claim. ", "page_idx": 39}, {"type": "text", "text": "Step 3: Decouple the dependence of $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}\\,\\mathbf{on}\\,\\hat{\\mathsf{P}}$ by constructing an $\\textstyle{\\frac{1}{N}}$ -net. ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Define $\\begin{array}{r}{\\mathfrak{U}\\,=\\,\\{\\frac{i}{N}\\,:\\,i\\,=\\,0,1,...,N\\}}\\end{array}$ . Clearly, $\\mathcal{U}$ is a $\\textstyle{\\frac{1}{N}}$ -net [43] of the interval $[0,1]$ , i.e., for any $u\\in[0,1]$ , there exists $u_{i}\\in\\mathcal{U}$ , such that $\\begin{array}{r}{|u-u_{i}|\\le\\frac{1}{N}}\\end{array}$ . ", "page_idx": 39}, {"type": "text", "text": "Clearly, each $u\\in\\mathcal{U}$ is a constant independent with $\\hat{\\mathsf{P}}_{s}^{a}$ , hence applying Lemma 14 implies that for any $u\\in\\mathcal{U}$ , ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\vert\\mathsf{P}_{s}^{a}V^{s,u}-\\hat{\\mathsf{P}}_{s}^{a}V^{s,u}\\vert\\leq\\sqrt{\\frac{c_{1}\\log(\\frac{4N}{\\delta})\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V^{s,u})}{N(s,a)}}+\\frac{c_{2}\\log(\\frac{4N}{\\delta})}{(1-\\gamma)N(s,a)}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Take the union bound over any $(s,a,u)\\in\\mathcal{S}\\times\\mathcal{A}\\times\\mathcal{U}$ , and we have the following inequality holds with probability at least $1-\\delta$ : ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\big|\\mathsf{P}_{s}^{a}V^{s,u}-\\hat{\\mathsf{P}}_{s}^{a}V^{s,u}\\big|\\leq\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathbf{V}\\mathbf{ar}_{\\mathsf{P}_{s}^{a}}(V^{s,u})}{N(s,a)}}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Step 4: Approximate $|\\mathsf{P}_{s}^{a}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}-\\hat{\\mathsf{P}}_{s}^{a}V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}|$ using the $\\textstyle{\\frac{1}{N}}$ -net. ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "As we showed above, there exists $u\\in\\mathcal{U}$ such that $\\begin{array}{r}{|u-u^{*}|\\le\\frac{1}{N}}\\end{array}$ . Moreover, note that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|V^{s,u}-V^{s,u^{*}}\\|=\\|\\tilde{\\mathbf{T}}^{s,u}V^{s,u}-\\tilde{\\mathbf{T}}^{s,u^{*}}V^{s,u^{*}}\\|}\\\\ &{\\qquad\\qquad\\leq\\|\\tilde{\\mathbf{T}}^{s,u}V^{s,u}-\\tilde{\\mathbf{T}}^{s,u}V^{s,u^{*}}\\|+\\|\\tilde{\\mathbf{T}}^{s,u}V^{s,u^{*}}-\\tilde{\\mathbf{T}}^{s,u^{*}}V^{s,u^{*}}\\|}\\\\ &{\\qquad\\qquad\\leq\\gamma\\|V^{s,u}-V^{s,u^{*}}\\|+\\|r^{s,u}-r^{s,u^{*}}\\|+\\gamma\\|\\sigma_{(\\tilde{\\mathcal{P}}^{s,u})}(V^{s,u^{*}})-\\sigma_{(\\tilde{\\mathcal{P}}^{s,u^{*}})}(V^{s,u^{*}})\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\gamma\\|V^{s,u}-V^{s,u^{*}}\\|+\\frac{1}{N},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the last inequality is from $\\sigma_{(\\tilde{\\mathcal{P}}^{s,u})_{x}^{a}}(V^{s,u^{*}})=\\sigma_{(\\tilde{\\mathcal{P}}^{s,u^{*}})_{s}^{a}}(V^{s,u^{*}})$ for any $x,a$ . Hence we have that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\lVert V^{s,u}-V^{s,u^{*}}\\rVert\\leq\\frac{1}{(1-\\gamma)N}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "We further have that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{P}_{s}^{a}V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}-\\hat{\\mathsf{P}}_{s}^{a}V_{\\bar{\\mathcal{P}}}^{\\bar{\\pi}}|}\\\\ &{\\le\\vert\\mathsf{P}_{s}^{a}V^{s,u}-\\hat{\\mathsf{P}}_{s}^{a}V^{s,u}\\vert+\\vert(\\mathsf{P}_{s}^{a}-\\hat{\\mathsf{P}}_{s}^{a})(V^{s,u}-V^{s,u^{*}})\\vert}\\\\ &{\\le\\frac{2}{(1-\\gamma)N}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathrm{Var}_{\\bar{s}}(V^{s,u})}{N(s,a)}}}\\\\ &{=\\frac{2}{(1-\\gamma)N}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})(\\mathrm{Var}_{\\bar{s}}(V^{s,u^{*}})+(\\mathrm{Var}_{\\mathrm{P}_{s}}(V^{s,u})-\\mathrm{Var}_{\\mathrm{P}_{s}}(V^{s,u^{*}}))}{N(s,a)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\frac{2}{(1-\\gamma)N}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathbf{Varp}_{s}(V^{s,u^{*}})}{N(s,a)}}}\\\\ &{\\quad+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})[\\mathbf{Varp}_{s}(V^{s,u})-\\mathbf{Varp}_{s}(V^{s,u^{*}})]}{N(s,a)}}}\\\\ &{\\leq\\frac{2}{(1-\\gamma)N}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathbf{Varp}_{s}(V^{s,u^{*}})}{N(s,a)}}}\\\\ &{\\quad+\\sqrt{\\frac{2c_{1}\\log(\\frac{4S A N^{2}}{\\delta})}{N(s,a)(1-\\gamma)^{2}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the last inequality is from ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\mathbf{Var}_{q}(V_{1})-\\mathbf{Var}_{q}(V_{2})\\right\\rvert}\\\\ &{\\displaystyle=\\left\\lvert q(V_{1}\\circ V_{1})-(q V_{1})\\circ(q V_{1})-q(V_{2}\\circ V_{2})+(q V_{2})\\circ(q V_{2})\\right\\rvert}\\\\ &{\\displaystyle\\leq\\left\\lvert q(V_{1}\\circ V_{1}-V_{2}\\circ V_{2})\\right\\rvert+\\left\\lvert(q V_{1}+q V_{2})q(V_{1}-V_{2})\\right\\rvert}\\\\ &{\\displaystyle\\leq2\\lVert V_{1}+V_{2}\\rVert\\lVert V_{1}-V_{2}\\rVert}\\\\ &{\\displaystyle\\leq\\frac{2\\lVert V_{1}-V_{2}\\rVert}{1-\\gamma}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Thus (182) can be further bounded as ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{P}_{s}^{\\alpha}\\mathsf{P}_{\\hat{\\mathcal{V}}}^{\\beta}-\\hat{\\mathsf{P}}_{s}^{\\alpha}V_{\\hat{\\mathcal{V}}}^{\\beta}\\,}\\\\ &{\\le\\frac{2}{(1-\\gamma)N}+\\frac{c_{2}\\log(\\frac{4S A N^{2}}{\\delta})}{(1-\\gamma)N(s,a)}+\\sqrt{\\frac{c_{1}\\log(\\frac{4S A N^{2}}{\\delta})\\mathsf{V a r p}_{s}(V^{\\beta,s^{\\prime}})}{N(s,a)}}}\\\\ &{\\quad+\\sqrt{\\frac{2c_{1}\\log(\\frac{4S A N^{2}}{\\delta})}{N(s,a)(1-\\gamma)^{2}}}}\\\\ &{\\le\\frac{1}{N(s,a)(1-\\gamma)}\\left(2+c_{2}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)+\\sqrt{2c_{1}\\log(\\frac{4S A N^{2}}{\\delta})}\\right)}\\\\ &{\\quad+\\sqrt{\\frac{c_{1}\\log\\left(\\frac{4S A N^{2}}{\\delta}\\right)\\mathsf{V a r p}_{s}(V^{\\beta,s^{\\prime}})}{N(s,a)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "We note that this inequality exactly matches (127) in [38], hence the following part directly follows, which is omitted here. \u53e3 ", "page_idx": 40}, {"type": "text", "text": "Lemma 16. (Lemma $^{l4}$ of [36]) For any $(s,a)$ satisfying $N(s,a)>0,$ , and any vector $V\\in\\mathbb{R}^{|\\mathcal{S}|}$ independent of $\\hat{\\mathsf{P}}_{s}^{a}$ obeying $\\begin{array}{r}{\\|V\\|\\le\\frac{1}{1-\\gamma}}\\end{array}$ , with probability at least $1-\\delta$ , it holds that ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\vert\\sigma\\scriptscriptstyle\\mathrm{{P}}_{s}^{a}(V)-\\sigma_{\\hat{\\Phi}_{s}^{a}}(V)\\vert\\leq\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{N S}{\\delta}}{N(s,a)\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{a}}}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Lemma 17. For the KL-divergence uncertainty set, and for any $(s,a)$ satisfying $N(s,a)>0$ , with probability at least $1-\\delta$ , it holds that ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\lvert\\sigma_{\\mathcal{P}_{s}^{2}}(V_{\\widetilde{\\mathcal{P}}}^{\\widetilde{\\pi}})-\\sigma_{\\hat{\\mathcal{P}}_{s}^{2}}(V_{\\widetilde{\\mathcal{P}}}^{\\widetilde{\\pi}})\\rvert\\le\\operatorname*{min}\\left\\{\\frac{1}{1-\\gamma},\\frac{4}{N R(1-\\gamma)}+\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{2(1+R)N^{3}S}{(1-\\gamma)\\delta}}{N(s,a)\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{a}}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Proof. Step 1. We first construct a robust MDP with state-absorbing empirical nominal transition kernels. More specifically, for each state $s$ and a constant $u\\,\\geq\\,0$ , define the following transition kernels for any $a\\in{\\mathcal{A}},x\\in{\\mathcal{S}}$ : ", "page_idx": 40}, {"type": "equation", "text": "$$\n(\\mathsf{P}^{s,u})_{s,x}^{a}=\\mathbf{1}_{s=x},\n$$", "text_format": "latex", "page_idx": 40}, {"type": "equation", "text": "$$\n(\\mathsf{P}^{s,u})_{s,x}^{a}=\\hat{\\mathsf{P}}_{s,x}^{a},\\,\\mathsf{i f}\\,x\\neq s.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Moreover, define the modified reward function: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{r^{s,u}(s,a)=u,}\\\\ {r^{s,u}(x,a)=r(x,a),\\;\\mathrm{if}\\;x\\neq s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "We then define the following uncertainty set $(\\mathcal{P}^{s,u})_{x}^{a}$ for any $a\\in{\\mathcal{A}},x\\in{\\mathcal{S}}$ as follows: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathbb{P}^{s,u})_{s}^{a}=\\{\\mathbf{1}_{s}\\},}\\\\ &{(\\mathbb{P}^{s,u})_{x}^{a}=\\{q\\in\\varDelta(\\mathbb{S}):D(q||(\\mathbb{P}^{s,u})_{x}^{a})\\leq R+\\kappa_{x}^{a}\\},\\;\\mathrm{if}\\;x\\neq s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "The auxiliary robust MDP is then defined as $M^{s,u}=(\\Phi^{s,u}=\\bigotimes_{s,a}(\\Phi^{s,u})_{s}^{a},r^{s,u}).$ ", "page_idx": 41}, {"type": "text", "text": "Step 2. We next show that if we set $u^{*}=(1-\\gamma)V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}(s)$ , then the optimal robust value function of $M^{s,u^{*}}$ is identical to $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ . ", "page_idx": 41}, {"type": "text", "text": "For any state $x\\neq s$ and action $b$ , it can be verified from the definitions that $(\\mathcal{P}^{s,u})_{x}^{b}=\\tilde{\\mathcal{P}}_{x}^{b}$ , and hence ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{b}\\{r^{s,u^{*}}(x,b)+\\gamma\\sigma_{(\\mathcal{P}^{s,u^{*}})_{x}^{b}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})\\}=\\operatorname*{max}_{b}\\{r(x,b)+\\gamma\\sigma_{\\hat{\\mathcal{P}}_{x}^{b}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})\\}=V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(x).\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "For state $s$ , we have that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{b}\\{r^{s,u^{*}}(s,b)+\\gamma\\sigma_{(\\mathcal{P}^{s,u^{*}})_{s}^{b}}(V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}})\\}=\\operatorname*{max}_{b}\\{u^{*}+\\gamma V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(s)\\}=V_{\\bar{\\mathcal{P}}}^{\\tilde{\\pi}}(s).\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Thus we verified that $V_{\\tilde{\\mathcal{P}}}^{\\tilde{\\pi}}$ is the fixed point of the robust Bellman operator of $M^{s,u}$ , and hence identical to the optimal robust value function of $M^{s,u}$ . ", "page_idx": 41}, {"type": "text", "text": "iSt tiesp c l3e. arD tehfaint $u^{*}\\leq1$ , $\\begin{array}{r}{\\mathcal{U}\\triangleq\\{\\frac{i}{N}:1\\leq i\\leq N\\}}\\end{array}$ $u_{0}\\in\\mathcal{U}$ c. hT thhea ts $\\begin{array}{r}{|u_{0}-u^{*}|\\leq\\frac{1}{N}}\\end{array}$ $\\mathcal{U}$ $\\textstyle{\\frac{1}{N}}$ -net of the interval $[0,1]$ . Since ", "page_idx": 41}, {"type": "text", "text": "On the other hand, for any $u\\in\\mathcal{U}$ , since $u\\leq1$ , the optimal robust value function $\\begin{array}{r}{\\|V^{s,u}\\|\\leq\\frac{1}{1-\\gamma}}\\end{array}$ ; Moreover, from the construction, the uncertainty set $\\Phi^{s,u}$ is independent of $\\hat{\\mathsf{P}}_{s}^{a}$ , hence invoking Lemma 16 implies ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\vert\\sigma\\scriptscriptstyle{\\mathcal{P}}_{s}^{a}\\big(V^{s,u}\\big)-\\sigma_{\\hat{\\mathcal{P}}_{s}^{a}}(V^{s,u})\\vert\\leq\\frac{C_{1}}{R(1-\\gamma)}\\sqrt{\\frac{\\log\\frac{N S}{\\delta}}{N(s,a)\\operatorname*{min}_{x}\\hat{\\mathsf{P}}_{s,x}^{a}}},\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "with probability at least $1-\\delta$ . ", "page_idx": 41}, {"type": "text", "text": "Step 4. We further show the following claim: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\|V^{s,u_{0}}-V^{s,u^{*}}\\|\\leq\\frac{1}{N(1-\\gamma)}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "To show (196), for $s$ , we have that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|V^{s,u_{0}}(s)-V^{s,u^{*}}(s)|\\overset{(a)}{\\leq}\\underset{b}{\\operatorname*{max}}\\,|(u_{0}-u^{*})+\\gamma\\big(\\sigma_{(\\mathcal{P}^{s,u_{0}})_{s}}\\big(V^{s,u_{0}}\\big)-\\sigma_{(\\mathcal{P}^{s,u^{*}})_{s}}\\big(V^{s,u^{*}}\\big)\\big)|}\\\\ &{\\overset{(b)}{\\leq}\\frac{1}{N}+\\gamma|V^{s,u_{0}}(s)-V^{s,u^{*}}(s)|}\\\\ &{\\leq\\cfrac{1}{N}+\\gamma\\|V^{s,u_{0}}(s)-V^{s,u^{*}}(s)\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where $(a)$ is from $|\\operatorname*{max}f-\\operatorname*{max}g|\\leq\\operatorname*{max}|f-g|$ , and $(b)$ is from the fact that $(\\Phi^{s,u})_{s}^{b}=\\{\\mathbf{1}_{s}\\}$ for any $u$ and $b$ . ", "page_idx": 41}, {"type": "text", "text": "And for state $x\\neq s$ , we have that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{V^{s,u_{0}}(x)-V^{s,u^{*}}(x)|\\displaystyle{\\leq\\operatorname*{max}_{b}|r^{s,u_{0}}(x,b)-r^{s,u^{*}}(x,b)+\\gamma\\big(\\sigma_{(\\mathcal{P}^{s,u_{0}})_{x}^{b}}(V^{s,u_{0}})-\\sigma_{(\\mathcal{P}^{s,u^{*}})_{x}^{b}}(V^{s,u^{*}})\\big)}|}}\\\\ {{(\\ a)}}\\\\ {{\\leq\\gamma\\|V^{s,u_{0}}-V^{s,u^{*}}\\|,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where $(a)$ is from $(\\mathcal{P}^{s,u})_{x}^{b}=\\tilde{\\mathcal{P}}_{x}^{b}$ and $r^{s,u_{0}}(x,b)=r^{s,u^{*}}(x,b)$ for any $b\\in{\\mathcal{A}}$ and $x\\neq s$ . ", "page_idx": 41}, {"type": "text", "text": "Hence together we proved (196), which is identical to (240) of [36]. The remaining proof hence follows exactly the same as [36]. ", "page_idx": 41}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: All the claims are directly from the main theorems of the paper. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 42}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Justification: We discuss the limitations and future works in Section 6. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 42}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: Proofs of all the theorems are provided in the appendix. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 43}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: Information that are needed to reproduce the main experimental results of the paper is disclosed in Experiment section. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 43}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 43}, {"type": "text", "text": "Answer: [No] ", "page_idx": 44}, {"type": "text", "text": "Justification: The code will be released if the paper is accepted. The experiments are straightforward and easy to reproduce. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 44}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We clearly specify all the details for the experiments. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 44}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We plot a error bar/envelop to indicate the statistical significance. For 10 independence experiments, we plot the mean and the standard deviation of them as the error bar. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: No computing resources are required. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 45}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We have reciewed the Code of Ethics. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 45}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: There is no potential societal impact that needs to be specified. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 46}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: We do not use any existing assets. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 46}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 47}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: We do not release new assets. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 47}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 47}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 47}]