[{"figure_path": "HcqV2bPFKz/figures/figures_1_1.jpg", "caption": "Figure 1: Qualitative domain generalization results of PSMNet [3] baseline and HODC-PSMNet (Ours). The latter is trained with our proposed hierarchical object-aware contrastive loss. Both models are trained only on the synthetic SceneFlow [27] dataset and evaluated directly on realistic datasets KITTI-2015 [28] and Middlebury [32].", "description": "This figure showcases a qualitative comparison of the PSMNet baseline and the proposed HODC-PSMNet model's performance on domain generalization.  The models are trained solely on the synthetic SceneFlow dataset, then directly tested on the realistic KITTI-2015 and Middlebury datasets.  The comparison highlights the improved ability of HODC-PSMNet to generalize to unseen real-world data due to the incorporation of the hierarchical object-aware contrastive loss during training.", "section": "1 Introduction"}, {"figure_path": "HcqV2bPFKz/figures/figures_3_1.jpg", "caption": "Figure 2: Overall illustration of the proposed hierarchical object-aware dual-level contrastive learning (HODC) framework. An example of hierarchical segmentation of a car within the input image is demonstrated, alongside with the illustration of inter- and intra-scale positive and negative pairs for dual-level contrastive learning.", "description": "This figure illustrates the HODC framework.  It shows how the left and right feature maps are processed through object segmentation at multiple scales to create hierarchical representations.  These representations are then used to form positive and negative pairs (both intra- and inter-scale) for contrastive learning. The contrastive loss aims to improve correspondence between these hierarchical representations, leading to semantically and structurally driven stereo matching. The example shows the segmentation of a car at different scales.", "section": "3 Method"}, {"figure_path": "HcqV2bPFKz/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of generating regional representations for HODC with the feature map f and object index map I under scale (4,4) and (8,8). Different color on the image denotes pixels with different indexes, and regional representations are generated by aggregating the features of pixels with the same region index.", "description": "This figure illustrates the process of generating hierarchical object-aware regional representations in the HODC framework. It shows how the object index map is segmented into regions at different scales (4x4 and 8x8 grids), and how regional representations are computed by averaging the features within each region. This process uses the object index map to guide the creation of meaningful regional representations for use in dual-level contrastive learning, thus capturing both local and global context in the feature maps.", "section": "3.3 Hierarchical Object-Aware Regional Representations"}, {"figure_path": "HcqV2bPFKz/figures/figures_8_1.jpg", "caption": "Figure 1: Qualitative domain generalization results of PSMNet [3] baseline and HODC-PSMNet (Ours). The latter is trained with our proposed hierarchical object-aware contrastive loss. Both models are trained only on the synthetic SceneFlow [27] dataset and evaluated directly on realistic datasets KITTI-2015 [28] and Middlebury [32].", "description": "This figure displays a qualitative comparison of the PSMNet baseline and the proposed HODC-PSMNet model for domain generalization in stereo matching.  The HODC-PSMNet model leverages a hierarchical object-aware contrastive loss during training.  Importantly, both models are trained exclusively on the synthetic SceneFlow dataset, yet their disparity prediction performance is evaluated on the challenging real-world KITTI-2015 and Middlebury datasets. This demonstrates the HODC model's improved ability to generalize to unseen domains.", "section": "1 Introduction"}, {"figure_path": "HcqV2bPFKz/figures/figures_16_1.jpg", "caption": "Figure A: Qualitative comparisons on the DrivingStereo [45] dataset under 4 different weather conditions. The first column shows the left image and the corresponding ground-truth disparity map. The rest columns show the error map and the predicted disparity map of PSMNet [3], HODC-PSMNet, GwcNet [13] and HODC-GwcNet, respectively.", "description": "This figure compares the qualitative results of PSMNet, HODC-PSMNet, GwcNet, and HODC-GwcNet on the DrivingStereo dataset under four different weather conditions (Sunny, Cloudy, Rainy, Foggy).  Each row represents a different weather condition. The first column shows the left input image and the corresponding ground truth disparity map. The subsequent columns display the disparity error maps and predicted disparity maps generated by each method, allowing for a visual comparison of their performance under various weather conditions.", "section": "G More Qualitative Results"}, {"figure_path": "HcqV2bPFKz/figures/figures_17_1.jpg", "caption": "Figure A: Qualitative comparisons on the DrivingStereo [45] dataset under 4 different weather conditions. The first column shows the left image and the corresponding ground-truth disparity map. The rest columns show the error map and the predicted disparity map of PSMNet [3], HODC-PSMNet, GwcNet [13] and HODC-GwcNet, respectively.", "description": "This figure shows a qualitative comparison of the performance of four different stereo matching networks (PSMNet, HODC-PSMNet, GwcNet, and HODC-GwcNet) under various weather conditions (sunny, cloudy, rainy, and foggy).  Each row represents a different scene from the DrivingStereo dataset. The first column displays the left image and its corresponding ground truth disparity map.  The remaining columns visually represent the error maps and predicted disparity maps generated by each of the four stereo matching networks.  The purpose is to demonstrate the improved performance of the HODC method in handling challenging real-world conditions.", "section": "G More Qualitative Results"}, {"figure_path": "HcqV2bPFKz/figures/figures_17_2.jpg", "caption": "Figure 4: Qualitative result of semantically and structurally driven matching on realistic Middlebury [32] and ETH3D [33] datasets. The first column shows the query region, which is marked red and highlighted with green box. The remaining columns show the region on the target image that has cosine similarity larger than the threshold \u03b1 = 0.9 with different methods.", "description": "This figure demonstrates the qualitative results of semantically and structurally driven matching methods on the Middlebury and ETH3D datasets.  It compares the performance of PSMNet, FC-PSMNet, and HODC-PSMNet.  Each row shows a different example, with the leftmost column showing the query region from the left image which is highlighted in red and a green box. The subsequent columns show the corresponding regions in the right image that achieved cosine similarity above a threshold of 0.9. The figure highlights how the proposed HODC method improves the accuracy of matching by incorporating semantic and structural information, resulting in better selection of corresponding regions compared to the baseline methods.", "section": "4.3 Semantically and Structurally Driven Matching"}, {"figure_path": "HcqV2bPFKz/figures/figures_18_1.jpg", "caption": "Figure 4: Qualitative result of semantically and structurally driven matching on realistic Middlebury [32] and ETH3D [33] datasets. The first column shows the query region, which is marked red and highlighted with green box. The remaining columns show the region on the target image that has cosine similarity larger than the threshold \u03b1 = 0.9 with different methods.", "description": "This figure shows a qualitative comparison of semantically and structurally driven matching results on the Middlebury and ETH3D datasets using three different methods: PSMNet, FC-PSMNet, and HODC-PSMNet.  For each scene, a query region (marked in red and green) is selected from the left image. The remaining columns display the corresponding regions on the right image with cosine similarity above a threshold of 0.9.  The figure visually demonstrates the improved ability of HODC-PSMNet to accurately identify semantically and structurally relevant regions compared to the baseline methods.", "section": "4.3 Semantically and Structurally Driven Matching"}, {"figure_path": "HcqV2bPFKz/figures/figures_18_2.jpg", "caption": "Figure A: Qualitative comparisons on the DrivingStereo [45] dataset under 4 different weather conditions. The first column shows the left image and the corresponding ground-truth disparity map. The rest columns show the error map and the predicted disparity map of PSMNet [3], HODC-PSMNet, GwcNet [13] and HODC-GwcNet, respectively.", "description": "This figure shows a qualitative comparison of the performance of four different stereo matching networks (PSMNet, HODC-PSMNet, GwcNet, and HODC-GwcNet) on the DrivingStereo dataset under four different weather conditions (Sunny, Cloudy, Rainy, and Foggy).  For each weather condition, the figure displays the left image, the ground truth disparity map, and the error maps and disparity predictions produced by each of the four networks.  The error maps highlight the differences between the predicted disparity maps and the ground truth.  The goal is to visually demonstrate the improved performance of the networks incorporating the HODC method, especially in challenging weather conditions.", "section": "G More Qualitative Results"}, {"figure_path": "HcqV2bPFKz/figures/figures_19_1.jpg", "caption": "Figure F: Qualitative comparisons on the Middlebury [32] dataset. The first column shows the left image and the corresponding ground-truth disparity map. The rest columns compare the results of the different stereo matching networks w/ and w/o using HODC. In each scene, the first row denotes the baselines and the second row denotes the results with HODC.", "description": "This figure presents qualitative results comparing the performance of several stereo matching networks (PSMNet, GwcNet, IGEV) with and without the proposed HODC method on the Middlebury dataset.  It visually demonstrates the impact of HODC on disparity estimation accuracy, particularly in challenging areas. The first column displays the left image and its corresponding ground truth disparity map. Subsequent columns show disparity error maps, using color-coding to represent the difference between the estimated and ground truth disparities for each network, both with and without HODC.  The top row shows results without HODC and the bottom row with HODC.", "section": "G More Qualitative Results"}, {"figure_path": "HcqV2bPFKz/figures/figures_20_1.jpg", "caption": "Figure G: Qualitative comparisons on the ETH3D [33] dataset. The first column shows the left image and the corresponding ground-truth disparity map. The rest columns compare the results of the different stereo matching networks w/ and w/o using HODC. In each scene, the first row denotes the baselines and the second row denotes the results with HODC.", "description": "This figure compares the disparity maps generated by PSMNet, GwcNet, and IGEV, both with and without the proposed HODC method, on the ETH3D dataset.  The ground truth disparity map is also shown for comparison.  The goal is to visually demonstrate the improvement in accuracy and robustness provided by HODC.", "section": "G More Qualitative Results"}]