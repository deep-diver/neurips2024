[{"figure_path": "xDrKZOZEOc/tables/tables_5_1.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of various algorithms on the Traveling Salesman Problem (TSP) with 50 and 100 cities.  The algorithms are categorized into exact solvers (providing optimal solutions), heuristics (approximations), and learning-based solvers using greedy decoding.  The metrics used are solution length (how long the tour is), the percentage drop in length compared to the optimal solution, and the computation time required. The learning-based methods are further distinguished by whether they use reinforcement learning (RL) or supervised learning (SL).  Asterisks (*) indicate that the results were taken from prior published works.  The table highlights the performance of Fast T2T in comparison to these other methods.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_6_1.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of various algorithms, including the proposed Fast T2T, on two Traveling Salesman Problem (TSP) instances, TSP-50 and TSP-100.  The algorithms are categorized by type (exact, heuristic, reinforcement learning with greedy decoding, or supervised learning with greedy decoding), and their performance is measured by tour length, percentage drop from the optimal solution, and runtime.  The table highlights the superior performance of Fast T2T in terms of both solution quality and efficiency.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_7_1.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of Fast T2T against other state-of-the-art methods for solving the Traveling Salesman Problem (TSP) with 50 and 100 cities.  The metrics used are solution length, the percentage drop in length compared to the optimal solution, and the time taken to find the solution.  The table includes results from exact solvers, heuristics, and various learning-based approaches using greedy decoding.  It highlights the speed and accuracy advantages of Fast T2T, even when using a single step for both solution generation and gradient search.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_8_1.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of various algorithms, including the proposed Fast T2T model, on two instances of the Traveling Salesman Problem (TSP): TSP-50 (50 cities) and TSP-100 (100 cities).  The metrics used are solution length (how long the tour is), the percentage drop in length compared to the optimal solution (indicating the quality of the approximation), and the time taken to find the solution.  Different algorithm types are included (reinforcement learning, supervised learning, and heuristic methods).  The table helps showcase the speed and solution quality advantages of Fast T2T, particularly when compared to previous state-of-the-art diffusion-based methods.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_8_2.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of Fast T2T with several other algorithms (including exact and heuristic methods) on two instances of the Traveling Salesman Problem (TSP), one with 50 cities and one with 100 cities.  The comparison considers solution length, the percentage difference from the optimal solution length (drop), and the time taken to find a solution.  The table highlights Fast T2T's superior performance and efficiency, particularly when using only one step for generating solutions and one step for gradient search.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_13_1.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of Fast T2T with other state-of-the-art methods on two instances of the Traveling Salesman Problem (TSP), one with 50 cities and the other with 100 cities.  The metrics used are solution length, percentage drop in length compared to optimal, and inference time.  Different algorithms are categorized by their type (exact, heuristic, reinforcement learning, and supervised learning) and whether they use greedy decoding or not.  The table highlights Fast T2T's superiority in terms of both solution quality and efficiency.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_13_2.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of Fast T2T against other state-of-the-art methods for solving the Traveling Salesman Problem (TSP) with 50 and 100 cities.  Metrics include solution length, the percentage difference from the optimal solution (drop), and the time taken to find the solution.  The table shows Fast T2T's competitive performance, especially when considering its speed.  Different approaches are categorized as using Reinforcement Learning (RL) or Supervised Learning (SL) and whether they used greedy decoding.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_14_1.jpg", "caption": "Table 5: Solution quality for methods trained on random 100-node problems and evaluated on TSPLIB instances with 50-200 nodes. * denotes results quoted from previous works [56].", "description": "This table compares the performance of various methods (AM, GCN, Learn2OPT, GNNGLS, DIFUSCO, T2T, and Fast T2T with and without gradient search) on TSPLIB instances with 50-200 nodes. The methods were trained on random 100-node problems. The results are presented in terms of solution quality, measured as the percentage drop in tour length relative to the optimal solution.  The table shows that Fast T2T consistently achieves superior performance.", "section": "6.1 Experiments for TSP"}, {"figure_path": "xDrKZOZEOc/tables/tables_14_2.jpg", "caption": "Table 6: Solution quality for methods trained on random 500-node problems and evaluated on TSPLIB instances with 200-1000 nodes.", "description": "This table presents the performance of different methods on larger TSPLIB instances (200-1000 nodes).  The methods were initially trained on randomly generated 500-node TSP problems. The table shows the average optimality gap (Drop) for each method across various test instances. Lower values indicate better performance.", "section": "6.1 Experiments for TSP"}, {"figure_path": "xDrKZOZEOc/tables/tables_15_1.jpg", "caption": "Table 7: Results on MIS SATLIB dataset.", "description": "This table presents the results of different methods on the MIS SATLIB dataset.  The methods include heuristic methods (KAMIS), an exact solver (Gurobi), and several learning-based methods (LwD, DIMES, GlowNets, DIFUSCO, T2T, Fast T2T). The table shows the size, drop (percentage difference from the optimal solution), and time taken by each method to solve the problem.", "section": "6.2 Experiments for MIS"}, {"figure_path": "xDrKZOZEOc/tables/tables_16_1.jpg", "caption": "Table 8: Generalization Performance from p = 0.15 to p = 0.2, p = 0.3, and p = 0.4.", "description": "This table presents the generalization performance of different methods (DIFUSCO, T2T, and Fast T2T) on the MIS problem. It shows the size, drop, and time for different values of p (edge probability), which tests the robustness of each method to changes in the input data distribution.", "section": "6.2 Experiments for MIS"}, {"figure_path": "xDrKZOZEOc/tables/tables_16_2.jpg", "caption": "Table 2: Results on TSP-500 and TSP-1000. AS: Active Search, S: Sampling Decoding, BS: Beam Search. * denotes results that are quoted from previous works [8, 6].", "description": "This table presents the experimental results on two larger Traveling Salesman Problem (TSP) instances: TSP-500 and TSP-1000.  It compares the performance of Fast T2T against various state-of-the-art methods, including exact solvers (Concorde, Gurobi), heuristics (LKH-3, Farthest Insertion), and other learning-based solvers. The results are presented in terms of solution length (how long the tour is), the percentage drop in solution length from the optimal, and the time taken to find the solution.  The table also breaks down the methods by their type (exact, heuristic, reinforcement learning, supervised learning) and decoding strategy (greedy, sampling, beam search) to help readers understand the relative strengths and weaknesses of the approaches. The '*' symbol indicates that some results are taken from previous publications.", "section": "6.1 Experiments for TSP"}, {"figure_path": "xDrKZOZEOc/tables/tables_17_1.jpg", "caption": "Table 2: Results on TSP-500 and TSP-1000. AS: Active Search, S: Sampling Decoding, BS: Beam Search. * denotes results that are quoted from previous works [8, 6].", "description": "This table compares the performance of Fast T2T against various baselines on two larger TSP instances (TSP-500 and TSP-1000).  The results show the solution length, optimality drop (percentage difference from the optimal solution), and the solving time. The baselines include exact solvers, heuristics, and other learning-based methods that utilize techniques such as greedy decoding, sampling decoding, beam search, and active search. The table highlights Fast T2T's superior performance in both solution quality and speed.", "section": "6.1 Experiments for TSP"}, {"figure_path": "xDrKZOZEOc/tables/tables_17_2.jpg", "caption": "Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. * denotes results that are quoted from previous works.", "description": "This table compares the performance of Fast T2T against various state-of-the-art algorithms on two Traveling Salesperson Problems (TSP) of different sizes (50 and 100 cities).  Metrics include solution length, optimality drop (percentage difference from the optimal solution), and solution time.  The table shows that Fast T2T achieves competitive or superior results, often with a significantly faster solving time.", "section": "6 Experiments"}, {"figure_path": "xDrKZOZEOc/tables/tables_18_1.jpg", "caption": "Table 12: Noise Degree for each benchmark.", "description": "This table shows the hyperparameter \\( \\alpha \\) used for each benchmark problem in the experiments. The \\( \\alpha \\) value is the noise degree used in the training process.", "section": "C.5 Hyperparamters"}]