[{"type": "text", "text": "Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yang $\\mathbf{Li}^{1\\dagger}$ , Jinpei $\\mathbf{Guo}^{1\\dagger}$ , Runzhong Wang2, Hongyuan Zha3, Junchi Yan1 \u2217 1Dept. of CSE & School of AI & MOE Key Lab of AI, Shanghai Jiao Tong University ", "page_idx": 0}, {"type": "text", "text": "2Massachusetts Institute of Technology 3The Chinese University of Hong Kong, Shenzhen {yanglily,mike0728,yanjunchi}@sjtu.edu.cn runzhong@mit.edu, zhahy@cuhk.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models have recently advanced Combinatorial Optimization (CO) as a powerful backbone for neural solvers. However, their iterative sampling process requiring denoising across multiple noise levels incurs substantial overhead. We propose to learn direct mappings from different noise levels to the optimal solution for a given instance, facilitating high-quality generation with minimal shots. This is achieved through an optimization consistency training protocol, which, for a given instance, minimizes the difference among samples originating from varying generative trajectories and time steps relative to the optimal solution. The proposed model enables fast single-step solution generation while retaining the option of multi-step sampling to trade for sampling quality, which offers a more effective and efficient alternative backbone for neural solvers. In addition, within the training-to-testing (T2T) framework, to bridge the gap between training on historical instances and solving new instances, we introduce a novel consistency-based gradient search scheme during the test stage, enabling more effective exploration of the solution space learned during training. It is achieved by updating the latent solution probabilities under objective gradient guidance during the alternation of noise injection and denoising steps. We refer to this model as Fast T2T. Extensive experiments on two popular tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), demonstrate the superiority of Fast T2T regarding both solution quality and efficiency, even outperforming LKH given limited time budgets. Notably, Fast T2T with merely one-step generation and one-step gradient search can mostly outperform the SOTA diffusion-based counterparts that require hundreds of steps, while achieving tens of times speedup. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Combinatorial Optimization (CO) problems, which involve optimizing discrete variables under given objectives, are essential in computer science and operational research. Due to the inherent computational difficulty, e.g. NP-hardness, solving efficiency poses significant challenges and requires exhaustive human efforts to design solving heuristics. Recent progress in this domain has shown promise in automatically learning heuristics with Machine Learning (ML) in a data-driven manner [1, 2, 3, 4, 5, 6, 7, 8], bringing practical advantages in both quality and speed, especially when the instances are within a certain domain. In addition, learning can help quickly uncover new heuristics for new problems or new instance distributions where experts are not there. ", "page_idx": 0}, {"type": "image", "img_path": "xDrKZOZEOc/tmp/a06709e0b8ae43324b04ba40c11862848013d76b8f106e91d0c262ed61ca475b.jpg", "img_caption": ["Figure 1: Optimization consistency models for CO solving where the model learns how to map from varying levels of noise to the solution distribution, conditioned on the problem graph instance. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Learning-based solvers for CO typically employ neural networks to generate neural predictions for solution construction or search guidance, aiming to minimize either the objective score [2, 4, 5, 6, 9] or the deviation from reference solutions [10, 3, 11, 12, 13]. The problem-solving task places significant demands on the testing performance of the model, while optimizing the average performance across training data does not ensure optimal performance for every encountered test instance. Thus, methods [14, 15, 6, 8] have been proposed to perform tailored optimization on neural predictions for every testing instance. In particular, generative modeling like diffusion has shown promise in learning instance-conditioned quality solution distributions [7, 8] with robust expressive power to achieve state-of-the-art performance, which also provides more informative support for further exploitation like gradient search in the solving stage, which was previously proposed as the diffusion-based training-to-testing (T2T) framework [8]. However, a major drawback of the diffusion backbone lies in its costly inference process, which necessitates tens or hundreds of denoising steps to solve one problem instance. This limitation in inference speed is crucial since CO seeks to achieve the highest solution quality within the shortest possible time, where both performance and efficiency are pivotal metrics in this pursuit. Although the diffusion solvers [7, 8] can exhibit superiority in inference speed compared to certain traditional methods and prior learning-based solvers, there remains substantial potential for speed enhancement, where bolstering this aspect could provide fundamental support and several-fold speedup for neural solvers based on generative modeling. ", "page_idx": 1}, {"type": "text", "text": "To resolve this issue, drawing inspiration from the successful practice of consistency models [16] for image generation, we propose the optimization consistency models to speed up the diffusion-based T2T framework, dubbed as Fast T2T, specifically for optimization problem-solving. We follow [8] to approach CO problems as conditional generation tasks, with the goal of modeling the distribution of high-quality solutions specific to given problem instances. As illustrated in Fig. 1, Fast T2T builds upon the methodology foundation of the discrete diffusion models [17, 18, 19] where a smooth transition from random uniform noise to the high-quality solution distribution is established. Given a problem instance, Fast T2T trains the conditional prediction consistency directly from varying noise levels to the solution distribution centered on the optimal solution to enable fast one-step solution distribution estimation. Meanwhile, to bridge the disparity between data-driven training and problem-solving, Fast T2T incorporates a novel objective gradient search for every instance in the testing phase based on the trained optimization consistency mappings. ", "page_idx": 1}, {"type": "text", "text": "Specifically, for the solving task, the model is expected to deliver the optimal solution output to the best extent possible for a given input instance. Thus, we define the optimization consistency property for the optimization scenario by conditional generation: conditoned on a given instance $G$ , points on all trajectories of all noising steps consistently map to the optimal solution of $G$ . Compared to the diffusion prediction of the data distribution from noising step $t$ to step $t-1$ , the consistency modeling enables generating solutions ( $\\mathbf{x}_{0}$ in Fig. 1) from random noise vectors $\\mathbf{\\nabla}\\mathbf{x}_{T}$ in Fig. 1) by a single step of model inference. This is achieved by an optimization consistency training protocol that minimizes the difference among samples originating from varying trajectories and noising steps relative to the optimal solution. The model retains the capability for multi-step sampling to trade for sampling quality by alternating noise introduction on $\\mathbf{x}_{\\mathrm{0}}$ to generate a less noisy point $\\mathbf{x}_{t}$ and solution reconstruction to obtain a new $\\mathbf{x}_{\\mathrm{0}}$ . Additionally, we design a novel objective gradient-based search on top of the learned consistency mapping to further explore the learned solution distribution for every test instance. We introduce instance-specific guidance from the objective to the learned solution prior $p_{\\theta}(\\mathbf{x}|G)$ and obtain the posterior $p_{\\theta}(\\mathbf{x}|y^{\\ast},G)$ where $y^{\\ast}$ represents the optimal objective score given instance $G$ , thereby directing the sampling process to the optimal $\\mathbf{x}^{*}$ . It specifically entails minimizing the free energy corresponding to the posterior by updating the probability parameters of intermediate noisy points through exponential gradient updates guided by the objective function during the alternation of noise injection and denoising steps. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "We show the efficacy of Fast T2T on two typical CO problems for edge-decision and node-decision types respectively, i.e., Traveling Salesman Problem (TSP) and Maximum Independent Set (MIS). We show that Fast T2T, even with a single-step initial solution generation and a single-step gradient search, can mostly outperform the SOTA diffusion-based counterparts with hundreds of inference steps. Meanwhile, due to its reduced step requirement, Fast T2T naturally demands significantly less inference time to achieve comparable quality, with more steps for further enhancement. ", "page_idx": 2}, {"type": "text", "text": "The highlights of this paper include: 1) We introduce the optimization consistency condition and establish Fast T2T based on the proposed optimization consistency models to facilitate fast high-quality CO solving, which offers a highly effective and efficient backbone for learning-based solvers. 2) To complement the learned prior and bridge the disparity between data-driven training and the requirement of problem-solving, we introduce a novel gradient search with objective guidance based on consistency mappings to conduct a tailored search for every test instance. 3) Extensive experiments show that Fast T2T exhibits strong performance superiority over existing SOTA neural solvers on benchmark datasets across various scales. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Machine Learning for Combinatorial Optimization. Current learning-based CO solvers can be categorized into constructive approaches and improvement-based approaches. Constructive approaches refer to autoregressive methods [20, 2, 4, 21, 5] that directly construct solutions by sequentially determining decision variables until a complete solution is constructed, and non-autoregressive methods [3, 12, 22, 6, 7, 23] that predict soft-constrained solutions in one shot and then perform postprocessing to achieve feasibility. Improvement-based solvers [24, 25, 26, 27, 28] learn to iteratively refine a solution through local search operators toward minimizing the optimization objective. ", "page_idx": 2}, {"type": "text", "text": "Generative modeling for CO has recently shown promise with its potent representational capabilities and informative distribution estimation. It models the problem-solving task as a conditional generation task for learning solution distributions conditioned on given instances [21, 29, 7, 30, 31, 8]. Drawing from diffusion models, DIFUSCO [7] has attained SOTA performance in solving TSP and MIS. Nonetheless, it does not incorporate any instance-specific search paradigms to fully capitalize on the estimated solution distribution. Addressing this limitation, the T2T framework [8] further introduces an objective-guided gradient search process during solving to leverage the learned distribution. However, every aspect of this system, including distribution learning and gradient search, hinges on the diffusion model for step-by-step generation. This reliance renders the diffusion-based approaches computationally inefficient and impedes further search computations to trade for solution quality. ", "page_idx": 2}, {"type": "text", "text": "Diffusion Models and Consistency Models. Diffusion models entail a dual process comprising noise injection and learnable denoising, wherein neural networks predict the data distribution at each step based on the data from the previous step. For Diffusion in continuous space [17, 32, 33, 34, 35, 36, 37], the solution trajectories can be modeled by Probability Flow ODE [38]. Similar paradigms have also been adopted for discrete data using binomial or multinomial/categorial noises [17, 18, 19]. On top of the foundation of diffusion models, consistency models [16] define the self-consistency for every generation trajectory and introduce a consistency training paradigm for continuous data to directly learn the mappings from noise to the data. Inspired by this paradigm, we define the optimization consistency condition tailored for the optimization scenario, which requires consistency across multiple trajectories and time steps with the optimal solution as the target in a conditional context, thereby proposing the optimization consistency models as the solver embodiment. The models are employed on the discrete multinomial data for the benefit of CO. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries and Problem Definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Adopting the conventions established in [39, 40] we define $\\mathcal{G}$ as the collection of CO problem instances represented by graphs $G(V,E)\\in\\mathcal{G}$ , where $V$ and $E$ denote the nodes and edges respectively. CO problems can be broadly classified into two types based on the solution composition: edge-decision problems that involve determining the selection of edges and node-decision problems that determine nodes. Let $\\mathbf{x}\\in\\{0,1\\}^{N\\times2}$ denote the optimization variable, where each entry is represented by a one-hot vector, i.e., each entry with $(0,1)$ indicates that it is included in $\\mathbf{x}$ and $(1,0)$ indicates the opposite. For edge-decision problems, $N=n^{2}$ and ${\\bf x}_{i,j}$ indicates whether $E_{i,j}$ is included in $\\mathbf{x}$ . For node-decision problems, $N=n$ and $\\mathbf{x}_{i}$ indicates whether $V_{i}$ is included in $\\mathbf{x}$ . The feasible set $\\Omega$ consists of $\\mathbf{x}$ satisfying specific constraints as feasible solutions. A CO problem on $G$ aims to find a feasible $\\mathbf{x}$ that minimize the given objective function $l(\\cdot;G):\\{0,1\\}^{N\\times\\mathbf{\\bar{2}}}\\to\\mathbb{R}_{\\geq0}$ : ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\{0,1\\}^{N\\times2}}l(\\mathbf{x};G)\\quad\\mathrm{s.t.}\\quad\\mathbf{x}\\in\\Omega\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "TSP is defined on an undirected complete graph $G=(V,E)$ , where $V$ represents $n$ cities and each edge $E_{i,j}$ is assigned a non-negative weight $w_{i,j}$ representing the distance between cities $i$ and $j$ . The problem revolves around identifying a Hamiltonian cycle of minimum weight in $G$ . For MIS, given an undirected graph $G=(V,E)$ , an independent set is a subset of vertices $S\\subseteq V$ such that no two vertices in $S$ are adjacent in $G$ . MIS entails finding an independent set of maximum cardinality in $G$ . ", "page_idx": 3}, {"type": "text", "text": "4 Training-Stage Optimization Consistency Modeling ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "4.1 Solution Encoding and Noising Process ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Using the notations in Sec. 3, we represent the solutions of CO problems as $\\mathbf{x}\\in\\{0,1\\}^{N\\times2}$ with $\\mathbf{x}\\in\\Omega$ . The distribution of $\\mathbf{x}$ is represented by $N$ Bernoulli distributions indicating whether each entry should be selected, i.e., $p(\\mathbf{x})\\in[\\dot{0},1]^{N\\times2}$ . The objective of utilizing generative modeling for problemsolving is to capture the distribution of high-quality solutions conditioned on a given instance $G$ , denoted as $p_{\\theta}(\\mathbf{x}|G)$ . The neural models try to establish transition trajectories from random uniform noise to high-quality soft-constrained solutions, i.e., $\\mathbf{x}\\in\\{0,1\\}^{N\\times2}$ . These soft-constrained solutions are directly sampled from the estimated Bernoulli distributions where feasibility constraints can be broadly captured through learning and eventually hard-guaranteed by post-processing. ", "page_idx": 3}, {"type": "text", "text": "To establish the transition trajectories of data, we follow the discrete diffusion modeling [7, 8] to define the noising process, which takes the initial solution $\\mathbf{x}_{\\mathrm{0}}$ sampled from the distribution $q(\\mathbf{x}_{0}|G)$ and progressively introduces noise to generate a sequence of latent variables ${\\bf x}_{1:T}={\\bf x}_{1},{\\bf x}_{2},\\cdot\\cdot\\cdot{\\bf\\nabla},{\\bf x}_{T}$ . Specifically, the noising process is formulated as $\\begin{array}{r}{q(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})=\\prod_{t=1}^{T}q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})}\\end{array}$ , which is achieved by multiplying $\\mathbf{x}_{t}\\in\\{0,1\\}^{N\\times2}$ at step $t$ with a forward transiti on probability matrix $\\mathbf{Q}_{t}\\in[0,1]^{2\\times2}$ which indicates the transforming probability of decision state. We set $\\mathbf{Q}_{t}=\\left[\\begin{array}{c c}{\\beta_{t}}&{1-\\dot{\\beta_{t}}}\\\\ {1-\\beta_{t}}&{\\beta_{t}}\\end{array}\\right]$ [18], where $\\beta_{t}\\in[0,1]$ such that the transition matrix is doubly stochastic with strictly positive entries, ensuring that the stationary distribution is uniform which is an unbiased prior for sampling. The noising process for each step and the $t$ -step marginal are formulated as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})=\\mathtt{C a t}(\\mathbf{x}_{t};\\mathbf{p}=\\mathbf{x}_{t-1}\\mathbf{Q}_{t})\\quad\\mathrm{and}\\quad q(\\mathbf{x}_{t}|\\mathbf{x}_{0})=\\mathtt{C a t}(\\mathbf{x}_{t};\\mathbf{p}=\\mathbf{x}_{0}\\mathbf{\\overline{{Q}}}_{t})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathtt{C a t}(\\mathbf{x};\\mathbf{p})$ is a categorical distribution over $N$ one-hot variables and $\\overline{{\\mathbf{Q}}}_{t}=\\mathbf{Q}_{1}\\mathbf{Q}_{2}\\cdot\\cdot\\cdot\\mathbf{Q}_{t}$ . ", "page_idx": 3}, {"type": "text", "text": "4.2 Optimization Consistency Training Scheme ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Unlike the diffusion models modeling $p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},G)$ , we aim to directly map random noise to data by $p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},G)$ in an optimization context. In continuous-time diffusion models defined on $(\\epsilon,T]$ [38], consistency models [16] defines the self-consistency property as points on the same trajectory map to the same initial point, and optimize the learned consistency function $f_{\\theta}(\\cdot,\\cdot)$ to satisfy the requirement by: 1) boundary condition: $f_{\\theta}(\\mathbf{x}_{\\epsilon},\\epsilon)=\\mathbf{x}_{\\epsilon};2)$ self-consistency property: $f_{\\theta}$ outputs consistent estimation for arbitrary pairs of $\\left(\\mathbf{x}_{t},t\\right)$ that belong to the same trajectory, i.e., $f_{\\theta}(\\mathbf{x}_{t},t)=$ $f_{\\theta}(\\mathbf{x}_{t^{\\prime}},t^{\\prime}),\\forall\\;t,t^{\\prime}\\;\\in\\;[\\epsilon,T]$ . The joint effect of these two constraints serves as the necessary and sufficient condition to achieve a reliable data prediction from noise step $T$ to data, i.e., $f_{\\theta}(\\mathbf{x}_{T},T)\\rightarrow$ $\\mathbf{x}_{\\epsilon}$ . In the optimization scenario of mapping instance $G$ to approximate its optimal solution $\\mathbf{x}^{*}$ , the generation process is conditioned on the problem instance $G$ with a reference optimal solution $\\mathbf{x}^{*}$ serving as the commonly targeted initial point for all the conditional trajectories. Based on the discrete diffusion process with an explicit sampling process [18, 7, 8], we use the consistency function to estimate the optimal solution distribution as a point estimate $\\delta(\\mathbf{x}-\\mathbf{x}^{*})$ where $\\delta(\\cdot)$ represents Dirac delta. Below defines optimization consistency for the conditional context of problem-solving. ", "page_idx": 3}, {"type": "image", "img_path": "xDrKZOZEOc/tmp/209dce1eccca831769fe4281c1067a459524af0eba5b28ccb12cff8eef4b0c40.jpg", "img_caption": ["Figure 2: Vannila consistency models are trained to map points on any trajectory to its origin. Optimization consistency enforces that all trajectories conditioned on $G$ consistently map to the same initial point, i.e., the optimal solution of $G$ . ", "", ""], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Definition 4.1 (Optimization Consistency). Given a solution trajectory $\\{\\mathbf{x}_{t}\\}_{t\\in[0,T]}$ , we define the consistency function as $f:(\\mathbf{x}_{t},t,G)\\mapsto\\delta(\\mathbf{x}-\\mathbf{x}^{*})$ , which maintains the optimization consistency property: conditioned on instance $G$ , all points along any trajectory map to its optimal solution, i.e., $f_{\\theta}(\\mathbf{\\bar{x}}_{t}^{i},t,G)=f_{\\theta}(\\mathbf{x}_{t^{\\prime}}^{j},t^{\\prime},G)=\\delta(\\mathbf{x}-\\mathbf{x}^{*})$ for distinct trajectories $i$ and $j$ at distinct steps $t$ and $t^{\\prime}$ . ", "page_idx": 4}, {"type": "text", "text": "As illustrated in Fig. 2, the goal of the consistency model $f_{\\theta}$ in the optimization context, is to estimate the consistency function from data by learning to enforce optimization consistency. To achieve such consistency in the context of optimization to learn $f:G\\mapsto\\mathbf{x}^{*}$ , given its nature as a conditional generation and the aim for an explicit optimal solution $\\mathbf{x}^{*}$ , we can seamlessly integrate $\\mathbf{x}^{*}$ into the objective function for smooth training. Instead of optimizing the expectation of the variation of the consistency mappings over two noise points $\\mathbf{x}$ and $\\mathbf{x}^{\\prime}$ , i.e., $\\begin{array}{r}{\\bar{\\mathcal{L}}_{\\mathrm{CM}}(\\dot{\\theta})\\,=\\,\\mathbb{E}\\big[d\\big(f_{\\theta}\\left(\\mathbf{x},t,G\\right),f_{\\theta}\\left(\\mathbf{x}^{\\prime},t^{\\prime},G\\right)\\big)\\big].}\\end{array}$ , we introduce $\\mathbf{x}^{*}$ to optimize the upper bound of $\\mathcal{L}_{\\mathrm{CM}}$ through triangle inequality of distance measures as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\sf O p t C M}(\\theta)=\\mathbb{E}\\big[d\\big(f_{\\theta}({\\bf x},t,G),\\delta({\\bf x}-{\\bf x}^{*})\\big)+d\\big(f_{\\theta}({\\bf x}^{\\prime},t^{\\prime},G),\\delta({\\bf x}-{\\bf x}^{*})\\big)\\big]\\geq\\mathcal{L}_{\\sf C M}(\\theta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here $d(\\cdot,\\cdot)$ is a distance metric function. In this case, the boundary conditions become less significant, since we have already dispersed the information of $\\mathbf{x}^{*}$ across all noise time steps. Therefore, we can directly utilize the neural network $\\theta$ to estimate the consistency function $f_{\\theta}({\\bar{\\cdot}},\\cdot,\\cdot)$ . In addition, all learned trajectories are expected to map to the optimal solution $\\mathbf{x}^{*}$ given the instance $G$ , and the estimated solution distribution is expected to center on $\\mathbf{x}^{*}$ . This calls for the requirement of consistency extending across all trajectories, rather than being confined within a single trajectory. ", "page_idx": 4}, {"type": "text", "text": "Definition 4.2. The optimization consistency loss for conditional problem-solving is defined as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathrm{OptCM}}^{N_{t}}(\\theta):=\\mathbb{E}\\left[\\lambda(t_{n})\\left(d\\left(f_{\\theta}(\\mathbf{x}_{t_{n}}^{i},t_{n},G),\\delta(\\mathbf{x}-\\mathbf{x}^{*})\\right)+d\\left(f_{\\theta}(\\mathbf{x}_{t_{n+1}}^{j},t_{n+1},G),\\delta(\\mathbf{x}-\\mathbf{x}^{*})\\right)\\right)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the expectation is taken with respect to $G\\sim p_{G}$ , $n\\sim\\mathcal{U}[1,N_{t}-1]$ , $\\mathbf{x}_{t_{n}}^{i}\\sim\\mathsf{C a t}(\\mathbf{x}_{t_{n}};\\mathbf{p}=$ x\u2217Qtn), and xtjn+1 $\\mathbf{x}_{t_{n+1}}^{j}\\sim\\mathsf{C a t}(\\mathbf{x}_{t_{n+1}};\\mathbf{p}=\\mathbf{x}^{*}\\overline{{\\mathbf{Q}}}_{t_{n+1}})$ . Here $\\mathcal{U}[1,N_{t}-1]$ denotes the uniform distribution over $\\{1,2,\\cdot\\cdot\\cdot,N-1\\}$ , $\\lambda(\\cdot)\\in\\mathbb{R}^{+}$ is a positive weighting function. ", "page_idx": 4}, {"type": "text", "text": "Since the model outputs $N$ Bernoulli distributions as the distribution of $\\mathbf{x}_{\\mathrm{0}}$ , we adopt the binary cross entropy to measure the distance between the estimation $p_{\\theta}(\\mathbf{x})$ and $\\delta(\\mathbf{x}-\\mathbf{x}^{*})$ . We set $\\lambda(t_{n})\\equiv1$ and discover a decent empirical performance. $\\mathbf{x}_{t_{n}}^{i}$ and $\\mathbf{x}_{t_{n+1}}^{j}$ are identically and independently sampled from different noising trajectories, in comparison to $\\mathbf{x}_{t_{n}}^{i}\\sim\\mathsf{C a t}(\\mathbf{x}_{t_{n}};\\mathbf{p}=\\mathbf{x}^{*}\\overline{{\\mathbf{Q}}}_{t_{n}}),\\mathbf{x}_{t_{n+1}}^{i}\\sim$ $\\mathtt{C a t}(\\mathbf{x}_{t_{n+1}};\\mathbf{p}=\\mathbf{x}_{t_{n}}\\mathbf{Q}_{t_{n}+1}\\cdot\\cdot\\cdot\\mathbf{Q}_{t_{n+1}})$ where $\\mathbf{x}_{t_{n}}^{i}$ and $\\mathbf{x}_{t_{n+1}}^{i}$ are from the same trajectory. Since very close $t_{n}$ and $t_{n+1}$ would make Eq. 4.2 very easy to learn, we reschedule the time horizon into $N_{t}-1$ sub-intervals $t_{1}=1<t_{2}<\\cdot\\cdot\\cdot<t_{N_{t}}=T$ through the cosine denoising schedular such that $\\begin{array}{r}{t_{i}=\\lfloor\\cos\\left(\\frac{1-\\pi\\cdot c i}{2}\\right)\\cdot T\\rfloor}\\end{array}$ following DDIM [34]. This training procedure enforces the model to learn conditional consistency across different noise steps to consistently map to the optimal solution $\\mathbf{x}^{*}$ of the given condition $G$ . Note that although we enforce the noise to map to the Dirac delta on $\\mathbf{x}^{*}$ , the generative modeling process with a single sample per instance condition during training still enables the model to estimate a solution distribution (centering around the optimal solution) to enjoy diversity to enhance performance via parallel sampling, as evidenced by the experiments in Table. 2. ", "page_idx": 4}, {"type": "text", "text": "Specifically for implementation, the network $\\theta$ is embodied as an anisotropic graph neural network with edge gating mechanisms [3], and instance $G$ serves as a part of the conditional input as the node or edge features. For TSP, the 2D coordinates of the vertices serve as the instance condition, and the input edge features are from the embeddings of entries in $\\mathbf{x}_{t}$ integrated with the embedding of the input time step $t$ . For MIS, the edges $E$ serve as the instance condition and the node embeddings are from $\\mathbf{x}_{t}$ to collectively form the input. After the GNN iterations, the features of the decision variables (edges for TSP and nodes for MIS) are projected to 2-D outputs $p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},G)\\in[0,1]^{N\\times2}$ featuring $N$ Bernoulli distributions for $N$ entries in $\\mathbf{x}_{\\mathrm{0}}$ via a linear layer followed by a Softmax layer. ", "page_idx": 5}, {"type": "text", "text": "5 Testing-Stage Problem Solving via Consistency-Based Gradient Search ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The solving involves obtaining the initial solution from the raw consistency sampling process and a consistency-based gradient search process with objective feedback for iterative solution improvement. ", "page_idx": 5}, {"type": "text", "text": "5.1 Consistency Sampling for Initial Solutions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "With a well-trained $f_{\\theta}(\\cdot,\\cdot,\\cdot)$ , we generate solutions for a given instance $G$ by sampling $\\mathbf{x}_{T}$ from the uniform distribution and then evaluate it for $\\textbf{x}_{0}\\sim$ $p_{\\theta}(\\mathbf{x}_{0})=f_{\\theta}(\\mathbf{x}_{T},T,G)$ . This process requires only one forward pass through the consistency model, resulting in sampling in a single step. Solution sampling with multiple steps of inferences can also be accomplished via alternating denoising and noise injection, allowing trading runtime for improved solving quality. Given a sequence of time points $\\tau_{1}>\\tau_{2}>\\dots>\\tau_{N_{\\tau}-1}$ , in time step $\\tau_{n}$ , the multistep sampling process adds noise to the $\\mathbf{x}_{\\mathrm{0}}$ obtained from the last step $\\tau_{n-1}$ by $\\mathbf{x}_{\\tau_{n}}\\;\\sim\\;\\complement{\\sf a t}(\\mathbf{x}_{\\tau_{n}};\\mathbf{p}\\;=$ $\\mathbf{x}\\overline{{\\mathbf{Q}}}_{\\tau_{n}})$ , then denoise to find the new solution by $\\begin{array}{r}{\\mathbf{x}_{0}\\sim\\mathop{f_{\\boldsymbol\\theta}}(\\mathbf{x}_{\\tau_{n}},\\tau_{n},G)}\\end{array}$ , as shown in Algorithm. 1. ", "page_idx": 5}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/67119931ec3b8fb52a5e887f4b2b53b2a811c7e928697e78d9c4682daf75d7e5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "5.2 Consistency-based Gradient Search with Objective Feedback ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For CO, the integration of objective optimization facilitates direct engagement with the objective and enables efficient exploration of the solution space to minimize the score. [8] has established such a procedure for the step-by-step denoising function, yet it is not transferable to the consistency function, and incorporating objective optimization may prove more challenging as the consistency function maps across longer distance time steps. With the learned conditional solution prior $p_{\\theta}(\\mathbf{x}|G)$ , this section aims to introduce a constraint $c(\\mathbf{x},y^{*}|G)$ on $\\mathbf{x}$ to this prior for inference, where $y^{\\ast}$ represents the optimal objective score given the instance $G$ . That is, we want to find an approximation to the posterior distribution $p_{\\theta}(\\mathbf{x}|y^{*},G)\\propto p_{\\theta}(\\mathbf{x}|G)c(\\mathbf{x},y^{*}|G)$ to guide the sampling process to the optimal $\\mathbf{x}^{*}$ . ", "page_idx": 5}, {"type": "text", "text": "Here we follow [8] to determine $c(\\mathbf{x},y^{*}|G)$ by utilizing energy-based modeling [41] with the energy function $E(y,\\mathbf{x},G)=|y-l(\\mathbf{x};G)|$ , which quantifies the compatibility between $y$ and $(\\mathbf{x},G)$ , and it reaches zero when $y$ is exactly the objective score of $\\mathbf{x}$ with respect to $G$ . Such a design enables the best $y$ matching the inputs to maintain the highest probability density and the probability density is positively correlated with the matching degree. Then we employ the Gibbs distribution to characterize the probability distribution over a collection of arbitrary energies: ", "page_idx": 5}, {"type": "equation", "text": "$$\nc(\\mathbf{x},y|G)=\\frac{\\exp(-E(y,\\mathbf{x},G))}{\\int_{y^{\\prime}}\\exp(-E(y^{\\prime},\\mathbf{x},G))}=Z\\exp(-\\left|y-l(\\mathbf{x};G)\\right|)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Following [42], we introduce an approximate variational posterior $q(\\mathbf{x}|G)$ and the free energy ", "page_idx": 5}, {"type": "equation", "text": "$$\nF=\\underbrace{-\\mathbb{E}_{q(\\mathbf{x}|G)q(\\mathbf{h}|\\mathbf{x},G)}\\left[\\log p_{\\theta}(\\mathbf{x},\\mathbf{h}|G)-\\log q(\\mathbf{x})q(\\mathbf{h}|\\mathbf{x},G)\\right]}_{F_{1}}\\underbrace{-\\mathbb{E}_{q(\\mathbf{x}|G)}\\left[\\log c(\\mathbf{x},y^{*}|G)\\right]}_{F_{2}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "is minimized when $\\mathrm{KL}(q(\\mathbf{x}|G)||p_{\\theta}(\\mathbf{x}|y^{*},G))$ is minimized. Here $\\mathbf{h}=\\mathbf{x}_{1},\\cdot\\cdot\\cdot,\\mathbf{x}_{T}$ represent the latent variables. Through the diffusion process, we can obtain $\\begin{array}{r}{q(\\mathbf{h}|\\mathbf{x})=\\prod_{t=1}^{T}q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})}\\end{array}$ . We apply ", "page_idx": 5}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/129c4f5dac2dced1a323dd51deee72fa0a79913068de1ba51b32dbdf6bdf4ce7.jpg", "table_caption": ["Table 1: Results with Greedy Decoding on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. \u2217denotes results that are quoted from previous works. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "an approximation to the posterior over $\\mathbf{x}=\\mathbf{x}_{0}$ as a point estimate $q(\\mathbf{x}|G)=\\delta(\\mathbf{x}-\\pmb{\\eta})$ . $F_{1}$ aligns with the objective of the consistency and diffusion models and $F_{2}$ can be transformed using Eq. 5: ", "page_idx": 6}, {"type": "equation", "text": "$$\nF_{1}=\\mathbb{E}_{q(\\mathbf{h}\\mid\\eta,G)}\\left[\\log{\\frac{q(\\mathbf{h}\\mid\\eta,G)}{p_{\\theta}(\\eta,\\mathbf{h}\\mid G)}}\\right]\\quad{\\mathrm{and}}\\quad F_{2}=-\\log c(\\eta,y^{*}\\mid G)=l(\\eta;G)-\\log Z-y^{*}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Initializing $\\eta$ from Sec. 5.1, we aim to update $\\eta$ to reach conditional solution distribution $p_{\\theta}(\\mathbf{x}|y^{\\ast},G)$ through exponential gradient decent on the latent continuous probability $\\begin{array}{r}{\\mathbf{p}_{\\mathbf{x}}=p(\\mathbf{x}_{\\alpha T})=\\eta\\overline{{\\mathbf{Q}}}_{\\alpha T}\\in}\\end{array}$ $[0,1]^{\\breve{N}\\times2}$ at each iteration minimizing $F_{1}$ and $F_{2}$ . Here $\\mathbf{p_{x}}$ parameterizes $N$ Bernoulli distributions and $\\alpha$ serves as a hyperparameter to control the noise degree. We view $\\mathbf{p_{x}}$ as the expectation of $\\mathbf{x}_{\\alpha T}$ over $\\mathbf{p_{x}}$ , i.e., $\\mathbb{E}_{\\mathbf{p}_{\\mathbf{x}}}(\\mathbf{x}_{\\alpha T})=\\mathbf{p}_{\\mathbf{x}}$ , since $\\mathbf{p_{x}}$ is a multivariate Bernoulli. To obtain reliable gradients on $\\mathbf{p_{x}}$ , we estimate the expected distribution of $\\mathbf{x}_{\\mathrm{0}}$ by $f_{\\theta}(\\mathbf{p_{x}},\\alpha T,G)$ . Note $F_{1}$ is exactly the (implicit) objective of the diffusion and consistency models, i.e., the variational upper bound of the negative log-likelihood with the targeted data $\\eta$ , which we optimize by minimizing the consistency over the re-predicted solutions $\\bar{d}\\big(f_{\\theta}(\\mathbf{p_{x}},\\alpha\\bar{T},G),\\delta(\\mathbf{x}-\\pmb{\\eta})\\big)$ . While $F_{2}$ can be optimized by minimizing $l\\big(f_{\\theta}(\\mathbf{p_{x}},\\alpha T,G);G\\big)+\\mathbf{Const}(\\mathbf{p_{x}})$ , where the objectives are defined following [8] as $l_{\\mathrm{MIS}}(\\mathbf{x};G)\\triangleq$ $\\begin{array}{r}{-\\sum_{1\\leq i\\leq N}\\mathbf{x}_{i}+\\beta\\sum_{(i,j)\\in E}\\mathbf{x}_{i}\\mathbf{x}_{j}}\\end{array}$ and $l_{\\mathrm{TSP}}=\\mathbf{x}\\odot D$ where $D\\in\\mathbb{R}_{+}^{n\\times n}$ denotes the distance matrix. ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{p_{x}}\\leftarrow\\mathbf{p_{x}}\\odot\\exp\\Big\\{-\\nabla_{\\mathbf{p_{x}}}\\Big[\\lambda_{1}\\cdot d\\big(\\mathbb{E}_{p_{\\theta}(\\eta)}\\eta,\\delta\\left(\\mathbf{x}-\\eta\\right)\\big)+\\lambda_{2}\\cdot l\\big(\\mathbb{E}_{p_{\\theta}(\\eta)}\\eta;G\\big)\\Big]\\Big\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\lambda_{1},\\lambda_{2}$ are weighting hyperparameters. Then we sample $\\mathbf{x}_{\\alpha T}\\sim\\mathbf{p}_{\\mathbf{x}}$ and reconstruct a new distribution estimate of $\\eta$ by $p_{\\theta}^{\\prime}(\\eta)=f_{\\theta}(\\mathbf{x}_{\\alpha T},\\alpha T,G)$ . To guarantee the feasibility, we utilize the logits of $p_{\\theta}(\\pmb{\\eta})$ and $p_{\\theta}^{\\prime}(\\eta)$ to produce the heatmaps where each element denotes each edge/node\u2019s confidence to be selected, and then adopt post-processin $\\mathrm{g}^{2}$ to obtain two feasible solutions. This iteration concludes by outputting the lower-cost solution as $\\eta$ . ", "page_idx": 6}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We test on two CO problems, TSP and MIS. The comparison includes SOTA learning-based solvers, heuristics, and exact solvers for each problem. To configure the generative-based models, we adopt $\\mathrm{T_{s}}$ and $\\mathrm{T_{g}}$ to represent the number of inference steps in initial solution sampling and the number of gradient search steps, respectively. For diffusion-based baselines including DIFUSCO [7] and T2T [8], we adopt $\\mathrm{T}_{\\mathrm{s}}{=}50$ and involve 3 iterations with 5 guided denoising steps per iteration for T2T\u2019s gradient search, i.e., $\\mathrm{T_{g}}{=}15$ . Fast T2T can achieve promising results with merely one-step initial solution sampling and one-step gradient search, i.e., ${\\mathrm{T}}_{\\mathrm{s}}{=}1$ and $\\mathrm{Tg}{=}1$ . However, the affordability of model inference facilitates a more extensive exploration of the solution distribution through a thorough search. ", "page_idx": 6}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/183ba01a2bb08cf7a773f875a9d03df07d1d4af974d33eaf4678150d97093948.jpg", "table_caption": ["Table 2: Results on TSP-500 and TSP-1000. AS: Active Search, S: Sampling Decoding, BS: Beam Search. \u2217denotes results that are quoted from previous works [8, 6]. "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "xDrKZOZEOc/tmp/86454e722518003a3dfa8bb3f1678ee983b0c86713e1a2ab161c535e401945ff.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "xDrKZOZEOc/tmp/a7aa56f4e058cc2eafdc449ccba480ea9fcbc6a0250aa50dbfbef4e35b5d1177.jpg", "img_caption": ["performance drop. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "6.1 Experiments for TSP ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Datasets. A TSP instance includes $N$ 2-D coordinates and a reference solution obtained by heuristics. Training and testing instances are generated via uniformly sampling $N$ nodes from the unit square $[0,1]^{2}$ , which is a standard procedure as adopted in [2, 21, 3, 48, 6, 7, 8]. We experiment on various problem scales including TSP-50, 100, 500, and 1000. ", "page_idx": 7}, {"type": "text", "text": "Metrics. Following [2, 3, 6, 7, 8], we adopt three evaluation metrics: 1) Length: the average total distance or cost of the solved tours w.r.t. the corresponding instances, as directly corresponds to the objective. 2) Drop: the relative performance drop w.r.t. length compared to the global optimality or the reference solution; 3) Time: the average computational time to solve the problems. ", "page_idx": 7}, {"type": "text", "text": "Results for TSP-50/100. Given the recent success of learning-based solvers in achieving near-optimal performance on small-scale problems, we follow [8] to assess methods within the naive greedy decoding setting, aiming for a more discernable evaluation. The comparison includes state-of-the-art learning-based methods with greedy decoding and traditional solvers. Hyperparameter $\\alpha$ is set as 0.2. The sampling steps and gradient search steps are explicitly marked. Table. 1 shows that Fast T2T with merely one-step sampling steps approximates diffusion-based solvers with 100 sampling steps with a slight average performance gain of $5.7\\%$ , yet with an average speedup of $\\mathbf{82.8x}$ . A similar conclusion can be made for methods with gradient search with an average performance gain of $4.5\\%$ and speedup of $\\mathbf{35.4x}$ . Fast T2T variants with more sampling and gradient search steps achieve ${\\bf82.1\\%}$ performance gain with $\\mathbf{14.7x}$ speedup compared to previous state-of-the-art diffusion-based counterparts. ", "page_idx": 7}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/4359284076dc2d691420063cbade1fb4f657fa7cc1c2abef3c674d894610f195.jpg", "table_caption": ["Table 4: Results on MIS. TS: Tree Search, UL: Unsupervised Learning. \u2217denotes results quoted from previous works [8, 31]. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Results for TSP-500/1000. Learning-based solvers are compared using greedy decoding and sampling decoding $(\\times4)$ , i.e., sampling multiple solutions and reporting the best one. Hyperparameter $\\alpha$ is set as 0.2. The sampling steps and gradient search steps are explicitly marked. Table. 2 shows that Fast T2T with merely one-step sampling steps averagely outperforms diffusion-based solvers with 100 sampling steps by a performance gain of $10.1\\%$ and a speedup of $16.8\\mathbf{x}$ . A similar conclusion can be made for methods with gradient search with an average performance gain of ${\\bf14.9\\%}$ and a speedup of $\\mathbf{8.5x}$ . Fast T2T variants with more sampling and gradient search steps achieve $52.1\\%$ performance gain with 7.4x speedup compared to previous SOTA diffusion-based counterparts. ", "page_idx": 8}, {"type": "text", "text": "Results for Generalization. Based on the problem set {TSP-50, TSP-100, TSP-500, TSP-1000}, we train the model on a specific problem scale and then evaluate it on all problem scales. Table 3 presents the generalization results of Fast T2T compared with diffusion-based counterparts with greedy decoding. The results show the satisfying cross-domain generalization ability of Fast T2T, e.g., the model trained on TSP-1000 achieves less than a $0.6\\%$ optimality gap on all other problem scales. ", "page_idx": 8}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/a584bf90f66b69fc2e59cb1e7d0d9732989125c3bfd565130ae3a84314aa15d1.jpg", "table_caption": ["Table 3: Generalization results. Tour length and drop with Greedy Decoding are reported. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Soving Time vs. Optimality Drop on TSP-100/1000. Fig. 3 and Fig. 4 illustrate the solving progress via the runtime-drop curves of Fast T2T and the prominent mathematical solver LKH3 [45]. The comparison is conducted on TSP-100 and TSP-1000. We are excited to discover that Fast T2T surpasses LKH3 in the early solving stage while also performing comparably in the later stage. This suggests that Fast T2T can serve as an effective rapid solver for approximate solutions outperforming LKH3, which may find widespread applications requiring prompt responses. Other neural solver baselines fall far outside the comparable range; please refer to Fig. 6 for an intuitive illustration. ", "page_idx": 8}, {"type": "text", "text": "Ablation and Hyperparameter Study. Fig. 5 illustrates the performance variation when altering the noise hyperparameter $\\alpha$ , and we discover a relatively superior and stable performance at $\\alpha=0.2$ . Fig. 6 shows the performance variation when varying the sampling and gradient search steps. We also include DIFUSCO [7] and T2T [8] for direct comparison, in order to see whether diffusionbased methods can achieve promising results using minimal sampling steps. In this case, we let the gradient search steps equal to the sampling steps for Fast T2T and T2T. The results show a significant performance overwhelm of Fast T2T to diffusion-based counterparts. ", "page_idx": 8}, {"type": "text", "text": "6.2 Experiments for MIS ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Datasets. Two datasets are tested for the MIS problem following [52, 54, 53, 6, 7], including RB graphs [31] and Erdo\u02dds\u2013R\u00e9nyi (ER) graphs [55]. We randomly sample 200 to 300 vertices uniformly and generate the graph instances. ER graphs are randomly generated with each edge maintaining a fixed probability of being present or absent, independently of the other edges. We adopt ER graphs of 700 to 800 nodes with the pairwise connection probability set as 0.15. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Metrics. Following previous works [2, 3, 6, 7], we adopt three evaluation metrics to measure model performance: 1) Size: the average size of the solutions w.r.t. the corresponding instances, i.e. the objective. 2) Drop: the relative performance drop w.r.t. size compared to the optimal solution or the reference solution; 3) Time: the average computational time required to solve the problems. ", "page_idx": 9}, {"type": "text", "text": "Main Results. The baselines include SOTA neural methods with greedy and sampling decoding $(\\times4)$ , as well as exact solver Gurobi [49] and heuristic solver KaMIS [51]. The solving time of Gurobi is set as comparable to neural solvers, thus it does not reach optimality. Table. 4 shows that Fast T2T with merely one-step sampling and gradient search steps averagely approximates diffusion-based counterparts with approximately 100 sampling steps by a slight performance gain of $2.5\\%$ and a speedup of 26.3x. Fast T2T variants with more sampling and gradient search steps achieve $23.7\\%$ performance gain with 9.1x speedup compared to previous SOTA diffusion-based counterparts. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduce optimization consistency on top of the diffusion-based training-to-testing solving framework for efficient and effective combinatorial optimization solving. Our proposed model facilitates rapid single-step solving, demonstrating comparable or superior performance to SOTA diffusion-based counterparts, offering a more effective and efficient alternative backbone for neural solvers. In addition, a novel consistency-based gradient search scheme is introduced to further complement the generalization capability during solving. Experimental results on TSP and MIS datasets showcase the superiority of our methods, exhibiting significant performance gains in both solution quality and speed compared to previous state-of-the-art neural solvers. Furthermore, our approach demonstrates superiority over LKH3 in the early stages of solving. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Y. Bengio, A. Lodi, and A. Prouvost, \u201cMachine learning for combinatorial optimization: a methodological tour d\u2019horizon,\u201d European Journal of Operational Research, 2021. [2] W. Kool, H. Van Hoof, and M. Welling, \u201cAttention, learn to solve routing problems!\u201d arXiv preprint arXiv:1803.08475, 2018. [3] C. K. Joshi, T. Laurent, and X. Bresson, \u201cAn efficient graph convolutional network technique for the travelling salesman problem,\u201d arXiv preprint arXiv:1906.01227, 2019.   \n[4] Y.-D. Kwon, J. Choo, B. Kim, I. Yoon, Y. Gwon, and S. Min, \u201cPomo: Policy optimization with multiple optima for reinforcement learning,\u201d Advances in Neural Information Processing Systems, vol. 33, pp. 21 188\u201321 198, 2020.   \n[5] M. Kim, J. Park, and J. Park, \u201cSym-nco: Leveraging symmetricity for neural combinatorial optimization,\u201d arXiv preprint arXiv:2205.13209, 2022. [6] R. Qiu, Z. Sun, and Y. Yang, \u201cDimes: A differentiable meta solver for combinatorial optimization problems,\u201d arXiv preprint arXiv:2210.04123, 2022.   \n[7] Z. Sun and Y. Yang, \u201cDIFUSCO: Graph-based diffusion solvers for combinatorial optimization,\u201d in Thirty-seventh Conference on Neural Information Processing Systems, 2023. [Online]. Available: https://openreview.net/forum?id $=$ JV8Ff0lgVV   \n[8] Y. Li, J. Guo, R. Wang, and J. Yan, \u201cT2t: From distribution learning in training to gradient search in testing for combinatorial optimization,\u201d in Advances in Neural Information Processing Systems, 2023.   \n[9] Y. Min, Y. Bai, and C. P. Gomes, \u201cUnsupervised learning for solving the travelling salesman problem,\u201d Advances in Neural Information Processing Systems, vol. 36, 2024.   \n[10] O. Vinyals, M. Fortunato, and N. Jaitly, \u201cPointer networks,\u201d Advances in neural information processing systems, vol. 28, 2015.   \n[11] B. Hudson, Q. Li, M. Malencia, and A. Prorok, \u201cGraph neural network guided local search for the traveling salesperson problem,\u201d in International Conference on Learning Representations, 2022. [Online]. Available: https://openreview.net/forum?id $\\left.\\vert=\\right.$ ar92oEosBIg   \n[12] Z.-H. Fu, K.-B. Qiu, and H. Zha, \u201cGeneralize a small pre-trained model to arbitrarily large tsp instances,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 8, 2021, pp. 7474\u20137482.   \n[13] F. Luo, X. Lin, F. Liu, Q. Zhang, and Z. Wang, \u201cNeural combinatorial optimization with heavy decoder: Toward large scale generalization,\u201d Advances in Neural Information Processing Systems, vol. 36, 2024.   \n[14] I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio, \u201cNeural combinatorial optimization with reinforcement learning,\u201d arXiv preprint arXiv:1611.09940, 2016.   \n[15] A. Hottung, Y.-D. Kwon, and K. Tierney, \u201cEfficient active search for combinatorial optimization problems,\u201d arXiv preprint arXiv:2106.05126, 2021.   \n[16] Y. Song, P. Dhariwal, M. Chen, and I. Sutskever, \u201cConsistency models,\u201d arXiv preprint arXiv:2303.01469, 2023.   \n[17] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, \u201cDeep unsupervised learning using nonequilibrium thermodynamics,\u201d in International Conference on Machine Learning, 2015, pp. 2256\u20132265.   \n[18] J. Austin, D. D. Johnson, J. Ho, D. Tarlow, and R. van den Berg, \u201cStructured denoising diffusion models in discrete state-spaces,\u201d Advances in Neural Information Processing Systems, vol. 34, pp. 17 981\u201317 993, 2021.   \n[19] E. Hoogeboom, D. Nielsen, P. Jaini, P. Forr\u00e9, and M. Welling, \u201cArgmax flows and multinomial diffusion: Learning categorical distributions,\u201d Advances in Neural Information Processing Systems, vol. 34, pp. 12 454\u201312 465, 2021.   \n[20] E. Khalil, H. Dai, Y. Zhang, B. Dilkina, and L. Song, \u201cLearning combinatorial optimization algorithms over graphs,\u201d Advances in neural information processing systems, vol. 30, 2017.   \n[21] A. Hottung, B. Bhandari, and K. Tierney, \u201cLearning a latent search space for routing problems using variational autoencoders,\u201d in International Conference on Learning Representations, 2021.   \n[22] S. Geisler, J. Sommer, J. Schuchardt, A. Bojchevski, and S. G\u00fcnnemann, \u201cGeneralization of neural combinatorial solvers through the lens of adversarial robustness,\u201d in International Conference on Learning Representations, 2022.   \n[23] X. Zheng, Y. Li, C. Fan, H. Wu, X. Song, and J. Yan, \u201cLearning plaintext-ciphertext cryptographic problems via anf-based sat instance representation,\u201d Advances in Neural Information Processing Systems, 2024.   \n[24] P. R. d O Costa, J. Rhuggenaath, Y. Zhang, and A. Akcay, \u201cLearning 2-opt heuristics for the traveling salesman problem via deep reinforcement learning,\u201d in Asian Conference on Machine Learning, 2020, pp. 465\u2013480.   \n[25] Y. Wu, W. Song, Z. Cao, J. Zhang, and A. Lim, \u201cLearning improvement heuristics for solving routing problems,\u201d IEEE transactions on neural networks and learning systems, vol. 33, no. 9, pp. 5057\u20135069, 2021.   \n[26] X. Chen and Y. Tian, \u201cLearning to perform local rewriting for combinatorial optimization,\u201d Advances in Neural Information Processing Systems, vol. 32, 2019.   \n[27] S. Li, Z. Yan, and C. Wu, \u201cLearning to delegate for large-scale vehicle routing,\u201d Advances in Neural Information Processing Systems, vol. 34, pp. 26 198\u201326 211, 2021.   \n[28] Q. Hou, J. Yang, Y. Su, X. Wang, and Y. Deng, \u201cGeneralize learned heuristics to solve largescale vehicle routing problems in real-time,\u201d in The Eleventh International Conference on Learning Representations, 2023.   \n[29] R. Cheng, X. Lyu, Y. Li, J. Ye, J. Hao, and J. Yan, \u201cThe policy-gradient placement and generative routing neural networks for chip design,\u201d Advances in Neural Information Processing Systems, vol. 35, pp. 26 350\u201326 362, 2022.   \n[30] X. Du, C. Wang, R. Zhong, and J. Yan, \u201cHubrouter: Learning global routing via hub generation and pin-hub connection,\u201d in Advances in Neural Information Processing Systems, 2023.   \n[31] D. Zhang, H. Dai, N. Malkin, A. Courville, Y. Bengio, and L. Pan, \u201cLet the flows tell: Solving graph combinatorial optimization problems with gflownets,\u201d arXiv preprint arXiv:2305.17010, 2023.   \n[32] Y. Song and S. Ermon, \u201cGenerative modeling by estimating gradients of the data distribution,\u201d Advances in neural information processing systems, vol. 32, 2019.   \n[33] J. Ho, A. Jain, and P. Abbeel, \u201cDenoising diffusion probabilistic models,\u201d Advances in Neural Information Processing Systems, vol. 33, pp. 6840\u20136851, 2020.   \n[34] J. Song, C. Meng, and S. Ermon, \u201cDenoising diffusion implicit models,\u201d arXiv preprint arXiv:2010.02502, 2020.   \n[35] Y. Song and S. Ermon, \u201cImproved techniques for training score-based generative models,\u201d Advances in neural information processing systems, vol. 33, pp. 12 438\u201312 448, 2020.   \n[36] A. Q. Nichol and P. Dhariwal, \u201cImproved denoising diffusion probabilistic models,\u201d in International Conference on Machine Learning, 2021, pp. 8162\u20138171.   \n[37] P. Dhariwal and A. Nichol, \u201cDiffusion models beat gans on image synthesis,\u201d Advances in Neural Information Processing Systems, vol. 34, pp. 8780\u20138794, 2021.   \n[38] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, \u201cScore-based generative modeling through stochastic differential equations,\u201d arXiv preprint arXiv:2011.13456, 2020.   \n[39] N. Karalias and A. Loukas, \u201cErdos goes neural: an unsupervised learning framework for combinatorial optimization on graphs,\u201d Advances in Neural Information Processing Systems, vol. 33, pp. 6659\u20136672, 2020.   \n[40] H. P. Wang, N. Wu, H. Yang, C. Hao, and P. Li, \u201cUnsupervised learning for combinatorial optimization with principled objective relaxation,\u201d in Advances in Neural Information Processing Systems, 2022.   \n[41] Y. LeCun, S. Chopra, R. Hadsell, M. Ranzato, and F. Huang, \u201cA tutorial on energy-based learning,\u201d Predicting structured data, vol. 1, no. 0, 2006.   \n[42] A. Graikos, N. Malkin, N. Jojic, and D. Samaras, \u201cDiffusion models as plug-and-play priors,\u201d arXiv preprint arXiv:2206.09012, 2022.   \n[43] S. Lin and B. W. Kernighan, \u201cAn effective heuristic algorithm for the traveling-salesman problem,\u201d Operations research, vol. 21, no. 2, pp. 498\u2013516, 1973.   \n[44] D. Applegate, R. Bixby, V. Chvatal, and W. Cook, \u201cConcorde tsp solver,\u201d 2006.   \n[45] K. Helsgaun, \u201cAn extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems,\u201d Roskilde: Roskilde University, pp. 24\u201350, 2017.   \n[46] G. A. Croes, \u201cA method for solving traveling-salesman problems,\u201d Operations research, vol. 6, no. 6, pp. 791\u2013812, 1958.   \n[47] X. Bresson and T. Laurent, \u201cThe transformer network for the traveling salesman problem,\u201d arXiv preprint arXiv:2103.03012, 2021.   \n[48] P. R. d. O. da Costa, J. Rhuggenaath, Y. Zhang, and A. Akcay, \u201cLearning 2-opt heuristics for the traveling salesman problem via deep reinforcement learning,\u201d arXiv preprint arXiv:2004.01608, 2020.   \n[49] Gurobi Optimization, \u201cGurobi optimizer reference manual,\u201d http://www.gurobi.com, 2020.   \n[50] M. Deudon, P. Cournut, A. Lacoste, Y. Adulyasak, and L.-M. Rousseau, \u201cLearning heuristics for the tsp by policy gradient,\u201d in International conference on the integration of constraint programming, artificial intelligence, and operations research. Springer, 2018, pp. 170\u2013181.   \n[51] S. Lamm, P. Sanders, C. Schulz, D. Strash, and R. F. Werneck, \u201cFinding near-optimal independent sets at scale,\u201d in 2016 Proceedings of the Eighteenth Workshop on Algorithm Engineering and Experiments (ALENEX). SIAM, 2016, pp. 138\u2013150.   \n[52] Z. Li, Q. Chen, and V. Koltun, \u201cCombinatorial optimization with graph convolutional networks and guided tree search,\u201d Advances in neural information processing systems, vol. 31, 2018.   \n[53] M. B\u00f6ther, O. Ki\u00dfig, M. Taraz, S. Cohen, K. Seidel, and T. Friedrich, \u201cWhat\u2019s wrong with deep learning in tree search for combinatorial optimization,\u201d arXiv preprint arXiv:2201.10494, 2022.   \n[54] S. Ahn, Y. Seo, and J. Shin, \u201cLearning what to defer for maximum independent sets,\u201d in International Conference on Machine Learning, 2020, pp. 134\u2013144.   \n[55] P. Erd\u02ddos, A. R\u00e9nyi et al., \u201cOn the evolution of random graphs,\u201d Publ. Math. Inst. Hung. Acad. Sci, vol. 5, no. 1, pp. 17\u201360, 1960.   \n[56] B. Hudson, Q. Li, M. Malencia, and A. Prorok, \u201cGraph neural network guided local search for the traveling salesperson problem,\u201d arXiv preprint arXiv:2110.05291, 2021.   \n[57] H. H. Hoos and T. St\u00fctzle, \u201cSatlib: An online resource for research on sat,\u201d Sat, vol. 2000, pp. 283\u2013292, 2000. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Training Details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Training Algorithm ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1: Input dataset $\\mathcal{D}$ , consistency model $f_{\\theta}(\\cdot,\\cdot)$ , initial model parameter $\\theta$ , learning rate $\\eta$ , consistency loss function $d(\\cdot,\\cdot)$ , inference steps $T$ , scaling factor $\\alpha$ , Bernoulli noise matrix $\\bar{Q}_{1,...,T}$ , weighting function $\\lambda(\\cdot)$ ", "page_idx": 13}, {"type": "text", "text": "L   \n3: repeat   \n4: Sample $\\mathbf{x}^{*}\\sim\\mathcal{D}$ , $t_{1}\\sim[1,T]$ , $t_{2}\\gets\\lceil\\alpha t_{1}\\rceil$   \n5: Sample $\\mathbf{z_{1}}\\sim\\mathbf{x}^{*}\\bar{Q}_{t_{1}}$ , $\\mathbf{z_{2}}\\sim\\mathbf{x}^{*}\\bar{Q}_{t_{2}}$   \n6: $\\mathcal{L}(\\theta)\\leftarrow\\lambda(t_{1})\\left(d\\left(\\mathbf{f}_{\\theta}\\left(\\mathbf{z}_{1},t_{1}\\right),\\delta(\\mathbf{z_{1}}-\\mathbf{x}^{*})\\right)\\right)+d\\left(\\mathbf{f}_{\\theta}\\left(\\mathbf{z}_{2},t_{2}\\right),\\delta(\\mathbf{z_{1}}-\\mathbf{x}^{*})\\right)$   \n7: $\\theta\\leftarrow\\theta-\\eta\\nabla_{\\theta}\\mathcal{L}(\\theta)$   \n8:   \n9: until convergence ", "page_idx": 13}, {"type": "text", "text": "A.2 Design Choices for Optimization Consistency ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We supplement the specific design choices of the optimization consistency models, and the listed hyperparameters correspond to those used in the algorithm presented in sections 4 and 5. ", "page_idx": 13}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/cf1c4681038a9557523941a21ed822c5fcd1e12a8186e747989a1004bd88c321.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/55c57e1decd164a7bbb60a679a8e91275750aad7553be656d330075aa0fe9423.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "B Supplementary Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "B.1 Results on TSP Real-World Data ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Results on TSPLIB 50-200. We evaluate our model trained with random 100-node problems on real-world TSPLIB instances with 50-200 nodes. The compared baselines include DIFUSCO [7], T2T [8], and baselines listed in [56]\u2019s Table 3. The hyperparameter settings of the compared baselines are: DIFUSCO: $\\mathrm{T}_{\\mathrm{s}}{=}50$ ; T2T: $\\mathrm{T}_{\\mathrm{s}}{=}50$ and $\\mathrm{T}_{\\mathrm{g}}{=}30$ ; Fast T2T (w/o GS): $\\mathrm{T_{s}}{=}10$ ; Fast T2T (w/ GS): ${\\mathrm{T}}_{\\mathrm{s}}{=}10$ and $\\mathrm{T_{g}}{=}10$ . The diffusion-based methods are compared in the same settings with greedy decoding and Two-Opt post-processing. For each instance, we normalize the coordinates to [0,1]. ", "page_idx": 13}, {"type": "text", "text": "Results on TSPLIB 50-200. We also supplement the results (optimality drop) of diffusion-based baselines and Fast T2T on large-scale TSPLIB benchmark instances with 200-1000 nodes. The models are trained on TSP-500 and inference with greedy decoding and Two-Opt post-processing. For each instance, we normalize the coordinates to [0,1]. ", "page_idx": 13}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/9530013bcbc5d35ec96649ef8b976f6c8aa45eaef5e624a8c96d478e8550ceae.jpg", "table_caption": ["Table 5: Solution quality for methods trained on random 100-node problems and evaluated on TSPLIB instances with 50-200 nodes. \u2217denotes results quoted from previous works [56]. "], "table_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/96e361def43dc1fa12fbc8777893d45185b0928a5442b176d7b215a2873de3ce.jpg", "table_caption": ["Table 6: Solution quality for methods trained on random 500-node problems and evaluated on TSPLIB instances with 200-1000 nodes. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "B.2 Results on MIS Real-World Data ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We supplement the results on the SATLIB real-world dataset [57] below. Initially, we did not include the SATLIB results because Fast T2T requires more data to learn the consistency mapping, which, due to its greater power, is more challenging to learn. Unfortunately, SATLIB does not provide sufficient data for this purpose. However, we still discover a positive results of Fast T2T outperforming previous baselines. ", "page_idx": 14}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/6f01e51cb526a04d09eed34352ecb1b7b1618ad903aca94960b5266bef273e67.jpg", "table_caption": ["Table 7: Results on MIS SATLIB dataset. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "B.3 Results for Generalization on TSP Datasets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Fig. 7 visualized the performance of DIFUSCO, T2T, and Fast T2T on different scales of TSP instances. The experimental settings are the same to Sec. 6.1. ", "page_idx": 15}, {"type": "image", "img_path": "xDrKZOZEOc/tmp/401d9d93d2f547a3749855d16d20786c76773900059636c7e1c0d619f427928a.jpg", "img_caption": ["Figure 7: Confusion matrix of four scales from TSP datasets. Models are trained on scales on the $y$ -axis, and tested with Greedy Decoding on scales on the $x$ -axis. Values in matrices are the corresponding drop compared to exact solvers. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "B.4 Results for Generalization on MIS ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We provide supplementary results for generalization results on the MIS problem below. We test the model trained on ER 700-800 with $p=0.15$ to different $p$ (the probability that each simple edge exists) and $n$ (graph size). We find that the generalization ability of Fast T2T is significantly better than that of the previous diffusion-based methods DIFUSCO and T2T regarding both solution quality and speed, e.g., in ER 350-400 Sampling setting Fast T2T achieves significant performance gain from $23.28\\%$ , $24\\mathrm{m}31\\mathrm{s}$ ) to $\\lvert11.45\\%$ , 1m1s). Results are presented in Tables 8 and 9. ", "page_idx": 15}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/fdd72eb11ff1c8a03dc733c6d4172db574da374330a1beb296571aaf2e391c73.jpg", "table_caption": ["Table 8: Generalization Performance from $p=0.15$ to $p=0.2$ , $p=0.3$ , and $p=0.4$ "], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/4d7069250d75ef5e78c8d13b681969860a5008895b500fea4513789b45f4435e.jpg", "table_caption": ["Table 9: Generalization Performance from ER 700-800 to ER 350-400 and 1400-1600. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "We also supplement cross-dataset generalization results between RB graphs and ER graphs in Table 10. As seen, Fast T2T outperforms previous diffusion-based counterparts by a clear margin, e.g., in \"Train:ER; Test:RB\" \"Sampling\" setting, Fast T2T achieves significant performance gain from the previous $23.24\\%$ , $30\\mathrm{m}13\\mathrm{s}$ ) to $(9.10\\%$ , $4\\mathrm{m}20\\mathrm{s}$ ). ", "page_idx": 16}, {"type": "text", "text": "C Experimental Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1 Computational Resources. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Test evaluations on TSP-50/100 and MIS are performed on a single GPU of NVIDIA RTX 4090, and evaluations on TSP-500/1000 are performed on a single GPU of NVIDIA Telsla A100. ", "page_idx": 16}, {"type": "text", "text": "C.2 Graph Sparsification. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "For large-scale TSP problems, we follow [7, 8] to employ sparse graphs, as sparsified by constraining each node to connect to only its $k$ nearest neighbors, determined by Euclidean distances. For TSP-500, ", "page_idx": 16}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/acd86a60ca1c83fc4d90597d3fc8c8159afa32f0f3a925dcee1f5a650825604c.jpg", "table_caption": ["Table 10: Performance Comparison Between Greedy and Sampling Methods (Train:ER; Test:RB). "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "we set $k=50$ , and for TSP-1000, $k=100$ . This strategy prevents the exponential increase in edges typical in dense graphs as node count rises. ", "page_idx": 17}, {"type": "text", "text": "C.3 Datasets. ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The reference solutions for TSP-50/100 are labeled by the Concorde exact solver [44] and the solutions for TSP-500/1000 are labeled by the LKH-3 heuristic solver [45]. The test set for TSP50/100 is taken from [2, 3] with 1280 instances and the test set for TSP-500/1000 is from [12] with 128 instances for the fair comparison. ", "page_idx": 17}, {"type": "text", "text": "The reference solutions for both RB graphs and ER graphs are labeled with KaMIS [51]. For RB graphs, we randomly generate 90000 instances for the training set and 500 instances for the test set. For ER graphs, we randomly generate 163840 instaces for the training set and the test is from [6]. ", "page_idx": 17}, {"type": "text", "text": "C.4 Training Resource Requirement ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We outline the offline training resource requirements of the Fast T2T framework in Table 11, with computations conducted on A100 GPUs. For contextual comparison, AM [2] necessitates 128M instances generated on-the-fly to train TSP-100, consuming 45.8 hours on 2 1080Ti GPUs. POMO [4] mandates 200M instances generated dynamically for TSP-100 training, entailing approximately one week on a single Titan RTX. Sym-NCO [5], an extension of POMO, requires approximately two weeks on a single A100 for training. Additionally, Sym-NCO [5] built upon AM [2] necessitates three days on 4 A100 GPUs. Compared with DIFUSCO [7], Fast T2T necessitates approximately double training time and GPU memory under the same settings, because our consistency training method requires forward twice for each training instance, leading to more time and memory consumption. ", "page_idx": 17}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/57cd526a5832886307832660e8e386d9668273a9cbae0193de5a0ecf3680c45e.jpg", "table_caption": ["Table 11: Details about the training resource requirement of Fast T2T framework. The results are calculated on A100 GPUs. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "C.5 Hyperparamters ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We conduct experiments on TSP and MIS benchmarks with our methods and compare the performance with prevalent learning-based solvers, heuristics, and exact solvers. The noise degree $\\alpha$ associated with each benchmark is listed in Table. 12. ", "page_idx": 17}, {"type": "table", "img_path": "xDrKZOZEOc/tmp/3510bef2a2251f26ca5b170e44e39a98359ef48631afa5d110139d0381a70912.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "C.6 Baseline Settings ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.6.1 TSP Benchmarks ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "TSP-50/100: In the evaluation of TSP-50 and TSP-100, we compare our proposed Fast T2T against 11 baseline methods. These baselines include one exact solver, Concorde [44], two heuristic solvers - 2OPT [46] and Farthest Insertion - and seven learning-based solvers: AM [2], GCN [3], Transformer [47], POMO [4], Sym-NCO [5], Image Diffusion [42], DIFUSCO [7], and T2T [8]. Our post-processing involves greedy sampling and 2OPT refinement. To ensure equitable comparisons in terms of computational effort, we limit the number of inference steps for DIFUSCO to 100, and for T2T, we set the number of inference steps and guided search steps to 50 and 30, respectively. ", "page_idx": 18}, {"type": "text", "text": "TSP-500/1000: In the evaluation of TSP-500 and TSP-1000, our method is compared with 2 exact solvers, Concorde [44] and Gurobi [49], 2 heuristic solvers, LKH-3 [45] and Farthest Insertion, and 6 learning-based methods, including EAN [50], AM [2], GCN [3], POMO $^+$ EAS [15], DIMES [6], and DIFUSCO [7]. These learning-based methods can be further categorized into supervised learning (SL) and reinforcement learning (RL). Post-processing techniques employed encompass greedy sampling (Grdy, G), multiple sampling (S), 2OPT refinement (2OPT), beam search (BS), active search (AS), and combinations thereof. To ensure fair comparisons in terms of computational resources, we cap the number of inference steps for DIFUSCO at 100. Additionally, for T2T, we fix the number of inference steps and guided search steps at 50 and 30, respectively. ", "page_idx": 18}, {"type": "text", "text": "C.6.2 MIS Benchmarks ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We assess our method on two distinct benchmarks: RB-[200-300] and ER-[700-800]. Across both benchmarks, we compare the performance of Fast T2T against one exact solver, Gurobi [49], one heuristic solver, KaMIS [51], and 5 learning-based frameworks: Intel [52], DGL [52], LwD [54], DIMES [6], and DIFUSCO [7]. Post-processing strategies encompass greedy sampling (Grdy) and tree search (TS). Specifically, on both benchmarks, we set the number of inference steps at 100 for DIFUSCO. For T2T, we set the number of inference steps and guided search steps at 50 and 30, respectively. ", "page_idx": 18}, {"type": "text", "text": "D Network Architecture Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "D.1 Input Embedding Layer ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Given node vector $\\boldsymbol{x}\\in\\mathbb{R}^{N\\times2}$ , weighted edge vector $e\\in\\mathbb{R}^{E}$ , denoising timestep $t\\in\\{\\tau_{1},\\dots,\\tau_{M}\\}$ , where $N$ denotes the number of nodes in the graph, and $E$ denotes the number of edges, we compute the sinusoidal features of each input element respectively: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{x}_{i}=\\mathrm{concat}(\\widetilde{x}_{i,0},\\widetilde{x}_{i,1})}\\\\ &{\\widetilde{x}_{i,j}=\\mathrm{concat}\\left(\\sin\\frac{x_{i,j}}{T^{\\frac{0}{d}}},\\cos\\frac{x_{i,j}}{T^{\\frac{0}{d}}},\\sin\\frac{x_{i,j}}{T^{\\frac{2}{d}}},\\cos\\frac{x_{i,j}}{T^{\\frac{2}{d}}},\\ldots,\\sin\\frac{x_{i,j}}{T^{\\frac{d}{d}}},\\cos\\frac{x_{i,j}}{T^{\\frac{d}{d}}}\\right)}\\\\ &{\\widetilde{e}_{i}=\\mathrm{concat}\\left(\\sin\\frac{e_{i}}{T^{\\frac{0}{d}}},\\cos\\frac{e_{i}}{T^{\\frac{0}{d}}},\\sin\\frac{e_{i}}{T^{\\frac{2}{d}}},\\cos\\frac{e_{i}}{T^{\\frac{2}{d}}},\\ldots,\\sin\\frac{e_{i}}{T^{\\frac{d}{d}}},\\cos\\frac{e_{i}}{T^{\\frac{d}{d}}}\\right)}\\\\ &{\\widetilde{t}=\\mathrm{concat}\\left(\\sin\\frac{t}{T^{\\frac{0}{d}}},\\cos\\frac{t}{T^{\\frac{0}{d}}},\\sin\\frac{t}{T^{\\frac{2}{d}}},\\cos\\frac{t}{T^{\\frac{2}{d}}},\\ldots,\\sin\\frac{t}{T^{\\frac{d}{d}}},\\cos\\frac{t}{T^{\\frac{d}{d}}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $d$ is the embedding dimension, $T$ is a large number (usually selected as 10000), concat(\u00b7) denotes concatenation. ", "page_idx": 18}, {"type": "text", "text": "Next, we compute the input features of the graph convolution layer: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x_{i}^{0}=W_{1}^{0}\\tilde{x}_{i}}\\\\ &{e_{i}^{0}=W_{2}^{0}\\tilde{e}_{i}}\\\\ &{t^{0}=W_{4}^{0}(\\operatorname{ReLU}(W_{3}^{0}\\tilde{t}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $t^{0}\\in\\mathbb{R}^{d_{t}}$ , $d_{t}$ is the time feature embedding dimension. Specifically, for TSP, the embedding input edge vector $e$ is a weighted adjacency matrix, which represents the distance between different nodes, and $e^{0}$ is computed as above. For MIS, we initialize $e^{0}$ to a zero matrix $0^{E\\times d}$ . ", "page_idx": 19}, {"type": "text", "text": "D.2 Graph Convolution Layer ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Following [3], the cross-layer convolution operation is formulated as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x_{i}^{l+1}=x_{i}^{l}+\\mathrm{ReLU}(\\mathrm{BN}(W_{1}^{l}x_{i}^{l}+\\displaystyle\\sum_{j\\sim i}\\eta_{i j}^{l}\\odot W_{2}^{l}x_{j}^{l}))}\\\\ &{e_{i j}^{l+1}=e_{i}^{l}+\\mathrm{ReLU}(\\mathrm{BN}(W_{3}^{l}e_{i j}^{l}+W_{4}^{l}x_{i}^{l}+W_{5}^{l}x_{j}^{l}))}\\\\ &{\\quad\\eta_{i j}^{l}=\\displaystyle\\frac{\\sigma(e_{i j}^{l})}{\\sum_{j^{\\prime}\\sim i}\\sigma(e_{i j^{\\prime}}^{l})+\\epsilon}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\boldsymbol{x}_{i}^{l}$ and $e_{i j}^{l}$ denote the node feature vector and edge feature vector at layer $l$ $,W_{1},\\cdots,W_{5}\\in$ Rh\u00d7h denote the model weights, \u03b7ilj denotes the dense attention map. The convolution operation integrates the edge feature to accommodate the significance of edges in routing problems. ", "page_idx": 19}, {"type": "text", "text": "For TSP, we aggregate the timestep feature with the edge convolutional feature and reformulate the update for edge features as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\ne_{i j}^{l+1}=e_{i j}^{l}+\\mathrm{ReLU}(\\mathrm{BN}(W_{3}^{l}e_{i j}^{l}+W_{4}^{l}x_{i}^{l}+W_{5}^{l}x_{j}^{l}))+W_{6}^{l}(\\mathrm{ReLU}(t^{0}))\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For MIS, we aggregate the timestep feature with the node convolutional feature and reformulate the update for node features as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\nx_{i}^{l+1}=x_{i}^{l}+\\mathrm{ReLU}(\\mathrm{BN}(W_{1}^{l}x_{i}^{l}+\\sum_{j\\sim i}\\eta_{i j}^{l}\\odot W_{2}^{l}x_{j}^{l}))+W_{6}^{l}(\\mathrm{ReLU}(t^{0}))\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "D.3 Output Layer ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The prediction of the edge heatmap in TSP and node heatmap in MIS is as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{e_{i,j}=\\operatorname{Softmax}(\\operatorname{norm}(\\operatorname{ReLU}(W_{e}e_{i,j}^{L})))}\\\\ {x_{i}=\\operatorname{Softmax}(\\operatorname{norm}(\\operatorname{ReLU}(W_{n}x_{i}^{L})))}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $L$ is the number of GCN layers and norm is layer normalization. ", "page_idx": 19}, {"type": "text", "text": "D.4 Hyper-parameters ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For both TSP and MIS tasks, we construct a 12-layer GCN derived above. We set the node, edge, and timestep embedding dimension $d=256$ , 128 for TSP and MIS tasks, respectively. ", "page_idx": 19}, {"type": "text", "text": "E Limitations and Broader Impacts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "As the scale increases, our method\u2019s improvement in solving speed compared to diffusion-based methods will experience a certain degree of attenuation. This is because, with the expansion of the scale, the proportion of time required for relevant serial processing becomes larger, while the proportion of time for model inference is squeezed, resulting in a weakening of the speed improvement in the overall pipeline. This limitation can be addressed by combining our model with more efficient traditional solving strategies, which we leave for future work. Since the consistency model requires two inference predictions with different noise levels during training, it requires twice the training cost of the original diffusion model. However, this overhead on training is offline, and the consistency model is much more efficient than diffusion at inference time. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Our work provides a more powerful and efficient backbone for neural combinatorial optimization, enabling significant performance improvement and versatility, making its application feasible across various solving frameworks. This work can be integrated into existing and future research in this field, driving progress in related studies. ", "page_idx": 20}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The abstract and introduction explicitly state the claims made, including the contributions made in the paper (Sec. 1). The claims match the experimental results in Sec. 6. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 21}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We discuss the limitations in Appendix E. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 21}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The theoretical derivation of this paper has been given in Sec. 5, and there are no additional theorems needed to be proved. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 22}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The experimental details are in Sec. 6 and Append. B, C. We will make our source code publicly available upon acceptance. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No] ", "page_idx": 23}, {"type": "text", "text": "Justification: The source code will be made publicly available upon acceptance. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 23}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The experimental details are in Sec. 6 and Append. B, C. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 23}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No] ", "page_idx": 23}, {"type": "text", "text": "Justification: we follow the setting of previous works to report the average solution quality over 128 or 1,280 instances in Sec. 6. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provide the testing GPUs and time-consumption of our methods as well as previous works in Sec. 6. The training resource requirement is in Appendix. C ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 24}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 24}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We discuss the borader impacts in Appendix. E. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 25}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 25}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The original papers that introduce models and datasets used in the paper are cited in Sec. 6. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: Currently, the paper does not release new assets. Our source code will be released upon the acceptance of the paper with comprehensive documents. As parts of the documents, we formally describe our proposed model and the corresponding details in Sec. 4 and 5. The training details are presented in Appendix. C. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 26}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 26}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not incur such risks. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]