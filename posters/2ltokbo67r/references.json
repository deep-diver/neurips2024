{"references": [{"fullname_first_author": "Alekh Agarwal", "paper_title": "Taming the monster: A fast and simple algorithm for contextual bandits", "publication_date": "2014-00-00", "reason": "This paper is foundational for contextual bandits with general function classes, which is the core focus of the current paper."}, {"fullname_first_author": "Dylan Foster", "paper_title": "Beyond UCB: Optimal and efficient contextual bandits with regression oracles", "publication_date": "2020-00-00", "reason": "This paper introduces the concept of reducing contextual bandits to regression oracles, a key technique used in the current paper's algorithms."}, {"fullname_first_author": "David Simchi-Levi", "paper_title": "Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability", "publication_date": "2021-00-00", "reason": "This paper proposes a novel algorithm for contextual bandits with improved regret bounds, inspiring some of the current paper's strategies."}, {"fullname_first_author": "Dylan J Foster", "paper_title": "Efficient first-order contextual bandits: Prediction, allocation, and triangular discrimination", "publication_date": "2021-00-00", "reason": "This paper provides key theoretical results on contextual bandits with first-order optimization, which are used in the current paper's analysis."}, {"fullname_first_author": "Tong Zhang", "paper_title": "Feel-good Thompson Sampling for contextual bandits and reinforcement learning", "publication_date": "2022-00-00", "reason": "This paper introduces the Feel-Good Thompson Sampling algorithm, which is adapted in the current paper for the contextual MNL bandit setting."}]}