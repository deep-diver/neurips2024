[{"figure_path": "MuPlJ9fT4b/tables/tables_9_1.jpg", "caption": "Table 1: Inputs and outputs for learning different PDEs. See Table 3 for resolutions. \"NS\": Navier-Stokes. \u201cRD\": Reaction-Diffusion.", "description": "This table summarizes the input and output data used for training neural operators on various partial differential equations (PDEs).  It shows the input features (e.g., source function, diffusion coefficients, vorticity, spatiotemporal coordinates) and the corresponding output targets (e.g., potential field, wave function, velocity, pressure) for each PDE.  The table also provides abbreviations for the PDE names: NS for Navier-Stokes and RD for Reaction-Diffusion.  Table 3, referenced in this caption, provides the resolution details of the data.", "section": "B Detailed Experiment Settings"}, {"figure_path": "MuPlJ9fT4b/tables/tables_17_1.jpg", "caption": "Table 1: Inputs and outputs for learning different PDEs. See Table 3 for resolutions. \"NS\": Navier-Stokes. \u201cRD\u201d: Reaction-Diffusion.", "description": "This table provides a summary of the input and output data used for training neural operators on various partial differential equations (PDEs).  It shows the different types of PDEs considered (Poisson, Helmholtz, Navier-Stokes, and Reaction-Diffusion), the input features used for each PDE (e.g., source function, diffusion coefficients, vorticity, velocity, pressure), the shape of the input data, and the corresponding target outputs that the model aims to predict. Note that the table refers to Table 3 for the spatial resolution (H x W) of the data which is not provided in this table itself.", "section": "B Detailed Experiment Settings"}, {"figure_path": "MuPlJ9fT4b/tables/tables_17_2.jpg", "caption": "Table 2: Ranges of physical parameters (integers) for unsupervised pretraining, training (fine-tuning), and out-of-distribution (OOD) inference.", "description": "This table shows the ranges of physical parameters used for different stages of the experiment. The parameters include the diffusion coefficient for Poisson's equation, the wavenumber for the Helmholtz equation, and the Reynolds number for the Navier-Stokes equation.  The ranges are different for unsupervised pretraining, fine-tuning/training, and out-of-distribution testing, reflecting the strategy used to progressively refine the model's ability to handle different levels of data availability and complexity.", "section": "B Detailed Experiment Settings"}, {"figure_path": "MuPlJ9fT4b/tables/tables_18_1.jpg", "caption": "Table 3: Hyperparameters for pretraining and training/fine-tuning. \u201cN.S.\u201d: 2D Incompressible Navier-Stokes. \"DAdapt\": adaptive learning rate by D-adaptation [10]. \"ns\": total number of simulated training samples. A batch size of \"min(32, ns)\" is because the total number of training samples might be fewer than 32.", "description": "This table shows the hyperparameters used for both pretraining and training/fine-tuning stages for various PDEs.  It specifies the number of samples, learning rate, batch size, resolution, epochs/iterations, and rollouts used for each PDE and stage.  Note the use of D-adaptation for the learning rate in some cases and the dynamic batch size based on the number of samples.", "section": "B Detailed Experiment Settings"}, {"figure_path": "MuPlJ9fT4b/tables/tables_18_2.jpg", "caption": "Table 4: Simulation time costs on 2D Incompressible Navier-Stokes (\"N.S.\") on PINO Dataset [46] and Reaction-Diffusion (\"R.D.\") on PDE-Bench [74]. \"Re\": Reynolds number. \"Du, Dv\": diffusion coefficients. N: number of samples. T: temporal resolution. H \u00d7 W: spatial resolution. C: input channels (1 for the vorticity in N.S., 2 for velocities u, v in R.D.).", "description": "This table compares the computation time required to generate unlabeled PDE data only versus generating both unlabeled data and solutions for two different PDEs: 2D incompressible Navier-Stokes and Reaction-Diffusion.  It highlights the significant cost savings achievable by using only unlabeled data for unsupervised pretraining, making the approach more computationally feasible.", "section": "C Examples of Simulation Costs"}, {"figure_path": "MuPlJ9fT4b/tables/tables_21_1.jpg", "caption": "Table 5: Best choice of mask ratio and blur sigma for pretraining on Poisson equation.", "description": "This table shows the best hyperparameter choices for mask ratio and blur sigma used during the pretraining phase of the Poisson equation, categorized by the number of training samples.  The optimal values for these hyperparameters depend on the amount of data available.", "section": "J.1 Magnitude of Perturbations during Pretraining"}, {"figure_path": "MuPlJ9fT4b/tables/tables_21_2.jpg", "caption": "Table 6: Best choice of mask ratio and blur sigma for pretraining on Helmholtz equation.", "description": "This table shows the best hyperparameter settings for the Helmholtz equation in the context of unsupervised pretraining.  The hyperparameters considered are the mask ratio (portion of input data masked) and blur sigma (standard deviation of the Gaussian blur applied to the masked regions). The table demonstrates that the optimal hyperparameters depend on the amount of training data available.", "section": "J.1 Magnitude of Perturbations during Pretraining"}, {"figure_path": "MuPlJ9fT4b/tables/tables_22_1.jpg", "caption": "Table 7: Best choice of mask ratio and blur sigma for pretraining on 2D Diffusion-Reaction equation.", "description": "This table shows the best hyperparameter settings (mask ratio and blur sigma) for pretraining a 2D Diffusion-Reaction equation model using different numbers of training samples.  The optimal settings vary depending on the dataset size, suggesting that stronger perturbations (higher masking ratio and blur sigma) are beneficial when training data is scarce, while milder perturbations suffice with larger datasets.", "section": "J.1 Magnitude of Perturbations during Pretraining"}, {"figure_path": "MuPlJ9fT4b/tables/tables_22_2.jpg", "caption": "Table 8: Best choice of mask ratio and blur sigma for pretraining on 2D incompressible Navier-Stokes.", "description": "This table shows the best hyperparameter choices for mask ratio and blur sigma during the pretraining phase on the 2D incompressible Navier-Stokes equation, categorized by the number of training samples.  It demonstrates that the optimal hyperparameters depend on the amount of data available.", "section": "J.1 Magnitude of Perturbations during Pretraining"}, {"figure_path": "MuPlJ9fT4b/tables/tables_22_3.jpg", "caption": "Table 9: More unlabeled PDE data improve the quality of pretraining. FNO on 2D incompressible Navier-Stokes, pretrained with mask ratio as 0.7.", "description": "This table shows the impact of the number of unlabeled PDE data samples used for pretraining on the relative l2 error of the FNO model for the 2D incompressible Navier-Stokes equation.  It demonstrates that increasing the number of pretraining samples leads to a reduction in the relative l2 error, suggesting that more data improves the quality of the pretrained model.", "section": "J More Ablation Studies"}]