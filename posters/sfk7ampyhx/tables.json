[{"figure_path": "SFk7AMpyhx/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative evaluation on 4D generation.", "description": "This table presents a quantitative comparison of different methods for 4D generation, focusing on image quality, temporal consistency, video quality, and spatial consistency.  The metrics used are CLIP-I (higher is better), CLIP-C (higher is better), FVD (lower is better), LPIPS (lower is better), and PSNR (higher is better).  The results show that the proposed method ('Ours') outperforms existing methods in most of the metrics.", "section": "4 Experiments"}, {"figure_path": "SFk7AMpyhx/tables/tables_9_1.jpg", "caption": "Table 2: Quantitative evaluation on multi-view video generation. Here, we employ Consistent4D test dataset to evaluate 4DM and ImageDream. 'Spa. Con.' and 'Tem. Con.' refer to spatial consistency and temporal consistency, respectively.", "description": "This table presents a quantitative comparison of multi-view video generation results between the proposed 4DM model, the ImageDream model, and the results obtained when using the entire Objaverse dataset to train 4DM.  The metrics used for comparison include CLIP-I (image quality), CLIP-C (temporal consistency), FVD (video quality), LPIPS (spatial consistency), and PSNR (spatial consistency). The table highlights the superior performance of the proposed 4DM model in generating high-quality, spatially and temporally consistent multi-view videos. ", "section": "4.2 Multi-view Video Generation"}, {"figure_path": "SFk7AMpyhx/tables/tables_14_1.jpg", "caption": "Table 3: Hash encoding parameters of  Pxyz and Pxyzt", "description": "This table lists the hyperparameters used for the hash encoding of the spatial and spatio-temporal features in the dynamic NeRF representation.  Specifically, it details the number of levels in the multiresolution hash table, the size of each hash table, the number of feature dimensions per level, and the coarsest and finest resolutions used.", "section": "A.1 More Implementation Details"}]