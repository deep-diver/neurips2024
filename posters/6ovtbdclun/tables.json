[{"figure_path": "6OvTbDClUn/tables/tables_6_1.jpg", "caption": "Table 1: The statistics of false positive and false negative ratios (%) with respective to different datasets and \u03b7 in the experiments.", "description": "This table shows the ratio of false positives and false negatives for five different datasets used in the experiments.  The false positive ratio (FP) is varied (\u03b7 = 0.0, 0.2, 0.5, 0.8), while the false negative ratio (FN) remains constant for each dataset.  These ratios represent the noise level in the cross-view correspondence data used for training the model, simulating the dual noisy correspondence (DNC) problem.", "section": "4 Experiments"}, {"figure_path": "6OvTbDClUn/tables/tables_7_1.jpg", "caption": "Table 2: Clustering performance comparisons on five widely-used multi-view datasets. The results are the mean of five individual runs. The best and second best results are shown in bold and underline, respectively.", "description": "This table presents a comparison of clustering performance across five different multi-view datasets using various methods.  The performance metrics used are Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI).  The table shows results for different false positive (FP) ratios (0%, 20%, 50%, 80%), illustrating the robustness of various methods to noise in the data.  The best and second-best performing methods for each dataset and metric are highlighted.", "section": "4.2 Comparison with State of the Arts (Performance Superiority)"}, {"figure_path": "6OvTbDClUn/tables/tables_7_2.jpg", "caption": "Table 2: Clustering performance comparisons on five widely-used multi-view datasets. The results are the mean of five individual runs. The best and second best results are shown in bold and underline, respectively.", "description": "This table presents a comparison of clustering performance across five benchmark datasets using nine different multi-view clustering methods, including the proposed CANDY method.  It shows the Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI) for each method at different false positive ratios (0%, 20%, 50%, and 80%). The best and second-best performing methods are highlighted for each metric and dataset.", "section": "4.2 Comparison with State of the Arts (Performance Superiority)"}, {"figure_path": "6OvTbDClUn/tables/tables_8_1.jpg", "caption": "Table 2: Clustering performance comparisons on five widely-used multi-view datasets. The results are the mean of five individual runs. The best and second best results are shown in bold and underline, respectively.", "description": "This table presents a comparison of the clustering performance of CANDY against eight other state-of-the-art multi-view clustering methods across five benchmark datasets.  The comparison uses three metrics: Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI). The results are averaged over five independent runs.  The table is organized to show results for different false positive ratios (FP Ratio) in the data, demonstrating CANDY's robustness to noisy data.", "section": "4.2 Comparison with State of the Arts (Performance Superiority)"}, {"figure_path": "6OvTbDClUn/tables/tables_9_1.jpg", "caption": "Table 2: Clustering performance comparisons on five widely-used multi-view datasets. The results are the mean of five individual runs. The best and second best results are shown in bold and underline, respectively.", "description": "This table compares the performance of CANDY against 8 state-of-the-art multi-view clustering methods across five benchmark datasets.  The comparison uses three metrics: ACC (accuracy), NMI (normalized mutual information), and ARI (adjusted rand index).  Results are shown for different false positive (FP) ratios (0%, 20%, 50%, 80%) to demonstrate CANDY's robustness to noise in positive correspondence.  The best and second-best results for each metric are highlighted.", "section": "4.2 Comparison with State of the Arts (Performance Superiority)"}]