[{"figure_path": "eYNYnYle41/figures/figures_1_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the dimensionality reduction results of several parametric and non-parametric methods on the MNIST dataset.  The top row shows the results of non-parametric methods (Info-NC-t-SNE, NCVis, UMAP, PaCMAP), while the bottom row shows the results of their parametric counterparts. The figure demonstrates that parametric methods struggle to preserve the local structure of the dataset compared to their non-parametric counterparts. The authors' proposed method, ParamRepulsor, is shown in the bottom-right corner and achieves superior local structure preservation.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_4_1.jpg", "caption": "Figure 2: Embeddings of the MNIST [15] dataset generated by various DR methods with different numbers of hidden layers: 0 (Linear), 1, 2, or 3, or non-parametric variant. See Section 5.1 for details of SVM Acc. It is helpful to envision these images in black and white (without labels) to see when clusters would be difficult to visually separate. More datasets/methods can be found in App. C.", "description": "This figure shows the results of dimensionality reduction on the MNIST dataset using various methods.  It compares parametric methods (with varying numbers of hidden layers in a neural network) against a non-parametric method.  The SVM accuracy (a measure of local structure preservation) is provided for each embedding. The visualization highlights how parametric methods struggle to preserve the distinct separation of clusters compared to the non-parametric approach, particularly with fewer hidden layers.", "section": "3 Effect of Parametrization on DR Results"}, {"figure_path": "eYNYnYle41/figures/figures_4_2.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset. The top row shows the results of non-parametric methods, while the bottom row shows the results of parametric methods. The figure demonstrates that parametric methods fail to preserve the local structure of the dataset as well as non-parametric methods. The authors' proposed method, ParamRepulsor, addresses this issue and achieves state-of-the-art performance in local structure preservation.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_6_1.jpg", "caption": "Figure 4: Effect of Hard Negative Mining on MNIST. We progressively increase the coefficient of the repulsive force applied to MN hard negatives. Close clusters are circled. Results indicate that Hard Negative Mining alone effectively preserves local structure while maintaining relative proximities.", "description": "This figure shows the impact of applying Hard Negative Mining (HNM) to the ParamRepulsor algorithm. The MNIST dataset is used.  Different plots show the resulting embeddings with varying coefficients applied to the repulsive force of mid-near pairs, which are considered hard negatives.  The circles highlight how clusters are separated better when the coefficient increases, indicating improved local structure preservation while still maintaining the general global structure.", "section": "4 ParamRepulsor"}, {"figure_path": "eYNYnYle41/figures/figures_13_1.jpg", "caption": "Figure 5: Effect of the number of layers on the MNIST dataset. As a supplement to Fig. 2, we extend the number of layers beyond three for Into-NC-t-SNE, UMAP and PaCMAP. Here, the local metric represents 10-NN accuracy, while the global metric denotes the random triplet preservation. Results show that further increasing the number of layers beyond increasing the number of layers beyond three yields only diminishing and negligible improvements in local structure on all three methods.", "description": "This figure shows an experiment on the MNIST dataset to test the effect of increasing the number of hidden layers in the neural network projector for three different dimensionality reduction methods (Info-NC-t-SNE, UMAP, and PaCMAP).  The results indicate that increasing the number of layers beyond three provides minimal improvement in local structure preservation, while the global structure remains largely unaffected.", "section": "A Discussion on the Depth of Neural Network Projector"}, {"figure_path": "eYNYnYle41/figures/figures_14_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of different dimensionality reduction (DR) methods on the MNIST dataset.  The top row shows the results of several non-parametric methods, while the bottom row shows the results of their parametric counterparts. The results show that the parametric methods fail to preserve the local structure of the data, meaning they struggle to accurately represent the relationships between nearby data points.  In contrast, the authors' new method, ParamRepulsor, is shown to significantly improve the preservation of local structure in parametric DR methods, suggesting that their improvements address a significant weakness in existing methods. Hard Negative Mining is highlighted as a key component of their improved approach.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_15_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset. The top row shows the results of non-parametric methods, which preserve local structure well.  The bottom row displays the results of parametric methods, which fail to preserve the local structure, showing blurred cluster boundaries.  The authors' proposed method, ParamRepulsor, is shown to significantly improve local structure preservation compared to other parametric approaches, effectively resolving this shortcoming through a technique called Hard Negative Mining.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_16_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of several dimensionality reduction (DR) methods on the MNIST dataset. The top row shows the results of non-parametric methods, while the bottom row shows the results of parametric methods. The figure demonstrates that parametric methods fail to preserve the local structure of the dataset as well as non-parametric methods. The authors introduce a new parametric method called ParamRepulsor that addresses this issue by incorporating Hard Negative Mining.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_17_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of parametric and non-parametric dimensionality reduction methods on the MNIST dataset. The top row shows the results of several non-parametric methods, while the bottom row shows the results of their parametric counterparts.  It demonstrates that parametric methods struggle to preserve the local structure of the data compared to non-parametric methods. The authors' proposed method, ParamRepulsor, significantly improves the local structure preservation in parametric methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_18_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of parametric and non-parametric dimensionality reduction methods on the MNIST dataset.  The top row shows the results of several well-known non-parametric methods (Info-NC-t-SNE, NCVis, UMAP, PaCMAP), while the bottom row shows the results of their parametric counterparts.  The visualization clearly demonstrates that the parametric methods fail to preserve the local structure of the data (the distinct clusters of handwritten digits are blurred together), whereas the non-parametric methods maintain better local structure preservation.  The authors' proposed method, ParamRepulsor, is shown in the bottom-right, successfully addressing the local structure preservation issue present in other parametric methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_19_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset. The top row shows non-parametric methods, while the bottom row shows parametric methods.  The results demonstrate that parametric methods fail to preserve the local structure of the data as well as the non-parametric methods.  ParamRepulsor, a new method developed by the authors, is shown to significantly improve local structure preservation in parametric dimensionality reduction methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_20_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of several dimensionality reduction methods on the MNIST dataset. The top row shows the results of non-parametric methods (t-SNE, NCVis, UMAP, PaCMAP), while the bottom row shows the results of their parametric counterparts.  The results demonstrate that parametric methods struggle to preserve the local structure of the data, while the proposed method (ParamRepulsor) improves this significantly by incorporating Hard Negative Mining.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_21_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset.  The top row shows results from non-parametric methods (t-SNE, NCVis, UMAP, PaCMAP), demonstrating good preservation of local data structure. The bottom row shows results from parametric versions of the same algorithms, revealing a significant loss of local structure.  The last column displays the results of the authors' proposed method, ParamRepulsor, which shows improved local structure preservation compared to other parametric approaches.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_22_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the dimensionality reduction results of several parametric and non-parametric methods on the MNIST dataset. It shows that non-parametric methods (top row) preserve local data structure better than parametric methods (bottom row). The authors' proposed method, ParamRepulsor, significantly improves the local structure preservation of the parametric approach. ", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_23_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares dimensionality reduction results on the MNIST dataset using various parametric and non-parametric methods. The top row shows the results of non-parametric methods, which effectively preserve local structure, while the bottom row shows the results of parametric methods, which fail to preserve local structure.  The authors' proposed method, ParamRepulsor, is shown in the bottom right and addresses the shortcomings of other parametric methods by preserving both global and local structure.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_24_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset. The top row shows the results of non-parametric methods, while the bottom row shows the results of parametric methods. The figure demonstrates that parametric methods struggle to preserve the local structure of the data, while non-parametric methods are much better at preserving this structure. The authors' new method, ParamRepulsor, is shown to significantly improve the performance of parametric methods in preserving local structure.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_25_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of different dimensionality reduction methods on the MNIST dataset.  The top row shows the results of several non-parametric methods, demonstrating good preservation of local data structure (clusters). The bottom row shows the results of their parametric counterparts, revealing a significant loss of local structure, resulting in blurry clusters.  The final column showcases the results of the authors' proposed method, ParamRepulsor, which successfully recovers the local structure while maintaining global structure, outperforming other parametric methods.  Hard Negative Mining is highlighted as the key improvement.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_26_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of parametric and non-parametric dimensionality reduction methods on the MNIST dataset.  The top row shows the results of several established non-parametric methods, while the bottom row displays the results of their parametric counterparts.  The visualization clearly demonstrates that parametric methods struggle to preserve the local structure of the data compared to their non-parametric equivalents. The authors' proposed method, ParamRepulsor, is shown to significantly improve local structure preservation within the parametric methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_27_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset.  The top row shows the results of non-parametric methods (t-SNE, NCVis, UMAP, PaCMAP), which preserve local structure well. The bottom row shows the results of their parametric counterparts, which fail to preserve local structure.  ParamRepulsor, a new method introduced in the paper, is shown to address the shortcomings of parametric methods and achieve results closer to the non-parametric methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_28_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction (DR) methods on the MNIST dataset.  The top row shows the results of non-parametric methods (t-SNE, NCVis, UMAP, PaCMAP), demonstrating good preservation of local data structure. The bottom row shows the results of their parametric counterparts, which fail to maintain local structure as effectively.  The figure highlights that the authors' new method, ParamRepulsor, significantly improves local structure preservation in the parametric setting.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_30_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset. The top row shows the results of non-parametric methods, while the bottom row shows the results of parametric methods.  The figure demonstrates that parametric methods, which are generally preferred for their ability to generalize to unseen data, fail to preserve the local structure of the data as well as non-parametric methods. The authors' proposed method, ParamRepulsor, is shown to significantly improve upon the performance of existing parametric methods.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_33_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction (DR) methods on the MNIST dataset.  The top row shows the results of non-parametric methods (t-SNE, NCVis, UMAP, PaCMAP), which are known to preserve local structure well. The bottom row shows the results of parametric versions of the same methods. The parametric methods fail to maintain the clear separation and local structure present in the non-parametric versions, demonstrating a key weakness of parametric approaches. The final column showcases the results of ParamRepulsor, the authors' proposed method. ParamRepulsor successfully recovers the local structure, achieving results comparable to the non-parametric techniques.", "section": "1 Introduction"}, {"figure_path": "eYNYnYle41/figures/figures_34_1.jpg", "caption": "Figure 1: Dimensionality reduction results on the MNIST digit dataset [15]. Parametric methods (bottom row) fail to preserve the local structure of the dataset compared to their non-parametric counterparts (top row). Our method, ParamRepulsor, effectively resolves this problem via Hard Negative Mining.", "description": "This figure compares the performance of various dimensionality reduction methods on the MNIST dataset.  The top row shows non-parametric methods, which preserve local structure well. The bottom row shows parametric methods, which fail to preserve local structure as effectively. The authors' proposed method, ParamRepulsor, is shown in the bottom right and significantly improves local structure preservation compared to other parametric methods.", "section": "1 Introduction"}]