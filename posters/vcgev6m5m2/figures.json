[{"figure_path": "vcGEV6m5m2/figures/figures_2_1.jpg", "caption": "Figure 1: The pipeline of proposed approach. Our approach follows a two-stage training strategy. In the first stage (i.e., dynamic stage), we learn the 3D Gaussians and superpoints to reconstruct the appearance. Each superpoint is associated with a rigid part, and the adaptive control strategy is used to control the count. After finishing the training of dynamic stage, we can discover the skeleton model based on superpoints. After we finish the second stage (i.e., kinematic stage), we can obtain an articulated model based on the kinematic model.", "description": "This figure illustrates the two-stage training process of the proposed method. The dynamic stage focuses on reconstructing the 3D object using 3D Gaussians and superpoints. An adaptive control strategy is employed to manage the number of superpoints. Subsequently, in the kinematic stage, a skeleton model is derived based on superpoint motions, leading to an articulated 3D model.", "section": "3 Methods"}, {"figure_path": "vcGEV6m5m2/figures/figures_6_1.jpg", "caption": "Figure 2: Qualitative comparison on D-NeRF datasets.", "description": "This figure shows a qualitative comparison of novel view synthesis results on the D-NeRF dataset for five different sequences.  The methods compared are WIM, AP-NeRF, the proposed 'ours' method, and the ground truth. Each row represents a different sequence, with several frames shown from different viewpoints for each method.  The red boxes highlight specific areas where differences between the methods are apparent. The goal is to visualize the strengths and weaknesses of each approach in terms of visual fidelity, detail preservation, and overall realism.", "section": "4.1 Datasets and Evaluation Metrics"}, {"figure_path": "vcGEV6m5m2/figures/figures_7_1.jpg", "caption": "Figure 3: Qualitative comparison for the Robots[3] dataset.", "description": "This figure compares the qualitative results of novel view synthesis on the Robots dataset using three different methods: WIM, AP-NeRF, and the proposed method.  The figure shows several examples of robot poses, with each row representing a different robot. For each robot, there are four columns showcasing the results from WIM, AP-NeRF, the authors' proposed method, and finally the ground truth. Red boxes highlight areas where differences between the methods and the ground truth are most apparent, giving a visual illustration of the relative performance of each method on object reconstruction and pose accuracy.", "section": "4 Experiments"}, {"figure_path": "vcGEV6m5m2/figures/figures_7_2.jpg", "caption": "Figure 2: Qualitative comparison on D-NeRF datasets.", "description": "This figure displays a qualitative comparison of novel view synthesis results on the D-NeRF dataset.  It showcases the ground truth images alongside the results generated by four different methods: the authors' proposed approach, AP-NeRF, WIM, and Ours.  The comparison highlights the visual differences between the methods, particularly in terms of detail preservation, reconstruction accuracy, and overall visual fidelity.", "section": "4 Experiments"}, {"figure_path": "vcGEV6m5m2/figures/figures_8_1.jpg", "caption": "Figure 5: Reposing using skeleton. Interpolation from canonical to novel pose.", "description": "This figure demonstrates the reposing capability of the proposed method. It shows how the learned skeleton model can be used to generate novel poses by interpolating between a canonical pose and a target pose. The interpolation is smooth and natural, showing the effectiveness of the method in controlling the movement of individual parts of the object.", "section": "4.6 Reposing"}, {"figure_path": "vcGEV6m5m2/figures/figures_8_2.jpg", "caption": "Figure 2: Qualitative comparison on D-NeRF datasets.", "description": "This figure shows a qualitative comparison of novel view synthesis results on the D-NeRF dataset.  It compares the results of the proposed method with those of WIM, AP-NeRF, and the ground truth.  Each column represents a different method, and each row represents a different sequence from the dataset. The images visually demonstrate the quality of novel view synthesis achieved by each method, allowing for a direct comparison of visual fidelity, motion accuracy and detail.", "section": "4 Experiments"}, {"figure_path": "vcGEV6m5m2/figures/figures_15_1.jpg", "caption": "Figure 2: Qualitative comparison on D-NeRF datasets.", "description": "This figure shows a qualitative comparison of novel view synthesis results on the D-NeRF dataset. It compares the results of the proposed method with those of WIM [3] and AP-NeRF [4]. The comparison includes five different sequences of human actions (jumping jacks, mutant, hook, T-rex, and standup) and their corresponding novel views generated by each method. The ground truth images are also provided for reference. The figure visually demonstrates the superior visual quality and rendering speed of the proposed method compared to the baseline methods.", "section": "4 Experiments"}, {"figure_path": "vcGEV6m5m2/figures/figures_15_2.jpg", "caption": "Figure 2: Qualitative comparison on D-NeRF datasets.", "description": "This figure presents a qualitative comparison of novel view synthesis results on the D-NeRF dataset.  It shows the reconstructed objects from four different methods: AP-NeRF, ours, WIM, and the ground truth. For each method, multiple views of the same object in different poses are presented, allowing for a visual comparison of the accuracy and quality of the reconstructions. This comparison highlights the strengths and weaknesses of each approach in terms of visual fidelity and detail preservation.", "section": "4 Experiments"}]