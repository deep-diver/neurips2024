{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a model that learns visual representations by aligning images and text, which is foundational to many of the Vision Language Models discussed in the paper."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-24", "reason": "This paper introduces LLaMA, a powerful and efficient large language model that is used as a crucial component in many VLMs described in the paper."}, {"fullname_first_author": "Haotian Liu", "paper_title": "LLaVA-NeXT: Improved reasoning, OCR, and world knowledge", "publication_date": "2024-01-01", "reason": "LLaVA-NeXT is a significant improvement on LLaVA, demonstrating superior performance that's extensively analyzed in the paper."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-VL: A frontier large vision-language model with versatile abilities", "publication_date": "2023-08-01", "reason": "This paper introduces Qwen-VL, a state-of-the-art open-source VLM that is among the models whose capabilities are compared and analyzed in the paper."}, {"fullname_first_author": "Lin Chen", "paper_title": "Are we on the right way for evaluating large vision-language models?", "publication_date": "2024-03-01", "reason": "This paper critically examines the existing methods for evaluating VLMs, highlighting the importance of decoupled analysis, a key aspect addressed by the Prism framework in this paper."}]}