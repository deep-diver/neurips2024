[{"figure_path": "Q4QUCN2ioc/figures/figures_2_1.jpg", "caption": "Figure 1: Our proposed EGATH framework consists of three main modules: 1) a feature extraction module, which employs the CLIP and transformer encoders to extract the global features of each modality; 2) a GAT classification module, which uses a graph attention network to dig deeper into the structural and semantic information of the labels; 3) a hash code module, which employs two functions and an optimization strategy to generate a hash code that preserves semantic information.", "description": "This figure illustrates the EGATH (End-to-End Graph Attention Network Hashing) framework, which is composed of three modules: 1) Feature Extraction, where CLIP and transformers are used to extract image and text features respectively. 2) GAT Classification, using a Graph Attention Network to classify labels and enhance feature representation. 3) Hash Code Module, using similarity learning and a triple loss function to generate compact and semantically informative hash codes. The figure shows the data flow and connections between these three modules.", "section": "2.2 Network Architecture of EGATH"}, {"figure_path": "Q4QUCN2ioc/figures/figures_7_1.jpg", "caption": "Figure 2: PR curves on the three datasets", "description": "This figure presents the Precision-Recall (PR) curves for the image-to-text (I\u2192T) and text-to-image (T\u2192I) retrieval tasks across three datasets: MIRFlickr25K, NUS-WIDE, and MS-COCO.  Each dataset is shown with curves for 32-bit and 64-bit hash codes. The curves visually compare the performance of the proposed EGATH method against several state-of-the-art baselines (UCCH, EGATH, DSPH, DCHMT, JDSH, DJSRH).  The curves illustrate the trade-off between precision and recall at various threshold settings for each method, allowing for a visual comparison of retrieval effectiveness. ", "section": "3.4 Performance Comparison"}, {"figure_path": "Q4QUCN2ioc/figures/figures_8_1.jpg", "caption": "Figure 2: PR curves on the three datasets", "description": "This figure presents the precision-recall (PR) curves for image-to-text and text-to-image retrieval tasks across three datasets (MIRFlickr25K, NUS-WIDE, and MS-COCO) using different bit lengths (32-bit and 64-bit).  The curves compare the proposed EGATH method against several state-of-the-art cross-modal hashing methods. The PR curves visually demonstrate the trade-off between precision and recall at different threshold settings for each method on the three datasets, providing a comprehensive view of model performance across various thresholds. ", "section": "3.4 Performance Comparison"}, {"figure_path": "Q4QUCN2ioc/figures/figures_9_1.jpg", "caption": "Figure 2: PR curves on the three datasets", "description": "This figure shows the precision-recall (PR) curves for the three datasets (MIRFlickr25K, NUS-WIDE, and MS-COCO) for both image-to-text (I\u2192T) and text-to-image (T\u2192I) retrieval tasks.  The curves compare the performance of the proposed EGATH method against several state-of-the-art methods (DSPH, DCHMT, JDSH, DJSRH, UCCH).  The PR curves illustrate the trade-off between precision and recall at various threshold levels for each method, providing a comprehensive view of their performance across different retrieval scenarios. The results visually demonstrate the superiority of EGATH across different datasets and retrieval tasks.", "section": "3.4 Performance Comparison"}]