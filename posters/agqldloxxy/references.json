{"references": [{"fullname_first_author": "A. Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-04-02", "reason": "This is the primary model that UnSAM builds upon, providing the foundation for the unsupervised approach."}, {"fullname_first_author": "X. Wang", "paper_title": "Cut and learn for unsupervised object detection and instance segmentation", "publication_date": "2023-00-00", "reason": "This paper introduces the CutLER method which is crucial for the divide-and-conquer strategy used in UnSAM."}, {"fullname_first_author": "M. Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper introduces the DINO model, which UnSAM leverages as a pre-trained backbone, enabling efficient self-supervised feature extraction."}, {"fullname_first_author": "B. Cheng", "paper_title": "Masked-attention mask transformer for universal image segmentation", "publication_date": "2022-00-00", "reason": "UnSAM uses this as the base model for whole-image segmentation and incorporates its masked attention mechanism."}, {"fullname_first_author": "T. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This is foundational for the self-supervised learning paradigm, providing theoretical support for the scaling laws that UnSAM utilizes."}]}