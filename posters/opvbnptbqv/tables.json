[{"figure_path": "oPvBnPTbQv/tables/tables_7_1.jpg", "caption": "Table 1: Comparisons with the state-of-the-art approaches on three benchmarks, i.e., RefCOCO, RefCOCO+, RefCOCOg. * indicates models that use additionally data beyond RefCOCO series. \u2020 indicates that models simply combine RefCOCO, RefCOCO+, and RefCOCOg.", "description": "This table compares the performance of the proposed RefFormer model with several state-of-the-art visual grounding methods on three benchmark datasets: RefCOCO, RefCOCO+, and RefCOCOg.  The table shows the performance (in terms of Recall@0.5) achieved by each method on the validation and test sets of each benchmark.  It also notes which models used additional data beyond the standard RefCOCO datasets and which models simply combined the three datasets.  The visual backbone used by each method is also specified.", "section": "5 Experiment"}, {"figure_path": "oPvBnPTbQv/tables/tables_7_2.jpg", "caption": "Table 2: Comparison with state-of-the-art approaches on the Flickr30K Entities and ReferItGame.", "description": "This table compares the performance of the proposed method against state-of-the-art approaches on two visual grounding benchmarks: Flickr30K Entities and ReferItGame.  It shows the test set performance (Prec@0.5) for each method, highlighting the superiority of the proposed approach.", "section": "5.3 Comparisons with State-of-the-art Methods"}, {"figure_path": "oPvBnPTbQv/tables/tables_7_3.jpg", "caption": "Table 1: Comparisons with the state-of-the-art approaches on three benchmarks, i.e., RefCOCO, RefCOCO+, RefCOCOg. * indicates models that use additionally data beyond RefCOCO series. \u2020 indicates that models simply combine RefCOCO, RefCOCO+, and RefCOCOg.", "description": "This table compares the proposed method's performance against other state-of-the-art visual grounding methods on three benchmark datasets: RefCOCO, RefCOCO+, and RefCOCOg.  The table shows the performance (in terms of accuracy) on validation and test sets, categorized by the type of visual grounding method (two-stage, one-stage, transformer-based) and the backbone network used. It also notes which methods used additional datasets beyond the standard RefCOCO datasets and which methods simply combined the three RefCOCO datasets.  The results demonstrate the superiority of the proposed method.", "section": "5.3 Comparisons with State-of-the-art Methods"}, {"figure_path": "oPvBnPTbQv/tables/tables_8_1.jpg", "caption": "Table 5: Ablation study of the QA position on RefCOCOg.", "description": "This table presents the ablation study on the position of the Query Adaption module (QA) in the RefFormer model. It shows the performance (in terms of Prec@0.5) on the RefCOCOg dataset for different QA positions (fusion layer K).  The results demonstrate the impact of adding the QA module at various layers of the CLIP backbone on the overall accuracy. The best performance is achieved when QA is inserted at multiple layers ({4, 6, 8, 10, 12}).", "section": "5.4 Ablation Studies"}, {"figure_path": "oPvBnPTbQv/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study of the QA position on RefCOCOg.", "description": "This table presents the ablation study results on the RefCOCOg dataset, focusing on the impact of the Query Adaption (QA) module's position within the CLIP model. Different combinations of layers in the CLIP model where the QA module is inserted are tested, showing the effect on the model's performance. The results demonstrate that strategically placing the QA module across multiple layers significantly improves the model's performance, highlighting the effectiveness of this approach in leveraging multi-level contextual information.", "section": "5.4 Ablation Studies"}, {"figure_path": "oPvBnPTbQv/tables/tables_9_1.jpg", "caption": "Table 6: Ablation studies of backbone, auxiliary loss, and learnable queries on RefCOCOg.", "description": "This table presents the ablation study results on the RefCOCOg dataset, assessing the impact of different components of the proposed RefFormer model.  It shows the performance (measured by validation and test Prec@0.5) when using different backbones (Swin+Bert vs. the default), excluding the auxiliary loss (Laux), and using different query generation methods (referential query, linguistic embeddings, and random initialization). The results highlight the contribution of each component to the overall performance improvement.", "section": "5.4 Ablation Studies"}, {"figure_path": "oPvBnPTbQv/tables/tables_14_1.jpg", "caption": "Table 7: Ablation study of the direction of the features flow from the QA module on RefCOCOg.", "description": "This table presents the ablation study results focusing on the direction of the feature flow from the Query Adaption Module (QA) in the RefFormer model.  The experiment was conducted on the RefCOCOg benchmark.  The table compares the performance (measured in terms of 'val' and 'test' scores) of four different configurations:  'None' (no feature flow from QA), 'Only text' (textual features only), 'Only image' (image features only), and 'Image & Text' (both image and text features). The numbers in parentheses show the performance improvement relative to the 'None' configuration, highlighting the effect of bidirectional feature flow.", "section": "A.1 Effect on the RefFormer's direction"}]