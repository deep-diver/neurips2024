[{"figure_path": "FbXQrfkvtY/tables/tables_15_1.jpg", "caption": "Table 1: TNP transformers model sizes and architectures.", "description": "This table shows the different sizes of Transformer Neural Processes (TNP) models used in the experiments.  Each model is defined by its number of parameters (in millions), input embedding dimension, feedforward dimension, number of heads, and number of layers. The models vary significantly in size and complexity, allowing for an analysis of how model scale affects the results.", "section": "D Training Transformers from Scratch"}]