[{"figure_path": "L1jajNWON5/figures/figures_1_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure demonstrates the difference in evaluation metrics between dataset condensation for classification and time series forecasting.  The left panel illustrates that for classification, successful condensation is determined by whether the model trained on the condensed dataset produces the same class labels as the model trained on the full dataset, regardless of the similarity in the output logits distribution.  Conversely, for time series forecasting, successful condensation requires that the predictions from the condensed dataset model closely match the predictions from the full dataset model across all data points.  The right panel shows that the proposed CondTSF method improves the performance of several existing dataset condensation methods, across various datasets, especially at lower condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_3_1.jpg", "caption": "Figure 2: Complete process of dataset condensation using CondTSF.", "description": "The figure illustrates the overall process of dataset condensation using CondTSF.  It starts with a full training dataset 'f', from which an initial synthetic dataset 's' is randomly sampled.  This 's' is then optimized in two stages. The first stage involves Parameter Matching, which focuses on minimizing the distance between the full dataset's model parameters (\u03b8f) and the synthetic dataset's model parameters (\u03b8s) \u2013 this is Gradient Term Optimization. The second stage involves CondTSF, which minimizes the label error (Llabel) by optimizing the Value Term. This two-stage process results in a distilled synthetic dataset 's*', which is expected to be a more effective and efficient representation of the original dataset 'f' for training.", "section": "4 Method"}, {"figure_path": "L1jajNWON5/figures/figures_4_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The figure compares the evaluation metrics of dataset condensation methods between classification and time series forecasting tasks. The left panel illustrates that for classification, successful condensation is indicated by identical predicted labels between models trained on full and condensed datasets, irrespective of the distribution of output logits.  In contrast, the right panel shows that for time-series forecasting, successful condensation requires similar predictions across all data points, emphasizing a stricter evaluation criterion. The right panel also presents a comparison of the performance of several existing methods with and without CondTSF (Condensation for Time Series Forecasting), a proposed one-line plugin that aims to improve performance, especially at low condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_8_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure compares the evaluation metrics of dataset condensation methods between classification tasks and time series forecasting. The left panel illustrates how the evaluation differs between these two types of tasks. In classification, similar predictions are judged based on whether models trained on the full dataset and synthetic dataset assign the same label to the same input; differences in the output probability distributions are not considered. Time series forecasting, however, demands that all data points in the prediction are similar, creating a more stringent evaluation.  The right panel shows a comparison of the performance of previous dataset condensation methods with and without CondTSF, demonstrating CondTSF's improvement.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_20_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure compares the evaluation methods for dataset condensation between classification and time series forecasting tasks. The left panel shows that for image classification, similar predictions are considered good synthetic data if the model trained on the synthetic dataset produces the same predicted label as the model trained on the full dataset, irrespective of variations in the output logits distribution.  However, for time series forecasting, predictions must have low pointwise distance between the models trained on the synthetic and full datasets to be considered good synthetic data. The right panel displays the improved performance of previous dataset condensation methods when CondTSF is integrated, showcasing its effectiveness across various datasets, especially at low condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_20_2.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The figure on the left demonstrates how the evaluation of dataset condensation differs between classification and time series forecasting tasks.  In classification, similar predictions are deemed successful if the models output the same class labels regardless of differences in the output probability distributions. However, in time series forecasting, successful condensation requires similar predictions across all data points. The figure on the right showcases a comparison of various dataset condensation methods with and without the proposed CondTSF plugin, highlighting the improvement in performance achieved by incorporating CondTSF.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_21_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The figure is composed of three subfigures. The left subfigure shows the difference in how dataset condensation is evaluated for classification versus time series forecasting tasks. In classification, the success is measured by whether the model trained on a condensed dataset produces the same class label as the model trained on the full dataset.  In time series forecasting, however, the success is based on the similarity of the entire prediction curve produced by models trained on the condensed and full datasets. The right subfigure demonstrates the improved performance achieved by adding CondTSF (a novel one-line plugin proposed in the paper) to existing dataset condensation methods.  It shows that performance across multiple time-series datasets improves significantly for various methods, especially at lower condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_22_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The figure showcases a comparison between dataset condensation evaluation methods for classification and time series forecasting.  The left panel illustrates the key difference: for classification, similar predictions mean identical class labels, regardless of the logits distribution. In contrast, for time series forecasting, similar predictions require similar values for all data points. The right panel demonstrates how the proposed CondTSF plugin improves performance across different datasets and methods, particularly at lower condensing ratios, compared to traditional dataset condensation methods.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_23_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure shows the difference in evaluating dataset condensation between classification and time series forecasting tasks. The left panel illustrates that for classification, similar predictions are considered well-distilled if the models trained on full and synthetic datasets produce identical labels regardless of the output distribution differences. However, for time series forecasting, well-distilled synthetic data requires similar predictions across all data points. The right panel demonstrates the performance improvement using CondTSF across various dataset condensation methods on eight commonly used time series datasets.  CondTSF consistently boosts performance across all methods and datasets, especially at low condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_24_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The left panel of Figure 1 contrasts the evaluation metrics for dataset condensation applied to classification versus time series forecasting tasks.  For classification, successful condensation is determined by whether the model trained on the synthetic data predicts the same class labels as the model trained on the full data, regardless of the distribution of output logits.  However, for time series forecasting, successful condensation requires that the predictions from both models are point-wise similar across all time steps. The right panel displays the comparative performance of various dataset condensation methods, both with and without the CondTSF plugin, demonstrating improved performance (lower test error) across multiple time series datasets when CondTSF is used.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_24_2.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure consists of two parts. The left part shows the difference in the evaluation of dataset condensation for classification tasks and time series forecasting tasks. In classification, similar predictions are considered good synthetic data if the model trained with the synthetic dataset yields identical labels with the model trained on the full dataset.  However, for time series forecasting, the distance between the predictions of the two models determines the quality of synthetic data; similar predictions for all data points indicate well-distilled data. The right part shows the comparison of performance of different methods with and without CondTSF.  In this experiment, CondTSF consistently improved the performance of previous dataset condensation methods, across all datasets and condensing ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_25_1.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "This figure compares the evaluation metrics for dataset condensation between classification tasks and time series forecasting tasks.  The left panel illustrates that in classification, successful condensation is determined by whether the model trained on the condensed dataset predicts the same class labels as the model trained on the full dataset.  The right panel showcases how CondTSF improves the performance of existing dataset condensation methods by reducing the distance between predictions made by the models trained on the condensed and full datasets. This reduction is particularly significant at low condensation ratios.", "section": "1 Introduction"}, {"figure_path": "L1jajNWON5/figures/figures_25_2.jpg", "caption": "Figure 1: Left: Difference between evaluation of dataset condensation for classification tasks and time series forecasting tasks. Right: Comparison in performance of previous methods with and without CondTSF.", "description": "The figure is composed of three subfigures. The left subfigure illustrates the difference between evaluating synthetic data for image classification and time series forecasting. Image classification considers synthetic data well-distilled if models trained on full and synthetic datasets produce identical labels, regardless of output distribution. Conversely, time series forecasting requires similar predictions across all data points, making evaluation more rigorous. The right subfigure presents performance comparisons of several dataset condensation methods, with and without the proposed CondTSF plugin. The results show consistent improvement by incorporating CondTSF, especially at low condensing ratios.", "section": "1 Introduction"}]