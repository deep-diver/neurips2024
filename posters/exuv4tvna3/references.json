{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduces the Vision Transformer (ViT) architecture, a foundational model for the current work, which adapts the Transformer architecture to image processing."}, {"fullname_first_author": "Yujia Bao", "paper_title": "Channel Vision Transformers: An image is worth 1 x 16 x 16 words", "publication_date": "2024-00-00", "reason": "This paper directly inspires the current work by proposing ChannelViT, a channel-adaptive ViT model which the current work improves upon."}, {"fullname_first_author": "Nicolas Bourriez", "paper_title": "Chada-ViT: Channel adaptive attention for joint representation learning of heterogeneous microscopy images", "publication_date": "2024-00-00", "reason": "This paper is another important related work that proposes a channel-adaptive ViT model and provides a strong baseline for comparison."}, {"fullname_first_author": "Zitong Chen", "paper_title": "CHAMMI: A benchmark for channel-adaptive models in microscopy imaging", "publication_date": "2023-00-00", "reason": "This paper introduces the CHAMMI dataset, one of the datasets used to evaluate the proposed model, providing a relevant benchmark for channel-adaptive models."}, {"fullname_first_author": "Xiao Xiang Zhu", "paper_title": "So2Sat LCZ42: A benchmark dataset for the classification of global local climate zones", "publication_date": "2020-00-00", "reason": "This paper introduces the So2Sat dataset, another dataset used for evaluation, providing a real-world benchmark for multi-channel image classification."}]}