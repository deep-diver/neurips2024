[{"figure_path": "EXuv4tVNa3/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]. (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares ChannelViT and DiChaViT's performance on the Human Protein Atlas (HPA) dataset within the CHAMMI benchmark.  The left sub-figure (a) shows mutual information between channel tokens, indicating redundancy in ChannelViT and diversity in DiChaViT. The right sub-figure (b) displays aggregated attention scores, demonstrating that ChannelViT focuses on specific channels, while DiChaViT distributes attention more evenly.", "section": "Introduction"}, {"figure_path": "EXuv4tVNa3/figures/figures_1_2.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]). (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares the information learned by ChannelViT and DiChaViT models.  (a) shows that ChannelViT learns redundant information across channels while DiChaViT learns more diverse features. (b) illustrates that ChannelViT focuses attention on specific channels for prediction whereas DiChaViT distributes attention evenly across channels.", "section": "Introduction"}, {"figure_path": "EXuv4tVNa3/figures/figures_2_1.jpg", "caption": "Figure 2: An overview of DiChaViT. We introduce two regularization methods on the features and a channel sampling strategy to promote diversity in feature representations. We apply (a) Channel Diversification Loss (CDL) (Sec. 3.1) for channel tokens (), and (b) Token Diversification Loss (TDL) (Sec. 3.2) on the patch tokens (). Additionally, we (c) sample a subset of dissimilar channels using Diverse Channel Sampling (DCS) (Sec. 3.3).", "description": "This figure illustrates the architecture of DiChaViT, a vision transformer designed for multi-channel imaging.  It shows three main components:  (a) Channel Diversification Loss (CDL) to diversify channel tokens, (b) Token Diversification Loss (TDL) to diversify patch tokens within each channel, and (c) Diverse Channel Sampling (DCS) to select a subset of dissimilar channels during training.  The figure highlights how these components work together to improve feature diversity and robustness in multi-channel vision transformers.", "section": "3 Encouraging Diverse Representations in multi-channel ViTs"}, {"figure_path": "EXuv4tVNa3/figures/figures_7_1.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]. (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares the redundant information learned by ChannelViT and DiChaViT models on the Human Protein Atlas (HPA) dataset.  Part (a) shows the mutual information between channel tokens, revealing high redundancy in ChannelViT and low redundancy in DiChaViT, indicating that DiChaViT encourages each channel to learn distinct features. Part (b) visualizes aggregated patch token attention scores by channel, demonstrating that ChannelViT focuses on specific channels for predictions while DiChaViT distributes attention more evenly across channels.", "section": "1 Introduction"}, {"figure_path": "EXuv4tVNa3/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]. (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares ChannelViT and DiChaViT's performance on the Human Protein Atlas (HPA) dataset from CHAMMI.  Panel (a) shows mutual information between channel tokens, revealing redundancy in ChannelViT but diversity in DiChaViT. Panel (b) illustrates attention scores, demonstrating that DiChaViT distributes attention more evenly across channels than ChannelViT.", "section": "Introduction"}, {"figure_path": "EXuv4tVNa3/figures/figures_9_1.jpg", "caption": "Figure 5: Comparison of DCS and HCS [18] in terms of the frequency (%) each channel is sampled during training on So2Sat. Unlike HCS, which provides a uniform distribution for all channels (red dashed line), some channels in DCS are trained much more than others (blue bars). For example, Real Lee-Cov channel (rightmost) is sampled twice as much as Band B8a (first bar).", "description": "This figure compares the channel sampling frequencies of Diverse Channel Sampling (DCS) and Hierarchical Channel Sampling (HCS) on the So2Sat dataset.  DCS, unlike HCS which samples channels uniformly, shows a non-uniform distribution, with some channels being sampled significantly more often than others. This highlights the inherent difference in the training strategies employed by the two methods.", "section": "4.4.3 Ablations for Diverse Channel Sampling (DCS)"}, {"figure_path": "EXuv4tVNa3/figures/figures_15_1.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]. (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares the performance of ChannelViT and DiChaViT on the Human Protein Atlas (HPA) dataset from the CHAMMI benchmark.  Panel (a) shows the mutual information between channel tokens, revealing high redundancy in ChannelViT and low redundancy in DiChaViT, indicating DiChaViT learns more distinct features per channel. Panel (b) visualizes aggregated attention scores from the [CLS] token to patch tokens, demonstrating that ChannelViT relies heavily on specific channels while DiChaViT distributes attention more evenly across channels. This highlights DiChaViT's ability to leverage diverse information from all channels.", "section": "1 Introduction"}, {"figure_path": "EXuv4tVNa3/figures/figures_16_1.jpg", "caption": "Figure 1: Comparison of the redundant information learned by different models on the HPA dataset in CHAMMI [14]). (a) Measures the mutual information between the channel tokens, which captured the configuration of channels in an image. Note we gray out the diagonal for better visualization. We find ChannelViT tokens have high mutual information, which suggests significant redundancy exists across channels [34, 35]. In contrast, DiChaViT has little mutual information as each channel is encouraged to learn different features. (b) We compute attention scores of the [CLS] token to the patch tokens in the penultimate layers and aggregate them by channel. ChannelViT (top) relies on certain channels (e.g., microtubules and nucleus) to make predictions and less on other channels (e.g., protein and er). In contrast, DiChaViT demonstrates more evenly distributed attention scores across channels, suggesting that each channel contributes more to the model's predictions.", "description": "This figure compares the redundant information learned by ChannelViT and DiChaViT models on the Human Protein Atlas (HPA) dataset.  Panel (a) shows the mutual information between channel tokens, revealing high redundancy in ChannelViT but low redundancy in DiChaViT, indicating that DiChaViT effectively learns diverse features from each channel. Panel (b) displays the aggregated patch token attention scores by channel, demonstrating that ChannelViT focuses on specific channels while DiChaViT distributes attention more evenly, suggesting improved feature utilization.", "section": "1 Introduction"}]