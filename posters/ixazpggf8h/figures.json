[{"figure_path": "IxazPgGF8h/figures/figures_1_1.jpg", "caption": "Figure 1: Empowering camera control through conversational AI. Our proposed ChatCam assists users in generating desired camera trajectories through natural language interactions. The generated trajectories can be used to render videos on radiance field representations such as NeRF [52] or 3DGS [36].", "description": "This figure illustrates the ChatCam system, which uses conversational AI to control camera movements for video generation.  The user provides a natural language instruction (e.g., \"Let's capture a video for the breathtaking Opera House!\"). ChatCam processes this request, generates a camera trajectory, and renders a corresponding video using radiance field techniques (NeRF or 3DGS). The figure shows a visual representation of this process, highlighting the interaction between the user, the ChatCam system, and the generated video output.", "section": "1 Introduction"}, {"figure_path": "IxazPgGF8h/figures/figures_2_1.jpg", "caption": "Figure 1: Empowering camera control through conversational AI. Our proposed ChatCam assists users in generating desired camera trajectories through natural language interactions. The generated trajectories can be used to render videos on radiance field representations such as NeRF [52] or 3DGS [36].", "description": "This figure illustrates the ChatCam system, which allows users to control camera movements using natural language.  The user inputs a description of the desired camera trajectory (e.g., \"First capture the Opera House with the Harbour Bridge in the background\"), and ChatCam generates a trajectory that mimics a professional cinematographer's workflow.  The system uses this trajectory to render a high-quality video using radiance field representations (NeRF or 3DGS). The figure shows the interaction between the user and ChatCam, the 3D scene, the generated trajectory, and the final rendered video.", "section": "1 Introduction"}, {"figure_path": "IxazPgGF8h/figures/figures_2_2.jpg", "caption": "Figure 2: Overview of the ChatCam pipeline. Given a camera operation instruction, ChatCam reasons the user's request and devises a plan to generate a trajectory using our proposed CineGPT and Anchor Determinator. The agent then utilizes the outputs from these tools to compose the complete trajectory and render a video.", "description": "This figure illustrates the ChatCam pipeline.  It shows how a user's natural language camera instruction is processed.  First, the system reasons about the instruction, identifying key elements.  Then, it uses CineGPT and Anchor Determinator to generate trajectory segments. Finally, an AI agent combines these segments into a complete camera trajectory and renders the video.", "section": "3 Method"}, {"figure_path": "IxazPgGF8h/figures/figures_3_1.jpg", "caption": "Figure 3: (a) CineGPT. We quantize camera trajectories to sequences of tokens and adopt a GPT-based architecture to generate the tokens autoregressively. Learning trajectory and language jointly, CineGPT is capable of text-conditioned trajectory generation. (b) Anchor Determination. Given a prompt describing the image rendered from an anchor point, the anchor selector chooses the best matching input image. An anchor refinement procedure further fine-tunes the anchor position.", "description": "This figure illustrates the architecture of CineGPT and Anchor Determination. CineGPT is a GPT-based model that takes text and quantized camera trajectory tokens as input and generates camera trajectory tokens. Anchor Determination uses a CLIP-based approach to select an anchor image from input images based on a text prompt, followed by a refinement process to fine-tune the anchor position.  The diagram shows the flow of data from text input, through tokenization, to the generation of trajectory tokens by CineGPT. It also shows the selection and refinement of an anchor image in 3D scene understanding to guide trajectory generation.", "section": "3 Method"}, {"figure_path": "IxazPgGF8h/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative results on indoor and outdoor scenes. Visualizations of our generated trajectories from input text descriptions and the frames in the final rendered video. Our method is capable of understanding and executing instructions and providing correct translations, rotations, and camera focal lengths. Additionally, our method can comprehend more specialized terms such as \"dolly zoom\".", "description": "This figure shows qualitative results of the ChatCam system on both indoor and outdoor scenes.  It presents three example user prompts and the resulting video frames generated by the system. The prompts demonstrate the system's ability to handle various camera movements (dolly zoom, panning, zooming) and to understand specialized cinematic terminology. The rendered frames showcase the accuracy and realism of the generated trajectories.", "section": "4 Experiments"}, {"figure_path": "IxazPgGF8h/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative results on human-centric scenes. Visualizations of our generated trajectories from input text descriptions and the frames in the final rendered video. Our method performs effectively in scenes with multiple humans.", "description": "This figure shows qualitative results of ChatCam on human-centric scenes.  It demonstrates the system's ability to generate camera trajectories from natural language descriptions, even in complex scenes with multiple people. The top row presents a text prompt describing the desired camera movement, while the bottom row displays the resulting video frames.  The figure highlights ChatCam's effectiveness in interpreting and translating complex human-centric instructions into precise camera movements.", "section": "4. Results"}, {"figure_path": "IxazPgGF8h/figures/figures_8_1.jpg", "caption": "Figure 6: Qualitative comparisons. Our approach avoids moving the camera to unreasonable positions such as inside objects, obtaining videos with better visual effects, and aligning best with input texts.", "description": "This figure shows a qualitative comparison of the proposed ChatCam approach against two baseline methods, SA3D and LERF, for generating camera trajectories from natural language instructions.  The results demonstrate that ChatCam produces more reasonable and visually appealing camera paths, avoiding unrealistic placements (e.g., inside objects) and achieving better alignment with the intended text descriptions. The images illustrate the camera's movement and the resulting viewpoints for each method.", "section": "4 Experiments"}, {"figure_path": "IxazPgGF8h/figures/figures_14_1.jpg", "caption": "Figure 4: Qualitative results on indoor and outdoor scenes. Visualizations of our generated trajectories from input text descriptions and the frames in the final rendered video. Our method is capable of understanding and executing instructions and providing correct translations, rotations, and camera focal lengths. Additionally, our method can comprehend more specialized terms such as \"dolly zoom\".", "description": "This figure shows qualitative results of the proposed ChatCam system on both indoor and outdoor scenes.  Three example user requests are presented along with the resulting camera trajectories and frames from the rendered videos.  The results demonstrate the system's ability to correctly interpret and execute complex camera instructions, including those using specialized cinematography terms like \"dolly zoom\".", "section": "4 Results"}, {"figure_path": "IxazPgGF8h/figures/figures_15_1.jpg", "caption": "Figure B: Additional qualitative results. (2)", "description": "This figure shows additional qualitative results of the ChatCam system.  It presents examples of generated camera trajectories and resulting video frames from various natural language instructions, demonstrating the system's ability to interpret and execute complex and nuanced instructions in different scenes.  The instructions include both simple movements and more elaborate ones such as specifying camera position relative to objects in the scene and following S-shaped paths. The images illustrate the quality of the generated trajectories and the realism of the rendered videos.", "section": "B Additional Results"}]