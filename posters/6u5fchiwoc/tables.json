[{"figure_path": "6U5fCHIWOC/tables/tables_6_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between different topological complexity measures and the generalization gap, calculated using the granulated Kendall's tau coefficient.  The results are shown for various models (vision transformers and graph neural networks) and datasets, across three different distance metrics: the data-dependent pseudometric (ps), the Euclidean distance (||.||2), and the 0-1 loss (01).  The columns represent the correlation across all data, the correlation when only the learning rate is varied (LR), the correlation when only the batch size is varied (BS), and the average of LR and BS correlations (\u03a8).  The table aims to demonstrate the strong correlation between the proposed topological measures and the generalization gap, and their consistent outperformance compared to state-of-the-art persistent homology dimensions (dimpH).", "section": "Empirical Analysis"}, {"figure_path": "6U5fCHIWOC/tables/tables_29_1.jpg", "caption": "Table 2: Architecture details for the vision transformers (taken from [29]). WS refers to Window Size.", "description": "This table presents the architecture details for the vision transformers used in the experiments.  The details include the model name, dataset used, depth, patch size, token dimension, number of heads, MLP ratio, window size, and the total number of parameters for each model. This information is crucial for understanding the computational complexity and scale of the models used in the research. The models listed are ViT, Swin, and CaiT, all tested on CIFAR10 and CIFAR100 datasets.", "section": "C.1.1 Vision Transformers Architecture and implementation details"}, {"figure_path": "6U5fCHIWOC/tables/tables_35_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between different topological complexity measures and the generalization error for various deep learning models and datasets.  The correlation is measured using Granulated Kendall's coefficient (GKC) which considers the correlation of topological complexity measure with generalization gap when only one hyperparameter is changing. The table includes three different pseudometrics used to compute distance matrices. The table helps to quantify the relationship between topological complexity and generalization performance across different deep learning models and datasets, providing a comparative evaluation of different topological measures.", "section": "5 Empirical Analysis"}, {"figure_path": "6U5fCHIWOC/tables/tables_37_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between several topological complexity measures and the generalization error.  It shows the correlation for different models (Vision Transformers and Graph Neural Networks), datasets (CIFAR10, CIFAR100, MNIST), and distance metrics (Euclidean distance, data-dependent pseudometrics based on loss).  The correlations are assessed using the granulated Kendall's coefficient (GKC)  considering learning rates and batch sizes.  The table helps in comparing the effectiveness of different topological measures in predicting generalization.", "section": "Empirical Analysis"}, {"figure_path": "6U5fCHIWOC/tables/tables_39_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between different topological complexity measures and the generalization error for various deep learning models trained on different datasets.  The correlation is calculated using the granulated Kendall's coefficient, which accounts for correlation when only a single hyperparameter changes, as well as the traditional Kendall's coefficient (\u03c4). The table includes results for several models (ViT, Swin, GraphSage, GatedGCN), datasets (CIFAR10, CIFAR100, MNIST), and distance metrics (ps, Euclidean, 01 loss). It facilitates comparison of the effectiveness of various topological measures, including the persistent homology dimension and our proposed measures (Ea, Mag, PMag).", "section": "Empirical Analysis"}, {"figure_path": "6U5fCHIWOC/tables/tables_40_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between various topological complexity measures (Ea, Mag(n), Mag(0.01), PMag(n), PMag(0.01), dimPH) and the generalization gap for different models (ViT, Swin, GraphSage, GatedGCN) and datasets (CIFAR10, CIFAR100, MNIST).  Each topological measure is computed using different distance metrics (ps, ||.||2, 01). The table shows the Kendall's correlation coefficients (\u03c4, \u03c8LR, \u03c8BS, \u03c8) which measure the correlation between the topological complexities and the generalization gap for different hyperparameters (learning rate, batch size).", "section": "Empirical Analysis"}, {"figure_path": "6U5fCHIWOC/tables/tables_42_1.jpg", "caption": "Table 1: Correlation coefficients associated with the different topological complexities.", "description": "This table presents the correlation coefficients between different topological complexity measures (Ea, Mag(n), Mag(0.01), PMag(n), PMag(0.01), and dimPH) and the generalization error (Gs) for various models (ViT, Swin, GraphSage, GatedGCN) and datasets (CIFAR10, CIFAR100, MNIST).  Different distance metrics (ps, ||.||2, 01) are used for computing the topological complexities.  The table also shows the granulated Kendall's coefficients (\u03c4, \u03c8LR, \u03c8BS, \u03c8) for each measure, providing a more nuanced understanding of the correlation strength based on the variation of learning rate and batch size.", "section": "Empirical Analysis"}]