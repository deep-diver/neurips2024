[{"figure_path": "H0qu4moFly/figures/figures_4_1.jpg", "caption": "Figure 2: Example construction of \u2730. The embedding \u27304 is computed based on the embeddings of its already processed neighbors \u27301, \u27302, \u27303. We find the solution \u27304 to the linear system so that, for each edge to a preceding neighbor, the inner product equals the rank of the edge.", "description": "This figure illustrates how the embedding vector for a node (x4) is constructed based on the embedding vectors of its preceding neighbors (x1, x2, x3) in the constraint graph.  The inner product between the embedding vectors of connected nodes is set to be equal to the rank of the edge connecting them, ensuring that the distance between the nodes reflects their relative importance according to the edge weights.", "section": "2 Contrastive Learning in l2 Norm"}, {"figure_path": "H0qu4moFly/figures/figures_9_1.jpg", "caption": "Figure 4: Experiments on CIFAR-10 (left) and CIFAR-100 (right). The data points show the average over 5 runs, and the shaded area shows the minimum and the maximum values over the runs", "description": "The figure shows the results of the CIFAR-10 and CIFAR-100 experiments, showing the fraction of unsatisfied samples over training epochs for different numbers of samples (m) and embedding dimensions (d).  The shaded areas represent the minimum and maximum values across five runs, illustrating the variability of the results.  It visually demonstrates the relationship between the number of samples, embedding dimension, and the success of contrastive learning.", "section": "4 Experiments"}, {"figure_path": "H0qu4moFly/figures/figures_9_2.jpg", "caption": "Figure 4: Experiments on CIFAR-10 (left) and CIFAR-100 (right). The data points show the average over 5 runs, and the shaded area shows the minimum and the maximum values over the runs", "description": "This figure presents the results of experiments conducted on CIFAR-10 and CIFAR-100 datasets to evaluate the performance of contrastive learning with varying embedding dimensions. The plots show the fraction of unsatisfied samples over epochs for different embedding dimensions (d = 1, 4, 16, 64, 256, 1024).  The shaded regions represent the minimum and maximum values across five runs, illustrating variability in the results. The results suggest a relationship between embedding dimension and the accuracy of contrastive learning.", "section": "4 Experiments"}, {"figure_path": "H0qu4moFly/figures/figures_9_3.jpg", "caption": "Figure 4: Experiments on CIFAR-10 (left) and CIFAR-100 (right). The data points show the average over 5 runs, and the shaded area shows the minimum and the maximum values over the runs", "description": "This figure visualizes the results of experiments conducted on CIFAR-10 and CIFAR-100 datasets to evaluate the impact of the number of samples and embedding dimension on the accuracy of contrastive learning.  The plots show the fraction of unsatisfied samples (error rate) over training epochs for varying numbers of samples (m) and embedding dimensions (d). The shaded regions represent the minimum and maximum values across five runs, illustrating the variability of the results.", "section": "4 Experiments"}, {"figure_path": "H0qu4moFly/figures/figures_9_4.jpg", "caption": "Figure 4: Experiments on CIFAR-10 (left) and CIFAR-100 (right). The data points show the average over 5 runs, and the shaded area shows the minimum and the maximum values over the runs", "description": "This figure presents the results of experiments conducted on CIFAR-10 and CIFAR-100 datasets to evaluate the impact of the number of samples and embedding dimension on the accuracy of contrastive learning.  The plots show the fraction of unsatisfied samples over training epochs for various settings.  The shaded regions indicate the variability across multiple runs of the experiments.", "section": "4 Experiments"}, {"figure_path": "H0qu4moFly/figures/figures_16_1.jpg", "caption": "Figure 5: CIFAR-100: the fraction of unsatisfied samples for various choices of the number of samples m. The embedding dimension is d = 128.", "description": "The figure shows the training accuracy on CIFAR-100 dataset for various values of m. The embedding dimension is fixed at 128.  It supports the theoretical result that  \u221am dimensions are required to preserve contrastive samples. For m \u2264 d\u00b2/2 (where d is the embedding dimension), accuracy is near perfect (99%).  Accuracy starts decreasing when m > d\u00b2/2.", "section": "4 Experiments"}]