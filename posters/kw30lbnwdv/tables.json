[{"figure_path": "kW30LbNwdV/tables/tables_7_1.jpg", "caption": "Table 1: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on CIFAR-10 of ResNet-18.", "description": "This table presents the performance comparison of different adversarial robustness methods on the CIFAR-10 dataset using ResNet-18 as the model.  The metrics used are average robustness (higher is better), worst-case robustness (higher is better), and normalized standard deviation (NSD, lower is better).  The NSD metric is used to assess robust fairness, where a lower value indicates better fairness.  The results show the performance under various attacks (Clean, FGSM, PGD, CW\u221e, AA).", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/tables/tables_7_2.jpg", "caption": "Table 1: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on CIFAR-10 of ResNet-18.", "description": "This table presents the results of different adversarial training methods on the CIFAR-10 dataset using ResNet-18 as the model.  It compares the average robustness, the worst-case robustness (robustness on the hardest class), and the normalized standard deviation (NSD) of robustness across classes.  Lower NSD values indicate better fairness.  The metrics are evaluated under four different attacks: FGSM, PGD, CW\u221e, and Auto-Attack (AA).", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/tables/tables_17_1.jpg", "caption": "Table 1: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on CIFAR-10 of ResNet-18.", "description": "This table presents the results of experiments conducted on the CIFAR-10 dataset using the ResNet-18 model.  It compares various adversarial robustness methods (including the proposed ABSLD) across multiple attack types (FGSM, PGD, CW\u221e, and AA). The metrics used are average robustness (higher is better), worst-case robustness (higher is better), and normalized standard deviation (NSD, lower is better, reflecting fairness).", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/tables/tables_17_2.jpg", "caption": "Table 1: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on CIFAR-10 of ResNet-18.", "description": "This table presents the performance comparison of different adversarial training and robustness methods on the CIFAR-10 dataset using ResNet-18 as the model.  The metrics used for comparison are average robustness (higher is better), worst-case robustness (higher is better), and normalized standard deviation (NSD, lower is better).  The NSD metric is specifically designed to capture the fairness of the model's robustness across different classes. Lower values of NSD indicate better fairness. The table shows that ABSLD outperforms existing state-of-the-art methods.", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/tables/tables_18_1.jpg", "caption": "Table 5: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on Tiny-ImageNet of PreActResNet-18.", "description": "This table presents the results of experiments conducted on the Tiny-ImageNet dataset using the PreActResNet-18 model.  The metrics evaluated include average robustness (higher is better), worst-case robustness (higher is better), and normalized standard deviation (NSD, lower is better). The average robustness represents the overall performance of the model across all classes. The worst-case robustness focuses on the model's performance on the most vulnerable class.  The NSD measures the fairness of the model, indicating whether the model is equally robust across all classes.  The table compares three different models: RSLAD, CFA, and ABSLD (the proposed method).", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/tables/tables_18_2.jpg", "caption": "Table 6: Result in average robustness(%) (Avg.\u2191), worst robustness(%) (Worst\u2191), and normalized standard deviation (NSD\u2193) on CIFAR-10 of ResNet-18.", "description": "This table presents the results of average robustness, worst-case robustness, and normalized standard deviation (NSD) on the CIFAR-10 dataset using ResNet-18. It compares the performance of two methods: Manual and Adaptive.  The Manual method uses a static temperature for different classes, while the Adaptive method uses a self-adaptive temperature adjustment strategy.  Higher average and worst robustness values are better, while a lower NSD value indicates better fairness.", "section": "5.3 Ablation Study"}, {"figure_path": "kW30LbNwdV/tables/tables_18_3.jpg", "caption": "Table 7: Robustness (%) of the teachers in our experiments.", "description": "This table presents the robustness of the teacher models used in the ABSLD experiments. The robustness is measured under various attacks (clean, FGSM, PGD, CW\u221e, AA) for three different datasets: CIFAR-10, CIFAR-100, and Tiny-ImageNet.  Each dataset uses a different teacher model architecture tailored for optimal performance on that dataset.", "section": "A.7 The Robustness of Teacher Models"}]