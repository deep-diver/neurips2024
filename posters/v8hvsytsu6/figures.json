[{"figure_path": "V8HVsyTSu6/figures/figures_7_1.jpg", "caption": "Figure 1: Excess risk of standard DRO, OR-WDRO, and UOT-DRO with varied sample size and dimension for linear regression. The error bar denotes \u00b1 standard deviation.", "description": "This figure compares the excess risk (difference between obtained loss and the minimum achievable loss) of three different distributionally robust optimization (DRO) methods: standard DRO, outlier-robust WDRO, and the proposed UOT-DRO. The comparison is done across varying sample sizes (Figure 1a) and dimensions (Figure 1b) in a linear regression setting.  UOT-DRO consistently shows lower excess risk across different sample sizes and dimensions, indicating superior robustness and less sensitivity to data dimensionality, especially compared to the standard DRO method.", "section": "5.1 Linear regression"}, {"figure_path": "V8HVsyTSu6/figures/figures_7_2.jpg", "caption": "Figure 4: Excess risk and accuracy of standard DRO, OR-WDRO, and UOT-DRO with varied dimensions for linear classification. The error bar denotes \u00b1 standard deviation.", "description": "This figure compares the performance of three different distributionally robust optimization (DRO) methods for linear classification tasks across various dimensions.  The x-axis represents the dimensionality of the data, and the y-axis shows the excess risk (the difference between the achieved loss and the minimum possible loss). The plot includes error bars indicating the standard deviation of the results. The figure helps illustrate how each DRO method handles varying dimensional data, allowing readers to assess the robustness of each approach in high-dimensional settings.", "section": "5.2 Linear classification"}, {"figure_path": "V8HVsyTSu6/figures/figures_9_1.jpg", "caption": "Figure 2: Excess risk and accuracy of standard DRO and UOT-DRO with varied sample sizes for logistic regression. The error bar denotes \u00b1 standard deviation.", "description": "This figure displays the performance comparison of standard DRO and the proposed UOT-DRO method on logistic regression tasks. The left panel shows the excess risk (the difference between the achieved loss and the minimum possible loss) for different sample sizes. The right panel shows the accuracy for different sample sizes.  Both panels include error bars, representing the standard deviation across multiple trials, to illustrate the variability of the results.", "section": "5 Experiments"}, {"figure_path": "V8HVsyTSu6/figures/figures_18_1.jpg", "caption": "Figure 1: Excess risk of standard DRO, OR-WDRO, and UOT-DRO with varied sample size and dimension for linear regression. The error bar denotes \u00b1 standard deviation.", "description": "This figure presents the excess risk (difference between the model's loss and the minimum achievable loss) for linear regression using three different methods: standard DRO, OR-WDRO (outlier-robust Wasserstein DRO), and the proposed UOT-DRO method.  The experiment is conducted with varying sample sizes (Figure 1a) and dimensions (Figure 1b) of the dataset, showcasing the robustness and efficiency of UOT-DRO in handling outliers and different data properties.  The error bars show the standard deviation.", "section": "5.1 Linear regression"}, {"figure_path": "V8HVsyTSu6/figures/figures_18_2.jpg", "caption": "Figure 3: Excess risk and accuracy of standard DRO, OR-WDRO, and UOT-DRO with varied sample sizes for linear classification. The error bar denotes \u00b1 standard deviation.", "description": "This figure compares the performance of three different distributionally robust optimization (DRO) methods - standard DRO, outlier-robust WDRO (OR-WDRO), and the proposed UOT-DRO - on a linear classification task.  The x-axis represents the number of samples used for training, and the y-axis shows the excess risk (difference between the achieved loss and the minimum possible loss) and the accuracy. Error bars indicate the standard deviation, showing variability in the results.  The plot demonstrates how the proposed UOT-DRO method achieves higher accuracy with increased sample sizes and outperforms the other methods in terms of excess risk.", "section": "5.2 Linear classification"}, {"figure_path": "V8HVsyTSu6/figures/figures_18_3.jpg", "caption": "Figure 4: Excess risk and accuracy of standard DRO, OR-WDRO, and UOT-DRO with varied dimensions for linear classification. The error bar denotes \u00b1 standard deviation.", "description": "This figure compares the performance of three different distributionally robust optimization (DRO) methods \u2013 Standard DRO, OR-WDRO, and UOT-DRO \u2013 in linear classification tasks, specifically focusing on their robustness to outliers.  The experiment varies the dimensionality (number of features) of the data, while keeping other factors (sample size, outlier contamination levels, etc) constant. The excess risk (the difference between the achieved risk and the minimum achievable risk) is plotted against the dimension.  Error bars show standard deviations across multiple trials, demonstrating the stability of each method. The results show UOT-DRO consistently demonstrates lower excess risk across various dimensions, indicating improved robustness to outliers compared to the other methods.", "section": "5.2 Linear classification"}, {"figure_path": "V8HVsyTSu6/figures/figures_18_4.jpg", "caption": "Figure 4: Excess risk and accuracy of standard DRO, OR-WDRO, and UOT-DRO with varied dimensions for linear classification. The error bar denotes \u00b1 standard deviation.", "description": "This figure compares the performance of three different distributionally robust optimization (DRO) methods for linear classification tasks across different feature dimensions (d).  The x-axis represents the feature dimension, while the y-axis shows both the excess risk (how much worse the model's performance is compared to the best achievable performance) and the accuracy (percentage of correctly classified samples). The figure shows that the proposed UOT-DRO method consistently outperforms standard DRO and OR-WDRO across all feature dimensions, indicating better robustness and generalization.", "section": "5.2 Linear classification"}]