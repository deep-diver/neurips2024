{"references": [{"fullname_first_author": "B. Poole", "paper_title": "Exponential expressivity in deep neural networks through transient chaos", "publication_date": "2016-12-31", "reason": "This paper lays the theoretical foundation for understanding the expressivity and trainability of neural networks through the lens of mean-field theory, which is central to the current work."}, {"fullname_first_author": "S. Schoenholz", "paper_title": "Deep information propagation", "publication_date": "2016-12-31", "reason": "This paper extends the mean-field theory to analyze the backpropagation dynamics in deep neural networks, providing crucial insights into the training dynamics that are relevant to the study of FNOs."}, {"fullname_first_author": "G. Yang", "paper_title": "Mean field residual networks: On the edge of chaos", "publication_date": "2017-12-31", "reason": "This paper applies the mean-field theory to residual networks, a widely used network architecture, and demonstrates similarities in their behavior with that of fully connected networks, which helps to contextualize the behavior of FNOs."}, {"fullname_first_author": "L. Xiao", "paper_title": "Dynamical isometry and a mean field theory of cnns: How to train 10,000-layer vanilla convolutional neural networks", "publication_date": "2018-12-31", "reason": "This paper extends the mean-field theory analysis to convolutional neural networks (CNNs), demonstrating the applicability of the theory across different network architectures, and highlighting shared characteristics with FNOs."}, {"fullname_first_author": "Z. Li", "paper_title": "Fourier neural operator for parametric partial differential equations", "publication_date": "2020-12-31", "reason": "This paper introduces the Fourier Neural Operator (FNO), the subject of the current study, providing the foundation upon which the theoretical and experimental analyses are built."}]}