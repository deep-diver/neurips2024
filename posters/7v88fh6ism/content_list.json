[{"type": "text", "text": "Learning Diffusion Priors from Observations by Expectation Maximization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Fran\u00e7ois Rozet University of Li\u00e8ge francois.rozet@uliege.be ", "page_idx": 0}, {"type": "text", "text": "G\u00e9r\u00f4me Andry University of Li\u00e8ge gandry@uliege.be ", "page_idx": 0}, {"type": "text", "text": "Fran\u00e7ois Lanusse Universit\u00e9 Paris-Saclay, Universit\u00e9 Paris Cit\u00e9, CEA, CNRS, AIM francois.lanusse@cnrs.fr ", "page_idx": 0}, {"type": "text", "text": "Gilles Louppe University of Li\u00e8ge g.louppe@uliege.be ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models recently proved to be remarkable priors for Bayesian inverse problems. However, training these models typically requires access to large amounts of clean data, which could prove difficult in some settings. In this work, we present a novel method based on the expectation-maximization algorithm for training diffusion models from incomplete and noisy observations only. Unlike previous works, our method leads to proper diffusion models, which is crucial for downstream tasks. As part of our method, we propose and motivate an improved posterior sampling scheme for unconditional diffusion models. We present empirical evidence supporting the effectiveness of our method. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Many scientific applications can be formalized as Bayesian inference in latent variable models, where the target is the posterior distribution $p(x\\mid y)\\propto p(y\\hat{\\mid}\\,x)\\,p(x)$ given an observation $y\\in\\mathbb{R}^{M}$ resulting from a forward process $p(y\\mid x)$ and a prior distribution $p(x)$ over the latent variable $\\vec{x}\\in\\mathbb{R}^{N}$ . Notable examples include gravitational lensing inversion [1\u20133], accelerated MRI [4\u20138], unfolding in particle physics [9, 10], and data assimilation [11\u201314]. In all of these examples, the observation $y$ alone is either too incomplete or too noisy to recover the latent $x$ . Additional knowledge in the form of an informative prior $p(x)$ is crucial for valuable inference. ", "page_idx": 0}, {"type": "text", "text": "Recently, diffusion models [15, 16] proved to be remarkable priors for Bayesian inference, demonstrating both quality and versatility [17\u201327]. However, to train a diffusion model for the latent $x$ , one would typically need a large number of latent realizations, which by definition are not or rarely accessible. This is notably the case in earth and space sciences where the systems of interest can only be probed superficially. ", "page_idx": 0}, {"type": "text", "text": "Empirical Bayes (EB) methods [28\u201331] offer a solution to the problem of prior specification in latent variable models when only observations $y$ are available. The objective of EB is to find the parameters $\\theta$ of a prior model $q_{\\theta}(x)$ for which the evidence distribution $\\begin{array}{r}{q_{\\theta}(\\stackrel{.}{y})=\\int p(y\\mid x)\\,q_{\\theta}(x)\\,\\mathrm{d}x}\\end{array}$ is closest to the empirical distribution of observations $p(y)$ . Many EB methods have been proposed over the years, but they remain limited to low-dimensional settings [32\u201337] or simple parametric models [38, 39]. ", "page_idx": 0}, {"type": "text", "text": "In this work, our goal is to use diffusion models for the prior $q_{\\theta}(x)$ , as they are best-in-class for modeling high-dimensional distributions and enable many downstream tasks, including Bayesian inference. This presents challenges for previous empirical Bayes methods which typically rely on models for which the density $q_{\\theta}(x)$ or samples $x\\,\\sim\\,q_{\\theta}(x)$ are differentiable with respect to the parameters $\\theta$ . Instead, we propose an adaptation of the expectation-maximization [40\u201344] algorithm where we alternate between generating samples from the posterior $q_{\\theta}(x\\mid y)$ and training the prior $q_{\\theta}(x)$ on these samples. As part of our method, we propose an improved posterior sampling scheme for unconditional diffusion models, which we motivate theoretically and empirically. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "2 Diffusion Models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The primary purpose of diffusion models (DMs) [15, 16], also known as score-based generative models [45, 46], is to generate plausible data from a distribution $p(x)$ of interest. Formally, adapting the continuous-time formulation of Song et al. [46], samples $\\boldsymbol{x}\\in\\mathbb{R}^{N}$ from $p(x)$ are progressively perturbed through a diffusion process expressed as a stochastic differential equation (SDE) ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}x_{t}=f_{t}\\,x_{t}\\,\\mathrm{d}t+g_{t}\\,\\mathrm{d}w_{t}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $f_{t}\\in\\mathbb{R}$ is the drift coefficient, $g_{t}\\in\\mathbb{R}_{+}$ is the diffusion coefficient, $w_{t}\\in\\mathbb{R}^{N}$ denotes a standard Wiener process and $\\boldsymbol{x}_{t}\\in\\mathbb{R}^{N}$ is the perturbed sample at time $t\\in[0,1]$ . Because the SDE is linear with respect to $x_{t}$ , the perturbation kernel from $x$ to $x_{t}$ is Gaussian and takes the form ", "page_idx": 1}, {"type": "equation", "text": "$$\np(x_{t}\\mid x)={\\mathcal{N}}(x_{t}\\mid\\alpha_{t}\\,x,\\Sigma_{t})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\alpha_{t}$ and $\\Sigma_{t}=\\sigma_{t}^{2}I$ are derived from $f_{t}$ and $g_{t}$ [46\u201349]. Crucially, the forward SDE (1) has an associated family of reverse SDEs [46\u201349] ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}x_{t}=\\left[f_{t}\\,x_{t}-{\\frac{1+\\eta^{2}}{2}}g_{t}^{2}\\,\\nabla_{\\!x_{t}}\\log p(x_{t})\\right]\\mathrm{d}t+\\eta\\,g_{t}\\,\\mathrm{d}w_{t}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\eta\\geq0$ is a parameter controlling stochasticity. In other words, we can draw noise samples $x_{1}\\sim$ $\\boldsymbol{p}(\\boldsymbol{x}_{1})\\approx\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{\\Sigma}_{1})$ and gradually remove the noise therein to obtain data samples $x_{0}\\sim p(x_{0})\\approx p(x)$ by simulating Eq. (3) from $t=1$ to 0 using an appropriate discretization scheme [16, 45, 46, 49\u201352]. In this work, we adopt the variance exploding SDE [45] for which $f_{t}=0$ and $\\alpha_{t}=1$ . ", "page_idx": 1}, {"type": "text", "text": "In practice, the score function $\\nabla_{x_{t}}\\log{p(x_{t})}$ in Eq. (3) is unknown, but can be approximated by a neural network trained via denoising score matching [53, 54]. Several equivalent parameterizations and objectives have been proposed for this task [16, 45, 46, 50\u201352]. In this work, we adopt the denoiser parameterization $d_{\\theta}(x_{t},t)$ and its objective [51] ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\arg\\operatorname*{min}_{\\theta}\\mathbb{E}_{p(x)p(t)p(x_{t}|x)}\\left[\\lambda_{t}\\left\\|d_{\\theta}(x_{t},t)-x\\right\\|_{2}^{2}\\right]\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "for which the optimal denoiser is the mean $\\mathbb{E}[x\\mid x_{t}]$ of $p(\\boldsymbol{x}\\mid\\boldsymbol{x}_{t})$ . Importantly, $\\mathbb{E}[x\\mid x_{t}]$ is linked to the score function through Tweedie\u2019s formula [55\u201358] ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{E}[x\\mid x_{t}]=x_{t}+\\Sigma_{t}\\nabla_{x_{t}}\\log p(x_{t})\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "which allows to use $s_{\\theta}(x_{t})=\\Sigma_{t}^{-1}(d_{\\theta}(x_{t},t)-x_{t})$ as a score estimate in Eq. (3). ", "page_idx": 1}, {"type": "text", "text": "3 Expectation-Maximization ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The objective of the expectation-maximization (EM) algorithm [40\u201344] is to find the parameters $\\theta$ of a latent variable model $q_{\\theta}(x,y)$ that maximize the log-evidence $\\log{q_{\\theta}(y)}$ of an observation $y$ . For a distribution of observations $p(y)$ , the objective is to maximize the expected log-evidence [43, 44] or, equivalently, to minimize the Kullback-Leibler (KL) divergence between $p(y)$ and $q_{\\theta}(y)$ . That is, ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{*}=\\arg\\operatorname*{max}_{\\theta}\\mathbb{E}_{p(y)}\\left[\\log q_{\\theta}(y)\\right]}\\\\ &{\\quad=\\arg\\operatorname*{min}_{\\theta}\\mathrm{KL}\\bigl(p(y)\\,\\|\\,q_{\\theta}(y)\\bigr)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The key idea behind the EM algorithm is that for any two sets of parameters $\\theta_{a}$ and $\\theta_{b}$ , we have ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\frac{q_{\\theta_{a}}(y)}{q_{\\theta_{b}}(y)}=\\log\\frac{q_{\\theta_{a}}(x,y)}{q_{\\theta_{b}}(x,y)}+\\log\\frac{q_{\\theta_{b}}(x\\mid y)}{q_{\\theta_{a}}(x\\mid y)}}\\\\ &{\\qquad\\qquad=\\mathbb{E}_{q_{\\theta_{b}}(x\\mid y)}\\left[\\log\\frac{q_{\\theta_{a}}(x,y)}{q_{\\theta_{b}}(x,y)}\\right]+\\mathrm{KL}\\bigl(q_{\\theta_{b}}(x\\mid y)\\left\\|\\,q_{\\theta_{a}}(x\\mid y)\\right)}\\\\ &{\\qquad\\qquad\\geq\\mathbb{E}_{q_{\\theta_{b}}(x\\mid y)}\\left[\\log q_{\\theta_{a}}(x,y)-\\log q_{\\theta_{b}}(x,y)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "This inequality also holds in expectation over $p(y)$ . Therefore, starting from arbitrary parameters $\\theta_{0}$ , the EM update ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta_{k+1}=\\arg\\underset{\\theta}{\\operatorname*{max}}\\,\\mathbb{E}_{p(y)}\\mathbb{E}_{q_{\\theta_{k}}(x\\mid y)}\\left[\\log q_{\\theta}(x,y)-\\log q_{\\theta_{k}}(x,y)\\right]}\\\\ &{\\qquad=\\arg\\underset{\\theta}{\\operatorname*{max}}\\,\\mathbb{E}_{p(y)}\\mathbb{E}_{q_{\\theta_{k}}(x\\mid y)}\\left[\\log q_{\\theta}(x,y)\\right]\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "leads to a sequence of parameters $\\theta_{k}$ for which the expected log-evidence $\\mathbb{E}_{p(y)}\\left[\\log q_{\\theta_{k}}(y)\\right]$ is monotonically increasing and converges to a local optimum [42\u201344]. ", "page_idx": 2}, {"type": "text", "text": "When the expectation in Eq. (12) is intractable, many have proposed to use Monte Carlo approximations instead [59\u201366]. Previous approaches include Markov chain Monte Carlo (MCMC) sampling, importance sampling, rejection sampling and their variations [63\u201366]. A perhaps surprising advantage of Monte Carlo EM (MCEM) algorithms is that they may be able to overcome local optimum traps [60, 61]. We refer the reader to Ruth [66] for a recent review of MCEM algorithms. ", "page_idx": 2}, {"type": "text", "text": "4 Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Although rarely mentioned in the literature, the expectation-maximization algorithm is a possible solution to the empirical Bayes problem. Indeed, both have the same objective: minimizing the KL between the empirical distribution of observations $p(y)$ and the evidence $q_{\\theta}(y)$ . In the empirical Bayes setting, the forward model $p(y\\mid x)$ is known and only the parameters of the prior $q_{\\theta}(x)$ should be optimized. In this case, Eq. (12) becomes ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta_{k+1}=\\arg\\underset{\\theta}{\\operatorname*{max}}\\,\\mathbb{E}_{p(y)}\\mathbb{E}_{q_{\\theta_{k}}(x\\mid y)}\\left[\\log q_{\\theta}(x)+\\log p(y\\mid x)\\right]}\\\\ &{\\quad\\quad=\\arg\\underset{\\theta}{\\operatorname*{max}}\\,\\mathbb{E}_{p(y)}\\mathbb{E}_{q_{\\theta_{k}}(x\\mid y)}\\left[\\log q_{\\theta}(x)\\right]}\\\\ &{\\quad\\quad=\\arg\\underset{\\theta}{\\operatorname*{min}}\\,\\mathrm{KL}\\bigl(\\pi_{k}(x)\\mid\\mid q_{\\theta}(x)\\bigr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\begin{array}{r}{\\pi_{k}(x)=\\int q_{\\theta_{k}}(x\\mid y)\\,p(y)\\,\\mathrm{d}y}\\end{array}$ . Intuitively, $\\pi_{k}(x)$ and therefore $q_{\\theta_{k+1}}(x)$ assign more density to latents $x$ which are consistent with observations $y\\sim p(y)$ than $q_{\\theta_{k}}(x)$ . In this work, we consider a special case of the empirical Bayes problem where each observation $y$ has an associated measurement matrix $A$ and the forward process takes a linear Gaussian form $p({\\dot{y}}\\mid x,A)={\\mathcal{N}}(y\\mid A x,\\Sigma_{y})$ . This formulation allows the forward process to be potentially different for each observation $y$ . For example, if the position or environment of a sensor changes, the measurement matrix $A$ may also change, which leads to an empirical distribution of pairs $(y,A)\\sim p(y,A)$ . As a result, $\\pi_{k}(x)$ in Eq. (15) becomes $\\textstyle\\pi_{k}(x)=\\int{\\dot{q_{\\theta_{k}}}}(x\\mid y,A)\\,p(y,A)\\,\\mathrm{d}{\\dot{y}}$ . ", "page_idx": 2}, {"type": "text", "text": "4.1 Pipeline ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Now that our goals and assumptions are set, we present our method to learn a diffusion model $q_{\\theta}(x)$ for the latent $x$ from observations $y$ by expectation-maximization. The idea is to decompose Eq. (15) into (i) generating a dataset of i.i.d. samples from $\\pi_{k}(x)$ and (ii) training $q_{\\theta_{k+1}}(x)$ to reproduce the generated dataset. We summarize the pipeline in Algorithms $1,2$ and 3, provided in Appendix A due to space constraints. ", "page_idx": 2}, {"type": "text", "text": "Expectation To draw from $\\pi_{k}(x)$ , we first sample a pair $(y,A)\\,\\sim\\,p(y,A)$ and then generate $\\bar{x}\\ \\stackrel{-}{\\sim}q_{\\theta_{k}}(x\\mid y,A)$ from the posterior. Unlike previous MCEM algorithms that rely on expensive and hard to tune sampling strategies [63\u201366], the use of a diffusion model enables efficient and embarrassingly parallelizable posterior sampling [21\u201323]. However, the quality of posterior samples is critical for the EM algorithm to converge properly [63\u201366] and, in this regard, we find previous posterior sampling methods [21\u201323, 25, 26] to be unsatisfactory. Therefore, we propose an improved posterior sampling scheme, named moment matching posterior sampling (MMPS), which we present and motivate in Section 4.2. We evaluate MMPS independently from the context of learning from observations in Appendix E. ", "page_idx": 2}, {"type": "text", "text": "Maximization We parameterize our diffusion model $q_{\\theta}(x)$ by a denoiser network $d_{\\theta}(x_{t},t)$ and train it via denoising score matching [53, 54], as presented in Section 2. To accelerate the training, we start each iteration with the previous parameters $\\theta_{k}$ . ", "page_idx": 2}, {"type": "text", "text": "Initialization An important part of our pipeline is the initial prior $q_{0}(x)$ . Any initial prior leads to a local optimum [42\u201344], but an informed initial prior can reduce the number of iterations until convergence. In our experiments, we take a Gaussian distribution ${\\mathcal{N}}(x\\mid\\mu_{x},\\Sigma_{x})$ as initial prior and fit its mean and covariance by \u2013 you guessed it! \u2013 expectation-maximization. Fitting a Gaussian distribution by EM is very fast as the maximization step can be conducted in closed-form, especially for low-rank covariance approximations [67]. ", "page_idx": 3}, {"type": "text", "text": "An alternative we do not explore in this work would be to use a pre-trained diffusion model as initial prior. Pre-training can be contucted on data we expect to be similar to the latents, such as computer simulations or even video games. The more similar, the faster the EM algorithm converges. However, if the initial prior $q_{0}(x)$ does not cover latents that are otherwise plausible under the observations, the following priors $q_{\\theta_{k}}(x)$ may not cover these latents either. A conservative initial prior is therefore preferable for scientific applications. ", "page_idx": 3}, {"type": "text", "text": "4.2 Moment Matching Posterior Sampling ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To sample from the posterior distribution $q_{\\theta}(x\\mid y)\\propto q_{\\theta}(x)\\,p(y\\mid x)$ of our diffusion prior $q_{\\theta}(x)$ , we have to estimate the posterior score $\\nabla_{x_{t}}\\log q_{\\theta}(x_{t}\\mid y)$ and plug it into the reverse SDE (3). In this section, we propose and motivate an improved approximation for the posterior score. As this contribution is not bound to the context of EM, we temporarily switch back to the notations of Section 2 where our prior is denoted $p(x)$ instead of $q_{\\theta}(x)$ . ", "page_idx": 3}, {"type": "text", "text": "Diffusion posterior sampling Thanks to Bayes\u2019 rule, the posterior score $\\nabla_{x_{t}}\\log{p(x_{t}\\mid y)}$ can be decomposed into two terms [17, 18, 21\u201325, 46] ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\nabla_{\\boldsymbol{x}_{t}}\\log{p(\\boldsymbol{x}_{t}\\mid\\boldsymbol{y})}=\\nabla_{\\boldsymbol{x}_{t}}\\log{p(\\boldsymbol{x}_{t})}+\\nabla_{\\boldsymbol{x}_{t}}\\log{p(\\boldsymbol{y}\\mid\\boldsymbol{x}_{t})}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As an estimate of the prior score $\\nabla_{x_{t}}\\log{p(x_{t})}$ is already available via the denoiser $d_{\\theta}(x_{t},t)$ , the remaining task is to estimate the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ . Assuming a differentiable measurement function $\\boldsymbol{\\mathcal{A}}$ and a Gaussian forward process $p(y\\mid x)={\\mathcal{N}}(y\\mid A(x),\\Sigma_{y})$ , Chung et al. [21] propose the approximation ", "page_idx": 3}, {"type": "equation", "text": "$$\np(\\boldsymbol{y}\\mid\\boldsymbol{x}_{t})=\\int p(\\boldsymbol{y}\\mid\\boldsymbol{x})\\,p(\\boldsymbol{x}\\mid\\boldsymbol{x}_{t})\\,\\mathrm{d}\\boldsymbol{x}\\approx\\mathcal{N}\\,(\\boldsymbol{y}\\mid\\mathcal{A}(\\mathbb{E}[\\boldsymbol{x}\\mid\\boldsymbol{x}_{t}]),\\boldsymbol{\\Sigma}_{\\boldsymbol{y}})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which allows to estimate the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ without training any other network than $d_{\\theta}(x_{t},t)\\approx\\mathbb{E}[x\\mid x_{t}]$ . The motivation behind Eq. (17) is that, when $\\sigma_{t}$ is small, assuming that $p(x\\mid x_{t})$ is narrowly concentrated around its mean $\\mathbb{E}[x\\mid x_{t}]$ is reasonable. However, this approximation is very poor when $\\sigma_{t}$ is not negligible. Consequently, DPS [21] is unstable, does not properly cover the support of the posterior $p(x\\mid y)$ and often leads to samples $x$ which are inconsistent with the observation $y$ [22\u201325]. ", "page_idx": 3}, {"type": "text", "text": "Moment matching To address these flaws, following studies [22\u201325] take the covariance $\\mathbb{V}[x\\mid x_{t}]$ into account when estimating the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ . Specifically, they consider the Gaussian approximation ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(x\\mid x_{t})=\\mathcal{N}\\left(x\\mid\\mathbb{E}[x\\mid x_{t}],\\mathbb{V}[x\\mid x_{t}]\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is closest to $p(x\\mid x_{t})$ in Kullback-Leibler (KL) divergence [68]. Then, assuming a linear Gaussian forward process $p(y\\mid x)={\\mathcal{N}}(y\\mid A x,\\Sigma_{y})$ , we obtain [68] ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(y\\mid x_{t})=\\int p(y\\mid x)\\,q(x\\mid x_{t})\\,\\mathrm{d}x=\\mathcal{N}\\left(y\\mid A\\mathbb{E}[x\\mid x_{t}],\\Sigma_{y}+A\\mathbb{V}[x\\mid x_{t}]A^{\\top}\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which allows to estimate the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\nabla_{x_{t}}\\log{q(y\\mid x_{t})}=\\nabla_{x_{t}}\\mathbb{E}[x\\mid x_{t}]^{\\top}A^{\\top}\\big(\\Sigma_{y}+A\\mathbb{V}[x\\mid x_{t}]A^{\\top}\\big)^{-1}\\big(y-A\\mathbb{E}[x\\mid x_{t}]\\big)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "under the assumption that the derivative of $\\mathbb{V}[x\\mid x_{t}]$ with respect to $x_{t}$ is negligible [24, 25]. Even with simple heuristics for $\\mathbb{V}[x\\mid x_{t}]$ , such as $\\Sigma_{t}$ [20] or $(\\Sigma_{t}^{-1}+\\Sigma_{x}^{-1})^{-1}$ [22, 23], this adaptation leads to significantly more stable sampling and better coverage of the posterior $p(x\\mid y)$ than DPS [21]. However, we find that heuristics lead to overly dispersed posteriors $q(x_{t}\\mid y)\\propto p(x_{t})\\,q(y\\mid x_{t})$ in the presence of local covariances \u2013 i.e. covariances in the neighborhood of $x_{t}$ . ", "page_idx": 3}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/c4d1464f7ace65a7ff49204d8cc274e99102ee5934a84e35b387d1b5d82811c7.jpg", "img_caption": ["Figure 1. Illustration of the posterior $q(x_{t}\\mid y)$ for the Gaussian approximation $q(x\\mid x_{t})$ when the prior $p(x)$ lies on a manifold. Ellipses represent $95\\,\\%$ credible regions of $q(x\\mid x_{t})$ . $(\\pmb{\\mathsf{A}})$ With $\\Sigma_{t}$ as heuristic for $\\mathbb{V}[x\\mid x_{t}]$ , any $x_{t}$ whose mean $\\mathbb{E}[x\\mid x_{t}]$ is close to the plane $y=A x$ is considered likely. (B) With $\\mathbb{V}[x\\mid x_{t}]$ , more regions are correctly pruned. (C) Ground-truth $p(x_{t}\\mid y)$ and $p(\\boldsymbol{x}\\mid\\boldsymbol{x}_{t})$ for reference. "], "img_footnote": [], "page_idx": 4}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/33f4afddaba09a6dea3c5e966855d6508cbae394a6bed4534afaaa34af97c319.jpg", "img_caption": ["Figure 2. Sinkhorn divergence [69] between the posteriors $p(x_{t}\\mid y)$ and $q(x_{t}\\mid y)$ for different heuristics of $\\mathbb{V}[x\\mid x_{t}]$ when the prior $p(x)$ lies on 1-d manifolds embedded in $\\mathbb{R}^{3}$ . Lines and shades represent the 25-50-75 percentiles for 64 randomly generated manifolds [71] and measurement matrices $A\\in\\mathbb{R}^{1\\times3}$ . Using $\\mathbb{V}[x\\mid x_{t}]$ instead of heuristics leads to orders of magnitude more accurate posteriors $q(x_{t}\\mid y)$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "We illustrate this behavior in Figure 1 and measure its impact as the Sinkhorn divergence [69, 70] between the posteriors $p(x_{t}\\mid\\boldsymbol{\\mathbf{\\mu}}_{y})$ and $q(x_{t}\\mid y)$ when the prior $p(x)$ lies on randomly generated 1-dimensional manifolds [71] embedded in $\\mathbb{R}^{3}$ . The prior $p(x)$ is modeled as a mixture of isotropic Gaussians centered around points of the manifold, which gives access to $p(x_{t}),\\mathbb{E}[x\\mid x_{t}]$ and $\\mathbb{V}[x\\mid{\\bar{x}}_{t}]$ analytically. The results, presented in Figure 2, indicate that using $\\mathbb{V}[x\\mid x_{t}]$ instead of heuristics leads to orders of magnitude more accurate posteriors $q(x_{t}\\mid y)$ . We expect this gap to further increase with real high-dimensional data as the latter often lies along low-dimensional manifolds and, therefore, presents strong local covariances. ", "page_idx": 4}, {"type": "text", "text": "Because the MCEM algorithm is sensitive to the accuracy of posterior samples [63\u201366], we choose to estimate $\\mathbb{V}[x\\mid x_{t}]$ using Tweedie\u2019s covariance formula [55\u201358] ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{V}[x\\mid x_{t}]=\\Sigma_{t}+\\Sigma_{t}\\,\\nabla_{x_{t}}^{2}\\log p(x_{t})\\,\\Sigma_{t}}\\\\ &{\\qquad\\qquad\\quad=\\Sigma_{t}\\nabla_{x_{t}}^{\\top}\\mathbb{E}[x\\mid x_{t}]\\approx\\Sigma_{t}\\nabla_{x_{t}}^{\\top}d_{\\theta}(x_{t},t)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Conjugate gradient method As noted by Finzi et al. [24], explicitly computing and materializing the Jacobian $\\nabla_{x_{t}}^{\\top}d_{\\theta}(x_{t},t)\\in\\mathbb{R}^{N\\times N}$ is intractable in high dimension. Furthermore, even if we had access to $\\mathbb{V}[x\\mid x_{t}]$ , naively computing the inverse of the matrix $\\Sigma_{y}+A\\mathbb{V}[x\\mid x_{t}]A^{\\top}$ in Eq. (20) would still be intractable. Fortunately, we observe that the matrix $\\Sigma_{y}+A\\mathbb{V}[x\\mid x_{t}]A^{\\top}$ is symmetric positive definite (SPD) and, therefore, compatible with the conjugate gradient (CG) method [72]. The CG method is an iterative algorithm to solve linear systems of the form $M v=b$ where the SPD matrix $M$ and the vector $b$ are known. Importantly, the CG method only requires implicit access to $M$ through an operator that performs the matrix-vector product $M v$ given a vector $v$ . In our case, the linear system to solve is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{y}-\\boldsymbol{A}\\mathbb{E}[\\boldsymbol{x}\\mid\\boldsymbol{x}_{t}]=\\left(\\boldsymbol{\\Sigma}_{\\boldsymbol{y}}+\\boldsymbol{A}\\mathbb{V}[\\boldsymbol{x}\\mid\\boldsymbol{x}_{t}]\\boldsymbol{A}^{\\top}\\right)\\boldsymbol{v}}\\\\ &{\\qquad\\qquad\\qquad=\\boldsymbol{\\Sigma}_{\\boldsymbol{y}}\\boldsymbol{v}+\\boldsymbol{A}\\big(\\underbrace{\\boldsymbol{v}^{\\top}\\boldsymbol{A}\\,\\boldsymbol{\\Sigma}_{t}\\boldsymbol{\\nabla}_{\\!\\!\\!x_{t}}^{\\top}\\mathbb{E}[\\boldsymbol{x}\\mid\\boldsymbol{x}_{t}]}_{\\mathrm{vector-Jacobian\\,product}}\\big)^{\\top}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Within automatic differentiation frameworks [73, 74], the vector-Jacobian product in the right-hand side can be cheaply evaluated. In practice, due to numerical errors and imperfect training, the Jacobian $\\nabla_{x_{t}}^{\\top}d_{\\theta}(x_{t},t)\\approx\\nabla_{x_{t}}^{\\top}\\mathbb{E}[x\\mid x_{t}]$ is not always perfectly SPD. Consequently, the CG method becomes unstable after a number of iterations and fails to reach an exact solution. Fortunately, we find that truncating the CG algorithm to very few iterations (1 to 3) already leads to significant improvements over using heuristics for the covariance $\\mathbb{V}[x\\mid x_{t}]$ . Alternatively, the CG method can be replaced by other iterative algorithms that can solve non-symmetric non-definite linear systems, such as GMRES [75] or BiCGSTAB [76], at the cost of slower convergence. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "5 Results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We conduct three experiments to demonstrate the effectiveness of our method. We design the first experiment around a low-dimensional latent variable $x$ whose ground-truth distribution $p(x)$ is known. In this setting, we can use asymptotically exact sampling schemes such as predictor-corrector sampling [23, 46] or twisted diffusion sampling [77] without worrying about their computational cost. This allows us to validate our expectation-maximization pipeline (see Algorithm 1) in the limit of (almost) exact posterior sampling. The remaining experiments target two benchmarks from previous studies: corrupted CIFAR-10 and accelerated MRI. These tasks provide a good understanding of how our method would perform in typical empirical Bayes applications with limited data and compute. ", "page_idx": 5}, {"type": "text", "text": "5.1 Low-dimensional manifold ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this experiment, the latent variable $x\\in\\mathbb{R}^{5}\\sim p(x)$ lies on a random 1-dimensional manifold embedded in $\\mathbb{R}^{5}$ represented in Figure 7. Each observation $y\\in\\mathbb{R}^{2}\\sim\\mathcal{N}(y\\mid A x,\\Sigma_{y})$ is the result of a random linear projection of a latent $x$ plus isotropic Gaussian noise $(\\Sigma_{y}=10^{-4}I)$ . The rows of the measurement matrix $A\\in\\mathbb{R}^{2\\times5}$ are drawn uniformly from the unit sphere ${\\mathbb S}^{4}$ . We note that observing all push-forward distributions $p(u^{\\top}x)$ with $u\\in\\mathbb{S}^{\\tilde{N}-1}$ of a distribution $p(x)$ in $\\mathbb{R}^{N}$ is sufficient to recover $p(x)$ in theory [78, 79]. In practice, we generate a finite training set of $2^{16}$ pairs $(y,A)$ . ", "page_idx": 5}, {"type": "text", "text": "We train a DM $q_{\\theta}(x)$ parameterized by a multi-layer perceptron $d_{\\theta}(x_{t},t)$ for $K=32$ EM iterations. We apply Algorithm 3 to estimate the posterior score $\\nabla_{x_{t}}\\log{q_{\\theta}(x_{t}\\mid y,A)}$ , but rely on the predictorcorrector [23, 46] sampling scheme with a large number (4096) of correction steps to sample from the posterior $q_{\\theta}(x\\mid y,A)$ . We provide additional details such as noise schedule, network architectures, and learning rate in Appendix C. ", "page_idx": 5}, {"type": "text", "text": "As expected, the model $q_{\\theta_{k}}(x)$ converges towards a stationary distribution whose marginals are close to the marginals of the ground-truth $p(x)$ , as illustrated in Figure 3. We attribute the remaining artifacts to finite data and inaccuracies in our sampling scheme. ", "page_idx": 5}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/3b87ce463db5b6677b5485edb8a7a5121d617cfab4d4e032ff2dfffa00d4fac8.jpg", "img_caption": ["Figure 3. Illustration of 2-d marginals of the model $q_{\\theta_{k}}(x)$ along the EM iterations. The initial Gaussian prior $q_{0}(x)$ leads to a very dispersed first model $q_{\\theta_{1}}(x)$ . The EM algorithm gradually prunes the density regions which are inconsistent with observations, until it reaches a stationary distribution. The marginals of the final distribution are close to the marginals of the ground-truth distribution. "], "img_footnote": [], "page_idx": 5}, {"type": "table", "img_path": "7v88Fh6iSM/tmp/03cd3babe5c0875c6f431764b2134f45eaad9b684d6827e1689810f989df812b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Table 1. Evaluation of final models trained on corrupted CIFAR-10. Our method outperforms AmbientDiffusion [80] at similar corruption levels. Using heuristics for $\\mathbb{V}[x\\mid x_{t}]$ instead of Tweedie\u2019s formula greatly decreases the sample quality. ", "page_idx": 6}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/7231c6c689bb65a005e6e2a133c7bca6a8ebd65d079fd4e42953b92b542ae4a2.jpg", "img_caption": ["Figure 4. FID of $q_{\\theta_{k}}(x)$ along the EM iterations for the corrupted CIFAR-10 experiment. "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/a7f93ff46c24c1c3c0df6392207437825eecfe7779b4e054bc19031cde4cbd8c.jpg", "img_caption": ["Figure 5. Example of samples from the model $q_{\\theta_{k}}(x)$ along the EM iterations for the corrupted CIFAR-10 experiment with $\\rho=0.75$ . We use the deterministic DDIM [50] sampling scheme for easier comparison. Generated images become gradually more detailed and less noisy. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "5.2 Corrupted CIFAR-10 ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Following Daras et al. [80], we take the 50 000 training images of the CIFAR-10 [81] dataset as latent variables $x$ . A single observation $y$ is generated for each image $x$ by randomly deleting pixels with probability $\\rho$ . The measurement matrix $A$ is therefore a binary diagonal matrix. We add negligible isotropic Gaussian noise $(\\Sigma_{y}\\,=\\,10^{-6}I)$ for fair comparison with AmbientDiffusion [80] which cannot handle noisy observations. ", "page_idx": 6}, {"type": "text", "text": "For each corruption rate $\\rho\\,\\in\\,\\{0.25,0.5,0.75\\}$ , we train a DM $q_{\\theta}(x)$ parameterized by a U-Net [82] inspired network $d_{\\theta}(x_{t},t)$ for $K=32\\,\\mathrm{EM}$ iterations. We apply Algorithm 2 with $T=256$ discretization steps and $\\eta=1$ to approximately sample from the posterior $q_{\\theta}(x\\mid y,A)$ . We apply Algorithm 3 with several heuristics for $\\mathbb{V}[x\\mid x_{t}]$ to compare their results against Tweedie\u2019s covariance formula. For the latter, we truncate the conjugate gradient method in Algorithm 4 to a single iteration. ", "page_idx": 6}, {"type": "text", "text": "For each model $q_{\\theta_{k}}(x)$ , we generate a set of 50 000 images and evaluate its Inception score (IS) [83] and Fr\u00e9chet Inception distance (FID) [84] against the uncorrupted training set of CIFAR-10. We report the results in Table 1 and Figures 4 and 5. At $75\\,\\%$ of corruption, our method performs similarly to AmbientDiffusion [80] at only $20\\,\\%$ of corruption. On the contrary, using heuristics for $\\mathbb{V}[x\\mid x_{t}]$ leads to poor sample quality. ", "page_idx": 6}, {"type": "text", "text": "5.3 Accelerated MRI ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Magnetic resonance imaging (MRI) is a non-invasive medical imaging technique used in radiology to inspect the internal anatomy and physiology of the body. MRI measurements of an object are obtained in the frequency domain, also called $k$ -space, using strong magnetic fields. However, measuring the entire $k$ -space can be time-consuming and expensive. Accelerated MRI [4\u20138] consists in inferring the scanned object based on partial, possibly randomized and noisy, frequency measurements. ", "page_idx": 6}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/76c51aa619f5e2202966a9eb83239026894848fe9d98af4268ac8bf921288fee.jpg", "img_caption": ["Figure 6. Examples of posterior samples for accelerated MRI using a diffusion prior trained from $k$ - space observations only. Posterior samples are detailed and present plausible variations, while remaining consistent with the observation. We provide the zero-filled inverse, where missing frequencies are set to zero, as baseline. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "In this experiment, following Kawar et al. [85], we consider the single-coil knee MRI scans from the fastMRI [7, 8] dataset. We treat each slice between the 10th and 40th of each scan as an independent latent variable $x$ , represented as a $320\\times320$ gray-scale image. Scans are min-max normalized such that pixel values range between $-2$ and 2. A single observation $y$ is generated for each slice $x$ by first applying the discrete Fourier transform and then a random horizontal frequency sub-sampling with acceleration factor $R=6$ [85, 86], meaning that a proportion $^1\\!/\\!R$ of all frequencies are observed on average. Eventually, we obtain $24\\,853\\;k$ -space observations to which we add isotropic Gaussian noise $(\\Sigma_{y}^{-}=10^{-4}I)$ to match Kawar et al. [85]. ", "page_idx": 7}, {"type": "text", "text": "Once again, we train a DM $q_{\\theta}(x)$ parameterized by a U-Net [82] inspired network $d_{\\theta}(x_{t},t)$ for $K\\,=\\,16~\\mathrm{EM}$ iterations. We apply Algorithm 2 with $T\\,=\\,64$ discretization steps and $\\eta\\,=\\,1$ to approximately sample from the posterior $q_{\\theta}(x\\mid y,A)$ and truncate the conjugate gradient method in Algorithm 4 to 3 iterations. After training, we employ our final model $q_{\\theta_{K}}(x)$ as a diffusion prior for accelerated MRI. Thanks to our moment matching posterior sampling, we are able to infer plausible scans at acceleration factors up to $R=32$ , as shown in Figure 6. Our samples are noticeably more detailed than the ones of Kawar et al. [85]. We choose not to report the PSNR/SSIM of our samples as these metrics only make sense for regression tasks and unfairly penalize proper generative models [87, 88]. We provide prior samples in Figure 13 and posterior samples for another kind of forward process in Figure 14. ", "page_idx": 7}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Empirical Bayes A number of previous studies have investigated the use of deep learning to solve the empirical Bayes problem. Louppe et al. [35] use adversarial training for learning a prior distribution that reproduces the empirical distribution of observations when pushed through a nondifferentiable black-box forward process. Dockhorn et al. [33] use normalizing flows [89, 90] to estimate the prior density by variational inference when the forward process consists of additive noise. Vandegar et al. [36] also use normalizing flows but consider black-box forward processes for which the likelihood $p(y\\mid x)$ is intractable. They note that empirical Bayes is an ill-posed problem in that distinct prior distributions may result in the same distribution over observations. Vetter et al. [37] address this issue by targeting the prior distribution of maximum entropy while minimizing the sliced-Wasserstein distance [78, 79] with the empirical distribution of observations. These methods rely on generative models $q_{\\theta}(x)$ for which the density $q_{\\theta}(x)$ or samples $x\\sim q_{\\theta}(x)$ are differentiable with respect to the parameters $\\theta$ , which is not or hardly the case for diffusion models. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Closer to this work, Daras et al. [80] and Kawar et al. [85] attempt to train DMs from linear observations only. Daras et al. [80] consider noiseless observations of the form $y=A x$ and train a network $d_{\\theta}(A x_{t},A,t)$ to approximate $\\mathbb{E}[x\\mid A x_{t}]$ under the assumption that $\\mathbb{E}[A^{\\top}A]$ is full-rank. The authors argue that $\\mathbb{E}[x\\mid A x_{t}]$ can act as a surrogate for $\\mathbb{E}[x\\mid x_{t}]$ . Similarly, Kawar et al. [85] assume Gaussian observations $\\dot{y}\\sim\\bar{\\mathcal{N}}(y\\mid A x,\\Sigma_{y})$ and train a network $\\bar{d}_{\\theta}(P x_{t},t)$ to approximate $\\mathbb{E}[x\\mid P x_{t}]$ under the assumption that $\\mathbb{E}[P]$ is full-rank where $P=A^{+}A$ and $A^{+}$ is the Moore-Penrose pseudoinverse of $A$ . The authors assume that $d_{\\theta}(P x_{t},t)$ can generalize to $P=I$ , even if the training data does not contain $P=I$ . In both cases, the trained networks are not proper denoisers approximating $\\mathbb{E}[x\\mid x_{t}]$ and cannot reliably parameterize a standard diffusion model, which is problematic for downstream applications. Notably, in the case of Bayesian inference, they require custom posterior sampling schemes such as the one proposed by Aali et al. [91] for AmbientDiffusion [80] models. Conversely, in this work, we do not make modifications to the denoising score matching objective [53, 54], which guarantees a proper DM that is compatible with any posterior sampling scheme at every iteration. In addition, we find that our method leads to quantitatively and qualitatively better diffusion priors. ", "page_idx": 8}, {"type": "text", "text": "In a concurrent work, Daras et al. [92] propose an algorithm to train DMs from noisy ( $A=I$ and $\\Sigma_{y}=\\sigma_{y}^{2}I)$ data by enforcing the \u201cconsistency\u201d of the denoiser along diffusion paths. They prove that the mean $\\mathbb{E}[x\\mid x_{t}]$ is the unique consistent denoiser. Interestingly, this training algorithm also relies on posterior samples, which are easy to obtain thanks to the white noise assumption. ", "page_idx": 8}, {"type": "text", "text": "Posterior sampling Recently, there has been much work on conditional generation using unconditional diffusion models, most of which adopt the posterior score decomposition in Eq. (16). As covered in Section 4.2, Chung et al. [21] propose an analytical approximation for the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ when the forward process $p(y\\mid x)$ is Gaussian. Song et al. [22] and Rozet et al. [23] improve this approximation by taking the covariance $\\mathbb{V}[x\\mid x_{t}]$ into account in the form of simple heuristics. We build upon this idea and replace heuristics with a proper estimate of the covariance $\\mathbb{V}[x\\mid x_{t}]$ based on Tweedie\u2019s covariance formula [55\u201358]. Finzi et al. [24] take the same approach, but materialize the matrix $A\\mathbb{V}[x\\mid x_{t}]A^{\\top}$ which is intractable in high dimension. Boys et al. [25] replace the covariance $\\mathbb{V}[x\\mid x_{t}]$ with a row-sum approximation $\\mathrm{diag}(e^{\\top}\\mathbb{V}[x\\mid x_{t}])$ where $e$ is the all-ones vector. This approximation is only valid when $\\mathbb{V}[x\\mid x_{t}]$ is diagonal, which limits its applicability. Instead, we take advantage of the conjugate gradient method [72] to avoid materializing $\\dot{A}\\Dot{\\mathbb{V}}[x\\mid x_{t}]\\,\\boldsymbol{\\dot{A}}^{\\top}$ . A potential cheaper solution is to train a sparse approximation of $\\mathbb{V}[x\\mid x_{t}]$ , as proposed by Peng et al. [93], but this approach is less general and not immediately applicable to any diffusion model. ", "page_idx": 8}, {"type": "text", "text": "A parallel line of work [94\u201396] extends the conditioning of diffusion models to arbitrary loss terms $\\ell(x,y)\\,\\propto\\,-\\log p(y\\mid x)$ , for which no reliable analytical approximation of the likelihood score $\\nabla_{x_{t}}\\log{p(y\\mid x_{t})}$ exists. Song et al. [94] rely on Monte Carlo approximations of the likelihood $\\begin{array}{r}{p(\\dot{y}\\mid x_{t})\\,=\\,\\int p(y\\,\\mid\\,x)\\,p(x\\,\\mid\\,x_{t})\\,\\mathrm{d}x}\\end{array}$ by sampling from a Gaussian approximation of $p(x\\mid x_{t})$ . Conversely, He et al. [96] use the mean $\\mathbb{E}[x\\mid x_{t}]$ as a point estimate for $p(x\\mid x_{t})$ , but leverage a pre-trained encoder-decoder pair to project the updates of $x_{t}$ within its manifold. We note that our use of the covariance $\\mathbb{V}[x\\mid x_{t}]$ similarly leads to updates tangent to the manifold of $x_{t}$ . ", "page_idx": 8}, {"type": "text", "text": "Finally, Wu et al. [77] propose a particle-based posterior sampling scheme that is asymptotically exact in the limit of infinitely many particles as long as the likelihood approximation $q(\\bar{y}\\mid\\bar{x}_{t})$ \u2013 here named the twisting function \u2013 converges to $p(y\\mid x)$ as $t$ approaches 0. Using TDS [77] as part of our expectation-maximization pipeline could lead to better results and/or faster convergence, at the cost of computational resources. In addition, the authors note that the efficiency of TDS [77] depends on how closely the twisting function approximates the exact likelihood. In this regard, our moment matching Gaussian approximation in Eq. (19) could be a good twisting candidate. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "7 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "To the best of our knowledge, we are the first to formalize the training of diffusion models from corrupted observations as an empirical Bayes [28\u201331] problem. In this work, we limit our analysis to linear Gaussian forward processes to take advantage of accurate and efficient high-dimensional posterior sampling schemes. This contrasts with typical empirical Bayes methods which target low-dimensional latent spaces and highly non-linear forward processes [33\u201337]. In addition, as mentionned in Section 6, these EB methods are not applicable to diffusion models. As such, we choose to benchmark our work against similar methods in the diffusion model literature [80, 85], but stress that a proper comparison with previous empirical Bayes methods would be valuable for both communities. We also note that Monte Carlo EM [59\u201366] can handle arbitrary forward processes $p(y~\\vert~x)$ as long as one can sample from the posterior $q_{\\theta}(x\\mid y)$ . Therefore, our method could be adapted to any kind of forward processes in the future. We believe that the works of Dhariwal et al. [97] and Ho et al. [98] on diffusion guidance are good avenues for adapting our method to non-linear, non-differentiable, or even black-box forward processes. ", "page_idx": 9}, {"type": "text", "text": "From a computational perspective, the iterative nature of our expectation-maximization method is a drawback compared to previous works [80, 85]. Notably, generating enough samples from the posterior can be expensive, although embarrassingly parallelizable. In addition, even though the architecture and training of the model $q_{\\theta}(x)$ itself are simpler than in previous works [80, 85], the sampling step adds a significant amount of complexity, especially as the convergence of our method is sensitive to the quality of posterior samples. In fact, we find that previous posterior sampling methods [21\u201323, 25, 26] lead to disappointing results, which motivates us to develop a better one. ", "page_idx": 9}, {"type": "text", "text": "As such, moment matching posterior sampling (MMPS) is a byproduct of our work. However, it is not bound to the context of learning from observations and is applicable to any linear inverse problem given a pre-trained diffusion prior. In Appendix E, we evaluate MMPS against previous posterior sampling methods for several linear inverse problems on the FFHQ [99] dataset. We find that MMPS consistently outperforms previous methods, both qualitatively and quantitatively. MMPS is remarkably stable and requires fewer sampling steps to generate qualitative samples, which largely makes up for its slightly higher step cost. ", "page_idx": 9}, {"type": "text", "text": "Finally, as mentioned in Section 6, empirical Bayes is an ill-posed problem in that distinct prior distributions may result in the same distribution over observations. In other words, it is generally impossible to identify \u201cthe\u201d ground-truth distribution $p(x)$ given an empirical distribution of observations $p(y)$ . Instead, for a sufficiently expressive diffusion model, our EM method will eventually converge to a prior $q_{\\theta}(x)$ that is consistent with $p(y)$ , but generally different from $p(x)$ . Following the maximum entropy principle, as advocated by Vetter et al. [37], is left to future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Fran\u00e7ois Rozet and G\u00e9r\u00f4me Andry are research fellows of the F.R.S.-FNRS (Belgium) and acknowledge its financial support. ", "page_idx": 9}, {"type": "text", "text": "The present research benefited from computational resources made available on Lucia, the Tier-1 supercomputer of the Walloon Region, infrastructure funded by the Walloon Region under the grant $\\mathtt{n}^{\\circ}1910247$ . The computational resources have been provided by the Consortium des \u00c9quipements de Calcul Intensif (C\u00c9CI), funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under the grant $\\mathtt{n}^{\\circ}2.5020.11$ and by the Walloon Region. ", "page_idx": 9}, {"type": "text", "text": "MRI data used in the preparation of this article were obtained from the NYU fastMRI Initiative database [7, 8]. As such, NYU fastMRI investigators provided data but did not participate in analysis or writing of this report. A listing of NYU fastMRI investigators, subject to updates, can be found at https://fastmri.med.nyu.edu/. The primary goal of fastMRI is to test whether machine learning can aid in the reconstruction of medical images. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] S. J. Warren and S. Dye. \u201cSemilinear Gravitational Lens Inversion\u201d. In The Astrophysical Journal (2003).   \n[2] Warren R. Morningstar et al. \u201cData-driven Reconstruction of Gravitationally Lensed Galaxies Using Recurrent Inference Machines\u201d. In The Astrophysical Journal (2019). [3] Siddharth Mishra-Sharma and Ge Yang. \u201cStrong Lensing Source Reconstruction Using Continuous Neural Fields\u201d. 2022.   \n[4] Shanshan Wang et al. \u201cAccelerating magnetic resonance imaging via deep learning\u201d. In International Symposium on Biomedical Imaging. 2016.   \n[5] Kerstin Hammernik et al. \u201cLearning a variational network for reconstruction of accelerated MRI data\u201d. In Magnetic Resonance in Medicine (2018).   \n[6] Yoseo Han et al. \u201ck-Space Deep Learning for Accelerated MRI\u201d. In Transactions on Medical Imaging (2020).   \n[7] Jure Zbontar et al. \u201cfastMRI: An Open Dataset and Benchmarks for Accelerated MRI\u201d. 2018.   \n[8] Florian Knoll et al. \u201cfastMRI: A Publicly Available Raw k-Space and DICOM Dataset of Knee Images for Accelerated MR Image Reconstruction Using Machine Learning\u201d. In Radiology: Artificial Intelligence (2020).   \n[9] G. Cowan. \u201cA survey of unfolding methods for particle physics\u201d. In Conf. Proc. C (2002).   \n[10] Volker Blobel. \u201cUnfolding Methods in Particle Physics\u201d. In PHYSTAT. CERN, 2011.   \n[11] Fran\u00e7ois-Xavier Le Dimet and Olivier Talagrand. \u201cVariational algorithms for analysis and assimilation of meteorological observations: theoretical aspects\u201d. In Tellus A: Dynamic Meteorology and Oceanography (1986).   \n[12] Yannick Tr\u00e9molet. \u201cAccounting for an imperfect model in 4D-Var\u201d. In Quarterly Journal of the Royal Meteorological Society (2006).   \n[13] Thomas M. Hamill. \u201cEnsemble-based atmospheric data assimilation\u201d. In Predictability of Weather and Climate. 2006.   \n[14] Alberto Carrassi et al. \u201cData assimilation in the geosciences: An overview of methods, issues, and perspectives\u201d. In WIREs Climate Change (2018).   \n[15] Jascha Sohl-Dickstein et al. \u201cDeep Unsupervised Learning using Nonequilibrium Thermodynamics\u201d. In Proceedings of the 32nd International Conference on Machine Learning. 2015.   \n[16] Jonathan Ho et al. \u201cDenoising Diffusion Probabilistic Models\u201d. In Advances in Neural Information Processing Systems. 2020.   \n[17] Yang Song et al. \u201cSolving Inverse Problems in Medical Imaging with Score-Based Generative Models\u201d. In International Conference on Learning Representations. 2022.   \n[18] Bahjat Kawar et al. \u201cSNIPS: Solving Noisy Inverse Problems Stochastically\u201d. In Advances in Neural Information Processing Systems. 2021.   \n[19] Bahjat Kawar et al. \u201cDenoising Diffusion Restoration Models\u201d. In Advances in Neural Information Processing Systems. 2022.   \n[20] Alexandre Adam et al. \u201cPosterior samples of source galaxies in strong gravitational lenses with score-based priors\u201d. 2022.   \n[21] Hyungjin Chung et al. \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems\u201d. In International Conference on Learning Representations. 2023.   \n[22] Jiaming Song et al. \u201cPseudoinverse-Guided Diffusion Models for Inverse Problems\u201d. In International Conference on Learning Representations. 2023.   \n[23] Fran\u00e7ois Rozet and Gilles Louppe. \u201cScore-based Data Assimilation\u201d. In Advances in Neural Information Processing Systems. 2023.   \n[24] Marc Anton Finzi et al. \u201cUser-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems\u201d. In Proceedings of the 40th International Conference on Machine Learning. 2023.   \n[25] Benjamin Boys et al. \u201cTweedie Moment Projected Diffusions For Inverse Problems\u201d. 2023.   \n[26] Y. Zhu et al. \u201cDenoising Diffusion Models for Plug-and-Play Image Restoration\u201d. In Conference on Computer Vision and Pattern Recognition Workshops. 2023.   \n[27] Noe Dia et al. \u201cBayesian Imaging for Radio Interferometry with Score-based Priors\u201d. 2023.   \n[28] Herbert E. Robbins. \u201cAn Empirical Bayes Approach to Statistics\u201d. In Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability. 1956.   \n[29] George Casella. \u201cAn Introduction to Empirical Bayes Data Analysis\u201d. In The American Statistician (1985).   \n[30] Bradley P. Carlin and Thomas A. Louis. \u201cEmpirical Bayes: Past, Present and Future\u201d. In Journal of the American Statistical Association (2000).   \n[31] Bradley Efron. \u201cTwo Modeling Strategies for Empirical Bayes Estimation\u201d. In Statistical Science (2014).   \n[32] G. D\u2019Agostini. \u201cA multidimensional unfolding method based on Bayes\u2019 theorem\u201d. In Nuclear Instruments and Methods in Physics Research (1995).   \n[33] Tim Dockhorn et al. \u201cDensity Deconvolution with Normalizing Flows\u201d. 2020.   \n[34] Anders Andreassen et al. \u201cOmniFold: A Method to Simultaneously Unfold All Observables\u201d. In Physical Review Letters (2020).   \n[35] Gilles Louppe et al. \u201cAdversarial Variational Optimization of Non-Differentiable Simulators\u201d. In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics. 2019.   \n[36] Maxime Vandegar et al. \u201cNeural Empirical Bayes: Source Distribution Estimation and its Applications to Simulation-Based Inference\u201d. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics. 2021.   \n[37] Julius Vetter et al. \u201cSourcerer: Sample-based Maximum Entropy Source Distribution Estimation\u201d. 2024.   \n[38] Bradley Efron. \u201cEmpirical Bayes deconvolution estimates\u201d. In Biometrika (2016).   \n[39] Balasubramanian Narasimhan and Bradley Efron. \u201cdeconvolveR: A G-Modeling Program for Deconvolution and Empirical Bayes Estimation\u201d. In Journal of Statistical Software (2020).   \n[40] H. O. Hartley. \u201cMaximum Likelihood Estimation from Incomplete Data\u201d. In Biometrics (1958).   \n[41] A. P. Dempster et al. \u201cMaximum Likelihood from Incomplete Data Via the EM Algorithm\u201d. In Journal of the Royal Statistical Society (1977).   \n[42] C. F. Jeff Wu. \u201cOn the Convergence Properties of the EM Algorithm\u201d. In The Annals of Statistics (1983).   \n[43] Geoffrey J McLachlan and Thriyambakam Krishnan. \u201cThe EM algorithm and extensions\u201d. John Wiley & Sons, 2007.   \n[44] Sivaraman Balakrishnan et al. \u201cStatistical guarantees for the EM algorithm: From population to sample-based analysis\u201d. In The Annals of Statistics (2017).   \n[45] Yang Song and Stefano Ermon. \u201cGenerative Modeling by Estimating Gradients of the Data Distribution\u201d. In Advances in Neural Information Processing Systems. 2019.   \n[46] Yang Song et al. \u201cScore-Based Generative Modeling through Stochastic Differential Equations\u201d. In International Conference on Learning Representations. 2021.   \n[47] Brian D. O. Anderson. \u201cReverse-time diffusion equation models\u201d. In Stochastic Processes and their Applications (1982).   \n[48] Simo S\u00e4rkk\u00e4 and Arno Solin. \u201cApplied Stochastic Differential Equations\u201d. Institute of Mathematical Statistics Textbooks. Cambridge University Press, 2019.   \n[49] Qinsheng Zhang and Yongxin Chen. \u201cFast Sampling of Diffusion Models with Exponential Integrator\u201d. In International Conference on Learning Representations. 2023.   \n[50] Jiaming Song et al. \u201cDenoising Diffusion Implicit Models\u201d. In International Conference on Learning Representations. 2021.   \n[51] Tero Karras et al. \u201cElucidating the Design Space of Diffusion-Based Generative Models\u201d. In Advances in Neural Information Processing Systems. 2022.   \n[52] Yaron Lipman et al. \u201cFlow Matching for Generative Modeling\u201d. In International Conference on Learning Representations. 2023.   \n[53] Aapo Hyv\u00e4rinen. \u201cEstimation of Non-Normalized Statistical Models by Score Matching\u201d. In Journal of Machine Learning Research (2005).   \n[54] Pascal Vincent. \u201cA Connection Between Score Matching and Denoising Autoencoders\u201d. In Neural Computation (2011).   \n[55] M. C. K. Tweedie. \u201cFunctions of a statistical variate with given means, with special reference to Laplacian distributions\u201d. In Mathematical Proceedings of the Cambridge Philosophical Society (1947).   \n[56] Bradley Efron. \u201cTweedie\u2019s Formula and Selection Bias\u201d. In Journal of the American Statistical Association (2011).   \n[57] Kwanyoung Kim and Jong Chul Ye. \u201cNoise2Score: Tweedie\u2019s Approach to Self-Supervised Image Denoising without Clean Images\u201d. In Advances in Neural Information Processing Systems. 2021.   \n[58] Chenlin Meng et al. \u201cEstimating High Order Gradients of the Data Distribution by Denoising\u201d. In Advances in Neural Information Processing Systems. 2021.   \n[59] Greg C. G. Wei and Martin A. Tanner. \u201cA Monte Carlo Implementation of the EM Algorithm and the Poor Man\u2019s Data Augmentation Algorithms\u201d. In Journal of the American Statistical Association (1990).   \n[60] Gilles Celeux and Jean Diebolt. \u201cA stochastic approximation type EM algorithm for the mixture problem\u201d. In Stochastics and Stochastic Reports (1992).   \n[61] Bernard Delyon et al. \u201cConvergence of a stochastic approximation version of the EM algorithm\u201d. In The Annals of Statistics (1999).   \n[62] James G. Booth and James P. Hobert. \u201cMaximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm\u201d. In Journal of the Royal Statistical Society (1999).   \n[63] Richard A. Levine and George Casella. \u201cImplementations of the Monte Carlo EM Algorithm\u201d. In Journal of Computational and Graphical Statistics (2001).   \n[64] Brian S. Caffo et al. \u201cAscent-Based Monte Carlo Expectation-Maximization\u201d. In Journal of the Royal Statistical Society (2005).   \n[65] Wolfgang Jank. \u201cThe EM Algorithm, Its Randomized Implementation and Global Optimization\u201d. In Perspectives in Operations Research. 2006.   \n[66] William Ruth. \u201cA review of Monte Carlo-based versions of the EM algorithm\u201d. 2024.   \n[67] Michael E. Tipping and Christopher M. Bishop. \u201cMixtures of Probabilistic Principal Component Analyzers\u201d. In Neural Computation (1999).   \n[68] Christopher M. Bishop. \u201cPattern Recognition and Machine Learning\u201d. Information Science and Statistics. Springer, 2006.   \n[69] L\u00e9na\u00efc Chizat et al. \u201cFaster Wasserstein Distance Estimation with the Sinkhorn Divergence\u201d. In Advances in Neural Information Processing Systems. 2020.   \n[70] R\u00e9mi Flamary et al. \u201cPOT: Python Optimal Transport\u201d. In Journal of Machine Learning Research (2021).   \n[71] Friedemann Zenke and Tim P. Vogels. \u201cThe Remarkable Robustness of Surrogate Gradient Learning for Instilling Complex Function in Spiking Neural Networks\u201d. In Neural Computation (2021).   \n[72] Magnus R. Hestenes and Eduard Stiefel. \u201cMethods of Conjugate Gradients for Solving Linear Systems\u201d. In Journal of Research of the National Bureau of Standards (1952).   \n[73] James Bradbury et al. \u201cJAX: Composable transformations of Python $^+$ NumPy programs\u201d. 2018.   \n[74] Adam Paszke et al. \u201cPyTorch: An Imperative Style, High-Performance Deep Learning Library\u201d. In Advances in Neural Information Processing Systems. 2019.   \n[75] Youcef Saad and Martin Schultz. \u201cGMRES: A Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems\u201d. In Journal on Scientific and Statistical Computing (1986).   \n[76] H. A. Van der Vorst. \u201cBi-CGSTAB: A Fast and Smoothly Converging Variant of Bi-CG for the Solution of Nonsymmetric Linear Systems\u201d. In Journal on Scientific and Statistical Computing (1992).   \n[77] Luhuan Wu et al. \u201cPractical and Asymptotically Exact Conditional Sampling in Diffusion Models\u201d. In Advances in Neural Information Processing Systems. 2023.   \n[78] Nicolas Bonneel et al. \u201cSliced and Radon Wasserstein Barycenters of Measures\u201d. In Journal of Mathematical Imaging and Vision (2015).   \n[79] Kimia Nadjahi et al. \u201cStatistical and Topological Properties of Sliced Probability Divergences\u201d. In Advances in Neural Information Processing Systems. 2020. [80] Giannis Daras et al. \u201cAmbient Diffusion: Learning Clean Distributions from Corrupted Data\u201d. In Advances in Neural Information Processing Systems. 2023. [81] Alex Krizhevsky, Geoffrey Hinton, et al. \u201cLearning Multiple Layers of Features from Tiny Images\u201d. 2009.   \n[82] Olaf Ronneberger et al. \u201cU-Net: Convolutional Networks for Biomedical Image Segmentation\u201d. In Medical Image Computing and Computer-Assisted Intervention. 2015. [83] Tim Salimans et al. \u201cImproved Techniques for Training GANs\u201d. In Advances in Neural Information Processing Systems. 2016. [84] Martin Heusel et al. \u201cGANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\u201d. In Advances in Neural Information Processing Systems. 2017. [85] Bahjat Kawar et al. \u201cGSURE-Based Diffusion Model Training with Corrupted Data\u201d. In Transactions on Machine Learning Research (2024).   \n[86] Ajil Jalal et al. \u201cRobust Compressed Sensing MRI with Deep Generative Priors\u201d. In Advances in Neural Information Processing Systems. 2021.   \n[87] Yochai Blau and Tomer Michaeli. \u201cThe Perception-Distortion Tradeoff\u201d. In Conference on Computer Vision and Pattern Recognition. 2018. [88] Mauricio Delbracio and Peyman Milanfar. \u201cInversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration\u201d. In Transactions on Machine Learning Research (2023).   \n[89] E. G. Tabak and Cristina V. Turner. \u201cA family of nonparametric density estimation algorithms\u201d. In Communications on Pure and Applied Mathematics (2013). [90] Danilo Rezende and Shakir Mohamed. \u201cVariational Inference with Normalizing Flows\u201d. In Proceedings of the 32nd International Conference on Machine Learning. 2015.   \n[91] Asad Aali et al. \u201cAmbient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data\u201d. 2024. [92] Giannis Daras et al. \u201cConsistent Diffusion Meets Tweedie: Training Exact Ambient Diffusion Models with Noisy Data\u201d. 2024. [93] Xinyu Peng et al. \u201cImproving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance\u201d. 2024.   \n[94] Jiaming Song et al. \u201cLoss-Guided Diffusion Models for Plug-and-Play Controllable Generation\u201d. In Proceedings of the 40th International Conference on Machine Learning. 2023. [95] Arpit Bansal et al. \u201cUniversal Guidance for Diffusion Models\u201d. In International Conference on Learning Representations. 2024. [96] Yutong He et al. \u201cManifold Preserving Guided Diffusion\u201d. In International Conference on Learning Representations. 2024.   \n[97] Prafulla Dhariwal and Alexander Quinn Nichol. \u201cDiffusion Models Beat GANs on Image Synthesis\u201d. In Advances in Neural Information Processing Systems. 2021. [98] Jonathan Ho and Tim Salimans. \u201cClassifier-Free Diffusion Guidance\u201d. 2022. [99] Tero Karras et al. \u201cA Style-Based Generator Architecture for Generative Adversarial Networks\u201d. In Conference on Computer Vision and Pattern Recognition. 2019.   \n[100] Ashish Vaswani et al. \u201cAttention is All you Need\u201d. In Advances in Neural Information Processing Systems. 2017.   \n[101] Stefan Elfwing et al. \u201cSigmoid-weighted linear units for neural network function approximation in reinforcement learning\u201d. In Neural Networks (2018).   \n[102] Jimmy Lei Ba et al. \u201cLayer Normalization\u201d. 2016.   \n[103] Diederik P. Kingma and Jimmy Ba. \u201cAdam: A Method for Stochastic Optimization\u201d. In International Conference on Learning Representations. 2015.   \n[104] Kaiming He et al. \u201cDeep Residual Learning for Image Recognition\u201d. In Conference on Computer Vision and Pattern Recognition. 2016.   \n[105] William Peebles and Saining Xie. \u201cScalable Diffusion Models with Transformers\u201d. In International Conference on Computer Vision. 2023.   \n[106] Anton Obukhov et al. \u201cHigh-fidelity performance metrics for generative models in PyTorch\u201d. 2020.   \n[107] Wenzhe Shi et al. \u201cReal-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\u201d. In Conference on Computer Vision and Pattern Recognition. 2016.   \n[108] Richard Zhang et al. \u201cThe Unreasonable Effectiveness of Deep Features as a Perceptual Metric\u201d. In Conference on Computer Vision and Pattern Recognition. 2018.   \n[109] Zhou Wang et al. \u201cImage quality assessment: from error visibility to structural similarity\u201d. In Transactions on Image Processing (2004). ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Algorithms ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1 Choose an initial prior $q_{0}(x)$   \n2 Initialize the parameters $\\theta$ of the denoiser $d_{\\theta}(x_{t},t)$   \n3 for $k=1$ to $K$ do   \n4 for $i=1$ to $S$ do   \n5 $\\begin{array}{l}{y_{i},A_{i}\\sim p(y,A)}\\\\ {x_{i}\\sim q_{k-1}(x\\mid y_{i},A_{i})}\\end{array}$   \n6 # Posterior sampling   \n7 repeat   \n8 i ( 1, . . . , S )   \n9 t (0, 1)   \n10 z \u223cN(0, I)   \n11 xt\u2190xi + \u03c3t z   \n12 \u2113\u2190\u03bbt d\u03b8(xt, t) \u2212xi 2 # Denoising score matching   \n13 \u03b8 \u2190GRADIENTDESCENT(\u03b8, \u2207\u03b8\u2113)   \n14 until convergence   \n15 \u03b8k \u03b8   \n16 qk := q\u03b8k   \n17 return \u03b8K ", "page_idx": 15}, {"type": "text", "text": "Algorithm 2 DDIM-style posterior sampling ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1 $\\boldsymbol{x}_{1}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{\\Sigma}_{1})$   \n2 for i = T to 1 do   \n3 s \u2190i\u22121/T   \n4 t \u2190i/T   \n5 $\\hat{x}\\gets x_{t}+\\Sigma_{t}\\,s_{\\theta}(x_{t}\\mid y,A)$ # Estimate $\\mathbb{E}[x\\mid x_{t},y,A]$   \n6 z \u223cN(0, I)   \nxt x\u02c6   \n7 xs x\u02c6 + \u03c3s + \u03c3   \n\u03c3t   \n8 return $x_{0}$ ", "page_idx": 15}, {"type": "text", "text": "Algorithm 3 Moment matching posterior score ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1 function $s_{\\theta}(x_{t}\\mid y,A)$ # Estimate $\\nabla_{x_{t}}\\log{q_{\\theta}(x_{t}\\mid y,A)}$   \n2 x\u02c6 \u2190d\u03b8(xt, t)   \n3 if Tweedie then   \n4 $\\Sigma_{x|x_{t}}\\gets\\Sigma_{t}\\nabla_{x_{t}}d_{\\theta}(x_{t},t)^{\\top}$   \n5 else   \n6 $\\Sigma_{x|x_{t}}\\leftarrow\\Sigma_{t}$ or $(I+\\Sigma_{t}^{-1})^{-1}$ or $(\\Sigma_{x}^{-1}+\\Sigma_{t}^{-1})^{-1}$   \n7 $u\\gets\\left(\\Sigma_{y}+A\\Sigma_{x|x_{t}}A^{\\top}\\right)^{-1}\\left(y-A\\hat{x}\\right)$ # Solve with conjugate gradient method   \n8 $s_{y\\mid x}\\gets\\nabla_{\\!x_{t}}d_{\\theta}(x_{t},t)^{\\top}A^{\\top}u$ # Estimate $\\nabla_{x_{t}}\\log q_{\\theta}(y\\mid x_{t},A)$   \n9 sx\u2190\u03a3t\u2212 1(x\u02c6 \u2212xt) # Estimate $\\nabla_{x_{t}}\\log{q_{\\theta}(x_{t})}$   \n10 return sx + sy|x ", "page_idx": 15}, {"type": "text", "text": "Algorithm 4 Conjugate gradient method ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1 function CONJUGATEGRADIENT(A, b, x0)   \n2 r0 b Ax0   \n3 p0\u2190r0   \n4 for $i=0$ to $N-1$ do   \n5 if $\\lVert r_{i}\\rVert\\leq\\epsilon$ then   \n6 return $x_{i}$   \n7 \u03b1i \u2190pi\u22a4 Api ri\u22a4 ri   \n8 xi+1\u2190xi + \u03b1ipi   \n9 ri+1 ri \u03b1iApi   \n10 \u03b2i\u2190 ri\u22a4+1ri+1 ri\u22a4 ri   \n11 pi+1\u2190ri + \u03b2ipi   \n12 return xN ", "page_idx": 16}, {"type": "text", "text": "B Tweedie\u2019s formulae ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem 1. For any distribution $p(x)$ and $p(x_{t}\\mid x)={\\mathcal{N}}(x_{t}\\mid x,\\Sigma_{t}),$ , the first and second moments of the distribution $p(\\boldsymbol{x}\\mid\\boldsymbol{x}_{t})$ are linked to the score function $\\nabla_{x_{t}}\\log{p(x_{t})}$ through ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[x\\mid x_{t}]=x_{t}+\\Sigma_{t}\\,\\nabla_{x_{t}}\\log p(x_{t})}\\\\ &{\\mathbb{V}[x\\mid x_{t}]=\\Sigma_{t}+\\Sigma_{t}\\,\\nabla_{x_{t}}^{2}\\log p(x_{t})\\,\\Sigma_{t}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We provide proofs of Theorem 1 for completeness, even though it is a well known result [55\u201358].   \nProof. ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{\\nabla_{x_{t}}\\log p(x_{t})={\\frac{1}{p(x_{t})}}\\nabla_{x_{t}}\\,p(x_{t})}\\\\ &{={\\cfrac{1}{p(x_{t})}}\\int\\nabla_{x_{t}}\\,p(x,x_{t})\\,\\mathrm{d}x}\\\\ &{={\\cfrac{1}{p(x_{t})}}\\int p(x,x_{t})\\,\\nabla_{x_{t}}\\log p(x,x_{t})\\,\\mathrm{d}x}\\\\ &{=\\int p(x\\mid x_{t})\\,\\nabla_{x_{t}}\\log p(x_{t}\\mid x)\\,\\mathrm{d}x}\\\\ &{=\\int p(x\\mid x_{t})\\,\\Sigma_{t}^{-1}(x-x_{t})\\,\\mathrm{d}x}\\\\ &{=\\Sigma_{t}^{-1}\\mathbb{E}[x\\mid x_{t}]-\\Sigma_{t}^{-1}x_{t}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\nabla_{x_{t}}^{2}\\log p(x_{t})=\\nabla_{x_{t}}\\nabla_{x_{t}}^{\\top}\\log p(x_{t})}\\\\ &{=\\nabla_{x_{t}}\\mathbb{E}[\\;x_{t}\\mid x_{t}]^{\\top}\\Sigma_{t}^{-1}-\\Sigma_{t}^{-1}}\\\\ &{=\\left(\\int\\nabla_{x_{t}}p(x\\mid x_{t})\\,x^{\\top}\\,\\mathrm{d}x\\right)\\Sigma_{t}^{-1}-\\Sigma_{t}^{-1}}\\\\ &{=\\left(\\int p(x\\mid x_{t})\\nabla_{x_{t}}\\log\\frac{p(x_{t}\\mid x)}{p(x_{t})}\\,x^{\\top}\\,\\mathrm{d}x\\right)\\Sigma_{t}^{-1}-\\Sigma_{t}^{-1}}\\\\ &{=\\left(\\int p(x\\mid x_{t})\\,\\Sigma_{t}^{-1}(x-\\mathbb{E}[x\\mid x_{t}])\\,x^{\\top}\\,\\mathrm{d}x\\right)\\Sigma_{t}^{-1}-\\Sigma_{t}^{-1}}\\\\ &{=\\Sigma_{t}^{-1}\\Big(\\mathbb{E}\\left[x x^{\\top}\\mid x_{t}\\right]-\\mathbb{E}[x\\mid x_{t}]\\,\\mathbb{E}[x\\mid x_{t}]^{\\top}\\Big)\\Sigma_{t}^{-1}-\\Sigma_{t}^{-1}}\\\\ &{=\\Sigma_{t}^{-1}\\Psi[x\\mid x_{t}]\\sum_{t=1}^{T}-\\Sigma_{t}^{-1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "C Experiment details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "All experiments are implemented within the JAX [73] automatic differentiation framework. The code for all experiments is made available at https://github.com/francois-rozet/ diffusion-priors. ", "page_idx": 18}, {"type": "text", "text": "Diffusion models As mentioned in Section 2, in this work, we adopt the variance exploding SDE [45] and the denoiser parameterization [51]. Following Karras et al. [51], we precondition our denoiser $d_{\\theta}(x_{t},t)$ as ", "page_idx": 18}, {"type": "equation", "text": "$$\nd_{\\theta}(x_{t},t)=\\frac{1}{\\sigma_{t}^{2}+1}x_{t}+\\frac{\\sigma_{t}}{\\sqrt{\\sigma_{t}^{2}+1}}h_{\\theta}\\left(\\frac{x_{t}}{\\sqrt{\\sigma_{t}^{2}+1}},\\log{\\sigma_{t}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $h_{\\theta}(x,\\log\\sigma)$ is an arbitrary noise-conditional network. The scalar $\\log\\sigma$ is embedded as a vector using a sinusoidal positional encoding [100]. In our experiments, we use an exponential noise schedule ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sigma_{t}=\\exp\\left(\\left(1-t\\right)\\log10^{-3}+t\\log10^{2}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "loss weights $\\begin{array}{r}{\\lambda_{t}=\\frac{1}{\\sigma_{t}^{2}}+1}\\end{array}$ and sample $t$ from a Beta distribution $B(\\alpha=3,\\beta=3)$ during training. ", "page_idx": 18}, {"type": "text", "text": "Low-dimensional manifold The noise-conditional network $h_{\\theta}(x,\\log\\sigma)$ is a multi-layer perceptron with 3 hidden layers of 256 neurons and SiLU [101] activation functions. A layer normalization [102] function is inserted after each activation. The input of the network is the concatenation of $x_{t}$ and the noise embedding vector. We train the network with Algorithm 1 for $K=32$ EM iterations. Each iteration consists of 16 384 optimization steps of the Adam [103] optimizer. The optimizer and learning rate are re-initialized after each EM iteration. Other hyperparameters are provided in Table 2. ", "page_idx": 18}, {"type": "table", "img_path": "7v88Fh6iSM/tmp/199aca30a5bf8525e26425779d32b8d2f64f527dccc452c49066421e95f59d13.jpg", "table_caption": ["Table 2. Hyperparameters for the low-dimensional manifold experiment. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "We apply Algorithm 3 to estimate the posterior score $\\nabla_{x_{t}}\\log{p(x_{t})}$ and truncate Algorithm 4 to 3 iterations. We rely on the predictor-corrector [23, 46] sampling scheme to sample from the posterior $q_{\\theta}(x\\mid y,A)$ . Following Rozet et al. [23], the predictor is a deterministic DDIM [50] step and the corrector is a Langevin Monte Carlo step. We perform 4096 prediction steps, each followed by 1 correction step. At each EM iteration, we generate a single latent $x$ for each pair $(y,A)$ . ", "page_idx": 18}, {"type": "text", "text": "We generate smooth random manifolds according to a procedure described by Zenke et al. [71]. We evaluate the Sinkhorn divergences using the POT [70] package with an entropic regularization factor $\\lambda=1e-3$ . ", "page_idx": 18}, {"type": "text", "text": "Corrupted CIFAR-10 The noise-conditional network $h_{\\theta}(x,\\log\\sigma)$ is a U-Net [82] with residual blocks [104], SiLU [101] activation functions and layer normalization [102]. Each residual block is modulated with respect to the noise $\\sigma_{t}$ in the style of diffusion transformers [105]. A multi-head self-attention block [100] is inserted after each residual block at the last level of the U-Net. We train the network with Algorithm 1 for $K=32$ EM iterations. Each iteration consists of 256 epochs over the training set (50 000 images). To prevent overfitting, images are augmented with horizontal flips and hue shifts. The optimizer is re-initialized after each EM iteration. Other hyperparameters are provided in Table 3. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "table", "img_path": "7v88Fh6iSM/tmp/dae87d39f0b5dbb2ef47c9dc6c854baf9c84ed7e82a9bbc13c664d33e1de2acb.jpg", "table_caption": ["Table 3. Hyperparameters for the corrupted CIFAR-10 and accelerated MRI experiments. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "We apply Algorithm 2 with $T=256$ discretization steps and $\\eta=1$ to sample from the posterior $q_{\\theta}(x\\mid y,A)$ . We apply Algorithm 3 with several heuristics for $\\mathbb{V}[x\\mid x_{t}]$ to compare their results against Tweedie\u2019s covariance formula. For the latter, we truncate the conjugate gradient method in Algorithm 4 to a single iteration. At each EM iteration, we generate a single latent $x$ for each pair $(y,A)$ . Each EM iteration (including sampling and training) takes around $\\mathrm{4\\,h}$ on 4 A100 (40GB) GPUs. ", "page_idx": 19}, {"type": "text", "text": "We evaluate the Inception score (IS) [83] and Fr\u00e9chet Inception distance (FID) [84] of generated images using the torch-fidelity [106] package. ", "page_idx": 19}, {"type": "text", "text": "Accelerated MRI The noise-conditional network architecture is the same as for the corrupted CIFAR-10 experiment. The $320\\times320\\times1$ tensor $x_{t}$ is reshaped into a $80\\times80\\times16$ tensor using pixel shuffilng [107] before entering the network. We train the network with Algorithm 1 for $K=16$ EM iterations. Each iteration consists of 64 epochs over the training set $2\\times24\\,853$ images). To prevent overfitting, images are augmented with horizontal flips and random crops. The optimizer is re-initialized after each EM iteration. Other hyperparameters are provided in Table 3. ", "page_idx": 19}, {"type": "text", "text": "We apply Algorithm 2 with $T\\,=\\,64$ discretization steps and $\\eta=1$ to sample from the posterior $q_{\\theta}(x\\mid y,A)$ . We truncate the conjugate gradient method in Algorithm 4 to 3 iterations. At each EM iteration, we generate 2 latents $x$ for each pair $(y,A)$ , which acts as data augmentation. Each EM iteration (including sampling and training) takes around $\\mathrm{3\\,h}$ on 4 A100 (40GB) GPUs. ", "page_idx": 19}, {"type": "text", "text": "D Additional figures ", "text_level": 1, "page_idx": 20}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/92a00cbb3695e86830046f7d21b6b40d0cef0d0d2c8652e844ffd7908a6ebcca.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 7. 1-d and 2-d marginals of the ground-truth distribution $p(x)$ used in the low-dimensional manifold experiment. The distribution lies on a random 1-dimensional manifold embedded in $\\mathbb{R}^{5}$ . ", "page_idx": 20}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/5b0ddf02c5ac095182d7444d6e714e17ae67cbf7f98bbf1c436f98e579944e30.jpg", "img_caption": ["Figure 8. Example of samples from the posterior $q_{\\theta_{k}}(x\\mid y)$ along the EM iterations for the CIFAR-10 experiment. The generated images become gradually more detailed and less noisy. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/60dcc4636bebd6b8a3232b5057beda5b12383c4ff2f138688bb7db95c3947aa9.jpg", "img_caption": ["Figure 9. Example of samples from the posterior $q_{\\theta_{k}}(x\\mid y)$ along the EM iterations for the CIFAR-10 experiment when the heuristic $(I+\\Sigma_{t}^{-1})^{-1}$ is used for $\\mathbb{V}[x\\mid x_{t}]$ . The generated images become gradually more detailed but some noise remains. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/2b10c85c25cd00179fa8954485e20c7db57744964fe00911ce15bc587c472dab.jpg", "img_caption": ["Figure 10. Example of samples from the posterior $q_{\\theta_{k}}(x\\mid y)$ along the EM iterations for the CIFAR10 experiment when the heuristic $\\Sigma_{t}$ is used for $\\mathbb{V}[x\\mid x_{t}]$ . The generated images remain very noisy. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/fb8728f10a2f0d0693e98bf4785b8d6d24b0f36dd836f368bf5a0553c2b709c6.jpg", "img_caption": ["Figure 11. Example of scan slices from the fastMRI [7, 8] dataset. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/337894c9a66e28e9aa4a44a3d96b0e1838885e421b8890dd5712a367df9e1edc.jpg", "img_caption": ["Figure 12. Example of $k$ -space sub-sampling observations with acceleration factor $R=6$ for the accelerated MRI experiment. We represent each observation by its zero-fliled inverse, where missing frequencies are set to zero before taking the inverse discrete Fourier transform. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/d8e96bd8f7705cc672b2f819463ee3d6a5af4f1b659166d7badf8ef28546be97.jpg", "img_caption": ["Figure 13. Example of samples from the final model $q_{\\theta_{k}}(x)$ for the accelerated MRI experiment. The samples present varied and coherent global structures. Samples seem slightly less sharp than real scans (see Figure 11), but do not present artifacts typical to unresolved frequencies (see Figure 12). "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/fffe2705c306020aef4f1fc2a2da73037ecfb714299753b423d42061c6566c85.jpg", "img_caption": ["Figure 14. Examples of posterior samples using a diffusion prior trained from $k$ -space observations only. The forward process crops the latent $x$ to a centered $160\\times160$ window. Moment matching posterior sampling is used to sample from the posterior. Samples are consistent with the ground-truth where observed, but present plausible variations elsewhere. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/97c34498683a0285d0415adebb49c729423344f0014a3804466d8bb22712b624.jpg", "img_caption": ["Figure 15. Example of samples from the model $q_{\\theta_{k}}(x)$ after $k=2$ EM iterations for the accelerated MRI experiment when the heuristic $(I+\\Sigma_{t}^{-1})^{-1}$ is used for $\\mathbb{V}[x\\mid x_{t}]$ . The samples start to present vertical artifacts due to poor sampling. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/3dd149ca9264c0ab0102d908b081d842f6e873bf7cf00d97a1cdddb3660d0ae2.jpg", "img_caption": ["Figure 16. Example of samples from the model $q_{\\theta_{k}}(x)$ after $k=4$ EM iterations for the accelerated MRI experiment when the heuristic $(I+\\Sigma_{t}^{-1})^{-1}$ is used for $\\mathbb{V}[x\\mid x_{t}]$ . The artifacts introduced by the poor sampling get amplified at each iteration, leading to a total collapse after few iterations. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "E Evaluation of MMPS ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we evaluate the moment matching posterior sampling (MMPS) method presented in Section 4.2 independently from the context of learning from observations. The code for this section is made available at https://github.com/francois-rozet/mmps-benchmark. ", "page_idx": 25}, {"type": "text", "text": "Tasks We consider four linear inverse problems on the $256\\times256$ FFHQ [99] dataset. (i) For box inpainting, we mask out a randomly positioned $128\\times128$ square of pixels and add a large amount of noise $(\\sigma_{y}=1)$ ). (ii) For random inpainting, we randomly delete pixels with $98\\,\\%$ probability and add a small amount of noise $(\\sigma_{y}=0.01)$ ). (iii) For motion deblur, we apply a randomly generated $61\\times61$ motion blur kernel and add a medium amount of noise $(\\sigma_{y}=0.1)$ ). (iv) For super resolution, we apply a $4\\times$ bicubic downsampling and add a medium amount of noise $(\\sigma_{y}=0.1)$ ). ", "page_idx": 25}, {"type": "text", "text": "Methods For all inverse problems, we use the pre-trained diffusion model provided by Chung et al. [21] as diffusion prior. We adapt and extend the DPS [21] codebase to support MMPS as well as DiffPIR [26], \u03a0GDM [22] and TMPD [25]. We use the DDIM [50] sampler with $\\eta=1$ for all methods, which is equivalent to the DDPM [16] sampler. We fine-tune the hyperparameters of DPS $\\left(\\zeta^{\\prime}=0.5\\right)$ and DiffPIR $\\lambda=8.0$ ) to have the best results across the four tasks. With MMPS, we find that the Jacobian of the pre-trained model provided by Chung et al. [21] is strongly non-symmetric and non-definite for large $\\sigma_{t}$ , which leads to unstable conjugate gradient (CG) [72] iterations. We therefore replace the CG solver with the GMRES [75] solver, which can solve non-symmetric non-definite linear systems. ", "page_idx": 25}, {"type": "text", "text": "Protocol We generate one observation per inverse problem for 100 images1 of the FFHQ [99] dataset. We generate a sample for each observation with all considered posterior sampling methods. All methods are executed with the same random seed. We compute three standard image reconstruction metrics \u2013 LPIPS [108], PSNR and SSIM [109] \u2013 for each sample and report their average in Table 4. We present generated samples for each inverse problem in Figures 17, 18 and 19. ", "page_idx": 25}, {"type": "text", "text": "As a side note, we emphasize that reconstruction metrics do not necessarily reflect the accuracy of the inferred posterior distribution, which we eventually care about. For example, PSNR and SSIM [109] favor smooth predictions such as the mean $\\mathbb{E}[x\\mid{\\dot{y}}]$ over actual samples from the posterior $p(x\\mid y)$ Conversely, LPIPS [108] favors predictions which are perceptually similar to the reference, even if they are distorted. In general, it is impossible to simultaneously optimize for all reconstruction metrics [87, 88]. ", "page_idx": 25}, {"type": "text", "text": "Results MMPS consistently outperforms all baselines, both qualitatively and quantitatively. As expected, performing more solver iterations improves the sample quality, especially when the Gram matrix $\\overset{\\cdot}{A A}^{\\top}$ is strongly non-diagonal, which is the case for the motion deblur task. However, the improvement shows rapidly diminishing returns, as the difference between 1 and 3 iterations is much larger than between 3 and 5. MMPS is also remarkably stable with respect to the number of sampling steps in contrast to DPS [21], DiffPIR [26] and \u03a0GDM [22] which are sensitive to the number of steps and choice of hyperparameters. Finally, MMPS requires fewer sampling steps to reach the same image quality as previous methods, which largely makes up for its slightly higher step cost. ", "page_idx": 25}, {"type": "table", "img_path": "7v88Fh6iSM/tmp/edafa306906f5b61662f211d6fa0fb93bff06e2441c405c4eaf6524c9c85bde9.jpg", "table_caption": ["Table 4. Quantitative evaluation of MMPS with 1, 3 and 5 solver iterations. "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "7v88Fh6iSM/tmp/55768ebb43f26c6e3b186e65e2fce07a073cd3401469f50368fb544b5dcf7578.jpg", "table_caption": ["Table 5. Time and memory complexity of MMPS for the $4\\times$ super resolution task. Each solver iteration increases the time per step by around $16\\,\\mathrm{ms}$ . The maximum memory allocated by MMPS is about $10\\,\\%$ larger than DPS [21] and \u03a0GDM [22]. "], "table_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/f4d8ba7fd71a17a2393b9c0d4798983570c66eb9afe5561ec2fe48f566b88ef9.jpg", "img_caption": ["Figure 17. Qualitative evaluation of MMPS with 1 and 5 solver iterations. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/c195efec9645976660af2805c0da164fd42506986cd8c8e2a0b91aaa25bbcd7b.jpg", "img_caption": ["Figure 18. Qualitative evaluation of DPS [21] and DiffPIR [26]. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "7v88Fh6iSM/tmp/43535b086d5f575329176b1b7a40f7cab24b6b43720274b7efba01d0c1f88b7b.jpg", "img_caption": ["Figure 19. Qualitative evaluation of \u03a0GDM [22] and TMPD [25]. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We only claim to present a new method, which we describe in Section 4. We compare our method against previous ones in Sections 5 and 6. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We discuss the limitations in Section 7. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No new theoretical results are presented, but methods are motivated by established literature. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The manuscript describes all methods and experiments. Algorithms are provided for the methods. The code for all experiments is made available at https: //github.com/francois-rozet/diffusion-priors. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The code for all experiments is made available at https://github.com/ francois-rozet/diffusion-priors. Instructions to acquire the datasets are provided. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Experiment details are provided in Appendix C. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [No] ", "page_idx": 31}, {"type": "text", "text": "Justification: Computing error bars for Table 1 and Figure 4 would require retraining every model several times for different datasets. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Experiment details are provided in Appendix C. We acknowledge the use of a computer cluster in the acknowledgments section. Preliminary experiments are not reported in the manuscript. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We have reviewed and agree with the NeurIPS Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 32}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We acknowledge the use of the NYU fastMRI dataset [7, 8] in the acknowledgments section and follow its terms of use. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}]