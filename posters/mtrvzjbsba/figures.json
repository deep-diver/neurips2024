[{"figure_path": "MtRvzJBsBA/figures/figures_1_1.jpg", "caption": "Figure 1: We present our LRM-Zero framework trained with synthesized procedural data Zeroverse. Zeroverse (top left) is created from random primitives with textures and augmentations, thus it does not contain semantical information as in Objaverse (bottom left). Nevertheless, when training with the same large reconstruction model architecture [107] on both datasets, LRM-Zero can match objaverse-trained LRM's (denoted as \u2018LRM') visual quality (right part) of reconstructions. A possible explanation is that 3D reconstruction, although serves as a core task in 3D vision, rely mostly on local information instead of global semantics. Reconstruction is visualized with RGB and position-based renderings, and interactive viewers can be found on our website.", "description": "This figure shows a comparison of the LRM-Zero framework trained on synthetic data (Zeroverse) and a traditional LRM trained on real-world data (Objaverse).  It demonstrates that despite lacking realistic global semantics, the procedurally generated Zeroverse dataset allows LRM-Zero to achieve similar reconstruction quality to the LRM trained on Objaverse, suggesting that local geometric and textural information are crucial for successful 3D reconstruction.", "section": "1 Introduction"}, {"figure_path": "MtRvzJBsBA/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the Zeroverse data creation process. A random textured shape is first composited from primitive shapes and textures (Sec. 3.1). Then different augmentations (i.e., height field, boolean difference, wireframes in Sec. 3.2) are applied to enhance the dataset characteristics (e.g., curved surfaces, concavity, and thin structures). More visualizations in Appendix and website.", "description": "This figure illustrates the process of creating synthetic 3D shapes for the Zeroverse dataset. It starts with a pool of primitive shapes (cube, sphere, cylinder, cone, and torus) and random textures. These primitives are combined randomly to create a composite shape. Three types of augmentations are then applied to add complexity and diversity to the shapes: height-field augmentation, boolean difference augmentation, and wireframe augmentation. The resulting shapes are more intricate and better resemble real-world objects.", "section": "3 The Zeroverse dataset"}, {"figure_path": "MtRvzJBsBA/figures/figures_6_1.jpg", "caption": "Figure 1: We present our LRM-Zero framework trained with synthesized procedural data Zeroverse. Zeroverse (top left) is created from random primitives with textures and augmentations, thus it does not contain semantical information as in Objaverse (bottom left). Nevertheless, when training with the same large reconstruction model architecture [107] on both datasets, LRM-Zero can match objaverse-trained LRM's (denoted as \u2018LRM') visual quality (right part) of reconstructions. A possible explanation is that 3D reconstruction, although serves as a core task in 3D vision, rely mostly on local information instead of global semantics. Reconstruction is visualized with RGB and position-based renderings, and interactive viewers can be found on our website.", "description": "This figure shows a comparison of the LRM-Zero framework trained on synthetic data (Zeroverse) and a comparable model trained on real-world data (Objaverse).  It highlights that despite using entirely synthetic data lacking global semantic information, LRM-Zero achieves similar reconstruction quality to the Objaverse-trained model, suggesting that local geometric and textural details are more crucial for successful 3D reconstruction than previously thought.  The figure includes visualizations of the input data, the model architecture, and the reconstruction results.", "section": "1 Introduction"}, {"figure_path": "MtRvzJBsBA/figures/figures_7_1.jpg", "caption": "Figure 1: We present our LRM-Zero framework trained with synthesized procedural data Zeroverse. Zeroverse (top left) is created from random primitives with textures and augmentations, thus it does not contain semantical information as in Objaverse (bottom left). Nevertheless, when training with the same large reconstruction model architecture [107] on both datasets, LRM-Zero can match objaverse-trained LRM's (denoted as \u2018LRM') visual quality (right part) of reconstructions. A possible explanation is that 3D reconstruction, although serves as a core task in 3D vision, rely mostly on local information instead of global semantics. Reconstruction is visualized with RGB and position-based renderings, and interactive viewers can be found on our website.", "description": "This figure shows a comparison between the LRM-Zero framework trained on synthetic data (Zeroverse) and a traditional LRM trained on real-world data (Objaverse).  The left side displays examples from each dataset, highlighting Zeroverse's procedural generation of non-semantic shapes compared to Objaverse's realistic objects. The right side shows the reconstruction results from both models, demonstrating that LRM-Zero achieves comparable visual quality despite being trained solely on synthetic data. This suggests that local geometric and textural information might be more crucial for 3D reconstruction than global semantic understanding.", "section": "1 Introduction"}, {"figure_path": "MtRvzJBsBA/figures/figures_7_2.jpg", "caption": "Figure 1: We present our LRM-Zero framework trained with synthesized procedural data Zeroverse. Zeroverse (top left) is created from random primitives with textures and augmentations, thus it does not contain semantical information as in Objaverse (bottom left). Nevertheless, when training with the same large reconstruction model architecture [107] on both datasets, LRM-Zero can match objaverse-trained LRM's (denoted as \u2018LRM') visual quality (right part) of reconstructions. A possible explanation is that 3D reconstruction, although serves as a core task in 3D vision, rely mostly on local information instead of global semantics. Reconstruction is visualized with RGB and position-based renderings, and interactive viewers can be found on our website.", "description": "This figure illustrates the LRM-Zero framework and compares its performance against a model trained on real data.  LRM-Zero uses synthetic data generated procedurally (Zeroverse) that lacks semantic information unlike the Objaverse dataset used for comparison. The comparison shows that despite the lack of real-world semantics in its training data, LRM-Zero achieves comparable reconstruction quality to models trained on real data. This suggests that local geometric and textural features may be more crucial to reconstruction than global scene understanding.", "section": "1 Introduction"}, {"figure_path": "MtRvzJBsBA/figures/figures_17_1.jpg", "caption": "Figure 6: Uniformly sampled objects from Zeroverse to visualize its data distribution.", "description": "This figure shows a collection of 16 randomly sampled 3D objects generated by the Zeroverse dataset.  The images illustrate the diversity of shapes, textures, and compositions produced by the procedural generation process.  It highlights the complexity and variety of objects present in Zeroverse, which are not constrained by real-world semantic information but exhibit rich local geometric details.", "section": "A Appendix summary"}, {"figure_path": "MtRvzJBsBA/figures/figures_18_1.jpg", "caption": "Figure 1: We present our LRM-Zero framework trained with synthesized procedural data Zeroverse. Zeroverse (top left) is created from random primitives with textures and augmentations, thus it does not contain semantical information as in Objaverse (bottom left). Nevertheless, when training with the same large reconstruction model architecture [107] on both datasets, LRM-Zero can match objaverse-trained LRM's (denoted as \u2018LRM') visual quality (right part) of reconstructions. A possible explanation is that 3D reconstruction, although serves as a core task in 3D vision, rely mostly on local information instead of global semantics. Reconstruction is visualized with RGB and position-based renderings, and interactive viewers can be found on our website.", "description": "This figure shows the overall framework of the LRM-Zero model.  The left side shows the training data: Zeroverse (synthetic data generated from simple primitives) and Objaverse (real-world data). The right side shows the input (sparse-view images) and output (3D reconstruction) of the model. The comparison highlights that despite using entirely synthetic data, LRM-Zero achieves comparable reconstruction quality to a model trained on real-world data, suggesting that local geometric features are more critical than global semantics for this task.", "section": "1 Introduction"}, {"figure_path": "MtRvzJBsBA/figures/figures_19_1.jpg", "caption": "Figure 8: Qualitative comparison of LRM-Zero (left two columns) and GS-LRM (right two columns). When there is invisible region in the input views (first row), LRM-Zero produces poor reconstruction results. When the input views have good coverage (second row to fifth row), LRM-Zero performs similarly well as GS-LRM.", "description": "This figure compares the qualitative results of 3D reconstruction between LRM-Zero and GS-LRM on several examples. The first row shows that when some parts of the objects are not visible in the input views, the reconstruction quality of LRM-Zero is significantly worse than GS-LRM. However, when the input views provide good coverage of the object (from the second row to the last row), both models achieve comparable results.", "section": "B Uniformly-sampled data visualization"}]