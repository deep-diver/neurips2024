[{"figure_path": "VLw8ZyKfcm/tables/tables_6_1.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table compares the prediction accuracy of different neural operator models on six benchmark problems for solving forward partial differential equations (PDEs).  The accuracy is measured by the relative L2 error.  The table shows the performance of various models, including the proposed Latent Neural Operator (LNO), highlighting LNO's superior performance on most benchmarks and its efficiency in reducing computational cost. The 'D.C.' column indicates whether a model decouples observation and prediction positions, a key feature of the proposed LNO.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_7_1.jpg", "caption": "Table 2: Relative MAE of different completers in the subdomain in the 1st stage of the inverse problem with different settings of observation ratio.", "description": "This table presents the relative Mean Absolute Error (MAE) achieved by three different models (DeepONet, GNOT, and the proposed LNO) in the first stage of an inverse problem.  The first stage involves reconstructing a complete solution within a subdomain using only a portion of the data.  The table compares the performance of these models at varying observation ratios (20%, 10%, 5%, 1%, and 0.5%).  Lower MAE values indicate better performance.", "section": "4.2 Accuracy for the inverse problem"}, {"figure_path": "VLw8ZyKfcm/tables/tables_7_2.jpg", "caption": "Table 3: The reconstruction error of different propagators in the 2nd stage of the inverse problem. Propagators are trained to reconstruct the solution in the whole domain based on the ground truth (G.T.) of the subdomain and are tested using the output of different completers. Relative MAE of t = 0 and t = 1 is reported.", "description": "This table compares the reconstruction error of three different propagators (DeepONet, GNOT, and LNO) in the second stage of an inverse problem.  The propagators aim to reconstruct the complete solution across the entire domain using the ground truth from a subdomain. The error is evaluated using the Relative Mean Absolute Error (MAE) at times t=0 and t=1, and is shown for different observation ratios (10%, 1%, 0.5%) in the initial subdomain used by the completer.", "section": "4.2 Accuracy for the inverse problem"}, {"figure_path": "VLw8ZyKfcm/tables/tables_7_3.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table presents a comparison of the prediction error achieved by various models on six benchmark problems for solving forward partial differential equations.  The models are evaluated using the Relative L2 error metric.  The table indicates which models allow decoupling of observation and prediction positions and highlights the best-performing model for each benchmark.  The table includes results reproduced by the authors as well as results from other publications.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_8_1.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table compares the prediction error (Relative L2 error) of the proposed Latent Neural Operator (LNO) model against several other state-of-the-art models on six benchmark forward problems (Darcy, NS2d, Airfoil, Elasticity, Plasticity, and Pipe).  The table shows the relative L2 error for each method and benchmark, indicating the accuracy of each model in solving the specific problem.  The \"D.C.\" column indicates whether each method decouples the observation and prediction positions.  The best performance for each benchmark is highlighted in bold.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_9_1.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table presents a comparison of the prediction error achieved by various models on six forward problems.  The models are evaluated based on their relative L2 error.  The table includes whether the method's results were reproduced by the authors or if it was unable to handle a specific benchmark.  A key aspect highlighted is whether the models decouple observation and prediction positions, indicating the flexibility and generalizability of the approach.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_9_2.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table compares the prediction accuracy of the proposed Latent Neural Operator (LNO) against other state-of-the-art methods across six benchmark datasets for solving forward Partial Differential Equations (PDEs).  The results are presented as relative L2 errors, indicating the difference between the predicted and ground truth solutions.  The table also notes whether each method decouples observation and prediction positions (D.C.) and indicates which results were reproduced by the authors of the paper.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_15_1.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table compares the prediction accuracy (Relative L2 error) of various models on six benchmark PDE problems.  The model LNO (Latent Neural Operator) is compared against several other state-of-the-art neural operator models, showing its accuracy and competitive performance compared to other existing methods. The table also highlights whether each method decouples observation and prediction positions, a key feature of LNO, and indicates where results were reproduced by the authors or are unavailable from the original sources.", "section": "4.1 Accuracy for the forward problems"}, {"figure_path": "VLw8ZyKfcm/tables/tables_15_2.jpg", "caption": "Table 3: The reconstruction error of different propagators in the 2nd stage of the inverse problem. Propagators are trained to reconstruct the solution in the whole domain based on the ground truth (G.T.) of the subdomain and are tested using the output of different completers. Relative MAE of t = 0 and t = 1 is reported.", "description": "This table shows the reconstruction error of different propagators in the second stage of the inverse problem. The propagators are trained using the ground truth of the subdomain and tested using different completers' outputs.  The relative mean absolute error (MAE) at t=0 and t=1 are shown for each combination of propagator and completer, providing insights into the accuracy of reconstructing the complete solution.", "section": "4.2 Accuracy for the inverse problem"}, {"figure_path": "VLw8ZyKfcm/tables/tables_15_3.jpg", "caption": "Table 1: Prediction error on the six forward problems. The best result is in bold. \"*\" means that the results of the method are reproduced by ourselves. \"/\" means that the method can not handle this benchmark. The column labeled D.C. indicates whether the observation positions and prediction positions are decoupled.", "description": "This table presents a comparison of the prediction error achieved by various models on six benchmark problems for solving forward partial differential equations (PDEs).  The models' accuracy is measured using the relative L2 error. The table also indicates whether each model decouples the observation positions from prediction positions. This decoupling is a key feature of the proposed Latent Neural Operator (LNO) and allows it to perform interpolation and extrapolation.", "section": "4.1 Accuracy for the forward problems"}]