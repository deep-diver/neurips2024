{"references": [{"fullname_first_author": "Stephen Robertson", "paper_title": "The probabilistic relevance framework: Bm25 and beyond", "publication_date": "2009-00-00", "reason": "This paper introduces BM25, a foundational and widely used technique in information retrieval, providing a benchmark against which QA-Emb's performance is evaluated."}, {"fullname_first_author": "Nils Reimers", "paper_title": "Sentence-bert: Sentence embeddings using siamese bert-networks", "publication_date": "2019-00-00", "reason": "Sentence-BERT is a prominent method for generating sentence embeddings, forming a key part of the background for and comparison to the proposed QA-Emb method."}, {"fullname_first_author": "Alexander G. Huth", "paper_title": "Natural speech reveals the semantic maps that tile human cerebral cortex", "publication_date": "2016-00-00", "reason": "This paper provides the foundational neuroscience dataset and model that QA-Emb uses to test the performance of its approach to creating interpretable fMRI models."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2018-00-00", "reason": "BERT is a highly influential language model that is used as a comparison for QA-Emb, showcasing how the new approach stacks up against a state-of-the-art model."}, {"fullname_first_author": "Tomas Mikolov", "paper_title": "Efficient estimation of word representations in vector space", "publication_date": "2013-00-00", "reason": "Word2Vec, introduced in this paper, is a classic method for generating word embeddings, representing an important stage in the evolution of text embedding techniques which the paper builds upon."}]}