[{"figure_path": "P4s6FUpCbG/tables/tables_6_1.jpg", "caption": "Table 1: A quantitative comparison of few-shot 3D reconstruction. Experiments on DL3DV and LLFF follow the setting of [44]. Experiments on Mip-NeRF 360 follow the setting of [41].", "description": "This table presents a quantitative comparison of different few-shot 3D reconstruction methods on three datasets: DL3DV, LLFF, and Mip-NeRF 360.  The methods are evaluated based on their performance with varying numbers of input views (3, 6, and 9). The metrics used for evaluation are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity).  The table allows for a comparison of the proposed 3DGS-Enhancer method against several state-of-the-art techniques.", "section": "5 Experiments"}, {"figure_path": "P4s6FUpCbG/tables/tables_8_1.jpg", "caption": "Table 2: A quantitative comparison of methods on the unseen Mip-NeRF360 dataset [2].", "description": "This table presents a quantitative comparison of different novel view synthesis methods on the Mip-NeRF360 dataset.  The methods are evaluated using PSNR, SSIM, and LPIPS metrics for both 6 and 9 input views.  The results demonstrate the performance of the proposed 3DGS-Enhancer method compared to several baselines, highlighting its cross-dataset generalization capabilities.", "section": "5.2 Comparison with State-of-the-Arts"}, {"figure_path": "P4s6FUpCbG/tables/tables_9_1.jpg", "caption": "Table 3: An ablation study of the four modules of our 3DGS-Enhancer framework, where all results are averaged across 3, 6, 9, and 12 input views on DL3DV dataset [21].", "description": "This table presents the results of an ablation study conducted on the 3DGS-Enhancer framework.  The study evaluates the impact of four different modules: video diffusion, real image, image confidence, and pixel confidence. The results are averaged across 3, 6, 9, and 12 input views using the DL3DV dataset.  The table shows the PSNR, SSIM, and LPIPS scores for each configuration to demonstrate how each module contributes to the overall performance of the framework.", "section": "5.3 Ablation Study"}, {"figure_path": "P4s6FUpCbG/tables/tables_9_2.jpg", "caption": "Table 4: An ablation study of STD (temporal layers) and color correction module on the DL3DV test dataset with a 9-view setting.", "description": "This table presents the ablation study of the spatial-temporal decoder (STD) and color correction module within the 3DGS-Enhancer framework.  It shows the impact of  temporal layers and color correction on the PSNR, SSIM, and LPIPS metrics using the DL3DV test dataset with 9 input views.  It demonstrates the individual and combined effects of these components on image quality.", "section": "5.3 Ablation Study"}, {"figure_path": "P4s6FUpCbG/tables/tables_15_1.jpg", "caption": "Table 5: A comparison of per-scene training time and rendering FPS between methods. For our method, the LQ-3DGS reconstruction takes 10.5 minutes, stable video diffusion inference for 50 novel views requires 2.0 minutes, and the HQ-3DGS reconstruction takes 12.0 minutes.", "description": "This table compares the per-scene training time and rendering FPS (frames per second) of different novel-view synthesis methods.  It highlights the trade-off between training time and rendering speed.  The authors' method (3DGS-Enhancer) achieves a good balance, offering relatively fast rendering while maintaining reasonable training times.", "section": "5 Experiments"}]