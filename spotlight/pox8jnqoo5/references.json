{"references": [{"fullname_first_author": "Omri Barak", "paper_title": "Recurrent neural networks as versatile tools of neuroscience research", "publication_date": "2017-00-00", "reason": "This paper provides a broad overview of RNNs applications in neuroscience, forming a foundational context for the current work."}, {"fullname_first_author": "David Sussillo", "paper_title": "Generating coherent patterns of activity from chaotic neural networks", "publication_date": "2009-00-00", "reason": "This paper introduces the FORCE learning algorithm, a key second-order optimization method that is compared against SOFO in the current study."}, {"fullname_first_author": "James Martens", "paper_title": "Learning recurrent neural networks with Hessian-free optimization", "publication_date": "2011-00-00", "reason": "This paper details Hessian-free optimization, a second-order method that SOFO builds upon and improves upon in terms of computational efficiency and parallelization."}, {"fullname_first_author": "Atilim Gunes Baydin", "paper_title": "Automatic differentiation in machine learning: a survey", "publication_date": "2018-00-00", "reason": "This paper provides a comprehensive overview of automatic differentiation techniques, which are fundamental to SOFO's efficient computation of second-order gradients."}, {"fullname_first_author": "David Sussillo", "paper_title": "Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks", "publication_date": "2013-00-00", "reason": "This paper investigates the dynamics of RNNs and serves as a theoretical foundation for understanding some of the training challenges addressed by SOFO."}]}