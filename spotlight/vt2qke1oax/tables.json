[{"figure_path": "vt2qkE1Oax/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of our low-rank trajectory loss (LRTL) with prior subspace clustering approaches in a per-video optimisation setting.", "description": "This table compares the performance of the proposed method (LRTL) against several baseline methods for unsupervised motion segmentation.  The comparison uses the adjusted Rand index (ARI) and foreground adjusted Rand index (FG-ARI) metrics to evaluate the accuracy of the clustering results. The results show that the proposed LRTL method significantly outperforms existing subspace clustering approaches like K-Means, SSC, and LLR, demonstrating the effectiveness of the proposed loss function for unsupervised motion segmentation.", "section": "5.1 Comparison to trajectory-based methods"}, {"figure_path": "vt2qkE1Oax/tables/tables_7_1.jpg", "caption": "Table 2: Unsupervised video segmentation on DAVIS, SegTrackv2, and FBMS. Where possible, we report results without widely applicable post-processing (e.g., CRF) or indicate results in grey.", "description": "This table compares the proposed method (LRTL) with various unsupervised video object segmentation methods across three benchmark datasets (DAVIS, SegTrackv2, and FBMS).  The comparison includes single-sequence, single-stage end-to-end, and multi-stage methods.  The table shows the input modality (RGB, Motion), input resolution, motion estimation method used, and the resulting Jaccard index (J\u2191) scores for each dataset.", "section": "5.2 Unsupervised video object segmentation"}, {"figure_path": "vt2qkE1Oax/tables/tables_7_2.jpg", "caption": "Table 3: Alternative losses to our proposal. Other variants do not match the performance of our formulation.", "description": "This table compares the performance of different loss functions for training the video object segmentation model using point trajectories.  The loss functions are variations of the proposed loss, each designed to capture different aspects of trajectory motion. The results demonstrate that the proposed loss function outperforms the alternative formulations, indicating its effectiveness for unsupervised video object segmentation.", "section": "5.3 Ablations"}, {"figure_path": "vt2qkE1Oax/tables/tables_7_3.jpg", "caption": "Table 4: Ablation of loss terms. All loss terms synergise to improve performance.", "description": "This table presents an ablation study on the proposed loss function. It shows the performance of the model on the DAVIS dataset using different combinations of the optical flow loss (Lf), trajectory loss (Lt), and temporal smoothing loss (Lr). The results demonstrate that all three loss terms contribute positively to the overall performance, with the combination of all three losses achieving the highest Jaccard score (J).", "section": "5.2 Unsupervised video object segmentation"}, {"figure_path": "vt2qkE1Oax/tables/tables_13_1.jpg", "caption": "Table 5: Influence of r, the rank of the trajectory matrix used in loss function (4).", "description": "This table shows the result of the experiment to find the optimal rank (r) of the trajectory matrix used in the loss function. The rank controls the degrees of freedom in the system and implicitly controls the assumptions about the types of motion and cameras used to capture sequences.  The table shows that a rank of 5 provides the best performance (82.2 on DAVIS J\u2191) indicating that it is sufficient to group and explain simple motions.", "section": "5 Experiments"}, {"figure_path": "vt2qkE1Oax/tables/tables_13_2.jpg", "caption": "Table 6: Influence of k, the number of predicted components before merging.", "description": "This table presents the results of an ablation study on the influence of the number of predicted components (k) before merging on the DAVIS J\u2191 metric.  The experiment varied k (number of components before merging) and measured the resulting performance on the DAVIS dataset.  The results show that k=4 yields the best performance.", "section": "5 Experiments"}, {"figure_path": "vt2qkE1Oax/tables/tables_13_3.jpg", "caption": "Table 7: Influence of context length of the trajectory matrix.", "description": "This table shows the impact of varying the context length (temporal window) used for analyzing point trajectories on the performance of the video object segmentation task, measured by the Jaccard index (J) on the DAVIS dataset.  A longer context allows for the consideration of more temporal motion information, but excessively long contexts might introduce noise or irrelevant information. The results show an optimal context length around 20 frames, suggesting a balance between capturing sufficient temporal information and avoiding excessive noise.", "section": "5 Experiments"}, {"figure_path": "vt2qkE1Oax/tables/tables_13_4.jpg", "caption": "Table 8: Influence of trackers used to estimate point trajectories.", "description": "This table shows the performance of the proposed method using different point trackers on the DAVIS dataset.  The Jaccard index (J) is used as the evaluation metric.  The results indicate that the CoTracker outperforms other trackers, achieving the highest Jaccard index.", "section": "5 Experiments"}, {"figure_path": "vt2qkE1Oax/tables/tables_14_1.jpg", "caption": "Table 9: Alternative network architectures for segmentation.", "description": "This table presents the performance of different segmentation network architectures on the DAVIS dataset. The results show that using a stronger backbone network, such as MaskFormer with DINO, leads to better performance compared to using a simpler architecture such as UNet.", "section": "5.1 Comparison to trajectory-based methods"}, {"figure_path": "vt2qkE1Oax/tables/tables_14_2.jpg", "caption": "Table 2: Unsupervised video segmentation on DAVIS, SegTrackv2, and FBMS. Where possible, we report results without widely applicable post-processing (e.g., CRF) or indicate results in grey.", "description": "This table compares the proposed LRTL method with several state-of-the-art unsupervised video object segmentation methods on three benchmark datasets: DAVIS 2016, SegTrackv2, and FBMS.  The comparison includes single-sequence, single-stage end-to-end, and multi-stage methods. The table shows the Jaccard index (J) for each method on each dataset, highlighting the superior performance of LRTL, particularly in the absence of extensive post-processing.", "section": "5.2 Unsupervised video object segmentation"}]