[{"figure_path": "YgJPQW0lkO/tables/tables_3_1.jpg", "caption": "Table 2: Our claim-level uncertainty estimate based on the closeness centrality metric consistently and significantly outperforms baselines. We assess the AUROC (ROC) and AUPRC-Negative (PRC) to compare baselines and different centrality metrics (Table 1) with the number of samples |R| \u2208 {5, 10} on the FactScore and PopQA datasets. Results with statistically significant gains are bolded. All p-values are significantly less than 0.05 through a pairwise significance test detailed in Appx. C.2. Each setup is annotated as \u201cmodel, |R|\u201d. Abbreviations are used for baselines, as defined in the baseline discussion, and for centrality metrics, as defined in Sec. 4.2.", "description": "This table presents the results of a comparative analysis of claim-level uncertainty estimation methods.  It shows AUROC and AUPRC-Negative scores for various methods (including different centrality metrics and baselines) across two datasets (FactScore and PopQA) and different numbers of LLM samples.  Statistically significant improvements are highlighted, indicating the superior performance of closeness centrality.", "section": "Uncertainty Estimation"}, {"figure_path": "YgJPQW0lkO/tables/tables_6_1.jpg", "caption": "Table 2: Our claim-level uncertainty estimate based on the closeness centrality metric consistently and significantly outperforms baselines. We assess the AUROC (ROC) and AUPRC-Negative (PRC) to compare baselines and different centrality metrics (Table 1) with the number of samples |R| \u2208 {5, 10} on the FactScore and PopQA datasets. Results with statistically significant gains are bolded. All p-values are significantly less than 0.05 through a pairwise significance test detailed in Appx. C.2. Each setup is annotated as \u201cmodel, |R|\u201d. Abbreviations are used for baselines, as defined in the baseline discussion, and for centrality metrics, as defined in Sec. 4.2.", "description": "This table presents the results of a comparative analysis of different claim-level uncertainty estimation methods.  It compares the Area Under the ROC Curve (AUROC) and Area Under the Precision-Recall Curve for the negative class (AUPRC-Negative) across various models (GPT-3.5, GPT-4, Llama-3), numbers of response samples (|R|=5 or 10), and uncertainty estimation methods (including closeness centrality, self-consistency, and verbalized confidence).  Statistically significant improvements are highlighted. The table helps to show that the closeness centrality method outperforms other methods for estimating uncertainty at the claim level.", "section": "6.1 Uncertainty Estimation"}, {"figure_path": "YgJPQW0lkO/tables/tables_16_1.jpg", "caption": "Table 2: Our claim-level uncertainty estimate based on the closeness centrality metric consistently and significantly outperforms baselines. We assess the AUROC (ROC) and AUPRC-Negative (PRC) to compare baselines and different centrality metrics (Table 1) with the number of samples |R| \u2208 {5, 10} on the FactScore and PopQA datasets. Results with statistically significant gains are bolded. All p-values are significantly less than 0.05 through a pairwise significance test detailed in Appx. C.2. Each setup is annotated as \u201cmodel, |R|\u201d. Abbreviations are used for baselines, as defined in the baseline discussion, and for centrality metrics, as defined in Sec. 4.2.", "description": "This table presents the results of a systematic comparison of different claim-level uncertainty estimation methods.  It compares the Area Under the ROC Curve (AUROC) and the Area Under the Precision-Recall Curve for the Negative class (AUPRC-Negative) across various models (GPT-3.5, GPT-4, Llama-3), dataset (FactScore, PopQA), and number of response samples (|R|=5, |R|=10).  The methods compared include several baselines (Verbalized Confidence, Self-Consistency) and the proposed Graph Uncertainty method using various centrality metrics (degree, betweenness, eigenvector, PageRank, closeness). Statistically significant improvements (p<0.05) are highlighted in bold.", "section": "6.1 Uncertainty Estimation"}]