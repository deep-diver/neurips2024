[{"figure_path": "WpPNVPAEyv/tables/tables_7_1.jpg", "caption": "Table 1: Top-1 accuracy on CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT, where the test class distribution is uniform.", "description": "This table presents the top-1 accuracy results achieved by various long-tailed recognition methods on four benchmark datasets (CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT).  The key aspect is that the test data distribution is uniform, meaning the class balance is even during testing, in contrast to the imbalanced training data. This allows for a comparison of how well different methods can generalize to balanced data after training on long-tailed data.  The table shows the performance of each method across different imbalance ratios in CIFAR100-LT (IR=10, IR=50, IR=100) and the overall accuracy for Places-LT, iNaturalist 2018, and ImageNet-LT.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_7_2.jpg", "caption": "Table 2: Top-1 accuracy on CIFAR100-LT (IR100) with various unknown test class distributions.", "description": "This table presents the top-1 accuracy results on the CIFAR100-LT dataset (imbalance ratio of 100) under various unknown test class distributions.  The distributions tested are: Forward-LT (head classes over-represented), Uniform (balanced), and Backward-LT (tail classes over-represented). The results are shown for different proportions of each class in the test set, allowing analysis of the model's performance across various distribution shifts. The 'Prior' column indicates whether the prior probabilities of the test data were used during testing. This allows for evaluating the method's adaptability to various real-world distribution shifts and understanding its performance relative to different test conditions.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_8_1.jpg", "caption": "Table 2: Top-1 accuracy on CIFAR100-LT (IR100) with various unknown test class distributions.", "description": "This table presents the top-1 accuracy results on the CIFAR100-LT dataset (imbalance ratio of 100) using various test set distributions.  The different distributions represent varying degrees of head-tail class imbalance, ranging from forward-biased (forward-LT), uniform (Uni.), to backward-biased (backward-LT) distributions.  The results allow a comparison of different models' performance across different test set distribution scenarios.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_8_2.jpg", "caption": "Table 2: Top-1 accuracy on CIFAR100-LT (IR100) with various unknown test class distributions.", "description": "This table presents the Top-1 accuracy results on the CIFAR100-LT dataset (imbalance ratio of 100) under various unknown test class distributions.  It compares the performance of several long-tailed recognition methods including Softmax, Balanced Softmax, MiSLAS, LADE (with and without prior knowledge), RIDE, SADE, LSC, BalPoE, and the proposed PRL method. The distributions considered are forward-LT (where tail classes are more frequent in testing), uniform (equal distribution), and backward-LT (where head classes are more frequent in testing).  The results show how each model performs across various scenarios of class distribution in test data.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_18_1.jpg", "caption": "Table 5: Statistics of the long-tailed datasets.", "description": "This table presents the key statistics for four long-tailed image datasets used in the paper's experiments: CIFAR100-LT, ImageNet-LT, iNaturalist 2018, and Places365-LT.  For each dataset, it lists the number of classes, the number of training images, the number of test images, and the imbalance ratio (the ratio between the most frequent class and least frequent class). The imbalance ratios vary significantly across datasets, reflecting the varying degrees of class imbalance common in real-world scenarios.", "section": "5.1 Experimental Setups"}, {"figure_path": "WpPNVPAEyv/tables/tables_19_1.jpg", "caption": "Table 1: Top-1 accuracy on CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT, where the test class distribution is uniform.", "description": "This table presents the top-1 accuracy results of several state-of-the-art long-tailed recognition methods and the proposed PRL method on four benchmark datasets: CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT.  The test class distribution is uniform across all datasets, providing a comparison under standard long-tailed recognition settings.  The results showcase the performance of different approaches in handling class imbalances in the context of balanced testing data.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_19_2.jpg", "caption": "Table 1: Top-1 accuracy on CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT, where the test class distribution is uniform.", "description": "This table presents the top-1 accuracy results achieved by various state-of-the-art long-tailed recognition methods and the proposed PRL method on four benchmark datasets: CIFAR100-LT, Places-LT, iNaturalist 2018, and ImageNet-LT.  The key characteristic is that the test data distribution is uniform, allowing for a direct comparison of model performance under standard evaluation conditions.  The results showcase the superior performance of PRL compared to other methods across all datasets.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_20_1.jpg", "caption": "Table 2: Top-1 accuracy on CIFAR100-LT (IR100) with various unknown test class distributions.", "description": "This table presents the top-1 accuracy results on CIFAR100-LT with an imbalance ratio (IR) of 100, across various unknown test class distributions, comparing several long-tailed learning methods.  The distributions include forward-LT (skewed towards head classes), uniform, and backward-LT (skewed towards tail classes).  The 'Prior' column indicates whether prior information was used in the method.  The table provides a detailed comparison of performance across different scenarios, illustrating the relative strengths and weaknesses of each approach when dealing with distribution shifts and class imbalance.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_20_2.jpg", "caption": "Table 2: Top-1 accuracy on CIFAR100-LT (IR100) with various unknown test class distributions.", "description": "This table presents the Top-1 accuracy results on the CIFAR100-LT dataset (imbalance ratio of 100) under various unknown test class distributions.  It compares different methods' performance across different test set distributions: forward-LT (skewed towards head classes), uniform (balanced), and backward-LT (skewed towards tail classes). The results are further broken down by the number of samples per class (Prior) in the test distribution.  This allows for an in-depth analysis of each method's robustness to varying distribution shifts and the impact of class imbalance.", "section": "5.2 Comparative Evaluation on Standard and Test-Agnostic Long-Tailed Recognition"}, {"figure_path": "WpPNVPAEyv/tables/tables_20_3.jpg", "caption": "Table 9: Model size and computational cost with and without hypernetworks.", "description": "This table shows the model size (in MB) and computational cost (in GFLOPs) for different models (ResNet-32, ResNeXt-50, ResNet-50) with and without the hypernetwork. The hypernetwork increases the number of parameters but doesn't significantly impact the computational cost.", "section": "G Complexity Analysis"}]