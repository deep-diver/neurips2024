[{"type": "text", "text": "Extensive-Form Game Solving via Blackwell Approachability on Treeplexes ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Darshan Chakrabarti Julien Grand- Cl\u00e9ment Christian Kroer IEOR Department ISOM Department IEOR Department Columbia University HEC Paris Columbia University dc3595@columbia.edu grand-clement@hec.fr christian.kroer@columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We introduce the first algorithmic framework for Blackwell approachability on the sequence-form polytope, the class of convex polytopes capturing the strategies of players in extensive-form games (EFGs). This leads to a new class of regretminimization algorithms that are stepsize-invariant, in the same sense as the Regret Matching and Regret Matching+ algorithms for the simplex. Our modular framework can be combined with any existing regret minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs with perfect recall, through the self-play framework. Leveraging predictive online mirror descent, we introduce Predictive Treeplex Blackwell+ $(\\mathsf{P T B}^{+})$ , and show a $O(1/\\sqrt{T})$ convergence rate to Nash equilibrium in self-play. We then show how to stabilize ${\\mathsf{P T B}}^{+}$ with a stepsize, resulting in an algorithm with a state-of-the-art ${\\cal O}(1/T)$ convergence rate. We provide an extensive set of experiments to compare our framework with several algorithmic benchmarks, including ${\\mathsf{C F R}}^{+}$ and its predictive variant, and we highlight interesting connections between practical performance and the stepsize-dependence or stepsize-invariance properties of classical algorithms. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we focus on solving Extensive-Form Games (EFGs). Finding a Nash equilibrium of a two-player zero-sum EFG can be cast as solving ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}}\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{Y}}\\left\\langle\\pmb{x},M\\pmb{y}\\right\\rangle\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where the sets $\\mathcal{X},\\mathcal{Y}$ are two sequence-form polytopes (also referred to as treeplexes) representing the strategies $\\mathbf{\\boldsymbol{x}},\\mathbf{\\boldsymbol{y}}$ of each player, and $_M$ is a payoff matrix. EFGs have been successfully used to obtain superhuman performances in several recent poker AI breakthroughs [37, 4, 5]. Many algorithms have been developed based on (1). Since $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ are polytopes, (1) can be formulated as a linear program [38]. However, because $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ themselves have very large dimensions in realistic applications, first-order methods (FOMs) and regret minimization approaches are preferred for large-scale game solving. FOMs such as the Excessive Gap Technique (EGT, [32]) and Mirror Prox [31] instantiated for EFGs [23, 27] converge to a Nash equilibrium at a rate of ${\\cal O}(1/T)$ , where $T$ is the number of iterations. Regret minimization techniques rely on a folk theorem relating the regrets of the players and the duality gap of the average iterates [19]. For instance, predictive online mirror descent with the treeplexes $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ as decision sets achieves a ${\\cal O}(1/T)$ convergence rate [14]. ", "page_idx": 0}, {"type": "text", "text": "Counterfactual regret minimization (CFR) [39] is a regret minimizer for the treeplex that runs regret minimizers locally, i.e. directly at the level of the information sets of each player. ${\\mathsf{C F R}}^{+}$ , used in virtually all poker AI milestones [37, 30, 5], instantiates the CFR framework with a regret minimizer called Regret Matching+ $(\\mathsf{R M}^{+})$ ) [37] and guarantees a $O(1/\\sqrt{T})$ convergence rate. The strong empirical performance of ${\\mathsf{C F R}}^{+}$ remains mostly unexplained, since this algorithm does not achieve the fastest theoretical ${\\cal O}(1/T)$ convergence rate. Interestingly, there is a stark contrast between the role of stepsizes in ${\\mathsf{C F R}}^{+}$ versus in other algorithms. ${\\mathsf{C F R}}^{+}$ may use different stepsizes across different infosets, and the iterates of ${\\mathsf{C F R}}^{+}$ do not depend on the values of these stepsizes. We identify this property as infoset stepsize invariance. In contrast, the convergence properties of FOMs depend on the choice of a single stepsize used across the entire treeplex, which may be hard to tune in practice. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "$\\mathsf{R M}^{+}$ is an instantiation of Blackwell approachability [3] for the simplex, a versatile framework with connections to online learning [1]. Empirically, using a regret minimizer (over simplexes) based on Blackwell approachability $(\\mathsf{R M}^{+})$ is central to the success of ${\\mathsf{C F R}}^{+}$ : combining CFR with other local regret minimizers than $\\mathsf{R M}^{+}$ , e.g., Online Mirror Descent (OMD), leads to much weaker practical performance [6]. This raises the question of whether the performance of ${\\mathsf{C F R}}^{+}$ is mostly explained by the use of Blackwell approachability on simplexes $(\\mathsf{R M}^{+})$ , and if a Blackwell approachability-based algorithm operating directly on treeplexes, bypassing the CFR decomposition, could outperform ${\\mathsf{C F R}}^{+}$ . Our goal in this paper is to address these questions. To do so, we develop the first Blackwell approachability-based algorithms for treeplexes, and we provide a new hypothesis for explaining the performance of ${\\mathsf{C F R}}^{+}$ . In particular, our main contributions are as follows. ", "page_idx": 1}, {"type": "text", "text": "Treeplex Blackwell approachability. We introduce the first Blackwell approachability-based regret minimizer for treeplexes. Using the self-play framework, we correspondingly get the first framework for solving two-player zero-sum EFGs via Blackwell approachability on treeplexes. Blackwell approachability enables an equivalence between regret minimization over the treeplex $\\tau$ and over its conic hull cone $(\\tau)$ , and any existing regret minimizer for cone $(\\tau)$ yields a new algorithm for solving EFGs. A crucial advantage of using Blackwell approachability on the treeplex, rather than regret minimization directly on the treeplex, is that it leads to a variety of interesting stepsize properties (e.g. stepsize invariance), which are not achieved by regret minimizers such as $0\\mathsf{M D}$ on the treeplex. ", "page_idx": 1}, {"type": "text", "text": "We then provide several instantiations of our framework. ${\\mathsf{P T B}}^{+}$ (Predictive Treeplex Blackwell+, Algorithm 2) combines our framework with predictive $0\\mathsf{M D}$ over cone $(\\tau)$ and achieves a $O(1/\\sqrt{T})$ convergence rate. ${\\mathsf{P T B}}^{+}$ is treeplex stepsize invariant: its iterates do not change if we rescale all stepsizes by a positive constant. This is a desirable property for practical use, although it is a weaker property than the infoset stepsize invariance of ${\\mathsf{C F R}}^{+}$ . Smooth ${\\mathsf{P T B}}^{+}$ (Algorithm 3) is a variant of ${\\mathsf{P T B}}^{+}$ ensuring that successive iterates vary smoothly. We show that Smooth $\\mathsf{P T B}^{+}$ is the first EFG-solving algorithm based on Blackwell approachability achieving a ${\\cal O}(1/T)$ convergence rate, answering an important open question. Crucially, it is necessary to introduce a stepsize to achieve this faster convergence, and thus Smooth ${\\mathsf{P T B}}^{+}$ is not treeplex stepsize invariant; this is analogous to existing FOM-based ${\\cal O}(1/T)$ -methods for solving EFGs. We also consider AdaGradTB+ and AdamTB+, which learn different stepsizes for every dimension of the treeplexes, based on AdaGrad [12] and Adam [25]. We present the convergence properties of our algorithms in Table 1. ", "page_idx": 1}, {"type": "text", "text": "Numerical experiments. We provide two comprehensive sets of numerical experiments over benchmark EFGs. We find that ${\\mathsf{P T B}}^{+}$ performs the best among all the algorithms introduced in our paper (Figure 4), highlighting the advantage of treeplex stepsize invariant algorithms $(\\mathsf{P T B}^{+})$ over stepsize-dependent algorithms achieving faster theoretical convergence rate (Smooth ${\\mathsf{P T B}}^{+}$ ), and over adaptive algorithms learning decreasing stepsizes (AdaGradTB+, AdamTB+). We then compare our best method $(\\mathsf{P T B}^{+})$ with ${\\mathsf{C F R}}^{+}$ , predictive ${\\mathsf{C F R}}^{+}$ $({\\mathsf{P C F R}}^{+})$ , and predictive OMD (POMD) (Figure 2). We expected ${\\mathsf{P T B}}^{+}$ to perform on par with ${\\mathsf{P C F R}}^{+}$ , since ${\\mathsf{P T B}}^{+}$ is stepsize invariant, predictive, and based on Blackwell approachability. However, we find that $\\mathsf{P C F R}^{+}$ outperforms all other algorithms. This suggests that infoset stepsize invariance is an important property, even more than the treeplex stepsize invariance of ${\\mathsf{P T B}}^{+}$ . Due to the CFR decomposition, $\\mathsf{P C F R}^{+}$ can use different stepsizes at different infosets, where the values of the variables may be of very different magnitudes (typically, smaller for infosets appearing deeper in the treeplex), and $\\mathsf{P C F R}^{+}$ does not require tuning these different stepsizes, which may be impossible for large instances. No algorithms appear to consistently outperform the others for the last-iterate performances, and we leave studying this as an open question. ", "page_idx": 1}, {"type": "text", "text": "A new hypothesis on EFG-solving algorithms: the role of stepsize invariance. Overall, as part of our main contributions, we identify and distinguish the infoset and treeplex stepsize invariance properties, and based on our empirical experiments, we posit that infoset stepsize invariance explains part of the puzzle behind the strong empirical performance of ${\\mathsf{C F R}}^{+}$ and ${\\mathsf{P C F R}}^{+}$ . Our results highlight that for practical performance, the stepsize invariance properties may be more important than faster theoretical convergence rates, which require introducing a stepsize, as for Smooth ${\\mathsf{P T B}}^{+}$ or POMD. The very strong empirical performance of (predictive) ${\\mathsf{C F R}}^{+}$ has been unexplained for a long time and is one of the major open questions in EFG-solving; we view providing a new hypothesis for this phenomenon (infoset stepsize invariance) as important contributions to the EFG-solving community. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/1232554b207b398291abacd869babde5525f638851e241aea9c907e16407c96f.jpg", "table_caption": [], "table_footnote": ["Table 1: Convergence rates to a Nash equilibrium of a two-player zero-sum EFG for several algorithms. $\\checkmark\\checkmark$ refers to infoset stepsize invariance and $\\checkmark$ refers to treeplex stepsize invariance. "], "page_idx": 2}, {"type": "text", "text": "2 Preliminaries on EFGs ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We first provide some background on EFGs and treeplexes. ", "page_idx": 2}, {"type": "text", "text": "Extensive-form games. Two-player zero-sum extensive-form games (later referred to as $E F G s$ ) are represented by a game tree and a payoff matrix. Each node of the tree belongs either to one of the players, or to a chance player, modeling the random events in the game, e.g., tossing a coin. The players are assigned payoffs at the terminal nodes only. Imperfect information is modeled using information sets (infosets), which are subsets of nodes of the game tree. A player cannot distinguish between the nodes in a given infoset, and they must take the same action at all these nodes. ", "page_idx": 2}, {"type": "text", "text": "Treeplexes. The strategy of a player can be described by a polytope called the treeplex, also known as the sequence-form polytope. The treeplex is constructed as follows. We index the infosets of a player by $\\mathcal{I}=\\{1,...,|\\mathcal{I}|\\}$ . The set of actions available at infoset $j\\in\\mathcal{I}$ is written $\\mathcal{A}_{j}$ with cardinality $|{\\mathcal{A}}_{j}|=n_{j}$ . We represent choosing action $a\\in A_{j}$ at infoset $j\\in\\mathcal{I}$ by a sequence $(j,a)$ , and we denote by $\\mathcal{C}_{j a}$ the set of next infosets reachable from $(j,a)$ (possibly empty if the game terminates). The parent $p_{j}$ of an infoset $j\\in\\mathcal{I}$ is the sequence leading to $j$ ; note that $p_{j}$ is unique assuming perfect recall. We assume that there is a single root denoted as $\\mathcal{Q}$ and called the empty sequence. If the player does not take any action before reaching $j\\in\\mathcal{I}$ , then by convention $p_{j}=\\mathcal{E}$ . Under the perfect recall assumption, the set of infosets has a tree structure: $\\mathcal{C}_{j a}\\cap\\mathcal{C}_{j^{\\prime}a^{\\prime}}=\\bar{\\emptyset}$ , for all pairs of sequences $(j,a)$ and $(j^{\\prime},a^{\\prime})$ such that $j\\neq j^{\\prime},a\\neq a^{\\prime}$ . This tree is the treeplex and it represents the set of all admissible strategies for a given player. We denote by $n\\in\\mathbb N$ the total number of sequences $(j,a)$ with $j\\in\\mathcal{I}$ and $a\\in A_{j}$ . With these notations, the treeplex $\\tau$ of a given player is ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{T}=\\{\\pmb{x}\\in\\mathbb{R}_{+}^{n+1}\\mid x_{\\mathcal{O}}=1,\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\,j\\in\\mathcal{I}\\}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the first component $x_{\\mathcal{O}}$ is related to the empty sequence $\\mathcal{Q}$ . A player makes an observation to arrive at $j$ , if $|\\mathcal{C}_{p_{j}}|>1$ . We define the depth $d$ of a treeplex to be the maximum number of actions and observations that can be made starting at the root until reaching a leaf infoset. Computing a Nash equilibrium of EFGs can be formulated as solving (1) (under the perfect recall assumption), with $\\bar{\\boldsymbol{x}^{\\intercal}}\\subset\\mathbb{R}^{n_{1}+1}$ and $\\mathcal{V}\\subset\\,\\mathbb{R}^{n_{2}+1}$ the treeplex of each player, $n_{1}$ and $n_{2}$ are the number of sequences of each player, and $M\\in\\mathbb{R}^{(n_{1}+1)\\times(\\bar{n}_{2}+1)}$ the payoff matrix such that for a pair of strategy $({\\bar{\\mathbf{x}}},{\\bar{\\mathbf{y}}})\\in\\mathcal{X}\\times\\mathcal{Y}$ , $\\langle x,M y\\rangle$ is the expected value that the second player receives from the first player. ", "page_idx": 2}, {"type": "text", "text": "Regret minimization and self-play framework. A regret minimizer Regmin over a decision set $\\mathcal{Z}\\subset\\mathbb{R}^{d}$ is an algorithm such that, at every iteration, Regmin chooses a decision $z^{t}\\in\\mathcal{Z}$ , a loss vector $\\ell\\in\\mathbb{R}^{d}$ is observed, and the scalar loss $\\langle\\pmb{\\ell}^{t},\\pmb{x}^{t}\\rangle$ is incurred. A regret minimizer ensures that the regret ${\\sf R e g}^{T}=\\operatorname*{max}_{\\hat{z}\\in\\mathcal{Z}}\\sum_{t=1}^{T}\\langle\\ell^{t},z^{t}-\\hat{z}\\rangle$ grows at most as $O({\\sqrt{T}})$ . As an example, predictive online mirror descent (POMD, [34]) generates a sequence of decisions $z_{1},...,z_{T}\\in\\mathcal{Z}$ as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\nz_{t}=\\Pi_{\\mathcal{Z}}\\left(\\hat{z}_{t}-\\eta m_{t}\\right),\\hat{z}_{t+1}=\\Pi_{\\mathcal{Z}}\\left(\\hat{z}_{t}-\\eta\\ell_{t}\\right)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with $\\mathbf{\\Phi}_{m_{1},\\,...,\\,m_{T}}\\in\\,\\mathbb{R}^{d}$ some predictions of the losses $\\ell_{1},...,\\ell_{T}\\,\\in\\,\\mathbb{R}^{d}$ , and where we write the orthogonal projection of $\\boldsymbol{y}\\in\\mathbb{R}^{\\dot{d}}$ onto $\\mathcal{Z}$ as $\\begin{array}{r}{\\Pi_{\\mathcal{Z}}\\left(\\pmb{y}\\right):=\\arg\\operatorname*{min}_{\\pmb{z}\\in\\mathcal{Z}}\\|\\pmb{z}-\\pmb{y}\\|_{2}}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "The self-play framework solves EFGs via regret minimization. The players compute two sequences of strategies $\\pmb{x}_{1},...,\\pmb{x}_{T}$ and $\\pmb{y}_{1},...,\\pmb{y}_{T}$ such that, at iteration $t\\geq1$ , the first player observes its loss vector ${\\cal M}y_{t-1}$ and the second player observes its loss vector $-M^{\\top}x_{t-1}$ . Each player computes their current strategies $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}$ and $_{y_{t}}\\in\\mathcal{V}$ via regret minimization. A well-known theorem states that the duality gap of the average of the iterates is bounded by the sum of the average regrets of the players. ", "page_idx": 3}, {"type": "text", "text": "Proposition 2.1 ([19]). Let $\\mathbf{\\sigma}_{\\mathbf{x}_{1},\\mathbf{\\varepsilon}...,\\,\\mathbf{x}_{T}}\\,\\in\\,\\,\\mathcal{X}$ and $y_{1},...,y_{T}\\;\\in\\;\\mathcal{Y}$ be computed in the self-play framework. Let $\\begin{array}{r}{\\left(\\bar{\\pmb x}_{T},\\bar{\\pmb y}_{T}\\right)=\\frac{1}{T}\\sum_{t=1}^{T}\\left(\\pmb x_{t},\\pmb y_{t}\\right)}\\end{array}$ . Then, for ${\\mathsf{R e g}}_{1}^{T}$ and ${\\mathsf{R e g}}_{2}^{T}$ the regret of each player, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\hat{y}\\in\\mathcal{Y}}\\,\\left\\langle\\bar{x}_{T},M\\hat{y}\\right\\rangle-\\operatorname*{min}_{\\hat{x}\\in\\mathcal{X}}\\,\\left\\langle\\hat{x},M\\bar{y}_{T}\\right\\rangle=\\left(\\mathsf{R e g}_{1}^{T}+\\mathsf{R e g}_{2}^{T}\\right)/T.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We present more details on the self-play framework in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "CFR and Regret Matching+. Counterfactual Regret minimization (CFR, [39]) runs independent regret minimizers with counterfactual losses at each infoset of the treeplexes. This considerably simplifies the optimization problem, since the decision set at each infoset $j\\in\\mathcal{I}$ is the simplex over the set of next available actions $\\Delta^{n_{j}}:=\\{\\pmb{x}\\in\\mathbb{R}_{+}^{n_{j}}\\ |\\ \\sum_{i=1}^{n_{j}}x_{i}=1\\}$ . In the CFR framework, the regret of each player (over the treeplex) is bounded b y the maximum of the local regrets incurred at each infoset. Therefore, CFR combined with any regret minimizer over the simplex converges to a Nash equilibrium at a rate of $O(1/\\sqrt{T})$ . We refer to Appendix B for more details. Combining CFR with a local regret minimizer called Regret Matching+ $\\left(\\mathsf{R M}^{+}$ , [37]) along with alternation and linear averaging yields an algorithm called ${\\mathsf{C F R}}^{+}$ , which has been observed to attain strong practical performance compared to theoretically-faster methods [27]. Crucially, $\\mathsf{R M}^{+}$ can only be implemented on the simplex and not for other decision sets, and proceeds as follows: given a sequence of loss $\\ell_{1},...,\\ell_{T}\\in\\mathbb{R}^{d}$ , $\\mathsf{R M}^{+}$ maintains a sequence $\\pmb{R}_{1},...,\\pmb{R}_{T}^{\\star}\\in\\mathbb{R}^{d}$ such that ${\\cal R}_{1}={\\bf0}$ and ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pmb{x}_{t}=\\pmb{R}_{t}/\\lVert\\pmb{R}_{t}\\rVert_{1},\\pmb{R}_{t+1}=\\Pi_{\\mathbb{R}_{+}^{d}}\\left(\\pmb{R}_{t}-\\eta\\pmb{g}(\\pmb{x}_{t},\\ell_{t})\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with $\\eta>0$ and $\\mathbf{0}/0:=(1/d)\\mathbf{1}$ for $\\mathbf{1}:=(1,...,1)\\in\\mathbb{R}^{d}$ , and, for $\\mathbf{x},\\pmb{\\ell}\\in\\mathbb{R}^{d}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\ng(x,\\ell):=\\ell-\\langle x,\\ell\\rangle\\mathbf{1}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "$\\mathsf{R M}^{+}$ is stepsize invariant: $\\pmb{x}_{1},...,\\pmb{x}_{T}$ are independent of $\\eta$ , since $\\pmb{x}_{t}=R_{t}/\\lVert\\pmb{R}_{t}\\rVert_{1}$ and $\\eta$ only rescales the entire sequence $\\scriptstyle R_{1},\\;...,R_{T}$ . Since ${\\mathsf{C F R}}^{+}$ runs $\\mathsf{R M}^{+}$ at each infoset independently, ${\\mathsf{C F R}}^{+}$ is infoset stepsize invariant: there may be different stepsizes across different infosets and the iterates of ${\\mathsf{C F R}}^{+}$ do not depend on them, which is desirable for large-scale EFGs where stepsize tuning may be difficult. ", "page_idx": 3}, {"type": "text", "text": "$\\mathsf{R M}^{+}$ can be interpreted as an instantiation of Blackwell approachability [3, 1], where the goal of the decision maker is to compute the sequence of strategies $\\bar{\\pmb{x}_{1}},...,\\pmb{x}_{T}\\in\\bar{\\Delta}^{d}$ to ensure that the auxiliary sequence ${\\cal R}_{T}/{\\cal T}\\in\\mathbb{R}_{+}^{d}$ approaches the target set $\\mathbb{R}_{-}^{d}$ as $T\\to+\\infty$ .  S\u2208ince $R_{t}\\in\\mathbb{R}_{+}^{d}$ , this is equivalent to ensuring that $\\mathrm{lim}_{T\\rightarrow+\\infty}\\,R_{T}/T={\\bf0}$ . The vector $\\ensuremath{\\boldsymbol{g}}(\\ensuremath{\\boldsymbol{\\mathbf{\\mathit{x}}}},\\ell)$ is interpreted as an instantaneous loss for the approachability instance. As an instantiation of Blackwell approachability, at each iteration $\\mathsf{R M}^{+}$ computes an orthogonal projection onto the conic hull of the decision set: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{R}_{+}^{d}=\\mathsf{c o n e}(\\Delta^{d})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with $\\mathsf{c o n e}(\\mathcal{Z}):=\\left\\{\\alpha\\pmb{x}\\mid\\pmb{x}\\in\\mathcal{Z},\\alpha\\geq0\\right\\}$ for a set $\\mathcal{Z}$ . The function $R\\mapsto R/\\lVert R\\rVert_{1}$ is based on ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Delta^{d}\\subset\\{\\pmb{x}\\in\\mathbb{R}^{d}\\mid\\langle\\pmb{x},\\mathbf{1}\\rangle=1\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Since for $R\\in\\mathbb{R}_{+}^{d},\\langle\\pmb{R},\\pmb{1}\\rangle=\\|\\pmb{R}\\|_{1}$ , then $\\pmb{x}_{t}=R_{t}/\\lVert\\pmb{R}_{t}\\rVert_{1}$ can be written $\\pmb{x}_{t}=\\pmb{R}_{t}/\\langle\\pmb{R}_{t},\\mathbf{1}\\rangle$ , with 1 a vector such that the decision set $\\Delta^{d}$ satisfies (7). This ensures that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\langle\\pmb{R}_{t},\\pmb{g}(\\pmb{x}_{t},\\pmb{\\ell})\\rangle=0,\\forall\\,\\pmb{\\ell}\\in\\mathbb{R}^{d}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We provide an illustration of the dynamics of $\\mathsf{R M}^{+}$ in Figure 1. Equation (8) is known as a hyperplane forcing condition and is a key ingredient in any Blackwell approachability-based algorithm; it ensures that the vector $R_{T}$ grows at most at a rate of $O({\\sqrt{T}})$ so that $\\mathrm{lim}_{T\\rightarrow+\\infty}\\,R_{T}/T={\\bf0}$ . We refer to [33, 22] and to Appendix $\\mathbf{C}$ for more details on Blackwell approachability. ", "page_idx": 3}, {"type": "text", "text": "3 Blackwell Approachability on Treeplexes ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section we introduce a modular regret minimization framework for the treeplex based on Blackwell approachability. This framework can be used as a regret minimizer over $\\tau$ in the self-play framework (described in the previous section and in Appendix A) to obtain an algorithm for solving EFGs. Our algorithms are based on the fact that for $\\bar{\\mathcal{T}}\\bar{\\subset}\\,\\mathbb{R}^{n+1}$ a treeplex as defined in (2), we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{T}\\subset\\{\\pmb{x}\\in\\mathbb{R}^{n+1}\\mid\\langle\\pmb{x},\\pmb{a}\\rangle=1\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "for $\\pmb{a}=(1,\\mathbf{0})\\in\\mathbb{R}^{n+1}$ with $\\mathbf{0}=(0,...,0)\\in\\mathbb{R}^{n}$ . This property is analogous to (7) for the simplex. With this analogy in mind, we define $\\mathcal{C}\\subset\\mathbb{R}^{n+1}$ and $\\pmb{f}(\\pmb{x},\\dot{\\pmb{\\ell}})\\in\\mathbb{R}^{n+1}$ as, for $\\mathbf{\\Delta}_{\\mathbf{x},\\,}\\ell\\in\\mathbb{R}^{n+1}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}{\\mathcal{C}:=\\mathsf{c o n e}(\\mathcal{T})}\\\\ {f(x,\\ell):=\\ell-\\langle x,\\ell\\rangle a.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Equation (10) and Equation (11) are analogous to (6) and (5). The cone $\\mathcal{C}$ and the vector $\\scriptstyle f(x,\\ell)$ play a similar role for $\\tau$ as $\\mathbb{R}_{+}^{d}$ and $\\ensuremath{\\boldsymbol{g}}(\\ensuremath{\\boldsymbol{\\mathbf{\\mathit{x}}}},\\ell)$ play for $\\Delta^{d}$ in $\\mathsf{R M}^{+}$ . Our framework is described in Algorithm 1 and relies on running a regret minimizer Regmin over $\\mathcal{C}=\\mathsf{c o n e}(\\mathcal{T})$ against the losses ${\\bf\\nabla}{\\bf f}({\\bf x}_{t},\\ell_{t})$ to obtain a regret minimizer over $\\tau$ against the losses $\\ell_{t}$ , for $t\\geq1$ . ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Blackwell approachability on the treeplex ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "1: Input: A regret minimizer Regmin with decision   \nset $\\mathcal{C}$   \n2: Initialization: $\\pmb{R}_{1}=\\mathbf{0}\\in\\mathbb{R}^{n+1}$   \n3: for $t=1,\\dots,T$ do   \n4: ${\\pmb x}_{t}=R_{t}/\\langle R_{t},{\\pmb a}\\rangle$   \n5: Observe the loss vector $\\ell_{t}\\in\\mathbb{R}^{n+1}$   \n6: Regmin observes $f(\\mathbf{x}_{t},\\ell_{t})\\in\\mathbb{R}^{n+1}$   \n7: $\\bar{\\pmb{R}_{t+1}}=\\mathsf{R e g m i n}\\left(\\right.$ \u00b7) ", "page_idx": 4}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/a7e2a4423b6863c6393272dec70494fa890a5da2ebccb6415d01b302b1a32df8.jpg", "img_caption": ["Figure $1\\colon{\\mathsf{R M}}^{+}$ in $\\mathbb{R}_{+}^{2}$ , with $\\pmb{g}_{t}=\\pmb{g}(\\pmb{x}_{t},\\pmb{\\ell}_{t})$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "By convention that ${\\bf0}/0$ is the uniform strategy for the treeplex. Algorithm 1 is the first Blackwell approachability-based algorithm operating on the entire treeplex (in contrast to ${\\mathsf{C F R}}^{+}$ which relies on Blackwell approachability locally at the infosets level). We first describe some important properties of Algorithm 1: ", "page_idx": 4}, {"type": "text", "text": "Feasibility of the iterates. Algorithm 1 produces feasible strategies, i.e., $\\pmb{x}_{t}\\in\\mathcal{T},\\forall\\,t\\geq1$ . Indeed, since Regmin is a regret minimizer with $\\mathcal{C}$ as the decision set, $R_{t}\\in\\mathsf{c o n e}(T)$ , i.e., $R_{t}=\\alpha z$ with \u03b1 \u2208R+ and z \u2208T . From (9), we have \u27e8z, a\u27e9= 1. Therefore, xt = \u27e8RRt,ta\u27e9 $\\begin{array}{r}{\\pmb{x}_{t}=\\frac{\\pmb{R}_{t}}{\\langle\\pmb{R}_{t},\\pmb{a}\\rangle}=\\frac{\\alpha z}{\\alpha\\langle\\pmb{z},\\pmb{a}\\rangle}=\\pmb{z}\\in\\mathcal{T}}\\end{array}$ . This is analogous to $\\mathsf{R M}^{+}$ , where $\\pmb{x}_{t}$ is proportional to $R_{t}$ , see (4) and Figure 1. ", "page_idx": 4}, {"type": "text", "text": "Hyperplane forcing. For any $t\\in\\mathbb{N}$ we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\langle\\pmb{R}_{t},f(\\pmb{x}_{t},\\ell)\\rangle=0,\\forall\\,\\ell\\in\\mathbb{R}^{n+1}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The hyperplane forcing equation (12) is a crucial component of algorithms based on Blackwell approachability. It ensures that $\\|R_{t}\\|_{2}=O(\\sqrt{T})$ . Equation (12) is analogous to (8) for $\\mathsf{R M}^{+}$ and follows from $\\begin{array}{r}{\\pmb{x}_{t}=\\frac{\\pmb{R}_{t}}{\\langle\\pmb{R}_{t},\\pmb{a}\\rangle}}\\end{array}$ , so that ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{t},f(x_{t},\\ell)\\rangle=\\langle R_{t},\\ell\\rangle-\\langle x_{t},\\ell\\rangle\\langle R_{t},a\\rangle=\\langle R_{t},\\ell\\rangle-\\langle{\\frac{R_{t}}{\\langle R_{t},a\\rangle}},\\ell\\rangle\\langle R_{t},a\\rangle=\\langle R_{t},\\ell\\rangle-\\langle R_{t},\\ell\\rangle=0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Regret minimization over $\\tau$ . Algorithm 1 always yields a regret minimizer over the treeplex $\\tau$ , i.e., it ensures that the regret of $\\pmb{x}_{1},...,\\pmb{x}_{T}\\in\\mathcal{T}$ against any $\\ell_{1},...,\\ell_{T}\\in\\mathbb{R}^{n+1}$ is bounded by $O({\\sqrt{T}})$ . The proof is instructive and shows a central component to Blackwell approachability-based algorithms: minimizing regret over $\\tau$ can be achieved by minimizing regret over cone $(\\tau)$ . ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.1. Let Regmin be a regret minimizer with $\\mathcal{C}$ as the decision set. Let $x_{1},...,x_{T}\\in{\\mathcal{T}}\\,b,$ e computed by Algorithm 1. Then $\\begin{array}{r}{\\operatorname*{max}_{\\hat{\\pmb{x}}\\in\\mathcal{T}}\\sum_{t=1}^{T}\\langle\\pmb{x}_{t}-\\hat{\\pmb{x}},\\pmb{\\ell}_{t}\\rangle=O(\\sqrt{T})}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. Let ${\\hat{\\mathbf{x}}}\\in{\\mathcal{T}}$ and let us write $\\hat{R}=\\hat{x}$ . We have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle x_{t}-\\hat{x},\\ell_{t}\\rangle=\\sum_{t=1}^{T}\\langle-\\hat{x},f\\left(x_{t},\\ell_{t}\\right)\\rangle=\\sum_{t=1}^{T}\\langle-\\hat{R},f\\left(x_{t},\\ell_{t}\\right)\\rangle=\\sum_{t=1}^{T}\\langle R_{t}-\\hat{R},f\\left(x_{t},\\ell_{t}\\right)\\rangle\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the first equality follows from the definition of ${\\bf{\\nabla}}{\\bf{\\mathcal{f}}}\\left({\\bf{\\boldsymbol{x}}}_{t},{\\boldsymbol{\\ell}}_{t}\\right)$ and $\\langle z,a\\rangle=1$ for any $z\\in\\mathcal{T}$ , the second equality is because $\\hat{\\mathbf{x}}=\\hat{\\pmb{R}}$ , and the last equality follows from the hyperplane forcing condition (12). Now note that $\\begin{array}{r}{\\sum_{t=1}^{T}\\langle R_{t}-\\hat{R},f\\left(x_{t},\\ell_{t}\\right)\\rangle}\\end{array}$ is the regret of a regret minimizer Regmin choosing $R_{1},...,R_{T}$ in the d ecision set $\\mathcal{C}:=\\mathsf{c o n e}(T)$ against a sequence of loss $\\pmb{f}\\left(\\pmb{x}_{1},\\ell_{1}\\right),\\-b\\left(\\pmb{x}_{T},\\ell_{T}\\right)$ and a comparator $\\hat{R}\\in\\mathsf{c o n e}(\\mathcal{T})$ . Therefore, $\\begin{array}{r}{\\sum_{t=1}^{T}\\langle R_{t}-\\hat{R},f\\left(x_{t},\\ell_{t}\\right)\\rangle=O(\\sqrt{T})}\\end{array}$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Remark 3.2. In their seminal paper, Abernethy et al. $I I J$ show a general reduction from regret minimization to Blackwell approachability for compact convex decision sets. Our reduction from Algorithm 1 builds upon the ideas in [1], but our reduction is different and exploits the structure of treeplexes. Additionally, [1] focuses on the case of adversarial losss, whereas we focus on solving EFGs, where stepsize invariance properties is crucial and where we can prove fast ${\\cal O}(1/T)$ convergence rates. We provide a more detailed comparison with [1] in Appendix $C$ . ", "page_idx": 5}, {"type": "text", "text": "4 Instantiations of Algorithm 1 ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We can instantiate Algorithm 1 with any regret minimizer over $\\mathcal{C}$ to obtain various properties such as stepsize invariance or achieving ${\\cal O}(1/T)$ convergence rate. We show next how to do so. ", "page_idx": 5}, {"type": "text", "text": "Predictive Treeplex Blackwell $^+$ $(\\mathsf{P T B}^{+})$ ). We first introduce Predictive Treeplex Blackwell+ (Algorithm 2), combining Algorithm 1 with POMD with $\\mathcal{C}$ as a decision set. ", "page_idx": 5}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/c6c719a425b069737438a6227e3e99a6ab1a2d14098b73e4b8df52d3cf711d21.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "We start by highlighting a crucial property of $\\mathsf{P T B}^{+}$ , treeplex stepsize invariance. The sequence of iterates $\\pmb{x}_{1},...,\\pmb{x}_{T}$ generated by Algorithm 2 is independent of the choice of the stepsize $\\eta>0$ , that only rescales the sequences $\\bar{R}_{1},...,\\bar{R}_{T}$ and $R_{1},...,R_{T}$ , the orthogonal projection onto a cone is positively homogeneous of degree 1: $\\Pi_{\\mathcal{C}}(\\eta\\pmb{z})=\\eta\\Pi_{\\mathcal{C}}(\\pmb{z})$ for $\\eta>0$ and $z\\in\\bar{\\mathbb{R}}^{n+1}$ , and the function $R\\mapsto R/\\langle R,a\\rangle$ is scale-invariant: $\\begin{array}{r}{\\frac{\\left(\\eta R\\right)}{\\left<\\left(\\eta R\\right),a\\right>}\\,=\\,\\frac{R}{\\left<R,a\\right>}}\\end{array}$ RR,a\u27e9for \u03b7 > 0 and R \u2208Rn+1. We provide a rigorous statement in the following proposition and we present the proof in Appendix D. ", "page_idx": 5}, {"type": "text", "text": "Proposition 4.1. The sequence $\\pmb{x}_{1},...,\\pmb{x}_{T}$ computed by ${\\mathsf{P T B}}^{+}$ is independent on the stepsize $\\eta>0$ . ", "page_idx": 5}, {"type": "text", "text": "Treeplex stepsize invariance is a crucial property, since in large EFGs, stepsize tuning is difficult and resource-consuming. This is the main advantage of using Blackwell approachability: running POMD directly on the treeplex $\\tau$ does not result in a stepsize invariant algorithm, whereas $\\mathsf{P T B}^{+}$ runs POMD on cone $(\\tau)$ and is stepsize invariant. To our knowledge, ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ are the only other treeplex stepsize invariant algorithms for solving EFGs. In fact, they satisfy a stronger infoset stepsize invariance property: different stepsizes can be used at different infosets, and the iterates do not depend on their values. We discuss the relation between $\\mathsf{P T B}^{+}$ and known instantiations of Blackwell approachability over the simplex $^{\\mathsf{R M}^{+}}$ and ${\\mathsf{C B A}}^{+}$ [22]) in Appendix E. ", "page_idx": 5}, {"type": "text", "text": "From Proposition 3.1 and the regret bounds on POMD (see for instance section 3.1.1 in [34] or section 6 in [16]), we obtain the following proposition. We define $\\Omega\\in\\mathbb{R}_{+}$ as $\\Omega:=\\operatorname*{max}_{\\mathbf{x}\\in T}\\|\\mathbf{x}\\|_{2}$ . ", "page_idx": 5}, {"type": "text", "text": "Proposition 4.2. Let $\\pmb{x}_{1},...,\\pmb{x}_{T}$ be computed by $\\mathsf{P T B}^{+}$ . Then $\\begin{array}{r l}{\\operatorname*{max}_{\\hat{\\mathbf{x}}\\in\\mathcal{T}}\\sum_{t=1}^{T}\\langle\\mathbf{x}_{t}\\,-\\,\\hat{\\mathbf{x}},\\ell_{t}\\rangle\\ \\le}&{}\\end{array}$ $\\begin{array}{r}{\\Omega\\sqrt{\\sum_{t=1}^{T}\\|\\boldsymbol{f}(\\boldsymbol{x}_{t},\\ell_{t})-\\boldsymbol{m}_{t}\\|_{2}^{2}}.}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "From Proposition 4.2, ${\\mathsf{P T B}}^{+}$ is a regret minimizer over treeplexes, and we can combine it with the self-play framework to solve EFGs, as shown in the next corollary. We use the notations d := max{n, m} + 1, \u2126\u02c6:= max{\u2225z\u22252| z \u2208X \u222aY}, \u2225M\u22252 := supv\u0338=0\u2225\u2225Mv\u2225v2\u22252 ", "page_idx": 6}, {"type": "text", "text": "Corollary 4.3. Let $(\\mathbf{\\boldsymbol{x}}_{t})_{t\\ge1}$ and $(\\pmb{y}_{t})_{t\\geq1}$ be the sequence of strategies computed by both players employing ${\\mathsf{P T B}}^{+}$ in the self-play framework, with previous losses as predictions: $\\mathbf{\\Psi}^{m_{t}^{x}}\\mathbf{\\Psi}=$ $\\pmb{f}(\\pmb{x}_{t-1},\\pmb{M}\\pmb{y}_{t-1}),\\pmb{m}_{t}^{y}=\\pmb{f}(\\pmb{y}_{t-1},-\\pmb{M}^{\\top}\\pmb{x}_{t-1})$ . Let $\\begin{array}{r}{\\left(\\bar{\\pmb x}_{T},\\bar{\\pmb y}_{T}\\right)=\\frac{1}{T}\\sum_{t=1}^{T}\\left(\\pmb x_{t},\\pmb y_{t}\\right)}\\end{array}$ . Then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{y\\in\\mathcal{Y}}\\,\\left\\langle\\bar{x}_{T},M\\pmb{y}\\right\\rangle-\\operatorname*{min}_{x\\in\\mathcal{X}}\\,\\langle x,M\\bar{y}_{T}\\rangle\\leq\\frac{\\hat{\\Omega}^{3}\\sqrt{d}\\sqrt{\\|M\\|_{2}}}{\\sqrt{T}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Finally, we can efficiently compute the orthogonal projection onto $\\mathcal{C}$ , since $\\mathcal{C}$ admits the following simple formulation of as a polytope: $\\begin{array}{r}{\\mathcal{C}=\\{\\pmb{x}\\in\\mathbb{R}_{+}^{n+1}\\mid\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\:j\\in\\mathcal{I}\\}}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.4. Let $\\tau$ be a treeplex with depth $d,$ , number of sequences $n$ , number of leaf sequences $l_{i}$ , and number of infosets m. The orthogonal projection $\\Pi_{\\mathcal{C}}(\\pmb{y})$ of a point $\\pmb{y}\\in\\mathbb{R}^{n+1}$ onto $\\mathcal{C}=\\mathsf{c o n e}(\\mathcal{T})$ can be computed in $O(d n\\log(l+m))$ ) arithmetic operations. ", "page_idx": 6}, {"type": "text", "text": "A stable algorithm: Smooth ${\\mathsf{P T B}}^{+}$ . We now modify ${\\mathsf{P T B}}^{+}$ to obtain faster convergence rates. The $O(1/\\sqrt{T})$ average convergence rate of $\\mathsf{P T B}^{+}$ may seem surprising since in the matrix game setting, POMD over the simplexes obtains a ${\\cal O}(1/T)$ average convergence [36]. This discrepancy comes from ${\\mathsf{P T B}}^{+}$ running POMD on the set $\\mathcal{C}=\\mathsf{c o n e}(\\mathcal{T})$ instead of the original decision set $\\tau$ , so that the Lipschtiz continuity of the loss function and the classical $R V U$ bounds (Regret Bounded by Variation in Utilities, see Equation (1) in [36]), central to proving the fast convergence of predictive algorithms, may not hold. For $\\mathsf{P T B}^{+}$ , the Lipschitz continuity of the loss $\\scriptstyle R\\;\\mapsto\\;{\\bar{f}}\\left(x,\\ell\\right)$ with $\\pmb{x}=R/\\langle\\pmb{R},\\pmb{a}\\rangle$ depends on the Lipschitz continuity of the decision function ${R\\mapsto R/\\langle R,a\\rangle}$ over $\\mathcal{C}$ , which we analyze next. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.5. Let $R_{1},R_{2}\\in\\mathsf{c o n e}(\\mathcal{T})$ $\\begin{array}{r}{).\\ T h e n\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{R_{2}}{\\langle R_{2},a\\rangle}\\right\\|_{2}\\leq\\frac{\\Omega\\cdot\\|R_{1}-R_{2}\\|_{2}}{\\operatorname*{max}\\{\\langle R_{1},a\\rangle,\\langle R_{2},a\\rangle\\}}.}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "We present the proof of Proposition 4.5 in Appendix F. Proposition 4.5 shows that when the vector $\\boldsymbol{R}$ is such that $\\langle R,a\\rangle$ is small, the decision function ${R\\mapsto R/\\langle R,a\\rangle}$ may vary rapidly, an issue known as instability and also observed for a predictive variant of $\\mathsf{R M}^{+}$ [18]. To ensure the Lipschitzness of the decision function, we can ensure that $\\textstyle R_{t}$ and $\\hat{R}_{t}$ always belong to the stable region $\\ensuremath{\\mathcal{C}}_{\\geq}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal C_{\\geq}:=\\mathsf{c o n e}({\\mathcal T})\\cap\\{R\\in\\mathbb R^{n+1}\\mid\\langle R,a\\rangle\\geq R_{0}\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "for $R_{0}>0$ , and we recover Lipschitz continuity over $c_{\\ge}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{R_{2}}{\\langle R_{2},a\\rangle}\\right\\|_{2}\\leq\\frac{\\Omega}{R_{0}}\\|R_{1}-R_{2}\\|_{2},\\forall\\,R_{1},R_{2}\\in\\mathcal C_{\\geq}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This leads us to introduce Smooth ${\\mathsf{P T B}}^{+}$ (Algorithm 3), a variant of ${\\mathsf{P T B}}^{+}$ ,where $R_{t}$ and $\\hat{R}_{t}$ always belong to $\\ensuremath{\\mathcal{C}}_{\\geq}$ . For Smooth $\\mathsf{P T B}^{+},\\pmb{x}_{t}\\in\\mathcal{T}$ since $R_{t}\\in\\mathcal{C}_{\\geq}\\subset\\mathsf{c o n e}(T)$ , and we also have the hyperplane forcing property (12), which only depends on $\\pmb{x}_{t}\\bar{=}\\pmb{R}_{t}/\\langle\\pmb{R}_{t},\\pmb{a}\\rangle$ . However, Smooth ${\\mathsf{P T B}}^{+}$ is not treeplex stepsize invariant, because the orthogonal projections are onto $\\ensuremath{\\mathcal{C}}_{\\geq}$ , which is not a cone. Note that $\\ensuremath{\\mathcal{C}}_{\\geq}$ admits a simple polytope formulation: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\geq}=\\{x\\in\\mathbb{R}_{+}^{n+1}\\;|x_{\\mathcal{Q}}\\geq R_{0},\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\:j\\in\\mathcal{T}\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "so the complexity of computing the orthogonal projection onto $\\ensuremath{\\mathcal{C}}_{\\geq}$ is the same as computing the orthogonal projection onto $\\mathcal{C}$ . We provide a proof in Appendix H. We now show that Smooth ${\\mathsf{P T B}}^{+}$ is a regret minimizer. Indeed, the proof of Proposition 3.1 can be adapted to relate the regret in $\\mathbf{\\Delta}x_{1},...,x_{T}$ in $\\tau$ to regret in $R_{1},...,R_{T}$ in $\\ensuremath{\\mathcal{C}}_{\\geq}$ . ", "page_idx": 6}, {"type": "text", "text": "Proposition 4.6. Let $\\mathbf{\\Delta}x_{1},...,x_{T}$ be computed by Smooth $\\mathsf{P T B}^{+}$ . Let $\\begin{array}{r}{\\eta\\,=\\,\\frac{\\sqrt{2\\Omega}}{\\sqrt{\\sum_{t=1}^{T}\\|f(\\pmb{x}_{t},\\ell_{t})-\\pmb{m}_{t}\\|_{2}^{2}}}}\\end{array}$ The $\\begin{array}{r}{\\eta\\operatorname*{max}_{\\hat{x}\\in{\\mathcal T}}\\sum_{t=1}^{T}\\langle x_{t}-\\hat{x},\\ell_{t}\\rangle\\leq\\Omega\\sqrt{\\sum_{t=1}^{T}\\left\\Vert f(x_{t},\\ell_{t})-m_{t}\\right\\Vert_{2}^{2}}.}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "In Smooth $\\mathsf{P T B}^{+}\\,{\\cal R}_{t}$ and $\\hat{R}_{t}$ always belong to $\\ensuremath{\\mathcal{C}}_{\\geq}$ , and we are able to recover a RVU bound and show faster convergence. We let $\\|M\\|$ be the maximum $\\ell_{2}$ -norm of any column and any row of $_M$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.7. Let $(\\pmb{x}_{t})_{t\\geq1}$ and $(\\pmb{y}_{t})_{t\\geq1}$ be the sequence of strategies computed by both players employing Smooth $\\bar{\\mathsf{P}}\\mathsf{T}\\mathsf{B}^{+}$ in the self-play framework, with previous losses as predictions: $m_{t}^{x}\\;=\\;f\\bigl(x_{t-1},M y_{t-1}\\bigr),m_{t}^{y}\\;=\\;f\\bigl(y_{t-1},-\\dot{M}^{\\top}x_{t-1}\\bigr)$ . Let $\\begin{array}{r}{\\eta\\ \\stackrel{\\star}{=}\\ \\frac{R_{0}}{\\sqrt{8d\\hat{\\Omega}^{3}}\\lVert M\\rVert}}\\end{array}$ and $(\\bar{\\pmb{x}}_{T},\\bar{\\pmb{y}}_{T})\\;=$ $\\begin{array}{r}{\\frac{1}{T}\\sum_{t=1}^{T}\\left(x_{t},y_{t}\\right).\\ T h e n\\operatorname*{max}_{y\\in\\mathcal{Y}}\\left\\langle\\bar{x}_{T},M y\\right\\rangle-\\operatorname*{min}_{x\\in\\mathcal{X}}\\left\\langle x,M\\bar{y}_{T}\\right\\rangle\\leq\\frac{2\\hat{\\Omega}^{2}}{\\eta}\\frac{1}{T}.}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "We present the proof of Theorem 4.7 in Appendix I. To the best of our knowledge, Smooth ${\\mathsf{P T B}}^{+}$ is the first algorithm based on Blackwell approachability achieving a ${\\cal O}(1/T)$ convergence rate for solving EFGs as in (1), answering an important open question. However, achieving the faster rate in Smooth ${\\mathsf{P T B}}^{+}$ requires introducing a stepsize, a situation similar to all other $O(1/\\bar{T})$ -methods for EFGs, like Mirror Prox and Excessive Gap Technique for EFGs [27] and predictive OMD directly on the treeplex [14]. We can compare the ${\\cal O}(1/T)$ convergence rate of Smooth $\\mathsf{P T B}^{+}$ with the $O(1/\\sqrt{T})$ convergence rate of Predictive ${\\mathsf{C F R}}^{+}$ [16], which combines CFR with Predictive $\\mathsf{R M}^{+}$ (see Appendix B). Despite its predictive nature, Predictive ${\\mathsf{C F R}}^{+}$ only achieves a $O(1/\\sqrt{T})$ convergence rate because of the CFR decomposition, which enables running regret minimizers independently and locally at each infoset, and it is not clear how to combine, at the treeplex level, the regret bounds obtained at each infoset. Since Smooth $\\mathsf{P T B}^{+}$ operates over the entire treeplex, we can combine the RVU bound for each player to obtain a ${\\cal O}(1/T)$ convergence rate. ", "page_idx": 7}, {"type": "text", "text": "Remark 4.8. The Clairvoyant CFR algorithm from $I I8J$ is based on Blackwell approachability over simplexes, combined with the CFR decomposition and a Mirror Prox-style update [31]. For solving EFGs, Clairvoyant CFR achieves a $O(\\log(T)/T)$ ) convergence rate, slower than the ${\\cal O}(1/T)$ convergence rate of Smooth $\\mathsf{P T B}^{+}$ , where the additional $\\log(T)$ factor occurs because each outer iteration of Clairvoyant CFR itself solves an approximate fixed-point problem. ", "page_idx": 7}, {"type": "text", "text": "For completeness, we also instantiate Algorithm 1 with regret minimizers that learn heterogeneous stepsizes across information sets in an adaptive fashion. This results in AdaGradTB+(Algorithm 6) and AdamTB+(Algorithm 7), which adapt the scale of the stepsizes for each dimension to the magnitude of the observed gradients for this dimension based on AdaGrad [12] and Adam [25]. This may be useful if the losses across different dimensions differ in magnitudes, but the stepsizes decrease over time, which could be conservative. These algorithms are presented in Appendix J ", "page_idx": 7}, {"type": "text", "text": "Remark 4.9 (Comparison with Lagrangian Hedging). Algorithm 1 is related to Lagrangian Hedging [21, 11]. Lagrangian Hedging builds upon Blackwell approachability with various potential functions to construct regret minimizers for general decision sets. As explained in the introduction, the main focus of our paper is on two-player zero-sum EFGs, i.e., on the case where the decision sets are treeplexes, and where we can obtain several additional interesting properties not studied in [21, 11], such as stepsize invariance, fast convergence rates, and efficient projection, as we detail in the next section. If one were to instantiate Algorithm 1 with the Follow-The-Regularized Leader algorithm, it would yield the regret minimizer for treeplexes studied in Gordon [21], and our Proposition 4.4 in the next section yields an efficient projection oracle for the setup in Gordon [21], which appealed to general convex optimization as an oracle. ", "page_idx": 7}, {"type": "text", "text": "5 Numerical Experiments ", "text_level": 1, "page_idx": 7}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/765f2b84a58a873ef21c5bb48dbf6a699b825c4c11ed7c1c923f4e39fd6841d8.jpg", "img_caption": ["Figure 2: Convergence to a Nash equilibrium for ${\\mathsf{P T B}}^{+}$ , ${\\mathsf{C F R}}^{+}$ , $\\mathsf{P C F R}^{+}$ and SC-POMD. All algorithms use alternation and quadratic averaging except ${\\mathsf{C F R}}^{+}$ instantiated with linear averaging. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/14493b9599f73fc0193009d86ca584f8313174144c2cf8e771f505d305d62923.jpg", "img_caption": ["Figure 3: Convergence to a Nash equilibrium for the last iterates of ${\\mathsf{P T B}}^{+}$ , ${\\mathsf{C F R}}^{+}$ , $\\mathsf{P C F R}^{+}$ , and SC-POMD. Every algorithm is using alternation. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "We conduct two sets of numerical experiments to investigate the performance of our algorithms for solving several two-player zero-sum EFG benchmark games: Kuhn poker, Leduc poker, Liar\u2019s Dice, Goofspiel and Battleship. Additional experimental detail is given in Appendix K. ", "page_idx": 8}, {"type": "text", "text": "We first determine the best instantiatons our framework. We compare $\\mathsf{P T B}^{+}$ , Smooth $\\mathsf{P T B}^{+}$ and AdaGradTB+ in the self-play framework with alternation (see Appendix A) and uniform, linear or quadratic weights for the iterates. ${\\mathsf{P T B}}^{+}$ and Smooth ${\\mathsf{P T B}}^{+}$ use the previous losses as predictions. We also study Treeplex Blackwell+ $(\\mathsf{T B}^{+})$ , corresponding to $\\mathsf{P T B}^{+}$ without predictions $\\mathbf{\\nabla}m_{t}=\\mathbf{0}$ ), and AdamTB+. For conciseness, we present our plots in Appendix K.3 (Figure 4) and state our conclusion here. We find that, for every game, ${\\mathsf{P T B}}^{+}$ performs the best or is among the best algorithms. This underlines the advantage of treeplex stepsize invariance over algorithms that require tuning a stepsize (Smooth ${\\mathsf{P T B}}^{+}$ ) and adaptive algorithms (AdaGradTB+), which may perform poorly due to the stepsize decreasing at a rate of $\\bar{O}(1/\\sqrt{T})$ . AdamTB+ does not even converge in some games. ", "page_idx": 8}, {"type": "text", "text": "We then compare the best of our algorithms $(\\mathsf{P T B}^{+})$ with some of the best existing methods for solving EFGs: ${\\mathsf{C F R}}^{+}$ [37], predictive ${\\mathsf{C F R}}^{+}$ $\\mathsf{P C F R}^{+}$ , [16], see Appendix B), and a version of optimistic online mirror descent with a single call to the orthogonal projection at every iteration (SC-POMD, [24]) achieving a ${\\cal O}(1/T)$ convergence rate; there are a variety of FOMs with a ${\\cal O}(1/T)$ rate, SC-POMD was observed to perform well in [8]. We determine the best empirical setup for each algorithm in Appendix K.4. In Figure 2, we compare the performance of the (weighted) average iterates. We find that $\\mathsf{P C F R}^{+}$ outperforms both ${\\mathsf{C F R}}^{+}$ and the theoretically-faster SC-POMD, as expected from past work. We had hoped to see at least comparable performance between ${\\mathsf{P T B}}^{+}$ and $\\mathsf{P C F R}^{+}$ , since they are both based on Blackwell-approachability regret minimizers derived from applying POMD on the conic hull of their respective decision sets (simplexes at each infoset for ${\\mathsf{P C F R}}^{+}$ , treeplexes of each player for $\\mathsf{P T B}^{+}$ ). However, in some games $\\mathsf{P C F R}^{+}$ performs much better than ${\\mathsf{P T B}}^{+}$ . Given the similarity between ${\\mathsf{P T B}}^{+}$ and $\\mathsf{P C F R}^{+}$ , our results suggest that the use of the CFR decomposition is part of the key to the performance of $\\mathsf{P C F R}^{+}$ . The CFR decomposition allows $\\mathsf{P C F R}^{+}$ to have stepsize invariance at an infoset level, as opposed to stepsize invariance at the treeplex level in ${\\mathsf{P T B}}^{+}$ . Because of the structure of treeplexes, the numerical values of variables associated with infosets appearing late in the game, i.e., deeper in the treeplexes, may be much smaller than the numerical values of the variables appearing closer to the root. For this reason, allowing for different stepsizes at each infosets (like ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ do) appears to be more efficient than using a single stepsize across all the infosets, even when the iterates do not depend on the value of this single stepsize (like in ${\\mathsf{P T B}}^{+}$ ) and when this stepsize is fine-tuned (like in SC-POMD). Of course one could try to run SC-POMD with different stepsizes at each infoset and attempt to tune each of these stepsizes, but this is impossible in practical instances where the number of actions is large, e.g., $4.9\\times10^{4}$ actions in Liar\u2019s Dice and $5.3\\times10^{6}$ actions in Goofspiel. ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ bypass this issue with their infoset stepsize invariance, which enables both each infoset to have its own stepsize (via the CFR decomposition) and not needing to choose these stepsizes (via using $\\mathsf{R M}^{+}$ and $\\mathsf{P R M}^{+}$ as local regret minimizers, which are stepsize invariant). ", "page_idx": 8}, {"type": "text", "text": "We also investigate the performance of the last iterates in Figure 3. No algorithm appears to be the best across all game instances. ${\\mathsf{C F R}}^{+}$ may not converge to a Nash equilibrium (e.g., on Kuhn), as has been observed before [29]. $\\mathsf{P C F R}^{+}$ exhibits linear convergence in some games (Kuhn, Liar\u2019s Dice, Goofspiel) but not others (Leduc). The same is true for $\\mathsf{P T B}^{+}$ . Further investigations about last-iterate convergence are left as an important open question. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We propose the first Blackwell approachability-based regret minimizer over the treeplex (Algorithm 1) and we give several instantiations of our framework with different properties, including treeplex stepsize invariance $(\\mathsf{P T B}^{+})$ , adaptive stepsizes (AdaGradTB+) and achieving $\\bar{O}(1/T)$ convergence rates on EFGs with a Blackwell approachability-based algorithm for the first time (Smooth ${\\mathsf{P T B}}^{+}$ ). Since ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ are stepsize invariant and have strong empirical performance, we were expecting ${\\mathsf{P T B}}^{+}$ to have comparable performance. However, our experiments show that ${\\mathsf{P T B}}^{+}$ often converges slower than ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ , so this treeplex stepsize invariance is not the only driver behind the practical performance of ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ . We view this negative result as an important contribution of our paper, since it rules out a previously plausible explanation for the practical performance of ${\\mathsf{C F R}}^{+}$ . Instead, we propose that one piece of the puzzle behind the ${\\mathsf{C F R}}^{+}$ and $\\mathsf{P C F R}^{+}$ performances is their infoset stepsize invariance, a consequence of combining the CFR framework with Blackwell approachability-based regret minimizers $\\left(\\mathsf{R M}^{+}$ and $\\mathsf{P R M}^{+}$ , themselves stepsize invariant over simplexes). Future directions include better understanding the last-iterate performance of algorithms based on Blackwell approachability as well as the role of alternation. It would also be interesting to explore EFG applications of new reductions between Blackwell approachability and regret minimization [10] (which differs from the reduction in [2]) and Blackwell approachability generalizations based on various norms and pseudo-norms [28, 9], potentially to obtain better stepsize invariance properties. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Darshan Chakrabarti was supported by the National Science Foundation Graduate Research Fellowship Program under award number DGE-2036197. Julien Grand-Cl\u00e9ment was supported by Hi! Paris and Agence Nationale de la Recherche (Grant 11-LABX-0047). Christian Kroer was supported by the Office of Naval Research awards N00014-22-1-2530 and N00014-23-1-2374, and the National Science Foundation awards IIS-2147361 and IIS-2238960. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] J. Abernethy, P. L. Bartlett, and E. Hazan. Blackwell approachability and no-regret learning are equivalent. In Proceedings of the 24th Annual Conference on Learning Theory, pages 27\u201346. JMLR Workshop and Conference Proceedings, 2011.   \n[2] J. D. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. 2009.   \n[3] D. Blackwell. An analog of the minimax theorem for vector payoffs. Pacific Journal of Mathematics, 6(1):1\u20138, 1956.   \n[4] N. Brown and T. Sandholm. Superhuman AI for heads-up no-limit poker: Libratus beats top professionals. Science, 359(6374):418\u2013424, 2018.   \n[5] N. Brown and T. Sandholm. Superhuman AI for multiplayer poker. Science, 365(6456):885\u2013890, 2019.   \n[6] N. Brown, C. Kroer, and T. Sandholm. Dynamic thresholding and pruning for regret minimization. In Proceedings of the AAAI conference on artificial intelligence, volume 31, 2017.   \n[7] N. Burch, M. Moravcik, and M. Schmid. Revisiting $\\mathrm{CFR+}$ and alternating updates. Journal of Artificial Intelligence Research, 64:429\u2013443, 2019.   \n[8] D. Chakrabarti, J. Diakonikolas, and C. Kroer. Block-coordinate methods and restarting for solving extensive-form games. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[9] C. Dann, Y. Mansour, M. Mohri, J. Schneider, and B. Sivan. Pseudonorm approachability and applications to regret minimization. In International Conference on Algorithmic Learning Theory, pages 471\u2013509. PMLR, 2023.   \n[10] C. Dann, Y. Mansour, M. Mohri, J. Schneider, and B. Sivan. Rate-preserving reductions for blackwell approachability. arXiv preprint arXiv:2406.07585, 2024.   \n[11] R. D\u2019Orazio and R. Huang. Optimistic and adaptive lagrangian hedging. In Thirty-fifth AAAI conference on artificial intelligence, 2021.   \n[12] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7), 2011.   \n[13] G. Farina, C. Kroer, and T. Sandholm. Online convex optimization for sequential decision processes and extensive-form games. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1917\u20131925, 2019.   \n[14] G. Farina, C. Kroer, and T. Sandholm. Optimistic regret minimization for extensive-form games via dilated distance-generating functions. In Advances in Neural Information Processing Systems, pages 5222\u20135232, 2019.   \n[15] G. Farina, C. Kroer, and T. Sandholm. Better regularization for sequential decision spaces fast convergence rates for Nash, correlated, and team equilibria. In EC\u201921: Proceedings of the 22nd ACM Conference on Economics and Computation, 2021.   \n[16] G. Farina, C. Kroer, and T. Sandholm. Faster game solving via predictive Blackwell approachability: Connecting regret matching and mirror descent. In Proceedings of the AAAI Conference on Artificial Intelligence. AAAI, 2021.   \n[17] G. Farina, I. Anagnostides, H. Luo, C.-W. Lee, C. Kroer, and T. Sandholm. Near-optimal noregret learning dynamics for general convex games. Advances in Neural Information Processing Systems, 35:39076\u201339089, 2022.   \n[18] G. Farina, J. Grand-Cl\u00e9ment, C. Kroer, C.-W. Lee, and H. Luo. Regret matching+: (in)stability and fast convergence in games. In Advances in Neural Information Processing Systems, 2023.   \n[19] Y. Freund and R. E. Schapire. Adaptive game playing using multiplicative weights. Games and Economic Behavior, 29(1-2):79\u2013103, 1999.   \n[20] A. Gilpin, J. Pena, and T. Sandholm. First-order algorithm with convergence for-equilibrium in two-person zero-sum games. Mathematical programming, 133(1-2):279\u2013298, 2012.   \n[21] G. J. Gordon. No-regret algorithms for online convex programs. In Advances in Neural Information Processing Systems, pages 489\u2013496. Citeseer, 2007.   \n[22] J. Grand-Cl\u00e9ment and C. Kroer. Solving optimization problems with Blackwell approachability. Mathematics of Operations Research, 2023.   \n[23] S. Hoda, A. Gilpin, J. Pena, and T. Sandholm. Smoothing techniques for computing Nash equilibria of sequential games. Mathematics of Operations Research, 35(2):494\u2013512, 2010.   \n[24] P. Joulani, A. Gy\u00f6rgy, and C. Szepesv\u00e1ri. A modular analysis of adaptive (non-) convex optimization: Optimism, composite objectives, and variational bounds. In International Conference on Algorithmic Learning Theory, pages 681\u2013720. PMLR, 2017.   \n[25] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations, ICLR, 2015.   \n[26] C. Kroer, G. Farina, and T. Sandholm. Solving large sequential games with the excessive gap technique. In Advances in Neural Information Processing Systems, pages 864\u2013874, 2018.   \n[27] C. Kroer, K. Waugh, F. K\u0131l\u0131n\u00e7-Karzan, and T. Sandholm. Faster algorithms for extensive-form game solving via improved smoothing functions. Mathematical Programming, pages 1\u201333, 2020.   \n[28] J. Kwon. Refined approachability algorithms and application to regret minimization with global costs. Journal of Machine Learning Research, 22(200):1\u201338, 2021.   \n[29] C.-W. Lee, C. Kroer, and H. Luo. Last-iterate convergence in extensive-form games. Advances in Neural Information Processing Systems, 34:14293\u201314305, 2021.   \n[30] M. Morav\u02c7c\u00edk, M. Schmid, N. Burch, V. Lis\\`y, D. Morrill, N. Bard, T. Davis, K. Waugh, M. Johanson, and M. Bowling. Deepstack: Expert-level artificial intelligence in heads-up no-limit poker. Science, 356(6337):508\u2013513, 2017.   \n[31] A. Nemirovski. Prox-method with rate of convergence $\\mathrm{O}(1/\\mathfrak{t})$ for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems. SIAM Journal on Optimization, 15(1):229\u2013251, 2004.   \n[32] Y. Nesterov. Excessive gap technique in nonsmooth convex minimization. SIAM Journal on Optimization, 16(1):235\u2013249, 2005.   \n[33] V. Perchet. Approachability, Calibration and Regret in Games with Partial Observations. PhD thesis, PhD thesis, Universit\u00e9 Pierre et Marie Curie, 2010.   \n[34] A. Rakhlin and K. Sridharan. Online learning with predictable sequences. In Conference on Learning Theory, pages 993\u20131019. PMLR, 2013.   \n[35] S. J. Reddi, S. Kale, and S. Kumar. On the convergence of Adam and beyond. International Conference on Learning Representations (ICLR), 2018.   \n[36] V. Syrgkanis, A. Agarwal, H. Luo, and R. E. Schapire. Fast convergence of regularized learning in games. Advances in Neural Information Processing Systems, 28, 2015.   \n[37] O. Tammelin, N. Burch, M. Johanson, and M. Bowling. Solving heads-up limit Texas hold\u2019em. In Twenty-Fourth International Joint Conference on Artificial Intelligence, 2015.   \n[38] B. von Stengel. Efficient computation of behavior strategies. Games and Economic Behavior, 14(2):220\u2013246, 1996.   \n[39] M. Zinkevich, M. Johanson, M. Bowling, and C. Piccione. Regret minimization in games with incomplete information. In Advances in neural information processing systems, pages 1729\u20131736, 2007. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Self-Play Framework ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The (vanilla) self-play framework for two-player zero-sum EFGs is presented in Algorithm 4. The self-play framework can be combined with alternation, a simple variant that is known to lead to significant empirical speedups, for instance, when ${\\mathsf{C F R}}^{+}$ and predictive ${\\mathsf{C F R}}^{+}$ are used as regret minimizers [37, 16, 7]. When using alternation, at iteration $t$ the second player is provided with the current strategy of the first player $\\pmb{x}_{t}$ before choosing its own strategy. We describe the self-play framework with alternation in Algorithm 5. ", "page_idx": 12}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/d937b03d5288b881147b2cc3a87257dcdd23d10f36b30df5f20b5ed7bab4dcc0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "text_level": 1, "page_idx": 12}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/8fd223c616039f98587bfb44629d1344ff8d6371c503f2ca0da9702113770809.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "B Counterfactual Regret Minimization (CFR), ${\\mathsf{C F R}}^{+}$ and Predictive ${\\mathsf{C F R}}^{+}$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Counterfactual Regret Minimization (CFR, [39]) is a framework for regret minimization over the treeplex. CFR runs a regret minimizer ${\\mathsf{R e g m i n}}_{j}$ locally at each infoset $j\\in\\mathcal{I}$ of the treeplex. Note that here ${\\mathsf{R e g m i n}}_{j}$ is a regret minimizer over the simplex $\\Delta^{n_{j}}$ with $n_{j}=|{\\mathcal{A}}_{j}|$ , i.e., over the set of probability distributions over $\\mathcal{A}_{j}$ , the set of actions available at infoset $j\\in\\mathcal{I}$ . Let $\\pmb{x}_{t}^{j}\\in\\Delta^{n_{j}}$ be the decision chosen by ${\\mathsf{R e g m i n}}_{j}$ at iteration $t$ in CFR and let $\\ell_{t}\\in\\mathbb{R}^{n+1}$ be the loss across the entire treeplex. The local loss $\\ell_{t}^{j}\\in\\mathbb{R}^{n_{j}}$ that CFR passes to ${\\mathsf{R e g m i n}}_{j}$ is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\ell_{t,a}^{j}:=\\ell_{t,(j,a)}+\\sum_{j^{\\prime}\\in\\mathcal{C}_{j a}}V_{t}^{j^{\\prime}},\\forall\\;a\\in\\mathcal{A}_{j},\\forall\\;j\\in\\mathcal{I}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $V_{t}^{j}$ is the value function for infoset $j$ at iteration $t$ , defined inductively: ", "page_idx": 12}, {"type": "equation", "text": "$$\nV_{t}^{j}:=\\sum_{a\\in\\mathcal{A}_{j}}x_{t,a}^{j}\\ell_{t,(j,a)}+\\sum_{j^{\\prime}\\in\\mathcal{C}_{j a}}V_{t}^{j^{\\prime}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The regret over the entire treeplex $\\tau$ can be related to the regrets accumulated at each infoset via the following laminar regret decomposition [13]: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathsf{R e g}^{T}:=\\operatorname*{max}_{\\hat{x}\\in\\mathcal{T}}\\sum_{t=1}^{T}\\langle\\pmb{x}_{t}-\\hat{\\pmb{x}},\\ell_{t}\\rangle\\leq\\operatorname*{max}_{\\hat{x}\\in\\mathcal{T}}\\sum_{j\\in\\mathcal{I}}\\hat{x}_{p_{j}}\\mathsf{R e g}_{j}^{T}\\left(\\hat{\\pmb{x}}^{j}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "with $\\begin{array}{r}{\\mathsf{R e g}_{j}^{T}\\left(\\hat{\\pmb{x}}^{j}\\right):=\\sum_{t=1}^{T}\\langle\\pmb{x}_{t}^{j}-\\hat{\\pmb{x}}^{j},\\ell_{t}^{j}\\rangle}\\end{array}$ the regret incured by Regminj for the sequence of losses $\\ell_{1}^{j},...,\\ell_{T}^{j}$ against the comparator $\\hat{\\pmb{x}}^{j}\\;\\in\\;\\Delta^{n_{j}}$ . Combining CFR with regret minimizers at each information set ensures ${\\mathsf{R e g}}^{T}=O\\left({\\sqrt{T}}\\right)$ . ", "page_idx": 12}, {"type": "text", "text": "${\\mathsf{C F R}}^{+}$ [37] corresponds to instantiating the self-play framework with alternation (Algorithm 5) and Regret Matching+ $\\left.\\mathsf{R M}^{+}$ as presented in (4)) as a regret minimizer at each information set. Additionally, ${\\mathsf{C F R}}^{+}$ uses linear averaging, i.e., it returns $\\bar{x}_{T}$ such that $\\begin{array}{r}{\\bar{\\pmb{x}}_{T}=\\frac{1}{\\sum_{t=1}^{T}\\omega_{t}}\\sum_{t=1}^{T}\\omega_{t}\\pmb{x}_{t}}\\end{array}$ with $\\omega_{t}=t$ . We also consider uniform weights $\\omega_{t}=1$ ) and quadratic weights $(\\omega=t^{2}$ ) in our simulations (Figure 10). ${\\mathsf{C F R}}^{+}$ guarantees a $O(1/\\sqrt{T})$ convergence rate to a Nash equilibrium. ", "page_idx": 13}, {"type": "text", "text": "Predictive ${\\mathsf{C F R}}^{+}({\\mathsf{P C F R}}^{+}$ , [16]) corresponds to instantiating the self-play framework with alternation (Algorithm 5) and Predictive Regret Matching+ $(\\mathsf{P R M}^{+})$ as a regret minimizer at each information set. Given a simplex $\\Delta^{d}$ , $\\mathsf{P R M}^{+}$ is a regret minimizer that returns a sequence of decisions $z_{1},...,z_{T}\\in\\Delta^{d}$ as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\pmb{R}}_{t}=\\Pi_{\\mathbb{R}_{+}^{d}}\\left(\\pmb{R}_{t}-\\eta\\pmb{g}(\\boldsymbol{z}_{t-1},\\boldsymbol{\\ell}_{t-1})\\right)}\\\\ &{\\quad\\quad\\boldsymbol{z}_{t}=\\hat{\\pmb{R}}_{t}/\\|\\hat{\\pmb{R}}_{t}\\|_{1},}\\\\ &{\\pmb{R}_{t+1}=\\Pi_{\\mathbb{R}_{+}^{d}}\\left(\\pmb{R}_{t}-\\eta\\pmb{g}(\\boldsymbol{z}_{t},\\boldsymbol{\\ell}_{t})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the function $g$ is defined in (5). Similar to ${\\mathsf{C F R}}^{+}$ , for $\\mathsf{P C F R}^{+}$ we investigate different weighting schemes in our numerical experiments (Figure 11). It is not known if the self-play framework with alternation, combined with ${\\mathsf{P C F R}}^{+}$ , has convergence guarantees, but $\\mathsf{P C F R}^{+}$ has been observed to achieve state-of-the-art practical performance in many EFG instances [16]. ", "page_idx": 13}, {"type": "text", "text": "C Comparison with [1] ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this appendix, we describe the results in [1] connecting Blackwell approachability and regret minimization, and we highlight the main differences with our framework described in Algorithm 1. ", "page_idx": 13}, {"type": "text", "text": "In particular, Abernethy et al. [1] describe a meta-algorithm connecting Blackwell approachability and regret minimization. Given a decision set $\\mathcal{X}\\subset\\mathbb{R}^{n}$ assumed to be convex and compact, Abernethy et al. [1] consider a lifted set $\\tilde{\\mathcal{X}}=\\{\\kappa\\}\\times\\mathcal{X}\\subset\\mathbb{R}^{n+1}$ with ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\kappa:=\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}\\|\\pmb{x}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Abernethy et al. [1] then constructs a regret minimizer over $\\mathcal{X}$ by considering a Blackwell approachability instance, where the target set is defined as $\\mathsf{c o n e}(\\tilde{\\boldsymbol{X}})\\subset\\mathbb{R}^{\\dot{n}+1}$ , the decision set is $\\mathcal{X}\\subset\\mathbb{R}^{n}$ , and the instantaneous loss at time $t$ is \u27e8xt\u03ba,\u2113t\u27e9, \u2212\u2113t \u2208Rn+1 with \u2113t \u2208Rn the loss vector when the decision maker chooses $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}$ . The average aggregated loss vector $\\pmb{u}_{t}\\in\\mathbb{R}^{n+1}$ is updated using a regret minimizer over cone $(\\tilde{\\mathcal{X}})$ and the decision maker in the Blackwell approachability instance chooses the sequence of decisions $\\mathbf{\\Delta}x_{1},...,x_{T}$ to ensure that $\\left(\\frac{1}{T}{\\bf u}_{T}\\right)_{T\\geq1}$ approaches the target set, defined as the polar cone of cone $(\\tilde{\\mathcal{X}})$ . We refer to Section 4 in [1] for more detail on this construction. ", "page_idx": 13}, {"type": "text", "text": "As evident from the description in the previous paragraph, our framework described in Algorithm 1 differs from the meta-algorithm from [1] in various ways. In particular, if one were to directly use the reduction from [1] for deriving regret minimizers over treeplexes, one would need to consider $\\tilde{\\mathcal{T}}=\\{\\boldsymbol{\\kappa}\\}\\times\\mathcal{T}$ , with $\\tau$ a treeplex and $\\kappa=\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{T}}||\\mathbf{x}||_{2}$ , and one would need to consider a bound for the value of $\\kappa$ , which could be conservative for large-scale EFG instances. However, since we have designed Algorithm 1 specifically for treeplexes as decision sets, we do not need to lift the set $\\tau$ by adding an additional dimension depending on the maximum $\\ell_{2}$ -norm over $\\tau$ . We can circumvent relying on $\\kappa$ and therefore obtain a simpler, more practical framework as in Algorithm 1 by exploiting the structure of treeplexes. This is because the variable $x_{\\mathcal{Q}}$ associated with the empty sequence always has a value of 1: $x_{\\partial}=1$ , and we can then exploit the fact that $\\mathcal{T}\\subset\\{\\pmb{x}\\in\\mathbb{R}^{n+1}\\}\\,\\,\\langle\\pmb{x},\\bar{\\pmb{a}}\\rangle=1\\}$ , as in the proof of Proposition 3.1. ", "page_idx": 13}, {"type": "text", "text": "Another fundamental difference with [1] is our positioning and our objectives. Abernethy et al. [1] analyze Blackwell approachability with adversial losses and in a more theoretical way (e.g., no implementations or simulations), whereas we focus on practically solving EFGs with Blackwell approachability, i.e., we focus on the game setting and on explaining the empirical performance of ${\\mathsf{C F R}}^{+}$ . A direct application of the results in [1] would only result in algorithms achieving $O(1/\\sqrt{T})$ convergence rates, and for which no concrete implementations are known. In contrast, we provide details on the practical implementations of our algorithms (Proposition 4.4 and Appendix $\\mathrm{H}$ ), we are the first to highlight the role of stepsize invariance, which only makes sense for EFGs (and not for the adversarial loss setup as in [1]), and in our EFG applications we can obtain faster ${\\cal O}(1/T)$ convergence rate (e.g. for Smooth ${\\mathsf{P T B}}^{+}$ , see our new results as in Proposition 4.5 and Theorem 4.7), which is impossible against adversarial losses. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "D Proof of Proposition 4.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof. The proof of Proposition 4.1 is based on the following lemma. ", "page_idx": 14}, {"type": "text", "text": "Lemma D.1. Let $\\mathcal{C}\\subset\\mathbb{R}^{n}$ be a convex cone and let $\\pmb{u}\\in\\mathbb{R}^{n},\\eta>0$ . Then $\\Pi_{\\mathcal{C}}(\\eta\\pmb{u})=\\eta\\Pi_{\\mathcal{C}}(\\pmb{u}).$ . ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma D.1. We have, by definition, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Pi_{\\mathcal{C}}(\\eta\\pmb{u})=\\arg\\operatorname*{min}_{\\pmb{R}\\in\\mathcal{C}}\\|\\pmb{R}-\\eta\\pmb{u}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now we also have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\boldsymbol R\\in\\mathcal C}\\|\\boldsymbol R-\\eta\\boldsymbol u\\|_{2}=\\eta\\cdot\\operatorname*{min}_{\\boldsymbol R\\in\\mathcal C}\\|\\frac{1}{\\eta}\\boldsymbol R-\\boldsymbol u\\|_{2}=\\eta\\cdot\\operatorname*{min}_{\\boldsymbol R\\in\\mathcal C}\\|\\boldsymbol R-\\boldsymbol u\\|_{2}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the last equality follows from $\\mathcal{C}$ being a cone. This shows that $\\arg\\operatorname*{min}_{\\pmb{R}\\in\\mathcal{C}}\\|\\pmb{R}-\\eta\\pmb{u}\\|_{2}$ is attained at $\\eta\\Pi_{\\mathcal{C}}(u)$ , i.e., that $\\Pi_{\\mathcal{C}}(\\eta\\pmb{u})=\\eta\\Pi_{\\mathcal{C}}(\\pmb{u})$ . ", "page_idx": 14}, {"type": "text", "text": "We are now ready to prove Proposition 4.1. For the sake of conciseness we prove this with $_{m_{1}}=$ . $\\dots=m_{T}={\\bf0}$ ; the proof for $\\mathsf{P T B}^{+}$ with predictions is identical. In this case, $R_{t}=\\hat{R}_{t},\\forall\\;t\\geq1$ Consider the sequence of strategies $\\tilde{x}_{1},...,\\tilde{x}_{T}$ and $\\tilde{R}_{1},...,\\tilde{R}_{T}$ generated by ${\\mathsf{P T B}}^{+}$ with a step size of 1. We also consider the sequence of strategies $\\pmb{x}_{1},...,\\pmb{x}_{T}$ and $R_{1},...,R_{T}$ generated with a step size $\\eta>0$ . We claim that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{\\it{x}}}_{t}=\\mathbf{\\it{x}}_{t},R_{t}=\\eta\\tilde{\\mathbf{R}}_{t},\\;\\forall\\;t\\in\\{1,...,T\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We prove this by induction. Both sequences of iterates are initialized with $R_{1}=\\tilde{R}_{1}=\\mathbf{0}$ so that $\\tilde{\\mathbf{x}}_{1}=\\mathbf{x}_{1}$ . Therefore, both sequences face the same loss $\\ell_{1}$ at $t=1$ , and we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{R_{2}=\\Pi_{\\mathcal{C}}(-\\eta f(\\pmb{x}_{1},\\ell_{1}))=\\eta\\pi_{\\mathcal{C}}(-\\pmb{f}(\\pmb{x}_{1},\\ell_{1})))=\\eta\\tilde{R}_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let us now consider an iteration $t\\geq1$ and suppose that $\\tilde{\\pmb{x}}_{t}=\\pmb{x}_{t},\\pmb{R}_{t}=\\eta\\tilde{\\pmb{R}}_{t}$ . Since $\\tilde{\\pmb{x}}_{t}=\\pmb{x}_{t}$ then both algorithms will face the next loss vector $\\ell_{t}$ . Then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{R_{t+1}=\\pi_{C}(R_{t}-\\eta f(x_{t},\\ell_{t}))}&{}\\\\ {=\\pi_{C}(\\eta\\tilde{R}_{t}-\\eta f(x_{t},\\ell_{t}))}&{}\\\\ {=\\eta\\pi_{C}(\\tilde{R}_{t}-f(x_{t},\\ell_{t}))}&{}\\\\ {=\\eta\\tilde{R}_{t+1}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which in turns implies that $\\pmb{x}_{t+1}=\\tilde{\\pmb{x}}_{t+1}$ . We conclude that ${\\pmb x}_{t}=\\tilde{{\\pmb x}}_{t},\\forall\\,t=1,...,T$ . ", "page_idx": 14}, {"type": "text", "text": "E Comparison Between $\\mathsf{R M}^{+}$ and PTB+ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For the sake of discussion, we assume that the original decision set of each player is a simplex $\\Delta^{d}$ and that there are no predictions: $m_{t}=\\mathbf{0},\\forall\\,t\\geq1$ . ", "page_idx": 14}, {"type": "text", "text": "${\\mathsf{P T B}}^{+}$ over the simplex. For $\\mathsf{P T B}^{+}$ , the empty sequence variable $x_{\\mathcal{O}}$ is introduced and appended to the decision $\\Delta^{d}$ . The resulting treepplex can be written $\\mathcal{T}\\,=\\,\\{1\\}\\times\\Delta^{d}$ , the set $\\mathcal{C}$ becomes $\\mathcal{C}:=\\mathsf{c o n e}(\\mathcal{T})=\\mathsf{c o n e}(\\{1\\}\\times\\Delta^{d})$ and $\\pmb{a}=(1,\\mathbf{0})\\in\\mathbb{R}_{+}^{d+1}$ with 1 on the first component related to $x_{\\mathcal{O}}$ and 0 everywhere else. In this case, ${\\mathsf{P T B}}^{+}$ without prediction is exactly the Conic Blackwell Algorithm+ $({\\mathsf{C B A}}^{+}$ , [22]). Crucially, to run ${\\mathsf{P T B}}^{+}$ we need to compute the orthogonal projection onto ${\\mathsf{c o n e}}(T)={\\mathsf{c o n e}}(\\{1\\}\\times\\Delta)$ at every iteration, which can not be computed in closed-form, but it can be computed in $O(n\\log(n))$ arithmetic operations (see Appendix G.1 in [22]). ", "page_idx": 14}, {"type": "text", "text": "Regret Matching+. $\\mathsf{R M}^{+}$ operates directly over the simplex $\\Delta^{d}$ without the introduction of the empty sequence $x_{\\mathcal{O}}$ , in contrast to ${\\mathsf{P T B}}^{+}$ which operates over $\\{1\\}\\times\\Delta^{d}$ . Importantly, in $\\mathsf{R M}^{+}$ , at every iteration the orthogonal projection onto $\\mathbb{R}_{+}^{d}$ can be computed in closed form by simply thresholding to zero the negative components (and leaving unchanged the positive components): $\\Pi_{\\mathbb{R}_{+}^{d}}\\left(z\\right)=\\bar{\\left(\\operatorname*{max}\\{z_{i},0\\}\\right)_{i\\in[d]}}$ for any $\\bar{z}\\in\\mathbb R^{d}$ . ", "page_idx": 15}, {"type": "text", "text": "Empirical comparisons over simplexes. The numerical experiments in [22] show that ${\\mathsf{C B A}}^{+}$ may be slightly faster than $\\mathsf{R M}^{+}$ for some matrix games in terms of speed of convergence as a function of the number of iterations, but it can be slower in running times because of the orthogonal projections onto cone $(\\{1\\}\\times\\Delta)$ at each iteration (Figures 2,3,4 in [22]). When $\\tau$ is a treeplex that is not the simplex, introducing $x_{\\mathcal{O}}$ also changes the resulting algorithm but not the complexity of the orthogonal projection onto cone $(\\tau)$ , since there is no closed-form anymore, even without $x_{\\mathcal{O}}$ . As a convention, in this paper, we will always use $x_{\\mathcal{O}}$ in our description of treeplexes and of our algorithms since it is convenient from a writing and implementation standpoint. ", "page_idx": 15}, {"type": "text", "text": "Overall, we notice that in the case of the simplex introducing the empty sequence variable $x_{\\mathcal{O}}$ radically alters the complexity per iterations and the resulting algorithm, a fact that has not been noticed in previous work. ", "page_idx": 15}, {"type": "text", "text": "Empirical comparisons for EFGs. For solving EFGs, [22] combine the CFR decomposition with ${\\mathsf{C B A}}^{+}$ and compare the resulting algorithm with ${\\mathsf{C F R}}^{+}$ (i.e., combining the CFR decomposition with RM+). The authors in [22] observe similar numerical results as for the cases of simplexes: the resulting algorithm may slightly outperform ${\\mathsf{C F R}}^{+}$ in terms of duality gap achieved after a certain number of iterations, but it is outperformed by ${\\mathsf{C F R}}^{+}$ in terms of duality gap achieved after a certain computation time, because of the orthogonal projection required at every iteration at every simplex present in the treeplexes of each player. ", "page_idx": 15}, {"type": "text", "text": "F Proof of Proposition 4.5 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of Proposition 4.5. 1. Let $\\hat{R}_{2}\\,=\\,R_{2}/\\lVert R_{2}\\rVert_{2}$ be the unit vector pointing in the same direction as $R_{2}$ and let $\\pmb{h}\\;:=\\;\\left(\\langle\\pmb{R}_{1},\\hat{\\pmb{R}_{2}}\\rangle\\right)\\hat{\\pmb{R}_{2}}$ the orthogonal projection of $R_{1}$ onto $\\{\\alpha\\hat{R}_{2}\\mid\\alpha\\in\\mathbb{R}\\}$ . We thus have $\\|R_{1}-R_{2}\\|_{2}\\geq\\|R_{1}-h\\|_{2}$ . ", "page_idx": 15}, {"type": "text", "text": "2. Let $\\begin{array}{r}{p=\\frac{\\langle R_{1},a\\rangle}{\\langle R_{2},a\\rangle}\\hat{R}_{2}}\\end{array}$ \u27e8\u27e8RR1,,aa\u27e9\u27e9R\u02c62. Since p and R2 are colinear, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\frac{R_{1}}{\\left\\langle R_{1},a\\right\\rangle}-\\frac{R_{2}}{\\left\\langle R_{2},a\\right\\rangle}\\right\\|_{2}=\\left\\|\\frac{R_{1}}{\\left\\langle R_{1},a\\right\\rangle}-\\frac{p}{\\left\\langle p,a\\right\\rangle}\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Additionally, by construction, $\\langle p,a\\rangle=\\langle R_{1},a\\rangle$ , so that we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{R_{2}}{\\langle R_{2},a\\rangle}\\right\\|_{2}=\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{p}{\\langle R_{1},a\\rangle}\\right\\|_{2}=\\frac{1}{\\langle R_{1},a\\rangle}\\|R_{1}-p\\|_{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Note that $\\langle R_{1},a\\rangle\\geq0$ since $R_{1}\\in\\mathsf{c o n e}(\\mathcal{T})$ and $\\mathcal{T}\\subset\\{\\pmb{x}\\in\\mathbb{R}^{n+1}\\mid\\langle\\pmb{x},\\pmb{a}\\rangle=1\\}$ . Assume that we can compute $D>0$ such that ${\\frac{\\|R_{1}-p\\|_{2}}{\\|R_{1}-h\\|_{2}}}\\leq D$ . Then we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{R_{2}}{\\langle R_{2},a\\rangle}\\right\\|_{2}\\leq\\frac{D}{\\langle R_{1},a\\rangle}\\|R_{1}-h\\|_{2}\\leq\\frac{D}{\\langle R_{1},a\\rangle}\\|R_{1}-R_{2}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "3. The rest of this proof focuses on showing that $\\begin{array}{r}{\\frac{\\|R_{1}-p\\|_{2}}{\\|R_{1}-h\\|_{2}}\\leq\\Omega}\\end{array}$ with $\\Omega=\\operatorname*{max}\\{||\\pmb{x}||_{2}|\\ \\pmb{x}\\in T\\}$ Note that $\\langle R_{1}-p,a\\rangle=0$ . Therefore, $\\frac{1}{\\|\\pmb{R}_{1}-\\pmb{p}\\|_{2}}\\left(\\pmb{R}_{1}-\\pmb{p}\\right)$ and $\\frac{1}{\\|\\pmb{a}\\|_{2}}\\pmb{a}$ can be completed to form an orthonormal basis of . In this basis, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\hat{{\\cal R}}_{2}\\|_{2}^{2}\\geq\\frac{\\Big(\\langle{\\cal R}_{1}-p,\\hat{{\\cal R}}_{2}\\rangle\\Big)^{2}}{\\|{\\cal R}_{1}-p\\|_{2}^{2}}+\\frac{\\Big(\\langle{\\pmb a},\\hat{{\\cal R}}_{2}\\rangle\\Big)^{2}}{\\|{\\pmb a}\\|_{2}^{2}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Note that by construction we have $\\|\\hat{R_{2}}\\|_{2}^{2}\\,=\\,1$ . Additionally, $R_{\\mathrm{2}}\\,\\in\\,\\mathsf{c o n e}(\\mathcal{T})$ so that there exists $\\alpha\\,>\\,0$ and $\\pmb{y}\\in\\mathcal{T}$ such that $R_{2}\\,=\\,\\alpha x$ . By construction of $\\hat{R}_{2}$ , we have $\\begin{array}{r}{\\hat{R}_{2}=\\frac{\\alpha\\pmb{x}}{\\|\\alpha\\pmb{x}\\|_{2}}=\\frac{\\pmb{x}}{\\|\\pmb{x}\\|_{2}}}\\end{array}$ and $\\langle\\pmb{x},\\pmb{a}\\rangle=1$ . This shows that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\left(\\langle a,\\hat{\\mathbf{R}_{2}}\\rangle\\right)^{2}}{\\|a\\|_{2}^{2}}=\\frac{\\left(\\langle a,x\\rangle\\right)^{2}}{\\|a\\|_{2}^{2}\\|x\\|_{2}^{2}}=\\frac{1}{\\|a\\|_{2}^{2}\\|x\\|_{2}^{2}}\\geq\\frac{1}{\\Omega\\|a\\|_{2}^{2}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with $\\Omega=\\operatorname*{max}\\{||\\pmb{x}||_{2}|\\ \\pmb{x}\\in\\mathcal{T}\\}$ . Recall that we have chosen $\\pmb{a}=(1,\\mathbf{0})$ so that $\\|\\pmb{a}\\|_{2}=1$ . Overall, we have obtained ", "page_idx": 16}, {"type": "equation", "text": "$$\n1-\\frac{1}{\\Omega^{2}}\\geq\\frac{\\Big(\\langle{\\pmb R}_{1}-{\\pmb p},\\hat{{\\pmb R}_{2}}\\rangle\\Big)^{2}}{\\|{\\pmb R}_{1}-{\\pmb p}\\|_{2}^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From the definition of the vectors $\\mathbf{\\delta}_{p,\\,h}$ and $\\hat{R}_{2}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\Big(\\langle R_{1}-p,\\hat{R_{2}}\\rangle\\Big)^{2}}{\\|R_{1}-p\\|_{2}^{2}}=\\frac{\\|p-h\\|_{2}^{2}}{\\|R_{1}-p\\|_{2}^{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|p-h\\|_{2}^{2}\\leq\\left(1-\\frac{1}{\\Omega^{2}}\\right)\\|R_{1}-p\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This shows that $\\begin{array}{r}{\\|{\\cal R}_{1}-h\\|_{2}^{2}\\geq\\frac{1}{\\Omega^{2}}\\|x-p\\|_{2}^{2}}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "4. We conclude that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left\\|\\frac{R_{1}}{\\langle R_{1},a\\rangle}-\\frac{R_{2}}{\\langle R_{2},a\\rangle}\\right\\|_{2}\\leq\\frac{\\Omega}{\\operatorname*{max}\\{\\langle R_{1},a\\rangle,\\langle R_{2},a\\rangle\\}}\\|R_{1}-R_{2}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "G Proof of Proposition 4.4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section we show how to efficiently compute the orthogonal projection onto the cone ${\\mathcal{C}}:=$ cone $(\\tau)$ . We start by reviewing the existing methods for computing the orthogonal projection onto the treeplex $\\tau$ . This is an important cornerstone of our analysis, since the treeplex $\\tau$ and the cone $\\mathcal{C}$ share an analogous structure: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{T}=\\{\\pmb{x}\\in\\mathbb{R}_{+}^{n+1}\\mid x_{\\mathcal{O}}=1,\\displaystyle\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\;j\\in\\mathcal{I}\\}}\\\\ &{\\mathcal{C}=\\{\\pmb{x}\\in\\mathbb{R}_{+}^{n+1}\\mid\\displaystyle\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\;j\\in\\mathcal{I}\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "[20] were the first to show an algorithm for computing Euclidean projection onto the treeplex. They do this by defining a value function for the projection of a given point $\\textit{\\textbf{y}}$ onto the closed and convex scaled set $t\\mathcal{Z}$ , letting it be half the squared distance between $\\textit{\\textbf{y}}$ and $t\\mathcal{Z}$ , for $t\\in\\mathbb{R}_{>0}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nv_{\\mathcal{Z}}(t,\\pmb{y}):=\\frac{1}{2}\\operatorname*{min}_{z\\in t\\mathcal{Z}}\\|z-\\pmb{y}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "[20] show how to recursively compute $\\lambda_{\\mathcal{Z}}(t,y)$ , the derivative of this function with respect to $t$ , for a given treeplex, since treeplexes can be constructed recursively using two operations: branching and Cartesian product. In the first case, given $k$ treeplexes $\\mathcal{Z}_{1},\\ldots,\\mathcal{Z}_{k}$ , then $\\bar{\\mathcal{Z}}=\\mathsf{\\bar{\\Phi}}\\{x,x[1]z_{1},\\ldots,x[\\bar{k}]z_{k}:$ $x\\in\\Delta_{k},z_{i}\\in\\mathcal{Z}_{i}\\forall i\\in[k]\\}$ is also a treeplex. In the second case, given $k$ treeplexes $\\mathcal{Z}_{1},\\ldots,\\mathcal{Z}_{k}$ , then $\\mathcal{Z}=\\mathcal{Z}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{Z}_{k}$ is also a treeplex. In fact, letting the empty set be a treeplex as a base case, all treeplexes can be constructed in this way. ", "page_idx": 16}, {"type": "text", "text": "However, [20] did not state the total complexity of computing the projection, instead only stating the complexity of computing $\\lambda_{\\mathcal{Z}}(t,y)$ given the corresponding $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i})$ functions for the treeplexes $\\mathcal{Z}_{i}$ that are used to construct $\\mathcal{Z}$ using $i\\in[k]$ . They state that this complexity is $O(n\\log n)$ , where $n$ is the number of sequences in $\\mathcal{Z}$ . Their analysis involves showing that the function $t\\mapsto\\lambda_{\\mathcal{Z}}(t,\\pmb{y})$ is piecewise linear. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "[17] also consider this problem, generalizing the problem to weighted projection on the scaled treeplex, by adding an additional positive parameter $\\pmb{w}\\in\\mathbb{R}_{>0}^{n}$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\nv_{\\mathcal{Z}}(t,\\pmb{y},\\pmb{w}):=\\frac{1}{2}\\operatorname*{min}_{z\\in t\\mathcal{Z}}\\sum_{i=1}^{n}\\left(z[i]-\\frac{\\pmb{y}[i]}{\\pmb{w}[i]}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "They do a similar analysis to [20], by showing how to compute the derivative $\\lambda_{\\mathcal{Z}}(t,y,w)$ of $v_{\\mathcal{Z}}(\\dot{t},y,w)$ with respect to $t$ recursively. They show that $t\\mapsto\\lambda_{\\mathcal{Z}}(t,\\pmb{y},\\pmb{w})$ are strictly-monotonicallyincreasing piecewise-linear (SMPL) functions. We will follow the analysis in [17], letting ${\\pmb w}={\\bf1}$ . ", "page_idx": 17}, {"type": "text", "text": "We first define a standard representation of a SMPL function. ", "page_idx": 17}, {"type": "text", "text": "Definition G.1 ([17]). Given a SMPL function $f$ , a standard representation is an expression of the form ", "page_idx": 17}, {"type": "equation", "text": "$$\nf(x)=\\zeta+\\alpha_{0}x+\\sum_{s=1}^{S}\\alpha_{s}\\operatorname*{max}\\{0,x-\\beta_{s}\\}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "valid for all $x\\in\\operatorname{dom}(f),$ , $S\\in\\mathbb{N}\\cup\\{0\\}$ , and $\\beta_{1}<\\dots<\\beta_{S}$ . The size of the standard representation is defined to be $S$ . ", "page_idx": 17}, {"type": "text", "text": "Next, we prove the following lemma, showing the computational complexity of computing the derivative of the value function for a given treeplex. ", "page_idx": 17}, {"type": "text", "text": "Lemma G.2. For a given treeplex $\\mathcal{Z}$ with depth $d_{:}$ , n sequences, $l$ leaf sequences, and m infosets, and $\\pmb{y}\\in\\mathbb{R}^{n},\\pmb{w}\\in\\mathbb{R}_{>0}^{n}$ , a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ can be computed in $O{\\bigl(}d n\\log(l+m){\\bigr)}$ time. ", "page_idx": 17}, {"type": "text", "text": "Proof. We will proceed by structural induction over treeplexes, following the analysis done by [17].   \nThe base case is trivially true, because the empty set has no sequences or depth. ", "page_idx": 17}, {"type": "text", "text": "For the inductive case, we will assume that it requires $O\\big((d-1)n\\log(l+m)\\big)$ time to compute the respective Euclidean projections onto the subtreeplexes that we use to inductively construct our current treeplex, where $d-1$ is the depth of a given subtreeplex, $n$ is the number of sequences in the subtreeplex, and $m$ is the total number of sequences among both players and chance corresponding to the game from which the treeplex originates. ", "page_idx": 17}, {"type": "text", "text": "We will use two results shown in Lemma 14 of [17]: ", "page_idx": 17}, {"type": "text", "text": "Lemma G.3 (Recursive complexity of Euclidean projection for branching operation [17]). Consider a treeplex $\\mathcal{Z}$ that can be written as the result of a branching operation on $k$ treeplexes $\\mathcal{Z}_{1},\\ldots,\\mathcal{Z}_{k}$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\mathcal{Z}}=\\{x,x[1]z_{1},\\ldots,x[k]z_{k}:x\\in\\Delta_{k},z_{i}\\in{\\mathcal{Z}}_{i}\\forall i\\in[k]\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $\\mathcal{Z}$ have $n$ sequences and let $\\pmb{y},\\pmb{w}\\in\\mathbb{R}^{n}$ , and let $\\pmb{y}[i]$ and $w[i]$ denote the corresponding respective components of $\\textit{\\textbf{y}}$ and $\\mathbf{\\nabla}w$ for the treeplex $\\mathcal{Z}_{i}$ . ", "page_idx": 17}, {"type": "text", "text": "Then, given standard representations of $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ of size $n_{i}$ for all $i\\,\\in\\,[k]$ , where $n_{i}$ is the number of sequences that $\\mathcal{Z}_{i}$ has, a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ of size $n$ can be computed in $O(n\\log k)$ time. ", "page_idx": 17}, {"type": "text", "text": "Furthermore, given a value of $t$ , the argument $\\textbf{\\em x}$ which leads to the realization of the optimal value of the value function, can be computed in time $O(n)$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma G.4 (Recursive complexity of Euclidean projection for Cartesian product [17]). Consider a treeplex $\\mathcal{Z}$ that can be written as a Cartesian product of $k$ treeplexes $\\mathcal{Z}_{1},\\ldots,\\mathcal{Z}_{k}$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{Z}=\\mathcal{Z}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{Z}_{k}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $\\mathcal{Z}$ have n sequences and let $\\pmb{y},\\pmb{w}\\in\\mathbb{R}^{n}$ , and let $\\pmb{y}[i]$ and $w[i]$ denote the corresponding respective components of $\\textit{\\textbf{y}}$ and $\\mathbf{\\nabla}w$ for the treeplex $\\mathcal{Z}_{i}$ . ", "page_idx": 17}, {"type": "text", "text": "Then, given standard representations of $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ of size $n_{i}$ for all $i\\,\\in\\,[k]$ , where $n_{i}$ is the number of sequences that $\\mathcal{Z}_{i}$ has, a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ of size $n$ can be computed in $O(n\\log k)$ time. ", "page_idx": 17}, {"type": "text", "text": "First, we consider the case that the last operation used to construct our treeplex was the branching operation. Let the root of of the treeplex be called $j$ . Define $\\mathcal{Z}_{i}$ as the treeplex that is underneath action $a_{i}\\in A_{j}$ . Let $n_{i}$ denote the number of sequences in $\\mathcal{Z}_{i}$ , $m_{i}$ denote the number of infosets in $\\mathcal{Z}_{i}$ , $l_{i}$ denote the number of leaf sequences in $\\mathcal{Z}_{i}$ , and $d-1$ be the maximum depth of any of these subtreeplexes. ", "page_idx": 18}, {"type": "text", "text": "Given a standard representation of $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ of size $n_{i}$ for all $i\\in[|A_{j}|]$ , by Lemma G.3, it takes $O(n\\log|A_{j}|)$ time to compute a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ of size $n$ . By induction, it takes $O\\big((d-1)n_{i}\\log m_{i}\\big)$ to compute $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ for treeplex $\\mathcal{Z}_{i}$ . Thus the total computation required to compute $\\lambda_{\\mathcal{Z}}(t,y,w)$ is ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{2(n\\log|A_{j}|)+\\sum_{i\\in[|A_{j}|]}O\\big((d-1)n_{i}\\log(l_{i}+m_{i})\\big)=O(n\\log|A_{j}|)+\\sum_{i\\in[|A_{j}|]}O\\big((d-1)n_{i}\\log(l+m_{i})\\big)}}\\\\ &{}&{=O(n\\log|A_{j}|)+O\\big((d-1)\\sum_{i\\in[|A_{j}|]}n_{i}\\log(l+m_{i})\\big)}\\\\ &{}&{=O(n\\log|A_{j}|)+O\\big((d-1)n\\log(l+m)\\big)}\\\\ &{}&{=O\\big(n\\log(l+m)\\big)+O\\big((d-1)n\\log(l+m)\\big)}\\\\ &{}&{=O\\big(d n\\log(l+m)\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "since we have necessarily that $l_{i}~\\leq~l$ and $m_{i}~\\leq~m$ for all $i\\;\\in\\;[|A_{j}|],\\;\\sum_{i\\in[|A_{j}|]}n_{i}\\;\\leq\\;n$ , and $|A_{j}|\\leq l+m$ . ", "page_idx": 18}, {"type": "text", "text": "Second, we consider the case the last operation to construct our treeplex was a Cartesian product. Let $\\mathcal{Z}=\\mathcal{Z}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{Z}_{k}$ , and again define $n_{i}$ as the number of sequences in $\\mathcal{Z}_{i}$ , $m_{i}$ as the number of infosets in $\\mathcal{Z}_{i}$ , $l_{i}$ as the number of leaf sequences in $\\mathcal{Z}_{i}$ , and $d-1$ as the maximum depth of any of these subtreeplexes. ", "page_idx": 18}, {"type": "text", "text": "Given a standard representation of $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ of size $n_{i}$ for all $i\\in[k]$ , by Lemma G.4 it takes $O(n\\log k)$ to compute a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ of size $n$ . By induction, it takes $O\\left((d-1)n_{i}\\log(l_{i}+m_{i})\\right)$ to compute $\\lambda_{\\mathcal{Z}_{i}}(t,y_{i},w_{i})$ for treeplex $\\mathcal{Z}_{i}$ . Thus the total computation required to compute $\\lambda_{\\mathcal{Z}}(t,y,w)$ is ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{O(n\\log k)+\\sum_{i\\in[k]}O\\big((d-1)n_{i}\\log(l_{i}+m_{i})\\big)=O(n\\log k)+\\sum_{i\\in[k]}O\\big((d-1)n_{i}\\log(l+m)\\big)}}\\\\ &{}&{=O(n\\log k)+O\\big((d-1)\\sum_{i\\in[k]}n_{i}\\log(l+m)\\big)}\\\\ &{}&{=O(n\\log k)+O\\big((d-1)n\\log(l+m)\\big)}\\\\ &{}&{=O(n\\log m)+O\\big((d-1)n\\log(l+m)\\big)}\\\\ &{}&{=O(d n\\log(l+m))}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "since we have necessarily that $l_{i}\\leq l$ and $m_{i}\\leq m$ for all $i\\in[k]$ , and $k\\leq m$ . ", "page_idx": 18}, {"type": "text", "text": "Finally, we are ready to prove the main statement. ", "page_idx": 18}, {"type": "text", "text": "Proof of Proposition 4.4. By Lemma G.2, we know that we can recursively compute a standard representation of $\\lambda_{\\mathcal{Z}}(t,y,w)$ in ${\\cal O}\\big(d n\\log(l\\!+\\!m)\\big)$ time. Assuming we use this construction, invoking Lemma G.3, given an optimal value of $t$ , we can compute the partial argument corresponding to the values of the sequences that originate at the root infosets, which allow the optimal value to be realized for the value function. Then, we can use optimal arguments for these sequences recursively at the subtreeplexes to continue computing the optimal argument at sequences lower on the treeplex. We can do this because in the process of computing the derivative of the value function of the entire treeplex, we have also computed the derivative of the value function for each of the subtreeplexes. Thus, once we have computed an optimval value of $t$ for the value function at the top level, we can do a top-down pass to compute the optimal values for all sequences that occur at any level in the treeplex. This is detailed in the analysis done in the proof of Lemma 14 in [17]. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "In order to pick the optimal value of $t$ for the value function, since $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ is strictly increasing, we only have to consider two cases: ${\\lambda}_{\\mathcal{Z}}(0,y,w)<0$ and $\\lambda_{\\mathcal{Z}}(0,{\\pmb y},{\\pmb w})\\ge0$ . In the first case, the value function $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ will be minimized when $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ is equal to 0, and this can be directly computed using the standard representation (it will be necessarily 0 somewhere because it is strictly monotone). In the second case, since $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ is strictly monotone and $\\lambda_{\\mathcal{Z}}(0,y,w)\\ge0$ , we must have that $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)\\ge0$ , which means that $v_{\\mathcal{Z}}(\\cdot,y,w)$ is minimized at $t^{*}=0$ . \u53e3 ", "page_idx": 19}, {"type": "text", "text": "H Practical Implementation of Smooth PTB+ ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We have the following lemma, which shows that the stable region $\\ensuremath{\\mathcal{C}}_{\\geq}$ admits a relatively simple formulation. ", "page_idx": 19}, {"type": "text", "text": "Lemma H.1. The stable region ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal C_{\\geq}:=\\mathsf{c o n e}({\\mathcal T})\\cap\\{R\\in\\mathbb R^{n+1}\\mid\\langle R,a\\rangle\\geq R_{0}\\}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "can be reformulated as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\mathcal C}_{\\geq}=\\{\\alpha{\\pmb x}\\mid\\alpha\\geq R_{0},{\\pmb x}\\in{\\mathcal T}\\}}\\\\ {\\quad=\\{{\\pmb x}\\in{\\mathbb R}_{+}^{n+1}\\mid x_{\\mathcal{O}}\\geq R_{0},\\displaystyle\\sum_{a\\in{\\mathcal A}_{j}}x_{j a}=x_{p_{j}},\\forall\\,j\\in{\\mathcal T}\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. By definition, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal C_{\\geq}=\\{R\\in\\mathsf{c o n e}({\\mathcal T})\\mid\\langle R,a\\rangle\\geq R_{0}\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that for $R\\in{\\mathsf{c o n e}}({\\mathcal{T}}),R=\\alpha\\pmb{x}$ with $\\alpha\\geq0$ and $\\langle\\pmb{x},\\pmb{a}\\rangle=1$ . Therefore, for $\\scriptstyle R\\;\\in\\;{\\mathcal{C}}$ we have $\\langle R,a\\rangle\\geq R_{0}\\iff\\alpha\\geq R_{0}$ . This shows that we can write ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\geq}=\\{\\alpha{\\pmb x}\\mid\\alpha\\geq R_{0},{\\pmb x}\\in\\mathcal{T}\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now let $\\pmb{x}\\in\\mathcal{C}_{\\ge}$ , i.e., let ${\\pmb x}=\\alpha\\hat{\\pmb x}$ with $\\alpha\\geq R_{0}$ and $\\pmb{x}\\in\\mathcal{T}$ . Since ${\\hat{\\mathbf{x}}}\\in{\\mathcal{T}}$ , we have $x_{\\partial}=1$ , so that $\\hat{x}_{\\varnothing}=\\alpha\\geq R_{0}$ . Additionally, we have $\\begin{array}{r}{\\hat{\\pmb{x}}\\geq0,\\sum_{a\\in\\mathcal{A}_{j}}\\hat{x}_{j a}=\\hat{x}_{p_{j}},\\forall~j\\in\\mathcal{T}.}\\end{array}$ . Multiplying by $\\alpha\\geq R_{0}$ , we obtain that $\\pmb{x}\\ge0$ and $\\begin{array}{r}{\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\;j\\in\\mathcal{J}}\\end{array}$ . Overall we have shown ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal C_{\\geq}\\subseteq\\{x\\in\\mathbb R^{n+1}\\;|x_{\\mathcal{Q}}\\geq R_{0},\\sum_{a\\in\\mathcal A_{j}}x_{j a}=x_{p_{j}},\\forall\\:j\\in\\mathcal T,x\\geq0\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We now consider $\\begin{array}{r}{\\pmb{x}\\in\\{\\pmb{x}\\in\\mathbb{R}^{n+1}\\,\\left|x_{\\mathcal{Q}}\\geq R_{0},\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall~j\\in\\mathcal{I},\\pmb{x}\\geq\\mathbf{0}\\right\\}}\\end{array}$ with $\\mathbf{\\Delta}x\\neq\\mathbf{0}$ Then $\\pmb{x}=\\alpha\\frac{\\pmb{x}}{\\alpha}$ with $\\alpha=x_{\\mathcal{S}}$ , so that $\\alpha\\geq R_{0}$ and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{a\\in{\\cal A}_{j}}x_{j a}=x_{p_{j}},\\forall\\;j\\in{\\mathcal{I}}\\iff\\sum_{a\\in{\\cal A}_{j}}{\\frac{x_{j a}}{\\alpha}}={\\frac{x_{p_{j}}}{\\alpha}},\\forall\\;j\\in{\\mathcal{I}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\{\\boldsymbol{x}\\in\\mathbb{R}^{n+1}\\;|x_{\\mathcal{Q}}\\geq R_{0},\\sum_{a\\in\\mathcal{A}_{j}}x_{j a}=x_{p_{j}},\\forall\\;j\\in\\mathcal{J},\\boldsymbol{x}\\geq\\boldsymbol{0}\\}\\subseteq\\mathcal{C}_{\\geq}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This shows that we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal C_{\\geq}=\\{{\\pmb x}\\in\\mathbb R^{n+1}\\,|x_{\\mathcal{Q}}\\geq R_{0},\\sum_{a\\in\\mathcal A_{j}}x_{j a}=x_{p_{j}},\\forall\\,j\\in\\mathcal T,{\\pmb x}\\geq{\\bf0}\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proposition H.2. For a treeplex $\\tau$ with depth $d$ , number of sequences $n$ , number of leaf sequences $l$ , and number of infosets $m$ , the complexity of computing the orthogonal projection of a point $y\\in\\mathbb{R}^{n+1}$ onto $\\mathcal{C}_{\\geq}=\\left\\{\\alpha{\\pmb x}\\mid\\alpha\\geq R_{0},{\\pmb x}\\in\\mathcal{T}\\right\\}$ is ${\\dot{O}}({\\dot{d}}n\\log(l+{\\dot{m}}))$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. The proof is the same as that for Proposition 4.4, since the derivative of the value function can be computed in $O{\\bigl(}d n\\log(l+m){\\bigr)}$ time. However, this time, we have an additional constraint that $t\\geq R_{0}$ . Thus instead of checking the sign of $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ at $t=0$ , we check the sign at $R_{0}$ . ", "page_idx": 20}, {"type": "text", "text": "If $\\lambda_{\\mathcal{Z}}(R_{0},\\pmb{y},\\pmb{w})<0.$ , then because $\\lambda_{\\mathcal{Z}}(\\cdot,y,w)$ is a strictly monotone function, the function will be 0 for some value of $t$ , and this is exactly $t^{*}$ , which minimizes the value function with respect to $t$ , when $t\\geq R_{0}$ . On the other hand, if $\\lambda_{\\mathcal{Z}}(R_{0},y,w)\\ge0$ , then again because the function is strictly monotone in $t$ , we know that the value function must get minimized at $t^{*}=R_{0}$ . Using the same argument as in the proof of Proposition 4.4, since we have computed the standard representations of the derivatives of the value functions at all of the treeplexes, we can do a top-down pass to compute the argument which leads to the optimal value of the value function. ", "page_idx": 20}, {"type": "text", "text": "I Proof of Theorem 4.7 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 4.7. For the sake of conciseness we write $\\pmb{f}_{t}^{x}~=~\\pmb{f}(\\pmb{x}_{t},M\\pmb{y}_{t})$ and $\\begin{array}{r l}{f_{t}^{y}}&{{}=}\\end{array}$ $f(g_{t},-M^{\\top}x_{t})$ . ", "page_idx": 20}, {"type": "text", "text": "From our Proposition 4.2, we have that, for the first player, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle\\pmb{x}_{t}-\\hat{\\pmb{x}},M\\pmb{y}_{t}\\rangle=\\sum_{t=1}^{T}\\langle\\pmb{R}_{t}-\\hat{\\pmb{R}},\\pmb{f}_{t}^{x}\\rangle.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now $\\textstyle\\sum_{t=1}^{T}\\langle R_{t}-{\\hat{R}},f_{t}^{x}\\rangle$ is the regret obtained by running Predictive $0\\mathsf{M D}$ on $\\ensuremath{\\mathcal{C}}_{\\geq}$ against the sequence of loss $f_{1}^{x},...,f_{T}^{x}$ . From Proposition 5 in [16], we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle R_{t}^{x}-\\hat{R}^{x},f_{t}^{x}\\rangle\\leq\\frac{\\|\\hat{R}\\|_{2}^{2}}{2\\eta}+\\eta\\sum_{t=1}^{T}\\|f_{t}^{x}-f_{t-1}^{x}\\|_{2}^{2}-\\frac{1}{8\\eta}\\sum_{t=1}^{T}\\|R_{t+1}^{x}-R_{t+1}^{x}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\hat{R}_{t}\\in\\mathcal{C}_{\\ge}$ , we can use our Proposition 4.5 to show that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\pmb{x}_{t+1}-\\pmb{x}_{t}\\|_{2}^{2}\\leq\\frac{\\Omega}{R_{0}^{2}}\\|\\pmb{R}_{t+1}^{x}-\\pmb{R}_{t+1}^{x}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This shows that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle R_{t}^{x}-\\hat{R}^{x},f_{t}^{x}\\rangle\\leq\\frac{\\|\\hat{R}\\|_{2}^{2}}{2\\eta}+\\eta\\sum_{t=1}^{T}\\|f_{t}^{x}-f_{t-1}^{x}\\|_{2}^{2}-\\frac{R_{0}^{2}}{8\\Omega^{2}\\eta}\\sum_{t=1}^{T}\\|R_{t+1}^{x}-R_{t+1}^{x}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which gives, using the norm equivalence $\\|\\cdot\\|_{2}\\leq\\|\\cdot\\|_{1}\\leq{\\sqrt{n+1}}\\|\\cdot\\|_{2}$ , the following inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle\\pmb{R}_{t}^{x}-\\hat{\\pmb{R}}^{x},\\pmb{f}_{t}^{x}\\rangle\\leq\\frac{\\|\\hat{\\pmb{R}}\\|_{2}^{2}}{2\\eta}+\\eta\\sum_{t=1}^{T}\\|\\pmb{f}_{t}^{x}-\\pmb{f}_{t-1}^{x}\\|_{1}^{2}-\\frac{R_{0}^{2}}{8\\Omega^{2}(n+1)\\eta}\\sum_{t=1}^{T}\\|\\pmb{R}_{t+1}^{x}-\\pmb{R}_{t+1}^{x}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The above inequality is a RVU bound: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle R_{t}^{x}-\\hat{R}^{x},f_{t}^{x}\\rangle\\leq\\alpha+\\beta\\sum_{t=1}^{T}\\|f_{t}^{x}-f_{t-1}^{x}\\|_{1}^{2}-\\gamma\\sum_{t=1}^{T}\\|R_{t+1}^{x}-R_{t+1}^{x}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\alpha=\\frac{\\|\\hat{\\pmb{R}}\\|_{2}^{2}}{2\\eta},\\beta=\\eta,\\gamma=\\frac{R_{0}^{2}}{8\\Omega^{2}(n+1)\\eta}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To invoke Theorem 4 in [36], we also need the utilities of each player to be bounded by 1. This can be done can rescaling $\\pmb{f}_{t}^{x}=M y_{t}$ and $\\pmb{f}_{t}^{y}=-\\pmb{M}^{\\top}\\pmb{x}_{t}$ . In particular, we know that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\lVert M\\pmb{y}\\rVert_{\\infty}\\leq\\lVert M\\rVert_{\\ell_{2},\\ell_{\\infty}}\\lVert\\pmb{y}\\rVert_{2}\\leq\\lVert M\\rVert_{\\ell_{2},\\ell_{\\infty}}\\cdot\\hat{\\Omega}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with $\\begin{array}{r l r}{\\|M\\|_{\\ell_{2},\\ell_{\\infty}}}&{=}&{\\operatorname*{max}_{i\\in[n+1]}\\|\\left(A_{i j}\\right)_{j\\in[m+1]}\\|_{2}}\\end{array}$ and $\\hat{\\Omega}\\;\\;=\\;\\;\\mathrm{max}\\{\\mathrm{max}\\{\\|\\pmb{x}\\|_{2},\\|\\pmb{y}\\|_{2}\\}\\;\\;\\pmb{x}\\;\\;\\in$ $\\mathcal{X},\\pmb{\\mathscr{y}}\\in\\mathrm{~\\mathscr{y}\\}$ . This corresponds to multiplying $\\beta$ in (13) by $\\|M\\|\\,\\times\\,{\\hat{\\Omega}}$ with $\\begin{array}{r l}{\\|M\\|}&{{}:=}\\end{array}$ $\\operatorname*{max}\\{\\|M\\|_{\\ell_{2},\\ell_{\\infty}},\\|M^{\\top}\\|_{\\ell_{2},\\ell_{\\infty}}\\}$ . To apply Theorem 4 in [36] we also need $\\beta\\ \\leq\\ \\gamma$ . Since we need the same condition for the second player, we take ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\eta=R_{0}\\left(\\sqrt{8d\\hat{\\Omega}^{3}}\\|M\\|\\right)^{-1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Under this condition on the stepsize, we can invoke Theorem 4 in [36] to conclude that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle R_{t}^{x}-\\hat{R}^{x},f_{t}^{x}\\rangle+\\sum_{t=1}^{T}\\langle R_{t}^{y}-\\hat{R}^{y},f_{t}^{y}\\rangle\\leq\\frac{\\|\\hat{R}^{x}\\|_{2}^{2}+\\|\\hat{R}^{y}\\|_{2}^{2}}{\\eta}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since the duality gap is bounded by the average of the sum of the regrets of both players [19], and replacing $\\eta$ by its expression, we obtain that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{y\\in\\mathcal{Y}}\\,\\langle\\bar{x}_{T},M\\pmb{y}\\rangle-\\operatorname*{min}_{x\\in\\mathcal{X}}\\,\\langle\\pmb{x},M\\bar{y}_{T}\\rangle\\leq\\frac{2\\hat{\\Omega}^{2}}{\\eta}\\frac{1}{T}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "J AdaGradTB+ and AdamTB+ ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "AdaGradTB+. We introduce AdaGradTB+in Algorithm 6. Given matrix $\\pmb{A}$ and a vector $\\pmb{y}\\in\\mathbb{R}^{n+1}$ , let diag $\\mathbf{\\Pi}(\\pmb{y})$ be the diagonal matrix with $\\textit{\\textbf{y}}$ on its diagonal and $\\Pi_{\\mathcal{C}}^{A}(\\pmb{y})=\\arg\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{C}}\\langle\\pmb{x}-\\pmb{\\dot{y}},A(\\pmb{x}-\\pmb{y})\\rangle$ . We first show that AdaGradTB+ is a regret minimizer. ", "page_idx": 21}, {"type": "text", "text": "Proposition J.1. Let $\\pmb{x}_{1},...,\\pmb{x}_{T}$ be computed by AdaGradTB+. For $\\begin{array}{r}{\\eta=\\frac{\\operatorname*{max}_{t\\le T}(\\|R_{t}\\|_{2}+\\Omega)^{2}}{\\sqrt{2}}}\\end{array}$ , we have $\\begin{array}{r l}&{\\operatorname*{max}_{\\hat{x}\\in\\mathcal{T}}\\sum_{t=1}^{T}\\langle x_{t}-\\hat{x},\\ell_{t}\\rangle\\leq2\\eta\\sum_{i=1}^{d}\\sqrt{\\sum_{t=1}^{T}\\left(f_{t}(x_{t},\\ell_{t})\\right)_{i}^{2}}.}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "We omit the proof of Proposition J.1 for conciseness; it follows from the regret guarantees of AdaGrad (Theorem 5 in [12]) and Proposition 3.1. We conclude that combining AdaGradTB+ with the self-play framework ensures a $O(1/\\sqrt{T})$ convergence rate. ", "page_idx": 21}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/5de4ec8bd278625a9a246b49e93ceb2b1edcb1c371986b0ce78652e218d54d9f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "AdamTB+. We present AdamTB+, our instantiation of Algorithm 1 inspired from the adaptive algorithm Adam [25] in Algorithm 7. Since Adam is not necessarily a regret minimizer [35], there are no regret guarantees for AdamT $^{\\cdot}\\mathsf{B}^{+}$ . We choose to consider this algorithm for the sake of completeness, since Adam is widely used in other settings. ", "page_idx": 21}, {"type": "text", "text": "K Details on Numerical Experiments ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "K.1 Additional Algorithms ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Single-call Predictive Online Mirror Descent (SC-POMD). We present SC-POMD in Algorithm 8. This algorithm runs a variant of predictive online mirror descent with only one orthogonal projection ", "page_idx": 21}, {"type": "text", "text": "Algorithm 7 AdamTB+   \n1: Input: $\\eta,\\delta>0,\\beta_{1},\\beta_{2}\\in[0,1]$   \n2: Initialization: R1 = 0 Rn+1, $\\pmb{s}_{0}=\\mathbf{0}\\in\\mathbb{R}^{n+1},\\pmb{g}_{0}=\\mathbf{0}\\in\\mathbb{R}^{n+1}$   \n3: for $t=1,\\dots,T$ do   \n4: ${\\pmb x}_{t}=R_{t}/\\langle R_{t},{\\pmb a}\\rangle$   \n5: Observe the loss vector $\\ell_{t}\\in\\mathbb{R}^{n+1}$   \n6: $\\begin{array}{r l}&{s_{t}=\\beta_{2}s_{t-1}+(1-\\beta_{2})\\dot{\\pmb{f}}(\\pmb{x}_{t},\\ell_{t})\\odot\\pmb{f}(\\pmb{x}_{t},\\ell_{t})}\\\\ &{\\hat{s}_{t}=s_{t}/(1-\\beta_{2}^{t})}\\\\ &{\\pmb{g}_{t}=\\beta_{1}\\pmb{g}_{t-1}+(1-\\beta_{1})\\pmb{f}(\\pmb{x}_{t},\\ell_{t})}\\\\ &{\\hat{\\pmb{g}}_{t}=\\pmb{g}_{t}/(1-\\beta_{1}^{t})}\\\\ &{\\pmb{H}_{t}=\\mathsf{d i a g}\\left(\\sqrt{\\hat{s}_{t}}+\\epsilon\\mathbf{1}\\right)}\\\\ &{\\pmb{R}_{t+1}\\in\\Pi_{\\ell}^{\\pmb{H}_{t}}\\left(\\pmb{R}_{t}-\\eta\\pmb{H}_{t}^{-1}\\hat{\\pmb{g}}_{t}\\right)}\\end{array}$   \n7:   \n8:   \n9:   \n10:   \n11: ", "page_idx": 22}, {"type": "text", "text": "at every iteration [24]. The pseudocode from Algorithm 8 corresponds to choosing the squared $\\ell_{2}$ -norm as a distance generating function - in principle, other distance generating functions are possible, e.g. dilated entropy [15]. Combined with the self-play framework, SC-POMD ensures that the average of the visited iterates converges to a Nash equilibrium at a rate of ${\\cal O}(1/T)$ , similar to the variant of predictive online mirror descent with two orthogonal projections at every iteration [15]. ", "page_idx": 22}, {"type": "table", "img_path": "8aA3DHLK5h/tmp/8ecf13d56e2882d50c0fda6369d287832de373b29771d6b13e50f75e59cf1c1b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "K.2 Algorithm Implementation Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "All algorithms are initialized using the uniform strategy (placing equal probability on each action at each decision point). For algorithms that are not stepsize invariant (Smooth $\\mathsf{P T B}^{+}$ and SC-POMD), we try stepsizes in $\\eta\\in\\{0.05,\\bar{0}.1,0.5,1,2,5\\}$ and we present the performance with the best stepsize. For Smooth $\\mathsf{P T B}^{+}$ , we use $R_{0}=0.1$ . For both AdaGradTB+ and Adam ${\\mathsf{T B}}^{+}$ , we use $\\delta=1\\times10^{-\\dot{6}}$ , and for Adam ${\\mathsf{T B}}^{+}$ we use $\\beta_{1}=0.9$ and $\\beta_{2}=0.999$ . ", "page_idx": 22}, {"type": "text", "text": "K.3 Comparing the Performance of our Algorithms ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In Figure 4 we compare the performance of ${}^{\\mathsf{T B}^{+}}$ , $\\mathsf{P T B}^{+}$ , Smooth $\\mathsf{P T B}^{+}$ , AdaGradTB+ and AdamTB+. ", "page_idx": 22}, {"type": "text", "text": "It can be seen that $\\mathsf{P T B}^{+}$ and Smooth $\\mathsf{P T B}^{+}$ perform similarly, both when using quadratic averaging and when using the last iterate, and they generally outperform the other algorithms. In Kuhn, Liar\u2019s Dice, and Battleship, the last iterate seems to perform quite well, whereas in Leduc and Goofspiel, the quadratic averaging scheme works better. Adam ${}^{\\mathsf{T B}^{+}}$ seems to not converge in any of the games, which is not surprising, because it does not have theoretical guarantees for convergence. ", "page_idx": 22}, {"type": "text", "text": "K.4 Individual Performance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In Figure 5fig:scpomd, we compare the individual performance of ${}^{\\mathsf{T B}^{+}}$ , $\\mathsf{P T B}^{+}$ , Smooth ${\\mathsf{P T B}}^{+}$ , AdaGradTB+, AdamTB+, ${\\mathsf{C F R}}^{+}$ , $\\mathsf{P C F R}^{+}$ and $S C-P O M D$ with different weighting schemes, with and without alternation. We also show the performance of the last iterate. The goal is to choose the most favorable framework for each algorithms, in order to have a fair comparison. We find that all algorithms benefit from using alternation. ${\\mathsf{C F R}}^{+}$ enjoys stronger performance using linear weights, whereas $\\mathsf{P T B}^{+}$ , $\\mathsf{P C F R}^{+}$ and SC-POMD have stronger performances with quadratic weights. For this reason this is the setup that we present for comparing the performance of these algorithms in our main body (Figure 2). ", "page_idx": 22}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/babf7f03a6b7471a4c5e4faa8b221c673a8b5b361b75336aa851eb2d681041a0.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Figure 4: Convergence to Nash equilibrium as a function of number of iterations for ${}^{\\mathsf{T B}^{+}}$ with quadratic averaging, ${\\mathsf{P T B}}^{+}$ with quadratic averaging and last iterate, and Smooth ${\\mathsf{P T B}}^{+}$ with quadratic averaging and last iterate. Every algorithm is using alternation. ", "page_idx": 23}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/f15a5bf28d1acc6e73d0fcf0a2b8670729c0d4fa289084baf6579660139b41af.jpg", "img_caption": ["Figure 5: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for ${}^{\\mathsf{T B}^{+}}$ . "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": ". Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide all proofs. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: This is done in the main body. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. ", "page_idx": 23}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/5ad006fff028cf7403c08f48e61c1f75a75804cefda006c0aab6909a13ed1306.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 6: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for ${\\mathsf{P T B}}^{+}$ . ", "page_idx": 24}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/d57c8398dfbb54211e23466661b7f10af6a77d9633600f7a0eb6a77a0908f682.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 7: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for Smooth ${\\mathsf{P T B}}^{+}$ . ", "page_idx": 24}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/dc6a82e570e9c3a3c14e2a32d795d1cf264d964045a5be4a641aa5f18e97c8a6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 8: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for AdaGradTB+. ", "page_idx": 24}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/8c6ff741e5b6c3d167a655919be359dd11b98acb6e706dcf4021161cbfb1aed8.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 9: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for AdaGradTB+. ", "page_idx": 24}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/a94a51c145b60acc4fd848207e5ade0ce1d4c3e3bfe8b18eb9f1d9b36466803d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 10: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for ${\\mathsf{C F R}}^{+}$ . ", "page_idx": 24}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/240c408dd6d2b005169d7336ce6c59e8f704707c558e059d76c2b54ea7f8db94.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure 11: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for ${\\mathsf{P C F R}}^{+}$ . ", "page_idx": 25}, {"type": "image", "img_path": "8aA3DHLK5h/tmp/39839511f113af8e009ad6f7d7ef61d44fa25a0aa2f29bde3958fb7a53a44a97.jpg", "img_caption": ["Figure 12: Convergence to Nash equilibrium as a function of number of iterations using uniform, linear, and quadratic averaging, as well as the last iterate, with and without alternation for $S C-P O M D$ . "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is done in the main body and in the appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We do so in the main body and in the appendices (Appendix H, Appendix K). Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We plan to do so after the revision process. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We do so in the main body and in the appendices. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: No random experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We do so in the main body and in the appendices. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This research focuses on foundational questions. There is no direct societal impacts of the work performed. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 28}, {"type": "text", "text": "\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Not applicable to our paper. There is no release of data. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide citations to the packages we use. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Not applicable to our paper. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not release new assets. ", "page_idx": 29}, {"type": "text", "text": "\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Not applicable to our paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Not applicable to our paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]