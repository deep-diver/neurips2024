[{"type": "text", "text": "A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yan Sun The University of Sydney ysun9899@uni.sydney.edu.au ", "page_idx": 0}, {"type": "text", "text": "Li Shen\u2217 Shenzhen Campus of Sun Yat-sen University mathshenli@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Dacheng Tao\u2020 Nanyang Technological University dacheng.tao@ntu.edu.sg ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As a popular paradigm for juggling data privacy and collaborative training, federated learning (FL) is flourishing to distributively process the large scale of heterogeneous datasets on edged clients. Due to bandwidth limitations and security considerations, it ingeniously splits the original problem into multiple subproblems to be solved in parallel, which empowers primal dual solutions to great application values in FL. In this paper, we review the recent development of classical federated primal dual methods and point out a serious common defect of such methods in non-convex scenarios, which we say is a \u201cdual drift\u201d caused by dual hysteresis of those longstanding inactive clients under partial participation training. To further address this problem, we propose a novel Aligned Federated Primal Dual (A-FedPD) method, which constructs virtual dual updates to align global consensus and local dual variables for those protracted unparticipated local clients. Meanwhile, we provide a comprehensive analysis of the optimization and generalization efficiency for the A-FedPD method on smooth non-convex objectives, which confirms its high efficiency and practicality. Extensive experiments are conducted on several classical FL setups to validate the effectiveness of our proposed method. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Since McMahan et al. [2017] propose the federated average paradigm, FL has gradually become a promising approach to handle both data privacy and efficient training on the large scale of edged clients, which employs a global server to coordinate local clients jointly train one model. Due to privacy protection, it disables the direct information interaction across clients. All clients must only communicate with an accredited global server. This paradigm creates an unavoidable issue, that is, bandwidth congestion caused by mass communication. Therefore, FL advocates training models on local clients as much as possible within the maximum bandwidth utilization range and only communicates with a part of clients per communication round in a partial participation manner. Under this particular training mechanism, FL needs to effectively split the original problem into several subproblems for local clients to solve in parallel. Because of this harsh limitation, general algorithms are often less efficient in practice. But the primal dual methods just match this training pattern, which empowers it with huge application potential and great values in FL. ", "page_idx": 0}, {"type": "text", "text": "Primal dual methods, which are specified as Lagrangian primal dual in this paper, solve the problem by penalizing and relaxing the constraints to the original objective via non-negative Lagrange multipliers, which make great progress in convex optimization. It beneftis from the consideration of splitting a large problem into several small simple problems to solve, which has been widely developed and applied in the distributed framework as a global consensus problem. This solution is also well suited to the FL scenarios for its effective split characteristic. Recent studies revealed the application potential of such methods. Since Tran Dinh et al. [2021] propose the Randomized Douglas-Rachford Splitting in FL, which unblocks the study of this important branch. With further exploration of Zhang et al. [2021], Durmus et al. [2021], Zhang and Hong [2021], federated primal dual methods are proven to achieve the fast $\\mathcal{O}(1/T)$ convergence rate. Then it is expanded to the more complicated scenarios and incorporated with several novel techniques to achieve state-of-the-art (SOTA) performance in the FL community, which further confirms the great contributions. ", "page_idx": 1}, {"type": "text", "text": "However, as studies go further, a series of problems of federated primal dual methods in the experiments are also exposed. Sensitivity to hyperparameters and fluctuations affected by the large scale makes it extremely unstable in practice, especially in the partial participation manner which is one of the most important concerns in FL. Specifically, primal dual methods successfully solve the problems by alternately updating each primal variable and each dual variable. When it is grafted onto the partial participation training in FL, most clients will remain inactive for a long time, which means most of the dual variables will be stagnant and very outdated in the training. As the training process continues, when one long-term inactive client is reactivated ", "page_idx": 1}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/afe7b8785e6608173f568ba1c4e53c1682f2227a736b1d9f0d2c1fe3c7a8290d.jpg", "img_caption": ["Figure 1: \u201cDual drift\u201d issue of the federated primal dual method under different participation ratios. When the participation ratio is low, dual drift introduces a very large variance, yielding divergence. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "to participate in training, the solving process of its local subproblem will become extremely unstable due to excessive differences between the primal and dual variables, and sometimes even fail. We call this a \u201cdual drift\u201d problem, which is also one of the most formidable challenges in practice in FL. In Fig.1, we clearly show how the \u201cdual drift\u201d deteriorates as the participation ratio decreases. ", "page_idx": 1}, {"type": "text", "text": "To efficiently expand the primal dual methods to partial participation scenarios while enhancing the training stability in practice, and further alleviate the \u201cdual drift\u201d problem, we propose a novel algorithm, named Aligned Federated Primal Dual (A-FedPD), which constructs the virtual dual updates for those unparticipated clients per communication round to align with primal variables. Concretely, after each communication round, we first aggregate the local solutions received from active clients as the unbiased approximation of the local solution of those unparticipated clients. Then we provide a virtual update on the dual variables to align with the primal variable in the training. Updating errors for dual variables will be diminished as global consensus is achieved. The proposed A-FedPD method enables unparticipated clients to keep up-to-date, which approximates the quasi-full-participation training, which can efficiently alleviate the \u201cdual drift\u201d in practice. ", "page_idx": 1}, {"type": "text", "text": "Furthermore, we provide a comprehensive analysis of the optimization and generalization efficiency of the proposed A-FedPD method, which also could be easily extended to the whole federated primal dual family. On smooth non-convex objectives, compared with the vanilla FedAvg method, the A-FedPD could achieve a fast $\\mathcal{O}(1/T)$ convergence rate which maintains consistent with SOTA federated primal dual methods. Moreover, it could support longer local training without affecting stability. Under the same training costs, the A-FedPD method achieves less generalization error. We conduct extensive experiments to validate its efficiency across several general federated setups. We also test a simple variant to show its good scalability incorporated with other novel techniques in FL. ", "page_idx": 1}, {"type": "text", "text": "We summarize our major contributions as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We review the development of federated primal dual family and point out one of its most formidable challenges in the practical application in FL, which is summarized as the \u201cdual drift\u201d problem in this paper. \u2022 We propose a novel A-FedPD method to alleviate the \u201cdual drift\u201d, which constructs the virtual update for dual variables of those unparticipated clients to align with primal variables. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We provide a comprehensive analysis of the optimization and generalization efficiency of A-FedPD. It could achieve a fast convergence rate and a lower generalization error bound than the vanilla FedAvg method. \u2022 Extensive experiments are conducted to validate the performance of the A-FedPD method. Furthermore, we test a simple variant of it to show its good scalability. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Federated primal average. Since McMahan et al. [2017] propose the FedAvg paradigm, a lot of primal average-based methods are learned to enhance its performance. Most of them target strengthening global consistency and alleviating the \u201cclient drift\u201d problem [Karimireddy et al., 2020]. Li et al. [2020] propose to adopt proxy terms to control local updates. Karimireddy et al. [2020] propose the variance reduction version to handle the biases in the primal average. Similar implementations include [Dieuleveut et al., 2021, Jhunjhunwala et al., 2022]. Moreover, momentum-based methods are also popular for correcting local biases. Ozfatura et al. [2021], Xu et al. [2021] propose to adopt the global consistency controller in the local training to force a high consensus. Remedios et al. [2020] expand the local momentum to achieve higher accuracy in the training. Similarly, Wang et al. [2019], Kim et al. [2022] incorporate the global momentum which could further improve its performance. Wang et al. [2020b] tackle the local inconsistency and utilize the weighted primal average to balance different clients with different computing power. Based on this, Horv\u00e1th et al. [2022] further select the important clients set to balance the training trends under different heterogeneous datasets. Liu et al. [2023] summarize the inertial momentum implementation which could achieve a more stable result. Qu et al. [2022] utilize the Sharpeness Aware Minimization (SAM) [Foret et al., 2020] to make the loss landscape smooth with higher generalization performance. Then Caldarola et al. [2022, 2023] propose to improve its stability via Adaptive SAM and window-based model averaging. In summary, Federated primal average methods focus on alleviating the local inconsistency caused by \u201cclient drift\u201d [Malinovskiy et al., 2020, Wang et al., 2020a, Charles and Kone\u02c7cn\\`y, 2021]. However, as analyzed by Durmus et al. [2021], the federated primal dual methods will regularize the local objective gradually close to global consensus by dynamically adjusting the dual variables. This allows \u201cclient drift\u201d to be effectively translated into a dual consistency problem on cross-silo devices. ", "page_idx": 2}, {"type": "text", "text": "Convex optimization of federated primal dual. The primal-dual method was originally proposed to solve convex optimization problems and achieved high theoretical performance. In the FL setups, this method has also made significant advancements. Grudzie\u00b4n et al. [2023a] compute inexactly a proximity operator to work as a variant of primal dual methods. Another technique is loopless instead of an inner loop of local steps. Mishchenko et al. [2022] propose the Scaffnew method to achieve the higher optimization efficiency, which is interpreted as a variant of primal dual approach [Condat and Richt\u00e1rik, 2022]. These techniques can also be easily combined with existing efficient communication methods, e.g. compression and quantization [Grudzien\u00b4 et al., 2023b, Condat et al., 2023]. ", "page_idx": 2}, {"type": "text", "text": "Non-convex optimization of federated primal dual. Since Tran Dinh et al. [2021] adopt the Randomized Douglas-Rachford Splitting, which unblocks the study of the important branch of utilizing primal dual methods in FL [Pathak and Wainwright, 2020]. With further exploration of Zhang et al. [2021], federated primal dual methods are proven to achieve the fast convergence rate. Yuan et al. [2021] learn the composite optimization via a primal dual method in FL. Meanwhile, Sarcheshmehpour et al. [2021] empower its potential on the undirected empirical graph. Shen et al. [2021] also study an agnostic approach under class imbalance targets. Then, Gong et al. [2022], Wang et al. [2022] expand its theoretical analysis to the partial participation scenarios with global regularization. Durmus et al. [2021] improve its implementation by introducing the global dual variable. Moreover, Zhou and Li [2023] learn the effect of subproblem precision on training efficiency. Sun et al. [2023b,a] incorporate it with the SAM to achieve a higher generalization efficiency. Niu and Wei [2023] propose hybrid primal dual updates with both first-order and second-order optimization. Wang et al. [2023] propose a variance reduction variant to further improve the training efficiency. Li et al. [2023a] expand it to a decentralized approach, which could achieve comparable performance in the centralized. Tyou et al. [2023] propose a localized primal dual approach for FL training. Li et al. [2023b] further explore its efficiency on the specific non-convex objectives with non-smooth regularization. Current researches reveal the great application value of the primal dual methods in FL. However, most of them still face the serious \u201cdual drift\u201d problem at low participation ratios. Our improvements further alleviate this issue and make the federated primal dual methods perform more stably in the FL community. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We first review the primal dual methods in FL and demonstrate the \u201cdual drift\u201d issue. Then, we demonstrate the A-FedPD approach to eliminate the \u201cdual drift\u201d challenge. Notations are stated in Table 1. Other symbols are defined when they are first introduced. We denote $\\mathbb{R}$ as the real set and $\\mathbb{E}$ as the expectation in the corresponding probability space. Other notations are defined as first stated. ", "page_idx": 3}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/3f0092081c9970ba7f83fe9db2575f579d7c7f47d7847661b5d134a25f5c8d89.jpg", "table_caption": ["Table 1: Notations adopted in this paper. "], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "3.1 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Setups. In the general and classical federated frameworks, we usually consider the general objective as a finite-sum minimization problem $F(\\theta):\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}F(\\theta)=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}F_{i}(\\theta),\\quad F_{i}(\\theta)\\triangleq\\mathbb{E}_{\\xi\\sim\\mathcal{D}_{i}}f_{i}(\\theta,\\xi).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In each client, there exists a local private data set $\\boldsymbol{S}_{i}$ which is considered a uniform sampling set of the distribution $\\mathcal{D}_{i}$ . In $\\mathrm{FL}$ setups, $\\mathcal{D}_{i}$ is unknown to others for the privacy protection mechanism. Therefore, we usually consider the local Empirical Risk Minimization (ERM) as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}f(\\theta)=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}f_{i}(\\theta),\\quad f_{i}(\\theta)\\triangleq\\frac{1}{S}\\sum_{\\xi\\in S_{i}}f_{i}(\\theta,\\xi).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Our desired optimal solution is $\\theta^{\\star}=\\arg\\operatorname*{min}F(\\theta)$ . However, we can only approximate it on the limited dataset as $\\theta_{S}^{\\star}=\\arg\\operatorname*{min}f(\\theta)$ , which spontaneously introduces the unavoidable biases on its generalization performance. This is one of the main concerns in the field of the current machine learning community. Motivated by this imminent challenge, we conduct a comprehensive study on the performance of primal dual-based algorithms in $\\mathrm{FL}$ and further propose an improvement to enhance its generalization efficiency and stability performance. ", "page_idx": 3}, {"type": "text", "text": "3.2 Primal Dual-family in FL ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Primal Dual methods optimize the global objective by decomposing it into several subproblems and iteratively updating local variables incorporated by Lagrangian multipliers [Boyd et al., 2011], which gives it a unique position in solving FL problems. Due to local data privacy, we have to split the global task into several local tasks for optimization on their private dataset. This similarity also provides an adequate foundation for their applications in the FL community. A lot of studies extend it to the general FL framework and achieve considerable success. ", "page_idx": 3}, {"type": "text", "text": "We follow studies [Zhang et al., 2021, Durmus et al., 2021, Wang et al., 2022, Gong et al., 2022, Sun et al., 2023b, Zhou and Li, 2023, Sun et al., 2023a, Fan et al., 2023, Zhang et al., 2024] to summarize the original objective Eq.(2) as the global consensus reformulation: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta,\\theta_{i}}\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}f_{i}(\\theta_{i}),\\quad\\mathrm{s.t.}\\quad\\theta_{i}=\\theta,\\quad\\forall i\\in\\mathcal{C}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By relaxing equality constraints $\\theta_{i}=\\theta$ , Eq.(3) is separable across different local clients. Wang et al. [2022] demonstrate the difference between the solution on the primal problem and dual problem in detail and confirm the equivalence of these two cases in FL. By penalizing the constraint on the local objective $f_{i}$ , we can define the augmented Lagrangian function associated with Eq.(3) as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\theta_{i},\\theta,\\lambda_{i})=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\left[f_{i}(\\theta_{i})\\!+\\!\\langle\\lambda_{i},\\theta_{i}\\!-\\!\\theta\\rangle\\!+\\!\\frac{\\rho}{2}\\|\\theta_{i}-\\theta\\|^{2}\\right],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\rho$ denotes the penalty coefficient. To train the global model, each local client should first minimize the local augmented Lagrangian function and solve for local parameters. Based on updated local parameters, we then update the dual variable to align the Lagrangian function with the consensus ", "page_idx": 3}, {"type": "text", "text": "constraints. Finally, we minimize the augmented Lagrangian function and solve for the consensus. Objective Eq.(3) could be solved after multiple alternating updates as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l c l}{\\theta_{i}^{t+1}}&{=}&{\\arg\\operatorname*{min}_{\\theta_{i}}\\,\\,\\mathcal{L}(\\theta_{i}^{t},\\theta^{t},\\lambda_{i}^{t})\\quad i\\in\\mathcal{C},}\\\\ {\\lambda_{i}^{t+1}}&{=}&{\\lambda_{i}^{t}+\\rho(\\theta_{i}^{t+1}-\\theta^{t}),}\\\\ {\\theta^{t+1}}&{=}&{\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}(\\theta_{i}^{t+1}+\\frac{1}{\\rho}\\lambda_{i}^{t+1}).}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We then review the classical federated primal dual methods. ", "page_idx": 4}, {"type": "text", "text": "FedPD. Zhang et al. [2021] propose a general federated framework from the primal-dual optimization perspective which can be directly summarized as Eq.(5). As an underlying method in the federated primal dual-family, it requires all local clients to participate in the training per round, which also significantly reduces communication efficiency. ", "page_idx": 4}, {"type": "text", "text": "FedADMM. Wang et al. [2022] extend the theory of the primal-dual optimization in $\\mathrm{FL}$ and prove the equivalence between FedDR [Tran Dinh et al., 2021] and FedADMM. Furthermore, it considers the complete format of composite objective $f(\\theta_{i})+g(\\theta)$ . To optimize the composite objective, after the iterations of Eq.(5), it additionally solves the proximal step on the function $g(\\theta)$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l l l}{\\theta_{i}^{t+1}}&{=}&{\\arg\\operatorname*{min}_{\\theta_{i}}\\,\\,\\mathcal{L}(\\theta_{i}^{t},\\theta^{t},\\lambda_{i}^{t})+g(\\theta^{t})}&{i\\in\\mathcal{P}^{t},}\\\\ {\\lambda_{i}^{t+1}}&{=}&{\\lambda_{i}^{t}+\\rho(\\theta_{i}^{t+1}-\\theta^{t}),}\\\\ {\\overline{{\\theta}}^{t+1}}&{=}&{\\frac{1}{P}\\sum_{i\\in\\mathcal{P}^{t}}(\\theta_{i}^{t+1}+\\frac{1}{\\rho}\\lambda_{i}^{t+1}),}\\\\ {\\theta^{t+1}}&{=}&{\\arg\\operatorname*{min}g(\\theta^{t})+\\frac{1}{2\\rho}\\|\\theta^{t}-\\overline{{\\theta}}^{t+1}\\|^{2}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "FedADMM introduces a more general update with the regularization term $g(\\theta)$ and supports the partial participation training mechanism, which also brings a great application value of primal-dual methods to the FL community. When g(\u00b7) \u22610, it degrades to the partial FedPD by \u03b8t+1 = \u03b8t+1. When $\\mathcal{P}^{t}\\neq\\mathcal{C}$ , \u201cdual drift\u201d brings great distress for training. ", "page_idx": 4}, {"type": "text", "text": "FedDyn. Durmus et al. [2021] utilize the insight of primal-dual optimization to introduce a dynamic regularization term to solve the local augmented Lagrangian function, which is actually the dual variable in FedADMM. Differently, they propose a global dual variable $\\lambda^{t}$ to update global parameters $\\theta^{t}$ instead of only active local dual variables $\\lambda_{i}^{t}\\;(i\\stackrel{\\cdot}{\\in}\\mathcal{P}^{t})$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{r c l}{\\theta_{i}^{t+1}}&{=}&{\\arg\\operatorname*{min}_{\\theta_{i}}\\,\\,\\mathcal{L}(\\theta_{i}^{t},\\theta^{t},\\lambda_{i}^{t})\\quad i\\in\\mathcal{P}^{t},}\\\\ {\\lambda_{i}^{t+1}}&{=}&{\\lambda_{i}^{t}+\\rho(\\theta_{i}^{t+1}-\\theta^{t}),}\\\\ {\\lambda^{t+1}}&{=}&{\\lambda^{t}+\\rho\\frac{1}{C}\\sum_{i\\in\\mathcal{P}^{t}}(\\theta_{i}^{t+1}-\\theta^{t}),}\\\\ {\\theta^{t+1}}&{=}&{\\frac{1}{P}\\sum_{i\\in\\mathcal{P}^{t}}\\theta_{i}^{t+1}+\\frac{1}{\\rho}\\lambda^{t}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Compared with FedADMM, although the global dual variable further corrects the primal parameters, it still hinders the training efficiency, which must rely on the anachronistic historical directions of the local dual variables. Moreover, the global dual variable always updates slowly, which results in consensus constraints that are more difficult to satisfy when solving local subproblems. ", "page_idx": 4}, {"type": "text", "text": "Dual drift. Kang et al. [2024] have indicated that the update mismatch between primal and dual variables leads to a \u201ddrift\u201d. Here, we provide a detailed analysis of the key differences caused by this mismatch. When adopting partial participation, each client is activated at a very low probability, especially on a large scale of edged devices, which widely leads to very high hysteresis between global parameters $\\theta$ and local dual variable $\\lambda_{i}$ . For instance, at round $t$ , we select a subset $\\mathcal{P}^{t}$ to participate in current training and then update the global parameters by $\\theta^{t+1}=\\arg\\operatorname*{min}_{\\theta}$ $\\mathcal{L}(\\theta_{i}^{t+1},\\theta^{t},\\lambda_{i}^{t})$ for $i\\in\\mathcal{P}^{t}$ . Then at round $t+1$ , when a client $i\\not\\in\\{\\mathcal{P}^{\\tau}\\}_{\\tau=t_{0}+1}^{t}(t_{0}\\ll t)$ that has not been involved in training for a long time is activated, its local dual variable $\\lambda_{i}^{t_{0}}$ may severely mismatch the current global parameters $\\theta^{t}$ . This triggers that the local subproblem $\\mathcal{L}(\\theta_{i}^{t+1},\\theta^{t+1},\\lambda_{i}^{t_{0}})$ fail to be optimized properly and even become completely distorted in extreme scenarios, yielding a \u201cdual drift\u201d issue. ", "page_idx": 4}, {"type": "text", "text": "3.3 A-FedPD Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "As introduced in the last part, \u201cdual drift\u201d problem usually results in the unstable optimization of each local subproblem under partial participation. To further mitigate the negative effects of dual drift problems and improve the training efficiency, we propose a novel $A$ -FedPD method (see Algorithm 1), which aligns the virtual dual variables of unparticipated clients via global average models. ", "page_idx": 4}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/482434ec7114aca29fddc693ffa839f95f6bbcb53a244a35ad4acb84fc9ebee7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Specifically, we solve dual variables for unified management and distribution. At round $t$ , we select an active client set $\\mathcal{P}^{t}$ and send the corresponding variables to each active client. Then local client solves the subproblem with $K$ stochastic gradient descent steps and sends the last state $\\theta_{i,K}^{t}$ back i,K ", "page_idx": 5}, {"type": "text", "text": "to the global server. On the global server, it first aggregates the updated parameters as $\\overline{{\\theta}}^{t+1}$ . Then it performs the updates of the dual variables. For each active client $i\\,\\in\\,\\mathcal P^{t}$ , it equally updates the local dual variable as vanilla FedPD. For the unparticipated clients $i\\not\\in\\mathcal{P}^{t}$ , they update the virtual dual variable with the aggregated parameters $\\bar{\\boldsymbol{\\theta}}^{t+1}$ . Finally, we can update the global model with the aggregated parameters and averaged dual variables. Since each client virtually updates, we can directly use the global average as the output. Repeat this training process for a total of $T$ communication rounds to output the final global average model. ", "page_idx": 5}, {"type": "text", "text": "Because of the central storage and management of the dual variables on the global server, it significantly reduces storage requirements for lightweight-edged devices, i.e., mobile phones. For the unparticipated clients, we use their unbiased estimations $\\begin{array}{r}{\\bar{\\mathbb{E}}\\left[w_{i}^{t+1}|\\;w^{t}\\right]=\\mathbb{E}_{\\mathcal{P}^{t}}\\left[\\frac{1}{\\bar{P}}\\sum_{i\\in\\mathcal{P}^{t}}w_{i}^{t+1}|\\;w^{t}\\right]}\\end{array}$ to construct the virtual dual update, which maintains a continuous update of local dual variables. For the global averaged dual variable $\\overline{{\\lambda}}$ , we can reformulate its update as $\\overline{{\\lambda}}^{t+1}=\\overline{{\\lambda}}^{t}+\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t})$ which also could be approximated as a virtual all participation case. This efficiently alleviates the dual drift between $\\theta^{t}$ and $\\lambda_{i}^{t}$ and also ensures fast iteration of the global dual variable in the training, which constitutes an efficient federated framework. ", "page_idx": 5}, {"type": "text", "text": "4 Theoretical Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this part, we mainly introduce the theoretical analysis of the optimization and generalization efficiency of our proposed A-FedPD method. We first introduce the assumptions adopted in our proofs. Optimization analysis is stated in Sec.4.1 and generalization analysis is stated in Sec.4.2. ", "page_idx": 5}, {"type": "text", "text": "Assumption 1 (Smoothness) The local function $f_{i}(\\cdot)$ satisfies the $L$ -smoothness property, i.e., $\\lVert\\nabla f_{i}({\\bar{\\theta_{1}}})-\\nabla f_{i}(\\theta_{2})\\rVert\\leq L\\lVert\\theta_{1}-\\theta_{2}\\rVert$ . ", "page_idx": 5}, {"type": "text", "text": "Assumption 2 (Lipschitz continuity) $F o r\\ \\forall\\ \\theta_{1},\\theta_{2}\\ \\in\\ \\mathbb{R}^{d},$ , the global function $f(\\cdot)$ satisfies the Lipschitz-continuity, i.e., $\\lVert f(\\theta_{1})-f(\\theta_{2})\\rVert\\leq G\\lVert\\theta_{1}-\\theta_{2}\\rVert$ . ", "page_idx": 5}, {"type": "text", "text": "Optimization analysis only adopts Assumption 1. Generalization analysis adopts both assumptions that were followed from the previous work on analyzing the stability [Hardt et al., 2016, Lei and Ying, 2020, Zhou et al., 2021, Sun et al., 2023e,d,c]. Moreover, we consider that the minimization of each local Lagrangian problem achieves the $\\epsilon$ -inexact solution during each local training process, i.e. $\\lVert\\nabla{\\mathcal{L}}_{i}\\rVert^{2}\\ \\breve{\\leq}\\ \\epsilon$ [Zhang et al., 2021, Li et al., 2023a, Gong et al., 2022, Wang et al., 2022]. This consideration is more aligned with the practical scenarios encountered in the empirical studies for non-convex optimization. In fact, it is precisely because the errors from local inexact solutions can be excessively large that the dual drift problem is further exacerbated. ", "page_idx": 5}, {"type": "text", "text": "4.1 Optimization ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this part, we introduce the convergence analysis of the proposed A-FedPD method. ", "page_idx": 6}, {"type": "text", "text": "Theorem 1 Let non-convex objective $f$ satisfies Assumption $^{l}$ , let $\\rho$ be selected as a non-zero positive constant, {\u03b8t}tT=0 sequence generated by algorithm 1 satisfies: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}\\leq\\frac{\\rho\\left[f(\\overline{{\\theta}}^{1})-f^{\\star}\\right]+R_{0}}{T}+\\mathcal{O}\\left(\\epsilon\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $f^{\\star}$ is the optimum and $\\begin{array}{r}{R_{0}=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{1}-\\theta^{0}\\|^{2}}\\end{array}$ is the first local training volumes. ", "page_idx": 6}, {"type": "text", "text": "Remark 1.1 To achieve the \u03f5 error, the A-FedPD requires $O(\\epsilon^{-1})$ rounds, yielding $\\mathcal{O}(1/T)$ convergence rate. Concretely, the federated primal dual methods can locally train more and communicate less, which empowers it a great potential in the applications. Our analysis is consistent with the previous understandings [Zhang et al., 2021, Durmus et al., 2021, Gong et al., 2022, Li et al., 2023a]. ", "page_idx": 6}, {"type": "text", "text": "Remark 1.2 Generally, the federated primal-dual methods require a long local interval. Zhang et al. [2021], Gong et al. [2022], Wang et al. [2022] have summarized the corresponding selections of $K$ for different local optimizers. To complete the analysis, we just list a general selection of the local interval $K$ . Specifically, to achieve the \u03f5 error, local interval $K$ of A-FedPD can be selected as $O(\\epsilon^{-1})$ with total $\\bar{\\mathcal{O}}(\\epsilon^{-2})$ sample complexity in the training. Due to the page limitation, we state more discussions in the Appendix B.2.2. ", "page_idx": 6}, {"type": "text", "text": "4.2 Generalization ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this part, we explore the efficiency of A-FedPD from the stability and generalization perspective, which could also be extended to the common primal dual-family in the federated learning community. We first introduce the setups and assumptions and then demonstrate the main theorem and discussions. ", "page_idx": 6}, {"type": "text", "text": "Setups. To understand the stability and generalization efficiency, we follow Hardt et al. [2016], Lei and Ying [2020], Zhou et al. [2021], Sun et al. [2023e] to adopt the uniform stability analysis to measure its error bound. To learn the generalization gap E $\\left[F(\\theta^{\\dot{T}})-f(\\theta^{T})\\right]$ where $\\theta^{T}$ is generated by a stochastic algorithm, we could study its stability gaps. We consider a joint client set $\\mathcal{C}$ (union dataset) for training. Each client $i$ has a private dataset $\\boldsymbol{S}_{i}$ with total $S$ samples which are sampled from the unknown distribution $\\mathcal{D}_{i}$ . To explore the stability gaps, we construct a mirror dataset $\\hat{\\mathcal{C}}$ that there is at most one different data sample from the raw dataset $\\mathcal{C}$ . Let $\\theta^{T}$ and ${\\hat{\\theta}}^{T}$ be two models trained on $\\mathcal{C}$ and $\\hat{\\mathcal{C}}$ respectively. Therefore, the generalization of a uniformly stable method satisfies: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[|F(\\boldsymbol{\\theta}^{T})-f(\\boldsymbol{\\theta}^{T})|\\right]\\le\\operatorname*{sup}_{\\boldsymbol{\\xi}}\\mathbb{E}\\left[|f(\\boldsymbol{\\theta}^{T},\\boldsymbol{\\xi})-f(\\boldsymbol{\\hat{\\theta}}^{T},\\boldsymbol{\\xi})|\\right]\\le\\varepsilon.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Key properties. From the local training, we can first upper bound the local stability. To compare the difference between vanilla $S G D$ updates and primal dual-family updates, we can reformulate them: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\theta_{i,k+1}^{t}-\\theta^{t}}&{=(\\theta_{i,k}^{t}-\\theta^{t})+\\eta^{t}g_{i,k}^{t},}\\\\ {\\theta_{i,k+1}^{t}-\\theta^{t}}&{=(1-\\eta^{t}\\rho)(\\theta_{i,k}^{t}-\\theta^{t})+\\eta^{t}(g_{i,k}^{t}+\\lambda_{i}).}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The above update is for vanilla $F e d A v g$ and the below update is for primal dual-family. When the dual variables are ignored, local update $\\theta_{i,k}^{\\bar{t}}-\\theta^{t}$ in primal dual could be considered as a stable decayed sequence with $1-\\eta^{t}\\rho$ that has a constant upper bound. Based on this, we can provide a tighter generalization error bound for the primal dual-family methods in FL than the vanilla FedAvg method. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2 Let non-convex objective $f$ satisfies Assumption $^{\\,l}$ and 2 and $H=\\operatorname*{sup}_{\\theta,\\xi}f(\\theta,\\xi),$ , after $T$ communication rounds training with Algorithm $^{l}$ , the generalization error bound achieves: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[F(\\boldsymbol{\\theta}^{T})-f(\\boldsymbol{\\theta}^{T})\\right]\\le\\frac{\\kappa_{c}}{C S}\\left(H P T\\right)^{\\frac{\\mu L}{1+\\mu L}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\mu$ is a constant related to the learning rate and $\\kappa_{c}=4\\left(G^{2}/L\\right)^{\\frac{1}{1+\\mu L}}$ is a constant. ", "page_idx": 6}, {"type": "text", "text": "Remark 2.1 We assume that the total number of data samples participating in the training is $C S$ and the total iterations of the training are $K T$ . Hardt et al. [2016] prove that on non-convex objectives, vanilla SGD method achieves $\\mathcal{O}((T K)^{\\frac{\\mu L}{1+\\mu L}}/C S)$ error bound. Compared with SGD, FL adopts the cyclical local training and partial participation mechanism which further increases the stability error. Sun et al. [2023d] learn a fast rate on sample size as $\\mathcal{O}((P K T)^{\\frac{\\mu L}{1+\\mu L}}/C S)$ under the Lipschitz assumption only. However, primal dual-family can achieve faster rate ${\\mathcal{O}}((P T)^{\\frac{\\mu L}{1+\\mu L}}/C S)$ in FL, which is due to the stable iterations in Eq.(10). It guarantees that the local training could be bounded in a constant order even under the fixed learning rate. From the local training perspective, primal dual-family in FL can support a very long local interval $K$ without losing stability. This property is also proven in its optimization progress, that the primal dual-family could adopt a larger local interval to accelerate the training and reduce the communication rounds. In general training, especially in situations where communication bandwidth is limited and frequent communication is not possible, the primal dual-family in FL could achieve a more stable result than the general methods. Our analysis further confirms its good adaptivity in FL. Due to page limitation, we summarize some recent results of the generalization error bound in Appendix B.3.2. ", "page_idx": 6}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/a15a7e801a1ca675b2419cc4c0caa732abf679ffbcd24f08ba7697897618752a.jpg", "table_caption": ["Table 2: Test accuracy on the CIFAR- $10\\ /\\ 100$ dataset. We fix the total client $C\\;=\\;100$ and $P=10$ under training local 50 iterations. We test 3 setups of IID, Dir-1.0, and Dir-0.1 on each dataset. Each group is tested on LeNet (upper portion) and ResNet-18 (lower portion) models. Each results are tested with 4 different random seeds. \u201c\u2212\u201d means can not stably converge. \u201cFamily\u201d distinguishes whether the algorithm is a primal method (P) or a primal dual method (PD) and \u201cLocal Opt\u201d distinguishes whether the algorithm adopts SGD-based or SAM-based local optimizer. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we introduce the experiments conducted to validate the efficiency of our proposed A-FedPD and a variant A-FedPDSAM (see details in Appendix A.1). We first introduce experimental setups and benchmarks, and then we show the empirical studies. ", "page_idx": 7}, {"type": "text", "text": "Backbones and Datasets. In our experiments, we adopt LeNet LeCun et al. [1998] and ResNet He et al. [2016] as backbones. We follow previous work to test the performance of benchmarks on the CIFAR- $10\\,/\\,100$ dataset Krizhevsky et al. [2009]. We introduce the heterogeneity to split the raw dataset to local clients with independent Dirichlet distribution Hsu et al. [2019] controlled by a concentration parameter. In our setups, we mainly test the performance of the IID, Dir-1.0, and Dir-0.1 splitting. The Dir-1.0 represents the low heterogeneity and Dir-0.1 represents the high heterogeneity. We also adopt the sampling with replacement to further enhance the heterogeneity. ", "page_idx": 7}, {"type": "text", "text": "Setups. We test the accuracy experiments on $C=100$ and $P/C=10\\%$ , which is also the most popular setup in the FL community. In the comparison experiments, we test the participated ratio $\\mathbf{\\bar{}{P}}/{C}=[5\\%$ , $10\\%$ , $20\\%$ , $50\\%$ , $80\\%$ , $100\\%]$ and local interval $K=[10,20,50,100,200]$ respectively. In each setup, for a fair comparison, we freeze the most of hyperparameters for all methods. We fix total communication rounds $T=800$ except for the ablation studies. ", "page_idx": 7}, {"type": "text", "text": "Baselines. FedAvg [McMahan et al., 2017] is the fundamental paradigm in $\\mathrm{FL}$ scenarios. FedCM [Xu et al., 2021], SCAFFOLD [Karimireddy et al., 2020] and FedSAM [Qu et al., 2022] are three classical SOTA methods in the federated primal average family. FedDyn [Durmus et al., 2021] and ", "page_idx": 7}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/39e1ed0155206b881fc42765cd6af8814584422f289a4226cb2d585a0f31db28.jpg", "img_caption": ["Figure 2: Test of the proposed A-FedPD method on setups of different participation ratios, different local intervals, and different rounds. In these experiments, we fix the total training data samples and total training iterations and then learn their variation trends. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "FedSpeed Sun et al. [2023b] are relatively stable federated primal dual methods. A more detailed introduction of these methods is presented in Table 2, including the family-basis and local optimizer. ", "page_idx": 8}, {"type": "text", "text": "5.1 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this part, we introduce the phenomena observed in our empirical studies. We primarily investigated performance comparisons, including settings with different participation rates, various local intervals, and different numbers of communication rounds. Then we report the comparison of wall-clock time. ", "page_idx": 8}, {"type": "text", "text": "Performance Comparison. Table 2 shows the test accuracy on CIFAR-10 / 100 dataset. The vanilla FedAvg provides the standard bars as the baseline. In the federated primal average methods, The FedCM is not stable enough and is largely affected by different backbones, which is caused by the forced consistency momentum and may introduce very large biases. SCAFFOLD and FedSAM performs well. However, both are less than the primal dual-based methods. In summary, SCAFFOLD is on average $3.2\\%$ lower than FedSpeed. As heterogeneity increases, SCAFFOLD drops on average about $5.6\\%$ on CIFAR-10 and $3.43\\%$ on CIFAR-100. In the federated primal dual methods, we can clearly see that FedDyn is not stable in the training. It performs well on the LeNet, which could achieve at least $1\\%$ improvements than SCAFFOLD. However, when the task becomes difficult, i.e., ResNet-18 on CIFAR-100, its accuracy is affected by the \u201cdual drift\u201d and drops quickly. To maintain stability, we have to select some weak coefficients to stabilize it and finally get a lower accuracy. Our proposed A-FedPD could efficiently alleviate the negative impacts of the \u201cdual drift\u201d. It performs about on average $0.8\\%$ higher than FedDyn on the CIFAR-10 dataset. When FedDyn has to compromise the hyperparameters and becomes extremely unstable on ResNet-18 on the CIFAR-100 dataset, A-FedPD still performs stably. It\u2019s also very scalable. When we introduce the SAM optimizer to replace the vanilla $S G D$ , it could achieve higher performance. ", "page_idx": 8}, {"type": "text", "text": "Different Participation Ratios. In this part we compare the sensitivity to the participation ratios. In each setup, we fix the scale as 100 and the local interval as 50 iterations. Active ratio is selected from $[5\\%$ , $10\\%$ , $20\\%$ , $50\\%$ , $80\\%$ , $100\\%]$ as shown in Figure 2 (a). Under frozen hyperparameters, all methods perform well on each selection. The best performance is approximately located in the range of $[20\\%,\\bar{8}0\\%]$ . Our proposed methods achieve high efficiency in handling large-scale training, which performs more steadily than other benchmarks across all selections. ", "page_idx": 8}, {"type": "text", "text": "Different Local Intervals. In this part we compare the sensitivity to the local intervals. In each setup, we fix the scale as 100 and the participation as $10\\%$ . Local interval $K$ is selected from [10, 20, 50, 100, 200] as shown in Figure 2 (b). More local training iterations usually mean more overfitting on the local dataset, which leads to a serious \u201cclient drift\u201d issue. All methods will be affected by this and drop accuracy. It is a trade-off in selecting the local interval $K$ to balance both optimization efficiency and generalization stability. Our proposed methods still could achieve the best performance even on the very long local training iterations. ", "page_idx": 8}, {"type": "text", "text": "Different Communication Rounds. In this part, we compare the sensitivity to the communication rounds. In each setup, we fix total iterations $T K=40,000$ . Communication round $T$ is selected from [200, 400, 800, 2000, 4000] as shown in Figure 2 (c). We always expect the local clients can handle more and communicate less, which will significantly reduce the communication costs. In the experiments, our proposed methods could achieve higher efficiency than the benchmarks. A-FedPD saves about half the communication overhead compared to SCAFFOLD, and about one-third of FedDyn. Under favorable communication bandwidths, they can achieve SOTA performance. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Wall-clock Time Efficiency. In this part we test the practical wall-clock time comparisons as shown in Figure 3. Though some methods are communication-efficiency, complicated calculations hinder the real efficiency in wall-clock training time. Though FedSpeed and AFedPDSAM perform well at the end, additional calculations per single round make their early-stage competitiveness lower. AFedPD and SCAFFOLD consume fewer time costs, hence achieving better results at the early stage. Without considering training time costs, AFedPDSAM achieves the SOTA results at the end. Detailed comparisons are stated in Sec.A.4.4. ", "page_idx": 9}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/5044180cd09f8221f42f12c7ad0add8421def95280abe1d4584ecb34c75b4a4f.jpg", "img_caption": ["Figure 3: Wall-clock time test of training process after total of 600 communication rounds. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we first review the development of the federated primal dual methods. Under the exploration of the experiments, we point out a serious challenge that hinders the efficiency of such methods, which is summarized as the \u201cdual drift\u201d problem due to the mismatched primal and dual variables in the partial participation manners. Furthermore, we propose a novel A-FedPD method to alleviate this issue via constructing virtual dual updates for those unparticipated clients. We also theoretically learn its convergence rate and generalization error bound to demonstrate its efficiency. Extensive experiments are conducted to validate its significant performance. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Muhammad Asad, Ahmed Moustafa, and Takayuki Ito. Fedopt: Towards communication efficiency and privacy preservation in federated learning. Applied Sciences, 10(8):2864, 2020. ", "page_idx": 10}, {"type": "text", "text": "Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et al. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends\u00ae in Machine learning, 3(1):1\u2013122, 2011.   \nDebora Caldarola, Barbara Caputo, and Marco Ciccone. Improving generalization in federated learning by seeking flat minima. In European Conference on Computer Vision, pages 654\u2013672. Springer, 2022.   \nDebora Caldarola, Barbara Caputo, and Marco Ciccone. Window-based model averaging improves generalization in heterogeneous federated learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2263\u20132271, 2023.   \nZachary Charles and Jakub Kone\u02c7cn\\`y. Convergence and accuracy trade-offs in federated learning and metalearning. In International Conference on Artificial Intelligence and Statistics, pages 2575\u20132583. PMLR, 2021.   \nLaurent Condat and Peter Richt\u00e1rik. Randprox: Primal-dual optimization algorithms with randomized proximal updates. arXiv preprint arXiv:2207.12891, 2022.   \nLaurent Condat, Ivan Agarsky\\`, Grigory Malinovsky, and Peter Richt\u00e1rik. Tamuna: Doubly accelerated federated learning with local training, compression, and partial participation. arXiv preprint arXiv:2302.09832, 2023.   \nAymeric Dieuleveut, Gersende Fort, Eric Moulines, and Genevi\u00e8ve Robin. Federated-em with heterogeneity mitigation and variance reduction. Advances in Neural Information Processing Systems, 34:29553\u201329566, 2021.   \nAlp Emre Durmus, Zhao Yue, Matas Ramon, Mattina Matthew, Whatmough Paul, and Saligrama Venkatesh. Federated learning based on dynamic regularization. In International Conference on Learning Representations, 2021.   \nZiqing Fan, Yanfeng Wang, Jiangchao Yao, Lingjuan Lyu, Ya Zhang, and Qi Tian. Fedskip: Combatting statistical heterogeneity with federated skip aggregation. In 2022 IEEE International Conference on Data Mining (ICDM), pages 131\u2013140. IEEE, 2022.   \nZiqing Fan, Jiangchao Yao, Ruipeng Zhang, Lingjuan Lyu, Yanfeng Wang, and Ya Zhang. Federated learning under partially disjoint data via manifold reshaping. Transactions on Machine Learning Research, 2023.   \nZiqing Fan, Shengchao Hu, Jiangchao Yao, Gang Niu, Ya Zhang, Masashi Sugiyama, and Yanfeng Wang. Locally estimated global perturbations are better than local perturbations for federated sharpness-aware minimization. arXiv preprint arXiv:2405.18890, 2024a.   \nZiqing Fan, Jiangchao Yao, Bo Han, Ya Zhang, Yanfeng Wang, et al. Federated learning with bilateral curation for partially class-disjoint data. Advances in Neural Information Processing Systems, 36, 2024b.   \nPierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. arXiv preprint arXiv:2010.01412, 2020.   \nYonghai Gong, Yichuan Li, and Nikolaos M Freris. Fedadmm: A robust federated deep learning framework with adaptivity to system heterogeneity. In 2022 IEEE 38th International Conference on Data Engineering (ICDE), pages 2575\u20132587. IEEE, 2022.   \nMicha\u0142 Grudzien\u00b4, Grigory Malinovsky, and Peter Richt\u00e1rik. Can 5th generation local training methods support client sampling? yes! In International Conference on Artificial Intelligence and Statistics, pages 1055\u20131092. PMLR, 2023a.   \nMicha\u0142 Grudzie\u00b4n, Grigory Malinovsky, and Peter Richt\u00e1rik. Improving accelerated federated learning with compression and importance sampling. arXiv preprint arXiv:2306.03240, 2023b.   \nMoritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. In International conference on machine learning, pages 1225\u20131234. PMLR, 2016.   \nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \nSamuel Horv\u00e1th, Maziar Sanjabi, Lin Xiao, Peter Richt\u00e1rik, and Michael Rabbat. Fedshuffle: Recipes for better use of local work in federated learning. arXiv preprint arXiv:2204.13169, 2022.   \nTzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data distribution for federated visual classification. arXiv preprint arXiv:1909.06335, 2019.   \nXiaolin Hu, Shaojie Li, and Yong Liu. Generalization bounds for federated learning: Fast rates, unparticipating clients and unbounded losses. In The Eleventh International Conference on Learning Representations, 2022.   \nDivyansh Jhunjhunwala, Pranay Sharma, Aushim Nagarkatti, and Gauri Joshi. Fedvarp: Tackling the variance due to partial client participation in federated learning. In Uncertainty in Artificial Intelligence, pages 906\u2013916. PMLR, 2022.   \nHeejoo Kang, Minsoo Kim, Bumsuk Lee, and Hongseok Kim. Fedand: Federated learning exploiting consensus admm by nulling drift. IEEE Transactions on Industrial Informatics, 2024.   \nSai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning, pages 5132\u20135143. PMLR, 2020.   \nGeeho Kim, Jinkyu Kim, and Bohyung Han. Communication-efficient federated learning with acceleration of global momentum. arXiv preprint arXiv:2201.03172, 2022.   \nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \nYann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.   \nYunwen Lei and Yiming Ying. Fine-grained analysis of stability and generalization for stochastic gradient descent. In International Conference on Machine Learning, pages 5809\u20135819. PMLR, 2020.   \nQinglun Li, Li Shen, Guanghao Li, Quanjun Yin, and Dacheng Tao. Dfedadmm: Dual constraints controlled model inconsistency for decentralized federated learning. arXiv preprint arXiv:2308.08290, 2023a.   \nTian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2:429\u2013450, 2020.   \nYiwei Li, Chien-Wei Huang, Shuai Wang, Chong-Yung Chi, and Tony QS Quek. Privacy-preserving federated primal-dual learning for non-convex problems with non-smooth regularization. In 2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP), pages 1\u20136. IEEE, 2023b.   \nYixing Liu, Yan Sun, Zhengtao Ding, Li Shen, Bo Liu, and Dacheng Tao. Enhance local consistency in federated learning: A multi-step inertial momentum approach. arXiv preprint arXiv:2302.05726, 2023.   \nGrigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, and Peter Richtarik. From local sgd to local fixed-point methods for federated learning. In International Conference on Machine Learning, pages 6692\u20136701. PMLR, 2020.   \nBrendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communicationefficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017.   \nKonstantin Mishchenko, Grigory Malinovsky, Sebastian Stich, and Peter Richt\u00e1rik. Proxskip: Yes! local gradient steps provably lead to communication acceleration! finally! In International Conference on Machine Learning, pages 15750\u201315769. PMLR, 2022.   \nMehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In International Conference on Machine Learning, pages 4615\u20134625. PMLR, 2019.   \nXiaochun Niu and Ermin Wei. Fedhybrid: A hybrid federated optimization method for heterogeneous clients. IEEE Transactions on Signal Processing, 71:150\u2013163, 2023.   \nEmre Ozfatura, Kerem Ozfatura, and Deniz G\u00fcnd\u00fcz. Fedadc: Accelerated federated learning with drift control. In 2021 IEEE International Symposium on Information Theory (ISIT), pages 467\u2013472. IEEE, 2021.   \nReese Pathak and Martin J Wainwright. Fedsplit: An algorithmic framework for fast federated optimization. Advances in neural information processing systems, 33:7057\u20137066, 2020.   \nZhe Qu, Xingyu Li, Rui Duan, Yao Liu, Bo Tang, and Zhuo Lu. Generalized federated learning via sharpness aware minimization. In International Conference on Machine Learning, pages 18250\u201318280. PMLR, 2022.   \nSamuel W Remedios, John A Butman, Bennett A Landman, and Dzung L Pham. Federated gradient averaging for multi-site training with momentum-based optimizers. In Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4\u20138, 2020, Proceedings 2, pages 170\u2013180. Springer, 2020.   \nYasmin Sarcheshmehpour, M Leinonen, and Alexander Jung. Federated learning from big data over networks. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3055\u20133059. IEEE, 2021.   \nZebang Shen, Juan Cervino, Hamed Hassani, and Alejandro Ribeiro. An agnostic approach to federated learning with class imbalance. In International Conference on Learning Representations, 2021.   \nYan Sun, Li Shen, Shixiang Chen, Liang Ding, and Dacheng Tao. Dynamic regularized sharpness aware minimization in federated learning: Approaching global consistency and smooth landscape. arXiv preprint arXiv:2305.11584, 2023a.   \nYan Sun, Li Shen, Tiansheng Huang, Liang Ding, and Dacheng Tao. Fedspeed: Larger local interval, less communication round, and higher generalization accuracy. arXiv preprint arXiv:2302.10429, 2023b.   \nYan Sun, Li Shen, Hao Sun, Liang Ding, and Dacheng Tao. Efficient federated learning via local adaptive amended optimizer with linear speedup. arXiv preprint arXiv:2308.00522, 2023c.   \nYan Sun, Li Shen, and Dacheng Tao. Which mode is better for federated learning? centralized or decentralized. arXiv preprint arXiv:2310.03461, 2023d.   \nYan Sun, Li Shen, and Dacheng Tao. Understanding how consistency works in federated learning via stage-wise relaxed initialization. arXiv preprint arXiv:2306.05706, 2023e.   \nQuoc Tran Dinh, Nhan H Pham, Dzung Phan, and Lam Nguyen. Feddr\u2013randomized douglas-rachford splitting algorithms for nonconvex federated composite optimization. Advances in Neural Information Processing Systems, 34:30326\u201330338, 2021.   \nIifan Tyou, Tomoya Murata, Takumi Fukami, Yuki Takezawa, and Kenta Niwa. A localized primal-dual method for centralized/decentralized federated learning robust to data heterogeneity. IEEE Transactions on Signal and Information Processing over Networks, 2023.   \nHan Wang, Siddartha Marella, and James Anderson. Fedadmm: A federated primal-dual algorithm allowing partial participation. In 2022 IEEE 61st Conference on Decision and Control (CDC), pages 287\u2013294. IEEE, 2022.   \nJianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat. Slowmo: Improving communication-efficient distributed sgd with slow momentum. arXiv preprint arXiv:1910.00643, 2019.   \nJianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33: 7611\u20137623, 2020a.   \nJianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33: 7611\u20137623, 2020b.   \nShuai Wang, Yanqing Xu, Zhiguo Wang, Tsung-Hui Chang, Tony QS Quek, and Defeng Sun. Beyond admm: a unified client-variance-reduced adaptive federated learning framework. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 10175\u201310183, 2023.   \nZheshun Wu, Zenglin Xu, Hongfang Yu, and Jie Liu. Information-theoretic generalization analysis for topologyaware heterogeneous federated edge learning over noisy channels. IEEE Signal Processing Letters, 2023.   \nJing Xu, Sen Wang, Liwei Wang, and Andrew Chi-Chih Yao. Fedcm: Federated learning with client-level momentum. arXiv preprint arXiv:2106.10874, 2021.   \nHonglin Yuan, Manzil Zaheer, and Sashank Reddi. Federated composite optimization. In International Conference on Machine Learning, pages 12253\u201312266. PMLR, 2021.   \nRuipeng Zhang, Ziqing Fan, Jiangchao Yao, Ya Zhang, and Yanfeng Wang. Domain-inspired sharpness-aware minimization under domain shifts. arXiv preprint arXiv:2405.18861, 2024.   \nXinwei Zhang and Mingyi Hong. On the connection between fed-dyn and fedpd. FedDyn_FedPD. pdf, 2021.   \nXinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin, and Yang Liu. Fedpd: A federated learning framework with adaptivity to non-iid data. IEEE Transactions on Signal Processing, 69:6055\u20136070, 2021.   \nPan Zhou, Hanshu Yan, Xiaotong Yuan, Jiashi Feng, and Shuicheng Yan. Towards understanding why lookahead generalizes better than sgd and beyond. Advances in Neural Information Processing Systems, 34:27290\u201327304, 2021.   \nShenglong Zhou and Geoffrey Ye Li. Federated learning via inexact admm. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "In this part, we introduce the appendix. We introduce the additional experiments in Sec.A including backgrounds, setups, hyperparameters selections, and some figures of experiments. We introduce the theoretical proofs in Sec.B. ", "page_idx": 14}, {"type": "text", "text": "Limitations. To avoid the dual drifts, we propose the virtual dual updates to align the old dual variables with the new global model. This requires those dual variables of non-active clients to be updated on the global server, yielding more storage costs. As a trade-off, our method applies additional variable assistance to greatly improve the stability of such algorithms. It also is an interesting future study to approximate the virtual dual update on the local clients. ", "page_idx": 14}, {"type": "text", "text": "A Additional Experiments ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Benchmarks ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We select 6 classical state-of-the-art (SOTA) benchmarks as baselines in our paper, including (a) primal: FedAvg McMahan et al. [2017], SCAFFOLD Karimireddy et al. [2020], FedCM Xu et al. [2021], FedSAM Qu et al. [2022]; (b) primal dual: FedADMM Wang et al. [2022], FedDyn Wang et al. [2022], FedSpeed Sun et al. [2023b]. We mainly focus on infrastructure improvements instead of combinations of techniques. In the primal group, SCAFFOLD and FedCM alleviate \u201cclient drift\u201d via variance reduction and client-level momentum correction respectively. FedSAM introduce the Sharpeness Aware Minimization (SAM) Foret et al. [2020] in vanilla FedAvg to smoothen the loss landscape. In the primal dual group, we select the FedDyn as the stable basis under partial participation. We also show the instability of the vanilla FedADMM to show the negative impacts of the \u201cdual drift\u201d. FedSpeed introduces the $S A M$ in vanilla FedADMM / FedDyn. We also test the variant of SAM version of our proposed A-FedPD method, which is named A-FedPDSAM. ", "page_idx": 14}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/652ab9d5abe096c530c3ddc54c641e752ac1610a44d67b4b0764cc659dfdddc7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "A.2 Hyperparameters Selection ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We first introduce the hyperparameter selections. To fairly compare the efficiency of the benchmarks, we fix the most of hyperparameters, including the initial global learning rate, the initial learning rate, the weight decay coefficient, and the local batchsize. The other hyperparameters are selected properly on a grid search within the valid range. The specific hyperparameters of specific methods are defined in the experiments. We report the corresponding selections of their best performance, which is summarized in the following Table 3. ", "page_idx": 14}, {"type": "text", "text": "The global learning rate is fixed in our experiments. Though Asad et al. [2020] propose to adopt the double learning rate decay both on the global server and local client can make training more efficient, we find some methods will easily over-fit under a global learning rate decay. For the weight decay coefficient, we recommend to adopt 0.001. Actually, we find that adjusting it still can improve the performance of some specific methods. One of the most important hyperparameters is learning rate decay. Generally, we use $d^{T}=1\\;/\\;0.8\\;/\\;0.1\\;/\\;0.005$ to select the proper $d$ as a decayed coefficient, which means the level of the initial learning rate will be decayed after $T$ communication rounds. We follow previous studies to fix the learning rate within the communication round. Another important hyperparameter is the batchsize. In our experiments, we fixed the local interval which means the fixed local iterations. Due to the sample size being fixed, different batchsizes mean different training epochs. Generally speaking, training epochs always decide the optimization level on the local optimum. A too-long interval always leads to overfitting to the local dataset and falling into the serious \u201cclient drift\u201d problem [Karimireddy et al., 2020]. In our experiments, we control it to stop when the local client is optimized well enough, i.e., a proper loss or accuracy. For the specific hyperparameters for each method, we directly grid search from the selections. For A-FedPDSAM method, the selections are consistent with the FedDyn and FedSpeed methods except for the learning rate decay is fixed as 0.998. To alleviate the \u201cdual drift\u201d, we properly reduce the proxy coefficient for the FedDyn on those difficult tasks to maintain stable training. ", "page_idx": 14}, {"type": "table", "img_path": "", "table_caption": ["Table 3: Hyperparameters selections of benchmarks. "], "table_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/f4016e6d1a6caa1ce7857b1c282fb314396819b458c5865e4df53bf661333b1d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "", "img_caption": ["Figure 4: Label ratios under different splitting manners. Different color means the samples are in different labels. We show the different splitting distributions on a total of 100 clients. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A.3 Dataset and Splitting ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We use the CIFAR-10 / 100 datasets to validate the efficiency, which is widely used to verify the federated efficiency [McMahan et al., 2017, Karimireddy et al., 2020, Li et al., 2020, Xu et al., 2021, Durmus et al., 2021, Gong et al., 2022, Wang et al., 2022, Fan et al., 2022, Caldarola et al., 2022, Sun et al., 2023b,a, Li et al., 2023a, Fan et al., 2024a,b]. The total dataset of both contain 50,000 training samples and 10,000 test samples of 10 / 100 classes. Each is a colorful image in the size of $32\\!\\times\\!32$ . We follow the training as the vanilla SGD to add data augmentation without additional operations. ", "page_idx": 15}, {"type": "text", "text": "Label Heterogeneity. For the dataset splitting, we adopt the label imbalanced splitting under the Dirichlet manners. We first generate a distribution matrix and then generate a random number to sample each data. To further enhance the local heterogeneity, we also adopt the sampling with replacement, which means one data sample may exist on several clients simultaneously. This is more related to real-world scenarios because of the local unknown dataset distribution. We generate the matrices in Fig. 4 to show their distribution differences. We can clearly see that Dir-0.1 introduces a very large heterogeneity in that there is almost one dominant class in a client. Dir-1.0 handles approximately 3 classes in one client. Actually, in practical scenarios, label imbalance may be the most popular heterogeneity because we often expect both the local task and local dataset to be still unknown to others. For instance, client $i$ may be an expert on task $A$ , and client $j$ may be an expert on another task $B$ . To combine the tasks $A$ and $B$ , if we can directly merge them with a training policy without beforehand knowing the tasks, then it must further enhance local privacy. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Brightness Heterogeneity. To further simulate the real-world manners, we allow different clients to change the brightness and ratios of different color channels. This corresponds to different sources of data collected by different local clients. We show some samples in Fig. 5 to show how different they are on different clients. Specifically, after splitting the local dataset, we will calculate the average brightness of each local dataset. Then we generate a noise from Gaussian to randomly change the brightness and one of the color channels, which means that even similar samples have large color differences on different clients. ", "page_idx": 16}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/6e6f479d388a4a20927643841123e33369a33311ecd15e942b050e671d0e1c59.jpg", "img_caption": ["Figure 5: Introducing the brightness biases to different clients. We calculate the average brightness to control each sample to a proper state. Each client will randomly sample a Gaussian noise to perturb the local samples. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "A.4 Additional Experiments ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A.4.1 Some Training Curves ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In Figure 6 we can see some experiment curves. From the (a), (b), (c), and (d), we can clearly see that the A-FedPD method achieves the fastest convergence rate on each setup. Due to the virtual update on the dual variables, we can treat those unparticipated clients as virtually trained ones. This empowers the A-FedPD method with a great convergence speed. Especially on the IID dataset, due to the local datasets being similar (drawn from a global distribution), the expectation of the updated averaged models is the same as that of the updated local model with lower variance. Then we could approximate the local dual update as the global one. This greatly speeds up the training time. We also can see the fast rate of the FedDyn method. However, due to its lagging dual update, it will be slower than the A-FedPD method. As for the SAM variant, it introduces an additional perturbation step that could avoid overftiting. Therefore, its loss does not drop quickly because of the additional ascent step. ", "page_idx": 16}, {"type": "text", "text": "From the (e), (f), (g), and (h), we can clearly see the improvements of A-FedPD and A-FedPDSAM methods. From the basic version, A-FedPD could achieve higher performance due to the virtual dual updates. After incorporating SAM, local clients could efficiently alleviate overfitting. The global model becomes more stable and could achieve the SOTA results. We will learn the consistency performance in the next part. ", "page_idx": 16}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/43c350deaa2bb5afa12f8539c8a1bb0daeeeb89b35113c892c3d75e99aee88cf.jpg", "img_caption": ["Figure 6: Loss and accuracy curves in the experiments. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "A.4.2 Primal Residual and Dual Residual ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In the primal dual methods, due to the joint solution on both the primal and dual problems, it leads to an issue that both residuals should maintain a proper ratio. Therefore, the quantity of global updates in the training could be considered as a residual for the dual feasibility condition. The same, the constraint itself could be considered as the primal residual. Then we consider Eq.(3) objectives. The constraint is the global consensus level $\\theta-\\theta_{i}$ and the global update is $\\theta^{t+1}-\\theta^{t}$ . To generally express them, we define the primal residual $\\begin{array}{r}{p_{r}^{t}=\\frac{1}{C}\\sum_{i}\\|\\theta^{t}-\\theta_{i}^{t}\\|}\\end{array}$ and the dual residual $d_{r}^{t}\\,{=}\\,\\rho\\|\\theta^{t}-\\theta^{\\bar{t}-1}\\|$ . Actually, the primal residual could be considered as the consistency, and the dual residual could be considered as the update. In the training, if we focus more on the dual residual, it leads to a fast convergence on an extremely biased objective that is far away from the true optimal. If we focus more on the primal residual, the local training cannot perform normally for its strong regularizations. Therefore, we must maintain stable trends on both $p_{r}$ and $d_{r}$ to implement stable training. In this part, we study the relationships between primal and dual residuals. ", "page_idx": 17}, {"type": "text", "text": "As shown in Figure 7, we can clearly see the lower stable ratio between the primal and dual residuals on the A-FedPD and A-FedPDSAM methods, which indicates that both the primal training and dual training are performed well simultaneously. However, the federated primal average-based methods, i.e., FedAvg and SCAFFOLD, focus more on the primal training which leads to the dual residuals are too small (dual residuals measure the global update; primal residuals measure the global consistency). ", "page_idx": 17}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/885fea39b778533c1d7680d57ac0a02b6c4b8b75dfc722764309324cb1bf2449.jpg", "img_caption": ["(a) Residuals on the CIFAR-10 test. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "h1iMVi2iEM/tmp/1d1a5c111f0d205d2e5f530ca18ed771a31fcef37795476f271974a32cf1e625.jpg", "img_caption": ["Figure 7: Loss and accuracy curves in the experiments. ", "(b) Residuals on the CIFAR-100 test. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "A.4.3 Communication Efficiency ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this part, we learn the general communication efficiency. We fix all local intervals, clients, participation ratios, and hyperparameters for fairness. We select the different targets as the objective to calculate the communication efficiency. ", "page_idx": 18}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/27b0035a18bc679ade67791420eb25d800562e96ef7e9791cc290dff84a201fb.jpg", "table_caption": ["Table 4: Communication rounds required to achieve the target accuracy. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Table 4 shows the communication efficiency among different methods on the CIFAR-10 / 100 dataset trained with LeNet. We calculate the first communication round index of achieving the target accuracy for comparison. We can clearly see that the communication rounds required for training are saved a lot on the proposed A-FedPD and A-FedPDSAM methods. It generally accelerates the training process by at least $3\\times$ on CIFAR-10 and $6\\times$ on CIFAR-100 than the vanilla FedAvg method. Compared with the other benchmarks, our proposed method performs stably and efficiently. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "A.4.4 Wall clock Time for Training Costs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Then we further study the wall clock time required in the training. We provide the experimental setups as follows. ", "page_idx": 19}, {"type": "text", "text": "Platform: Pytorch 2.0.1 Cuda: 11.7 Hardware: NVIDIA GeForce RTX 2080 Ti Table 5: Wall clock time required to train 1 round (100 iterations) on ResNet. ", "page_idx": 19}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/59ced76fb40e5d86f0674f9a629beaf191f09f7cf0aa8729df6e1a1d7fe95862.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/9bacdecb0dd4ba589e79f0d925c5f05a627597ed3784f1d48ff2d40e593b8d90.jpg", "table_caption": ["Table 6: Wall clock time required to train 1 round (100 iterations) on LeNet. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Actually, the LeNet is too small for the GPU and the training time does not achieve the capacity, which leads to the close time costs in Table 6. We recommend referring to the cost ratio on the ResNet (Table 5), which is much closer to the real algorithmic efficiency. ", "page_idx": 19}, {"type": "text", "text": "B Proofs. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this part, we mainly show the proof details of the main theorems in this paper. We will reiterate the background details in Sec.B.1. Then we introduce the important lemmas used in the proof in Sec.B.3.1, and show the proof details of the main theorems in Sec.B.3.2. ", "page_idx": 20}, {"type": "text", "text": "B.1 Preliminaries ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Here we reiterate the background details in the proofs. To understand the stability efficiency, we follow Hardt et al. [2016], Lei and Ying [2020], Zhou et al. [2021], Sun et al. [2023e] to adopt the uniform stability analysis in our analysis. Through refining the local subproblem of the solution of the Augmented Lagrangian objective, we provide the error term of the primal and dual terms and their corresponding complexity bound in FL. ", "page_idx": 20}, {"type": "text", "text": "Before introducing the important lemmas, we re-summarize the pipelines in the analysis. According to the federated setups, we assume a global server coordinates a set of local clients ${\\mathcal{C}}\\triangleq\\{i\\}_{i=1}^{C}$ to train one model. Each client has a private dataset $\\boldsymbol{S_{i}}=\\left\\{\\zeta_{i j}\\right\\}_{j=1}^{S}$ . We assume that the global joint dataset is the union of $\\{S_{1}\\cup S_{2}\\cup\\cdot\\cdot\\cdot\\cup S_{C}\\}$ . To study its stability, we assume there is another global joint dataset that contains at most one different data sample from $\\mathcal{C}$ . Let the index of the different pair be $(i^{\\star},j^{\\star})$ . We train two global models $\\theta^{T}$ and $\\hat{\\theta}^{T}$ on these two global joint datasets respectively and gauge their gaps during the training process. ", "page_idx": 20}, {"type": "text", "text": "Then we rethink the local solution of the local augmented Lagrangian function. According to the basic algorithm, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathcal{L}_{i}(\\theta,\\lambda_{i}^{t},\\theta^{t})=f_{i}(\\theta)+\\langle\\lambda_{i}^{t},\\theta-\\theta^{t}\\rangle+\\frac{\\rho}{2}\\|\\theta-\\theta^{t}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To upper bound its stability without loss of generality, we consider adopting the general SGD optimizer to solve the sub-problem via total $K$ iterations with the local learning rate $\\eta^{\\bar{t}}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\theta_{i,k+1}^{t}=\\theta_{i,k}^{t}-\\eta^{t}\\nabla{\\mathcal L}_{i}(\\theta_{i,k}^{t},\\lambda_{i}^{t},\\theta^{t})=\\theta_{i,k}^{t}-\\eta^{t}\\left[g_{i,k}^{t}+\\lambda_{i}^{t}+\\rho\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)\\right],\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $k$ is the index of local iterations $(0\\leq k\\leq K)$ ). ", "page_idx": 20}, {"type": "text", "text": "B.2 Optimization ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "B.2.1 Important Lemmas ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this part, we mainly introduce some important lemmas adopted in the optimization proofs. ", "page_idx": 20}, {"type": "text", "text": "Motivated by Durmus et al. [2021], we assume the local client solves the inexact solution of each local Lagrangian function, therefore we have $\\nabla f_{i}(\\theta_{i}^{t+1})+\\lambda_{i}^{t}+\\rho(\\theta_{i}^{t+1}-\\theta^{t})=e$ , where $e$ can be considered as an error variable with $\\lVert e\\rVert^{2}\\leq\\epsilon$ . This can characterize the different solutions of the local sub-problems. We always expect the error to achieve zero. Durmus et al. [2021] only assume that the local solution is exact and this may be not possible in practice. ", "page_idx": 20}, {"type": "text", "text": "Lemma 1 ([Durmus et al., 2021]) The conditionally expected gaps between the current averaged local parameters and last averaged local parameters satisfy: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t}\\|\\overline{{\\theta}}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}\\leq\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. According to the averaged randomly sampling, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{t}\\|\\bar{\\theta}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}=\\mathbb{E}_{t}\\|\\displaystyle\\frac{1}{P}\\sum_{i\\in\\mathcal{P}^{t}}\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}\\leq\\displaystyle\\frac{1}{P}\\mathbb{E}_{t}\\sum_{i\\in\\mathcal{P}^{t}}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{1}{P}\\mathbb{E}_{t}\\sum_{i\\in\\mathcal{C}}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}\\cdot\\mathbb{I}_{i}\\leq\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "$\\mathbb{I}_{i}$ is the indicator function as $\\mathbb{I}_{i}=1\\,i f\\,i\\in\\mathcal{P}^{t}$ else $\\boldsymbol{O}$ . ", "page_idx": 20}, {"type": "text", "text": "Lemma 2 Under Assumption 1 and let the local solution be an \u03f5-inexact solution, the conditionally expected averaged local updates satisfy: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left(1-\\frac{4L^{2}}{\\rho^{2}}\\right)\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}\\leq\\frac{8L^{2}}{\\rho^{2}}\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\theta_{i}^{t}-\\overline{{\\theta}}^{t}\\Vert^{2}+\\frac{4L^{2}}{\\rho^{2}}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}+\\frac{4\\epsilon}{\\rho^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. First, we reconstruct the update of the dual variable. From the updated rules, we have $\\overline{{\\lambda_{i}}}^{t+1}-\\overline{{\\lambda_{i}}}^{t}=\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t})$ . From the first order condition of $\\nabla f_{i}(\\theta_{i}^{t+1})+\\lambda_{i}^{t}+\\rho(\\theta_{i}^{t+1}-\\theta^{t})=e$ . By expanding Lemma $_{l l}$ in [Durmus et al., 2021], then we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\cfrac{1}{C}\\displaystyle\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}}\\\\ &{=\\displaystyle\\frac{1}{C}\\displaystyle\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\theta^{t}+\\frac{1}{\\rho}\\overline{{\\lambda}}^{t}\\|^{2}}\\\\ &{\\leq\\displaystyle\\frac{4L^{2}}{\\rho^{2}}\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\Big(\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}+2\\mathbb{E}_{t}\\|\\theta_{i}^{t}-\\overline{{\\theta}}^{t}\\|^{2}+\\mathbb{E}_{t}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}\\Big)+\\frac{4\\epsilon}{\\rho^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, we can reconstruct its relationship as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left(1-\\frac{4L^{2}}{\\rho^{2}}\\right)\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}\\leq\\frac{8L^{2}}{\\rho^{2}}\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\theta_{i}^{t}-\\overline{{\\theta}}^{t}\\Vert^{2}+\\frac{4L^{2}}{\\rho^{2}}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}+\\frac{4\\epsilon}{\\rho^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This completes the proofs. ", "page_idx": 21}, {"type": "text", "text": "Lemma 3 Under Assumption $^{\\,l}$ , the conditionally expected averaged local consistency satisfies: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t+1}\\|^{2}\\leq\\frac{4}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. According to the update rules, we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t+1}\\|^{2}=\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}+\\overline{{\\theta}}^{t}-\\overline{{\\theta}}^{t+1}\\|^{2}}\\\\ {\\displaystyle\\leq\\frac{2}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}+2\\mathbb{E}_{t}\\|\\overline{{\\theta}}^{t}-\\overline{{\\theta}}^{t+1}\\|^{2}}\\\\ {\\displaystyle\\leq\\frac{2}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}+\\displaystyle\\frac{2}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}}\\\\ {\\displaystyle}&{\\leq\\displaystyle\\frac{4}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This completes the proofs. ", "page_idx": 21}, {"type": "text", "text": "B.2.2 Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "According to the smoothness, we take the conditional expectation on round $t$ and expand the global function as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{t}\\left[f(\\overline{\\theta}^{t+1})\\right]-f(\\overline{\\theta}^{t})}\\\\ &{\\le\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\|\\overline{\\theta}^{t+1}-\\overline{\\theta}^{t}\\|^{2}+\\mathbb{E}_{t}\\langle\\nabla f(\\overline{\\theta}^{t}),\\overline{\\theta}^{t+1}-\\overline{\\theta}^{t}\\rangle}\\\\ &{=\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\|\\overline{\\theta}^{t+1}-\\overline{\\theta}^{t}\\|^{2}+\\mathbb{E}_{t}\\langle\\nabla f(\\overline{\\theta}^{t}),\\displaystyle\\frac{1}{C}\\sum_{i\\in C}\\theta_{i}^{t+1}-\\overline{\\theta}^{t}\\rangle}\\\\ &{=\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\|\\overline{\\theta}^{t+1}-\\overline{\\theta}^{t}\\|^{2}+\\mathbb{E}_{t}\\langle\\nabla f(\\overline{\\theta}^{t}),\\displaystyle\\frac{1}{C}\\sum_{i\\in C}\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)+\\theta^{t}-\\overline{\\theta}^{t}\\rangle}\\\\ &{=\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\|\\overline{\\theta}^{t+1}-\\overline{\\theta}^{t}\\|^{2}-\\mathbb{E}_{t}\\langle\\nabla f(\\overline{\\theta}^{t}),\\displaystyle\\frac{1}{C}\\sum_{i\\in C}\\frac{1}{\\rho}\\left(\\nabla f_{i}(\\theta_{i}^{t+1})+\\lambda_{i}^{t}-e\\right)-\\frac{1}{\\rho}\\overline{\\lambda}^{t}\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}-\\mathbb{E}_{t}\\langle\\nabla f(\\overline{{\\theta}}^{t}),\\frac{1}{C}\\sum_{i\\in C}\\frac{1}{\\rho}\\nabla f_{i}(\\theta_{i}^{t+1})\\rangle}\\\\ &{\\le\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}+\\frac{1}{2\\rho}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})-\\frac{1}{C}\\sum_{i\\in C}\\nabla f_{i}(\\theta_{i}^{t+1})\\Vert^{2}-\\frac{1}{2\\rho}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}}\\\\ &{\\le\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}+\\frac{1}{2\\rho}\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\nabla f_{i}(\\overline{{\\theta}}^{t})-\\nabla f_{i}(\\theta_{i}^{t+1})\\Vert^{2}-\\frac{1}{2\\rho}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}}\\\\ &{\\le\\displaystyle\\frac{L}{2}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t+1}-\\overline{{\\theta}}^{t}\\Vert^{2}+\\frac{L^{2}}{2\\rho}\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t}-\\theta_{i}^{t+1}\\Vert^{2}-\\frac{1}{2\\rho}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}}\\\\ &{\\le\\displaystyle\\frac{L}{2}\\left(1+\\frac{L}{\\rho}\\right)\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}_{t}\\Vert\\overline{{\\theta}}^{t}-\\theta_{i}^{t+1}\\Vert^{2}-\\frac{1}{2\\rho}\\mathbb{E}_{t}\\Vert\\nabla f(\\overline{{\\theta}}^{t})\\Vert^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "To simplify the expression, we define $\\begin{array}{r}{R_{t}=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t+1}-\\overline{{\\theta}}^{t}\\|^{2},J_{t}=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{t}-\\overline{{\\theta}}^{t}\\|^{2}}\\end{array}$ . Actually from Lemma 2 and 3, we can reconstruct the relationship as: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\{\\mathbb{E}_{t}\\left[f(\\overline{{\\theta}}^{t+1})\\right]\\right.}&{\\leq f(\\overline{{\\theta}}^{t})+\\frac{L}{2}\\left(1+\\frac{L}{\\rho}\\right)R_{t}-\\frac{1}{2\\rho}\\mathbb{E}_{t}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2},}\\\\ {\\left(1-\\frac{4L^{2}}{\\rho^{2}}\\right)R_{t}}&{\\leq\\frac{32L^{2}}{\\rho^{2}}R_{t-1}+\\frac{4L^{2}}{\\rho^{2}}\\mathbb{E}_{t}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}+\\frac{4\\epsilon}{\\rho^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let the second inequality be multiplied by $q$ and add it to the first, we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{t}\\left[f(\\overline{{\\theta}}^{t+1})\\right]+\\left[q\\left(1-\\frac{4L^{2}}{\\rho^{2}}\\right)-\\frac{L}{2}\\left(1+\\frac{L}{\\rho}\\right)\\right]R_{t}}\\\\ &{\\leq f(\\overline{{\\theta}}^{t})+q\\frac{32L^{2}}{\\rho^{2}}R_{t-1}-\\left(\\frac{1}{2\\rho}-\\frac{4q L^{2}}{\\rho^{2}}\\right)\\mathbb{E}_{t}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}+\\frac{4q\\epsilon}{\\rho^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then we discuss the selection of q. First, let21\u03c1 \u22124q\u03c12L2 > 0 be positive, which requires q < 8\u03c1L2 . Then we let the following relationship hold: ", "page_idx": 22}, {"type": "equation", "text": "$$\nq\\left(1-\\frac{4L^{2}}{\\rho^{2}}\\right)-\\frac{L}{2}\\left(1+\\frac{L}{\\rho}\\right)=q\\frac{32L^{2}}{\\rho^{2}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus it requires $\\begin{array}{r}{2q=\\frac{L(\\rho^{2}+\\rho L)}{\\rho^{2}-36L^{2}}<\\frac{\\rho}{4L^{2}}}\\end{array}$ . We can solve this to get the range of the coefficient $\\rho$ as: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\rho^{2}-4L^{3}\\rho-36L^{2}-4L^{4}>0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then $\\rho>\\mathcal{O}(L^{3})$ satisfies all the conditions above. ", "page_idx": 22}, {"type": "text", "text": "Therefore, let $\\begin{array}{r}{q=\\frac{\\rho}{32L^{2}}}\\end{array}$ and then $\\begin{array}{r}{q\\frac{32L^{2}}{\\rho^{2}}=\\frac{1}{\\rho}}\\end{array}$ . By further relaxing the last coefficient we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t}\\left[f(\\overline{{\\theta}}^{t+1})\\right]+\\frac{1}{\\rho}R_{t}\\leq f(\\overline{{\\theta}}^{t})+\\frac{1}{\\rho}R_{t-1}-\\frac{1}{\\rho}\\mathbb{E}_{t}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}+\\frac{\\epsilon}{8L^{2}\\rho}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Taking the full expectation and accumulating the above inequality from $t=0$ to $T-1$ , we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\|\\nabla f(\\overline{{\\theta}}^{t})\\|^{2}\\leq\\frac{f(\\overline{{\\theta}}^{1})-\\mathbb{E}\\left[f(\\overline{{\\theta}}^{T+1})\\right]}{T}+\\frac{R_{0}-R_{T}}{\\rho T}+\\frac{\\epsilon}{8L^{2}\\rho}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{\\rho\\left[f(\\overline{{\\theta}}^{1})-f^{\\star}\\right]+R_{0}}{T}+\\frac{\\epsilon}{8L^{2}\\rho}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In the last inequality, $f^{\\star}$ is the optimum of the function $f$ . For the $R_{-1}$ term, we have $R_{0}\\ =$ $\\begin{array}{r}{\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{1}-\\overline{{\\theta}}^{0}\\|^{2}=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}_{t}\\|\\theta_{i}^{1}-\\theta^{0}\\|^{2}}\\end{array}$ for $\\theta^{0}=\\overline{{{\\theta}}}^{0}$ . ", "page_idx": 22}, {"type": "text", "text": "Discussions of the optimization errors. We show some classical results of the generalization errors in the following Table 7. Zhang et al. [2021] provides a first optimization analysis for the federated primal-dual methods. However, it requires all clients to participate in the training in each round (do not support partial participation). Wang et al. [2022], Gong et al. [2022] proposes to adopt partial participation for the federated primal-dual method and adopt a stronger assumption on the local solution. It proves that even though each local solution is different, the total optimization error can be bounded by the average of the trajectory of each local client. However, the initial bias may be affected by the factor $C$ under some special learning rate. Durmus et al. [2021] further provides a variant to calculate the global dual variable. It provides a lower constant for the $D$ term, which is ${\\frac{C}{P}}D$ (faster than $C D$ in FedADMM). Our proposed method A-FedPD updates the virtual dual variables, which could approximate the full-participation training under the partial participation case. Therefore, compared with the result in [Durmus et al., 2021], we further provide a faster constant for the term $D$ ( $\\frac{C}{P}\\stackrel{\\bullet}{\\times}$ faster than FedDyn on the first term when $\\rho$ is selected properly). If the initialization bias $D$ dominates the optimization errors, i.e. training from scratch, A-FedPD can greatly improve the training efficiency. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/965465083bb37b02b40bed69d2c6bfdcba62734c2abca829c6387aa859a08b63.jpg", "table_caption": ["Table 7: Optimization rate of federated smooth non-convex objectives. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Our Improvements. In [Zhang et al., 2021], it must rely on the full participation. In [Gong et al., 2022, Wang et al., 2022], the impact of the initial bias is $\\frac{\\d C}{\\d P}$ times. In [Durmus et al., 2021], it must rely on the local exact solution, which is an extremely ideal condition. Our results can achieve the $\\mathcal{O}\\!\\left(\\frac{1}{T}\\right)$ rate under the general assumptions and support the partial participation case. ", "page_idx": 23}, {"type": "text", "text": "B.3 Generalization ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "B.3.1 Important Lemmas ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this part, we mainly introduce some important lemmas adopted in our proofs. Let \u02c6\u00b7 be the corresponding variable trained on the dataset C\u02c6, and then we can explore the gaps of corresponding terms. We first consider the stability definition. ", "page_idx": 23}, {"type": "text", "text": "Lemma 4 (Hardt et al. [2016]) Under Assumption $^{l}$ and 2, the model $\\theta^{T}$ and $\\hat{\\theta}^{T}$ are generated on the two different datasets $\\mathcal{C}$ and $\\hat{\\mathcal{C}}$ with the same algorithm. We can track the difference between these two sequences. Before we first select the different sample pairs, the difference is always 0. Therefore, we define an event $\\zeta$ to measure whether $\\theta^{T}\\,=\\,{\\hat{\\theta}}^{T}$ still holds at $\\tau_{0}$ -th round. Let $\\begin{array}{r}{H=\\operatorname*{sup}_{\\theta,\\xi}f(\\theta,\\xi)\\stackrel{}{<}+\\infty,}\\end{array}$ if the algorithm is uniform stable, we can measure its uniform stability by: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\epsilon_{G}\\leq\\operatorname*{sup}_{\\mathcal{C},\\hat{\\mathcal{C}},}\\mathbb{E}\\left[f(\\theta^{T},\\xi)-f(\\hat{\\theta}^{T},\\xi)\\right]\\leq G\\mathbb{E}\\|\\theta^{T}-\\hat{\\theta}^{T}\\|+\\frac{H P\\tau_{0}}{C S}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. By expanding the inequality, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\left[|f(\\theta^{T},\\xi)-f(\\hat{\\theta}^{T},\\xi)|\\right]}\\\\ &{\\leq P(\\zeta)\\mathbb{E}\\left[|f(\\theta^{T},\\xi)-f(\\hat{\\theta}^{T},\\xi)|\\mid\\zeta\\right]+P(\\zeta^{c})\\mathbb{E}\\left[|f(\\theta^{T},\\xi)-f(\\hat{\\theta}^{T},\\xi)|\\mid\\zeta^{c}\\right]}\\\\ &{\\leq G\\mathbb{E}\\left[\\|\\theta^{T}-\\hat{\\theta}^{T}\\|\\mid\\zeta\\right]+H P(\\zeta^{c}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Here we assume that the difference pairs are selected on $\\tau$ -th round, therefore we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\nP(\\zeta^{c})=P(\\tau\\leq\\tau_{0})\\leq\\sum_{t=0}^{\\tau_{0}}P(\\tau=t)=\\sum_{t=0}^{\\tau_{0}}P(i^{\\star}\\in\\mathcal{P}^{t})P(j^{\\star})\\leq\\frac{P\\tau_{0}}{C S}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This completes the proofs. ", "page_idx": 23}, {"type": "text", "text": "Specifically, because $\\mathcal{C}$ only differs from $\\hat{\\mathcal{C}}$ on client $i^{\\star}$ , we could bound each term on two different situations respectively. ", "page_idx": 24}, {"type": "text", "text": "We consider the difference of the local updates on the client $i$ $(i\\neq i^{\\star}$ ). ", "page_idx": 24}, {"type": "text", "text": "Lemma 5 Under Assumption $I$ , we can bound the difference of the local updates on the active client $i\\;(i\\neq i^{\\star})$ . The local update satisfies: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Vert\\left(\\theta_{i,k+1}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k+1}^{t}-\\hat{\\theta}^{t}\\right)\\Vert\\leq\\eta^{t}K L\\mathbb{E}\\Vert\\theta^{t}-\\hat{\\theta}^{t}\\Vert+\\eta^{t}K\\mathbb{E}\\Vert\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\Vert.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Reconstructing Eq.(13) we can get the following iteration relationship: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\theta_{i,k+1}^{t}-\\theta^{t}=\\left(1-\\eta^{t}\\rho\\right)\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\eta^{t}\\left(g_{i,k}^{t}+\\lambda_{i}^{t}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "On each client $i$ $(i\\neq i^{\\star}.$ ), each data sample is the same, thus we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\|\\left(\\theta_{i,k+1}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k+1}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ &{=\\mathbb{E}\\|\\left(1-\\eta^{t}\\rho\\right)\\left[\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\right]-\\eta^{t}\\left(g_{i,k}^{t}-\\hat{g}_{i,k}^{t}\\right)-\\eta^{t}\\left(\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\right)\\|}\\\\ &{\\leq\\left(1-\\eta^{t}\\rho\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+\\eta^{t}L\\mathbb{E}\\|\\theta_{i,k}^{t}-\\hat{\\theta}_{i,k}^{t}\\|+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|}\\\\ &{\\leq\\left(1-\\eta^{t}\\rho_{L}\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+\\eta^{t}L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\rho_{L}=\\rho-L$ is a constant. ", "page_idx": 24}, {"type": "text", "text": "Unrolling the recursion from $k=0$ to $K-1$ , and adopting the factors $\\theta_{i}^{t+1}=\\theta_{i,k}^{t}$ and $\\theta_{i,0}^{t}=\\theta^{t}$ , we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|=\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ &{\\le\\left[\\displaystyle\\prod_{k=0}^{K-1}\\left(1-\\eta^{t}\\rho_{L}\\right)\\right]\\mathbb{E}\\|\\left(\\theta_{i,0}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,0}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ &{\\quad+\\displaystyle\\sum_{k=0}^{K-1}\\eta^{t}\\left[\\displaystyle\\prod_{j=k+1}^{K-1}\\left(1-\\eta^{t}\\rho_{L}\\right)\\right]\\left(L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|\\right)}\\\\ &{=\\displaystyle\\sum_{k=0}^{K-1}\\eta^{t}\\left[\\displaystyle\\prod_{j=k+1}^{K-1}\\left(1-\\eta^{t}\\rho_{L}\\right)\\right]\\left(L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Simplifying the relationships, we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|=\\frac{1-\\left(1-\\eta^{t}\\rho_{L}\\right)^{K}}{\\rho_{L}}\\left(L\\mathbb{E}\\|\\theta^{T}-\\hat{\\theta}^{T}\\|+\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\eta^{t}K L\\mathbb{E}\\|\\theta^{T}-\\hat{\\theta}^{T}\\|+\\eta^{t}K\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The last inequality adopts the Bernoulli inequality $\\left(1+x\\right)^{K}\\geq1+K x$ for $K\\geq1$ and $x\\geq-1$ . ", "page_idx": 24}, {"type": "text", "text": "Then we consider the difference of the local updates on client $i^{\\star}$ . ", "page_idx": 24}, {"type": "text", "text": "Lemma 6 Under Assumption $I$ and 2, we can bound the difference of the local updates on the active client $i^{\\star}$ . The local update satisfies: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Vert\\left(\\theta_{i,k+1}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k+1}^{t}-\\hat{\\theta}^{t}\\right)\\Vert\\leq\\eta^{t}K L\\mathbb{E}\\Vert\\theta^{t}-\\hat{\\theta}^{t}\\Vert+\\eta^{t}K\\mathbb{E}\\Vert\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\Vert+\\frac{2\\eta^{t}K G}{s}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Reconstructing Eq.(13) we can get the following iteration relationship: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\theta_{i,k+1}^{t}-\\theta^{t}=\\left(1-\\eta^{t}\\rho\\right)\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\eta^{t}\\left(g_{i,k}^{t}+\\lambda_{i}^{t}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lemma $^{5}$ shows the recursive formulation when we select the same data sample. However, on the client $i^{\\star}$ , it also may select the different sample pairs. Therefore, we first study the recursive ", "page_idx": 24}, {"type": "text", "text": "formulation of this situation. When the stochastic gradients are calculated with different sample pairs $(\\xi,\\hat{\\xi})$ , we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\|\\left(\\theta_{i,k+1}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k+1}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ &{=\\mathbb{E}\\|\\left(1-\\eta^{t}\\rho\\right)\\left[\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\right]-\\eta^{t}\\left(g_{i,k}^{t}-\\hat{g}_{i,k}^{t}\\right)-\\eta^{t}\\left(\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\right)\\|}\\\\ &{\\leq\\left(1-\\eta^{t}\\rho\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+2\\eta^{t}G+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For every single sample, the probability of selecting the $\\xi_{j^{\\star}}$ is $\\textstyle{\\frac{1}{S}}$ . Therefore, combining Lemma 5, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\|\\left(\\theta_{i,k+1}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k+1}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ &{\\leq\\left(1-\\displaystyle\\frac{1}{S}\\right)\\left[\\left(1-\\eta^{t}\\rho_{L}\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+\\eta^{t}L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|\\right]}\\\\ &{\\quad+\\displaystyle\\frac{1}{S}\\left[\\left(1-\\eta^{t}\\rho\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+2\\eta^{t}G+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|\\right]}\\\\ &{\\le\\left(1-\\eta^{t}\\rho_{L}\\right)\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|+\\eta^{t}L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\eta^{t}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|+\\displaystyle\\frac{2\\eta^{t}G}{s}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Generally, we consider the size of samples $S$ to be large enough. In current deep learning, the dataset adopted usually maintains even millions of samples, which indicates that $1-\\mathit{\\Pi}_{\\overline{{S}}}^{1}\\to1$ . ", "page_idx": 25}, {"type": "text", "text": "Unrolling the recursion from $k=0$ to $K-1$ and adopting the $\\theta_{i}^{t+1}=\\theta_{i,K}^{t}$ and $\\theta_{i,0}^{t}=\\theta^{t}$ , we have a similar relationship: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|=\\mathbb{E}\\|\\left(\\theta_{i,k}^{t}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i,k}^{t}-\\hat{\\theta}^{t}\\right)\\|}\\\\ {\\leq\\displaystyle\\sum_{k=0}^{K-1}\\eta^{t}\\left[\\displaystyle\\prod_{j=k+1}^{K-1}\\left(1-\\eta^{t}\\rho_{L}\\right)\\right]\\left(L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|+\\displaystyle\\frac{2G}{s}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Simplifying the relationships, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|=\\frac{1-\\left(1-\\eta^{t}\\rho_{L}\\right)^{K}}{\\rho_{L}}\\left(L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|+\\frac{2G}{s}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\eta^{t}K L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\eta^{t}K\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|+\\frac{2\\eta^{t}K G}{s}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The last inequality adopts the Bernoulli inequality. ", "page_idx": 25}, {"type": "text", "text": "B.3.2 Proofs ", "text_level": 1, "page_idx": 25}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/03f26d7df95691af1eb1f7de6078dc13d5e06f3a0c8758a125aeed27b9cb520d.jpg", "table_caption": ["Table 8: Notations in the proofs. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "In this part, we mainly introduce the proof of the main theorems. Combining the local updates and global updates, we can further upper bound both the primal and dual variables. Before proving the theorems, we first introduce the notations of updates of the global parameters and dual variables in Table 8. ", "page_idx": 25}, {"type": "text", "text": "$\\Delta^{t}$ measures the difference of the primal models during the training. $\\delta^{t}$ is the local separate difference when the local objective is solved. $\\sigma^{t}$ measures the difference of the dual gaps. $\\bar{\\pi}^{t}$ measures the difference of the local updates, which is also an important variable to connect global variables and dual variables. In our proofs, we first discuss the process of the primal variables and dual variables respectively. Then we can use the $\\pi$ term to construct an inequality to eliminate redundant terms, which could further provide the recursive relationship of the primal variables and dual variables separately. Next, we introduce these three processes one by one. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "From the global updates, according to the global aggregation and let $\\mathbb{I}_{i}$ be the indicator function, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\Delta}\\mathrm{x}^{t+1}=\\mathbb{E}\\|\\theta^{t+1}-\\hat{\\theta}^{t+1}\\|=\\mathbb{E}\\|\\displaystyle\\frac{1}{P}\\sum_{i\\in\\mathcal{P}^{t}}\\left(\\theta_{i}^{t+1}-\\hat{\\theta}_{i}^{t+1}\\right)+\\displaystyle\\frac{1}{\\rho}\\left(\\overline{{\\lambda}}_{i}^{t+1}-\\frac{\\hat{\\lambda}_{i}^{t+1}}{\\hat{\\lambda}_{i}}\\right)\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{1}{P}\\mathbb{E}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}\\|\\theta_{i}^{t+1}-\\hat{\\theta}_{i}^{t+1}\\|\\cdot\\mathbb{I}_{i}+\\displaystyle\\frac{1}{\\rho}\\mathbb{E}\\|\\overline{{\\lambda}}_{i}^{t+1}-\\hat{\\lambda}_{i}^{t+1}\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}\\|\\theta_{i}^{t+1}-\\hat{\\theta}_{i}^{t+1}\\|+\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\frac{1}{\\rho}\\mathbb{E}\\|\\overline{{\\lambda}}_{i}^{t+1}-\\hat{\\lambda}_{i}^{t+1}\\|\\leq\\delta^{t+1}+\\displaystyle\\frac{1}{\\rho}\\sigma^{t+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "From the dual updates, according to the local dual variable, we have two different cases. Combing the $D$ -Update we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\overline{{\\lambda}}^{t+1}=\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\lambda_{i}^{t+1}=\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\lambda_{i}^{t}+\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{P}^{t}}\\rho(\\theta_{i}^{t+1}-\\theta^{t})+\\displaystyle\\frac{1}{C}\\sum_{i\\notin\\mathcal{P}^{t}}\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t})}}\\\\ {{=\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\lambda_{i}^{t}+\\displaystyle\\frac{P}{C}\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t})+\\displaystyle\\frac{C-P}{C}\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t})=\\overline{{\\lambda}}^{t}+\\rho(\\overline{{\\theta}}^{t+1}-\\theta^{t}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Considering the randomness of selecting $\\mathcal{P}^{t}$ and expectation of $\\overline{{\\theta}}$ , we have $\\sigma^{t+1}\\leq\\sigma^{t}+\\rho\\pi^{t}$ . ", "page_idx": 26}, {"type": "text", "text": "Here we add the additional definition of the unparticipated clients. We let the $\\theta_{i}^{t+1}\\,=\\,\\theta^{t}$ where $i\\not\\in\\mathcal{P}^{t}$ , which enlarge the summation from $\\mathcal{P}^{t}$ to $\\mathcal{C}$ . Then we summarize Lemma 5 and 6 as the following formulation: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\pi^{t+1}=\\displaystyle\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|=\\displaystyle\\frac{1}{C}\\sum_{i\\in\\mathcal{P}^{t}}\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|}}\\\\ {{<\\eta^{t}K L\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|+\\eta^{t}K\\displaystyle\\frac{1}{C}\\sum_{i\\in C}\\mathbb{E}\\|\\lambda_{i}^{t}-\\hat{\\lambda}_{i}^{t}\\|+\\displaystyle\\frac{2\\eta^{t}K G}{C S}=c_{1}\\Delta^{t}+c_{2}\\sigma^{t}+c_{3}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, we can directly expand the $\\pi$ term by the triangle inequality: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\delta^{t+1}=\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}\\|\\theta_{i}^{t+1}-\\hat{\\theta}_{i}^{t+1}\\|}\\\\ {\\displaystyle\\qquad\\leq\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}\\|\\left(\\theta_{i}^{t+1}-\\theta^{t}\\right)-\\left(\\hat{\\theta}_{i}^{t+1}-\\hat{\\theta}^{t}\\right)\\|+\\frac{1}{C}\\sum_{i\\in\\mathcal{C}}\\mathbb{E}\\|\\theta^{t}-\\hat{\\theta}^{t}\\|=\\pi^{t+1}+\\Delta^{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combing the above recursive formulations, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l l l}{\\Delta^{t+1}}&{\\leq\\delta^{t+1}+\\frac{1}{\\rho}\\sigma^{t+1},}\\\\ {\\sigma^{t+1}}&{\\leq\\sigma^{t}+\\rho\\pi^{t+1},}\\\\ {\\delta^{t+1}}&{\\leq\\pi^{t+1}+\\Delta^{t},}\\\\ {\\pi^{t+1}}&{\\leq c_{1}\\Delta^{t}+c_{2}\\sigma^{t}+c_{3}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By multiplying three additional positive coefficients $\\alpha,\\,\\beta$ , and $\\gamma$ on the last three inequalities respectively, and adding them to the first one, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n{\\bf\\lambda}^{t+1}+\\left(\\alpha-\\frac{1}{\\rho}\\right)\\sigma^{t+1}+\\left(\\beta-1\\right)\\delta^{t+1}+\\left(\\gamma-\\alpha\\rho-\\beta\\right)\\pi^{t+1}\\leq\\left(\\beta+\\gamma c_{1}\\right)\\Delta^{t}+\\left(\\alpha+\\gamma c_{2}\\right)\\sigma^{t}+\\gamma c_{3}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By observing the LHS and RHS of the inequality, we notice that it could be summarized as a recursive formulation of $\\Delta^{t}$ and $\\sigma^{t}$ terms by selecting proper coefficients. Therefore, let the following conditions hold, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\beta-1\\geq0,}\\\\ {\\gamma-\\alpha\\rho-\\beta\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By simply selecting the minimal values of $\\beta=1$ and $\\gamma=1+\\alpha\\rho$ , we have: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta^{t+1}+\\left(\\alpha-\\displaystyle\\frac{1}{\\rho}\\right)\\sigma^{t+1}=\\Delta^{t+1}+\\left(\\alpha-\\displaystyle\\frac{1}{\\rho}\\right)\\sigma^{t+1}+\\left(\\beta-1\\right)\\delta^{t+1}+\\left(\\gamma-\\alpha\\rho-\\beta\\right)\\pi^{t+1}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\left(\\beta+\\gamma c_{1}\\right)\\Delta^{t}+\\left(\\alpha+\\gamma c_{2}\\right)\\sigma^{t}+\\gamma c_{3}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\left(1+\\gamma\\eta^{t}K L\\right)\\left(\\Delta^{t}+\\displaystyle\\frac{\\alpha+\\left(1+\\alpha\\rho\\right)\\eta^{t}K L}{1+\\left(1+\\alpha\\rho\\right)\\eta^{t}K L}\\right)+\\displaystyle\\frac{2\\gamma\\eta^{t}K G}{C S}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Here we further let \u03b1 \u2212\u03c11 \u22651\u03b1++((11++\u03b1\u03b1\u03c1\u03c1))\u03b7\u03b7ttKKL to support the above recursive relationships. To satisfy this, we can solve the following inequality: ", "page_idx": 27}, {"type": "equation", "text": "$$\nL(\\alpha\\rho)^{2}-\\rho(\\alpha\\rho)-\\bigg(L+\\rho+\\frac{1}{\\eta^{t}K}\\bigg)\\geq0.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "From the fundamental knowledge of quadratic equations, we know that there must exist a positive number belonging to interval $[x^{+},+\\infty]$ to satisfy the condition, where $x^{+}$ is the larger zero point of the equation Lx2 \u2212\u03c1x \u2212 L + \u03c1 +\u03b7t1K = 0. We can solve x+ = \u03c1+ \u03c12+4L2(LL+\u03c1+\u03b7t1K ) $\\begin{array}{r}{\\frac{\\rho+\\sqrt{(\\rho+2L)^{2}+\\frac{4L}{\\eta^{t}K}}}{2L}\\leq1+\\frac{\\rho}{L}+2\\sqrt{\\frac{L}{\\eta^{t}K}}}\\end{array}$ . When we select the proper $\\alpha\\rho\\geq x^{+}$ , the above inequality always holds. This also indicates that $\\begin{array}{r}{\\alpha\\,-\\,\\frac{1}{\\rho}\\,\\geq\\,\\frac{x^{+}-1}{\\rho}\\,>\\,\\frac{1}{L}}\\end{array}$ . Here we denote $\\begin{array}{r}{\\alpha_{\\rho}\\,=\\,\\alpha\\,-\\,\\frac{1}{\\rho}}\\end{array}$ and the previous definition $\\gamma=1+\\alpha\\rho$ as two constant coefficients, we can simplify the final iteration relationship as: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\Delta^{t+1}+\\alpha_{\\rho}\\sigma^{t+1}\\leq\\left(1+\\gamma\\eta^{t}K L\\right)\\left(\\Delta^{t}+\\alpha_{\\rho}\\sigma^{t}\\right)+\\frac{\\gamma\\eta^{t}K G}{C S}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Unrolling this from $t=\\tau_{0}$ to $T-1$ and adopting the factors of $\\Delta^{\\tau_{0}}=0$ and $\\lambda^{\\tau_{0}}=0$ , we have: ", "page_idx": 27}, {"type": "text", "text": "(1) When the global learning rate is selected as a constant $\\eta^{t}=\\eta_{0}^{t}$ where the initial learning rate $\\begin{array}{r}{\\dot{\\eta}_{0}^{t}\\leq\\frac{1}{K L}}\\end{array}$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\Delta^{T}+\\alpha_{\\rho}\\lambda^{T}\\leq\\sum_{t=\\tau_{0}}^{T-1}\\left(1+\\gamma\\eta_{0}^{t}K L\\right)^{t}\\frac{2\\gamma\\eta_{0}^{t}K G}{C S}<\\frac{2G\\left(1+\\gamma\\right)^{T}}{L C S}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(2) When the global learning rate is selected as a decayed sequence $\\begin{array}{r}{\\eta^{t}\\,=\\,\\frac{\\eta_{0}}{t+1}}\\end{array}$ where the initial learning rate $\\begin{array}{r}{\\eta_{0}\\leq\\frac{\\mu}{\\gamma K}}\\end{array}$ where $\\mu$ is a positive constant, we have: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\lambda}^{T}+\\alpha_{\\rho}\\lambda^{T}\\leq\\displaystyle\\sum_{t=\\tau_{0}}^{T-1}\\left(\\prod_{j=t}^{T-1}\\left(1+\\frac{\\gamma\\eta_{0}^{t}K L}{j+1}\\right)\\right)\\frac{2\\gamma\\eta_{0}^{t}K G}{C S(t+1)}\\leq\\sum_{t=\\tau_{0}}^{T-1}\\exp\\left(\\gamma\\eta_{0}^{t}K L\\ln\\left(\\frac{T}{t+1}\\right)\\right)\\frac{2\\gamma\\eta_{0}^{t}K L}{C S(t+1)}\\leq\\eta_{0}^{t},}\\\\ &{\\mathrm{\\lambda}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\frac{2\\gamma\\eta_{0}^{t}K G T^{\\gamma\\eta_{0}^{t}K L}}{C S}\\displaystyle\\sum_{t=\\tau_{0}}^{T-1}\\left(\\frac{1}{t+1}\\right)^{1+\\gamma\\eta_{0}^{t}K L}<\\frac{2G}{L C S}\\left(\\frac{T}{\\tau_{0}}\\right)^{\\mu L}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Here we mainly focus on the case of the decayed learning rates. According to Lemma 4, we have: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\varepsilon_{G}\\leq G\\Delta^{T}+\\frac{H P\\tau_{0}}{C S}\\leq\\frac{2G^{2}}{L C S}\\left(\\frac{T}{\\tau_{0}}\\right)^{\\mu L}+\\frac{H P\\tau_{0}}{C S}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By selecting the proper $\\begin{array}{r}{\\tau_{0}=\\left(\\frac{2G^{2}}{H P L}\\right)^{\\frac{1}{1+\\mu L}}T^{\\frac{\\mu L}{1+\\mu L}}}\\end{array}$ , we can get the minimal error bound as: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\varepsilon_{G}\\leq\\frac{2}{C S}\\left(\\frac{2G^{2}}{L}\\right)^{\\frac{1}{1+\\mu L}}(H P T)^{\\frac{\\mu L}{1+\\mu L}}\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Discussions of the generalization errors. We show some general results of the generalization errors in the following Table 9. We prove that the federated primal-dual family can benefit from the local interval $K$ than the vanilla SGD methods, which is one of the key properties of the primal-dual methods. ", "page_idx": 28}, {"type": "table", "img_path": "h1iMVi2iEM/tmp/d820f51aebc493bda501b17c33a6c008dcdec5fe29c07e52216c160b7dc49c08.jpg", "table_caption": ["Table 9: Generalization error bounds of smooth non-convex objectives. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We illustrate the dual drift issues and propose the A-FedPD with the virtual updates of the dual variables. We prove its efficiency from the optimization and generalization analysis. Extensive experiments are conducted to validate its performance. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We discuss the storage cost limitations at the beginning of the Appendix. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We introduce all assumptions in our analysis and clearly note their adaptivity. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We submit our code demo to reproduce the experiments and all hyperparameters can be found in our paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We submit the code demo to reproduce the experiments. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We detail all selections of each hyperparameter in our paper with corresponding experiments. Some of them are based on the previous classical work, and we also note where they are adopted. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: In the performance comparison and main table, we report both mean accuracy with its variance under different random seeds. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We submitted the code demo and it has the instructions for reproducing the experiments. We report the hardware sources and time cost details in Appendix A.4.4. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: This research conducted in the paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: There is no obvious societal impact of the work performed since our research focuses more on general studies on the FL frameworks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper poses no such risks. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We cite all papers on the models and datasets used in our paper. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}]