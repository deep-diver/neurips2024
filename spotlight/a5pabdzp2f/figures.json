[{"figure_path": "A5pabdZp2F/figures/figures_1_1.jpg", "caption": "Figure 1: The FPR95 (lower is better) and AUROC (higher is better) on HMDB51 dataset across various modalities. Multimodal OOD substantially improves unimodal OOD w/o bells and whistles.", "description": "This figure displays the False Positive Rate at 95% true positive rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC) for different unimodal and multimodal out-of-distribution (OOD) detection methods on the HMDB51 dataset.  It demonstrates that using multiple modalities (e.g., video and optical flow) significantly improves OOD detection performance compared to using only a single modality.", "section": "1 Introduction"}, {"figure_path": "A5pabdZp2F/figures/figures_2_1.jpg", "caption": "Figure 2: An overview of MultiOOD Benchmark.", "description": "This figure provides a visual representation of the MultiOOD benchmark, which is a novel dataset designed for evaluating multimodal out-of-distribution (OOD) detection algorithms.  The benchmark consists of two main setups: Near-OOD and Far-OOD.  Near-OOD uses subsets of existing datasets to create in-distribution and out-of-distribution sets, while Far-OOD utilizes completely distinct datasets as the out-of-distribution data.  The image showcases the datasets used in each setup, along with visualizations of the types of modalities (video, optical flow, audio) included and the number of videos and classes per dataset.  The chart highlights the diversity in dataset sizes and modality combinations.", "section": "3 MultiOOD Benchmark"}, {"figure_path": "A5pabdZp2F/figures/figures_3_1.jpg", "caption": "Figure 3: An example of softmax outputs for ID and OOD data. The predictions from video and optical flow demonstrate uniformity across ID data and exhibit variability across OOD data.", "description": "This figure illustrates the Modality Prediction Discrepancy phenomenon.  It shows softmax prediction probabilities for both video and optical flow modalities for both in-distribution (ID) and out-of-distribution (OOD) data. The left panel (a) displays the predictions for ID data, showing high agreement between the video and flow predictions, indicating a small L1 distance between them. The right panel (b) shows the predictions for OOD data, where the video and flow predictions show significant disagreement and larger L1 distance.  This highlights that the discrepancy in predictions between different modalities is negligible for ID data but significant for OOD data. This discrepancy is used as the basis for the Agree-to-Disagree (A2D) algorithm proposed in the paper.", "section": "4.1 Modality Prediction Discrepancy"}, {"figure_path": "A5pabdZp2F/figures/figures_4_1.jpg", "caption": "Figure 4: Average prediction L\u2081 distances between ID and OOD data (lOOD \u2013 lID) before and after A2D training across various datasets within the MultiOOD, where Energy [43] is used as score function. The distances are highly correlated to the ultimate OOD performance. A2D training amplifies such distances, consequently enhancing the efficacy of OOD detection.", "description": "This figure shows the strong correlation between the average L1 distance of prediction probabilities between in-distribution (ID) and out-of-distribution (OOD) data and the OOD detection performance (AUROC).  The left panel shows the L1 distances *before* A2D training, and the right panel shows them *after* A2D training.  The A2D algorithm increases the L1 distances between ID and OOD data, leading to improved OOD detection performance. This visually demonstrates the effectiveness of the A2D algorithm in enhancing the discrepancy between ID and OOD data.", "section": "4.1 Modality Prediction Discrepancy"}, {"figure_path": "A5pabdZp2F/figures/figures_5_1.jpg", "caption": "Figure 5: An overview of the proposed framework for Multimodal OOD Detection. We introduce A2D algorithm to encourage enlarging the prediction discrepancy across modalities. Additionally, we propose a novel outlier synthesis algorithm, NP-Mix, designed to explore broader feature spaces, which complements A2D to strengthen the OOD detection performance.", "description": "This figure illustrates the proposed framework for multimodal out-of-distribution (OOD) detection.  The top half shows the Agree-to-Disagree (A2D) algorithm which aims to maximize the discrepancy in prediction probabilities between modalities for out-of-distribution samples while maintaining agreement for in-distribution samples.  The bottom half depicts the Nearest Prototype Mixup (NP-Mix) outlier synthesis method which generates synthetic outliers by mixing prototypes from nearest neighbor classes, thereby exploring broader feature spaces to improve OOD detection performance. Both A2D and NP-Mix work together to enhance the overall accuracy of the multimodal OOD detection system.", "section": "4 Methodology"}, {"figure_path": "A5pabdZp2F/figures/figures_14_1.jpg", "caption": "Figure 6: Visualization of action recognition datasets used in our MultiOOD benchmark.", "description": "This figure shows sample frames from the five action recognition datasets used in the MultiOOD benchmark: EPIC-Kitchens, HAC, HMDB51, UCF101, and Kinetics-600.  Each dataset contains videos depicting various human actions, and the images provide a visual representation of the diversity in action types and visual characteristics across the datasets.  The diversity is important because it allows for a more robust evaluation of multimodal OOD detection methods.", "section": "B More Details on the MultiOOD Benchmark"}, {"figure_path": "A5pabdZp2F/figures/figures_15_1.jpg", "caption": "Figure 7: Visualization of synthesized outliers compared against other methods. VOS and NPOS tend to generate outliers near the ID data, neglecting to explore the broader embedding space. Mixup randomly selects samples from all classes to mix and inadvertently introduces unwanted noise samples within the distribution of ID data. NP-Mix excels at generating synthesized outliers by effectively utilizing information from neighbor classes and spanning wider embedding spaces.", "description": "This figure compares the outlier synthesis methods VOS, NPOS, Mixup and NP-Mix. VOS and NPOS tend to generate outliers close to the in-distribution data.  Mixup randomly mixes samples from all classes, potentially adding noise.  NP-Mix, by contrast, leverages information from nearest neighbor classes to generate outliers that explore a broader feature space.", "section": "4.3 Nearest Neighbor Prototype-based Mixup for Outlier Synthesis"}, {"figure_path": "A5pabdZp2F/figures/figures_16_1.jpg", "caption": "Figure 8: Score distributions of different baseline methods on the HMDB51 25/26 dataset before and after training with A2D and NP-Mix.", "description": "This figure compares the score distributions of in-distribution (ID) and out-of-distribution (OOD) data for several baseline methods (Energy, ASH, KNN, LogitNorm) before and after training with the proposed A2D and NP-Mix techniques. The goal is to show how the A2D and NP-Mix methods improve the separation between ID and OOD data, making it easier to distinguish between them. The improved separation is evident in the plots (e) to (h), where the distributions of ID and OOD scores have less overlap compared to the plots (a) to (d).", "section": "Visualization of Results"}, {"figure_path": "A5pabdZp2F/figures/figures_16_2.jpg", "caption": "Figure 9: Visualization of the learned embeddings on ID and OOD data using t-SNE on the HMDB51 25/26 dataset before and after training with A2D and NP-Mix.", "description": "This figure shows the visualization of the learned embeddings using t-SNE on the HMDB51 25/26 dataset.  Subfigure (a) shows the embeddings before training with the A2D and NP-Mix methods, while subfigure (b) displays the embeddings after training with these methods. The visualization helps illustrate the impact of A2D and NP-Mix on the separability of in-distribution (ID) and out-of-distribution (OOD) data in the learned feature space.  The better separation in (b) suggests that A2D and NP-Mix improve the model's ability to distinguish between ID and OOD samples.", "section": "Visualization of Results"}, {"figure_path": "A5pabdZp2F/figures/figures_20_1.jpg", "caption": "Figure 10: Influences of Mixup \u03b1 for OOD performance in NP-Mix.", "description": "This figure shows the impact of the hyperparameter \u03b1 in the NP-Mix outlier synthesis method on the out-of-distribution (OOD) detection performance.  Two metrics are plotted against different values of \u03b1: the False Positive Rate at 95% true positive rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC).  The results show that the optimal value of \u03b1 depends on the specific OOD algorithm and dataset used but in the case of Energy and Energy++,  performance is relatively stable.", "section": "5.4 Ablation Studies"}, {"figure_path": "A5pabdZp2F/figures/figures_20_2.jpg", "caption": "Figure 10: Influences of Mixup  \u03b1  for OOD performance in NP-Mix.", "description": "The figure shows the impact of the hyperparameter \u03b1 in the NP-Mix outlier synthesis method on the out-of-distribution (OOD) detection performance.  The left plot displays the false positive rate (FPR95) while the right plot shows the area under the receiver operating characteristic curve (AUROC). Both plots show the results for different values of \u03b1 (2, 4, 10) for the baseline Energy method and the Energy++ method (which incorporates A2D and NP-Mix). The results show that the optimal value of \u03b1  depends on the specific OOD detection method used.", "section": "Ablation Studies"}, {"figure_path": "A5pabdZp2F/figures/figures_22_1.jpg", "caption": "Figure 1: The FPR95 (lower is better) and AUROC (higher is better) on HMDB51 dataset across various modalities. Multimodal OOD substantially improves unimodal OOD w/o bells and whistles.", "description": "This figure displays the performance of different OOD detection methods on the HMDB51 dataset using various modalities (Flow, Video, and Video+Flow). The bars represent the False Positive Rate at 95% True Positive Rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC). The results show that multimodal OOD detection significantly outperforms unimodal methods, demonstrating the benefits of incorporating multiple modalities for improved OOD detection performance.", "section": "1 Introduction"}, {"figure_path": "A5pabdZp2F/figures/figures_22_2.jpg", "caption": "Figure 12: Experiments using three random seeds for Multimodal Near-OOD Detection on the HMDB51 25/26. Foreground points in bold show results averaged across three different seeds while background points, shown feint, indicate results from the underlying individual seeds.", "description": "This figure shows the results of Multimodal Near-OOD detection experiments on the HMDB51 25/26 dataset using three different random seeds. The results are presented for four different OOD detection methods (Energy, GEN, KNN, VIM).  The bold foreground points represent the average performance across the three seeds, while the fainter background points represent the individual results from each seed. The figure allows for the visual comparison of the performance consistency and variability across different random seeds for each method.  It highlights the impact of using A2D and NP-Mix on the OOD detection performance.", "section": "5.2 Multimodal Near-OOD Detection"}]