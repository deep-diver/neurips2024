[{"figure_path": "ZEVDMQ6Mu5/figures/figures_1_1.jpg", "caption": "Figure 1: Visualizing low and high input curvature samples from a ResNet50 trained on ImageNet. Low input curvature training set images are prototypical and have lots of support in the trainset, while high input curvature train set examples have less support and are atypical. Test set examples lie around the training set images in higher curvature regions.", "description": "This figure visualizes the concept of input loss curvature in the context of ImageNet. It shows that low-curvature training examples are prototypical images with lots of similar images in the training set, while high-curvature training examples are less common or atypical, thus the model is less confident and memorizes them. Test examples tend to fall in higher-curvature regions which is slightly off from the flat minima, representing less confident prediction and memorization.", "section": "1 Introduction"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_4_1.jpg", "caption": "Figure 2: Marginal curvature score histogram for all images in ImageNet when samples in train set vs test set.", "description": "This figure shows the distribution of input loss curvature scores for both training and testing datasets from ImageNet.  The x-axis represents the log of the curvature score, and the y-axis represents the count of images. The distribution for the test set is shifted towards higher curvature values (to the right), indicating a difference in curvature between training and testing examples. This difference in curvature is leveraged for membership inference attacks.", "section": "4 Theoretical Analysis"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_4_2.jpg", "caption": "Figure 2: Marginal curvature score histogram for all images in ImageNet when samples in train set vs test set.", "description": "This figure shows the distribution of input loss curvature scores for training and testing samples from the ImageNet dataset.  The histogram visually compares the frequency of different curvature values between the train and test sets. The x-axis represents the curvature values, while the y-axis represents the normalized count or frequency. It helps to understand how curvature values differ between the sets that were used to train a model and the set used for testing a trained model.", "section": "4 Theoretical Analysis"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_7_1.jpg", "caption": "Figure 4: Comparing our method against existing techniques at low FPR. The proposed parametric Curv LR technique has the highest TPR at very low FPR.", "description": "This figure compares the performance of the proposed input loss curvature-based membership inference attack with several existing methods at low false positive rates (FPR).  The x-axis represents the false positive rate (FPR), and the y-axis represents the true positive rate (TPR).  The plot shows that the proposed parametric Curv LR technique significantly outperforms existing methods, achieving the highest true positive rate at very low false positive rates, indicating its effectiveness in identifying members of the training set even when the allowed error rate is very low.", "section": "6.2 Membership Inference"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_8_1.jpg", "caption": "Figure 6: Visualizing MIA performance as a function of the size of the train set, which is randomly sampled.", "description": "This figure shows how the performance of membership inference attacks (MIAs) changes as the size of the training dataset increases. The x-axis represents the fraction of the dataset used for training, while the y-axis shows the area under the receiver operating characteristic curve (AUROC), a common metric for evaluating the performance of binary classification. The plot compares the AUROC scores of the proposed curvature-based MIA method ('Curv ZO NLL' and 'Curv ZO LR') with two existing MIA methods ('Carlini et al.' and 'Yeom et al.'). It demonstrates that the performance of the proposed method generally decreases as the fraction of the dataset used for training increases, indicating that larger training sets make it more difficult to accurately determine whether a given data point was used during the training of the model.", "section": "6.4 Effect of Dataset Size"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_8_2.jpg", "caption": "Figure 6: Visualizing MIA performance as a function of the size of the train set, which is randomly sampled.", "description": "This figure shows how the performance of the membership inference attack (MIA) changes as the size of the training dataset increases. The x-axis represents the fraction of the dataset used for training, ranging from 0 to 0.9. The y-axis represents both the AUROC and the balanced accuracy, which are metrics used to measure the performance of the MIA. The figure includes two lines, one for AUROC (blue circles) and one for balanced accuracy (red circles), showing how each metric changes with the fraction of the training dataset used. The dotted lines represent a trendline showing the general pattern. The figure suggests that as more data is used for training, the performance of the MIA tends to decrease, indicating a potential improvement in privacy with larger training datasets.", "section": "6.4 Effect of Dataset Size"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_17_1.jpg", "caption": "Figure 6: Visualizing MIA performance as a function of the size of the train set, which is randomly sampled.", "description": "This figure shows how the True Positive Rate (TPR) of different membership inference attack (MIA) methods changes as the size of the training dataset varies.  The x-axis represents the fraction of the dataset used for training, while the y-axis shows the TPR at a 0.1% False Positive Rate (FPR).  It compares the performance of the proposed curvature-based MIA methods ('Curv ZO NLL' and 'Curv ZO LR') with existing state-of-the-art methods ('Carlini et al.' and 'Yeom et al.').  The plot illustrates how MIA effectiveness is affected by training set size.", "section": "6.4 Effect of Dataset Size"}, {"figure_path": "ZEVDMQ6Mu5/figures/figures_17_2.jpg", "caption": "Figure 9: Low TPR performance comparison on CIFAR100 of ZO estimation (Curv ZO, black-box) vs. Hutchinson (Curv, white-box).", "description": "This figure compares the performance of zero-order (ZO) estimation and Hutchinson's trace estimator for calculating input loss curvature in a membership inference attack.  The plot shows the True Positive Rate (TPR) against the False Positive Rate (FPR) on a log-log scale, emphasizing performance at low FPR.  The zero-order method is a black-box attack (no model parameters needed), while the Hutchinson method is white-box (requires model parameters). The comparison highlights the differences between the two approaches, particularly at very low FPRs.", "section": "A.9 ZO Estimation Performance"}]