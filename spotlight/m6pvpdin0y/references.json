{"references": [{"fullname_first_author": "Pierre Foret", "paper_title": "Sharpness-aware minimization for efficiently improving generalization", "publication_date": "2020-10-01", "reason": "This paper introduces Sharpness-Aware Minimization (SAM), a key algorithm analyzed and built upon in the current research."}, {"fullname_first_author": "James Martens", "paper_title": "Optimizing neural networks with Kronecker-factored approximate curvature", "publication_date": "2015-06-01", "reason": "This paper is foundational in the study of second-order optimization methods for neural networks, a crucial aspect of the current work."}, {"fullname_first_author": "Chris M Bishop", "paper_title": "Training with noise is equivalent to Tikhonov regularization", "publication_date": "1995-01-01", "reason": "This paper establishes a fundamental connection between adding noise during training and regularization, a concept relevant to the current research on sharpness regularization."}, {"fullname_first_author": "Atish Agarwala", "paper_title": "SAM operates far from home: Eigenvalue regularization as a dynamical phenomenon", "publication_date": "2023-07-15", "reason": "This very recent work by the current authors provides further insights into SAM and its connection to eigenvalue regularization, enriching the current paper's findings."}, {"fullname_first_author": "James Martens", "paper_title": "Learning recurrent neural networks with Hessian-free optimization", "publication_date": "2011-01-01", "reason": "This paper presents a significant approach to second-order optimization, which the current research uses as a point of comparison and contrast."}]}