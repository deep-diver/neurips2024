[{"figure_path": "zGN0YWy2he/tables/tables_5_1.jpg", "caption": "Table 1: Performance comparison on COCO-Stuff and Visual Genome datasets using Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) metrics. We report the results of methods with two generator structures, namely GAN- and Diffusion-based. The architecture of these methods is based on the layout (L) or semantics (S), while our approach includes both. The best results are bolded.", "description": "This table presents a quantitative comparison of the proposed DisCo model against several state-of-the-art GAN-based and diffusion-based image generation methods on two benchmark datasets: COCO-Stuff and Visual Genome.  The comparison focuses on two key metrics: Inception Score (IS) and Fr\u00e9chet Inception Distance (FID).  IS measures the quality and diversity of generated images, while FID assesses the similarity between generated and real images.  The table highlights DisCo's superior performance, outperforming existing models in both IS and FID scores, and showcasing the benefit of using a combined layout and semantics approach compared to models based solely on layout or semantics.", "section": "4 Experiments"}, {"figure_path": "zGN0YWy2he/tables/tables_6_1.jpg", "caption": "Table 2: Relationship and attribute generation compared with text-to-image methods on T2I-CompBench [35].", "description": "This table presents a comparison of the proposed DisCo model against several state-of-the-art text-to-image methods on the T2I-CompBench benchmark.  The benchmark evaluates the models' ability to generate images based on compositional prompts.  The table shows the performance of each method across four metrics: UniDet, CLIP, B-VQA, and 3-in-1, which assess the generation of spatial/non-spatial relationships, attributes, and complex scenes.", "section": "4 Experiments"}, {"figure_path": "zGN0YWy2he/tables/tables_6_2.jpg", "caption": "Table 3: User study. The score quantifies the user evaluation (i.e., relationships, quantities, and generation quality) of the alignment between the given prompt and the generated image.", "description": "This table presents the results of a user study conducted to evaluate the alignment between image prompts and generated images.  Fifty participants scored the alignment of prompts and images from different methods on a scale of 1-5. The average scores are presented here, indicating DisCo's superior performance in generating images that align well with the given prompts.", "section": "4 Experiments"}, {"figure_path": "zGN0YWy2he/tables/tables_7_1.jpg", "caption": "Table 4: Ablation study for overall architecture. Table 5: Ablation study for attention mechanism. SL-VAE w/o Ds means independent use of O. Vanilla attention means off-the-shelf T2I attention.", "description": "This table presents the results of ablation studies conducted to analyze the impact of different components on the overall performance and attention mechanism. Table 4 shows the ablation results for the overall architecture of the model, specifically focusing on the role of the layout decoder (D_l), semantic decoder (D_s), and their combination in the SL-VAE. It also includes a comparison using SL-VAE without the semantic decoder (D_s). The metrics used for evaluation are G2I-ACC and I2G-ACC. Table 5 presents ablation results for different attention mechanisms, including vanilla attention, CMA without the mask (M), CMA with a union Multilayer Perceptron (MLP), and CMA with separate MLPs. The evaluation metrics used here are IS and FID.", "section": "3.3 Multi-Layered Sampler"}, {"figure_path": "zGN0YWy2he/tables/tables_7_2.jpg", "caption": "Table 5: Ablation study for attention mechanism. Vanilla attention means off-the-shelf T2I attention.", "description": "This table presents the ablation study for different attention mechanisms used in the proposed model. It compares the performance of using the vanilla attention mechanism from a standard text-to-image diffusion model against the proposed Compositional Masked Attention (CMA) mechanism with and without different variations of the masking and Multi-Layer Perceptron (MLP) structures. The results are evaluated using the Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) metrics. The table shows that the CMA with separate MLPs significantly improves the performance compared to the other methods.", "section": "3.2 Diffusion with Compositional Masked Attention"}, {"figure_path": "zGN0YWy2he/tables/tables_8_1.jpg", "caption": "Table 6: Ablation study for Multi-Layer Sampler (MLS).", "description": "This ablation study compares the performance of three different methods for generating images using scene graphs: a baseline method, a method using Layered Scene Diffusion (LSD), and the proposed Multi-Layered Sampler (MLS) method.  The table shows the Inception Score (IS), Fr\u00e9chet Inception Distance (FID), and Attribute Classification Accuracy (ACCattr) for each method. The results demonstrate the improved performance of the proposed MLS method compared to the baseline and LSD methods, particularly in terms of attribute control.", "section": "3.3 Multi-Layered Sampler"}, {"figure_path": "zGN0YWy2he/tables/tables_14_1.jpg", "caption": "Table 7: Ablation study for graph construction.", "description": "This table presents the ablation study on the impact of different components in the graph construction process.  It shows the Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) metrics when excluding CLIP embeddings, bounding box embeddings, and learnable embeddings from the graph. The results indicate that all components contribute to performance gains.", "section": "4 Experiments"}, {"figure_path": "zGN0YWy2he/tables/tables_15_1.jpg", "caption": "Table 1: Performance comparison on COCO-Stuff and Visual Genome datasets using Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) metrics. We report the results of methods with two generator structures, namely GAN- and Diffusion-based. The architecture of these methods is based on the layout (L) or semantics (S), while our approach includes both. The best results are bolded.", "description": "This table compares the performance of various image generation methods on two benchmark datasets (COCO-Stuff and Visual Genome).  The methods are categorized by their underlying architecture (GAN-based or Diffusion-based) and the type of input condition (layout or semantics). The DisCo method, proposed by the authors, uses both layout and semantic information.  Performance is evaluated using Inception Score (IS) and Fr\u00e9chet Inception Distance (FID), with higher IS and lower FID indicating better image quality and diversity.", "section": "4 Experiments"}]