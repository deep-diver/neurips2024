[{"figure_path": "ektPEcqGLb/tables/tables_3_1.jpg", "caption": "Table 1: Models considered in this paper.", "description": "This table summarizes the different variational autoencoder (VAE) models used in the paper for comparison purposes.  It highlights whether the model utilizes a discrete or continuous latent space, and provides references for each model.  The models include the Poisson VAE (P-VAE), the Categorical VAE (C-VAE), the Gaussian VAE (G-VAE), and the Laplace VAE (L-VAE).", "section": "4 Experiments"}, {"figure_path": "ektPEcqGLb/tables/tables_5_1.jpg", "caption": "Table 1: Models considered in this paper.", "description": "This table presents four different variational autoencoder (VAE) models used for comparison in the paper.  Two are discrete VAEs (Poisson VAE and Categorical VAE), and two are continuous VAEs (Gaussian VAE and Laplace VAE).  The table lists the name of each model and relevant citations to prior work where those models were introduced.", "section": "Experiments"}, {"figure_path": "ektPEcqGLb/tables/tables_7_1.jpg", "caption": "Table 2: Proportion of active neurons. All models considered in this table had a latent dimensionality of K = 512. The decoders were linear, and the encoders were either linear or convolutional.", "description": "This table shows the proportion of active neurons for different VAE models.  A high proportion indicates that the model is effectively using the latent dimensions, while a low proportion suggests posterior collapse.  The results are broken down by dataset (van Hateren, CIFAR16x16, MNIST) and encoder type (linear, convolutional).", "section": "Experiments"}, {"figure_path": "ektPEcqGLb/tables/tables_8_1.jpg", "caption": "Table 3: Geometry of representations (K = 10 only; see Table 5 for the full set of results).", "description": "This table presents the results of a K-Nearest Neighbors (KNN) classification task performed on unsupervised learned representations from various VAE models.  The goal is to assess the sample efficiency and geometric properties of the different latent spaces in a downstream classification task.  The table shows the accuracy of KNN classification for different numbers of labeled samples (N = 200, 1000, 5000) and also includes the \"shattering dimension\", which measures the linear separability of the learned representations.  A higher shattering dimension generally indicates better linear separability.", "section": "4 Experiments"}, {"figure_path": "ektPEcqGLb/tables/tables_22_1.jpg", "caption": "Table 2: Proportion of active neurons. All models considered in this table had a latent dimensionality of K = 512. The decoders were linear, and the encoders were either linear or convolutional.", "description": "This table shows the proportion of active neurons for different VAE models.  A \"dead neuron\" indicates a latent dimension that is not actively encoding information, a phenomenon known as posterior collapse.  The table compares the performance of the Poisson VAE (P-VAE) against other continuous and discrete VAE models (G-VAE, L-VAE, and C-VAE) across different datasets (van Hateren, CIFAR16x16, and MNIST) and encoder architectures (linear and convolutional). Lower numbers indicate fewer dead neurons and thus better performance.", "section": "Experiments"}, {"figure_path": "ektPEcqGLb/tables/tables_23_1.jpg", "caption": "Table 3: Geometry of representations (K = 10 only; see Table 5 for the full set of results).", "description": "This table presents the results of a downstream classification task using K-Nearest Neighbors (KNN) with different numbers of labeled samples (N = 200, 1000, 5000).  The task is to classify MNIST digits using feature representations learned by various VAE models (P-VAE, C-VAE, L-VAE, G-VAE, G-VAE+relu, G-VAE+exp) with a latent dimensionality of K=10. The table shows the accuracy of each model for each sample size (N), and also includes the \"shattering dimension\", which measures the average accuracy over all possible pairwise classification tasks. This provides insight into the geometry of the learned representations and how well the models generalize to different classification tasks.", "section": "4 Experiments"}]