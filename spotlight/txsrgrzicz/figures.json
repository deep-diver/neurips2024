[{"figure_path": "TXsRGrzICz/figures/figures_1_1.jpg", "caption": "Figure 1: Factor graphs: [Left] Standard MDP [Right] Factored MDP with sparse factor connectivity.", "description": "This figure displays two factor graphs representing Markov Decision Processes (MDPs). The left graph shows a standard MDP, where all states and actions are explicitly represented.  The right graph illustrates a factored MDP, which breaks down the state space into smaller, interacting components. This factorization allows for a more compact representation but introduces dependencies between the factors, indicated by the sparse connectivity. The figure highlights the difference in representation complexity between standard and factored MDPs, with factored MDPs offering potential advantages for scalability in large state spaces, even though they introduce computational challenges related to approximate inference.", "section": "Introduction"}, {"figure_path": "TXsRGrzICz/figures/figures_9_1.jpg", "caption": "Figure 2: Performance of different types of inference on factored MDPs as a function of their level of stochasticity (normalized entropy). [Left] Estimation error of the best utility. Lower is better. [Right] Advantage of the next action prescribed by a method vs. optimal planning. Higher is better.", "description": "This figure compares the performance of different inference methods (MFVI-Bwd, CSVI-Bwd, ARollout, SOGBOFA-LC*, exact marginal, exact MAP, exact MMAP, exact planning, VBP, VI LP) on factored Markov Decision Processes (MDPs) with varying levels of stochasticity.  The left panel shows the estimation error of the best utility, where lower values indicate better performance. The right panel shows the advantage of the action chosen by each method compared to the optimal planning action, with higher values indicating better performance.  The x-axis represents the normalized entropy, a measure of stochasticity.", "section": "6 Empirical validation"}, {"figure_path": "TXsRGrzICz/figures/figures_15_1.jpg", "caption": "Figure 4: Correspondence between the message passing updates and the factorized MDP.", "description": "This figure illustrates the correspondence between the message-passing updates used in the Value Belief Propagation (VBP) algorithm and the factor graph representation of a factored Markov Decision Process (MDP).  It visually connects the messages (m, n, and b) exchanged between factor nodes during VBP with the variables and factors within the factored MDP. This helps clarify the relationship between the approximate inference algorithm and the underlying probabilistic model.", "section": "3.2 VI LP and VBP for factored MDPs"}]