[{"figure_path": "DAtNDZHbqj/tables/tables_5_1.jpg", "caption": "Table 1: Amount of steps required to reach the threshold Retaf in MuJoCo tasks with 5 constant delays within 1M global steps, where \u00d7 denotes that failed to hit the threshold within 1M global steps. The best result is in blue.", "description": "This table presents the sample efficiency results of VDPO and several baseline algorithms on nine MuJoCo tasks with a constant delay of 5.  The goal is to reach a performance threshold (Retaf), defined by the performance of a delay-free policy trained using SAC. The table shows the number of steps required by each algorithm to reach this threshold within a maximum of 1 million global steps.  '\u00d7' indicates that the algorithm failed to reach the threshold within the time limit. The best result for each task is highlighted in blue, demonstrating VDPO's superior sample efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "DAtNDZHbqj/tables/tables_6_1.jpg", "caption": "Table 1: Amount of steps required to reach the threshold Retaf in MuJoCo tasks with 5 constant delays within 1M global steps, where \u00d7 denotes that failed to hit the threshold within 1M global steps. The best result is in blue.", "description": "This table presents the sample efficiency results for nine different MuJoCo benchmark tasks, each with a constant delay of 5.  It shows the number of steps required by various algorithms (A-SAC, DC/AC, DIDA, BPQL, AD-SAC, and VDPO) to reach a performance threshold (Retaf) set by a delay-free SAC policy within a maximum of 1 million global steps.  'X' indicates that an algorithm failed to reach the threshold within the limit. The best-performing algorithm for each task is highlighted in blue, showcasing VDPO's superior sample efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "DAtNDZHbqj/tables/tables_7_1.jpg", "caption": "Table 2: Normalized Performance Retnor in MuJoCo tasks with 5, 25, and 50 constant delays for 1M global steps, where \u00b1 denotes the standard deviation. The best performance is in blue.", "description": "This table presents the normalized performance (Retnor) of different reinforcement learning algorithms on various MuJoCo tasks with varying constant delays (5, 25, and 50).  The best-performing algorithm for each task and delay setting is highlighted in blue.  The table allows for a comparison of algorithm performance across different delay conditions and highlights the relative strengths of the algorithms in handling observation delays.", "section": "4.2.2 Performance Comparison"}, {"figure_path": "DAtNDZHbqj/tables/tables_7_2.jpg", "caption": "Table 3: Normalized Performance Retnor of VDPO using different representations in MuJoCo tasks with 5 constant delays, where \u00b1 denotes the standard deviation. The best result is in blue.", "description": "This table presents the results of an ablation study on the different neural network representations used in the VDPO algorithm.  It compares the performance (normalized performance indicator) across nine MuJoCo benchmark tasks using three different architectures: a Multilayer Perceptron (MLP), a Transformer without a belief decoder, and the proposed Transformer with a belief decoder.  The best performing architecture for each task is highlighted in blue, indicating the superiority of the proposed Transformer with a belief decoder in terms of sample efficiency and overall performance.", "section": "4.2.3 Additional Discussions"}, {"figure_path": "DAtNDZHbqj/tables/tables_8_1.jpg", "caption": "Table 2: Normalized Performance Retnor in MuJoCo tasks with 5, 25, and 50 constant delays for 1M global steps, where \u00b1 denotes the standard deviation. The best performance is in blue.", "description": "This table presents the performance comparison of VDPO and other state-of-the-art methods across multiple MuJoCo benchmark tasks.  The performance is normalized using the formula Retnor = Retalg - Retrand, where Retalg and Retrand represent the algorithm's performance and random policy performance, respectively. Results are shown for 5, 25, and 50 constant delays, with the best performance in each scenario highlighted in blue. The \u00b1 values indicate the standard deviation across multiple runs.", "section": "4.2.2 Performance Comparison"}, {"figure_path": "DAtNDZHbqj/tables/tables_13_1.jpg", "caption": "Table 5: Hyper-parameters table of VDPO.", "description": "This table lists the hyperparameters used in the Variational Delayed Policy Optimization (VDPO) algorithm.  It includes settings for buffer size, batch size, global timesteps, discount factor, learning rates for actor and critic, network layers and neurons, activation function, optimizer, initial entropy, entropy learning rate, training frequencies for actor and critic, soft update factor for the critic, sequence length, embedding dimension, attention heads, number of layers, dropout rates for attention, residual, and embedding, and training frequencies for the belief and policy decoders.", "section": "3.3 VDPO Implementation"}, {"figure_path": "DAtNDZHbqj/tables/tables_17_1.jpg", "caption": "Table 6: Amount of steps required to reach the threshold Retaf in MuJoCo tasks with 25 constant delays within 1M global steps, where \u00d7 denotes that failed to hit the threshold within 1M global steps. The best result is in blue.", "description": "This table presents the sample efficiency results for nine MuJoCo tasks with a constant delay of 25.  It shows the number of steps required by VDPO and several other algorithms (A-SAC, DC/AC, DIDA, BPQL, AD-SAC) to reach a performance threshold (Retaf) defined as the performance of a delay-free policy trained by SAC.  A value of 'x' indicates that the algorithm failed to reach the threshold within the 1 million global steps limit.  The best performance for each task is highlighted in blue, demonstrating VDPO's superior sample efficiency compared to other methods in most tasks.", "section": "4.2 Experimental Results"}, {"figure_path": "DAtNDZHbqj/tables/tables_17_2.jpg", "caption": "Table 7: Amount of steps required to hit the threshold Retaf in MuJoCo tasks with 50 constant delays within 1M global steps, where \u00d7 denotes that failed to hit the threshold within 1M global steps. The best result is in blue.", "description": "This table shows the sample efficiency results for the MuJoCo benchmark with 50 constant delays.  It reports the number of steps required by different algorithms (A-SAC, DC/AC, DIDA, BPQL, AD-SAC, and VDPO) to reach a performance threshold (Retaf) within a maximum of 1 million global steps. A value of 'x' indicates that the algorithm failed to reach the threshold within the time limit. The best performance for each task is highlighted in blue, demonstrating the superior sample efficiency of VDPO in many cases.", "section": "4.2 Experimental Results"}]