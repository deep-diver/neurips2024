[{"figure_path": "OJximyClit/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of prompt distribution learning and label bias correction on ImageNet using CLIP ViT-B/16. (a) Existing zero-shot models [1, 27]. (b) Our prompt distribution learning (c) Average probability prediction of original CLIP. (d) Average probability prediction of our Frolic.", "description": "This figure illustrates the core idea of the proposed method, Frolic, which is to learn the distribution of prompt prototypes for each class and correct the label bias of the pre-trained CLIP model.  Subfigure (a) shows the decision boundary of existing zero-shot models, which is biased due to the imbalanced pre-training data. Subfigure (b) shows how Frolic learns the distributions over prompt prototypes for each class. Subfigures (c) and (d) compare the average probability predictions of the original CLIP and Frolic on ImageNet, respectively, demonstrating that Frolic corrects the label bias and provides more balanced predictions.", "section": "Introduction"}, {"figure_path": "OJximyClit/figures/figures_3_1.jpg", "caption": "Figure 2: Comparison of confidence.", "description": "This figure shows a bar chart comparing the average confidence scores of two models, fc and fg, across various datasets.  The confidence score represents the model's certainty in its predictions. The chart visually demonstrates that model fg generally exhibits higher confidence scores than model fc across all the datasets shown.", "section": "3.3 Prediction Fusion via Adaptive Calibration"}, {"figure_path": "OJximyClit/figures/figures_8_1.jpg", "caption": "Figure 3: Relation between gains and confidence differences.", "description": "This figure shows the relationship between the accuracy gains achieved by using the adaptive fusion technique (compared to simple fusion) and the difference in confidence between the Gaussian model (fg) and the original CLIP model (fc).  A linear regression line is fitted to the data points, demonstrating a positive correlation: larger confidence differences between the two models generally lead to greater improvements in accuracy by using the adaptive fusion strategy.", "section": "4.3 Ablation Studies and Further Analysis"}, {"figure_path": "OJximyClit/figures/figures_8_2.jpg", "caption": "Figure 4: Convergence of accuracy and \u21131 error of \u03b2 on ImageNet.", "description": "This figure shows the convergence behavior of the accuracy and the \u21131 error during the iterative process of Algorithm 2 for estimating \u03b2 on the ImageNet dataset.  The x-axis represents the iteration number, the left y-axis shows the accuracy in percentage, and the right y-axis displays the \u21131 error. The plot demonstrates that the accuracy quickly increases and stabilizes after around 6 iterations, while the \u21131 error steadily decreases to a value below the defined threshold (\u03b5 = 0.01) within 10 iterations. This visualizes the convergence of Algorithm 2, highlighting its efficiency in estimating \u03b2.", "section": "Experiments"}]