[{"figure_path": "enlxHLwwFf/figures/figures_1_1.jpg", "caption": "Figure 1: Parametric vs functional approaches for solving FBO by implicit differentiation.", "description": "This figure compares the parametric and functional approaches to bilevel optimization, focusing on the implicit differentiation step.  The functional approach, which the paper proposes, first performs implicit differentiation in a function space, resulting in a well-defined solution, and then approximates this solution with a parameterized model. This contrasts with the parametric approach, where a parameterized model is used first, and implicit differentiation is then performed in the parameter space. The parametric approach often leads to multiple solutions and an ill-defined implicit gradient due to the non-convexity of the inner objective in the parameter space.", "section": "1 Introduction"}, {"figure_path": "enlxHLwwFf/figures/figures_7_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations.", "description": "This figure compares different bilevel optimization methods on an instrumental variable regression task using the dsprites dataset.  The left panel shows a box plot of the out-of-sample mean squared error (MSE) for each method, highlighting the performance of FuncID. The middle and right panels display the outer and inner losses, respectively, plotted against the number of outer and inner iterations. These plots reveal the convergence behavior of the algorithms, illustrating how FuncID achieves lower losses compared to other methods.", "section": "4 Applications"}, {"figure_path": "enlxHLwwFf/figures/figures_9_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations.", "description": "This figure compares the performance of several bilevel optimization methods on an instrumental variable regression task.  The left panel shows a box plot of the out-of-sample mean squared error (MSE) for each method, indicating FuncID's superior performance.  The middle and right panels display the outer and inner losses, respectively, over training iterations. The plots show that FuncID converges faster and achieves lower losses than other methods.", "section": "4 Applications"}, {"figure_path": "enlxHLwwFf/figures/figures_39_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations. The bold lines in the middle and right plots indicate the mean loss, the shaded area corresponds to standard deviation.", "description": "This figure compares the performance of different bilevel optimization methods for instrumental variable regression.  Three plots show the out-of-sample mean squared error (MSE), outer loss, and inner loss over training iterations. The left plot shows box plots of the test MSE, while the middle and right plots show the outer and inner losses with mean and standard deviation for each method.  The results highlight the superior performance of the proposed FuncID method compared to other baselines.", "section": "4 Applications"}, {"figure_path": "enlxHLwwFf/figures/figures_39_2.jpg", "caption": "Figure 5: The causal relationships between all variables in an Instrumental Variable (IV) causal graph, where t is the treatment variable (dsprites image), o is the outcome (label in R), x is the instrument and e is the unobserved confounder", "description": "This figure is a causal graph showing the relationship between the treatment variable (t), outcome variable (o), instrumental variable (x), and unobserved confounder (e) in an instrumental variable regression setting.  The arrows indicate the causal direction. The treatment variable is directly influenced by the unobserved confounder and the instrumental variable. The outcome is influenced by both the treatment variable and the unobserved confounder. The instrumental variable only influences the outcome through the treatment variable. This graph visually represents the causal structure used in the 2SLS experiment described in section 4.1.", "section": "4.1 Two-stage least squares regression (2SLS)"}, {"figure_path": "enlxHLwwFf/figures/figures_41_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations.", "description": "This figure compares the performance of different bilevel optimization methods on an instrumental variable regression task.  The left panel shows a box plot of the out-of-sample mean squared error (MSE) for each method, providing a summary of the model's prediction accuracy. The middle and right panels show the evolution of the outer and inner losses, respectively, over training iterations, allowing for a comparison of convergence speed and stability.", "section": "4 Applications"}, {"figure_path": "enlxHLwwFf/figures/figures_42_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations. The bold lines in the middle and right plots indicate the mean loss, the shaded area corresponds to standard deviation.", "description": "This figure compares the performance of different bilevel optimization methods on the instrumental variable regression task.  The left panel shows a box plot of the out-of-sample mean squared error (MSE) for each method, highlighting the test performance. The central and right panels present the evolution of the outer and inner losses during the training iterations, respectively, allowing for a more detailed analysis of convergence behavior.  Shaded areas represent standard deviations, providing an indication of uncertainty in the results.", "section": "4 Applications"}, {"figure_path": "enlxHLwwFf/figures/figures_43_1.jpg", "caption": "Figure 2: Performance metrics for Instrumental Variable (IV) regression. All results are averaged over 20 runs with 5000 training samples and 588 test samples. (Left) box plot of the test loss, with the dashed black line indicating the mean test error. (Middle) outer loss vs training iterations, (Right) inner loss vs training iterations. The bold lines in the middle and right plots indicate the mean loss, the shaded area corresponds to standard deviation.", "description": "This figure compares the performance of various bilevel optimization methods on an instrumental variable regression task.  The left panel shows a box plot summarizing the out-of-sample mean squared error (MSE) achieved by each method on a held-out test set. The middle and right panels display the training curves of the outer and inner objectives, respectively, showing how these losses evolve as the optimization progresses.  The results indicate that the proposed FuncID method outperforms alternative approaches in terms of out-of-sample MSE.", "section": "4 Applications"}]