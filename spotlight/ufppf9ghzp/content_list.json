[{"type": "text", "text": "A Neural Network Approach for Efficiently Answering Most Probable Explanation Queries in Probabilistic Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Shivvrat Arya ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tahrima Rahman ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Computer Science The University of Texas at Dallas shivvrat.arya@utdallas.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science The University of Texas at Dallas tahrima.rahman@utdallas.edu ", "page_idx": 0}, {"type": "text", "text": "Vibhav Gogate Department of Computer Science The University of Texas at Dallas vibhav.gogate@utdallas.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We propose a novel neural networks based approach to efficiently answer arbitrary Most Probable Explanation (MPE) queries\u2014a well-known NP-hard task\u2014in large probabilistic models such as Bayesian and Markov networks, probabilistic circuits, and neural auto-regressive models. By arbitrary MPE queries, we mean that there is no predefined partition of variables into evidence and non-evidence variables. The key idea is to distill all MPE queries over a given probabilistic model into a neural network and then use the latter for answering queries, eliminating the need for time-consuming inference algorithms that operate directly on the probabilistic model. We improve upon this idea by incorporating inference-time optimization with self-supervised loss to iteratively improve the solutions and employ a teacherstudent framework that provides a better initial network, which in turn, helps reduce the number of inference-time optimization steps. The teacher network utilizes a self-supervised loss function optimized for getting the exact MPE solution, while the student network learns from the teacher\u2019s near-optimal outputs through supervised loss. We demonstrate the efficacy and scalability of our approach on various datasets and a broad class of probabilistic models, showcasing its practical effectiveness. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Probabilistic representations such as Probabilistic Circuits (PCs) [8], graphical models [26] such as Bayesian Networks (BNs) and Markov Networks (MNs), and Neural Autoregressive Models (NAMs) [50] are widely used to model large, multi-dimensional probability distributions. However, they face a significant challenge: as the complexity of these distributions increases, solving practically relevant NP-hard inference tasks such as finding the Most Probable Explanation (MPE) via exact inference techniques [39, 40] becomes increasingly difficult and time-consuming. In particular, although various exact and approximate solvers exist for the MPE task in PCs, BNs and MNs, exact solvers are often too slow for practical use, and approximate solvers tend to lack the necessary accuracy, particularly in autoregressive models that currently rely on slow hill-climbing/beam search methods. ", "page_idx": 0}, {"type": "text", "text": "In recent work, Arya et al. [4] proposed a method to overcome the limitations of existing approximate methods by using neural networks (NNs) to solve the MPE task in PCs.1 Their method draws inspiration from the learning to optimize literature [12, 15, 29, 42, 55]. Given a PC and a predefined partition of variables into query and evidence sets, the core idea is to train a NN that takes an assignment to the evidence variables as input and outputs the most likely assignment to the query variables w.r.t. the distribution defined by the PC. Arya et al. suggest using either supervised or self-supervised learning techniques to train the NN; the former requires access to exact inference schemes, while the latter does not and is therefore more practical. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we address a more general and complex version of the MPE task than the one considered by Arya et al. Specifically, we assume that there is no predefined partition of the variables into evidence and query sets, which we refer to as the any-MPE task. The complexity of the any-MPE task arises from the exponential increase in the number of input configurations, compounded by the exponential number of possible divisions of variables into evidence and query sets. Furthermore, our method applies to a broad class of probabilistic models, including BNs, MNs and NAMs, whereas Arya et al.\u2019s method is limited to PCs. In addition, Arya et al.\u2019s method does not fully exploit the capabilities of self-supervision, and the benefits of combining supervised and self-supervised loss functions. ", "page_idx": 1}, {"type": "text", "text": "This paper presents a novel approach that uses a NN for solving the any-MPE task in a broad class of probabilistic models (PMs) and achieves technical advancements in three key aspects: ", "page_idx": 1}, {"type": "text", "text": "1. Efficient MPE Inference via Encoding Scheme and Loss Function: We introduce a new encoding scheme that tailors the NN architecture to the specific structure of the input PM. This scheme not only delineates the input and output nodes for the NN but also establishes a methodology for setting input values and extracting the MPE solution from the NN\u2019s outputs. Furthermore, we propose a tractable, and differentiable self-supervised loss function, enabling efficient training. ", "page_idx": 1}, {"type": "text", "text": "2. Inference Time Optimization with ITSELF: We introduce a novel inference technique called Inference Time Self Supervised Training (ITSELF). This technique iteratively refines the MPE solution during the inference process itself. It utilizes gradient descent (back-propagation) to update the NN\u2019s parameters using our proposed self-supervised loss, leading to continual (anytime) improvement towards near-optimal solutions. ITSELF fully utilizes the power of our self-supervised loss, as it does not require labeled data or an external MPE solver. ", "page_idx": 1}, {"type": "text", "text": "3. Two-Phase Pre-training with Teacher-Student Architecture: To address challenges associated with self-supervised learning and ITSELF, we propose a two-phase pre-training strategy that leverages a teacher-student architecture. Self-supervised learning can suffer from overftiting and requires careful regularization. Additionally, ITSELF, especially with random initializations, might necessitate a substantial number of gradient updates to converge on optimal solutions. Our approach addresses these issues using the following methodology: (i) The teacher network first overftis the training data using ITSELF and (ii) The student network is then trained using supervised loss functions (e.g., binary cross-entropy) by treating the teacher network\u2019s output as pseudo-labels. This supervised training phase improves and regularizes the parameter learning process of the student network. It also provides a robust starting point for ITSELF, significantly reducing the required optimization steps and leading to substantial performance gains. ", "page_idx": 1}, {"type": "text", "text": "Finally, we conduct a detailed experimental comparison of our method with existing approaches on several types of PMs such as PCs, PGMs and NAMs. Our results demonstrate that our method surpasses state-of-the-art approximate inference techniques in terms of both accuracy and speed. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Motivation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Without loss of generality, we use binary variables which take values from the set $\\{0,1\\}$ . We denote a random variable by an uppercase letter (e.g., $X$ ), and a value assigned to it by the corresponding lowercase letter (e.g., $x$ ). We denote a set of random variables by a bold uppercase letter (e.g., $\\mathbf{X}_{,}$ and an assignment of values to all variables in the set by the corresponding bold lowercase letter (e.g., x). ", "page_idx": 1}, {"type": "text", "text": "Throughout the paper when we use the term probabilistic models (PMs), we are referring to a broad class of probabilistic models in which computing the likelihood2 of an assignment to all variables in the model can be done in polynomial (preferably linear) time in the size of the model. This class includes, among others, Bayesian and Markov networks collectively called Probabilistic Graphical Models (PGMs) [26], smooth and decomposable Probabilistic Circuits (PCs) [8], and Neural Autoregressive Models (NAMs) such as NADE [50] and MADE [17]. ", "page_idx": 2}, {"type": "text", "text": "We are interested in solving the most probable explanation (MPE) task in PMs, namely the task of finding the most likely assignment to all unobserved (non-evidence) variables given observations (evidence). Formally, let $\\mathcal{M}$ denote a probabilistic model defined over a set of variables $\\mathbf{X}$ that represents the distribution $\\mathsf{p}_{\\mathcal{M}}(\\mathbf{x})$ . We categorize the variables $\\mathbf{X}$ into evidence $\\mathbf{E}\\subseteq\\mathbf{X}$ and query $\\mathbf{Q}\\subseteq\\mathbf{X}$ groups, ensuring that $\\dot{\\mathbf{E}}\\cap\\mathbf{Q}=\\emptyset$ and $\\mathbf{E}\\cup\\mathbf{Q}=\\mathbf{X}$ . Then, given an assignment e to the set of evidence variables $\\mathbf{E}$ , the MPE task can be formulated as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{M}\\mathbb{P}\\mathbb{E}\\!\\left(\\mathbf{Q},\\mathbf{e}\\right)=\\underset{\\mathbf{q}}{\\mathrm{argmax}}\\,\\mathrm{p}_{\\mathcal{M}}\\!\\left(\\mathbf{q}|\\mathbf{e}\\right)=\\underset{\\mathbf{q}}{\\mathrm{argmax}}\\left\\{\\log\\mathrm{p}_{\\mathcal{M}}(\\mathbf{q},\\mathbf{e})\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "It is known that the MPE task is NP-hard in general and even hard to approximate [9, 11, 36, 41, 44]. ", "page_idx": 2}, {"type": "text", "text": "Motivation: The goal of this paper is to develop a method that trains a NN for a given PM and, at test time, serves as an approximate MPE solver for any-MPE query posed over the PM. By any-MPE, we mean that the NN can take an assignment to an arbitrary subset of variables (evidence) as input and output the most likely assignments to the remaining (query) variables. Recently, Arya et al. [4] proposed a NN-based solution for solving the MPE task in PCs under the constraint that the partition of the variables into evidence and query sets is known before training the NN. This constraint is highly restrictive because, for generative models, it is unlikely that such a partition of variables is known in advance. In such cases, one would typically train a discriminative model rather than a generative one. Unlike Arya et al.\u2019s method, our approach yields an any-MPE solver. Additionally, Arya et al.\u2019s approach has several limitations in that it does not fully exploit the beneftis of self-supervision during inference time and requires the use of relatively large NNs to achieve good performance in practice. Our proposed approach, described next, addresses these limitations. ", "page_idx": 2}, {"type": "text", "text": "3 A Self-Supervised Neural Approximator for any-MPE ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we develop a neural network (NN) based approach for solving the any-MPE task. Specifically, given a PM, we develop an input encoding (see Section 3.1) that determines the number of input nodes of the NN and sets their values for the given MPE query. Additionally, we develop an output encoding scheme that specifies the number of NN output nodes required for the given PM and enables the recovery of the MPE solution from the outputs. For training the NN, we introduce a tractable and differentiable self-supervised loss function (see Section 3.2), whose global minima aligns with the MPE solutions to efficiently learn the parameters of the NN given unlabeled data. ", "page_idx": 2}, {"type": "text", "text": "3.1 An Encoding For any-MPE Instances ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Since NNs require fixed-sized inputs and outputs, we introduce input and output encodings that generate fixed-length input and output vectors for each PM from a given MPE problem instance $\\mathrm{MPE}(\\mathbf{Q},\\mathbf{e})$ . To encode the input, for each variable $X_{i}\\in\\mathbf{X}$ , we associate two input nodes in the NN, denoted by $\\hat{X_{i}}$ and $\\bar{X_{i}}$ . Thus for a PM having $n$ (namely, $|\\mathbf{X}|=n!$ ) variables, the corresponding NN has $2n$ input nodes. Given a query $\\mathrm{MPE}(\\mathbf{Q},\\mathbf{e})$ , we set the values of the input nodes as follows: (1) If $X_{i}\\in\\mathbf{E}$ and $X_{i}=0$ is in e, then we set $\\hat{X_{i}}=0$ and $\\bar{X_{i}}=1$ ; (2) If $X_{i}\\in\\mathbf{E}$ and $X_{i}=1$ is in e, then we set $\\hat{X_{i}}=1$ and $\\bar{X_{i}}=0$ ; and (3) If $X_{i}\\in\\mathbf{Q}$ then we set $\\hat{X_{i}}=0$ and $\\bar{X_{i}}=0$ . (The assignment $\\hat{X_{i}}=1$ and $\\bar{X_{i}}=1$ is not used.) It is easy to see that the input encoding described above yields an injective mapping between the set of all possible MPE queries over the given PM and the set $\\lbrack0,1\\rbrack^{2n}$ . This means that each unique MPE query $\\left(\\mathbf{Q},\\mathbf{e}\\right)$ will yield a unique 0-1 input vector of size $2n$ . ", "page_idx": 2}, {"type": "text", "text": "The output of the neural network comprises of $n$ nodes with sigmoid activation, where each output node is associated with a variable $X_{i}\\in\\mathbf{X}$ . We ignore the outputs corresponding to the evidence variables and define a loss function over the outputs corresponding to the query variables in the set $\\mathbf{Q}$ . The MPE solution can be reconstructed from the output nodes of the NN by thresholding the output nodes corresponding to the query variables appropriately (e.g., if the value of the output node is greater than 0.5, then the query variable is assigned the value 1; otherwise it is assigned to 0). ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3.2 A Self-Supervised Loss Function for any-MPE ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Since the output nodes of our proposed NN use sigmoid activation, each output is continuous and lies in the range [0, 1]. Given an MPE query $\\mathrm{MPE}(\\mathbf{Q},\\mathbf{e})$ , let $\\mathbf{q}^{c}\\in[0,1]^{|\\mathbf{Q}|}$ denote the (continuous) Most Probable Explanation (MPE) assignment predicted by the NN. In MPE inference, given e, we want to find an assignment $\\mathbf{q}$ such that $\\log\\operatorname{p}_{\\mathcal{M}}(\\mathbf{q},\\mathbf{e})$ is maximized, namely, $-\\log\\mathrm{p}_{\\mathcal{M}}(\\mathbf{q},\\mathbf{e})$ is minimized. Thus, a natural loss function that we can use is $-\\log\\mathrm{p}_{\\mathcal{M}}(\\mathbf{q},\\mathbf{e})$ . Unfortunately, the NN outputs a continuous vector $\\mathbf{q}^{c}$ and as a result $\\mathsf{p}_{\\mathcal{M}}(\\mathbf{q}^{c},\\mathbf{e})$ is not defined. ", "page_idx": 3}, {"type": "text", "text": "Next, we describe how to solve the above problem by leveraging the following property of the class of PMs that we consider in this paper\u2014specifically BNs, MNs, PCs and NAMs. In these PMs, the function $\\ell({\\bf q},{\\bf e})=-\\log\\mathrm{p}_{\\mathcal{M}}({\\bf e},{\\bf q})$ , which is a function from $\\{0,1\\}^{n}\\rightarrow\\mathbb{R}$ is either a multi-linear polynomial or a neural network, and can be computed in linear time in the size of the PM. To facilitate the use of continuous outputs, we define a loss function $\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e}):[0,1]^{n}\\to\\mathbb{R}$ such that $\\ell^{c}$ coincides with $\\ell$ on $\\{0,1\\}^{n}$ . For PGMs and PCs, $\\ell$ is a multi-linear function and $\\ell^{c}$ is obtained by substituting each occurrence of a discrete variable $q_{i}\\in{\\bf q}$ with the corresponding continuous variable $q_{i}^{c}\\in{\\bf q}^{c}$ where $q_{i}^{c}\\in[0,1]$ . In NAMs, $\\ell$ is a NN and we can perform a similar substitution\u2014we substitute each binary input $q_{i}$ in the NN with a continuous variable $q_{i}^{c}\\in[0,1]$ . This substitution transforms the discrete NN into a continuous function while preserving its functional form. ", "page_idx": 3}, {"type": "text", "text": "An important property of $\\ell^{c}$ is that it can be evaluated and differentiated in polynomial time. Moreover, when $\\ell$ is defined by either a neural network (in NAMs) or a multilinear function (in BNs, MNs and PCs), the minimum value of $\\ell^{c}$ over the domain $[0,1]^{n}$ is less than or equal to the minimum value of the original function $\\ell$ over the discrete domain $\\{0,1\\}^{n}$ . Formally, ", "page_idx": 3}, {"type": "text", "text": "Proposition 1. Let $l(\\mathbf{q},\\mathbf{e}):\\{0,1\\}^{n}\\rightarrow\\mathbb{R}$ be either a neural network or a multilinear function, and let $l^{\\overline{{c}}}(\\mathbf{q}^{c},\\mathbf{e}):[0,1]^{n}\\overset{\\because}{\\rightarrow}\\mathbb{R}$ be its continuous extension obtained by substituting each binary input $q_{i}$ with a continuous variable $q_{i}^{c}\\in[0,1]$ . Then, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{q}^{c}\\in[0,1]^{n}}\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e})\\leq\\operatorname*{min}_{\\mathbf{q}\\in\\{0,1\\}^{n}}\\ell(\\mathbf{q},\\mathbf{e})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Following Arya et al. [4], we propose to improve the quality of the loss function by tightening the lower bound given in proposition 1 with an entropy-based penalty $(\\ell_{E})$ , governed by $\\alpha>0$ . ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{E}(\\mathbf{q}^{c},\\alpha)=-\\alpha\\sum_{j=1}^{|\\mathbf{Q}|}\\left[q_{j}^{c}\\log(q_{j}^{c})+(1-q_{j}^{c})\\log(1-q_{j}^{c})\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This penalty encourages discrete solutions by preferring $q_{j}^{c}$ values close to 0 or 1, where $\\alpha$ modulates the trade-off. Setting $\\alpha$ to 0 yields the continuous approximation; conversely, an $\\alpha$ value of $\\infty$ results exclusively in discrete outcomes. From proposition 1 and by using the theory of Lagrange multipliers, we can show that for any $\\alpha>0$ , the use of the entropy penalty yields a tighter lower bound: ", "page_idx": 3}, {"type": "text", "text": "Proposition 2. ", "text_level": 1, "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{q}^{c}\\in[0,1]^{n}}\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e})\\leq\\operatorname*{min}_{\\mathbf{q}^{c}\\in[0,1]^{n}}\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e})+\\ell_{E}(\\mathbf{q}^{c},\\boldsymbol{\\alpha})\\leq\\operatorname*{min}_{\\mathbf{q}\\in\\{0,1\\}^{n}}\\ell(\\mathbf{q},\\mathbf{e})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "How to use the Loss Function: Given a PM defined over $n$ variables, we can use the self-supervised loss function $\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e})+\\ell_{E}(\\mathbf{q}^{c},\\alpha)$ (treating $\\alpha$ as a hyper-parameter) to train any neural network (NN) architecture that has $2n$ input nodes and $n$ output nodes. This trained NN can then be used to answer any arbitrary MPE query posed over the PM. The training data for the neural network consists of assignments (evidence e) to a subset of the variables. Each training example can be generated using the following three-step process. We first sample a full assignment $\\mathbf{x}$ to all variables in the PM using techniques like Gibbs sampling or perfect sampling for tractable distributions such as PCs and BNs. Second, we choose an integer $k$ uniformly at random from the range $\\{1,\\ldots,n\\}$ and designate $k$ randomly selected variables as evidence variables $\\mathbf{E}$ , and the remaining $n-k$ as query variables $\\mathbf{Q}$ . Finally, we project the full assignment $\\mathbf{x}$ on $\\mathbf{E}$ . The primary advantage of using the self-supervised loss function is that it eliminates the need for access to a dedicated MPE solver to provide supervision during training; gradient-based training of the neural network provides the necessary supervision. ", "page_idx": 3}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/0109990eb9def255775daadb0fcea2dd60e46f29fba3f88816f91d06b6aa7e8b.jpg", "img_caption": ["Figure 1: ITSELF Training Procedure ", "Figure 2: One Training Epoch for GUIDE "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.3 Inference-Time Neural Optimization using Self-Supervised Loss ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "At a high level, assuming that the NN is over-parameterized, if we use the self-supervised loss and repeatedly run (stochastic) gradient updates over the NN for a given dataset, theoretical results [2, 13] as well as prior experimental work [46, 56] suggest that the parameters of the NN will converge to a point near the global minimum of the self-supervised loss function. This means that through gradient updates, the network will find a near-optimal MPE assignment for each training example. This strategy of performing gradient updates over the NN can also be used during inference (test) time to iteratively improve the MPE solution, thereby maximizing the benefits of self-supervision. ", "page_idx": 4}, {"type": "text", "text": "Specifically, at test time, given a test dataset (or example), we initialize the NN either randomly or using a pre-trained model and then run gradient-based updates over the NN iteratively until convergence. The gradient is computed w.r.t. the self-supervised loss function $\\ell^{c}(\\mathbf{q}^{c},\\mathbf{e})+\\ell_{E}(\\mathbf{q}^{c},\\alpha)$ . We call the resulting algorithm ITSELF (Inference Time Optimization using SELF-Supervised Loss), as detailed in Figure 1. The performance of ITSELF typically improves with each iteration until the loss converges. ", "page_idx": 4}, {"type": "text", "text": "Our proposed method, ITSELF, is closely related to test-time training approaches which are widely used to solve problems in deep learning [1, 10, 19, 30\u201332, 38, 49, 51, 57]. Our method differs from these previous approaches in that the global minima of our proposed self-supervised loss correspond to the MPE solutions, provided that the penalty $\\alpha$ is sufficiently large. ", "page_idx": 4}, {"type": "text", "text": "4 Supervised Knowledge Transfer from ITSELF ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A drawback of our self-supervised loss function is that, unlike supervised loss functions such as binary cross entropy, it is a non-convex function of the NN outputs3. As a result, it has a significantly larger number of local minima compared to the supervised loss function, but also a potentially exponential number of global minima, because an MPE problem can have multiple optimal solutions [35], all of which have the same loss function value. Thus, optimizing and regularizing using the self-supervised loss is difficult compared to a supervised loss, especially when the number of training examples is large. ", "page_idx": 4}, {"type": "text", "text": "Moreover, our experiments show that large datasets necessitate large, over-parameterized neural networks (NNs) to achieve near-optimal MPE solutions for all examples. However, when the training data is limited and the NN is sufficiently over-parameterized, our preliminary findings, along with theoretical and empirical results from prior studies [3, 6, 23, 27, 28], suggest that the NN is more likely to approach the global optima. Specifically, with a reasonably sized NN and a small dataset, the algorithm ITSELF tends to yield near-optimal MPE solutions. A further challenge with ITSELF is that even for small datasets, achieving convergence from a random initialization requires numerous iterations of gradient descent, rendering the training process inefficient and slow. ", "page_idx": 4}, {"type": "text", "text": "1: Input: Training data $\\mathcal{D}$ , teacher $\\tau$ and student $\\boldsymbol{S}$ having the same structure   \n2: Output: Trained student network $\\boldsymbol{S}$   \n3: $\\triangleright$ Database $D B$ stores the best MPE assignment and loss value for each example in $\\mathcal{D}$   \n4: Initialize: Randomly initialize $\\tau,s$ , and $_{D B}$   \n5: for each epoch do   \n6: Sample a mini-batch $\\mathcal{D}^{\\prime}$ from $\\mathcal{D}$   \n7: Update the parameters of $\\tau$ using the algorithm ITSELF (self-supervised loss) with Dataset $\\mathcal{D}^{\\prime}$   \n8: for each example $\\mathbf{e}_{i}$ in $\\mathcal{D}^{\\prime}$ do   \n9: Make a forward-pass over $\\tau$ to get an MPE assignment $\\mathbf{q}_{i}$ for $\\mathbf{e}_{i}$   \n10: Update the entry in $D B$ for $\\mathbf{e}_{i}$ with $\\mathbf{q}_{i}$ if it has a lower loss value than the current entry   \n11: end for   \n12: Update the parameters of $\\boldsymbol{S}$ using the mini-batch $\\mathcal{D}^{\\prime}$ and labels from $D B$ and a supervised loss   \n13: $\\tau\\leftarrow s$ $\\triangleright$ Initialize $\\tau$ with $\\boldsymbol{S}$ for the next epoch   \n14: end for ", "page_idx": 5}, {"type": "text", "text": "4.1 Teacher-Student Strategy ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To address these challenges (using small datasets with ITSELF; designing better initialization for it; and using non-convex loss functions for training), we propose a two-network teacher-student strategy [7, 16, 20\u201322, 24, 37, 47, 52\u201354], where we have two networks with the same structure that are trained via mini-batch gradient updates. The teacher network is overftited to the mini-batch using our self-supervised loss via the ITSELF algorithm, and the student network is subsequently trained with a supervised loss function such as binary cross entropy. By overfitting the teacher network via ITSELF on the mini-batch, we ensure that it finds near-optimal MPE assignments for all (unlabeled) examples in the mini-batch and eventually over the whole training dataset. ", "page_idx": 5}, {"type": "text", "text": "The student network then learns from the teacher\u2019s outputs, using them as soft labels in a supervised learning framework. This transfer of knowledge mitigates the optimization difficulties associated with the non-convex self-supervised loss, allowing the student network to achieve faster convergence and better generalization with a more manageable model size. Additionally, this strategy reduces the need for severe over-parameterization and extensive training iterations for the teacher network because it is operating on a smaller dataset. It also helps achieve better initialization for ITSELF. ", "page_idx": 5}, {"type": "text", "text": "4.2 Training Procedure ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our proposed training procedure, which we call ${\\mathcal{G U I D}}{\\mathcal{E}}$ , is detailed in Algorithm 1. The algorithm trains a two-network system comprising a teacher network $(\\tau)$ and a student network $(S)$ with the same structure. The goal is to train the student network using a combination of self-supervised and supervised learning strategies. The algorithm takes as input the training data $\\mathcal{D}$ , along with the teacher and student networks, $\\tau$ and $\\boldsymbol{S}$ , respectively and outputs a trained network $\\boldsymbol{S}$ . A database $(D B)$ is utilized to store the best MPE assignment and corresponding loss value for each example in $\\mathcal{D}$ . The parameters of $\\tau$ and $\\boldsymbol{S}$ , and the entries in $_{D B}$ , are randomly initialized at the start. ", "page_idx": 5}, {"type": "text", "text": "In each epoch, a mini-batch $\\mathcal{D}^{\\prime}$ is sampled from the training data $\\mathcal{D}$ . The parameters of the teacher network $\\tau$ are then updated using the ITSELF algorithm (which uses a self-supervised loss), applied to the mini-batch $\\mathcal{D}^{\\prime}$ (the mini-batch helps address large data issues associated with ITSELF). For each example $\\mathbf{e}_{i}$ in $\\mathcal{D}^{\\prime}$ , we perform a forward-pass over $\\tau$ to obtain an MPE assignment $\\mathbf{q}_{i}$ . The database $D B$ is subsequently updated with $\\mathbf{q}_{i}$ if it has a lower loss value than the current entry for $\\mathbf{e}_{i}$ ", "page_idx": 5}, {"type": "text", "text": "Following this, the parameters of the student network $\\boldsymbol{S}$ are updated using the mini-batch $\\mathcal{D}^{\\prime}$ , the labels from $_{D B}$ , and a supervised loss function $(\\ell_{s u p})$ such as Binary Cross Entropy or $L2$ loss. Finally, the parameters of the teacher network $\\tau$ are reinitialized with the updated parameters of the student network $\\boldsymbol{S}$ to prepare for the next epoch (addressing the initialization issue associated with ITSELF). Figure 2 illustrates a single training epoch of GUIDE. ", "page_idx": 5}, {"type": "text", "text": "Thus, at a high level, Algorithm 1 leverages the strengths of both self-supervised and supervised learning to improve training efficiency and reduce the model complexity, yielding a student network $\\boldsymbol{S}$ . Moreover, at test time, the student network can serve as an initialization for ITSELF. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section evaluates the ITSELF method (see section 3.3), the GUIDE teacher-student training method (see section 4) and the method that uses only self-supervised training, which we call SSMP (see section 3.2). We benchmark these against various baselines, including neural network-based and traditional polynomial-time algorithms that directly operate on the probabilistic model. We begin by detailing our experimental framework, including competing methods, evaluation metrics, neural network architectures, and datasets. ", "page_idx": 6}, {"type": "text", "text": "5.1 Datasets and Graphical Models ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We used twenty binary datasets extensively used in tractable probabilistic models literature [5, 18, 34, 50]\u2014referred to as TPM datasets\u2014for evaluating PCs and NAMs. For the purpose of evaluating PGMs, we utilized high treewidth models from previous UAI inference competitions [14]. ", "page_idx": 6}, {"type": "text", "text": "To train Sum Product Networks (SPNs), our choice of PCs, we employed the DeeProb-kit library [33], with SPN sizes ranging from 46 to 9666 nodes. For NAMs, we trained Masked Autoencoder for Distribution Estimation (MADE) models using PyTorch, following the approach in Germain et al. [17]. For Markov Networks (MNs), a specific type of PGM, we applied Gibbs sampling to generate 8,000, 1,000, and 1,000 samples for the training, testing, and validation sets, respectively. The query ratio $(q r)$ , defined as the fraction of variables in the query set, was varied across the set $\\{0.1,0.3,0.5,0.7,0.8,0.9\\}$ for each probabilistic model (PM). ", "page_idx": 6}, {"type": "text", "text": "5.2 Baseline Methods and Evaluation Criteria ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "PCs - We used three polynomial-time baseline methods from the probabilistic circuits and probabilistic graphical models literature as benchmarks [41, 45]. ", "page_idx": 6}, {"type": "text", "text": "\u2022 MAX Approximation (MAX) [45] transforms sum nodes into max nodes. During the upward pass, max nodes output the highest weighted value from their children. The downward pass, starting from the root, selects the child with the highest value at each max node and includes all children of product nodes.   \n\u2022 Maximum Likelihood Approximation (ML) [41] computes the marginal distribution $p_{\\mathcal{M}}(Q_{i}|\\mathbf{e})$ for each variable $Q_{i}\\in\\mathbf{Q}$ , setting $Q_{i}$ to its most likely value.   \n\u2022 Sequential Approximation (Seq) [41] iteratively assigns query variables according to an order $o$ . At each step $j$ , it selects the $j$ -th query variable $Q_{j}$ in $o$ and assigns to it a value $q_{j}$ such that $\\mathtt{p}_{\\mathcal{M}}(q_{j}|\\mathbf{e},\\mathbf{y})$ is maximized, where $\\mathbf{y}$ is an assignment of values to all query variables from 1 to $j-1$ . ", "page_idx": 6}, {"type": "text", "text": "We further evaluated the impact of initializing stochastic hill climbing searches using solutions from all baseline approaches and our proposed methods for MPE inference, conducting 60-second searches for each MPE problem in our experiments, as detailed in Park and Darwiche [41]. ", "page_idx": 6}, {"type": "text", "text": "NAMs - As a baseline, we used the stochastic hill-climbing search (HC) algorithm. Following a procedure similar to that used for PCs, we conducted a 60-second hill-climbing search for each test example, with query variables initialized randomly and setting evidence variables according to the values in the given example. ", "page_idx": 6}, {"type": "text", "text": "PGMs - We employed the distributed AND/OR Branch and Bound (AOBB) method [39] as a baseline, using the implementation outlined in Otten [40]. Since AOBB is an anytime algorithm, we set a 60-second time limit for inference per test example. ", "page_idx": 6}, {"type": "text", "text": "Neural Baselines - Arya et al. [4] introduced Self-Supervised learning based MMAP solver for PCs (SSMP), training a neural network to handle queries on a fixed variable partition within PCs. We extend this approach to address the any-MPE task in PMs (see Section 3.2), using a single network to answer any-MPE queries as an additional neural baseline. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Criteria - We evaluated competing approaches based on log-likelihood (LL) scores, calculated as $\\ln p_{\\mathcal{M}}(\\mathbf{e},\\mathbf{q})$ , and inference times for given evidence e and query output q. Higher log-likelihood scores indicate better performance, while shorter inference times are preferable. ", "page_idx": 6}, {"type": "text", "text": "5.3 Neural Network-Based Approaches ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We implemented two neural network training protocols for each PM and query ratio: SSMP and $\\mathit{g l d x}$ . Each model was trained for 20 epochs following the training procedure outlined by Arya et al. [4] for SSMP. Both protocols employed two distinct inference strategies, thus forming four neural-based variants. In the first strategy, we performed a single forward pass through the network to estimate the values of query variable, as specified by Arya et al. [4]. The second strategy utilized our novel testtime optimization-based ITSELF approach for inference. The ITSELF optimization terminates after 100 iterations or upon loss convergence for both PCs and PGMs. For NAMs, we increase the limit to 1,000 iterations while keeping the convergence criterion. ", "page_idx": 7}, {"type": "text", "text": "We standardized network architectures for PMs across all experiments. For PCs, we used fully connected Neural Networks (NN) with three hidden layers (128, 256, 512 nodes). For NAMs and PGMs, a single hidden layer of 512 nodes was employed. All hidden layers featured ReLU activation, while the output layers used sigmoid functions with dropout for regularization [48]. We optimized all models using Adam [25] and implemented them in PyTorch [43] on an NVIDIA A40 GPU. ", "page_idx": 7}, {"type": "text", "text": "Results for PCs: We compare methods\u2014including three polynomial-time baselines, neural network-based SSMP, and our ITSELF and $\\mathit{g l d x}$ methods\u2014on 20 TPM datasets as shown in the contingency table in figure 3a (detailed results in the supplementary materials). We generated 120 test datasets for the MPE task using $20\\;\\mathrm{PCs}$ across 6 query ratios $(q r)$ . Each cell $(i,j)$ in the table represents how often (out of 120) the method in row $i$ outperformed the method in column $j$ based on average log-likelihood scores. Any difference between 120 and the combined frequencies of cells $(i,j)$ and $(j,i)$ indicates cases where the compared methods achieved similar scores. We present similar contingency tables for Hill Climbing Search over PCs (Fig. 3b), NAMs (Fig. 3c), and PGMs (Fig. 3d) to benchmark the proposed methods against the baselines. ", "page_idx": 7}, {"type": "text", "text": "The contingency table for PC (Fig. 3a) shows that methods incorporating ITSELF consistently outperform both polynomial-time and traditional neural baselines, as indicated by the dark blue cells in the corresponding rows. Notably, $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ is superior to all the other methods in almost two-thirds of the 120 cases, while $\\mathrm{SSMP+ITSELF}$ is better than both SSMP and $\\mathit{g l d x}$ . In contrast, the polynomial-time baseline MAX is better than both SSMP and $\\mathit{g l d x}$ (as used in Arya et al. [4]), highlighting ITSELF\u2019s significant role in boosting model performance for the complex any-MPE task. ", "page_idx": 7}, {"type": "text", "text": "We compare MAX and $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ using a heatmap in Figure 4a. The y-axis presents datasets by variable count and the ${\\bf X}$ -axis represents query ratio. Each cell displays the percentage difference in mean LL scores between the methods, calculated as $\\%\\mathrm{Diff.}=100\\times(l l_{n n}-l l_{m a x})/|l l_{m a x}|$ . The heatmap shows that $\\mathcal{G}\\mathcal{U}\\mathcal{I}\\mathcal{D}\\mathcal{E}+\\mathrm{ITS}$ ELF achieves performance comparable to MAX for small query sets. As the problem complexity increases with an increase in query set size, our method consistently outperforms MAX across all datasets, except for NLTCS and Tretail, as highlighted by the green cells. In the 12 cases where $\\mathit{G u I D E}$ $+\\;{\\mathrm{ITSELF}}$ underperforms, the performance gap remains minimal, as indicated by the limited number of red cells in the heatmap. ", "page_idx": 7}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/2407e482b7a7f0578ab029072d0d13728fc2894517cf1aadf6f7660c8ed5063c.jpg", "img_caption": ["(a) PCs: Initial Solutions "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/e80b03f00b71a962deed62c555f66cf6d0a8ceb052346fbb75f634c6a50d3366.jpg", "img_caption": ["(b) PCs: Hill-Climbing "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/12cb4aff9508080142b08e8828d12ba4b454a2dae7fb04644b9196d22604c096.jpg", "img_caption": ["Figure 3: MPE method comparison across PMs. Blue shows row superiority, red shows column superiority; darker shades indicate larger values. ", "(d) PGMs "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 3b further analyzes the performance of our proposed methods against various baselines as initialization strategies for Hill Climbing Search. This comparison evaluates the effectiveness of ITSELF and $\\mathit{g l d x}$ in enhancing anytime methods compared to conventional heuristic initialization approaches. Notably, methods incorporating ITSELF provide superior initialization for local search-based algorithms. ", "page_idx": 8}, {"type": "text", "text": "Results for NAMs: The contingency table in Figure 3c presents our evaluation of several methods for NAMs, including HC and two neural network approaches, SSMP and , each tested with two inference schemes. We evaluated these methods on 20 TPM datasets, creating 80 test sets for the MPE task using 20 MADEs across four query ratios $(q r)$ . ", "page_idx": 8}, {"type": "text", "text": "The $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ approach demonstrates superior performance compared to both baseline methods and other neural inference schemes, aligning with observations from PC. While HC outperforms SSMP, both $\\mathit{G u I D E}$ and the combination of SSMP-based training with ITSELF-based inference surpass HC, highlighting their advantages over the baseline. ", "page_idx": 8}, {"type": "text", "text": "The heatmaps in Figure 4b further highlight the superior performance of $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ for NAMs, particularly in larger datasets where it outperforms the HC baseline by over $50\\%$ in most cases, as indicated by the dark green cells. The combination of $\\mathit{g l d x}$ -based learning with ITSELF-based inference consistently outperforms the baseline across most datasets, with exceptions only in the Mushrooms, Connect 4, and Retail. Overall, the $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ approach significantly enhances the quality of the MPE solutions in NAM models. ", "page_idx": 8}, {"type": "text", "text": "Results for PGMs: The contingency table in 3d compares the performance of AOBB and four neural-network-based methods on PGMs across four high-treewidth networks. For this evaluation, we generated 16 test datasets for the MPE task using four PGMs across four query ratios $(q r)$ . ", "page_idx": 8}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/c290631a008abfc2a2e71b419dc34bb4f28defbfa266aae67fb60d0f3147f865.jpg", "img_caption": ["(a) PC: GUIDE + ITSELF vs. MAX "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Consistent with results from previous PMs, methods using ITSELF for inference consistently outperform the baseline methods AOBB and SSMP across most scenarios. Both $\\mathit{g l d x}$ and SSMP outperform AOBB in at least 50 percent of the tests. The supplementary material presents comparisons against exact solutions, conducted on less complex probabilistic models where ground truth computation remains tractable. ", "page_idx": 8}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/e7a3a043d162c7f03a03b2d966885a32ec99c24ab978fe7702faa2e31a01316c.jpg", "img_caption": ["(b) NAM: GUIDE $^+$ ITSELF vs. HC "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Does a teacher-student-based network outperform a single network trained with the self-supervised loss? (GUIDE vs. SSMP): ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This analysis aims to evaluate the performance of  against traditional neural network training methods used in SSMP across different PMs and inference schemes. Using traditional inference scheme (i.e., one forward pass through the network), consistently outperforms SSMP, demonstrating its superiority in $60\\%$ of scenarios for PCs, more than $80\\%$ for NAM models, and $75\\%$ for PGM models. When employing ITSELF-based inference, $\\mathit{G u I D E}$ maintains this advantage, achieving higher quality solutions in more than $75\\%$ , $85\\%$ , and $80\\%$ of cases for PCs, NAMs, and PGMs, respectively. Therefore, models trained using $\\mathit{g l d x}$ are consistently superior to those trained with SSMP for the any-MPE task. ", "page_idx": 8}, {"type": "text", "text": "Figure 4: Heatmaps showing LL $\\%$ Differences. Top: PC; Bottom: NAM. Green cells: our method is better. Darker shades indicate larger values. ", "page_idx": 8}, {"type": "text", "text": "Does inference time optimization improve performance? (One-Pass vs. Multi-Pass): ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this analysis, we compare the performance of the single-pass inference method to that of the proposed multi-pass inference method (ITSELF). ITSELF combined with SSMP training outperforms the other methods in over $85\\%$ cases for PC, and more than $75\\%$ for NAM and PGM models. When used on models trained with $g l I D{\\mathcal{E}}$ , ITSELF demonstrates even better results, achieving superior performance in nearly $90\\%$ of PC cases and $75\\%$ for both NAMs and PGMs. Overall, $\\mathit{g l d x}$ with ITSELF inference emerges as the most effective method across all experiments. Empirical evidence consistently demonstrates ITSELF\u2019s superiority over single-pass inference across PMs. ", "page_idx": 9}, {"type": "text", "text": "The inference time analysis, detailed in the supplementary material, compares computational efficiency across methods using the natural logarithm of execution time in microseconds. Neural network-based approaches with traditional inference demonstrate the fastest performance across all PMs, as they only require a single forward pass to compute query variable values. For MADE, models trained with $\\mathit{g l d x}$ and ITSELF are the next most efficient. In PGMs, $\\mathcal{G}\\mathcal{U}\\mathcal{I}\\mathcal{D}\\mathcal{E}+\\mathrm{ITS}$ ELF ranks third, followed by SSMP $^+$ ITSELF. For PCs, MAX is marginally faster than both $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ and SSMP $^+$ ITSELF, while ML and Seq have the longest computational times. In general, models trained with $\\mathit{g l d x}$ achieve shorter inference times than those trained with the self-supervised loss (SSMP), as they require fewer ITSELF iterations due to more effective initial training. ", "page_idx": 9}, {"type": "text", "text": "Summary: Our experiments demonstrate that $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ outperforms both polynomial-time and neural-based baselines across various PMs, as evidenced by higher log-likelihood scores. Notably, ITSELF demonstrates significant advantages over traditional single-pass inference in addressing the complex any-MPE query task within probabilistic models, emphasizing the importance of Inference Time Optimization. Furthermore, the superior performance of models trained with $\\mathit{g l d x}$ compared to SSMP highlights the effectiveness of the dual network approach, which improves initial model quality and establishes an optimal starting point for ITSELF. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduced novel methods for answering Most Probable Explanation (MPE) queries in probabilistic models. Our approach employs self-supervised loss functions to represent MPE objectives, enabling tractable loss and gradient computations during neural network training. We also proposed a new inference time optimization technique, ITSELF, which iteratively improves the solution to the MPE problem via gradient updates. Additionally, we introduced a dual-network-based strategy that combines supervised and unsupervised training which we call $\\mathit{g l d x}$ to provide better initialization for ITSELF and addressing various challenges associated with self-supervised training. Our method was tested on various benchmarks, including probabilistic circuits, neural autoregressive models, and probabilistic graphical models, using 20 binary datasets and high tree-width networks. It outperformed polytime baselines and other neural methods, substantially in some cases. Additionally, it improved the effectiveness of stochastic hill climbing (local) search strategies. ", "page_idx": 9}, {"type": "text", "text": "Future work includes solving complex queries in probabilistic models with constraints; training neural networks with losses from multiple probabilistic models to embed their inference mechanisms; boosting performance by developing advanced encoding strategies for similar tasks; implementing sophisticated neural architectures tailored to probabilistic models; etc. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported in part by the DARPA Perceptually-Enabled Task Guidance (PTG) Program under contract number HR00112220005, the DARPA Assured Neuro Symbolic Learning and Reasoning (ANSR) Program under contract number HR001122S0039, the National Science Foundation grant IIS-1652835, and the AFOSR award FA9550-23-1-0239. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Ferran Alet, Maria Bauza, Kenji Kawaguchi, Nurullah Giray Kuru, Tom\u00e1s Lozano-P\u00e9rez, and Leslie Kaelbling. Tailoring: Encoding inductive biases by optimizing unsupervised objectives at prediction time. In Advances in Neural Information Processing Systems, volume 34, pages 29206\u201329217. Curran Associates, Inc., 2021. ", "page_idx": 9}, {"type": "text", "text": "[2] Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-parameterization. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 242\u2013252. PMLR, 09\u201315 Jun 2019.   \n[3] Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 322\u2013332. PMLR, 2019.   \n[4] Shivvrat Arya, Tahrima Rahman, and Vibhav Gogate. Neural Network Approximators for Marginal MAP in Probabilistic Circuits. Proceedings of the AAAI Conference on Artificial Intelligence, 38(10):10918\u201310926, March 2024. ISSN 2374-3468. doi: 10.1609/aaai.v38i10. 28966. [5] Jessa Bekker, Jesse Davis, Arthur Choi, Adnan Darwiche, and Guy Van den Broeck. Tractable learning for complex probability queries. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015.   \n[6] L\u00e9na\u00efc Chizat and Francis R. Bach. On the global convergence of gradient descent for overparameterized models using optimal transport. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pages 3040\u20133050, 2018.   \n[7] Jang Hyun Cho and Bharath Hariharan. On the Efficacy of Knowledge Distillation. 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 4793\u20134801, October 2019. doi: 10.1109/ICCV.2019.00489.   \n[8] YooJung Choi, Antonio Vergari, and Guy Van den Broeck. Probabilistic circuits: A unifying framework for tractable probabilistic models. Technical report, University of California, Los Angeles, 2020.   \n[9] Gregory F. Cooper. The computational complexity of probabilistic inference using bayesian belief networks. Artificial Intelligence, 42(2-3):393\u2013405, March 1990. ISSN 00043702. doi: 10.1016/0004-3702(90)90060-D.   \n[10] Mohammad Zalbagi Darestani, Jiayu Liu, and Reinhard Heckel. Test-time training can close the natural distribution shift performance gap in deep learning based compressed sensing. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 4754\u20134776. PMLR, 17\u201323 Jul 2022.   \n[11] Cassio P de Campos. New Complexity Results for MAP in Bayesian Networks. IJCAI International Joint Conference on Artificial Intelligence, pages 2100\u20132106, 01 2011. doi: 10.5591/978-1-57735-516-8/IJCAI11-351.   \n[12] Priya L. Donti, David Rolnick, and J. Zico Kolter. DC3: A learning method for optimization with hard constraints. In International Conference on Learning Representations, October 2020.   \n[13] S. Du, Xiyu Zhai, B. P\u00f3czos, and Aarti Singh. Gradient descent provably optimizes overparameterized neural networks. International Conference on Learning Representations, 2018.   \n[14] G. Elidan and A. Globerson. The 2010 UAI Approximate Inference Challenge. 2010.   \n[15] Ferdinando Fioretto, Terrence W. K. Mak, and Pascal Van Hentenryck. Predicting AC Optimal Power Flows: Combining Deep Learning and Lagrangian Dual Methods. Proceedings of the AAAI Conference on Artificial Intelligence, 34(01):630\u2013637, April 2020. ISSN 2374-3468. doi: 10.1609/aaai.v34i01.5403.   \n[16] Tommaso Furlanello, Zachary Chase Lipton, M. Tschannen, L. Itti, and Anima Anandkumar. Born Again Neural Networks. In International Conference on Machine Learning, May 2018.   \n[17] Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle. Made: Masked autoencoder for distribution estimation. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 881\u2013889, Lille, France, 07\u201309 Jul 2015. PMLR.   \n[18] Jan Van Haaren and Jesse Davis. Markov Network Structure Learning: A Randomized Feature Generation Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 26(1): 1148\u20131154, 2012. ISSN 2374-3468. doi: 10.1609/aaai.v26i1.8315.   \n[19] Moritz Hardt and Yu Sun. Test-time training on nearest neighbors for large language models. In The Twelfth International Conference on Learning Representations, 2024.   \n[20] Byeongho Heo, Jeesoo Kim, Sangdoo Yun, Hyojin Park, Nojun Kwak, and Jin Young Choi. A Comprehensive Overhaul of Feature Distillation. 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 1921\u20131930, October 2019. doi: 10.1109/ICCV.2019.00201.   \n[21] Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin Young Choi. Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 3779\u20133787, July 2019. doi: 10.1609/aaai.v33i01.33013779.   \n[22] Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. CoRR, abs/1503.02531, 2015.   \n[23] Arthur Jacot, Cl\u00e9ment Hongler, and Franck Gabriel. Neural tangent kernel: Convergence and generalization in neural networks. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pages 8580\u20138589, 2018.   \n[24] Jangho Kim, Seonguk Park, and Nojun Kwak. Paraphrasing Complex Network: Network Compression via Factor Transfer. ArXiv, February 2018.   \n[25] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.   \n[26] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.   \n[27] Jaehoon Lee, S. Schoenholz, Jeffrey Pennington, Ben Adlam, Lechao Xiao, Roman Novak, and Jascha Narain Sohl-Dickstein. Finite versus infinite neural networks: an empirical study. Neural Information Processing Systems, 2020.   \n[28] Jaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, and Jeffrey Pennington. Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent. Journal of Statistical Mechanics: Theory and Experiment, 2020(12):124002, December 2020. ISSN 1742-5468. doi: 10.1088/1742-5468/abc62b.   \n[29] Ke Li and Jitendra Malik. Learning to optimize. International Conference on Learning Representations, 2016.   \n[30] Yushu Li, Xun Xu, Yongyi Su, and Kui Jia. On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion. In 2023 IEEE/CVF International Conference on Computer Vision (ICCV), pages 11802\u201311812, Paris, France, October 2023. IEEE. ISBN 9798350307184. doi: 10.1109/ICCV51070.2023.01087.   \n[31] Huan Liu, Zijun Wu, Liangyan Li, Sadaf Salehkalaibar, Jun Chen, and Keyan Wang. Towards Multi-domain Single Image Dehazing via Test-time Training. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5821\u20135830, New Orleans, LA, USA, June 2022. IEEE. ISBN 978-1-66546-946-3. doi: 10.1109/CVPR52688.2022.00574.   \n[32] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. TTT $^{++}$ : When Does Self-Supervised Test-Time Training Fail or Thrive? In Advances in Neural Information Processing Systems, volume 34, pages 21808\u201321820. Curran Associates, Inc., 2021.   \n[33] Lorenzo Loconte and Gennaro Gala. DeeProb-kit: a python library for deep probabilistic modelling, 2022. URL https://github.com/deeprob-org/deeprob-kit.   \n[34] Daniel Lowd and Jesse Davis. Learning Markov Network Structure with Decision Trees. In 2010 IEEE International Conference on Data Mining, pages 334\u2013343. IEEE, 2010. ISBN 978-1-4244-9131-5. doi: 10.1109/ICDM.2010.128.   \n[35] Radu Marinescu and Rina Dechter. Counting the optimal solutions in graphical models. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/ fc2e6a440b94f64831840137698021e1-Paper.pdf.   \n[36] Denis Deratani Mau\u00e1 and Cassio P. de Campos. Approximation complexity of maximum A posteriori inference in sum-product networks. CoRR, abs/1703.06045, 2017.   \n[37] Seyed Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro Matsukawa, and Hassan Ghasemzadeh. Improved Knowledge Distillation via Teacher Assistant. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 5191\u20135198, April 2020. doi: 10.1609/aaai.v34i04.5963.   \n[38] David Osowiechi, G. A. V. Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, and Christian Desrosiers. Tttflow: Unsupervised test-time training with normalizing flow. IEEE Workshop/Winter Conference on Applications of Computer Vision, 2022. doi: 10.48550/arXiv. 2210.11389.   \n[39] L. Otten and R. Dechter. A case study in complexity estimation: Towards parallel branch-andbound over graphical models. Conference on Uncertainty in Artificial Intelligence, 2012.   \n[40] Lars Otten. DAOOPT: Sequential and distributed AND/OR branch and bound for MPE problems. 2012. URL https://github.com/lotten/daoopt.   \n[41] James D. Park and Adnan Darwiche. Complexity results and approximation strategies for map explanations. J. Artif. Int. Res., 21(1):101\u2013133, feb 2004. ISSN 1076-9757.   \n[42] Seonho Park and Pascal Van Hentenryck. Self-Supervised Primal-Dual Learning for Constrained Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4):4052\u20134060, June 2023. ISSN 2374-3468. doi: 10.1609/aaai.v37i4.25520.   \n[43] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019.   \n[44] Robert Peharz. Foundations of Sum-Product Networks for Probabilistic Modeling. PhD thesis, PhD thesis, Medical University of Graz, 2015.   \n[45] Hoifung Poon and Pedro Domingos. Sum-Product Networks: A New Deep Architecture. In Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence, pages 337\u2013346. AUAI Press, 2011.   \n[46] Tiancheng Qin, S. Rasoul Etesami, and Cesar A Uribe. Faster convergence of local SGD for over-parameterized models. Transactions on Machine Learning Research, 2024. ISSN 2835-8856.   \n[47] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, C. Gatta, and Yoshua Bengio. FitNets: Hints for Thin Deep Nets. CoRR, December 2014.   \n[48] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15(56):1929\u20131958, 2014. ISSN 1533-7928.   \n[49] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-Time Training with Self-Supervision for Generalization under Distribution Shifts. In Proceedings of the 37th International Conference on Machine Learning, pages 9229\u20139248. PMLR, November 2020.   \n[50] Benigno Uria, Marc-Alexandre C\u00f4t\u00e9, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural autoregressive distribution estimation. Journal of Machine Learning Research, 17(205):1\u201337, 2016.   \n[51] Dequan Wang, Evan Shelhamer, Shaoteng Liu, B. Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. International Conference on Learning Representations, 2021.   \n[52] Chenglin Yang, Lingxi Xie, Chi Su, and Alan L. Yuille. Snapshot Distillation: Teacher-Student Optimization in One Generation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 2854\u20132863, June 2019. doi: 10.1109/CVPR.2019.00297.   \n[53] Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 7130\u20137138, July 2017. doi: 10.1109/CVPR.2017.754.   \n[54] Sergey Zagoruyko and N. Komodakis. Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer. ArXiv, November 2016.   \n[55] Ahmed S. Zamzam and Kyri Baker. Learning Optimal Solutions for Extremely Fast AC Optimal Power Flow. In 2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), pages 1\u20136, November 2020. doi: 10.1109/SmartGridComm47815.2020.9303008.   \n[56] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.   \n[57] Wentao Zhu, Yufang Huang, Daguang Xu, Zhen Qian, Wei Fan, and Xiaohui Xie. Test-time training for deformable multi-scale image registration. IEEE International Conference on Robotics and Automation, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Experimental Setup ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Datasets and Models ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Table 1 summarizes the datasets and the probabilistic circuits trained on them. We use the same datasets for both PCs [8] and NAMs [17, 50]. The selection includes both smaller datasets, such as NLTCS and MSNBC, and larger datasets with over 1000 nodes. ", "page_idx": 14}, {"type": "text", "text": "For Markov networks, we utilize high treewidth grid networks, specifically grid40x40.f2.wrap, grid40x40.f5.wrap, grid40x40.f10.wrap, and grid $\\lvert40\\mathrm{x}40\\$ .f15.wrap. Each model contains 4800 variables and 1600 factors. ", "page_idx": 14}, {"type": "table", "img_path": "ufPPf9ghzP/tmp/99335bf5f997fdc06d50e6262ae0d5f3fa4c53196e3d07b68fc72c561e02e9e9.jpg", "table_caption": ["Table 1: Summary of datasets used with their respective numbers of variables and nodes in probabilistic circuits. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "A.2 Hyperparameters Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Our experimental framework was designed to ensure consistency and efficiency across all conducted experiments. For NAM\u2019s, we used MADE, training the model with two hidden layers of 512 and 1024 units, respectively, using the hyperparameters from Germain et al. [17]. ", "page_idx": 14}, {"type": "text", "text": "For neural network-based solvers, the mini-batch size was set to 512 samples, and a learning rate decay strategy, reducing the rate by 0.9 upon loss plateauing, was implemented to improve training efficiency. Optimal hyperparameters were identified via extensive 5-fold cross-validation. ", "page_idx": 14}, {"type": "text", "text": "In discrete loss scenarios, the hyperparameter $\\alpha$ played a pivotal role. We systematically explored the optimal $\\alpha$ value across the range 0.001, 0.01, 0.1, 1, 10, 100, 1000 for neural-based models, including ITSELF and ${\\mathcal{G U I D}}{\\mathcal{E}}$ . Notably, higher $\\alpha$ values better constrain outputs to binary, thereby facilitating near-optimal results. ", "page_idx": 14}, {"type": "text", "text": "B Extending the Current Approach to Other Data Types and Inference Tasks ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The current approach can be extended to support both multi-valued discrete and continuous variables, broadening its utility in diverse scenarios. ", "page_idx": 14}, {"type": "text", "text": "For multi-valued discrete variables, the method can be adapted by implementing a multi-class, multioutput classification head. Each query variable is represented by a softmax output node, which provides soft evidence by generating probabilistic distributions across multiple discrete values. ", "page_idx": 14}, {"type": "text", "text": "To incorporate continuous variables, we introduce a linear activation function in the output layer. The loss function, specifically the multi-linear representation of the PM, is modified to accommodate continuous neural network outputs. For example, in Probabilistic Circuits that use Gaussian distributions, continuous values can be directly integrated into the loss function, facilitating gradient-based backpropagation. ", "page_idx": 15}, {"type": "text", "text": "These extensions primarily involve adjusting the network\u2019s output layer and refining the selfsupervised loss function represented by the PM. Notably, other elements of our approach, including the ITSELF and GUIDE procedures, remain unchanged. ", "page_idx": 15}, {"type": "text", "text": "Our approach further extends to additional inference tasks over probabilistic models, including marginal MAP and constrained most probable explanation (CMPE) tasks. However, the scalability of this approach depends on the computational efficiency of evaluating the loss function for each inference task. When this evaluation becomes computationally infeasible, the proposed method\u2014training a neural network to answer queries over probabilistic models\u2014may itself become infeasible. For example, performing marginal MAP inference over NAMs and PGMs requires repeated evaluations of the loss function associated with the marginal MAP task and its gradient during training. This iterative process, essential for updating the neural network\u2019s parameters, can become prohibitively resource-intensive due to the high computational demands of evaluating the marginal MAP loss over these probabilistic models. ", "page_idx": 15}, {"type": "text", "text": "C A Comparative Analysis of Performance of ITSELF for Different Pre-Training Methods ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "This section evaluates the performance of models initialized through various techniques\u2014random initialization, SSMP, and GUIDE. Each plot represents the loss for a distinct test example, with the $\\mathbf{X}$ -axis denoting the number of ITSELF iterations and the y-axis showing the Negative Log Likelihood (NLL) scores. Lower NLL values signify better solutions. Through this empirical assessment, we compare the impact of different pre-training methods on model performance. ", "page_idx": 15}, {"type": "text", "text": "Figures 5 to 28 present the plots for NAMs. The plots for PCs are shown in Figures 29 to 67. Figures 68 to 78 illustrate the plots for PGMs. We selected the following datasets for PCs and NAMs: DNA, RCV-1, Reuters-52, Netflix, WebKB, Audio, Moviereview, and Jester. For PGMs, we used all the datasets presented in the main paper. Each plot consists of two sections. The left section presents the Negative Log-Likelihood Loss for 1000 iterations for all methods. The right section contains two sub-plots: the top sub-plot displays the zoomed-in losses for the first 200 iterations, while the bottom sub-plot shows the zoomed-in losses for the last 200 iterations. ", "page_idx": 15}, {"type": "text", "text": "We randomly initialize the parameters for the random model and perform 1000 iterations of ITSELF for inference. For the two pre-trained models (SSMP and $\\mathit{G u I D E}$ ), we update the top $N$ layers, where $N$ is the number of layers corresponding to that loss curve, and fix the remaining bottom layers. We extract features by passing the input through these fixed layers and then train the parameters of the top $N$ layers. We again perform 1000 iterations of ITSELF for inference. For NAMs and PGMs, we use neural networks with up to one hidden layer, while for PCs, we employ models with up to three hidden layers. ", "page_idx": 15}, {"type": "text", "text": "From the plots for the three Probabilistic Modelss (PMs), we observe that models pre-trained using the proposed $\\mathit{g l d x}$ training scheme generally have a better starting point for ITSELF, indicated by a lower loss, compared to all other models. Across a wide array of datasets, PGMs, and query percentages, the $\\mathit{g l d x}$ method consistently converges to a lower or equivalent loss compared to other models. Remarkably, it sometimes achieves a loss value that is less than half of the nearest competing model. Furthermore, the losses for $\\mathit{G u I D E}$ are typically more stable than those of other initialization. In some scenarios, all models achieve a similar final loss, although models initialized with SSMP and those randomly initialized may experience oscillations in their loss values. ", "page_idx": 15}, {"type": "text", "text": "Models pre-trained using the traditional self-supervised loss (SSMP) typically have better or similar starting points than randomly initialized models. However, models pre-trained using the SSMP method might converge to a worse loss than their $\\mathit{g l d x}$ pre-trained counterparts. ", "page_idx": 15}, {"type": "text", "text": "In most cases, convergence is rapid, even with a reduced learning rate of $10^{-4}$ compared to the experiments shown in the main paper. Most methods converge within 200 to 300 iterations, although some may still oscillate during the later iterations of ITSELF. ", "page_idx": 15}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/d5b31a1a17d443e720fa469ad61204571297951d1b7f18a7e97c2b2ceb37e38b.jpg", "img_caption": ["Figure 5: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the DNA Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/cdfd97ad31c91be8224cce11d6ccca1c9af15d510007d7d97338299fdeb980b0.jpg", "img_caption": ["Figure 6: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the DNA Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/b736b950e7dc1fcba00a221c717161cf1065a508be92745321440ba77ffb98b3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 7: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the DNA Dataset at a Query Ratio of 0.9. ", "page_idx": 16}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/13eea94cc8a44e63e94e4338ae53ff41583c8688d9ba43422aa151c441f64cc8.jpg", "img_caption": ["Figure 8: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the RCV-1 Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/29323d6e57698670159cf040893fa074ad4ff5d6daeea0a7983bd4b8b86efb55.jpg", "img_caption": ["Figure 9: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the RCV-1 Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/3cf6d7c93d55fbc89f72219f341b92b788b8a6a8c7b997f53196a7691abad130.jpg", "img_caption": ["Figure 10: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the RCV-1 Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/a0b7f8b9638115daabd44f4ba542fc1a5929e8767149fad1b3401481a978a117.jpg", "img_caption": ["Figure 11: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Reuters-52 Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/a5c678b60600c073bad3c9fab5fbc91e3fc3758f639894a86071dbff00ff7953.jpg", "img_caption": ["Figure 12: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Reuters-52 Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/1da0a6e2308244bbc2f1dfead6f00483bcaa8b21bae83774d8a55b7bc685ee3e.jpg", "img_caption": ["Figure 13: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Reuters-52 Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/20cc309c3eb3e6d22e07bfcc3539f66547b774f623f25f173ceef57d1f647613.jpg", "img_caption": ["Figure 14: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Netflix Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/103ced4165d6930937c196d57b4403455bfe24370a2b4c36d67f1193680519b4.jpg", "img_caption": ["Figure 15: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Netflix Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4ebbba1eecc9d03bae1e6d8f4543e34231d458713aeaf24a403e8b914239cb5a.jpg", "img_caption": ["Figure 16: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Netflix Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/cb0e30ef04711b7c1ab38021c24e2e92bda3219d40ea8410219ffabd6dadd04d.jpg", "img_caption": ["Figure 17: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the WebKB Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/99305600f349c37775727759a1ffa943814198969e9728d6a112f36c6e05c48b.jpg", "img_caption": ["Figure 18: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the WebKB Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/038b8133df3bfb223ae0da418f69a130e420bbe17b32661542ecacde1b7c1590.jpg", "img_caption": ["Figure 19: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the WebKB Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/be5ba8bfe59ad29284fd14f3ea9d484792624a4d3b61d9fbe9620957d35ab3f5.jpg", "img_caption": ["Figure 20: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Audio Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/6c3f4694e9cd8334c4b8af41a436e2022743177226faddbcc66b17f914a4defb.jpg", "img_caption": ["Figure 21: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Audio Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4046f17dd2243aa428451386222f827082a34d47058d9d255e6d21c7519785e4.jpg", "img_caption": ["Figure 22: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Audio Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/f0ad82cbba6e1da826f1cdf0ecc2ea74e8f525390aea0d8937021be1abdc700d.jpg", "img_caption": ["Figure 23: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Movie reviews Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/30c7c8715a9de8042794460034d903b7924c6a209ae1fc7a1b2396a4a733c2fb.jpg", "img_caption": ["Figure 24: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Movie reviews Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/20d35fa6a548d2e53f6e6877e3edf4624a8739b9c6074c4ba72d0b8cb98d69ca.jpg", "img_caption": ["Figure 25: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Movie reviews Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/b23e84bb8ddf5210bc739a186bbbecd6ce26a7c1dfc40f58fd5b0e430dedd01a.jpg", "img_caption": ["Figure 26: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Jester Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/2be5b416e1399acc07214977aaf7c418974eed06277d2431cbdebf6cf50af3ba.jpg", "img_caption": ["Figure 27: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Jester Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/9e9a4d4b16cb07f096a5dc8b45e9ed5be8e89f6d46492d5651c161cd223b172f.jpg", "img_caption": ["Figure 28: Analysis of ITSELF Loss Across Various Pre-Trained Models for NAMs on the Jester Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/630ad3a7b33d9a5e4e06cae885d84faf1c15ca25e687eda6dac20685052ee2d8.jpg", "img_caption": ["Figure 29: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the DNA Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/c7c1c1974af9c72113b137fe654e17e7e9c91a302224c0d8ac60b2f08e249558.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 30: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the DNA Dataset at a Query Ratio of 0.3. ", "page_idx": 24}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/a667f1301f46b7a42f5c40dbf21a42c95f2da39c3c98ca3c3162aedb1f0d196f.jpg", "img_caption": ["Figure 31: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the DNA Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/68331c119bba8bf08878e5d8b9c08db8bf6e4e647a8c61de89ead7235688ab4e.jpg", "img_caption": ["Figure 32: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the DNA Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/78eed86eec461a2b28b5b91999ae44570f40f9262c0e9ea6547de351805d3c6a.jpg", "img_caption": ["Figure 33: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the DNA Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/3621abe820d4e10c66692143e3ceeab7d11ca289deb2e8aeee3fc6dae303d925.jpg", "img_caption": ["Figure 34: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the RCV-1 Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/cb11c27ac05dbb69437a3fac8003d3301883974eda6ffb53c4eaa16897bbdc01.jpg", "img_caption": ["Figure 35: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the RCV-1 Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/625b24b5e9fa45b162243b3f1ccab6ef85484b4463467926f9ac15ed60303f60.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure 36: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the RCV-1 Dataset at a Query Ratio of 0.5. ", "page_idx": 26}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/5e89ffa165d293f88d319e390a9a335da691bb5cb1050b5354bc2da8ee3a976e.jpg", "img_caption": ["Figure 37: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the RCV-1 Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/913d446e036a5e1e39bf0c4432e32fbe866edd8a08785ead5978f6e63e9f1676.jpg", "img_caption": ["Figure 38: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the RCV-1 Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/65b42293ff7937402243abca82a8ae5bb29b35cbbc2a34641549d691094391b2.jpg", "img_caption": ["Figure 39: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Reuters-52 Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/647da1d995829738f76fbf91ba1e4605d19e952c649d3a037be072930f20abaf.jpg", "img_caption": ["Figure 40: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Reuters-52 Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/553d8dafe19aefdaac6107cf93416ecd9ecfea56b20bd6fe1ef4290dd0a3ae29.jpg", "img_caption": ["Figure 41: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Reuters-52 Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/d7e367e7f71906bb0b4b97c6307bdf32a8dddcd6ba4ba2d52658448b7b5657d0.jpg", "img_caption": ["Figure 42: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Reuters-52 Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/957f9d5714182481e41680c57c6827bf49f6a2a38672c17fa736f07ff754ac16.jpg", "img_caption": ["Figure 43: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Reuters-52 Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/8c036401af10d60f1e26f928f10b7be3507ed83836fd5b595af513cf09990141.jpg", "img_caption": ["Figure 44: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Netflix Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/07e973c5ae10fabd827b5a0877b8aafa3add383eb5017a8b6458d9e89d576957.jpg", "img_caption": ["Figure 45: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Netflix Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/d0f96b04e370e999a2c1c47abc6ee2b98fdde7968beddd7a6aac95180516b5a0.jpg", "img_caption": ["Figure 46: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Netflix Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/b41de5fd5d781428329304533d9f951f7dc04ff824ff8ce50abd065e73f4743b.jpg", "img_caption": ["Figure 47: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Netflix Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/021f68e6c3569962345d019d46f10204d7e45536b01d1fda58758305774f87b3.jpg", "img_caption": ["Figure 48: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Netflix Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/595273e2eccba83a71071489fad38a8da60c52f651db4d45b9650c9e6e44b185.jpg", "img_caption": ["Figure 49: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the WebKB Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/17a38993fc58aa13fc91667581430cd186577ad398e1ba9ce38cfcb671513e07.jpg", "img_caption": ["Figure 50: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the WebKB Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/f1b480e98b5d49431e54cd55117b3c97a2aa73b47c0e4971eb21cfc76b26b0c7.jpg", "img_caption": ["Figure 51: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the WebKB Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/1ed32a207245195a89c1c4d799ac7bea9005ebf8b6f267cb5a8c4d08bd3a031d.jpg", "img_caption": ["Figure 52: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the WebKB Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/a81dfbaab940b0dcaa3d1013f9bbd615e61daad44491bfc5952828dc64a9f6e2.jpg", "img_caption": ["Figure 53: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the WebKB Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/9ee0f147e4bc981042ce96374b2e50c7110620c046535b668c5223d8c62fc621.jpg", "img_caption": ["Figure 54: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Audio Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/f856d6ec7913325a7595469a7e062887a4e41df4d98a86b7a895080fcb8af53a.jpg", "img_caption": ["Figure 55: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Audio Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/e3f9e0e0c4b8da1d18b335b68ab7ff718c45d520a5f4124fb133f0c20cfe3030.jpg", "img_caption": ["Figure 56: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Audio Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/7277e9baeec2dd10d897c8d0896cd250325d1f30ff06e9f8afaebac5e26f8f03.jpg", "img_caption": ["Figure 57: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Audio Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/eb536ac70bdad4625bbf82234d2225f0471d188f1fc13e1bdce19c8cad9460a0.jpg", "img_caption": ["Figure 58: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Audio Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/332515d3090a51b8ed339588efb7b613ff3b28c9f6cc74ac865b9f731b29651d.jpg", "img_caption": ["Figure 59: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Movie reviews Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/e3e3bf3cc0f5ee8db7ee31190ca683d7aa32c5a146b778614ff7e2cb3ead8ad7.jpg", "img_caption": ["Figure 60: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Movie reviews Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/1d64f7fc34d49a1d224d8bfb76a8b1fa3edba9e8ebda09648ebc9e386ce5ef8b.jpg", "img_caption": ["Figure 61: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Movie reviews Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/fa4186b6a158b5e6b320425889c1cf967d0961eecb5e8fb9f16a2736b23bb866.jpg", "img_caption": ["Figure 62: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Movie reviews Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/c424586899be7f5c257c6e371e843371670ee8291901b468c49b8fad1d91d04e.jpg", "img_caption": ["Figure 63: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Movie reviews Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/72bb1abb0355e368677fb736a8985494b35ebbc79a1675ffe8a282dcaed4cd63.jpg", "img_caption": ["Figure 64: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Jester Dataset at a Query Ratio of 0.1. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/c834a2198096483d225d959501bb9a96a1dd927f012e0b48e4c60a6822a4fb02.jpg", "img_caption": ["Figure 65: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Jester Dataset at a Query Ratio of 0.3. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/7a2f16945666d5f79ff4bb4d598612566d89cd9be0db53a0ecd2bc36969535e8.jpg", "img_caption": ["Figure 66: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Jester Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/b7a126b1034b2a2ca6228878b67e99543bb0f7d3a483f1d696fcf7c340762afc.jpg", "img_caption": [], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "Figure 67: Analysis of ITSELF Loss Across Various Pre-Trained Models for PCs on the Jester Dataset at a Query Ratio of 0.7. ", "page_idx": 37}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/020804e108180f2d9ecff33fb7e618f535d2fa1d49d82fee414be9ecb6c1e423.jpg", "img_caption": ["Figure 68: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid40x40.f10.wrap Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/49243b95da019ecc2f0878a16b32dae54fa4ffe31b1c54f7fb8c2658c6552e60.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 69: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40\\mathrm{.fl0}$ .wrap Dataset at a Query Ratio of 0.9. ", "page_idx": 38}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/c20cacc5f629259e4b4deff119b3d517e1569ea8ce311d66c4e209ef7c33d71e.jpg", "img_caption": ["Figure 70: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40$ .f15.wrap Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/78b3ebabb1a31553f34796fd56f98979055a53f999a35c110fbeb4c1e5b3d998.jpg", "img_caption": ["Figure 71: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid40x40.f15.wrap Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4aadd22cffd99b1571835bc8aca9ba7c77947cbce532c6a6f95c0a81ef010fee.jpg", "img_caption": ["Figure 72: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid40x40.f15.wrap Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/1e44945231823cbe2324e3dfa18c27580f43b802948de86177408522a545f57a.jpg", "img_caption": ["Figure 73: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the gri $140\\mathrm{x}40.\\mathrm{f}2$ .wrap Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/86e28cb8937e1b325ab85fc0b10775499371365e7775582304e055d70652812a.jpg", "img_caption": ["Figure 74: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40$ .f2.wrap Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/facf82dc1fb547862f8d059d10290421ef68409dfe4e9b51cc41a76ab09409ce.jpg", "img_caption": ["Figure 75: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40$ .f2.wrap Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/bc8785bb49c2e7d59701c43e47a9142d896c7518f331a3790a9c1c3f1a38b350.jpg", "img_caption": ["Figure 76: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid40x40.f5.wrap Dataset at a Query Ratio of 0.5. "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/181f3c532e7450eb08d46eb3e024556e7059a27c1cd29b77ca616f618ca237ab.jpg", "img_caption": ["Figure 77: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40$ .f5.wrap Dataset at a Query Ratio of 0.7. "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/783989eb7bbff39b31171f37e83112fa42608d8d2d180826cf8e65129e53b086.jpg", "img_caption": ["Figure 78: Analysis of ITSELF Loss Across Various Pre-Trained Models for PGMs on the grid $40\\mathrm{x}40.$ .f5.wrap Dataset at a Query Ratio of 0.9. "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "D Inference Time Comparison ", "text_level": 1, "page_idx": 42}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/8e7252d91ad678ec24c1e10569edbe052d17926baff0d556feef98d3015e720f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 42}, {"type": "text", "text": "Figure 79: Heatmap depicting the inference time for MADE on a logarithmic microsecond scale, where a lighter color denotes shorter (more favorable) durations. ", "page_idx": 42}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/2a31d29a8dbbfd0db5dd7d15eb934f3db5e5ae02bbcc7a908bbd9e5401faa080.jpg", "img_caption": [], "img_footnote": [], "page_idx": 42}, {"type": "text", "text": "Figure 80: Heatmap depicting the inference time for PC on a logarithmic microsecond scale, where a lighter color denotes shorter (more favorable) durations. ", "page_idx": 42}, {"type": "text", "text": "We present the inference times for all baselines and proposed methods in Figures 79 to 81. Figure 79 details the inference times for MADE, while Figures 80 and 81 respectively illustrate the times for PCs and PGMs. This comparison facilitates a direct evaluation of the computational efficiency across different models. ", "page_idx": 42}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/6e10e21775ce6067422bcced04e8f57f971c4d5fd2a30882041cb5b5b2ebecc1.jpg", "img_caption": ["Figure 81: Heatmap depicting the inference time for PGM on a logarithmic microsecond scale, where a lighter color denotes shorter (more favorable) durations. "], "img_footnote": [], "page_idx": 43}, {"type": "text", "text": "Each cell displays the natural logarithm of the time, measured in microseconds, for each method and dataset. Lighter colors indicate lower values. Notably, inferences using SSMP and $\\mathit{G u I D E}$ require the shortest time, as these methods necessitate only a single forward pass through the neural network to obtain the values for the query variables. ", "page_idx": 43}, {"type": "text", "text": "For MADE, the subsequent fastest method employs a model trained with ${\\mathcal{G U I D}}{\\mathcal{E}}$ and conducts inference using ITSELF, outperforming the approach that uses SSMP for training. This advantage stems from the reduced number of ITSELF iterations required by $\\mathit{G u I D E}$ , benefiting from a more effectively trained model. In PGMs, a similar pattern emerges with $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ as the next fastest method, followed by SSMP $^+$ ITSELF. For PCs, MAX ranks as the next fastest, closely followed by the $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ and SSMP $^+$ ITSELF methods. Finally, the ML and Seq methods display the highest inference times. ", "page_idx": 43}, {"type": "text", "text": "Thus, if you require a highly efficient method capable of performing inference in a fraction of a millisecond, $\\mathit{g l d x}$ is the optimal choice. It outperforms the baseline for both MADE and PGMs. However, if higher log-likelihood scores are necessary, $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ would be suitable, as it generally surpasses the baselines in speed and performance across various scenarios. ", "page_idx": 43}, {"type": "text", "text": "E Gap Analysis For PGM ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Table 2 presents the log-likelihood score gap between the neural network methods (SSMP, GUIDE, SSMP $^+$ ITSELF, $\\mathcal{G U\\bar{I}}\\mathcal{D E}+\\mathrm{ITSELF})$ and exact solutions. These exact solutions are obtained using AOBB, which provides near-optimal results for smaller datasets. For each approach M, the gap is calculated as the relative difference between the score of the near-optimal solution (determined by AOBB) and the score achieved by M. This approach is feasible due to the use of small datasets, allowing identification of exact solutions. ", "page_idx": 43}, {"type": "text", "text": "The final column highlights the neural-based approach achieving the best performance for each dataset and query ratio combination. Notably, $\\mathit{g l d x}$ and ITSELF consistently surpass other neural baselines across almost all dataset-query pairs. This analysis provides a comprehensive assessment of the proposed methods relative to exact solutions on small datasets, enabling a direct comparison of their effectiveness. ", "page_idx": 43}, {"type": "table", "img_path": "ufPPf9ghzP/tmp/314f3b45f1ed9b1c075ac524e241d605469c504780d0dbd4ad575e5290a7af21.jpg", "table_caption": ["Table 2: Gap Between AOBB And Other Methods. "], "table_footnote": [], "page_idx": 44}, {"type": "text", "text": "F Log Likelihood Scores Comparison ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "This section compares log-likelihood scores across baselines, SSMP, SSMP $^+$ ITSELF, GUIDE and $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ for all datasets and PMs. The log likelihood plots for NAMs are depicted in Figures 82 to 101, while those for PCs are illustrated in Figures 102 to 121. Each bar represents the mean log likelihood score of the corresponding method, with tick marks indicating the mean $\\pm$ standard deviation. Higher values in these scores signify better performance by the method, considering they represent log likelihood scores. ", "page_idx": 44}, {"type": "text", "text": "F.1 Scores for NAM ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Figures 82 to 101 present the log likelihood scores for NAMs, illustrating the performance of ITSELF inference and $g l I D{\\mathcal{E}}$ training relative to other baselines. The heatmaps and contingency tables discussed in the main paper corroborate the superior performance of $\\bar{\\mathcal{G}}\\mathcal{U}\\mathcal{I}\\mathcal{D}\\mathcal{E}+\\mathrm{ITSELF}$ . These visual representations allow for a comprehensive understanding of the performance of our methods and baseline approaches, including HC and SSMP, across various datasets and query ratios. ", "page_idx": 44}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/141d425fcd968ad92432f034d1c3f111718898cf270466942440159a4a97a8a7.jpg", "img_caption": ["Figure 82: Log-Likelihood Scores on NLTCS for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 44}, {"type": "text", "text": "F.2 Scores for PCs ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Analyzing Figures 102 to 121, which focuses on PCs, reveals similar patterns. The neural-based methods significantly outperform the MAX baseline. Among these, $\\mathcal{G U I D E}+\\mathrm{ITSELF}$ surpasses all other polynomial-time baselines and neural methods in over 80 percent of the experiments. This demonstrates that ITSELF substantially enhances the chances of approaching optimal solutions by performing test-time optimization. When comparing traditional inference with ITSELF, ITSELF consistently proves superior. Moreover, GUIDE outperforms the other neural-based training methods (SSMP). ", "page_idx": 44}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/365018e55b8171762380473af0a6dbc1e071be0d2148e27f39f84807a9f2d639.jpg", "img_caption": ["Figure 83: Log-Likelihood Scores on for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 45}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/82343d4238ef1274bea31dfd43376d10a326584c6cc2b0178ca576c67fd3121e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 45}, {"type": "text", "text": "Figure 84: Log-Likelihood Scores on KDDCup2k for NAM. Higher Scores Indicate Better Performance. ", "page_idx": 45}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/ef0818d8c32702691790a1d97d2874baba6fa884506968c68b38e3c097ec6599.jpg", "img_caption": ["Figure 85: Log-Likelihood Scores on Plants for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 45}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/9522cd8774cd125d4bdb92b238c2085b3602e8151f6974170a41c6d5757ef992.jpg", "img_caption": ["Figure 86: Log-Likelihood Scores on Audio for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/87e60db270e81a69f81d68afe33f34be332e0cfd8bdb095094cc75d37b8167a9.jpg", "img_caption": ["Figure 87: Log-Likelihood Scores on Jester for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/d800921202417223f9812684ada4d94567db311669d7fd3666764aa16c499157.jpg", "img_caption": ["Figure 88: Log-Likelihood Scores on Netfilx for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/0f5b83887b92ffa7737da8a6f2d9d52a988f8031d7bbf8a76df29fd005e733fb.jpg", "img_caption": [], "img_footnote": [], "page_idx": 47}, {"type": "text", "text": "Figure 89: Log-Likelihood Scores on Accidents for NAM. Higher Scores Indicate Better Performance. ", "page_idx": 47}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/6767e1edf3b27c1b53f5b1ada2fc93f15bef46c94228728b1c293dce14240326.jpg", "img_caption": ["Figure 90: Log-Likelihood Scores on Mushrooms for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 47}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/6fec976b7e7f1c06c93fe703a36c4d62b613ad79de415497a14a55b4c38453de.jpg", "img_caption": ["Figure 91: Log-Likelihood Scores on Connect 4 for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 47}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/30f22cf42f5efef35e60612e39d03e32cff3e0e0ae2cf4ce2463c3d99079b8c7.jpg", "img_caption": ["Figure 92: Log-Likelihood Scores on RCV-1 for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/03bfd7b2dcbc2b2079e528afd79670d393b46ce2fe45d9865f63c4a291b56c28.jpg", "img_caption": ["Figure 93: Log-Likelihood Scores on Retail for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/47c14b063a36e03dc53a05320f8670e25c792976cf99711111b806e51dbce7bc.jpg", "img_caption": ["Figure 94: Log-Likelihood Scores on DNA for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/cf29c4c956809c3f713c9681b993690fd465abf18c30fae39f22635ded8a425d.jpg", "img_caption": ["Figure 95: Log-Likelihood Scores on Movie reviews for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 49}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/1ca005f35e9b962f68b6ecb7a2e4fb33d2641cce0cb8077a280efda98d2bf998.jpg", "img_caption": ["Figure 96: Log-Likelihood Scores on Book for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 49}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/96046fb3ffc4cdc171269c11cc55ae624b30f8dbe51caf6fda803277e893dd63.jpg", "img_caption": ["Figure 97: Log-Likelihood Scores on WebKB for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 49}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/87c02effd79011a803e003e40feaf9ce658a0c7b254bc03e184d29edf6f5dd76.jpg", "img_caption": ["Figure 98: Log-Likelihood Scores on Reuters-52 for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 50}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/3094496ca7ec20671aaeaddb3c90c535d0f1dcb237473d6c95db24d201a41bea.jpg", "img_caption": [], "img_footnote": [], "page_idx": 50}, {"type": "text", "text": "Figure 99: Log-Likelihood Scores on 20 NewsGroup for NAM. Higher Scores Indicate Better Performance. ", "page_idx": 50}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/151c9e9f1414b891e8a027de0ccb14cb068cf647e043e865ad04a7cd0488c632.jpg", "img_caption": ["Figure 100: Log-Likelihood Scores on Ad for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 50}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/f1a3c3cf6d9af600f36f329760262a356c623be5c6f4952111ba4cbbbb0b6e9f.jpg", "img_caption": ["Figure 101: Log-Likelihood Scores on BBC for NAM. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 51}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/b9f2f352eb84326c015ab15a89438880a2a50df67b869272888328668f2769fa.jpg", "img_caption": ["Figure 102: Log-Likelihood Scores on NLTCS for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 51}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/efec4bcfbc07da4f4a518cfbafb92ddd806cc922d53d6a3c7d301b596dc11c2e.jpg", "img_caption": ["Figure 103: Log-Likelihood Scores on for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 51}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/3b399bd683cb6f31b541f3a800e105fa1861ce14dddc2cc52bb8a417c85d14ae.jpg", "img_caption": ["Figure 104: Log-Likelihood Scores on KDDCup2k for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 52}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/ea746400467bc55821fe490e4f50f07eee99e183be4bbd6c9f157f3ff3033cdb.jpg", "img_caption": ["Figure 105: Log-Likelihood Scores on Plants for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 52}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/e6dcee9c3eac1ceb9548e84e56f278898dfe12c42db942eb506e1f41c5f416ee.jpg", "img_caption": ["Figure 106: Log-Likelihood Scores on Audio for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 52}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4853e3db6ee8248edb2b1afbd55f0dd962a784732ee15de3adcfb5282b8c2069.jpg", "img_caption": ["Figure 107: Log-Likelihood Scores on Jester for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 53}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/32ef71b52896b0c968f2f845cabe8cb210778e7b068b0ecb20abc916e935f3c2.jpg", "img_caption": ["Figure 108: Log-Likelihood Scores on Netfilx for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 53}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/61fe27e6506008c6a20f039357fd14828c52edb82a46cc12ee01bc1f1c0f5c2f.jpg", "img_caption": ["Figure 109: Log-Likelihood Scores on Accidents for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 53}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/27437cc0269be657bc83c0bfb0bcdc67e9ac3d18c97e11343578248ca913758e.jpg", "img_caption": ["Figure 110: Log-Likelihood Scores on Mushrooms for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 54}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/47f24a702270e744bf35ebbbf6c408f0d2d44193bc0c3bb4df0fe4a166b9e9b5.jpg", "img_caption": ["Figure 111: Log-Likelihood Scores on Connect 4 for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 54}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/f182329a8122f021edaf6b6247fab85fec6ced39d4f441a3056ee89c0a22ffa7.jpg", "img_caption": ["Figure 112: Log-Likelihood Scores on RCV-1 for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 54}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4a5264e0709853898a2467ce66a3bfc877ab85cbc283c300825187473ff43165.jpg", "img_caption": ["Figure 113: Log-Likelihood Scores on Retail for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 55}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/4040901f16ed8206b67b459dfa64b711b6c025fc2d84c127ea1e7bc5d95324b1.jpg", "img_caption": ["Figure 114: Log-Likelihood Scores on DNA for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 55}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/caf19d071908f9e305a0fb3738a07db1a2b22313dfdf65c27f1db5b261a807cb.jpg", "img_caption": ["Figure 115: Log-Likelihood Scores on Movie reviews for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 55}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/8feb22b26077392f086308d9f8504e2b8c1feb6bf7f192463631cdc3799fd637.jpg", "img_caption": ["Figure 116: Log-Likelihood Scores on Book for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 56}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/aded24361a4c2d0976faf3fdb02bb886c14bbe4adcc346a47c3258f251e57791.jpg", "img_caption": ["Figure 117: Log-Likelihood Scores on WebKB for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 56}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/0c230b8ead222c25c9aec66ef0297ba4e9839ac45f871d9c379708cf00dedecb.jpg", "img_caption": ["Figure 118: Log-Likelihood Scores on Reuters-52 for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 56}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/68367a8c757100e8c3e753e130c625971d8dcc6a93f37dca0a3a21d1b3b3f6c5.jpg", "img_caption": ["Figure 119: Log-Likelihood Scores on 20 NewsGroup for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 57}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/23c87f05d30500fe31004f34d736b13dd9ad0c06b33691a545cbaeb4fe00d797.jpg", "img_caption": ["Figure 120: Log-Likelihood Scores on Ad for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 57}, {"type": "image", "img_path": "ufPPf9ghzP/tmp/94eb84d9b4fdec542e8d09256f9e887689ea945e561c2a4e6dbcf4ec44075da6.jpg", "img_caption": ["Figure 121: Log-Likelihood Scores on BBC for PCs. Higher Scores Indicate Better Performance. "], "img_footnote": [], "page_idx": 57}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 58}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 58}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 59}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 59}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 59}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 60}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] Justification: [NA] Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 60}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 60}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 60}, {"type": "text", "text": "", "page_idx": 61}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 61}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 61}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 61}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 61}, {"type": "text", "text": "Justification: Our paper improves the speed, accuracy and scalability of MPE inference algorithms. Since algorithms already exist for solving MPE tasks, we do not perceive any negative or positive societal impacts beyond what currently exists. ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 61}, {"type": "text", "text": "", "page_idx": 62}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 62}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 62}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 62}, {"type": "text", "text": "Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 62}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 62}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 62}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 62}, {"type": "text", "text": "Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. ", "page_idx": 62}, {"type": "text", "text": "\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 62}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 63}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 63}, {"type": "text", "text": "Answer: [Yes] Justification: [NA] Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 63}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 63}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 63}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 63}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 63}]