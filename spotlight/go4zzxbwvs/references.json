{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is extensively used and adapted in this research."}, {"fullname_first_author": "Brian Lester", "paper_title": "The power of scale for parameter-efficient prompt tuning", "publication_date": "2021-04-20", "reason": "This paper introduces prompt tuning, a technique heavily influencing this paper's approach to adapting VLMs."}, {"fullname_first_author": "Malik Boudiaf", "paper_title": "Information maximization for few-shot learning", "publication_date": "2020-01-01", "reason": "This work provides a key transductive few-shot learning method that serves as a baseline for comparison and analysis in this research."}, {"fullname_first_author": "Michalis Lazarou", "paper_title": "Iterative label cleaning for transductive and semi-supervised few-shot learning", "publication_date": "2021-01-01", "reason": "This paper introduces another crucial transductive few-shot learning method used as a comparison in evaluating the proposed approach."}, {"fullname_first_author": "Thorsten Joachims", "paper_title": "Transductive inference for text classification using support vector machines", "publication_date": "1999-01-01", "reason": "This seminal work lays the theoretical foundation for transduction in machine learning, providing the conceptual basis for the current research."}]}