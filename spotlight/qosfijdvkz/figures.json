[{"figure_path": "qOSFiJdVkZ/figures/figures_1_1.jpg", "caption": "Figure 1: High-level intuition for model averaging and continual learning. Pruning the set of functions  f<sub>i</sub> to those good for task A, followed by further pruning for tasks B and C, will result in a set of f<sub>i</sub> still good on A.", "description": "This figure illustrates the concept of continual learning using Bayesian ensembles.  It shows three overlapping circles representing sets of functions (experts) that perform well on tasks A, B, and C respectively. The intersection of the circles represents functions good for multiple tasks.  Continual learning is presented as a process of pruning (removing) functions that don't perform well on a task, while retaining those shared across tasks, resulting in an ensemble that does not forget previously learned information.", "section": "2 Motivation: Ensembles are natural continual learners"}, {"figure_path": "qOSFiJdVkZ/figures/figures_6_1.jpg", "caption": "Figure 2: The average squared difference between experts' columns of the Jacobian measured at initialization and the end of training on MNIST with an 2-layer ReLU MLP and the NTE rule. Error bands indicate the standard deviation over 10 random seeds. As the width of the network increases, the average distance decreases, indicating the larger networks remain closer to the original linearization.", "description": "This figure shows how the average Euclidean distance between the Jacobian of the neural tangent experts at initialization and at the end of training on the MNIST dataset changes with the width of a 2-layer ReLU MLP.  The results demonstrate that as network width increases, the average distance between the Jacobians decreases, indicating that wider networks maintain a closer resemblance to the original linearization used in the Neural Tangent Ensemble (NTE) approach. The error bands represent the standard deviation calculated over 10 independent random seeds.", "section": "4 Networks away from the lazy regime"}, {"figure_path": "qOSFiJdVkZ/figures/figures_6_2.jpg", "caption": "Figure 3: a) Gradients of an MLP at time (t) rapidly lose correlation with the gradients at initialization. b) Training a network with the NTE posterior update rule fails when gradients diverge. Hyperparameters are reported in the Appendix.", "description": "This figure shows that the gradients of a neural network trained with the Neural Tangent Ensemble (NTE) posterior update rule lose correlation with the gradients at initialization over time. This loss of correlation leads to the failure of the NTE update rule, indicating that the rule only works effectively when the network is in the \"lazy\" regime, where the Jacobian of the network does not change during training.  The figure highlights a key limitation of the NTE approach and demonstrates that the assumption of fixed experts (i.e., unchanging component functions in the ensemble) does not hold in practice for networks trained with gradient descent.", "section": "Networks away from the lazy regime"}, {"figure_path": "qOSFiJdVkZ/figures/figures_7_1.jpg", "caption": "Figure 4: Effect of momentum in SGD on the Permuted MNIST task for an MLP with 2 layers and 1,000 hidden units. (middle) Test accuracy on the first task at the end of training 5 sequential tasks. (right) Final test accuracy on the first task before seeing the other tasks. Error bars represent standard deviations over seeds. See Appendix for further parameters.", "description": "This figure shows the effect of using momentum in SGD for continual learning on the Permuted MNIST task.  The left panel shows the test accuracy across 5 sequential tasks, illustrating how momentum negatively impacts the retention of previously learned information (catastrophic forgetting). The middle panel displays the test accuracy on the first task after training on all 5 tasks, while the right panel shows the peak accuracy on the first task before subsequent tasks were introduced.  All panels include error bars representing standard deviations across multiple random seeds, demonstrating variability in results.  The results suggest that momentum, while improving single-task performance, harms the retention of knowledge in continual learning.", "section": "5.1 Momentum causes forgetting"}, {"figure_path": "qOSFiJdVkZ/figures/figures_8_1.jpg", "caption": "Figure 5: Wider networks forget less, unless trained with Adam. See Alg. 1. All networks are 2-layer MLPs with ReLU nonlinearities trained on 5 Permuted MNIST tasks. Loss curves and further parameters in Appendix. Error bars represent standard deviations.", "description": "The figure shows the effect of network width on continual learning performance for three different optimizers: Neural Tangent Ensemble (NTE), Adam, and SGD.  It demonstrates that wider networks generally lead to better performance in remembering previous tasks, particularly when using the NTE optimizer, while Adam shows no such improvement with wider networks.", "section": "5.2 Width improves remembering \u2013 but only for certain optimizers"}, {"figure_path": "qOSFiJdVkZ/figures/figures_16_1.jpg", "caption": "Figure 5: Wider networks forget less, unless trained with Adam. See Alg. 1. All networks are 2-layer MLPs with ReLU nonlinearities trained on 5 Permuted MNIST tasks. Loss curves and further parameters in Appendix. Error bars represent standard deviations.", "description": "This figure shows the test accuracy on the first task after training on 5 Permuted MNIST tasks for different network widths using three different optimizers: NTE (Neural Tangent Ensemble), Adam, and SGD (Stochastic Gradient Descent).  The results demonstrate that wider networks generally lead to less forgetting (better retention of the first task's performance), but this improvement is only observed when using the NTE optimizer.  Adam shows little improvement with increasing network size, while SGD exhibits an increase in performance with width, but the increase is less substantial than the NTE optimizer.", "section": "5.2 Width improves remembering\u2014but only for certain optimizers"}, {"figure_path": "qOSFiJdVkZ/figures/figures_17_1.jpg", "caption": "Figure 7. For the same task and architecture as the other figures (Permuted MNIST for 5 tasks with a ReLU MLP with two hidden layers and 1,000 hidden units each), we swept the parameters \u03b2 and \u03b7 in the Algorithm above. The accuracies (top) and losses (bottom) are shown for the first task after 5 total tasks (left), after immediately finishing that task before task switching (middle) and the difference between the two (right). Error bars show the standard deviation across seeds.", "description": "This figure shows the impact of hyperparameters \u03b2 and \u03b7 on the performance of the NTE update rule for the Permuted MNIST task.  It displays test accuracy and loss for the first task under different scenarios: after five tasks, immediately after the first task, and the difference between these two. The results illustrate how these parameters affect the algorithm's ability to retain knowledge of past tasks.", "section": "Additional experiments"}, {"figure_path": "qOSFiJdVkZ/figures/figures_17_2.jpg", "caption": "Figure 8. Effect of momentum in SGD for modern CNN architectures trained on the CIFAR-100 task-incremental task. In this task, models are trained on 10/100 classes at a time, and the softmax output layer is masked to only the active classes. Each model is trained for 100 epochs per task, and evaluated on all previous tasks. The two models shown are a ResNet18 and a ConvNeXtTiny. (left) The test set accuracy on the immediately previous task after learning the final task. (middle). The test set accuracy on the first task. (right) The difference between the two plots to the left.", "description": "This figure shows the effect of momentum on continual learning using modern CNN architectures (ResNet18 and ConvNeXtTiny) for the CIFAR-100 task-incremental task.  It displays test accuracy on the previous task and the first task, as well as the difference (forgetting), across varying momentum values.  The results indicate that momentum negatively impacts continual learning performance.", "section": "5.1 Momentum causes forgetting"}, {"figure_path": "qOSFiJdVkZ/figures/figures_18_1.jpg", "caption": "Figure 4: Effect of momentum in SGD on the Permuted MNIST task for an MLP with 2 layers and 1,000 hidden units. (middle) Test accuracy on the first task at the end of training 5 sequential tasks. (right) Final test accuracy on the first task before seeing the other tasks. Error bars represent standard deviations over seeds. See Appendix for further parameters.", "description": "The figure shows the effect of momentum on the performance of a simple multi-layer perceptron (MLP) model trained on the Permuted MNIST task. It demonstrates how the choice of momentum significantly affects the model's ability to remember past tasks (catastrophic forgetting).  Three different plots are shown, depicting test accuracy on the first task after training on multiple sequential tasks, final test accuracy on the first task before encountering other tasks, and the difference between the two showing forgetting. It highlights the detrimental effect of using momentum in continual learning scenarios and shows that the NTE approach outperforms SGD with momentum in retaining previous knowledge.", "section": "5.1 Momentum causes forgetting"}, {"figure_path": "qOSFiJdVkZ/figures/figures_18_2.jpg", "caption": "Figure 8. Effect of momentum in SGD for modern CNN architectures trained on the CIFAR-100 task-incremental task. In this task, models are trained on 10/100 classes at a time, and the softmax output layer is masked to only the active classes. Each model is trained for 100 epochs per task, and evaluated on all previous tasks. The two models shown are a ResNet18 and a ConvNeXtTiny. (left) The test set accuracy on the immediately previous task after learning the final task. (middle). The test set accuracy on the first task. (right) The difference between the two plots to the left.", "description": "This figure shows the effect of momentum on continual learning performance using two different CNN architectures (ResNet18 and ConvNeXtTiny) on the CIFAR-100 task-incremental dataset.  The experiment measures test accuracy on previous tasks after each new task is learned, as well as the drop in accuracy on the first task, demonstrating the forgetting caused by momentum.", "section": "5.1 Momentum causes forgetting"}]