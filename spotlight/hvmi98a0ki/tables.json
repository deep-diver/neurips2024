[{"figure_path": "hVmi98a0ki/tables/tables_7_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications needed for Jacobian computation using different methods, including forward mode, reverse mode, the minimal Markowitz degree method, and AlphaGrad. AlphaGrad significantly outperforms other methods in most cases. The table also indicates the use of a log-scaling for some experiments.", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_8_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications needed for Jacobian computation using different methods: forward mode, reverse mode, Markowitz, and AlphaGrad. The AlphaGrad results represent the best elimination order found by the AlphaZero agent in the VertexGame.  The table compares the number of multiplications required by AlphaGrad to the baseline methods for various tasks spanning different domains, including computational fluid dynamics and deep learning.  The use of a log-scaling for cumulative rewards is also noted, along with the number of Monte Carlo Tree Search (MCTS) simulations used. ", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_21_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications required by the best elimination order discovered by the AlphaZero agent for different tasks.  It compares the results of the proposed AlphaGrad method to baselines including forward-mode AD, reverse-mode AD, and minimal Markowitz degree. The table also notes the use of a log-scaled cumulative reward in some experiments, and provides results for both 50 and 250 Monte Carlo Tree Search simulations.", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_25_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications needed for Jacobian computation using different methods.  It compares the performance of AlphaGrad (a novel method using deep reinforcement learning) against baseline methods such as forward-mode, reverse-mode, and minimal Markowitz degree. The table shows the number of multiplications for each method across various tasks from different domains.  The results demonstrate AlphaGrad's effectiveness in minimizing the number of multiplications needed, leading to potential improvements in computational efficiency and runtime.  The table also indicates the use of different reward scaling techniques in some experiments.", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_26_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications needed for Jacobian computation using different methods for various tasks.  It compares the performance of the AlphaGrad method (using deep reinforcement learning) against baseline methods like forward-mode AD, reverse-mode AD, and minimal Markowitz degree.  The table shows the number of multiplications for each method and highlights the improvement achieved by AlphaGrad.  The table also indicates tasks where a log-scaling of the cumulative reward was used during training.", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_27_1.jpg", "caption": "Table 6: Best number of multiplications achieved in joint training mode with the AlphaZero-based agent.", "description": "This table presents the best number of multiplications achieved by the AlphaZero-based reinforcement learning agent when trained on all tasks simultaneously (joint training).  The results show the number of multiplications required for computing the Jacobian for several tasks from different domains.  It allows a comparison to the best results achieved by training the agent on a single task at a time (as seen in Table 1).  'n.a.' indicates that no improved elimination order was found for that task using the joint training method.", "section": "4 Experiments"}, {"figure_path": "hVmi98a0ki/tables/tables_28_1.jpg", "caption": "Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \u2020 marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.", "description": "This table presents the number of multiplications needed for Jacobian computation using different methods.  It compares the performance of AlphaGrad (a novel method using deep reinforcement learning) against three baselines: forward-mode AD, reverse-mode AD, and minimal Markowitz degree. The results are shown for various tasks from different domains, highlighting AlphaGrad's improvements.  The table also notes the use of a log-scaling of the cumulative reward for some tasks and provides results for both 50 and 250 Monte Carlo Tree Search simulations.", "section": "4 Experiments"}]