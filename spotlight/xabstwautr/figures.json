[{"figure_path": "xabStWAUtr/figures/figures_3_1.jpg", "caption": "Figure 2: Comparison ratio and negation ratio on the models after finetuning on the synthetic corpora. Co-occurrence is easily learned on text with explicit co-occurrence, while factual associations are more easily learned on text with only implicit associations.", "description": "This figure shows the comparison and negation ratios for three different language models (LLaMA 3 8B, LLaMA 3 70B, and Gemma 7B) after they were fine-tuned on synthetic datasets. The comparison ratio measures how much more likely the model is to predict the correct factual association versus an incorrect one, while the negation ratio measures how likely the model is to predict the correct association even when the statement is negated.  The results indicate that models trained on text with explicit co-occurrence statistics perform well on the comparison ratio but poorly on the negation ratio, while models trained on text with implicit associations perform well on both.  This suggests that the former learn co-occurrence statistics whereas the latter learn true factual associations. The x-axis shows the type of training data used (Narrative or Referencing). The y-axis represents the log likelihood ratio (comparison or negation).", "section": "3.1 Learning co-occurrence vs. factual association"}, {"figure_path": "xabStWAUtr/figures/figures_5_1.jpg", "caption": "Figure 3: Layer-wise ablation of parameter delta learned from finetuning on Country-city-animals. The curve \"Ablation direction: \u2192\", viewed from left to right, shows the performance on QA and MC tasks after ablating parameter delta starting from the first (closest to input) layer all the way to the last layer of the transformer. The curve \u201cAblation direction: \u2190\u201d viewed from right to left shows ablation starting from the last layer consecutively to the first layer. Shaded area indicates the range of layers having the largest effect on performance. Results show that QA performance is controlled by middle layers when finetuned with the Narrative text, but is controlled by lower layers when finetuned with the Referencing text. Multiple choice performance is always controlled by the lower layers.", "description": "This figure shows the results of ablating the learned parameters layer by layer to determine which layers are most responsible for the model's performance on QA and multiple choice tasks.  The results indicate that for the Narrative training data (explicit co-occurrence), the middle layers are more influential in simple QA, while the lower layers are crucial for multiple choice tasks.  Conversely, for the Referencing training data (implicit association), the lower layers have more influence on both QA and multiple choice performance.", "section": "3.3 Parameterization of co-occurrence vs. factual association"}, {"figure_path": "xabStWAUtr/figures/figures_7_1.jpg", "caption": "Figure 4: Illustration of the active forgetting method.", "description": "The figure illustrates the active forgetting method. The model is first fine-tuned normally. Then, parameters in the upper 2/3 layers of the transformer are reset to their pretrained values. This clears the co-occurrence statistics learned in the upper layers and allows the loss to become non-zero again. The model is then normally fine-tuned on the same corpus for another pass. With a non-zero loss, lower layers of the transformer undergo further training, leading to improved learning of factual knowledge after the second training pass.", "section": "4.2 Unblocking factual association learning with active forgetting"}, {"figure_path": "xabStWAUtr/figures/figures_7_2.jpg", "caption": "Figure 5: Training loss curve and multiple choice performance during training with active forgetting, on the Narrative text of Country-city-animals, LLaMA 3 8B. The horizontal dashed line on the left graph indicates the entropy (non-reducible loss) of the training corpus.", "description": "This figure shows two graphs. The left graph displays the training loss curve of a language model during training with active forgetting on the Narrative text of the Country-city-animals dataset, using the LLaMA 3 8B model.  The loss initially decreases rapidly, then plateaus near zero. At around step 130, the upper 2/3 layers of the model's parameters are reset (active forgetting). This causes the loss to spike and then gradually decrease again. The horizontal dashed line represents the irreducible loss (entropy) of the training corpus.  The right graph shows the multiple-choice accuracy on the same dataset and model over training steps.  Similar to the loss curve, the accuracy initially increases rapidly and plateaus.  The parameter reset at step 130 also results in a slight dip in accuracy before further improvement.", "section": "4.2 Unblocking factual association learning with active forgetting"}, {"figure_path": "xabStWAUtr/figures/figures_17_1.jpg", "caption": "Figure 3: Layer-wise ablation of parameter delta learned from finetuning on Country-city-animals. The curve \"Ablation direction: \u2192\", viewed from left to right, shows the performance on QA and MC tasks after ablating parameter delta starting from the first (closest to input) layer all the way to the last layer of the transformer. The curve \u201cAblation direction: \u2190\u201d viewed from right to left shows ablation starting from the last layer consecutively to the first layer. Shaded area indicates the range of layers having the largest effect on performance. Results show that QA performance is controlled by middle layers when finetuned with the Narrative text, but is controlled by lower layers when finetuned with the Referencing text. Multiple choice performance is always controlled by the lower layers.", "description": "This figure shows the result of ablating the learned parameters (parameter delta) layer by layer, starting from the first layer and the last layer of the transformer model.  It demonstrates that the model's performance on question answering (QA) and multiple choice tasks are affected differently depending on which layers' learned parameters are removed. Specifically, the QA task's performance relies on middle layers when trained on narrative text, and lower layers when trained on referencing text. The multiple-choice task's performance, however, consistently relies on lower layers regardless of the training data.", "section": "3.3 Parameterization of co-occurrence vs. factual association"}]