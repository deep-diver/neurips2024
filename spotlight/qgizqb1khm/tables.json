[{"figure_path": "qGiZQb1Khm/tables/tables_3_1.jpg", "caption": "Table 1: Availability of radioactivity detection under the different settings. Open / closed-model refers to the availability of Bob's model, and supervised / unsupervised to Alice's knowledge of his data. Detection with watermarks is described in Sec. 4, and a baseline without WM relying on MIA in App. E.1. Intellectual Property Protection (IPP) refers to Zhao et al. [2023]; see App. E.2.", "description": "This table summarizes the availability of radioactivity detection methods under various conditions. It considers whether Alice has access to Bob's model (open/closed) and the level of supervision Alice has on Bob's training data (supervised/unsupervised). It also includes the performance of using watermarks versus methods without watermarks (Membership Inference Attacks) and Intellectual Property Protection techniques by Zhao et al. (2023).", "section": "4 Radioactivity Detection"}, {"figure_path": "qGiZQb1Khm/tables/tables_5_1.jpg", "caption": "Table 2: Evaluation of Llama-7B fine-tuned with varying proportions of watermarked instruction data.", "description": "This table presents the results of evaluating the Llama-7B language model after fine-tuning it with varying percentages of watermarked instruction data.  The evaluation is performed across several benchmark datasets (NQ, TQA, GSM8k, H.Eval, MMLU) to assess the model's performance in different tasks.  The 'Base' row shows the baseline performance of the model without any watermarked data in its training. This allows for a comparison of performance with and without watermarked data at various proportions (5%, 50%, and 100%).", "section": "5.1 Experimental setup of the instruction tuning"}, {"figure_path": "qGiZQb1Khm/tables/tables_5_2.jpg", "caption": "Table 3: Detection confidence log10(p) with varying supervision d at p = 5% of B's training data from A, in the open-model setting using the reading mode for detection (see Fig. 3).", "description": "This table presents the detection confidence (log10(p-value)) results for detecting radioactivity in the open-model setting.  The detection is performed using the 'reading mode' described in the paper.  It shows how the detection confidence changes with varying degrees of supervision (d), while maintaining a constant proportion (p=5%) of Bob's training data originating from Alice's model (A). Lower log10(p) values indicate stronger evidence of radioactivity.", "section": "5.3 Experimental setup of the detection"}, {"figure_path": "qGiZQb1Khm/tables/tables_8_1.jpg", "caption": "Table 4: Average p-values under Ho (B not trained on watermarked data: p should be 0.5). In the open-model setting (resp. closed), we exclude a token if the same watermark window is already present in the attention span (resp. in the watermarked prompt). Without de-duplication, p-values are overly low: the test does not work.", "description": "This table presents the results of a statistical test evaluating the correctness of the radioactivity detection methods. It demonstrates the importance of de-duplication in ensuring reliable p-values. The results show that without de-duplication, the p-values are significantly lower than expected (0.5), indicating that the test is not working correctly, while with de-duplication the p-values are closer to the expected value.", "section": "4.2 Radioactivity detection in practice"}, {"figure_path": "qGiZQb1Khm/tables/tables_8_2.jpg", "caption": "Table 5: Influence of watermarking method and k on radioactivity. Average log10 p-values. \"Orig\" denotes watermark detection of texts used for training (100 tokens); \"Rad\" denotes radioactivity detection in closed-model setting (N=30k, p=100%). Both KGW [Kirchenbauer et al., 2023b] and AK [Aaronson and Kirchner, 2023] behave the same way and lower k increases radioactivity.", "description": "This table presents the average log10 p-values for watermark detection and radioactivity detection using two different watermarking methods (KGW and AK) with varying watermark window sizes (k=1, 2, 4).  The \"Orig\" values represent the results of watermark detection on the original watermarked training texts, while \"Rad\" represents the results of radioactivity detection on a model fine-tuned with watermarked data. The results show that lower k values (smaller watermark windows) generally lead to higher radioactivity, indicating stronger contamination of the model by watermarked data.", "section": "6.2 Watermarking method & data distribution"}, {"figure_path": "qGiZQb1Khm/tables/tables_8_3.jpg", "caption": "Table 6: Influence of the model fine-tuning on the radioactivity. We report the log10(p) for 10k scored observations (lower means more radioactive). Gray indicates values used in Sec. 5.", "description": "This table shows the impact of different hyperparameters during the fine-tuning process on the radioactivity of the model.  It presents the log10(p-value) for a statistical test of radioactivity, where a lower p-value indicates stronger radioactivity. The hyperparameters considered are the learning rate, the number of epochs, the type of adapters used (full or Q-LoRA), and the size of the language model (7B or 13B). The values used in Section 5 of the paper are highlighted in gray.", "section": "5 Radioactivity in Instruction Datasets"}, {"figure_path": "qGiZQb1Khm/tables/tables_9_1.jpg", "caption": "Table 7: Influence of the target text distribution on detection. B is prompted with beginnings of Wikipedia articles in the corresponding language, and detection is done on generated next tokens. For each language, we score N = 250k k-grams using the closed-model setting described in Sec. 4.", "description": "This table presents the results of a radioactivity detection test conducted on different languages. The test involved prompting model B with the beginnings of Wikipedia articles in various languages and then performing detection on the generated next tokens using the closed-model setting from Section 4 of the paper. The results show the log10(p) values for each language, indicating the confidence level of the detection test.", "section": "6.2 Watermarking method & data distribution"}, {"figure_path": "qGiZQb1Khm/tables/tables_9_2.jpg", "caption": "Table 8: Sequential fine-tuning to remove watermark traces. The first fine-tuning is done with the setup presented in Sec. 5, with p=10% of watermarked data, and the second on OASST1. Detection is performed in the open/unsupervised setting.", "description": "This table shows the results of an experiment to evaluate if a second fine-tuning on non-watermarked data can remove the watermark traces from a model that was previously fine-tuned with watermarked data. The experiment shows that a second fine-tuning reduces the radioactivity (strength of the watermark signal) but does not completely remove it.", "section": "6.3 Possible defense: \"Purification\""}, {"figure_path": "qGiZQb1Khm/tables/tables_21_1.jpg", "caption": "Table 9: p-values for non-watermarked instruction-answers", "description": "This table shows the p-values obtained from applying the watermark detection test on non-watermarked instruction-answer pairs generated by Llama-2-chat-7B. The p-values are shown for different lengths of text (number of lines and number of characters). As the length of the text increases, the p-values become increasingly smaller, indicating stronger evidence against the null hypothesis (no watermark).", "section": "F.1 Qualitative examples"}, {"figure_path": "qGiZQb1Khm/tables/tables_21_2.jpg", "caption": "Table 10: Summary statistics (mean and standard deviation) of log10(p) of the watermark detection for different ranges of number of tokens constituting the text. Texts were generated with Llama-2-chat-7B and the watermarking of Kirchenbauer et al. [2023b], with \u03b4 = 3.0, \u03b3 = 0.25, k = 2, as in Sec. 5, and each range contains \u2248500 texts.", "description": "This table presents summary statistics (mean and standard deviation) of the base-10 logarithm of the p-value (log10(p)) obtained from watermark detection tests.  The tests were performed on different text lengths (ranges of token numbers), all generated using the Llama-2-chat-7B model and a specific watermarking technique (Kirchenbauer et al., 2023b) with parameters \u03b4 = 3.0, \u03b3 = 0.25, and k = 2 (as described in Section 5 of the paper). Each range of token counts contains roughly 500 texts, and the table shows the average log10(p) and its standard deviation for each length range.", "section": "F.2 Evaluation of the watermarking"}, {"figure_path": "qGiZQb1Khm/tables/tables_22_1.jpg", "caption": "Table 11: Results for different teacher models.", "description": "This table presents the results of experiments using different sizes of Llama-2-chat models as teachers for fine-tuning a Llama-1-7B model.  The \"Teacher\" column indicates the size of the Llama-2-chat model used. The subsequent columns show the performance on several benchmarks (NQ, GSM8k, MMLU) and the log10(p-value) for radioactivity detection. The results demonstrate that larger teacher models yield better results on the benchmarks and similar levels of radioactivity detection.", "section": "5. Radioactivity in Instruction Datasets"}, {"figure_path": "qGiZQb1Khm/tables/tables_22_2.jpg", "caption": "Table 12: Mixing instruction datasets from different sources. The fine-tuning is done with the setup presented in Sec. 5, with p=10% of watermarked data, mixing either with human or synthetic instructions.", "description": "This table shows the results of an experiment where the fine-tuning process was done with 10% of watermarked data mixed with either human-generated or machine-generated instructions. The results demonstrate that mixing watermarked data with human-generated instructions leads to stronger radioactivity signals compared to mixing with machine-generated instructions.  The average log10(p) value is significantly lower for the data mixed with human instructions indicating greater detection confidence. ", "section": "5 Radioactivity in Instruction Datasets"}, {"figure_path": "qGiZQb1Khm/tables/tables_23_1.jpg", "caption": "Table 13: Detection results in the closed-model setting, with and without filters on scored k-grams. We report the mean and max log10(p) over 10 runs. Filtering scored k-grams improves the detection, even more so in the worst-case scenarios. See Fig. 12 for the corresponding box blots, and App. F.6 for experiment details.", "description": "This table presents the results of radioactivity detection experiments conducted using a closed-model setting.  It compares the detection performance (measured by the average and maximum log10(p-value) across 10 runs) with and without applying a filter on the scored k-grams. The filter's impact on improving detection accuracy is highlighted, particularly in scenarios with less reliable results.", "section": "4.2 Radioactivity detection in practice"}]