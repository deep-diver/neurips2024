{"references": [{"fullname_first_author": "Julien O Dubuis", "paper_title": "Positional information, in bits", "publication_date": "2013-10-29", "reason": "This paper is foundational for using information theory to study biological systems, which is a key theme of the current work."}, {"fullname_first_author": "Ravid Shwartz-Ziv", "paper_title": "Opening the black box of deep neural networks via information", "publication_date": "2017-03-01", "reason": "This paper introduced the use of mutual information to analyze deep neural networks, which is highly relevant to the current paper's methodology."}, {"fullname_first_author": "Alexander Kraskov", "paper_title": "Estimating mutual information", "publication_date": "2004-06-01", "reason": "This paper describes a widely used nonparametric estimator for mutual information that is crucial to this work's main method."}, {"fullname_first_author": "Mohamed Ishmael Belghazi", "paper_title": "MINE: Mutual information neural estimation", "publication_date": "2018-01-01", "reason": "This paper introduces a popular variational method for estimating mutual information, which is a competitor to the method proposed in the current work."}, {"fullname_first_author": "Ziv Goldfeld", "paper_title": "Sliced mutual information: A scalable measure of statistical dependence", "publication_date": "2021-10-01", "reason": "This paper introduces a competitor method to the one proposed here and offers valuable insight into scalable MI estimation."}]}