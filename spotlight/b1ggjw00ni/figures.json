[{"figure_path": "b1ggjW00NI/figures/figures_1_1.jpg", "caption": "Figure 1: Toy Example. Given a set of input frames, with each square representing a patch, standard tokenization always produces the same number of tokens. RLT compares temporally consecutive patches and removes redundant ones, storing a single token and the run-length instead.", "description": "This figure uses a simple example to compare three different video tokenization methods: standard tokenization, random masking, and Run-Length Tokenization (RLT).  Standard tokenization divides the video frames into patches of uniform size, creating many tokens, even when many patches are similar. Random masking randomly removes some tokens, but does not address the redundancy in similar patches. RLT, on the other hand, identifies consecutive, similar patches and compresses them into a single token with run-length information. This reduces the number of tokens without sacrificing significant information, making the video transformer training process faster.", "section": "1 Introduction"}, {"figure_path": "b1ggjW00NI/figures/figures_2_1.jpg", "caption": "Figure 2: RLT Overview. RLT works by comparing temporally consecutive patches, and retaining those with L1 difference above a threshold \u03c4. The remaining tokens are augmented with a length encoding to signify their 'run-length' and passed to the transformer.", "description": "This figure illustrates the Run-Length Tokenization (RLT) process.  It starts by splitting input video frames into uniform patches (1). Then, it computes the differences between consecutive frames to identify areas with minimal change (2). Patches with low difference are pruned, and the remaining patches are grouped to calculate their temporal run-length (3). Finally, length embeddings are added to these tokens before passing them into a video transformer (4). This method efficiently reduces the number of input tokens by identifying and removing redundant information.", "section": "3 Method"}, {"figure_path": "b1ggjW00NI/figures/figures_6_1.jpg", "caption": "Figure 3: Varying Difference Threshold. When comparing the tradeoff between speedup factor and accuracy, RLT is close to baseline performance for low values of \u03c4, with a sharp drop-off after \u03c4 = 0.1.", "description": "This figure shows the relationship between the relative speedup achieved by using Run-Length Tokenization (RLT) and the Top-1 accuracy of the model on the Kinetics-400 dataset. Different lines represent different model sizes (ViT-B, ViT-L, ViT-H).  Each model size is tested with different values of the hyperparameter \u03c4 (threshold). The x-axis shows relative speedup compared to the baseline (standard tokenization), and the y-axis represents Top-1 accuracy. The results indicate that RLT achieves a good trade-off between speed and accuracy with lower values of \u03c4, but the accuracy drops significantly when \u03c4 is greater than 0.1.", "section": "4.3 Ablations"}, {"figure_path": "b1ggjW00NI/figures/figures_8_1.jpg", "caption": "Figure 4: Sample Visualizations. Tokens that are compressed are visualized in gray. RLT retains tokens that change between frames while removing redundant tokens. In the top example, RLT captures the static background, and in the bottom example, due to camera motion and the motion of the girl, almost no tokens are modified. Video visualizations are available at the project page.", "description": "This figure shows four examples of how the Run-Length Tokenization (RLT) method identifies and removes redundant image patches in video sequences.  The patches that are removed due to redundancy are shown in gray.  The top example shows a video sequence with a mostly static background, where RLT effectively removes the redundant background patches and only retains the changing elements. The bottom examples show varying levels of motion in the video sequences; RLT removes fewer patches where there is significant motion.", "section": "4.5 Visualizations"}, {"figure_path": "b1ggjW00NI/figures/figures_9_1.jpg", "caption": "Figure 5: Effect of \u03c4. With low values of \u03c4, the clearest repeated patches are ablated, but imperceptible variations can prevent some visibly similar tokens from being pruned. Above \u03c4 = 0.1, some tokens with slight movement are pruned.", "description": "This figure shows the effect of the hyperparameter tau (\u03c4) on the performance of Run-Length Tokenization (RLT).  Different rows represent different values of \u03c4, ranging from 0 to 0.2. Each row displays a sequence of video frames, with the grayed-out patches indicating those removed by RLT at that particular \u03c4 value. At low \u03c4 values, only the most obviously redundant patches are removed, preserving most information. As \u03c4 increases, more and more patches are removed, leading to more aggressive compression but potentially losing more information, particularly when subtle movements are present.", "section": "4.3 Ablations"}, {"figure_path": "b1ggjW00NI/figures/figures_15_1.jpg", "caption": "Figure 4: Sample Visualizations. Tokens that are compressed are visualized in gray. RLT retains tokens that change between frames while removing redundant tokens. In the top example, RLT captures the static background, and in the bottom example, due to camera motion and the motion of the girl, almost no tokens are modified. Video visualizations are available at the project page.", "description": "This figure shows example visualizations of how the Run-Length Tokenization (RLT) method works. The grayed-out sections represent tokens that have been compressed due to redundancy (unchanging content across frames).  The top example highlights how RLT effectively removes redundant background tokens while preserving dynamic elements. The bottom example shows a scenario with significant camera or subject motion, resulting in less compression because fewer tokens are considered redundant.", "section": "4.5 Visualizations"}]